\documentclass[12pt,a4paper]{article}
    \usepackage[utf8]{inputenc}
    \usepackage[T1]{fontenc}
    \usepackage{amsmath,amsfonts,amssymb}
    \usepackage{graphicx}
    \usepackage[margin=2.5cm]{geometry}
    \usepackage{setspace}
    \usepackage{natbib}
    \usepackage{url}
    \usepackage{hyperref}
    \usepackage{booktabs}
    \usepackage{longtable}
    \usepackage{array}
    \usepackage{multirow}
    \usepackage{wrapfig}
    \usepackage{float}
    \usepackage{colortbl}
    \usepackage{pdflscape}
    \usepackage{tabu}
    \usepackage{threeparttable}
    \usepackage{threeparttablex}
    \usepackage[normalem]{ulem}
    \usepackage{makecell}
    \usepackage{xcolor}

    % Set line spacing
    \doublespacing

    % Configure hyperref
    \hypersetup{
        colorlinks=true,
        linkcolor=blue,
        filecolor=magenta,      
        urlcolor=cyan,
        citecolor=red,
    }

    % Title and author information
    \title{A Comprehensive Literature Review with Self-Reflection}
    \author{Literature Review}
    \date{\today}

    \begin{document}

    \maketitle

    % Abstract (optional)
    \begin{abstract}
    This literature review provides a comprehensive analysis of recent research in the field. The review synthesizes findings from 92 research papers, identifying key themes, methodological approaches, and future research directions.
    \end{abstract}

    \newpage
    \tableofcontents
    \newpage

    \label{sec:1._introduction}

\section{Introduction}
Knowledge Graphs (KGs) have emerged as a powerful and intuitive paradigm for representing structured knowledge, capturing real-world entities and their intricate relationships in a machine-readable format \cite{buehler2024, mathur2024}. Organized as collections of factual triples, typically in the form of (head entity, relation, tail entity), KGs provide a rich semantic foundation that underpins various artificial intelligence (AI) applications. From organizing vast scientific literature to enabling sophisticated reasoning in multi-agent systems, KGs offer a structured yet flexible framework for knowledge representation \cite{rubaiat2025, ghafarollahi2024}. However, the symbolic nature of KGs presents a fundamental challenge for computational models that operate in continuous vector spaces. This necessitates the transformation of symbolic knowledge into dense, low-dimensional vector embeddings, a process known as Knowledge Graph Embedding (KGE). KGE aims to represent entities and relations as vectors or matrices, such that the structural and semantic properties of the KG are preserved, thereby facilitating computational reasoning and generalization. This review delves into the foundational concepts of KGE, its critical role in advancing AI capabilities, and the diverse landscape of models and applications that have emerged in this rapidly evolving field.

\subsection{Background: Knowledge Graphs and Their Significance}
Knowledge Graphs serve as a cornerstone for intelligent systems by providing a structured representation of information, moving beyond unstructured text to explicitly define entities and their relationships \cite{buehler2024}. This structured format, typically comprising triples $(h, r, t)$, where $h$ is the head entity, $r$ is the relation, and $t$ is the tail entity, allows for clear semantic interpretation and facilitates automated reasoning. The significance of KGs spans numerous domains, from general-purpose knowledge bases like Freebase and WordNet to specialized applications in scientific discovery and materials engineering. For instance, in materials science, KGs can integrate diverse data sources, such as experimental results, simulation data, and theoretical models, to accelerate the design and discovery of novel materials \cite{ghafarollahi2024, ghafarollahi2025}. Similarly, in domains like agriculture, KGs can model complex relationships between crops, environmental factors, and suitable populations, as demonstrated by the TeaPle dataset for tea varieties \cite{li2025}. The explicit encoding of relationships within KGs enables systems to perform complex queries, infer new facts, and understand contextual information, which is crucial for developing robust and interpretable AI solutions. The ability to integrate and reason over heterogeneous information makes KGs indispensable for tasks requiring a deep understanding of domain-specific knowledge, thereby bridging the gap between human-understandable facts and machine-processable data structures \cite{mathur2024, rubaiat2025}.

\subsection{The Role of Knowledge Graph Embedding}
Despite their power, the symbolic nature of KGs poses a challenge for many machine learning algorithms that operate on continuous numerical data. Knowledge Graph Embedding (KGE) addresses this by projecting entities and relations into a continuous, low-dimensional vector space, allowing for efficient computation and generalization \cite{wang2014}. The fundamental problem in KGE is to learn representations (embeddings) that accurately capture the semantic and structural properties of the KG, such that plausible triples are assigned higher scores than implausible ones. Early KGE models, such as TransE, conceptualized relations as translation vectors in the entity embedding space, aiming for $h + r \approx t$ \cite{wang2014}. However, these models struggled with complex relation patterns like one-to-many, many-to-one, and reflexive relations. This limitation led to the development of more sophisticated models like TransH, which projects entities onto relation-specific hyperplanes before translation, thereby allowing entities to have different representations depending on the relation \cite{wang2014}. Further advancements introduced relation-adaptive translation functions, such as RatE, which utilize weighted products in complex space to enhance modeling capacity and explicitly alleviate embedding ambiguity in one-to-many relations \cite{huang2020}.

The importance of KGE extends to a wide array of AI tasks:
\begin{itemize}
    \item \textbf{Link Prediction:} This is a core application of KGE, aiming to predict missing entities or relations in incomplete KGs. Models like GNN-FTuckER combine Graph Neural Networks (GNNs) with tensor decomposition to capture rich semantic and structural information for tasks like identifying suitable populations for tea varieties \cite{li2025}. Similarly, in Temporal Knowledge Graphs (TKGs), models like TCompoundE and RotateQVS leverage compound geometric operations or quaternion vector spaces to capture complex temporal evolution patterns and predict missing facts over time \cite{ying2024, chen2022, sadeghian2021, chen2023, dileo2023}. The ability of KGE models to extrapolate to unseen data, driven by semantic evidence, further underscores their utility in completing dynamic and evolving knowledge bases \cite{li2021}.
    \item \textbf{Question Answering (QA):} KGE facilitates QA systems by enabling the retrieval and reasoning over relevant facts. By embedding knowledge, systems can efficiently match natural language queries to KG facts, even supporting logical query answering with fuzzy logic \cite{chen2021}.
    \item \textbf{Recommendation Systems:} KGE enhances recommendation systems by modeling user-item interactions and item attributes within a KG, allowing for more personalized and context-aware recommendations.
    \item \textbf{Scientific Discovery:} KGE plays a crucial role in accelerating scientific discovery by providing structured representations for complex scientific data. For example, KGE can be integrated into multi-agent AI systems for autonomous materials discovery, enabling rapid alloy design and property prediction by learning from atomistic simulations \cite{ghafarollahi2024, ghafarollahi2025}.
\end{itemize}
The ongoing development of KGE models, including those addressing temporal dynamics \cite{cai2024, cai2024} and continual learning challenges \cite{zhu2025, li2025, liu2024, sun2025}, highlights the field's commitment to creating robust and adaptable knowledge representation techniques.

\subsection{Scope and Organization of the Review}
This review aims to provide a comprehensive overview of Knowledge Graph Embedding, focusing on its foundational principles, diverse model architectures, and critical applications. We will synthesize information from recent advancements, critically evaluating the strengths and limitations of various approaches. The primary focus is on how KGE models represent entities and relations, their ability to capture complex patterns, and their performance in downstream AI tasks. We will explore different taxonomies of KGE models, including translation-based, semantic matching, and geometric models, as well as emerging directions such as temporal and continual KGE.

The remainder of this review is structured as follows: Section 2 will delve into the foundational KGE models, categorizing them by their underlying mechanisms and discussing their evolution. Section 3 will focus on advanced KGE architectures, including those leveraging neural networks and graph convolutional networks, and their capacity to capture richer semantic and structural information. Section 4 will explore specialized KGE paradigms, such as Temporal KGE and Continual KGE, addressing the challenges of dynamic and evolving knowledge graphs. Section 5 will discuss the critical applications of KGE across various AI domains, providing specific examples and performance benchmarks. Finally, Section 6 will offer a critical analysis of current challenges, limitations, and promising future research directions in the field of Knowledge Graph Embedding.

\label{sec:2._foundational_knowledge_graph_embedding_models:_translational_and_geometric_paradigms}

\section{Foundational Knowledge Graph Embedding Models: Translational and Geometric Paradigms}
The initial wave of Knowledge Graph Embedding (KGE) research laid the groundwork for representing symbolic knowledge in continuous vector spaces, primarily through the translational paradigm. These foundational models, exemplified by TransE, conceptualized relations as simple translation vectors, aiming to satisfy the geometric principle $h + r \approx t$ for a valid triple $(h, r, t)$. While elegant and efficient, these early approaches faced inherent limitations, particularly in handling complex relation patterns and managing embedding regularization. This section delves into the evolution of these foundational models, tracing their initial refinements within traditional Euclidean or vector spaces and highlighting pioneering efforts to transcend these boundaries by exploring non-Euclidean geometric structures. The journey from basic translation to sophisticated geometric transformations underscores a continuous pursuit of enhanced model capacity, improved expressiveness for diverse relation types, and more robust embedding regularization. This exploration forms the bedrock for understanding more advanced KGE techniques, demonstrating how fundamental challenges in knowledge representation were systematically addressed through innovative mathematical and geometric interpretations.

\noindent\textbf{Taxonomy Summary:} This section primarily covers models within the "Translational Models and Geometric Extensions" group. Specifically, it examines "Subgroup 1.1: Enhancing Relation Modeling within Euclidean Space" by discussing models like TransH and RatE, and "Subgroup 1.2: Exploring Non-Euclidean Embedding Spaces" through the lens of TorusE. The development direction highlighted here moves from refining core translation mechanics to exploring alternative embedding geometries.

\subsection{Core Translational Models and Their Initial Refinements}
The translational paradigm, pioneered by TransE, established a simple yet powerful principle for Knowledge Graph Embedding: the embedding of a head entity plus the embedding of a relation should approximately equal the embedding of the tail entity ($h + r \approx t$). This approach gained significant traction due to its computational efficiency and intuitive interpretability. However, TransE struggled with certain fundamental limitations. A major challenge was its inability to adequately model complex relation mapping properties, such as one-to-many, many-to-one, and many-to-many relations. In such scenarios, TransE's rigid translation often forced entities involved in these complex mappings to occupy similar points in the embedding space, leading to a loss of discriminative power. For instance, if a head entity has multiple tail entities via the same relation, TransE might struggle to differentiate between these tails.

Beyond the scoring function, the training process itself presented avenues for refinement. \cite{nayyeri2019} critically investigated TransE's limitations, arguing that the choice of the \textbf{loss function} is as crucial as the score function in encoding complex relation patterns. Their theoretical and empirical work demonstrated that a proper selection of the loss function could significantly mitigate TransE's shortcomings, particularly concerning many-to-many and symmetric relations. This insight highlighted that optimizing the learning objective, rather than solely redesigning the embedding operations, offers a powerful path for refining core translational models. This represents a crucial conceptual shift within the "core mechanics" phase of KGE development, emphasizing that the training objective is as critical as the scoring function in improving translation-based models, thereby opening a new avenue for research and optimization.

\subsection{Enhancing Relation Modeling within Euclidean Space}
To overcome the limitations of basic translational models in handling complex relation patterns, subsequent research focused on enriching the representation of relations within Euclidean or complex vector spaces. These efforts aimed to introduce more flexibility and capacity into the translation mechanism without sacrificing the inherent efficiency.

A significant step in this direction was \textbf{TransH} \cite{wang2014}, which addresses TransE's inability to efficiently model complex relation mapping properties (one-to-many, many-to-one, many-to-many). Instead of representing a relation as a simple vector, TransH models each relation $r$ as a \textbf{hyperplane} defined by a normal vector $w\_r$, along with a translation vector $d\_r$ that lies on this hyperplane. For a given triple $(h, r, t)$, both the head entity $h$ and tail entity $t$ are first projected onto the relation-specific hyperplane. The translation operation then occurs between these projected entities. This mechanism allows an entity to have different representations (projections) when involved in different relations, thereby effectively differentiating entities in complex mappings. \cite{wang2014} demonstrated that TransH delivers significant improvements in predictive accuracy over TransE on benchmark datasets like WordNet and Freebase, while maintaining comparable scalability and efficiency. This marked a crucial trade-off between model capacity and computational cost, falling under "Subgroup 1.1: Enhancing Relation Modeling within Euclidean Space."

Further advancements in this vein include \textbf{RatE (Relation-Adaptive Translating Embedding)} \cite{huang2020}. RatE operates in complex vector space and aims to enhance the expressive power of translational models by introducing a novel element-wise \textit{weighted product} in its translation function. Unlike the rigid complex number multiplication in models like RotatE, RatE employs a learnable, relation-specific weight matrix $W(r)$ for each relation. This adaptive weighting allows for more flexible transformations, significantly improving the model's capacity to capture intricate relational semantics. Crucially, RatE explicitly addresses the problem of embedding ambiguity, particularly prevalent in one-to-many relations, by dynamically adjusting distances between tail entities. This prevents distinct entities from being assigned overly similar embeddings, a common pitfall in earlier models. \cite{huang2020} showed that RatE achieves state-of-the-art performance across multiple benchmark datasets, demonstrating its effectiveness in balancing enhanced modeling capacity with computational efficiency.

\subsection{Exploring Non-Euclidean Embedding Spaces}
While refinements within Euclidean and complex vector spaces significantly improved translational models, a fundamental limitation persisted: the need for explicit regularization. Models like TransE often forced entity embeddings onto a unit sphere to prevent divergence during training, a practice that could inadvertently warp the embedding space and hinder the model's ability to accurately capture the translation principle. This challenge motivated a pioneering shift towards exploring non-Euclidean geometric structures for KGE, aiming for spaces that intrinsically offer desirable properties like compactness.

\textbf{TorusE: Knowledge Graph Embedding on a Lie Group} \cite{ebisu2017} represents a groundbreaking effort in this direction. The paper identifies the regularization problem in TransE, where forcing embeddings onto a sphere warps the space and adversely affects link prediction accuracy. To address this, TorusE proposes embedding entities and relations not in a real or complex vector space, but on a \textbf{compact Lie group}, specifically a \textbf{torus}. The core insight is that the translation principle of TransE can be naturally defined on any Lie group. By choosing a compact Lie group like a torus, the inherent compactness of the space naturally regularizes the embeddings, preventing them from diverging without the need for explicit regularization. This avoids the adverse effects of regularization on embedding accuracy and interpretability. \cite{ebisu2017} highlights TorusE as the first model to embed objects on a space other than a real or complex vector space, marking a significant conceptual leap. Experiments demonstrated that TorusE outperforms state-of-the-art approaches, including TransE, DistMult, and ComplEx, on standard link prediction tasks, while also being scalable and faster than the original TransE. This innovation falls under "Subgroup 1.2: Exploring Non-Euclidean Embedding Spaces" and opened a new research direction for KGE, encouraging the exploration of other geometric spaces (e.g., hyperbolic spaces) for knowledge representation. The success of TorusE underscored the potential of leveraging advanced mathematical structures to fundamentally address challenges in KGE, moving beyond mere architectural tweaks to reconsider the very nature of the embedding space.

\label{sec:3._advanced_kge_architectures_and_training_optimizations}

\section{Advanced KGE Architectures and Training Optimizations}
Moving beyond the foundational translational models, the field of Knowledge Graph Embedding (KGE) has significantly advanced by exploring more sophisticated architectures and refining training methodologies. This evolution is driven by the persistent need to capture richer semantic and structural information, handle complex relation patterns, improve generalization to unseen data, and optimize the learning process for efficiency and robustness. While early models laid the groundwork by establishing the concept of embedding entities and relations in continuous vector spaces, their limitations in expressiveness, scalability, and ability to handle diverse relation types spurred the development of more powerful approaches. This section delves into three critical areas of this advancement: the application of Graph Neural Networks (GNNs) for learning expressive entity and relation representations, the development of sophisticated negative sampling strategies and refined loss functions to optimize training, and the emergence of hybrid or generalized embedding frameworks that combine diverse strengths or leverage novel mathematical spaces. These innovations collectively push the boundaries of KGE, enabling models to tackle increasingly complex knowledge graph challenges and facilitate advanced reasoning tasks, moving towards more intelligent and adaptable knowledge representation systems.

\noindent\textbf{Taxonomy Summary:} This section primarily draws from "Group 3: Graph Neural Network-based Models with Focus on Extrapolation and Interpretability" for its core architectural innovations. It also incorporates advanced aspects of "Group 1: Translational Models and Geometric Extensions," specifically focusing on the exploration of non-Euclidean embedding spaces and sophisticated training optimizations (negative sampling and loss functions) that build upon or critically re-evaluate foundational principles. Elements from "Group 2: Temporal and Continual Knowledge Graph Embedding" and "Group 4: Generative AI and Multimodal Reasoning for Scientific Discovery" are integrated where they introduce advanced architectures or training optimizations relevant to the section's focus on pushing the boundaries of KGE. The development direction highlighted here moves towards models that are more expressive, robust, and capable of handling complex scenarios through architectural innovation and optimized learning, rather than merely extending basic translational mechanisms.

\subsection{Graph Neural Network-based Models for Representation Learning}
Graph Neural Networks (GNNs) have emerged as a powerful paradigm for Knowledge Graph Embedding, offering a natural way to leverage the inherent graph structure and learn rich, context-aware representations for entities and relations. Unlike traditional KGE models that often treat entities and relations as isolated points or vectors, GNNs explicitly aggregate information from an entity's local neighborhood, allowing for the capture of multi-hop relational paths and complex structural patterns. This capability is particularly crucial for tasks requiring strong generalization and extrapolation abilities, as GNNs can learn functions that generate embeddings based on structural context, rather than relying on pre-defined, fixed embeddings for every entity and relation. This makes them highly adaptable to evolving knowledge graphs and unseen entities, a significant advantage over many foundational KGE models.

\subsubsection{Understanding and Enhancing Extrapolation through Semantic Evidences}
A significant contribution to GNN-based KGE is the work by \cite{li2021}, which addresses the critical question of \textit{how} KGE models extrapolate to unseen data, a key challenge for real-world applications. The authors identify three levels of "Semantic Evidences" (SEs) at the relation, entity, and triple levels, which provide crucial semantic information for effective extrapolation. Building on this insight, they propose \textbf{SE-GNN (Semantic Evidence aware Graph Neural Network)}, a novel GNN-based model. SE-GNN explicitly models each level of SE through corresponding neighbor patterns and multi-layer aggregation, leading to more extrapolative knowledge representations. This approach allows the model to generalize patterns learned from observed triples to unseen ones by recognizing similar semantic structures. Experiments on benchmark datasets like FB15k-237 and WN18RR demonstrate SE-GNN's state-of-the-art performance and superior extrapolation ability, highlighting the power of GNNs in capturing semantic context for robust generalization. The explicit modeling of semantic evidences provides a more interpretable mechanism for understanding how GNNs achieve their strong performance in inductive settings.

Further building on this foundation, \cite{li2025} introduces \textbf{GNN-FTuckER}, a novel link prediction model that integrates the SE-GNN structural encoder with an improved TuckER model decoder. This hybrid architecture leverages the SE-GNN's ability to model global graph structure and capture rich semantic embeddings through its attention-weighted aggregation mechanism. By combining this powerful GNN encoder, which excels at learning context-aware representations, with a tensor decomposition-based decoder, GNN-FTuckER enhances the model's capacity to capture complex non-linear relationships and contextual information. This is particularly valuable in specialized knowledge graphs, such as the TeaPle dataset for identifying suitable populations for tea varieties, where intricate domain-specific patterns need to be learned. This demonstrates how GNNs, specifically SE-GNN, can serve as robust encoders for learning highly expressive representations that are then effectively utilized by other KGE components, forming powerful hybrid systems.

GNNs also extend to more challenging extrapolation scenarios, such as those involving temporal knowledge graphs (TKGs), where entities and relations evolve over time. \cite{chen2023} proposes a meta-learning based approach for knowledge extrapolation in TKGs, specifically addressing unseen entities and relations. Their method meta-trains a \textbf{GNN framework} to capture relative position and temporal sequence patterns, allowing the transfer of learned patterns to embed unseen components. This illustrates the adaptability of GNNs in dynamic environments, where they learn generalizable mechanisms for representation generation rather than fixed embeddings, thereby enabling robust extrapolation to emergent knowledge. This is a critical advancement as real-world knowledge is rarely static. Beyond traditional KGE tasks, GNNs are also being applied in scientific discovery, showcasing their versatility in learning complex, domain-specific representations. For instance, \cite{ghafarollahi2024} developed a novel GNN model for rapidly predicting atomic-scale physical properties in multi-principal element alloys. This GNN learns rich representations of alloy configurations, encoding chemical and configurational features as nodes and bond types as edges, to bypass expensive atomistic simulations. This showcases GNNs' capacity to learn complex, physics-aware representations for advanced scientific applications, demonstrating their utility far beyond typical knowledge graph completion.

\subsection{Optimizing the Training Process: Negative Sampling and Loss Functions}
Beyond architectural innovations, the efficacy of KGE models heavily relies on sophisticated training methodologies, particularly in how negative examples are constructed and how the learning objective is formulated. These optimizations are crucial for guiding the model to learn discriminative and robust embeddings, preventing trivial solutions, and ensuring the learned representations accurately reflect the underlying knowledge. The evolution of these techniques reflects a deeper understanding of the challenges in KGE training, such as false negatives, embedding ambiguity, and catastrophic forgetting in dynamic settings.

\subsubsection{Sophisticated Negative Sampling Strategies}
Negative sampling is a critical component of KGE training, as it provides counter-examples to positive facts, preventing the model from trivially assigning high scores to all triples. Early models often used uniform negative sampling, which could inadvertently introduce "false negatives" (valid triples mistakenly labeled as negative), thereby hindering learning. A foundational advancement to mitigate this was introduced by \cite{wang2014} with a \textbf{Bernoulli sampling strategy} for TransH. This method leveraged the mapping properties of relations (e.g., one-to-many, many-to-one) to reduce the likelihood of sampling false negatives. For relations that are predominantly one-to-many, corrupting the tail entity is preferred, while for many-to-one relations, corrupting the head is more effective. While applied to a foundational model, this innovation marked a crucial step towards context-aware negative sampling, recognizing that not all negative samples are equally informative or valid.

Building significantly on this concept, \cite{huang2020} proposed a more advanced \textbf{Local-Cognitive Negative Sampling} method for their RatE model, which operates in complex vector space. This strategy integrates two key components to generate highly informative negative samples: \textbf{type-constraint training} and \textbf{self-adversarial learning}. Type-constraint training leverages prior knowledge by sampling negative entities only from relation-specific domains and ranges, drastically reducing the chance of false negatives and focusing the model on plausible corruptions. Simultaneously, self-adversarial learning dynamically scores uniformly sampled negative triples based on the current model's difficulty, prioritizing "hard" negative examples that the model struggles to distinguish from positive ones. By using a dynamic coefficient to balance samples from these two sources, RatE's negative sampling mechanism becomes highly adaptive and informative. This explicit strategy is designed to alleviate embedding ambiguity caused by one-to-many relations, where multiple tail entities might be incorrectly mapped close to a single head-relation pair. The adaptive nature of RatE's negative sampling, combined with its relation-adaptive translation function, significantly enhances the model's expressive power and disambiguation capabilities, representing a substantial leap from earlier, simpler sampling methods.

\subsubsection{Refined Loss Functions}
The choice and design of the loss function are equally paramount, as they dictate how the model learns from both positive and negative examples and shapes the embedding space. While much KGE research focuses on designing intricate scoring functions, \cite{nayyeri2019} critically argues that for translation-based embeddings like TransE, the \textbf{loss function is as important as the score function}. Their theoretical investigations and empirical validations demonstrate that a proper selection of the loss function can significantly mitigate TransE's previously perceived limitations in encoding complex relation patterns (e.g., many-to-many, symmetric relations), even without altering the core scoring mechanism. They show that by allowing a non-zero margin or "region of truth" for positive triples, many limitations attributed to TransE's architecture can be resolved. This work underscored the importance of optimizing the learning objective itself, opening new avenues for improving KGE models through careful loss design and a deeper theoretical understanding of their capabilities. This re-evaluation of foundational models through the lens of advanced loss function theory highlights that even "basic" architectures can achieve greater expressiveness with refined optimization strategies.

In the context of dynamic knowledge graphs, training optimizations extend to preserving knowledge over time, a challenge known as catastrophic forgetting. \cite{liu2024} addresses continual KGE (CKGE) with their \textbf{Incremental Distillation (IncDE)} method. While IncDE is a broader continual learning framework, its novel \textbf{incremental distillation mechanism} serves as a sophisticated loss function optimization. This mechanism facilitates the seamless transfer of entity representations from previous learning layers to subsequent ones, effectively preserving old knowledge while learning new facts. By incorporating a hierarchical strategy for learning new triples based on graph structure and a two-stage training paradigm, IncDE demonstrates how refined loss functions, particularly those involving knowledge distillation, can be crucial for addressing complex challenges like catastrophic forgetting in evolving knowledge graphs. This represents a significant advancement in loss function design, moving beyond simple margin-based objectives to incorporate mechanisms for knowledge retention and transfer in dynamic learning environments.

\subsection{Hybrid and Generalized Embedding Frameworks}
The pursuit of more expressive and robust KGE models has also led to the development of hybrid architectures that combine different strengths, and generalized frameworks that explore novel mathematical spaces beyond conventional Euclidean vectors. These approaches aim to overcome the inherent limitations of single-paradigm models by integrating diverse modeling capabilities, leading to more powerful and versatile knowledge representation.

\subsubsection{Exploring Non-Euclidean Embedding Spaces}
A groundbreaking direction in generalized embedding frameworks is the exploration of non-Euclidean spaces, which offer richer geometric properties to capture complex relational patterns. A pioneering work in this area was \cite{ebisu2017}, which introduced \textbf{TorusE: Knowledge Graph Embedding on a Lie Group}. TorusE directly addressed a fundamental regularization problem in TransE: the practice of forcing embeddings onto a unit sphere, which can warp the embedding space and hinder the translation principle. TorusE proposed to embed entities and relations on a \textbf{compact Lie group}, specifically an \textbf{n-dimensional torus}, instead of a real or complex vector space. The inherent compactness of the torus naturally regularizes the embeddings, preventing divergence without the need for explicit regularization and its adverse effects. This seminal work demonstrated that the translation principle could be effectively defined on a Lie group, opening a new research direction for KGE by encouraging the exploration of other geometric spaces for knowledge representation, such as hyperbolic spaces. While TorusE itself is a translation-based model, its innovation lies in the \textit{space} it operates within, fundamentally altering the geometric properties of the embeddings and paving the way for more advanced non-Euclidean KGE models that leverage the unique characteristics of such spaces to model hierarchies, complex dependencies, or specific relational patterns more effectively than Euclidean counterparts.

\subsubsection{Hybrid Geometric Operations and Multimodal Integration}
Beyond changing the embedding space, hybrid frameworks also involve combining different types of geometric operations or integrating KGE with other advanced AI paradigms. \cite{ying2024} proposed \textbf{TCompoundE}, a novel Temporal Knowledge Graph Embedding (TKGE) model that leverages \textit{compound geometric operations} for temporal knowledge graph completion. Unlike prior TKGE models that often rely on a single geometric operation (e.g., translation or rotation), TCompoundE integrates both time-specific translation and scaling operations within relation-specific operations. This allows it to capture both dynamic and static aspects of relations over time, demonstrating superior performance in modeling complex, diverse, and dynamically evolving temporal patterns. The combination of operations provides a richer vocabulary for describing temporal changes. Similarly, \cite{chen2022} introduced \textbf{RotateQVS}, which represents temporal information as rotations in a quaternion vector space. Quaternions, a generalization of complex numbers, offer a richer mathematical structure for modeling rotations, enabling RotateQVS to capture a comprehensive set of relation patterns, including crucial temporal evolution, with greater expressiveness and interpretability. These models exemplify how combining or extending geometric operations can unlock greater representational power.

At the cutting edge, hybrid frameworks integrate KGE with advanced AI paradigms, moving towards more holistic and intelligent systems. \cite{buehler2024} presents a highly generalized framework for accelerating scientific discovery by combining generative AI, graph-based representation, and multimodal intelligent graph reasoning. This approach employs generative AI to transform scientific papers into an ontological knowledge graph, uses a large language embedding model for deep node representations, and leverages combinatorial node similarity ranking with path sampling to link dissimilar concepts. Crucially, it integrates multimodal intelligent graph reasoning across diverse data (graphs, images, text, numerical data) and even artistic principles for novel material design. This represents a powerful hybrid framework that transcends traditional KGE by integrating it into a broader generative and multimodal reasoning system for complex, cross-domain scientific innovation. Such frameworks demonstrate the future direction of KGE, where embeddings are not just an end in themselves but a crucial component within larger, intelligent systems capable of processing and reasoning over diverse data modalities.

\label{sec:4._addressing_dynamic_knowledge_graphs:_temporal_and_continual_kge}

\section{Addressing Dynamic Knowledge Graphs: Temporal and Continual KGE}
Knowledge graphs (KGs) are not static repositories of facts but rather dynamic entities that evolve continuously over time, with new entities, relations, and facts emerging, and existing ones changing or becoming obsolete. This inherent dynamism poses significant challenges for traditional Knowledge Graph Embedding (KGE) models, which are primarily designed for static graphs and assume a fixed set of entities and relations. Such static models struggle to capture the non-stationarity and temporal dependencies of real-world events, leading to outdated representations and poor performance on evolving data. Furthermore, retraining these models from scratch on continuously growing KGs is computationally prohibitive and prone to catastrophic forgetting, where newly learned information overwrites previously acquired knowledge.

Addressing these critical limitations, the field has seen the emergence of two pivotal research directions: Temporal Knowledge Graph Embedding (TKGE) and Continual Knowledge Graph Embedding (CKGE). TKGE methods explicitly model the temporal dimension of facts, capturing time-varying relationships and ensuring temporal consistency. They aim to represent entities, relations, and timestamps in a continuous vector space such that temporal facts $(h, r, t, \tau)$ (head, relation, tail, timestamp) can be accurately predicted and reasoned upon. In contrast, CKGE approaches focus on incrementally learning new knowledge from evolving KGs without forgetting old information, a phenomenon known as catastrophic forgetting. This involves developing strategies for efficient model updates that adapt to new facts while preserving the ability to reason over historical knowledge. This section delves into the methodologies, advancements, and challenges within these dynamic KGE paradigms, highlighting how they enable models to adapt to evolving knowledge, maintain robust performance over time, and overcome the limitations of static embedding approaches. We will critically analyze the design choices, underlying mechanisms, and comparative advantages of various TKGE and CKGE models, emphasizing their contributions to building more adaptive and intelligent knowledge systems.

\subsection{Temporal KGE: Modeling Time-Varying Facts}
Temporal Knowledge Graph Embedding (TKGE) aims to represent entities, relations, and timestamps in a continuous vector space such that temporal facts $(h, r, t, \tau)$ can be accurately predicted and reasoned upon. The core challenge lies in capturing the non-stationarity, heterogeneity, and complex temporal dependencies inherent in real-world events. Early KGE models largely ignored the temporal dimension, treating all facts as timeless. However, the recognition that facts are often time-sensitive and that relationships evolve has led to the development of sophisticated models that explicitly incorporate time into their embedding mechanisms. These models primarily achieve this through two main strategies: leveraging geometric transformations to model temporal evolution and enforcing temporal consistency and sensitivity in the learned embeddings. The goal is not just to predict facts, but to understand \textit{when} and \textit{how} relations hold or change, which is crucial for dynamic reasoning tasks like event forecasting and temporal question answering.

\subsubsection{Rotation-Based and Advanced Geometric Transformations}
A prominent and increasingly sophisticated approach in TKGE involves leveraging geometric transformations to model how entities and relations evolve over time. The fundamental idea is that temporal changes can be represented as transformations in the embedding space, allowing for a continuous and differentiable way to capture dynamics.

A foundational work in this area is \textbf{ChronoR} by \cite{sadeghian2021}. ChronoR introduced a novel model that employs a $k$-dimensional rotation transformation, uniquely parametrized by both relation and time. For a given fact $(h, r, t, \tau)$, ChronoR transforms the head entity's embedding using this specific rotation to align it with its tail entity's embedding. The model's scoring function is based on the inner product (cosine of the angle) between the transformed head and tail entities, which \cite{sadeghian2021} theoretically demonstrated to be a generalization of previously used complex-domain scoring functions (e.g., ComplEx's $Re(a \cdot b)$). This high-dimensional rotation, which relaxes the unit norm constraint to include scaling, effectively captures rich interactions between the temporal and multi-relational characteristics of a TKG. Furthermore, ChronoR introduced a novel regularization method inspired by tensor nuclear norms and a 4-norm temporal smoothness objective to encourage similar transformations for closer timestamps, enhancing temporal consistency. ChronoR demonstrated superior performance in temporal link prediction, particularly for facts within observed timestamps, highlighting the efficacy of rotation for temporal modeling.

Building upon the success of rotation-based models, subsequent research has explored more expressive algebraic spaces. \cite{chen2022} proposed \textbf{RotateQVS}, which extends the rotation concept by representing temporal entities as rotations in a Quaternion Vector Space. Relations are modeled as complex vectors in Hamilton's quaternion space, allowing for a more nuanced representation of relation patterns, including symmetry, asymmetry, inverse, and crucially, temporal evolution. The use of quaternions, which naturally encode 3D rotations and offer a richer mathematical structure than complex numbers, provides a more expressive framework for capturing intricate temporal dynamics. This approach not only improves modeling capacity but also offers improved interpretability compared to simpler rotation matrices by directly mapping relational transformations to quaternion operations.

Further advancing this, \cite{ying2024} introduced \textbf{TCompoundE}, a TKGE model that leverages compound geometric operations. Unlike ChronoR or RotateQVS which primarily rely on a single type of geometric operation (rotation), TCompoundE integrates \textit{both} time-specific translation and scaling operations \textit{within} relation-specific operations. Specifically, it applies time-specific translation ($T\_\tau$) and scaling ($S\_\tau$) to the relation-specific scaling component ($S\_{\hat{r}}$), while keeping the relation-specific translation ($T\_{\hat{r}}$) time-invariant. This allows TCompoundE to capture both dynamic (time-varying) and static (time-invariant) aspects of relations over time. The model's ability to combine multiple operations in a structured manner enables it to model a wider variety of relation patterns, including symmetric, asymmetric, inverse, and complex temporal evolution patterns, which single-operation models often struggle with \cite{ying2024}. TCompoundE's superior performance across benchmark datasets underscores the benefit of moving beyond monolithic transformations to a more modular and expressive compound approach.

The progression from ChronoR's k-dimensional rotations to RotateQVS's quaternion rotations and TCompoundE's compound operations illustrates a clear development direction: increasingly sophisticated geometric and algebraic transformations are being employed to model the continuous and dynamic nature of time and relations. While rotation-based methods excel at capturing cyclic or evolving patterns, compound operations offer greater flexibility by combining different types of transformations, potentially at the cost of increased model complexity and hyperparameter tuning. A critical challenge remains in determining the optimal geometric space and combination of operations for diverse temporal patterns, as well as ensuring the interpretability of these complex transformations.

\subsubsection{Temporal Consistency and Sensitivity}
Beyond the core embedding mechanisms, another critical aspect of TKGE is ensuring the temporal consistency of embeddings and capturing the varying importance of time for different facts. Facts do not always change abruptly; often, their evolution is smooth, and the relevance of a timestamp can differ significantly across relations.

\cite{dileo2023} addressed the challenge of temporal consistency by focusing on \textbf{temporal smoothness regularizers} for neural link predictors. This work systematically analyzed various regularization techniques, including those using linear functions and recurrent architectures, that enforce similar transformations for adjacent timestamps. By applying these regularizers to existing tensor factorization models like TNTComplEx, they demonstrated that explicitly encouraging embeddings to evolve smoothly over time significantly enhances model performance. This highlights that a continuous, gradual change in entity and relation representations, rather than abrupt shifts, often better reflects real-world temporal dynamics and improves predictive accuracy. The effectiveness of these regularizers suggests that incorporating prior knowledge about temporal continuity can be as crucial as the choice of the embedding function itself.

Complementing the focus on consistency, \cite{cai2024} introduced a model that operates within a complex space to address the crucial problem of \textbf{time sensitivity}. This model captures semantic characteristics with temporal sensitivity through transformation and an attention mechanism in its real part, while its imaginary part learns connections between fact elements without predefined weights. This approach allows the model to dynamically weigh the relevance of temporal information for specific facts, moving beyond uniform temporal modeling to context-aware temporal understanding. For instance, some relations might be highly sensitive to the exact timestamp (e.g., "was elected president on"), while others might be more enduring (e.g., "is a part of"). By employing an attention mechanism, the model can adaptively determine how much temporal information to incorporate, thereby improving the precision of temporal reasoning.

The comprehensive survey by \cite{cai2024} further consolidates these developments, defining TKGs, reviewing datasets and evaluation metrics, and proposing a taxonomy based on core technologies. It synthesizes diverse approaches, including those focusing on temporal consistency and sensitivity, and outlines future research directions, serving as a foundational resource for understanding the landscape and guiding further development in this rapidly evolving field. While temporal smoothness regularizers offer a global constraint on embedding evolution, time-sensitive models provide a more granular, context-dependent mechanism for leveraging temporal information. The trade-off often lies between the computational overhead of dynamic attention mechanisms and the generalizability of simpler regularization techniques. Future research will likely explore hybrid approaches that combine both global consistency and local sensitivity for more robust temporal modeling.

\subsection{Continual KGE: Incremental Learning and Catastrophic Forgetting Mitigation}
Continual Knowledge Graph Embedding (CKGE) addresses the critical challenge of incrementally learning new knowledge from evolving KGs while simultaneously preventing catastrophic forgetting of previously learned information. As KGs grow and change, retraining KGE models from scratch on the entire dataset becomes computationally prohibitive and inefficient. CKGE methods are designed to efficiently update embeddings by adapting to new facts without losing the ability to reason over old ones, a critical requirement for real-world, continuously updated knowledge bases like Wikipedia or biomedical databases. The core problem is to achieve a balance between \textit{plasticity} (the ability to learn new information) and \textit{stability} (the ability to retain old information), often referred to as the stability-plasticity dilemma. This section explores strategies that leverage knowledge distillation, parameter-efficient techniques, and adaptive learning to navigate this challenge.

\subsubsection{Distillation and Graph Structure Awareness}
A key strategy for mitigating catastrophic forgetting in CKGE is knowledge distillation, where a "teacher" model (representing old knowledge) guides the learning of a "student" model (learning new knowledge). However, generic distillation methods often overlook the explicit graph structure, which is crucial for efficient learning and preservation in KGs.

\cite{liu2024} proposed \textbf{Incremental Distillation (IncDE)}, a competitive method for CKGE that explicitly considers the full use of the explicit graph structure in KGs, a factor often overlooked by previous methods. IncDE introduces a hierarchical strategy to optimize the learning order of new triples based on graph structure features. This strategy involves two levels of ordering:
\begin{enumerate}
    \item \textbf{Inter-hierarchical Ordering}: New triples are divided into multiple layers using Breadth-First Search (BFS) expansion from the existing old graph. This prioritizes learning triples that are structurally closer to the already known knowledge.
    \item \textbf{Intra-hierarchical Ordering}: Within each layer, triples are further sorted based on the importance of their entities and relations, measured by node centrality and betweenness centrality. This ensures that critical structural elements are learned first, preserving the inherent semantics and structure of the new KGs.
\end{enumerate}
Crucially, IncDE devises a novel incremental distillation mechanism that facilitates the seamless transfer of entity representations from the previous layer to the next. This mechanism is importance-aware, dynamically weighting distillation loss based on the graph structure features (node and betweenness centrality) of entities. This ensures that more critical entities receive higher preservation priority, addressing the limitation of previous methods that preserved old triples with equal priority. The approach also employs a two-stage training paradigm to prevent the corruption of old knowledge by under-trained new knowledge: first, only new entity/relation representations are trained while old ones are fixed; then, all embeddings are fine-tuned. Experimental results demonstrate that IncDE consistently outperforms state-of-the-art baselines, with the distillation mechanism contributing significantly to performance improvements. This approach showcases how integrating graph structure awareness with sophisticated distillation techniques can effectively address the challenges of continual learning in dynamic KGs, offering a more principled way to balance plasticity and stability.

\subsubsection{Parameter-Efficient and Adaptive Learning Strategies}
The continuous growth of KGs also exacerbates the problem of parameter storage costs, as traditional KGE methods assign unique embeddings to every entity and relation, leading to a linear increase in parameters with KG size. To address this, parameter-efficient and adaptive learning strategies are crucial for CKGE models to dynamically adjust to new knowledge without prohibitive resource demands.

\cite{chen2023} introduced \textbf{Entity-Agnostic Representation Learning (EARL)}, a novel paradigm where embeddings are learned only for a small set of "reserved entities." For all other entities, their embeddings are dynamically generated by universal, entity-agnostic encoders that transform their distinguishable contextual information (from connected relations, k-nearest reserved entities, and multi-hop neighbors). This approach allows EARL to maintain a static, efficient, and significantly lower parameter count, independent of the total number of entities in the KG, while still achieving state-of-the-art performance on link prediction tasks. By decoupling entity count from parameter count, EARL offers a scalable solution for ever-growing KGs.

Beyond parameter efficiency, adaptive learning strategies are crucial for CKGE models to dynamically adjust to new knowledge. \cite{liu2024} further explored parameter-efficient continual learning with \textbf{Fast and Continual Knowledge Graph Embedding via Incremental LoRA}. This method leverages Low-Rank Adaptation (LoRA) to incrementally learn new knowledge by updating only a small number of parameters, significantly reducing computational overhead and memory footprint while preserving old knowledge. LoRA's effectiveness stems from its ability to inject trainable low-rank matrices into the model's layers, allowing for efficient adaptation without modifying the original pre-trained weights.

Similarly, \cite{li2025} proposed \textbf{Learning to Evolve: Bayesian-Guided Continual Knowledge Graph Embedding}, which uses a Bayesian approach to adaptively learn and update embeddings. This provides a principled way to quantify uncertainty and balance new and old information by maintaining posterior distributions over parameters, allowing for more robust and adaptive updates. Another adaptive strategy is presented by \cite{li2025} with \textbf{SAGE (Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding)}, which focuses on a scale-aware gradual evolution process to handle the varying impact of new knowledge. SAGE recognizes that new knowledge can have different "scales" of impact on the existing KG and adapts its learning rate and regularization accordingly. Furthermore, \cite{zhang2025} introduced a \textbf{Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning}, which uses generative models to replay past experiences. By synthesizing "pseudo-samples" from old knowledge, this approach prevents catastrophic forgetting in a more adaptive and data-efficient manner, reducing the need to store large amounts of old data.

These parameter-efficient and adaptive learning strategies represent critical advancements towards building scalable, robust, and intelligent KGE systems that can continuously learn and evolve with dynamic knowledge. While EARL offers a paradigm shift in parameter management, LoRA provides an efficient fine-tuning mechanism. Bayesian methods, scale-aware evolution, and generative replay offer different facets of adaptive learning, each with its own trade-offs between computational complexity, memory usage, and the effectiveness of forgetting mitigation. The challenge lies in combining these strategies to create truly general-purpose CKGE models that can handle diverse types of KG evolution with minimal resource expenditure.

\label{sec:5._extrapolation,_generalization,_and_unseen_data_handling}

\section{Extrapolation, Generalization, and Unseen Data Handling}
The ability of Knowledge Graph Embedding (KGE) models to extrapolate and generalize to unseen data is paramount for their utility in real-world, dynamic applications. This encompasses handling novel entities, relations, or facts that were not present during training, a critical requirement for tasks like scientific discovery, materials design, and evolving knowledge bases. Traditional KGE models often struggle with such emergent knowledge, necessitating frameworks that provide a semantic understanding of how models achieve extrapolation, advanced meta-learning techniques for dynamic settings, and robust architectural designs. This section delves into these crucial aspects, exploring the evolution from foundational geometric models to sophisticated Graph Neural Network (GNN)-based and multimodal AI systems, aligning with the "Taxonomy of Development Direction: KGE Extrapolation, Temporal Dynamics, and GNN Architectures" and the "Method Groups for the Survey". The progression highlights a shift from merely predicting missing links to understanding the underlying mechanisms of generalization and designing models that can actively discover novel insights.

\subsection{Understanding Extrapolation through Semantic Evidences}
A fundamental challenge in KGE has been to understand \textit{why} models extrapolate to unseen data, rather than just \textit{how} they measure plausibility. This semantic understanding is crucial for designing more robust and generalizable models. \cite{li2021} directly addresses this by proposing a framework centered on "Semantic Evidences" (SEs). They identify three levels of observable semantic relatednessrelation, entity, and triplewithin the training set that provide critical information for predicting unseen triples. For instance, relation-level SE quantifies co-occurrence frequency, entity-level SE measures path connections, and triple-level SE assesses similarity between candidate tails and known tails for a given head-relation pair. To leverage these insights, \cite{li2021} introduced \textbf{SE-GNN}, a GNN-based model that explicitly models each level of SE through corresponding neighbor patterns and multi-layer aggregation, leading to more extrapolative knowledge representations. This work, falling under the "Graph Neural Network-based Models with Focus on Extrapolation and Interpretability" group, provides a foundational semantic view for KGE extrapolation.

The practical utility of this semantic evidence approach is further demonstrated by \cite{li2025} with \textbf{GNN-FTuckER}. This model, designed for a specialized domain (identifying suitable populations for tea varieties), integrates the \textbf{SE-GNN structural encoder} with an improved TuckER decoder. By explicitly modeling global graph structure and semantic evidences through the SE-GNN component, GNN-FTuckER enhances its ability to capture rich semantic information and complex non-linear relationships, thereby improving link prediction performance in a real-world application. This illustrates how the semantic evidence framework can be effectively deployed and refined for robust extrapolation in domain-specific knowledge graphs.

Earlier works also contributed to improving generalization by enhancing model capacity to capture complex patterns, albeit without explicitly framing it as "semantic evidence." For example, \cite{wang2014} introduced \textbf{TransH}, a "Translational Model and Geometric Extension," which models relations as hyperplanes with translation operations. This allowed entities to have different representations when involved in complex mapping properties (one-to-many, many-to-one), significantly improving its ability to generalize to such relations compared to simpler translational models. Similarly, \cite{ebisu2017} proposed \textbf{TorusE}, another "Translational Model and Geometric Extension," which embeds entities and relations on a compact Lie group (a torus). This inherent compactness naturally regularizes embeddings, avoiding the warping effects of explicit regularization in Euclidean space and thereby enhancing the model's capacity to learn more accurate and generalizable representations. While \cite{li2021} provides an explicit semantic framework, TransH and TorusE represent architectural advancements that implicitly improve the model's ability to capture and extrapolate complex patterns by providing more suitable embedding spaces or relation modeling mechanisms. The progression shows a move from implicit architectural improvements to explicit semantic understanding as a design principle for extrapolation.

\subsection{Meta-Learning for Generalization to Unseen Entities and Relations}
Handling emergent knowledge, including entirely novel entities and relations, in dynamic knowledge graphs (TKGs) is a significant challenge that meta-learning techniques are well-suited to address. This falls under the "Temporal and Continual Knowledge Graph Embedding" and "Graph Neural Network-based Models with Focus on Extrapolation and Interpretability" groups, as meta-learning often leverages GNNs for dynamic settings. \cite{chen2023} directly tackles this problem by proposing a \textbf{meta-learning based knowledge extrapolation} approach for Temporal Knowledge Graphs (TKGs) with unseen entities and relations. Their method meta-trains a GNN framework to capture relative position and temporal sequence patterns, enabling the transfer of learned patterns to embed and reason about novel components. This allows the model to quickly adapt to new knowledge by learning how to learn, rather than retraining from scratch.

Complementing meta-learning, continual learning strategies are crucial for incrementally adapting to emergent knowledge. \cite{liu2024} introduced \textbf{IncDE (Incremental Distillation)}, a method for Continual KGE that explicitly leverages graph structure awareness. IncDE employs a hierarchical strategy to optimize the learning order of new triples based on their structural features and devises a novel incremental distillation mechanism. This mechanism facilitates the seamless transfer of entity representations from previous learning layers to new ones, promoting old knowledge preservation while efficiently integrating emergent facts. This approach, while not strictly meta-learning, addresses the same core problem of adapting to dynamic knowledge by balancing plasticity and stability.

Furthermore, foundational temporal KGE models contribute to generalization in dynamic settings by enhancing the representation of temporal patterns, which are a form of emergent knowledge. \cite{sadeghian2021} proposed \textbf{ChronoR}, a "Temporal KGE with Rotation Transformations" model that uses a $k$-dimensional rotation transformation, parametrized by relation and time, to capture rich temporal and multi-relational interactions. This expressive transformation enables the model to generalize to unseen temporal facts by learning the underlying dynamics. Building on this, \cite{chen2022} introduced \textbf{RotateQVS}, which represents temporal information as rotations in a quaternion vector space, offering a richer mathematical structure for modeling complex temporal evolution patterns. More recently, \cite{ying2024} presented \textbf{TCompoundE}, a TKGE model that leverages compound geometric operations (translation and scaling) to capture both dynamic and static aspects of relations over time. These models, by enhancing the expressiveness of temporal transformations, inherently improve their ability to generalize to novel temporal facts and emergent patterns in dynamic KGs. Meta-learning provides a powerful paradigm for adapting to entirely new entities and relations, while continual learning and advanced temporal embedding models offer robust mechanisms for incrementally integrating and generalizing to evolving temporal facts.

\subsection{Architectural Considerations for Robust Extrapolation}
The architectural design of KGE models plays a pivotal role in enhancing their robustness and generalization capabilities, particularly when dealing with truly unseen data or aiming for novel discovery. This area spans from foundational geometric models to advanced multimodal generative AI systems. Early "Translational Models and Geometric Extensions" like \textbf{TransH} \cite{wang2014} introduced relation-specific hyperplanes, allowing entities to have distinct representations depending on the relation. This architectural innovation significantly improved the model's ability to handle complex relation mapping properties (e.g., one-to-many), thereby enhancing its generalization to diverse relational patterns. Similarly, \textbf{TorusE} \cite{ebisu2017} proposed embedding entities and relations on a compact Lie group (a torus). This non-Euclidean embedding space inherently regularizes the embeddings, preventing divergence without explicit regularization and thus leading to more robust and generalizable representations. These early architectural choices laid the groundwork for better generalization by improving the fundamental representation space and relation modeling.

More recently, "Graph Neural Network-based Models with Focus on Extrapolation and Interpretability" have emerged as powerful architectures. The \textbf{SE-GNN} model by \cite{li2021}, discussed earlier, is a prime example of an architectural design explicitly crafted for robust extrapolation. By integrating three levels of Semantic Evidences (relation, entity, triple) through tailored neighbor aggregation and multi-layer processing, SE-GNN learns more extrapolative knowledge representations. This GNN-based architecture directly addresses \textit{how} to build models with better generalization by incorporating semantic patterns into its design.

Pushing the boundaries of robust extrapolation and generalization are advanced "Generative AI and Multimodal Reasoning for Scientific Discovery" systems. \cite{buehler2024} describes a groundbreaking framework that employs generative AI to transform scientific papers into an ontological knowledge graph. This system leverages a large language embedding model for deep node representations and uses combinatorial node similarity ranking with path sampling to link dissimilar concepts. Crucially, it integrates multimodal intelligent graph reasoning (transitive, isomorphic properties) across diverse data (graphs, images, text, numerical data), even incorporating artistic principles for novel material design. This architecture exemplifies robust extrapolation by identifying knowledge gaps, proposing never-before-seen material designs, and uncovering unprecedented interdisciplinary relationships. Similarly, \cite{ghafarollahi2024} presents a multi-agent AI model that integrates Large Language Models (LLMs) with a novel GNN for rapid retrieval of atomic-scale physical properties in alloy design. This system dynamically explores vast compositional spaces and proposes new alloy designs, demonstrating robust generalization to unseen material compositions by synergizing GNN predictions with LLM-driven reasoning. These advanced architectures represent the pinnacle of current efforts to achieve robust extrapolation, moving beyond simple link prediction to generative discovery by combining diverse AI paradigms and multimodal reasoning. The evolution of KGE architectures reflects a continuous effort to build models that are not only accurate but also capable of truly generalizing and discovering novel knowledge in complex, dynamic, and often incomplete real-world scenarios.

\label{sec:6._reasoning,_interpretability,_and_hybrid_approaches}

\section{Reasoning, Interpretability, and Hybrid Approaches}
Advancing Knowledge Graph Embedding (KGE) models beyond mere pattern recognition necessitates a deeper integration of explicit reasoning mechanisms and a concerted effort to improve their interpretability. This section delves into methodologies that move beyond opaque vector operations, focusing on embedding logical principles, enhancing models with analogical inference capabilities, and exploring hybrid architectures. These hybrid approaches combine the strengths of dense embedding models with symbolic graph patterns or observed features, leading to more transparent, robust, and explainable knowledge completion. The development in this area reflects a growing demand for KGE models that can not only predict missing links but also provide insights into \textit{why} a prediction is made, thereby fostering trust and enabling more sophisticated applications, particularly in complex domains like scientific discovery. This evolution aligns with the broader shift towards interpretable AI and the integration of diverse AI paradigms for more comprehensive knowledge representation and reasoning.

\subsection{Integrating Logical and Rule-Based Reasoning}
The integration of explicit logical principles and rule-based reasoning into KGE models represents a significant step towards enhancing their interpretability and robustness. Traditional embedding models often learn implicit patterns, which can be brittle or difficult to explain. By embedding logical structures, models can adhere to known axioms and infer facts in a more principled manner.

One approach to embedding logical principles is demonstrated by the "logical-default attention graph convolution neural network" (LDAGCN) \cite{li2025}. While the full details are not provided, the title suggests an attempt to infuse logical principles or default assumptions directly into the attention mechanism of a Graph Convolutional Network (GCN). This implies guiding the neural network's aggregation process with structured reasoning, potentially allowing the model to prioritize certain paths or relationships based on predefined logical rules (e.g., transitivity, symmetry) or to handle missing information through default inferences. Such an explicit guidance mechanism, if effectively implemented, could lead to more robust embeddings that align with human-understandable logic, thereby improving both performance and interpretability in link prediction tasks. This method falls under the "Graph Neural Network-based Models with Focus on Extrapolation and Interpretability" taxonomy, as it leverages GNNs to integrate reasoning for better generalization.

Another distinct direction is the use of fuzzy logic to define logical operators, as seen in \textbf{FuzzQE} \cite{chen2021}. This framework addresses the challenge of answering complex First-Order Logical (FOL) queries on incomplete knowledge graphs. Unlike previous methods that relied on parameterized logical operators often lacking axiomatic consistency and requiring extensive complex query training data, FuzzQE defines its logical operators (e.g., conjunction, disjunction, negation) in a principled and learning-free manner based on fuzzy logic. This ensures axiomatic consistency, a crucial aspect for reliable reasoning, and significantly reduces the reliance on large, difficult-to-collect complex query datasets. By only requiring learning for entity and relation embeddings, FuzzQE offers a data-efficient and robust solution for logical query answering. The ability of FuzzQE to achieve comparable performance even when trained solely on KG link prediction data, without complex query supervision, highlights the power of grounding logical operations in a mathematically sound framework. This represents a novel methodological path within the "Advanced Reasoning Mechanisms for Knowledge Graph Embeddings" group, specifically Subgroup 1.1, by shifting from empirical operator learning to axiomatically sound, fuzzy-logic-based definitions.

\subsection{Enhancing KGE with Analogical Inference}
Analogical inference, a cornerstone of human cognition, involves transferring knowledge or understanding from a familiar situation (source) to an unfamiliar one (target) based on perceived similarities. Integrating this form of reasoning into KGE models can significantly enhance their ability to infer incomplete triples, especially in inductive settings where direct evidence is scarce.

\textbf{AnKGE (Analogical Inference Enhanced Knowledge Graph Embedding)} \cite{yao2023} proposes a novel self-supervised framework that explicitly imbues KGE models with analogical inference capabilities. The core of AnKGE lies in its "analogical object retriever," which identifies relevant analogical objects at three distinct levels: entity-level, relation-level, and triple-level. For instance, at the entity level, it might identify entities that play similar roles in different contexts, while at the relation level, it could find relations that exhibit similar patterns of interaction. AnKGE then trains dedicated "analogy functions" for each level, taking embeddings from a pre-trained base KGE model as input and outputting analogical object embeddings. The final prediction score for a triple is derived by adaptively interpolating the analogy score with the base KGE model's score, using learned weights. This adaptive combination allows AnKGE to leverage both the inductive inference capabilities of the base model and the enhanced analogical reasoning, leading to improved link prediction and better handling of incomplete data.

The significance of AnKGE lies in its systematic approach to integrating analogical reasoning. By explicitly retrieving and modeling analogies at multiple granularities, it provides a more nuanced way to generalize from observed patterns. This moves beyond simple similarity matching in embedding space to a more structured form of relational inference. The framework's self-supervised nature also reduces the need for extensive labeled analogical data, making it practical for real-world knowledge graphs. AnKGE's success on benchmark datasets like FB15k-237 and WN18RR demonstrates that analogical inference can effectively complement traditional KGE methods, offering a distinct form of reasoning that helps bridge knowledge gaps and improve inductive capabilities. This work represents a new method path under the "Advanced Reasoning Mechanisms for Knowledge Graph Embeddings" group, specifically Subgroup 1.2, by introducing a multi-level, adaptive framework for analogical inference.

\subsection{Combining Embeddings with Graph Patterns and Observed Features}
Hybrid approaches that combine the representational power of embedding models with the explicit structure of symbolic graph patterns or observed features offer a compelling pathway towards more transparent and robust knowledge completion. These methods aim to leverage the strengths of both paradigms: the continuous, dense representations of embeddings for capturing nuanced semantics, and the discrete, interpretable nature of graph patterns for explainability and logical consistency.

One prominent example is \textbf{GRank (Graph Pattern Entity Ranking Model)} \cite{ebisu2019}. This model directly addresses the "black box" nature of many KGE models by focusing on interpretability through explicit graph patterns. Instead of relying solely on learned embeddings, GRank utilizes observable graph patterns within the knowledge graph to construct an entity ranking system for each pattern. This allows for the identification of patterns that are most helpful for a given prediction, providing a human-readable explanation for the model's output. By shifting the focus from purely numerical embedding operations to leveraging explicit graph structure, GRank demonstrates that KGC can be achieved and understood through interpretable patterns, offering a valuable alternative or complement to opaque vector spaces. This approach is a key component of the "Phase 2: Expanding Beyond Pure Embeddings - Interpretability and Integration" in the development direction, highlighting a pivot towards transparency.

Further advancing this hybrid philosophy, \cite{ebisu2019} also proposed a framework that offers a "Combination of Unified Embedding Model and Observed Features for Knowledge Graph Completion." This work provides an integrated view by reinterpreting state-of-the-art embedding models (such as ComplEx and \textbf{TorusE} \cite{ebisu2017}) as variants of translation-based models that implicitly utilize paths. Building on this insight, the authors propose a faster method for evaluating rules based on this path-centric understanding and then explicitly combine an embedding model with "observed feature models" (which also leverage paths) to predict missing triples. This approach effectively bridges the gap between continuous embeddings and symbolic rule-based methods by revealing their underlying connection through graph paths. The resulting framework aims for improved performance, faster rule evaluation, and enhanced interpretability by linking dense embeddings to observable, human-understandable features and paths.

In a more recent development, \textbf{GNN-FTuckER} \cite{li2025} exemplifies a powerful hybrid architecture by integrating a Graph Neural Network (GNN) encoder with an improved TuckER model decoder. Specifically, it employs the \textbf{SE-GNN} structural encoder \cite{li2021}, which explicitly models semantic evidences at relation, entity, and triple levels through attention-based aggregation. This allows GNN-FTuckER to capture rich semantic and structural information from the global graph. The enhanced TuckER decoder, incorporating a non-linear activation function, then leverages these embeddings to model complex, non-linear relationships. This end-to-end hybrid model successfully combines the context-aware capabilities of GNNs with the interpretability and flexibility of tensor decomposition, demonstrating superior performance on link prediction tasks across various datasets.

Beyond traditional KGC, highly advanced hybrid approaches are emerging in scientific discovery. \cite{buehler2024} presents a groundbreaking framework that uses generative AI to extract knowledge from scientific papers into an ontological knowledge graph. This system combines a large language embedding model for deep node representations with combinatorial node similarity ranking and path sampling to link dissimilar concepts. Crucially, it employs multimodal intelligent graph reasoning (transitive, isomorphic properties) across diverse data modalities (graphs, images, text, numerical data), even integrating artistic principles for novel material design. This highly integrated, multimodal approach represents the pinnacle of hybrid reasoning for scientific discovery, moving beyond simple completion to generating novel insights and designs. Similarly, \cite{ghafarollahi2024} introduces a multi-agent AI model that integrates Large Language Models (LLMs) with a novel Graph Neural Network (GNN) for rapid retrieval of atomic-scale physical properties in alloy design. This system dynamically explores vast compositional spaces by synergizing GNN predictions with LLM-driven reasoning and physics-based theories, demonstrating a robust hybrid approach for automated scientific discovery. These cutting-edge systems, falling under the "Generative AI and Multimodal Reasoning for Scientific Discovery" group, showcase the transformative potential of combining diverse AI paradigms for transparent and robust knowledge generation.

\label{sec:7._scalability_and_efficiency_for_large-scale_knowledge_graphs}

\section{Scalability and Efficiency for Large-Scale Knowledge Graphs}
The practical application of Knowledge Graph Embedding (KGE) models to real-world knowledge graphs (KGs) is often hampered by significant scalability and efficiency challenges. As KGs grow to encompass billions of entities and relations, the parameter storage cost and computational burden associated with traditional KGE methods become prohibitive. This section addresses these critical issues by reviewing advanced techniques designed to reduce model complexity and enhance operational efficiency. We explore parameter-efficient representation learning methods that mitigate the linear growth of embedding parameters and delve into strategies for managing large-scale, dynamic KGs, including those that implicitly support efficient deployment through continual learning. These advancements are crucial for enabling KGE models to move beyond benchmark datasets and into massive, evolving industrial and scientific applications, aligning with the broader challenges of Group 2: Addressing Scalability and Temporal Dynamics in KGEs, particularly Subgroup 2.1: Parameter-Efficient Representation Learning.

\subsection{Parameter-Efficient Representation Learning}
Traditional Knowledge Graph Embedding (KGE) models typically assign a unique vector embedding to every entity and relation in the graph. While effective for capturing semantic information, this approach leads to a parameter count that scales linearly with the number of entities and relations. For massive, real-world knowledge graphs, this results in exorbitant memory requirements and computational costs, hindering training and deployment. Parameter-efficient representation learning addresses this by devising methods that reduce the number of learnable parameters without sacrificing expressive power.

A significant stride in this direction is the \textbf{Entity-Agnostic Representation Learning (EARL)} method \cite{chen2023}. EARL tackles the parameter storage problem by fundamentally altering how entity embeddings are generated. Instead of learning and storing embeddings for all entities, EARL maintains embeddings for only a small, pre-defined set of "reserved entities." For all other entities, their representations are dynamically generated by universal, entity-agnostic encoders that process their contextual information, including connected relations, k-nearest reserved entities, and multi-hop neighbors. This innovative approach allows EARL to achieve a static and significantly lower parameter count, largely independent of the total number of entities in the knowledge graph. Experimental results demonstrate that EARL not only uses fewer parameters but also achieves superior performance on link prediction tasks, highlighting its effectiveness in balancing efficiency and accuracy \cite{chen2023}. This method directly falls under Subgroup 2.1: Parameter-Efficient Representation Learning, offering a novel paradigm for resource-constrained KGE.

Further advancements in parameter efficiency, particularly for dynamic and continually evolving knowledge graphs, are seen in techniques like \textbf{Incremental LoRA (Low-Rank Adaptation)} \cite{liu2024} and \textbf{Efficient Task-driven Tokens (ETT-CKGE)} \cite{zhu2025}. LoRA-based methods, originally popular in large language models, adapt a pre-trained model to new tasks or data by injecting small, low-rank matrices into existing layers, significantly reducing the number of trainable parameters compared to full fine-tuning. Applying this to KGEs, as in \cite{liu2024}, enables fast and continual learning by incrementally adapting to new knowledge without catastrophic forgetting, which is crucial for large-scale KGs that are constantly updated. Similarly, ETT-CKGE \cite{zhu2025} proposes using efficient task-driven tokens for continual KGE, suggesting a parameter-efficient mechanism to represent and update knowledge in a dynamic setting. These methods represent a shift towards adaptive and modular parameterization, ensuring that KGE models remain viable and efficient even as knowledge graphs expand and evolve.

\subsection{Strategies for Large-Scale Deployment and Dynamic KGs}
Deploying KGE models on truly massive knowledge graphs necessitates strategies that go beyond mere parameter reduction, encompassing efficient training, inference, and adaptation to dynamic changes. While traditional approaches often involve parallel computing and graph partitioning to distribute the computational load and memory footprint across multiple machines, recent research also focuses on continual learning paradigms to maintain efficiency for evolving large-scale KGs. These methods are critical for real-world applications where KGs are constantly updated with new facts, entities, and relations.

For static, large graphs, graph partitioning techniques divide the graph into smaller, manageable subgraphs that can be processed in parallel, either on a single machine with multiple GPUs or across a distributed cluster. This reduces the memory footprint per processing unit and allows for concurrent computation. While not explicitly detailed in the provided summaries, the underlying need for such strategies is evident in the context of large-scale systems like those described by \cite{ghafarollahi2024} and \cite{buehler2024}, which leverage GNNs and LLMs for scientific discovery over vast knowledge bases. These systems implicitly rely on efficient graph processing to handle the immense data volumes and complex interactions involved in tasks like alloy design or materials analysis. The "rapid predictive model" and "overcoming the computational bottleneck" mentioned in \cite{ghafarollahi2024} underscore the imperative for efficient underlying graph operations.

For dynamic knowledge graphs, which are prevalent in real-world scenarios, continual learning approaches are paramount for maintaining efficiency and scalability. Instead of retraining KGE models from scratch with every update, continual learning allows models to incrementally learn new information while retaining previously acquired knowledge, thereby saving significant computational resources. Methods like \textbf{Incremental Distillation} \cite{liu2024} and \textbf{Bayesian-Guided Continual KGE} \cite{li2025} are designed to address the challenge of catastrophic forgetting, a common issue in continual learning where new knowledge overwrites old. Incremental distillation, for instance, leverages knowledge transfer from an old model to a new one, ensuring that the model remains up-to-date without full retraining. Similarly, \textbf{Scale-Aware Gradual Evolution (SAGE)} \cite{li2025} and \textbf{A Generative Adaptive Replay Continual Learning Model} \cite{zhang2025} offer mechanisms for KGE models to adapt to growing and changing KGs efficiently. These continual learning strategies, by enabling efficient updates and reducing redundant computations, are indispensable for the scalable and sustainable deployment of KGE models in large-scale, dynamic environments, ensuring that the models remain relevant and performant over time.

\label{sec:8._emerging_trends_and_applications}

\section{Emerging Trends and Applications}
The landscape of Knowledge Graph Embedding (KGE) and related Artificial Intelligence (AI) techniques is rapidly evolving, pushing the boundaries of what is possible in scientific discovery and complex data analysis. This section delves into two cutting-edge research directions that exemplify this trend: the integration of generative AI and multimodal data for accelerating scientific discovery, particularly in materials science, and advanced deep learning methods for trajectory analysis. These emerging areas highlight a shift towards more autonomous, intelligent, and context-aware AI systems capable of extracting nuanced knowledge, reasoning across diverse data modalities, and making predictions in dynamic environments. By leveraging sophisticated graph-based representations, multi-agent architectures, and novel embedding techniques, researchers are addressing long-standing challenges in fields ranging from materials design to urban computing, demonstrating the transformative potential of next-generation AI.

\subsection{Generative AI and Multimodal Reasoning for Scientific Discovery}
The acceleration of scientific discovery, particularly in complex domains like materials science, is increasingly reliant on AI systems that can not only process vast amounts of data but also generate novel hypotheses and designs. This area of research is characterized by the synergistic integration of generative AI, multimodal data processing, and sophisticated graph-based reasoning, often orchestrated within multi-agent frameworks. The overarching development direction in this field is towards fully autonomous scientific discovery systems, moving from foundational knowledge representation to iterative design, simulation, and self-correction.

\subsubsection{Generative Knowledge Extraction and Graph-based Representation}
A fundamental step in accelerating scientific discovery is the ability to systematically extract and structure knowledge from the ever-growing corpus of scientific literature and diverse data sources. Traditional methods often struggle with the sheer volume and heterogeneity of scientific data, necessitating advanced AI techniques. A pioneering approach in this regard involves leveraging generative AI to transform unstructured scientific papers into comprehensive ontological knowledge graphs \cite{buehler2024}. This methodology, as demonstrated by \cite{buehler2024}, takes a dataset of scientific papers (e.g., 1000 papers on biological materials) and converts them into a structured knowledge graph, enabling in-depth structural analysis. Such analysis reveals inherent properties like scale-free networks and high connectedness, providing a rich foundation for downstream reasoning.

The core innovation lies in the use of generative AI for automated knowledge extraction, which significantly reduces the manual effort typically required for knowledge graph construction. Furthermore, the integration of multimodal dataincluding graphs, images, text, and numerical datainto these representations is crucial. By employing large language embedding models, deep node representations are computed, allowing for combinatorial node similarity ranking and path sampling strategies. This enables the system to link previously unrelated or dissimilar concepts, fostering interdisciplinary insights. For instance, \cite{buehler2024} showed how this approach could reveal structural parallels between biological materials and Beethoven's 9th Symphony through isomorphic mapping, or propose novel mycelium-based composites inspired by Kandinsky's 'Composition VII' painting. This generative approach to knowledge graph construction and multimodal representation forms the bedrock for more advanced reasoning and design tasks, transcending disciplinary boundaries and achieving a higher degree of novelty and explorative capacity than conventional methods.

\subsubsection{Multimodal Intelligent Graph Reasoning and Multi-Agent Systems}
Building upon robust knowledge extraction and graph-based representation, the next frontier involves intelligent reasoning and the orchestration of AI components into multi-agent systems for complex scientific problems. This development direction moves towards creating AI systems that can not only understand existing knowledge but also actively participate in the scientific process, from ideation to experimental design and validation.

The concept of multi-agent AI systems, where specialized agents collaborate to solve complex problems, is gaining traction. AtomAgents \cite{ghafarollahi2024} exemplifies this by introducing a physics-aware multi-modal multi-agent AI for alloy design and discovery. This system synergizes Large Language Models (LLMs) with specialized AI agents, each possessing expertise in areas such as knowledge retrieval, multimodal data integration, and crucially, physics-based simulations. This collaborative framework allows for addressing multi-scale problems and integrating fundamental scientific principles, moving beyond purely data-driven approaches. Further enhancing the capabilities of these LLM-driven agents, research by \cite{lu2024} explores various fine-tuning strategies and model merging techniques for domain adaptation in materials science. This work demonstrates that merging multiple fine-tuned models can lead to emergent capabilities, significantly boosting domain-specific performance and enabling new functionalities essential for sophisticated multi-agent systems.

The efficiency of these multi-agent systems is further optimized by integrating specialized tools. For instance, \cite{ghafarollahi2024} (Rapid and Automated Alloy Design...) refines the multi-agent approach by incorporating a novel Graph Neural Network (GNN) model for rapid retrieval of atomic-scale physical properties, such as Peierls barrier and dislocation interaction energy. This GNN acts as a fast surrogate for computationally expensive atomistic simulations, reducing the burden on the LLM-driven system while maintaining physics awareness. The culmination of these advancements is seen in the vision of fully autonomous scientific discovery. SparksMatter \cite{ghafarollahi2025} proposes a multi-agent AI model designed to execute the entire inorganic materials discovery cycle autonomously, encompassing ideation, planning, experimental workflow generation, continuous evaluation, iterative refinement, and even self-critique. This represents a profound shift towards AI-driven scientific innovation, where multi-agent systems, powered by advanced LLMs and specialized AI tools, can independently navigate the complexities of scientific research, identifying gaps, proposing novel designs, and suggesting rigorous validation steps.

\subsection{Advanced Deep Learning for Trajectory Analysis}
Beyond scientific discovery, cutting-edge deep learning techniques are also transforming the analysis of complex spatio-temporal data, such as trajectories. Trajectory similarity computation is a fundamental task for numerous spatial information applications, but existing deep learning methods often suffer from limitations in embedding quality, generality, and the heavy preprocessing burden for training. Addressing these challenges involves novel approaches in spatial contextual embedding, prompt-enhanced trajectory embedding, and self-supervised learning for similarity.

A significant advancement in this domain is the KGTS (Knowledge Graph Trajectory Similarity) framework \cite{chen2024}. KGTS integrates three key methodological components to achieve superior performance and generality. Firstly, it employs a \textbf{Knowledge Graph Grid Embedding (GRot embedding)} method for spatial contextual embedding. This technique vigorously grasps the neighboring relations of map grids, providing a rich, structured representation of the underlying geographical environment. By embedding spatial units as part of a knowledge graph, KGTS effectively captures intricate spatial relationships that are crucial for understanding trajectory movements. This approach falls under the taxonomy of spatial contextual embedding, where graph-based techniques are leveraged to encode geographical context.

Secondly, KGTS introduces a \textbf{Prompt Trajectory Embedding Network}. This network incorporates the learned grid embeddings and extracts essential trajectory structure and point order information. A critical innovation here is the use of a customized prompt paradigm. This paradigm is specifically designed to mitigate the representational gap between the static grid embeddings and the dynamic trajectory embeddings, thereby enhancing the quality and relevance of the trajectory representations. This prompt-enhanced embedding strategy allows the model to better understand the sequential and contextual nuances of movement patterns, which is vital for accurate similarity computation.

Finally, the prompt trajectory embedding network in KGTS is trained using \textbf{unsupervised contrastive learning} \cite{chen2024}. This method is particularly impactful as it not only alleviates the heavy preprocessing burden typically associated with labeled similarity pairs but also provides exceptional generality. By creatively designing strategies for positive sample generation, KGTS learns a robust metric space where similar trajectories are drawn closer and dissimilar ones pushed apart, all without explicit human annotation of similarity. This self-supervised approach significantly improves the model's applicability across diverse datasets and scenarios, making it a highly generalizable solution for trajectory similarity computation. The synergistic combination of these three advanced deep learning techniquesknowledge graph grid embedding, prompt-enhanced trajectory embedding, and unsupervised contrastive learningpositions KGTS as a state-of-the-art framework that addresses critical limitations in trajectory analysis, offering a powerful tool for various spatial information applications.

\label{sec:9._conclusion_and_future_directions}

\section{Conclusion and Future Directions}
The preceding sections have highlighted the profound advancements and diverse methodological landscape within Knowledge Graph Embedding (KGE) and its specialized subfields, particularly Temporal Knowledge Graphs (TKGs). We have observed a significant evolution from foundational translation-based models to sophisticated geometric transformations, hybrid neural architectures, and the burgeoning integration with large language models (LLMs) for complex scientific discovery. This trajectory underscores a continuous drive towards more expressive, context-aware, and intelligent systems capable of representing, reasoning over, and extending knowledge in dynamic and multimodal environments. While substantial progress has been made in capturing intricate relational patterns and temporal dynamics, persistent challenges remain, paving the way for exciting future research avenues. This concluding section synthesizes these key advancements, identifies critical open problems, and outlines promising directions that will shape the next generation of knowledge-centric AI.

\subsection{Summary of Key Advancements}
The development in Temporal Knowledge Graph (TKG) representation learning, as illustrated by the reviewed literature, showcases a clear progression towards increasingly sophisticated modeling of dynamic facts and relations over time. Initial forays into geometric transformations, such as the rotation-based embeddings introduced by ChronoR \cite{sadeghian2021}, demonstrated the efficacy of high-dimensional rotations in capturing rich temporal and multi-relational interactions. This foundational work established rotations as a powerful mechanism for modeling temporal dynamics, outperforming earlier state-of-the-art methods for temporal link prediction.

Building upon this, the field advanced into more expressive algebraic spaces. RotateQVS \cite{chen2022} extended the rotation concept by leveraging Quaternion Vector Space, representing temporal entities as rotations and relations as complex vectors within Hamilton's quaternion space. This move significantly enhanced the expressiveness of rotation-based models, theoretically demonstrating the ability to capture complex relation patterns like symmetry, asymmetry, inverse, and crucial temporal evolution, which simpler complex-number-based approaches struggled with. Further sophistication was achieved by models like TCompoundE \cite{ying2024}, which employed compound geometric operations (translation and scaling) for both relations and timestamps. This approach allowed for a more nuanced capture of both time-varying and time-invariant features within relations, proving superior to single-operation methods across various benchmark datasets. Complementary to these core embedding mechanisms, research also focused on ensuring temporal consistency and sensitivity. Methods like those employing temporal smoothness regularizers \cite{dileo2023} highlighted the importance of coherent embedding evolution over time, while models leveraging complex space with attention mechanisms addressed the varying relevance of temporal information for different facts \cite{cai2024}.

Beyond temporal aspects, general KGE advancements have focused on improving the handling of complex relation patterns and enhancing interpretability. TransH \cite{wang2014} addressed the limitations of early translation models like TransE by projecting entities onto relation-specific hyperplanes, allowing for distributed representations that better handle one-to-many, many-to-one, and many-to-many relations. RatE \cite{huang2020} further refined translating embeddings in complex space by introducing relation-adaptive weighted products and local-cognitive negative sampling, explicitly alleviating embedding ambiguity caused by one-to-many relations. The concept of Semantic Evidence (SE) \cite{li2021} provided a crucial theoretical framework, identifying and quantifying relation, entity, and triple-level semantic relatedness as drivers for KGE extrapolation, leading to models like SE-GNN. This synthesis of geometric, algebraic, and semantic insights culminated in hybrid models such as GNN-FTuckER \cite{li2025}, which integrates GNN encoders with enhanced tensor decomposition decoders to capture both structural context and non-linear relationships, demonstrating superior performance in specialized domains like tea suitability prediction. These diverse advancements collectively underscore a maturing field that continually seeks more powerful, flexible, and interpretable ways to represent and reason with knowledge.

\subsection{Open Challenges}
Despite the significant strides in KGE and TKG representation learning, several persistent open challenges demand further research and innovation. One critical challenge is the \textbf{robust handling of extreme sparsity} within knowledge graphs. While models like SE-GNN \cite{li2021} have improved extrapolation to unseen data by leveraging semantic evidence, many real-world KGs, especially in emerging scientific domains, suffer from very few observed facts for certain entities or relations. This extreme sparsity makes it difficult for embedding models to learn meaningful representations, leading to poor generalization and unreliable predictions. Developing KGE models that can effectively infer knowledge from minimal evidence, perhaps through meta-learning \cite{chen2023} or few-shot learning techniques, remains a key area.

Another significant hurdle lies in \textbf{real-time inference and dynamic updates}. As knowledge graphs are constantly evolving, particularly in domains like news or scientific discovery, the ability to perform real-time link prediction or update embeddings efficiently without retraining the entire model is crucial. Current models often require extensive retraining, which is computationally prohibitive for large-scale, frequently changing KGs. This challenge is particularly acute for TKGs, where new events and facts are continuously added, necessitating efficient continual learning strategies \cite{liu2024, li2025, zhang2025}. Furthermore, ensuring \textbf{ethical considerations} and mitigating biases embedded within KGEs is paramount. Knowledge graphs, and by extension their embeddings, can reflect and amplify societal biases present in their source data. Addressing issues of fairness, transparency, and accountability in KGE models, especially when applied in sensitive domains like healthcare or legal systems, is an underdeveloped but vital research direction. This includes developing methods to detect and debias embeddings, and ensuring that model predictions do not perpetuate harmful stereotypes or discrimination. Finally, \textbf{scalability to truly massive and heterogeneous knowledge graphs} remains a concern. While many models perform well on benchmark datasets, their computational complexity often limits their applicability to KGs with billions of entities and relations, or those integrating highly diverse data types. Efficient architectures and distributed training paradigms are essential to unlock the full potential of KGE in real-world, large-scale applications.

\subsection{Promising Research Avenues}
The identified challenges naturally lead to several promising research avenues that are poised to drive the next wave of innovation in KGE. A foremost direction is the \textbf{further integration with large language models (LLMs)}. The synergy between KGEs and LLMs holds immense potential, as LLMs offer powerful reasoning, generation, and natural language understanding capabilities that can complement the structured knowledge of KGs. Research in this area, exemplified by multi-agent systems like AtomAgents \cite{ghafarollahi2024} and the vision of autonomous scientific discovery \cite{ghafarollahi2025}, demonstrates how LLMs can orchestrate specialized AI agents, leverage GNNs for rapid property prediction, and integrate multimodal data to accelerate complex tasks like alloy design. The ability of LLMs to perform generative knowledge extraction \cite{buehler2024} and adapt to specific domains through fine-tuning and model merging \cite{lu2024} will be critical in building more intelligent and autonomous scientific discovery platforms.

Another vital direction is the development of \textbf{Explainable AI (XAI) for KGE}. As KGE models become more complex, their black-box nature can hinder trust and adoption, especially in high-stakes applications. Future research should focus on developing methods that can elucidate \textit{why} a particular link prediction was made or \textit{how} an entity's embedding contributes to a specific inference. This could involve leveraging the interpretability inherent in geometric models \cite{chen2022} or explicitly tracing the influence of semantic evidence \cite{li2021} through the embedding process. Techniques such as attention mechanisms, feature attribution, and counterfactual explanations could provide valuable insights into model decisions, fostering greater transparency and user confidence.

Finally, expanding \textbf{applications in complex scientific domains} represents a vast and impactful research avenue. The success of KGE in materials science \cite{ghafarollahi2024, ghafarollahi2025} and specialized agricultural contexts \cite{li2025} highlights its transformative potential. Future work will likely see KGE applied to a broader spectrum of scientific fields, including drug discovery, environmental modeling, and personalized medicine, where the ability to integrate heterogeneous data and uncover hidden relationships is paramount. This also extends to complex spatio-temporal domains like trajectory analysis, where frameworks like KGTS \cite{chen2024} combine knowledge graph grid embeddings, prompt-enhanced trajectory embeddings, and unsupervised contrastive learning to achieve superior performance. Such applications will necessitate the development of highly specialized KGE models that can handle domain-specific constraints, leverage multimodal data (e.g., images, sensor data, experimental results), and integrate with domain-specific simulation tools, ultimately accelerating scientific discovery and innovation across disciplines.

\newpage
\section*{References}
\addcontentsline{toc}{section}{References}

\begin{thebibliography}{92}

\bibitem{ghafarollahi2024}
Alireza Ghafarollahi, and Markus J. Buehler (2024). \textit{Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems}. arXiv.org.

\bibitem{li2021}
Ren Li, Yanan Cao, Qiannan Zhu, et al. (2021). \textit{How Does Knowledge Graph Embedding Extrapolate to Unseen Data: a Semantic Evidence View}. AAAI Conference on Artificial Intelligence.

\bibitem{li2025}
Jun Li, Bing Yang, Jiaxin Liu, et al. (2025). \textit{GNN-FTuckER: A novel link prediction model for identifying suitable populations for tea varieties}. PLoS ONE.

\bibitem{ying2024}
Rui Ying, Mengting Hu, Jianfeng Wu, et al. (2024). \textit{Simple but Effective Compound Geometric Operations for Temporal Knowledge Graph Completion}. Annual Meeting of the Association for Computational Linguistics.

\bibitem{chen2022}
Kai Chen, Ye Wang, Yitong Li, et al. (2022). \textit{RotateQVS: Representing Temporal Information as Rotations in Quaternion Vector Space for Temporal Knowledge Graph Completion}. Annual Meeting of the Association for Computational Linguistics.

\bibitem{wang2014}
Zhen Wang, Jianwen Zhang, Jianlin Feng, et al. (2014). \textit{Knowledge Graph Embedding by Translating on Hyperplanes}. AAAI Conference on Artificial Intelligence.

\bibitem{huang2020}
Hao Huang, Guodong Long, Tao Shen, et al. (2020). \textit{RatE: Relation-Adaptive Translating Embedding for Knowledge Graph Completion}. International Conference on Computational Linguistics.

\bibitem{mathur2024}
Shray Mathur, Noah van der Vleuten, Kevin Yager, et al. (2024). \textit{VISION: a modular AI assistant for natural human-instrument interaction at scientific user facilities}. Machine Learning: Science and Technology.

\bibitem{ebisu2019}
Takuma Ebisu, and R. Ichise (2019). \textit{Graph Pattern Entity Ranking Model for Knowledge Graph Completion}. North American Chapter of the Association for Computational Linguistics.

\bibitem{chen2023}
Zhongwu Chen, Chengjin Xu, Fenglong Su, et al. (2023). \textit{Meta-Learning Based Knowledge Extrapolation for Temporal Knowledge Graph}. The Web Conference.

\bibitem{sadeghian2021}
A. Sadeghian, Mohammadreza Armandpour, Anthony Colas, et al. (2021). \textit{ChronoR: Rotation Based Temporal Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{cai2024}
Lianshang Cai, Xin Mao, Zhihong Wang, et al. (2024). \textit{Temporal Knowledge Graph Completion with Time-sensitive Relations in Hypercomplex Space}. arXiv.org.

\bibitem{wang2024}
Tao Wang, Bo Shen, Jinglin Zhang, et al. (2024). \textit{Knowledge Graph Embedding via Triplet Component Interactions}. Neural Processing Letters.

\bibitem{cai2024}
Lianshang Cai, Xin Mao, Yuhao Zhou, et al. (2024). \textit{A Survey on Temporal Knowledge Graph: Representation Learning and Applications}. arXiv.org.

\bibitem{ghafarollahi2024}
Alireza Ghafarollahi, and Markus J. Buehler (2024). \textit{AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence}. arXiv.org.

\bibitem{ghafarollahi2025}
Alireza Ghafarollahi, and Markus J. Buehler (2025). \textit{Autonomous Inorganic Materials Discovery via Multi-Agent Physics-Aware Scientific Reasoning}. Unpublished manuscript.

\bibitem{buehler2024}
Markus J. Buehler (2024). \textit{Cephalo: MultiModal VisionLanguage Models for BioInspired Materials Analysis and Design}. Advanced Functional Materials.

\bibitem{zhu2025}
Lijing Zhu, Qizhen Lan, Qing Tian, et al. (2025). \textit{ETT-CKGE: Efficient Task-driven Tokens for Continual Knowledge Graph Embedding}. arXiv.org.

\bibitem{dileo2023}
Manuel Dileo, Pasquale Minervini, Matteo Zignani, et al. (2023). \textit{Temporal Smoothness Regularisers for Neural Link Predictors}. arXiv.org.

\bibitem{berkovich2024}
Jaime A. Berkovich, and Markus J. Buehler (2024). \textit{LifeGPT: Topology-Agnostic Generative Pretrained Transformer Model for Cellular Automata}. npj Artificial Intelligence.

\bibitem{ebisu2017}
Takuma Ebisu, and R. Ichise (2017). \textit{TorusE: Knowledge Graph Embedding on a Lie Group}. AAAI Conference on Artificial Intelligence.

\bibitem{sun2025}
Guiquan Sun, Xikun Zhang, Jingchao Ni, et al. (2025). \textit{Towards Heterogeneous Continual Graph Learning via Meta-knowledge Distillation}. arXiv.org.

\bibitem{lu2024}
Wei Lu, Rachel K. Luu, and Markus J. Buehler (2024). \textit{Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities}. npj Computational Materials.

\bibitem{buehler2024}
Markus J. Buehler (2024). \textit{Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning}. Machine Learning: Science and Technology.

\bibitem{zhu2024}
Yushan Zhu, Wen Zhang, Zhiqiang Liu, et al. (2024). \textit{Croppable Knowledge Graph Embedding}. Annual Meeting of the Association for Computational Linguistics.

\bibitem{fan2023}
Zhiguang Fan, Yuedong Yang, Mingyuan Xu, et al. (2023). \textit{Node-based Knowledge Graph Contrastive Learning for Medical Relationship Prediction}. arXiv.org.

\bibitem{liu2025}
Jiajun Liu, Wenjun Ke, Peng Wang, et al. (2025). \textit{Unlearning of Knowledge Graph Embedding via Preference Optimization}. arXiv.org.

\bibitem{buehler2024}
Markus J. Buehler (2024). \textit{PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking}. npj Artificial Intelligence.

\bibitem{rubaiat2025}
Sajratul Y. Rubaiat, and Hasan M. Jamil (2025). \textit{Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models}. arXiv.org.

\bibitem{li2025}
Linyu Li, Zhi Jin, Yuanpeng He, et al. (2025). \textit{Learning to Evolve: Bayesian-Guided Continual Knowledge Graph Embedding}. arXiv.org.

\bibitem{liu2024}
Jiajun Liu, Wenjun Ke, Peng Wang, et al. (2024). \textit{Fast and Continual Knowledge Graph Embedding via Incremental LoRA}. International Joint Conference on Artificial Intelligence.

\bibitem{zhang2025}
Zhiyu Zhang, Wei Chen, Youfang Lin, et al. (2025). \textit{A Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning}. Annual Meeting of the Association for Computational Linguistics.

\bibitem{ebisu2019}
Takuma Ebisu, and R. Ichise (2019). \textit{Combination of Unified Embedding Model and Observed Features for Knowledge Graph Completion}. arXiv.org.

\bibitem{li2025}
Yifei Li, Lingling Zhang, Hang Yan, et al. (2025). \textit{SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding}. Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2.

\bibitem{nayyeri2019}
M. Nayyeri, Chengjin Xu, Yadollah Yaghoobzadeh, et al. (2019). \textit{On the Knowledge Graph Completion Using Translation Based Embedding: The Loss Is as Important as the Score}. arXiv.org.

\bibitem{liu2024}
Jiajun Liu, Wenjun Ke, Peng Wang, et al. (2024). \textit{Towards Continual Knowledge Graph Embedding via Incremental Distillation}. AAAI Conference on Artificial Intelligence.

\bibitem{li2021}
Ren Li, Yanan Cao, Qiannan Zhu, et al. (2021). \textit{How Does Knowledge Graph Embedding Extrapolate to Unseen Data: a Semantic Evidence View}. AAAI Conference on Artificial Intelligence.

\bibitem{chen2023}
Mingyang Chen, Wen Zhang, Zhen Yao, et al. (2023). \textit{Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{wang2014}
Zhen Wang, Jianwen Zhang, Jianlin Feng, et al. (2014). \textit{Knowledge Graph Embedding by Translating on Hyperplanes}. AAAI Conference on Artificial Intelligence.

\bibitem{yao2023}
Zhen Yao, Wen Zhang, Mingyang Chen, et al. (2023). \textit{Analogical Inference Enhanced Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{sadeghian2021}
A. Sadeghian, Mohammadreza Armandpour, Anthony Colas, et al. (2021). \textit{ChronoR: Rotation Based Temporal Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{chen2024}
Zhen Chen, Dalin Zhang, Shanshan Feng, et al. (2024). \textit{KGTS: Contrastive Trajectory Similarity Learning over Prompt Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{ebisu2017}
Takuma Ebisu, and R. Ichise (2017). \textit{TorusE: Knowledge Graph Embedding on a Lie Group}. AAAI Conference on Artificial Intelligence.

\bibitem{buehler2024}
Markus J. Buehler (2024). \textit{Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning}. Machine Learning: Science and Technology.

\bibitem{chen2021}
X. Chen, Ziniu Hu, and Yizhou Sun (2021). \textit{Fuzzy Logic based Logical Query Answering on Knowledge Graph}. AAAI Conference on Artificial Intelligence.

\bibitem{liu2024}
Jiajun Liu, Wenjun Ke, Peng Wang, et al. (2024). \textit{Towards Continual Knowledge Graph Embedding via Incremental Distillation}. AAAI Conference on Artificial Intelligence.

\bibitem{ghafarollahi2024}
Alireza Ghafarollahi, and Markus J. Buehler (2024). \textit{Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems}. arXiv.org.

\bibitem{li2021}
Ren Li, Yanan Cao, Qiannan Zhu, et al. (2021). \textit{How Does Knowledge Graph Embedding Extrapolate to Unseen Data: a Semantic Evidence View}. AAAI Conference on Artificial Intelligence.

\bibitem{li2025}
Jun Li, Bing Yang, Jiaxin Liu, et al. (2025). \textit{GNN-FTuckER: A novel link prediction model for identifying suitable populations for tea varieties}. PLoS ONE.

\bibitem{ying2024}
Rui Ying, Mengting Hu, Jianfeng Wu, et al. (2024). \textit{Simple but Effective Compound Geometric Operations for Temporal Knowledge Graph Completion}. Annual Meeting of the Association for Computational Linguistics.

\bibitem{chen2022}
Kai Chen, Ye Wang, Yitong Li, et al. (2022). \textit{RotateQVS: Representing Temporal Information as Rotations in Quaternion Vector Space for Temporal Knowledge Graph Completion}. Annual Meeting of the Association for Computational Linguistics.

\bibitem{wang2014}
Zhen Wang, Jianwen Zhang, Jianlin Feng, et al. (2014). \textit{Knowledge Graph Embedding by Translating on Hyperplanes}. AAAI Conference on Artificial Intelligence.

\bibitem{huang2020}
Hao Huang, Guodong Long, Tao Shen, et al. (2020). \textit{RatE: Relation-Adaptive Translating Embedding for Knowledge Graph Completion}. International Conference on Computational Linguistics.

\bibitem{mathur2024}
Shray Mathur, Noah van der Vleuten, Kevin Yager, et al. (2024). \textit{VISION: a modular AI assistant for natural human-instrument interaction at scientific user facilities}. Machine Learning: Science and Technology.

\bibitem{ebisu2019}
Takuma Ebisu, and R. Ichise (2019). \textit{Graph Pattern Entity Ranking Model for Knowledge Graph Completion}. North American Chapter of the Association for Computational Linguistics.

\bibitem{chen2023}
Zhongwu Chen, Chengjin Xu, Fenglong Su, et al. (2023). \textit{Meta-Learning Based Knowledge Extrapolation for Temporal Knowledge Graph}. The Web Conference.

\bibitem{sadeghian2021}
A. Sadeghian, Mohammadreza Armandpour, Anthony Colas, et al. (2021). \textit{ChronoR: Rotation Based Temporal Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{cai2024}
Lianshang Cai, Xin Mao, Zhihong Wang, et al. (2024). \textit{Temporal Knowledge Graph Completion with Time-sensitive Relations in Hypercomplex Space}. arXiv.org.

\bibitem{wang2024}
Tao Wang, Bo Shen, Jinglin Zhang, et al. (2024). \textit{Knowledge Graph Embedding via Triplet Component Interactions}. Neural Processing Letters.

\bibitem{cai2024}
Lianshang Cai, Xin Mao, Yuhao Zhou, et al. (2024). \textit{A Survey on Temporal Knowledge Graph: Representation Learning and Applications}. arXiv.org.

\bibitem{ghafarollahi2024}
Alireza Ghafarollahi, and Markus J. Buehler (2024). \textit{AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence}. arXiv.org.

\bibitem{ghafarollahi2025}
Alireza Ghafarollahi, and Markus J. Buehler (2025). \textit{Autonomous Inorganic Materials Discovery via Multi-Agent Physics-Aware Scientific Reasoning}. Unpublished manuscript.

\bibitem{buehler2024}
Markus J. Buehler (2024). \textit{Cephalo: MultiModal VisionLanguage Models for BioInspired Materials Analysis and Design}. Advanced Functional Materials.

\bibitem{zhu2025}
Lijing Zhu, Qizhen Lan, Qing Tian, et al. (2025). \textit{ETT-CKGE: Efficient Task-driven Tokens for Continual Knowledge Graph Embedding}. arXiv.org.

\bibitem{dileo2023}
Manuel Dileo, Pasquale Minervini, Matteo Zignani, et al. (2023). \textit{Temporal Smoothness Regularisers for Neural Link Predictors}. arXiv.org.

\bibitem{berkovich2024}
Jaime A. Berkovich, and Markus J. Buehler (2024). \textit{LifeGPT: Topology-Agnostic Generative Pretrained Transformer Model for Cellular Automata}. npj Artificial Intelligence.

\bibitem{ebisu2017}
Takuma Ebisu, and R. Ichise (2017). \textit{TorusE: Knowledge Graph Embedding on a Lie Group}. AAAI Conference on Artificial Intelligence.

\bibitem{sun2025}
Guiquan Sun, Xikun Zhang, Jingchao Ni, et al. (2025). \textit{Towards Heterogeneous Continual Graph Learning via Meta-knowledge Distillation}. arXiv.org.

\bibitem{lu2024}
Wei Lu, Rachel K. Luu, and Markus J. Buehler (2024). \textit{Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities}. npj Computational Materials.

\bibitem{buehler2024}
Markus J. Buehler (2024). \textit{Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning}. Machine Learning: Science and Technology.

\bibitem{zhu2024}
Yushan Zhu, Wen Zhang, Zhiqiang Liu, et al. (2024). \textit{Croppable Knowledge Graph Embedding}. Annual Meeting of the Association for Computational Linguistics.

\bibitem{fan2023}
Zhiguang Fan, Yuedong Yang, Mingyuan Xu, et al. (2023). \textit{Node-based Knowledge Graph Contrastive Learning for Medical Relationship Prediction}. arXiv.org.

\bibitem{liu2025}
Jiajun Liu, Wenjun Ke, Peng Wang, et al. (2025). \textit{Unlearning of Knowledge Graph Embedding via Preference Optimization}. arXiv.org.

\bibitem{buehler2024}
Markus J. Buehler (2024). \textit{PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking}. npj Artificial Intelligence.

\bibitem{rubaiat2025}
Sajratul Y. Rubaiat, and Hasan M. Jamil (2025). \textit{Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models}. arXiv.org.

\bibitem{li2025}
Linyu Li, Zhi Jin, Yuanpeng He, et al. (2025). \textit{Learning to Evolve: Bayesian-Guided Continual Knowledge Graph Embedding}. arXiv.org.

\bibitem{liu2024}
Jiajun Liu, Wenjun Ke, Peng Wang, et al. (2024). \textit{Fast and Continual Knowledge Graph Embedding via Incremental LoRA}. International Joint Conference on Artificial Intelligence.

\bibitem{zhang2025}
Zhiyu Zhang, Wei Chen, Youfang Lin, et al. (2025). \textit{A Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning}. Annual Meeting of the Association for Computational Linguistics.

\bibitem{ebisu2019}
Takuma Ebisu, and R. Ichise (2019). \textit{Combination of Unified Embedding Model and Observed Features for Knowledge Graph Completion}. arXiv.org.

\bibitem{li2025}
Yifei Li, Lingling Zhang, Hang Yan, et al. (2025). \textit{SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding}. Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2.

\bibitem{nayyeri2019}
M. Nayyeri, Chengjin Xu, Yadollah Yaghoobzadeh, et al. (2019). \textit{On the Knowledge Graph Completion Using Translation Based Embedding: The Loss Is as Important as the Score}. arXiv.org.

\bibitem{liu2024}
Jiajun Liu, Wenjun Ke, Peng Wang, et al. (2024). \textit{Towards Continual Knowledge Graph Embedding via Incremental Distillation}. AAAI Conference on Artificial Intelligence.

\bibitem{li2021}
Ren Li, Yanan Cao, Qiannan Zhu, et al. (2021). \textit{How Does Knowledge Graph Embedding Extrapolate to Unseen Data: a Semantic Evidence View}. AAAI Conference on Artificial Intelligence.

\bibitem{chen2023}
Mingyang Chen, Wen Zhang, Zhen Yao, et al. (2023). \textit{Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{wang2014}
Zhen Wang, Jianwen Zhang, Jianlin Feng, et al. (2014). \textit{Knowledge Graph Embedding by Translating on Hyperplanes}. AAAI Conference on Artificial Intelligence.

\bibitem{yao2023}
Zhen Yao, Wen Zhang, Mingyang Chen, et al. (2023). \textit{Analogical Inference Enhanced Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{sadeghian2021}
A. Sadeghian, Mohammadreza Armandpour, Anthony Colas, et al. (2021). \textit{ChronoR: Rotation Based Temporal Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{chen2024}
Zhen Chen, Dalin Zhang, Shanshan Feng, et al. (2024). \textit{KGTS: Contrastive Trajectory Similarity Learning over Prompt Knowledge Graph Embedding}. AAAI Conference on Artificial Intelligence.

\bibitem{ebisu2017}
Takuma Ebisu, and R. Ichise (2017). \textit{TorusE: Knowledge Graph Embedding on a Lie Group}. AAAI Conference on Artificial Intelligence.

\bibitem{buehler2024}
Markus J. Buehler (2024). \textit{Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning}. Machine Learning: Science and Technology.

\bibitem{chen2021}
X. Chen, Ziniu Hu, and Yizhou Sun (2021). \textit{Fuzzy Logic based Logical Query Answering on Knowledge Graph}. AAAI Conference on Artificial Intelligence.

\bibitem{liu2024}
Jiajun Liu, Wenjun Ke, Peng Wang, et al. (2024). \textit{Towards Continual Knowledge Graph Embedding via Incremental Distillation}. AAAI Conference on Artificial Intelligence.

\end{thebibliography}

\end{document}