{
  "nodes": [
    {
      "id": "098c12e7995675c1026d86d5f52843a035d3fa28",
      "title": "Out-of-distribution detection-assisted trustworthy machinery fault diagnosis approach with uncertainty-aware deep ensembles",
      "abstract": "",
      "authors": [
        "Te Han",
        "Yanfang Li"
      ],
      "year": 2022,
      "citation_count": 188,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/098c12e7995675c1026d86d5f52843a035d3fa28",
      "pdf_link": "",
      "venue": "Reliability Engineering & System Safety",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "60108b8e0d7204fa33f686b09128c7fc8489a224",
      "title": "Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection",
      "abstract": "In some scenarios, classifier requires detecting out-of-distribution samples far from its training data. With desirable characteristics, reconstruction autoencoder-based methods deal with this problem by using input reconstruction error as a metric of novelty vs. normality. We formulate the essence of such approach as a quadruplet domain translation with an intrinsic bias to only query for a proxy of conditional data uncertainty. Accordingly, an improvement direction is formalized as maximumly compressing the autoencoder's latent space while ensuring its reconstructive power for acting as a described domain translator. From it, strategies are introduced including semantic reconstruction, data certainty decomposition and normalized L2 distance to substantially improve original methods, which together establish state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method works without any additional data, hard-to-implement structure, time-consuming pipeline, and even harming the classification accuracy of known classes.",
      "authors": [
        "Yibo Zhou"
      ],
      "year": 2022,
      "citation_count": 70,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/60108b8e0d7204fa33f686b09128c7fc8489a224",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "title": "Full-Spectrum Out-of-Distribution Detection",
      "abstract": "Existing out-of-distribution (OOD) detection literature clearly defines semantic shift as a sign of OOD but does not have a consensus over covariate shift. Samples experiencing covariate shift but not semantic shift from the in-distribution (ID) are either excluded from the test set or treated as OOD, which contradicts the primary goal in machine learning—being able to generalize beyond the training distribution. In this paper, we take into account both shift types and introduce full-spectrum OOD (F-OOD) detection, a more realistic problem setting that considers both detecting semantic shift and being tolerant to covariate shift; and design three benchmarks. These new benchmarks have a more fine-grained categorization of distributions ( i.e let@tokeneonedot, training ID, covariate-shifted ID, near-OOD, and far-OOD) for the purpose of more comprehensively evaluating the pros and cons of algorithms. To address the F-OOD detection problem, we propose SEM, a simple feature-based semantics score function. SEM is mainly composed of two probability measures: one is based on high-level features containing both semantic and non-semantic information, while the other is based on low-level feature statistics only capturing non-semantic image styles. With a simple combination, the non-semantic part is canceled out, which leaves only semantic information in SEM that can better handle F-OOD detection. Extensive experiments on the three new benchmarks show that SEM significantly outperforms current state-of-the-art methods. Our code and benchmarks are released in https://github.com/Jingkang50/OpenOOD .",
      "authors": [
        "Jingkang Yang",
        "Kaiyang Zhou",
        "Ziwei Liu"
      ],
      "year": 2022,
      "citation_count": 68,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "pdf_link": "",
      "venue": "International Journal of Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "af5b1a35271efd17ff3d5ddd152bacc96dff0e81",
      "title": "Deep Residual Flow for Out of Distribution Detection",
      "abstract": "The effective application of neural networks in the real-world relies on proficiently detecting out-of-distribution examples. Contemporary methods seek to model the distribution of feature activations in the training data for adequately distinguishing abnormalities, and the state-of-the-art method uses Gaussian distribution models. In this work, we present a novel approach that improves upon the state-of-the-art by leveraging an expressive density model based on normalizing flows. We introduce the residual flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution. Our model is general, and can be applied to any data that is approximately Gaussian. For out of distribution detection in image datasets, our approach provides a principled improvement over the state-of-the-art. Specifically, we demonstrate the effectiveness of our method in ResNet and DenseNet architectures trained on various image datasets. For example, on a ResNet trained on CIFAR-100 and evaluated on detection of out-of-distribution samples from the ImageNet dataset, holding the true positive rate (TPR) at 95%, we improve the true negative rate (TNR) from 56.7% (current state of-the-art) to 77.5% (ours).",
      "authors": [
        "E. Zisselman",
        "Aviv Tamar"
      ],
      "year": 2020,
      "citation_count": 106,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/af5b1a35271efd17ff3d5ddd152bacc96dff0e81",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "title": "RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection",
      "abstract": "The task of out-of-distribution (OOD) detection is crucial for deploying machine learning models in real-world settings. In this paper, we observe that the singular value distributions of the in-distribution (ID) and OOD features are quite different: the OOD feature matrix tends to have a larger dominant singular value than the ID feature, and the class predictions of OOD samples are largely determined by it. This observation motivates us to propose \\texttt{RankFeat}, a simple yet effective \\texttt{post hoc} approach for OOD detection by removing the rank-1 matrix composed of the largest singular value and the associated singular vectors from the high-level feature (\\emph{i.e.,} $\\mathbf{X}{-} \\mathbf{s}_{1}\\mathbf{u}_{1}\\mathbf{v}_{1}^{T}$). \\texttt{RankFeat} achieves the \\emph{state-of-the-art} performance and reduces the average false positive rate (FPR95) by 17.90\\% compared with the previous best method. Extensive ablation studies and comprehensive theoretical analyses are presented to support the empirical results.",
      "authors": [
        "Yue Song",
        "N. Sebe",
        "Wei Wang"
      ],
      "year": 2022,
      "citation_count": 63,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "305941292b59d808af1f6646993747ba0f76f4ac",
      "title": "GOOD-D: On Unsupervised Graph Out-Of-Distribution Detection",
      "abstract": "Most existing deep learning models are trained based on the closed-world assumption, where the test data is assumed to be drawn i.i.d. from the same distribution as the training data, known as in-distribution (ID). However, when models are deployed in an open-world scenario, test samples can be out-of-distribution (OOD) and therefore should be handled with caution. To detect such OOD samples drawn from unknown distribution, OOD detection has received increasing attention lately. However, current endeavors mostly focus on grid-structured data and its application for graph-structured data remains under-explored. Considering the fact that data labeling on graphs is commonly time-expensive and labor-intensive, in this work we study the problem of unsupervised graph OOD detection, aiming at detecting OOD graphs solely based on unlabeled ID data. To achieve this goal, we develop a new graph contrastive learning framework GOOD-D for detecting OOD graphs without using any ground-truth labels. By performing hierarchical contrastive learning on the augmented graphs generated by our perturbation-free graph data augmentation method, GOOD-D is able to capture the latent ID patterns and accurately detect OOD graphs based on the semantic inconsistency in different granularities (i.e., node-level, graph-level, and group-level). As a pioneering work in unsupervised graph-level OOD detection, we build a comprehensive benchmark to compare our proposed approach with different state-of-the-art methods. The experiment results demonstrate the superiority of our approach over different methods on various datasets.",
      "authors": [
        "Yixin Liu",
        "Kaize Ding",
        "Huan Liu",
        "Shirui Pan"
      ],
      "year": 2022,
      "citation_count": 63,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/305941292b59d808af1f6646993747ba0f76f4ac",
      "pdf_link": "",
      "venue": "Web Search and Data Mining",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "title": "Out-of-Distribution Detection Using Union of 1-Dimensional Subspaces",
      "abstract": "The goal of out-of-distribution (OOD) detection is to handle the situations where the test samples are drawn from a different distribution than the training data. In this paper, we argue that OOD samples can be detected more easily if the training data is embedded into a low-dimensional space, such that the embedded training samples lie on a union of 1-dimensional subspaces. We show that such embedding of the in-distribution (ID) samples provides us with two main advantages. First, due to compact representation in the feature space, OOD samples are less likely to occupy the same region as the known classes. Second, the first singular vector of ID samples belonging to a 1-dimensional subspace can be used as their robust representative. Motivated by these observations, we train a deep neural network such that the ID samples are embedded onto a union of 1-dimensional subspaces. At the test time, employing sampling techniques used for approximate Bayesian inference in deep learning, input samples are detected as OOD if they occupy the region corresponding to the ID samples with probability 0. Spectral components of the ID samples are used as robust representative of this region. Our method does not have any hyperparameter to be tuned using extra information and it can be applied on different modalities with minimal change. The effectiveness of the proposed method is demonstrated on different benchmark datasets, both in the image and video classification domains.",
      "authors": [
        "Alireza Zaeemzadeh",
        "Niccoló Bisagno",
        "Zeno Sambugaro",
        "N. Conci",
        "Nazanin Rahnavard",
        "M. Shah"
      ],
      "year": 2021,
      "citation_count": 82,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "title": "On the Impact of Spurious Correlation for Out-of-distribution Detection",
      "abstract": "Modern neural networks can assign high confidence to inputs drawn from outside the training distribution, posing threats to models in real-world deployments. While much research attention has been placed on designing new out-of-distribution (OOD) detection methods, the precise definition of OOD is often left in vagueness and falls short of the desired notion of OOD in reality. In this paper, we present a new formalization and model the data shifts by taking into account both the invariant and environmental (spurious) features. Under such formalization, we systematically investigate how spurious correlation in the training set impacts OOD detection. Our results suggest that the detection performance is severely worsened when the correlation between spurious features and labels is increased in the training set. We further show insights on detection methods that are more effective in reducing the impact of spurious correlation, and provide theoretical analysis on why reliance on environmental features leads to high OOD detection error. Our work aims to facilitate better understanding of OOD samples and their formalization, as well as the exploration of methods that enhance OOD detection. Code is available at https://github.com/deeplearning-wisc/Spurious_OOD.",
      "authors": [
        "Yifei Ming",
        "Hang Yin",
        "Yixuan Li"
      ],
      "year": 2021,
      "citation_count": 81,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "pdf_link": "",
      "venue": "AAAI Conference on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "title": "Boosting Out-of-distribution Detection with Typical Features",
      "abstract": "Out-of-distribution (OOD) detection is a critical task for ensuring the reliability and safety of deep neural networks in real-world scenarios. Different from most previous OOD detection methods that focus on designing OOD scores or introducing diverse outlier examples to retrain the model, we delve into the obstacle factors in OOD detection from the perspective of typicality and regard the feature's high-probability region of the deep model as the feature's typical set. We propose to rectify the feature into its typical set and calculate the OOD score with the typical features to achieve reliable uncertainty estimation. The feature rectification can be conducted as a {plug-and-play} module with various OOD scores. We evaluate the superiority of our method on both the commonly used benchmark (CIFAR) and the more challenging high-resolution benchmark with large label space (ImageNet). Notably, our approach outperforms state-of-the-art methods by up to 5.11$\\%$ in the average FPR95 on the ImageNet benchmark.",
      "authors": [
        "Yao Zhu",
        "YueFeng Chen",
        "Chuanlong Xie",
        "Xiaodan Li",
        "Rong Zhang",
        "Hui Xue",
        "Xiang Tian",
        "Bolun Zheng",
        "Yao-wu Chen"
      ],
      "year": 2022,
      "citation_count": 59,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "558f6cfc2daa06fa6562084a566392b907fc1642",
      "title": "Robust Out-of-distribution Detection for Neural Networks",
      "abstract": "Detecting anomalous inputs is critical for safely deploying deep learning models in the real world. Existing approaches for detecting out-of-distribution (OOD) examples work well when evaluated on natural samples drawn from a sufficiently different distribution than the training data distribution. However, in this paper, we show that existing detection mechanisms can be extremely brittle when evaluating on inputs with minimal adversarial perturbations which don't change their semantics. Formally, we introduce a novel and challenging problem, Robust Out-of-Distribution Detection, and propose an algorithm that can fool existing OOD detectors by adding small perturbations to the inputs while preserving their semantics and thus the distributional membership. We take a first step to solve this challenge, and propose an effective algorithm called ALOE, which performs robust training by exposing the model to both adversarially crafted inlier and outlier examples. Our method can be flexibly combined with, and render existing methods robust. On common benchmark datasets, we show that ALOE substantially improves the robustness of state-of-the-art OOD detection, with 58.4% AUROC improvement on CIFAR-10 and 46.59% improvement on CIFAR-100. Finally, we provide theoretical analysis for our method, underpinning the empirical results above.",
      "authors": [
        "Jiefeng Chen",
        "Yixuan Li",
        "Xi Wu",
        "Yingyu Liang",
        "S. Jha"
      ],
      "year": 2020,
      "citation_count": 91,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/558f6cfc2daa06fa6562084a566392b907fc1642",
      "pdf_link": "",
      "venue": "",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4b83c2ec2c5119057979ae64cf4b5d1aef04466b",
      "title": "Density of States Estimation for Out-of-Distribution Detection",
      "abstract": "Perhaps surprisingly, recent studies have shown probabilistic model likelihoods have poor specificity for out-of-distribution (OOD) detection and often assign higher likelihoods to OOD data than in-distribution data. To ameliorate this issue we propose DoSE, the density of states estimator. Drawing on the statistical physics notion of ``density of states,'' the DoSE decision rule avoids direct comparison of model probabilities, and instead utilizes the ``probability of the model probability,'' or indeed the frequency of any reasonable statistic. The frequency is calculated using nonparametric density estimators (e.g., KDE and one-class SVM) which measure the typicality of various model statistics given the training data and from which we can flag test points with low typicality as anomalous. Unlike many other methods, DoSE requires neither labeled data nor OOD examples. DoSE is modular and can be trivially applied to any existing, trained model. We demonstrate DoSE's state-of-the-art performance against other unsupervised OOD detectors on previously established ``hard'' benchmarks.",
      "authors": [
        "W. Morningstar",
        "Cusuh Ham",
        "Andrew Gallagher",
        "Balaji Lakshminarayanan",
        "Alexander A. Alemi",
        "Joshua V. Dillon"
      ],
      "year": 2020,
      "citation_count": 90,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4b83c2ec2c5119057979ae64cf4b5d1aef04466b",
      "pdf_link": "",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "title": "Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection in Semantic Segmentation",
      "abstract": "Semantic segmentation models classify pixels into a set of known (\"in-distribution\") visual classes. When deployed in an open world, the reliability of these models depends on their ability to not only classify in-distribution pixels but also to detect out-of-distribution (OoD) pixels. Historically, the poor OoD detection performance of these models has motivated the design of methods based on model re-training using synthetic training images that include OoD visual objects. Although successful, these re-trained methods have two issues: 1) their in-distribution segmentation accuracy may drop during re-training, and 2) their OoD detection accuracy does not generalise well to new contexts outside the training set (e.g., from city to country context). In this paper, we mitigate these issues with: (i) a new residual pattern learning (RPL) module that assists the segmentation model to detect OoD pixels with minimal deterioration to inlier segmentation accuracy; and (ii) a novel context-robust contrastive learning (CoroCL) that enforces RPL to robustly detect OoD pixels in various contexts. Our approach improves by around 10% FPR and 7% AuPRC previous state-of-the-art in Fishyscapes, Segment-Me-If-You-Can, and RoadAnomaly datasets.",
      "authors": [
        "Yuyuan Liu",
        "Choubo Ding",
        "Yu Tian",
        "Guansong Pang",
        "Vasileios Belagiannis",
        "I. Reid",
        "G. Carneiro"
      ],
      "year": 2022,
      "citation_count": 50,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "pdf_link": "",
      "venue": "IEEE International Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "63ff7c225079eba3838d45b11bb15a58037f1415",
      "title": "MOOD 2020: A Public Benchmark for Out-of-Distribution Detection and Localization on Medical Images",
      "abstract": "Detecting Out-of-Distribution (OoD) data is one of the greatest challenges in safe and robust deployment of machine learning algorithms in medicine. When the algorithms encounter cases that deviate from the distribution of the training data, they often produce incorrect and over-confident predictions. OoD detection algorithms aim to catch erroneous predictions in advance by analysing the data distribution and detecting potential instances of failure. Moreover, flagging OoD cases may support human readers in identifying incidental findings. Due to the increased interest in OoD algorithms, benchmarks for different domains have recently been established. In the medical imaging domain, for which reliable predictions are often essential, an open benchmark has been missing. We introduce the Medical-Out-Of-Distribution-Analysis-Challenge (MOOD) as an open, fair, and unbiased benchmark for OoD methods in the medical imaging domain. The analysis of the submitted algorithms shows that performance has a strong positive correlation with the perceived difficulty, and that all algorithms show a high variance for different anomalies, making it yet hard to recommend them for clinical practice. We also see a strong correlation between challenge ranking and performance on a simple toy test set, indicating that this might be a valuable addition as a proxy dataset during anomaly detection algorithm development.",
      "authors": [
        "David Zimmerer",
        "Peter M. Full",
        "Fabian Isensee",
        "Paul F. Jager",
        "T. Adler",
        "Jens Petersen",
        "Gregor Koehler",
        "T. Ross",
        "Annika Reinke",
        "Antanas Kascenas",
        "B. S. Jensen",
        "Alison Q. O'Neil",
        "Jeremy Tan",
        "Benjamin Hou",
        "James Batten",
        "Huaqi Qiu",
        "Bernhard Kainz",
        "Nina Shvetsova",
        "Irina Fedulova",
        "D. Dylov",
        "Baolun Yu",
        "Jianyang Zhai",
        "Jingtao Hu",
        "Runxuan Si",
        "Sihang Zhou",
        "Siqi Wang",
        "Xinyang Li",
        "Xuerun Chen",
        "Yang Zhao",
        "Sergio Naval Marimont",
        "G. Tarroni",
        "Victor Saase",
        "L. Maier-Hein",
        "K. Maier-Hein"
      ],
      "year": 2022,
      "citation_count": 50,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/63ff7c225079eba3838d45b11bb15a58037f1415",
      "pdf_link": "",
      "venue": "IEEE Transactions on Medical Imaging",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "34d35e460b39edb19581ef345c4b32ce45aa9eae",
      "title": "iDECODe: In-distribution Equivariance for Conformal Out-of-distribution Detection",
      "abstract": "Machine learning methods such as deep neural networks (DNNs), despite their success across different domains, are known to often generate incorrect predictions with high confidence on inputs outside their training distribution. The deployment of DNNs in safety-critical domains requires detection of out-of-distribution (OOD) data so that DNNs can abstain from making predictions on those. A number of methods have been recently developed for OOD detection, but there is still room for improvement. We propose the new method iDECODe, leveraging in-distribution equivariance for conformal OOD detection. It relies on a novel base non-conformity measure and a new aggregation method, used in the inductive conformal anomaly detection framework, thereby guaranteeing a bounded false detection rate. We demonstrate the efficacy of iDECODe by experiments on image and audio datasets, obtaining state-of-the-art results. We also show that iDECODe can detect adversarial examples. Code, pre-trained models, and data are available at https://github.com/ramneetk/iDECODe.",
      "authors": [
        "R. Kaur",
        "Susmit Jha",
        "Anirban Roy",
        "Sangdon Park",
        "Edgar Dobriban",
        "O. Sokolsky",
        "Insup Lee"
      ],
      "year": 2022,
      "citation_count": 49,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/34d35e460b39edb19581ef345c4b32ce45aa9eae",
      "pdf_link": "",
      "venue": "AAAI Conference on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "title": "Mixture Outlier Exposure: Towards Out-of-Distribution Detection in Fine-grained Environments",
      "abstract": "Many real-world scenarios in which DNN-based recognition systems are deployed have inherently fine-grained attributes (e.g., bird-species recognition, medical image classification). In addition to achieving reliable accuracy, a critical subtask for these models is to detect Out-of-distribution (OOD) inputs. Given the nature of the deployment environment, one may expect such OOD inputs to also be fine-grained w.r.t. the known classes (e.g., a novel bird species), which are thus extremely difficult to identify. Unfortunately, OOD detection in fine-grained scenarios remains largely underexplored. In this work, we aim to fill this gap by first carefully constructing four large-scale fine-grained test environments, in which existing methods are shown to have difficulties. Particularly, we find that even explicitly incorporating a diverse set of auxiliary outlier data during training does not provide sufficient coverage over the broad region where fine-grained OOD samples locate. We then propose Mixture Outlier Exposure (MixOE), which mixes ID data and training outliers to expand the coverage of different OOD granularities, and trains the model such that the prediction confidence linearly decays as the input transitions from ID to OOD. Extensive experiments and analyses demonstrate the effectiveness of MixOE for building up OOD detector in finegrained environments. The code is available at https://github.com/zjysteven/MixOE.",
      "authors": [
        "Jingyang Zhang",
        "Nathan Inkawhich",
        "Randolph Linderman",
        "Yiran Chen",
        "H. Li"
      ],
      "year": 2021,
      "citation_count": 65,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "pdf_link": "",
      "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "903966632e84a59ca49914ebbadbbfbfe84e7c29",
      "title": "Neural Mean Discrepancy for Efficient Out-of-Distribution Detection",
      "abstract": "Various approaches have been proposed for out-of-distribution (OOD) detection by augmenting models, input examples, training sets, and optimization objectives. Deviating from existing work, we have a simple hypothesis that standard off-the-shelf models may already contain sufficient information about the training set distribution which can be leveraged for reliable OOD detection. Our empirical study on validating this hypothesis, which measures the model activation's mean for OOD and in-distribution (ID) minibatches, surprisingly finds that activation means of OOD mini-batches consistently deviate more from those of the training data. In addition, training data's activation means can be computed offline efficiently or retrieved from batch normalization layers as a ‘free lunch’. Based upon this observation, we propose a novel metric called Neural Mean Discrepancy (NMD), which compares neural means of the input examples and training data. Leveraging the simplicity of NMD, we propose an efficient OOD detector that computes neural means by a standard forward pass followed by a lightweight classifier. Extensive experiments show that NMD outperforms state-of-the-art OOD approaches across multiple datasets and model architectures in terms of both detection accuracy and computational cost.",
      "authors": [
        "Xin Dong",
        "Junfeng Guo",
        "Ang Li",
        "W. Ting",
        "Cong Liu",
        "H. Kung"
      ],
      "year": 2021,
      "citation_count": 65,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/903966632e84a59ca49914ebbadbbfbfe84e7c29",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "ba39d83ec8b79f35d8195835f46cc4e36e5a4211",
      "title": "Real-time Out-of-distribution Detection in Learning-Enabled Cyber-Physical Systems",
      "abstract": "Cyber-physical systems (CPS) greatly benefit by using machine learning components that can handle the uncertainty and variability of the real-world. Typical components such as deep neural networks, however, introduce new types of hazards that may impact system safety. The system behavior depends on data that are available only during runtime and may be different than the data used for training. Out-of-distribution data may lead to a large error and compromise safety. The paper considers the problem of efficiently detecting out-of-distribution data in CPS control systems. Detection must be robust and limit the number of false alarms while being computational efficient for real-time monitoring. The proposed approach leverages inductive conformal prediction and anomaly detection for developing a method that has a well-calibrated false alarm rate. We use variational autoencoders and deep support vector data description to learn models that can be used efficiently compute the nonconformity of new inputs relative to the training set and enable realtime detection of out-of-distribution high-dimensional inputs. We demonstrate the method using an advanced emergency braking system and a self-driving end-to-end controller implemented in an open source simulator for self-driving cars. The simulation results show very small number of false positives and detection delay while the execution time is comparable to the execution time of the original machine learning components.",
      "authors": [
        "Feiyang Cai",
        "X. Koutsoukos"
      ],
      "year": 2020,
      "citation_count": 80,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/ba39d83ec8b79f35d8195835f46cc4e36e5a4211",
      "pdf_link": "",
      "venue": "International Conference on Cyber-Physical Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "dcfca93185c49811ec6cf7c995eea58cf88c7bb3",
      "title": "A Survey on Out-of-Distribution Detection in NLP",
      "abstract": "Out-of-distribution (OOD) detection is essential for the reliable and safe deployment of machine learning systems in the real world. Great progress has been made over the past years. This paper presents the first review of recent advances in OOD detection with a particular focus on natural language processing approaches. First, we provide a formal definition of OOD detection and discuss several related fields. We then categorize recent algorithms into three classes according to the data they used: (1) OOD data available, (2) OOD data unavailable + in-distribution (ID) label available, and (3) OOD data unavailable + ID label unavailable. Third, we introduce datasets, applications, and metrics. Finally, we summarize existing work and present potential future research topics.",
      "authors": [
        "Hao Lang",
        "Yinhe Zheng",
        "Yixuan Li",
        "Jian Sun",
        "Feiling Huang",
        "Yongbin Li"
      ],
      "year": 2023,
      "citation_count": 27,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/dcfca93185c49811ec6cf7c995eea58cf88c7bb3",
      "pdf_link": "",
      "venue": "Trans. Mach. Learn. Res.",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "7d826dfb184be983018590c64cfb4a79349472a4",
      "title": "Block Selection Method for Using Feature Norm in Out-of-Distribution Detection",
      "abstract": "Detecting out-of-distribution (OOD) inputs during the inference stage is crucial for deploying neural networks in the real world. Previous methods typically relied on the highly activated feature map outputted by the network. In this study, we revealed that the norm of the feature map obtained from a block other than the last block can serve as a better indicator for OOD detection. To leverage this insight, we propose a simple framework that comprises two metrics: FeatureNorm, which computes the norm of the feature map, and NormRatio, which calculates the ratio of FeatureNorm for ID and OOD samples to evaluate the OOD detection performance of each block. To identify the block that provides the largest difference between FeatureNorm of ID and FeatureNorm of OOD, we create jigsaw puzzles as pseudo OOD from ID training samples and compute NormRatio, selecting the block with the highest value. After identifying the suitable block, OOD detection using FeatureNorm outperforms other methods by reducing FPR95 by up to 52.77% on CIFAR10 benchmark and up to 48.53% on ImageNet benchmark. We demonstrate that our framework can generalize to various architectures and highlight the significance of block selection, which can also improve previous OOD detection methods. Our code is available at https://github.com/gistailab/block-selection-for-OOD-detection.",
      "authors": [
        "Yeonguk Yu",
        "Sungho Shin",
        "Seongju Lee",
        "C. Jun",
        "Kyoobin Lee"
      ],
      "year": 2022,
      "citation_count": 40,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/7d826dfb184be983018590c64cfb4a79349472a4",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "ff29bf27e1c4e95c4eec448ed1d4adfa81983302",
      "title": "NECO: NEural Collapse Based Out-of-distribution detection",
      "abstract": "Detecting out-of-distribution (OOD) data is a critical challenge in machine learning due to model overconfidence, often without awareness of their epistemological limits. We hypothesize that ``neural collapse'', a phenomenon affecting in-distribution data for models trained beyond loss convergence, also influences OOD data. To benefit from this interplay, we introduce NECO, a novel post-hoc method for OOD detection, which leverages the geometric properties of ``neural collapse'' and of principal component spaces to identify OOD data. Our extensive experiments demonstrate that NECO achieves state-of-the-art results on both small and large-scale OOD detection tasks while exhibiting strong generalization capabilities across different network architectures. Furthermore, we provide a theoretical explanation for the effectiveness of our method in OOD detection. Code is available at https://gitlab.com/drti/neco",
      "authors": [
        "Mouin Ben Ammar",
        "Nacim Belkhir",
        "Sebastian Popescu",
        "Antoine Manzanera",
        "Gianni Franchi"
      ],
      "year": 2023,
      "citation_count": 25,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/ff29bf27e1c4e95c4eec448ed1d4adfa81983302",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "393e0b8459eb1608b6b35d6057da4ddb09957555",
      "title": "Triggering Failures: Out-Of-Distribution detection by learning from local adversarial attacks in Semantic Segmentation",
      "abstract": "In this paper, we tackle the detection of out-of-distribution (OOD) objects in semantic segmentation. By analyzing the literature, we found that current methods are either accurate or fast but not both which limits their usability in real world applications. To get the best of both aspects, we propose to mitigate the common shortcomings by following four design principles: decoupling the OOD detection from the segmentation task, observing the entire segmentation network instead of just its output, generating training data for the OOD detector by leveraging blind spots in the segmentation network and focusing the generated data on localized regions in the image to simulate OOD objects. Our main contribution is a new OOD detection architecture called ObsNet associated with a dedicated training scheme based on Local Adversarial Attacks (LAA). We validate the soundness of our approach across numerous ablation studies. We also show it obtains top performances both in speed and accuracy when compared to ten recent methods of the literature on three different datasets.",
      "authors": [
        "Victor Besnier",
        "Andrei Bursuc",
        "David Picard",
        "Alexandre Briot"
      ],
      "year": 2021,
      "citation_count": 50,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/393e0b8459eb1608b6b35d6057da4ddb09957555",
      "pdf_link": "",
      "venue": "IEEE International Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e",
      "title": "Out-Of-Distribution Detection Is Not All You Need",
      "abstract": "The usage of deep neural networks in safety-critical systems is limited by our ability to guarantee their correct behavior. Runtime monitors are components aiming to identify unsafe predictions and discard them before they can lead to catastrophic consequences. Several recent works on runtime monitoring have focused on out-of-distribution (OOD) detection, i.e., identifying inputs that are different from the training data. In this work, we argue that OOD detection is not a well-suited framework to design efficient runtime monitors and that it is more relevant to evaluate monitors based on their ability to discard incorrect predictions. We call this setting out-of-model-scope detection and discuss the conceptual differences with OOD. We also conduct extensive experiments on popular datasets from the literature to show that studying monitors in the OOD setting can be misleading: 1. very good OOD results can give a false impression of safety, 2. comparison under the OOD setting does not allow identifying the best monitor to detect errors. Finally, we also show that removing erroneous training data samples helps to train better monitors.",
      "authors": [
        "Joris Gu'erin",
        "Kevin Delmas",
        "Raul Sena Ferreira",
        "Jérémie Guiochet"
      ],
      "year": 2022,
      "citation_count": 37,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e",
      "pdf_link": "",
      "venue": "AAAI Conference on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "title": "Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization",
      "abstract": "The out-of-distribution (OOD) problem generally arises when neural networks encounter data that significantly deviates from the training data distribution, i.e., in-distribution (InD). In this paper, we study the OOD problem from a neuron activation view. We first formulate neuron activation states by considering both the neuron output and its influence on model decisions. Then, to characterize the relationship between neurons and OOD issues, we introduce the \\textit{neuron activation coverage} (NAC) -- a simple measure for neuron behaviors under InD data. Leveraging our NAC, we show that 1) InD and OOD inputs can be largely separated based on the neuron behavior, which significantly eases the OOD detection problem and beats the 21 previous methods over three benchmarks (CIFAR-10, CIFAR-100, and ImageNet-1K). 2) a positive correlation between NAC and model generalization ability consistently holds across architectures and datasets, which enables a NAC-based criterion for evaluating model robustness. Compared to prevalent InD validation criteria, we show that NAC not only can select more robust models, but also has a stronger correlation with OOD test performance.",
      "authors": [
        "Y. Liu",
        "Chris Xing Tian",
        "Haoliang Li",
        "Lei Ma",
        "Shiqi Wang"
      ],
      "year": 2023,
      "citation_count": 24,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "3430707312d8d9192f2f4b967f541f96618ba393",
      "title": "Confidence-based Out-of-Distribution Detection: A Comparative Study and Analysis",
      "abstract": "Image classification models deployed in the real world may receive inputs outside the intended data distribution. For critical applications such as clinical decision making, it is important that a model can detect such out-of-distribution (OOD) inputs and express its uncertainty. In this work, we assess the capability of various state-of-the-art approaches for confidence-based OOD detection through a comparative study and in-depth analysis. First, we leverage a computer vision benchmark to reproduce and compare multiple OOD detection methods. We then evaluate their capabilities on the challenging task of disease classification using chest X-rays. Our study shows that high performance in a computer vision task does not directly translate to accuracy in a medical imaging task. We analyse factors that affect performance of the methods between the two tasks. Our results provide useful insights for developing the next generation of OOD detection methods.",
      "authors": [
        "Christoph Berger",
        "Magdalini Paschali",
        "Ben Glocker",
        "K. Kamnitsas"
      ],
      "year": 2021,
      "citation_count": 47,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/3430707312d8d9192f2f4b967f541f96618ba393",
      "pdf_link": "",
      "venue": "UNSURE/PIPPI@MICCAI",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "977384045381a2c45dfac4797196d34658d8a44f",
      "title": "Out-of-Distribution Detection with Semantic Mismatch under Masking",
      "abstract": "This paper proposes a novel out-of-distribution (OOD) detection framework named MoodCat for image classifiers. MoodCat masks a random portion of the input image and uses a generative model to synthesize the masked image to a new image conditioned on the classification result. It then calculates the semantic difference between the original image and the synthesized one for OOD detection. Compared to existing solutions, MoodCat naturally learns the semantic information of the in-distribution data with the proposed mask and conditional synthesis strategy, which is critical to identifying OODs. Experimental results demonstrate that MoodCat outperforms state-of-the-art OOD detection solutions by a large margin.",
      "authors": [
        "Yijun Yang",
        "Ruiyuan Gao",
        "Qiang Xu"
      ],
      "year": 2022,
      "citation_count": 35,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/977384045381a2c45dfac4797196d34658d8a44f",
      "pdf_link": "",
      "venue": "European Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "f0f220240fc752b6b3c56464d96aeb322f221ef0",
      "title": "Out-of-Distribution Detection in Long-Tailed Recognition with Calibrated Outlier Class Learning",
      "abstract": "Existing out-of-distribution (OOD) methods have shown great success on balanced datasets but become ineffective in long-tailed recognition (LTR) scenarios where 1) OOD samples are often wrongly classified into head classes and/or 2) tail-class samples are treated as OOD samples. To address these issues, current studies fit a prior distribution of auxiliary/pseudo OOD data to the long-tailed in-distribution (ID) data. However, it is difficult to obtain such an accurate prior distribution given the unknowingness of real OOD samples and heavy class imbalance in LTR. A straightforward solution to avoid the requirement of this prior is to learn an outlier class to encapsulate the OOD samples. The main challenge is then to tackle the aforementioned confusion between OOD samples and head/tail-class samples when learning the outlier class. To this end, we introduce a novel calibrated outlier class learning (COCL) approach, in which 1) a debiased large margin learning method is introduced in the outlier class learning to distinguish OOD samples from both head and tail classes in the representation space and 2) an outlier-class-aware logit calibration method is defined to enhance the long-tailed classification confidence. Extensive empirical results on three popular benchmarks CIFAR10-LT, CIFAR100-LT, and ImageNet-LT demonstrate that COCL substantially outperforms existing state-of-the-art OOD detection methods in LTR while being able to improve the classification accuracy on ID data. Code is available at https://github.com/mala-lab/COCL.",
      "authors": [
        "Wenjun Miao",
        "Guansong Pang",
        "Tianqi Li",
        "Xiaolong Bai",
        "Jingyi Zheng"
      ],
      "year": 2023,
      "citation_count": 22,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/f0f220240fc752b6b3c56464d96aeb322f221ef0",
      "pdf_link": "",
      "venue": "AAAI Conference on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "41e68a78f5bd266b1ae54d521ebd0be0e9314cd8",
      "title": "Watermarking for Out-of-distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection aims to identify OOD data based on representations extracted from well-trained deep models. However, existing methods largely ignore the reprogramming property of deep models and thus may not fully unleash their intrinsic strength: without modifying parameters of a well-trained deep model, we can reprogram this model for a new purpose via data-level manipulation (e.g., adding a specific feature perturbation to the data). This property motivates us to reprogram a classification model to excel at OOD detection (a new task), and thus we propose a general methodology named watermarking in this paper. Specifically, we learn a unified pattern that is superimposed onto features of original data, and the model's detection capability is largely boosted after watermarking. Extensive experiments verify the effectiveness of watermarking, demonstrating the significance of the reprogramming property of deep models in OOD detection.",
      "authors": [
        "Qizhou Wang",
        "Feng Liu",
        "Yonggang Zhang",
        "Jing Zhang",
        "Chen Gong",
        "Tongliang Liu",
        "Bo Han"
      ],
      "year": 2022,
      "citation_count": 33,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/41e68a78f5bd266b1ae54d521ebd0be0e9314cd8",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4c1601f2582b351aea86a1d56dfd20f59a9f44ba",
      "title": "From Global to Local: Multi-Scale Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection aims to detect “unknown” data whose labels have not been seen during the in-distribution (ID) training process. Recent progress in representation learning gives rise to distance-based OOD detection that recognizes inputs as ID/OOD according to their relative distances to the training data of ID classes. Previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal as the inevitable background clutter and intra-class variation may drive image-level representations from the same ID class far apart in a given representation space. In this work, we overcome this challenge by proposing Multi-scale OOD DEtection (MODE), a first framework leveraging both global visual information and local region details of images to maximally benefit OOD detection. Specifically, we first find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation ( $\\mathtt {ALPA}$ ), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision ( $\\mathtt {CSD}$ ) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks – on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.",
      "authors": [
        "Ji Zhang",
        "Lianli Gao",
        "Bingguang Hao",
        "Hao Huang",
        "Jingkuan Song",
        "H. Shen"
      ],
      "year": 2023,
      "citation_count": 21,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4c1601f2582b351aea86a1d56dfd20f59a9f44ba",
      "pdf_link": "",
      "venue": "IEEE Transactions on Image Processing",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "6f136ee16da4f01f30b267478d5127699c983e20",
      "title": "Back to the Basics: Revisiting Out-of-Distribution Detection Baselines",
      "abstract": "We study simple methods for out-of-distribution (OOD) image detection that are compatible with any already trained classifier, relying on only its predictions or learned representations. Evaluating the OOD detection performance of various methods when utilized with ResNet-50 and Swin Transformer models, we find methods that solely consider the model's predictions can be easily outperformed by also considering the learned representations. Based on our analysis, we advocate for a dead-simple approach that has been neglected in other studies: simply flag as OOD images whose average distance to their K nearest neighbors is large (in the representation space of an image classifier trained on the in-distribution data).",
      "authors": [
        "Jo-Lan Kuan",
        "Jonas W. Mueller"
      ],
      "year": 2022,
      "citation_count": 31,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/6f136ee16da4f01f30b267478d5127699c983e20",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "091ef8678781d1b53a5a07643ae37e3d44f9ed61",
      "title": "Balanced Energy Regularization Loss for Out-of-distribution Detection",
      "abstract": "In the field of out-of-distribution (OOD) detection, a previous method that use auxiliary data as OOD data has shown promising performance. However, the method provides an equal loss to all auxiliary data to differentiate them from inliers. However, based on our observation, in various tasks, there is a general imbalance in the distribution of the auxiliary OOD data across classes. We propose a balanced energy regularization loss that is simple but generally effective for a variety of tasks. Our balanced energy regularization loss utilizes class-wise different prior probabilities for auxiliary data to address the class imbalance in OOD data. The main concept is to regularize auxiliary samples from majority classes, more heavily than those from minority classes. Our approach performs better for OOD detection in semantic segmentation, long-tailed image classification, and image classification than the prior energy regularization loss. Furthermore, our approach achieves state-of-the-art performance in two tasks: OOD detection in semantic segmentation and long-tailed image classification.",
      "authors": [
        "Hyunjun Choi",
        "Hawook Jeong",
        "Jin Young Choi"
      ],
      "year": 2023,
      "citation_count": 20,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/091ef8678781d1b53a5a07643ae37e3d44f9ed61",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "3f9f3ca7832f36285fbb0a65c221ded5e32382a1",
      "title": "GL-MCM: Global and Local Maximum Concept Matching for Zero-Shot Out-of-Distribution Detection",
      "abstract": "\n Zero-shot OOD detection is a task that detects OOD images during inference with only in-distribution (ID) class names. Existing methods assume ID images contain a single, centered object, and do not consider the more realistic multi-object scenarios, where both ID and OOD objects are present. To meet the needs of many users, the detection method must have the flexibility to adapt the type of ID images. To this end, we present Global-Local Maximum Concept Matching (GL-MCM), which incorporates local image scores as an auxiliary score to enhance the separability of global and local visual features. Due to the simple ensemble score function design, GL-MCM can control the type of ID images with a single weight parameter. Experiments on ImageNet and multi-object benchmarks demonstrate that GL-MCM outperforms baseline zero-shot methods and is comparable to fully supervised methods. Furthermore, GL-MCM offers strong flexibility in adjusting the target type of ID images. The code is available via https://github.com/AtsuMiyai/GL-MCM.",
      "authors": [
        "Atsuyuki Miyai",
        "Qing Yu",
        "Go Irie",
        "K. Aizawa"
      ],
      "year": 2023,
      "citation_count": 20,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/3f9f3ca7832f36285fbb0a65c221ded5e32382a1",
      "pdf_link": "",
      "venue": "International Journal of Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "ca9974ac55dacf8db6eb4a57f489756068797cab",
      "title": "Breaking Down Out-of-Distribution Detection: Many Methods Based on OOD Training Data Estimate a Combination of the Same Core Quantities",
      "abstract": "It is an important problem in trustworthy machine learning to recognize out-of-distribution (OOD) inputs which are inputs unrelated to the in-distribution task. Many out-of-distribution detection methods have been suggested in recent years. The goal of this paper is to recognize common objectives as well as to identify the implicit scoring functions of different OOD detection methods. We focus on the sub-class of methods that use surrogate OOD data during training in order to learn an OOD detection score that generalizes to new unseen out-distributions at test time. We show that binary discrimination between in- and (different) out-distributions is equivalent to several distinct formulations of the OOD detection problem. When trained in a shared fashion with a standard classifier, this binary discriminator reaches an OOD detection performance similar to that of Outlier Exposure. Moreover, we show that the confidence loss which is used by Outlier Exposure has an implicit scoring function which differs in a non-trivial fashion from the theoretically optimal scoring function in the case where training and test out-distribution are the same, which again is similar to the one used when training an Energy-Based OOD detector or when adding a background class. In practice, when trained in exactly the same way, all these methods perform similarly.",
      "authors": [
        "Julian Bitterwolf",
        "Alexander Meinke",
        "Maximilian Augustin",
        "Matthias Hein"
      ],
      "year": 2022,
      "citation_count": 29,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/ca9974ac55dacf8db6eb4a57f489756068797cab",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "2815a5e7ba661ae278aa7c19e08ac884cde17bf7",
      "title": "Igeood: An Information Geometry Approach to Out-of-Distribution Detection",
      "abstract": "Reliable out-of-distribution (OOD) detection is fundamental to implementing safer modern machine learning (ML) systems. In this paper, we introduce Igeood, an effective method for detecting OOD samples. Igeood applies to any pre-trained neural network, works under various degrees of access to the ML model, does not require OOD samples or assumptions on the OOD data but can also benefit (if available) from OOD samples. By building on the geodesic (Fisher-Rao) distance between the underlying data distributions, our discriminator can combine confidence scores from the logits outputs and the learned features of a deep neural network. Empirically, we show that Igeood outperforms competing state-of-the-art methods on a variety of network architectures and datasets.",
      "authors": [
        "Eduardo Dadalto Camara Gomes",
        "F. Alberge",
        "P. Duhamel",
        "P. Piantanida"
      ],
      "year": 2022,
      "citation_count": 29,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/2815a5e7ba661ae278aa7c19e08ac884cde17bf7",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "57f4b117744112e4000894a5f939e114f1907719",
      "title": "DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models",
      "abstract": "Given a classifier, the inherent property of semantic Out-of-Distribution (OOD) samples is that their contents differ from all legal classes in terms of semantics, namely semantic mismatch. There is a recent work that directly applies it to OOD detection, which employs a conditional Generative Adversarial Network (cGAN) to enlarge semantic mismatch in the image space. While achieving remarkable OOD detection performance on small datasets, it is not applicable to ImageNet-scale datasets due to the difficulty in training cGANs with both input images and labels as conditions.As diffusion models are much easier to train and amenable to various conditions compared to cGANs, in this work, we propose to directly use pre-trained diffusion models for semantic mismatch-guided OOD detection, named DiffGuard. Specifically, given an OOD input image and the predicted label from the classifier, we try to enlarge the semantic difference between the reconstructed OOD image under these conditions and the original input image. We also present several test-time techniques to further strengthen such differences. Experimental results show that DiffGuard is effective on both Cifar-10 and hard cases of the large-scale ImageNet, and it can be easily combined with existing OOD detection techniques to achieve state-of-the-art OOD detection results.",
      "authors": [
        "Ruiyuan Gao",
        "Chenchen Zhao",
        "Lanqing Hong",
        "Q. Xu"
      ],
      "year": 2023,
      "citation_count": 19,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/57f4b117744112e4000894a5f939e114f1907719",
      "pdf_link": "",
      "venue": "IEEE International Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "8ef5a28955ce4fbd170e4dddbd37930e025edb69",
      "title": "Deep Hybrid Models for Out-of-Distribution Detection",
      "abstract": "We propose a principled and practical method for out-of-distribution (OoD) detection with deep hybrid models (DHMs), which model the joint density p(x, y) of features and labels with a single forward pass. By factorizing the joint density p(x, y) into three sources of uncertainty, we show that our approach has the ability to identify samples semantically different from the training data. To ensure computational scalability, we add a weight normalization step during training, which enables us to plug in state-of-the-art (SoTA) deep neural network (DNN) architectures for approximately modeling and inferring expressive probability distributions. Our method provides an efficient, general, and flexible framework for predictive uncertainty estimation with promising results and theoretical support. To our knowledge, this is the first work to reach 100% in OoD detection tasks on both vision and language datasets, especially on notably difficult dataset pairs such as CIFAR -10 vs. SVHN and CIFAR-100 vs. CIFAR-10. This work is a step towards enabling DNNs in real-world deployment for safety-critical applications.",
      "authors": [
        "Senqi Cao",
        "Zhongfei Zhang"
      ],
      "year": 2022,
      "citation_count": 28,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/8ef5a28955ce4fbd170e4dddbd37930e025edb69",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba",
      "title": "EAT: Towards Long-Tailed Out-of-Distribution Detection",
      "abstract": "Despite recent advancements in out-of-distribution (OOD) detection, most current studies assume a class-balanced in-distribution training dataset, which is rarely the case in real-world scenarios. This paper addresses the challenging task of long-tailed OOD detection, where the in-distribution data follows a long-tailed class distribution. The main difficulty lies in distinguishing OOD data from samples belonging to the tail classes, as the ability of a classifier to detect OOD instances is not strongly correlated with its accuracy on the in-distribution classes. To overcome this issue, we propose two simple ideas: (1) Expanding the in-distribution class space by introducing multiple abstention classes. This approach allows us to build a detector with clear decision boundaries by training on OOD data using virtual labels. (2) Augmenting the context-limited tail classes by overlaying images onto the context-rich OOD data. This technique encourages the model to pay more attention to the discriminative features of the tail classes. We provide a clue for separating in-distribution and OOD data by analyzing gradient noise. Through extensive experiments, we demonstrate that our method outperforms the current state-of-the-art on various benchmark datasets. Moreover, our method can be used as an add-on for existing long-tail learning approaches, significantly enhancing their OOD detection performance. Code is available at: https://github.com/Stomach-ache/Long-Tailed-OOD-Detection.",
      "authors": [
        "Tong Wei",
        "Bo-Lin Wang",
        "Min-Ling Zhang"
      ],
      "year": 2023,
      "citation_count": 18,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba",
      "pdf_link": "",
      "venue": "AAAI Conference on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "6db1cc71f6cfad8d7a9e09882711c722766562b6",
      "title": "GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients",
      "abstract": "Detecting out-of-distribution (OOD) data is crucial for ensuring the safe deployment of machine learning models in real-world applications. However, existing OOD detection approaches primarily rely on the feature maps or the full gradient space information to derive OOD scores neglecting the role of most important parameters of the pre-trained network over in-distribution (ID) data. In this study, we propose a novel approach called GradOrth to facilitate OOD detection based on one intriguing observation that the important features to identify OOD data lie in the lower-rank subspace of in-distribution (ID) data. In particular, we identify OOD data by computing the norm of gradient projection on the subspaces considered important for the in-distribution data. A large orthogonal projection value (i.e. a small projection value) indicates the sample as OOD as it captures a weak correlation of the ID data. This simple yet effective method exhibits outstanding performance, showcasing a notable reduction in the average false positive rate at a 95% true positive rate (FPR95) of up to 8% when compared to the current state-of-the-art methods.",
      "authors": [
        "Sima Behpour",
        "T. Doan",
        "Xin Li",
        "Wenbin He",
        "Liangke Gou",
        "Liu Ren"
      ],
      "year": 2023,
      "citation_count": 18,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/6db1cc71f6cfad8d7a9e09882711c722766562b6",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "a1ce596ef67f28f433f3de1001774211d00b54f0",
      "title": "GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation",
      "abstract": "Despite graph neural networks' (GNNs) great success in modelling graph-structured data, out-of-distribution (OOD) test instances still pose a great challenge for current GNNs. One of the most effective techniques to detect OOD nodes is to expose the detector model with an additional OOD node-set, yet the extra OOD instances are often difficult to obtain in practice. Recent methods for image data address this problem using OOD data synthesis, typically relying on pre-trained generative models like Stable Diffusion. However, these approaches require vast amounts of additional data, as well as one-for-all pre-trained generative models, which are not available for graph data. Therefore, we propose the GOLD framework for graph OOD detection, an implicit adversarial learning pipeline with synthetic OOD exposure without pre-trained models. The implicit adversarial training process employs a novel alternating optimisation framework by training: (1) a latent generative model to regularly imitate the in-distribution (ID) embeddings from an evolving GNN, and (2) a GNN encoder and an OOD detector to accurately classify ID data while increasing the energy divergence between the ID embeddings and the generative model's synthetic embeddings. This novel approach implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, effectively simulating exposure to OOD scenarios without auxiliary data. Extensive OOD detection experiments are conducted on five benchmark graph datasets, verifying the superior performance of GOLD without using real OOD data compared with the state-of-the-art OOD exposure and non-exposure baselines.",
      "authors": [
        "Danny Wang",
        "Ruihong Qiu",
        "Guangdong Bai",
        "Zi Huang"
      ],
      "year": 2025,
      "citation_count": 9,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/a1ce596ef67f28f433f3de1001774211d00b54f0",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4ec3a01aee0ae0e4d334e552373ccd74ca66b76e",
      "title": "Unsupervised 3D out-of-distribution detection with latent diffusion models",
      "abstract": "Methods for out-of-distribution (OOD) detection that scale to 3D data are crucial components of any real-world clinical deep learning system. Classic denoising diffusion probabilistic models (DDPMs) have been recently proposed as a robust way to perform reconstruction-based OOD detection on 2D datasets, but do not trivially scale to 3D data. In this work, we propose to use Latent Diffusion Models (LDMs), which enable the scaling of DDPMs to high-resolution 3D medical data. We validate the proposed approach on near- and far-OOD datasets and compare it to a recently proposed, 3D-enabled approach using Latent Transformer Models (LTMs). Not only does the proposed LDM-based approach achieve statistically significant better performance, it also shows less sensitivity to the underlying latent representation, more favourable memory scaling, and produces better spatial anomaly maps. Code is available at https://github.com/marksgraham/ddpm-ood",
      "authors": [
        "M. Graham",
        "W. H. Pinaya",
        "P. Wright",
        "Petru-Daniel Tudosiu",
        "Y. Mah",
        "J. Teo",
        "H. Jäger",
        "D. Werring",
        "P. Nachev",
        "S. Ourselin",
        "M. Cardoso"
      ],
      "year": 2023,
      "citation_count": 17,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4ec3a01aee0ae0e4d334e552373ccd74ca66b76e",
      "pdf_link": "",
      "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "0e3a01e0bd1beff9e77d8809629db24fc706c085",
      "title": "Understanding the Feature Norm for Out-of-Distribution Detection",
      "abstract": "A neural network trained on a classification dataset often exhibits a higher vector norm of hidden layer features for in-distribution (ID) samples, while producing relatively lower norm values on unseen instances from out-of-distribution (OOD). Despite this intriguing phenomenon being utilized in many applications, the underlying cause has not been thoroughly investigated. In this study, we demystify this very phenomenon by scrutinizing the discriminative structures concealed in the intermediate layers of a neural network. Our analysis leads to the following discoveries: (1) The feature norm is a confidence value of a classifier hidden in the network layer, specifically its maximum logit. Hence, the feature norm distinguishes OOD from ID in the same manner that a classifier confidence does. (2) The feature norm is class-agnostic, thus it can detect OOD samples across diverse discriminative models. (3) The conventional feature norm fails to capture the deactivation tendency of hidden layer neurons, which may lead to misidentification of ID samples as OOD instances. To resolve this drawback, we propose a novel negative-aware norm (NAN) that can capture both the activation and deactivation tendencies of hidden layer neurons. We conduct extensive experiments on NAN, demonstrating its efficacy and compatibility with existing OOD detectors, as well as its capability in label-free environments.",
      "authors": [
        "Jaewoo Park",
        "Jacky Chen Long Chai",
        "Jaeho Yoon",
        "Andrew Beng Jin Teoh"
      ],
      "year": 2023,
      "citation_count": 16,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/0e3a01e0bd1beff9e77d8809629db24fc706c085",
      "pdf_link": "",
      "venue": "IEEE International Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "69c2808097e7dfd357856f1ae82dcb6ce1bf64df",
      "title": "ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms",
      "abstract": "The task of out-of-distribution (OOD) detection is notoriously ill-defined. Earlier works focused on new-class detection, aiming to identify label-altering data distribution shifts, also known as\"semantic shift.\"However, recent works argue for a focus on failure detection, expanding the OOD evaluation framework to account for label-preserving data distribution shifts, also known as\"covariate shift.\"Intriguingly, under this new framework, complex OOD detectors that were previously considered state-of-the-art now perform similarly to, or even worse than the simple maximum softmax probability baseline. This raises the question: what are the latest OOD detectors actually detecting? Deciphering the behavior of OOD detection algorithms requires evaluation datasets that decouples semantic shift and covariate shift. To aid our investigations, we present ImageNet-OOD, a clean semantic shift dataset that minimizes the interference of covariate shift. Through comprehensive experiments, we show that OOD detectors are more sensitive to covariate shift than to semantic shift, and the benefits of recent OOD detection algorithms on semantic shift detection is minimal. Our dataset and analyses provide important insights for guiding the design of future OOD detectors.",
      "authors": [
        "William Yang",
        "Byron Zhang",
        "Olga Russakovsky"
      ],
      "year": 2023,
      "citation_count": 15,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/69c2808097e7dfd357856f1ae82dcb6ce1bf64df",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "8f53788139d97189af8204a36b109473a0a2b61f",
      "title": "Unified Out-Of-Distribution Detection: A Model-Specific Perspective",
      "abstract": "Out-of-distribution (OOD) detection aims to identify test examples that do not belong to the training distribution and are thus unlikely to be predicted reliably. Despite a plethora of existing works, most of them focused only on the scenario where OOD examples come from semantic shift (e.g., unseen categories), ignoring other possible causes (e.g., covariate shift). In this paper, we present a novel, unifying framework to study OOD detection in a broader scope. Instead of detecting OOD examples from a particular cause, we propose to detect examples that a deployed machine learning model (e.g., an image classifier) is unable to predict correctly. That is, whether a test example should be detected and rejected or not is \"model-specific\". We show that this framework unifies the detection of OOD examples caused by semantic shift and covariate shift, and closely addresses the concern of applying a machine learning model to uncontrolled environments. We provide an extensive analysis that involves a variety of models (e.g., different architectures and training strategies), sources of OOD examples, and OOD detection approaches, and reveal several insights into improving and understanding OOD detection in uncontrolled environments.",
      "authors": [
        "Reza Averly",
        "Wei-Lun Chao"
      ],
      "year": 2023,
      "citation_count": 15,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/8f53788139d97189af8204a36b109473a0a2b61f",
      "pdf_link": "",
      "venue": "IEEE International Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "8505cb57677d296351a1b86d15c843410778daca",
      "title": "Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection Capability",
      "abstract": "Out-of-distribution (OOD) detection is an indispensable aspect of secure AI when deploying machine learning models in real-world applications. Previous paradigms either explore better scoring functions or utilize the knowledge of outliers to equip the models with the ability of OOD detection. However, few of them pay attention to the intrinsic OOD detection capability of the given model. In this work, we generally discover the existence of an intermediate stage of a model trained on in-distribution (ID) data having higher OOD detection performance than that of its final stage across different settings, and further identify one critical data-level attribution to be learning with the atypical samples. Based on such insights, we propose a novel method, Unleashing Mask, which aims to restore the OOD discriminative capabilities of the well-trained model with ID data. Our method utilizes a mask to figure out the memorized atypical samples, and then finetune the model or prune it with the introduced mask to forget them. Extensive experiments and analysis demonstrate the effectiveness of our method. The code is available at: https://github.com/tmlr-group/Unleashing-Mask.",
      "authors": [
        "Jianing Zhu",
        "Hengzhuang Li",
        "Jiangchao Yao",
        "Tongliang Liu",
        "Jianliang Xu",
        "Bo Han"
      ],
      "year": 2023,
      "citation_count": 15,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/8505cb57677d296351a1b86d15c843410778daca",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "23bbd94f93e360f373f78ce20f61ec3486b1923d",
      "title": "Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is essential for reliable and trustworthy machine learning. Recent multi-modal OOD detection leverages textual information from in-distribution (ID) class names for visual OOD detection, yet it currently neglects the rich contextual information of ID classes. Large language models (LLMs) encode a wealth of world knowledge and can be prompted to generate descriptive features for each class. Indiscriminately using such knowledge causes catastrophic damage to OOD detection due to LLMs' hallucinations, as is observed by our analysis. In this paper, we propose to apply world knowledge to enhance OOD detection performance through selective generation from LLMs. Specifically, we introduce a consistency-based uncertainty calibration method to estimate the confidence score of each generation. We further extract visual objects from each image to fully capitalize on the aforementioned world knowledge. Extensive experiments demonstrate that our method consistently outperforms the state-of-the-art.",
      "authors": [
        "Yi Dai",
        "Hao Lang",
        "Kaisheng Zeng",
        "Fei Huang",
        "Yongbin Li"
      ],
      "year": 2023,
      "citation_count": 14,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/23bbd94f93e360f373f78ce20f61ec3486b1923d",
      "pdf_link": "",
      "venue": "Conference on Empirical Methods in Natural Language Processing",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "f911f3b51fcc88f2240def8f38ed8dff1da2e605",
      "title": "VRA: Variational Rectified Activation for Out-of-distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is critical to building reliable machine learning systems in the open world. Researchers have proposed various strategies to reduce model overconfidence on OOD data. Among them, ReAct is a typical and effective technique to deal with model overconfidence, which truncates high activations to increase the gap between in-distribution and OOD. Despite its promising results, is this technique the best choice for widening the gap? To answer this question, we leverage the variational method to find the optimal operation and verify the necessity of suppressing abnormally low and high activations and amplifying intermediate activations in OOD detection, rather than focusing only on high activations like ReAct. This motivates us to propose a novel technique called ``Variational Rectified Activation (VRA)'', which simulates these suppression and amplification operations using piecewise functions. Experimental results on multiple benchmark datasets demonstrate that our method outperforms existing post-hoc strategies. Meanwhile, VRA is compatible with different scoring functions and network architectures. \\textcolor[rgb]{0.93,0.0,0.47}{Our code can be found in Supplementary Material}.",
      "authors": [
        "Ming Xu",
        "Zheng Lian",
        "B. Liu",
        "Jianhua Tao"
      ],
      "year": 2023,
      "citation_count": 13,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/f911f3b51fcc88f2240def8f38ed8dff1da2e605",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "955dd252793ea3f07de81b2f61165b6a822e07d5",
      "title": "Average of Pruning: Improving Performance and Stability of Out-of-Distribution Detection",
      "abstract": "Detecting out-of-distribution (OOD) inputs has been a critical issue for neural networks in the open world. However, the unstable behavior of OOD detection along the optimization trajectory during training has not been explored clearly. In this article, we first find the performance of OOD detection suffers from overfitting and instability during training: 1) the performance could decrease when the training error is near zero and 2) the performance would vary sharply in the final stage of training. Based on our findings, we propose an average of pruning (AoP), consisting of model averaging (MA) and pruning, to mitigate the unstable behaviors. Specifically, MA can help achieve a stable performance by smoothing the landscape, and pruning is theoretically and empirically verified to eliminate overfitting by avoiding redundant features. Comprehensive experiments on various datasets and architectures are conducted to verify the effectiveness of our method.",
      "authors": [
        "Zhen Cheng",
        "Fei Zhu",
        "Xu-Yao Zhang",
        "Cheng-Lin Liu"
      ],
      "year": 2023,
      "citation_count": 13,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/955dd252793ea3f07de81b2f61165b6a822e07d5",
      "pdf_link": "",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "65e63d2d9168fa3cca6cd8bc083612b5f6cecc84",
      "title": "Limitations of Out-of-Distribution Detection in 3D Medical Image Segmentation",
      "abstract": "Deep learning models perform unreliably when the data come from a distribution different from the training one. In critical applications such as medical imaging, out-of-distribution (OOD) detection methods help to identify such data samples, preventing erroneous predictions. In this paper, we further investigate OOD detection effectiveness when applied to 3D medical image segmentation. We designed several OOD challenges representing clinically occurring cases and found that none of the methods achieved acceptable performance. Methods not dedicated to segmentation severely failed to perform in the designed setups; the best mean false-positive rate at a 95% true-positive rate (FPR) was 0.59. Segmentation-dedicated methods still achieved suboptimal performance, with the best mean FPR being 0.31 (lower is better). To indicate this suboptimality, we developed a simple method called Intensity Histogram Features (IHF), which performed comparably or better in the same challenges, with a mean FPR of 0.25. Our findings highlight the limitations of the existing OOD detection methods with 3D medical images and present a promising avenue for improving them. To facilitate research in this area, we release the designed challenges as a publicly available benchmark and formulate practical criteria to test the generalization of OOD detection beyond the suggested benchmark. We also propose IHF as a solid baseline to contest emerging methods.",
      "authors": [
        "Anton Vasiliuk",
        "Daria Frolova",
        "M. Belyaev",
        "B. Shirokikh"
      ],
      "year": 2023,
      "citation_count": 13,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/65e63d2d9168fa3cca6cd8bc083612b5f6cecc84",
      "pdf_link": "",
      "venue": "Journal of Imaging",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "b723d4e9fbe81890624d11c873acb63ddf21b64b",
      "title": "On the use of Mahalanobis distance for out-of-distribution detection with neural networks for medical imaging",
      "abstract": "Implementing neural networks for clinical use in medical applications necessitates the ability for the network to detect when input data differs significantly from the training data, with the aim of preventing unreliable predictions. The community has developed several methods for out-of-distribution (OOD) detection, within which distance-based approaches - such as Mahalanobis distance - have shown potential. This paper challenges the prevailing community understanding that there is an optimal layer, or combination of layers, of a neural network for applying Mahalanobis distance for detection of any OOD pattern. Using synthetic artefacts to emulate OOD patterns, this paper shows the optimum layer to apply Mahalanobis distance changes with the type of OOD pattern, showing there is no one-fits-all solution. This paper also shows that separating this OOD detector into multiple detectors at different depths of the network can enhance the robustness for detecting different OOD patterns. These insights were validated on real-world OOD tasks, training models on CheXpert chest X-rays with no support devices, then using scans with unseen pacemakers (we manually labelled 50% of CheXpert for this research) and unseen sex as OOD cases. The results inform best-practices for the use of Mahalanobis distance for OOD detection. The manually annotated pacemaker labels and the project's code are available at: https://github.com/HarryAnthony/Mahalanobis-OOD-detection.",
      "authors": [
        "Harry Anthony",
        "K. Kamnitsas"
      ],
      "year": 2023,
      "citation_count": 13,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/b723d4e9fbe81890624d11c873acb63ddf21b64b",
      "pdf_link": "",
      "venue": "UNSURE@MICCAI",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "ecd30803a587687db2e5a2ff659391e56b792714",
      "title": "MixOOD: Improving Out-of-distribution Detection with Enhanced Data Mixup",
      "abstract": "Detecting out-of-distribution (OOD) inputs for deep learning models is a critical task when models are deployed in real-world environments. Recently, a large number of works have been dedicated to tackling the OOD detection problem. One of the most straightforward and effective ways is OOD training, which adds heterogeneous auxiliary data in the training stage. However, the extra auxiliary data cannot be involved arbitrarily. A high-quality and powerful auxiliary dataset must contain samples that belong to OOD but are close to in-distribution (ID), which can teach the model to learn more information about OOD samples, furthermore, distinguish OOD from ID. The key issue for this problem is how to simply acquire such distinctive OOD samples. In this article, we propose an enhanced Mixup-based OOD (MixOOD) detection strategy that can be attached to any threshold-based OOD detecting method. Different from the traditional Mixup designed for ID data augmentation, our proposed MixOOD generates augmented images with deliberately modified Mixup and then uses them as auxiliary OOD data to leverage the OOD detection. We test our method with classical OOD detecting approaches like Maximum Softmax Probability, Energy Score, and Out-of-distribution detector for Neural networks. Experiments show that models with MixOOD can better distinguish in- and out-of-distribution samples than the original version of each approach.",
      "authors": [
        "Taocun Yang",
        "Y. Huang",
        "Yanlin Xie",
        "Junbo Liu",
        "Shengchun Wang"
      ],
      "year": 2023,
      "citation_count": 13,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/ecd30803a587687db2e5a2ff659391e56b792714",
      "pdf_link": "",
      "venue": "ACM Trans. Multim. Comput. Commun. Appl.",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "350b00baaddd9f42dd3689f475bea3139e24099d",
      "title": "Revisit PCA-based technique for Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is a desired ability to ensure the reliability and safety of intelligent systems. A scoring function is often designed to measure the degree of any new data being an OOD sample. While most designed scoring functions are based on a single source of information (e.g., the classifier’s output, logits, or feature vector), recent studies demonstrate that fusion of multiple sources may help better detect OOD data. In this study, after detailed analysis of the issue in OOD detection by the conventional principal component analysis (PCA), we propose fusing a simple regularized PCA-based reconstruction error with other source of scoring function to further improve OOD detection performance. In particular, when combined with a strong energy score-based OOD method, the regularized reconstruction error helps achieve new state-of the-art OOD detection results on multiple standard benchmarks. The code is available at https://github.com/SYSUMIA-GROUP/pca-based-out-of-distribution-detection.",
      "authors": [
        "Xiaoyuan Guan",
        "Zhouwu Liu",
        "Weishi Zheng",
        "Yuren Zhou",
        "Ruixuan Wang"
      ],
      "year": 2023,
      "citation_count": 12,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/350b00baaddd9f42dd3689f475bea3139e24099d",
      "pdf_link": "",
      "venue": "IEEE International Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4de791464e08ba25d2466abf78fd9b529ce6d2d5",
      "title": "Category-Extensible Out-of-Distribution Detection via Hierarchical Context Descriptions",
      "abstract": "The key to OOD detection has two aspects: generalized feature representation and precise category description. Recently, vision-language models such as CLIP provide significant advances in both two issues, but constructing precise category descriptions is still in its infancy due to the absence of unseen categories. This work introduces two hierarchical contexts, namely perceptual context and spurious context, to carefully describe the precise category boundary through automatic prompt tuning. Specifically, perceptual contexts perceive the inter-category difference (e.g., cats vs apples) for current classification tasks, while spurious contexts further identify spurious (similar but exactly not) OOD samples for every single category (e.g., cats vs panthers, apples vs peaches). The two contexts hierarchically construct the precise description for a certain category, which is, first roughly classifying a sample to the predicted category and then delicately identifying whether it is truly an ID sample or actually OOD. Moreover, the precise descriptions for those categories within the vision-language framework present a novel application: CATegory-EXtensible OOD detection (CATEX). One can efficiently extend the set of recognizable categories by simply merging the hierarchical contexts learned under different sub-task settings. And extensive experiments are conducted to demonstrate CATEX's effectiveness, robustness, and category-extensibility. For instance, CATEX consistently surpasses the rivals by a large margin with several protocols on the challenging ImageNet-1K dataset. In addition, we offer new insights on how to efficiently scale up the prompt engineering in vision-language models to recognize thousands of object categories, as well as how to incorporate large language models (like GPT-3) to boost zero-shot applications. Code is publicly available at https://github.com/alibaba/catex.",
      "authors": [
        "Kai Liu",
        "Zhihang Fu",
        "Chao Chen",
        "Sheng Jin",
        "Ze Chen",
        "Mingyuan Tao",
        "Rongxin Jiang",
        "Jieping Ye"
      ],
      "year": 2024,
      "citation_count": 6,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4de791464e08ba25d2466abf78fd9b529ce6d2d5",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "913d26360f1a715f6ae80f5a775f398aa2f66c9d",
      "title": "DOS: Diverse Outlier Sampling for Out-of-Distribution Detection",
      "abstract": "Modern neural networks are known to give overconfident prediction for out-of-distribution inputs when deployed in the open world. It is common practice to leverage a surrogate outlier dataset to regularize the model during training, and recent studies emphasize the role of uncertainty in designing the sampling strategy for outlier dataset. However, the OOD samples selected solely based on predictive uncertainty can be biased towards certain types, which may fail to capture the full outlier distribution. In this work, we empirically show that diversity is critical in sampling outliers for OOD detection performance. Motivated by the observation, we propose a straightforward and novel sampling strategy named DOS (Diverse Outlier Sampling) to select diverse and informative outliers. Specifically, we cluster the normalized features at each iteration, and the most informative outlier from each cluster is selected for model training with absent category loss. With DOS, the sampled outliers efficiently shape a globally compact decision boundary between ID and OOD data. Extensive experiments demonstrate the superiority of DOS, reducing the average FPR95 by up to 25.79% on CIFAR-100 with TI-300K.",
      "authors": [
        "Wenyu Jiang",
        "Hao Cheng",
        "Mingcai Chen",
        "Chongjun Wang",
        "Hongxin Wei"
      ],
      "year": 2023,
      "citation_count": 12,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/913d26360f1a715f6ae80f5a775f398aa2f66c9d",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f",
      "title": "ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation",
      "abstract": "Recent advancements in dense out-of-distribution (OOD) detection have primarily focused on scenarios where the training and testing datasets share a similar domain, with the assumption that no domain shift exists between them. However, in real-world situations, domain shift often exits and significantly affects the accuracy of existing out-of-distribution (OOD) detection models. In this work, we propose a dual-level OOD detection framework to handle domain shift and semantic shift jointly. The first level distinguishes whether domain shift exists in the image by leveraging global low-level features, while the second level identifies pixels with semantic shift by utilizing dense high-level feature maps. In this way, we can selectively adapt the model to unseen domains as well as enhance model's capacity in detecting novel classes. We validate the efficacy of our proposed method on several OOD segmentation benchmarks, including those with significant domain shifts and those without, observing consistent performance improvements across various baseline models. Code is available at ${\\href{https://github.com/gaozhitong/ATTA}{https://github.com/gaozhitong/ATTA}}$.",
      "authors": [
        "Zhitong Gao",
        "Shipeng Yan",
        "Xuming He"
      ],
      "year": 2023,
      "citation_count": 12,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "7da7d9d38b964a70396fa842bf69f9a897111c26",
      "title": "SPN: A Method of Few-Shot Traffic Classification With Out-of-Distribution Detection Based on Siamese Prototypical Network",
      "abstract": "Traffic classification has always been one of the important research directions in the field of cyber security. Achieving rapid traffic classification and detecting unknown traffic are critical for preventing network attacks, malicious software, transaction fraud, and other types of cyber security threats. However, most existing models are based on large-scale data and are unable to quickly learn and recognize unknown traffic. Some methods based on few-shot learning solve the problem of rapidly learning new types of traffic, but they cannot detect out-of-distribution samples. Based on this, this paper proposes a few-shot traffic multi-classification method that supports out-of-distribution detection, named SPN. It improves the performance by integrating twin networks into the meta-learning framework based on the idea of metric learning, and introduces margin loss to ensure detection performance. We conduct two types of experiments, and compare them with the relevant baseline methods. The results show that SPN has excellent performance in implementing few-shot multi-classification and out-of-distribution detection, and performs well in intrusion detection.",
      "authors": [
        "Gongxun Miao",
        "Guohua Wu",
        "Zhen Zhang",
        "Yongjie Tong",
        "Bing Lu"
      ],
      "year": 2023,
      "citation_count": 11,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/7da7d9d38b964a70396fa842bf69f9a897111c26",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "08925eef04eada4dd46dd3a33ea35f05795b12a9",
      "title": "GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection",
      "abstract": "Detecting out-of-distribution (OOD) examples is crucial to guarantee the reliability and safety of deep neural networks in real-world settings. In this paper, we offer an innovative perspective on quantifying the disparities between in-distribution (ID) and OOD data -- analyzing the uncertainty that arises when models attempt to explain their predictive decisions. This perspective is motivated by our observation that gradient-based attribution methods encounter challenges in assigning feature importance to OOD data, thereby yielding divergent explanation patterns. Consequently, we investigate how attribution gradients lead to uncertain explanation outcomes and introduce two forms of abnormalities for OOD detection: the zero-deflation abnormality and the channel-wise average abnormality. We then propose GAIA, a simple and effective approach that incorporates Gradient Abnormality Inspection and Aggregation. The effectiveness of GAIA is validated on both commonly utilized (CIFAR) and large-scale (ImageNet-1k) benchmarks. Specifically, GAIA reduces the average FPR95 by 23.10% on CIFAR10 and by 45.41% on CIFAR100 compared to advanced post-hoc methods.",
      "authors": [
        "Jinggang Chen",
        "Junjie Li",
        "Xiaoyang Qu",
        "Jianzong Wang",
        "Jiguang Wan",
        "Jing Xiao"
      ],
      "year": 2023,
      "citation_count": 11,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/08925eef04eada4dd46dd3a33ea35f05795b12a9",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4fc9a9046cab45de423cadb2db887881cd0972e8",
      "title": "Continual Evidential Deep Learning for Out-of-Distribution Detection",
      "abstract": "Uncertainty-based deep learning models have attracted a great deal of interest for their ability to provide accurate and reliable predictions. Evidential deep learning stands out achieving remarkable performance in detecting out-of-distribution (OOD) data with a single deterministic neural network. Motivated by this fact, in this paper we propose the integration of an evidential deep learning method into a continual learning framework in order to perform simultaneously incremental object classification and OOD detection. Moreover, we analyze the ability of vacuity and dissonance to differentiate between in-distribution data belonging to old classes and OOD data. The proposed method 1, called CEDL, is evaluated on CIFAR-100 considering two settings consisting of 5 and 10 tasks, respectively. From the obtained results, we could appreciate that the proposed method, in addition to provide comparable results in object classification with respect to the baseline, largely outperforms OOD detection compared to several posthoc methods on three evaluation metrics: AUROC, AUPR and FPR95.",
      "authors": [
        "Eduardo Aguilar",
        "B. Raducanu",
        "P. Radeva",
        "Joost van de Weijer"
      ],
      "year": 2023,
      "citation_count": 11,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4fc9a9046cab45de423cadb2db887881cd0972e8",
      "pdf_link": "",
      "venue": "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "e75e08851675eb506ea0149b0403828b6fb24900",
      "title": "Hybrid Energy Based Model in the Feature Space for Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is a critical requirement for the deployment of deep neural networks. This paper introduces the HEAT model, a new post-hoc OOD detection method estimating the density of in-distribution (ID) samples using hybrid energy-based models (EBM) in the feature space of a pre-trained backbone. HEAT complements prior density estimators of the ID density, e.g. parametric models like the Gaussian Mixture Model (GMM), to provide an accurate yet robust density estimation. A second contribution is to leverage the EBM framework to provide a unified density estimation and to compose several energy terms. Extensive experiments demonstrate the significance of the two contributions. HEAT sets new state-of-the-art OOD detection results on the CIFAR-10 / CIFAR-100 benchmark as well as on the large-scale Imagenet benchmark. The code is available at: https://github.com/MarcLafon/heatood.",
      "authors": [
        "Marc Lafon",
        "Elias Ramzi",
        "Clément Rambour",
        "Nicolas Thome"
      ],
      "year": 2023,
      "citation_count": 11,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/e75e08851675eb506ea0149b0403828b6fb24900",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "2f615dc49f38928fb08534b6edd1ad2c0102243a",
      "title": "Revisiting Out-of-Distribution Detection in LiDAR-based 3D Object Detection",
      "abstract": "LiDAR-based 3D object detection has become an essential part of automated driving due to its ability to localize and classify objects precisely in 3D. However, object detectors face a critical challenge when dealing with unknown foreground objects, particularly those that were not present in their original training data. These out-of-distribution (OOD) objects can lead to misclassifications, posing a significant risk to the safety and reliability of automated vehicles. Currently, LiDAR-based OOD object detection has not been well studied. We address this problem by generating synthetic training data for OOD objects by perturbing known object categories. Our idea is that these synthetic OOD objects produce different responses in the feature map of an object detector compared to in-distribution (ID) objects. We then extract features using a pre-trained and fixed object detector and train a simple multilayer perceptron (MLP) to classify each detection as either ID or OOD. In addition, we propose a new evaluation protocol that allows the use of existing datasets without modifying the point cloud, ensuring a more authentic evaluation of real-world scenarios. The effectiveness of our method is validated through experiments on the newly proposed nuScenes OOD benchmark. The source code is available at https://github.com/uulm-mrm/mmood3d.",
      "authors": [
        "Michael Kösel",
        "M. Schreiber",
        "Michael Ulrich",
        "Claudius Gläser",
        "Klaus C. J. Dietmayer"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/2f615dc49f38928fb08534b6edd1ad2c0102243a",
      "pdf_link": "",
      "venue": "2024 IEEE Intelligent Vehicles Symposium (IV)",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "7466087f3748165181b0463153008d39879d5879",
      "title": "Zero-Shot Out-of-Distribution Detection with Outlier Label Exposure",
      "abstract": "As vision-language models like CLIP are widely applied to zero-shot tasks and gain remarkable performance on in-distribution (ID) data, detecting and rejecting out-of-distribution (OOD) inputs in the zero-shot setting have become crucial for ensuring the safety of using such models on the fly. Most existing zero-shot OOD detectors rely on ID class label-based prompts to guide CLIP in classifying ID images and rejecting OOD images. In this work we instead propose to leverage a large set of diverse auxiliary outlier class labels as pseudo OOD class text prompts to CLIP for enhancing zero-shot OOD detection, an approach we called Outlier Label Exposure (OLE). The key intuition is that ID images are expected to have lower similarity to these outlier class prompts than OOD images. One issue is that raw class labels often include noise labels, e.g., synonyms of ID labels, rendering raw OLE-based detection ineffective. To address this issue, we introduce an outlier prototype learning module that utilizes the prompt embeddings of the outlier labels to learn a small set of pivotal outlier prototypes for an embedding similarity-based OOD scoring. Additionally, the outlier classes and their prototypes can be loosely coupled with the ID classes, leading to an inseparable decision region between them. Thus, we also introduce an outlier label generation module that synthesizes our outlier prototypes and ID class embeddings to generate in-between outlier prototypes to further calibrate the detection in OLE. Despite its simplicity, extensive experiments show that OLE substantially improves detection performance and achieves new state-of-the-art performance in large-scale OOD and hard OOD detection benchmarks. Code is available at https://github.com/Choubo/OLE",
      "authors": [
        "Choubo Ding",
        "Guansong Pang"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/7466087f3748165181b0463153008d39879d5879",
      "pdf_link": "",
      "venue": "IEEE International Joint Conference on Neural Network",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "8529e0bbf80f36998f9b65b11bc0177099f11b07",
      "title": "Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection",
      "abstract": "In the open world, detecting out-of-distribution (OOD) data, whose labels are disjoint with those of in-distribution (ID) samples, is important for reliable deep neural networks (DNNs). To achieve better detection performance, one type of approach proposes to fine-tune the model with auxiliary OOD datasets to amplify the difference between ID and OOD data through a separation loss defined on model outputs. However, none of these studies consider enlarging the feature disparity, which should be more effective compared to outputs. The main difficulty lies in the diversity of OOD samples, which makes it hard to describe their feature distribution, let alone design losses to separate them from ID features. In this paper, we neatly fence off the problem based on an aggregation property of ID features named Neural Collapse (NC). NC means that the penultimate features of ID samples within a class are nearly identical to the last layer weight of the corresponding class. Based on this property, we propose a simple but effective loss called Separation Loss, which binds the features of OOD data in a subspace orthogonal to the principal subspace of ID features formed by NC. In this way, the features of ID and OOD samples are separated by different dimensions. By optimizing the feature separation loss rather than purely enlarging output differences, our detection achieves SOTA performance on CIFAR10, CIFAR100 and ImageNet benchmarks without any additional data augmentation or sampling, demonstrating the importance of feature separation in OOD detection. Code is available at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.",
      "authors": [
        "Yingwen Wu",
        "Ruiji Yu",
        "Xinwen Cheng",
        "Zhengbao He",
        "Xiaolin Huang"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/8529e0bbf80f36998f9b65b11bc0177099f11b07",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "565d5a9038154fbbcba3d4a6f17671af9515fbcc",
      "title": "Out-Of-Distribution Detection with Diversification (Provably)",
      "abstract": "Out-of-distribution (OOD) detection is crucial for ensuring reliable deployment of machine learning models. Recent advancements focus on utilizing easily accessible auxiliary outliers (e.g., data from the web or other datasets) in training. However, we experimentally reveal that these methods still struggle to generalize their detection capabilities to unknown OOD data, due to the limited diversity of the auxiliary outliers collected. Therefore, we thoroughly examine this problem from the generalization perspective and demonstrate that a more diverse set of auxiliary outliers is essential for enhancing the detection capabilities. However, in practice, it is difficult and costly to collect sufficiently diverse auxiliary outlier data. Therefore, we propose a simple yet practical approach with a theoretical guarantee, termed Diversity-induced Mixup for OOD detection (diverseMix), which enhances the diversity of auxiliary outlier set for training in an efficient way. Extensive experiments show that diverseMix achieves superior performance on commonly used and recent challenging large-scale benchmarks, which further confirm the importance of the diversity of auxiliary outliers.",
      "authors": [
        "Haiyu Yao",
        "Zongbo Han",
        "Huazhu Fu",
        "Xi Peng",
        "Qinghua Hu",
        "Changqing Zhang"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/565d5a9038154fbbcba3d4a6f17671af9515fbcc",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "590659832401c015e20a264cfdd7e0e4097b478b",
      "title": "Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection",
      "abstract": "For a machine learning model deployed in real world scenarios, the ability of detecting out-of-distribution (OOD) samples is indispensable and challenging. Most existing OOD detection methods focused on exploring advanced training skills or training-free tricks to prevent the model from yielding overconfident confidence score for unknown samples. The training-based methods require expensive training cost and rely on OOD samples which are not always available, while most training-free methods can not efficiently utilize the prior information from the training data. In this work, we propose an \\textbf{O}ptimal \\textbf{P}arameter and \\textbf{N}euron \\textbf{P}runing (\\textbf{OPNP}) approach, which aims to identify and remove those parameters and neurons that lead to over-fitting. The main method is divided into two steps. In the first step, we evaluate the sensitivity of the model parameters and neurons by averaging gradients over all training samples. In the second step, the parameters and neurons with exceptionally large or close to zero sensitivities are removed for prediction. Our proposal is training-free, compatible with other post-hoc methods, and exploring the information from all training data. Extensive experiments are performed on multiple OOD detection tasks and model architectures, showing that our proposed OPNP consistently outperforms the existing methods by a large margin.",
      "authors": [
        "Chao Chen",
        "Zhihang Fu",
        "Kai Liu",
        "Ze Chen",
        "Mingyuan Tao",
        "Jieping Ye"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/590659832401c015e20a264cfdd7e0e4097b478b",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1fd384324d878cdb770a51cd333b7451b2fe5bcc",
      "title": "Out-of-distribution Detection in Dependent Data for Cyber-physical Systems with Conformal Guarantees",
      "abstract": "Uncertainty in the predictions of learning-enabled components hinders their deployment in safety-critical cyber-physical systems (CPS). A shift from the training distribution of a learning-enabled component (LEC) is one source of uncertainty in the LEC’s predictions. Detection of this shift or out-of-distribution (OOD) detection on individual datapoints has therefore gained attention recently. But in many applications, inputs to CPS form a temporal sequence. Existing techniques for OOD detection in time-series data for CPS either do not exploit temporal relationships in the sequence or do not provide any guarantees on detection. We propose using deviation from the in-distribution temporal equivariance as the non-conformity measure in conformal anomaly detection framework for OOD detection in time-series data for CPS. Computing independent predictions from multiple conformal detectors based on the proposed measure and combining these predictions by Fisher’s method leads to the proposed detector CODiT with bounded false alarms. CODiT performs OOD detection on fixed-length windows of consecutive time-series datapoints by using Fisher value of the input window. We further propose performing OOD detection on real-time time-series traces of variable lengths with bounded false alarms. This can be done by using CODiT to compute Fisher values of the sliding windows in the input trace and combining these values by a merging function. Merging functions such as Harmonic Mean, Arithmetic Mean, Geometric Mean, Bonferroni Method, and so on, can be used to combine Fisher values of the sliding windows in the input trace, and the combined value can be used for OOD detection on the trace with bounded false alarm rate guarantees. We illustrate the efficacy of CODiT by achieving state-of-the-art results in two case studies for OOD detection on fixed-length windows. The first one is on an autonomous driving system with perception (or vision) LEC. The second case study is on a medical CPS for walking pattern or GAIT analysis where physiological (non-vision) data is collected with force-sensitive resistors attached to the subject’s body. For OOD detection on variable length traces, we consider the same case studies on the autonomous driving system and medical CPS for GAIT analysis. We report our results with four merging functions on the Fisher values computed by CODiT on the sliding windows of the input trace. We also compare the false alarm rate guarantees by these four merging functions in the autonomous driving system case study. Code, data, and trained models are available at https://github.com/kaustubhsridhar/time-series-OOD.",
      "authors": [
        "Ramneet Kaur",
        "Yahan Yang",
        "O. Sokolsky",
        "Insup Lee"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1fd384324d878cdb770a51cd333b7451b2fe5bcc",
      "pdf_link": "",
      "venue": "ACM Trans. Cyber Phys. Syst.",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4f292e3e9d34471631203d222e597912ae936a05",
      "title": "Multimodal Classification and Out-of-distribution Detection for Multimodal Intent Understanding",
      "abstract": "Multimodal intent understanding is a significant research area that requires effective leveraging of multiple modalities to analyze human language. Existing methods face two main challenges in this domain. Firstly, they have limitations in capturing the nuanced and high-level semantics underlying complex in-distribution (ID) multimodal intents. Secondly, they exhibit poor generalization when confronted with unseen out-of-distribution (OOD) data in real-world scenarios. To address these issues, we propose a novel method for both ID classification and OOD detection (MIntOOD). We first introduce a weighted feature fusion network that models multimodal representations. This network dynamically learns the importance of each modality, adapting to multimodal contexts. To develop discriminative representations for both tasks, we synthesize pseudo-OOD data from convex combinations of ID data and engage in multimodal representation learning from both coarse-grained and fine-grained perspectives. The coarse-grained perspective focuses on distinguishing between ID and OOD binary classes, while the fine-grained perspective not only enhances the discrimination between different ID classes but also captures instance-level interactions between ID and OOD samples, promoting proximity among similar instances and separation from dissimilar ones. We establish baselines for three multimodal intent datasets and build an OOD benchmark. Extensive experiments on these datasets demonstrate that our method significantly improves OOD detection performance with a 3~10% increase in AUROC scores while achieving new state-of-the-art results in ID classification. Data and codes are available at https://github.com/thuiar/MIntOOD.",
      "authors": [
        "Hanlei Zhang",
        "Qianrui Zhou",
        "Hua Xu",
        "Jianhua Su",
        "Roberto Evans",
        "Kai Gao"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4f292e3e9d34471631203d222e597912ae936a05",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "726cf970e8dc6642bb6064f78e7279cee50a9222",
      "title": "A Unified Approach Towards Active Learning and Out-of-Distribution Detection",
      "abstract": "When applying deep learning models in open-world scenarios, active learning (AL) strategies are crucial for identifying label candidates from a nearly infinite amount of unlabeled data. In this context, robust out-of-distribution (OOD) detection mechanisms are essential for handling data outside the target distribution of the application. However, current works investigate both problems separately. In this work, we introduce SISOM as the first unified solution for both AL and OOD detection. By leveraging feature space distance metrics SISOM combines the strengths of the currently independent tasks to solve both effectively. We conduct extensive experiments showing the problems arising when migrating between both tasks. In these evaluations SISOM underlined its effectiveness by achieving first place in two of the widely used OpenOOD benchmarks and second place in the remaining one. In AL, SISOM outperforms others and delivers top-1 performance in three benchmarks",
      "authors": [
        "Sebastian Schmidt",
        "Leonard Schenk",
        "Leo Schwinn",
        "Stephan Günnemann"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/726cf970e8dc6642bb6064f78e7279cee50a9222",
      "pdf_link": "",
      "venue": "Trans. Mach. Learn. Res.",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4ae78016f21de53032cba4d7327e21b12fe1dcf5",
      "title": "Out-of-Distribution Detection with Virtual Outlier Smoothing",
      "abstract": "Detecting out-of-distribution (OOD) inputs plays a crucial role in guaranteeing the reliability of deep neural networks (DNNs) when deployed in real-world scenarios. However, DNNs typically exhibit overconfidence in OOD samples, which is attributed to the similarity in patterns between OOD and in-distribution (ID) samples. To mitigate this overconfidence, advanced approaches suggest the incorporation of auxiliary OOD samples during model training, where the outliers are assigned with an equal likelihood of belonging to any category. However, identifying outliers that share patterns with ID samples poses a significant challenge. To address the challenge, we propose a novel method, Virtual Outlier Smoothing (VOSo), which constructs auxiliary outliers using ID samples, thereby eliminating the need to search for OOD samples. Specifically, VOSo creates these virtual outliers by perturbing the semantic regions of ID samples and infusing patterns from other ID samples. For instance, a virtual outlier might consist of a cat’s face with a dog’s nose, where the cat’s face serves as the semantic feature for model prediction. Meanwhile, VOSo adjusts the labels of virtual OOD samples based on the extent of semantic region perturbation, aligning with the notion that virtual outliers may contain ID patterns. Extensive experiments are conducted on diverse OOD detection benchmarks, demonstrating the effectiveness of the proposed VOSo. Our code will be available at https://github.com/junz-debug/VOSo.\n",
      "authors": [
        "Jun Nie",
        "Yadan Luo",
        "Shanshan Ye",
        "Yonggang Zhang",
        "Xinmei Tian",
        "Zhen Fang"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4ae78016f21de53032cba4d7327e21b12fe1dcf5",
      "pdf_link": "",
      "venue": "International Journal of Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "eb332d020cb8877358157b7810e949d8f0256b1e",
      "title": "Calibrated Out-of-Distribution Detection with a Generic Representation",
      "abstract": "Out-of-distribution detection is a common issue in deploying vision models in practice and solving it is an essential building block in safety critical applications. Most of the existing OOD detection solutions focus on improving the OOD robustness of a classification model trained exclusively on in-distribution (ID) data. In this work, we take a different approach and propose to leverage generic pre-trained representation. We propose a novel OOD method, called GROOD, that formulates the OOD detection as a Neyman-Pearson task with well calibrated scores and which achieves excellent performance, predicated by the use of a good generic representation. Only a trivial training process is required for adapting GROOD to a particular problem. The method is simple, general, efficient, calibrated and with only a few hyper-parameters. The method achieves state-of-the-art performance on a number of OOD benchmarks, reaching near perfect performance on several of them. The source code is available at https://github.com/vojirt/GROOD.",
      "authors": [
        "Tomás Vojír",
        "Jan Sochman",
        "Rahaf Aljundi",
        "Juan E. Sala Matas"
      ],
      "year": 2023,
      "citation_count": 10,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/eb332d020cb8877358157b7810e949d8f0256b1e",
      "pdf_link": "",
      "venue": "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "79c72327dd14466c4db3865902c8317f74bb4c56",
      "title": "Learning with Mixture of Prototypes for Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection aims to detect testing samples far away from the in-distribution (ID) training data, which is crucial for the safe deployment of machine learning models in the real world. Distance-based OOD detection methods have emerged with enhanced deep representation learning. They identify unseen OOD samples by measuring their distances from ID class centroids or prototypes. However, existing approaches learn the representation relying on oversimplified data assumptions, e.g, modeling ID data of each class with one centroid class prototype or using loss functions not designed for OOD detection, which overlook the natural diversities within the data. Naively enforcing data samples of each class to be compact around only one prototype leads to inadequate modeling of realistic data and limited performance. To tackle these issues, we propose PrototypicAl Learning with a Mixture of prototypes (PALM) which models each class with multiple prototypes to capture the sample diversities, and learns more faithful and compact samples embeddings to enhance OOD detection. Our method automatically identifies and dynamically updates prototypes, assigning each sample to a subset of prototypes via reciprocal neighbor soft assignment weights. PALM optimizes a maximum likelihood estimation (MLE) loss to encourage the sample embeddings to be compact around the associated prototypes, as well as a contrastive loss on all prototypes to enhance intra-class compactness and inter-class discrimination at the prototype level. Moreover, the automatic estimation of prototypes enables our approach to be extended to the challenging OOD detection task with unlabelled ID data. Extensive experiments demonstrate the superiority of PALM, achieving state-of-the-art average AUROC performance of 93.82 on the challenging CIFAR-100 benchmark. Code is available at https://github.com/jeff024/PALM.",
      "authors": [
        "Haodong Lu",
        "Dong Gong",
        "Shuo Wang",
        "Jason Xue",
        "Lina Yao",
        "Kristen Moore"
      ],
      "year": 2024,
      "citation_count": 37,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/79c72327dd14466c4db3865902c8317f74bb4c56",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "522513df46de56f4eeaca95b0a8196dae065f75e",
      "title": "Out-of-Distribution Detection with Negative Prompts",
      "abstract": "",
      "authors": [
        "Jun Nie",
        "Yonggang Zhang",
        "Zhen Fang",
        "Tongliang Liu",
        "Bo Han",
        "Xinmei Tian"
      ],
      "year": 2024,
      "citation_count": 32,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/522513df46de56f4eeaca95b0a8196dae065f75e",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "bea84d4f28799628fa91585690088c00e8dca827",
      "title": "How Does Unlabeled Data Provably Help Out-of-Distribution Detection?",
      "abstract": "Using unlabeled data to regularize the machine learning models has demonstrated promise for improving safety and reliability in detecting out-of-distribution (OOD) data. Harnessing the power of unlabeled in-the-wild data is non-trivial due to the heterogeneity of both in-distribution (ID) and OOD data. This lack of a clean set of OOD samples poses significant challenges in learning an optimal OOD classifier. Currently, there is a lack of research on formally understanding how unlabeled data helps OOD detection. This paper bridges the gap by introducing a new learning framework SAL (Separate And Learn) that offers both strong theoretical guarantees and empirical effectiveness. The framework separates candidate outliers from the unlabeled data and then trains an OOD classifier using the candidate outliers and the labeled ID data. Theoretically, we provide rigorous error bounds from the lens of separability and learnability, formally justifying the two components in our algorithm. Our theory shows that SAL can separate the candidate outliers with small error rates, which leads to a generalization guarantee for the learned OOD classifier. Empirically, SAL achieves state-of-the-art performance on common benchmarks, reinforcing our theoretical insights. Code is publicly available at https://github.com/deeplearning-wisc/sal.",
      "authors": [
        "Xuefeng Du",
        "Zhen Fang",
        "Ilias Diakonikolas",
        "Yixuan Li"
      ],
      "year": 2024,
      "citation_count": 31,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/bea84d4f28799628fa91585690088c00e8dca827",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "531762d327ac99a898f4976181c1c69e2e3076cb",
      "title": "Learning Transferable Negative Prompts for Out-of-Distribution Detection",
      "abstract": "Existing prompt learning methods have shown certain capabilities in Out-of-Distribution (OOD) detection, but the lack of OOD images in the target dataset in their training can lead to mismatches between OOD images and In-Distribution (ID) categories, resulting in a high false positive rate. To address this issue, we introduce a novel OOD detection method, named ‘NegPrompt’, to learn a set of negative prompts, each representing a negative connotation of a given class label, for delineating the boundaries between ID and OOD images. It learns such negative prompts with ID data only, without any reliance on external out-lier data. Further, current methods assume the availability of samples of all ID classes, rendering them ineffective in open-vocabulary learning scenarios where the inference stage can contain novel ID classes not present during training. In contrast, our learned negative prompts are transferable to novel class labels. Experiments on various ImageNet benchmarks show that NegPrompt surpasses state-of-the-art prompt-learning-based OOD detection methods and maintains a consistent lead in hard OOD detection in closed- and open-vocabulary classification scenarios. Code is available at https://github.com/mala-lab/negprompt.",
      "authors": [
        "Tianqi Li",
        "Guansong Pang",
        "Xiaolong Bai",
        "Wenjun Miao",
        "Jingyi Zheng"
      ],
      "year": 2024,
      "citation_count": 30,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/531762d327ac99a898f4976181c1c69e2e3076cb",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "5ad0eb12bedd86b88181cea5a9669d2a8e39cda1",
      "title": "Your data is not perfect: Towards cross-domain out-of-distribution detection in class-imbalanced data",
      "abstract": "",
      "authors": [
        "Xiang Fang",
        "A. Easwaran",
        "B. Genest",
        "P. Suganthan"
      ],
      "year": 2024,
      "citation_count": 28,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/5ad0eb12bedd86b88181cea5a9669d2a8e39cda1",
      "pdf_link": "",
      "venue": "Expert systems with applications",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "89b2a10540611860c4f48f5e6b412b8a17dfb036",
      "title": "Diffusion models for out-of-distribution detection in digital pathology",
      "abstract": "",
      "authors": [
        "J. Linmans",
        "Gabriel Raya",
        "J. Laak",
        "G. Litjens"
      ],
      "year": 2024,
      "citation_count": 27,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/89b2a10540611860c4f48f5e6b412b8a17dfb036",
      "pdf_link": "",
      "venue": "Medical Image Anal.",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "67dabdc0b1250d43641ea79869554741431c4b76",
      "title": "A Novel Single-Word Speech Recognition on Embedded Systems Using a Convolution Neuron Network with Improved Out-of-Distribution Detection",
      "abstract": "Advancements in AI have elevated speech recognition, with convolutional neural networks (CNNs) proving effective in processing spectrogram-transformed speech signals. CNNs, with lower parameters and higher accuracy compared to traditional models, are particularly efficient for deployment on storage-limited embedded devices. Artificial neural networks excel in predicting inputs within their expected output range but struggle with anomalies. This is usually harmful to a speech recognition system. In this paper, the neural network classifier for speech recognition is trained with a “negative branch” method, incorporating directional regularization with out-of-distribution training data, allowing it to maintain a high confidence score to the input within distribution while expressing a low confidence score to the anomaly input. It can enhance the performance of anomaly detection of the classifier, addressing issues like misclassifying the speech command that is out of the distribution. The result of the experiment suggests that the accuracy of the CNN model will not be affected by the regularization of the “negative branch”, and the performance of abnormal detection will be improved as the number of kernels of the convolutional layer increases.",
      "authors": [
        "Jiaqi Chen",
        "T. H. Teo",
        "C. Kok",
        "Yit Yan Koh"
      ],
      "year": 2024,
      "citation_count": 23,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/67dabdc0b1250d43641ea79869554741431c4b76",
      "pdf_link": "",
      "venue": "Electronics",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "f9ac68dc1fdd070a65a71c739e7135361c0d3006",
      "title": "MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities",
      "abstract": "Detecting out-of-distribution (OOD) samples is important for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. Existing research has mainly focused on unimodal scenarios on image data. However, real-world applications are inherently multimodal, which makes it essential to leverage information from multiple modalities to enhance the efficacy of OOD detection. To establish a foundation for more realistic Multimodal OOD Detection, we introduce the first-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes and varying modality combinations. We first evaluate existing unimodal OOD detection algorithms on MultiOOD, observing that the mere inclusion of additional modalities yields substantial improvements. This underscores the importance of utilizing multiple modalities for OOD detection. Based on the observation of Modality Prediction Discrepancy between in-distribution (ID) and OOD data, and its strong correlation with OOD performance, we propose the Agree-to-Disagree (A2D) algorithm to encourage such discrepancy during training. Moreover, we introduce a novel outlier synthesis method, NP-Mix, which explores broader feature spaces by leveraging the information from nearest neighbor classes and complements A2D to strengthen OOD detection performance. Extensive experiments on MultiOOD demonstrate that training with A2D and NP-Mix improves existing OOD detection algorithms by a large margin. Our source code and MultiOOD benchmark are available at https://github.com/donghao51/MultiOOD.",
      "authors": [
        "Hao Dong",
        "Yue Zhao",
        "Eleni Chatzi",
        "Olga Fink"
      ],
      "year": 2024,
      "citation_count": 21,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/f9ac68dc1fdd070a65a71c739e7135361c0d3006",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey",
      "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety of machine learning systems and has shaped the field of OOD detection. Meanwhile, several other problems are closely related to OOD detection, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD). To unify these problems, a generalized OOD detection framework was proposed, taxonomically categorizing these five problems. However, Vision Language Models (VLMs) such as CLIP have significantly changed the paradigm and blurred the boundaries between these fields, again confusing researchers. In this survey, we first present a generalized OOD detection v2, encapsulating the evolution of these fields in the VLM era. Our framework reveals that, with some field inactivity and integration, the demanding challenges have become OOD detection and AD. Then, we highlight the significant shift in the definition, problem settings, and benchmarks; we thus feature a comprehensive review of the methodology for OOD detection and related tasks to clarify their relationship to OOD detection. Finally, we explore the advancements in the emerging Large Vision Language Model (LVLM) era, such as GPT-4V. We conclude with open challenges and future directions. The resource is available at https://github.com/AtsuMiyai/Awesome-OOD-VLM.",
      "authors": [
        "Atsuyuki Miyai",
        "Jingkang Yang",
        "Jingyang Zhang",
        "Yifei Ming",
        "Yueqian Lin",
        "Qing Yu",
        "Go Irie",
        "Shafiq R. Joty",
        "Yixuan Li",
        "Hai Li",
        "Ziwei Liu",
        "T. Yamasaki",
        "Kiyoharu Aizawa"
      ],
      "year": 2024,
      "citation_count": 20,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "pdf_link": "",
      "venue": "Trans. Mach. Learn. Res.",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "14cfe2588311870325e2770c5159d3100d7031ea",
      "title": "Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection",
      "abstract": "Detecting out-of-distribution (OOD) samples is essential when deploying machine learning models in open-world scenarios. Zero-shot OOD detection, requiring no training on in-distribution (ID) data, has been possible with the advent of vision-language models like CLIP. Existing methods build a text-based classifier with only closed-set labels. However, this largely restricts the inherent capability of CLIP to recognize samples from large and open label space. In this paper, we propose to tackle this constraint by leveraging the expert knowledge and reasoning capability of large language models (LLM) to Envision potential Outlier Exposure, termed EOE, without access to any actual OOD data. Owing to better adaptation to open-world scenarios, EOE can be generalized to different tasks, including far, near, and fine-grained OOD detection. Technically, we design (1) LLM prompts based on visual similarity to generate potential outlier class labels specialized for OOD detection, as well as (2) a new score function based on potential outlier penalty to distinguish hard OOD samples effectively. Empirically, EOE achieves state-of-the-art performance across different OOD tasks and can be effectively scaled to the ImageNet-1K dataset. The code is publicly available at: https://github.com/tmlr-group/EOE.",
      "authors": [
        "Chentao Cao",
        "Zhun Zhong",
        "Zhanke Zhou",
        "Yang Liu",
        "Tongliang Liu",
        "Bo Han"
      ],
      "year": 2024,
      "citation_count": 18,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/14cfe2588311870325e2770c5159d3100d7031ea",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "f9cf8d53b1a157ab9dee16f03290d28865f3089a",
      "title": "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection",
      "abstract": "Post-hoc out-of-distribution (OOD) detection has garnered intensive attention in reliable machine learning. Many efforts have been dedicated to deriving score functions based on logits, distances, or rigorous data distribution assumptions to identify low-scoring OOD samples. Nevertheless, these estimate scores may fail to accurately reflect the true data density or impose impractical constraints. To provide a unified perspective on density-based score design, we propose a novel theoretical framework grounded in Bregman divergence, which extends distribution considerations to encompass an exponential family of distributions. Leveraging the conjugation constraint revealed in our theorem, we introduce a \\textsc{ConjNorm} method, reframing density function design as a search for the optimal norm coefficient $p$ against the given dataset. In light of the computational challenges of normalization, we devise an unbiased and analytically tractable estimator of the partition function using the Monte Carlo-based importance sampling technique. Extensive experiments across OOD detection benchmarks empirically demonstrate that our proposed \\textsc{ConjNorm} has established a new state-of-the-art in a variety of OOD detection setups, outperforming the current best method by up to 13.25$\\%$ and 28.19$\\%$ (FPR95) on CIFAR-100 and ImageNet-1K, respectively.",
      "authors": [
        "Bo Peng",
        "Yadan Luo",
        "Yonggang Zhang",
        "Yixuan Li",
        "Zhen Fang"
      ],
      "year": 2024,
      "citation_count": 17,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/f9cf8d53b1a157ab9dee16f03290d28865f3089a",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "2902a67f9aebb115fc2b6cdf611910e72e896bdd",
      "title": "GOODAT: Towards Test-time Graph Out-of-Distribution Detection",
      "abstract": "Graph neural networks (GNNs) have found widespread application in modeling graph data across diverse domains. While GNNs excel in scenarios where the testing data shares the distribution of their training counterparts (in distribution, ID), they often exhibit incorrect predictions when confronted with samples from an unfamiliar distribution (out-of-distribution, OOD). To identify and reject OOD samples with GNNs, recent studies have explored graph OOD detection, often focusing on training a specific model or modifying the data on top of a well-trained GNN. Despite their effectiveness, these methods come with heavy training resources and costs, as they need to optimize the GNN-based models on training data. Moreover, their reliance on modifying the original GNNs and accessing training data further restricts their universality. To this end, this paper introduces a method to detect Graph Out-of-Distribution At Test-time (namely GOODAT), a data-centric, unsupervised, and plug-and-play solution that operates independently of training data and modifications of GNN architecture. With a lightweight graph masker, GOODAT can learn informative subgraphs from test samples, enabling the capture of distinct graph patterns between OOD and ID samples. To optimize the graph masker, we meticulously design three unsupervised objective functions based on the graph information bottleneck principle, motivating the masker to capture compact yet informative subgraphs for OOD detection. Comprehensive evaluations confirm that our GOODAT method outperforms state-of-the-art benchmarks across a variety of real-world datasets.",
      "authors": [
        "Luzhi Wang",
        "Dongxiao He",
        "He Zhang",
        "Yixin Liu",
        "Wenjie Wang",
        "Shirui Pan",
        "Di Jin",
        "Tat-Seng Chua"
      ],
      "year": 2024,
      "citation_count": 16,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/2902a67f9aebb115fc2b6cdf611910e72e896bdd",
      "pdf_link": "",
      "venue": "AAAI Conference on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "d212c555293b81f845b3c99af4e922b0fcdb4290",
      "title": "Unifying Unsupervised Graph-Level Anomaly Detection and Out-of-Distribution Detection: A Benchmark",
      "abstract": "To build safe and reliable graph machine learning systems, unsupervised graph-level anomaly detection (GLAD) and unsupervised graph-level out-of-distribution (OOD) detection (GLOD) have received significant attention in recent years. Though those two lines of research indeed share the same objective, they have been studied independently in the community due to distinct evaluation setups, creating a gap that hinders the application and evaluation of methods from one to the other. To bridge the gap, in this work, we present a \\underline{\\textbf{U}}nified \\underline{\\textbf{B}}enchmark for unsupervised \\underline{\\textbf{G}}raph-level \\underline{\\textbf{O}}OD and anoma\\underline{\\textbf{L}}y \\underline{\\textbf{D}}etection (\\ourmethod), a comprehensive evaluation framework that unifies GLAD and GLOD under the concept of generalized graph-level OOD detection. Our benchmark encompasses 35 datasets spanning four practical anomaly and OOD detection scenarios, facilitating the comparison of 18 representative GLAD/GLOD methods. We conduct multi-dimensional analyses to explore the effectiveness, OOD sensitivity spectrum, robustness, and efficiency of existing methods, shedding light on their strengths and limitations. Furthermore, we provide an open-source codebase (https://github.com/UB-GOLD/UB-GOLD) of \\ourmethod to foster reproducible research and outline potential directions for future investigations based on our insights.",
      "authors": [
        "Yili Wang",
        "Yixin Liu",
        "Xu Shen",
        "Chenyu Li",
        "Kaize Ding",
        "Rui Miao",
        "Ying Wang",
        "Shirui Pan",
        "Xin Wang"
      ],
      "year": 2024,
      "citation_count": 14,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/d212c555293b81f845b3c99af4e922b0fcdb4290",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "d2d056e705902d33d769206489d53e0659e376cc",
      "title": "Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning",
      "abstract": "Real-world data deviating from the independent and identically distributed (i.i.d.) assumption of in-distribution training data poses security threats to deep networks, thus advancing out-of-distribution (OOD) detection algorithms. Detection methods in generative language models (GLMs) mainly focus on uncertainty estimation and embedding distance measurement, with the latter proven to be most effective in traditional linguistic tasks like summarization and translation. However, another complex generative scenario mathematical reasoning poses significant challenges to embedding-based methods due to its high-density feature of output spaces, but this feature causes larger discrepancies in the embedding shift trajectory between different samples in latent spaces. Hence, we propose a trajectory-based method TV score, which uses trajectory volatility for OOD detection in mathematical reasoning. Experiments show that our method outperforms all traditional algorithms on GLMs under mathematical reasoning scenarios and can be extended to more applications with high-density features in output spaces, such as multiple-choice questions.",
      "authors": [
        "Yiming Wang",
        "Pei Zhang",
        "Baosong Yang",
        "Derek F. Wong",
        "Zhuosheng Zhang",
        "Rui Wang"
      ],
      "year": 2024,
      "citation_count": 12,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/d2d056e705902d33d769206489d53e0659e376cc",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "70da774b2b30397ee2f7e2abc819ed126641a70d",
      "title": "Out-of-distribution Detection in Medical Image Analysis: A survey",
      "abstract": "Computer-aided diagnostics has benefited from the development of deep learning-based computer vision techniques in these years. Traditional supervised deep learning methods assume that the test sample is drawn from the identical distribution as the training data. However, it is possible to encounter out-of-distribution samples in real-world clinical scenarios, which may cause silent failure in deep learning-based medical image analysis tasks. Recently, research has explored various out-of-distribution (OOD) detection situations and techniques to enable a trustworthy medical AI system. In this survey, we systematically review the recent advances in OOD detection in medical image analysis. We first explore several factors that may cause a distributional shift when using a deep-learning-based model in clinic scenarios, with three different types of distributional shift well defined on top of these factors. Then a framework is suggested to categorize and feature existing solutions, while the previous studies are reviewed based on the methodology taxonomy. Our discussion also includes evaluation protocols and metrics, as well as the challenge and a research direction lack of exploration.",
      "authors": [
        "Zesheng Hong",
        "Yubiao Yue",
        "Yubin Chen",
        "Huanjie Lin",
        "Yuanmei Luo",
        "Mini Han Wang",
        "Weidong Wang",
        "Jialong Xu",
        "Xiaoqi Yang",
        "Zhenzhang Li",
        "Sihong Xie"
      ],
      "year": 2024,
      "citation_count": 12,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/70da774b2b30397ee2f7e2abc819ed126641a70d",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "be422ce2f64425f5c7bedf9a8498ab1e993060cc",
      "title": "Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is crucial for deploying reliable machine learning models in open-world applications. Recent advances in CLIP-based OOD detection have shown promising results via regularizing prompt tuning with OOD features extracted from ID data. However, the irrelevant context mined from ID data can be spurious due to the inaccurate foreground-background decomposition, thus limiting the OOD detection performance. In this work, we propose a novel framework, namely, Self-Calibrated Tuning (SCT), to mitigate this problem for effective OOD detection with only the given few-shot ID data. Specifically, SCT introduces modulating factors respectively on the two components of the original learning objective. It adaptively directs the optimization process between the two tasks during training on data with different prediction uncertainty to calibrate the influence of OOD regularization, which is compatible with many prompt tuning based OOD detection methods. Extensive experiments and analyses have been conducted to characterize and demonstrate the effectiveness of the proposed SCT. The code is publicly available.",
      "authors": [
        "Geng Yu",
        "Jianing Zhu",
        "Jiangchao Yao",
        "Bo Han"
      ],
      "year": 2024,
      "citation_count": 11,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/be422ce2f64425f5c7bedf9a8498ab1e993060cc",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1f24e041e10239cba8ff26ffcff4902343e55cab",
      "title": "Kernel PCA for Out-of-Distribution Detection",
      "abstract": "Out-of-Distribution (OoD) detection is vital for the reliability of Deep Neural Networks (DNNs). Existing works have shown the insufficiency of Principal Component Analysis (PCA) straightforwardly applied on the features of DNNs in detecting OoD data from In-Distribution (InD) data. The failure of PCA suggests that the network features residing in OoD and InD are not well separated by simply proceeding in a linear subspace, which instead can be resolved through proper non-linear mappings. In this work, we leverage the framework of Kernel PCA (KPCA) for OoD detection, and seek suitable non-linear kernels that advocate the separability between InD and OoD data in the subspace spanned by the principal components. Besides, explicit feature mappings induced from the devoted task-specific kernels are adopted so that the KPCA reconstruction error for new test samples can be efficiently obtained with large-scale data. Extensive theoretical and empirical results on multiple OoD data sets and network structures verify the superiority of our KPCA detector in efficiency and efficacy with state-of-the-art detection performance.",
      "authors": [
        "Kun Fang",
        "Qinghua Tao",
        "Kexin Lv",
        "M. He",
        "Xiaolin Huang",
        "Jie Yang"
      ],
      "year": 2024,
      "citation_count": 11,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1f24e041e10239cba8ff26ffcff4902343e55cab",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "06436653774a7cb8d53005d3f25af2a7229c1f8b",
      "title": "PixOOD: Pixel-Level Out-of-Distribution Detection",
      "abstract": "We propose a dense image prediction out-of-distribution detection algorithm, called PixOOD, which does not require training on samples of anomalous data and is not designed for a specific application which avoids traditional training biases. In order to model the complex intra-class variability of the in-distribution data at the pixel level, we propose an online data condensation algorithm which is more robust than standard K-means and is easily trainable through SGD. We evaluate PixOOD on a wide range of problems. It achieved state-of-the-art results on four out of seven datasets, while being competitive on the rest. The source code is available at https://github.com/vojirt/PixOOD.",
      "authors": [
        "Tom'avs Voj'ivr",
        "Jan Sochman",
        "Jivr'i Matas"
      ],
      "year": 2024,
      "citation_count": 11,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/06436653774a7cb8d53005d3f25af2a7229c1f8b",
      "pdf_link": "",
      "venue": "European Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "28582980cc55e3ed002fae2cf0e9b9b92714694b",
      "title": "DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is essential for ensuring the robustness of machine learning models by identifying samples that deviate from the training distribution. While traditional OOD detection has primarily focused on single-modality inputs, such as images, recent advances in multimodal models have demonstrated the potential of leveraging multiple modalities (e.g., video, optical flow, audio) to enhance detection performance. However, existing methods often overlook intra-class variability within in-distribution (ID) data, assuming that samples of the same class are perfectly cohesive and consistent. This assumption can lead to performance degradation, especially when prediction discrepancies are uniformly amplified across all samples. To address this issue, we propose Dynamic Prototype Updating (DPU), a novel plug-and-play framework for multimodal OOD detection that accounts for intra-class variations. Our method dynamically updates class center representations for each class by measuring the variance of similar samples within each batch, enabling adaptive adjustments. This approach allows us to amplify prediction discrepancies based on the updated class centers, thereby improving the model's robustness and generalization across different modalities. Extensive experiments on two tasks, five datasets, and nine base OOD algorithms demonstrate that DPU significantly improves OOD detection performance, setting a new state-of-the-art in multimodal OOD detection, with improvements of up to 80 percent in Far-OOD detection. To facilitate accessibility and reproducibility, our code is publicly available on GitHub.",
      "authors": [
        "Li Li",
        "Huixian Gong",
        "Hao Dong",
        "Tiankai Yang",
        "Zhengzhong Tu",
        "Yue Zhao"
      ],
      "year": 2024,
      "citation_count": 11,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/28582980cc55e3ed002fae2cf0e9b9b92714694b",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "6618d8b3643745d60772d4ec522ad76204522f7d",
      "title": "MOODv2: Masked Image Modeling for Out-of-Distribution Detection",
      "abstract": "The crux of effective out-of-distribution (OOD) detection lies in acquiring a robust in-distribution (ID) representation, distinct from OOD samples. While previous methods predominantly leaned on recognition-based techniques for this purpose, they often resulted in shortcut learning, lacking comprehensive representations. In our study, we conducted a comprehensive analysis, exploring distinct pretraining tasks and employing various OOD score functions. The results highlight that the feature representations pre-trained through reconstruction yield a notable enhancement and narrow the performance gap among various score functions. This suggests that even simple score functions can rival complex ones when leveraging reconstruction-based pretext tasks. Reconstruction-based pretext tasks adapt well to various score functions. As such, it holds promising potential for further expansion. Our OOD detection framework, MOODv2, employs the masked image modeling pretext task. Without bells and whistles, MOODv2 impressively enhances 14.30% AUROC to 95.68% on ImageNet and achieves 99.98% on CIFAR-10.",
      "authors": [
        "Jingyao Li",
        "Pengguang Chen",
        "Shaozuo Yu",
        "Shu Liu",
        "Jiaya Jia"
      ],
      "year": 2024,
      "citation_count": 10,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/6618d8b3643745d60772d4ec522ad76204522f7d",
      "pdf_link": "",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0",
      "title": "Energy-based Hopfield Boosting for Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is critical when deploying machine learning models in the real world. Outlier exposure methods, which incorporate auxiliary outlier data in the training process, can drastically improve OOD detection performance compared to approaches without advanced training strategies. We introduce Hopfield Boosting, a boosting approach, which leverages modern Hopfield energy (MHE) to sharpen the decision boundary between the in-distribution and OOD data. Hopfield Boosting encourages the model to concentrate on hard-to-distinguish auxiliary outlier examples that lie close to the decision boundary between in-distribution and auxiliary outlier data. Our method achieves a new state-of-the-art in OOD detection with outlier exposure, improving the FPR95 metric from 2.28 to 0.92 on CIFAR-10 and from 11.76 to 7.94 on CIFAR-100.",
      "authors": [
        "Claus Hofmann",
        "Simon Schmid",
        "Bernhard Lehner",
        "Daniel Klotz",
        "Sepp Hochreiter"
      ],
      "year": 2024,
      "citation_count": 10,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "bcbee683ff34f87675448471d780541f7ae25ce9",
      "title": "DeCoOp: Robust Prompt Tuning with Out-of-Distribution Detection",
      "abstract": "Vision-language models (VLMs), such as CLIP, have demonstrated impressive zero-shot capabilities for various downstream tasks. Their performance can be further enhanced through few-shot prompt tuning methods. However, current studies evaluate the performance of learned prompts separately on base and new classes. This evaluation lacks practicality for real-world applications since downstream tasks cannot determine whether the data belongs to base or new classes in advance. In this paper, we explore a problem setting called Open-world Prompt Tuning (OPT), which involves tuning prompts on base classes and evaluating on a combination of base and new classes. By introducing Decomposed Prompt Tuning framework (DePT), we theoretically demonstrate that OPT can be solved by incorporating out-of-distribution detection into prompt tuning, thereby enhancing the base-to-new discriminability. Based on DePT, we present a novel prompt tuning approach, namely, Decomposed Context Optimization (DeCoOp), which introduces new-class detectors and sub-classifiers to further enhance the base-class and new-class discriminability. Experimental results on 11 benchmark datasets validate the effectiveness of DePT and demonstrate that DeCoOp outperforms current state-of-the-art methods, providing a significant 2% average accuracy improvement.",
      "authors": [
        "Zhi Zhou",
        "Ming Yang",
        "Jiang-Xin Shi",
        "Lan-Zhe Guo",
        "Yu-Feng Li"
      ],
      "year": 2024,
      "citation_count": 9,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/bcbee683ff34f87675448471d780541f7ae25ce9",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "b3f21af3032246b6fa87e05a6d9455433b25ce55",
      "title": "Taming False Positives in Out-of-Distribution Detection with Human Feedback",
      "abstract": "Robustness to out-of-distribution (OOD) samples is crucial for safely deploying machine learning models in the open world. Recent works have focused on designing scoring functions to quantify OOD uncertainty. Setting appropriate thresholds for these scoring functions for OOD detection is challenging as OOD samples are often unavailable up front. Typically, thresholds are set to achieve a desired true positive rate (TPR), e.g., $95\\%$ TPR. However, this can lead to very high false positive rates (FPR), ranging from 60 to 96\\%, as observed in the Open-OOD benchmark. In safety-critical real-life applications, e.g., medical diagnosis, controlling the FPR is essential when dealing with various OOD samples dynamically. To address these challenges, we propose a mathematically grounded OOD detection framework that leverages expert feedback to \\emph{safely} update the threshold on the fly. We provide theoretical results showing that it is guaranteed to meet the FPR constraint at all times while minimizing the use of human feedback. Another key feature of our framework is that it can work with any scoring function for OOD uncertainty quantification. Empirical evaluation of our system on synthetic and benchmark OOD datasets shows that our method can maintain FPR at most $5\\%$ while maximizing TPR.",
      "authors": [
        "Harit Vishwakarma",
        "Heguang Lin",
        "Ramya Korlakai Vinayak"
      ],
      "year": 2024,
      "citation_count": 9,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/b3f21af3032246b6fa87e05a6d9455433b25ce55",
      "pdf_link": "",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "48020e5f1a0d5703f6169c20051eeb056194c25b",
      "title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
      "abstract": "Detecting anomalies or out-of-distribution (OOD) samples is critical for maintaining the reliability and trustworthiness of machine learning systems. Recently, Large Language Models (LLMs) have demonstrated their effectiveness not only in natural language processing but also in broader applications due to their advanced comprehension and generative capabilities. The integration of LLMs into anomaly and OOD detection marks a significant shift from the traditional paradigm in the field. This survey focuses on the problem of anomaly and OOD detection under the context of LLMs. We propose a new taxonomy to categorize existing approaches into two classes based on the role played by LLMs. Following our proposed taxonomy, we further discuss the related work under each of the categories and finally discuss potential challenges and directions for future research in this field. We also provide an up-to-date reading list of relevant papers.",
      "authors": [
        "Ruiyao Xu",
        "Kaize Ding"
      ],
      "year": 2024,
      "citation_count": 9,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/48020e5f1a0d5703f6169c20051eeb056194c25b",
      "pdf_link": "",
      "venue": "North American Chapter of the Association for Computational Linguistics",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "87268ea5825cd65c1c3151d6ecc0973f267b3c68",
      "title": "When and How Does In-Distribution Label Help Out-of-Distribution Detection?",
      "abstract": "Detecting data points deviating from the training distribution is pivotal for ensuring reliable machine learning. Extensive research has been dedicated to the challenge, spanning classical anomaly detection techniques to contemporary out-of-distribution (OOD) detection approaches. While OOD detection commonly relies on supervised learning from a labeled in-distribution (ID) dataset, anomaly detection may treat the entire ID data as a single class and disregard ID labels. This fundamental distinction raises a significant question that has yet to be rigorously explored: when and how does ID label help OOD detection? This paper bridges this gap by offering a formal understanding to theoretically delineate the impact of ID labels on OOD detection. We employ a graph-theoretic approach, rigorously analyzing the separability of ID data from OOD data in a closed-form manner. Key to our approach is the characterization of data representations through spectral decomposition on the graph. Leveraging these representations, we establish a provable error bound that compares the OOD detection performance with and without ID labels, unveiling conditions for achieving enhanced OOD detection. Lastly, we present empirical results on both simulated and real datasets, validating theoretical guarantees and reinforcing our insights. Code is publicly available at https://github.com/deeplearning-wisc/id_label.",
      "authors": [
        "Xuefeng Du",
        "Yiyou Sun",
        "Yixuan Li"
      ],
      "year": 2024,
      "citation_count": 9,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/87268ea5825cd65c1c3151d6ecc0973f267b3c68",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "f418971afad1d44fb64610b91128a4eb6c3855ef",
      "title": "Exploiting Diffusion Prior for Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is crucial for deploying robust machine learning models, especially in areas where security is critical. However, traditional OOD detection methods often fail to capture complex data distributions from large scale date. In this paper, we present a novel approach for OOD detection that leverages the generative ability of diffusion models and the powerful feature extraction capabilities of CLIP. By using these features as conditional inputs to a diffusion model, we can reconstruct the images after encoding them with CLIP. The difference between the original and reconstructed images is used as a signal for OOD identification. The practicality and scalability of our method is increased by the fact that it does not require class-specific labeled ID data, as is the case with many other methods. Extensive experiments on several benchmark datasets demonstrate the robustness and effectiveness of our method, which have significantly improved the detection accuracy.",
      "authors": [
        "Armando Zhu",
        "Jiabei Liu",
        "Keqin Li",
        "Shuying Dai",
        "Bo Hong",
        "Peng Zhao",
        "Changsong Wei"
      ],
      "year": 2024,
      "citation_count": 9,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/f418971afad1d44fb64610b91128a4eb6c3855ef",
      "pdf_link": "",
      "venue": "Irish Interdisciplinary Journal of Science &amp; Research",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "36dd3bee303671d45c6ab4631c34b2dd67e19e69",
      "title": "Discriminability-Driven Channel Selection for Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is essential for deploying machine learning models in open-world environments. Activation-based methods are a key approach in OOD detection, working to mitigate overconfident predictions of OOD data. These techniques rectifying anomalous activations, enhancing the distinguishability between in-distribution (ID) data and OOD data. However, they assume by default that every channel is necessary for OOD detection, and rectify anomalous activations in each channel. Empirical evidence has shown that there is a significant difference among various channels in OOD detection, and discarding some channels can greatly enhance the performance of OOD detection. Based on this insight, we propose Discriminability-Driven Channel Selection (DDCS), which leverages an adaptive channel selection by estimating the discriminative score of each channel to boost OOD detection. The discriminative score takes inter-class similarity and inter-class variance of training data into account. However, the estimation of discriminative score itself is susceptible to anomalous activations. To better estimate score, we pre-rectify anomalous activations for each channel mildly. The experimental results show that DDCS achieves state-of-the-art performance on CIFAR and ImageNet-1K benchmarks. Moreover, DDCS can generalize to different backbones and OOD scores.",
      "authors": [
        "Yue Yuan",
        "Rundong He",
        "Yicong Dong",
        "Zhongyi Han",
        "Yilong Yin"
      ],
      "year": 2024,
      "citation_count": 9,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/36dd3bee303671d45c6ab4631c34b2dd67e19e69",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4ff175285ef575f4dc24a518869139382665c12e",
      "title": "On the Learnability of Out-of-distribution Detection",
      "abstract": "Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms, and corresponding learning theory is still an open problem. To study the generalization of OOD detection, this paper investigates the probably approximately correct (PAC) learning theory of OOD detection that fits the commonly used evaluation metrics in the literature. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we offer theoretical support for representative OOD detection works based on our OOD theory.",
      "authors": [
        "Zhen Fang",
        "Yixuan Li",
        "Feng Liu",
        "Bo Han",
        "Jie Lu"
      ],
      "year": 2024,
      "citation_count": 9,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4ff175285ef575f4dc24a518869139382665c12e",
      "pdf_link": "",
      "venue": "Journal of machine learning research",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "39af99b93c6b95f54f78952522e6d22496dd5bf1",
      "title": "Out-of-Distribution Detection with a Single Unconditional Diffusion Model",
      "abstract": "Out-of-distribution (OOD) detection is a critical task in machine learning that seeks to identify abnormal samples. Traditionally, unsupervised methods utilize a deep generative model for OOD detection. However, such approaches require a new model to be trained for each inlier dataset. This paper explores whether a single model can perform OOD detection across diverse tasks. To that end, we introduce Diffusion Paths (DiffPath), which uses a single diffusion model originally trained to perform unconditional generation for OOD detection. We introduce a novel technique of measuring the rate-of-change and curvature of the diffusion paths connecting samples to the standard normal. Extensive experiments show that with a single model, DiffPath is competitive with prior work using individual models on a variety of OOD tasks involving different distributions. Our code is publicly available at https://github.com/clear-nus/diffpath.",
      "authors": [
        "Alvin Heng",
        "A. Thiéry",
        "Harold Soh"
      ],
      "year": 2024,
      "citation_count": 8,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/39af99b93c6b95f54f78952522e6d22496dd5bf1",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "47cfe2c7ba31259ed8b005a348a48db4676279fa",
      "title": "Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection",
      "abstract": "Feature shaping refers to a family of methods that exhibit state-of-the-art performance for out-of-distribution (OOD) detection. These approaches manipulate the feature representation, typically from the penultimate layer of a pre-trained deep learning model, so as to better differentiate between in-distribution (ID) and OOD samples. However, existing feature-shaping methods usually employ rules manually designed for specific model architectures and OOD datasets, which consequently limit their generalization ability. To address this gap, we first formulate an abstract optimization framework for studying feature-shaping methods. We then propose a concrete reduction of the framework with a simple piecewise constant shaping function and show that existing feature-shaping methods approximate the optimal solution to the concrete optimization problem. Further, assuming that OOD data is inaccessible, we propose a formulation that yields a closed-form solution for the piecewise constant shaping function, utilizing solely the ID data. Through extensive experiments, we show that the feature-shaping function optimized by our method improves the generalization ability of OOD detection across a large variety of datasets and model architectures.",
      "authors": [
        "Qinyu Zhao",
        "Ming Xu",
        "Kartik Gupta",
        "Akshay Asthana",
        "Liang Zheng",
        "Stephen Gould"
      ],
      "year": 2024,
      "citation_count": 8,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/47cfe2c7ba31259ed8b005a348a48db4676279fa",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "209c949e277081b8f2847cf3e66b90df26dcf179",
      "title": "Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings",
      "abstract": "Despite significant advancements in out-of-distribution (OOD) detection, existing methods still struggle to maintain robustness against adversarial attacks, compromising their reliability in critical real-world applications. Previous studies have attempted to address this challenge by exposing detectors to auxiliary OOD datasets alongside adversarial training. However, the increased data complexity inherent in adversarial training, and the myriad of ways that OOD samples can arise during testing, often prevent these approaches from establishing robust decision boundaries. To address these limitations, we propose AROS, a novel approach leveraging neural ordinary differential equations (NODEs) with Lyapunov stability theorem in order to obtain robust embeddings for OOD detection. By incorporating a tailored loss function, we apply Lyapunov stability theory to ensure that both in-distribution (ID) and OOD data converge to stable equilibrium points within the dynamical system. This approach encourages any perturbed input to return to its stable equilibrium, thereby enhancing the model's robustness against adversarial perturbations. To not use additional data, we generate fake OOD embeddings by sampling from low-likelihood regions of the ID data feature space, approximating the boundaries where OOD data are likely to reside. To then further enhance robustness, we propose the use of an orthogonal binary layer following the stable feature space, which maximizes the separation between the equilibrium points of ID and OOD samples. We validate our method through extensive experiments across several benchmarks, demonstrating superior performance, particularly under adversarial attacks. Notably, our approach improves robust detection performance from 37.8% to 80.1% on CIFAR-10 vs. CIFAR-100 and from 29.0% to 67.0% on CIFAR-100 vs. CIFAR-10.",
      "authors": [
        "Hossein Mirzaei",
        "Mackenzie W. Mathis"
      ],
      "year": 2024,
      "citation_count": 8,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/209c949e277081b8f2847cf3e66b90df26dcf179",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "title": "Gradient-Regularized Out-of-Distribution Detection",
      "abstract": "One of the challenges for neural networks in real-life applications is the overconfident errors these models make when the data is not from the original training distribution. Addressing this issue is known as Out-of-Distribution (OOD) detection. Many state-of-the-art OOD methods employ an auxiliary dataset as a surrogate for OOD data during training to achieve improved performance. However, these methods fail to fully exploit the local information embedded in the auxiliary dataset. In this work, we propose the idea of leveraging the information embedded in the gradient of the loss function during training to enable the network to not only learn a desired OOD score for each sample but also to exhibit similar behavior in a local neighborhood around each sample. We also develop a novel energy-based sampling method to allow the network to be exposed to more informative OOD samples during the training phase. This is especially important when the auxiliary dataset is large. We demonstrate the effectiveness of our method through extensive experiments on several OOD benchmarks, improving the existing state-of-the-art FPR95 by 4% on our ImageNet experiment. We further provide a theoretical analysis through the lens of certified robustness and Lipschitz analysis to showcase the theoretical foundation of our work. Our code is available at https://github.com/o4lc/Greg-OOD.",
      "authors": [
        "Sina Sharifi",
        "Taha Entesari",
        "Bardia Safaei",
        "Vishal M. Patel",
        "Mahyar Fazlyab"
      ],
      "year": 2024,
      "citation_count": 8,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "pdf_link": "",
      "venue": "European Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1f2462ad6ffef934b7470313ffc3d42a0af35c9c",
      "title": "Out-of-Distribution Detection with Logical Reasoning",
      "abstract": "Machine Learning models often only generalize reliably to samples from the training distribution. Consequentially, detecting when input data is out-of-distribution (OOD) is crucial, especially in safety-critical applications. Current OOD detection methods, however, tend to be domain agnostic and often fail to incorporate valuable prior knowledge about the structure of the training distribution. To address this limitation, we introduce a novel, hybrid OOD detection algorithm that combines a deep learning-based perception system with a first-order logic-based knowledge representation. A logical reasoning system uses this knowledge base at run-time to infer whether inputs are consistent with prior knowledge about the training distribution. In contrast to purely neural systems, the structured knowledge representation allows humans to inspect and modify the rules that govern the OOD detectors’ behavior. This not only enhances performance but also fosters a level of explainability that is particularly beneficial in safety-critical contexts. We demonstrate the effectiveness of our method through experiments on several datasets and discuss advantages and limitations. Our code is available online.1",
      "authors": [
        "Konstantin Kirchheim",
        "Tim Gonschorek",
        "F. Ortmeier"
      ],
      "year": 2024,
      "citation_count": 8,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1f2462ad6ffef934b7470313ffc3d42a0af35c9c",
      "pdf_link": "",
      "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "728afc51ac20d79133d8c747a2d18b01c6a6de5e",
      "title": "SeTAR: Out-of-Distribution Detection with Selective Low-Rank Approximation",
      "abstract": "Out-of-distribution (OOD) detection is crucial for the safe deployment of neural networks. Existing CLIP-based approaches perform OOD detection by devising novel scoring functions or sophisticated fine-tuning methods. In this work, we propose SeTAR, a novel, training-free OOD detection method that leverages selective low-rank approximation of weight matrices in vision-language and vision-only models. SeTAR enhances OOD detection via post-hoc modification of the model's weight matrices using a simple greedy search algorithm. Based on SeTAR, we further propose SeTAR+FT, a fine-tuning extension optimizing model performance for OOD detection tasks. Extensive evaluations on ImageNet1K and Pascal-VOC benchmarks show SeTAR's superior performance, reducing the relatively false positive rate by up to 18.95% and 36.80% compared to zero-shot and fine-tuning baselines. Ablation studies further validate SeTAR's effectiveness, robustness, and generalizability across different model backbones. Our work offers a scalable, efficient solution for OOD detection, setting a new state-of-the-art in this area.",
      "authors": [
        "Yixia Li",
        "Boya Xiong",
        "Guanhua Chen",
        "Yun Chen"
      ],
      "year": 2024,
      "citation_count": 7,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/728afc51ac20d79133d8c747a2d18b01c6a6de5e",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "88b9e2bce0caadf7495490603f5292166e2a1860",
      "title": "Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection",
      "abstract": "Out-of-Distribution (OOD) detection, aiming to distinguish outliers from known categories, has gained prominence in practical scenarios. Recently, the advent of vision-language models (VLM) has heightened interest in enhancing OOD detection for VLM through few-shot tuning. However, existing methods mainly focus on optimizing global prompts, ignoring refined utilization of local information with regard to outliers. Motivated by this, we freeze global prompts and introduce Local-Prompt, a novel coarse-to-fine tuning paradigm to emphasize regional enhancement with local prompts. Our method comprises two integral components: global prompt guided negative augmentation and local prompt enhanced regional regularization. The former utilizes frozen, coarse global prompts as guiding cues to incorporate negative augmentation, thereby leveraging local outlier knowledge. The latter employs trainable local prompts and a regional regularization to capture local information effectively, aiding in outlier identification. We also propose regional-related metric to empower the enrichment of OOD detection. Moreover, since our approach explores enhancing local prompts only, it can be seamlessly integrated with trained global prompts during inference to boost the performance. Comprehensive experiments demonstrate the effectiveness and potential of our method. Notably, our method reduces average FPR95 by 5.17% against state-of-the-art method in 4-shot tuning on challenging ImageNet-1k dataset, even outperforming 16-shot results of previous methods. Code is released at https://github.com/AuroraZengfh/Local-Prompt.",
      "authors": [
        "Fanhu Zeng",
        "Zhen Cheng",
        "Fei Zhu",
        "Xu-Yao Zhang"
      ],
      "year": 2024,
      "citation_count": 7,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/88b9e2bce0caadf7495490603f5292166e2a1860",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "5df7dcb96a465ed4d4d2fa2414413a41494fee8c",
      "title": "ATS: Adaptive Temperature Scaling for Enhancing Out-of-Distribution Detection Methods",
      "abstract": "Out-of-distribution (OOD) detection is essential to ensure the reliability and robustness of machine learning models in real-world applications. Post-hoc OOD detection methods have gained significant attention due to the fact that they offer the advantage of not requiring additional re-training, which could degrade model performance and increase training time. However, most existing post-hoc methods rely only on the encoder output (features), logits, or the softmax probability, meaning they have no access to information that might be lost in the feature extraction process. In this work, we address this limitation by introducing Adaptive Temperature Scaling (ATS), a novel approach that dynamically calculates a temperature value based on activations of the intermediate layers. Fusing this sample-specific adjustment with class-dependent logits, our ATS captures additional statistical information before they are lost in the feature extraction process, leading to a more robust and powerful OOD detection method. We conduct extensive experiments to demonstrate the efficacy of our approach. Notably, our method can be seamlessly combined with SOTA post-hoc OOD detection methods that rely on the logits, thereby enhancing their performance and improving their robustness.",
      "authors": [
        "Gerhard Krumpl",
        "H. Avenhaus",
        "Horst Possegger",
        "Horst Bischof"
      ],
      "year": 2024,
      "citation_count": 7,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/5df7dcb96a465ed4d4d2fa2414413a41494fee8c",
      "pdf_link": "",
      "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "db5059dea1ee639dfc7eba751183ce3564a4b593",
      "title": "COOD: Combined out-of-distribution detection using multiple measures for anomaly & novel class detection in large-scale hierarchical classification",
      "abstract": "High-performing out-of-distribution (OOD) detection, both anomaly and novel class, is an important prerequisite for the practical use of classification models. In this paper we focus on the species recognition task in images, concerned with large databases, a large number of fine-grained hierarchical classes, severe class imbalance, and varying image quality. We propose a framework for combining individual OOD measures into one combined OOD (COOD) measure using a supervised model. The individual measures are several existing state-of-the-art measures and several novel OOD measures developed with novel class detection and hierarchical class structure in mind. COOD was extensively evaluated on three large-scale (500k+ images) biodiversity datasets in the context of anomaly and novel class detection. We show that COOD outperforms individual, including state-of-the-art, OOD measures by a large margin in terms of TPR@1%FPR in the majority of experiments, e.g., improving detecting ImageNet images (OOD) from 54.3% to 83.3% for the iNaturalist 2018 dataset. SHAP (feature contribution) analysis shows that different individual OOD measures are essential for various tasks, indicating that multiple OOD measures and combinations are needed to generalize. Additionally, we show that explicitly considering ID images that are incorrectly classified for the original (species) recognition task is important for constructing high-performing OOD detection methods and for practical applicability. The framework can easily be extended or adapted to other tasks and media modalities.",
      "authors": [
        "L. Hogeweg",
        "Rajesh Gangireddy",
        "Django Brunink",
        "V. Kalkman",
        "Ludo Cornelissen",
        "Jacob W. Kamminga"
      ],
      "year": 2024,
      "citation_count": 6,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/db5059dea1ee639dfc7eba751183ce3564a4b593",
      "pdf_link": "",
      "venue": "2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "201817ff23481abd4ef48ce9e2ce71314f720ea7",
      "title": "Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks",
      "abstract": "Detecting test-time distribution shift has emerged as a key capability for safely deployed machine learning models, with the question being tackled under various guises in recent years. In this paper, we aim to provide a consolidated view of the two largest sub-fields within the community: out-of-distribution (OOD) detection and open-set recognition (OSR). In particular, we aim to provide rigorous empirical analysis of different methods across settings and provide actionable takeaways for practitioners and researchers. Concretely, we make the following contributions: (i) We perform rigorous cross-evaluation between state-of-the-art methods in the OOD detection and OSR settings and identify a strong correlation between the performances of methods for them; (ii) We propose a new, large-scale benchmark setting which we suggest better disentangles the problem tackled by OOD detection and OSR, re-evaluating state-of-the-art OOD detection and OSR methods in this setting; (iii) We surprisingly find that the best performing method on standard benchmarks (Outlier Exposure) struggles when tested at scale, while scoring rules which are sensitive to the deep feature magnitude consistently show promise; and (iv) We conduct empirical analysis to explain these phenomena and highlight directions for future research. Code: https://github.com/Visual-AI/Dissect-OOD-OSR",
      "authors": [
        "Hongjun Wang",
        "S. Vaze",
        "Kai Han"
      ],
      "year": 2024,
      "citation_count": 6,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/201817ff23481abd4ef48ce9e2ce71314f720ea7",
      "pdf_link": "",
      "venue": "International Journal of Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "title": "Out-of-Distribution Detection: A Task-Oriented Survey of Recent Advances",
      "abstract": "Out-of-distribution (OOD) detection aims to detect test samples outside the training category space, which is an essential component in building reliable machine learning systems. Existing reviews on OOD detection primarily focus on method taxonomy, surveying the field by categorizing various approaches. However, many recent works concentrate on non-traditional OOD detection scenarios, such as test-time adaptation, multi-modal data sources and other novel contexts. In this survey, we uniquely review recent advances in OOD detection from the task-oriented perspective for the first time. According to the user's access to the model, that is, whether the OOD detection method is allowed to modify or retrain the model, we classify the methods as training-driven or training-agnostic. Besides, considering the rapid development of pre-trained models, large pre-trained model-based OOD detection is also regarded as an important category and discussed separately. Furthermore, we provide a discussion of the evaluation scenarios, a variety of applications, and several future research directions. We believe this survey with new taxonomy will benefit the proposal of new methods and the expansion of more practical scenarios. A curated list of related papers is provided in the Github repository: https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection.",
      "authors": [
        "Shuo Lu",
        "Yingsheng Wang",
        "Lijun Sheng",
        "Lingxiao He",
        "Aihua Zheng",
        "Jian Liang"
      ],
      "year": 2024,
      "citation_count": 6,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "pdf_link": "",
      "venue": "",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "63cc6260b838f2cc559715a9f68360edc743f50b",
      "title": "Endoood: Uncertainty-Aware Out-of-Distribution Detection in Capsule Endoscopy Diagnosis",
      "abstract": "Wireless capsule endoscopy (WCE) is a non-invasive diagnostic procedure that enables visualization of the gastrointestinal (GI) tract. Deep learning-based methods have shown effectiveness in disease screening using WCE data, alleviating the burden on healthcare professionals. However, existing capsule endoscopy classification methods mostly rely on predefined categories, making it challenging to identify and classify out-of-distribution (OOD) data, such as undefined categories or anatomical landmarks. To address this issue, we propose the Endoscopy Out-Of-Distribution (EndoOOD) framework, which aims to effectively handle the OOD detection challenge in WCE diagnosis. The proposed framework focuses on improving the robustness and reliability of WCE diagnostic capabilities by incorporating uncertainty-aware mixup training and long-tailed in-distribution (ID) data calibration techniques. Additionally, virtual-logit matching is employed to accurately distinguish between OOD and ID data while minimizing information loss. To assess the performance of our proposed solution, we conduct evaluations and comparisons with 12 state-of-the-art (SOTA) methods using two publicly available datasets. The results demonstrate the effectiveness of the proposed framework in enhancing diagnostic accuracy and supporting clinical decision-making.",
      "authors": [
        "Qiaozhi Tan",
        "Long Bai",
        "Guan-Feng Wang",
        "Mobarak Islam Hoque",
        "Hongliang Ren"
      ],
      "year": 2024,
      "citation_count": 6,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/63cc6260b838f2cc559715a9f68360edc743f50b",
      "pdf_link": "",
      "venue": "IEEE International Symposium on Biomedical Imaging",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "5f8ccbe2a87df5e1340d4bda8f6e3458ef1bf6ae",
      "title": "Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?)",
      "abstract": "Research on Out-Of-Distribution (OOD) detection focuses mainly on building scores that efficiently distinguish OOD data from In Distribution (ID) data. On the other hand, Conformal Prediction (CP) uses non-conformity scores to construct prediction sets with probabilistic coverage guarantees. In this work, we propose to use CP to better assess the efficiency of OOD scores. Specifically, we emphasize that in standard OOD benchmark settings, evaluation metrics can be overly optimistic due to the finite sample size of the test dataset. Based on the work of (Bates et al., 2022), we define new conformal AUROC and conformal FRP@TPR95 metrics, which are corrections that provide probabilistic conservativeness guarantees on the variability of these metrics. We show the effect of these corrections on two reference OOD and anomaly detection benchmarks, OpenOOD (Yang et al., 2022) and ADBench (Han et al., 2022). We also show that the benefits of using OOD together with CP apply the other way around by using OOD scores as non-conformity scores, which results in improving upon current CP methods. One of the key messages of these contributions is that since OOD is concerned with designing scores and CP with interpreting these scores, the two fields may be inherently intertwined.",
      "authors": [
        "Paul Novello",
        "Joseba Dalmau",
        "L'eo Andeol"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/5f8ccbe2a87df5e1340d4bda8f6e3458ef1bf6ae",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "835d157e2c23d3577f23778ce051ab8d706babf6",
      "title": "TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is crucial in many real-world applications. However, intelligent models are often trained solely on in-distribution (ID) data, leading to overconfidence when misclassifying OOD data as ID classes. In this study, we propose a new learning framework which leverage simple Jigsaw-based fake OOD data and rich semantic embeddings (`anchors') from the ChatGPT description of ID knowledge to help guide the training of the image encoder. The learning framework can be flexibly combined with existing post-hoc approaches to OOD detection, and extensive empirical evaluations on multiple OOD detection benchmarks demonstrate that rich textual representation of ID knowledge and fake OOD knowledge can well help train a visual encoder for OOD detection. With the learning framework, new state-of-the-art performance was achieved on all the benchmarks. The code is available at https://github.com/Cverchen/TagFog.",
      "authors": [
        "Jiankang Chen",
        "Tong Zhang",
        "Weishi Zheng",
        "Ruixuan Wang"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/835d157e2c23d3577f23778ce051ab8d706babf6",
      "pdf_link": "",
      "venue": "AAAI Conference on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129",
      "title": "Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation",
      "abstract": "One key challenge in Out-of-Distribution (OOD) detection is the absence of ground-truth OOD samples during training. One principled approach to address this issue is to use samples from external datasets as outliers (i.e., pseudo OOD samples) to train OOD detectors. However, we find empirically that the outlier samples often present a distribution shift compared to the true OOD samples, especially in Long-Tailed Recognition (LTR) scenarios, where ID classes are heavily imbalanced, \\ie, the true OOD samples exhibit very different probability distribution to the head and tailed ID classes from the outliers. In this work, we propose a novel approach, namely normalized outlier distribution adaptation (AdaptOD), to tackle this distribution shift problem. One of its key components is dynamic outlier distribution adaptation that effectively adapts a vanilla outlier distribution based on the outlier samples to the true OOD distribution by utilizing the OOD knowledge in the predicted OOD samples during inference. Further, to obtain a more reliable set of predicted OOD samples on long-tailed ID data, a novel dual-normalized energy loss is introduced in AdaptOD, which leverages class- and sample-wise normalized energy to enforce a more balanced prediction energy on imbalanced ID samples. This helps avoid bias toward the head samples and learn a substantially better vanilla outlier distribution than existing energy losses during training. It also eliminates the need of manually tuning the sensitive margin hyperparameters in energy losses. Empirical results on three popular benchmarks for OOD detection in LTR show the superior performance of AdaptOD over state-of-the-art methods. Code is available at https://github.com/mala-lab/AdaptOD.",
      "authors": [
        "Wenjun Miao",
        "Guansong Pang",
        "Jingyi Zheng",
        "Xiaolong Bai"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "59f40cf3eebd2cb6ad30363fa6abf1caea06555f",
      "title": "Are We Ready for Out-of-Distribution Detection in Digital Pathology?",
      "abstract": "The detection of semantic and covariate out-of-distribution (OOD) examples is a critical yet overlooked challenge in digital pathology (DP). Recently, substantial insight and methods on OOD detection were presented by the ML community, but how do they fare in DP applications? To this end, we establish a benchmark study, our highlights being: 1) the adoption of proper evaluation protocols, 2) the comparison of diverse detectors in both a single and multi-model setting, and 3) the exploration into advanced ML settings like transfer learning (ImageNet vs. DP pre-training) and choice of architecture (CNNs vs. transformers). Through our comprehensive experiments, we contribute new insights and guidelines, paving the way for future research and discussion.",
      "authors": [
        "Ji-Hun Oh",
        "Kianoush Falahkheirkhah",
        "Rohit Bhargava"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/59f40cf3eebd2cb6ad30363fa6abf1caea06555f",
      "pdf_link": "",
      "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "d03cf8819aeff52708a70d506b87e50214af53b6",
      "title": "Out-of-Distribution Detection with Prototypical Outlier Proxy",
      "abstract": "Out-of-distribution (OOD) detection is a crucial task for deploying deep learning models in the wild. One of the major challenges is that well-trained deep models tend to perform over-confidence on unseen test data. Recent research attempts to leverage real or synthetic outliers to mitigate the issue, which may significantly increase computational costs and be biased toward specific outlier characteristics. In this paper, we propose a simple yet effective framework, Prototypical Outlier Proxy (POP), which introduces virtual OOD prototypes to reshape the decision boundaries between ID and OOD data. Specifically, we transform the learnable classifier into a fixed one and augment it with a set of prototypical weight vectors. Then, we introduce a hierarchical similarity boundary loss to impose adaptive penalties depending on the degree of misclassification. Extensive experiments across various benchmarks demonstrate the effectiveness of POP. Notably, POP achieves average FPR95 reductions of 7.70%, 6.30%, and 5.42% over the second-best methods on CIFAR-10, CIFAR-100, and ImageNet-200, respectively. Moreover, compared to the recent method NPOS, which relies on outlier synthesis, POP trains 7.2 times faster and performs inference 19.5 times faster.",
      "authors": [
        "Mingrong Gong",
        "Chaoqi Chen",
        "Qingqiang Sun",
        "Yue Wang",
        "Hui Huang"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/d03cf8819aeff52708a70d506b87e50214af53b6",
      "pdf_link": "",
      "venue": "AAAI Conference on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "33fb671a3289027c84a71fc996f948195b1baeb4",
      "title": "OpenCIL: Benchmarking Out-of-Distribution Detection in Class-Incremental Learning",
      "abstract": "Class incremental learning (CIL) aims to learn a model that can not only incrementally accommodate new classes, but also maintain the learned knowledge of old classes. Out-of-distribution (OOD) detection in CIL is to retain this incremental learning ability, while being able to reject unknown samples that are drawn from different distributions of the learned classes. This capability is crucial to the safety of deploying CIL models in open worlds. However, despite remarkable advancements in the respective CIL and OOD detection, there lacks a systematic and large-scale benchmark to assess the capability of advanced CIL models in detecting OOD samples. To fill this gap, in this study we design a comprehensive empirical study to establish such a benchmark, named $\\textbf{OpenCIL}$. To this end, we propose two principled frameworks for enabling four representative CIL models with 15 diverse OOD detection methods, resulting in 60 baseline models for OOD detection in CIL. The empirical evaluation is performed on two popular CIL datasets with six commonly-used OOD datasets. One key observation we find through our comprehensive evaluation is that the CIL models can be severely biased towards the OOD samples and newly added classes when they are exposed to open environments. Motivated by this, we further propose a new baseline for OOD detection in CIL, namely Bi-directional Energy Regularization ($\\textbf{BER}$), which is specially designed to mitigate these two biases in different CIL models by having energy regularization on both old and new classes. Its superior performance is justified in our experiments. All codes and datasets are open-source at https://github.com/mala-lab/OpenCIL.",
      "authors": [
        "Wenjun Miao",
        "Guansong Pang",
        "Trong-Tung Nguyen",
        "Ruohang Fang",
        "Jingyi Zheng",
        "Xiaolong Bai"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/33fb671a3289027c84a71fc996f948195b1baeb4",
      "pdf_link": "",
      "venue": "Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "12f04ecb1c9a76bed28656e1cb178c1b97eb7506",
      "title": "Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression",
      "abstract": "As language models become more general purpose, increased attention needs to be paid to detecting out-of-distribution (OOD) instances, i.e., those not belonging to any of the distributions seen during training. Existing methods for detecting OOD data are computationally complex and storage-intensive. We propose a novel soft clustering approach for OOD detection based on non-negative kernel regression. Our approach greatly reduces computational and space complexities (up to 11x improvement in inference time and 87% reduction in storage requirements) and outperforms existing approaches by up to 4 AUROC points on four different benchmarks. We also introduce an entropy-constrained version of our algorithm, which leads to further reductions in storage requirements (up to 97% lower than comparable approaches) while retaining competitive performance. Our soft clustering approach for OOD detection highlights its potential for detecting tail-end phenomena in extreme-scale data settings.",
      "authors": [
        "Aryan Gulati",
        "Xingjian Dong",
        "Carlos Hurtado",
        "Sarath Shekkizhar",
        "Swabha Swayamdipta",
        "Antonio Ortega"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/12f04ecb1c9a76bed28656e1cb178c1b97eb7506",
      "pdf_link": "",
      "venue": "Conference on Empirical Methods in Natural Language Processing",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "8cb280caa94c758e659adfb413b25a3d2e37a837",
      "title": "Multi-Label Out-of-Distribution Detection with Spectral Normalized Joint Energy",
      "abstract": "In today's interconnected world, achieving reliable out-of-distribution (OOD) detection poses a significant challenge for machine learning models. While numerous studies have introduced improved approaches for multi-class OOD detection tasks, the investigation into multi-label OOD detection tasks has been notably limited. We introduce Spectral Normalized Joint Energy (SNoJoE), a method that consolidates label-specific information across multiple labels through the theoretically justified concept of an energy-based function. Throughout the training process, we employ spectral normalization to manage the model's feature space, thereby enhancing model efficacy and generalization, in addition to bolstering robustness. Our findings indicate that the application of spectral normalization to joint energy scores notably amplifies the model's capability for OOD detection. We perform OOD detection experiments utilizing PASCAL-VOC as the in-distribution dataset and ImageNet-22K or Texture as the out-of-distribution datasets. Our experimental results reveal that, in comparison to prior top performances, SNoJoE achieves 11% and 54% relative reductions in FPR95 on the respective OOD datasets, thereby defining the new state of the art in this field of study.",
      "authors": [
        "Yihan Mei",
        "Xinyu Wang",
        "De-Fu Zhang",
        "Xiaoling Wang"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/8cb280caa94c758e659adfb413b25a3d2e37a837",
      "pdf_link": "",
      "venue": "APWeb/WAIM",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "05a8b19f4b4ddd316eb959d6f68378842f1c65a2",
      "title": "Comparison of Out-of-Distribution Detection Performance of CLIP-based Fine-Tuning Methods",
      "abstract": "In recent years, large-scale vision-language models such as CLIP have shown remarkable performance on various zero-shot classification tasks. Inspired by these pretrained models, many studies have proposed effective fine-tuning methods to exploit the models’ pre-trained knowledge. One common approach is to fine-tune the entire model to transfer the pre-trained knowledge to target tasks. On the other hand, given the high cost of fine-tuning large-scale models, parameter-efficient fine-tuning methods are also being explored. While there have been performance comparisons of existing fine-tuning methods, they often focus solely on classification performance. Such a singular focus is not sufficient to assess the quality of the transferred pre-trained knowledge comprehensively. For a more rigorous evaluation, other metrics, such as the detection of out-of-distribution samples, should be considered, given their importance for model reliability. However, the comparison of fine-tuning methods concerning model reliability has been less explored. Therefore, we aim to fill this gap by offering a comprehensive comparative analysis on the out-of-distribution detection performance of CLIP-based fine-tuning methods along with their in-distribution classification performance. Our experimental results on the OpenOOD v1.5 benchmark dataset suggest that fine-tuning the entire model provides superior performance in both classification and out-of-distribution detection in a few-shot setting.",
      "authors": [
        "Jeonghyeon Kim",
        "Jihyo Kim",
        "Sangheum Hwang"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/05a8b19f4b4ddd316eb959d6f68378842f1c65a2",
      "pdf_link": "",
      "venue": "International Conference on Electronics, Information and Communications",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "400333890cf74f523068ab767a87fede2042131e",
      "title": "FOOD: Facial Authentication and Out-of-Distribution Detection with Short-Range FMCW Radar",
      "abstract": "This paper proposes a short-range FMCW radar-based facial authentication and out-of-distribution (OOD) detection framework. Our pipeline jointly estimates the correct classes for the in-distribution (ID) samples and detects the OOD samples to prevent their inaccurate prediction. Our reconstruction-based architecture consists of a main convolutional block with one encoder and multi-decoder configuration, and intermediate linear encoder-decoder parts. Together, these elements form an accurate human face classifier and a robust OOD detector. For our dataset, gathered using a 60 GHz short-range FMCW radar, our network achieves an average classification accuracy of 98.07% in identifying in-distribution human faces. As an OOD detector, it achieves an average Area Under the Receiver Operating Characteristic (AUROC) curve of 98.50% and an average False Positive Rate at 95% True Positive Rate (FPR95) of 6.20%. Also, our extensive experiments show that the proposed approach outperforms previous OOD detectors in terms of common OOD detection metrics.",
      "authors": [
        "Sabri Mustafa Kahya",
        "Boran Hamdi Sivrikaya",
        "Muhammet Sami Yavuz",
        "Eckehard G. Steinbach"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/400333890cf74f523068ab767a87fede2042131e",
      "pdf_link": "",
      "venue": "International Conference on Information Photonics",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "71fdc063701dc3f431942398d53b0290a9975d32",
      "title": "Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning",
      "abstract": "Detecting out-of-distribution (OOD) samples is a critical task for reliable machine learning. However, it becomes particularly challenging when the models are trained on long-tailed datasets, as the models often struggle to distinguish tail-class in-distribution samples from OOD samples. We examine the main challenges in this problem by identifying the trade-offs between OOD detection and in-distribution (ID) classification, faced by existing methods. We then introduce our method, called \\textit{Representation Norm Amplification} (RNA), which solves this challenge by decoupling the two problems. The main idea is to use the norm of the representation as a new dimension for OOD detection, and to develop a training method that generates a noticeable discrepancy in the representation norm between ID and OOD data, while not perturbing the feature learning for ID classification. Our experiments show that RNA achieves superior performance in both OOD detection and classification compared to the state-of-the-art methods, by 1.70\\% and 9.46\\% in FPR95 and 2.43\\% and 6.87\\% in classification accuracy on CIFAR10-LT and ImageNet-LT, respectively. The code for this work is available at https://github.com/dgshin21/RNA.",
      "authors": [
        "Dong Geun Shin",
        "Hye Won Chung"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/71fdc063701dc3f431942398d53b0290a9975d32",
      "pdf_link": "",
      "venue": "Trans. Mach. Learn. Res.",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "59fdf00e73e64dd9104ec4df010fc3bc4eac6c66",
      "title": "Towards Out-of-Distribution Detection in Vocoder Recognition via Latent Feature Reconstruction",
      "abstract": "Advancements in synthesized speech have created a growing threat of impersonation, making it crucial to develop deepfake algorithm recognition. One significant aspect is out-of-distribution (OOD) detection, which has gained notable attention due to its important role in deepfake algorithm recognition. However, most of the current approaches for detecting OOD in deepfake algorithm recognition rely on probability-score or classified-distance, which may lead to limitations in the accuracy of the sample at the edge of the threshold. In this study, we propose a reconstruction-based detection approach that employs an autoencoder architecture to compress and reconstruct the acoustic feature extracted from a pre-trained WavLM model. Each acoustic feature belonging to a specific vocoder class is only aptly reconstructed by its corresponding decoder. When none of the decoders can satisfactorily reconstruct a feature, it is classified as an OOD sample. To enhance the distinctiveness of the reconstructed features by each decoder, we incorporate contrastive learning and an auxiliary classifier to further constrain the reconstructed feature. Experiments demonstrate that our proposed approach surpasses baseline systems by a relative margin of 10\\% in the evaluation dataset. Ablation studies further validate the effectiveness of both the contrastive constraint and the auxiliary classifier within our proposed approach.",
      "authors": [
        "Renmingyue Du",
        "Jixun Yao",
        "Qiuqiang Kong",
        "Yin Cao"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/59fdf00e73e64dd9104ec4df010fc3bc4eac6c66",
      "pdf_link": "",
      "venue": "",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "38866b5afbf33b7207ce4e23b0a58d0745835570",
      "title": "Foundation Models and Fine-Tuning: A Benchmark for Out of Distribution Detection",
      "abstract": "The rise of foundation models is pushing Computer Vision research towards a paradigm shift, in the wake of what already happened in the Natural Language Processing field. These models, trained at scale on huge data collections, provide high-quality representations that generalize well enough to be applied directly to downstream tasks, often outperforming task-specific models. The Out Of Distribution (OOD) detection problem, which involves the ability to recognize when test samples come from a previously unseen semantic category, represents one of the research fields in which this paradigm shift could have the greatest impact. However, existing testbeds are limited in scale and scope and get easily saturated when adopting foundation-based pretrainings. With this work, we introduce a new benchmark covering realistic yet harder OOD detection tasks to properly assess the performance of large pretrained models. We design an experimental framework to analyze specific choices in the model learning and use (which dataset, pretraining objective, OOD scoring function) and extensively evaluate the comparison to standard approaches that leverage a training phase on the available In Distribution (ID) data. The results highlight the actual performance benefits of leveraging foundation models in this context without any further learning effort, and identify situations where task-specific fine-tuning remains the best choice.",
      "authors": [
        "Francesco Cappio Borlino",
        "L. Lu",
        "Tatiana Tommasi"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/38866b5afbf33b7207ce4e23b0a58d0745835570",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "26d34f9c230a93506b60465daaaae8c23011f412",
      "title": "Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond",
      "abstract": "In recent years, research on out-of-distribution (OoD) detection for semantic segmentation has mainly focused on road scenes -- a domain with a constrained amount of semantic diversity. In this work, we challenge this constraint and extend the domain of this task to general natural images. To this end, we introduce: 1. the ADE-OoD benchmark, which is based on the ADE20k dataset and includes images from diverse domains with a high semantic diversity, and 2. a novel approach that uses Diffusion score matching for OoD detection (DOoD) and is robust to the increased semantic diversity. ADE-OoD features indoor and outdoor images, defines 150 semantic categories as in-distribution, and contains a variety of OoD objects. For DOoD, we train a diffusion model with an MLP architecture on semantic in-distribution embeddings and build on the score matching interpretation to compute pixel-wise OoD scores at inference time. On common road scene OoD benchmarks, DOoD performs on par or better than the state of the art, without using outliers for training or making assumptions about the data domain. On ADE-OoD, DOoD outperforms previous approaches, but leaves much room for future improvements.",
      "authors": [
        "Silvio Galesso",
        "Philipp Schröppel",
        "Hssan Driss",
        "Thomas Brox"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/26d34f9c230a93506b60465daaaae8c23011f412",
      "pdf_link": "",
      "venue": "European Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "74491e50e381210badd7c8a0eee69d10410f6a68",
      "title": "Rethinking the Evaluation of Out-of-Distribution Detection: A Sorites Paradox",
      "abstract": "Most existing out-of-distribution (OOD) detection benchmarks classify samples with novel labels as the OOD data. However, some marginal OOD samples actually have close semantic contents to the in-distribution (ID) sample, which makes determining the OOD sample a Sorites Paradox. In this paper, we construct a benchmark named Incremental Shift OOD (IS-OOD) to address the issue, in which we divide the test samples into subsets with different semantic and covariate shift degrees relative to the ID dataset. The data division is achieved through a shift measuring method based on our proposed Language Aligned Image feature Decomposition (LAID). Moreover, we construct a Synthetic Incremental Shift (Syn-IS) dataset that contains high-quality generated images with more diverse covariate contents to complement the IS-OOD benchmark. We evaluate current OOD detection methods on our benchmark and find several important insights: (1) The performance of most OOD detection methods significantly improves as the semantic shift increases; (2) Some methods like GradNorm may have different OOD detection mechanisms as they rely less on semantic shifts to make decisions; (3) Excessive covariate shifts in the image are also likely to be considered as OOD for some methods. Our code and data are released in https://github.com/qqwsad5/IS-OOD.",
      "authors": [
        "Xingming Long",
        "Jie Zhang",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/74491e50e381210badd7c8a0eee69d10410f6a68",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "b826af7705a11f6fefc9452eed5db6309520f170",
      "title": "Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation",
      "abstract": "Out-of-distribution (OOD) detection and segmentation are crucial for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. While prior research has primarily focused on unimodal image data, real-world applications are inherently multimodal, requiring the integration of multiple modalities for improved OOD detection. A key challenge is the lack of supervision signals from unknown data, leading to overconfident predictions on OOD samples. To address this challenge, we propose Feature Mixing, an extremely simple and fast method for multimodal outlier synthesis with theoretical support, which can be further optimized to help the model better distinguish between in-distribution (ID) and OOD data. Feature Mixing is modality-agnostic and applicable to various modality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal dataset for OOD segmentation, featuring synthetic OOD objects across diverse scenes and weather conditions. Extensive experiments on SemanticKITTI, nuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that Feature Mixing achieves state-of-the-art performance with a $10 \\times$ to $370 \\times$ speedup. Our source code and dataset will be available at https://github.com/mona4399/FeatureMixing.",
      "authors": [
        "Moru Liu",
        "Hao Dong",
        "Jessica Kelly",
        "Olga Fink",
        "Mario Trapp"
      ],
      "year": 2025,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/b826af7705a11f6fefc9452eed5db6309520f170",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "title": "Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection",
      "abstract": "Out-of-distribution (OOD) detection is crucial for developing trustworthy and reliable machine learning systems. Recent advances in training with auxiliary OOD data demonstrate efficacy in enhancing detection capabilities. Nonetheless, these methods heavily rely on acquiring a large pool of high-quality natural outliers. Some prior methods try to alleviate this problem by synthesizing virtual outliers but suffer from either poor quality or high cost due to the monotonous sampling strategy and the heavy-parameterized generative models. In this paper, we overcome all these problems by proposing the Hamiltonian Monte Carlo Outlier Synthesis (HamOS) framework, which views the synthesis process as sampling from Markov chains. Based solely on the in-distribution data, the Markov chains can extensively traverse the feature space and generate diverse and representative outliers, hence exposing the model to miscellaneous potential OOD scenarios. The Hamiltonian Monte Carlo with sampling acceptance rate almost close to 1 also makes our framework enjoy great efficiency. By empirically competing with SOTA baselines on both standard and large-scale benchmarks, we verify the efficacy and efficiency of our proposed HamOS.",
      "authors": [
        "Hengzhuang Li",
        "Teng Zhang"
      ],
      "year": 2025,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/50864505777b344d2ee4b4d18880f3ba3ca58836",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "0e6010e6b53e1d281107844fbcf54608194599cf",
      "title": "Digital Twin-based Out-of-Distribution Detection in Autonomous Vessels",
      "abstract": "An autonomous vessel (AV) is a complex cyber-physical system (CPS) with software enabling many key functionalities, e.g., navigation software enables an AV to autonomously or semi-autonomously follow a path to its destination. Digital twins of such AVs enable advanced functionalities such as running what-if scenarios, performing predictive maintenance, and enabling fault diagnosis. Due to technological improvements, real-time analyses using continuous data from vessels' real-time operations have become increasingly possible. However, the literature has little explored developing advanced analyses in real-time data in AVs with digital twins built with machine learning techniques. To this end, we present a novel digital twin-based approach (ODDIT) to detect future out-of-distribution (OOD) states of an AV before reaching them, enabling proactive intervention. Such states may indicate anomalies requiring attention (e.g., manual correction by the ship master) and assist testers in scenario-centered testing. The digital twin consists of two machine-learning models predicting future vessel states and whether the predicted state will be OOD. We evaluated ODDIT with five vessels across waypoint and zigzag maneuvering under simulated conditions, including sensor and actuator noise and environmental disturbances i.e., ocean current. ODDIT achieved high accuracy in detecting OOD states, with AUROC and TNR@TPR95 scores reaching 99\\% across multiple vessels.",
      "authors": [
        "Erblin Isaku",
        "Hassan Sartaj",
        "Shaukat Ali"
      ],
      "year": 2025,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/0e6010e6b53e1d281107844fbcf54608194599cf",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    }
  ],
  "edges": [
    {
      "source": "60108b8e0d7204fa33f686b09128c7fc8489a224",
      "target": "0e6010e6b53e1d281107844fbcf54608194599cf",
      "weight": 0.23207822862036426
    },
    {
      "source": "60108b8e0d7204fa33f686b09128c7fc8489a224",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.25230621829363614
    },
    {
      "source": "60108b8e0d7204fa33f686b09128c7fc8489a224",
      "target": "14cfe2588311870325e2770c5159d3100d7031ea",
      "weight": 0.25999225776535384
    },
    {
      "source": "60108b8e0d7204fa33f686b09128c7fc8489a224",
      "target": "f9ac68dc1fdd070a65a71c739e7135361c0d3006",
      "weight": 0.23388234715909448
    },
    {
      "source": "60108b8e0d7204fa33f686b09128c7fc8489a224",
      "target": "f9cf8d53b1a157ab9dee16f03290d28865f3089a",
      "weight": 0.23525747936941077
    },
    {
      "source": "60108b8e0d7204fa33f686b09128c7fc8489a224",
      "target": "5df7dcb96a465ed4d4d2fa2414413a41494fee8c",
      "weight": 0.2403975123948518
    },
    {
      "source": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "target": "a1ce596ef67f28f433f3de1001774211d00b54f0",
      "weight": 0.28437002222997954
    },
    {
      "source": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2846359867353895
    },
    {
      "source": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "target": "201817ff23481abd4ef48ce9e2ce71314f720ea7",
      "weight": 0.3038416322718382
    },
    {
      "source": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.10056373633745395
    },
    {
      "source": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "target": "74491e50e381210badd7c8a0eee69d10410f6a68",
      "weight": 0.5956676221014207
    },
    {
      "source": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "target": "69c2808097e7dfd357856f1ae82dcb6ce1bf64df",
      "weight": 0.6480612255630454
    },
    {
      "source": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "target": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "weight": 0.26228410949836206
    },
    {
      "source": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "target": "8f53788139d97189af8204a36b109473a0a2b61f",
      "weight": 0.46268570337640963
    },
    {
      "source": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "target": "38866b5afbf33b7207ce4e23b0a58d0745835570",
      "weight": 0.34318025382090733
    },
    {
      "source": "af5b1a35271efd17ff3d5ddd152bacc96dff0e81",
      "target": "48020e5f1a0d5703f6169c20051eeb056194c25b",
      "weight": 0.22242480715833252
    },
    {
      "source": "af5b1a35271efd17ff3d5ddd152bacc96dff0e81",
      "target": "8529e0bbf80f36998f9b65b11bc0177099f11b07",
      "weight": 0.2693365917637704
    },
    {
      "source": "af5b1a35271efd17ff3d5ddd152bacc96dff0e81",
      "target": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "weight": 0.2671979203592214
    },
    {
      "source": "af5b1a35271efd17ff3d5ddd152bacc96dff0e81",
      "target": "e75e08851675eb506ea0149b0403828b6fb24900",
      "weight": 0.36573901120562374
    },
    {
      "source": "af5b1a35271efd17ff3d5ddd152bacc96dff0e81",
      "target": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "weight": 0.10711119415238662
    },
    {
      "source": "af5b1a35271efd17ff3d5ddd152bacc96dff0e81",
      "target": "2815a5e7ba661ae278aa7c19e08ac884cde17bf7",
      "weight": 0.09501830074659942
    },
    {
      "source": "af5b1a35271efd17ff3d5ddd152bacc96dff0e81",
      "target": "34d35e460b39edb19581ef345c4b32ce45aa9eae",
      "weight": 0.33983892334026866
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "71fdc063701dc3f431942398d53b0290a9975d32",
      "weight": 0.27676071670817853
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "36dd3bee303671d45c6ab4631c34b2dd67e19e69",
      "weight": 0.2582170680529798
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "74491e50e381210badd7c8a0eee69d10410f6a68",
      "weight": 0.2608358619254848
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "726cf970e8dc6642bb6064f78e7279cee50a9222",
      "weight": 0.22754861739701607
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "1f24e041e10239cba8ff26ffcff4902343e55cab",
      "weight": 0.24972686603200145
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "47cfe2c7ba31259ed8b005a348a48db4676279fa",
      "weight": 0.26029432443131073
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "08925eef04eada4dd46dd3a33ea35f05795b12a9",
      "weight": 0.08497132337547356
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "ff29bf27e1c4e95c4eec448ed1d4adfa81983302",
      "weight": 0.2703007460246001
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "350b00baaddd9f42dd3689f475bea3139e24099d",
      "weight": 0.2529855744209383
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "b723d4e9fbe81890624d11c873acb63ddf21b64b",
      "weight": 0.2522419999121143
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "weight": 0.23619136712219235
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "f911f3b51fcc88f2240def8f38ed8dff1da2e605",
      "weight": 0.26246081498903323
    },
    {
      "source": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "target": "7d826dfb184be983018590c64cfb4a79349472a4",
      "weight": 0.28433353929175664
    },
    {
      "source": "305941292b59d808af1f6646993747ba0f76f4ac",
      "target": "a1ce596ef67f28f433f3de1001774211d00b54f0",
      "weight": 0.4849209907203331
    },
    {
      "source": "305941292b59d808af1f6646993747ba0f76f4ac",
      "target": "d212c555293b81f845b3c99af4e922b0fcdb4290",
      "weight": 0.40649558813073683
    },
    {
      "source": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "target": "4f292e3e9d34471631203d222e597912ae936a05",
      "weight": 0.31435880549752687
    },
    {
      "source": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "target": "7466087f3748165181b0463153008d39879d5879",
      "weight": 0.2742503296861043
    },
    {
      "source": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "target": "6618d8b3643745d60772d4ec522ad76204522f7d",
      "weight": 0.26274415519278166
    },
    {
      "source": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "target": "08925eef04eada4dd46dd3a33ea35f05795b12a9",
      "weight": 0.03987755402853952
    },
    {
      "source": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "target": "ff29bf27e1c4e95c4eec448ed1d4adfa81983302",
      "weight": 0.25556394036857294
    },
    {
      "source": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "target": "41e68a78f5bd266b1ae54d521ebd0be0e9314cd8",
      "weight": 0.24807114544559056
    },
    {
      "source": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "target": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "weight": 0.2886070888946002
    },
    {
      "source": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "target": "977384045381a2c45dfac4797196d34658d8a44f",
      "weight": 0.24805377064903772
    },
    {
      "source": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6",
      "target": "903966632e84a59ca49914ebbadbbfbfe84e7c29",
      "weight": 0.2639196929221451
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "be422ce2f64425f5c7bedf9a8498ab1e993060cc",
      "weight": 0.33883960185672346
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.0909338934323484
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "87268ea5825cd65c1c3151d6ecc0973f267b3c68",
      "weight": 0.348636658070565
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "4ff175285ef575f4dc24a518869139382665c12e",
      "weight": 0.28463160439082874
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "bea84d4f28799628fa91585690088c00e8dca827",
      "weight": 0.31502140226727493
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "23bbd94f93e360f373f78ce20f61ec3486b1923d",
      "weight": 0.27825729843575725
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "0e3a01e0bd1beff9e77d8809629db24fc706c085",
      "weight": 0.2460557742762287
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f",
      "weight": 0.27576395710118934
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "8f53788139d97189af8204a36b109473a0a2b61f",
      "weight": 0.29019726250220235
    },
    {
      "source": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31",
      "target": "1007a43d42c7c92d765cdf614c98f6fc974aaf15",
      "weight": 0.28776141572843245
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "71fdc063701dc3f431942398d53b0290a9975d32",
      "weight": 0.2997350302162951
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "4de791464e08ba25d2466abf78fd9b529ce6d2d5",
      "weight": 0.2457729109513232
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "36dd3bee303671d45c6ab4631c34b2dd67e19e69",
      "weight": 0.32265372671047243
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "8529e0bbf80f36998f9b65b11bc0177099f11b07",
      "weight": 0.3424339156817231
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "87268ea5825cd65c1c3151d6ecc0973f267b3c68",
      "weight": 0.28385229461632805
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "1f24e041e10239cba8ff26ffcff4902343e55cab",
      "weight": 0.28563291840004346
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "bea84d4f28799628fa91585690088c00e8dca827",
      "weight": 0.25710169646059944
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "590659832401c015e20a264cfdd7e0e4097b478b",
      "weight": 0.2795748267185741
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "350b00baaddd9f42dd3689f475bea3139e24099d",
      "weight": 0.29457083466378736
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "913d26360f1a715f6ae80f5a775f398aa2f66c9d",
      "weight": 0.32268900541233003
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "f911f3b51fcc88f2240def8f38ed8dff1da2e605",
      "weight": 0.3189430134533944
    },
    {
      "source": "df8176027e3b9857e6bc6f45b3fc183351571fbd",
      "target": "7d826dfb184be983018590c64cfb4a79349472a4",
      "weight": 0.3219438853347072
    },
    {
      "source": "558f6cfc2daa06fa6562084a566392b907fc1642",
      "target": "209c949e277081b8f2847cf3e66b90df26dcf179",
      "weight": 0.40597787266343827
    },
    {
      "source": "558f6cfc2daa06fa6562084a566392b907fc1642",
      "target": "4ff175285ef575f4dc24a518869139382665c12e",
      "weight": 0.2572444612717274
    },
    {
      "source": "558f6cfc2daa06fa6562084a566392b907fc1642",
      "target": "6f136ee16da4f01f30b267478d5127699c983e20",
      "weight": 0.2498889402616546
    },
    {
      "source": "558f6cfc2daa06fa6562084a566392b907fc1642",
      "target": "7da7d9d38b964a70396fa842bf69f9a897111c26",
      "weight": 0.26467500442488967
    },
    {
      "source": "4b83c2ec2c5119057979ae64cf4b5d1aef04466b",
      "target": "39af99b93c6b95f54f78952522e6d22496dd5bf1",
      "weight": 0.2673123890290799
    },
    {
      "source": "4b83c2ec2c5119057979ae64cf4b5d1aef04466b",
      "target": "903966632e84a59ca49914ebbadbbfbfe84e7c29",
      "weight": 0.26840518100836075
    },
    {
      "source": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "target": "b826af7705a11f6fefc9452eed5db6309520f170",
      "weight": 0.3203552205087443
    },
    {
      "source": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "target": "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129",
      "weight": 0.2624490414772649
    },
    {
      "source": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "target": "26d34f9c230a93506b60465daaaae8c23011f412",
      "weight": 0.10872395297183635
    },
    {
      "source": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "target": "33fb671a3289027c84a71fc996f948195b1baeb4",
      "weight": 0.27111903205298377
    },
    {
      "source": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "target": "7466087f3748165181b0463153008d39879d5879",
      "weight": 0.2813068689650834
    },
    {
      "source": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "target": "06436653774a7cb8d53005d3f25af2a7229c1f8b",
      "weight": 0.24157832588911804
    },
    {
      "source": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "target": "531762d327ac99a898f4976181c1c69e2e3076cb",
      "weight": 0.2888442109920561
    },
    {
      "source": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0",
      "target": "f0f220240fc752b6b3c56464d96aeb322f221ef0",
      "weight": 0.26372603754764984
    },
    {
      "source": "63ff7c225079eba3838d45b11bb15a58037f1415",
      "target": "db5059dea1ee639dfc7eba751183ce3564a4b593",
      "weight": 0.2626404417194191
    },
    {
      "source": "63ff7c225079eba3838d45b11bb15a58037f1415",
      "target": "f9cf8d53b1a157ab9dee16f03290d28865f3089a",
      "weight": 0.2610322179831849
    },
    {
      "source": "63ff7c225079eba3838d45b11bb15a58037f1415",
      "target": "79c72327dd14466c4db3865902c8317f74bb4c56",
      "weight": 0.24324307043329385
    },
    {
      "source": "63ff7c225079eba3838d45b11bb15a58037f1415",
      "target": "65e63d2d9168fa3cca6cd8bc083612b5f6cecc84",
      "weight": 0.3767719969375672
    },
    {
      "source": "34d35e460b39edb19581ef345c4b32ce45aa9eae",
      "target": "b3f21af3032246b6fa87e05a6d9455433b25ce55",
      "weight": 0.26315922619152876
    },
    {
      "source": "34d35e460b39edb19581ef345c4b32ce45aa9eae",
      "target": "5f8ccbe2a87df5e1340d4bda8f6e3458ef1bf6ae",
      "weight": 0.307606948311076
    },
    {
      "source": "7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "target": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "weight": 0.26889668412390944
    },
    {
      "source": "7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "target": "d03cf8819aeff52708a70d506b87e50214af53b6",
      "weight": 0.27135108405166863
    },
    {
      "source": "7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "target": "565d5a9038154fbbcba3d4a6f17671af9515fbcc",
      "weight": 0.3256576556181569
    },
    {
      "source": "7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2966042195561382
    },
    {
      "source": "7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "target": "7466087f3748165181b0463153008d39879d5879",
      "weight": 0.32193024552326543
    },
    {
      "source": "7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "target": "bcbee683ff34f87675448471d780541f7ae25ce9",
      "weight": 0.2305874788656883
    },
    {
      "source": "7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "target": "9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0",
      "weight": 0.30263835282569
    },
    {
      "source": "7bdc1a737a8864b80c7abd5cca71c6514de25345",
      "target": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "weight": 0.30108722869760585
    },
    {
      "source": "903966632e84a59ca49914ebbadbbfbfe84e7c29",
      "target": "a1ce596ef67f28f433f3de1001774211d00b54f0",
      "weight": 0.30565073406929877
    },
    {
      "source": "903966632e84a59ca49914ebbadbbfbfe84e7c29",
      "target": "71fdc063701dc3f431942398d53b0290a9975d32",
      "weight": 0.2802090103568433
    },
    {
      "source": "903966632e84a59ca49914ebbadbbfbfe84e7c29",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.051312432706547485
    },
    {
      "source": "903966632e84a59ca49914ebbadbbfbfe84e7c29",
      "target": "5df7dcb96a465ed4d4d2fa2414413a41494fee8c",
      "weight": 0.2625605417267079
    },
    {
      "source": "903966632e84a59ca49914ebbadbbfbfe84e7c29",
      "target": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "weight": 0.3115800005987662
    },
    {
      "source": "ba39d83ec8b79f35d8195835f46cc4e36e5a4211",
      "target": "726cf970e8dc6642bb6064f78e7279cee50a9222",
      "weight": 0.24693231957515402
    },
    {
      "source": "ba39d83ec8b79f35d8195835f46cc4e36e5a4211",
      "target": "b3f21af3032246b6fa87e05a6d9455433b25ce55",
      "weight": 0.2805665159486659
    },
    {
      "source": "ba39d83ec8b79f35d8195835f46cc4e36e5a4211",
      "target": "1fd384324d878cdb770a51cd333b7451b2fe5bcc",
      "weight": 0.44037827780771244
    },
    {
      "source": "ba39d83ec8b79f35d8195835f46cc4e36e5a4211",
      "target": "2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e",
      "weight": 0.34114680173245904
    },
    {
      "source": "ba39d83ec8b79f35d8195835f46cc4e36e5a4211",
      "target": "34d35e460b39edb19581ef345c4b32ce45aa9eae",
      "weight": 0.37415179821105443
    },
    {
      "source": "dcfca93185c49811ec6cf7c995eea58cf88c7bb3",
      "target": "a1ce596ef67f28f433f3de1001774211d00b54f0",
      "weight": 0.3370954668930354
    },
    {
      "source": "dcfca93185c49811ec6cf7c995eea58cf88c7bb3",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.38243262618373175
    },
    {
      "source": "dcfca93185c49811ec6cf7c995eea58cf88c7bb3",
      "target": "d2d056e705902d33d769206489d53e0659e376cc",
      "weight": 0.26458622412340566
    },
    {
      "source": "dcfca93185c49811ec6cf7c995eea58cf88c7bb3",
      "target": "4ff175285ef575f4dc24a518869139382665c12e",
      "weight": 0.3160223588142477
    },
    {
      "source": "dcfca93185c49811ec6cf7c995eea58cf88c7bb3",
      "target": "23bbd94f93e360f373f78ce20f61ec3486b1923d",
      "weight": 0.31479699655968585
    },
    {
      "source": "7d826dfb184be983018590c64cfb4a79349472a4",
      "target": "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129",
      "weight": 0.2793635672592101
    },
    {
      "source": "7d826dfb184be983018590c64cfb4a79349472a4",
      "target": "71fdc063701dc3f431942398d53b0290a9975d32",
      "weight": 0.32989644620109615
    },
    {
      "source": "7d826dfb184be983018590c64cfb4a79349472a4",
      "target": "33fb671a3289027c84a71fc996f948195b1baeb4",
      "weight": 0.2439455490950348
    },
    {
      "source": "7d826dfb184be983018590c64cfb4a79349472a4",
      "target": "726cf970e8dc6642bb6064f78e7279cee50a9222",
      "weight": 0.23363518335223465
    },
    {
      "source": "7d826dfb184be983018590c64cfb4a79349472a4",
      "target": "1f24e041e10239cba8ff26ffcff4902343e55cab",
      "weight": 0.2631280413956061
    },
    {
      "source": "7d826dfb184be983018590c64cfb4a79349472a4",
      "target": "5df7dcb96a465ed4d4d2fa2414413a41494fee8c",
      "weight": 0.2592032887506205
    },
    {
      "source": "7d826dfb184be983018590c64cfb4a79349472a4",
      "target": "f911f3b51fcc88f2240def8f38ed8dff1da2e605",
      "weight": 0.24319937963426352
    },
    {
      "source": "ff29bf27e1c4e95c4eec448ed1d4adfa81983302",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.32151492174659213
    },
    {
      "source": "ff29bf27e1c4e95c4eec448ed1d4adfa81983302",
      "target": "8529e0bbf80f36998f9b65b11bc0177099f11b07",
      "weight": 0.33582387917517265
    },
    {
      "source": "393e0b8459eb1608b6b35d6057da4ddb09957555",
      "target": "06436653774a7cb8d53005d3f25af2a7229c1f8b",
      "weight": 0.23952192244104614
    },
    {
      "source": "2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e",
      "target": "59f40cf3eebd2cb6ad30363fa6abf1caea06555f",
      "weight": 0.2535104573966971
    },
    {
      "source": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "target": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "weight": 0.23127771909464984
    },
    {
      "source": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.25089081217390374
    },
    {
      "source": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "target": "726cf970e8dc6642bb6064f78e7279cee50a9222",
      "weight": 0.22814383272594427
    },
    {
      "source": "3430707312d8d9192f2f4b967f541f96618ba393",
      "target": "70da774b2b30397ee2f7e2abc819ed126641a70d",
      "weight": 0.41184773144973486
    },
    {
      "source": "3430707312d8d9192f2f4b967f541f96618ba393",
      "target": "b723d4e9fbe81890624d11c873acb63ddf21b64b",
      "weight": 0.33839111339684147
    },
    {
      "source": "3430707312d8d9192f2f4b967f541f96618ba393",
      "target": "65e63d2d9168fa3cca6cd8bc083612b5f6cecc84",
      "weight": 0.30697750698899046
    },
    {
      "source": "977384045381a2c45dfac4797196d34658d8a44f",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.24975505218444644
    },
    {
      "source": "977384045381a2c45dfac4797196d34658d8a44f",
      "target": "5df7dcb96a465ed4d4d2fa2414413a41494fee8c",
      "weight": 0.24905288567156836
    },
    {
      "source": "977384045381a2c45dfac4797196d34658d8a44f",
      "target": "57f4b117744112e4000894a5f939e114f1907719",
      "weight": 0.4178051822569261
    },
    {
      "source": "f0f220240fc752b6b3c56464d96aeb322f221ef0",
      "target": "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129",
      "weight": 0.631787582861032
    },
    {
      "source": "f0f220240fc752b6b3c56464d96aeb322f221ef0",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.27413246532702396
    },
    {
      "source": "f0f220240fc752b6b3c56464d96aeb322f221ef0",
      "target": "71fdc063701dc3f431942398d53b0290a9975d32",
      "weight": 0.5053662845399389
    },
    {
      "source": "f0f220240fc752b6b3c56464d96aeb322f221ef0",
      "target": "33fb671a3289027c84a71fc996f948195b1baeb4",
      "weight": 0.2961922830350511
    },
    {
      "source": "f0f220240fc752b6b3c56464d96aeb322f221ef0",
      "target": "7466087f3748165181b0463153008d39879d5879",
      "weight": 0.4421976214303425
    },
    {
      "source": "f0f220240fc752b6b3c56464d96aeb322f221ef0",
      "target": "531762d327ac99a898f4976181c1c69e2e3076cb",
      "weight": 0.3865733758273059
    },
    {
      "source": "41e68a78f5bd266b1ae54d521ebd0be0e9314cd8",
      "target": "14cfe2588311870325e2770c5159d3100d7031ea",
      "weight": 0.28873893125457384
    },
    {
      "source": "41e68a78f5bd266b1ae54d521ebd0be0e9314cd8",
      "target": "87268ea5825cd65c1c3151d6ecc0973f267b3c68",
      "weight": 0.273313770859682
    },
    {
      "source": "41e68a78f5bd266b1ae54d521ebd0be0e9314cd8",
      "target": "bea84d4f28799628fa91585690088c00e8dca827",
      "weight": 0.25777696070035927
    },
    {
      "source": "4c1601f2582b351aea86a1d56dfd20f59a9f44ba",
      "target": "88b9e2bce0caadf7495490603f5292166e2a1860",
      "weight": 0.403950218223359
    },
    {
      "source": "6f136ee16da4f01f30b267478d5127699c983e20",
      "target": "835d157e2c23d3577f23778ce051ab8d706babf6",
      "weight": 0.31559976135112633
    },
    {
      "source": "6f136ee16da4f01f30b267478d5127699c983e20",
      "target": "350b00baaddd9f42dd3689f475bea3139e24099d",
      "weight": 0.30356943832215844
    },
    {
      "source": "6f136ee16da4f01f30b267478d5127699c983e20",
      "target": "4fc9a9046cab45de423cadb2db887881cd0972e8",
      "weight": 0.2682945887977732
    },
    {
      "source": "091ef8678781d1b53a5a07643ae37e3d44f9ed61",
      "target": "b826af7705a11f6fefc9452eed5db6309520f170",
      "weight": 0.3263800424928321
    },
    {
      "source": "091ef8678781d1b53a5a07643ae37e3d44f9ed61",
      "target": "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129",
      "weight": 0.44298560934997744
    },
    {
      "source": "091ef8678781d1b53a5a07643ae37e3d44f9ed61",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.27235930201351943
    },
    {
      "source": "091ef8678781d1b53a5a07643ae37e3d44f9ed61",
      "target": "71fdc063701dc3f431942398d53b0290a9975d32",
      "weight": 0.3593623235142321
    },
    {
      "source": "091ef8678781d1b53a5a07643ae37e3d44f9ed61",
      "target": "7466087f3748165181b0463153008d39879d5879",
      "weight": 0.3063689801203535
    },
    {
      "source": "091ef8678781d1b53a5a07643ae37e3d44f9ed61",
      "target": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "weight": 0.3846745190139983
    },
    {
      "source": "3f9f3ca7832f36285fbb0a65c221ded5e32382a1",
      "target": "be422ce2f64425f5c7bedf9a8498ab1e993060cc",
      "weight": 0.2667259693959332
    },
    {
      "source": "3f9f3ca7832f36285fbb0a65c221ded5e32382a1",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.040751021727773215
    },
    {
      "source": "3f9f3ca7832f36285fbb0a65c221ded5e32382a1",
      "target": "f418971afad1d44fb64610b91128a4eb6c3855ef",
      "weight": 0.3021290241399089
    },
    {
      "source": "3f9f3ca7832f36285fbb0a65c221ded5e32382a1",
      "target": "7466087f3748165181b0463153008d39879d5879",
      "weight": 0.3474647745522462
    },
    {
      "source": "ca9974ac55dacf8db6eb4a57f489756068797cab",
      "target": "913d26360f1a715f6ae80f5a775f398aa2f66c9d",
      "weight": 0.30707247062610316
    },
    {
      "source": "ca9974ac55dacf8db6eb4a57f489756068797cab",
      "target": "eb332d020cb8877358157b7810e949d8f0256b1e",
      "weight": 0.32029754956719597
    },
    {
      "source": "ca9974ac55dacf8db6eb4a57f489756068797cab",
      "target": "955dd252793ea3f07de81b2f61165b6a822e07d5",
      "weight": 0.26418404038201426
    },
    {
      "source": "2815a5e7ba661ae278aa7c19e08ac884cde17bf7",
      "target": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2",
      "weight": 0.2535455786590222
    },
    {
      "source": "57f4b117744112e4000894a5f939e114f1907719",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2927415906339463
    },
    {
      "source": "57f4b117744112e4000894a5f939e114f1907719",
      "target": "26d34f9c230a93506b60465daaaae8c23011f412",
      "weight": 0.18659421317867972
    },
    {
      "source": "8ef5a28955ce4fbd170e4dddbd37930e025edb69",
      "target": "209c949e277081b8f2847cf3e66b90df26dcf179",
      "weight": 0.36398787243953423
    },
    {
      "source": "8ef5a28955ce4fbd170e4dddbd37930e025edb69",
      "target": "4de791464e08ba25d2466abf78fd9b529ce6d2d5",
      "weight": 0.2772435919323302
    },
    {
      "source": "7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba",
      "target": "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129",
      "weight": 0.4189542332238635
    },
    {
      "source": "7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.313419735337512
    },
    {
      "source": "7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba",
      "target": "71fdc063701dc3f431942398d53b0290a9975d32",
      "weight": 0.4109913174875515
    },
    {
      "source": "6db1cc71f6cfad8d7a9e09882711c722766562b6",
      "target": "209c949e277081b8f2847cf3e66b90df26dcf179",
      "weight": 0.3064498505508503
    },
    {
      "source": "6db1cc71f6cfad8d7a9e09882711c722766562b6",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.31966183573569423
    },
    {
      "source": "6db1cc71f6cfad8d7a9e09882711c722766562b6",
      "target": "b3f21af3032246b6fa87e05a6d9455433b25ce55",
      "weight": 0.3157362880279172
    },
    {
      "source": "a1ce596ef67f28f433f3de1001774211d00b54f0",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.33391304599190524
    },
    {
      "source": "4ec3a01aee0ae0e4d334e552373ccd74ca66b76e",
      "target": "70da774b2b30397ee2f7e2abc819ed126641a70d",
      "weight": 0.300909531118265
    },
    {
      "source": "0e3a01e0bd1beff9e77d8809629db24fc706c085",
      "target": "71fdc063701dc3f431942398d53b0290a9975d32",
      "weight": 0.417001021305434
    },
    {
      "source": "69c2808097e7dfd357856f1ae82dcb6ce1bf64df",
      "target": "74491e50e381210badd7c8a0eee69d10410f6a68",
      "weight": 0.6261027676818072
    },
    {
      "source": "8f53788139d97189af8204a36b109473a0a2b61f",
      "target": "69c2808097e7dfd357856f1ae82dcb6ce1bf64df",
      "weight": 0.5147025697200396
    },
    {
      "source": "8f53788139d97189af8204a36b109473a0a2b61f",
      "target": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d",
      "weight": 0.25050872801734925
    },
    {
      "source": "8505cb57677d296351a1b86d15c843410778daca",
      "target": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "weight": 0.256484965629715
    },
    {
      "source": "8505cb57677d296351a1b86d15c843410778daca",
      "target": "be422ce2f64425f5c7bedf9a8498ab1e993060cc",
      "weight": 0.3229307981159937
    },
    {
      "source": "8505cb57677d296351a1b86d15c843410778daca",
      "target": "14cfe2588311870325e2770c5159d3100d7031ea",
      "weight": 0.32819518668112424
    },
    {
      "source": "8505cb57677d296351a1b86d15c843410778daca",
      "target": "87268ea5825cd65c1c3151d6ecc0973f267b3c68",
      "weight": 0.3074690838899703
    },
    {
      "source": "8505cb57677d296351a1b86d15c843410778daca",
      "target": "bea84d4f28799628fa91585690088c00e8dca827",
      "weight": 0.2884531835860891
    },
    {
      "source": "23bbd94f93e360f373f78ce20f61ec3486b1923d",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.29910461137358635
    },
    {
      "source": "23bbd94f93e360f373f78ce20f61ec3486b1923d",
      "target": "728afc51ac20d79133d8c747a2d18b01c6a6de5e",
      "weight": 0.27552790200592936
    },
    {
      "source": "23bbd94f93e360f373f78ce20f61ec3486b1923d",
      "target": "dcfca93185c49811ec6cf7c995eea58cf88c7bb3",
      "weight": 0.11479699655968584
    },
    {
      "source": "f911f3b51fcc88f2240def8f38ed8dff1da2e605",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2627047334208822
    },
    {
      "source": "f911f3b51fcc88f2240def8f38ed8dff1da2e605",
      "target": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "weight": 0.24671199218105616
    },
    {
      "source": "f911f3b51fcc88f2240def8f38ed8dff1da2e605",
      "target": "6db1cc71f6cfad8d7a9e09882711c722766562b6",
      "weight": 0.25424139436286847
    },
    {
      "source": "955dd252793ea3f07de81b2f61165b6a822e07d5",
      "target": "88b9e2bce0caadf7495490603f5292166e2a1860",
      "weight": 0.22495004281830414
    },
    {
      "source": "955dd252793ea3f07de81b2f61165b6a822e07d5",
      "target": "590659832401c015e20a264cfdd7e0e4097b478b",
      "weight": 0.2874752470210862
    },
    {
      "source": "ecd30803a587687db2e5a2ff659391e56b792714",
      "target": "565d5a9038154fbbcba3d4a6f17671af9515fbcc",
      "weight": 0.40731549298378
    },
    {
      "source": "ecd30803a587687db2e5a2ff659391e56b792714",
      "target": "7466087f3748165181b0463153008d39879d5879",
      "weight": 0.3287374118016524
    },
    {
      "source": "350b00baaddd9f42dd3689f475bea3139e24099d",
      "target": "1f24e041e10239cba8ff26ffcff4902343e55cab",
      "weight": 0.4527133134263582
    },
    {
      "source": "4de791464e08ba25d2466abf78fd9b529ce6d2d5",
      "target": "209c949e277081b8f2847cf3e66b90df26dcf179",
      "weight": 0.24616777681498425
    },
    {
      "source": "4de791464e08ba25d2466abf78fd9b529ce6d2d5",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.0941579175975426
    },
    {
      "source": "913d26360f1a715f6ae80f5a775f398aa2f66c9d",
      "target": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "weight": 0.3998162718500682
    },
    {
      "source": "913d26360f1a715f6ae80f5a775f398aa2f66c9d",
      "target": "565d5a9038154fbbcba3d4a6f17671af9515fbcc",
      "weight": 0.392231032020252
    },
    {
      "source": "913d26360f1a715f6ae80f5a775f398aa2f66c9d",
      "target": "8529e0bbf80f36998f9b65b11bc0177099f11b07",
      "weight": 0.3157989505706301
    },
    {
      "source": "913d26360f1a715f6ae80f5a775f398aa2f66c9d",
      "target": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "weight": 0.3713654134127867
    },
    {
      "source": "f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f",
      "target": "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129",
      "weight": 0.29702523508893064
    },
    {
      "source": "f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.28502824698144225
    },
    {
      "source": "f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f",
      "target": "06436653774a7cb8d53005d3f25af2a7229c1f8b",
      "weight": 0.30590294929476264
    },
    {
      "source": "08925eef04eada4dd46dd3a33ea35f05795b12a9",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.24553413206989438
    },
    {
      "source": "e75e08851675eb506ea0149b0403828b6fb24900",
      "target": "a1ce596ef67f28f433f3de1001774211d00b54f0",
      "weight": 0.30097539610471025
    },
    {
      "source": "2f615dc49f38928fb08534b6edd1ad2c0102243a",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2965649546683614
    },
    {
      "source": "7466087f3748165181b0463153008d39879d5879",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.25011691566204086
    },
    {
      "source": "7466087f3748165181b0463153008d39879d5879",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.11452624236207573
    },
    {
      "source": "590659832401c015e20a264cfdd7e0e4097b478b",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.3154351824556188
    },
    {
      "source": "726cf970e8dc6642bb6064f78e7279cee50a9222",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.26739004247610215
    },
    {
      "source": "4ae78016f21de53032cba4d7327e21b12fe1dcf5",
      "target": "d03cf8819aeff52708a70d506b87e50214af53b6",
      "weight": 0.30909637804240486
    },
    {
      "source": "eb332d020cb8877358157b7810e949d8f0256b1e",
      "target": "06436653774a7cb8d53005d3f25af2a7229c1f8b",
      "weight": 0.28591166808849416
    },
    {
      "source": "79c72327dd14466c4db3865902c8317f74bb4c56",
      "target": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "weight": 0.23213882512721534
    },
    {
      "source": "79c72327dd14466c4db3865902c8317f74bb4c56",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.26330410998461096
    },
    {
      "source": "79c72327dd14466c4db3865902c8317f74bb4c56",
      "target": "728afc51ac20d79133d8c747a2d18b01c6a6de5e",
      "weight": 0.24802124983385904
    },
    {
      "source": "79c72327dd14466c4db3865902c8317f74bb4c56",
      "target": "9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0",
      "weight": 0.25856075545641355
    },
    {
      "source": "79c72327dd14466c4db3865902c8317f74bb4c56",
      "target": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "weight": 0.3039734916877974
    },
    {
      "source": "bea84d4f28799628fa91585690088c00e8dca827",
      "target": "a1ce596ef67f28f433f3de1001774211d00b54f0",
      "weight": 0.3034060294503745
    },
    {
      "source": "bea84d4f28799628fa91585690088c00e8dca827",
      "target": "209c949e277081b8f2847cf3e66b90df26dcf179",
      "weight": 0.2639592684040181
    },
    {
      "source": "bea84d4f28799628fa91585690088c00e8dca827",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2602078404943656
    },
    {
      "source": "bea84d4f28799628fa91585690088c00e8dca827",
      "target": "87268ea5825cd65c1c3151d6ecc0973f267b3c68",
      "weight": 0.411701687787669
    },
    {
      "source": "bea84d4f28799628fa91585690088c00e8dca827",
      "target": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "weight": 0.3128548019035171
    },
    {
      "source": "bea84d4f28799628fa91585690088c00e8dca827",
      "target": "4ff175285ef575f4dc24a518869139382665c12e",
      "weight": 0.34712404012652875
    },
    {
      "source": "531762d327ac99a898f4976181c1c69e2e3076cb",
      "target": "be422ce2f64425f5c7bedf9a8498ab1e993060cc",
      "weight": 0.3659851024206231
    },
    {
      "source": "531762d327ac99a898f4976181c1c69e2e3076cb",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.09452207268564984
    },
    {
      "source": "531762d327ac99a898f4976181c1c69e2e3076cb",
      "target": "33fb671a3289027c84a71fc996f948195b1baeb4",
      "weight": 0.30057904422269466
    },
    {
      "source": "531762d327ac99a898f4976181c1c69e2e3076cb",
      "target": "7466087f3748165181b0463153008d39879d5879",
      "weight": 0.4553855687953291
    },
    {
      "source": "f9ac68dc1fdd070a65a71c739e7135361c0d3006",
      "target": "b826af7705a11f6fefc9452eed5db6309520f170",
      "weight": 0.5521848645216926
    },
    {
      "source": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "target": "be422ce2f64425f5c7bedf9a8498ab1e993060cc",
      "weight": 0.3099181290887027
    },
    {
      "source": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "target": "48020e5f1a0d5703f6169c20051eeb056194c25b",
      "weight": 0.4078328048609186
    },
    {
      "source": "14cfe2588311870325e2770c5159d3100d7031ea",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.318808577375658
    },
    {
      "source": "14cfe2588311870325e2770c5159d3100d7031ea",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.16745867599547598
    },
    {
      "source": "14cfe2588311870325e2770c5159d3100d7031ea",
      "target": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "weight": 0.31146985895150847
    },
    {
      "source": "f9cf8d53b1a157ab9dee16f03290d28865f3089a",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2708770353493193
    },
    {
      "source": "f9cf8d53b1a157ab9dee16f03290d28865f3089a",
      "target": "33fb671a3289027c84a71fc996f948195b1baeb4",
      "weight": 0.23545638874566277
    },
    {
      "source": "f9cf8d53b1a157ab9dee16f03290d28865f3089a",
      "target": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "weight": 0.335024826197621
    },
    {
      "source": "2902a67f9aebb115fc2b6cdf611910e72e896bdd",
      "target": "a1ce596ef67f28f433f3de1001774211d00b54f0",
      "weight": 0.5231792850164028
    },
    {
      "source": "2902a67f9aebb115fc2b6cdf611910e72e896bdd",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.29468132420856563
    },
    {
      "source": "2902a67f9aebb115fc2b6cdf611910e72e896bdd",
      "target": "d212c555293b81f845b3c99af4e922b0fcdb4290",
      "weight": 0.36335101901496725
    },
    {
      "source": "d2d056e705902d33d769206489d53e0659e376cc",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2651626801552386
    },
    {
      "source": "70da774b2b30397ee2f7e2abc819ed126641a70d",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.09566784724357795
    },
    {
      "source": "be422ce2f64425f5c7bedf9a8498ab1e993060cc",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2984164013104744
    },
    {
      "source": "be422ce2f64425f5c7bedf9a8498ab1e993060cc",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.1099181290887027
    },
    {
      "source": "28582980cc55e3ed002fae2cf0e9b9b92714694b",
      "target": "b826af7705a11f6fefc9452eed5db6309520f170",
      "weight": 0.3934146613874026
    },
    {
      "source": "28582980cc55e3ed002fae2cf0e9b9b92714694b",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.3177241453425398
    },
    {
      "source": "6618d8b3643745d60772d4ec522ad76204522f7d",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.26867508151722896
    },
    {
      "source": "9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0",
      "target": "728afc51ac20d79133d8c747a2d18b01c6a6de5e",
      "weight": 0.25366279320799656
    },
    {
      "source": "bcbee683ff34f87675448471d780541f7ae25ce9",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.05770171117523644
    },
    {
      "source": "b3f21af3032246b6fa87e05a6d9455433b25ce55",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2771290161697483
    },
    {
      "source": "48020e5f1a0d5703f6169c20051eeb056194c25b",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.423064534987527
    },
    {
      "source": "48020e5f1a0d5703f6169c20051eeb056194c25b",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.2078328048609186
    },
    {
      "source": "87268ea5825cd65c1c3151d6ecc0973f267b3c68",
      "target": "4ff175285ef575f4dc24a518869139382665c12e",
      "weight": 0.3385845309394121
    },
    {
      "source": "f418971afad1d44fb64610b91128a4eb6c3855ef",
      "target": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "weight": 0.27650768098059947
    },
    {
      "source": "36dd3bee303671d45c6ab4631c34b2dd67e19e69",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.27747970233510355
    },
    {
      "source": "36dd3bee303671d45c6ab4631c34b2dd67e19e69",
      "target": "c5b439fa6766e4d9dabf09d1b0d686311b494914",
      "weight": 0.2840617362716016
    },
    {
      "source": "36dd3bee303671d45c6ab4631c34b2dd67e19e69",
      "target": "1f24e041e10239cba8ff26ffcff4902343e55cab",
      "weight": 0.2552732018899291
    },
    {
      "source": "47cfe2c7ba31259ed8b005a348a48db4676279fa",
      "target": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "weight": 0.25163228610134464
    },
    {
      "source": "47cfe2c7ba31259ed8b005a348a48db4676279fa",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2691874636773277
    },
    {
      "source": "209c949e277081b8f2847cf3e66b90df26dcf179",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2619500847556578
    },
    {
      "source": "1f2462ad6ffef934b7470313ffc3d42a0af35c9c",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.3124336064886864
    },
    {
      "source": "728afc51ac20d79133d8c747a2d18b01c6a6de5e",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2733317808229234
    },
    {
      "source": "728afc51ac20d79133d8c747a2d18b01c6a6de5e",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.09017904883396939
    },
    {
      "source": "88b9e2bce0caadf7495490603f5292166e2a1860",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.25290236530432547
    },
    {
      "source": "88b9e2bce0caadf7495490603f5292166e2a1860",
      "target": "2e6813cad2e41c683277aa2d400dc2a2761309a2",
      "weight": 0.08127855277395572
    },
    {
      "source": "db5059dea1ee639dfc7eba751183ce3564a4b593",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2938130037613786
    },
    {
      "source": "63cc6260b838f2cc559715a9f68360edc743f50b",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.24797419442913834
    },
    {
      "source": "835d157e2c23d3577f23778ce051ab8d706babf6",
      "target": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "weight": 0.27482079658637637
    },
    {
      "source": "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129",
      "target": "33fb671a3289027c84a71fc996f948195b1baeb4",
      "weight": 0.3192906079874463
    },
    {
      "source": "59f40cf3eebd2cb6ad30363fa6abf1caea06555f",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2967821697368696
    },
    {
      "source": "d03cf8819aeff52708a70d506b87e50214af53b6",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2577662053052582
    },
    {
      "source": "33fb671a3289027c84a71fc996f948195b1baeb4",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.26381187065837464
    },
    {
      "source": "8cb280caa94c758e659adfb413b25a3d2e37a837",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.30470122935365657
    },
    {
      "source": "05a8b19f4b4ddd316eb959d6f68378842f1c65a2",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.30269990206407593
    },
    {
      "source": "400333890cf74f523068ab767a87fede2042131e",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.24132842957094097
    },
    {
      "source": "59fdf00e73e64dd9104ec4df010fc3bc4eac6c66",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.25229641933138053
    },
    {
      "source": "50864505777b344d2ee4b4d18880f3ba3ca58836",
      "target": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7",
      "weight": 0.2751212525125083
    }
  ]
}