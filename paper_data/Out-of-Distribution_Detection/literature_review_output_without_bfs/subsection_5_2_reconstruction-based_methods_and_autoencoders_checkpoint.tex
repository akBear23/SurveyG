\subsection{Reconstruction-Based Methods and Autoencoders}
Out-of-distribution (OOD) detection methods leveraging reconstruction errors operate on the fundamental premise that models trained exclusively on in-distribution (ID) data will reconstruct ID samples faithfully while struggling with OOD samples, leading to higher reconstruction errors. This section explores the evolution of such approaches, from classical autoencoders and their variants to advanced generative models and innovative clustering-based techniques. It encompasses both literal pixel-level reconstruction and conceptual extensions that assess semantic consistency or reconstruct features in a learned latent space.

Historically, autoencoders (AEs) served as a foundational model for anomaly detection, including OOD. The core idea involved training an AE to minimize reconstruction error on ID data, then using a high reconstruction error as a signal for OOD samples. However, a critical limitation quickly emerged: deep autoencoders, due to their high capacity, often learned to reconstruct various OOD samples surprisingly well, undermining the assumption that high reconstruction error reliably signals OOD data \cite{perera2019ocd}. Simpler linear methods, such as Principal Component Analysis (PCA), also utilize reconstruction error by projecting data onto a lower-dimensional subspace and measuring the deviation from this subspace. While straightforward, conventional PCA-based methods can be limited by their linearity and sensitivity to noise. To address this, \cite{guan2023dwv} proposed fusing a regularized PCA-based reconstruction error with other scoring functions, such as energy scores, demonstrating that even foundational reconstruction techniques can be enhanced through combination, achieving improved OOD detection results.

Variational Autoencoders (VAEs) offered a more principled generative approach by learning a latent distribution and providing a probabilistic reconstruction. \cite{cai2020lsi} leveraged VAEs within an Inductive Conformal Anomaly Detection (ICAD) framework for real-time OOD detection in Cyber-Physical Systems (CPS). By using VAEs to efficiently compute nonconformity scores based on reconstruction accuracy, they overcame the scalability limitations of traditional ICAD for high-dimensional inputs. This approach, while robust and providing calibrated false alarm rates, still relies on the VAE's ability to accurately model the ID distribution and may struggle if the VAE's generative capacity inadvertently extends to certain OOD patterns, or if the exchangeability assumption is violated.

Addressing the inherent flaw of autoencoders generalizing too well, \cite{zhou202250i} presented a significant "rethinking" of reconstruction autoencoder-based OOD detection. They formalized the preconditions for reconstruction error to be a valid uncertainty measure and introduced a novel framework centered on "layerwise semantic reconstruction." Instead of reconstructing raw pixels, their method reconstructs Activation Vector (AV) features from a pre-trained classifier, which are lower-dimensional and semantically rich. This is coupled with a maximally compressed latent space and a Normalized L2 Distance (NL2) metric, which normalizes reconstruction by the input's norm to counteract misleadingly small L2 errors for OOD samples. This comprehensive approach significantly enhanced the efficacy of autoencoder-based methods by focusing on semantic fidelity rather than pixel-level exactness. A key limitation, however, is its dependency on the quality and robustness of the pre-trained classifier used to extract the semantic features.

Further advancements in autoencoder architectures specifically designed for OOD detection include the multi-decoder autoencoder proposed by \cite{du2024kj8} for vocoder recognition in deepfake detection. This method employs a single encoder but multiple decoders, each specialized to reconstruct acoustic features corresponding to a specific in-distribution vocoder class. An input is classified as OOD if none of the class-specific decoders can satisfactorily reconstruct its features, effectively leveraging reconstruction error in a fine-grained manner. To enhance distinctiveness and constrain the encoder's output, they integrated contrastive learning and an auxiliary classifier. While innovative, this approach still relies on a predefined Mean Square Error (MSE) threshold for OOD classification, which requires careful tuning and might be sensitive to variations in reconstruction quality.

The advent of more sophisticated generative models, particularly diffusion models, further expanded the capabilities of reconstruction-based OOD detection by enabling more complex semantic consistency checks. \cite{gao2023kmk} proposed DiffGuard, a semantic mismatch-guided OOD detection method that utilizes pre-trained diffusion models. Unlike prior generative approaches that struggled with scalability, DiffGuard leverages the stable and flexible conditional generation of diffusion models. It detects OOD samples by measuring the dissimilarity between an input image and a new image synthesized by the diffusion model conditioned on the classifier's predicted label. This effectively highlights semantic mismatches for OOD inputs, making it scalable to large datasets like ImageNet. While powerful, DiffGuard's inference latency and computational cost can be substantial due to the iterative nature of diffusion models, and its performance is inherently tied to the accuracy of the underlying classifier's predictions. Similarly, diffusion models are being explored for OOD detection in specialized domains, such as digital pathology \cite{linmans2024pi9}, indicating their growing versatility.

Beyond direct image generation, reconstruction principles have been adapted to address scalability and performance for complex data modalities like text. \cite{gulati2024dbi} introduced a novel post-hoc OOD detection method that employs soft clustering with Non-Negative Kernel Regression (NNK-Means). This approach learns a compact dictionary of in-distribution representations, and OOD scores are derived from the reconstruction error of new data points against this dictionary. To mitigate hyperparameter sensitivity and improve efficiency, they developed Entropy-Constrained NNK-Means (EC-NNK-Means), which adaptively prunes less important dictionary atoms. This method effectively bridges the gap between the high performance of storage-intensive distance-based methods and the efficiency of classifier-based techniques, particularly for large language models and text data, by providing a scalable and storage-efficient way to model the ID manifold and detect deviations. However, the performance can still be sensitive to the choice of kernel and the dictionary size, requiring careful validation.

In conclusion, reconstruction-based OOD detection has evolved significantly from its early autoencoder roots. Researchers have moved beyond simple pixel-level reconstruction to focus on semantic fidelity, leveraging advanced autoencoder architectures, VAEs, and modern generative models like diffusion models for more robust density estimation and semantic mismatch detection. Furthermore, innovative techniques like soft clustering with non-negative kernel regression demonstrate a continuous effort to refine the concept of "reconstruction error" as an OOD signal, addressing critical challenges such as scalability and performance for complex data modalities like text. These advancements highlight a persistent drive to develop more accurate, efficient, and context-aware OOD detection systems, while also acknowledging the ongoing challenges related to computational expense, reliance on auxiliary components, and threshold sensitivity.