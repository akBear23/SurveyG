\subsection{Multi-Scale and Prototype-Based Feature Learning}

Advanced representation learning techniques are crucial for enhancing Out-of-Distribution (OOD) detection by moving beyond simplistic feature norm analyses to capture more nuanced aspects of in-distribution (ID) data. This subsection explores methods that leverage multi-scale representations, combining global and local features to provide richer context for OOD discrimination, and prototype-based learning, which models ID classes with a mixture of prototypes to account for intra-class variability. These approaches collectively aim to create more discriminative and fine-grained feature spaces for robust OOD detection.

A significant direction in this area involves integrating information from various scales within a neural network's architecture. Traditional OOD detection often relies on features from a single layer, typically the penultimate one, which can overlook valuable contextual information. \cite{zhang202312h} introduces Multi-scale OOD DEtection (MODE), a framework that explicitly leverages both global visual information and local region details. Their Attention-based Local PropAgation (ALPA) objective encourages locally discriminative representations during training, while a Cross-Scale Decision (CSD) function combines these multi-scale features at test time, significantly improving OOD detection by addressing limitations of single-scale global representations. Extending this concept to Vision-Language Models (VLMs), \cite{miyai2023591} proposes GL-MCM, which combines global features from CLIP with local visual-text alignments to achieve zero-shot OOD detection, offering flexibility in defining ID images in multi-object scenes. This method addresses the "contamination" of global features when OOD objects are present, a limitation of purely global approaches.

Other works also implicitly or explicitly utilize multi-scale information. \cite{song2022f5d} presents RankFeat, a post-hoc method that performs Singular Value Decomposition (SVD) on high-level feature maps to remove a dominant rank-1 component, observed to disproportionately influence OOD predictions. It further incorporates multi-scale fusion by combining scores from features at different network depths, demonstrating that diverse semantic information across layers can enhance OOD discrimination. Similarly, \cite{liu2022fdj} addresses pixel-wise OOD detection in semantic segmentation by leveraging intermediate features and a Context-robust Contrastive Learning (CoroCL) module. This approach, by operating at a pixel level and utilizing features from different depths, implicitly incorporates multi-scale information to learn residual patterns of anomalies. From a generative perspective, \cite{zhou202250i} rethinks reconstruction autoencoder-based OOD detection by proposing a layerwise semantic reconstruction framework. This method decomposes data certainty across different encoding layers, effectively using multi-scale features for reconstruction, and introduces a Normalized L2 Distance (NL2) to robustly measure reconstruction error, thereby creating a more maximally compressed and discriminative latent space.

Beyond multi-scale feature aggregation, prototype-based learning has emerged as a powerful paradigm for modeling the intricate structure of ID data, especially its intra-class variability. Traditional distance-based OOD methods often oversimplify ID classes by representing each with a single centroid, which fails to capture the inherent diversity within real-world data. To address this, \cite{lu20249d4} introduces Prototypic ALearning with a Mixture of prototypes (PALM), which models each ID class with multiple prototypes using a mixture of von Mises-Fisher (vMF) distributions in a hyperspherical embedding space. This allows for a more faithful and compact representation of intra-class diversity, leading to improved OOD detection by better separating ID and OOD samples. Building on the concept of prototypes, \cite{li2024rs5} proposes Dynamic Prototype Updating (DPU) for multimodal OOD detection. DPU dynamically adjusts multimodal prediction discrepancy intensification based on a sample's similarity to its class prototype, accounting for intra-class variations and preventing uniform discrepancy amplification from degrading ID accuracy. This method uses Cohesive-Separate Contrastive Training (CSCT) to build a robust representation space and dynamically refines prototypes using batch-wise variance. At an even finer granularity, \cite{vojivr202444c} introduces PixOOD for pixel-level OOD detection without requiring OOD training samples. PixOOD employs a novel incremental soft-to-hard data condensation algorithm to model complex intra-class variability using multiple etalons (prototypes) at the pixel level, achieving state-of-the-art results across diverse benchmarks.

Further advancements in learning discriminative and fine-grained feature spaces include methods that refine the underlying data representation. \cite{zaeemzadeh2021lmh} argues for embedding training data into a low-dimensional space where ID samples lie on a union of 1-dimensional subspaces, providing a compact representation that makes OOD samples less likely to occupy the same region. \cite{ammar2023pr1} leverages the Neural Collapse phenomenon, proposing NECO, which identifies OOD samples by projecting features onto the principal component space derived from ID data. This method exploits the observed ID/OOD orthogonality during neural network training to enhance OOD detection. \cite{liu2023zb3} introduces Neuron Activation Coverage (NAC), a statistical measure that quantifies the "coverage degree" of neuron states under ID training data. By formulating a novel neuron activation state that considers both raw output and gradient-based influence, NAC-UE achieves state-of-the-art OOD detection by identifying abnormal neuron behaviors in OOD samples. Lastly, \cite{fang2024lv2} addresses the linear inseparability of ID and OOD features by employing Kernel PCA (KPCA) with task-specific non-linear feature mappings, such as Cosine Mapping (CoP) and Cosine-Gaussian Mapping (CoRP). These mappings enable more effective separation of ID and OOD data in the transformed feature space, offering a computationally efficient alternative to traditional KPCA and k-Nearest Neighbors.

In conclusion, the progression from simpler feature norm analyses to multi-scale and prototype-based feature learning marks a significant step towards more robust OOD detection. These advanced techniques provide richer contextual understanding, better model intra-class diversity, and create more discriminative feature spaces. However, challenges remain, including the computational overhead of multi-scale feature extraction, the optimal determination and dynamic adaptation of prototype mixtures, and the generalizability of learned feature transformations to highly diverse and unforeseen OOD distributions. Future research could focus on developing more adaptive and computationally efficient mechanisms for these nuanced feature learning paradigms.