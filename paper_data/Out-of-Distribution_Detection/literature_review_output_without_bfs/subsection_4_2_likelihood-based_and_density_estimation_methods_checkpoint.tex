\subsection{Likelihood-Based and Density Estimation Methods}

Out-of-distribution (OOD) detection approaches that explicitly model the probability density of in-distribution (ID) data offer a principled alternative to heuristic confidence scores, aiming to identify atypical samples based on their divergence from the learned data manifold. These methods leverage deep generative models, such as Variational Autoencoders (VAEs) \cite{kingma2013auto} and Generative Adversarial Networks (GANs) \cite{goodfellow2014generative}, to learn the complex underlying distribution of ID data. The core idea is that OOD samples will exhibit low likelihood or high reconstruction error under this learned ID model, thereby providing a theoretical grounding for OOD detection by quantifying how typical a given sample is under the learned ID distribution. Early applications of VAEs and GANs for anomaly detection often relied on reconstruction error or the evidence lower bound (ELBO) as an OOD score \cite{an2015variational, schlegl2017unsupervised}.

Despite the theoretical appeal of density estimation, relying solely on raw likelihoods or reconstruction errors for OOD detection presents notable challenges. A seminal work by Nalisnick et al. \cite{nalisnick2019do} critically demonstrated the "bad likelihoods" problem, where state-of-the-art deep generative models, including VAEs and Normalizing Flows, often assign higher likelihoods to OOD inputs than to ID data. This counter-intuitive phenomenon undermines the direct utility of raw density estimates. The issue stems from the high-dimensional nature of data, where the typical set of a distribution (where most of the probability mass lies) may not coincide with the region of highest density, leading models to assign high likelihoods to "simple" OOD samples that fall outside the typical ID manifold but are easily reconstructed or have high density in regions irrelevant to the ID data's semantic content \cite{morningstar2020re9, osada20246an}. For instance, \cite{osada20246an} specifically investigates this phenomenon in Normalizing Flows, hypothesizing that less complex OOD images can concentrate in high-density regions of the latent space, leading to untrustworthy likelihood assignments. Indeed, comprehensive evaluations in complex domains like 3D medical image segmentation have highlighted the severe limitations of reconstruction-based anomaly detection methods, often finding them to be inferior to other self-supervised or confidence-based approaches \cite{vasiliuk20233w9}. This suggests that while generative models excel at learning the ID manifold, the direct interpretation of their reconstruction quality or estimated likelihood as a robust OOD score remains a significant hurdle, as simple reconstruction errors do not always capture the true typicality of a sample.

To address these limitations, research has explored more sophisticated techniques beyond simple reconstruction errors or raw likelihoods. One promising direction involves **tractable density estimators**, such as Normalizing Flows (NFs) \cite{rezende2015variational, dinh2014nice}. Unlike VAEs, which provide an approximate lower bound on the likelihood, NFs allow for exact and efficient computation of log-likelihoods, bypassing the "amortization gap" and offering more reliable density estimates. Early works explored NFs for OOD detection, leveraging their ability to model complex distributions and provide precise likelihoods \cite{nalisnick2019do}. More recently, \cite{zisselman2020cmx} introduced Deep Residual Flow for OOD detection, a novel flow architecture that learns the residual distribution from a base Gaussian distribution in the feature space of a pre-trained classifier, demonstrating significant improvements over Gaussian distribution models. Further advancing this, \cite{peng20243ji} proposed ConjNorm, a method for tractable density estimation that unifies density function design within the exponential family of distributions using Bregman divergence. ConjNorm devises an unbiased and analytically tractable estimator for the partition function using Monte Carlo-based importance sampling, overcoming a major computational challenge and achieving state-of-the-art performance in post-hoc OOD detection by providing more accurate density estimates.

Another critical approach to overcome "bad likelihoods" is the use of **likelihood ratios** and **typicality-based methods**. Instead of relying on the absolute likelihood under a single ID model, likelihood ratio tests compare the likelihood of a sample under an ID model versus a background or OOD model, providing a more discriminative score \cite{ren2019likelihood}. This contrastive approach helps to filter out OOD samples that might coincidentally have high likelihoods under the ID model but would have even higher likelihoods under a more general or OOD-specific model. Building on this, \cite{morningstar2020re9} introduced Density of States Estimation (DoSE), an unsupervised method that moves beyond direct model probabilities. DoSE leverages the "probability of the model probability" or, more generally, the frequency (typicality) of *multiple summary statistics* derived from a generative model (e.g., VAEs, Glow/NFs). By training nonparametric density estimators (like KDE or one-class SVMs) on these statistics, DoSE identifies atypical points even if they have high raw likelihoods, directly addressing the core failure mode of direct likelihood comparison in high dimensions. Similarly, energy-based models, which define an OOD score based on an energy function, can be seen as implicitly leveraging density differences. For example, \cite{hofmann2024gnx} introduced Energy-based Hopfield Boosting, which defines an OOD score by contrasting information from ID and auxiliary OOD memories, effectively creating a score that reflects the relative "energy" or typicality of a sample with respect to both distributions.

Recent advancements in deep generative models have also pushed the boundaries of likelihood-based OOD detection. A significant development, particularly for high-resolution volumetric data, is the application of Latent Diffusion Models (LDMs) for unsupervised 3D OOD detection \cite{graham20232re}. This approach employs a two-stage generative process, initially using a Vector Quantized Generative Adversarial Network (VQ-GAN) to compress 3D medical images into a latent representation. Subsequently, a Denoising Diffusion Probabilistic Model (DDPM) is trained on these compressed latent codes to learn the ID data distribution through an iterative denoising process. For OOD detection, an input is noised and then denoised by the LDM, with the OOD score derived from the reconstruction error (e.g., Mean Squared Error and perceptual similarity) between the original and reconstructed images. This LDM-based framework demonstrates superior performance over previous likelihood-based Latent Transformer Models (LTMs) by offering better memory scaling, reduced sensitivity to latent representation quality, and the ability to generate high-resolution, accurate spatial anomaly maps, which are crucial for precise localization of abnormalities in medical imaging \cite{graham20232re}. While powerful, this method notes reduced performance on certain low-intensity OOD classes, indicating that even advanced generative models can struggle with specific types of OOD data where reconstruction error might not perfectly correlate with OODness \cite{graham20232re}.

In conclusion, likelihood-based and density estimation methods hold immense promise for OOD detection by providing a principled framework grounded in probability theory. The field has evolved significantly from relying on raw likelihoods or simple reconstruction errors, which were found to be unreliable due to the "bad likelihoods" problem. Modern approaches emphasize the use of tractable density estimators like Normalizing Flows for exact likelihood computation and the development of more robust scores based on likelihood ratios or the typicality of multiple summary statistics from generative models. While recent advancements, such as Latent Diffusion Models, demonstrate impressive capabilities in modeling complex data distributions and generating high-resolution anomaly maps, the field continues to grapple with the challenge of translating these density estimates into robust and semantically meaningful OOD scores. Future research must focus on developing more robust likelihood-based metrics, exploring novel generative architectures that inherently yield more discriminative OOD indicators, and further understanding the interplay between image complexity, latent space density, and OOD detection performance, particularly in high-stakes applications where the consequences of misclassification are severe.