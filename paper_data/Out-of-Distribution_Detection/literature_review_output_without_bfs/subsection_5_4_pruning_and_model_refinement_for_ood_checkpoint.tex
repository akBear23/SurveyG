\subsection{Pruning and Model Refinement for OOD}

The inherent overconfidence of deep neural networks on out-of-distribution (OOD) samples poses a significant challenge for their reliable deployment in open-world scenarios. Addressing this, a distinct line of research focuses on refining or pruning neural network models, often as a post-training optimization, to improve their OOD detection capabilities. These techniques aim to mitigate overconfidence, enhance stability, and foster models that are inherently better at distinguishing novel inputs without necessarily relying on explicit OOD data during their primary training phase.

One prominent direction involves post-training refinement through the modification of neuron activations or feature representations. \cite{zhu2022oir} introduced Batch Normalization Assisted Typical Set Estimation (BATS) with Truncated Batch Normalization (TrBN), a plug-and-play module that rectifies neuron activations by clamping them within a "typical set" derived from Batch Normalization statistics. This post-hoc approach effectively makes the model more conservative, boosting OOD detection by mitigating the impact of extreme features. Building upon this concept, \cite{xu2023767} provided a theoretical foundation for optimal activation rectification with Variational Rectified Activation (VRA). Their work demonstrated that an optimal strategy involves not only suppressing abnormally high activations (as in TrBN) but also low ones, while amplifying intermediate activations, thereby offering a more generalized and theoretically grounded approach to feature-level refinement. Complementing these activation-based methods, \cite{song2022f5d} proposed RankFeat, a post-hoc technique that leverages spectral analysis of high-level features. RankFeat improves OOD detection by identifying and removing the dominant rank-1 component from feature maps, which is observed to disproportionately contribute to OOD overconfidence, thus refining the feature space for better discrimination.

Beyond modifying activations or features, direct pruning of model parameters and neurons has emerged as a powerful strategy. \cite{chen2024kl7} introduced Optimal Parameter and Neuron Pruning (OPNP), a training-free method that optimizes parameter and neuron pruning based on gradient sensitivity. OPNP identifies and removes both exceptionally sensitive (risky) and least sensitive (redundant) parameters and neurons by averaging the magnitude of energy score gradients over training samples. This targeted pruning reduces model complexity and overconfidence, leading to significant improvements in OOD detection performance without requiring any retraining or auxiliary OOD data.

While many methods focus on post-training adjustments, another crucial area explores pruning and refinement during the training process itself to build inherently more robust models. \cite{cheng20233yi} addressed the critical issues of OOD detection instability and overfitting during neural network training. Their Average of Pruning (AoP) method combines model averaging (e.g., Stochastic Weight Averaging) to achieve stable OOD performance by smoothing the loss landscape, with network pruning (via the Lottery Ticket Hypothesis) to alleviate overfitting by removing redundant and noisy features that cause overlap between in-distribution (ID) and OOD data. This holistic approach ensures that models are more stable and less prone to overconfidence on novel inputs from the outset. Further enhancing inherent OOD capabilities, \cite{wu20242p3} proposed a novel Separation Loss (`LSep`) that explicitly separates ID and OOD features in the latent space during training. Leveraging the Neural Collapse phenomenon, which describes the geometric structure of ID features, `LSep` constrains OOD features to lie in a subspace orthogonal to the principal subspace of ID features, thereby creating models inherently better at distinguishing novel inputs. Similarly, \cite{li2024n34} demonstrated the efficacy of Masked Image Modeling (MIM) as a pre-training objective for robust OOD detection. Their MOODv2 framework shows that MIM-pretrained models learn comprehensive, pixel-level ID representations that inherently create a larger and more exploitable domain gap between ID and OOD samples, leading to superior OOD detection without requiring explicit OOD data for the detection phase.

In conclusion, the landscape of pruning and model refinement for OOD detection spans both post-training optimizations and integrated training-time strategies. Post-hoc methods like activation rectification (\cite{zhu2022oir, xu2023767}) and feature modification (\cite{song2022f5d}) offer efficient ways to recalibrate existing models. More direct post-hoc pruning (\cite{chen2024kl7}) provides structural optimization without retraining. Crucially, training-time approaches (\cite{cheng20233yi, wu20242p3, li2024n34}) aim to embed OOD robustness directly into the model's learning process, fostering stability and inherently better discrimination of novel inputs. A key challenge remains in developing universally applicable methods that can adapt to diverse OOD scenarios without compromising in-distribution performance or incurring significant computational overhead during inference. Future research may explore more adaptive pruning strategies that dynamically adjust model complexity based on input uncertainty, or hybrid approaches that combine the benefits of both post-hoc efficiency and training-time robustness.