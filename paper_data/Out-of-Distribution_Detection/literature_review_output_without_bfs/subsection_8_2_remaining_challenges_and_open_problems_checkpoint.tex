\subsection*{Remaining Challenges and Open Problems}

Despite significant advancements, Out-of-Distribution (OOD) detection faces persistent challenges that hinder its widespread adoption and reliable deployment in real-world, open-set environments. A fundamental hurdle lies in the ambiguous definition and nuanced evaluation of OOD samples, particularly distinguishing between near-OOD and far-OOD instances. Current benchmarks often suffer from semantic ambiguities, ID contamination, and unintended covariate shifts, making it difficult to accurately assess a method's true OOD detection capability \cite{yang2023ckx}. For instance, \cite{long2024os1} highlights the "Sorites Paradox," where the boundary for "how different" an OOD sample must be is unclear, leading to a need for continuous measurement of shift degrees rather than binary classification. Similarly, \cite{ming2021wu7} demonstrates that spurious correlations in training data can severely degrade OOD detection performance, especially for "spurious OOD" samples that share non-causal features with in-distribution (ID) data. This issue is further complicated by the inconsistent treatment of covariate shift across different evaluation frameworks, with some considering it OOD and others as ID, as discussed by \cite{yang2022it3} and \cite{averly20239rv}. The lack of standardized, disentangled benchmarks, particularly for complex domains like 3D medical imaging, remains a critical gap, as underscored by \cite{zimmerer2022rv6} and \cite{vasiliuk20233w9}, which show that even state-of-the-art methods perform poorly or inconsistently in these safety-critical applications. The survey by \cite{miyai20247ro} further emphasizes the blurred boundaries and lack of a unified taxonomy for OOD and related tasks in the era of Vision-Language Models (VLMs), contributing to evaluation confusion.

Another significant challenge is the pervasive reliance on auxiliary OOD data for training, a paradigm known as Outlier Exposure (OE). While methods like Mixture Outlier Exposure \cite{zhang20212tb}, Diverse Outlier Sampling \cite{jiang2023vzb}, and diverseMix \cite{yao2024epq} leverage auxiliary data to improve OOD detection, their effectiveness is inherently tied to the availability, quality, and diversity of this auxiliary data. \cite{wang2024is1} critically notes that OE surprisingly struggles to scale to large datasets due to the difficulty of finding suitable auxiliary OOD data that covers the vast space of potential distribution shifts. Moreover, \cite{bitterwolf2022rw0} provides theoretical evidence that many OE methods are asymptotically equivalent to a simple binary discriminator, suggesting that performance gains often stem from better estimation procedures or choice of auxiliary data rather than fundamentally new principles. The complexity of generating effective synthetic outliers, as explored by Virtual Outlier Smoothing \cite{nie2024ghv} and local adversarial attacks \cite{besnier2021jgn}, or handling class imbalance within auxiliary OOD data \cite{choi202367m}, adds further overhead. To circumvent this reliance, a growing body of research focuses on OOD-free methods, such as rethinking reconstruction autoencoders \cite{zhou202250i}, leveraging generic representations \cite{vojr2023ee1}, or applying post-hoc pruning \cite{chen2024kl7}. However, some of these approaches, particularly density-based methods, can incur high computational costs during inference due to the intractability of normalization constants \cite{peng20243ji}. Other advanced approaches, like ensemble methods for semantic segmentation \cite{besnier2021jgn} or certain generative models \cite{gao2023kmk}, also face computational intensity challenges, limiting their real-time applicability.

The scalability and generalizability of OOD detection solutions across diverse and unpredictable real-world distribution shifts remain a critical gap between laboratory performance and practical deployment. For large models and datasets, methods must be efficient. For instance, while diffusion models show promise, DiffGuard \cite{gao2023kmk} was developed to overcome the prior scalability issues of cGAN-based generative methods. Similarly, for graph-structured data, methods like GOODAT \cite{wang2024es5} aim for test-time, training data-independent solutions to avoid the computational and data access burdens of traditional approaches, which often struggle with the lack of auxiliary OOD data or pre-trained generative models for graphs \cite{wang2025xwm}. In the context of Vision-Language Models (VLMs), zero-shot OOD detection, as pursued by GL-MCM \cite{miyai2023591} and Outlier Label Exposure \cite{ding20242m0}, aims to improve scalability by avoiding per-task training, but still grapples with the lack of explicit OOD knowledge or the presence of spurious OOD features \cite{yu20249dd}. The challenge of "pattern collapse" in generative language models for mathematical reasoning further exemplifies the domain-specific hurdles to generalizability \cite{wang2024rej}. Moreover, methods often struggle with fine-grained distinctions, such as differentiating OOD from tail classes in long-tailed recognition \cite{miao2023brn, wei2023f15} or handling intra-class variability in multimodal data \cite{li2024rs5}. The inherent limitations of current evaluation benchmarks, as highlighted by \cite{borlino20245ku} for foundation models, mean that even seemingly high-performing lab results may not translate to reliable performance in unpredictable real-world scenarios, emphasizing the urgent need for more robust, theoretically grounded \cite{fang20249gd, du2024aea}, and truly generalizable solutions.

In conclusion, the field of OOD detection is still grappling with fundamental issues ranging from the precise definition and robust evaluation of OOD samples to the practical constraints of data availability and computational efficiency. The persistent challenges of distinguishing near-OOD from far-OOD, ensuring scalability for large models, reducing reliance on auxiliary OOD data, and mitigating computational intensity collectively underscore a significant gap between current laboratory performance and the demands of practical, safety-critical deployments. Future research must prioritize the development of theoretically sound, resource-efficient, and context-aware solutions that can reliably generalize across the diverse and unpredictable distribution shifts encountered in real-world applications.