\subsection{Outlier Exposure and Synthetic OOD Generation}

Out-of-Distribution (OOD) detection aims to equip models with the crucial ability to identify inputs that deviate from their training distribution, a necessity for reliable deployment in open-world scenarios. While purely post-hoc methods analyze a trained model's outputs, Outlier Exposure (OE) represents a powerful training strategy that explicitly teaches models to distinguish in-distribution (ID) from OOD samples by exposing them to auxiliary OOD data during training. This paradigm is often complemented by methods that synthesize diverse and informative OOD examples, thereby enhancing the model's capacity to form tighter ID boundaries and improve OOD discrimination.

The theoretical underpinnings of OE reveal that many such methods asymptotically converge to a binary discriminator between in-distribution and the auxiliary OOD data \cite{bitterwolf2022rw0}. This insight underscores the critical importance of the quality and diversity of the auxiliary OOD data. Building on this, early approaches to synthetic OOD generation focused on mixing strategies. \textcite{zhang20212tb} introduced Mixture Outlier Exposure (MixOE), which generates "virtual" outliers by mixing ID data with auxiliary OOD samples. This technique effectively expands the coverage of the feature space, enabling more robust OOD detection, particularly in challenging fine-grained environments where OOD samples are semantically close to ID data. Similarly, \textcite{yang2023pre} proposed MixOOD, an enhanced Mixup-based strategy that generates augmented images from ID data to serve as auxiliary OOD, demonstrating its plug-and-play capability with various threshold-based OOD detection methods. To bolster robustness against adversarial attacks, \textcite{chen2020mbk} developed Adversarial Learning with inlier and Outlier Exposure (ALOE), which generates adversarial outliers by maximizing KL-divergence to a uniform distribution, thus explicitly training the model to reject perturbed OOD inputs. Furthermore, \textcite{yu2022egq} utilized Jigsaw puzzles of ID images to create "pseudo OOD" samples, which are then used to select optimal intermediate feature blocks for OOD detection, circumventing the need for real OOD data during development.

The challenge of limited diversity and representativeness in auxiliary OOD datasets led to more sophisticated sampling and generation strategies. \textcite{jiang2023vzb} introduced Diverse Outlier Sampling (DOS), which addresses the bias of uncertainty-based sampling by clustering normalized latent features of auxiliary OOD data and actively selecting the most informative outliers from each cluster. This ensures a broader representation of the OOD space, leading to more globally compact decision boundaries. Extending this, \textcite{yao2024epq} presented `diverseMix`, a theoretically-guaranteed mixup strategy that dynamically adjusts interpolation to generate novel and distinct auxiliary outliers, with formal proofs demonstrating its ability to enhance diversity and reduce generalization error. Addressing the often-overlooked issue of class imbalance within auxiliary OOD data, \textcite{choi202367m} proposed a balanced energy regularization loss. This loss adaptively applies stronger regularization to auxiliary samples from majority classes, leading to improved OOD detection in scenarios like semantic segmentation and long-tailed classification. In a different vein, \textcite{nie2024ghv} introduced Virtual Outlier Smoothing (VOSo), which constructs virtual outliers by perturbing semantic regions of ID samples in the image space, assigning them dynamic soft labels based on perturbation extent. This approach creates a smoother transition in decision boundaries, enhancing uncertainty estimation without relying on external OOD datasets. \textcite{hofmann2024gnx} further refined outlier sampling with Hopfield Boosting, leveraging a novel energy function derived from Modern Hopfield Networks to adaptively sample "hard" outliers that lie close to the ID-OOD decision boundary.

Beyond general classification, synthetic OOD generation has been tailored for specialized contexts. In semantic segmentation, \textcite{besnier2021jgn} developed ObsNet+LAA, which generates OOD-like training data through local adversarial attacks on in-distribution images. This creates synthetic failure modes to train an auxiliary OOD detector, achieving both speed and accuracy. For long-tailed recognition, where distinguishing tail classes from OOD is difficult, \textcite{wei2023f15} proposed Context-rich Tail Class Augmentation, overlaying tail-class images onto OOD data to improve generalization. Similarly, \textcite{miao2023brn} introduced Calibrated Outlier Class Learning (COCL), which leverages auxiliary OOD data within a debiased large margin learning framework to better separate OOD from both head and tail ID classes. The advent of generative models, particularly diffusion models, has also opened new avenues. \textcite{gao2023kmk} presented DiffGuard, which uses pre-trained diffusion models to synthesize images conditioned on a classifier's predicted label. OOD samples are then identified by measuring the semantic mismatch between the original and synthesized images, demonstrating a powerful application of synthetic data generation for OOD scoring. In 3D LiDAR object detection, \textcite{ksel20246fe} tackled data scarcity by generating synthetic OOD objects through unusual scaling perturbations of known ID objects, providing a realistic training signal for OOD detection. Multimodal OOD detection also benefits from synthetic data; \textcite{dong2024a8k} proposed Nearest Neighbor Prototype-based Mixup (NP-Mix) to generate outliers by leveraging nearest neighbor class prototypes, exploring broader feature spaces. \textcite{zhang2024cx0} (MIntOOD) generates pseudo-OOD data through convex combinations of ID features to improve multimodal intent understanding.

Vision-Language Models (VLMs) have further expanded the scope of synthetic OOD generation. \textcite{ding20242m0} introduced Outlier Label Exposure (OLE), which uses auxiliary outlier class labels as pseudo OOD text prompts and generates "hard outlier prototypes" by mixing fringe ID embeddings with refined outlier prototypes. This creates synthetic OOD knowledge in the textual embedding space. \textcite{li20245b6} proposed NegPrompt, a method that learns transferable "negative prompts" for each ID class using only ID training data. These negative prompts implicitly define OOD boundaries by representing characteristics contrary to ID classes, effectively synthesizing textual representations of "non-ID" for OOD discrimination. \textcite{yu20249dd} developed Self-Calibrated Tuning (SCT) for VLMs, which uses ID-irrelevant local context as surrogate OOD data for regularization during prompt tuning, adaptively balancing ID classification and OOD regularization based on prediction uncertainty. Finally, \textcite{liu20245e5} introduced a perturbation-guided spurious synthesis strategy to generate high-quality adversarial samples for training hierarchical contexts, enhancing OOD detection in VLMs. Even Masked Image Modeling (MIM), as explored by \textcite{li2024n34} (MOODv2), contributes to OOD detection by learning comprehensive, pixel-level ID representations. This robust ID modeling implicitly creates a larger domain gap, making OOD samples inherently more distinguishable during reconstruction, thus serving as an indirect but powerful form of synthetic OOD generation.

In conclusion, Outlier Exposure and synthetic OOD generation have evolved from simple mixing techniques to sophisticated, theoretically-grounded strategies that adaptively sample or generate diverse and informative outliers. These methods are crucial for training models that can form tighter in-distribution boundaries and achieve superior OOD discrimination, often with theoretical guarantees for diversity. While significant progress has been made in addressing limitations such as auxiliary data diversity, class imbalance, and domain-specific challenges, future work must continue to explore the representativeness of synthetic data, scalability to truly open-ended OOD types, and the integration of these techniques with emerging foundation models for even more robust and reliable AI systems.