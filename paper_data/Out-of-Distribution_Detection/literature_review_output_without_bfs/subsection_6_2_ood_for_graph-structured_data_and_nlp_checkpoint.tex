\subsection{OOD for Graph-Structured Data and NLP}
Out-of-distribution (OOD) detection in graph-structured data and Natural Language Processing (NLP) presents unique challenges that traditional image-based methods often fail to address, necessitating specialized approaches that account for the relational nature of graphs and the sequential, semantic complexities of text. These domains push the boundaries of OOD applicability by requiring models to understand intricate structural dependencies and nuanced semantic meanings.

For graph-structured data, the core challenge lies in defining and detecting OOD samples when data is inherently relational and often lacks explicit labels. Pioneering work by \cite{liu202227x} introduced \texttt{GOOD-D}, a self-supervised framework for unsupervised graph-level OOD detection. This method addresses the limitations of traditional graph contrastive learning (GCL) augmentations, which can inadvertently introduce OOD-like samples, by proposing perturbation-free graph data augmentation and hierarchical contrastive learning at node, graph, and group levels to capture comprehensive in-distribution (ID) patterns. Building on the need for unsupervised graph OOD, \cite{wang2025xwm} proposed \texttt{GOLD}, an implicit adversarial latent generation framework. \texttt{GOLD} tackles the critical limitation of requiring auxiliary OOD data for exposure-based methods by implicitly synthesizing pseudo-OOD samples solely from ID training data, enhancing OOD detection without external outliers.

Addressing the practical constraints of real-world deployment, \cite{wang2024es5} introduced \texttt{GOODAT}, a novel approach for test-time graph OOD detection. This method is plug-and-play, operates without access to original training data, and requires no modifications to the pre-trained Graph Neural Network (GNN) architecture, overcoming the computational and data-dependency limitations of prior methods by leveraging a graph masker guided by the Graph Information Bottleneck principle. Furthermore, to provide a unified evaluation framework for the fragmented fields of graph anomaly detection and graph OOD detection, \cite{wang2024q01} presented \texttt{UB-GOLD}. This comprehensive benchmark unifies unsupervised graph-level anomaly detection (GLAD) and OOD detection (GLOD) across 35 datasets and four distinct scenarios, facilitating a systematic comparison of methods and highlighting the inherent challenges in distinguishing various types of graph-level distribution shifts.

In the realm of Natural Language Processing, OOD detection faces distinct challenges due to the discrete nature of text, complex output structures, and the paramount importance of semantic understanding. A comprehensive survey by \cite{lang20237w3} highlights these NLP-specific considerations, categorizing methods based on OOD data availability and emphasizing the role of pre-trained transformer models in learning robust representations for semantic shift detection. Leveraging the vast world knowledge of Large Language Models (LLMs) to address semantic OOD, \cite{dai2023mhn} explored multi-modal OOD detection by integrating LLM-generated descriptive features. Critically, this work introduces a novel consistency-based uncertainty calibration method to mitigate LLM hallucinations, which can otherwise degrade OOD performance, thus enabling the selective and safe integration of LLM knowledge.

Extending the application of LLMs for OOD detection in zero-shot settings, \cite{cao20246gj} proposed Envisioning Outlier Exposure (EOE). EOE utilizes LLMs to "envision" potential outlier class labels based on visual similarity to ID classes, effectively generating synthetic outlier exposure without requiring actual OOD data. This approach, combined with a novel OOD score function, significantly improves detection performance across far, near, and fine-grained OOD scenarios, demonstrating how LLMs can bridge the gap between theoretical benefits of OOD knowledge and practical data unavailability. For highly specialized NLP tasks, such as mathematical reasoning, \cite{wang2024rej} introduced the Trajectory Volatility (TV) Score for OOD detection in Generative Language Models (GLMs). This method addresses the unique "pattern collapse" phenomenon in mathematical reasoning, where distinct samples converge in static embedding spaces, by focusing on the dynamic embedding trajectory volatility across GLM layers, showcasing a specialized solution for complex sequential and semantic challenges.

The literature demonstrates a clear progression towards more sophisticated and domain-aware OOD detection methods for graphs and NLP. While significant strides have been made in developing unsupervised, test-time, and LLM-enhanced solutions, a persistent challenge remains in creating truly universal OOD detectors that are robust to the full spectrum of semantic and covariate shifts without requiring extensive domain-specific engineering or auxiliary OOD data. Future work could focus on developing more generalized frameworks that can adapt to diverse data structures and semantic complexities with minimal human intervention, potentially by further exploring the intrinsic properties of foundation models and their emergent capabilities for uncertainty quantification.