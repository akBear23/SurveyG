\subsection{OOD Detection in Semantic Segmentation and 3D Data}

Out-of-distribution (OOD) detection presents specialized challenges in dense prediction tasks like semantic segmentation and for complex 3D data, such as LiDAR point clouds and medical images, where unique structural and contextual properties necessitate tailored solutions. Unlike image classification, these domains require pixel-wise or object-level OOD identification, often exhibiting distinct OOD patterns.

For semantic segmentation, a key challenge is to detect OOD pixels without compromising the primary segmentation task. \cite{liu2022fdj} addresses this with Residual Pattern Learning (RPL), an external module that decouples OOD detection from the segmentation network. RPL leverages intermediate features and employs Context-robust Contrastive Learning (CoroCL) to enhance generalization across diverse scene contexts, overcoming limitations of prior re-training methods that often degrade inlier accuracy. Complementing this, \cite{besnier2021jgn} proposes ObsNet+LAA, an observer network trained using local adversarial attacks to generate OOD-like training data. This approach enables fast and accurate pixel-wise OOD detection by learning from localized failure modes, addressing the scarcity of real OOD training samples. Furthermore, real-world deployments of segmentation models face dynamic environmental changes. \cite{gao2023epm} introduces ATTA (Anomaly-aware Test-Time Adaptation), a dual-level framework that adapts to both domain and semantic shifts at test time. ATTA selectively updates Batch Normalization statistics and uses an anomaly-aware self-training loss to maintain performance under covariate shifts while detecting novel objects. When auxiliary OOD data is utilized, \cite{choi202367m} identifies and mitigates the overlooked problem of class imbalance within these datasets. Their balanced energy regularization loss adaptively applies stronger regularization to majority OOD classes, leading to improved performance in semantic segmentation tasks. Moving towards more general solutions, \cite{vojivr202444c} presents PixOOD, a pixel-level OOD detection method that remarkably does not require OOD training samples. PixOOD models intra-class variability using a novel incremental soft-to-hard data condensation algorithm and formulates OOD detection as a calibrated Neyman-Pearson task, demonstrating state-of-the-art performance across diverse domains like road anomaly detection and industrial inspection.

OOD detection in 3D data, particularly medical imaging and LiDAR, introduces its own set of complexities due to data sparsity, high dimensionality, and the critical nature of applications. The need for robust benchmarks in medical imaging was highlighted by \cite{zimmerer2022rv6} with the introduction of the MOOD 2020 challenge. Building on this, \cite{vasiliuk20233w9} critically evaluates state-of-the-art OOD methods for 3D medical image segmentation, revealing their severe limitations and proposing a simple yet highly effective Intensity Histogram Features (IHF) baseline that often outperforms complex deep learning approaches. This underscores the necessity for solutions tailored to the unique properties of medical data. For unsupervised 3D OOD detection in high-resolution medical data, \cite{graham20232re} proposes using Latent Diffusion Models (LDMs). This innovative approach scales Denoising Diffusion Probabilistic Models (DDPMs) to 3D by first compressing data with a VQ-GAN, overcoming memory constraints of prior methods and producing high-resolution, accurate spatial anomaly maps. Addressing the inconsistent performance of feature-based methods like Mahalanobis distance in medical contexts, \cite{anthony2023slf} conducts a layer-wise analysis, demonstrating that optimal detection layers vary significantly with the OOD pattern. They introduce Multi-branch Mahalanobis (MBM), a robust framework employing multiple depth-specific detectors, which substantially improves OOD detection for unseen medical anomalies. A comprehensive overview of OOD detection in medical image analysis, including a structured taxonomy of distributional shifts and solution frameworks, is provided by the survey from \cite{hong2024xls}, which is crucial for guiding future research in this specialized domain.

For LiDAR-based 3D object detection, where real OOD data is scarce, \cite{ksel20246fe} tackles the problem by generating synthetic OOD objects through geometric perturbations of known in-distribution objects. Their post-hoc multilayer perceptron (MLP) approach, combined with a novel, realistic evaluation protocol for nuScenes, offers a practical solution for identifying unknown foreground objects in autonomous driving scenarios. Beyond specific 3D modalities, the principles of multimodal OOD detection are increasingly relevant for complex sensor setups. \cite{dong2024a8k} introduces the MultiOOD benchmark and the Agree-to-Disagree (A2D) algorithm, which leverages inter-modal prediction discrepancies (e.g., between video and audio) to enhance OOD detection. Further refining this, \cite{li2024rs5} proposes Dynamic Prototype Updating (DPU), a plug-and-play framework that adaptively intensifies multimodal prediction discrepancies based on each sample's similarity to its class prototype, thereby accounting for intra-class variability and improving robustness in multimodal settings.

In conclusion, significant strides have been made in adapting OOD detection to the intricacies of semantic segmentation and 3D data. Solutions range from decoupling OOD detection from the primary task and leveraging local adversarial attacks to test-time adaptation for domain shifts and generative models for complex 3D data. The emphasis on synthetic OOD generation, handling auxiliary data imbalances, and developing OOD-sample-free pixel-level methods highlights the field's maturity. However, challenges persist in achieving universal context robustness, ensuring reliable performance across the vast diversity of real-world OOD patterns, and developing truly generalizable solutions that do not rely on any form of OOD data or strong assumptions about data distributions. Future research will likely focus on more sophisticated generative models, adaptive learning strategies that account for nuanced intra-class variability, and robust evaluation protocols that truly reflect the unpredictability of real-world OOD scenarios in these complex domains.