\subsection{Categorizing Distribution Shifts: Covariate, Semantic, and Spurious OOD}

The efficacy of Out-of-Distribution (OOD) detection hinges on moving beyond a simplistic binary definition to embrace the diverse nature of real-world distribution shifts. A nuanced understanding of these categories—covariate, semantic, and spurious OOD—is paramount for developing robust detection mechanisms and designing comprehensive benchmarks.

Early work highlighted the challenge posed by spurious correlations, where models learn to rely on statistically informative but non-causal features, leading to overconfident predictions on OOD inputs. \cite{ming2021wu7} formally introduced the concept of "spurious OOD," distinguishing it from conventional OOD by defining samples that contain environmental (spurious) features but lack the invariant features essential for in-distribution (ID) labels. Their theoretical and empirical analysis demonstrated that increasing spurious correlation in training data significantly degrades OOD detection performance, particularly for spurious OOD samples, which remain challenging to detect due to the model's reliance on these non-causal cues.

Building on the recognition of diverse shifts, \cite{yang2022it3} introduced the "Full-Spectrum OOD (FS-OOD)" problem, explicitly distinguishing between semantic shift (novel classes or concepts) and covariate shift (changes in input features while the label-conditional distribution remains constant). The authors proposed the SEM score function, designed to be sensitive only to semantic shifts and robust to covariate shifts, and developed new benchmarks (DIGITS, OBJECTS, COVID) with fine-grained categorizations to evaluate methods in this more realistic setting. This work underscored that many existing OOD methods struggle to differentiate between true semantic novelty and mere appearance variations.

Further dissecting the complexities of OOD evaluation, \cite{yang2023ckx} critically analyzed existing ImageNet-based OOD benchmarks, revealing significant shortcomings such as ID contamination, semantic ambiguities, and unintended covariate shifts. To address this, they meticulously curated `ImageNet-OOD`, a clean semantic shift dataset, and demonstrated that many state-of-the-art OOD detection algorithms are disproportionately sensitive to covariate shifts rather than genuine semantic novelty. This finding challenged the perceived efficacy of complex OOD detectors, suggesting their performance gains often stemmed from exploiting covariate shifts rather than truly identifying new classes.

Complementing these data-centric definitions, \cite{averly20239rv} proposed a "Model-Specific OOD (MS-OOD)" framework, which unifies the detection of semantic shift, covariate shift, and even misclassified in-distribution examples. This framework defines OOD based on whether a *deployed machine learning model* is unable to correctly predict an example, thus offering a nuanced, context-dependent definition of OOD that accounts for the model's actual performance. This perspective highlights that the "OOD" status of a sample can be dynamic and model-dependent, rather than solely an intrinsic property of the data. The practical relevance of these distinctions is further emphasized by \cite{hong2024xls}, which, in a comprehensive survey on OOD detection in medical image analysis, explicitly categorizes distributional shifts into semantic, covariate, and contextual shifts, providing a structured framework for understanding anomalies in high-stakes clinical settings.

The evolution of OOD understanding also extends to more granular evaluations. \cite{long2024os1} introduced the "Sorites Paradox" in OOD evaluation, arguing that current benchmarks, by relying on binary semantic labels, fail to capture the continuous "degree" of shift. They proposed the "Incremental Shift OOD (IS-OOD)" benchmark and the Language Aligned Image feature Decomposition (LAID) method, which leverages CLIP to decompose image features into distinct semantic and covariate components. This allows for evaluating OOD detection methods across incremental levels of both semantic and covariate shifts, providing a more nuanced understanding of their sensitivities. Similarly, \cite{wang2024is1} provided a critical analysis of OOD detection and Open-Set Recognition (OSR), proposing a conceptual framework to disentangle semantic and covariate shifts and introducing a new large-scale benchmark for this purpose. Their findings revealed that magnitude-aware scoring rules consistently show promise across tasks, often due to the lower feature magnitude of "unfamiliar" examples, while methods like Outlier Exposure struggle to scale effectively to large datasets due to the inherent difficulty in representing diverse shifts.

In conclusion, the field has moved significantly beyond a simplistic binary view of OOD, recognizing the critical need to differentiate between covariate, semantic, and spurious shifts. Works such as \cite{ming2021wu7}, \cite{yang2022it3}, and \cite{yang2023ckx} have been instrumental in defining and disentangling these categories, while \cite{averly20239rv} and \cite{hong2024xls} have provided unifying frameworks and domain-specific applications. The development of more sophisticated benchmarks by \cite{long2024os1} and \cite{wang2024is1} that account for continuous and disentangled shifts is crucial. Unresolved challenges remain in developing methods that are truly robust to covariate shifts while being highly sensitive to semantic novelty, and in creating scalable benchmarks that accurately reflect the full spectrum of real-world OOD scenarios.