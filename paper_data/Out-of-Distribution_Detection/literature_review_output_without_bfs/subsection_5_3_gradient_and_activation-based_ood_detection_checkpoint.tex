\subsection{Gradient and Activation-Based OOD Detection}

Out-of-distribution (OOD) detection methods that leverage the internal dynamics of neural networks, such as gradients or activation patterns, offer a powerful avenue to discern anomalous inputs beyond mere output probabilities. These techniques exploit the observation that OOD inputs often elicit distinct internal responses compared to in-distribution (ID) samples, providing a deeper, more mechanistic insight into model behavior. By analyzing how information flows and is transformed within the network, these methods aim to uncover subtle anomalies that might be missed by examining only the final output layer.

A primary category of these methods focuses on the **statistical and density-based analysis of activations**. Early approaches sought to characterize the distribution of internal features. \cite{zisselman2020cmx} proposed Deep Residual Flow, which models feature activations using normalizing flows. This approach offers a more expressive representation of the ID distribution compared to traditional Gaussian models, allowing for more nuanced anomaly detection. Building on this, \cite{cook2024hyb} further explored feature density estimation via normalizing flows, demonstrating a fully unsupervised, post-hoc method that trains a lightweight auxiliary flow on features. This method showed strong performance for far-OOD detection, highlighting the potential of learning complex feature distributions. Similarly, \cite{dong2021swz} introduced Neural Mean Discrepancy (NMD), which quantifies the deviation of activation means from training data, efficiently leveraging statistics stored in Batch Normalization layers. This provides a simple yet effective statistical measure of abnormality. Expanding on statistical distance, \cite{gomes2022zyv} presented IGEOOD, an information geometry approach that applies the Fisher-Rao distance to measure dissimilarity between probability distributions derived from latent features. By modeling latent representations as a mixture of Gaussian PDFs, IGEOOD offers a unified framework that can analyze the statistical divergence of internal feature distributions, providing a more robust measure of OODness. These methods collectively demonstrate that a detailed understanding of the statistical properties of internal activations can yield significant mechanistic insights into how OOD inputs perturb the model's learned representations.

Another significant line of research focuses on **rectifying or gating activation patterns** to explicitly amplify OOD signals. The underlying mechanistic insight here is that OOD inputs often trigger "abnormal" or "extreme" activations that can be suppressed or enhanced to improve discrimination. \cite{zhu2022oir} proposed Batch Normalization Assisted Typical Set Estimation (BATS) with Truncated BN (TrBN), a post-hoc method that rectifies deep features by clamping activations. This process effectively pushes features into their "typical set," mitigating the negative impact of extreme features on uncertainty estimation. While effective, such methods were often heuristic. Addressing this, \cite{xu2023767} provided a theoretical foundation for optimal activation rectification, deriving a variational rectified activation (VRA and VRA+) function. Their work mechanistically demonstrated that optimal OOD separation requires not only suppressing abnormally high activations (as in prior heuristic methods like ReAct) but also suppressing abnormally low activations and amplifying intermediate ones, leading to state-of-the-art performance. This theoretical grounding transforms activation rectification from a heuristic trick into a principled approach for enhancing OOD signals by actively shaping the internal feature space.

Beyond simple statistics and rectification, methods have explored more intricate **advanced feature space pattern analysis**. These techniques delve into the structural and geometric properties of intermediate feature maps. \cite{yu2022egq} introduced FeatureNorm, which utilizes the channel-wise averaged L2-norm of *rectified* feature maps from *intermediate* convolutional blocks. Their key mechanistic insight was demonstrating that earlier layers can offer superior OOD separation compared to the last layer, which often exhibits an "overconfidence issue" for OOD inputs. This highlights that OOD signals are not uniformly distributed across layers. Taking a spectral approach, \cite{song2022f5d} proposed RankFeat, which performs Singular Value Decomposition on high-level feature maps and removes the dominant rank-1 component. This method leverages the observation that OOD features tend to have a significantly larger dominant singular value, and its removal disproportionately affects OOD predictions, providing a mechanistic understanding of how OOD inputs alter the principal components of feature representations. Further leveraging feature space geometry, \cite{ammar2023pr1} introduced NECO, which exploits the "ID/OOD Orthogonality" property of Neural Collapse. NECO projects feature vectors onto the principal component space derived from ID training data, using the relative norm of this projection as an OOD score. This method offers a geometric interpretation of OOD detection, where OOD samples deviate from the orthogonal structure learned by ID data, providing a mechanistic link between model collapse and OOD discrimination.

A distinct and increasingly important category of methods focuses on **gradient-based OOD detection**, which probes the model's sensitivity and decision-making process. These methods offer a direct mechanistic insight into how the model reacts to OOD inputs by analyzing the derivatives of its outputs or internal states with respect to inputs or parameters. \cite{behpour2023x13} proposed GradOrth, which identifies OOD data by computing the norm of the gradient projection onto a low-rank subspace derived from important ID parameters. This method leverages the insight that crucial discriminative features for OOD data reside in the gradient subspace of ID data, indicating a mechanistic difference in how OOD inputs activate these critical directions. Expanding on gradient analysis, \cite{chen2023za1} introduced GAIA (Gradient Abnormality Inspection and Aggregation), which quantifies "abnormality" in gradient-based attribution results (input gradients) for OOD detection. GAIA identifies two forms of abnormality: zero-deflation (abnormal non-zero density) and channel-wise average abnormality. This provides a novel mechanistic perspective by linking model interpretability to OOD detection, suggesting that OOD inputs lead to "meaningless" or "noisy" explanations. Bridging activations and gradients, \cite{liu2023zb3} developed Neuron Activation Coverage (NAC-UE), which formulates a neuron activation state by considering both the neuron's raw output and its gradient-based influence on model decisions. NAC-UE then quantifies the "coverage degree" of these neuron states by ID training data, using lower coverage as an indicator of OOD samples. This method provides a mechanistic view of how OOD inputs activate novel combinations of neurons and their associated decision-influencing gradients. More broadly, \cite{schmidt2024syr} presented SISOM, a unified approach for active learning and OOD detection that leverages gradient-enhanced feature representations. By weighting neurons based on their gradient contribution to KL divergence, SISOM enriches feature representations for more effective OOD discrimination, demonstrating how gradients can mechanistically guide the learning of more robust features. Furthermore, some methods leverage gradients during training to instill OOD robustness. \cite{sharifi2024gok} proposed Gradient-Regularized OOD Detection (GReg), which introduces a regularization term that penalizes the norm of the score function's gradient for correctly detected ID and OOD samples. This promotes a smoother score manifold, ensuring local stability and preventing abrupt changes in OOD scores due to minor input perturbations, thereby offering a training-time mechanistic approach to enhance OOD robustness.

In conclusion, the field has progressed from simple statistical analyses of activations to theoretically-grounded rectification techniques and sophisticated geometric interpretations of feature spaces. Concurrently, a growing body of work is demonstrating the rich information embedded within gradients, both in terms of their subspace properties and their patterns of attribution, offering a deeper mechanistic understanding of model behavior. While significant advancements have been made in leveraging these internal model dynamics for OOD detection, challenges remain in developing methods that are robust across all types of OOD data, computationally efficient for real-time deployment, and equipped with strong theoretical guarantees. Future directions may involve combining the strengths of activation rectification with gradient-based insights, exploring more adaptive and dynamic internal analysis techniques, and integrating these methods into comprehensive uncertainty quantification frameworks that provide transparent mechanistic explanations for OOD decisions.