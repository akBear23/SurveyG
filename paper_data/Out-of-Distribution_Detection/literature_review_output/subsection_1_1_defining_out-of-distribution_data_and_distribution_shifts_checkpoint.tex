\subsection{Defining Out-of-Distribution Data and Distribution Shifts}
The robust deployment of machine learning models in real-world, open-world environments critically hinges on their ability to recognize when input data deviates from the distribution they were trained on. This fundamental challenge is addressed by Out-of-Distribution (OOD) detection, a field dedicated to distinguishing In-Distribution (ID) data, which models are designed to process, from novel, unfamiliar OOD data. Initially, OOD was often conceptualized as a straightforward "semantic shift," implying entirely new classes or concepts unseen during training. However, this definition has evolved significantly to encompass a more complex spectrum of distribution shifts that profoundly challenge model generalization.

Early work often struggled to consistently categorize various forms of data shifts. \cite{yang2022it3} critically addressed this by introducing the "Full-Spectrum OOD (FS-OOD)" problem, explicitly distinguishing between **semantic shift** (novel classes) and **covariate shift** (changes in input appearance or style, such as lighting or viewpoint, while retaining the same semantic class). Their proposed SEM score function, which disentangles semantic and non-semantic features, aimed to detect true semantic novelty while remaining robust to covariate variations, highlighting the necessity of a nuanced approach beyond simple binary classification. Further complicating this, \cite{ming2021wu7} introduced the concept of "spurious OOD," demonstrating that models can make overconfident predictions on OOD inputs that share spurious correlations with ID data, even if they lack the essential invariant features. This revealed a deeper vulnerability where models exploit non-causal features, making detection particularly challenging and underscoring the inherent ambiguity in OOD boundaries.

The need for more rigorous evaluation and clearer definitions led to significant advancements in benchmarking. \cite{yang2023ckx} meticulously curated `ImageNet-OOD`, a dataset designed to isolate pure semantic shift by removing ID contamination, semantic ambiguities, and unintended covariate shifts prevalent in prior benchmarks. This effort emphasized the difficulty in creating truly clean OOD definitions and highlighted how existing methods often inadvertently detected covariate shifts rather than genuine semantic novelty. Building on this, \cite{averly20239rv} proposed a "Model-Specific Out-of-Distribution (MS-OOD)" framework, which redefined OOD not solely by data properties but by whether a *deployed model* could correctly classify an example. This unified the detection of semantic shift, covariate shift (when misclassified), and even misclassified ID examples under a single, performance-driven ground truth, providing a more practical and holistic perspective. The "Sorites Paradox" of OOD, where the degree of shift is continuous rather than binary, was addressed by \cite{long2024os1}. They introduced the "Incremental Shift OOD (IS-OOD)" benchmark and the LAID method, which leverages CLIP to decompose image features into distinct semantic and covariate components, allowing for a continuous measurement of shift levels. This moved the field towards understanding OOD as a spectrum rather than a discrete boundary. \cite{wang2024is1} further dissected OOD detection and open-set recognition, providing a critical analysis of methods and benchmarks, and emphasizing the need for evaluation protocols that disentangle semantic and covariate shifts, especially at scale where methods like Outlier Exposure struggle due to the difficulty of acquiring representative auxiliary OOD data.

Beyond visual data, the definition and challenges of OOD extend to other modalities. \cite{liu202227x} pioneered unsupervised OOD detection for graph-structured data with GOOD-D, addressing the unique topological and feature-based shifts in graphs. \cite{dong2024a8k} scaled OOD detection to multimodal settings, introducing the `MultiOOD` benchmark and the Agree-to-Disagree (A2D) algorithm to leverage complementary information across modalities (e.g., video, audio, optical flow) and identify `Modality Prediction Discrepancy` as an OOD signal. For natural language processing, \cite{lang20237w3} provided a comprehensive survey, highlighting the distinct challenges of discrete input spaces and contextual semantic shifts. In generative language models, \cite{wang2024rej} tackled OOD detection in mathematical reasoning, identifying "pattern collapse" in output spaces and proposing a "Trajectory Volatility Score" based on dynamic embedding changes, demonstrating how domain-specific phenomena necessitate specialized OOD definitions. Furthermore, theoretical investigations have deepened our understanding of OOD learnability. \cite{fang20249gd} explored the PAC learnability of OOD detection, proving that it is not universally learnable and depends critically on the characteristics of the data distributions and hypothesis spaces. \cite{du2024aea} provided theoretical conditions for *when and how* in-distribution labels help OOD detection, particularly for "near OOD" scenarios. Finally, \cite{park2023n97} offered a theoretical explanation for the efficacy of feature norms in OOD detection, linking it to hidden classifier confidence and proposing a "Negative-Aware Norm" (NAN) that accounts for both activation and deactivation tendencies of neurons, providing a deeper insight into the internal mechanisms that differentiate ID from OOD.

In conclusion, the definition of OOD data and distribution shifts has evolved from a simplistic notion of novel classes to a multifaceted concept encompassing semantic, covariate, and spurious shifts, often viewed as a continuous spectrum rather than a hard boundary. The field now grapples with model-specific interpretations, multimodal challenges, and fundamental questions about learnability, necessitating robust detection mechanisms that are sensitive to diverse forms of unfamiliarity while being resilient to expected variations. The inherent ambiguity in precisely delineating OOD boundaries remains a central, ongoing challenge in the field.