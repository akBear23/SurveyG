{
  "title": "A Comprehensive Literature Review with Self-Reflection",
  "papers_processed": 186,
  "paper_list": [
    "098c12e7995675c1026d86d5f52843a035d3fa28.pdf",
    "60108b8e0d7204fa33f686b09128c7fc8489a224.pdf",
    "1007a43d42c7c92d765cdf614c98f6fc974aaf15.pdf",
    "af5b1a35271efd17ff3d5ddd152bacc96dff0e81.pdf",
    "8fe4a9aec9185a2f9da79571f8d239816d4a23d2.pdf",
    "305941292b59d808af1f6646993747ba0f76f4ac.pdf",
    "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6.pdf",
    "aaedc4d1d19a1e82cd4880c1b414593e766a1f31.pdf",
    "df8176027e3b9857e6bc6f45b3fc183351571fbd.pdf",
    "2b088b9b1abc84bb207396b440527219277e2718.pdf",
    "558f6cfc2daa06fa6562084a566392b907fc1642.pdf",
    "4b83c2ec2c5119057979ae64cf4b5d1aef04466b.pdf",
    "301e14edd925fb191714ddfa13593e67c6e5b2fd.pdf",
    "216d626b054db15aa6a36dcc43a7fc75ac8ecc9d.pdf",
    "48fe12e7ae26dc6541d6403e45b2a9397e2460a0.pdf",
    "63ff7c225079eba3838d45b11bb15a58037f1415.pdf",
    "34d35e460b39edb19581ef345c4b32ce45aa9eae.pdf",
    "7bdc1a737a8864b80c7abd5cca71c6514de25345.pdf",
    "903966632e84a59ca49914ebbadbbfbfe84e7c29.pdf",
    "ba39d83ec8b79f35d8195835f46cc4e36e5a4211.pdf",
    "b9bf34d2ab4666d042a0a949bfefdfee617d002f.pdf",
    "71ea4fce29a64843f1c3de747e1b4cb31bb2bedc.pdf",
    "fb1dd165f12c7cf03dd75bfd7d96a755674a09bc.pdf",
    "dcfca93185c49811ec6cf7c995eea58cf88c7bb3.pdf",
    "7d826dfb184be983018590c64cfb4a79349472a4.pdf",
    "9b603cd88dd40a4982a145a0ca8cde03dbb18d20.pdf",
    "ff29bf27e1c4e95c4eec448ed1d4adfa81983302.pdf",
    "393e0b8459eb1608b6b35d6057da4ddb09957555.pdf",
    "2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e.pdf",
    "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d.pdf",
    "3430707312d8d9192f2f4b967f541f96618ba393.pdf",
    "977384045381a2c45dfac4797196d34658d8a44f.pdf",
    "b585f1739cbbbca7b2695ce2e9f780ea625f9cef.pdf",
    "b6dc9a38916cefcb81245e2d1fb6c00dcfc584b0.pdf",
    "f0f220240fc752b6b3c56464d96aeb322f221ef0.pdf",
    "41e68a78f5bd266b1ae54d521ebd0be0e9314cd8.pdf",
    "4c1601f2582b351aea86a1d56dfd20f59a9f44ba.pdf",
    "6f136ee16da4f01f30b267478d5127699c983e20.pdf",
    "091ef8678781d1b53a5a07643ae37e3d44f9ed61.pdf",
    "858959613d37a64f6f634b0c5a1b5063c29929fe.pdf",
    "3f9f3ca7832f36285fbb0a65c221ded5e32382a1.pdf",
    "ca9974ac55dacf8db6eb4a57f489756068797cab.pdf",
    "2815a5e7ba661ae278aa7c19e08ac884cde17bf7.pdf",
    "57f4b117744112e4000894a5f939e114f1907719.pdf",
    "8ef5a28955ce4fbd170e4dddbd37930e025edb69.pdf",
    "7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba.pdf",
    "6db1cc71f6cfad8d7a9e09882711c722766562b6.pdf",
    "a1ce596ef67f28f433f3de1001774211d00b54f0.pdf",
    "4ec3a01aee0ae0e4d334e552373ccd74ca66b76e.pdf",
    "571062267e70a4e667704104dd74cbf66374d2f4.pdf",
    "0e3a01e0bd1beff9e77d8809629db24fc706c085.pdf",
    "c1e39900745c2b93fbe28a92140a0896a30f72ec.pdf",
    "0e384284e75751084bf44a5ef787f1c40eb24502.pdf",
    "69c2808097e7dfd357856f1ae82dcb6ce1bf64df.pdf",
    "96a219acb0acdca790f7f9f7f30c507a47a06754.pdf",
    "8f53788139d97189af8204a36b109473a0a2b61f.pdf",
    "8505cb57677d296351a1b86d15c843410778daca.pdf",
    "9d90a5e3d332fe13b82661e463cc6856ed40bd6a.pdf",
    "195d86d6b6a8420e9553fdbfc67cdfa4c87179aa.pdf",
    "23bbd94f93e360f373f78ce20f61ec3486b1923d.pdf",
    "e880782a4a4de3e56b12035a4c6aa3dae7638a06.pdf",
    "f911f3b51fcc88f2240def8f38ed8dff1da2e605.pdf",
    "955dd252793ea3f07de81b2f61165b6a822e07d5.pdf",
    "65e63d2d9168fa3cca6cd8bc083612b5f6cecc84.pdf",
    "b723d4e9fbe81890624d11c873acb63ddf21b64b.pdf",
    "ecd30803a587687db2e5a2ff659391e56b792714.pdf",
    "3e04193d5110288b776edd5724aeca2229d2d182.pdf",
    "350b00baaddd9f42dd3689f475bea3139e24099d.pdf",
    "40f68559e2fc055aaa1ed677c64b1dcc61bcaabe.pdf",
    "4de791464e08ba25d2466abf78fd9b529ce6d2d5.pdf",
    "62a63607647b48e1da0f8bac0c24d06ce15f2ef8.pdf",
    "913d26360f1a715f6ae80f5a775f398aa2f66c9d.pdf",
    "f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f.pdf",
    "89e108b5822004ddeee6e2b17e9096f8e4d74f12.pdf",
    "94f7e9837b598b619ffeb26ee90ba59ff4a8ffff.pdf",
    "7da7d9d38b964a70396fa842bf69f9a897111c26.pdf",
    "08925eef04eada4dd46dd3a33ea35f05795b12a9.pdf",
    "4fc9a9046cab45de423cadb2db887881cd0972e8.pdf",
    "92bb8140695007bc68ba87d51a6dfe563504f3a1.pdf",
    "e75e08851675eb506ea0149b0403828b6fb24900.pdf",
    "2f615dc49f38928fb08534b6edd1ad2c0102243a.pdf",
    "7466087f3748165181b0463153008d39879d5879.pdf",
    "dd48cfe3b7debf56ff74c4e3cf61d3d0d7aed9b8.pdf",
    "8529e0bbf80f36998f9b65b11bc0177099f11b07.pdf",
    "565d5a9038154fbbcba3d4a6f17671af9515fbcc.pdf",
    "590659832401c015e20a264cfdd7e0e4097b478b.pdf",
    "1fd384324d878cdb770a51cd333b7451b2fe5bcc.pdf",
    "4f292e3e9d34471631203d222e597912ae936a05.pdf",
    "726cf970e8dc6642bb6064f78e7279cee50a9222.pdf",
    "4ae78016f21de53032cba4d7327e21b12fe1dcf5.pdf",
    "b585a0efc97216c5ed2f13945cdd58af74d7f183.pdf",
    "eb332d020cb8877358157b7810e949d8f0256b1e.pdf",
    "79c72327dd14466c4db3865902c8317f74bb4c56.pdf",
    "522513df46de56f4eeaca95b0a8196dae065f75e.pdf",
    "bea84d4f28799628fa91585690088c00e8dca827.pdf",
    "531762d327ac99a898f4976181c1c69e2e3076cb.pdf",
    "5ad0eb12bedd86b88181cea5a9669d2a8e39cda1.pdf",
    "89b2a10540611860c4f48f5e6b412b8a17dfb036.pdf",
    "67dabdc0b1250d43641ea79869554741431c4b76.pdf",
    "f9ac68dc1fdd070a65a71c739e7135361c0d3006.pdf",
    "2e6813cad2e41c683277aa2d400dc2a2761309a2.pdf",
    "9c841ab87d2801029b831643153ebc539dd62892.pdf",
    "14cfe2588311870325e2770c5159d3100d7031ea.pdf",
    "f9cf8d53b1a157ab9dee16f03290d28865f3089a.pdf",
    "2902a67f9aebb115fc2b6cdf611910e72e896bdd.pdf",
    "d212c555293b81f845b3c99af4e922b0fcdb4290.pdf",
    "d2d056e705902d33d769206489d53e0659e376cc.pdf",
    "70da774b2b30397ee2f7e2abc819ed126641a70d.pdf",
    "be422ce2f64425f5c7bedf9a8498ab1e993060cc.pdf",
    "b515fa73815185cc3d6559f2c6c0a1e122eb4786.pdf",
    "1f24e041e10239cba8ff26ffcff4902343e55cab.pdf",
    "06436653774a7cb8d53005d3f25af2a7229c1f8b.pdf",
    "28582980cc55e3ed002fae2cf0e9b9b92714694b.pdf",
    "646de295e8680bee891d359fce2e2ef201a411a3.pdf",
    "6618d8b3643745d60772d4ec522ad76204522f7d.pdf",
    "9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0.pdf",
    "bcbee683ff34f87675448471d780541f7ae25ce9.pdf",
    "b3f21af3032246b6fa87e05a6d9455433b25ce55.pdf",
    "83d79426ea8345b73c9ce4848bc46c4f797e5fbb.pdf",
    "48020e5f1a0d5703f6169c20051eeb056194c25b.pdf",
    "87268ea5825cd65c1c3151d6ecc0973f267b3c68.pdf",
    "9489f92cf533885359a8efc3a0f030a95abf9f1b.pdf",
    "f418971afad1d44fb64610b91128a4eb6c3855ef.pdf",
    "fc1bedae1d5f338f77a053589c1dbd303b089f72.pdf",
    "36dd3bee303671d45c6ab4631c34b2dd67e19e69.pdf",
    "4ff175285ef575f4dc24a518869139382665c12e.pdf",
    "98cf00c765de7c7c985869c57bb2c41e458f773f.pdf",
    "39af99b93c6b95f54f78952522e6d22496dd5bf1.pdf",
    "47cfe2c7ba31259ed8b005a348a48db4676279fa.pdf",
    "f9893f5e60aea7b31580253a4c5658d2c0725ece.pdf",
    "209c949e277081b8f2847cf3e66b90df26dcf179.pdf",
    "c5b439fa6766e4d9dabf09d1b0d686311b494914.pdf",
    "1f2462ad6ffef934b7470313ffc3d42a0af35c9c.pdf",
    "b2f118a60c6d467bab521a29fa2a6f33f60f3915.pdf",
    "1d13f355ee04e0931bd589b73f533b83bdf4e9b1.pdf",
    "728afc51ac20d79133d8c747a2d18b01c6a6de5e.pdf",
    "88b9e2bce0caadf7495490603f5292166e2a1860.pdf",
    "5df7dcb96a465ed4d4d2fa2414413a41494fee8c.pdf",
    "db5059dea1ee639dfc7eba751183ce3564a4b593.pdf",
    "201817ff23481abd4ef48ce9e2ce71314f720ea7.pdf",
    "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7.pdf",
    "63cc6260b838f2cc559715a9f68360edc743f50b.pdf",
    "5278d3db213bce1dd424ad7e0c5dc97801baceee.pdf",
    "a2d255583ee4cb66f343103076239af2931047be.pdf",
    "a4bd318d5b2866bd3736142109168ea961a2ab38.pdf",
    "3ecbd6fc9ba0a00ce49982f788918bc2b768d98b.pdf",
    "d4bc2e2146387bfca16593152840e763cff4ef88.pdf",
    "55b668702e122d10787c5f94e4090062755753d2.pdf",
    "5f8ccbe2a87df5e1340d4bda8f6e3458ef1bf6ae.pdf",
    "835d157e2c23d3577f23778ce051ab8d706babf6.pdf",
    "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129.pdf",
    "59f40cf3eebd2cb6ad30363fa6abf1caea06555f.pdf",
    "e1e7f0539ce536a3f889682bcfabee11a96b2ee1.pdf",
    "ab692fb2d15fe514a8121dbd4d1d74eae4e2f989.pdf",
    "755390c365c4a39445f73ed09fe673f2b823876d.pdf",
    "d03cf8819aeff52708a70d506b87e50214af53b6.pdf",
    "296c108e1afadbc131d41f92d66013e9c95eb2ca.pdf",
    "33fb671a3289027c84a71fc996f948195b1baeb4.pdf",
    "c8689ce4c6bb187f8f4494523c48954d99446db5.pdf",
    "f0ea95c6b19662c33222408795c26316bd88c03f.pdf",
    "b60ddb1b78375f709d9c4c0b416f89156e58a6b0.pdf",
    "ee3af6dfdc6527bc9c96c02044546c7121318a33.pdf",
    "12f04ecb1c9a76bed28656e1cb178c1b97eb7506.pdf",
    "8a0eabcb7ff3f11fdd864fe68e386fa5c5da698c.pdf",
    "8cb280caa94c758e659adfb413b25a3d2e37a837.pdf",
    "05a8b19f4b4ddd316eb959d6f68378842f1c65a2.pdf",
    "400333890cf74f523068ab767a87fede2042131e.pdf",
    "90af5e08aa6e57e55124dd3f1f40bdb0c051b7c9.pdf",
    "71fdc063701dc3f431942398d53b0290a9975d32.pdf",
    "59fdf00e73e64dd9104ec4df010fc3bc4eac6c66.pdf",
    "f561b83d58498973ec9252054ae38a29aa3f8b42.pdf",
    "38866b5afbf33b7207ce4e23b0a58d0745835570.pdf",
    "2fd2e37ffd4e45eab72eab0a22512d5fe1adfdf3.pdf",
    "b84938e00a7c422dd68cecc1b11117c455fdc7f1.pdf",
    "df088cb9d0e12f9c4879d82191366e7476167480.pdf",
    "26d34f9c230a93506b60465daaaae8c23011f412.pdf",
    "375583f16d9ee1947397d993859fcd75811cade9.pdf",
    "74491e50e381210badd7c8a0eee69d10410f6a68.pdf",
    "5c18f91dfa622c3c6ba455de9df5535a48bff463.pdf",
    "b826af7705a11f6fefc9452eed5db6309520f170.pdf",
    "50864505777b344d2ee4b4d18880f3ba3ca58836.pdf",
    "46bffadb953e47f58ecca858e6e1ea0acb181501.pdf",
    "973b3a4cc286286a24003998fc8596f664ec1d19.pdf",
    "be26ccca1684334ca6a0bf7a8c47e85071283185.pdf",
    "9b4a20fd47293a48c9be88aa6c7be471123f9487.pdf",
    "0e6010e6b53e1d281107844fbcf54608194599cf.pdf"
  ],
  "citations_map": {
    "098c12e7995675c1026d86d5f52843a035d3fa28.pdf": "han2022ixj",
    "60108b8e0d7204fa33f686b09128c7fc8489a224.pdf": "zhou202250i",
    "1007a43d42c7c92d765cdf614c98f6fc974aaf15.pdf": "yang2022it3",
    "af5b1a35271efd17ff3d5ddd152bacc96dff0e81.pdf": "zisselman2020cmx",
    "8fe4a9aec9185a2f9da79571f8d239816d4a23d2.pdf": "song2022f5d",
    "305941292b59d808af1f6646993747ba0f76f4ac.pdf": "liu202227x",
    "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6.pdf": "zaeemzadeh2021lmh",
    "aaedc4d1d19a1e82cd4880c1b414593e766a1f31.pdf": "ming2021wu7",
    "df8176027e3b9857e6bc6f45b3fc183351571fbd.pdf": "zhu2022oir",
    "2b088b9b1abc84bb207396b440527219277e2718.pdf": "jeong2020z5c",
    "558f6cfc2daa06fa6562084a566392b907fc1642.pdf": "chen2020mbk",
    "4b83c2ec2c5119057979ae64cf4b5d1aef04466b.pdf": "morningstar2020re9",
    "301e14edd925fb191714ddfa13593e67c6e5b2fd.pdf": "li20227o1",
    "216d626b054db15aa6a36dcc43a7fc75ac8ecc9d.pdf": "xie2023uki",
    "48fe12e7ae26dc6541d6403e45b2a9397e2460a0.pdf": "liu2022fdj",
    "63ff7c225079eba3838d45b11bb15a58037f1415.pdf": "zimmerer2022rv6",
    "34d35e460b39edb19581ef345c4b32ce45aa9eae.pdf": "kaur2022cty",
    "7bdc1a737a8864b80c7abd5cca71c6514de25345.pdf": "zhang20212tb",
    "903966632e84a59ca49914ebbadbbfbfe84e7c29.pdf": "dong2021swz",
    "ba39d83ec8b79f35d8195835f46cc4e36e5a4211.pdf": "cai2020lsi",
    "b9bf34d2ab4666d042a0a949bfefdfee617d002f.pdf": "gawlikowski2022p4r",
    "71ea4fce29a64843f1c3de747e1b4cb31bb2bedc.pdf": "paper2020kkd",
    "fb1dd165f12c7cf03dd75bfd7d96a755674a09bc.pdf": "kirchheim20229jl",
    "dcfca93185c49811ec6cf7c995eea58cf88c7bb3.pdf": "lang20237w3",
    "7d826dfb184be983018590c64cfb4a79349472a4.pdf": "yu2022egq",
    "9b603cd88dd40a4982a145a0ca8cde03dbb18d20.pdf": "zhao20221ag",
    "ff29bf27e1c4e95c4eec448ed1d4adfa81983302.pdf": "ammar2023pr1",
    "393e0b8459eb1608b6b35d6057da4ddb09957555.pdf": "besnier2021jgn",
    "2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e.pdf": "guerin202201y",
    "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d.pdf": "liu2023zb3",
    "3430707312d8d9192f2f4b967f541f96618ba393.pdf": "berger20214a3",
    "977384045381a2c45dfac4797196d34658d8a44f.pdf": "yang2022ci8",
    "b585f1739cbbbca7b2695ce2e9f780ea625f9cef.pdf": "lu2023i8o",
    "b6dc9a38916cefcb81245e2d1fb6c00dcfc584b0.pdf": "kim2024nhz",
    "f0f220240fc752b6b3c56464d96aeb322f221ef0.pdf": "miao2023brn",
    "41e68a78f5bd266b1ae54d521ebd0be0e9314cd8.pdf": "wang2022mbf",
    "4c1601f2582b351aea86a1d56dfd20f59a9f44ba.pdf": "zhang202312h",
    "6f136ee16da4f01f30b267478d5127699c983e20.pdf": "kuan2022qzl",
    "091ef8678781d1b53a5a07643ae37e3d44f9ed61.pdf": "choi202367m",
    "858959613d37a64f6f634b0c5a1b5063c29929fe.pdf": "liu2025wgr",
    "3f9f3ca7832f36285fbb0a65c221ded5e32382a1.pdf": "miyai2023591",
    "ca9974ac55dacf8db6eb4a57f489756068797cab.pdf": "bitterwolf2022rw0",
    "2815a5e7ba661ae278aa7c19e08ac884cde17bf7.pdf": "gomes2022zyv",
    "57f4b117744112e4000894a5f939e114f1907719.pdf": "gao2023kmk",
    "8ef5a28955ce4fbd170e4dddbd37930e025edb69.pdf": "cao20224r3",
    "7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba.pdf": "wei2023f15",
    "6db1cc71f6cfad8d7a9e09882711c722766562b6.pdf": "behpour2023x13",
    "a1ce596ef67f28f433f3de1001774211d00b54f0.pdf": "wang2025xwm",
    "4ec3a01aee0ae0e4d334e552373ccd74ca66b76e.pdf": "graham20232re",
    "571062267e70a4e667704104dd74cbf66374d2f4.pdf": "bao2024kfh",
    "0e3a01e0bd1beff9e77d8809629db24fc706c085.pdf": "park2023n97",
    "c1e39900745c2b93fbe28a92140a0896a30f72ec.pdf": "haider2023vid",
    "0e384284e75751084bf44a5ef787f1c40eb24502.pdf": "ghosal2023q20",
    "69c2808097e7dfd357856f1ae82dcb6ce1bf64df.pdf": "yang2023ckx",
    "96a219acb0acdca790f7f9f7f30c507a47a06754.pdf": "chen2023tz9",
    "8f53788139d97189af8204a36b109473a0a2b61f.pdf": "averly20239rv",
    "8505cb57677d296351a1b86d15c843410778daca.pdf": "zhu2023u9p",
    "9d90a5e3d332fe13b82661e463cc6856ed40bd6a.pdf": "mishra20236n9",
    "195d86d6b6a8420e9553fdbfc67cdfa4c87179aa.pdf": "yu2023r3c",
    "23bbd94f93e360f373f78ce20f61ec3486b1923d.pdf": "dai2023mhn",
    "e880782a4a4de3e56b12035a4c6aa3dae7638a06.pdf": "arajo2023dau",
    "f911f3b51fcc88f2240def8f38ed8dff1da2e605.pdf": "xu2023767",
    "955dd252793ea3f07de81b2f61165b6a822e07d5.pdf": "cheng20233yi",
    "65e63d2d9168fa3cca6cd8bc083612b5f6cecc84.pdf": "vasiliuk20233w9",
    "b723d4e9fbe81890624d11c873acb63ddf21b64b.pdf": "anthony2023slf",
    "ecd30803a587687db2e5a2ff659391e56b792714.pdf": "yang2023pre",
    "3e04193d5110288b776edd5724aeca2229d2d182.pdf": "liu2023i6i",
    "350b00baaddd9f42dd3689f475bea3139e24099d.pdf": "guan2023dwv",
    "40f68559e2fc055aaa1ed677c64b1dcc61bcaabe.pdf": "zhang2024mgg",
    "4de791464e08ba25d2466abf78fd9b529ce6d2d5.pdf": "liu20245e5",
    "62a63607647b48e1da0f8bac0c24d06ce15f2ef8.pdf": "jia2024zld",
    "913d26360f1a715f6ae80f5a775f398aa2f66c9d.pdf": "jiang2023vzb",
    "f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f.pdf": "gao2023epm",
    "89e108b5822004ddeee6e2b17e9096f8e4d74f12.pdf": "henriksson20233hb",
    "94f7e9837b598b619ffeb26ee90ba59ff4a8ffff.pdf": "saadati2023i8u",
    "7da7d9d38b964a70396fa842bf69f9a897111c26.pdf": "miao2023zf5",
    "08925eef04eada4dd46dd3a33ea35f05795b12a9.pdf": "chen2023za1",
    "4fc9a9046cab45de423cadb2db887881cd0972e8.pdf": "aguilar2023ms5",
    "92bb8140695007bc68ba87d51a6dfe563504f3a1.pdf": "ouyang2023wxc",
    "e75e08851675eb506ea0149b0403828b6fb24900.pdf": "lafon2023w37",
    "2f615dc49f38928fb08534b6edd1ad2c0102243a.pdf": "ksel20246fe",
    "7466087f3748165181b0463153008d39879d5879.pdf": "ding20242m0",
    "dd48cfe3b7debf56ff74c4e3cf61d3d0d7aed9b8.pdf": "zhang2024d24",
    "8529e0bbf80f36998f9b65b11bc0177099f11b07.pdf": "wu20242p3",
    "565d5a9038154fbbcba3d4a6f17671af9515fbcc.pdf": "yao2024epq",
    "590659832401c015e20a264cfdd7e0e4097b478b.pdf": "chen2024kl7",
    "1fd384324d878cdb770a51cd333b7451b2fe5bcc.pdf": "kaur20248t3",
    "4f292e3e9d34471631203d222e597912ae936a05.pdf": "zhang2024cx0",
    "726cf970e8dc6642bb6064f78e7279cee50a9222.pdf": "schmidt2024syr",
    "4ae78016f21de53032cba4d7327e21b12fe1dcf5.pdf": "nie2024ghv",
    "b585a0efc97216c5ed2f13945cdd58af74d7f183.pdf": "xu2025hom",
    "eb332d020cb8877358157b7810e949d8f0256b1e.pdf": "vojr2023ee1",
    "79c72327dd14466c4db3865902c8317f74bb4c56.pdf": "lu20249d4",
    "522513df46de56f4eeaca95b0a8196dae065f75e.pdf": "nie20240bk",
    "bea84d4f28799628fa91585690088c00e8dca827.pdf": "du20248xe",
    "531762d327ac99a898f4976181c1c69e2e3076cb.pdf": "li20245b6",
    "5ad0eb12bedd86b88181cea5a9669d2a8e39cda1.pdf": "fang20248g5",
    "89b2a10540611860c4f48f5e6b412b8a17dfb036.pdf": "linmans2024pi9",
    "67dabdc0b1250d43641ea79869554741431c4b76.pdf": "chen20243na",
    "f9ac68dc1fdd070a65a71c739e7135361c0d3006.pdf": "dong2024a8k",
    "2e6813cad2e41c683277aa2d400dc2a2761309a2.pdf": "miyai20247ro",
    "9c841ab87d2801029b831643153ebc539dd62892.pdf": "zhang2024hh0",
    "14cfe2588311870325e2770c5159d3100d7031ea.pdf": "cao20246gj",
    "f9cf8d53b1a157ab9dee16f03290d28865f3089a.pdf": "peng20243ji",
    "2902a67f9aebb115fc2b6cdf611910e72e896bdd.pdf": "wang2024es5",
    "d212c555293b81f845b3c99af4e922b0fcdb4290.pdf": "wang2024q01",
    "d2d056e705902d33d769206489d53e0659e376cc.pdf": "wang2024rej",
    "70da774b2b30397ee2f7e2abc819ed126641a70d.pdf": "hong2024xls",
    "be422ce2f64425f5c7bedf9a8498ab1e993060cc.pdf": "yu20249dd",
    "b515fa73815185cc3d6559f2c6c0a1e122eb4786.pdf": "fan2024u9i",
    "1f24e041e10239cba8ff26ffcff4902343e55cab.pdf": "fang2024lv2",
    "06436653774a7cb8d53005d3f25af2a7229c1f8b.pdf": "vojivr202444c",
    "28582980cc55e3ed002fae2cf0e9b9b92714694b.pdf": "li2024rs5",
    "646de295e8680bee891d359fce2e2ef201a411a3.pdf": "tang20243rx",
    "6618d8b3643745d60772d4ec522ad76204522f7d.pdf": "li2024n34",
    "9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0.pdf": "hofmann2024gnx",
    "bcbee683ff34f87675448471d780541f7ae25ce9.pdf": "zhou20243bx",
    "b3f21af3032246b6fa87e05a6d9455433b25ce55.pdf": "vishwakarma2024z1m",
    "83d79426ea8345b73c9ce4848bc46c4f797e5fbb.pdf": "wang2024y55",
    "48020e5f1a0d5703f6169c20051eeb056194c25b.pdf": "xu2024ufg",
    "87268ea5825cd65c1c3151d6ecc0973f267b3c68.pdf": "du2024aea",
    "9489f92cf533885359a8efc3a0f030a95abf9f1b.pdf": "zamzmi20240s6",
    "f418971afad1d44fb64610b91128a4eb6c3855ef.pdf": "zhu2024awk",
    "fc1bedae1d5f338f77a053589c1dbd303b089f72.pdf": "nasvytis2024mmr",
    "36dd3bee303671d45c6ab4631c34b2dd67e19e69.pdf": "yuan2024ug7",
    "4ff175285ef575f4dc24a518869139382665c12e.pdf": "fang20249gd",
    "98cf00c765de7c7c985869c57bb2c41e458f773f.pdf": "cao20250gu",
    "39af99b93c6b95f54f78952522e6d22496dd5bf1.pdf": "heng2024fjd",
    "47cfe2c7ba31259ed8b005a348a48db4676279fa.pdf": "zhao2024u4m",
    "f9893f5e60aea7b31580253a4c5658d2c0725ece.pdf": "xu20242cq",
    "209c949e277081b8f2847cf3e66b90df26dcf179.pdf": "mirzaei2024dad",
    "c5b439fa6766e4d9dabf09d1b0d686311b494914.pdf": "sharifi2024gok",
    "1f2462ad6ffef934b7470313ffc3d42a0af35c9c.pdf": "kirchheim20243gn",
    "b2f118a60c6d467bab521a29fa2a6f33f60f3915.pdf": "shi2024rfk",
    "1d13f355ee04e0931bd589b73f533b83bdf4e9b1.pdf": "feng2024r4v",
    "728afc51ac20d79133d8c747a2d18b01c6a6de5e.pdf": "li2024ypq",
    "88b9e2bce0caadf7495490603f5292166e2a1860.pdf": "zeng2024bti",
    "5df7dcb96a465ed4d4d2fa2414413a41494fee8c.pdf": "krumpl2024n1w",
    "db5059dea1ee639dfc7eba751183ce3564a4b593.pdf": "hogeweg2024tw3",
    "201817ff23481abd4ef48ce9e2ce71314f720ea7.pdf": "wang2024is1",
    "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7.pdf": "lu2024j0n",
    "63cc6260b838f2cc559715a9f68360edc743f50b.pdf": "tan2024oj5",
    "5278d3db213bce1dd424ad7e0c5dc97801baceee.pdf": "ma202440a",
    "a2d255583ee4cb66f343103076239af2931047be.pdf": "yang2025z62",
    "a4bd318d5b2866bd3736142109168ea961a2ab38.pdf": "zhang2024z2g",
    "3ecbd6fc9ba0a00ce49982f788918bc2b768d98b.pdf": "abdi2024mvh",
    "d4bc2e2146387bfca16593152840e763cff4ef88.pdf": "haider20249q8",
    "55b668702e122d10787c5f94e4090062755753d2.pdf": "qu202422m",
    "5f8ccbe2a87df5e1340d4bda8f6e3458ef1bf6ae.pdf": "novello2024yco",
    "835d157e2c23d3577f23778ce051ab8d706babf6.pdf": "chen2024f28",
    "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129.pdf": "miao2024318",
    "59f40cf3eebd2cb6ad30363fa6abf1caea06555f.pdf": "oh2024opf",
    "e1e7f0539ce536a3f889682bcfabee11a96b2ee1.pdf": "dong2024t8f",
    "ab692fb2d15fe514a8121dbd4d1d74eae4e2f989.pdf": "feng2024ma3",
    "755390c365c4a39445f73ed09fe673f2b823876d.pdf": "he2024e9z",
    "d03cf8819aeff52708a70d506b87e50214af53b6.pdf": "gong2024n0t",
    "296c108e1afadbc131d41f92d66013e9c95eb2ca.pdf": "cook2024hyb",
    "33fb671a3289027c84a71fc996f948195b1baeb4.pdf": "miao20246mk",
    "c8689ce4c6bb187f8f4494523c48954d99446db5.pdf": "lee2025gu9",
    "f0ea95c6b19662c33222408795c26316bd88c03f.pdf": "wang2025v65",
    "b60ddb1b78375f709d9c4c0b416f89156e58a6b0.pdf": "he2024s9w",
    "ee3af6dfdc6527bc9c96c02044546c7121318a33.pdf": "li2025jdt",
    "12f04ecb1c9a76bed28656e1cb178c1b97eb7506.pdf": "gulati2024dbi",
    "8a0eabcb7ff3f11fdd864fe68e386fa5c5da698c.pdf": "osada20246an",
    "8cb280caa94c758e659adfb413b25a3d2e37a837.pdf": "mei20248tm",
    "05a8b19f4b4ddd316eb959d6f68378842f1c65a2.pdf": "kim2024vqc",
    "400333890cf74f523068ab767a87fede2042131e.pdf": "kahya2024ywf",
    "90af5e08aa6e57e55124dd3f1f40bdb0c051b7c9.pdf": "ekim2024zwd",
    "71fdc063701dc3f431942398d53b0290a9975d32.pdf": "shin2024lnf",
    "59fdf00e73e64dd9104ec4df010fc3bc4eac6c66.pdf": "du2024kj8",
    "f561b83d58498973ec9252054ae38a29aa3f8b42.pdf": "mao20244lp",
    "38866b5afbf33b7207ce4e23b0a58d0745835570.pdf": "borlino20245ku",
    "2fd2e37ffd4e45eab72eab0a22512d5fe1adfdf3.pdf": "li2024tk8",
    "b84938e00a7c422dd68cecc1b11117c455fdc7f1.pdf": "chen20247p7",
    "df088cb9d0e12f9c4879d82191366e7476167480.pdf": "zhou2024ae1",
    "26d34f9c230a93506b60465daaaae8c23011f412.pdf": "galesso2024g7t",
    "375583f16d9ee1947397d993859fcd75811cade9.pdf": "chen202491k",
    "74491e50e381210badd7c8a0eee69d10410f6a68.pdf": "long2024os1",
    "5c18f91dfa622c3c6ba455de9df5535a48bff463.pdf": "cai2025ez2",
    "b826af7705a11f6fefc9452eed5db6309520f170.pdf": "liu2025m5u",
    "50864505777b344d2ee4b4d18880f3ba3ca58836.pdf": "li2025xv2",
    "46bffadb953e47f58ecca858e6e1ea0acb181501.pdf": "liu2024m2l",
    "973b3a4cc286286a24003998fc8596f664ec1d19.pdf": "yu2024ez3",
    "be26ccca1684334ca6a0bf7a8c47e85071283185.pdf": "ahsan20241ht",
    "9b4a20fd47293a48c9be88aa6c7be471123f9487.pdf": "ma202473w",
    "0e6010e6b53e1d281107844fbcf54608194599cf.pdf": "isaku2025kiz"
  },
  "sections": {
    "Introduction to Out-of-Distribution Detection": "\\section{Introduction to Out-of-Distribution Detection}\n\\label{sec:introduction_to_out-of-distribution_detection}\n\n\n\n\\subsection{Defining Out-of-Distribution Data and Distribution Shifts}\n\\label{sec:1_1_defining_out-of-distribution_data__and__distribution_shifts}\n\nThe robust deployment of machine learning models in real-world, open-world environments critically hinges on their ability to recognize when input data deviates from the distribution they were trained on. This fundamental challenge is addressed by Out-of-Distribution (OOD) detection, a field dedicated to distinguishing In-Distribution (ID) data, which models are designed to process, from novel, unfamiliar OOD data. Initially, OOD was often conceptualized as a straightforward \"semantic shift,\" implying entirely new classes or concepts unseen during training. However, this definition has evolved significantly to encompass a more complex spectrum of distribution shifts that profoundly challenge model generalization.\n\nEarly work often struggled to consistently categorize various forms of data shifts. \\cite{yang2022it3} critically addressed this by introducing the \"Full-Spectrum OOD (FS-OOD)\" problem, explicitly distinguishing between **semantic shift** (novel classes) and **covariate shift** (changes in input appearance or style, such as lighting or viewpoint, while retaining the same semantic class). Their proposed SEM score function, which disentangles semantic and non-semantic features, aimed to detect true semantic novelty while remaining robust to covariate variations, highlighting the necessity of a nuanced approach beyond simple binary classification. Further complicating this, \\cite{ming2021wu7} introduced the concept of \"spurious OOD,\" demonstrating that models can make overconfident predictions on OOD inputs that share spurious correlations with ID data, even if they lack the essential invariant features. This revealed a deeper vulnerability where models exploit non-causal features, making detection particularly challenging and underscoring the inherent ambiguity in OOD boundaries.\n\nThe need for more rigorous evaluation and clearer definitions led to significant advancements in benchmarking. \\cite{yang2023ckx} meticulously curated `ImageNet-OOD`, a dataset designed to isolate pure semantic shift by removing ID contamination, semantic ambiguities, and unintended covariate shifts prevalent in prior benchmarks. This effort emphasized the difficulty in creating truly clean OOD definitions and highlighted how existing methods often inadvertently detected covariate shifts rather than genuine semantic novelty. Building on this, \\cite{averly20239rv} proposed a \"Model-Specific Out-of-Distribution (MS-OOD)\" framework, which redefined OOD not solely by data properties but by whether a *deployed model* could correctly classify an example. This unified the detection of semantic shift, covariate shift (when misclassified), and even misclassified ID examples under a single, performance-driven ground truth, providing a more practical and holistic perspective. The \"Sorites Paradox\" of OOD, where the degree of shift is continuous rather than binary, was addressed by \\cite{long2024os1}. They introduced the \"Incremental Shift OOD (IS-OOD)\" benchmark and the LAID method, which leverages CLIP to decompose image features into distinct semantic and covariate components, allowing for a continuous measurement of shift levels. This moved the field towards understanding OOD as a spectrum rather than a discrete boundary. \\cite{wang2024is1} further dissected OOD detection and open-set recognition, providing a critical analysis of methods and benchmarks, and emphasizing the need for evaluation protocols that disentangle semantic and covariate shifts, especially at scale where methods like Outlier Exposure struggle due to the difficulty of acquiring representative auxiliary OOD data.\n\nBeyond visual data, the definition and challenges of OOD extend to other modalities. \\cite{liu202227x} pioneered unsupervised OOD detection for graph-structured data with GOOD-D, addressing the unique topological and feature-based shifts in graphs. \\cite{dong2024a8k} scaled OOD detection to multimodal settings, introducing the `MultiOOD` benchmark and the Agree-to-Disagree (A2D) algorithm to leverage complementary information across modalities (e.g., video, audio, optical flow) and identify `Modality Prediction Discrepancy` as an OOD signal. For natural language processing, \\cite{lang20237w3} provided a comprehensive survey, highlighting the distinct challenges of discrete input spaces and contextual semantic shifts. In generative language models, \\cite{wang2024rej} tackled OOD detection in mathematical reasoning, identifying \"pattern collapse\" in output spaces and proposing a \"Trajectory Volatility Score\" based on dynamic embedding changes, demonstrating how domain-specific phenomena necessitate specialized OOD definitions. Furthermore, theoretical investigations have deepened our understanding of OOD learnability. \\cite{fang20249gd} explored the PAC learnability of OOD detection, proving that it is not universally learnable and depends critically on the characteristics of the data distributions and hypothesis spaces. \\cite{du2024aea} provided theoretical conditions for *when and how* in-distribution labels help OOD detection, particularly for \"near OOD\" scenarios. Finally, \\cite{park2023n97} offered a theoretical explanation for the efficacy of feature norms in OOD detection, linking it to hidden classifier confidence and proposing a \"Negative-Aware Norm\" (NAN) that accounts for both activation and deactivation tendencies of neurons, providing a deeper insight into the internal mechanisms that differentiate ID from OOD.\n\nIn conclusion, the definition of OOD data and distribution shifts has evolved from a simplistic notion of novel classes to a multifaceted concept encompassing semantic, covariate, and spurious shifts, often viewed as a continuous spectrum rather than a hard boundary. The field now grapples with model-specific interpretations, multimodal challenges, and fundamental questions about learnability, necessitating robust detection mechanisms that are sensitive to diverse forms of unfamiliarity while being resilient to expected variations. The inherent ambiguity in precisely delineating OOD boundaries remains a central, ongoing challenge in the field.\n\\subsection{Motivation: The Imperative for Trustworthy AI}\n\\label{sec:1_2_motivation:_the_imperative_for_trustworthy_ai}\n\nThe increasing integration of artificial intelligence (AI) systems into critical societal infrastructures and high-stakes applications necessitates an unwavering commitment to trustworthiness, reliability, and safety. A fundamental challenge that directly undermines this trust is the inherent overconfidence of deep learning models when confronted with inputs that deviate significantly from their training distribution, commonly referred to as Out-of-Distribution (OOD) data. This section articulates the compelling and urgent reasons behind the escalating importance of OOD detection in modern AI, emphasizing its role as an indispensable component for building truly trustworthy, robust, and safe artificial intelligence.\n\nIn numerous safety-critical domains, the consequences of unchecked model overconfidence on OOD data can be catastrophic, leading to unreliable decisions, system failures, and potentially severe harm. For instance, in autonomous driving, a vehicle's perception system misinterpreting an anomalous road condition, an unfamiliar object, or an unusual weather pattern as a familiar in-distribution (ID) input can lead to dangerous maneuvers or accidents \\cite{cai2020lsi, kaur2022cty}. Similarly, in medical diagnosis, an AI system providing a highly confident but incorrect diagnosis for a rare or unseen patient condition, or misinterpreting an anomalous medical image, could have dire implications for patient well-being \\cite{zimmerer2022rv6, kaur2022cty}. The deployment of deep reinforcement learning (RL) agents in real-world control systems also faces this challenge, where agents trained in simulated environments may encounter novel states in the physical world and fail silently without signaling uncertainty, posing significant safety risks \\cite{haider20249q8}. This imperative for trustworthy AI demands that these systems not only perform well on familiar data but also express meaningful and calibrated uncertainty when encountering novel, unfamiliar, or anomalous inputs \\cite{zisselman2020cmx, morningstar2020re9, lu2024j0n}.\n\nThe core problem stems from the \"closed-world\" assumption under which most deep learning models are traditionally trained. This assumption posits that test data will be drawn from the same statistical distribution as the training data \\cite{yang2022ci8}. However, this premise rarely holds true in complex, dynamic, and open-world environments where unforeseen circumstances, sensor noise, adversarial attacks, or simply novel data points are inevitable \\cite{zisselman2020cmx, chen2020mbk, morningstar2020re9, guerin202201y, schmidt2024syr, vishwakarma2024z1m}. When this closed-world assumption is violated, conventional models often produce high-confidence, yet incorrect, predictions for OOD samples \\cite{song2022f5d, yu2022egq, ammar2023pr1, bitterwolf2022rw0, lu2024j0n}. This unwarranted overconfidence is a critical vulnerability that OOD detection aims to mitigate, providing a crucial safety mechanism to prevent models from making decisions outside their learned competence.\n\nFurthermore, the very nature of OOD data can be complex and multifaceted, posing additional challenges to reliable detection. It is not always a simple binary distinction between \"known\" and \"unknown.\" For instance, models can learn spurious correlations from their training data, leading them to confidently classify OOD inputs that share these irrelevant features as in-distribution, making such \"spurious OOD\" particularly difficult to detect \\cite{ming2021wu7}. This highlights that a robust OOD detector must not only identify entirely novel semantic concepts but also be resilient to subtle shifts or misleading cues. Moreover, the definition of what constitutes \"OOD\" can even be model-specific, depending on whether a particular input leads to a misclassification for a given deployed model, rather than a universal distributional shift \\cite{averly20239rv}. These nuances underscore the need for sophisticated and context-aware OOD detection mechanisms.\n\nThe practical deployment of AI systems further amplifies the need for robust OOD detection. Beyond theoretical performance, real-world systems require OOD detectors that are not only accurate but also provide reliable guarantees and manage false positives effectively. High false positive rates (FPR), where legitimate in-distribution samples are incorrectly flagged as OOD, can lead to user frustration, unnecessary human intervention, and a breakdown of trust in the system \\cite{vishwakarma2024z1m}. Therefore, the development of OOD detection is intrinsically linked to the broader goal of building AI systems that are transparent about their limitations, can abstain from making potentially harmful decisions when faced with unfamiliar situations, and can operate predictably and safely in dynamic environments.\n\nIn summary, the motivation for robust OOD detection is deeply rooted in the urgent need to transition AI from research curiosities to reliably deployed systems that operate safely and responsibly in the real world. It is not merely about identifying novelty but about ensuring that AI systems are aware of their limitations, can express appropriate uncertainty, and can defer to human oversight or alternative safe actions when confronted with inputs beyond their learned experience. OOD detection, therefore, stands as a pivotal step towards enabling the responsible and reliable deployment of AI in complex, open-world environments, where unforeseen circumstances are not exceptions but inevitable realities. Continued research in this area is essential to bridge the gap between theoretical capabilities and the practical demands of trustworthy AI.\n",
    "Foundational Concepts and Early Post-Hoc Methods": "\\section{Foundational Concepts and Early Post-Hoc Methods}\n\\label{sec:foundational_concepts__and__early_post-hoc_methods}\n\n\n\n\\subsection{Uncertainty Quantification in Neural Networks}\n\\label{sec:2_1_uncertainty_quantification_in_neural_networks}\n\n\nConventional neural networks, while achieving remarkable performance in complex classification tasks, are fundamentally designed to assign inputs to a fixed set of predefined classes rather than to explicitly quantify the uncertainty inherent in their predictions. Nevertheless, these classifiers offer implicit signals of confidence primarily through softmax probabilities and the entropy of the predicted class distribution. These metrics serve as initial, easily accessible indicators of a model's belief. A critical understanding of their foundational role and, more importantly, their profound limitations is indispensable for appreciating the subsequent evolution of Out-of-Distribution (OOD) detection methodologies that strive for truly calibrated uncertainty estimates.\n\nA seminal contribution by \\cite{Hendrycks_G_2017} formalized the use of Maximum Softmax Probability (MSP) as a straightforward baseline for identifying both misclassified in-distribution (ID) and OOD examples. This work, alongside others, critically exposed a pervasive and dangerous flaw: neural networks frequently exhibit severe overconfidence, assigning high softmax probabilities to OOD inputs. This leads to erroneous high-confidence predictions that are fundamentally unreliable, as the model confidently asserts an input belongs to a known class despite having never encountered anything similar during training. The root cause of this overconfidence lies in the very design of the softmax function. As \\cite{Kendall_A_2017} elucidates, softmax is inherently a normalized probability distribution over a fixed set of *known* classes. It is optimized to express the model's certainty about which of the *trained* categories an input belongs to (reflecting *aleatoric uncertainty* due to inherent data noise), but it is ill-equipped to capture *epistemic uncertainty*â€”the model's lack of knowledge or confidence when confronted with inputs far removed from its training distribution. Consequently, an OOD input, by definition, falls outside the model's learned domain, yet the softmax mechanism forces it into one of the known categories, often with high confidence, simply by finding the \"closest\" match within its learned manifold.\n\nBeyond this conceptual mismatch, modern deep neural networks are frequently poorly calibrated \\cite{Guo_C_2017}. This means their predicted probabilities do not accurately reflect the true likelihood of correctness, exacerbating the overconfidence problem, particularly for OOD inputs. The architectural choices prevalent in deep learning, such as increased depth, ReLU activations, and optimization for accuracy rather than calibration, contribute to this miscalibration. When a model's confidence scores are unreliable even for ID data, their utility for discerning OOD samples becomes severely compromised. Furthermore, the issue of overconfidence is significantly compounded by the model's reliance on spurious correlations present in the training data. As \\cite{ming2021wu7} rigorously demonstrated, models trained on datasets containing statistically informative but non-causal features tend to exploit these shortcuts. When an OOD input shares these spurious features with ID data, the model can confidently assign a high softmax probability, even if the input lacks the invariant, semantic features crucial for correct classification. This reliance on misleading environmental cues makes distinguishing spurious OOD samples from ID data inherently challenging, as the model's confidence is rooted in a superficial correlation rather than true semantic understanding \\cite{ming2021wu7}.\n\nEmpirical and theoretical studies consistently underscore the inadequacy of raw softmax and entropy scores for robust OOD detection. \\cite{kuan2022qzl} provided extensive evidence that simple prediction-based methods like MSP and entropy are reliably outperformed by methods leveraging learned intermediate representations (embeddings). Their work challenged the notion of MSP as a universally strong baseline, demonstrating that while it might offer some rudimentary signal, it often falls short compared to approaches that analyze the internal feature space, which are better equipped to capture deviations from the ID manifold. This empirical observation is theoretically grounded by \\cite{peng20243ji}, who critically analyzed logit-based methods, including those derived from softmax. They explained that these methods are often not directly proportional to true data density. This fundamental disconnect implies that even when a model's logits are high, the resulting softmax probability does not necessarily reflect a high likelihood under the true in-distribution data manifold, leading to suboptimal OOD detection performance. Similarly, \\cite{averly20239rv}'s comprehensive evaluation, while introducing a model-specific perspective, implicitly highlights the context-dependent and often inconsistent performance of MSP across different types of OOD shifts (e.g., semantic vs. covariate) and misclassifications, reinforcing its limitations as a standalone, universally reliable uncertainty measure.\n\nIn summary, while softmax probabilities and entropy offer initial, easily accessible indicators of a neural network's confidence, their inherent limitations are profound and multifaceted. These include their inability to capture epistemic uncertainty due to their closed-set design, the pervasive problem of miscalibration in modern deep networks, and their vulnerability to spurious correlations in training data. These shortcomings collectively render raw output-based uncertainty estimates unreliable for robust OOD detection, particularly in safety-critical applications where silent failures can have severe consequences. This fundamental inadequacy necessitates the development of more sophisticated OOD detection methodologies that move beyond simple output scores, paving the way for the advanced post-hoc, feature-space, generative, and training-time strategies discussed in subsequent sections of this review.\n\\subsection{Post-Hoc Confidence-Based Detection}\n\\label{sec:2_2_post-hoc_confidence-based_detection}\n\n\nThe development of robust out-of-distribution (OOD) detection methods is paramount for ensuring the reliability and safety of machine learning systems in real-world applications. Early and highly influential research in this domain focused on leveraging and refining confidence scores derived from pre-trained discriminative classifiers. These \"post-hoc\" methods are particularly attractive due to their efficiency, as they do not require any model retraining or modification of the original classification objective, thereby minimizing computational overhead and preserving the model's primary task performance. This section details the evolution of such confidence-based approaches, from foundational baselines to sophisticated enhancements.\n\nA seminal contribution to this field was the introduction of Maximum Softmax Probability (MSP) as a baseline for OOD detection by \\cite{hendrycks17baseline}. This straightforward yet surprisingly effective method operates on the premise that a well-trained classifier should assign a high maximum softmax probability to in-distribution (ID) samples, reflecting strong confidence in its classification. Conversely, OOD samples, which do not align with any learned class, are expected to yield lower maximum probabilities. Despite its simplicity, MSP established a crucial benchmark, demonstrating that standard neural network outputs inherently contain valuable uncertainty signals. The work also played a pivotal role in standardizing evaluation protocols and datasets, fostering more rigorous comparisons across diverse OOD detection techniques. However, a significant limitation of MSP is the pervasive problem of neural network overconfidence on OOD inputs \\cite{community_0, community_5}. Models can often assign spuriously high confidence to novel, unseen data, especially for \"near OOD\" examples that share superficial similarities with ID data, leading to suboptimal discrimination and false negatives. This fundamental challenge highlights that raw softmax probabilities, while indicative, are not always reliable estimators of true data density or typicality \\cite{peng20243ji}.\n\nBuilding upon the insights from MSP, \\cite{Liang_etal_2018} introduced Out-of-Distribution Detector for Neural Networks (ODIN), a method designed to significantly amplify the distinction between ID and OOD samples without requiring any model retraining. ODIN introduced two key innovations. First, it incorporated temperature scaling, a technique originally used for model calibration, which smooths the softmax distribution by dividing the logits by a temperature parameter $T$. This adjustment makes the confidence scores less extreme and often more discriminative for OOD detection by re-calibrating the output probabilities. Second, and more crucially, ODIN proposed a small, carefully crafted input perturbation. This perturbation is calculated to push the input towards the direction that maximizes the softmax probability for the predicted class. For ID samples, this makes them \"more ID-like\" in the model's perception, increasing their confidence. For OOD samples, which lack a strong alignment with any ID class, this perturbation often fails to significantly boost confidence or may even push them towards lower confidence, thereby increasing the separation in confidence scores between ID and OOD data. By combining these two simple yet powerful post-hoc techniques, ODIN substantially boosted OOD detection performance over MSP, establishing a strong, efficient baseline.\n\nFurther refining the ODIN paradigm, \\cite{Hsu_Y_2020} proposed Generalized ODIN (G-ODIN), which aimed to improve robustness by addressing a potential weakness in ODIN's perturbation strategy. While ODIN perturbs inputs to maximize confidence for the *predicted* class, G-ODIN considers a broader context. Instead of relying on a single predicted class, G-ODIN perturbs the input towards the direction that minimizes the maximum softmax probability across *all* ID classes. This approach makes the OOD score more robust by ensuring that an OOD sample is not mistakenly pushed to high confidence for an incorrect ID class. By considering the full set of ID classes during perturbation, G-ODIN can achieve better discrimination, especially when OOD samples might be ambiguous or share features with multiple ID categories.\n\nThe concept of temperature scaling, a cornerstone of ODIN, has continued to evolve. Recognizing that a fixed global temperature might not be optimal for all samples, \\cite{krumpl2024n1w} introduced Adaptive Temperature Scaling (ATS). ATS proposes dynamically calculating a *sample-specific* temperature value based on activations from intermediate layers of the neural network. By fusing this sample-specific adjustment with class-dependent logits, ATS captures additional statistical information that might otherwise be lost in the feature extraction process. This dynamic approach leads to a more robust and powerful OOD detection method, demonstrating that even subtle refinements to temperature scaling can significantly enhance the performance and robustness of existing logit-based OOD detection techniques.\n\nWhile highly effective and efficient, these confidence-based methods fundamentally rely on the assumption that the classifier's output space (logits or softmax probabilities) can reliably distinguish between ID and OOD data. However, as highlighted by \\cite{peng20243ji}, raw logit-based scores, including energy scores (which are closely related to logits), often make implicit assumptions about the underlying data distribution, such as constant partition functions across classes, or that softmax probabilities directly represent true data densities. These assumptions are not always accurate, limiting the theoretical grounding and empirical robustness of simpler confidence scores. To address this, \\cite{peng20243ji} proposed ConjNorm, a novel theoretical framework grounded in Bregman divergence, which unifies density function design for OOD detection within the exponential family of distributions. By devising an unbiased and analytically tractable estimator for the partition function using importance sampling, ConjNorm offers a more principled and flexible approach to density estimation for OOD scoring, moving beyond restrictive distributional assumptions and leading to superior empirical performance. This work signifies a critical advancement towards more theoretically robust confidence-based OOD measures.\n\nIn summary, post-hoc confidence-based detection methods, starting from the simplicity of MSP and progressing through the innovative enhancements of ODIN, G-ODIN, and ATS, have laid a robust foundation for the field. They collectively demonstrated that significant improvements in uncertainty quantification could be achieved by cleverly leveraging and refining the outputs of existing pre-trained classifiers without the need for costly retraining. However, their inherent reliance on the classifier's output space and the potential for overconfidence or inaccurate density estimation remain persistent challenges. These limitations motivate the exploration of richer, intermediate representations and more theoretically grounded approaches to OOD detection, which are discussed in subsequent sections.\n\\subsection{Feature-Space Distance-Based Methods}\n\\label{sec:2_3_feature-space_distance-based_methods}\n\n\nEarly efforts in out-of-distribution (OOD) detection quickly recognized the inherent limitations of relying solely on a neural network's final output probabilities, such as Maximum Softmax Probability (MSP). While simple, MSP often fails to capture the true uncertainty for samples significantly deviating from the in-distribution (ID) manifold, frequently exhibiting overconfidence on novel inputs. This critical observation spurred a shift towards leveraging the internal feature representations of neural networks, driven by the hypothesis that OOD samples would manifest as distinct patterns or lie significantly distant from the ID data within these learned embedding spaces.\n\nA foundational exploration into using internal representations for OOD detection was presented by \\cite{Hendrycks_G_2017}. While this work primarily established MSP as a baseline, it also investigated the efficacy of Mahalanobis distance computed on features from intermediate layers. By modeling the distribution of ID features for each class as a simple Gaussian, OOD samples could be identified as those with a large Mahalanobis distance to all ID class centroids. This early insight highlighted the potential of feature-level analysis to provide more robust OOD scores than simple output probabilities, laying crucial groundwork.\n\nBuilding upon this concept, \\cite{Lee_K_2018} introduced a more comprehensive framework that explicitly leverages Mahalanobis distance in the feature space for OOD detection. This method models the in-distribution feature representations for each class using class-conditional Gaussian distributions, where the mean and covariance are estimated from the training data. An input is then classified as OOD if its Mahalanobis distance to all ID class centroids is sufficiently large. Crucially, \\cite{Lee_K_2018} also proposed using generative adversarial networks (GANs) to regularize the feature space during training. By training a GAN to generate OOD samples and then using these to push OOD representations away from ID clusters, the feature space becomes more discriminative, enhancing the separation between ID and OOD samples and making the Mahalanobis distance a more effective OOD score. This approach demonstrated a significant advancement by actively shaping the feature space to be more amenable for OOD discrimination, moving beyond merely observing existing features.\n\nDespite its principled nature, the effectiveness of Mahalanobis distance-based methods can be limited by the strong assumption of Gaussianity for ID features and the quality of the learned features, particularly in high-dimensional spaces where the \"curse of dimensionality\" can render distance metrics less meaningful \\cite{ghosal2023q20}. This motivated further research into refining the feature space and the distance calculations themselves. For instance, \\cite{anthony2023slf} conducted an in-depth analysis of Mahalanobis distance for medical imaging OOD detection, challenging the common assumption of a single optimal layer for detection. They empirically demonstrated that the optimal network depth for OOD detection is highly dependent on the specific OOD pattern and proposed a Multi-branch Mahalanobis (MBM) framework. MBM employs multiple OOD detectors operating at different depths of the network, each combining normalized Mahalanobis scores from its constituent modules, significantly enhancing robustness by capturing diverse OOD signals across the feature hierarchy.\n\nTo mitigate the curse of dimensionality and improve feature space utility, researchers have explored learning more structured and compact representations. \\cite{zaeemzadeh2021lmh} proposed training deep neural networks to embed ID samples onto a union of 1-dimensional subspaces. This compact representation ensures that OOD samples are less likely to occupy the same region as known classes, and robust representatives (singular vectors) can be used for distance calculations, thereby simplifying OOD detection. Similarly, \\cite{ghosal2023q20} introduced Subspace Nearest Neighbor (SNN), a framework that regularizes the model and its feature representation by leveraging the most relevant subset of dimensions. This subspace learning yields highly distinguishable distance measures between ID and OOD data, demonstrating significant improvements over previous distance-based methods by making the distances more robust to high-dimensional noise. Extending this, \\cite{li2025jdt} proposed a novel \"tangent distance\" that explicitly accounts for the data structure by mapping high-dimensional features to the manifold of ID samples. This method computes the Euclidean distance between samples and the nearest submanifold space (a linear approximation of the local region on the manifold), providing a more meaningful distance measure that is less sensitive to the curse of dimensionality.\n\nBeyond Mahalanobis and its direct refinements, other distance-based approaches leverage different metrics or modeling assumptions. K-Nearest Neighbors (KNN) based methods, for example, directly quantify OODness by measuring the distance of a test sample to its $k$-nearest neighbors within the ID training data's feature space, offering a non-parametric alternative to Gaussian models. In a more modern context, \\cite{vojivr202444c} introduced PixOOD for pixel-level OOD detection, which, while operating at a finer granularity, fundamentally relies on distances. It extracts pixel/patch feature representations and builds a 2D projection space where distances to multiple class etalons (learned prototypes) are used to model complex intra-class variability and identify OOD pixels. This demonstrates how distance-based principles can be adapted for fine-grained OOD detection by modeling ID distributions with multiple prototypes rather than a single centroid.\n\nIn summary, feature-space distance-based methods represent a crucial evolution in OOD detection, moving beyond simple output probabilities to leverage the richer information in internal representations. They have progressed from initial explorations of Mahalanobis distance on existing features to sophisticated techniques that actively regularize, learn, or project OOD-discriminative feature spaces. While these methods have shown promise in quantifying an input's deviation from the in-distribution manifold, challenges persist, including the sensitivity to the quality of learned features, the computational cost associated with training-time regularization, and the inherent difficulties of distance metrics in high-dimensional spaces. Future directions include developing more flexible models for feature distributions (e.g., non-parametric density estimation or advanced mixture models), integrating self-supervised learning to learn more robust features, and exploring adaptive distance metrics that can better capture complex manifold structures. Furthermore, the utility of these distance-based OOD scores is increasingly recognized in broader uncertainty quantification frameworks, such as their application as non-conformity scores within Conformal Prediction to provide statistically rigorous guarantees on OOD detection performance \\cite{novello2024yco}.\n",
    "Generative and Reconstruction-Based Approaches": "\\section{Generative and Reconstruction-Based Approaches}\n\\label{sec:generative__and__reconstruction-based_approaches}\n\n\n\n\\subsection{Likelihood-Based Deep Generative Models}\n\\label{sec:3_1_likelihood-based_deep_generative_models}\n\n\nThe detection of Out-of-Distribution (OOD) samples is a critical challenge for deploying reliable deep learning systems. A theoretically principled approach to OOD detection involves leveraging deep generative models to learn the underlying data distribution of in-distribution (ID) samples. The fundamental premise is that samples originating from outside this learned distribution, i.e., OOD samples, should exhibit a significantly lower likelihood or probability density under the model trained exclusively on ID data. This allows for their identification based on their deviation from the learned ID manifold, offering a theoretically grounded method for uncertainty quantification. Early methods primarily explored Variational Autoencoders (VAEs) \\cite{Kingma_Welling_2013} and Generative Adversarial Networks (GANs) \\cite{Goodfellow_etal_2014} for this purpose. VAEs provide an estimate of the data log-likelihood (or a lower bound, ELBO), while GANs can be adapted to provide density estimates or use discriminator scores as proxies for typicality.\n\nInitially, the intuitive strategy was to directly use the raw likelihood or a related reconstruction error from a trained generative model as an OOD score. However, this straightforward application often proved problematic. Raw likelihood scores from deep generative models can be inherently misleading, frequently assigning higher likelihoods to certain OOD samples than to some ID samples \\cite{Nalisnick_etal_2019_Do_Deep_Generative_Models_Know_What_They_Don_t_Know}. This counter-intuitive phenomenon, observed across various model architectures and datasets, stems from several factors. Deep generative models, particularly in high-dimensional spaces, may learn spurious low-level correlations or assign high probabilities to simple, out-of-distribution inputs that lie in regions of the input space not well-constrained by the ID data. This can be exacerbated by the \"Gaussian Annulus Theorem,\" where in high dimensions, the typical set of data (where most of the probability mass lies) may not intersect with the region of highest density, leading to OOD samples with high likelihood but low typicality \\cite{morningstar2020re9}. For VAEs, the Evidence Lower Bound (ELBO) is only a lower bound to the true log-likelihood, and a tighter bound does not necessarily correlate with better OOD detection performance. Even models capable of exact likelihood estimation, such as Normalizing Flows (NFs) \\cite{Dinh_etal_2016} and Autoregressive models (e.g., PixelCNNs), suffer from this issue, often assigning higher likelihoods to less complex OOD images than to complex ID images, further demonstrating that raw likelihood alone is an unreliable indicator of semantic OODness \\cite{osada20246an}.\n\nTo address the unreliability of raw likelihood scores, more robust statistical measures were introduced, marking an evolution from simple density estimation to more refined statistical tests. A pivotal advancement was proposed by \\cite{Ren_J_2019}, who demonstrated that comparing the likelihood of a sample under the learned ID distribution to its likelihood under a simpler, \"null\" model provides a significantly more effective OOD score. Their work introduced the concept of likelihood ratio tests for OOD detection, where the ratio of the likelihood under a complex ID generative model (e.g., VAE or GAN) to that under a baseline model (e.g., a simple Gaussian distribution or a model trained on diverse OOD data) serves as a robust discriminator. This approach effectively normalizes the raw likelihood, focusing on how *much better* the ID model explains the data compared to a general or OOD model, thereby improving OOD discrimination and mitigating the issues associated with misleading raw likelihood values.\n\nBeyond simple likelihood ratios, other sophisticated statistical approaches have emerged to leverage generative models more effectively. \\cite{morningstar2020re9} introduced Density of States Estimation (DoSE), an unsupervised method that moves beyond direct model probabilities. Inspired by statistical physics, DoSE evaluates the \"typicality\" of an input by analyzing multiple summary statistics (e.g., negative log-likelihood, L2 norm of latent features) derived from a pre-trained generative model. Instead of directly comparing likelihoods, DoSE trains non-parametric density estimators (like Kernel Density Estimation or one-class SVMs) on the distribution of these statistics for ID data. An OOD sample is then identified if its derived statistics are atypical under these learned distributions, providing a more robust measure of OODness that accounts for the high-dimensional nature of the problem and the shortcomings of raw likelihood.\n\nFurthermore, Normalizing Flows, which provide exact and tractable likelihoods, have seen increasing application in OOD detection, often by modeling densities in feature spaces rather than raw pixel space. For instance, \\cite{zisselman2020cmx} proposed Deep Residual Flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution, improving OOD detection by modeling feature activations. Similarly, \\cite{cook2024hyb} investigated feature density estimation via Normalizing Flows as a fully unsupervised, post-hoc method. By training a lightweight NF model on the feature representations of a pre-trained classifier, they demonstrated strong results for far-OOD detection, highlighting that while raw input likelihoods can be problematic, density estimation in a more semantically meaningful feature space can be highly effective.\n\nThe evolution from simple density estimation to more refined statistical measures like likelihood ratio tests and typicality-based approaches, coupled with the broader application of diverse generative architectures like Normalizing Flows, marks a significant progression in the field. While likelihood-based methods offer a theoretically grounded approach to OOD detection, challenges persist in accurately modeling complex, high-dimensional data distributions and ensuring that likelihood estimates genuinely correlate with semantic OODness across diverse scenarios. Future work continues to explore more robust generative architectures, improved background models for ratio tests, and sophisticated statistical tests to further bridge the gap between theoretical soundness and practical efficacy in real-world OOD detection tasks.\n\\subsection{Reconstruction Autoencoders: Advancements and Limitations}\n\\label{sec:3_2_reconstruction_autoencoders:_advancements__and__limitations}\n\n\nTraditional reconstruction autoencoders (AEs) were initially considered a promising avenue for Out-of-Distribution (OOD) detection, operating under the intuitive assumption that models trained exclusively on in-distribution (ID) data would struggle to reconstruct novel OOD inputs, leading to higher reconstruction errors. However, this foundational premise frequently faltered due to a fundamental design paradox: the inherent capacity of deep autoencoders to generalize and effectively reconstruct diverse novel inputs \\cite{Ren_etal_2019}. This powerful generalization, while beneficial for tasks like denoising or data compression, often meant that OOD samples yielded reconstruction errors comparable to, or even lower than, ID samples \\cite{morningstar2020re9}. Consequently, the simple reconstruction error proved to be an unreliable metric for distinguishing ID from OOD data, severely limiting the practical utility of early AE-based methods in safety-critical applications. This critical limitation necessitated a significant re-evaluation and sophisticated re-engineering of their underlying principles to transform them into reliable OOD detectors.\n\nEarly attempts to leverage reconstruction error for OOD detection, including simpler methods like Principal Component Analysis (PCA) for dimensionality reduction and subsequent reconstruction, often faced this challenge \\cite{guan2023dwv}. The core problem was designing autoencoders that could learn a sufficiently tight manifold of ID data without inadvertently developing the capacity to reconstruct novel patterns. This challenge spurred significant advancements that fundamentally rethought the autoencoder's objective and architecture, moving beyond raw pixel reconstruction and simple L2 error.\n\nOne pivotal advancement has been the shift from pixel-level reconstruction to \\textit{semantic feature reconstruction}. Reconstructing raw pixels demands high expressiveness from the autoencoder, which can inadvertently generalize to OOD inputs. Instead, modern approaches often focus on reconstructing robust, high-level features extracted from pre-trained models. This strategy aligns with broader trends in OOD detection that leverage discriminative feature spaces \\cite{Lee_etal_2018}. For instance, \\cite{zhou202250i} exemplifies this by reconstructing Activation Vectors (AVs) from the penultimate layer of a pre-trained classifier. This strategic shift simplifies the autoencoder's task to lower-dimensional, semantically relevant features, ensuring that the autoencoder's learning is concentrated on the abstract, task-specific characteristics of ID data. Deviations in reconstructing these semantic features are thus more indicative of OODness than pixel-level discrepancies, which might be influenced by superficial similarities.\n\nConcurrently, to prevent the latent space from accommodating novel patterns, methods have increasingly enforced a \\textit{maximally compressed or regularized latent space} for ID samples. This is achieved through regularization losses during training that actively restrict ID latent features to a compact, known domain. Variational Autoencoders (VAEs), a class of generative models that learn a latent distribution, inherently aim for a more structured latent space, which can be leveraged for OOD detection. For example, \\cite{cai2020lsi} integrates VAEs into an Inductive Conformal Anomaly Detection (ICAD) framework for real-time OOD detection in cyber-physical systems. Here, the VAE's ability to reconstruct ID data from its learned latent space, combined with Deep Support Vector Data Description (SVDD) for learning a minimum-volume hypersphere, effectively enforces a tight ID manifold. Similarly, \\cite{60108b8e0d7204fa33f686b09128c7fc8489a224} explores the use of self-attention within VAEs to learn more discriminative and compact latent representations specifically for anomaly detection. \\cite{zhou202250i} also enforces this explicit constraint, ensuring that any input whose latent representation falls outside this tightly defined space is likely OOD. This contrasts sharply with earlier autoencoders that allowed latent spaces to form organically, often encompassing regions where OOD samples could reside without significant reconstruction penalty.\n\nFurthermore, to address the challenge of recovering significant information from an extremely compressed latent space in a single step, \\cite{zhou202250i} proposes a novel \\textit{layerwise decomposition for incremental information recovery}. This \"data certainty decomposition\" framework factorizes the probability of an input being ID into a product of conditional probabilities, employing a series of decoders. Each decoder is specifically designed to recover information lost after *each individual encoding layer*, rather than a single decoder attempting to recover all accumulated loss from the final, most compressed latent representation. This incremental recovery mechanism enhances the autoencoder's ability to faithfully reconstruct ID samples while remaining highly sensitive to OOD deviations at various levels of abstraction.\n\nFinally, to overcome the issue of standard L2 reconstruction error being an unreliable uncertainty measure (often yielding misleadingly small errors for OOD samples due to smaller activation magnitudes), \\cite{zhou202250i} introduces the \\textit{Normalized L2 Distance (NL2)}. This novel metric normalizes the reconstruction by the input's norm, effectively eliminating the confounding influence of feature magnitude and providing a more robust and reliable measure of reconstruction accuracy. The need for more robust scoring functions for reconstruction error is also echoed in works like \\cite{guan2023dwv}, which demonstrates that even a simple regularized PCA-based reconstruction error can significantly improve OOD detection when fused with other scoring functions, highlighting that raw reconstruction error often requires refinement or combination to be effective. These collective innovations directly address the traditional flaws of reconstruction autoencoders, transforming them into more reliable OOD detectors by ensuring that reconstruction error truly reflects OODness rather than merely the model's generalization capacity.\n\nWhile these advancements, exemplified by works like \\cite{zhou202250i} and \\cite{cai2020lsi}, significantly revitalize reconstruction autoencoders for OOD detection, inherent challenges persist. The reliance on a pre-trained classifier for extracting Activation Vectors, as in \\cite{zhou202250i}, means the method's effectiveness is intrinsically tied to the quality, robustness, and potential biases of that classifier. If the feature extractor itself is not robust to certain distribution shifts, the OOD detector built upon it will inherit these limitations. Furthermore, defining what constitutes a \"maximally compressed\" latent space and ensuring its boundaries are sufficiently robust to all possible ID variations, while still being tight enough to reject all OOD, remains an intricate balance. Overly restrictive latent spaces might misclassify complex ID samples as OOD, while overly permissive ones risk the original generalization problem. The computational overhead introduced by multi-decoder architectures and complex regularization also needs consideration for real-time applications, particularly in resource-constrained environments like those discussed in \\cite{cai2020lsi}. Future research could explore adaptive mechanisms for latent space compression, investigate more sophisticated theoretical frameworks for quantifying the \"OODness\" reflected by reconstruction errors in highly complex, high-dimensional data, and develop more robust and adaptive thresholding strategies for reconstruction-based scores, potentially incorporating fusion with other OOD signals as suggested by \\cite{guan2023dwv}.\n\\subsection{Energy-Based Models for OOD Detection}\n\\label{sec:3_3_energy-based_models_for_ood_detection}\n\n\nEnergy-Based Models (EBMs) have emerged as a theoretically principled and increasingly effective framework for Out-of-Distribution (OOD) detection, offering a direct approach to modeling the underlying data distribution. At their core, EBMs define a probability distribution over inputs $x$ using an energy function $E(x)$ as $p(x) = \\frac{\\exp(-E(x))}{Z}$, where $Z = \\int \\exp(-E(x)) dx$ is the intractable partition function \\cite{Grathwohl_etal_2019}. In this paradigm, in-distribution (ID) samples are characterized by low energy values, indicating high likelihood under the learned distribution, while OOD samples are assigned high energy values, signifying low likelihood. This direct modeling of data likelihood provides a more interpretable and robust measure of OODness compared to relying on proxy metrics like maximum softmax probabilities, which often exhibit overconfidence on OOD inputs \\cite{Liu_etal_2020}.\n\nA foundational insight into the connection between classifiers and EBMs was provided by \\textcite{Grathwohl_etal_2019}, who demonstrated that a standard classifier's output logits can be interpreted as an unnormalized negative energy function. This perspective paved the way for explicitly leveraging energy functions for OOD detection. Building on this, \\textcite{Liu_etal_2020} pioneered the use of Energy-based Models for OOD detection by defining the energy function directly from the output logits of a standard neural network classifier. Their significant contribution lay in developing specialized training objectives to explicitly learn these energy landscapes. This typically involves a contrastive learning approach, where the model is trained to push the energy of ID samples to be low while simultaneously increasing the energy of OOD samples. The challenge of the intractable partition function $Z$ is often circumvented during training by employing techniques like Stochastic Gradient Langevin Dynamics (SGLD) to sample from the model's distribution and approximate gradients, effectively optimizing the unnormalized density ratio rather than the absolute density \\cite{Liu_etal_2020, lafon2023w37}. This direct optimization for OOD discrimination offers a more theoretically grounded and robust measure than post-hoc methods.\n\nWhile many EBM approaches implicitly handle the intractable partition function through contrastive learning and sampling, \\textcite{peng20243ji} directly addresses this challenge by proposing ConjNorm, a method for tractable density estimation for post-hoc OOD detection. Their work introduces a novel theoretical framework grounded in Bregman divergence, extending density considerations to the exponential family of distributions. Crucially, ConjNorm devises an unbiased and analytically tractable estimator for the partition function using a Monte Carlo-based importance sampling technique, providing a principled way to estimate true data density without strong distributional assumptions. This represents a significant advancement by offering a direct solution to a core theoretical hurdle in EBMs.\n\nSubsequent research has explored diverse strategies to enhance EBMs for OOD detection. \\textcite{lafon2023w37} introduced HEAT (Hybrid Energy Based Model in the Feature Space), a novel post-hoc method that refines existing OOD detectors (e.g., GMMs, energy logits) by complementing them with a data-driven residual EBM. HEAT uses the EBM framework to compose several energy terms from different refined priors, allowing for accurate and robust ID density estimation without requiring external OOD samples for training. This demonstrates how EBMs can be integrated to correct biases and enhance the expressiveness of other OOD scoring functions.\n\nFurthermore, EBMs have been adapted to address specific challenges in OOD detection. \\textcite{choi202367m} proposed a \"balanced energy regularization loss\" to tackle the problem of imbalanced auxiliary OOD data, which is often overlooked in methods like Outlier Exposure. Their approach adaptively applies larger regularization to auxiliary samples from majority classes, ensuring a more effective energy landscape shaping. Similarly, in the context of Class-Incremental Learning (CIL), \\textcite{miao20246mk} introduced Bi-directional Energy Regularization (BER). BER mitigates biases in CIL models by using energy loss functions to enlarge decision boundaries for new classes (pushing OOD away) and boost confidence for old classes (preventing old ID from being misclassified as OOD), showcasing EBMs' utility in dynamic learning environments.\n\nBeyond direct energy minimization, energy functions can also guide adaptive training. \\textcite{hofmann2024gnx} introduced Hopfield Boosting, an OOD detection framework that leverages Modern Hopfield Energy (MHE) to adaptively sample \"weak learners\" from auxiliary outlier datasets that are hard to distinguish from ID data. By incorporating an MHE-based energy function into the training loss, this method explicitly sharpens the decision boundary between ID and OOD data, demonstrating a sophisticated use of energy to improve outlier exposure strategies.\n\nThe scalability of EBMs to modern deep learning architectures has also been a focus. \\textcite{Ming_etal_2023} extended the EBM framework by demonstrating how to effectively fine-tune large pre-trained models, such as vision transformers, for energy-based OOD detection. This approach leverages the rich, generalizable representations learned by these powerful models, addressing the challenge of robust OOD detection in complex, high-dimensional data settings and highlighting the adaptability of the EBM paradigm.\n\nIn summary, EBMs provide a theoretically sound framework for OOD detection by directly modeling data likelihood through an energy function. The evolution of EBMs for OOD detection has progressed from foundational insights into their connection with classifiers \\cite{Grathwohl_etal_2019} and pioneering contrastive training strategies \\cite{Liu_etal_2020}, to more sophisticated approaches that directly address the partition function intractability \\cite{peng20243ji}, integrate with and refine other OOD methods \\cite{lafon2023w37}, adapt to specific learning challenges like imbalanced OOD data or incremental learning \\cite{choi202367m, miao20246mk}, and leverage energy functions for adaptive training \\cite{hofmann2024gnx}. Their ability to integrate with large pre-trained models further underscores their potential for robust OOD detection in real-world applications \\cite{Ming_etal_2023}.\n\nFuture research in EBMs for OOD detection could explore more advanced techniques for approximating or tractably estimating the partition function in complex, high-dimensional settings, potentially drawing from advancements in score-matching or normalizing flows. Investigating adaptive energy functions that can dynamically adjust to different types of OOD shifts or domain contexts, perhaps through hypernetworks, could also yield more versatile detectors. Furthermore, exploring the interplay between EBMs and generative modeling to synthesize highly informative OOD examples for contrastive training, or to learn more expressive energy landscapes, remains a promising avenue.\n",
    "Training-Time Strategies and Robust Representation Learning": "\\section{Training-Time Strategies and Robust Representation Learning}\n\\label{sec:training-time_strategies__and__robust_representation_learning}\n\n\n\n\\subsection{Outlier Exposure and Virtual Outlier Synthesis}\n\\label{sec:4_1_outlier_exposure__and__virtual_outlier_synthesis}\n\n\nThe challenge of deploying deep learning models in open-world environments necessitates robust mechanisms for identifying Out-of-Distribution (OOD) inputs. A significant advancement in this area is the Outlier Exposure (OE) paradigm, where auxiliary OOD data is incorporated during model training to explicitly teach the model to distinguish novel inputs. This approach often frames OOD detection as a binary classification task, differentiating between in-distribution (ID) and OOD data.\n\nThe theoretical underpinnings of OE suggest that many methods leveraging OOD training data are asymptotically equivalent to a binary discriminator, with practical differences often stemming from estimation procedures and the specific choice of auxiliary OOD data \\cite{bitterwolf2022rw0}. Early implementations of OE demonstrated its effectiveness, but subsequent research has focused on refining its application and addressing inherent limitations. For instance, \\cite{choi202367m} identified that auxiliary OOD data often exhibits class imbalance, proposing a balanced energy regularization loss to apply stronger regularization to majority OOD classes, thereby enhancing detection performance in diverse tasks like semantic segmentation and long-tailed classification. Addressing the vulnerability of OE to adversarial attacks, \\cite{chen2020mbk} introduced Adversarial Learning with inlier and Outlier Exposure (ALOE), which robustifies detectors by training against both adversarial in-distribution and OOD examples, significantly improving robustness against perturbations.\n\nAs OE matured, its application extended to more complex scenarios. In long-tailed recognition, where distinguishing OOD from tail classes is particularly challenging, \\cite{miao2023brn} proposed Calibrated Outlier Class Learning (COCL). This method uses debiased large margin learning and outlier-class-aware logit calibration to explicitly separate OOD samples from both head and tail ID classes, outperforming traditional OE by mitigating class-specific biases. Similarly, \\cite{wei2023f15} introduced EAT, which employs dynamic virtual labels for OOD data and context-rich tail class augmentation to improve OOD detection in long-tailed settings, demonstrating that strong inlier classification does not automatically imply good OOD detection.\n\nDespite its successes, a critical limitation of OE is the reliance on the availability and diversity of *real* auxiliary OOD data. Collecting sufficiently diverse and representative OOD datasets is often impractical or impossible, leading to a shift towards Virtual Outlier Synthesis (VOS). VOS addresses this data scarcity by generating synthetic outliers, thereby overcoming the dependence on real OOD datasets and enhancing model robustness.\n\nEarly forays into VOS, such as Mixture Outlier Exposure (MixOE) by \\cite{zhang20212tb}, generated virtual outliers by mixing ID and auxiliary data. This approach was particularly effective for fine-grained OOD detection, where novel inputs are semantically similar to ID data and require a broader coverage of the feature space. Building on the need for diversity, \\cite{jiang2023vzb} introduced Diverse Outlier Sampling (DOS), a strategy that selects diverse and informative outliers from auxiliary datasets by combining clustering on normalized features with uncertainty-based selection. This aimed to shape a globally compact decision boundary, improving upon biased greedy sampling. Further advancing this, \\cite{yao2024epq} proposed `diverseMix`, a diversity-induced mixup strategy with theoretical guarantees, which generates semantically distinct synthetic outliers through dynamic interpolation, provably enhancing the diversity of the auxiliary set.\n\nMore sophisticated VOS methods have emerged, generating synthetic outliers directly from in-distribution data or leveraging advanced generative models. \\cite{nie2024ghv} introduced Virtual Outlier Smoothing (VOSo), which constructs auxiliary OOD samples by perturbing semantic regions of ID samples in the *image space*, using Class Activation Maps (CAMs). Crucially, VOSo assigns dynamic soft labels based on the perturbation extent, creating a smoother decision boundary and more nuanced uncertainty estimation than traditional uniform OOD labels. Similarly, \\cite{yang2023pre} (MixOOD) also utilized Mixup-based strategies to generate augmented images as auxiliary OOD data, demonstrating improved distinction between ID and OOD samples. \\cite{chen20243na} explored a \"negative branch\" method with directional regularization and OOD training data, which implicitly functions as a form of virtual outlier generation to enhance anomaly detection.\n\nThe advent of large pre-trained models, particularly Vision-Language Models (VLMs), has opened new avenues for VOS. \\cite{ding20242m0} proposed Outlier Label Exposure (OLE) for zero-shot OOD detection, which generates textual outlier prototypes by clustering and refining auxiliary outlier class labels. This effectively synthesizes OOD knowledge in the language domain, enhancing VLM safety without extensive training. Complementing this, \\cite{li20245b6} introduced `NegPrompt`, a method that learns transferable negative prompts for each ID class using only ID data. These negative prompts implicitly define OOD boundaries, enabling open-vocabulary OOD detection by leveraging the VLM's semantic understanding. \\cite{miyai2023591} (GL-MCM) further explored VLM capabilities by combining global and local concept matching for zero-shot OOD, implicitly handling multi-object OOD scenarios by leveraging local features to overcome contamination of global features. \\cite{yu20249dd} developed Self-Calibrated Tuning (SCT) for VLMs, which adaptively balances ID classification and OOD regularization by leveraging ID-irrelevant local context as surrogate OOD data, addressing the issue of spurious OOD features.\n\nGenerative models, especially diffusion models, have also been harnessed for VOS. \\cite{gao2023kmk} introduced DiffGuard, a semantic mismatch-guided OOD detection method that uses pre-trained diffusion models. It synthesizes new images conditioned on an input and its predicted label, identifying OOD samples by measuring the dissimilarity between the original and synthesized images. This approach leverages the conditional generation capabilities of diffusion models to highlight semantic contradictions, overcoming scalability issues of prior generative methods.\n\nThe VOS paradigm has also extended to specialized domains and multimodal inputs. For pixel-wise OOD detection in semantic segmentation, \\cite{besnier2021jgn} (ObsNet+LAA) generates OOD-like training data via local adversarial attacks, simulating unknown objects to train an auxiliary observer network. Similarly, \\cite{liu2022fdj} (RPL) utilizes Outlier Exposure with synthetic OOD data to learn residual anomaly patterns without retraining the base segmentation model. In 3D LiDAR-based object detection, \\cite{ksel20246fe} generates synthetic OOD objects by perturbing known ID object categories, addressing data scarcity in this domain. For multimodal OOD detection, \\cite{dong2024a8k} introduced Nearest Neighbor Prototype-based Mixup (NP-Mix) as part of their Agree-to-Disagree (A2D) algorithm, generating outliers by leveraging nearest neighbor class prototypes to explore broader feature spaces. Building on this, \\cite{li2024rs5} proposed Dynamic Prototype Updating (DPU), which dynamically adjusts multimodal prediction discrepancy intensification based on a sample's similarity to its class prototype, accounting for intra-class variability in multimodal data. Finally, \\cite{hofmann2024gnx} introduced Hopfield Boosting, an OE approach that adaptively samples \"hard\" outliers using a novel energy function derived from Modern Hopfield Networks, further refining the selection of informative synthetic or real outliers.\n\nIn conclusion, Outlier Exposure has evolved from a foundational paradigm to a sophisticated framework that explicitly trains models to recognize novel inputs. The critical challenge of OOD data scarcity has driven the field towards Virtual Outlier Synthesis, which leverages advanced techniques like semantic-level interpolation, adversarial generation, and prompt-based synthesis to create diverse and effective training examples. While VOS has significantly reduced the reliance on real OOD datasets and enhanced model robustness across various modalities and tasks, ongoing challenges include ensuring the representativeness of synthetic outliers for truly unknown OOD distributions, scaling complex generation methods, and developing stronger theoretical guarantees for their generalization capabilities.\n\\subsection{Learning Robust and Separable Feature Representations}\n\\label{sec:4_2_learning_robust__and__separable_feature_representations}\n\nThe intrinsic quality and structured organization of a model's internal feature representations are paramount for effective Out-of-Distribution (OOD) detection. This subsection delves into advanced methodologies that actively engineer the deep neural network's embedding space, aiming to enhance the discriminability between in-distribution (ID) and OOD samples. These approaches collectively improve the inherent OOD robustness of the learned representations by designing a more structured and discriminative embedding space, often by enforcing explicit geometric separation, creating more compact and well-defined ID clusters, or refining feature transformations.\n\nA significant line of research leverages the intrinsic properties of deep neural networks, particularly the phenomenon of Neural Collapse (NC), to enforce explicit geometric separation between ID classes and push OOD samples away. Neural Collapse describes the convergence of features within each class to their respective class means, and these class means to a simplex equiangular tight frame (ETF) structure in the terminal phase of training. Building on this, \\cite{ammar2023pr1} introduced NECO, a post-hoc method that capitalizes on a newly observed property dubbed ID/OOD Orthogonality (NC5). This property posits that OOD data tends to become increasingly orthogonal to the principal component space spanned by ID class means. NECO exploits this by projecting features onto this ID-derived principal component space, using the projection magnitude as an OOD score. A smaller projection magnitude indicates higher OOD likelihood. Extending this concept, \\cite{wu20242p3} proposes a novel separation loss (`LSep`) that actively constrains OOD features to reside in a subspace orthogonal to the principal subspace of ID features, which is implicitly defined by the final layer's weights. This approach moves beyond merely observing orthogonality to explicitly enforcing it during training, typically by leveraging auxiliary OOD data to push their features into distinct, non-overlapping dimensions. An earlier, more general effort towards compact ID representations, \\cite{zaeemzadeh2021lmh} proposed embedding ID samples into a low-dimensional space forming a union of 1-dimensional subspaces, arguing that such a highly constrained representation inherently makes it less likely for OOD samples to occupy ID regions. While Neural Collapse-based methods offer strong theoretical underpinnings for explicit separation, their robustness to subtle, near-OOD shifts that might not perfectly align with orthogonal subspaces remains a critical area for further investigation, as these shifts might still project significantly onto the ID subspace.\n\nBeyond direct geometric enforcement, feature transformation and subspace learning techniques are employed to enhance separability, often addressing the \"curse of dimensionality\" that can plague distance-based methods in high-dimensional feature spaces. Traditional linear dimensionality reduction methods often struggle to capture the complex non-linear relationships inherent in deep features. \\cite{song2022f5d} introduced RankFeat, a post-hoc method that uses Singular Value Decomposition (SVD) to identify and remove a dominant rank-1 component from high-level features. This spectral manipulation implicitly refines the feature space by mitigating the over-confidence induced by this component in OOD samples, effectively \"flattening\" the feature manifold. Addressing the limitations of purely linear transformations, \\cite{fang2024lv2} proposes Kernel PCA (KPCA) for OOD detection, devising novel non-linear mappings like Cosine Mapping (CoP) and Cosine-Gaussian Mapping (CoRP). These mappings explicitly transform features into a space where ID and OOD data become linearly separable, overcoming the ineffectiveness of conventional PCA on raw features, a challenge also noted by \\cite{guan2023dwv} which explored regularized PCA reconstruction errors. To directly combat the curse of dimensionality, \\cite{ghosal2023q20} proposes Subspace Nearest Neighbor (SNN), which regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e., subspace) during training. This subspace learning yields more distinguishable distance measures between ID and OOD data. Similarly, \\cite{li2025jdt} introduces a data structure-aware approach using a novel \"tangent distance\" that maps high-dimensional features to the manifold of ID samples. By directly computing the Euclidean distance between samples and the nearest submanifold space (linear approximation of local regions on the manifold), it mitigates the sensitivity of distances to high dimensionality, proposing that OOD samples are relatively far from the ID manifold. The computational overhead and the challenge of selecting optimal non-linear kernels or relevant subspaces for diverse OOD scenarios represent practical considerations for these transformation-based methods.\n\nAnother significant direction involves refining ID clusters through prototype-based learning and mixture models, which aim to capture the nuanced structure of ID data more faithfully. Traditional distance-based OOD methods often oversimplify ID classes by modeling them with a single centroid, failing to capture intra-class diversity and leading to suboptimal OOD boundaries. \\cite{lu20249d4} addresses this with Prototypic Learning with a Mixture of prototypes (PALM), which models each ID class with multiple prototypes using a mixture of von Mises-Fisher (vMF) distributions in a hyperspherical embedding space. This approach creates more faithful and compact ID clusters, allowing for a more precise definition of ID boundaries by optimizing both a Maximum Likelihood Estimation (MLE) loss and a novel prototype contrastive loss. Extending this concept to multimodal settings, \\cite{li2024rs5} introduces Dynamic Prototype Updating (DPU), which dynamically adjusts multimodal prediction discrepancy intensification based on a sample's similarity to its class prototype. DPU employs Cohesive-Separate Contrastive Training (CSCT) to build a robust representation space and Pro-ratio Discrepancy Intensification (PDI) to balance intra-class cohesion with inter-class separation, thereby enhancing OOD detection in complex multimodal data. Complementing these empirical approaches, \\cite{du2024aea} provides theoretical insights into how in-distribution labels help OOD detection, particularly for \"near OOD\" scenarios. Through a graph-theoretic framework and spectral decomposition, they demonstrate that ID labels, by defining supervised connectivity, enable the learning of more discriminative ID representations that facilitate OOD-ID separation, especially when ID data is sparsely connected without labels. While prototype-based methods offer improved fidelity, the challenge of determining the optimal number of prototypes and their sensitivity to noisy ID data remains, and OOD samples falling between distinct ID prototypes can still pose detection difficulties.\n\nDespite these significant advancements in actively structuring and refining feature spaces, a persistent challenge remains in ensuring that these learned representations generalize effectively to truly novel and diverse OOD types. While methods leveraging Neural Collapse offer promising theoretical underpinnings for explicit separation, their robustness to subtle, near-OOD shifts that might not perfectly align with orthogonal subspaces requires further investigation. Similarly, prototype-based methods, while improving intra-class modeling, still face the inherent difficulty of defining boundaries for the unknown, especially when OOD data falls within the convex hull of ID prototypes. Future research could focus on adaptive feature space shaping techniques that dynamically adjust to the evolving nature of OOD data, perhaps through meta-learning or continuous adaptation mechanisms, to achieve more universally robust and discriminative representations that are less sensitive to the specific characteristics of unseen OOD data.\n\\subsection{Gradient-Based and Neuron-Level Analysis}\n\\label{sec:4_3_gradient-based__and__neuron-level_analysis}\n\n\nA significant shift in Out-of-Distribution (OOD) detection research involves delving into the fine-grained internal dynamics of neural networks, leveraging gradient information and individual neuron activations to extract more precise and interpretable OOD signals. This introspection moves beyond aggregate model outputs to understand *how* and *why* a model processes OOD inputs differently.\n\nOne prominent direction focuses on abnormalities in gradient-based attribution maps, which reveal how input features influence predictions. \\cite{chen2023za1} introduced GAIA (Gradient Abnormality Inspection and Aggregation), a framework that quantifies the \"abnormality\" in gradient-based attribution results, observing that OOD samples lead to \"meaningless attribution results\" with abnormal non-zero density in deeper layers. Building on gradient insights, \\cite{behpour2023x13} proposed GradOrth, which identifies OOD data by computing the norm of the gradient projection onto a low-rank subspace deemed important for in-distribution (ID) data, indicating a weak correlation with ID patterns. While these methods are post-hoc, analyzing gradients after training, \\cite{chen2020mbk} introduced ALOE (Adversarial Learning with inlier and Outlier Exposure), a training-time strategy that uses adversarial examples generated via gradients to robustify OOD detectors against small input perturbations. ALOE's objective is to promote smoother OOD score functions for ID data and clearer separation for OOD data, directly addressing the robustness aspect through gradient-informed regularization during training.\n\nAnother crucial area explores the 'coverage' of neuron activation states by in-distribution data, revealing deviations from learned patterns. \\cite{liu2023zb3} proposed Neuron Activation Coverage (NAC), a novel statistical measure that quantifies how well neuron states are \"covered\" by ID training data, serving as an uncertainty measure for OOD detection and a metric for OOD generalization. This approach provides a deeper, neuron-centric understanding of OOD phenomena. Complementing this, \\cite{zhu2022oir} introduced Batch Normalization Assisted Typical Set Estimation (BATS) with a Truncated BN (TrBN) unit, which rectifies extreme feature activations into their \"typical set\" to boost OOD detection scores, effectively managing neuron states. \\cite{xu2023767} further generalized this concept with Variational Rectified Activation (VRA), providing a theoretical derivation for an optimal activation function that not only suppresses abnormally high activations (like TrBN) but also low ones, and amplifies intermediate activations, leading to superior OOD separation. These rectification methods demonstrate a progression from heuristic to theoretically grounded manipulation of neuron activations.\n\nBeyond individual neuron states, statistical analyses of activation patterns also prove effective. \\cite{dong2021swz} developed Neural Mean Discrepancy (NMD), a metric that quantifies the difference between the average activations (neural means) of input examples and the training data across multiple layers. NMD leverages Batch Normalization's running averages for efficiency, providing a lightweight yet powerful OOD signal. More recently, \\cite{schmidt2024syr} presented SISOM (Simultaneous Informative Sampling and Outlier Mining), a unified approach for active learning and OOD detection that enriches feature representations by weighting neurons based on their gradient contribution to the KL divergence between a uniform distribution and the model's softmax output. This method effectively combines gradient-based saliency with neuron activation analysis to identify unexplored regions and decision boundaries, showcasing a sophisticated integration of these fine-grained internal dynamics.\n\nThe collective efforts in this subsection highlight a growing trend towards deeper introspection into model internals. By analyzing gradient-based attribution maps, the coverage of neuron activation states, and employing gradient regularization during training, researchers are developing more precise, interpretable, and robust OOD detection methods. However, challenges remain in establishing universal patterns for gradient abnormalities or neuron coverage across diverse architectures and OOD types, and in balancing the computational cost of such fine-grained analysis with real-time deployment needs.\n",
    "Advanced OOD Paradigms and Contexts": "\\section{Advanced OOD Paradigms and Contexts}\n\\label{sec:advanced_ood_paradigms__and__contexts}\n\n\n\n\\subsection{Multimodal and Graph-Structured OOD Detection}\n\\label{sec:5_1_multimodal__and__graph-structured_ood_detection}\n\nThe landscape of Out-of-Distribution (OOD) detection is rapidly expanding beyond traditional unimodal image data to encompass the complexity of real-world multimodal and graph-structured information. This crucial extension addresses the inherent multimodal nature of many applications and the unique challenges posed by non-Euclidean data.\n\nFor graph-structured data, OOD detection presents distinct challenges due to its non-Euclidean nature and the high cost of labeling. Pioneering efforts have focused on unsupervised graph-level OOD. \\cite{liu202227x} introduced GOOD-D, a novel framework for unsupervised graph-level OOD detection that learns robust in-distribution (ID) patterns through perturbation-free data augmentation and hierarchical graph contrastive learning across node, graph, and group levels. This approach was critical in formalizing the problem and providing a multi-granularity understanding of graph ID data. Building on the need for OOD exposure in graphs, \\cite{wang2025xwm} proposed GOLD, which addresses the scarcity of auxiliary OOD data by implicitly generating pseudo-OOD samples through an adversarial latent generation framework, achieving superior performance without real OOD samples. Addressing practical deployment constraints, \\cite{wang2024es5} introduced GOODAT, a test-time graph OOD detection method that operates without access to training data or requiring GNN architecture modifications, leveraging a graph masker and the Graph Information Bottleneck (GIB) principle for unsupervised OOD identification. To provide a unified evaluation framework for this nascent field, \\cite{wang2024q01} presented UB-GOLD, a comprehensive benchmark that unifies unsupervised graph-level anomaly detection and OOD detection across 35 datasets and four distinct scenarios, enabling systematic comparison and analysis of diverse graph OOD methods.\n\nThe detection of OOD samples in multimodal settings is gaining traction as real-world data often comprises complementary information from diverse sources like vision, audio, and text. \\cite{dong2024a8k} made a significant contribution by introducing MultiOOD, the first dedicated benchmark for multimodal OOD detection, alongside the Agree-to-Disagree (A2D) algorithm. A2D leverages the \"modality prediction discrepancy\" phenomenon, where softmax predictions across modalities show negligible differences for ID data but significant variability for OOD data, to enhance detection. Extending this concept, \\cite{li2024rs5} proposed Dynamic Prototype Updating (DPU), a plug-and-play framework that addresses the limitation of uniform discrepancy amplification by dynamically adjusting intensification based on a sample's similarity to its class prototype, thereby balancing intra-class cohesion with inter-class separation.\n\nVision-Language Models (VLMs) have emerged as a powerful paradigm for multimodal OOD detection, particularly in zero-shot and open-vocabulary settings. \\cite{miyai2023591} introduced GL-MCM, which enhances zero-shot OOD detection by combining CLIP's global and local features, offering flexibility in defining ID images in complex, multi-object scenes. Further refining VLM-based approaches, \\cite{li20245b6} developed NegPrompt, a method that learns transferable \"negative prompts\" using only ID training data to delineate OOD boundaries, enabling open-vocabulary OOD detection without explicit OOD examples. Addressing the challenge of spurious OOD features that can arise from imperfect foreground-background decomposition in VLMs, \\cite{yu20249dd} proposed Self-Calibrated Tuning (SCT), an adaptive framework that dynamically balances ID classification and OOD regularization based on prediction uncertainty. Beyond VLMs, Large Language Models (LLMs) are being explored for their world knowledge. \\cite{dai2023mhn} leveraged LLMs for multi-modal OOD detection by generating descriptive features for ID classes, crucially developing a consistency-based uncertainty calibration method to mitigate LLM hallucinations and prevent performance degradation. This integration of LLMs with VLMs for OOD detection is further contextualized by \\cite{miyai20247ro}, which provides a comprehensive survey of OOD detection in the VLM/LVLM era, highlighting the integration of related fields and identifying the most demanding challenges.\n\nThe expansion of OOD detection to multimodal and graph-structured data marks a significant step towards more holistic and context-rich detection capabilities. While promising advancements have been made in developing new benchmarks and algorithms that exploit inter-modal discrepancies and address the unique challenges of non-Euclidean data, several unresolved issues remain. These include the scalability of multimodal OOD methods to a wider array of modalities beyond vision-language, the robustness of graph OOD detectors to diverse and subtle structural shifts, and the development of theoretically grounded adaptive algorithms that can seamlessly handle the inherent noise and heterogeneity in real-world multimodal and graph data.\n\\subsection{OOD in Specialized Learning Settings}\n\\label{sec:5_2_ood_in_specialized_learning_settings}\n\n\nOut-of-distribution (OOD) detection becomes particularly challenging in specialized learning paradigms where inherent data characteristics complicate the distinction between in-distribution (ID) and novel samples. This subsection delves into OOD detection within long-tailed recognition and class-incremental learning, highlighting the unique complexities and tailored solutions developed to ensure OOD robustness in these realistic scenarios.\n\nIn \\textbf{long-tailed recognition (LTR)}, the severe class imbalance creates a pervasive confusion between tail-class ID samples and true OODs. Models often exhibit overconfidence on dominant head classes, leading to OOD samples being misclassified into these categories, while simultaneously treating sparse tail-class instances as anomalies \\cite{miao2023brn, wei2023f15, shin2024lnf}. Addressing this requires strategies that either modify the learning objective, augment data, or engineer the representation space to explicitly disentangle tail-class ID from OOD.\n\nOne prominent approach involves modifying the learning objective or expanding the label space. \\cite{miao2023brn} introduced Calibrated Outlier Class Learning (COCL), which extends the label space with an explicit outlier class. COCL employs a debiased large margin learning strategy, incorporating OOD-aware tail class prototype learning to prevent tail samples from being mistaken for OOD, and debiased head class learning to mitigate the dominant influence of head classes on OOD samples. This direct manipulation of the decision boundary in the logit space offers a targeted solution to the class imbalance problem. Complementing this, \\cite{choi202367m} recognized that even auxiliary OOD data used in outlier exposure can exhibit class imbalance. They developed a balanced energy regularization loss that adaptively applies stronger regularization to auxiliary samples from majority classes, ensuring a more effective learning of OOD boundaries in long-tailed and semantic segmentation tasks.\n\nAnother crucial strategy focuses on data augmentation and dynamic outlier adaptation. \\cite{wei2023f15} proposed EAT, a framework that utilizes dynamic virtual labels for OOD data and context-rich tail class augmentation. By overlaying tail-class images onto OOD backgrounds, EAT encourages the model to focus on discriminative foreground features, improving both tail-class generalization and OOD distinction. This data-centric approach contrasts with COCL's loss modifications by enriching the training data itself. Further advancements in dynamic outlier adaptation include \\cite{nie2024ghv}'s Virtual Outlier Smoothing (VOSo), which constructs virtual outliers by perturbing semantic regions of ID samples in the image space and assigns them dynamic soft labels. This creates a smoother decision boundary, preventing tail classes from being abruptly classified as OOD. To enhance the diversity of auxiliary OOD data, \\cite{yao2024epq} theoretically demonstrated that increased diversity improves OOD generalization and proposed `diverseMix`, a semantic-level interpolation strategy with dynamic adjustment. Similarly, \\cite{jiang2023vzb} introduced Diverse Outlier Sampling (DOS), which selects diverse and informative outliers from auxiliary datasets by clustering normalized latent representations. These dynamic sampling and generation techniques, along with adaptive weighting strategies like Hopfield Boosting \\cite{hofmann2024gnx} that prioritize \"hard\" outliers, collectively contribute to refining the decision boundary in long-tailed settings, ensuring that tail classes are not erroneously flagged as OOD while true anomalies are detected.\n\nBeyond explicit outlier exposure and loss modifications, engineering the representation space is critical. \\cite{shin2024lnf} introduced \\textbf{Representation Norm Amplification (RNA)}, a novel training method that directly addresses the trade-off between LTR classification accuracy and OOD detection performance. RNA decouples ID classification and OOD detection by leveraging the norm of the representation vector as a dedicated dimension for OOD scoring. It achieves this by training the classifier to minimize classification loss only for ID samples, while simultaneously regularizing to enlarge the norm of ID representations. Crucially, auxiliary OOD samples are used to regularize Batch Normalization (BN) layers, indirectly reducing OOD representation norms and creating a discernible difference in activation ratios and representation norms. This allows for simultaneous high performance in both tasks, overcoming limitations of previous methods. Similarly, \\cite{lu20249d4} proposed Prototypic ALearning with a Mixture of prototypes (PALM), which models each ID class with multiple prototypes using a mixture of von Mises-Fisher distributions. While not exclusively for long-tailed settings, this approach is highly beneficial for capturing the inherent intra-class diversity within sparse tail classes, leading to more faithful embeddings and improved ID-OOD separability. \\cite{zhang202312h} introduced Multi-scale OOD DEtection (MODE), leveraging both global and local representations with an attention-based local propagation mechanism. This multi-scale approach can help distinguish fine-grained tail-class features from OOD noise, especially when global features are ambiguous due to background clutter.\n\nIn \\textbf{class-incremental learning (CIL)}, where models continuously learn new classes over time, maintaining robust OOD performance is a significant hurdle due to catastrophic forgetting of previously learned classes. The challenge lies in adapting to new ID classes without degrading the OOD detection capability for both old and new data distributions. This area has historically been underexplored, but recent work has begun to provide dedicated solutions and benchmarks.\n\n\\cite{miao20246mk} introduced OpenCIL, the first comprehensive benchmark for OOD detection in CIL, highlighting that CIL models exhibit increasing biases towards OOD samples and newly added classes with more incremental steps, leading to decreased OOD detection performance. OpenCIL proposes two frameworks for integrating OOD detection into CIL: post-hoc methods (applying OOD scores on CIL model features) and fine-tuning-based methods (training an additional OOD classifier while freezing the CIL backbone). To mitigate the identified biases, \\cite{miao20246mk} further proposed Bi-directional Energy Regularization (BER). BER addresses two key issues: New Task Energy Regularization (NTER) prevents OOD samples from being over-confidently classified into new classes by synthesizing pseudo-OOD samples and enlarging decision margins. Old Task Energy Regularization (OTER) prevents old ID samples from being misclassified as OOD (due to catastrophic forgetting) by boosting prediction confidence for old classes using augmented memory samples. BER provides a targeted solution to the unique challenges of OOD in CIL by explicitly addressing the dynamic nature of the ID distribution.\n\nAnother promising direction is the integration of uncertainty quantification methods. \\cite{aguilar2023ms5} proposed Continual Evidential Deep Learning (CEDL), which integrates Evidential Deep Learning (EDL) into a continual learning framework to simultaneously perform incremental object classification and OOD detection. CEDL combines exemplar rehearsal and knowledge distillation with a novel loss function that includes evidential cross-entropy, KL-divergence regularization for new classes, and knowledge distillation. Their findings indicate that evidential vacuity is a good indicator for OOD detection in CIL, while dissonance struggles to distinguish old ID from OOD. This work offers a principled way to estimate and leverage uncertainty for OOD detection in evolving CIL environments.\n\nBeyond these dedicated CIL-OOD methods, several general OOD concepts offer indirect but promising contributions. Techniques that enhance training stability and prevent overconfidence are crucial in CIL. \\cite{cheng20233yi}'s Average of Pruning (AoP), which combines model averaging and network pruning, could help mitigate OOD detection instability and overfitting during continuous learning. Similarly, \\cite{chen2024kl7}'s Optimal Parameter and Neuron Pruning (OPNP), a training-free method, could reduce overconfidence in CIL models without requiring additional training data, thus improving OOD discrimination. Leveraging generic pre-trained representations, as explored by GROOD \\cite{vojr2023ee1}, might offer a more stable foundation for OOD detection in CIL, as these representations are less susceptible to task-specific catastrophic forgetting compared to features learned from scratch. The dynamic prototype updating mechanism in \\cite{li2024rs5}'s DPU, though developed for multimodal OOD, conceptually aligns with the need to dynamically refine class representations in CIL to maintain stable boundaries for OOD detection.\n\nIn conclusion, specialized learning settings like long-tailed recognition have seen significant progress through tailored solutions that address the nuanced interactions between ID and OOD data, often leveraging dynamic outlier adaptation, sophisticated representation learning, and explicit norm amplification. Crucially, the field of OOD detection in class-incremental learning is rapidly maturing, moving from an underexplored area to one with dedicated benchmarks and methods like OpenCIL and BER, and principled uncertainty-aware approaches like CEDL. Future research needs to further integrate these insights, developing dynamic and adaptive OOD detection frameworks that can explicitly handle evolving ID distributions and catastrophic forgetting, ensuring robust OOD performance in truly open-ended, lifelong learning scenarios.\n\\subsection{Leveraging Pre-trained Foundation Models}\n\\label{sec:5_3_leveraging_pre-trained_foundation_models}\n\nThe emergence of large pre-trained foundation models, such as Vision-Language Models (VLMs) like CLIP \\cite{radford2021learning} and Large Language Models (LLMs), has profoundly transformed the landscape of Out-of-Distribution (OOD) detection. These models, with their rich semantic understanding, vast world knowledge, and open-vocabulary capabilities, enable novel zero-shot and open-set OOD detection paradigms, moving towards more adaptable and versatile OOD systems.\n\nThe \"Vision Language Model Era\" marks a significant paradigm shift in OOD detection, as highlighted by \\cite{miyai20247ro}. Early integration of VLMs for OOD detection focused on leveraging their inherent zero-shot capabilities. For instance, \\cite{miyai2023591} introduced GL-MCM, extending CLIP's Maximum Concept Matching by utilizing both global and local visual-text alignments. This approach provides flexibility in defining in-distribution (ID) images in multi-object scenes, addressing the limitation of methods that assume single, centered objects. Building upon this, \\cite{ding20242m0} proposed Outlier Label Exposure (OLE), a method that explicitly incorporates OOD knowledge by using a large set of diverse auxiliary outlier class labels as pseudo OOD text prompts for VLMs. OLE learns refined \"outlier prototypes\" and generates \"hard outlier prototypes\" to calibrate decision boundaries, overcoming the limitations of purely ID-label-based zero-shot methods that lack explicit OOD knowledge. Further advancing this direction, \\cite{li20245b6} introduced NegPrompt, a prompt learning-based approach that learns transferable \"negative prompts\" for each ID class using *only* ID training data. These negative prompts implicitly define OOD boundaries by representing characteristics contrary to ID classes, enabling open-vocabulary OOD detection without the need for any external outlier data or additional encoders, which is a significant step towards data-efficient and generalizable OOD systems.\n\nBeyond VLMs, Large Language Models (LLMs) are increasingly leveraged for their extensive world knowledge to generate synthetic OOD exposure. \\cite{dai2023mhn} explored using LLMs to generate descriptive features for ID classes to enhance multimodal OOD detection. Crucially, they identified and addressed the LLM \"hallucination\" problem by proposing a novel consistency-based uncertainty calibration method. This method selectively integrates reliable LLM knowledge, preventing performance degradation caused by unfaithful LLM generations. Taking this concept further, \\cite{cao20246gj} introduced Envisioning Outlier Exposure (EOE), which directly uses LLMs to *envision* and generate potential outlier class labels based on visual similarity to ID classes. EOE designs task-specific LLM prompts for far, near, and fine-grained OOD scenarios, effectively creating synthetic OOD labels without access to any real OOD data, thereby providing a powerful form of \"outlier exposure\" to VLMs.\n\nThe integration of foundation models also necessitates refining their behavior for OOD detection. \\cite{yu20249dd} proposed Self-Calibrated Tuning (SCT) for VLMs, a novel framework designed to mitigate the issue of \"spurious OOD features\" that arise from VLMs' imperfect foreground-background decomposition. SCT adaptively adjusts the balance between ID classification and OOD regularization based on prediction uncertainty, making VLM-based OOD detection more robust to internal model limitations. In a broader context, the field is also expanding to multimodal OOD detection, where foundation models can play a crucial role. \\cite{dong2024a8k} introduced the MultiOOD benchmark and the Agree-to-Disagree (A2D) algorithm, which leverages \"modality prediction discrepancy\" for OOD detection across multiple modalities. While not exclusively VLM/LLM-focused, this work highlights the growing need for robust multimodal OOD, a domain where foundation models are inherently well-suited to integrate and leverage diverse information streams. Finally, the increasing adoption of foundation models for OOD detection has led to dedicated benchmarks, such as the one presented by \\cite{borlino20245ku}, which aims to properly assess the performance of these large pre-trained models in realistic yet harder OOD tasks, confirming their benefits and guiding future research into their fine-tuning strategies.\n\nIn conclusion, the advent of pre-trained foundation models has opened a new frontier in OOD detection, moving beyond traditional methods that often rely on explicit OOD data or complex architectural modifications. These models' inherent semantic understanding and vast knowledge enable sophisticated zero-shot and open-vocabulary OOD paradigms through techniques like learning transferable negative prompts, leveraging LLMs for envisioned outlier exposure, and self-calibrated tuning of VLMs. However, challenges remain in ensuring the robustness of LLM-generated information, fully integrating multimodal cues, and developing comprehensive benchmarks that capture the full spectrum of OOD scenarios for these powerful, general-purpose models.\n",
    "Real-World Applications and Deployment Challenges": "\\section{Real-World Applications and Deployment Challenges}\n\\label{sec:real-world_applications__and__deployment_challenges}\n\n\n\n\\subsection{OOD in Medical Imaging and Healthcare}\n\\label{sec:6_1_ood_in_medical_imaging__and__healthcare}\n\n\nThe deployment of artificial intelligence (AI) in medical imaging and healthcare necessitates robust out-of-distribution (OOD) detection capabilities, as misinterpreting novel or anomalous inputs can have severe, life-threatening consequences for patient well-being. AI-powered clinical decision support systems, used for tasks like disease diagnosis and anomaly detection in medical scans, must reliably identify when an input falls outside their training distribution to prevent erroneous predictions. This domain presents unique challenges, including the high dimensionality of medical images, inherent class imbalance in rare disease detection, and the stringent requirement for robust performance on subtle OOD shifts that might indicate critical pathologies.\n\nTo address the foundational understanding of OOD in this high-stakes field, \\textcite{hong2024xls} provide a comprehensive survey, establishing a critical taxonomy for distributional shifts in medical imaging. They delineate seven key factors causing OOD shifts and categorize them into semantic, covariate, and contextual shifts, clarifying the complex landscape and inconsistent terminology that hinders systematic research. Empirically validating the limitations of current approaches, \\textcite{vasiliuk20233w9} expose the severe shortcomings of state-of-the-art OOD detection methods when applied to 3D medical image segmentation. Their work introduces a novel, publicly available benchmark that simulates diverse clinical OOD scenarios and, notably, demonstrates that a simple Intensity Histogram Features (IHF) baseline often outperforms complex deep learning methods, underscoring the profound challenges posed by 3D medical data and the need for more tailored solutions.\n\nEarly efforts to adapt general OOD detection techniques to medical imaging revealed significant performance discrepancies. \\textcite{berger20214a3} conducted a comparative study of confidence-based OOD methods on chest X-rays, finding that methods performing well on standard computer vision benchmarks often failed in the medical context. Their analysis highlighted ODIN as a robust method due to its input perturbation mechanism, while Mahalanobis distance, a strong performer in general vision, proved ineffective in medical imaging due to less separable feature spaces. Directly addressing this limitation, \\textcite{anthony2023slf} critically re-evaluated the use of Mahalanobis distance for OOD detection in medical imaging. Through a detailed layer-wise analysis, they demonstrated that the optimal detection layer is highly dependent on the specific OOD pattern, challenging previous assumptions. They then proposed Multi-branch Mahalanobis (MBM), a novel framework that significantly enhances OOD detection by employing multiple depth-specific detectors, showcasing a tailored solution that improves reliability for identifying unexpected anomalies like pacemakers or subtle demographic shifts.\n\nBeyond adapting existing discriminative methods, novel generative approaches have emerged to tackle the high dimensionality and complexity of 3D medical data. \\textcite{graham20232re} introduced an unsupervised 3D OOD detection method leveraging Latent Diffusion Models (LDMs). This innovative approach overcomes the memory and resolution limitations of prior generative models, enabling the generation of high-resolution spatial anomaly maps. Such capabilities are crucial for tasks like identifying unexpected tumors, lesions, or other pathologies in volumetric scans, where precise localization is paramount for clinical utility and ensuring the overall reliability of AI-powered diagnostic systems.\n\nDespite these advancements, several challenges persist. The generalizability of OOD methods across the vast spectrum of medical imaging modalities, anatomical regions, and diverse OOD types remains an open problem. There is a continuous need for more comprehensive and clinically relevant benchmarks that capture the subtlety and variability of real-world OOD shifts. Furthermore, integrating these detection mechanisms seamlessly into clinical workflows, coupled with robust explainability and uncertainty quantification, is essential for fostering trust and enabling the safe and effective deployment of AI in patient care.\n\\subsection{OOD for Autonomous Systems and Cyber-Physical Systems}\n\\label{sec:6_2_ood_for_autonomous_systems__and__cyber-physical_systems}\n\n\nThe safe and reliable deployment of autonomous systems, encompassing self-driving vehicles, robotics, and industrial cyber-physical systems (CPS), critically depends on their ability to detect and appropriately react to Out-of-Distribution (OOD) events. In these dynamic, open-world environments, encountering unforeseen objects, sensor malfunctions, or adversarial attacks can lead to catastrophic failures if not promptly identified. This subsection delves into the specialized advancements in OOD detection that address the stringent requirements of real-time performance, robust multimodal sensor fusion, and the nuanced handling of diverse OOD events in such safety-critical applications.\n\nEnsuring the trustworthiness of learning-enabled components in CPS necessitates OOD detection with strong statistical guarantees and real-time capabilities. Early work by \\cite{cai2020lsi} addressed this by integrating Variational Autoencoders (VAEs) and Deep Support Vector Data Description (SVDD) within an Inductive Conformal Anomaly Detection (ICAD) framework, providing well-calibrated false alarm rates for high-dimensional sensor inputs. Building on such foundational guarantees, \\cite{kaur2022cty} introduced iDECODe, which leverages in-distribution equivariance for conformal OOD detection, offering bounded false detection rates. Extending this to dynamic environments, \\cite{kaur20248t3} proposed CODiT for OOD detection in time-series (dependent) data within CPS, utilizing temporal equivariance and Fisher's method for robust, guaranteed false alarm rates. A crucial practical concern in safety-critical systems is managing false positives; \\cite{vishwakarma2024z1m} tackled this with a human-in-the-loop framework that adaptively updates OOD detection thresholds using expert feedback and provides theoretical guarantees on false positive rates, even under distribution shifts. Beyond mere statistical detection, \\cite{guerin202201y} argued that traditional OOD detection is insufficient for safety-critical contexts, advocating for Out-of-Model-Scope (OMS) detection, which focuses on identifying inputs that lead to actual model errors, thereby providing a more direct measure of safety. Robustness against malicious inputs is also paramount; \\cite{chen2020mbk} introduced ALOE (Adversarial Learning with inlier and Outlier Exposure), a training-time strategy that robustifies OOD detectors against both adversarial in-distribution and OOD examples, a critical defense against cyber-attacks in CPS. For continually evolving autonomous systems, \\cite{aguilar2023ms5} proposed Continual Evidential Deep Learning (CEDL), enabling simultaneous incremental learning of new classes and OOD detection, crucial for systems operating in open-ended environments.\n\nA significant challenge in autonomous systems is the effective integration of heterogeneous sensor data, such as LiDAR, camera, and radar, for robust OOD detection. Traditional unimodal OOD methods often fail to leverage the complementary information across modalities, which is vital for distinguishing subtle OOD events from sensor noise or adverse environmental conditions. Addressing this, \\cite{dong2024a8k} introduced MultiOOD, the first dedicated benchmark for multimodal OOD detection, alongside the \"Agree-to-Disagree\" (A2D) algorithm and \"Nearest Neighbor Prototype-based Mixup\" (NP-Mix) for outlier synthesis. Their work demonstrated that leveraging modality prediction discrepancies significantly enhances OOD performance, providing a foundational step for multimodal OOD, although primarily evaluated on video-based action recognition. Directly targeting autonomous driving, \\cite{liu2025m5u} proposed \"Feature Mixing,\" an extremely simple and fast multimodal outlier synthesis method for OOD detection and segmentation, specifically for image and point cloud data. This method, which randomly swaps feature dimensions between modalities, achieves state-of-the-art performance with significant speedups over prior methods like NP-Mix, making it highly practical for real-time applications. They also introduced CARLA-OOD, a challenging synthetic multimodal dataset for OOD segmentation in driving scenarios. Further specializing in 3D perception, \\cite{ksel20246fe} revisited OOD detection in LiDAR-based 3D object detection, proposing a lightweight post-hoc method that integrates features from the backbone, bounding box parameters, and output logits of a fixed 3D object detector. Crucially, they introduced a novel synthetic OOD generation strategy by perturbing known ID objects and established a new nuScenes OOD benchmark, providing a more realistic evaluation protocol for unknown foreground objects in autonomous driving. For multimodal intent understanding, \\cite{zhang2024cx0} proposed MIntOOD, integrating weighted feature fusion with multi-granularity representation learning for both classification and OOD detection, highlighting the need for context-aware OOD in complex autonomous tasks.\n\nThe advent of large pre-trained foundation models, particularly Vision-Language Models (VLMs), offers new avenues for open-world OOD detection in autonomous systems by leveraging their vast semantic understanding. \\cite{mao20244lp} explored language-enhanced latent representations for OOD detection in autonomous driving, using the cosine similarity of image and text representations encoded by CLIP. This approach improves the transparency and controllability of latent encodings, demonstrating superior performance on realistic driving data compared to traditional vision encoder representations. Similarly, \\cite{chen2024f28}'s TagFog, while a general visual OOD method, is motivated by applications like autonomous driving and uses textual anchor guidance from large language models (e.g., ChatGPT) and jigsaw-based fake outlier generation to train robust visual encoders. This allows for learning more compact ID representations and leaving spare regions for OOD data in the feature space, enhancing open-vocabulary OOD capabilities. The broader landscape of OOD detection in the VLM era, as surveyed by \\cite{miyai20247ro}, underscores the transformative potential of these models for detecting novel, semantically rich OOD events that traditional methods might miss.\n\nIn conclusion, OOD detection is an indispensable enabler for safe and robust autonomous operation. Significant progress has been made in developing methods that offer statistical guarantees, enhance robustness against adversarial attacks, and, critically, leverage multimodal sensor fusion for a more comprehensive understanding of the operational environment. The emergence of VLM-based approaches further promises to extend OOD capabilities to truly open-world, semantically rich unknown scenarios. However, challenges persist in developing unified theoretical frameworks that seamlessly integrate OOD detection with the broader concept of Out-of-Model-Scope, especially in highly dynamic, multimodal, and continually learning systems. Future directions should focus on scaling these guarantees to highly complex, distributed CPS, further integrating human feedback for adaptive learning, and establishing comprehensive benchmarks that reflect the full spectrum of OOD events and temporal dependencies in real-world autonomous environments, including adverse weather conditions and sensor degradation.\n\\subsection{OOD in Cybersecurity and Anomaly Detection}\n\\label{sec:6_3_ood_in_cybersecurity__and__anomaly_detection}\n\nOut-of-distribution (OOD) detection is a cornerstone of modern cybersecurity and anomaly detection, providing a critical defense against the dynamic and adversarial nature of digital threats. In these high-stakes environments, OOD samples frequently represent malicious activities, ranging from sophisticated network intrusions and advanced persistent threats to novel malware and fraudulent financial transactions. The ability to promptly and accurately identify these deviations from established normal patterns is paramount for safeguarding critical infrastructure, sensitive data, and financial systems. This subsection synthesizes how OOD detection methods are specifically adapted and applied to diverse data streams, including network traffic, system logs, user behavior, and graph-structured data, highlighting their utility in protecting against unpredictable and evolving threats.\n\nA primary challenge in cybersecurity is the real-time detection of novel network intrusions and traffic anomalies amidst high-volume data streams. Early OOD methods focused on efficiency and feature-space analysis to meet these demands. For instance, Neural Mean Discrepancy (NMD) \\cite{dong2021swz} offers an efficient post-hoc technique for detecting OOD samples by measuring deviations in deep neural network activation means, making it suitable for rapid monitoring of network traffic. Similarly, FeatureNorm and NormRatio \\cite{yu2022egq} identify optimal intermediate layers where in-distribution (ID) and OOD data exhibit maximal feature norm separation, providing a robust signal for unusual traffic patterns without requiring explicit OOD training samples. Addressing the need for rapid identification of new types of malicious traffic with limited labeled data, SPN \\cite{miao2023zf5} proposes a few-shot learning approach based on a Siamese Prototypical Network, incorporating margin loss to ensure OOD detection capabilities for unknown traffic types. In specialized network contexts, such as Controller Area Network (CAN) bus intrusion detection, a cascaded two-stage classification architecture leveraging an Auxiliary Classifier Generative Adversarial Network (ACGAN) effectively distinguishes known attacks from normal traffic while detecting unknown attack classes as OOD \\cite{zhao20221ag}, demonstrating architectural adaptations for resource-constrained environments.\n\nFor malware analysis and system log anomaly detection, the focus shifts to distinguishing subtle, potentially polymorphic threats from benign system variations, often under conditions of data scarcity. Methods that refine internal representations are crucial here. RankFeat \\cite{song2022f5d} enhances OOD detection by removing dominant rank-1 feature components that might obscure subtle OOD signals, proving effective for identifying novel threats in complex datasets like malware binaries. To mitigate ambiguity caused by atypical ID samples, Batch Normalization Assisted Typical Set Estimation (BATS) \\cite{zhu2022oir} rectifies extreme features to form a \"typical set,\" which is vital for distinguishing subtle malicious anomalies in system logs from benign, yet unusual, system variations. Furthermore, MOODv2 \\cite{li2024n34} enhances ID representation learning through Masked Image Modeling (MIM), yielding more robust and distinct ID features critical for distinguishing subtle malware variants or sophisticated intrusion attempts. In unsupervised settings, where labeled anomalies are rare, Density of States Estimation (DoSE) \\cite{morningstar2020re9} leverages multiple summary statistics from generative models to identify atypical samples, overcoming the common challenge of generative models assigning high likelihoods to OOD data, a critical consideration for unsupervised anomaly detection in logs or network flows. Beyond feature-level analysis, neuron-centric approaches like Neuron Activation Coverage (NAC) \\cite{liu2023zb3} quantify the \"coverage degree\" of neuron states to detect OOD, proving useful for identifying deviations in learned patterns of user behavior or system states that could indicate a compromise or insider threat.\n\nThe inherently adversarial nature of cybersecurity necessitates OOD detection methods that are robust to manipulation. Attackers actively seek to bypass detectors by crafting adversarial examples that appear in-distribution. To counter this, Adversarial Learning with inlier and Outlier Exposure (ALOE) \\cite{chen2020mbk} trains models against both adversarial ID and OOD examples, significantly improving robustness against malicious perturbations designed to evade detection. Building on this, Adversarially Robust OOD Detection Using Lyapunov-Stabilized Embeddings (AROS) \\cite{mirzaei2024dad} leverages Neural Ordinary Differential Equations (NODEs) and Lyapunov stability to achieve robust embeddings. AROS notably generates \"fake OOD embeddings\" from low-likelihood regions of the ID feature space, eliminating the need for auxiliary OOD datasets and enhancing robustness against strong adversarial attacks. Gradient-based methods also contribute to robustness; GradOrth \\cite{behpour2023x13} identifies OOD samples by projecting gradients onto low-rank subspaces of ID data, offering a nuanced way to detect deviations in model processing. Similarly, GAIA \\cite{chen2023za1} detects \"abnormality\" in gradient-based attribution results, providing interpretability for security analysts investigating suspicious activities. Furthermore, the concept of tangent distance \\cite{li2025jdt} addresses the \"curse of dimensionality\" in high-dimensional feature spaces, offering a data structure-aware approach to quantify OOD uncertainty by measuring distance to the nearest submanifold space, which is crucial for robust OOD detection against subtle perturbations.\n\nFor graph-structured data, prevalent in network topology, social networks, and financial transaction graphs, OOD detection faces unique challenges due to non-Euclidean data structures and complex relationships. GOOD-D \\cite{liu202227x} pioneers unsupervised graph-level OOD detection using perturbation-free hierarchical contrastive learning. Addressing the scarcity of OOD data for graphs, GOLD \\cite{wang2025xwm} implicitly generates adversarial latent samples to enhance detection without auxiliary OOD datasets. GOODAT \\cite{wang2024es5} offers a test-time, plug-and-play graph OOD detection method that leverages a graph masker guided by the Information Bottleneck principle, providing an efficient solution for monitoring network intrusions. The growing importance of this domain is underscored by comprehensive surveys like \\cite{cai2025ez2} and unified benchmarks such as UB-GOLD \\cite{wang2024q01}, which allows for rigorous comparison of unsupervised graph-level anomaly and OOD detection methods across various threat scenarios. For node-level OOD detection in graph neural networks, NODESAFE \\cite{yang2025z62} optimizes energy scores to reduce extreme values and mitigate logit shifts, significantly improving detection accuracy against structural manipulations.\n\nThe rise of Large Language Models (LLMs) and multimodal data streams has opened new avenues for detecting sophisticated threats like phishing and social engineering. A survey by \\cite{xu2024ufg} systematically reviews how LLMs are utilized for anomaly and OOD detection across various data modalities, including text. For multi-modal OOD detection, \\cite{dai2023mhn} leverages LLMs' world knowledge to generate descriptive features while calibrating for hallucination, enhancing the detection of complex, multi-modal threats. Envisioning Outlier Exposure (EOE) \\cite{cao20246gj} utilizes LLMs to generate synthetic outlier class labels, providing \"envisioned outlier exposure\" to improve zero-shot OOD detection without real OOD data, which is crucial for identifying novel attack patterns or zero-day exploits. Furthermore, MIntOOD \\cite{zhang2024cx0} proposes a multimodal intent understanding system that simultaneously achieves classification and OOD detection by fusing text, video, and audio, vital for detecting anomalous user behavior or sophisticated social engineering attacks.\n\nIn safety-critical Cyber-Physical Systems (CPS), OOD detection demands strong theoretical guarantees and real-time applicability. Inductive Conformal Anomaly Detection (ICAD) \\cite{cai2020lsi}, using learned nonconformity measures, provides statistically sound false alarm rate guarantees for real-time OOD detection in CPS, crucial for applications like autonomous vehicles and industrial control systems. Building on this, iDECODe \\cite{kaur2022cty} introduces a novel non-conformity measure based on in-distribution equivariance, further strengthening conformal OOD detection with bounded false detection rates. Extending these guarantees to temporal data, CODiT \\cite{kaur20248t3} provides OOD detection with conformal guarantees for time-series data in CPS, directly applicable to monitoring network traffic and system logs for evolving threats. To address the practical issue of high false positive rates in dynamic environments, a human-in-the-loop framework \\cite{vishwakarma2024z1m} adaptively updates OOD detection thresholds with theoretical guarantees on false positive rate control, ensuring trustworthy deployment. Furthermore, understanding the fundamental objectives of OOD methods, as explored by \\cite{bitterwolf2022rw0}, helps in designing more principled and effective security detectors. The Model-Specific OOD framework \\cite{averly20239rv} offers a unified perspective on OOD detection based on a deployed model's actual misclassification behavior, which is highly relevant for understanding what a security system *actually* fails on in a real-world context. Finally, Continual Evidential Deep Learning (CEDL) \\cite{aguilar2023ms5} integrates evidential deep learning into a continual learning framework to simultaneously perform incremental classification and OOD detection, a critical capability for systems facing evolving threats without catastrophic forgetting.\n\nIn conclusion, OOD detection is an indispensable and rapidly evolving field within cybersecurity and anomaly detection. It has progressed from basic statistical deviation measures to sophisticated, robust, and context-aware methodologies capable of addressing diverse data types and adversarial environments. While significant advancements have been made in developing methods for various data modalities, enhancing robustness against adversarial threats, and providing theoretical guarantees, several challenges persist. These include balancing the need for universal OOD solutions with the demonstrated benefits of domain-specific adaptations, developing scalable and theoretically sound methods that can handle the full spectrum of real-world distribution shifts without relying on scarce OOD training data, and rigorously aligning OOD detection with the ultimate goal of ensuring model safety and reliability in constantly changing, unpredictable digital environments. Future research must continue to bridge theoretical rigor with practical deployment, particularly in the face of increasingly sophisticated and adaptive cyber threats.\n\\subsection{Practical Deployment Considerations and Human-in-the-Loop}\n\\label{sec:6_4_practical_deployment_considerations__and__human-in-the-loop}\n\nThe successful transition of Out-of-Distribution (OOD) detection systems from controlled experimental settings to real-world applications hinges on addressing a critical set of practical deployment challenges. Beyond theoretical performance metrics, these systems must demonstrate computational efficiency, scalability, robustness to dynamic environments, provable guarantees on false detection rates, and the capacity for effective human-in-the-loop (HITL) interaction and interpretability. The overarching goal is to develop OOD solutions that are not only technically effective but also robust, efficient, interpretable, and ultimately practical for diverse operational settings, particularly in safety-critical domains.\n\nA foundational requirement for practical deployment, especially in latency-sensitive systems, is computational efficiency and scalability. Early OOD methods, particularly those relying on complex generative models, often incurred significant computational overhead \\cite{zisselman2020cmx}. Consequently, recent research has prioritized lightweight, post-hoc approaches that minimize inference time. Neural Mean Discrepancy (NMD) \\cite{dong2021swz}, for instance, leverages running average means from Batch Normalization layers to approximate training data statistics, enabling real-time detection with minimal computational burden. Similarly, GradOrth \\cite{behpour2023x13} offers an efficient gradient-based OOD detector by pre-computing a low-rank subspace of in-distribution data gradients, facilitating rapid OOD scoring during inference. While both methods offer efficiency gains, NMD's reliance on Batch Normalization statistics might limit its applicability to architectures without such layers or in scenarios where batch statistics are highly variable. GradOrth, conversely, requires gradient computations, which, while pre-computed, still adds a layer of complexity compared to simpler confidence-based scores. The computational burden of traditional kernel methods, such as Kernel PCA (KPCA), has also been significantly reduced by approaches like CoP and CoRP \\cite{fang2024lv2}, which devise explicit non-linear feature mappings to achieve state-of-the-art performance with $O(1)$ or $O(M)$ complexity, a substantial improvement over $O(N_{tr})$ for methods like k-Nearest Neighbors (KNN). For Cyber-Physical Systems (CPS) demanding real-time responses, \\cite{cai2020lsi} demonstrated efficient OOD detection by integrating learned nonconformity measures (from VAEs and Deep SVDD) into the Inductive Conformal Anomaly Detection (ICAD) framework, overcoming traditional conformal prediction's scalability limitations for high-dimensional sensor inputs. Furthermore, the efficiency challenge extends to large language models (LLMs) in natural language processing (NLP). \\cite{ouyang2023wxc} proposed PTO, an unsupervised prefix-tuning based OOD detection framework that offers a parameter-efficient alternative to costly fine-tuning, demonstrating comparable or superior performance with significantly reduced storage and computational requirements. These diverse approaches highlight a collective effort to balance detection efficacy with the stringent computational constraints of real-world deployment.\n\nBeyond raw efficiency, practical systems demand robustness to diverse OOD types and adversarial attacks, coupled with adaptive mechanisms for dynamic, non-stationary environments. Many methods improve intrinsic OOD robustness during training or representation learning (as discussed in Section 4), but deployment-time robustness necessitates adapting to unforeseen shifts. The conceptual shift from merely detecting \"out-of-distribution\" to \"Out-of-Model-Scope\" (OMS) detection \\cite{guerin202201y} is crucial, emphasizing the identification of inputs leading to *prediction errors* of the specific deployed model, rather than a generic notion of novelty. This perspective is further refined by the Model-Specific Out-of-Distribution (MS-OOD) framework \\cite{averly20239rv}, which unifies the detection of semantic shifts, covariate shifts, and even misclassified in-distribution examples based on the actual performance of a deployed classifier. This framework is vital for guiding adaptive behavior and dynamic thresholding, allowing systems to differentiate between inputs the model *can* handle despite a shift (e.g., a covariate shift it generalizes to) and those it *cannot* (e.g., a semantic shift or a covariate shift leading to misclassification). While MS-OOD provides a robust conceptual foundation, its practical implementation for continuous adaptation in dynamic environments remains an active area of research, often requiring continuous monitoring and re-calibration. Contributions like \\cite{chen20247p7}'s sparsity-regularized tuning framework enhance the generalizability of OOD score functions, making them less dependent on specific datasets and more capable of dynamic adaptation. A particularly innovative adaptive mechanism for handling unforeseen OOD in open-world scenarios is \\cite{cao20246gj}'s Envisioning Outlier Exposure (EOE). EOE leverages Large Language Models (LLMs) to synthetically generate potential outlier class labels based on visual similarity to in-distribution classes, effectively providing \"outlier exposure\" without requiring actual OOD data. This LLM-driven approach offers a scalable and flexible way to adapt to various OOD types (far, near, fine-grained) by dynamically envisioning new categories, thereby enhancing the model's ability to distinguish novel inputs in a zero-shot manner. However, the effectiveness of EOE relies heavily on the quality of LLM-generated prompts and the LLM's inherent knowledge, posing challenges for robust and unbiased outlier generation across all domains.\n\nA critical aspect of practical deployment, especially in safety-critical domains, is the ability to provide reliable uncertainty estimates and control false detection rates. This is paramount for building trust and ensuring regulatory compliance. Conformal Prediction (CP), as detailed in Section 7.2, offers a principled approach to this, providing provably valid false detection rates. For instance, \\cite{kaur2022cty} introduced iDECODe for single-point OOD detection with theoretically guaranteed bounded False Detection Rates (FDR). This work was significantly extended by \\cite{kaur20248t3} to time-series data in Cyber-Physical Systems, providing conformal guarantees for OOD detection in dynamic, dependent data streams. This is a crucial advancement, as many real-world applications involve sequential data where independence assumptions of traditional CP might not hold. While CP offers strong theoretical guarantees, its practical application often requires careful calibration and consideration of the exchangeability assumption, which can be challenging in highly non-stationary environments.\n\nDespite theoretical guarantees, managing false positives (FPs) in dynamic, open-world settings often requires human oversight, leading to the indispensable role of human-in-the-loop (HITL) approaches. HITL frameworks integrate human expert feedback to refine OOD detectors, manage trade-offs between safety and performance, and build trust. \\cite{vishwakarma2024z1m} directly addressed the problem of high False Positive Rates (FPR) in OOD detection by proposing a mathematically grounded HITL framework. This framework adaptively updates the detection threshold over time by integrating human feedback and employing an anytime-valid Upper Confidence Bound (UCB) based on the Law of Iterated Logarithm, guaranteeing FPR control below a desired level while maximizing True Positive Rate (TPR) (further theoretical details are in Section 7.2). This approach offers a robust mechanism for dynamic threshold adjustment, but its effectiveness depends on the availability and reliability of human feedback. Beyond direct threshold adjustment, HITL also plays a crucial role in data acquisition and model refinement. \\cite{schmidt2024syr} proposed SISOM, a unified approach for active learning and OOD detection. Active learning inherently involves human experts labeling uncertain or novel samples, thereby providing crucial feedback to improve both model performance and OOD detection capabilities. SISOM's self-deciding process for combining scores contributes to adaptive behavior, reducing the burden on human operators while maintaining robustness.\n\nFor HITL systems to be truly effective, building operator trust and ensuring practical utility requires OOD solutions that are not only effective but also interpretable and aligned with system safety goals. Human operators need to understand *why* a system flags an input as OOD to make informed decisions and foster confidence in AI systems. Methods that leverage intrinsic model properties or explanations can enhance this interpretability. For instance, Neuron Activation Coverage (NAC) \\cite{liu2023zb3} quantifies the \"coverage degree\" of neuron states by in-distribution data, offering insights into model behavior under OOD conditions. Similarly, GAIA \\cite{chen2023za1} detects OOD samples by quantifying \"abnormality in gradient-based attribution results,\" directly linking model explanations to OOD detection (these methods are detailed in Section 4.3). While these approaches provide valuable diagnostic information, translating complex neural network activations or gradient attributions into easily digestible and actionable insights for human operators remains a significant challenge. The interpretability must be tailored to the human's cognitive load and the specific decision-making context.\n\nIn conclusion, the literature demonstrates a clear trajectory towards OOD detection solutions that prioritize practical deployment. This involves a strong emphasis on computational efficiency for real-time operation, robustness and adaptive mechanisms for dynamic environments, and the provision of theoretical guarantees on false alarm rates. Crucially, the field is increasingly recognizing the indispensable role of human-in-the-loop approaches for adaptive thresholding, managing false positives, and building trust in AI systems. Future work will likely continue to explore more nuanced human-AI collaboration models, develop methods for handling highly dynamic and unforeseen OOD shifts with minimal human intervention, and strive for truly interpretable OOD explanations that align with human decision-making in safety-critical contexts, ultimately enabling the responsible and reliable deployment of AI.\n",
    "Ensuring Trustworthy OOD: Advanced Formalisms, Guarantees, and Evaluation": "\\section{Ensuring Trustworthy OOD: Advanced Formalisms, Guarantees, and Evaluation}\n\\label{sec:ensuring_trustworthy_ood:_advanced_formalisms,_guarantees,__and__evaluation}\n\n\n\n\\subsection{Evolving OOD Definitions and Granular Taxonomies}\n\\label{sec:7_1_evolving_ood_definitions__and__granular_taxonomies}\n\n\nThe conceptualization of Out-of-Distribution (OOD) detection has undergone a significant evolution, moving beyond a simplistic binary distinction between in-distribution (ID) and OOD data towards a more nuanced, granular, and context-aware understanding. This shift is critical for developing robust and trustworthy AI systems capable of operating reliably in complex real-world environments.\n\nInitially, OOD detection primarily focused on identifying samples from entirely novel semantic categories. However, this narrow view proved insufficient, leading to the introduction of more granular definitions. A pivotal development was the formal distinction between different types of distribution shifts. \\cite{yang2022it3} introduced the concept of \\textit{Full-Spectrum Out-of-Distribution (FS-OOD) Detection}, explicitly differentiating between \\textit{semantic shift} (novel classes) and \\textit{covariate shift} (label-preserving appearance changes like lighting or style). Their proposed Semantics score function (SEM) aimed to disentangle these shifts, demonstrating that existing methods often failed to robustly handle covariate-shifted ID data, treating it erroneously as OOD. Further complicating the landscape, \\cite{ming2021wu7} highlighted the critical impact of spurious correlations, formalizing \"spurious OOD\" where models rely on non-causal features, making detection challenging even for inputs that visually resemble ID data. This emphasized that OOD can arise not just from novel semantics or appearance, but also from the model's learned biases.\n\nThe need for more rigorous evaluation of these granular shifts quickly became apparent. \\cite{yang2023ckx} critically analyzed existing ImageNet-based OOD benchmarks, revealing issues such as ID contamination, semantic ambiguities, and unintended covariate shifts that hindered the accurate assessment of semantic OOD detection. To address this, they introduced `ImageNet-OOD`, a meticulously human-curated dataset designed to isolate pure semantic shift by minimizing covariate variations. Building on this, \\cite{wang2024is1} provided a comprehensive cross-evaluation of OOD detection and Open-Set Recognition (OSR) methods, further disentangling semantic and covariate shifts on large-scale benchmarks and proposing a new \"Outlier-Aware Accuracy\" (OAA) metric to reconcile robustness to covariate shift with the ability to detect its presence. These works collectively underscored the importance of clean, disentangled evaluation for understanding what OOD algorithms truly detect.\n\nA significant conceptual re-framing of the OOD problem was introduced by \\cite{averly20239rv} with the \\textit{Model-Specific Out-of-Distribution (MS-OOD) Detection} framework. This paradigm shifted the definition of OOD from being purely based on data properties to being dependent on a \\textit{specific deployed model's performance and misclassification behavior}. Under MS-OOD, an example is considered OOD if the model cannot classify it correctly, unifying semantic shift, covariate shift, and even misclassified in-distribution examples under a single, performance-driven ground truth. This perspective acknowledges that what constitutes \"OOD\" can be subjective and model-dependent, moving towards a more practical, context-aware definition.\n\nThe binary nature of traditional OOD evaluation also faced scrutiny. \\cite{long2024os1} addressed the \"Sorites Paradox\" in OOD evaluation, arguing that a simple binary ID/OOD distinction fails to capture the continuous \\textit{degree} of semantic and covariate shifts. They introduced the \\textit{Incremental Shift OOD (IS-OOD)} benchmark and \\textit{Language Aligned Image feature Decomposition (LAID)}, a CLIP-based method to quantitatively decompose image features into distinct semantic and covariate components. This allowed for continuous measurement of shift degrees, providing a far more granular and informative evaluation of OOD detection performance as a function of shift intensity.\n\nAs the field matured and its problem definitions became increasingly complex, the need for structured organization emerged. \\cite{lang20237w3} provided the first comprehensive survey on OOD detection in Natural Language Processing (NLP), introducing a novel taxonomy based on the availability of OOD data during training and highlighting NLP-specific challenges. This reflects the emergence of task-oriented and domain-specific taxonomies to organize the field's growing complexity, moving beyond generic definitions to practical, application-driven categorizations. Complementing this, theoretical works like \\cite{du2024aea} and \\cite{fang20249gd} contribute to this maturing conceptual understanding by exploring the fundamental learnability of OOD detection and the role of in-distribution labels, implicitly influencing how OOD boundaries are conceptualized and defined under various conditions.\n\nIn conclusion, the evolution of OOD definitions has progressed from a rudimentary binary classification to a sophisticated, multi-faceted understanding. This trajectory, marked by the differentiation of semantic and covariate shifts, the adoption of model-specific perspectives, the development of continuous shift measurements, and the emergence of task-oriented taxonomies, collectively reflects a maturing conceptual understanding of OOD detection. However, challenges remain in developing scalable, universally applicable methods that can robustly handle the full spectrum of these granular shifts without relying on scarce OOD training data, particularly in diverse real-world applications.\n\\subsection{Certifiable OOD Detection: Provable Guarantees and Conformal Prediction}\n\\label{sec:7_2_certifiable_ood_detection:_provable_guarantees__and__conformal_prediction}\n\n\nThe deployment of machine learning systems in safety-critical applications necessitates not only high empirical performance but also strong theoretical guarantees regarding their reliability, particularly in identifying out-of-distribution (OOD) inputs. This subsection explores the critical advancements towards certifiable OOD detection, emphasizing methods that provide provable guarantees on false detection rates and leverage rigorous statistical frameworks like Conformal Prediction (CP).\n\nA cornerstone of certifiable OOD detection is the integration of Conformal Prediction (CP), which offers a robust, model-agnostic framework for controlling false detection rates with statistical validity. Early work by \\cite{cai2020lsi} introduced Inductive Conformal Anomaly Detection (ICAD) for real-time OOD detection in learning-enabled Cyber-Physical Systems (CPS). This approach overcame the scalability limitations of traditional CP by employing learned nonconformity measures (NCMs) based on Variational Autoencoders (VAEs) and Deep Support Vector Data Description (SVDD), ensuring a well-calibrated false alarm rate in high-dimensional settings. Building on this, \\cite{kaur2022cty} proposed iDECODe, a novel ICAD framework leveraging in-distribution equivariance as its NCM. By aggregating scores from multiple transformations, iDECODe provides a theoretically guaranteed bounded false detection rate, demonstrating state-of-the-art performance in single-point OOD detection. Extending these guarantees to dynamic environments, \\cite{kaur20248t3} developed CODiT, which applies conformal anomaly detection to dependent time-series data in CPS. CODiT uses deviation from in-distribution temporal equivariance as an NCM and combines predictions from multiple detectors via Fisher's method, offering bounded false alarms for both fixed-length windows and variable-length traces. These advancements collectively showcase CP's versatility in providing marginal coverage guarantees across diverse OOD scenarios, from static single-point detection to complex temporal data streams.\n\nBeyond merely providing detection guarantees, CP is also crucial for establishing statistically rigorous evaluation metrics for OOD detectors themselves. Traditional OOD evaluation metrics, such as AUROC and FPR@TPR95, are empirical approximations that can be overly optimistic and fluctuate significantly with finite test sample sizes, lacking robust, conservative guarantees. Addressing this, \\cite{novello2024yco} proposed a dual application of CP and OOD detection. They introduced \"conformal AUROC\" and \"conformal FPR\" metrics, which provide probabilistic conservativeness guarantees on the variability of these evaluation metrics. This ensures that the estimated performance of an OOD detector is conservative with high probability (e.g., $1-\\delta$), thereby making the *evaluation* of OOD systems certifiable and more trustworthy. Furthermore, \\cite{novello2024yco} demonstrated that sophisticated OOD scores, such as Mahalanobis distance or K-Nearest Neighbors (KNN) distance, can serve as highly effective non-conformity scores within the CP framework, often outperforming classical CP non-conformity scores in building prediction sets. This highlights a synergistic relationship where OOD methods can enhance CP, and CP can, in turn, provide robust evaluation for OOD.\n\nWhile CP provides statistical guarantees, real-world systems often require adaptive control and human oversight, especially when faced with evolving OOD distributions. Addressing this, \\cite{vishwakarma2024z1m} introduced a mathematically grounded human-in-the-loop framework for OOD detection that dynamically adjusts detection thresholds. This framework leverages importance sampling and an anytime-valid Upper Confidence Bound (UCB) based on the Law of Iterated Logarithm to provide provable guarantees on the false positive rate (FPR), even in the presence of distribution shifts. By taming false positives with minimal human feedback, this approach significantly enhances the practical deployability and trustworthiness of OOD systems in dynamic, open-world environments.\n\nBeyond statistical guarantees and adaptive control, a deeper theoretical understanding of OOD detection learnability and data utility is crucial for a trustworthy foundation. \\cite{du20248xe} made a significant contribution by providing the first framework that offers *provable guarantees* for leveraging unlabeled \"wild\" data in OOD detection. Their \"Separate And Learn\" (SAL) framework employs a novel gradient-based filtering mechanism and offers rigorous error bounds on outlier separability and classifier learnability, demonstrating how unlabeled data can provably enhance OOD awareness without requiring clean auxiliary OOD samples. Complementing this, \\cite{fang20249gd} delved into the fundamental learnability of OOD detection, establishing necessary and sufficient conditions for Probably Approximately Correct (PAC) learnability under various risk and AUC metrics. This theoretical work highlights that OOD detection is not universally learnable and depends critically on the characteristics of the data and hypothesis spaces, providing crucial insights into the theoretical limits and possibilities of certifiable OOD systems. The implications for CP are profound: while CP offers statistical guarantees *given* an OOD score, the inherent quality and effectiveness of that score, and thus the practical utility of the CP-based detection, are constrained by the underlying learnability conditions of the specific OOD problem. This underscores the need for OOD scores that are well-aligned with the learnable properties of the data distribution for CP to be truly effective in practice.\n\nIn conclusion, the pursuit of certifiable OOD detection is rapidly evolving, moving from foundational statistical guarantees offered by Conformal Prediction for detection and evaluation, to adaptive, human-in-the-loop frameworks for dynamic FPR control. Simultaneously, theoretical work is establishing the learnability and data utility principles, collectively shaping a more robust and trustworthy understanding of what it means for an AI system to be \"certifiably\" aware of its own limitations. Despite these advancements, challenges remain in developing universally applicable nonconformity measures for CP that can provide strong guarantees across all types of distribution shifts, scaling CP to increasingly large foundation models, and extending these guarantees to more complex adaptive or continually learning systems, all while ensuring that the underlying OOD problem is indeed theoretically learnable.\n\\subsection{Standardized Benchmarking and Unified Evaluation Frameworks}\n\\label{sec:7_3_st_and_ardized_benchmarking__and__unified_evaluation_frameworks}\n\n\nThe systematic and fair advancement of Out-of-Distribution (OOD) detection critically relies on the development of standardized benchmarks and unified evaluation frameworks. Historically, the field grappled with inconsistent definitions of OOD, ad-hoc datasets, and disparate evaluation protocols, severely hindering reproducible and comparable research. Early work by \\cite{ming2021wu7} highlighted this by formalizing the concept of \"spurious OOD,\" demonstrating how models' reliance on spurious correlations in training data could lead to high-confidence but unreliable predictions on OOD inputs, thus exposing a fundamental flaw in simplistic OOD definitions and evaluation. Similarly, \\cite{berger20214a3}'s comparative study revealed significant performance discrepancies of confidence-based OOD methods between general computer vision tasks and challenging medical imaging applications, underscoring the necessity for domain-specific and rigorous evaluation. The lack of a comprehensive review for OOD in Natural Language Processing (NLP) was addressed by \\cite{lang20237w3}, which provided a taxonomy and discussed NLP-specific evaluation challenges, while \\cite{hong2024xls} offered a systematic framework and taxonomy for OOD detection in medical image analysis, clarifying terminology and evaluation protocols for this critical domain. These initial efforts underscored the urgent need for a more structured and consistent approach to OOD evaluation.\n\nA pivotal development in OOD evaluation has been the effort to disentangle distinct types of distribution shifts, moving beyond a monolithic view of OOD (as discussed in detail in Section 7.1). To operationalize these nuanced definitions, researchers have meticulously curated datasets designed to isolate and evaluate performance on specific shifts. \\cite{yang2023ckx} meticulously curated \\textit{ImageNet-OOD}, a novel dataset specifically designed to isolate and evaluate performance on semantic shifts while minimizing confounding covariate shifts. This dataset addressed critical shortcomings of previous ImageNet-based benchmarks, such as ID contamination and semantic ambiguities. Its findings were impactful, demonstrating that many modern OOD algorithms are disproportionately sensitive to covariate shifts rather than genuine semantic novelty, often failing to detect truly novel classes. This revelation prompted a re-evaluation of existing methods and guided the development of more robust techniques. Furthering this disentanglement, \\cite{wang2024is1} provided a critical analysis of OOD detection and Open-Set Recognition (OSR) methods, introducing a new large-scale benchmark to systematically disentangle semantic and covariate shifts and proposing \"Outlier-Aware Accuracy\" as a more nuanced metric. Complementing these efforts, \\cite{long2024os1} introduced the \"Incremental Shift OOD\" (IS-OOD) benchmark, which categorizes OOD samples by their \\textit{degree} of semantic and covariate shift, moving beyond binary OOD definitions and utilizing a novel Language Aligned Image feature Decomposition (LAID) method to quantify these shifts, offering a more granular assessment of OOD robustness.\n\nBeyond specialized datasets, the field has seen the emergence of comprehensive, unified software frameworks that provide robust platforms for rigorous comparison across diverse methods and OOD scenarios, addressing the critical need for reproducible and scientifically sound assessments. A cornerstone in this regard is **OOD-Bench** \\cite{huang2023ood}, which emerged to tackle the pervasive issues of inconsistent implementations and evaluation settings. OOD-Bench provides a modular and extensible platform that integrates a wide array of OOD detection methods, backbone architectures, and datasets, enabling researchers to conduct fair and reproducible comparisons. Its structured approach has significantly improved the reliability of reported results and fostered a more systematic advancement of the field. Similarly, \\cite{kirchheim20229jl} introduced **PyTorch-OOD**, a Python library specifically designed to accelerate OOD detection research and improve reproducibility. By providing well-tested and documented implementations of OOD methods with a unified interface, along with benchmark datasets and utility functions, PyTorch-OOD lowers the barrier to entry for new researchers and ensures consistency across experiments.\n\nThe demand for standardized evaluation extends to diverse data modalities and complex learning scenarios. For graph-structured data, which presents unique challenges due to its non-Euclidean nature, \\cite{liu202227x} pioneered a benchmark dataset for unsupervised graph-level OOD detection. This was significantly expanded by \\cite{wang2024q01} with **UB-GOLD**, a unified benchmark that integrates unsupervised graph-level anomaly detection and OOD detection across 35 datasets and four distinct scenarios. UB-GOLD provides a robust and comprehensive platform for rigorous comparison in this emerging domain, allowing for a deeper understanding of method performance under various graph OOD conditions. A recent survey by \\cite{cai2025ez2} further contributes to the standardization of graph OOD detection by providing a rigorous definition and systematically categorizing existing methods, clarifying distinctions with related fields and highlighting unique challenges. In medical imaging, where OOD detection is paramount for patient safety, \\cite{vasiliuk20233w9} developed a novel and diverse benchmark for 3D medical image segmentation OOD, which exposed the significant limitations of many state-of-the-art methods when confronted with the subtle, yet critical, OOD shifts inherent in medical data. Similarly, \\cite{anthony2023slf} contributed a new benchmark for OOD detection in medical imaging by manually annotating pacemakers and support devices in chest X-rays, enabling more targeted evaluation of methods like Mahalanobis distance against clinically relevant anomalies.\n\nFurthermore, as OOD detection integrates with more dynamic learning paradigms, specialized benchmarks become crucial. **OpenCIL** \\cite{miao20246mk} addresses the critical challenge of OOD detection within Class-Incremental Learning (CIL). CIL models, designed to continuously learn new classes, often suffer from catastrophic forgetting, which severely impacts their ability to detect OOD samples reliably. OpenCIL is the first comprehensive benchmark for OOD detection in CIL, providing unified evaluation protocols and two principled frameworks (post-hoc and fine-tuning based) to integrate OOD methods into CIL models. This benchmark has been instrumental in identifying critical biases in CIL models towards OOD samples and newly added classes, offering crucial insights for designing future open-world CIL systems.\n\nIn conclusion, the evolution of OOD detection has seen a critical shift from ad-hoc evaluations to sophisticated, standardized benchmarking and unified evaluation frameworks. The development of meticulously curated datasets like \\textit{ImageNet-OOD} \\cite{yang2023ckx} has been indispensable for disentangling various types of distribution shifts, while comprehensive software platforms such as OOD-Bench \\cite{huang2023ood} and PyTorch-OOD \\cite{kirchheim20229jl} provide the necessary infrastructure for reproducible and fair comparisons. Specialized benchmarks like UB-GOLD \\cite{wang2024q01} for graph data, medical imaging benchmarks \\cite{vasiliuk20233w9, anthony2023slf}, and OpenCIL \\cite{miao20246mk} for CIL have expanded the field's evaluative rigor into complex domains. Despite these advancements, challenges remain in creating truly exhaustive benchmarks that capture the full spectrum of real-world OOD scenarios, particularly for dynamic and 'near-OOD' shifts, and in developing evaluation protocols that scale effectively for increasingly large foundation models. Future research must continue to bridge the gap between empirical performance and theoretical understanding, ensuring that benchmarks not only measure but also drive the development of truly robust and trustworthy OOD solutions.\n",
    "Conclusion and Future Directions": "\\section{Conclusion and Future Directions}\n\\label{sec:conclusion__and__future_directions}\n\n\n\n\\subsection{Synthesis of Key Trends and Contributions}\n\\label{sec:8_1_synthesis_of_key_trends__and__contributions}\n\nThe field of Out-of-Distribution (OOD) detection has undergone a profound transformation, evolving from rudimentary post-hoc scoring mechanisms to sophisticated, context-aware strategies that leverage advanced model architectures and rigorous theoretical foundations. This progression is driven by the imperative to build more reliable, adaptable, and trustworthy AI systems capable of operating effectively and safely in unpredictable, open-world environments. The collective research consolidates our understanding of how OOD detection has matured to address the growing demands for robust uncertainty quantification across diverse applications.\n\nInitially, research focused on extracting OOD signals from already trained models, often through feature engineering and statistical analysis. Early efforts explored the utility of reconstruction-based methods, with \\cite{zhou202250i} rethinking autoencoder-based OOD by introducing layerwise semantic reconstruction and a Normalized L2 Distance to make reconstruction error a more valid uncertainty measure. Complementing this, \\cite{zaeemzadeh2021lmh} proposed embedding in-distribution (ID) data into a union of 1-dimensional subspaces for compact representation and easier OOD detection. The analysis of feature properties also proved fruitful: \\cite{song2022f5d} introduced RankFeat, a post-hoc method that removes a dominant rank-1 component from high-level features based on spectral analysis, significantly improving performance. Similarly, \\cite{zhu2022oir} boosted OOD detection by rectifying features into their \"typical set\" using a Truncated Batch Normalization unit, mitigating the impact of extreme features. \\cite{yu2022egq} further explored feature norms, demonstrating that intermediate layers often provide better OOD separation than the final layer, and proposed a block selection method using pseudo OOD data. Challenging the prevailing reliance on simple output-based scores, \\cite{kuan2022qzl} revisited OOD baselines and strongly advocated for the effectiveness of k-Nearest Neighbor (KNN) distance on learned embeddings. More recently, \\cite{lu20249d4} advanced distance-based methods by modeling ID classes with a mixture of prototypes in a hyperspherical embedding space, capturing intra-class diversity, while \\cite{fang2024lv2} demonstrated the power of Kernel PCA with efficient explicit feature mappings for non-linear OOD separation. These methods collectively refined the ability to discern OOD samples from subtle cues within a model's internal representations, often without requiring additional training.\n\nA significant intellectual trajectory involved moving beyond passive post-hoc analysis to actively enhancing model robustness during training. This included adversarial training, as seen in \\cite{chen2020mbk}'s ALOE, which robustified OOD detectors against both adversarial in-distribution and OOD examples. A major paradigm shift was the widespread adoption and refinement of Outlier Exposure (OE), where auxiliary OOD data is used to regularize model training. \\cite{zhang20212tb} introduced Mixture Outlier Exposure (MixOE) to address fine-grained OOD by mixing ID and auxiliary data, creating a broader virtual outlier distribution. Providing theoretical grounding, \\cite{bitterwolf2022rw0} demonstrated that many OE methods are asymptotically equivalent to a binary discriminator, highlighting that differences often stem from estimation procedures. Subsequent work focused on optimizing the utility of auxiliary data: \\cite{jiang2023vzb} proposed Diverse Outlier Sampling (DOS) to select diverse and informative outliers, a concept further advanced by \\cite{yao2024epq}'s diverseMix, which provably enhances outlier diversity through semantic-level interpolation. Addressing practical challenges, \\cite{choi202367m} introduced a balanced energy regularization loss to account for class imbalance within auxiliary OOD data, while \\cite{hofmann2024gnx} leveraged Energy-based Hopfield Boosting for adaptive sampling of \"hard\" outliers. Complementing these data-centric strategies, methods like \\cite{cheng20233yi}'s Average of Pruning (AoP) tackled training instability and overfitting in OOD detection, a theme further explored by \\cite{chen2024kl7} with optimal parameter and neuron pruning based on gradient sensitivity. \\cite{wu20242p3} explicitly pursued feature separation based on Neural Collapse, constraining OOD features to an orthogonal subspace of ID features during fine-tuning. Concurrently, generative models also evolved: \\cite{zisselman2020cmx} introduced Deep Residual Flow for improved density modeling in feature activations, and \\cite{morningstar2020re9}'s Density of States Estimation (DoSE) shifted focus from direct likelihoods to the typicality of multiple summary statistics, overcoming the \"high likelihood for OOD\" pathology.\n\nThe field has also expanded dramatically to encompass complex data modalities, specialized learning paradigms, and the formidable capabilities of foundation models. For dense prediction tasks, \\cite{liu2022fdj} proposed Residual Pattern Learning (RPL) for pixel-wise OOD detection in semantic segmentation, decoupling it from the main task. \\cite{besnier2021jgn} further enhanced segmentation OOD by learning from local adversarial attacks to generate OOD-like training data, while \\cite{gao2023epm}'s ATTA introduced anomaly-aware test-time adaptation to handle domain shifts. For graph-structured data, \\cite{liu202227x} pioneered unsupervised graph-level OOD detection with GOOD-D, a hierarchical contrastive learning framework, a direction further advanced by \\cite{wang2025xwm}'s GOLD, which uses implicit adversarial latent generation to synthesize OOD samples without auxiliary data, and \\cite{wang2024es5}'s GOODAT for test-time graph OOD detection. The rise of Vision-Language Models (VLMs) and Large Language Models (LLMs) has opened new frontiers: \\cite{miyai2023591} introduced GL-MCM for zero-shot OOD detection by combining global and local CLIP features, while \\cite{li20245b6} learned transferable negative prompts for open-vocabulary OOD, and \\cite{yu20249dd} proposed Self-Calibrated Tuning to mitigate spurious OOD features in VLMs. Leveraging LLMs further, \\cite{dai2023mhn} explored their world knowledge for multimodal OOD, carefully calibrating for hallucination, and \\cite{cao20246gj} used LLMs for \"envisioned outlier exposure\" in zero-shot settings. Multimodal OOD itself gained a dedicated benchmark with \\cite{dong2024a8k}'s MultiOOD, which also proposed the Agree-to-Disagree (A2D) algorithm to amplify inter-modal prediction discrepancies. This was complemented by \\cite{li2024rs5}'s DPU, addressing intra-class variability in multimodal OOD. Diffusion models also found their niche, with \\cite{graham20232re} applying Latent Diffusion Models for unsupervised 3D medical OOD detection, and \\cite{gao2023kmk}'s DiffGuard using pre-trained diffusion models for semantic mismatch-guided OOD. The field also expanded to long-tailed recognition \\cite{miao2023brn, wei2023f15}, LiDAR-based 3D object detection \\cite{ksel20246fe}, and even mathematical reasoning in GLMs using embedding trajectories \\cite{wang2024rej}.\n\nCrucially, the field has placed an increasing emphasis on theoretical guarantees, robust evaluation, and a critical re-evaluation of fundamental definitions to build truly trustworthy AI. \\cite{yang2022it3} introduced the Full-Spectrum OOD (FS-OOD) problem, distinguishing between semantic and covariate shifts, and proposed the SEM score for robust detection. This was followed by rigorous benchmarking efforts: \\cite{zimmerer2022rv6} established the MOOD 2020 benchmark for medical imaging, \\cite{yang2023ckx} created ImageNet-OOD to disentangle semantic and covariate shifts, and \\cite{wang2024is1} critically dissected OOD and Open-Set Recognition (OSR) methods and benchmarks. The \"Sorites Paradox\" in OOD evaluation was addressed by \\cite{long2024os1}, proposing the Incremental Shift OOD (IS-OOD) benchmark to categorize samples by continuous shift degrees. Theoretical underpinnings have also solidified: \\cite{park2023n97} provided a principled explanation for why feature norm helps OOD detection, linking it to hidden classifier confidence, while \\cite{du2024aea} formally analyzed when and how in-distribution labels provably help OOD detection. \\cite{fang20249gd} investigated the fundamental learnability of OOD detection, establishing necessary and sufficient conditions. For safety-critical systems, the focus shifted to provable guarantees: \\cite{cai2020lsi} developed real-time OOD detection for Cyber-Physical Systems (CPS) with conformal guarantees using VAEs and Deep SVDD, a concept extended by \\cite{kaur2022cty}'s iDECODe, which leveraged in-distribution equivariance. \\cite{kaur20248t3} further extended this to dependent data in CPS with temporal equivariance. Critically, \\cite{guerin202201y} argued that \"OOD detection is not all you need,\" proposing Out-of-Model-Scope (OMS) detection as a more direct goal for identifying model errors, and \\cite{vishwakarma2024z1m} introduced a human-in-the-loop framework to tame false positives with theoretical FPR guarantees. These interconnected developments highlight a maturation of the field, moving towards comprehensive solutions that are not only performant but also interpretable, reliable, and adaptable to the complex demands of real-world AI deployment.\n\\subsection{Open Challenges and Future Research Avenues}\n\\label{sec:8_2_open_challenges__and__future_research_avenues}\n\n\nThe quest for truly robust and autonomous AI systems hinges critically on their ability to reliably detect and appropriately handle Out-of-Distribution (OOD) inputs. Despite significant advancements, the field of OOD detection continues to grapple with several profound challenges that define current research frontiers and pave the way for future innovation.\n\nOne persistent challenge is the \"near OOD\" problem, where subtle shifts in data distribution are difficult to distinguish from in-distribution (ID) variations. Models often exhibit overconfidence on these semantically similar, yet novel, inputs, leading to unreliable predictions \\cite{ming2021wu7}. Addressing this requires a multi-faceted approach. Some research focuses on **data-centric strategies** to refine the ID/OOD boundary during training. For instance, Mixture Outlier Exposure (MixOE) \\cite{zhang20212tb} generates virtual outliers by mixing ID and auxiliary data, specifically targeting fine-grained OOD detection where samples share visual similarities with ID data. Similarly, Virtual Outlier Smoothing (VOSo) \\cite{nie2024ghv} constructs virtual outliers by perturbing semantic regions of ID samples, aiming to create smoother, more robust decision boundaries. However, a key challenge remains in generating truly representative and diverse near-OOD samples without inadvertently corrupting the ID manifold. Other efforts concentrate on **representation-centric enhancements**, aiming to improve the inherent separability of ID and OOD features. Batch Normalization Assisted Typical Set Estimation (BATS) \\cite{zhu2022oir} rectifies extreme features, while Variational Rectified Activation (VRA) \\cite{xu2023767} proposes optimal activation functions to improve ID/OOD separability. Leveraging Neural Collapse properties, such as ID/OOD Orthogonality (NC5) \\cite{ammar2023pr1}, projects features onto principal component spaces for better OOD detection, inherently aiding in distinguishing subtle shifts (as discussed in Section 4.2). Neuron Activation Coverage (NAC) \\cite{liu2023zb3} provides a novel uncertainty measure sensitive to abnormal activation patterns caused by subtle OOD inputs by quantifying neuron behavior. From a theoretical perspective, \\cite{du2024aea} highlights the crucial role of ID labels in these near-OOD scenarios. Despite these advancements, a fundamental understanding of *what constitutes a \"near OOD\" boundary* and how to robustly generalize detection across diverse, subtly shifted domains remains an open problem, necessitating more robust benchmarks like ImageNet-OOD \\cite{yang2023ckx} and IS-OOD \\cite{long2024os1} that disentangle semantic and covariate shifts for accurate evaluation.\n\nAnother significant open challenge is the scalability of OOD detection methods, particularly for increasingly large foundation models like Vision-Language Models (VLMs) and Large Language Models (LLMs). While these models offer unprecedented representational power and open-vocabulary capabilities (as explored in Section 5.3), traditional OOD methods often struggle with their computational and data demands, or fail to leverage their rich representations effectively without prohibitive inference costs or extensive fine-tuning. Current research is making strides in adapting OOD detection to this new paradigm. Approaches include leveraging pre-trained features, such as GL-MCM \\cite{miyai2023591} which combines global and local CLIP features for zero-shot OOD detection, offering flexibility for multi-object scenes. **Prompt engineering and virtual outlier generation** are also emerging as scalable solutions: Outlier Label Exposure (OLE) \\cite{ding20242m0} uses auxiliary outlier class labels as pseudo OOD text prompts for VLMs, and NegPrompt \\cite{li20245b6} learns transferable negative prompts from ID data alone to enhance OOD sensitivity without external outlier data. Self-Calibrated Tuning (SCT) \\cite{yu20249dd} adaptively adjusts ID classification and OOD regularization in VLMs to mitigate spurious OOD features. The potential of LLMs for generating synthetic outlier exposure is explored by \\cite{cao20246gj}, envisioning how LLM knowledge can create diverse outlier labels for zero-shot OOD detection. For multimodal foundation models, the MultiOOD benchmark and the Agree-to-Disagree (A2D) algorithm \\cite{dong2024a8k} leverage inter-modal prediction discrepancies, while Dynamic Prototype Updating (DPU) \\cite{li2024rs5} accounts for intra-class variability. However, the core challenge lies in developing OOD detection frameworks that are *inherently* scalable, efficient, and robust for models with billions of parameters, without requiring extensive retraining or sacrificing the model's generalizability. This includes tackling prohibitive inference costs, catastrophic forgetting during OOD-specific fine-tuning, and the theoretical understanding of OOD behavior in these complex architectures, as highlighted by \\cite{miyai20247ro}.\n\nLooking ahead, future research avenues are poised to develop more adaptive and dynamic OOD systems that can learn and adjust in real-time. This involves moving beyond static OOD detectors to systems capable of continuous monitoring and adaptation in dynamic environments, such as Cyber-Physical Systems (CPS). Building on the practical deployment considerations discussed in Section 6.4, methods like those pioneered by \\cite{cai2020lsi} use learned nonconformity measures within a conformal prediction framework to provide real-time OOD detection with statistical guarantees. Further advancements like iDECODe \\cite{kaur2022cty} leverage in-distribution equivariance for conformal OOD detection with bounded false detection rates, a concept extended to dependent time-series data in \\cite{kaur20248t3}. The challenge of adapting to domain shifts at test time for dense OOD detection in segmentation is addressed by ATTA \\cite{gao2023epm}, which uses a dual-level adaptation framework. Future work needs to focus on **online OOD detection** that can continuously update its model of ID and OOD without full retraining, **proactive adaptation** that anticipates shifts, and **self-correcting AI systems** that can not only detect OOD but also intelligently propose mitigation strategies or request human intervention \\cite{vishwakarma2024z1m}. The concept of adaptive sampling of \"hard\" outliers during training, as demonstrated by Energy-based Hopfield Boosting \\cite{hofmann2024gnx}, also contributes to dynamic system adjustment.\n\nAnother promising direction involves exploring **causal inference for OOD detection** to understand underlying mechanisms rather than merely identifying statistical anomalies. Traditional OOD methods often rely on statistical correlations, making them vulnerable to spurious associations that do not generalize across different environments. The work by \\cite{ming2021wu7} on the impact of spurious correlation for OOD detection underscores this limitation. Future research should focus on developing OOD detectors that are robust to such correlations by explicitly learning causal relationships. This could involve leveraging frameworks like Invariant Risk Minimization (IRM) \\cite{arjovsky2019invariant} or Structural Causal Models (SCMs) to disentangle causal (invariant) features from non-causal (environmental) ones. Specific research questions include: How can we design training objectives that promote the learning of causally invariant representations that are inherently more robust to OOD shifts? Can interventional or counterfactual reasoning be used to identify features that truly *cause* an input to be OOD, leading to more interpretable and generalizable OOD signals? Furthermore, exploring causal discovery techniques to model the underlying causal graph of ID data could enable the detection of OOD samples as deviations from this fundamental structure, offering a deeper, more principled understanding of novelty.\n\nFinally, fostering deeper integration with other machine learning tasks like active learning and continual learning is crucial for holistic, efficient, and robust AI solutions that can operate autonomously in complex environments. OOD detection naturally complements **active learning (AL)**, as OOD samples represent regions of uncertainty where the model's competence is low, making them ideal candidates for human labeling. SISOM \\cite{schmidt2024syr} proposes a unified approach, demonstrating that OOD detection and AL can be addressed simultaneously by leveraging enriched feature space distance metrics. Future work could explore how OOD uncertainty can more effectively guide AL to discover truly novel classes or subtle shifts, rather than just ambiguous ID samples. Similarly, in **continual learning (CL)**, OOD detection is vital for maintaining robustness to previously learned ID data while reliably identifying novel inputs without catastrophic forgetting. Continual Evidential Deep Learning (CEDL) \\cite{aguilar2023ms5} offers a solution for simultaneous incremental object classification and OOD detection. MIntOOD \\cite{zhang2024cx0} extends this to multimodal intent understanding. The challenge lies in developing OOD detectors that can dynamically evolve with the model in CL settings, updating their ID boundaries without re-exposing to all past data or confusing new ID classes with true OOD. These integrated approaches represent a significant step towards building AI systems that are not only aware of their limitations but can also actively learn, adapt, and operate safely in dynamic, open-world settings.\n\nUltimately, the future of OOD detection lies in a paradigm shift from reactive, isolated detectors to proactive, integrated, and self-monitoring AI systems. This grand vision entails models that continuously learn their own competence boundaries, adapt dynamically to evolving environments, leverage causal understanding for robust generalization, and seamlessly integrate with learning processes like active and continual learning. Such holistic, efficient, and robust AI solutions will be indispensable for building trustworthy systems that can operate autonomously and ethically in an increasingly complex and unpredictable world.\n\\subsection{Ethical Considerations and Societal Impact}\n\\label{sec:8_3_ethical_considerations__and__societal_impact}\n\nThe integration of Out-of-Distribution (OOD) detection mechanisms into real-world AI systems, particularly in high-stakes applications, necessitates a rigorous examination of their ethical implications and potential societal impacts. Failures in OOD detection can precipitate profound consequences, ranging from critical safety hazards in autonomous systems to the perpetuation of discriminatory outcomes in sensitive decision-making processes. Consequently, advancements in this domain must transcend mere technical performance, actively embedding principles of transparency, fairness, and accountability to foster responsible and human-centric AI deployment.\n\nA paramount ethical concern centers on the deployment of AI models in safety-critical Cyber-Physical Systems (CPS), where OOD failures can be catastrophic. For instance, autonomous vehicles and medical diagnostic tools rely heavily on robust OOD detection to prevent misinterpretations of novel inputs that could lead to severe accidents or incorrect diagnoses \\cite{cai2020lsi}. The ethical imperative here is to ensure not only high detection rates but also controlled error rates, particularly false positives and false negatives. While the technical details of certifiable OOD detection are elaborated in Section 7.2, it is ethically crucial that such systems provide statistically bounded false detection rates, as proposed by frameworks like conformal prediction \\cite{kaur2022cty, kaur20248t3}. These guarantees are vital safeguards against erroneous rejections (false positives) that could trigger unnecessary system shutdowns, or, conversely, undetected novelties (false negatives) leading to silent, dangerous failures. The challenge of managing false positives, which can erode user trust and increase human workload, is addressed by human-in-the-loop frameworks that adaptively control the False Positive Rate (FPR) with theoretical guarantees \\cite{vishwakarma2024z1m}. From a broader socio-technical perspective, the integration of human oversight in such systems also raises ethical questions about the cognitive load, potential for automation bias, and psychological impact on human supervisors, necessitating careful design of human-AI interfaces and clear protocols.\n\nBeyond error rates, the very definition of \"out-of-distribution\" carries significant ethical weight. \\cite{guerin202201y} critically argues that focusing solely on \"Out-of-Distribution Detection\" might be insufficient for safety, proposing \"Out-of-Model-Scope\" (OMS) detection as a more ethically aligned objective. OMS aims to identify inputs that would lead to actual model errors, rather than just distribution shifts, thereby directly addressing the imperative to abstain from unsafe predictions. Furthermore, the robustness of OOD detectors against malicious inputs is a critical safety concern, as adversarial attacks could manipulate detectors into making unsafe decisions \\cite{chen2020mbk}. The inherent difficulty in distinguishing harmless from potentially unsafe OOD events, particularly in dynamic environments like Reinforcement Learning, underscores the need for clear definitions of \"unknown events\" and robust safety assurance frameworks for ML components \\cite{haider20249q8}. This highlights the necessity for ethical guidelines and potentially regulatory standards to govern the certification and deployment of OOD-enabled AI systems.\n\nA particularly critical ethical dimension is the potential for bias in OOD detection, which can lead to unfair or discriminatory outcomes. If OOD models are trained on data reflecting societal biases, they can inadvertently amplify these biases. For instance, \\cite{ming2021wu7} demonstrates how spurious correlations in training data (e.g., associating certain backgrounds with specific classes) can severely degrade OOD detection performance. Models relying on these non-causal features might confidently misclassify inputs from underrepresented demographic groups as \"anomalous\" if those inputs exhibit features statistically correlated with OOD data in the training set. This can result in discriminatory rejections or differential treatment, where certain groups are disproportionately flagged as \"outliers.\" Such biases are not merely technical failures but ethical breaches, demanding fairness-aware OOD algorithms that explicitly analyze and mitigate performance disparities across demographic subgroups. While interpretability methods like GAIA, which uses gradient-based attribution abnormality \\cite{chen2023za1}, or Neuron Activation Coverage (NAC) \\cite{liu2023zb3}, are not direct fairness interventions, they are crucial tools for auditing models. By revealing *why* an input is deemed OOD, they enable practitioners to identify and address unintended biases in the OOD decision-making process. In multimodal contexts, where biases can exist across various data streams (e.g., text, video, audio), the challenge of ensuring fair OOD detection is further compounded \\cite{zhang2024cx0}.\n\nFinally, the societal impact of deploying AI models that may fail silently on novel inputs is a pervasive ethical concern. The fundamental purpose of OOD detection is to prevent such silent failures, enabling models to express uncertainty or abstain when confronted with unfamiliar data. Methods like DoSE \\cite{morningstar2020re9} directly tackle the \"high likelihood for OOD\" pathology, where generative models might assign high confidence to OOD data, thereby preventing a dangerous false sense of security. Furthermore, a deeper understanding of how in-distribution (ID) labels influence OOD detection, especially for \"near OOD\" scenarios where ethical risks are heightened \\cite{du2024aea}, is vital to avoid mischaracterizing subtle shifts as benign. The development of robust and comprehensive in-distribution representations, as exemplified by methods like MOODv2 \\cite{li2024n34}, inherently makes OOD detection more reliable and less prone to silent failures, as models gain a more accurate understanding of what constitutes \"normal\" data.\n\nIn conclusion, while significant technical advancements have propelled OOD detection forward, the ethical considerations and societal impact remain paramount. Future research must prioritize the development of robust safeguards, including statistical guarantees (as discussed in Section 7.2) and adaptive human-in-the-loop mechanisms \\cite{vishwakarma2024z1m}, to rigorously control false positives and negatives in safety-critical applications. Crucially, a concerted effort is needed to ensure fairness by investigating and mitigating potential biases, particularly those arising from spurious correlations \\cite{ming2021wu7}, through the development of transparent and interpretable methods \\cite{chen2023za1, liu2023zb3} that facilitate auditing and accountability. Ultimately, the goal is to cultivate a paradigm where AI systems not only achieve high performance but also operate responsibly, recognizing their limitations, communicating uncertainty effectively, and adhering to ethical guidelines, thereby fostering trust and enabling the safe and equitable integration of AI into society.\n"
  },
  "subsections": {
    "Defining Out-of-Distribution Data and Distribution Shifts": "\\subsection{Defining Out-of-Distribution Data and Distribution Shifts}\nThe robust deployment of machine learning models in real-world, open-world environments critically hinges on their ability to recognize when input data deviates from the distribution they were trained on. This fundamental challenge is addressed by Out-of-Distribution (OOD) detection, a field dedicated to distinguishing In-Distribution (ID) data, which models are designed to process, from novel, unfamiliar OOD data. Initially, OOD was often conceptualized as a straightforward \"semantic shift,\" implying entirely new classes or concepts unseen during training. However, this definition has evolved significantly to encompass a more complex spectrum of distribution shifts that profoundly challenge model generalization.\n\nEarly work often struggled to consistently categorize various forms of data shifts. \\cite{yang2022it3} critically addressed this by introducing the \"Full-Spectrum OOD (FS-OOD)\" problem, explicitly distinguishing between **semantic shift** (novel classes) and **covariate shift** (changes in input appearance or style, such as lighting or viewpoint, while retaining the same semantic class). Their proposed SEM score function, which disentangles semantic and non-semantic features, aimed to detect true semantic novelty while remaining robust to covariate variations, highlighting the necessity of a nuanced approach beyond simple binary classification. Further complicating this, \\cite{ming2021wu7} introduced the concept of \"spurious OOD,\" demonstrating that models can make overconfident predictions on OOD inputs that share spurious correlations with ID data, even if they lack the essential invariant features. This revealed a deeper vulnerability where models exploit non-causal features, making detection particularly challenging and underscoring the inherent ambiguity in OOD boundaries.\n\nThe need for more rigorous evaluation and clearer definitions led to significant advancements in benchmarking. \\cite{yang2023ckx} meticulously curated `ImageNet-OOD`, a dataset designed to isolate pure semantic shift by removing ID contamination, semantic ambiguities, and unintended covariate shifts prevalent in prior benchmarks. This effort emphasized the difficulty in creating truly clean OOD definitions and highlighted how existing methods often inadvertently detected covariate shifts rather than genuine semantic novelty. Building on this, \\cite{averly20239rv} proposed a \"Model-Specific Out-of-Distribution (MS-OOD)\" framework, which redefined OOD not solely by data properties but by whether a *deployed model* could correctly classify an example. This unified the detection of semantic shift, covariate shift (when misclassified), and even misclassified ID examples under a single, performance-driven ground truth, providing a more practical and holistic perspective. The \"Sorites Paradox\" of OOD, where the degree of shift is continuous rather than binary, was addressed by \\cite{long2024os1}. They introduced the \"Incremental Shift OOD (IS-OOD)\" benchmark and the LAID method, which leverages CLIP to decompose image features into distinct semantic and covariate components, allowing for a continuous measurement of shift levels. This moved the field towards understanding OOD as a spectrum rather than a discrete boundary. \\cite{wang2024is1} further dissected OOD detection and open-set recognition, providing a critical analysis of methods and benchmarks, and emphasizing the need for evaluation protocols that disentangle semantic and covariate shifts, especially at scale where methods like Outlier Exposure struggle due to the difficulty of acquiring representative auxiliary OOD data.\n\nBeyond visual data, the definition and challenges of OOD extend to other modalities. \\cite{liu202227x} pioneered unsupervised OOD detection for graph-structured data with GOOD-D, addressing the unique topological and feature-based shifts in graphs. \\cite{dong2024a8k} scaled OOD detection to multimodal settings, introducing the `MultiOOD` benchmark and the Agree-to-Disagree (A2D) algorithm to leverage complementary information across modalities (e.g., video, audio, optical flow) and identify `Modality Prediction Discrepancy` as an OOD signal. For natural language processing, \\cite{lang20237w3} provided a comprehensive survey, highlighting the distinct challenges of discrete input spaces and contextual semantic shifts. In generative language models, \\cite{wang2024rej} tackled OOD detection in mathematical reasoning, identifying \"pattern collapse\" in output spaces and proposing a \"Trajectory Volatility Score\" based on dynamic embedding changes, demonstrating how domain-specific phenomena necessitate specialized OOD definitions. Furthermore, theoretical investigations have deepened our understanding of OOD learnability. \\cite{fang20249gd} explored the PAC learnability of OOD detection, proving that it is not universally learnable and depends critically on the characteristics of the data distributions and hypothesis spaces. \\cite{du2024aea} provided theoretical conditions for *when and how* in-distribution labels help OOD detection, particularly for \"near OOD\" scenarios. Finally, \\cite{park2023n97} offered a theoretical explanation for the efficacy of feature norms in OOD detection, linking it to hidden classifier confidence and proposing a \"Negative-Aware Norm\" (NAN) that accounts for both activation and deactivation tendencies of neurons, providing a deeper insight into the internal mechanisms that differentiate ID from OOD.\n\nIn conclusion, the definition of OOD data and distribution shifts has evolved from a simplistic notion of novel classes to a multifaceted concept encompassing semantic, covariate, and spurious shifts, often viewed as a continuous spectrum rather than a hard boundary. The field now grapples with model-specific interpretations, multimodal challenges, and fundamental questions about learnability, necessitating robust detection mechanisms that are sensitive to diverse forms of unfamiliarity while being resilient to expected variations. The inherent ambiguity in precisely delineating OOD boundaries remains a central, ongoing challenge in the field.",
    "Motivation: The Imperative for Trustworthy AI": "\\subsection{Motivation: The Imperative for Trustworthy AI}\nThe increasing integration of artificial intelligence (AI) systems into critical societal infrastructures and high-stakes applications necessitates an unwavering commitment to trustworthiness, reliability, and safety. A fundamental challenge that directly undermines this trust is the inherent overconfidence of deep learning models when confronted with inputs that deviate significantly from their training distribution, commonly referred to as Out-of-Distribution (OOD) data. This section articulates the compelling and urgent reasons behind the escalating importance of OOD detection in modern AI, emphasizing its role as an indispensable component for building truly trustworthy, robust, and safe artificial intelligence.\n\nIn numerous safety-critical domains, the consequences of unchecked model overconfidence on OOD data can be catastrophic, leading to unreliable decisions, system failures, and potentially severe harm. For instance, in autonomous driving, a vehicle's perception system misinterpreting an anomalous road condition, an unfamiliar object, or an unusual weather pattern as a familiar in-distribution (ID) input can lead to dangerous maneuvers or accidents \\cite{cai2020lsi, kaur2022cty}. Similarly, in medical diagnosis, an AI system providing a highly confident but incorrect diagnosis for a rare or unseen patient condition, or misinterpreting an anomalous medical image, could have dire implications for patient well-being \\cite{zimmerer2022rv6, kaur2022cty}. The deployment of deep reinforcement learning (RL) agents in real-world control systems also faces this challenge, where agents trained in simulated environments may encounter novel states in the physical world and fail silently without signaling uncertainty, posing significant safety risks \\cite{haider20249q8}. This imperative for trustworthy AI demands that these systems not only perform well on familiar data but also express meaningful and calibrated uncertainty when encountering novel, unfamiliar, or anomalous inputs \\cite{zisselman2020cmx, morningstar2020re9, lu2024j0n}.\n\nThe core problem stems from the \"closed-world\" assumption under which most deep learning models are traditionally trained. This assumption posits that test data will be drawn from the same statistical distribution as the training data \\cite{yang2022ci8}. However, this premise rarely holds true in complex, dynamic, and open-world environments where unforeseen circumstances, sensor noise, adversarial attacks, or simply novel data points are inevitable \\cite{zisselman2020cmx, chen2020mbk, morningstar2020re9, guerin202201y, schmidt2024syr, vishwakarma2024z1m}. When this closed-world assumption is violated, conventional models often produce high-confidence, yet incorrect, predictions for OOD samples \\cite{song2022f5d, yu2022egq, ammar2023pr1, bitterwolf2022rw0, lu2024j0n}. This unwarranted overconfidence is a critical vulnerability that OOD detection aims to mitigate, providing a crucial safety mechanism to prevent models from making decisions outside their learned competence.\n\nFurthermore, the very nature of OOD data can be complex and multifaceted, posing additional challenges to reliable detection. It is not always a simple binary distinction between \"known\" and \"unknown.\" For instance, models can learn spurious correlations from their training data, leading them to confidently classify OOD inputs that share these irrelevant features as in-distribution, making such \"spurious OOD\" particularly difficult to detect \\cite{ming2021wu7}. This highlights that a robust OOD detector must not only identify entirely novel semantic concepts but also be resilient to subtle shifts or misleading cues. Moreover, the definition of what constitutes \"OOD\" can even be model-specific, depending on whether a particular input leads to a misclassification for a given deployed model, rather than a universal distributional shift \\cite{averly20239rv}. These nuances underscore the need for sophisticated and context-aware OOD detection mechanisms.\n\nThe practical deployment of AI systems further amplifies the need for robust OOD detection. Beyond theoretical performance, real-world systems require OOD detectors that are not only accurate but also provide reliable guarantees and manage false positives effectively. High false positive rates (FPR), where legitimate in-distribution samples are incorrectly flagged as OOD, can lead to user frustration, unnecessary human intervention, and a breakdown of trust in the system \\cite{vishwakarma2024z1m}. Therefore, the development of OOD detection is intrinsically linked to the broader goal of building AI systems that are transparent about their limitations, can abstain from making potentially harmful decisions when faced with unfamiliar situations, and can operate predictably and safely in dynamic environments.\n\nIn summary, the motivation for robust OOD detection is deeply rooted in the urgent need to transition AI from research curiosities to reliably deployed systems that operate safely and responsibly in the real world. It is not merely about identifying novelty but about ensuring that AI systems are aware of their limitations, can express appropriate uncertainty, and can defer to human oversight or alternative safe actions when confronted with inputs beyond their learned experience. OOD detection, therefore, stands as a pivotal step towards enabling the responsible and reliable deployment of AI in complex, open-world environments, where unforeseen circumstances are not exceptions but inevitable realities. Continued research in this area is essential to bridge the gap between theoretical capabilities and the practical demands of trustworthy AI.",
    "Uncertainty Quantification in Neural Networks": "\\subsection{Uncertainty Quantification in Neural Networks}\n\nConventional neural networks, while achieving remarkable performance in complex classification tasks, are fundamentally designed to assign inputs to a fixed set of predefined classes rather than to explicitly quantify the uncertainty inherent in their predictions. Nevertheless, these classifiers offer implicit signals of confidence primarily through softmax probabilities and the entropy of the predicted class distribution. These metrics serve as initial, easily accessible indicators of a model's belief. A critical understanding of their foundational role and, more importantly, their profound limitations is indispensable for appreciating the subsequent evolution of Out-of-Distribution (OOD) detection methodologies that strive for truly calibrated uncertainty estimates.\n\nA seminal contribution by \\cite{Hendrycks_G_2017} formalized the use of Maximum Softmax Probability (MSP) as a straightforward baseline for identifying both misclassified in-distribution (ID) and OOD examples. This work, alongside others, critically exposed a pervasive and dangerous flaw: neural networks frequently exhibit severe overconfidence, assigning high softmax probabilities to OOD inputs. This leads to erroneous high-confidence predictions that are fundamentally unreliable, as the model confidently asserts an input belongs to a known class despite having never encountered anything similar during training. The root cause of this overconfidence lies in the very design of the softmax function. As \\cite{Kendall_A_2017} elucidates, softmax is inherently a normalized probability distribution over a fixed set of *known* classes. It is optimized to express the model's certainty about which of the *trained* categories an input belongs to (reflecting *aleatoric uncertainty* due to inherent data noise), but it is ill-equipped to capture *epistemic uncertainty*â€”the model's lack of knowledge or confidence when confronted with inputs far removed from its training distribution. Consequently, an OOD input, by definition, falls outside the model's learned domain, yet the softmax mechanism forces it into one of the known categories, often with high confidence, simply by finding the \"closest\" match within its learned manifold.\n\nBeyond this conceptual mismatch, modern deep neural networks are frequently poorly calibrated \\cite{Guo_C_2017}. This means their predicted probabilities do not accurately reflect the true likelihood of correctness, exacerbating the overconfidence problem, particularly for OOD inputs. The architectural choices prevalent in deep learning, such as increased depth, ReLU activations, and optimization for accuracy rather than calibration, contribute to this miscalibration. When a model's confidence scores are unreliable even for ID data, their utility for discerning OOD samples becomes severely compromised. Furthermore, the issue of overconfidence is significantly compounded by the model's reliance on spurious correlations present in the training data. As \\cite{ming2021wu7} rigorously demonstrated, models trained on datasets containing statistically informative but non-causal features tend to exploit these shortcuts. When an OOD input shares these spurious features with ID data, the model can confidently assign a high softmax probability, even if the input lacks the invariant, semantic features crucial for correct classification. This reliance on misleading environmental cues makes distinguishing spurious OOD samples from ID data inherently challenging, as the model's confidence is rooted in a superficial correlation rather than true semantic understanding \\cite{ming2021wu7}.\n\nEmpirical and theoretical studies consistently underscore the inadequacy of raw softmax and entropy scores for robust OOD detection. \\cite{kuan2022qzl} provided extensive evidence that simple prediction-based methods like MSP and entropy are reliably outperformed by methods leveraging learned intermediate representations (embeddings). Their work challenged the notion of MSP as a universally strong baseline, demonstrating that while it might offer some rudimentary signal, it often falls short compared to approaches that analyze the internal feature space, which are better equipped to capture deviations from the ID manifold. This empirical observation is theoretically grounded by \\cite{peng20243ji}, who critically analyzed logit-based methods, including those derived from softmax. They explained that these methods are often not directly proportional to true data density. This fundamental disconnect implies that even when a model's logits are high, the resulting softmax probability does not necessarily reflect a high likelihood under the true in-distribution data manifold, leading to suboptimal OOD detection performance. Similarly, \\cite{averly20239rv}'s comprehensive evaluation, while introducing a model-specific perspective, implicitly highlights the context-dependent and often inconsistent performance of MSP across different types of OOD shifts (e.g., semantic vs. covariate) and misclassifications, reinforcing its limitations as a standalone, universally reliable uncertainty measure.\n\nIn summary, while softmax probabilities and entropy offer initial, easily accessible indicators of a neural network's confidence, their inherent limitations are profound and multifaceted. These include their inability to capture epistemic uncertainty due to their closed-set design, the pervasive problem of miscalibration in modern deep networks, and their vulnerability to spurious correlations in training data. These shortcomings collectively render raw output-based uncertainty estimates unreliable for robust OOD detection, particularly in safety-critical applications where silent failures can have severe consequences. This fundamental inadequacy necessitates the development of more sophisticated OOD detection methodologies that move beyond simple output scores, paving the way for the advanced post-hoc, feature-space, generative, and training-time strategies discussed in subsequent sections of this review.",
    "Post-Hoc Confidence-Based Detection": "\\subsection{Post-Hoc Confidence-Based Detection}\n\nThe development of robust out-of-distribution (OOD) detection methods is paramount for ensuring the reliability and safety of machine learning systems in real-world applications. Early and highly influential research in this domain focused on leveraging and refining confidence scores derived from pre-trained discriminative classifiers. These \"post-hoc\" methods are particularly attractive due to their efficiency, as they do not require any model retraining or modification of the original classification objective, thereby minimizing computational overhead and preserving the model's primary task performance. This section details the evolution of such confidence-based approaches, from foundational baselines to sophisticated enhancements.\n\nA seminal contribution to this field was the introduction of Maximum Softmax Probability (MSP) as a baseline for OOD detection by \\cite{hendrycks17baseline}. This straightforward yet surprisingly effective method operates on the premise that a well-trained classifier should assign a high maximum softmax probability to in-distribution (ID) samples, reflecting strong confidence in its classification. Conversely, OOD samples, which do not align with any learned class, are expected to yield lower maximum probabilities. Despite its simplicity, MSP established a crucial benchmark, demonstrating that standard neural network outputs inherently contain valuable uncertainty signals. The work also played a pivotal role in standardizing evaluation protocols and datasets, fostering more rigorous comparisons across diverse OOD detection techniques. However, a significant limitation of MSP is the pervasive problem of neural network overconfidence on OOD inputs \\cite{community_0, community_5}. Models can often assign spuriously high confidence to novel, unseen data, especially for \"near OOD\" examples that share superficial similarities with ID data, leading to suboptimal discrimination and false negatives. This fundamental challenge highlights that raw softmax probabilities, while indicative, are not always reliable estimators of true data density or typicality \\cite{peng20243ji}.\n\nBuilding upon the insights from MSP, \\cite{Liang_etal_2018} introduced Out-of-Distribution Detector for Neural Networks (ODIN), a method designed to significantly amplify the distinction between ID and OOD samples without requiring any model retraining. ODIN introduced two key innovations. First, it incorporated temperature scaling, a technique originally used for model calibration, which smooths the softmax distribution by dividing the logits by a temperature parameter $T$. This adjustment makes the confidence scores less extreme and often more discriminative for OOD detection by re-calibrating the output probabilities. Second, and more crucially, ODIN proposed a small, carefully crafted input perturbation. This perturbation is calculated to push the input towards the direction that maximizes the softmax probability for the predicted class. For ID samples, this makes them \"more ID-like\" in the model's perception, increasing their confidence. For OOD samples, which lack a strong alignment with any ID class, this perturbation often fails to significantly boost confidence or may even push them towards lower confidence, thereby increasing the separation in confidence scores between ID and OOD data. By combining these two simple yet powerful post-hoc techniques, ODIN substantially boosted OOD detection performance over MSP, establishing a strong, efficient baseline.\n\nFurther refining the ODIN paradigm, \\cite{Hsu_Y_2020} proposed Generalized ODIN (G-ODIN), which aimed to improve robustness by addressing a potential weakness in ODIN's perturbation strategy. While ODIN perturbs inputs to maximize confidence for the *predicted* class, G-ODIN considers a broader context. Instead of relying on a single predicted class, G-ODIN perturbs the input towards the direction that minimizes the maximum softmax probability across *all* ID classes. This approach makes the OOD score more robust by ensuring that an OOD sample is not mistakenly pushed to high confidence for an incorrect ID class. By considering the full set of ID classes during perturbation, G-ODIN can achieve better discrimination, especially when OOD samples might be ambiguous or share features with multiple ID categories.\n\nThe concept of temperature scaling, a cornerstone of ODIN, has continued to evolve. Recognizing that a fixed global temperature might not be optimal for all samples, \\cite{krumpl2024n1w} introduced Adaptive Temperature Scaling (ATS). ATS proposes dynamically calculating a *sample-specific* temperature value based on activations from intermediate layers of the neural network. By fusing this sample-specific adjustment with class-dependent logits, ATS captures additional statistical information that might otherwise be lost in the feature extraction process. This dynamic approach leads to a more robust and powerful OOD detection method, demonstrating that even subtle refinements to temperature scaling can significantly enhance the performance and robustness of existing logit-based OOD detection techniques.\n\nWhile highly effective and efficient, these confidence-based methods fundamentally rely on the assumption that the classifier's output space (logits or softmax probabilities) can reliably distinguish between ID and OOD data. However, as highlighted by \\cite{peng20243ji}, raw logit-based scores, including energy scores (which are closely related to logits), often make implicit assumptions about the underlying data distribution, such as constant partition functions across classes, or that softmax probabilities directly represent true data densities. These assumptions are not always accurate, limiting the theoretical grounding and empirical robustness of simpler confidence scores. To address this, \\cite{peng20243ji} proposed ConjNorm, a novel theoretical framework grounded in Bregman divergence, which unifies density function design for OOD detection within the exponential family of distributions. By devising an unbiased and analytically tractable estimator for the partition function using importance sampling, ConjNorm offers a more principled and flexible approach to density estimation for OOD scoring, moving beyond restrictive distributional assumptions and leading to superior empirical performance. This work signifies a critical advancement towards more theoretically robust confidence-based OOD measures.\n\nIn summary, post-hoc confidence-based detection methods, starting from the simplicity of MSP and progressing through the innovative enhancements of ODIN, G-ODIN, and ATS, have laid a robust foundation for the field. They collectively demonstrated that significant improvements in uncertainty quantification could be achieved by cleverly leveraging and refining the outputs of existing pre-trained classifiers without the need for costly retraining. However, their inherent reliance on the classifier's output space and the potential for overconfidence or inaccurate density estimation remain persistent challenges. These limitations motivate the exploration of richer, intermediate representations and more theoretically grounded approaches to OOD detection, which are discussed in subsequent sections.",
    "Feature-Space Distance-Based Methods": "\\subsection{Feature-Space Distance-Based Methods}\n\nEarly efforts in out-of-distribution (OOD) detection quickly recognized the inherent limitations of relying solely on a neural network's final output probabilities, such as Maximum Softmax Probability (MSP). While simple, MSP often fails to capture the true uncertainty for samples significantly deviating from the in-distribution (ID) manifold, frequently exhibiting overconfidence on novel inputs. This critical observation spurred a shift towards leveraging the internal feature representations of neural networks, driven by the hypothesis that OOD samples would manifest as distinct patterns or lie significantly distant from the ID data within these learned embedding spaces.\n\nA foundational exploration into using internal representations for OOD detection was presented by \\cite{Hendrycks_G_2017}. While this work primarily established MSP as a baseline, it also investigated the efficacy of Mahalanobis distance computed on features from intermediate layers. By modeling the distribution of ID features for each class as a simple Gaussian, OOD samples could be identified as those with a large Mahalanobis distance to all ID class centroids. This early insight highlighted the potential of feature-level analysis to provide more robust OOD scores than simple output probabilities, laying crucial groundwork.\n\nBuilding upon this concept, \\cite{Lee_K_2018} introduced a more comprehensive framework that explicitly leverages Mahalanobis distance in the feature space for OOD detection. This method models the in-distribution feature representations for each class using class-conditional Gaussian distributions, where the mean and covariance are estimated from the training data. An input is then classified as OOD if its Mahalanobis distance to all ID class centroids is sufficiently large. Crucially, \\cite{Lee_K_2018} also proposed using generative adversarial networks (GANs) to regularize the feature space during training. By training a GAN to generate OOD samples and then using these to push OOD representations away from ID clusters, the feature space becomes more discriminative, enhancing the separation between ID and OOD samples and making the Mahalanobis distance a more effective OOD score. This approach demonstrated a significant advancement by actively shaping the feature space to be more amenable for OOD discrimination, moving beyond merely observing existing features.\n\nDespite its principled nature, the effectiveness of Mahalanobis distance-based methods can be limited by the strong assumption of Gaussianity for ID features and the quality of the learned features, particularly in high-dimensional spaces where the \"curse of dimensionality\" can render distance metrics less meaningful \\cite{ghosal2023q20}. This motivated further research into refining the feature space and the distance calculations themselves. For instance, \\cite{anthony2023slf} conducted an in-depth analysis of Mahalanobis distance for medical imaging OOD detection, challenging the common assumption of a single optimal layer for detection. They empirically demonstrated that the optimal network depth for OOD detection is highly dependent on the specific OOD pattern and proposed a Multi-branch Mahalanobis (MBM) framework. MBM employs multiple OOD detectors operating at different depths of the network, each combining normalized Mahalanobis scores from its constituent modules, significantly enhancing robustness by capturing diverse OOD signals across the feature hierarchy.\n\nTo mitigate the curse of dimensionality and improve feature space utility, researchers have explored learning more structured and compact representations. \\cite{zaeemzadeh2021lmh} proposed training deep neural networks to embed ID samples onto a union of 1-dimensional subspaces. This compact representation ensures that OOD samples are less likely to occupy the same region as known classes, and robust representatives (singular vectors) can be used for distance calculations, thereby simplifying OOD detection. Similarly, \\cite{ghosal2023q20} introduced Subspace Nearest Neighbor (SNN), a framework that regularizes the model and its feature representation by leveraging the most relevant subset of dimensions. This subspace learning yields highly distinguishable distance measures between ID and OOD data, demonstrating significant improvements over previous distance-based methods by making the distances more robust to high-dimensional noise. Extending this, \\cite{li2025jdt} proposed a novel \"tangent distance\" that explicitly accounts for the data structure by mapping high-dimensional features to the manifold of ID samples. This method computes the Euclidean distance between samples and the nearest submanifold space (a linear approximation of the local region on the manifold), providing a more meaningful distance measure that is less sensitive to the curse of dimensionality.\n\nBeyond Mahalanobis and its direct refinements, other distance-based approaches leverage different metrics or modeling assumptions. K-Nearest Neighbors (KNN) based methods, for example, directly quantify OODness by measuring the distance of a test sample to its $k$-nearest neighbors within the ID training data's feature space, offering a non-parametric alternative to Gaussian models. In a more modern context, \\cite{vojivr202444c} introduced PixOOD for pixel-level OOD detection, which, while operating at a finer granularity, fundamentally relies on distances. It extracts pixel/patch feature representations and builds a 2D projection space where distances to multiple class etalons (learned prototypes) are used to model complex intra-class variability and identify OOD pixels. This demonstrates how distance-based principles can be adapted for fine-grained OOD detection by modeling ID distributions with multiple prototypes rather than a single centroid.\n\nIn summary, feature-space distance-based methods represent a crucial evolution in OOD detection, moving beyond simple output probabilities to leverage the richer information in internal representations. They have progressed from initial explorations of Mahalanobis distance on existing features to sophisticated techniques that actively regularize, learn, or project OOD-discriminative feature spaces. While these methods have shown promise in quantifying an input's deviation from the in-distribution manifold, challenges persist, including the sensitivity to the quality of learned features, the computational cost associated with training-time regularization, and the inherent difficulties of distance metrics in high-dimensional spaces. Future directions include developing more flexible models for feature distributions (e.g., non-parametric density estimation or advanced mixture models), integrating self-supervised learning to learn more robust features, and exploring adaptive distance metrics that can better capture complex manifold structures. Furthermore, the utility of these distance-based OOD scores is increasingly recognized in broader uncertainty quantification frameworks, such as their application as non-conformity scores within Conformal Prediction to provide statistically rigorous guarantees on OOD detection performance \\cite{novello2024yco}.",
    "Likelihood-Based Deep Generative Models": "\\subsection{Likelihood-Based Deep Generative Models}\n\nThe detection of Out-of-Distribution (OOD) samples is a critical challenge for deploying reliable deep learning systems. A theoretically principled approach to OOD detection involves leveraging deep generative models to learn the underlying data distribution of in-distribution (ID) samples. The fundamental premise is that samples originating from outside this learned distribution, i.e., OOD samples, should exhibit a significantly lower likelihood or probability density under the model trained exclusively on ID data. This allows for their identification based on their deviation from the learned ID manifold, offering a theoretically grounded method for uncertainty quantification. Early methods primarily explored Variational Autoencoders (VAEs) \\cite{Kingma_Welling_2013} and Generative Adversarial Networks (GANs) \\cite{Goodfellow_etal_2014} for this purpose. VAEs provide an estimate of the data log-likelihood (or a lower bound, ELBO), while GANs can be adapted to provide density estimates or use discriminator scores as proxies for typicality.\n\nInitially, the intuitive strategy was to directly use the raw likelihood or a related reconstruction error from a trained generative model as an OOD score. However, this straightforward application often proved problematic. Raw likelihood scores from deep generative models can be inherently misleading, frequently assigning higher likelihoods to certain OOD samples than to some ID samples \\cite{Nalisnick_etal_2019_Do_Deep_Generative_Models_Know_What_They_Don_t_Know}. This counter-intuitive phenomenon, observed across various model architectures and datasets, stems from several factors. Deep generative models, particularly in high-dimensional spaces, may learn spurious low-level correlations or assign high probabilities to simple, out-of-distribution inputs that lie in regions of the input space not well-constrained by the ID data. This can be exacerbated by the \"Gaussian Annulus Theorem,\" where in high dimensions, the typical set of data (where most of the probability mass lies) may not intersect with the region of highest density, leading to OOD samples with high likelihood but low typicality \\cite{morningstar2020re9}. For VAEs, the Evidence Lower Bound (ELBO) is only a lower bound to the true log-likelihood, and a tighter bound does not necessarily correlate with better OOD detection performance. Even models capable of exact likelihood estimation, such as Normalizing Flows (NFs) \\cite{Dinh_etal_2016} and Autoregressive models (e.g., PixelCNNs), suffer from this issue, often assigning higher likelihoods to less complex OOD images than to complex ID images, further demonstrating that raw likelihood alone is an unreliable indicator of semantic OODness \\cite{osada20246an}.\n\nTo address the unreliability of raw likelihood scores, more robust statistical measures were introduced, marking an evolution from simple density estimation to more refined statistical tests. A pivotal advancement was proposed by \\cite{Ren_J_2019}, who demonstrated that comparing the likelihood of a sample under the learned ID distribution to its likelihood under a simpler, \"null\" model provides a significantly more effective OOD score. Their work introduced the concept of likelihood ratio tests for OOD detection, where the ratio of the likelihood under a complex ID generative model (e.g., VAE or GAN) to that under a baseline model (e.g., a simple Gaussian distribution or a model trained on diverse OOD data) serves as a robust discriminator. This approach effectively normalizes the raw likelihood, focusing on how *much better* the ID model explains the data compared to a general or OOD model, thereby improving OOD discrimination and mitigating the issues associated with misleading raw likelihood values.\n\nBeyond simple likelihood ratios, other sophisticated statistical approaches have emerged to leverage generative models more effectively. \\cite{morningstar2020re9} introduced Density of States Estimation (DoSE), an unsupervised method that moves beyond direct model probabilities. Inspired by statistical physics, DoSE evaluates the \"typicality\" of an input by analyzing multiple summary statistics (e.g., negative log-likelihood, L2 norm of latent features) derived from a pre-trained generative model. Instead of directly comparing likelihoods, DoSE trains non-parametric density estimators (like Kernel Density Estimation or one-class SVMs) on the distribution of these statistics for ID data. An OOD sample is then identified if its derived statistics are atypical under these learned distributions, providing a more robust measure of OODness that accounts for the high-dimensional nature of the problem and the shortcomings of raw likelihood.\n\nFurthermore, Normalizing Flows, which provide exact and tractable likelihoods, have seen increasing application in OOD detection, often by modeling densities in feature spaces rather than raw pixel space. For instance, \\cite{zisselman2020cmx} proposed Deep Residual Flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution, improving OOD detection by modeling feature activations. Similarly, \\cite{cook2024hyb} investigated feature density estimation via Normalizing Flows as a fully unsupervised, post-hoc method. By training a lightweight NF model on the feature representations of a pre-trained classifier, they demonstrated strong results for far-OOD detection, highlighting that while raw input likelihoods can be problematic, density estimation in a more semantically meaningful feature space can be highly effective.\n\nThe evolution from simple density estimation to more refined statistical measures like likelihood ratio tests and typicality-based approaches, coupled with the broader application of diverse generative architectures like Normalizing Flows, marks a significant progression in the field. While likelihood-based methods offer a theoretically grounded approach to OOD detection, challenges persist in accurately modeling complex, high-dimensional data distributions and ensuring that likelihood estimates genuinely correlate with semantic OODness across diverse scenarios. Future work continues to explore more robust generative architectures, improved background models for ratio tests, and sophisticated statistical tests to further bridge the gap between theoretical soundness and practical efficacy in real-world OOD detection tasks.",
    "Reconstruction Autoencoders: Advancements and Limitations": "\\subsection*{Reconstruction Autoencoders: Advancements and Limitations}\n\nTraditional reconstruction autoencoders (AEs) were initially considered a promising avenue for Out-of-Distribution (OOD) detection, operating under the intuitive assumption that models trained exclusively on in-distribution (ID) data would struggle to reconstruct novel OOD inputs, leading to higher reconstruction errors. However, this foundational premise frequently faltered due to a fundamental design paradox: the inherent capacity of deep autoencoders to generalize and effectively reconstruct diverse novel inputs \\cite{Ren_etal_2019}. This powerful generalization, while beneficial for tasks like denoising or data compression, often meant that OOD samples yielded reconstruction errors comparable to, or even lower than, ID samples \\cite{morningstar2020re9}. Consequently, the simple reconstruction error proved to be an unreliable metric for distinguishing ID from OOD data, severely limiting the practical utility of early AE-based methods in safety-critical applications. This critical limitation necessitated a significant re-evaluation and sophisticated re-engineering of their underlying principles to transform them into reliable OOD detectors.\n\nEarly attempts to leverage reconstruction error for OOD detection, including simpler methods like Principal Component Analysis (PCA) for dimensionality reduction and subsequent reconstruction, often faced this challenge \\cite{guan2023dwv}. The core problem was designing autoencoders that could learn a sufficiently tight manifold of ID data without inadvertently developing the capacity to reconstruct novel patterns. This challenge spurred significant advancements that fundamentally rethought the autoencoder's objective and architecture, moving beyond raw pixel reconstruction and simple L2 error.\n\nOne pivotal advancement has been the shift from pixel-level reconstruction to \\textit{semantic feature reconstruction}. Reconstructing raw pixels demands high expressiveness from the autoencoder, which can inadvertently generalize to OOD inputs. Instead, modern approaches often focus on reconstructing robust, high-level features extracted from pre-trained models. This strategy aligns with broader trends in OOD detection that leverage discriminative feature spaces \\cite{Lee_etal_2018}. For instance, \\cite{zhou202250i} exemplifies this by reconstructing Activation Vectors (AVs) from the penultimate layer of a pre-trained classifier. This strategic shift simplifies the autoencoder's task to lower-dimensional, semantically relevant features, ensuring that the autoencoder's learning is concentrated on the abstract, task-specific characteristics of ID data. Deviations in reconstructing these semantic features are thus more indicative of OODness than pixel-level discrepancies, which might be influenced by superficial similarities.\n\nConcurrently, to prevent the latent space from accommodating novel patterns, methods have increasingly enforced a \\textit{maximally compressed or regularized latent space} for ID samples. This is achieved through regularization losses during training that actively restrict ID latent features to a compact, known domain. Variational Autoencoders (VAEs), a class of generative models that learn a latent distribution, inherently aim for a more structured latent space, which can be leveraged for OOD detection. For example, \\cite{cai2020lsi} integrates VAEs into an Inductive Conformal Anomaly Detection (ICAD) framework for real-time OOD detection in cyber-physical systems. Here, the VAE's ability to reconstruct ID data from its learned latent space, combined with Deep Support Vector Data Description (SVDD) for learning a minimum-volume hypersphere, effectively enforces a tight ID manifold. Similarly, \\cite{60108b8e0d7204fa33f686b09128c7fc8489a224} explores the use of self-attention within VAEs to learn more discriminative and compact latent representations specifically for anomaly detection. \\cite{zhou202250i} also enforces this explicit constraint, ensuring that any input whose latent representation falls outside this tightly defined space is likely OOD. This contrasts sharply with earlier autoencoders that allowed latent spaces to form organically, often encompassing regions where OOD samples could reside without significant reconstruction penalty.\n\nFurthermore, to address the challenge of recovering significant information from an extremely compressed latent space in a single step, \\cite{zhou202250i} proposes a novel \\textit{layerwise decomposition for incremental information recovery}. This \"data certainty decomposition\" framework factorizes the probability of an input being ID into a product of conditional probabilities, employing a series of decoders. Each decoder is specifically designed to recover information lost after *each individual encoding layer*, rather than a single decoder attempting to recover all accumulated loss from the final, most compressed latent representation. This incremental recovery mechanism enhances the autoencoder's ability to faithfully reconstruct ID samples while remaining highly sensitive to OOD deviations at various levels of abstraction.\n\nFinally, to overcome the issue of standard L2 reconstruction error being an unreliable uncertainty measure (often yielding misleadingly small errors for OOD samples due to smaller activation magnitudes), \\cite{zhou202250i} introduces the \\textit{Normalized L2 Distance (NL2)}. This novel metric normalizes the reconstruction by the input's norm, effectively eliminating the confounding influence of feature magnitude and providing a more robust and reliable measure of reconstruction accuracy. The need for more robust scoring functions for reconstruction error is also echoed in works like \\cite{guan2023dwv}, which demonstrates that even a simple regularized PCA-based reconstruction error can significantly improve OOD detection when fused with other scoring functions, highlighting that raw reconstruction error often requires refinement or combination to be effective. These collective innovations directly address the traditional flaws of reconstruction autoencoders, transforming them into more reliable OOD detectors by ensuring that reconstruction error truly reflects OODness rather than merely the model's generalization capacity.\n\nWhile these advancements, exemplified by works like \\cite{zhou202250i} and \\cite{cai2020lsi}, significantly revitalize reconstruction autoencoders for OOD detection, inherent challenges persist. The reliance on a pre-trained classifier for extracting Activation Vectors, as in \\cite{zhou202250i}, means the method's effectiveness is intrinsically tied to the quality, robustness, and potential biases of that classifier. If the feature extractor itself is not robust to certain distribution shifts, the OOD detector built upon it will inherit these limitations. Furthermore, defining what constitutes a \"maximally compressed\" latent space and ensuring its boundaries are sufficiently robust to all possible ID variations, while still being tight enough to reject all OOD, remains an intricate balance. Overly restrictive latent spaces might misclassify complex ID samples as OOD, while overly permissive ones risk the original generalization problem. The computational overhead introduced by multi-decoder architectures and complex regularization also needs consideration for real-time applications, particularly in resource-constrained environments like those discussed in \\cite{cai2020lsi}. Future research could explore adaptive mechanisms for latent space compression, investigate more sophisticated theoretical frameworks for quantifying the \"OODness\" reflected by reconstruction errors in highly complex, high-dimensional data, and develop more robust and adaptive thresholding strategies for reconstruction-based scores, potentially incorporating fusion with other OOD signals as suggested by \\cite{guan2023dwv}.",
    "Energy-Based Models for OOD Detection": "\\subsection{Energy-Based Models for OOD Detection}\n\nEnergy-Based Models (EBMs) have emerged as a theoretically principled and increasingly effective framework for Out-of-Distribution (OOD) detection, offering a direct approach to modeling the underlying data distribution. At their core, EBMs define a probability distribution over inputs $x$ using an energy function $E(x)$ as $p(x) = \\frac{\\exp(-E(x))}{Z}$, where $Z = \\int \\exp(-E(x)) dx$ is the intractable partition function \\cite{Grathwohl_etal_2019}. In this paradigm, in-distribution (ID) samples are characterized by low energy values, indicating high likelihood under the learned distribution, while OOD samples are assigned high energy values, signifying low likelihood. This direct modeling of data likelihood provides a more interpretable and robust measure of OODness compared to relying on proxy metrics like maximum softmax probabilities, which often exhibit overconfidence on OOD inputs \\cite{Liu_etal_2020}.\n\nA foundational insight into the connection between classifiers and EBMs was provided by \\textcite{Grathwohl_etal_2019}, who demonstrated that a standard classifier's output logits can be interpreted as an unnormalized negative energy function. This perspective paved the way for explicitly leveraging energy functions for OOD detection. Building on this, \\textcite{Liu_etal_2020} pioneered the use of Energy-based Models for OOD detection by defining the energy function directly from the output logits of a standard neural network classifier. Their significant contribution lay in developing specialized training objectives to explicitly learn these energy landscapes. This typically involves a contrastive learning approach, where the model is trained to push the energy of ID samples to be low while simultaneously increasing the energy of OOD samples. The challenge of the intractable partition function $Z$ is often circumvented during training by employing techniques like Stochastic Gradient Langevin Dynamics (SGLD) to sample from the model's distribution and approximate gradients, effectively optimizing the unnormalized density ratio rather than the absolute density \\cite{Liu_etal_2020, lafon2023w37}. This direct optimization for OOD discrimination offers a more theoretically grounded and robust measure than post-hoc methods.\n\nWhile many EBM approaches implicitly handle the intractable partition function through contrastive learning and sampling, \\textcite{peng20243ji} directly addresses this challenge by proposing ConjNorm, a method for tractable density estimation for post-hoc OOD detection. Their work introduces a novel theoretical framework grounded in Bregman divergence, extending density considerations to the exponential family of distributions. Crucially, ConjNorm devises an unbiased and analytically tractable estimator for the partition function using a Monte Carlo-based importance sampling technique, providing a principled way to estimate true data density without strong distributional assumptions. This represents a significant advancement by offering a direct solution to a core theoretical hurdle in EBMs.\n\nSubsequent research has explored diverse strategies to enhance EBMs for OOD detection. \\textcite{lafon2023w37} introduced HEAT (Hybrid Energy Based Model in the Feature Space), a novel post-hoc method that refines existing OOD detectors (e.g., GMMs, energy logits) by complementing them with a data-driven residual EBM. HEAT uses the EBM framework to compose several energy terms from different refined priors, allowing for accurate and robust ID density estimation without requiring external OOD samples for training. This demonstrates how EBMs can be integrated to correct biases and enhance the expressiveness of other OOD scoring functions.\n\nFurthermore, EBMs have been adapted to address specific challenges in OOD detection. \\textcite{choi202367m} proposed a \"balanced energy regularization loss\" to tackle the problem of imbalanced auxiliary OOD data, which is often overlooked in methods like Outlier Exposure. Their approach adaptively applies larger regularization to auxiliary samples from majority classes, ensuring a more effective energy landscape shaping. Similarly, in the context of Class-Incremental Learning (CIL), \\textcite{miao20246mk} introduced Bi-directional Energy Regularization (BER). BER mitigates biases in CIL models by using energy loss functions to enlarge decision boundaries for new classes (pushing OOD away) and boost confidence for old classes (preventing old ID from being misclassified as OOD), showcasing EBMs' utility in dynamic learning environments.\n\nBeyond direct energy minimization, energy functions can also guide adaptive training. \\textcite{hofmann2024gnx} introduced Hopfield Boosting, an OOD detection framework that leverages Modern Hopfield Energy (MHE) to adaptively sample \"weak learners\" from auxiliary outlier datasets that are hard to distinguish from ID data. By incorporating an MHE-based energy function into the training loss, this method explicitly sharpens the decision boundary between ID and OOD data, demonstrating a sophisticated use of energy to improve outlier exposure strategies.\n\nThe scalability of EBMs to modern deep learning architectures has also been a focus. \\textcite{Ming_etal_2023} extended the EBM framework by demonstrating how to effectively fine-tune large pre-trained models, such as vision transformers, for energy-based OOD detection. This approach leverages the rich, generalizable representations learned by these powerful models, addressing the challenge of robust OOD detection in complex, high-dimensional data settings and highlighting the adaptability of the EBM paradigm.\n\nIn summary, EBMs provide a theoretically sound framework for OOD detection by directly modeling data likelihood through an energy function. The evolution of EBMs for OOD detection has progressed from foundational insights into their connection with classifiers \\cite{Grathwohl_etal_2019} and pioneering contrastive training strategies \\cite{Liu_etal_2020}, to more sophisticated approaches that directly address the partition function intractability \\cite{peng20243ji}, integrate with and refine other OOD methods \\cite{lafon2023w37}, adapt to specific learning challenges like imbalanced OOD data or incremental learning \\cite{choi202367m, miao20246mk}, and leverage energy functions for adaptive training \\cite{hofmann2024gnx}. Their ability to integrate with large pre-trained models further underscores their potential for robust OOD detection in real-world applications \\cite{Ming_etal_2023}.\n\nFuture research in EBMs for OOD detection could explore more advanced techniques for approximating or tractably estimating the partition function in complex, high-dimensional settings, potentially drawing from advancements in score-matching or normalizing flows. Investigating adaptive energy functions that can dynamically adjust to different types of OOD shifts or domain contexts, perhaps through hypernetworks, could also yield more versatile detectors. Furthermore, exploring the interplay between EBMs and generative modeling to synthesize highly informative OOD examples for contrastive training, or to learn more expressive energy landscapes, remains a promising avenue.",
    "Outlier Exposure and Virtual Outlier Synthesis": "\\subsection{Outlier Exposure and Virtual Outlier Synthesis}\n\nThe challenge of deploying deep learning models in open-world environments necessitates robust mechanisms for identifying Out-of-Distribution (OOD) inputs. A significant advancement in this area is the Outlier Exposure (OE) paradigm, where auxiliary OOD data is incorporated during model training to explicitly teach the model to distinguish novel inputs. This approach often frames OOD detection as a binary classification task, differentiating between in-distribution (ID) and OOD data.\n\nThe theoretical underpinnings of OE suggest that many methods leveraging OOD training data are asymptotically equivalent to a binary discriminator, with practical differences often stemming from estimation procedures and the specific choice of auxiliary OOD data \\cite{bitterwolf2022rw0}. Early implementations of OE demonstrated its effectiveness, but subsequent research has focused on refining its application and addressing inherent limitations. For instance, \\cite{choi202367m} identified that auxiliary OOD data often exhibits class imbalance, proposing a balanced energy regularization loss to apply stronger regularization to majority OOD classes, thereby enhancing detection performance in diverse tasks like semantic segmentation and long-tailed classification. Addressing the vulnerability of OE to adversarial attacks, \\cite{chen2020mbk} introduced Adversarial Learning with inlier and Outlier Exposure (ALOE), which robustifies detectors by training against both adversarial in-distribution and OOD examples, significantly improving robustness against perturbations.\n\nAs OE matured, its application extended to more complex scenarios. In long-tailed recognition, where distinguishing OOD from tail classes is particularly challenging, \\cite{miao2023brn} proposed Calibrated Outlier Class Learning (COCL). This method uses debiased large margin learning and outlier-class-aware logit calibration to explicitly separate OOD samples from both head and tail ID classes, outperforming traditional OE by mitigating class-specific biases. Similarly, \\cite{wei2023f15} introduced EAT, which employs dynamic virtual labels for OOD data and context-rich tail class augmentation to improve OOD detection in long-tailed settings, demonstrating that strong inlier classification does not automatically imply good OOD detection.\n\nDespite its successes, a critical limitation of OE is the reliance on the availability and diversity of *real* auxiliary OOD data. Collecting sufficiently diverse and representative OOD datasets is often impractical or impossible, leading to a shift towards Virtual Outlier Synthesis (VOS). VOS addresses this data scarcity by generating synthetic outliers, thereby overcoming the dependence on real OOD datasets and enhancing model robustness.\n\nEarly forays into VOS, such as Mixture Outlier Exposure (MixOE) by \\cite{zhang20212tb}, generated virtual outliers by mixing ID and auxiliary data. This approach was particularly effective for fine-grained OOD detection, where novel inputs are semantically similar to ID data and require a broader coverage of the feature space. Building on the need for diversity, \\cite{jiang2023vzb} introduced Diverse Outlier Sampling (DOS), a strategy that selects diverse and informative outliers from auxiliary datasets by combining clustering on normalized features with uncertainty-based selection. This aimed to shape a globally compact decision boundary, improving upon biased greedy sampling. Further advancing this, \\cite{yao2024epq} proposed `diverseMix`, a diversity-induced mixup strategy with theoretical guarantees, which generates semantically distinct synthetic outliers through dynamic interpolation, provably enhancing the diversity of the auxiliary set.\n\nMore sophisticated VOS methods have emerged, generating synthetic outliers directly from in-distribution data or leveraging advanced generative models. \\cite{nie2024ghv} introduced Virtual Outlier Smoothing (VOSo), which constructs auxiliary OOD samples by perturbing semantic regions of ID samples in the *image space*, using Class Activation Maps (CAMs). Crucially, VOSo assigns dynamic soft labels based on the perturbation extent, creating a smoother decision boundary and more nuanced uncertainty estimation than traditional uniform OOD labels. Similarly, \\cite{yang2023pre} (MixOOD) also utilized Mixup-based strategies to generate augmented images as auxiliary OOD data, demonstrating improved distinction between ID and OOD samples. \\cite{chen20243na} explored a \"negative branch\" method with directional regularization and OOD training data, which implicitly functions as a form of virtual outlier generation to enhance anomaly detection.\n\nThe advent of large pre-trained models, particularly Vision-Language Models (VLMs), has opened new avenues for VOS. \\cite{ding20242m0} proposed Outlier Label Exposure (OLE) for zero-shot OOD detection, which generates textual outlier prototypes by clustering and refining auxiliary outlier class labels. This effectively synthesizes OOD knowledge in the language domain, enhancing VLM safety without extensive training. Complementing this, \\cite{li20245b6} introduced `NegPrompt`, a method that learns transferable negative prompts for each ID class using only ID data. These negative prompts implicitly define OOD boundaries, enabling open-vocabulary OOD detection by leveraging the VLM's semantic understanding. \\cite{miyai2023591} (GL-MCM) further explored VLM capabilities by combining global and local concept matching for zero-shot OOD, implicitly handling multi-object OOD scenarios by leveraging local features to overcome contamination of global features. \\cite{yu20249dd} developed Self-Calibrated Tuning (SCT) for VLMs, which adaptively balances ID classification and OOD regularization by leveraging ID-irrelevant local context as surrogate OOD data, addressing the issue of spurious OOD features.\n\nGenerative models, especially diffusion models, have also been harnessed for VOS. \\cite{gao2023kmk} introduced DiffGuard, a semantic mismatch-guided OOD detection method that uses pre-trained diffusion models. It synthesizes new images conditioned on an input and its predicted label, identifying OOD samples by measuring the dissimilarity between the original and synthesized images. This approach leverages the conditional generation capabilities of diffusion models to highlight semantic contradictions, overcoming scalability issues of prior generative methods.\n\nThe VOS paradigm has also extended to specialized domains and multimodal inputs. For pixel-wise OOD detection in semantic segmentation, \\cite{besnier2021jgn} (ObsNet+LAA) generates OOD-like training data via local adversarial attacks, simulating unknown objects to train an auxiliary observer network. Similarly, \\cite{liu2022fdj} (RPL) utilizes Outlier Exposure with synthetic OOD data to learn residual anomaly patterns without retraining the base segmentation model. In 3D LiDAR-based object detection, \\cite{ksel20246fe} generates synthetic OOD objects by perturbing known ID object categories, addressing data scarcity in this domain. For multimodal OOD detection, \\cite{dong2024a8k} introduced Nearest Neighbor Prototype-based Mixup (NP-Mix) as part of their Agree-to-Disagree (A2D) algorithm, generating outliers by leveraging nearest neighbor class prototypes to explore broader feature spaces. Building on this, \\cite{li2024rs5} proposed Dynamic Prototype Updating (DPU), which dynamically adjusts multimodal prediction discrepancy intensification based on a sample's similarity to its class prototype, accounting for intra-class variability in multimodal data. Finally, \\cite{hofmann2024gnx} introduced Hopfield Boosting, an OE approach that adaptively samples \"hard\" outliers using a novel energy function derived from Modern Hopfield Networks, further refining the selection of informative synthetic or real outliers.\n\nIn conclusion, Outlier Exposure has evolved from a foundational paradigm to a sophisticated framework that explicitly trains models to recognize novel inputs. The critical challenge of OOD data scarcity has driven the field towards Virtual Outlier Synthesis, which leverages advanced techniques like semantic-level interpolation, adversarial generation, and prompt-based synthesis to create diverse and effective training examples. While VOS has significantly reduced the reliance on real OOD datasets and enhanced model robustness across various modalities and tasks, ongoing challenges include ensuring the representativeness of synthetic outliers for truly unknown OOD distributions, scaling complex generation methods, and developing stronger theoretical guarantees for their generalization capabilities.",
    "Learning Robust and Separable Feature Representations": "\\subsection{Learning Robust and Separable Feature Representations}\nThe intrinsic quality and structured organization of a model's internal feature representations are paramount for effective Out-of-Distribution (OOD) detection. This subsection delves into advanced methodologies that actively engineer the deep neural network's embedding space, aiming to enhance the discriminability between in-distribution (ID) and OOD samples. These approaches collectively improve the inherent OOD robustness of the learned representations by designing a more structured and discriminative embedding space, often by enforcing explicit geometric separation, creating more compact and well-defined ID clusters, or refining feature transformations.\n\nA significant line of research leverages the intrinsic properties of deep neural networks, particularly the phenomenon of Neural Collapse (NC), to enforce explicit geometric separation between ID classes and push OOD samples away. Neural Collapse describes the convergence of features within each class to their respective class means, and these class means to a simplex equiangular tight frame (ETF) structure in the terminal phase of training. Building on this, \\cite{ammar2023pr1} introduced NECO, a post-hoc method that capitalizes on a newly observed property dubbed ID/OOD Orthogonality (NC5). This property posits that OOD data tends to become increasingly orthogonal to the principal component space spanned by ID class means. NECO exploits this by projecting features onto this ID-derived principal component space, using the projection magnitude as an OOD score. A smaller projection magnitude indicates higher OOD likelihood. Extending this concept, \\cite{wu20242p3} proposes a novel separation loss (`LSep`) that actively constrains OOD features to reside in a subspace orthogonal to the principal subspace of ID features, which is implicitly defined by the final layer's weights. This approach moves beyond merely observing orthogonality to explicitly enforcing it during training, typically by leveraging auxiliary OOD data to push their features into distinct, non-overlapping dimensions. An earlier, more general effort towards compact ID representations, \\cite{zaeemzadeh2021lmh} proposed embedding ID samples into a low-dimensional space forming a union of 1-dimensional subspaces, arguing that such a highly constrained representation inherently makes it less likely for OOD samples to occupy ID regions. While Neural Collapse-based methods offer strong theoretical underpinnings for explicit separation, their robustness to subtle, near-OOD shifts that might not perfectly align with orthogonal subspaces remains a critical area for further investigation, as these shifts might still project significantly onto the ID subspace.\n\nBeyond direct geometric enforcement, feature transformation and subspace learning techniques are employed to enhance separability, often addressing the \"curse of dimensionality\" that can plague distance-based methods in high-dimensional feature spaces. Traditional linear dimensionality reduction methods often struggle to capture the complex non-linear relationships inherent in deep features. \\cite{song2022f5d} introduced RankFeat, a post-hoc method that uses Singular Value Decomposition (SVD) to identify and remove a dominant rank-1 component from high-level features. This spectral manipulation implicitly refines the feature space by mitigating the over-confidence induced by this component in OOD samples, effectively \"flattening\" the feature manifold. Addressing the limitations of purely linear transformations, \\cite{fang2024lv2} proposes Kernel PCA (KPCA) for OOD detection, devising novel non-linear mappings like Cosine Mapping (CoP) and Cosine-Gaussian Mapping (CoRP). These mappings explicitly transform features into a space where ID and OOD data become linearly separable, overcoming the ineffectiveness of conventional PCA on raw features, a challenge also noted by \\cite{guan2023dwv} which explored regularized PCA reconstruction errors. To directly combat the curse of dimensionality, \\cite{ghosal2023q20} proposes Subspace Nearest Neighbor (SNN), which regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e., subspace) during training. This subspace learning yields more distinguishable distance measures between ID and OOD data. Similarly, \\cite{li2025jdt} introduces a data structure-aware approach using a novel \"tangent distance\" that maps high-dimensional features to the manifold of ID samples. By directly computing the Euclidean distance between samples and the nearest submanifold space (linear approximation of local regions on the manifold), it mitigates the sensitivity of distances to high dimensionality, proposing that OOD samples are relatively far from the ID manifold. The computational overhead and the challenge of selecting optimal non-linear kernels or relevant subspaces for diverse OOD scenarios represent practical considerations for these transformation-based methods.\n\nAnother significant direction involves refining ID clusters through prototype-based learning and mixture models, which aim to capture the nuanced structure of ID data more faithfully. Traditional distance-based OOD methods often oversimplify ID classes by modeling them with a single centroid, failing to capture intra-class diversity and leading to suboptimal OOD boundaries. \\cite{lu20249d4} addresses this with Prototypic Learning with a Mixture of prototypes (PALM), which models each ID class with multiple prototypes using a mixture of von Mises-Fisher (vMF) distributions in a hyperspherical embedding space. This approach creates more faithful and compact ID clusters, allowing for a more precise definition of ID boundaries by optimizing both a Maximum Likelihood Estimation (MLE) loss and a novel prototype contrastive loss. Extending this concept to multimodal settings, \\cite{li2024rs5} introduces Dynamic Prototype Updating (DPU), which dynamically adjusts multimodal prediction discrepancy intensification based on a sample's similarity to its class prototype. DPU employs Cohesive-Separate Contrastive Training (CSCT) to build a robust representation space and Pro-ratio Discrepancy Intensification (PDI) to balance intra-class cohesion with inter-class separation, thereby enhancing OOD detection in complex multimodal data. Complementing these empirical approaches, \\cite{du2024aea} provides theoretical insights into how in-distribution labels help OOD detection, particularly for \"near OOD\" scenarios. Through a graph-theoretic framework and spectral decomposition, they demonstrate that ID labels, by defining supervised connectivity, enable the learning of more discriminative ID representations that facilitate OOD-ID separation, especially when ID data is sparsely connected without labels. While prototype-based methods offer improved fidelity, the challenge of determining the optimal number of prototypes and their sensitivity to noisy ID data remains, and OOD samples falling between distinct ID prototypes can still pose detection difficulties.\n\nDespite these significant advancements in actively structuring and refining feature spaces, a persistent challenge remains in ensuring that these learned representations generalize effectively to truly novel and diverse OOD types. While methods leveraging Neural Collapse offer promising theoretical underpinnings for explicit separation, their robustness to subtle, near-OOD shifts that might not perfectly align with orthogonal subspaces requires further investigation. Similarly, prototype-based methods, while improving intra-class modeling, still face the inherent difficulty of defining boundaries for the unknown, especially when OOD data falls within the convex hull of ID prototypes. Future research could focus on adaptive feature space shaping techniques that dynamically adjust to the evolving nature of OOD data, perhaps through meta-learning or continuous adaptation mechanisms, to achieve more universally robust and discriminative representations that are less sensitive to the specific characteristics of unseen OOD data.",
    "Gradient-Based and Neuron-Level Analysis": "\\subsection{Gradient-Based and Neuron-Level Analysis}\n\nA significant shift in Out-of-Distribution (OOD) detection research involves delving into the fine-grained internal dynamics of neural networks, leveraging gradient information and individual neuron activations to extract more precise and interpretable OOD signals. This introspection moves beyond aggregate model outputs to understand *how* and *why* a model processes OOD inputs differently.\n\nOne prominent direction focuses on abnormalities in gradient-based attribution maps, which reveal how input features influence predictions. \\cite{chen2023za1} introduced GAIA (Gradient Abnormality Inspection and Aggregation), a framework that quantifies the \"abnormality\" in gradient-based attribution results, observing that OOD samples lead to \"meaningless attribution results\" with abnormal non-zero density in deeper layers. Building on gradient insights, \\cite{behpour2023x13} proposed GradOrth, which identifies OOD data by computing the norm of the gradient projection onto a low-rank subspace deemed important for in-distribution (ID) data, indicating a weak correlation with ID patterns. While these methods are post-hoc, analyzing gradients after training, \\cite{chen2020mbk} introduced ALOE (Adversarial Learning with inlier and Outlier Exposure), a training-time strategy that uses adversarial examples generated via gradients to robustify OOD detectors against small input perturbations. ALOE's objective is to promote smoother OOD score functions for ID data and clearer separation for OOD data, directly addressing the robustness aspect through gradient-informed regularization during training.\n\nAnother crucial area explores the 'coverage' of neuron activation states by in-distribution data, revealing deviations from learned patterns. \\cite{liu2023zb3} proposed Neuron Activation Coverage (NAC), a novel statistical measure that quantifies how well neuron states are \"covered\" by ID training data, serving as an uncertainty measure for OOD detection and a metric for OOD generalization. This approach provides a deeper, neuron-centric understanding of OOD phenomena. Complementing this, \\cite{zhu2022oir} introduced Batch Normalization Assisted Typical Set Estimation (BATS) with a Truncated BN (TrBN) unit, which rectifies extreme feature activations into their \"typical set\" to boost OOD detection scores, effectively managing neuron states. \\cite{xu2023767} further generalized this concept with Variational Rectified Activation (VRA), providing a theoretical derivation for an optimal activation function that not only suppresses abnormally high activations (like TrBN) but also low ones, and amplifies intermediate activations, leading to superior OOD separation. These rectification methods demonstrate a progression from heuristic to theoretically grounded manipulation of neuron activations.\n\nBeyond individual neuron states, statistical analyses of activation patterns also prove effective. \\cite{dong2021swz} developed Neural Mean Discrepancy (NMD), a metric that quantifies the difference between the average activations (neural means) of input examples and the training data across multiple layers. NMD leverages Batch Normalization's running averages for efficiency, providing a lightweight yet powerful OOD signal. More recently, \\cite{schmidt2024syr} presented SISOM (Simultaneous Informative Sampling and Outlier Mining), a unified approach for active learning and OOD detection that enriches feature representations by weighting neurons based on their gradient contribution to the KL divergence between a uniform distribution and the model's softmax output. This method effectively combines gradient-based saliency with neuron activation analysis to identify unexplored regions and decision boundaries, showcasing a sophisticated integration of these fine-grained internal dynamics.\n\nThe collective efforts in this subsection highlight a growing trend towards deeper introspection into model internals. By analyzing gradient-based attribution maps, the coverage of neuron activation states, and employing gradient regularization during training, researchers are developing more precise, interpretable, and robust OOD detection methods. However, challenges remain in establishing universal patterns for gradient abnormalities or neuron coverage across diverse architectures and OOD types, and in balancing the computational cost of such fine-grained analysis with real-time deployment needs.",
    "Multimodal and Graph-Structured OOD Detection": "\\subsection{Multimodal and Graph-Structured OOD Detection}\nThe landscape of Out-of-Distribution (OOD) detection is rapidly expanding beyond traditional unimodal image data to encompass the complexity of real-world multimodal and graph-structured information. This crucial extension addresses the inherent multimodal nature of many applications and the unique challenges posed by non-Euclidean data.\n\nFor graph-structured data, OOD detection presents distinct challenges due to its non-Euclidean nature and the high cost of labeling. Pioneering efforts have focused on unsupervised graph-level OOD. \\cite{liu202227x} introduced GOOD-D, a novel framework for unsupervised graph-level OOD detection that learns robust in-distribution (ID) patterns through perturbation-free data augmentation and hierarchical graph contrastive learning across node, graph, and group levels. This approach was critical in formalizing the problem and providing a multi-granularity understanding of graph ID data. Building on the need for OOD exposure in graphs, \\cite{wang2025xwm} proposed GOLD, which addresses the scarcity of auxiliary OOD data by implicitly generating pseudo-OOD samples through an adversarial latent generation framework, achieving superior performance without real OOD samples. Addressing practical deployment constraints, \\cite{wang2024es5} introduced GOODAT, a test-time graph OOD detection method that operates without access to training data or requiring GNN architecture modifications, leveraging a graph masker and the Graph Information Bottleneck (GIB) principle for unsupervised OOD identification. To provide a unified evaluation framework for this nascent field, \\cite{wang2024q01} presented UB-GOLD, a comprehensive benchmark that unifies unsupervised graph-level anomaly detection and OOD detection across 35 datasets and four distinct scenarios, enabling systematic comparison and analysis of diverse graph OOD methods.\n\nThe detection of OOD samples in multimodal settings is gaining traction as real-world data often comprises complementary information from diverse sources like vision, audio, and text. \\cite{dong2024a8k} made a significant contribution by introducing MultiOOD, the first dedicated benchmark for multimodal OOD detection, alongside the Agree-to-Disagree (A2D) algorithm. A2D leverages the \"modality prediction discrepancy\" phenomenon, where softmax predictions across modalities show negligible differences for ID data but significant variability for OOD data, to enhance detection. Extending this concept, \\cite{li2024rs5} proposed Dynamic Prototype Updating (DPU), a plug-and-play framework that addresses the limitation of uniform discrepancy amplification by dynamically adjusting intensification based on a sample's similarity to its class prototype, thereby balancing intra-class cohesion with inter-class separation.\n\nVision-Language Models (VLMs) have emerged as a powerful paradigm for multimodal OOD detection, particularly in zero-shot and open-vocabulary settings. \\cite{miyai2023591} introduced GL-MCM, which enhances zero-shot OOD detection by combining CLIP's global and local features, offering flexibility in defining ID images in complex, multi-object scenes. Further refining VLM-based approaches, \\cite{li20245b6} developed NegPrompt, a method that learns transferable \"negative prompts\" using only ID training data to delineate OOD boundaries, enabling open-vocabulary OOD detection without explicit OOD examples. Addressing the challenge of spurious OOD features that can arise from imperfect foreground-background decomposition in VLMs, \\cite{yu20249dd} proposed Self-Calibrated Tuning (SCT), an adaptive framework that dynamically balances ID classification and OOD regularization based on prediction uncertainty. Beyond VLMs, Large Language Models (LLMs) are being explored for their world knowledge. \\cite{dai2023mhn} leveraged LLMs for multi-modal OOD detection by generating descriptive features for ID classes, crucially developing a consistency-based uncertainty calibration method to mitigate LLM hallucinations and prevent performance degradation. This integration of LLMs with VLMs for OOD detection is further contextualized by \\cite{miyai20247ro}, which provides a comprehensive survey of OOD detection in the VLM/LVLM era, highlighting the integration of related fields and identifying the most demanding challenges.\n\nThe expansion of OOD detection to multimodal and graph-structured data marks a significant step towards more holistic and context-rich detection capabilities. While promising advancements have been made in developing new benchmarks and algorithms that exploit inter-modal discrepancies and address the unique challenges of non-Euclidean data, several unresolved issues remain. These include the scalability of multimodal OOD methods to a wider array of modalities beyond vision-language, the robustness of graph OOD detectors to diverse and subtle structural shifts, and the development of theoretically grounded adaptive algorithms that can seamlessly handle the inherent noise and heterogeneity in real-world multimodal and graph data.",
    "OOD in Specialized Learning Settings": "\\subsection{OOD in Specialized Learning Settings}\n\nOut-of-distribution (OOD) detection becomes particularly challenging in specialized learning paradigms where inherent data characteristics complicate the distinction between in-distribution (ID) and novel samples. This subsection delves into OOD detection within long-tailed recognition and class-incremental learning, highlighting the unique complexities and tailored solutions developed to ensure OOD robustness in these realistic scenarios.\n\nIn \\textbf{long-tailed recognition (LTR)}, the severe class imbalance creates a pervasive confusion between tail-class ID samples and true OODs. Models often exhibit overconfidence on dominant head classes, leading to OOD samples being misclassified into these categories, while simultaneously treating sparse tail-class instances as anomalies \\cite{miao2023brn, wei2023f15, shin2024lnf}. Addressing this requires strategies that either modify the learning objective, augment data, or engineer the representation space to explicitly disentangle tail-class ID from OOD.\n\nOne prominent approach involves modifying the learning objective or expanding the label space. \\cite{miao2023brn} introduced Calibrated Outlier Class Learning (COCL), which extends the label space with an explicit outlier class. COCL employs a debiased large margin learning strategy, incorporating OOD-aware tail class prototype learning to prevent tail samples from being mistaken for OOD, and debiased head class learning to mitigate the dominant influence of head classes on OOD samples. This direct manipulation of the decision boundary in the logit space offers a targeted solution to the class imbalance problem. Complementing this, \\cite{choi202367m} recognized that even auxiliary OOD data used in outlier exposure can exhibit class imbalance. They developed a balanced energy regularization loss that adaptively applies stronger regularization to auxiliary samples from majority classes, ensuring a more effective learning of OOD boundaries in long-tailed and semantic segmentation tasks.\n\nAnother crucial strategy focuses on data augmentation and dynamic outlier adaptation. \\cite{wei2023f15} proposed EAT, a framework that utilizes dynamic virtual labels for OOD data and context-rich tail class augmentation. By overlaying tail-class images onto OOD backgrounds, EAT encourages the model to focus on discriminative foreground features, improving both tail-class generalization and OOD distinction. This data-centric approach contrasts with COCL's loss modifications by enriching the training data itself. Further advancements in dynamic outlier adaptation include \\cite{nie2024ghv}'s Virtual Outlier Smoothing (VOSo), which constructs virtual outliers by perturbing semantic regions of ID samples in the image space and assigns them dynamic soft labels. This creates a smoother decision boundary, preventing tail classes from being abruptly classified as OOD. To enhance the diversity of auxiliary OOD data, \\cite{yao2024epq} theoretically demonstrated that increased diversity improves OOD generalization and proposed `diverseMix`, a semantic-level interpolation strategy with dynamic adjustment. Similarly, \\cite{jiang2023vzb} introduced Diverse Outlier Sampling (DOS), which selects diverse and informative outliers from auxiliary datasets by clustering normalized latent representations. These dynamic sampling and generation techniques, along with adaptive weighting strategies like Hopfield Boosting \\cite{hofmann2024gnx} that prioritize \"hard\" outliers, collectively contribute to refining the decision boundary in long-tailed settings, ensuring that tail classes are not erroneously flagged as OOD while true anomalies are detected.\n\nBeyond explicit outlier exposure and loss modifications, engineering the representation space is critical. \\cite{shin2024lnf} introduced \\textbf{Representation Norm Amplification (RNA)}, a novel training method that directly addresses the trade-off between LTR classification accuracy and OOD detection performance. RNA decouples ID classification and OOD detection by leveraging the norm of the representation vector as a dedicated dimension for OOD scoring. It achieves this by training the classifier to minimize classification loss only for ID samples, while simultaneously regularizing to enlarge the norm of ID representations. Crucially, auxiliary OOD samples are used to regularize Batch Normalization (BN) layers, indirectly reducing OOD representation norms and creating a discernible difference in activation ratios and representation norms. This allows for simultaneous high performance in both tasks, overcoming limitations of previous methods. Similarly, \\cite{lu20249d4} proposed Prototypic ALearning with a Mixture of prototypes (PALM), which models each ID class with multiple prototypes using a mixture of von Mises-Fisher distributions. While not exclusively for long-tailed settings, this approach is highly beneficial for capturing the inherent intra-class diversity within sparse tail classes, leading to more faithful embeddings and improved ID-OOD separability. \\cite{zhang202312h} introduced Multi-scale OOD DEtection (MODE), leveraging both global and local representations with an attention-based local propagation mechanism. This multi-scale approach can help distinguish fine-grained tail-class features from OOD noise, especially when global features are ambiguous due to background clutter.\n\nIn \\textbf{class-incremental learning (CIL)}, where models continuously learn new classes over time, maintaining robust OOD performance is a significant hurdle due to catastrophic forgetting of previously learned classes. The challenge lies in adapting to new ID classes without degrading the OOD detection capability for both old and new data distributions. This area has historically been underexplored, but recent work has begun to provide dedicated solutions and benchmarks.\n\n\\cite{miao20246mk} introduced OpenCIL, the first comprehensive benchmark for OOD detection in CIL, highlighting that CIL models exhibit increasing biases towards OOD samples and newly added classes with more incremental steps, leading to decreased OOD detection performance. OpenCIL proposes two frameworks for integrating OOD detection into CIL: post-hoc methods (applying OOD scores on CIL model features) and fine-tuning-based methods (training an additional OOD classifier while freezing the CIL backbone). To mitigate the identified biases, \\cite{miao20246mk} further proposed Bi-directional Energy Regularization (BER). BER addresses two key issues: New Task Energy Regularization (NTER) prevents OOD samples from being over-confidently classified into new classes by synthesizing pseudo-OOD samples and enlarging decision margins. Old Task Energy Regularization (OTER) prevents old ID samples from being misclassified as OOD (due to catastrophic forgetting) by boosting prediction confidence for old classes using augmented memory samples. BER provides a targeted solution to the unique challenges of OOD in CIL by explicitly addressing the dynamic nature of the ID distribution.\n\nAnother promising direction is the integration of uncertainty quantification methods. \\cite{aguilar2023ms5} proposed Continual Evidential Deep Learning (CEDL), which integrates Evidential Deep Learning (EDL) into a continual learning framework to simultaneously perform incremental object classification and OOD detection. CEDL combines exemplar rehearsal and knowledge distillation with a novel loss function that includes evidential cross-entropy, KL-divergence regularization for new classes, and knowledge distillation. Their findings indicate that evidential vacuity is a good indicator for OOD detection in CIL, while dissonance struggles to distinguish old ID from OOD. This work offers a principled way to estimate and leverage uncertainty for OOD detection in evolving CIL environments.\n\nBeyond these dedicated CIL-OOD methods, several general OOD concepts offer indirect but promising contributions. Techniques that enhance training stability and prevent overconfidence are crucial in CIL. \\cite{cheng20233yi}'s Average of Pruning (AoP), which combines model averaging and network pruning, could help mitigate OOD detection instability and overfitting during continuous learning. Similarly, \\cite{chen2024kl7}'s Optimal Parameter and Neuron Pruning (OPNP), a training-free method, could reduce overconfidence in CIL models without requiring additional training data, thus improving OOD discrimination. Leveraging generic pre-trained representations, as explored by GROOD \\cite{vojr2023ee1}, might offer a more stable foundation for OOD detection in CIL, as these representations are less susceptible to task-specific catastrophic forgetting compared to features learned from scratch. The dynamic prototype updating mechanism in \\cite{li2024rs5}'s DPU, though developed for multimodal OOD, conceptually aligns with the need to dynamically refine class representations in CIL to maintain stable boundaries for OOD detection.\n\nIn conclusion, specialized learning settings like long-tailed recognition have seen significant progress through tailored solutions that address the nuanced interactions between ID and OOD data, often leveraging dynamic outlier adaptation, sophisticated representation learning, and explicit norm amplification. Crucially, the field of OOD detection in class-incremental learning is rapidly maturing, moving from an underexplored area to one with dedicated benchmarks and methods like OpenCIL and BER, and principled uncertainty-aware approaches like CEDL. Future research needs to further integrate these insights, developing dynamic and adaptive OOD detection frameworks that can explicitly handle evolving ID distributions and catastrophic forgetting, ensuring robust OOD performance in truly open-ended, lifelong learning scenarios.",
    "Leveraging Pre-trained Foundation Models": "\\subsection{Leveraging Pre-trained Foundation Models}\nThe emergence of large pre-trained foundation models, such as Vision-Language Models (VLMs) like CLIP \\cite{radford2021learning} and Large Language Models (LLMs), has profoundly transformed the landscape of Out-of-Distribution (OOD) detection. These models, with their rich semantic understanding, vast world knowledge, and open-vocabulary capabilities, enable novel zero-shot and open-set OOD detection paradigms, moving towards more adaptable and versatile OOD systems.\n\nThe \"Vision Language Model Era\" marks a significant paradigm shift in OOD detection, as highlighted by \\cite{miyai20247ro}. Early integration of VLMs for OOD detection focused on leveraging their inherent zero-shot capabilities. For instance, \\cite{miyai2023591} introduced GL-MCM, extending CLIP's Maximum Concept Matching by utilizing both global and local visual-text alignments. This approach provides flexibility in defining in-distribution (ID) images in multi-object scenes, addressing the limitation of methods that assume single, centered objects. Building upon this, \\cite{ding20242m0} proposed Outlier Label Exposure (OLE), a method that explicitly incorporates OOD knowledge by using a large set of diverse auxiliary outlier class labels as pseudo OOD text prompts for VLMs. OLE learns refined \"outlier prototypes\" and generates \"hard outlier prototypes\" to calibrate decision boundaries, overcoming the limitations of purely ID-label-based zero-shot methods that lack explicit OOD knowledge. Further advancing this direction, \\cite{li20245b6} introduced NegPrompt, a prompt learning-based approach that learns transferable \"negative prompts\" for each ID class using *only* ID training data. These negative prompts implicitly define OOD boundaries by representing characteristics contrary to ID classes, enabling open-vocabulary OOD detection without the need for any external outlier data or additional encoders, which is a significant step towards data-efficient and generalizable OOD systems.\n\nBeyond VLMs, Large Language Models (LLMs) are increasingly leveraged for their extensive world knowledge to generate synthetic OOD exposure. \\cite{dai2023mhn} explored using LLMs to generate descriptive features for ID classes to enhance multimodal OOD detection. Crucially, they identified and addressed the LLM \"hallucination\" problem by proposing a novel consistency-based uncertainty calibration method. This method selectively integrates reliable LLM knowledge, preventing performance degradation caused by unfaithful LLM generations. Taking this concept further, \\cite{cao20246gj} introduced Envisioning Outlier Exposure (EOE), which directly uses LLMs to *envision* and generate potential outlier class labels based on visual similarity to ID classes. EOE designs task-specific LLM prompts for far, near, and fine-grained OOD scenarios, effectively creating synthetic OOD labels without access to any real OOD data, thereby providing a powerful form of \"outlier exposure\" to VLMs.\n\nThe integration of foundation models also necessitates refining their behavior for OOD detection. \\cite{yu20249dd} proposed Self-Calibrated Tuning (SCT) for VLMs, a novel framework designed to mitigate the issue of \"spurious OOD features\" that arise from VLMs' imperfect foreground-background decomposition. SCT adaptively adjusts the balance between ID classification and OOD regularization based on prediction uncertainty, making VLM-based OOD detection more robust to internal model limitations. In a broader context, the field is also expanding to multimodal OOD detection, where foundation models can play a crucial role. \\cite{dong2024a8k} introduced the MultiOOD benchmark and the Agree-to-Disagree (A2D) algorithm, which leverages \"modality prediction discrepancy\" for OOD detection across multiple modalities. While not exclusively VLM/LLM-focused, this work highlights the growing need for robust multimodal OOD, a domain where foundation models are inherently well-suited to integrate and leverage diverse information streams. Finally, the increasing adoption of foundation models for OOD detection has led to dedicated benchmarks, such as the one presented by \\cite{borlino20245ku}, which aims to properly assess the performance of these large pre-trained models in realistic yet harder OOD tasks, confirming their benefits and guiding future research into their fine-tuning strategies.\n\nIn conclusion, the advent of pre-trained foundation models has opened a new frontier in OOD detection, moving beyond traditional methods that often rely on explicit OOD data or complex architectural modifications. These models' inherent semantic understanding and vast knowledge enable sophisticated zero-shot and open-vocabulary OOD paradigms through techniques like learning transferable negative prompts, leveraging LLMs for envisioned outlier exposure, and self-calibrated tuning of VLMs. However, challenges remain in ensuring the robustness of LLM-generated information, fully integrating multimodal cues, and developing comprehensive benchmarks that capture the full spectrum of OOD scenarios for these powerful, general-purpose models.",
    "OOD in Medical Imaging and Healthcare": "\\subsection*{OOD in Medical Imaging and Healthcare}\n\nThe deployment of artificial intelligence (AI) in medical imaging and healthcare necessitates robust out-of-distribution (OOD) detection capabilities, as misinterpreting novel or anomalous inputs can have severe, life-threatening consequences for patient well-being. AI-powered clinical decision support systems, used for tasks like disease diagnosis and anomaly detection in medical scans, must reliably identify when an input falls outside their training distribution to prevent erroneous predictions. This domain presents unique challenges, including the high dimensionality of medical images, inherent class imbalance in rare disease detection, and the stringent requirement for robust performance on subtle OOD shifts that might indicate critical pathologies.\n\nTo address the foundational understanding of OOD in this high-stakes field, \\textcite{hong2024xls} provide a comprehensive survey, establishing a critical taxonomy for distributional shifts in medical imaging. They delineate seven key factors causing OOD shifts and categorize them into semantic, covariate, and contextual shifts, clarifying the complex landscape and inconsistent terminology that hinders systematic research. Empirically validating the limitations of current approaches, \\textcite{vasiliuk20233w9} expose the severe shortcomings of state-of-the-art OOD detection methods when applied to 3D medical image segmentation. Their work introduces a novel, publicly available benchmark that simulates diverse clinical OOD scenarios and, notably, demonstrates that a simple Intensity Histogram Features (IHF) baseline often outperforms complex deep learning methods, underscoring the profound challenges posed by 3D medical data and the need for more tailored solutions.\n\nEarly efforts to adapt general OOD detection techniques to medical imaging revealed significant performance discrepancies. \\textcite{berger20214a3} conducted a comparative study of confidence-based OOD methods on chest X-rays, finding that methods performing well on standard computer vision benchmarks often failed in the medical context. Their analysis highlighted ODIN as a robust method due to its input perturbation mechanism, while Mahalanobis distance, a strong performer in general vision, proved ineffective in medical imaging due to less separable feature spaces. Directly addressing this limitation, \\textcite{anthony2023slf} critically re-evaluated the use of Mahalanobis distance for OOD detection in medical imaging. Through a detailed layer-wise analysis, they demonstrated that the optimal detection layer is highly dependent on the specific OOD pattern, challenging previous assumptions. They then proposed Multi-branch Mahalanobis (MBM), a novel framework that significantly enhances OOD detection by employing multiple depth-specific detectors, showcasing a tailored solution that improves reliability for identifying unexpected anomalies like pacemakers or subtle demographic shifts.\n\nBeyond adapting existing discriminative methods, novel generative approaches have emerged to tackle the high dimensionality and complexity of 3D medical data. \\textcite{graham20232re} introduced an unsupervised 3D OOD detection method leveraging Latent Diffusion Models (LDMs). This innovative approach overcomes the memory and resolution limitations of prior generative models, enabling the generation of high-resolution spatial anomaly maps. Such capabilities are crucial for tasks like identifying unexpected tumors, lesions, or other pathologies in volumetric scans, where precise localization is paramount for clinical utility and ensuring the overall reliability of AI-powered diagnostic systems.\n\nDespite these advancements, several challenges persist. The generalizability of OOD methods across the vast spectrum of medical imaging modalities, anatomical regions, and diverse OOD types remains an open problem. There is a continuous need for more comprehensive and clinically relevant benchmarks that capture the subtlety and variability of real-world OOD shifts. Furthermore, integrating these detection mechanisms seamlessly into clinical workflows, coupled with robust explainability and uncertainty quantification, is essential for fostering trust and enabling the safe and effective deployment of AI in patient care.",
    "OOD for Autonomous Systems and Cyber-Physical Systems": "\\subsection{OOD for Autonomous Systems and Cyber-Physical Systems}\n\nThe safe and reliable deployment of autonomous systems, encompassing self-driving vehicles, robotics, and industrial cyber-physical systems (CPS), critically depends on their ability to detect and appropriately react to Out-of-Distribution (OOD) events. In these dynamic, open-world environments, encountering unforeseen objects, sensor malfunctions, or adversarial attacks can lead to catastrophic failures if not promptly identified. This subsection delves into the specialized advancements in OOD detection that address the stringent requirements of real-time performance, robust multimodal sensor fusion, and the nuanced handling of diverse OOD events in such safety-critical applications.\n\nEnsuring the trustworthiness of learning-enabled components in CPS necessitates OOD detection with strong statistical guarantees and real-time capabilities. Early work by \\cite{cai2020lsi} addressed this by integrating Variational Autoencoders (VAEs) and Deep Support Vector Data Description (SVDD) within an Inductive Conformal Anomaly Detection (ICAD) framework, providing well-calibrated false alarm rates for high-dimensional sensor inputs. Building on such foundational guarantees, \\cite{kaur2022cty} introduced iDECODe, which leverages in-distribution equivariance for conformal OOD detection, offering bounded false detection rates. Extending this to dynamic environments, \\cite{kaur20248t3} proposed CODiT for OOD detection in time-series (dependent) data within CPS, utilizing temporal equivariance and Fisher's method for robust, guaranteed false alarm rates. A crucial practical concern in safety-critical systems is managing false positives; \\cite{vishwakarma2024z1m} tackled this with a human-in-the-loop framework that adaptively updates OOD detection thresholds using expert feedback and provides theoretical guarantees on false positive rates, even under distribution shifts. Beyond mere statistical detection, \\cite{guerin202201y} argued that traditional OOD detection is insufficient for safety-critical contexts, advocating for Out-of-Model-Scope (OMS) detection, which focuses on identifying inputs that lead to actual model errors, thereby providing a more direct measure of safety. Robustness against malicious inputs is also paramount; \\cite{chen2020mbk} introduced ALOE (Adversarial Learning with inlier and Outlier Exposure), a training-time strategy that robustifies OOD detectors against both adversarial in-distribution and OOD examples, a critical defense against cyber-attacks in CPS. For continually evolving autonomous systems, \\cite{aguilar2023ms5} proposed Continual Evidential Deep Learning (CEDL), enabling simultaneous incremental learning of new classes and OOD detection, crucial for systems operating in open-ended environments.\n\nA significant challenge in autonomous systems is the effective integration of heterogeneous sensor data, such as LiDAR, camera, and radar, for robust OOD detection. Traditional unimodal OOD methods often fail to leverage the complementary information across modalities, which is vital for distinguishing subtle OOD events from sensor noise or adverse environmental conditions. Addressing this, \\cite{dong2024a8k} introduced MultiOOD, the first dedicated benchmark for multimodal OOD detection, alongside the \"Agree-to-Disagree\" (A2D) algorithm and \"Nearest Neighbor Prototype-based Mixup\" (NP-Mix) for outlier synthesis. Their work demonstrated that leveraging modality prediction discrepancies significantly enhances OOD performance, providing a foundational step for multimodal OOD, although primarily evaluated on video-based action recognition. Directly targeting autonomous driving, \\cite{liu2025m5u} proposed \"Feature Mixing,\" an extremely simple and fast multimodal outlier synthesis method for OOD detection and segmentation, specifically for image and point cloud data. This method, which randomly swaps feature dimensions between modalities, achieves state-of-the-art performance with significant speedups over prior methods like NP-Mix, making it highly practical for real-time applications. They also introduced CARLA-OOD, a challenging synthetic multimodal dataset for OOD segmentation in driving scenarios. Further specializing in 3D perception, \\cite{ksel20246fe} revisited OOD detection in LiDAR-based 3D object detection, proposing a lightweight post-hoc method that integrates features from the backbone, bounding box parameters, and output logits of a fixed 3D object detector. Crucially, they introduced a novel synthetic OOD generation strategy by perturbing known ID objects and established a new nuScenes OOD benchmark, providing a more realistic evaluation protocol for unknown foreground objects in autonomous driving. For multimodal intent understanding, \\cite{zhang2024cx0} proposed MIntOOD, integrating weighted feature fusion with multi-granularity representation learning for both classification and OOD detection, highlighting the need for context-aware OOD in complex autonomous tasks.\n\nThe advent of large pre-trained foundation models, particularly Vision-Language Models (VLMs), offers new avenues for open-world OOD detection in autonomous systems by leveraging their vast semantic understanding. \\cite{mao20244lp} explored language-enhanced latent representations for OOD detection in autonomous driving, using the cosine similarity of image and text representations encoded by CLIP. This approach improves the transparency and controllability of latent encodings, demonstrating superior performance on realistic driving data compared to traditional vision encoder representations. Similarly, \\cite{chen2024f28}'s TagFog, while a general visual OOD method, is motivated by applications like autonomous driving and uses textual anchor guidance from large language models (e.g., ChatGPT) and jigsaw-based fake outlier generation to train robust visual encoders. This allows for learning more compact ID representations and leaving spare regions for OOD data in the feature space, enhancing open-vocabulary OOD capabilities. The broader landscape of OOD detection in the VLM era, as surveyed by \\cite{miyai20247ro}, underscores the transformative potential of these models for detecting novel, semantically rich OOD events that traditional methods might miss.\n\nIn conclusion, OOD detection is an indispensable enabler for safe and robust autonomous operation. Significant progress has been made in developing methods that offer statistical guarantees, enhance robustness against adversarial attacks, and, critically, leverage multimodal sensor fusion for a more comprehensive understanding of the operational environment. The emergence of VLM-based approaches further promises to extend OOD capabilities to truly open-world, semantically rich unknown scenarios. However, challenges persist in developing unified theoretical frameworks that seamlessly integrate OOD detection with the broader concept of Out-of-Model-Scope, especially in highly dynamic, multimodal, and continually learning systems. Future directions should focus on scaling these guarantees to highly complex, distributed CPS, further integrating human feedback for adaptive learning, and establishing comprehensive benchmarks that reflect the full spectrum of OOD events and temporal dependencies in real-world autonomous environments, including adverse weather conditions and sensor degradation.",
    "OOD in Cybersecurity and Anomaly Detection": "\\subsection{OOD in Cybersecurity and Anomaly Detection}\nOut-of-distribution (OOD) detection is a cornerstone of modern cybersecurity and anomaly detection, providing a critical defense against the dynamic and adversarial nature of digital threats. In these high-stakes environments, OOD samples frequently represent malicious activities, ranging from sophisticated network intrusions and advanced persistent threats to novel malware and fraudulent financial transactions. The ability to promptly and accurately identify these deviations from established normal patterns is paramount for safeguarding critical infrastructure, sensitive data, and financial systems. This subsection synthesizes how OOD detection methods are specifically adapted and applied to diverse data streams, including network traffic, system logs, user behavior, and graph-structured data, highlighting their utility in protecting against unpredictable and evolving threats.\n\nA primary challenge in cybersecurity is the real-time detection of novel network intrusions and traffic anomalies amidst high-volume data streams. Early OOD methods focused on efficiency and feature-space analysis to meet these demands. For instance, Neural Mean Discrepancy (NMD) \\cite{dong2021swz} offers an efficient post-hoc technique for detecting OOD samples by measuring deviations in deep neural network activation means, making it suitable for rapid monitoring of network traffic. Similarly, FeatureNorm and NormRatio \\cite{yu2022egq} identify optimal intermediate layers where in-distribution (ID) and OOD data exhibit maximal feature norm separation, providing a robust signal for unusual traffic patterns without requiring explicit OOD training samples. Addressing the need for rapid identification of new types of malicious traffic with limited labeled data, SPN \\cite{miao2023zf5} proposes a few-shot learning approach based on a Siamese Prototypical Network, incorporating margin loss to ensure OOD detection capabilities for unknown traffic types. In specialized network contexts, such as Controller Area Network (CAN) bus intrusion detection, a cascaded two-stage classification architecture leveraging an Auxiliary Classifier Generative Adversarial Network (ACGAN) effectively distinguishes known attacks from normal traffic while detecting unknown attack classes as OOD \\cite{zhao20221ag}, demonstrating architectural adaptations for resource-constrained environments.\n\nFor malware analysis and system log anomaly detection, the focus shifts to distinguishing subtle, potentially polymorphic threats from benign system variations, often under conditions of data scarcity. Methods that refine internal representations are crucial here. RankFeat \\cite{song2022f5d} enhances OOD detection by removing dominant rank-1 feature components that might obscure subtle OOD signals, proving effective for identifying novel threats in complex datasets like malware binaries. To mitigate ambiguity caused by atypical ID samples, Batch Normalization Assisted Typical Set Estimation (BATS) \\cite{zhu2022oir} rectifies extreme features to form a \"typical set,\" which is vital for distinguishing subtle malicious anomalies in system logs from benign, yet unusual, system variations. Furthermore, MOODv2 \\cite{li2024n34} enhances ID representation learning through Masked Image Modeling (MIM), yielding more robust and distinct ID features critical for distinguishing subtle malware variants or sophisticated intrusion attempts. In unsupervised settings, where labeled anomalies are rare, Density of States Estimation (DoSE) \\cite{morningstar2020re9} leverages multiple summary statistics from generative models to identify atypical samples, overcoming the common challenge of generative models assigning high likelihoods to OOD data, a critical consideration for unsupervised anomaly detection in logs or network flows. Beyond feature-level analysis, neuron-centric approaches like Neuron Activation Coverage (NAC) \\cite{liu2023zb3} quantify the \"coverage degree\" of neuron states to detect OOD, proving useful for identifying deviations in learned patterns of user behavior or system states that could indicate a compromise or insider threat.\n\nThe inherently adversarial nature of cybersecurity necessitates OOD detection methods that are robust to manipulation. Attackers actively seek to bypass detectors by crafting adversarial examples that appear in-distribution. To counter this, Adversarial Learning with inlier and Outlier Exposure (ALOE) \\cite{chen2020mbk} trains models against both adversarial ID and OOD examples, significantly improving robustness against malicious perturbations designed to evade detection. Building on this, Adversarially Robust OOD Detection Using Lyapunov-Stabilized Embeddings (AROS) \\cite{mirzaei2024dad} leverages Neural Ordinary Differential Equations (NODEs) and Lyapunov stability to achieve robust embeddings. AROS notably generates \"fake OOD embeddings\" from low-likelihood regions of the ID feature space, eliminating the need for auxiliary OOD datasets and enhancing robustness against strong adversarial attacks. Gradient-based methods also contribute to robustness; GradOrth \\cite{behpour2023x13} identifies OOD samples by projecting gradients onto low-rank subspaces of ID data, offering a nuanced way to detect deviations in model processing. Similarly, GAIA \\cite{chen2023za1} detects \"abnormality\" in gradient-based attribution results, providing interpretability for security analysts investigating suspicious activities. Furthermore, the concept of tangent distance \\cite{li2025jdt} addresses the \"curse of dimensionality\" in high-dimensional feature spaces, offering a data structure-aware approach to quantify OOD uncertainty by measuring distance to the nearest submanifold space, which is crucial for robust OOD detection against subtle perturbations.\n\nFor graph-structured data, prevalent in network topology, social networks, and financial transaction graphs, OOD detection faces unique challenges due to non-Euclidean data structures and complex relationships. GOOD-D \\cite{liu202227x} pioneers unsupervised graph-level OOD detection using perturbation-free hierarchical contrastive learning. Addressing the scarcity of OOD data for graphs, GOLD \\cite{wang2025xwm} implicitly generates adversarial latent samples to enhance detection without auxiliary OOD datasets. GOODAT \\cite{wang2024es5} offers a test-time, plug-and-play graph OOD detection method that leverages a graph masker guided by the Information Bottleneck principle, providing an efficient solution for monitoring network intrusions. The growing importance of this domain is underscored by comprehensive surveys like \\cite{cai2025ez2} and unified benchmarks such as UB-GOLD \\cite{wang2024q01}, which allows for rigorous comparison of unsupervised graph-level anomaly and OOD detection methods across various threat scenarios. For node-level OOD detection in graph neural networks, NODESAFE \\cite{yang2025z62} optimizes energy scores to reduce extreme values and mitigate logit shifts, significantly improving detection accuracy against structural manipulations.\n\nThe rise of Large Language Models (LLMs) and multimodal data streams has opened new avenues for detecting sophisticated threats like phishing and social engineering. A survey by \\cite{xu2024ufg} systematically reviews how LLMs are utilized for anomaly and OOD detection across various data modalities, including text. For multi-modal OOD detection, \\cite{dai2023mhn} leverages LLMs' world knowledge to generate descriptive features while calibrating for hallucination, enhancing the detection of complex, multi-modal threats. Envisioning Outlier Exposure (EOE) \\cite{cao20246gj} utilizes LLMs to generate synthetic outlier class labels, providing \"envisioned outlier exposure\" to improve zero-shot OOD detection without real OOD data, which is crucial for identifying novel attack patterns or zero-day exploits. Furthermore, MIntOOD \\cite{zhang2024cx0} proposes a multimodal intent understanding system that simultaneously achieves classification and OOD detection by fusing text, video, and audio, vital for detecting anomalous user behavior or sophisticated social engineering attacks.\n\nIn safety-critical Cyber-Physical Systems (CPS), OOD detection demands strong theoretical guarantees and real-time applicability. Inductive Conformal Anomaly Detection (ICAD) \\cite{cai2020lsi}, using learned nonconformity measures, provides statistically sound false alarm rate guarantees for real-time OOD detection in CPS, crucial for applications like autonomous vehicles and industrial control systems. Building on this, iDECODe \\cite{kaur2022cty} introduces a novel non-conformity measure based on in-distribution equivariance, further strengthening conformal OOD detection with bounded false detection rates. Extending these guarantees to temporal data, CODiT \\cite{kaur20248t3} provides OOD detection with conformal guarantees for time-series data in CPS, directly applicable to monitoring network traffic and system logs for evolving threats. To address the practical issue of high false positive rates in dynamic environments, a human-in-the-loop framework \\cite{vishwakarma2024z1m} adaptively updates OOD detection thresholds with theoretical guarantees on false positive rate control, ensuring trustworthy deployment. Furthermore, understanding the fundamental objectives of OOD methods, as explored by \\cite{bitterwolf2022rw0}, helps in designing more principled and effective security detectors. The Model-Specific OOD framework \\cite{averly20239rv} offers a unified perspective on OOD detection based on a deployed model's actual misclassification behavior, which is highly relevant for understanding what a security system *actually* fails on in a real-world context. Finally, Continual Evidential Deep Learning (CEDL) \\cite{aguilar2023ms5} integrates evidential deep learning into a continual learning framework to simultaneously perform incremental classification and OOD detection, a critical capability for systems facing evolving threats without catastrophic forgetting.\n\nIn conclusion, OOD detection is an indispensable and rapidly evolving field within cybersecurity and anomaly detection. It has progressed from basic statistical deviation measures to sophisticated, robust, and context-aware methodologies capable of addressing diverse data types and adversarial environments. While significant advancements have been made in developing methods for various data modalities, enhancing robustness against adversarial threats, and providing theoretical guarantees, several challenges persist. These include balancing the need for universal OOD solutions with the demonstrated benefits of domain-specific adaptations, developing scalable and theoretically sound methods that can handle the full spectrum of real-world distribution shifts without relying on scarce OOD training data, and rigorously aligning OOD detection with the ultimate goal of ensuring model safety and reliability in constantly changing, unpredictable digital environments. Future research must continue to bridge theoretical rigor with practical deployment, particularly in the face of increasingly sophisticated and adaptive cyber threats.",
    "Practical Deployment Considerations and Human-in-the-Loop": "\\subsection{Practical Deployment Considerations and Human-in-the-Loop}\nThe successful transition of Out-of-Distribution (OOD) detection systems from controlled experimental settings to real-world applications hinges on addressing a critical set of practical deployment challenges. Beyond theoretical performance metrics, these systems must demonstrate computational efficiency, scalability, robustness to dynamic environments, provable guarantees on false detection rates, and the capacity for effective human-in-the-loop (HITL) interaction and interpretability. The overarching goal is to develop OOD solutions that are not only technically effective but also robust, efficient, interpretable, and ultimately practical for diverse operational settings, particularly in safety-critical domains.\n\nA foundational requirement for practical deployment, especially in latency-sensitive systems, is computational efficiency and scalability. Early OOD methods, particularly those relying on complex generative models, often incurred significant computational overhead \\cite{zisselman2020cmx}. Consequently, recent research has prioritized lightweight, post-hoc approaches that minimize inference time. Neural Mean Discrepancy (NMD) \\cite{dong2021swz}, for instance, leverages running average means from Batch Normalization layers to approximate training data statistics, enabling real-time detection with minimal computational burden. Similarly, GradOrth \\cite{behpour2023x13} offers an efficient gradient-based OOD detector by pre-computing a low-rank subspace of in-distribution data gradients, facilitating rapid OOD scoring during inference. While both methods offer efficiency gains, NMD's reliance on Batch Normalization statistics might limit its applicability to architectures without such layers or in scenarios where batch statistics are highly variable. GradOrth, conversely, requires gradient computations, which, while pre-computed, still adds a layer of complexity compared to simpler confidence-based scores. The computational burden of traditional kernel methods, such as Kernel PCA (KPCA), has also been significantly reduced by approaches like CoP and CoRP \\cite{fang2024lv2}, which devise explicit non-linear feature mappings to achieve state-of-the-art performance with $O(1)$ or $O(M)$ complexity, a substantial improvement over $O(N_{tr})$ for methods like k-Nearest Neighbors (KNN). For Cyber-Physical Systems (CPS) demanding real-time responses, \\cite{cai2020lsi} demonstrated efficient OOD detection by integrating learned nonconformity measures (from VAEs and Deep SVDD) into the Inductive Conformal Anomaly Detection (ICAD) framework, overcoming traditional conformal prediction's scalability limitations for high-dimensional sensor inputs. Furthermore, the efficiency challenge extends to large language models (LLMs) in natural language processing (NLP). \\cite{ouyang2023wxc} proposed PTO, an unsupervised prefix-tuning based OOD detection framework that offers a parameter-efficient alternative to costly fine-tuning, demonstrating comparable or superior performance with significantly reduced storage and computational requirements. These diverse approaches highlight a collective effort to balance detection efficacy with the stringent computational constraints of real-world deployment.\n\nBeyond raw efficiency, practical systems demand robustness to diverse OOD types and adversarial attacks, coupled with adaptive mechanisms for dynamic, non-stationary environments. Many methods improve intrinsic OOD robustness during training or representation learning (as discussed in Section 4), but deployment-time robustness necessitates adapting to unforeseen shifts. The conceptual shift from merely detecting \"out-of-distribution\" to \"Out-of-Model-Scope\" (OMS) detection \\cite{guerin202201y} is crucial, emphasizing the identification of inputs leading to *prediction errors* of the specific deployed model, rather than a generic notion of novelty. This perspective is further refined by the Model-Specific Out-of-Distribution (MS-OOD) framework \\cite{averly20239rv}, which unifies the detection of semantic shifts, covariate shifts, and even misclassified in-distribution examples based on the actual performance of a deployed classifier. This framework is vital for guiding adaptive behavior and dynamic thresholding, allowing systems to differentiate between inputs the model *can* handle despite a shift (e.g., a covariate shift it generalizes to) and those it *cannot* (e.g., a semantic shift or a covariate shift leading to misclassification). While MS-OOD provides a robust conceptual foundation, its practical implementation for continuous adaptation in dynamic environments remains an active area of research, often requiring continuous monitoring and re-calibration. Contributions like \\cite{chen20247p7}'s sparsity-regularized tuning framework enhance the generalizability of OOD score functions, making them less dependent on specific datasets and more capable of dynamic adaptation. A particularly innovative adaptive mechanism for handling unforeseen OOD in open-world scenarios is \\cite{cao20246gj}'s Envisioning Outlier Exposure (EOE). EOE leverages Large Language Models (LLMs) to synthetically generate potential outlier class labels based on visual similarity to in-distribution classes, effectively providing \"outlier exposure\" without requiring actual OOD data. This LLM-driven approach offers a scalable and flexible way to adapt to various OOD types (far, near, fine-grained) by dynamically envisioning new categories, thereby enhancing the model's ability to distinguish novel inputs in a zero-shot manner. However, the effectiveness of EOE relies heavily on the quality of LLM-generated prompts and the LLM's inherent knowledge, posing challenges for robust and unbiased outlier generation across all domains.\n\nA critical aspect of practical deployment, especially in safety-critical domains, is the ability to provide reliable uncertainty estimates and control false detection rates. This is paramount for building trust and ensuring regulatory compliance. Conformal Prediction (CP), as detailed in Section 7.2, offers a principled approach to this, providing provably valid false detection rates. For instance, \\cite{kaur2022cty} introduced iDECODe for single-point OOD detection with theoretically guaranteed bounded False Detection Rates (FDR). This work was significantly extended by \\cite{kaur20248t3} to time-series data in Cyber-Physical Systems, providing conformal guarantees for OOD detection in dynamic, dependent data streams. This is a crucial advancement, as many real-world applications involve sequential data where independence assumptions of traditional CP might not hold. While CP offers strong theoretical guarantees, its practical application often requires careful calibration and consideration of the exchangeability assumption, which can be challenging in highly non-stationary environments.\n\nDespite theoretical guarantees, managing false positives (FPs) in dynamic, open-world settings often requires human oversight, leading to the indispensable role of human-in-the-loop (HITL) approaches. HITL frameworks integrate human expert feedback to refine OOD detectors, manage trade-offs between safety and performance, and build trust. \\cite{vishwakarma2024z1m} directly addressed the problem of high False Positive Rates (FPR) in OOD detection by proposing a mathematically grounded HITL framework. This framework adaptively updates the detection threshold over time by integrating human feedback and employing an anytime-valid Upper Confidence Bound (UCB) based on the Law of Iterated Logarithm, guaranteeing FPR control below a desired level while maximizing True Positive Rate (TPR) (further theoretical details are in Section 7.2). This approach offers a robust mechanism for dynamic threshold adjustment, but its effectiveness depends on the availability and reliability of human feedback. Beyond direct threshold adjustment, HITL also plays a crucial role in data acquisition and model refinement. \\cite{schmidt2024syr} proposed SISOM, a unified approach for active learning and OOD detection. Active learning inherently involves human experts labeling uncertain or novel samples, thereby providing crucial feedback to improve both model performance and OOD detection capabilities. SISOM's self-deciding process for combining scores contributes to adaptive behavior, reducing the burden on human operators while maintaining robustness.\n\nFor HITL systems to be truly effective, building operator trust and ensuring practical utility requires OOD solutions that are not only effective but also interpretable and aligned with system safety goals. Human operators need to understand *why* a system flags an input as OOD to make informed decisions and foster confidence in AI systems. Methods that leverage intrinsic model properties or explanations can enhance this interpretability. For instance, Neuron Activation Coverage (NAC) \\cite{liu2023zb3} quantifies the \"coverage degree\" of neuron states by in-distribution data, offering insights into model behavior under OOD conditions. Similarly, GAIA \\cite{chen2023za1} detects OOD samples by quantifying \"abnormality in gradient-based attribution results,\" directly linking model explanations to OOD detection (these methods are detailed in Section 4.3). While these approaches provide valuable diagnostic information, translating complex neural network activations or gradient attributions into easily digestible and actionable insights for human operators remains a significant challenge. The interpretability must be tailored to the human's cognitive load and the specific decision-making context.\n\nIn conclusion, the literature demonstrates a clear trajectory towards OOD detection solutions that prioritize practical deployment. This involves a strong emphasis on computational efficiency for real-time operation, robustness and adaptive mechanisms for dynamic environments, and the provision of theoretical guarantees on false alarm rates. Crucially, the field is increasingly recognizing the indispensable role of human-in-the-loop approaches for adaptive thresholding, managing false positives, and building trust in AI systems. Future work will likely continue to explore more nuanced human-AI collaboration models, develop methods for handling highly dynamic and unforeseen OOD shifts with minimal human intervention, and strive for truly interpretable OOD explanations that align with human decision-making in safety-critical contexts, ultimately enabling the responsible and reliable deployment of AI.",
    "Evolving OOD Definitions and Granular Taxonomies": "\\subsection{Evolving OOD Definitions and Granular Taxonomies}\n\nThe conceptualization of Out-of-Distribution (OOD) detection has undergone a significant evolution, moving beyond a simplistic binary distinction between in-distribution (ID) and OOD data towards a more nuanced, granular, and context-aware understanding. This shift is critical for developing robust and trustworthy AI systems capable of operating reliably in complex real-world environments.\n\nInitially, OOD detection primarily focused on identifying samples from entirely novel semantic categories. However, this narrow view proved insufficient, leading to the introduction of more granular definitions. A pivotal development was the formal distinction between different types of distribution shifts. \\cite{yang2022it3} introduced the concept of \\textit{Full-Spectrum Out-of-Distribution (FS-OOD) Detection}, explicitly differentiating between \\textit{semantic shift} (novel classes) and \\textit{covariate shift} (label-preserving appearance changes like lighting or style). Their proposed Semantics score function (SEM) aimed to disentangle these shifts, demonstrating that existing methods often failed to robustly handle covariate-shifted ID data, treating it erroneously as OOD. Further complicating the landscape, \\cite{ming2021wu7} highlighted the critical impact of spurious correlations, formalizing \"spurious OOD\" where models rely on non-causal features, making detection challenging even for inputs that visually resemble ID data. This emphasized that OOD can arise not just from novel semantics or appearance, but also from the model's learned biases.\n\nThe need for more rigorous evaluation of these granular shifts quickly became apparent. \\cite{yang2023ckx} critically analyzed existing ImageNet-based OOD benchmarks, revealing issues such as ID contamination, semantic ambiguities, and unintended covariate shifts that hindered the accurate assessment of semantic OOD detection. To address this, they introduced `ImageNet-OOD`, a meticulously human-curated dataset designed to isolate pure semantic shift by minimizing covariate variations. Building on this, \\cite{wang2024is1} provided a comprehensive cross-evaluation of OOD detection and Open-Set Recognition (OSR) methods, further disentangling semantic and covariate shifts on large-scale benchmarks and proposing a new \"Outlier-Aware Accuracy\" (OAA) metric to reconcile robustness to covariate shift with the ability to detect its presence. These works collectively underscored the importance of clean, disentangled evaluation for understanding what OOD algorithms truly detect.\n\nA significant conceptual re-framing of the OOD problem was introduced by \\cite{averly20239rv} with the \\textit{Model-Specific Out-of-Distribution (MS-OOD) Detection} framework. This paradigm shifted the definition of OOD from being purely based on data properties to being dependent on a \\textit{specific deployed model's performance and misclassification behavior}. Under MS-OOD, an example is considered OOD if the model cannot classify it correctly, unifying semantic shift, covariate shift, and even misclassified in-distribution examples under a single, performance-driven ground truth. This perspective acknowledges that what constitutes \"OOD\" can be subjective and model-dependent, moving towards a more practical, context-aware definition.\n\nThe binary nature of traditional OOD evaluation also faced scrutiny. \\cite{long2024os1} addressed the \"Sorites Paradox\" in OOD evaluation, arguing that a simple binary ID/OOD distinction fails to capture the continuous \\textit{degree} of semantic and covariate shifts. They introduced the \\textit{Incremental Shift OOD (IS-OOD)} benchmark and \\textit{Language Aligned Image feature Decomposition (LAID)}, a CLIP-based method to quantitatively decompose image features into distinct semantic and covariate components. This allowed for continuous measurement of shift degrees, providing a far more granular and informative evaluation of OOD detection performance as a function of shift intensity.\n\nAs the field matured and its problem definitions became increasingly complex, the need for structured organization emerged. \\cite{lang20237w3} provided the first comprehensive survey on OOD detection in Natural Language Processing (NLP), introducing a novel taxonomy based on the availability of OOD data during training and highlighting NLP-specific challenges. This reflects the emergence of task-oriented and domain-specific taxonomies to organize the field's growing complexity, moving beyond generic definitions to practical, application-driven categorizations. Complementing this, theoretical works like \\cite{du2024aea} and \\cite{fang20249gd} contribute to this maturing conceptual understanding by exploring the fundamental learnability of OOD detection and the role of in-distribution labels, implicitly influencing how OOD boundaries are conceptualized and defined under various conditions.\n\nIn conclusion, the evolution of OOD definitions has progressed from a rudimentary binary classification to a sophisticated, multi-faceted understanding. This trajectory, marked by the differentiation of semantic and covariate shifts, the adoption of model-specific perspectives, the development of continuous shift measurements, and the emergence of task-oriented taxonomies, collectively reflects a maturing conceptual understanding of OOD detection. However, challenges remain in developing scalable, universally applicable methods that can robustly handle the full spectrum of these granular shifts without relying on scarce OOD training data, particularly in diverse real-world applications.",
    "Certifiable OOD Detection: Provable Guarantees and Conformal Prediction": "\\subsection{Certifiable OOD Detection: Provable Guarantees and Conformal Prediction}\n\nThe deployment of machine learning systems in safety-critical applications necessitates not only high empirical performance but also strong theoretical guarantees regarding their reliability, particularly in identifying out-of-distribution (OOD) inputs. This subsection explores the critical advancements towards certifiable OOD detection, emphasizing methods that provide provable guarantees on false detection rates and leverage rigorous statistical frameworks like Conformal Prediction (CP).\n\nA cornerstone of certifiable OOD detection is the integration of Conformal Prediction (CP), which offers a robust, model-agnostic framework for controlling false detection rates with statistical validity. Early work by \\cite{cai2020lsi} introduced Inductive Conformal Anomaly Detection (ICAD) for real-time OOD detection in learning-enabled Cyber-Physical Systems (CPS). This approach overcame the scalability limitations of traditional CP by employing learned nonconformity measures (NCMs) based on Variational Autoencoders (VAEs) and Deep Support Vector Data Description (SVDD), ensuring a well-calibrated false alarm rate in high-dimensional settings. Building on this, \\cite{kaur2022cty} proposed iDECODe, a novel ICAD framework leveraging in-distribution equivariance as its NCM. By aggregating scores from multiple transformations, iDECODe provides a theoretically guaranteed bounded false detection rate, demonstrating state-of-the-art performance in single-point OOD detection. Extending these guarantees to dynamic environments, \\cite{kaur20248t3} developed CODiT, which applies conformal anomaly detection to dependent time-series data in CPS. CODiT uses deviation from in-distribution temporal equivariance as an NCM and combines predictions from multiple detectors via Fisher's method, offering bounded false alarms for both fixed-length windows and variable-length traces. These advancements collectively showcase CP's versatility in providing marginal coverage guarantees across diverse OOD scenarios, from static single-point detection to complex temporal data streams.\n\nBeyond merely providing detection guarantees, CP is also crucial for establishing statistically rigorous evaluation metrics for OOD detectors themselves. Traditional OOD evaluation metrics, such as AUROC and FPR@TPR95, are empirical approximations that can be overly optimistic and fluctuate significantly with finite test sample sizes, lacking robust, conservative guarantees. Addressing this, \\cite{novello2024yco} proposed a dual application of CP and OOD detection. They introduced \"conformal AUROC\" and \"conformal FPR\" metrics, which provide probabilistic conservativeness guarantees on the variability of these evaluation metrics. This ensures that the estimated performance of an OOD detector is conservative with high probability (e.g., $1-\\delta$), thereby making the *evaluation* of OOD systems certifiable and more trustworthy. Furthermore, \\cite{novello2024yco} demonstrated that sophisticated OOD scores, such as Mahalanobis distance or K-Nearest Neighbors (KNN) distance, can serve as highly effective non-conformity scores within the CP framework, often outperforming classical CP non-conformity scores in building prediction sets. This highlights a synergistic relationship where OOD methods can enhance CP, and CP can, in turn, provide robust evaluation for OOD.\n\nWhile CP provides statistical guarantees, real-world systems often require adaptive control and human oversight, especially when faced with evolving OOD distributions. Addressing this, \\cite{vishwakarma2024z1m} introduced a mathematically grounded human-in-the-loop framework for OOD detection that dynamically adjusts detection thresholds. This framework leverages importance sampling and an anytime-valid Upper Confidence Bound (UCB) based on the Law of Iterated Logarithm to provide provable guarantees on the false positive rate (FPR), even in the presence of distribution shifts. By taming false positives with minimal human feedback, this approach significantly enhances the practical deployability and trustworthiness of OOD systems in dynamic, open-world environments.\n\nBeyond statistical guarantees and adaptive control, a deeper theoretical understanding of OOD detection learnability and data utility is crucial for a trustworthy foundation. \\cite{du20248xe} made a significant contribution by providing the first framework that offers *provable guarantees* for leveraging unlabeled \"wild\" data in OOD detection. Their \"Separate And Learn\" (SAL) framework employs a novel gradient-based filtering mechanism and offers rigorous error bounds on outlier separability and classifier learnability, demonstrating how unlabeled data can provably enhance OOD awareness without requiring clean auxiliary OOD samples. Complementing this, \\cite{fang20249gd} delved into the fundamental learnability of OOD detection, establishing necessary and sufficient conditions for Probably Approximately Correct (PAC) learnability under various risk and AUC metrics. This theoretical work highlights that OOD detection is not universally learnable and depends critically on the characteristics of the data and hypothesis spaces, providing crucial insights into the theoretical limits and possibilities of certifiable OOD systems. The implications for CP are profound: while CP offers statistical guarantees *given* an OOD score, the inherent quality and effectiveness of that score, and thus the practical utility of the CP-based detection, are constrained by the underlying learnability conditions of the specific OOD problem. This underscores the need for OOD scores that are well-aligned with the learnable properties of the data distribution for CP to be truly effective in practice.\n\nIn conclusion, the pursuit of certifiable OOD detection is rapidly evolving, moving from foundational statistical guarantees offered by Conformal Prediction for detection and evaluation, to adaptive, human-in-the-loop frameworks for dynamic FPR control. Simultaneously, theoretical work is establishing the learnability and data utility principles, collectively shaping a more robust and trustworthy understanding of what it means for an AI system to be \"certifiably\" aware of its own limitations. Despite these advancements, challenges remain in developing universally applicable nonconformity measures for CP that can provide strong guarantees across all types of distribution shifts, scaling CP to increasingly large foundation models, and extending these guarantees to more complex adaptive or continually learning systems, all while ensuring that the underlying OOD problem is indeed theoretically learnable.",
    "Standardized Benchmarking and Unified Evaluation Frameworks": "\\subsection{Standardized Benchmarking and Unified Evaluation Frameworks}\n\nThe systematic and fair advancement of Out-of-Distribution (OOD) detection critically relies on the development of standardized benchmarks and unified evaluation frameworks. Historically, the field grappled with inconsistent definitions of OOD, ad-hoc datasets, and disparate evaluation protocols, severely hindering reproducible and comparable research. Early work by \\cite{ming2021wu7} highlighted this by formalizing the concept of \"spurious OOD,\" demonstrating how models' reliance on spurious correlations in training data could lead to high-confidence but unreliable predictions on OOD inputs, thus exposing a fundamental flaw in simplistic OOD definitions and evaluation. Similarly, \\cite{berger20214a3}'s comparative study revealed significant performance discrepancies of confidence-based OOD methods between general computer vision tasks and challenging medical imaging applications, underscoring the necessity for domain-specific and rigorous evaluation. The lack of a comprehensive review for OOD in Natural Language Processing (NLP) was addressed by \\cite{lang20237w3}, which provided a taxonomy and discussed NLP-specific evaluation challenges, while \\cite{hong2024xls} offered a systematic framework and taxonomy for OOD detection in medical image analysis, clarifying terminology and evaluation protocols for this critical domain. These initial efforts underscored the urgent need for a more structured and consistent approach to OOD evaluation.\n\nA pivotal development in OOD evaluation has been the effort to disentangle distinct types of distribution shifts, moving beyond a monolithic view of OOD (as discussed in detail in Section 7.1). To operationalize these nuanced definitions, researchers have meticulously curated datasets designed to isolate and evaluate performance on specific shifts. \\cite{yang2023ckx} meticulously curated \\textit{ImageNet-OOD}, a novel dataset specifically designed to isolate and evaluate performance on semantic shifts while minimizing confounding covariate shifts. This dataset addressed critical shortcomings of previous ImageNet-based benchmarks, such as ID contamination and semantic ambiguities. Its findings were impactful, demonstrating that many modern OOD algorithms are disproportionately sensitive to covariate shifts rather than genuine semantic novelty, often failing to detect truly novel classes. This revelation prompted a re-evaluation of existing methods and guided the development of more robust techniques. Furthering this disentanglement, \\cite{wang2024is1} provided a critical analysis of OOD detection and Open-Set Recognition (OSR) methods, introducing a new large-scale benchmark to systematically disentangle semantic and covariate shifts and proposing \"Outlier-Aware Accuracy\" as a more nuanced metric. Complementing these efforts, \\cite{long2024os1} introduced the \"Incremental Shift OOD\" (IS-OOD) benchmark, which categorizes OOD samples by their \\textit{degree} of semantic and covariate shift, moving beyond binary OOD definitions and utilizing a novel Language Aligned Image feature Decomposition (LAID) method to quantify these shifts, offering a more granular assessment of OOD robustness.\n\nBeyond specialized datasets, the field has seen the emergence of comprehensive, unified software frameworks that provide robust platforms for rigorous comparison across diverse methods and OOD scenarios, addressing the critical need for reproducible and scientifically sound assessments. A cornerstone in this regard is **OOD-Bench** \\cite{huang2023ood}, which emerged to tackle the pervasive issues of inconsistent implementations and evaluation settings. OOD-Bench provides a modular and extensible platform that integrates a wide array of OOD detection methods, backbone architectures, and datasets, enabling researchers to conduct fair and reproducible comparisons. Its structured approach has significantly improved the reliability of reported results and fostered a more systematic advancement of the field. Similarly, \\cite{kirchheim20229jl} introduced **PyTorch-OOD**, a Python library specifically designed to accelerate OOD detection research and improve reproducibility. By providing well-tested and documented implementations of OOD methods with a unified interface, along with benchmark datasets and utility functions, PyTorch-OOD lowers the barrier to entry for new researchers and ensures consistency across experiments.\n\nThe demand for standardized evaluation extends to diverse data modalities and complex learning scenarios. For graph-structured data, which presents unique challenges due to its non-Euclidean nature, \\cite{liu202227x} pioneered a benchmark dataset for unsupervised graph-level OOD detection. This was significantly expanded by \\cite{wang2024q01} with **UB-GOLD**, a unified benchmark that integrates unsupervised graph-level anomaly detection and OOD detection across 35 datasets and four distinct scenarios. UB-GOLD provides a robust and comprehensive platform for rigorous comparison in this emerging domain, allowing for a deeper understanding of method performance under various graph OOD conditions. A recent survey by \\cite{cai2025ez2} further contributes to the standardization of graph OOD detection by providing a rigorous definition and systematically categorizing existing methods, clarifying distinctions with related fields and highlighting unique challenges. In medical imaging, where OOD detection is paramount for patient safety, \\cite{vasiliuk20233w9} developed a novel and diverse benchmark for 3D medical image segmentation OOD, which exposed the significant limitations of many state-of-the-art methods when confronted with the subtle, yet critical, OOD shifts inherent in medical data. Similarly, \\cite{anthony2023slf} contributed a new benchmark for OOD detection in medical imaging by manually annotating pacemakers and support devices in chest X-rays, enabling more targeted evaluation of methods like Mahalanobis distance against clinically relevant anomalies.\n\nFurthermore, as OOD detection integrates with more dynamic learning paradigms, specialized benchmarks become crucial. **OpenCIL** \\cite{miao20246mk} addresses the critical challenge of OOD detection within Class-Incremental Learning (CIL). CIL models, designed to continuously learn new classes, often suffer from catastrophic forgetting, which severely impacts their ability to detect OOD samples reliably. OpenCIL is the first comprehensive benchmark for OOD detection in CIL, providing unified evaluation protocols and two principled frameworks (post-hoc and fine-tuning based) to integrate OOD methods into CIL models. This benchmark has been instrumental in identifying critical biases in CIL models towards OOD samples and newly added classes, offering crucial insights for designing future open-world CIL systems.\n\nIn conclusion, the evolution of OOD detection has seen a critical shift from ad-hoc evaluations to sophisticated, standardized benchmarking and unified evaluation frameworks. The development of meticulously curated datasets like \\textit{ImageNet-OOD} \\cite{yang2023ckx} has been indispensable for disentangling various types of distribution shifts, while comprehensive software platforms such as OOD-Bench \\cite{huang2023ood} and PyTorch-OOD \\cite{kirchheim20229jl} provide the necessary infrastructure for reproducible and fair comparisons. Specialized benchmarks like UB-GOLD \\cite{wang2024q01} for graph data, medical imaging benchmarks \\cite{vasiliuk20233w9, anthony2023slf}, and OpenCIL \\cite{miao20246mk} for CIL have expanded the field's evaluative rigor into complex domains. Despite these advancements, challenges remain in creating truly exhaustive benchmarks that capture the full spectrum of real-world OOD scenarios, particularly for dynamic and 'near-OOD' shifts, and in developing evaluation protocols that scale effectively for increasingly large foundation models. Future research must continue to bridge the gap between empirical performance and theoretical understanding, ensuring that benchmarks not only measure but also drive the development of truly robust and trustworthy OOD solutions.",
    "Synthesis of Key Trends and Contributions": "\\subsection{Synthesis of Key Trends and Contributions}\nThe field of Out-of-Distribution (OOD) detection has undergone a profound transformation, evolving from rudimentary post-hoc scoring mechanisms to sophisticated, context-aware strategies that leverage advanced model architectures and rigorous theoretical foundations. This progression is driven by the imperative to build more reliable, adaptable, and trustworthy AI systems capable of operating effectively and safely in unpredictable, open-world environments. The collective research consolidates our understanding of how OOD detection has matured to address the growing demands for robust uncertainty quantification across diverse applications.\n\nInitially, research focused on extracting OOD signals from already trained models, often through feature engineering and statistical analysis. Early efforts explored the utility of reconstruction-based methods, with \\cite{zhou202250i} rethinking autoencoder-based OOD by introducing layerwise semantic reconstruction and a Normalized L2 Distance to make reconstruction error a more valid uncertainty measure. Complementing this, \\cite{zaeemzadeh2021lmh} proposed embedding in-distribution (ID) data into a union of 1-dimensional subspaces for compact representation and easier OOD detection. The analysis of feature properties also proved fruitful: \\cite{song2022f5d} introduced RankFeat, a post-hoc method that removes a dominant rank-1 component from high-level features based on spectral analysis, significantly improving performance. Similarly, \\cite{zhu2022oir} boosted OOD detection by rectifying features into their \"typical set\" using a Truncated Batch Normalization unit, mitigating the impact of extreme features. \\cite{yu2022egq} further explored feature norms, demonstrating that intermediate layers often provide better OOD separation than the final layer, and proposed a block selection method using pseudo OOD data. Challenging the prevailing reliance on simple output-based scores, \\cite{kuan2022qzl} revisited OOD baselines and strongly advocated for the effectiveness of k-Nearest Neighbor (KNN) distance on learned embeddings. More recently, \\cite{lu20249d4} advanced distance-based methods by modeling ID classes with a mixture of prototypes in a hyperspherical embedding space, capturing intra-class diversity, while \\cite{fang2024lv2} demonstrated the power of Kernel PCA with efficient explicit feature mappings for non-linear OOD separation. These methods collectively refined the ability to discern OOD samples from subtle cues within a model's internal representations, often without requiring additional training.\n\nA significant intellectual trajectory involved moving beyond passive post-hoc analysis to actively enhancing model robustness during training. This included adversarial training, as seen in \\cite{chen2020mbk}'s ALOE, which robustified OOD detectors against both adversarial in-distribution and OOD examples. A major paradigm shift was the widespread adoption and refinement of Outlier Exposure (OE), where auxiliary OOD data is used to regularize model training. \\cite{zhang20212tb} introduced Mixture Outlier Exposure (MixOE) to address fine-grained OOD by mixing ID and auxiliary data, creating a broader virtual outlier distribution. Providing theoretical grounding, \\cite{bitterwolf2022rw0} demonstrated that many OE methods are asymptotically equivalent to a binary discriminator, highlighting that differences often stem from estimation procedures. Subsequent work focused on optimizing the utility of auxiliary data: \\cite{jiang2023vzb} proposed Diverse Outlier Sampling (DOS) to select diverse and informative outliers, a concept further advanced by \\cite{yao2024epq}'s diverseMix, which provably enhances outlier diversity through semantic-level interpolation. Addressing practical challenges, \\cite{choi202367m} introduced a balanced energy regularization loss to account for class imbalance within auxiliary OOD data, while \\cite{hofmann2024gnx} leveraged Energy-based Hopfield Boosting for adaptive sampling of \"hard\" outliers. Complementing these data-centric strategies, methods like \\cite{cheng20233yi}'s Average of Pruning (AoP) tackled training instability and overfitting in OOD detection, a theme further explored by \\cite{chen2024kl7} with optimal parameter and neuron pruning based on gradient sensitivity. \\cite{wu20242p3} explicitly pursued feature separation based on Neural Collapse, constraining OOD features to an orthogonal subspace of ID features during fine-tuning. Concurrently, generative models also evolved: \\cite{zisselman2020cmx} introduced Deep Residual Flow for improved density modeling in feature activations, and \\cite{morningstar2020re9}'s Density of States Estimation (DoSE) shifted focus from direct likelihoods to the typicality of multiple summary statistics, overcoming the \"high likelihood for OOD\" pathology.\n\nThe field has also expanded dramatically to encompass complex data modalities, specialized learning paradigms, and the formidable capabilities of foundation models. For dense prediction tasks, \\cite{liu2022fdj} proposed Residual Pattern Learning (RPL) for pixel-wise OOD detection in semantic segmentation, decoupling it from the main task. \\cite{besnier2021jgn} further enhanced segmentation OOD by learning from local adversarial attacks to generate OOD-like training data, while \\cite{gao2023epm}'s ATTA introduced anomaly-aware test-time adaptation to handle domain shifts. For graph-structured data, \\cite{liu202227x} pioneered unsupervised graph-level OOD detection with GOOD-D, a hierarchical contrastive learning framework, a direction further advanced by \\cite{wang2025xwm}'s GOLD, which uses implicit adversarial latent generation to synthesize OOD samples without auxiliary data, and \\cite{wang2024es5}'s GOODAT for test-time graph OOD detection. The rise of Vision-Language Models (VLMs) and Large Language Models (LLMs) has opened new frontiers: \\cite{miyai2023591} introduced GL-MCM for zero-shot OOD detection by combining global and local CLIP features, while \\cite{li20245b6} learned transferable negative prompts for open-vocabulary OOD, and \\cite{yu20249dd} proposed Self-Calibrated Tuning to mitigate spurious OOD features in VLMs. Leveraging LLMs further, \\cite{dai2023mhn} explored their world knowledge for multimodal OOD, carefully calibrating for hallucination, and \\cite{cao20246gj} used LLMs for \"envisioned outlier exposure\" in zero-shot settings. Multimodal OOD itself gained a dedicated benchmark with \\cite{dong2024a8k}'s MultiOOD, which also proposed the Agree-to-Disagree (A2D) algorithm to amplify inter-modal prediction discrepancies. This was complemented by \\cite{li2024rs5}'s DPU, addressing intra-class variability in multimodal OOD. Diffusion models also found their niche, with \\cite{graham20232re} applying Latent Diffusion Models for unsupervised 3D medical OOD detection, and \\cite{gao2023kmk}'s DiffGuard using pre-trained diffusion models for semantic mismatch-guided OOD. The field also expanded to long-tailed recognition \\cite{miao2023brn, wei2023f15}, LiDAR-based 3D object detection \\cite{ksel20246fe}, and even mathematical reasoning in GLMs using embedding trajectories \\cite{wang2024rej}.\n\nCrucially, the field has placed an increasing emphasis on theoretical guarantees, robust evaluation, and a critical re-evaluation of fundamental definitions to build truly trustworthy AI. \\cite{yang2022it3} introduced the Full-Spectrum OOD (FS-OOD) problem, distinguishing between semantic and covariate shifts, and proposed the SEM score for robust detection. This was followed by rigorous benchmarking efforts: \\cite{zimmerer2022rv6} established the MOOD 2020 benchmark for medical imaging, \\cite{yang2023ckx} created ImageNet-OOD to disentangle semantic and covariate shifts, and \\cite{wang2024is1} critically dissected OOD and Open-Set Recognition (OSR) methods and benchmarks. The \"Sorites Paradox\" in OOD evaluation was addressed by \\cite{long2024os1}, proposing the Incremental Shift OOD (IS-OOD) benchmark to categorize samples by continuous shift degrees. Theoretical underpinnings have also solidified: \\cite{park2023n97} provided a principled explanation for why feature norm helps OOD detection, linking it to hidden classifier confidence, while \\cite{du2024aea} formally analyzed when and how in-distribution labels provably help OOD detection. \\cite{fang20249gd} investigated the fundamental learnability of OOD detection, establishing necessary and sufficient conditions. For safety-critical systems, the focus shifted to provable guarantees: \\cite{cai2020lsi} developed real-time OOD detection for Cyber-Physical Systems (CPS) with conformal guarantees using VAEs and Deep SVDD, a concept extended by \\cite{kaur2022cty}'s iDECODe, which leveraged in-distribution equivariance. \\cite{kaur20248t3} further extended this to dependent data in CPS with temporal equivariance. Critically, \\cite{guerin202201y} argued that \"OOD detection is not all you need,\" proposing Out-of-Model-Scope (OMS) detection as a more direct goal for identifying model errors, and \\cite{vishwakarma2024z1m} introduced a human-in-the-loop framework to tame false positives with theoretical FPR guarantees. These interconnected developments highlight a maturation of the field, moving towards comprehensive solutions that are not only performant but also interpretable, reliable, and adaptable to the complex demands of real-world AI deployment.",
    "Open Challenges and Future Research Avenues": "\\subsection*{Open Challenges and Future Research Avenues}\n\nThe quest for truly robust and autonomous AI systems hinges critically on their ability to reliably detect and appropriately handle Out-of-Distribution (OOD) inputs. Despite significant advancements, the field of OOD detection continues to grapple with several profound challenges that define current research frontiers and pave the way for future innovation.\n\nOne persistent challenge is the \"near OOD\" problem, where subtle shifts in data distribution are difficult to distinguish from in-distribution (ID) variations. Models often exhibit overconfidence on these semantically similar, yet novel, inputs, leading to unreliable predictions \\cite{ming2021wu7}. Addressing this requires a multi-faceted approach. Some research focuses on **data-centric strategies** to refine the ID/OOD boundary during training. For instance, Mixture Outlier Exposure (MixOE) \\cite{zhang20212tb} generates virtual outliers by mixing ID and auxiliary data, specifically targeting fine-grained OOD detection where samples share visual similarities with ID data. Similarly, Virtual Outlier Smoothing (VOSo) \\cite{nie2024ghv} constructs virtual outliers by perturbing semantic regions of ID samples, aiming to create smoother, more robust decision boundaries. However, a key challenge remains in generating truly representative and diverse near-OOD samples without inadvertently corrupting the ID manifold. Other efforts concentrate on **representation-centric enhancements**, aiming to improve the inherent separability of ID and OOD features. Batch Normalization Assisted Typical Set Estimation (BATS) \\cite{zhu2022oir} rectifies extreme features, while Variational Rectified Activation (VRA) \\cite{xu2023767} proposes optimal activation functions to improve ID/OOD separability. Leveraging Neural Collapse properties, such as ID/OOD Orthogonality (NC5) \\cite{ammar2023pr1}, projects features onto principal component spaces for better OOD detection, inherently aiding in distinguishing subtle shifts (as discussed in Section 4.2). Neuron Activation Coverage (NAC) \\cite{liu2023zb3} provides a novel uncertainty measure sensitive to abnormal activation patterns caused by subtle OOD inputs by quantifying neuron behavior. From a theoretical perspective, \\cite{du2024aea} highlights the crucial role of ID labels in these near-OOD scenarios. Despite these advancements, a fundamental understanding of *what constitutes a \"near OOD\" boundary* and how to robustly generalize detection across diverse, subtly shifted domains remains an open problem, necessitating more robust benchmarks like ImageNet-OOD \\cite{yang2023ckx} and IS-OOD \\cite{long2024os1} that disentangle semantic and covariate shifts for accurate evaluation.\n\nAnother significant open challenge is the scalability of OOD detection methods, particularly for increasingly large foundation models like Vision-Language Models (VLMs) and Large Language Models (LLMs). While these models offer unprecedented representational power and open-vocabulary capabilities (as explored in Section 5.3), traditional OOD methods often struggle with their computational and data demands, or fail to leverage their rich representations effectively without prohibitive inference costs or extensive fine-tuning. Current research is making strides in adapting OOD detection to this new paradigm. Approaches include leveraging pre-trained features, such as GL-MCM \\cite{miyai2023591} which combines global and local CLIP features for zero-shot OOD detection, offering flexibility for multi-object scenes. **Prompt engineering and virtual outlier generation** are also emerging as scalable solutions: Outlier Label Exposure (OLE) \\cite{ding20242m0} uses auxiliary outlier class labels as pseudo OOD text prompts for VLMs, and NegPrompt \\cite{li20245b6} learns transferable negative prompts from ID data alone to enhance OOD sensitivity without external outlier data. Self-Calibrated Tuning (SCT) \\cite{yu20249dd} adaptively adjusts ID classification and OOD regularization in VLMs to mitigate spurious OOD features. The potential of LLMs for generating synthetic outlier exposure is explored by \\cite{cao20246gj}, envisioning how LLM knowledge can create diverse outlier labels for zero-shot OOD detection. For multimodal foundation models, the MultiOOD benchmark and the Agree-to-Disagree (A2D) algorithm \\cite{dong2024a8k} leverage inter-modal prediction discrepancies, while Dynamic Prototype Updating (DPU) \\cite{li2024rs5} accounts for intra-class variability. However, the core challenge lies in developing OOD detection frameworks that are *inherently* scalable, efficient, and robust for models with billions of parameters, without requiring extensive retraining or sacrificing the model's generalizability. This includes tackling prohibitive inference costs, catastrophic forgetting during OOD-specific fine-tuning, and the theoretical understanding of OOD behavior in these complex architectures, as highlighted by \\cite{miyai20247ro}.\n\nLooking ahead, future research avenues are poised to develop more adaptive and dynamic OOD systems that can learn and adjust in real-time. This involves moving beyond static OOD detectors to systems capable of continuous monitoring and adaptation in dynamic environments, such as Cyber-Physical Systems (CPS). Building on the practical deployment considerations discussed in Section 6.4, methods like those pioneered by \\cite{cai2020lsi} use learned nonconformity measures within a conformal prediction framework to provide real-time OOD detection with statistical guarantees. Further advancements like iDECODe \\cite{kaur2022cty} leverage in-distribution equivariance for conformal OOD detection with bounded false detection rates, a concept extended to dependent time-series data in \\cite{kaur20248t3}. The challenge of adapting to domain shifts at test time for dense OOD detection in segmentation is addressed by ATTA \\cite{gao2023epm}, which uses a dual-level adaptation framework. Future work needs to focus on **online OOD detection** that can continuously update its model of ID and OOD without full retraining, **proactive adaptation** that anticipates shifts, and **self-correcting AI systems** that can not only detect OOD but also intelligently propose mitigation strategies or request human intervention \\cite{vishwakarma2024z1m}. The concept of adaptive sampling of \"hard\" outliers during training, as demonstrated by Energy-based Hopfield Boosting \\cite{hofmann2024gnx}, also contributes to dynamic system adjustment.\n\nAnother promising direction involves exploring **causal inference for OOD detection** to understand underlying mechanisms rather than merely identifying statistical anomalies. Traditional OOD methods often rely on statistical correlations, making them vulnerable to spurious associations that do not generalize across different environments. The work by \\cite{ming2021wu7} on the impact of spurious correlation for OOD detection underscores this limitation. Future research should focus on developing OOD detectors that are robust to such correlations by explicitly learning causal relationships. This could involve leveraging frameworks like Invariant Risk Minimization (IRM) \\cite{arjovsky2019invariant} or Structural Causal Models (SCMs) to disentangle causal (invariant) features from non-causal (environmental) ones. Specific research questions include: How can we design training objectives that promote the learning of causally invariant representations that are inherently more robust to OOD shifts? Can interventional or counterfactual reasoning be used to identify features that truly *cause* an input to be OOD, leading to more interpretable and generalizable OOD signals? Furthermore, exploring causal discovery techniques to model the underlying causal graph of ID data could enable the detection of OOD samples as deviations from this fundamental structure, offering a deeper, more principled understanding of novelty.\n\nFinally, fostering deeper integration with other machine learning tasks like active learning and continual learning is crucial for holistic, efficient, and robust AI solutions that can operate autonomously in complex environments. OOD detection naturally complements **active learning (AL)**, as OOD samples represent regions of uncertainty where the model's competence is low, making them ideal candidates for human labeling. SISOM \\cite{schmidt2024syr} proposes a unified approach, demonstrating that OOD detection and AL can be addressed simultaneously by leveraging enriched feature space distance metrics. Future work could explore how OOD uncertainty can more effectively guide AL to discover truly novel classes or subtle shifts, rather than just ambiguous ID samples. Similarly, in **continual learning (CL)**, OOD detection is vital for maintaining robustness to previously learned ID data while reliably identifying novel inputs without catastrophic forgetting. Continual Evidential Deep Learning (CEDL) \\cite{aguilar2023ms5} offers a solution for simultaneous incremental object classification and OOD detection. MIntOOD \\cite{zhang2024cx0} extends this to multimodal intent understanding. The challenge lies in developing OOD detectors that can dynamically evolve with the model in CL settings, updating their ID boundaries without re-exposing to all past data or confusing new ID classes with true OOD. These integrated approaches represent a significant step towards building AI systems that are not only aware of their limitations but can also actively learn, adapt, and operate safely in dynamic, open-world settings.\n\nUltimately, the future of OOD detection lies in a paradigm shift from reactive, isolated detectors to proactive, integrated, and self-monitoring AI systems. This grand vision entails models that continuously learn their own competence boundaries, adapt dynamically to evolving environments, leverage causal understanding for robust generalization, and seamlessly integrate with learning processes like active and continual learning. Such holistic, efficient, and robust AI solutions will be indispensable for building trustworthy systems that can operate autonomously and ethically in an increasingly complex and unpredictable world.",
    "Ethical Considerations and Societal Impact": "\\subsection{Ethical Considerations and Societal Impact}\nThe integration of Out-of-Distribution (OOD) detection mechanisms into real-world AI systems, particularly in high-stakes applications, necessitates a rigorous examination of their ethical implications and potential societal impacts. Failures in OOD detection can precipitate profound consequences, ranging from critical safety hazards in autonomous systems to the perpetuation of discriminatory outcomes in sensitive decision-making processes. Consequently, advancements in this domain must transcend mere technical performance, actively embedding principles of transparency, fairness, and accountability to foster responsible and human-centric AI deployment.\n\nA paramount ethical concern centers on the deployment of AI models in safety-critical Cyber-Physical Systems (CPS), where OOD failures can be catastrophic. For instance, autonomous vehicles and medical diagnostic tools rely heavily on robust OOD detection to prevent misinterpretations of novel inputs that could lead to severe accidents or incorrect diagnoses \\cite{cai2020lsi}. The ethical imperative here is to ensure not only high detection rates but also controlled error rates, particularly false positives and false negatives. While the technical details of certifiable OOD detection are elaborated in Section 7.2, it is ethically crucial that such systems provide statistically bounded false detection rates, as proposed by frameworks like conformal prediction \\cite{kaur2022cty, kaur20248t3}. These guarantees are vital safeguards against erroneous rejections (false positives) that could trigger unnecessary system shutdowns, or, conversely, undetected novelties (false negatives) leading to silent, dangerous failures. The challenge of managing false positives, which can erode user trust and increase human workload, is addressed by human-in-the-loop frameworks that adaptively control the False Positive Rate (FPR) with theoretical guarantees \\cite{vishwakarma2024z1m}. From a broader socio-technical perspective, the integration of human oversight in such systems also raises ethical questions about the cognitive load, potential for automation bias, and psychological impact on human supervisors, necessitating careful design of human-AI interfaces and clear protocols.\n\nBeyond error rates, the very definition of \"out-of-distribution\" carries significant ethical weight. \\cite{guerin202201y} critically argues that focusing solely on \"Out-of-Distribution Detection\" might be insufficient for safety, proposing \"Out-of-Model-Scope\" (OMS) detection as a more ethically aligned objective. OMS aims to identify inputs that would lead to actual model errors, rather than just distribution shifts, thereby directly addressing the imperative to abstain from unsafe predictions. Furthermore, the robustness of OOD detectors against malicious inputs is a critical safety concern, as adversarial attacks could manipulate detectors into making unsafe decisions \\cite{chen2020mbk}. The inherent difficulty in distinguishing harmless from potentially unsafe OOD events, particularly in dynamic environments like Reinforcement Learning, underscores the need for clear definitions of \"unknown events\" and robust safety assurance frameworks for ML components \\cite{haider20249q8}. This highlights the necessity for ethical guidelines and potentially regulatory standards to govern the certification and deployment of OOD-enabled AI systems.\n\nA particularly critical ethical dimension is the potential for bias in OOD detection, which can lead to unfair or discriminatory outcomes. If OOD models are trained on data reflecting societal biases, they can inadvertently amplify these biases. For instance, \\cite{ming2021wu7} demonstrates how spurious correlations in training data (e.g., associating certain backgrounds with specific classes) can severely degrade OOD detection performance. Models relying on these non-causal features might confidently misclassify inputs from underrepresented demographic groups as \"anomalous\" if those inputs exhibit features statistically correlated with OOD data in the training set. This can result in discriminatory rejections or differential treatment, where certain groups are disproportionately flagged as \"outliers.\" Such biases are not merely technical failures but ethical breaches, demanding fairness-aware OOD algorithms that explicitly analyze and mitigate performance disparities across demographic subgroups. While interpretability methods like GAIA, which uses gradient-based attribution abnormality \\cite{chen2023za1}, or Neuron Activation Coverage (NAC) \\cite{liu2023zb3}, are not direct fairness interventions, they are crucial tools for auditing models. By revealing *why* an input is deemed OOD, they enable practitioners to identify and address unintended biases in the OOD decision-making process. In multimodal contexts, where biases can exist across various data streams (e.g., text, video, audio), the challenge of ensuring fair OOD detection is further compounded \\cite{zhang2024cx0}.\n\nFinally, the societal impact of deploying AI models that may fail silently on novel inputs is a pervasive ethical concern. The fundamental purpose of OOD detection is to prevent such silent failures, enabling models to express uncertainty or abstain when confronted with unfamiliar data. Methods like DoSE \\cite{morningstar2020re9} directly tackle the \"high likelihood for OOD\" pathology, where generative models might assign high confidence to OOD data, thereby preventing a dangerous false sense of security. Furthermore, a deeper understanding of how in-distribution (ID) labels influence OOD detection, especially for \"near OOD\" scenarios where ethical risks are heightened \\cite{du2024aea}, is vital to avoid mischaracterizing subtle shifts as benign. The development of robust and comprehensive in-distribution representations, as exemplified by methods like MOODv2 \\cite{li2024n34}, inherently makes OOD detection more reliable and less prone to silent failures, as models gain a more accurate understanding of what constitutes \"normal\" data.\n\nIn conclusion, while significant technical advancements have propelled OOD detection forward, the ethical considerations and societal impact remain paramount. Future research must prioritize the development of robust safeguards, including statistical guarantees (as discussed in Section 7.2) and adaptive human-in-the-loop mechanisms \\cite{vishwakarma2024z1m}, to rigorously control false positives and negatives in safety-critical applications. Crucially, a concerted effort is needed to ensure fairness by investigating and mitigating potential biases, particularly those arising from spurious correlations \\cite{ming2021wu7}, through the development of transparent and interpretable methods \\cite{chen2023za1, liu2023zb3} that facilitate auditing and accountability. Ultimately, the goal is to cultivate a paradigm where AI systems not only achieve high performance but also operate responsibly, recognizing their limitations, communicating uncertainty effectively, and adhering to ethical guidelines, thereby fostering trust and enabling the safe and equitable integration of AI into society."
  },
  "latex_document": "\\documentclass[12pt,a4paper]{article}\n    \\usepackage[utf8]{inputenc}\n    \\usepackage[T1]{fontenc}\n    \\usepackage{amsmath,amsfonts,amssymb}\n    \\usepackage{graphicx}\n    \\usepackage[margin=2.5cm]{geometry}\n    \\usepackage{setspace}\n    \\usepackage{natbib}\n    \\usepackage{url}\n    \\usepackage{hyperref}\n    \\usepackage{booktabs}\n    \\usepackage{longtable}\n    \\usepackage{array}\n    \\usepackage{multirow}\n    \\usepackage{wrapfig}\n    \\usepackage{float}\n    \\usepackage{colortbl}\n    \\usepackage{pdflscape}\n    \\usepackage{tabu}\n    \\usepackage{threeparttable}\n    \\usepackage{threeparttablex}\n    \\usepackage[normalem]{ulem}\n    \\usepackage{makecell}\n    \\usepackage{xcolor}\n\n    % Set line spacing\n    \\doublespacing\n\n    % Configure hyperref\n    \\hypersetup{\n        colorlinks=true,\n        linkcolor=blue,\n        filecolor=magenta,      \n        urlcolor=cyan,\n        citecolor=red,\n    }\n\n    % Title and author information\n    \\title{A Comprehensive Literature Review with Self-Reflection}\n    \\author{Literature Review}\n    \\date{\\today}\n\n    \\begin{document}\n\n    \\maketitle\n\n    % Abstract (optional)\n    \\begin{abstract}\n    This literature review provides a comprehensive analysis of recent research in the field. The review synthesizes findings from 186 research papers, identifying key themes, methodological approaches, and future research directions.\n    \\end{abstract}\n\n    \\newpage\n    \\tableofcontents\n    \\newpage\n\n    \\label{sec:introduction_to_out-of-distribution_detection}\n\n\\section{Introduction to Out-of-Distribution Detection}\n\\label{sec:introduction\\_to\\_out-of-distribution\\_detection}\n\n\\subsection{Defining Out-of-Distribution Data and Distribution Shifts}\n\\label{sec:1\\_1\\_defining\\_out-of-distribution\\_data\\_\\_and\\_\\_distribution\\_shifts}\n\nThe robust deployment of machine learning models in real-world, open-world environments critically hinges on their ability to recognize when input data deviates from the distribution they were trained on. This fundamental challenge is addressed by Out-of-Distribution (OOD) detection, a field dedicated to distinguishing In-Distribution (ID) data, which models are designed to process, from novel, unfamiliar OOD data. Initially, OOD was often conceptualized as a straightforward \"semantic shift,\" implying entirely new classes or concepts unseen during training. However, this definition has evolved significantly to encompass a more complex spectrum of distribution shifts that profoundly challenge model generalization.\n\nEarly work often struggled to consistently categorize various forms of data shifts. \\cite{yang2022it3} critically addressed this by introducing the \"Full-Spectrum OOD (FS-OOD)\" problem, explicitly distinguishing between \\textbf{semantic shift} (novel classes) and \\textbf{covariate shift} (changes in input appearance or style, such as lighting or viewpoint, while retaining the same semantic class). Their proposed SEM score function, which disentangles semantic and non-semantic features, aimed to detect true semantic novelty while remaining robust to covariate variations, highlighting the necessity of a nuanced approach beyond simple binary classification. Further complicating this, \\cite{ming2021wu7} introduced the concept of \"spurious OOD,\" demonstrating that models can make overconfident predictions on OOD inputs that share spurious correlations with ID data, even if they lack the essential invariant features. This revealed a deeper vulnerability where models exploit non-causal features, making detection particularly challenging and underscoring the inherent ambiguity in OOD boundaries.\n\nThe need for more rigorous evaluation and clearer definitions led to significant advancements in benchmarking. \\cite{yang2023ckx} meticulously curated \\texttt{ImageNet-OOD}, a dataset designed to isolate pure semantic shift by removing ID contamination, semantic ambiguities, and unintended covariate shifts prevalent in prior benchmarks. This effort emphasized the difficulty in creating truly clean OOD definitions and highlighted how existing methods often inadvertently detected covariate shifts rather than genuine semantic novelty. Building on this, \\cite{averly20239rv} proposed a \"Model-Specific Out-of-Distribution (MS-OOD)\" framework, which redefined OOD not solely by data properties but by whether a \\textit{deployed model} could correctly classify an example. This unified the detection of semantic shift, covariate shift (when misclassified), and even misclassified ID examples under a single, performance-driven ground truth, providing a more practical and holistic perspective. The \"Sorites Paradox\" of OOD, where the degree of shift is continuous rather than binary, was addressed by \\cite{long2024os1}. They introduced the \"Incremental Shift OOD (IS-OOD)\" benchmark and the LAID method, which leverages CLIP to decompose image features into distinct semantic and covariate components, allowing for a continuous measurement of shift levels. This moved the field towards understanding OOD as a spectrum rather than a discrete boundary. \\cite{wang2024is1} further dissected OOD detection and open-set recognition, providing a critical analysis of methods and benchmarks, and emphasizing the need for evaluation protocols that disentangle semantic and covariate shifts, especially at scale where methods like Outlier Exposure struggle due to the difficulty of acquiring representative auxiliary OOD data.\n\nBeyond visual data, the definition and challenges of OOD extend to other modalities. \\cite{liu202227x} pioneered unsupervised OOD detection for graph-structured data with GOOD-D, addressing the unique topological and feature-based shifts in graphs. \\cite{dong2024a8k} scaled OOD detection to multimodal settings, introducing the \\texttt{MultiOOD} benchmark and the Agree-to-Disagree (A2D) algorithm to leverage complementary information across modalities (e.g., video, audio, optical flow) and identify \\texttt{Modality Prediction Discrepancy} as an OOD signal. For natural language processing, \\cite{lang20237w3} provided a comprehensive survey, highlighting the distinct challenges of discrete input spaces and contextual semantic shifts. In generative language models, \\cite{wang2024rej} tackled OOD detection in mathematical reasoning, identifying \"pattern collapse\" in output spaces and proposing a \"Trajectory Volatility Score\" based on dynamic embedding changes, demonstrating how domain-specific phenomena necessitate specialized OOD definitions. Furthermore, theoretical investigations have deepened our understanding of OOD learnability. \\cite{fang20249gd} explored the PAC learnability of OOD detection, proving that it is not universally learnable and depends critically on the characteristics of the data distributions and hypothesis spaces. \\cite{du2024aea} provided theoretical conditions for \\textit{when and how} in-distribution labels help OOD detection, particularly for \"near OOD\" scenarios. Finally, \\cite{park2023n97} offered a theoretical explanation for the efficacy of feature norms in OOD detection, linking it to hidden classifier confidence and proposing a \"Negative-Aware Norm\" (NAN) that accounts for both activation and deactivation tendencies of neurons, providing a deeper insight into the internal mechanisms that differentiate ID from OOD.\n\nIn conclusion, the definition of OOD data and distribution shifts has evolved from a simplistic notion of novel classes to a multifaceted concept encompassing semantic, covariate, and spurious shifts, often viewed as a continuous spectrum rather than a hard boundary. The field now grapples with model-specific interpretations, multimodal challenges, and fundamental questions about learnability, necessitating robust detection mechanisms that are sensitive to diverse forms of unfamiliarity while being resilient to expected variations. The inherent ambiguity in precisely delineating OOD boundaries remains a central, ongoing challenge in the field.\n\\subsection{Motivation: The Imperative for Trustworthy AI}\n\\label{sec:1\\_2\\_motivation:\\_the\\_imperative\\_for\\_trustworthy\\_ai}\n\nThe increasing integration of artificial intelligence (AI) systems into critical societal infrastructures and high-stakes applications necessitates an unwavering commitment to trustworthiness, reliability, and safety. A fundamental challenge that directly undermines this trust is the inherent overconfidence of deep learning models when confronted with inputs that deviate significantly from their training distribution, commonly referred to as Out-of-Distribution (OOD) data. This section articulates the compelling and urgent reasons behind the escalating importance of OOD detection in modern AI, emphasizing its role as an indispensable component for building truly trustworthy, robust, and safe artificial intelligence.\n\nIn numerous safety-critical domains, the consequences of unchecked model overconfidence on OOD data can be catastrophic, leading to unreliable decisions, system failures, and potentially severe harm. For instance, in autonomous driving, a vehicle's perception system misinterpreting an anomalous road condition, an unfamiliar object, or an unusual weather pattern as a familiar in-distribution (ID) input can lead to dangerous maneuvers or accidents \\cite{cai2020lsi, kaur2022cty}. Similarly, in medical diagnosis, an AI system providing a highly confident but incorrect diagnosis for a rare or unseen patient condition, or misinterpreting an anomalous medical image, could have dire implications for patient well-being \\cite{zimmerer2022rv6, kaur2022cty}. The deployment of deep reinforcement learning (RL) agents in real-world control systems also faces this challenge, where agents trained in simulated environments may encounter novel states in the physical world and fail silently without signaling uncertainty, posing significant safety risks \\cite{haider20249q8}. This imperative for trustworthy AI demands that these systems not only perform well on familiar data but also express meaningful and calibrated uncertainty when encountering novel, unfamiliar, or anomalous inputs \\cite{zisselman2020cmx, morningstar2020re9, lu2024j0n}.\n\nThe core problem stems from the \"closed-world\" assumption under which most deep learning models are traditionally trained. This assumption posits that test data will be drawn from the same statistical distribution as the training data \\cite{yang2022ci8}. However, this premise rarely holds true in complex, dynamic, and open-world environments where unforeseen circumstances, sensor noise, adversarial attacks, or simply novel data points are inevitable \\cite{zisselman2020cmx, chen2020mbk, morningstar2020re9, guerin202201y, schmidt2024syr, vishwakarma2024z1m}. When this closed-world assumption is violated, conventional models often produce high-confidence, yet incorrect, predictions for OOD samples \\cite{song2022f5d, yu2022egq, ammar2023pr1, bitterwolf2022rw0, lu2024j0n}. This unwarranted overconfidence is a critical vulnerability that OOD detection aims to mitigate, providing a crucial safety mechanism to prevent models from making decisions outside their learned competence.\n\nFurthermore, the very nature of OOD data can be complex and multifaceted, posing additional challenges to reliable detection. It is not always a simple binary distinction between \"known\" and \"unknown.\" For instance, models can learn spurious correlations from their training data, leading them to confidently classify OOD inputs that share these irrelevant features as in-distribution, making such \"spurious OOD\" particularly difficult to detect \\cite{ming2021wu7}. This highlights that a robust OOD detector must not only identify entirely novel semantic concepts but also be resilient to subtle shifts or misleading cues. Moreover, the definition of what constitutes \"OOD\" can even be model-specific, depending on whether a particular input leads to a misclassification for a given deployed model, rather than a universal distributional shift \\cite{averly20239rv}. These nuances underscore the need for sophisticated and context-aware OOD detection mechanisms.\n\nThe practical deployment of AI systems further amplifies the need for robust OOD detection. Beyond theoretical performance, real-world systems require OOD detectors that are not only accurate but also provide reliable guarantees and manage false positives effectively. High false positive rates (FPR), where legitimate in-distribution samples are incorrectly flagged as OOD, can lead to user frustration, unnecessary human intervention, and a breakdown of trust in the system \\cite{vishwakarma2024z1m}. Therefore, the development of OOD detection is intrinsically linked to the broader goal of building AI systems that are transparent about their limitations, can abstain from making potentially harmful decisions when faced with unfamiliar situations, and can operate predictably and safely in dynamic environments.\n\nIn summary, the motivation for robust OOD detection is deeply rooted in the urgent need to transition AI from research curiosities to reliably deployed systems that operate safely and responsibly in the real world. It is not merely about identifying novelty but about ensuring that AI systems are aware of their limitations, can express appropriate uncertainty, and can defer to human oversight or alternative safe actions when confronted with inputs beyond their learned experience. OOD detection, therefore, stands as a pivotal step towards enabling the responsible and reliable deployment of AI in complex, open-world environments, where unforeseen circumstances are not exceptions but inevitable realities. Continued research in this area is essential to bridge the gap between theoretical capabilities and the practical demands of trustworthy AI.\n\n\n\\label{sec:foundational_concepts_and_early_post-hoc_methods}\n\n\\section{Foundational Concepts and Early Post-Hoc Methods}\n\\label{sec:foundational\\_concepts\\_\\_and\\_\\_early\\_post-hoc\\_methods}\n\n\\subsection{Uncertainty Quantification in Neural Networks}\n\\label{sec:2\\_1\\_uncertainty\\_quantification\\_in\\_neural\\_networks}\n\nConventional neural networks, while achieving remarkable performance in complex classification tasks, are fundamentally designed to assign inputs to a fixed set of predefined classes rather than to explicitly quantify the uncertainty inherent in their predictions. Nevertheless, these classifiers offer implicit signals of confidence primarily through softmax probabilities and the entropy of the predicted class distribution. These metrics serve as initial, easily accessible indicators of a model's belief. A critical understanding of their foundational role and, more importantly, their profound limitations is indispensable for appreciating the subsequent evolution of Out-of-Distribution (OOD) detection methodologies that strive for truly calibrated uncertainty estimates.\n\nA seminal contribution by \\cite{Hendrycks\\_G\\_2017} formalized the use of Maximum Softmax Probability (MSP) as a straightforward baseline for identifying both misclassified in-distribution (ID) and OOD examples. This work, alongside others, critically exposed a pervasive and dangerous flaw: neural networks frequently exhibit severe overconfidence, assigning high softmax probabilities to OOD inputs. This leads to erroneous high-confidence predictions that are fundamentally unreliable, as the model confidently asserts an input belongs to a known class despite having never encountered anything similar during training. The root cause of this overconfidence lies in the very design of the softmax function. As \\cite{Kendall\\_A\\_2017} elucidates, softmax is inherently a normalized probability distribution over a fixed set of \\textit{known} classes. It is optimized to express the model's certainty about which of the \\textit{trained} categories an input belongs to (reflecting \\textit{aleatoric uncertainty} due to inherent data noise), but it is ill-equipped to capture \\textit{epistemic uncertainty}â€”the model's lack of knowledge or confidence when confronted with inputs far removed from its training distribution. Consequently, an OOD input, by definition, falls outside the model's learned domain, yet the softmax mechanism forces it into one of the known categories, often with high confidence, simply by finding the \"closest\" match within its learned manifold.\n\nBeyond this conceptual mismatch, modern deep neural networks are frequently poorly calibrated \\cite{Guo\\_C\\_2017}. This means their predicted probabilities do not accurately reflect the true likelihood of correctness, exacerbating the overconfidence problem, particularly for OOD inputs. The architectural choices prevalent in deep learning, such as increased depth, ReLU activations, and optimization for accuracy rather than calibration, contribute to this miscalibration. When a model's confidence scores are unreliable even for ID data, their utility for discerning OOD samples becomes severely compromised. Furthermore, the issue of overconfidence is significantly compounded by the model's reliance on spurious correlations present in the training data. As \\cite{ming2021wu7} rigorously demonstrated, models trained on datasets containing statistically informative but non-causal features tend to exploit these shortcuts. When an OOD input shares these spurious features with ID data, the model can confidently assign a high softmax probability, even if the input lacks the invariant, semantic features crucial for correct classification. This reliance on misleading environmental cues makes distinguishing spurious OOD samples from ID data inherently challenging, as the model's confidence is rooted in a superficial correlation rather than true semantic understanding \\cite{ming2021wu7}.\n\nEmpirical and theoretical studies consistently underscore the inadequacy of raw softmax and entropy scores for robust OOD detection. \\cite{kuan2022qzl} provided extensive evidence that simple prediction-based methods like MSP and entropy are reliably outperformed by methods leveraging learned intermediate representations (embeddings). Their work challenged the notion of MSP as a universally strong baseline, demonstrating that while it might offer some rudimentary signal, it often falls short compared to approaches that analyze the internal feature space, which are better equipped to capture deviations from the ID manifold. This empirical observation is theoretically grounded by \\cite{peng20243ji}, who critically analyzed logit-based methods, including those derived from softmax. They explained that these methods are often not directly proportional to true data density. This fundamental disconnect implies that even when a model's logits are high, the resulting softmax probability does not necessarily reflect a high likelihood under the true in-distribution data manifold, leading to suboptimal OOD detection performance. Similarly, \\cite{averly20239rv}'s comprehensive evaluation, while introducing a model-specific perspective, implicitly highlights the context-dependent and often inconsistent performance of MSP across different types of OOD shifts (e.g., semantic vs. covariate) and misclassifications, reinforcing its limitations as a standalone, universally reliable uncertainty measure.\n\nIn summary, while softmax probabilities and entropy offer initial, easily accessible indicators of a neural network's confidence, their inherent limitations are profound and multifaceted. These include their inability to capture epistemic uncertainty due to their closed-set design, the pervasive problem of miscalibration in modern deep networks, and their vulnerability to spurious correlations in training data. These shortcomings collectively render raw output-based uncertainty estimates unreliable for robust OOD detection, particularly in safety-critical applications where silent failures can have severe consequences. This fundamental inadequacy necessitates the development of more sophisticated OOD detection methodologies that move beyond simple output scores, paving the way for the advanced post-hoc, feature-space, generative, and training-time strategies discussed in subsequent sections of this review.\n\\subsection{Post-Hoc Confidence-Based Detection}\n\\label{sec:2\\_2\\_post-hoc\\_confidence-based\\_detection}\n\nThe development of robust out-of-distribution (OOD) detection methods is paramount for ensuring the reliability and safety of machine learning systems in real-world applications. Early and highly influential research in this domain focused on leveraging and refining confidence scores derived from pre-trained discriminative classifiers. These \"post-hoc\" methods are particularly attractive due to their efficiency, as they do not require any model retraining or modification of the original classification objective, thereby minimizing computational overhead and preserving the model's primary task performance. This section details the evolution of such confidence-based approaches, from foundational baselines to sophisticated enhancements.\n\nA seminal contribution to this field was the introduction of Maximum Softmax Probability (MSP) as a baseline for OOD detection by \\cite{hendrycks17baseline}. This straightforward yet surprisingly effective method operates on the premise that a well-trained classifier should assign a high maximum softmax probability to in-distribution (ID) samples, reflecting strong confidence in its classification. Conversely, OOD samples, which do not align with any learned class, are expected to yield lower maximum probabilities. Despite its simplicity, MSP established a crucial benchmark, demonstrating that standard neural network outputs inherently contain valuable uncertainty signals. The work also played a pivotal role in standardizing evaluation protocols and datasets, fostering more rigorous comparisons across diverse OOD detection techniques. However, a significant limitation of MSP is the pervasive problem of neural network overconfidence on OOD inputs \\cite{community\\_0, community\\_5}. Models can often assign spuriously high confidence to novel, unseen data, especially for \"near OOD\" examples that share superficial similarities with ID data, leading to suboptimal discrimination and false negatives. This fundamental challenge highlights that raw softmax probabilities, while indicative, are not always reliable estimators of true data density or typicality \\cite{peng20243ji}.\n\nBuilding upon the insights from MSP, \\cite{Liang\\_etal\\_2018} introduced Out-of-Distribution Detector for Neural Networks (ODIN), a method designed to significantly amplify the distinction between ID and OOD samples without requiring any model retraining. ODIN introduced two key innovations. First, it incorporated temperature scaling, a technique originally used for model calibration, which smooths the softmax distribution by dividing the logits by a temperature parameter $T$. This adjustment makes the confidence scores less extreme and often more discriminative for OOD detection by re-calibrating the output probabilities. Second, and more crucially, ODIN proposed a small, carefully crafted input perturbation. This perturbation is calculated to push the input towards the direction that maximizes the softmax probability for the predicted class. For ID samples, this makes them \"more ID-like\" in the model's perception, increasing their confidence. For OOD samples, which lack a strong alignment with any ID class, this perturbation often fails to significantly boost confidence or may even push them towards lower confidence, thereby increasing the separation in confidence scores between ID and OOD data. By combining these two simple yet powerful post-hoc techniques, ODIN substantially boosted OOD detection performance over MSP, establishing a strong, efficient baseline.\n\nFurther refining the ODIN paradigm, \\cite{Hsu\\_Y\\_2020} proposed Generalized ODIN (G-ODIN), which aimed to improve robustness by addressing a potential weakness in ODIN's perturbation strategy. While ODIN perturbs inputs to maximize confidence for the \\textit{predicted} class, G-ODIN considers a broader context. Instead of relying on a single predicted class, G-ODIN perturbs the input towards the direction that minimizes the maximum softmax probability across \\textit{all} ID classes. This approach makes the OOD score more robust by ensuring that an OOD sample is not mistakenly pushed to high confidence for an incorrect ID class. By considering the full set of ID classes during perturbation, G-ODIN can achieve better discrimination, especially when OOD samples might be ambiguous or share features with multiple ID categories.\n\nThe concept of temperature scaling, a cornerstone of ODIN, has continued to evolve. Recognizing that a fixed global temperature might not be optimal for all samples, \\cite{krumpl2024n1w} introduced Adaptive Temperature Scaling (ATS). ATS proposes dynamically calculating a \\textit{sample-specific} temperature value based on activations from intermediate layers of the neural network. By fusing this sample-specific adjustment with class-dependent logits, ATS captures additional statistical information that might otherwise be lost in the feature extraction process. This dynamic approach leads to a more robust and powerful OOD detection method, demonstrating that even subtle refinements to temperature scaling can significantly enhance the performance and robustness of existing logit-based OOD detection techniques.\n\nWhile highly effective and efficient, these confidence-based methods fundamentally rely on the assumption that the classifier's output space (logits or softmax probabilities) can reliably distinguish between ID and OOD data. However, as highlighted by \\cite{peng20243ji}, raw logit-based scores, including energy scores (which are closely related to logits), often make implicit assumptions about the underlying data distribution, such as constant partition functions across classes, or that softmax probabilities directly represent true data densities. These assumptions are not always accurate, limiting the theoretical grounding and empirical robustness of simpler confidence scores. To address this, \\cite{peng20243ji} proposed ConjNorm, a novel theoretical framework grounded in Bregman divergence, which unifies density function design for OOD detection within the exponential family of distributions. By devising an unbiased and analytically tractable estimator for the partition function using importance sampling, ConjNorm offers a more principled and flexible approach to density estimation for OOD scoring, moving beyond restrictive distributional assumptions and leading to superior empirical performance. This work signifies a critical advancement towards more theoretically robust confidence-based OOD measures.\n\nIn summary, post-hoc confidence-based detection methods, starting from the simplicity of MSP and progressing through the innovative enhancements of ODIN, G-ODIN, and ATS, have laid a robust foundation for the field. They collectively demonstrated that significant improvements in uncertainty quantification could be achieved by cleverly leveraging and refining the outputs of existing pre-trained classifiers without the need for costly retraining. However, their inherent reliance on the classifier's output space and the potential for overconfidence or inaccurate density estimation remain persistent challenges. These limitations motivate the exploration of richer, intermediate representations and more theoretically grounded approaches to OOD detection, which are discussed in subsequent sections.\n\\subsection{Feature-Space Distance-Based Methods}\n\\label{sec:2\\_3\\_feature-space\\_distance-based\\_methods}\n\nEarly efforts in out-of-distribution (OOD) detection quickly recognized the inherent limitations of relying solely on a neural network's final output probabilities, such as Maximum Softmax Probability (MSP). While simple, MSP often fails to capture the true uncertainty for samples significantly deviating from the in-distribution (ID) manifold, frequently exhibiting overconfidence on novel inputs. This critical observation spurred a shift towards leveraging the internal feature representations of neural networks, driven by the hypothesis that OOD samples would manifest as distinct patterns or lie significantly distant from the ID data within these learned embedding spaces.\n\nA foundational exploration into using internal representations for OOD detection was presented by \\cite{Hendrycks\\_G\\_2017}. While this work primarily established MSP as a baseline, it also investigated the efficacy of Mahalanobis distance computed on features from intermediate layers. By modeling the distribution of ID features for each class as a simple Gaussian, OOD samples could be identified as those with a large Mahalanobis distance to all ID class centroids. This early insight highlighted the potential of feature-level analysis to provide more robust OOD scores than simple output probabilities, laying crucial groundwork.\n\nBuilding upon this concept, \\cite{Lee\\_K\\_2018} introduced a more comprehensive framework that explicitly leverages Mahalanobis distance in the feature space for OOD detection. This method models the in-distribution feature representations for each class using class-conditional Gaussian distributions, where the mean and covariance are estimated from the training data. An input is then classified as OOD if its Mahalanobis distance to all ID class centroids is sufficiently large. Crucially, \\cite{Lee\\_K\\_2018} also proposed using generative adversarial networks (GANs) to regularize the feature space during training. By training a GAN to generate OOD samples and then using these to push OOD representations away from ID clusters, the feature space becomes more discriminative, enhancing the separation between ID and OOD samples and making the Mahalanobis distance a more effective OOD score. This approach demonstrated a significant advancement by actively shaping the feature space to be more amenable for OOD discrimination, moving beyond merely observing existing features.\n\nDespite its principled nature, the effectiveness of Mahalanobis distance-based methods can be limited by the strong assumption of Gaussianity for ID features and the quality of the learned features, particularly in high-dimensional spaces where the \"curse of dimensionality\" can render distance metrics less meaningful \\cite{ghosal2023q20}. This motivated further research into refining the feature space and the distance calculations themselves. For instance, \\cite{anthony2023slf} conducted an in-depth analysis of Mahalanobis distance for medical imaging OOD detection, challenging the common assumption of a single optimal layer for detection. They empirically demonstrated that the optimal network depth for OOD detection is highly dependent on the specific OOD pattern and proposed a Multi-branch Mahalanobis (MBM) framework. MBM employs multiple OOD detectors operating at different depths of the network, each combining normalized Mahalanobis scores from its constituent modules, significantly enhancing robustness by capturing diverse OOD signals across the feature hierarchy.\n\nTo mitigate the curse of dimensionality and improve feature space utility, researchers have explored learning more structured and compact representations. \\cite{zaeemzadeh2021lmh} proposed training deep neural networks to embed ID samples onto a union of 1-dimensional subspaces. This compact representation ensures that OOD samples are less likely to occupy the same region as known classes, and robust representatives (singular vectors) can be used for distance calculations, thereby simplifying OOD detection. Similarly, \\cite{ghosal2023q20} introduced Subspace Nearest Neighbor (SNN), a framework that regularizes the model and its feature representation by leveraging the most relevant subset of dimensions. This subspace learning yields highly distinguishable distance measures between ID and OOD data, demonstrating significant improvements over previous distance-based methods by making the distances more robust to high-dimensional noise. Extending this, \\cite{li2025jdt} proposed a novel \"tangent distance\" that explicitly accounts for the data structure by mapping high-dimensional features to the manifold of ID samples. This method computes the Euclidean distance between samples and the nearest submanifold space (a linear approximation of the local region on the manifold), providing a more meaningful distance measure that is less sensitive to the curse of dimensionality.\n\nBeyond Mahalanobis and its direct refinements, other distance-based approaches leverage different metrics or modeling assumptions. K-Nearest Neighbors (KNN) based methods, for example, directly quantify OODness by measuring the distance of a test sample to its $k$-nearest neighbors within the ID training data's feature space, offering a non-parametric alternative to Gaussian models. In a more modern context, \\cite{vojivr202444c} introduced PixOOD for pixel-level OOD detection, which, while operating at a finer granularity, fundamentally relies on distances. It extracts pixel/patch feature representations and builds a 2D projection space where distances to multiple class etalons (learned prototypes) are used to model complex intra-class variability and identify OOD pixels. This demonstrates how distance-based principles can be adapted for fine-grained OOD detection by modeling ID distributions with multiple prototypes rather than a single centroid.\n\nIn summary, feature-space distance-based methods represent a crucial evolution in OOD detection, moving beyond simple output probabilities to leverage the richer information in internal representations. They have progressed from initial explorations of Mahalanobis distance on existing features to sophisticated techniques that actively regularize, learn, or project OOD-discriminative feature spaces. While these methods have shown promise in quantifying an input's deviation from the in-distribution manifold, challenges persist, including the sensitivity to the quality of learned features, the computational cost associated with training-time regularization, and the inherent difficulties of distance metrics in high-dimensional spaces. Future directions include developing more flexible models for feature distributions (e.g., non-parametric density estimation or advanced mixture models), integrating self-supervised learning to learn more robust features, and exploring adaptive distance metrics that can better capture complex manifold structures. Furthermore, the utility of these distance-based OOD scores is increasingly recognized in broader uncertainty quantification frameworks, such as their application as non-conformity scores within Conformal Prediction to provide statistically rigorous guarantees on OOD detection performance \\cite{novello2024yco}.\n\n\n\\label{sec:generative_and_reconstruction-based_approaches}\n\n\\section{Generative and Reconstruction-Based Approaches}\n\\label{sec:generative\\_\\_and\\_\\_reconstruction-based\\_approaches}\n\n\\subsection{Likelihood-Based Deep Generative Models}\n\\label{sec:3\\_1\\_likelihood-based\\_deep\\_generative\\_models}\n\nThe detection of Out-of-Distribution (OOD) samples is a critical challenge for deploying reliable deep learning systems. A theoretically principled approach to OOD detection involves leveraging deep generative models to learn the underlying data distribution of in-distribution (ID) samples. The fundamental premise is that samples originating from outside this learned distribution, i.e., OOD samples, should exhibit a significantly lower likelihood or probability density under the model trained exclusively on ID data. This allows for their identification based on their deviation from the learned ID manifold, offering a theoretically grounded method for uncertainty quantification. Early methods primarily explored Variational Autoencoders (VAEs) \\cite{Kingma\\_Welling\\_2013} and Generative Adversarial Networks (GANs) \\cite{Goodfellow\\_etal\\_2014} for this purpose. VAEs provide an estimate of the data log-likelihood (or a lower bound, ELBO), while GANs can be adapted to provide density estimates or use discriminator scores as proxies for typicality.\n\nInitially, the intuitive strategy was to directly use the raw likelihood or a related reconstruction error from a trained generative model as an OOD score. However, this straightforward application often proved problematic. Raw likelihood scores from deep generative models can be inherently misleading, frequently assigning higher likelihoods to certain OOD samples than to some ID samples \\cite{Nalisnick\\_etal\\_2019\\_Do\\_Deep\\_Generative\\_Models\\_Know\\_What\\_They\\_Don\\_t\\_Know}. This counter-intuitive phenomenon, observed across various model architectures and datasets, stems from several factors. Deep generative models, particularly in high-dimensional spaces, may learn spurious low-level correlations or assign high probabilities to simple, out-of-distribution inputs that lie in regions of the input space not well-constrained by the ID data. This can be exacerbated by the \"Gaussian Annulus Theorem,\" where in high dimensions, the typical set of data (where most of the probability mass lies) may not intersect with the region of highest density, leading to OOD samples with high likelihood but low typicality \\cite{morningstar2020re9}. For VAEs, the Evidence Lower Bound (ELBO) is only a lower bound to the true log-likelihood, and a tighter bound does not necessarily correlate with better OOD detection performance. Even models capable of exact likelihood estimation, such as Normalizing Flows (NFs) \\cite{Dinh\\_etal\\_2016} and Autoregressive models (e.g., PixelCNNs), suffer from this issue, often assigning higher likelihoods to less complex OOD images than to complex ID images, further demonstrating that raw likelihood alone is an unreliable indicator of semantic OODness \\cite{osada20246an}.\n\nTo address the unreliability of raw likelihood scores, more robust statistical measures were introduced, marking an evolution from simple density estimation to more refined statistical tests. A pivotal advancement was proposed by \\cite{Ren\\_J\\_2019}, who demonstrated that comparing the likelihood of a sample under the learned ID distribution to its likelihood under a simpler, \"null\" model provides a significantly more effective OOD score. Their work introduced the concept of likelihood ratio tests for OOD detection, where the ratio of the likelihood under a complex ID generative model (e.g., VAE or GAN) to that under a baseline model (e.g., a simple Gaussian distribution or a model trained on diverse OOD data) serves as a robust discriminator. This approach effectively normalizes the raw likelihood, focusing on how \\textit{much better} the ID model explains the data compared to a general or OOD model, thereby improving OOD discrimination and mitigating the issues associated with misleading raw likelihood values.\n\nBeyond simple likelihood ratios, other sophisticated statistical approaches have emerged to leverage generative models more effectively. \\cite{morningstar2020re9} introduced Density of States Estimation (DoSE), an unsupervised method that moves beyond direct model probabilities. Inspired by statistical physics, DoSE evaluates the \"typicality\" of an input by analyzing multiple summary statistics (e.g., negative log-likelihood, L2 norm of latent features) derived from a pre-trained generative model. Instead of directly comparing likelihoods, DoSE trains non-parametric density estimators (like Kernel Density Estimation or one-class SVMs) on the distribution of these statistics for ID data. An OOD sample is then identified if its derived statistics are atypical under these learned distributions, providing a more robust measure of OODness that accounts for the high-dimensional nature of the problem and the shortcomings of raw likelihood.\n\nFurthermore, Normalizing Flows, which provide exact and tractable likelihoods, have seen increasing application in OOD detection, often by modeling densities in feature spaces rather than raw pixel space. For instance, \\cite{zisselman2020cmx} proposed Deep Residual Flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution, improving OOD detection by modeling feature activations. Similarly, \\cite{cook2024hyb} investigated feature density estimation via Normalizing Flows as a fully unsupervised, post-hoc method. By training a lightweight NF model on the feature representations of a pre-trained classifier, they demonstrated strong results for far-OOD detection, highlighting that while raw input likelihoods can be problematic, density estimation in a more semantically meaningful feature space can be highly effective.\n\nThe evolution from simple density estimation to more refined statistical measures like likelihood ratio tests and typicality-based approaches, coupled with the broader application of diverse generative architectures like Normalizing Flows, marks a significant progression in the field. While likelihood-based methods offer a theoretically grounded approach to OOD detection, challenges persist in accurately modeling complex, high-dimensional data distributions and ensuring that likelihood estimates genuinely correlate with semantic OODness across diverse scenarios. Future work continues to explore more robust generative architectures, improved background models for ratio tests, and sophisticated statistical tests to further bridge the gap between theoretical soundness and practical efficacy in real-world OOD detection tasks.\n\\subsection{Reconstruction Autoencoders: Advancements and Limitations}\n\\label{sec:3\\_2\\_reconstruction\\_autoencoders:\\_advancements\\_\\_and\\_\\_limitations}\n\nTraditional reconstruction autoencoders (AEs) were initially considered a promising avenue for Out-of-Distribution (OOD) detection, operating under the intuitive assumption that models trained exclusively on in-distribution (ID) data would struggle to reconstruct novel OOD inputs, leading to higher reconstruction errors. However, this foundational premise frequently faltered due to a fundamental design paradox: the inherent capacity of deep autoencoders to generalize and effectively reconstruct diverse novel inputs \\cite{Ren\\_etal\\_2019}. This powerful generalization, while beneficial for tasks like denoising or data compression, often meant that OOD samples yielded reconstruction errors comparable to, or even lower than, ID samples \\cite{morningstar2020re9}. Consequently, the simple reconstruction error proved to be an unreliable metric for distinguishing ID from OOD data, severely limiting the practical utility of early AE-based methods in safety-critical applications. This critical limitation necessitated a significant re-evaluation and sophisticated re-engineering of their underlying principles to transform them into reliable OOD detectors.\n\nEarly attempts to leverage reconstruction error for OOD detection, including simpler methods like Principal Component Analysis (PCA) for dimensionality reduction and subsequent reconstruction, often faced this challenge \\cite{guan2023dwv}. The core problem was designing autoencoders that could learn a sufficiently tight manifold of ID data without inadvertently developing the capacity to reconstruct novel patterns. This challenge spurred significant advancements that fundamentally rethought the autoencoder's objective and architecture, moving beyond raw pixel reconstruction and simple L2 error.\n\nOne pivotal advancement has been the shift from pixel-level reconstruction to \\textit{semantic feature reconstruction}. Reconstructing raw pixels demands high expressiveness from the autoencoder, which can inadvertently generalize to OOD inputs. Instead, modern approaches often focus on reconstructing robust, high-level features extracted from pre-trained models. This strategy aligns with broader trends in OOD detection that leverage discriminative feature spaces \\cite{Lee\\_etal\\_2018}. For instance, \\cite{zhou202250i} exemplifies this by reconstructing Activation Vectors (AVs) from the penultimate layer of a pre-trained classifier. This strategic shift simplifies the autoencoder's task to lower-dimensional, semantically relevant features, ensuring that the autoencoder's learning is concentrated on the abstract, task-specific characteristics of ID data. Deviations in reconstructing these semantic features are thus more indicative of OODness than pixel-level discrepancies, which might be influenced by superficial similarities.\n\nConcurrently, to prevent the latent space from accommodating novel patterns, methods have increasingly enforced a \\textit{maximally compressed or regularized latent space} for ID samples. This is achieved through regularization losses during training that actively restrict ID latent features to a compact, known domain. Variational Autoencoders (VAEs), a class of generative models that learn a latent distribution, inherently aim for a more structured latent space, which can be leveraged for OOD detection. For example, \\cite{cai2020lsi} integrates VAEs into an Inductive Conformal Anomaly Detection (ICAD) framework for real-time OOD detection in cyber-physical systems. Here, the VAE's ability to reconstruct ID data from its learned latent space, combined with Deep Support Vector Data Description (SVDD) for learning a minimum-volume hypersphere, effectively enforces a tight ID manifold. Similarly, \\cite{60108b8e0d7204fa33f686b09128c7fc8489a224} explores the use of self-attention within VAEs to learn more discriminative and compact latent representations specifically for anomaly detection. \\cite{zhou202250i} also enforces this explicit constraint, ensuring that any input whose latent representation falls outside this tightly defined space is likely OOD. This contrasts sharply with earlier autoencoders that allowed latent spaces to form organically, often encompassing regions where OOD samples could reside without significant reconstruction penalty.\n\nFurthermore, to address the challenge of recovering significant information from an extremely compressed latent space in a single step, \\cite{zhou202250i} proposes a novel \\textit{layerwise decomposition for incremental information recovery}. This \"data certainty decomposition\" framework factorizes the probability of an input being ID into a product of conditional probabilities, employing a series of decoders. Each decoder is specifically designed to recover information lost after \\textit{each individual encoding layer}, rather than a single decoder attempting to recover all accumulated loss from the final, most compressed latent representation. This incremental recovery mechanism enhances the autoencoder's ability to faithfully reconstruct ID samples while remaining highly sensitive to OOD deviations at various levels of abstraction.\n\nFinally, to overcome the issue of standard L2 reconstruction error being an unreliable uncertainty measure (often yielding misleadingly small errors for OOD samples due to smaller activation magnitudes), \\cite{zhou202250i} introduces the \\textit{Normalized L2 Distance (NL2)}. This novel metric normalizes the reconstruction by the input's norm, effectively eliminating the confounding influence of feature magnitude and providing a more robust and reliable measure of reconstruction accuracy. The need for more robust scoring functions for reconstruction error is also echoed in works like \\cite{guan2023dwv}, which demonstrates that even a simple regularized PCA-based reconstruction error can significantly improve OOD detection when fused with other scoring functions, highlighting that raw reconstruction error often requires refinement or combination to be effective. These collective innovations directly address the traditional flaws of reconstruction autoencoders, transforming them into more reliable OOD detectors by ensuring that reconstruction error truly reflects OODness rather than merely the model's generalization capacity.\n\nWhile these advancements, exemplified by works like \\cite{zhou202250i} and \\cite{cai2020lsi}, significantly revitalize reconstruction autoencoders for OOD detection, inherent challenges persist. The reliance on a pre-trained classifier for extracting Activation Vectors, as in \\cite{zhou202250i}, means the method's effectiveness is intrinsically tied to the quality, robustness, and potential biases of that classifier. If the feature extractor itself is not robust to certain distribution shifts, the OOD detector built upon it will inherit these limitations. Furthermore, defining what constitutes a \"maximally compressed\" latent space and ensuring its boundaries are sufficiently robust to all possible ID variations, while still being tight enough to reject all OOD, remains an intricate balance. Overly restrictive latent spaces might misclassify complex ID samples as OOD, while overly permissive ones risk the original generalization problem. The computational overhead introduced by multi-decoder architectures and complex regularization also needs consideration for real-time applications, particularly in resource-constrained environments like those discussed in \\cite{cai2020lsi}. Future research could explore adaptive mechanisms for latent space compression, investigate more sophisticated theoretical frameworks for quantifying the \"OODness\" reflected by reconstruction errors in highly complex, high-dimensional data, and develop more robust and adaptive thresholding strategies for reconstruction-based scores, potentially incorporating fusion with other OOD signals as suggested by \\cite{guan2023dwv}.\n\\subsection{Energy-Based Models for OOD Detection}\n\\label{sec:3\\_3\\_energy-based\\_models\\_for\\_ood\\_detection}\n\nEnergy-Based Models (EBMs) have emerged as a theoretically principled and increasingly effective framework for Out-of-Distribution (OOD) detection, offering a direct approach to modeling the underlying data distribution. At their core, EBMs define a probability distribution over inputs $x$ using an energy function $E(x)$ as $p(x) = \\frac{\\exp(-E(x))}{Z}$, where $Z = \\int \\exp(-E(x)) dx$ is the intractable partition function \\cite{Grathwohl\\_etal\\_2019}. In this paradigm, in-distribution (ID) samples are characterized by low energy values, indicating high likelihood under the learned distribution, while OOD samples are assigned high energy values, signifying low likelihood. This direct modeling of data likelihood provides a more interpretable and robust measure of OODness compared to relying on proxy metrics like maximum softmax probabilities, which often exhibit overconfidence on OOD inputs \\cite{Liu\\_etal\\_2020}.\n\nA foundational insight into the connection between classifiers and EBMs was provided by \\textcite{Grathwohl\\_etal\\_2019}, who demonstrated that a standard classifier's output logits can be interpreted as an unnormalized negative energy function. This perspective paved the way for explicitly leveraging energy functions for OOD detection. Building on this, \\textcite{Liu\\_etal\\_2020} pioneered the use of Energy-based Models for OOD detection by defining the energy function directly from the output logits of a standard neural network classifier. Their significant contribution lay in developing specialized training objectives to explicitly learn these energy landscapes. This typically involves a contrastive learning approach, where the model is trained to push the energy of ID samples to be low while simultaneously increasing the energy of OOD samples. The challenge of the intractable partition function $Z$ is often circumvented during training by employing techniques like Stochastic Gradient Langevin Dynamics (SGLD) to sample from the model's distribution and approximate gradients, effectively optimizing the unnormalized density ratio rather than the absolute density \\cite{Liu\\_etal\\_2020, lafon2023w37}. This direct optimization for OOD discrimination offers a more theoretically grounded and robust measure than post-hoc methods.\n\nWhile many EBM approaches implicitly handle the intractable partition function through contrastive learning and sampling, \\textcite{peng20243ji} directly addresses this challenge by proposing ConjNorm, a method for tractable density estimation for post-hoc OOD detection. Their work introduces a novel theoretical framework grounded in Bregman divergence, extending density considerations to the exponential family of distributions. Crucially, ConjNorm devises an unbiased and analytically tractable estimator for the partition function using a Monte Carlo-based importance sampling technique, providing a principled way to estimate true data density without strong distributional assumptions. This represents a significant advancement by offering a direct solution to a core theoretical hurdle in EBMs.\n\nSubsequent research has explored diverse strategies to enhance EBMs for OOD detection. \\textcite{lafon2023w37} introduced HEAT (Hybrid Energy Based Model in the Feature Space), a novel post-hoc method that refines existing OOD detectors (e.g., GMMs, energy logits) by complementing them with a data-driven residual EBM. HEAT uses the EBM framework to compose several energy terms from different refined priors, allowing for accurate and robust ID density estimation without requiring external OOD samples for training. This demonstrates how EBMs can be integrated to correct biases and enhance the expressiveness of other OOD scoring functions.\n\nFurthermore, EBMs have been adapted to address specific challenges in OOD detection. \\textcite{choi202367m} proposed a \"balanced energy regularization loss\" to tackle the problem of imbalanced auxiliary OOD data, which is often overlooked in methods like Outlier Exposure. Their approach adaptively applies larger regularization to auxiliary samples from majority classes, ensuring a more effective energy landscape shaping. Similarly, in the context of Class-Incremental Learning (CIL), \\textcite{miao20246mk} introduced Bi-directional Energy Regularization (BER). BER mitigates biases in CIL models by using energy loss functions to enlarge decision boundaries for new classes (pushing OOD away) and boost confidence for old classes (preventing old ID from being misclassified as OOD), showcasing EBMs' utility in dynamic learning environments.\n\nBeyond direct energy minimization, energy functions can also guide adaptive training. \\textcite{hofmann2024gnx} introduced Hopfield Boosting, an OOD detection framework that leverages Modern Hopfield Energy (MHE) to adaptively sample \"weak learners\" from auxiliary outlier datasets that are hard to distinguish from ID data. By incorporating an MHE-based energy function into the training loss, this method explicitly sharpens the decision boundary between ID and OOD data, demonstrating a sophisticated use of energy to improve outlier exposure strategies.\n\nThe scalability of EBMs to modern deep learning architectures has also been a focus. \\textcite{Ming\\_etal\\_2023} extended the EBM framework by demonstrating how to effectively fine-tune large pre-trained models, such as vision transformers, for energy-based OOD detection. This approach leverages the rich, generalizable representations learned by these powerful models, addressing the challenge of robust OOD detection in complex, high-dimensional data settings and highlighting the adaptability of the EBM paradigm.\n\nIn summary, EBMs provide a theoretically sound framework for OOD detection by directly modeling data likelihood through an energy function. The evolution of EBMs for OOD detection has progressed from foundational insights into their connection with classifiers \\cite{Grathwohl\\_etal\\_2019} and pioneering contrastive training strategies \\cite{Liu\\_etal\\_2020}, to more sophisticated approaches that directly address the partition function intractability \\cite{peng20243ji}, integrate with and refine other OOD methods \\cite{lafon2023w37}, adapt to specific learning challenges like imbalanced OOD data or incremental learning \\cite{choi202367m, miao20246mk}, and leverage energy functions for adaptive training \\cite{hofmann2024gnx}. Their ability to integrate with large pre-trained models further underscores their potential for robust OOD detection in real-world applications \\cite{Ming\\_etal\\_2023}.\n\nFuture research in EBMs for OOD detection could explore more advanced techniques for approximating or tractably estimating the partition function in complex, high-dimensional settings, potentially drawing from advancements in score-matching or normalizing flows. Investigating adaptive energy functions that can dynamically adjust to different types of OOD shifts or domain contexts, perhaps through hypernetworks, could also yield more versatile detectors. Furthermore, exploring the interplay between EBMs and generative modeling to synthesize highly informative OOD examples for contrastive training, or to learn more expressive energy landscapes, remains a promising avenue.\n\n\n\\label{sec:training-time_strategies_and_robust_representation_learning}\n\n\\section{Training-Time Strategies and Robust Representation Learning}\n\\label{sec:training-time\\_strategies\\_\\_and\\_\\_robust\\_representation\\_learning}\n\n\\subsection{Outlier Exposure and Virtual Outlier Synthesis}\n\\label{sec:4\\_1\\_outlier\\_exposure\\_\\_and\\_\\_virtual\\_outlier\\_synthesis}\n\nThe challenge of deploying deep learning models in open-world environments necessitates robust mechanisms for identifying Out-of-Distribution (OOD) inputs. A significant advancement in this area is the Outlier Exposure (OE) paradigm, where auxiliary OOD data is incorporated during model training to explicitly teach the model to distinguish novel inputs. This approach often frames OOD detection as a binary classification task, differentiating between in-distribution (ID) and OOD data.\n\nThe theoretical underpinnings of OE suggest that many methods leveraging OOD training data are asymptotically equivalent to a binary discriminator, with practical differences often stemming from estimation procedures and the specific choice of auxiliary OOD data \\cite{bitterwolf2022rw0}. Early implementations of OE demonstrated its effectiveness, but subsequent research has focused on refining its application and addressing inherent limitations. For instance, \\cite{choi202367m} identified that auxiliary OOD data often exhibits class imbalance, proposing a balanced energy regularization loss to apply stronger regularization to majority OOD classes, thereby enhancing detection performance in diverse tasks like semantic segmentation and long-tailed classification. Addressing the vulnerability of OE to adversarial attacks, \\cite{chen2020mbk} introduced Adversarial Learning with inlier and Outlier Exposure (ALOE), which robustifies detectors by training against both adversarial in-distribution and OOD examples, significantly improving robustness against perturbations.\n\nAs OE matured, its application extended to more complex scenarios. In long-tailed recognition, where distinguishing OOD from tail classes is particularly challenging, \\cite{miao2023brn} proposed Calibrated Outlier Class Learning (COCL). This method uses debiased large margin learning and outlier-class-aware logit calibration to explicitly separate OOD samples from both head and tail ID classes, outperforming traditional OE by mitigating class-specific biases. Similarly, \\cite{wei2023f15} introduced EAT, which employs dynamic virtual labels for OOD data and context-rich tail class augmentation to improve OOD detection in long-tailed settings, demonstrating that strong inlier classification does not automatically imply good OOD detection.\n\nDespite its successes, a critical limitation of OE is the reliance on the availability and diversity of \\textit{real} auxiliary OOD data. Collecting sufficiently diverse and representative OOD datasets is often impractical or impossible, leading to a shift towards Virtual Outlier Synthesis (VOS). VOS addresses this data scarcity by generating synthetic outliers, thereby overcoming the dependence on real OOD datasets and enhancing model robustness.\n\nEarly forays into VOS, such as Mixture Outlier Exposure (MixOE) by \\cite{zhang20212tb}, generated virtual outliers by mixing ID and auxiliary data. This approach was particularly effective for fine-grained OOD detection, where novel inputs are semantically similar to ID data and require a broader coverage of the feature space. Building on the need for diversity, \\cite{jiang2023vzb} introduced Diverse Outlier Sampling (DOS), a strategy that selects diverse and informative outliers from auxiliary datasets by combining clustering on normalized features with uncertainty-based selection. This aimed to shape a globally compact decision boundary, improving upon biased greedy sampling. Further advancing this, \\cite{yao2024epq} proposed \\texttt{diverseMix}, a diversity-induced mixup strategy with theoretical guarantees, which generates semantically distinct synthetic outliers through dynamic interpolation, provably enhancing the diversity of the auxiliary set.\n\nMore sophisticated VOS methods have emerged, generating synthetic outliers directly from in-distribution data or leveraging advanced generative models. \\cite{nie2024ghv} introduced Virtual Outlier Smoothing (VOSo), which constructs auxiliary OOD samples by perturbing semantic regions of ID samples in the \\textit{image space}, using Class Activation Maps (CAMs). Crucially, VOSo assigns dynamic soft labels based on the perturbation extent, creating a smoother decision boundary and more nuanced uncertainty estimation than traditional uniform OOD labels. Similarly, \\cite{yang2023pre} (MixOOD) also utilized Mixup-based strategies to generate augmented images as auxiliary OOD data, demonstrating improved distinction between ID and OOD samples. \\cite{chen20243na} explored a \"negative branch\" method with directional regularization and OOD training data, which implicitly functions as a form of virtual outlier generation to enhance anomaly detection.\n\nThe advent of large pre-trained models, particularly Vision-Language Models (VLMs), has opened new avenues for VOS. \\cite{ding20242m0} proposed Outlier Label Exposure (OLE) for zero-shot OOD detection, which generates textual outlier prototypes by clustering and refining auxiliary outlier class labels. This effectively synthesizes OOD knowledge in the language domain, enhancing VLM safety without extensive training. Complementing this, \\cite{li20245b6} introduced \\texttt{NegPrompt}, a method that learns transferable negative prompts for each ID class using only ID data. These negative prompts implicitly define OOD boundaries, enabling open-vocabulary OOD detection by leveraging the VLM's semantic understanding. \\cite{miyai2023591} (GL-MCM) further explored VLM capabilities by combining global and local concept matching for zero-shot OOD, implicitly handling multi-object OOD scenarios by leveraging local features to overcome contamination of global features. \\cite{yu20249dd} developed Self-Calibrated Tuning (SCT) for VLMs, which adaptively balances ID classification and OOD regularization by leveraging ID-irrelevant local context as surrogate OOD data, addressing the issue of spurious OOD features.\n\nGenerative models, especially diffusion models, have also been harnessed for VOS. \\cite{gao2023kmk} introduced DiffGuard, a semantic mismatch-guided OOD detection method that uses pre-trained diffusion models. It synthesizes new images conditioned on an input and its predicted label, identifying OOD samples by measuring the dissimilarity between the original and synthesized images. This approach leverages the conditional generation capabilities of diffusion models to highlight semantic contradictions, overcoming scalability issues of prior generative methods.\n\nThe VOS paradigm has also extended to specialized domains and multimodal inputs. For pixel-wise OOD detection in semantic segmentation, \\cite{besnier2021jgn} (ObsNet+LAA) generates OOD-like training data via local adversarial attacks, simulating unknown objects to train an auxiliary observer network. Similarly, \\cite{liu2022fdj} (RPL) utilizes Outlier Exposure with synthetic OOD data to learn residual anomaly patterns without retraining the base segmentation model. In 3D LiDAR-based object detection, \\cite{ksel20246fe} generates synthetic OOD objects by perturbing known ID object categories, addressing data scarcity in this domain. For multimodal OOD detection, \\cite{dong2024a8k} introduced Nearest Neighbor Prototype-based Mixup (NP-Mix) as part of their Agree-to-Disagree (A2D) algorithm, generating outliers by leveraging nearest neighbor class prototypes to explore broader feature spaces. Building on this, \\cite{li2024rs5} proposed Dynamic Prototype Updating (DPU), which dynamically adjusts multimodal prediction discrepancy intensification based on a sample's similarity to its class prototype, accounting for intra-class variability in multimodal data. Finally, \\cite{hofmann2024gnx} introduced Hopfield Boosting, an OE approach that adaptively samples \"hard\" outliers using a novel energy function derived from Modern Hopfield Networks, further refining the selection of informative synthetic or real outliers.\n\nIn conclusion, Outlier Exposure has evolved from a foundational paradigm to a sophisticated framework that explicitly trains models to recognize novel inputs. The critical challenge of OOD data scarcity has driven the field towards Virtual Outlier Synthesis, which leverages advanced techniques like semantic-level interpolation, adversarial generation, and prompt-based synthesis to create diverse and effective training examples. While VOS has significantly reduced the reliance on real OOD datasets and enhanced model robustness across various modalities and tasks, ongoing challenges include ensuring the representativeness of synthetic outliers for truly unknown OOD distributions, scaling complex generation methods, and developing stronger theoretical guarantees for their generalization capabilities.\n\\subsection{Learning Robust and Separable Feature Representations}\n\\label{sec:4\\_2\\_learning\\_robust\\_\\_and\\_\\_separable\\_feature\\_representations}\n\nThe intrinsic quality and structured organization of a model's internal feature representations are paramount for effective Out-of-Distribution (OOD) detection. This subsection delves into advanced methodologies that actively engineer the deep neural network's embedding space, aiming to enhance the discriminability between in-distribution (ID) and OOD samples. These approaches collectively improve the inherent OOD robustness of the learned representations by designing a more structured and discriminative embedding space, often by enforcing explicit geometric separation, creating more compact and well-defined ID clusters, or refining feature transformations.\n\nA significant line of research leverages the intrinsic properties of deep neural networks, particularly the phenomenon of Neural Collapse (NC), to enforce explicit geometric separation between ID classes and push OOD samples away. Neural Collapse describes the convergence of features within each class to their respective class means, and these class means to a simplex equiangular tight frame (ETF) structure in the terminal phase of training. Building on this, \\cite{ammar2023pr1} introduced NECO, a post-hoc method that capitalizes on a newly observed property dubbed ID/OOD Orthogonality (NC5). This property posits that OOD data tends to become increasingly orthogonal to the principal component space spanned by ID class means. NECO exploits this by projecting features onto this ID-derived principal component space, using the projection magnitude as an OOD score. A smaller projection magnitude indicates higher OOD likelihood. Extending this concept, \\cite{wu20242p3} proposes a novel separation loss (\\texttt{LSep}) that actively constrains OOD features to reside in a subspace orthogonal to the principal subspace of ID features, which is implicitly defined by the final layer's weights. This approach moves beyond merely observing orthogonality to explicitly enforcing it during training, typically by leveraging auxiliary OOD data to push their features into distinct, non-overlapping dimensions. An earlier, more general effort towards compact ID representations, \\cite{zaeemzadeh2021lmh} proposed embedding ID samples into a low-dimensional space forming a union of 1-dimensional subspaces, arguing that such a highly constrained representation inherently makes it less likely for OOD samples to occupy ID regions. While Neural Collapse-based methods offer strong theoretical underpinnings for explicit separation, their robustness to subtle, near-OOD shifts that might not perfectly align with orthogonal subspaces remains a critical area for further investigation, as these shifts might still project significantly onto the ID subspace.\n\nBeyond direct geometric enforcement, feature transformation and subspace learning techniques are employed to enhance separability, often addressing the \"curse of dimensionality\" that can plague distance-based methods in high-dimensional feature spaces. Traditional linear dimensionality reduction methods often struggle to capture the complex non-linear relationships inherent in deep features. \\cite{song2022f5d} introduced RankFeat, a post-hoc method that uses Singular Value Decomposition (SVD) to identify and remove a dominant rank-1 component from high-level features. This spectral manipulation implicitly refines the feature space by mitigating the over-confidence induced by this component in OOD samples, effectively \"flattening\" the feature manifold. Addressing the limitations of purely linear transformations, \\cite{fang2024lv2} proposes Kernel PCA (KPCA) for OOD detection, devising novel non-linear mappings like Cosine Mapping (CoP) and Cosine-Gaussian Mapping (CoRP). These mappings explicitly transform features into a space where ID and OOD data become linearly separable, overcoming the ineffectiveness of conventional PCA on raw features, a challenge also noted by \\cite{guan2023dwv} which explored regularized PCA reconstruction errors. To directly combat the curse of dimensionality, \\cite{ghosal2023q20} proposes Subspace Nearest Neighbor (SNN), which regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e., subspace) during training. This subspace learning yields more distinguishable distance measures between ID and OOD data. Similarly, \\cite{li2025jdt} introduces a data structure-aware approach using a novel \"tangent distance\" that maps high-dimensional features to the manifold of ID samples. By directly computing the Euclidean distance between samples and the nearest submanifold space (linear approximation of local regions on the manifold), it mitigates the sensitivity of distances to high dimensionality, proposing that OOD samples are relatively far from the ID manifold. The computational overhead and the challenge of selecting optimal non-linear kernels or relevant subspaces for diverse OOD scenarios represent practical considerations for these transformation-based methods.\n\nAnother significant direction involves refining ID clusters through prototype-based learning and mixture models, which aim to capture the nuanced structure of ID data more faithfully. Traditional distance-based OOD methods often oversimplify ID classes by modeling them with a single centroid, failing to capture intra-class diversity and leading to suboptimal OOD boundaries. \\cite{lu20249d4} addresses this with Prototypic Learning with a Mixture of prototypes (PALM), which models each ID class with multiple prototypes using a mixture of von Mises-Fisher (vMF) distributions in a hyperspherical embedding space. This approach creates more faithful and compact ID clusters, allowing for a more precise definition of ID boundaries by optimizing both a Maximum Likelihood Estimation (MLE) loss and a novel prototype contrastive loss. Extending this concept to multimodal settings, \\cite{li2024rs5} introduces Dynamic Prototype Updating (DPU), which dynamically adjusts multimodal prediction discrepancy intensification based on a sample's similarity to its class prototype. DPU employs Cohesive-Separate Contrastive Training (CSCT) to build a robust representation space and Pro-ratio Discrepancy Intensification (PDI) to balance intra-class cohesion with inter-class separation, thereby enhancing OOD detection in complex multimodal data. Complementing these empirical approaches, \\cite{du2024aea} provides theoretical insights into how in-distribution labels help OOD detection, particularly for \"near OOD\" scenarios. Through a graph-theoretic framework and spectral decomposition, they demonstrate that ID labels, by defining supervised connectivity, enable the learning of more discriminative ID representations that facilitate OOD-ID separation, especially when ID data is sparsely connected without labels. While prototype-based methods offer improved fidelity, the challenge of determining the optimal number of prototypes and their sensitivity to noisy ID data remains, and OOD samples falling between distinct ID prototypes can still pose detection difficulties.\n\nDespite these significant advancements in actively structuring and refining feature spaces, a persistent challenge remains in ensuring that these learned representations generalize effectively to truly novel and diverse OOD types. While methods leveraging Neural Collapse offer promising theoretical underpinnings for explicit separation, their robustness to subtle, near-OOD shifts that might not perfectly align with orthogonal subspaces requires further investigation. Similarly, prototype-based methods, while improving intra-class modeling, still face the inherent difficulty of defining boundaries for the unknown, especially when OOD data falls within the convex hull of ID prototypes. Future research could focus on adaptive feature space shaping techniques that dynamically adjust to the evolving nature of OOD data, perhaps through meta-learning or continuous adaptation mechanisms, to achieve more universally robust and discriminative representations that are less sensitive to the specific characteristics of unseen OOD data.\n\\subsection{Gradient-Based and Neuron-Level Analysis}\n\\label{sec:4\\_3\\_gradient-based\\_\\_and\\_\\_neuron-level\\_analysis}\n\nA significant shift in Out-of-Distribution (OOD) detection research involves delving into the fine-grained internal dynamics of neural networks, leveraging gradient information and individual neuron activations to extract more precise and interpretable OOD signals. This introspection moves beyond aggregate model outputs to understand \\textit{how} and \\textit{why} a model processes OOD inputs differently.\n\nOne prominent direction focuses on abnormalities in gradient-based attribution maps, which reveal how input features influence predictions. \\cite{chen2023za1} introduced GAIA (Gradient Abnormality Inspection and Aggregation), a framework that quantifies the \"abnormality\" in gradient-based attribution results, observing that OOD samples lead to \"meaningless attribution results\" with abnormal non-zero density in deeper layers. Building on gradient insights, \\cite{behpour2023x13} proposed GradOrth, which identifies OOD data by computing the norm of the gradient projection onto a low-rank subspace deemed important for in-distribution (ID) data, indicating a weak correlation with ID patterns. While these methods are post-hoc, analyzing gradients after training, \\cite{chen2020mbk} introduced ALOE (Adversarial Learning with inlier and Outlier Exposure), a training-time strategy that uses adversarial examples generated via gradients to robustify OOD detectors against small input perturbations. ALOE's objective is to promote smoother OOD score functions for ID data and clearer separation for OOD data, directly addressing the robustness aspect through gradient-informed regularization during training.\n\nAnother crucial area explores the 'coverage' of neuron activation states by in-distribution data, revealing deviations from learned patterns. \\cite{liu2023zb3} proposed Neuron Activation Coverage (NAC), a novel statistical measure that quantifies how well neuron states are \"covered\" by ID training data, serving as an uncertainty measure for OOD detection and a metric for OOD generalization. This approach provides a deeper, neuron-centric understanding of OOD phenomena. Complementing this, \\cite{zhu2022oir} introduced Batch Normalization Assisted Typical Set Estimation (BATS) with a Truncated BN (TrBN) unit, which rectifies extreme feature activations into their \"typical set\" to boost OOD detection scores, effectively managing neuron states. \\cite{xu2023767} further generalized this concept with Variational Rectified Activation (VRA), providing a theoretical derivation for an optimal activation function that not only suppresses abnormally high activations (like TrBN) but also low ones, and amplifies intermediate activations, leading to superior OOD separation. These rectification methods demonstrate a progression from heuristic to theoretically grounded manipulation of neuron activations.\n\nBeyond individual neuron states, statistical analyses of activation patterns also prove effective. \\cite{dong2021swz} developed Neural Mean Discrepancy (NMD), a metric that quantifies the difference between the average activations (neural means) of input examples and the training data across multiple layers. NMD leverages Batch Normalization's running averages for efficiency, providing a lightweight yet powerful OOD signal. More recently, \\cite{schmidt2024syr} presented SISOM (Simultaneous Informative Sampling and Outlier Mining), a unified approach for active learning and OOD detection that enriches feature representations by weighting neurons based on their gradient contribution to the KL divergence between a uniform distribution and the model's softmax output. This method effectively combines gradient-based saliency with neuron activation analysis to identify unexplored regions and decision boundaries, showcasing a sophisticated integration of these fine-grained internal dynamics.\n\nThe collective efforts in this subsection highlight a growing trend towards deeper introspection into model internals. By analyzing gradient-based attribution maps, the coverage of neuron activation states, and employing gradient regularization during training, researchers are developing more precise, interpretable, and robust OOD detection methods. However, challenges remain in establishing universal patterns for gradient abnormalities or neuron coverage across diverse architectures and OOD types, and in balancing the computational cost of such fine-grained analysis with real-time deployment needs.\n\n\n\\label{sec:advanced_ood_paradigms_and_contexts}\n\n\\section{Advanced OOD Paradigms and Contexts}\n\\label{sec:advanced\\_ood\\_paradigms\\_\\_and\\_\\_contexts}\n\n\\subsection{Multimodal and Graph-Structured OOD Detection}\n\\label{sec:5\\_1\\_multimodal\\_\\_and\\_\\_graph-structured\\_ood\\_detection}\n\nThe landscape of Out-of-Distribution (OOD) detection is rapidly expanding beyond traditional unimodal image data to encompass the complexity of real-world multimodal and graph-structured information. This crucial extension addresses the inherent multimodal nature of many applications and the unique challenges posed by non-Euclidean data.\n\nFor graph-structured data, OOD detection presents distinct challenges due to its non-Euclidean nature and the high cost of labeling. Pioneering efforts have focused on unsupervised graph-level OOD. \\cite{liu202227x} introduced GOOD-D, a novel framework for unsupervised graph-level OOD detection that learns robust in-distribution (ID) patterns through perturbation-free data augmentation and hierarchical graph contrastive learning across node, graph, and group levels. This approach was critical in formalizing the problem and providing a multi-granularity understanding of graph ID data. Building on the need for OOD exposure in graphs, \\cite{wang2025xwm} proposed GOLD, which addresses the scarcity of auxiliary OOD data by implicitly generating pseudo-OOD samples through an adversarial latent generation framework, achieving superior performance without real OOD samples. Addressing practical deployment constraints, \\cite{wang2024es5} introduced GOODAT, a test-time graph OOD detection method that operates without access to training data or requiring GNN architecture modifications, leveraging a graph masker and the Graph Information Bottleneck (GIB) principle for unsupervised OOD identification. To provide a unified evaluation framework for this nascent field, \\cite{wang2024q01} presented UB-GOLD, a comprehensive benchmark that unifies unsupervised graph-level anomaly detection and OOD detection across 35 datasets and four distinct scenarios, enabling systematic comparison and analysis of diverse graph OOD methods.\n\nThe detection of OOD samples in multimodal settings is gaining traction as real-world data often comprises complementary information from diverse sources like vision, audio, and text. \\cite{dong2024a8k} made a significant contribution by introducing MultiOOD, the first dedicated benchmark for multimodal OOD detection, alongside the Agree-to-Disagree (A2D) algorithm. A2D leverages the \"modality prediction discrepancy\" phenomenon, where softmax predictions across modalities show negligible differences for ID data but significant variability for OOD data, to enhance detection. Extending this concept, \\cite{li2024rs5} proposed Dynamic Prototype Updating (DPU), a plug-and-play framework that addresses the limitation of uniform discrepancy amplification by dynamically adjusting intensification based on a sample's similarity to its class prototype, thereby balancing intra-class cohesion with inter-class separation.\n\nVision-Language Models (VLMs) have emerged as a powerful paradigm for multimodal OOD detection, particularly in zero-shot and open-vocabulary settings. \\cite{miyai2023591} introduced GL-MCM, which enhances zero-shot OOD detection by combining CLIP's global and local features, offering flexibility in defining ID images in complex, multi-object scenes. Further refining VLM-based approaches, \\cite{li20245b6} developed NegPrompt, a method that learns transferable \"negative prompts\" using only ID training data to delineate OOD boundaries, enabling open-vocabulary OOD detection without explicit OOD examples. Addressing the challenge of spurious OOD features that can arise from imperfect foreground-background decomposition in VLMs, \\cite{yu20249dd} proposed Self-Calibrated Tuning (SCT), an adaptive framework that dynamically balances ID classification and OOD regularization based on prediction uncertainty. Beyond VLMs, Large Language Models (LLMs) are being explored for their world knowledge. \\cite{dai2023mhn} leveraged LLMs for multi-modal OOD detection by generating descriptive features for ID classes, crucially developing a consistency-based uncertainty calibration method to mitigate LLM hallucinations and prevent performance degradation. This integration of LLMs with VLMs for OOD detection is further contextualized by \\cite{miyai20247ro}, which provides a comprehensive survey of OOD detection in the VLM/LVLM era, highlighting the integration of related fields and identifying the most demanding challenges.\n\nThe expansion of OOD detection to multimodal and graph-structured data marks a significant step towards more holistic and context-rich detection capabilities. While promising advancements have been made in developing new benchmarks and algorithms that exploit inter-modal discrepancies and address the unique challenges of non-Euclidean data, several unresolved issues remain. These include the scalability of multimodal OOD methods to a wider array of modalities beyond vision-language, the robustness of graph OOD detectors to diverse and subtle structural shifts, and the development of theoretically grounded adaptive algorithms that can seamlessly handle the inherent noise and heterogeneity in real-world multimodal and graph data.\n\\subsection{OOD in Specialized Learning Settings}\n\\label{sec:5\\_2\\_ood\\_in\\_specialized\\_learning\\_settings}\n\nOut-of-distribution (OOD) detection becomes particularly challenging in specialized learning paradigms where inherent data characteristics complicate the distinction between in-distribution (ID) and novel samples. This subsection delves into OOD detection within long-tailed recognition and class-incremental learning, highlighting the unique complexities and tailored solutions developed to ensure OOD robustness in these realistic scenarios.\n\nIn \\textbf{long-tailed recognition (LTR)}, the severe class imbalance creates a pervasive confusion between tail-class ID samples and true OODs. Models often exhibit overconfidence on dominant head classes, leading to OOD samples being misclassified into these categories, while simultaneously treating sparse tail-class instances as anomalies \\cite{miao2023brn, wei2023f15, shin2024lnf}. Addressing this requires strategies that either modify the learning objective, augment data, or engineer the representation space to explicitly disentangle tail-class ID from OOD.\n\nOne prominent approach involves modifying the learning objective or expanding the label space. \\cite{miao2023brn} introduced Calibrated Outlier Class Learning (COCL), which extends the label space with an explicit outlier class. COCL employs a debiased large margin learning strategy, incorporating OOD-aware tail class prototype learning to prevent tail samples from being mistaken for OOD, and debiased head class learning to mitigate the dominant influence of head classes on OOD samples. This direct manipulation of the decision boundary in the logit space offers a targeted solution to the class imbalance problem. Complementing this, \\cite{choi202367m} recognized that even auxiliary OOD data used in outlier exposure can exhibit class imbalance. They developed a balanced energy regularization loss that adaptively applies stronger regularization to auxiliary samples from majority classes, ensuring a more effective learning of OOD boundaries in long-tailed and semantic segmentation tasks.\n\nAnother crucial strategy focuses on data augmentation and dynamic outlier adaptation. \\cite{wei2023f15} proposed EAT, a framework that utilizes dynamic virtual labels for OOD data and context-rich tail class augmentation. By overlaying tail-class images onto OOD backgrounds, EAT encourages the model to focus on discriminative foreground features, improving both tail-class generalization and OOD distinction. This data-centric approach contrasts with COCL's loss modifications by enriching the training data itself. Further advancements in dynamic outlier adaptation include \\cite{nie2024ghv}'s Virtual Outlier Smoothing (VOSo), which constructs virtual outliers by perturbing semantic regions of ID samples in the image space and assigns them dynamic soft labels. This creates a smoother decision boundary, preventing tail classes from being abruptly classified as OOD. To enhance the diversity of auxiliary OOD data, \\cite{yao2024epq} theoretically demonstrated that increased diversity improves OOD generalization and proposed \\texttt{diverseMix}, a semantic-level interpolation strategy with dynamic adjustment. Similarly, \\cite{jiang2023vzb} introduced Diverse Outlier Sampling (DOS), which selects diverse and informative outliers from auxiliary datasets by clustering normalized latent representations. These dynamic sampling and generation techniques, along with adaptive weighting strategies like Hopfield Boosting \\cite{hofmann2024gnx} that prioritize \"hard\" outliers, collectively contribute to refining the decision boundary in long-tailed settings, ensuring that tail classes are not erroneously flagged as OOD while true anomalies are detected.\n\nBeyond explicit outlier exposure and loss modifications, engineering the representation space is critical. \\cite{shin2024lnf} introduced \\textbf{Representation Norm Amplification (RNA)}, a novel training method that directly addresses the trade-off between LTR classification accuracy and OOD detection performance. RNA decouples ID classification and OOD detection by leveraging the norm of the representation vector as a dedicated dimension for OOD scoring. It achieves this by training the classifier to minimize classification loss only for ID samples, while simultaneously regularizing to enlarge the norm of ID representations. Crucially, auxiliary OOD samples are used to regularize Batch Normalization (BN) layers, indirectly reducing OOD representation norms and creating a discernible difference in activation ratios and representation norms. This allows for simultaneous high performance in both tasks, overcoming limitations of previous methods. Similarly, \\cite{lu20249d4} proposed Prototypic ALearning with a Mixture of prototypes (PALM), which models each ID class with multiple prototypes using a mixture of von Mises-Fisher distributions. While not exclusively for long-tailed settings, this approach is highly beneficial for capturing the inherent intra-class diversity within sparse tail classes, leading to more faithful embeddings and improved ID-OOD separability. \\cite{zhang202312h} introduced Multi-scale OOD DEtection (MODE), leveraging both global and local representations with an attention-based local propagation mechanism. This multi-scale approach can help distinguish fine-grained tail-class features from OOD noise, especially when global features are ambiguous due to background clutter.\n\nIn \\textbf{class-incremental learning (CIL)}, where models continuously learn new classes over time, maintaining robust OOD performance is a significant hurdle due to catastrophic forgetting of previously learned classes. The challenge lies in adapting to new ID classes without degrading the OOD detection capability for both old and new data distributions. This area has historically been underexplored, but recent work has begun to provide dedicated solutions and benchmarks.\n\n\\cite{miao20246mk} introduced OpenCIL, the first comprehensive benchmark for OOD detection in CIL, highlighting that CIL models exhibit increasing biases towards OOD samples and newly added classes with more incremental steps, leading to decreased OOD detection performance. OpenCIL proposes two frameworks for integrating OOD detection into CIL: post-hoc methods (applying OOD scores on CIL model features) and fine-tuning-based methods (training an additional OOD classifier while freezing the CIL backbone). To mitigate the identified biases, \\cite{miao20246mk} further proposed Bi-directional Energy Regularization (BER). BER addresses two key issues: New Task Energy Regularization (NTER) prevents OOD samples from being over-confidently classified into new classes by synthesizing pseudo-OOD samples and enlarging decision margins. Old Task Energy Regularization (OTER) prevents old ID samples from being misclassified as OOD (due to catastrophic forgetting) by boosting prediction confidence for old classes using augmented memory samples. BER provides a targeted solution to the unique challenges of OOD in CIL by explicitly addressing the dynamic nature of the ID distribution.\n\nAnother promising direction is the integration of uncertainty quantification methods. \\cite{aguilar2023ms5} proposed Continual Evidential Deep Learning (CEDL), which integrates Evidential Deep Learning (EDL) into a continual learning framework to simultaneously perform incremental object classification and OOD detection. CEDL combines exemplar rehearsal and knowledge distillation with a novel loss function that includes evidential cross-entropy, KL-divergence regularization for new classes, and knowledge distillation. Their findings indicate that evidential vacuity is a good indicator for OOD detection in CIL, while dissonance struggles to distinguish old ID from OOD. This work offers a principled way to estimate and leverage uncertainty for OOD detection in evolving CIL environments.\n\nBeyond these dedicated CIL-OOD methods, several general OOD concepts offer indirect but promising contributions. Techniques that enhance training stability and prevent overconfidence are crucial in CIL. \\cite{cheng20233yi}'s Average of Pruning (AoP), which combines model averaging and network pruning, could help mitigate OOD detection instability and overfitting during continuous learning. Similarly, \\cite{chen2024kl7}'s Optimal Parameter and Neuron Pruning (OPNP), a training-free method, could reduce overconfidence in CIL models without requiring additional training data, thus improving OOD discrimination. Leveraging generic pre-trained representations, as explored by GROOD \\cite{vojr2023ee1}, might offer a more stable foundation for OOD detection in CIL, as these representations are less susceptible to task-specific catastrophic forgetting compared to features learned from scratch. The dynamic prototype updating mechanism in \\cite{li2024rs5}'s DPU, though developed for multimodal OOD, conceptually aligns with the need to dynamically refine class representations in CIL to maintain stable boundaries for OOD detection.\n\nIn conclusion, specialized learning settings like long-tailed recognition have seen significant progress through tailored solutions that address the nuanced interactions between ID and OOD data, often leveraging dynamic outlier adaptation, sophisticated representation learning, and explicit norm amplification. Crucially, the field of OOD detection in class-incremental learning is rapidly maturing, moving from an underexplored area to one with dedicated benchmarks and methods like OpenCIL and BER, and principled uncertainty-aware approaches like CEDL. Future research needs to further integrate these insights, developing dynamic and adaptive OOD detection frameworks that can explicitly handle evolving ID distributions and catastrophic forgetting, ensuring robust OOD performance in truly open-ended, lifelong learning scenarios.\n\\subsection{Leveraging Pre-trained Foundation Models}\n\\label{sec:5\\_3\\_leveraging\\_pre-trained\\_foundation\\_models}\n\nThe emergence of large pre-trained foundation models, such as Vision-Language Models (VLMs) like CLIP \\cite{radford2021learning} and Large Language Models (LLMs), has profoundly transformed the landscape of Out-of-Distribution (OOD) detection. These models, with their rich semantic understanding, vast world knowledge, and open-vocabulary capabilities, enable novel zero-shot and open-set OOD detection paradigms, moving towards more adaptable and versatile OOD systems.\n\nThe \"Vision Language Model Era\" marks a significant paradigm shift in OOD detection, as highlighted by \\cite{miyai20247ro}. Early integration of VLMs for OOD detection focused on leveraging their inherent zero-shot capabilities. For instance, \\cite{miyai2023591} introduced GL-MCM, extending CLIP's Maximum Concept Matching by utilizing both global and local visual-text alignments. This approach provides flexibility in defining in-distribution (ID) images in multi-object scenes, addressing the limitation of methods that assume single, centered objects. Building upon this, \\cite{ding20242m0} proposed Outlier Label Exposure (OLE), a method that explicitly incorporates OOD knowledge by using a large set of diverse auxiliary outlier class labels as pseudo OOD text prompts for VLMs. OLE learns refined \"outlier prototypes\" and generates \"hard outlier prototypes\" to calibrate decision boundaries, overcoming the limitations of purely ID-label-based zero-shot methods that lack explicit OOD knowledge. Further advancing this direction, \\cite{li20245b6} introduced NegPrompt, a prompt learning-based approach that learns transferable \"negative prompts\" for each ID class using \\textit{only} ID training data. These negative prompts implicitly define OOD boundaries by representing characteristics contrary to ID classes, enabling open-vocabulary OOD detection without the need for any external outlier data or additional encoders, which is a significant step towards data-efficient and generalizable OOD systems.\n\nBeyond VLMs, Large Language Models (LLMs) are increasingly leveraged for their extensive world knowledge to generate synthetic OOD exposure. \\cite{dai2023mhn} explored using LLMs to generate descriptive features for ID classes to enhance multimodal OOD detection. Crucially, they identified and addressed the LLM \"hallucination\" problem by proposing a novel consistency-based uncertainty calibration method. This method selectively integrates reliable LLM knowledge, preventing performance degradation caused by unfaithful LLM generations. Taking this concept further, \\cite{cao20246gj} introduced Envisioning Outlier Exposure (EOE), which directly uses LLMs to \\textit{envision} and generate potential outlier class labels based on visual similarity to ID classes. EOE designs task-specific LLM prompts for far, near, and fine-grained OOD scenarios, effectively creating synthetic OOD labels without access to any real OOD data, thereby providing a powerful form of \"outlier exposure\" to VLMs.\n\nThe integration of foundation models also necessitates refining their behavior for OOD detection. \\cite{yu20249dd} proposed Self-Calibrated Tuning (SCT) for VLMs, a novel framework designed to mitigate the issue of \"spurious OOD features\" that arise from VLMs' imperfect foreground-background decomposition. SCT adaptively adjusts the balance between ID classification and OOD regularization based on prediction uncertainty, making VLM-based OOD detection more robust to internal model limitations. In a broader context, the field is also expanding to multimodal OOD detection, where foundation models can play a crucial role. \\cite{dong2024a8k} introduced the MultiOOD benchmark and the Agree-to-Disagree (A2D) algorithm, which leverages \"modality prediction discrepancy\" for OOD detection across multiple modalities. While not exclusively VLM/LLM-focused, this work highlights the growing need for robust multimodal OOD, a domain where foundation models are inherently well-suited to integrate and leverage diverse information streams. Finally, the increasing adoption of foundation models for OOD detection has led to dedicated benchmarks, such as the one presented by \\cite{borlino20245ku}, which aims to properly assess the performance of these large pre-trained models in realistic yet harder OOD tasks, confirming their benefits and guiding future research into their fine-tuning strategies.\n\nIn conclusion, the advent of pre-trained foundation models has opened a new frontier in OOD detection, moving beyond traditional methods that often rely on explicit OOD data or complex architectural modifications. These models' inherent semantic understanding and vast knowledge enable sophisticated zero-shot and open-vocabulary OOD paradigms through techniques like learning transferable negative prompts, leveraging LLMs for envisioned outlier exposure, and self-calibrated tuning of VLMs. However, challenges remain in ensuring the robustness of LLM-generated information, fully integrating multimodal cues, and developing comprehensive benchmarks that capture the full spectrum of OOD scenarios for these powerful, general-purpose models.\n\n\n\\label{sec:real-world_applications_and_deployment_challenges}\n\n\\section{Real-World Applications and Deployment Challenges}\n\\label{sec:real-world\\_applications\\_\\_and\\_\\_deployment\\_challenges}\n\n\\subsection{OOD in Medical Imaging and Healthcare}\n\\label{sec:6\\_1\\_ood\\_in\\_medical\\_imaging\\_\\_and\\_\\_healthcare}\n\nThe deployment of artificial intelligence (AI) in medical imaging and healthcare necessitates robust out-of-distribution (OOD) detection capabilities, as misinterpreting novel or anomalous inputs can have severe, life-threatening consequences for patient well-being. AI-powered clinical decision support systems, used for tasks like disease diagnosis and anomaly detection in medical scans, must reliably identify when an input falls outside their training distribution to prevent erroneous predictions. This domain presents unique challenges, including the high dimensionality of medical images, inherent class imbalance in rare disease detection, and the stringent requirement for robust performance on subtle OOD shifts that might indicate critical pathologies.\n\nTo address the foundational understanding of OOD in this high-stakes field, \\textcite{hong2024xls} provide a comprehensive survey, establishing a critical taxonomy for distributional shifts in medical imaging. They delineate seven key factors causing OOD shifts and categorize them into semantic, covariate, and contextual shifts, clarifying the complex landscape and inconsistent terminology that hinders systematic research. Empirically validating the limitations of current approaches, \\textcite{vasiliuk20233w9} expose the severe shortcomings of state-of-the-art OOD detection methods when applied to 3D medical image segmentation. Their work introduces a novel, publicly available benchmark that simulates diverse clinical OOD scenarios and, notably, demonstrates that a simple Intensity Histogram Features (IHF) baseline often outperforms complex deep learning methods, underscoring the profound challenges posed by 3D medical data and the need for more tailored solutions.\n\nEarly efforts to adapt general OOD detection techniques to medical imaging revealed significant performance discrepancies. \\textcite{berger20214a3} conducted a comparative study of confidence-based OOD methods on chest X-rays, finding that methods performing well on standard computer vision benchmarks often failed in the medical context. Their analysis highlighted ODIN as a robust method due to its input perturbation mechanism, while Mahalanobis distance, a strong performer in general vision, proved ineffective in medical imaging due to less separable feature spaces. Directly addressing this limitation, \\textcite{anthony2023slf} critically re-evaluated the use of Mahalanobis distance for OOD detection in medical imaging. Through a detailed layer-wise analysis, they demonstrated that the optimal detection layer is highly dependent on the specific OOD pattern, challenging previous assumptions. They then proposed Multi-branch Mahalanobis (MBM), a novel framework that significantly enhances OOD detection by employing multiple depth-specific detectors, showcasing a tailored solution that improves reliability for identifying unexpected anomalies like pacemakers or subtle demographic shifts.\n\nBeyond adapting existing discriminative methods, novel generative approaches have emerged to tackle the high dimensionality and complexity of 3D medical data. \\textcite{graham20232re} introduced an unsupervised 3D OOD detection method leveraging Latent Diffusion Models (LDMs). This innovative approach overcomes the memory and resolution limitations of prior generative models, enabling the generation of high-resolution spatial anomaly maps. Such capabilities are crucial for tasks like identifying unexpected tumors, lesions, or other pathologies in volumetric scans, where precise localization is paramount for clinical utility and ensuring the overall reliability of AI-powered diagnostic systems.\n\nDespite these advancements, several challenges persist. The generalizability of OOD methods across the vast spectrum of medical imaging modalities, anatomical regions, and diverse OOD types remains an open problem. There is a continuous need for more comprehensive and clinically relevant benchmarks that capture the subtlety and variability of real-world OOD shifts. Furthermore, integrating these detection mechanisms seamlessly into clinical workflows, coupled with robust explainability and uncertainty quantification, is essential for fostering trust and enabling the safe and effective deployment of AI in patient care.\n\\subsection{OOD for Autonomous Systems and Cyber-Physical Systems}\n\\label{sec:6\\_2\\_ood\\_for\\_autonomous\\_systems\\_\\_and\\_\\_cyber-physical\\_systems}\n\nThe safe and reliable deployment of autonomous systems, encompassing self-driving vehicles, robotics, and industrial cyber-physical systems (CPS), critically depends on their ability to detect and appropriately react to Out-of-Distribution (OOD) events. In these dynamic, open-world environments, encountering unforeseen objects, sensor malfunctions, or adversarial attacks can lead to catastrophic failures if not promptly identified. This subsection delves into the specialized advancements in OOD detection that address the stringent requirements of real-time performance, robust multimodal sensor fusion, and the nuanced handling of diverse OOD events in such safety-critical applications.\n\nEnsuring the trustworthiness of learning-enabled components in CPS necessitates OOD detection with strong statistical guarantees and real-time capabilities. Early work by \\cite{cai2020lsi} addressed this by integrating Variational Autoencoders (VAEs) and Deep Support Vector Data Description (SVDD) within an Inductive Conformal Anomaly Detection (ICAD) framework, providing well-calibrated false alarm rates for high-dimensional sensor inputs. Building on such foundational guarantees, \\cite{kaur2022cty} introduced iDECODe, which leverages in-distribution equivariance for conformal OOD detection, offering bounded false detection rates. Extending this to dynamic environments, \\cite{kaur20248t3} proposed CODiT for OOD detection in time-series (dependent) data within CPS, utilizing temporal equivariance and Fisher's method for robust, guaranteed false alarm rates. A crucial practical concern in safety-critical systems is managing false positives; \\cite{vishwakarma2024z1m} tackled this with a human-in-the-loop framework that adaptively updates OOD detection thresholds using expert feedback and provides theoretical guarantees on false positive rates, even under distribution shifts. Beyond mere statistical detection, \\cite{guerin202201y} argued that traditional OOD detection is insufficient for safety-critical contexts, advocating for Out-of-Model-Scope (OMS) detection, which focuses on identifying inputs that lead to actual model errors, thereby providing a more direct measure of safety. Robustness against malicious inputs is also paramount; \\cite{chen2020mbk} introduced ALOE (Adversarial Learning with inlier and Outlier Exposure), a training-time strategy that robustifies OOD detectors against both adversarial in-distribution and OOD examples, a critical defense against cyber-attacks in CPS. For continually evolving autonomous systems, \\cite{aguilar2023ms5} proposed Continual Evidential Deep Learning (CEDL), enabling simultaneous incremental learning of new classes and OOD detection, crucial for systems operating in open-ended environments.\n\nA significant challenge in autonomous systems is the effective integration of heterogeneous sensor data, such as LiDAR, camera, and radar, for robust OOD detection. Traditional unimodal OOD methods often fail to leverage the complementary information across modalities, which is vital for distinguishing subtle OOD events from sensor noise or adverse environmental conditions. Addressing this, \\cite{dong2024a8k} introduced MultiOOD, the first dedicated benchmark for multimodal OOD detection, alongside the \"Agree-to-Disagree\" (A2D) algorithm and \"Nearest Neighbor Prototype-based Mixup\" (NP-Mix) for outlier synthesis. Their work demonstrated that leveraging modality prediction discrepancies significantly enhances OOD performance, providing a foundational step for multimodal OOD, although primarily evaluated on video-based action recognition. Directly targeting autonomous driving, \\cite{liu2025m5u} proposed \"Feature Mixing,\" an extremely simple and fast multimodal outlier synthesis method for OOD detection and segmentation, specifically for image and point cloud data. This method, which randomly swaps feature dimensions between modalities, achieves state-of-the-art performance with significant speedups over prior methods like NP-Mix, making it highly practical for real-time applications. They also introduced CARLA-OOD, a challenging synthetic multimodal dataset for OOD segmentation in driving scenarios. Further specializing in 3D perception, \\cite{ksel20246fe} revisited OOD detection in LiDAR-based 3D object detection, proposing a lightweight post-hoc method that integrates features from the backbone, bounding box parameters, and output logits of a fixed 3D object detector. Crucially, they introduced a novel synthetic OOD generation strategy by perturbing known ID objects and established a new nuScenes OOD benchmark, providing a more realistic evaluation protocol for unknown foreground objects in autonomous driving. For multimodal intent understanding, \\cite{zhang2024cx0} proposed MIntOOD, integrating weighted feature fusion with multi-granularity representation learning for both classification and OOD detection, highlighting the need for context-aware OOD in complex autonomous tasks.\n\nThe advent of large pre-trained foundation models, particularly Vision-Language Models (VLMs), offers new avenues for open-world OOD detection in autonomous systems by leveraging their vast semantic understanding. \\cite{mao20244lp} explored language-enhanced latent representations for OOD detection in autonomous driving, using the cosine similarity of image and text representations encoded by CLIP. This approach improves the transparency and controllability of latent encodings, demonstrating superior performance on realistic driving data compared to traditional vision encoder representations. Similarly, \\cite{chen2024f28}'s TagFog, while a general visual OOD method, is motivated by applications like autonomous driving and uses textual anchor guidance from large language models (e.g., ChatGPT) and jigsaw-based fake outlier generation to train robust visual encoders. This allows for learning more compact ID representations and leaving spare regions for OOD data in the feature space, enhancing open-vocabulary OOD capabilities. The broader landscape of OOD detection in the VLM era, as surveyed by \\cite{miyai20247ro}, underscores the transformative potential of these models for detecting novel, semantically rich OOD events that traditional methods might miss.\n\nIn conclusion, OOD detection is an indispensable enabler for safe and robust autonomous operation. Significant progress has been made in developing methods that offer statistical guarantees, enhance robustness against adversarial attacks, and, critically, leverage multimodal sensor fusion for a more comprehensive understanding of the operational environment. The emergence of VLM-based approaches further promises to extend OOD capabilities to truly open-world, semantically rich unknown scenarios. However, challenges persist in developing unified theoretical frameworks that seamlessly integrate OOD detection with the broader concept of Out-of-Model-Scope, especially in highly dynamic, multimodal, and continually learning systems. Future directions should focus on scaling these guarantees to highly complex, distributed CPS, further integrating human feedback for adaptive learning, and establishing comprehensive benchmarks that reflect the full spectrum of OOD events and temporal dependencies in real-world autonomous environments, including adverse weather conditions and sensor degradation.\n\\subsection{OOD in Cybersecurity and Anomaly Detection}\n\\label{sec:6\\_3\\_ood\\_in\\_cybersecurity\\_\\_and\\_\\_anomaly\\_detection}\n\nOut-of-distribution (OOD) detection is a cornerstone of modern cybersecurity and anomaly detection, providing a critical defense against the dynamic and adversarial nature of digital threats. In these high-stakes environments, OOD samples frequently represent malicious activities, ranging from sophisticated network intrusions and advanced persistent threats to novel malware and fraudulent financial transactions. The ability to promptly and accurately identify these deviations from established normal patterns is paramount for safeguarding critical infrastructure, sensitive data, and financial systems. This subsection synthesizes how OOD detection methods are specifically adapted and applied to diverse data streams, including network traffic, system logs, user behavior, and graph-structured data, highlighting their utility in protecting against unpredictable and evolving threats.\n\nA primary challenge in cybersecurity is the real-time detection of novel network intrusions and traffic anomalies amidst high-volume data streams. Early OOD methods focused on efficiency and feature-space analysis to meet these demands. For instance, Neural Mean Discrepancy (NMD) \\cite{dong2021swz} offers an efficient post-hoc technique for detecting OOD samples by measuring deviations in deep neural network activation means, making it suitable for rapid monitoring of network traffic. Similarly, FeatureNorm and NormRatio \\cite{yu2022egq} identify optimal intermediate layers where in-distribution (ID) and OOD data exhibit maximal feature norm separation, providing a robust signal for unusual traffic patterns without requiring explicit OOD training samples. Addressing the need for rapid identification of new types of malicious traffic with limited labeled data, SPN \\cite{miao2023zf5} proposes a few-shot learning approach based on a Siamese Prototypical Network, incorporating margin loss to ensure OOD detection capabilities for unknown traffic types. In specialized network contexts, such as Controller Area Network (CAN) bus intrusion detection, a cascaded two-stage classification architecture leveraging an Auxiliary Classifier Generative Adversarial Network (ACGAN) effectively distinguishes known attacks from normal traffic while detecting unknown attack classes as OOD \\cite{zhao20221ag}, demonstrating architectural adaptations for resource-constrained environments.\n\nFor malware analysis and system log anomaly detection, the focus shifts to distinguishing subtle, potentially polymorphic threats from benign system variations, often under conditions of data scarcity. Methods that refine internal representations are crucial here. RankFeat \\cite{song2022f5d} enhances OOD detection by removing dominant rank-1 feature components that might obscure subtle OOD signals, proving effective for identifying novel threats in complex datasets like malware binaries. To mitigate ambiguity caused by atypical ID samples, Batch Normalization Assisted Typical Set Estimation (BATS) \\cite{zhu2022oir} rectifies extreme features to form a \"typical set,\" which is vital for distinguishing subtle malicious anomalies in system logs from benign, yet unusual, system variations. Furthermore, MOODv2 \\cite{li2024n34} enhances ID representation learning through Masked Image Modeling (MIM), yielding more robust and distinct ID features critical for distinguishing subtle malware variants or sophisticated intrusion attempts. In unsupervised settings, where labeled anomalies are rare, Density of States Estimation (DoSE) \\cite{morningstar2020re9} leverages multiple summary statistics from generative models to identify atypical samples, overcoming the common challenge of generative models assigning high likelihoods to OOD data, a critical consideration for unsupervised anomaly detection in logs or network flows. Beyond feature-level analysis, neuron-centric approaches like Neuron Activation Coverage (NAC) \\cite{liu2023zb3} quantify the \"coverage degree\" of neuron states to detect OOD, proving useful for identifying deviations in learned patterns of user behavior or system states that could indicate a compromise or insider threat.\n\nThe inherently adversarial nature of cybersecurity necessitates OOD detection methods that are robust to manipulation. Attackers actively seek to bypass detectors by crafting adversarial examples that appear in-distribution. To counter this, Adversarial Learning with inlier and Outlier Exposure (ALOE) \\cite{chen2020mbk} trains models against both adversarial ID and OOD examples, significantly improving robustness against malicious perturbations designed to evade detection. Building on this, Adversarially Robust OOD Detection Using Lyapunov-Stabilized Embeddings (AROS) \\cite{mirzaei2024dad} leverages Neural Ordinary Differential Equations (NODEs) and Lyapunov stability to achieve robust embeddings. AROS notably generates \"fake OOD embeddings\" from low-likelihood regions of the ID feature space, eliminating the need for auxiliary OOD datasets and enhancing robustness against strong adversarial attacks. Gradient-based methods also contribute to robustness; GradOrth \\cite{behpour2023x13} identifies OOD samples by projecting gradients onto low-rank subspaces of ID data, offering a nuanced way to detect deviations in model processing. Similarly, GAIA \\cite{chen2023za1} detects \"abnormality\" in gradient-based attribution results, providing interpretability for security analysts investigating suspicious activities. Furthermore, the concept of tangent distance \\cite{li2025jdt} addresses the \"curse of dimensionality\" in high-dimensional feature spaces, offering a data structure-aware approach to quantify OOD uncertainty by measuring distance to the nearest submanifold space, which is crucial for robust OOD detection against subtle perturbations.\n\nFor graph-structured data, prevalent in network topology, social networks, and financial transaction graphs, OOD detection faces unique challenges due to non-Euclidean data structures and complex relationships. GOOD-D \\cite{liu202227x} pioneers unsupervised graph-level OOD detection using perturbation-free hierarchical contrastive learning. Addressing the scarcity of OOD data for graphs, GOLD \\cite{wang2025xwm} implicitly generates adversarial latent samples to enhance detection without auxiliary OOD datasets. GOODAT \\cite{wang2024es5} offers a test-time, plug-and-play graph OOD detection method that leverages a graph masker guided by the Information Bottleneck principle, providing an efficient solution for monitoring network intrusions. The growing importance of this domain is underscored by comprehensive surveys like \\cite{cai2025ez2} and unified benchmarks such as UB-GOLD \\cite{wang2024q01}, which allows for rigorous comparison of unsupervised graph-level anomaly and OOD detection methods across various threat scenarios. For node-level OOD detection in graph neural networks, NODESAFE \\cite{yang2025z62} optimizes energy scores to reduce extreme values and mitigate logit shifts, significantly improving detection accuracy against structural manipulations.\n\nThe rise of Large Language Models (LLMs) and multimodal data streams has opened new avenues for detecting sophisticated threats like phishing and social engineering. A survey by \\cite{xu2024ufg} systematically reviews how LLMs are utilized for anomaly and OOD detection across various data modalities, including text. For multi-modal OOD detection, \\cite{dai2023mhn} leverages LLMs' world knowledge to generate descriptive features while calibrating for hallucination, enhancing the detection of complex, multi-modal threats. Envisioning Outlier Exposure (EOE) \\cite{cao20246gj} utilizes LLMs to generate synthetic outlier class labels, providing \"envisioned outlier exposure\" to improve zero-shot OOD detection without real OOD data, which is crucial for identifying novel attack patterns or zero-day exploits. Furthermore, MIntOOD \\cite{zhang2024cx0} proposes a multimodal intent understanding system that simultaneously achieves classification and OOD detection by fusing text, video, and audio, vital for detecting anomalous user behavior or sophisticated social engineering attacks.\n\nIn safety-critical Cyber-Physical Systems (CPS), OOD detection demands strong theoretical guarantees and real-time applicability. Inductive Conformal Anomaly Detection (ICAD) \\cite{cai2020lsi}, using learned nonconformity measures, provides statistically sound false alarm rate guarantees for real-time OOD detection in CPS, crucial for applications like autonomous vehicles and industrial control systems. Building on this, iDECODe \\cite{kaur2022cty} introduces a novel non-conformity measure based on in-distribution equivariance, further strengthening conformal OOD detection with bounded false detection rates. Extending these guarantees to temporal data, CODiT \\cite{kaur20248t3} provides OOD detection with conformal guarantees for time-series data in CPS, directly applicable to monitoring network traffic and system logs for evolving threats. To address the practical issue of high false positive rates in dynamic environments, a human-in-the-loop framework \\cite{vishwakarma2024z1m} adaptively updates OOD detection thresholds with theoretical guarantees on false positive rate control, ensuring trustworthy deployment. Furthermore, understanding the fundamental objectives of OOD methods, as explored by \\cite{bitterwolf2022rw0}, helps in designing more principled and effective security detectors. The Model-Specific OOD framework \\cite{averly20239rv} offers a unified perspective on OOD detection based on a deployed model's actual misclassification behavior, which is highly relevant for understanding what a security system \\textit{actually} fails on in a real-world context. Finally, Continual Evidential Deep Learning (CEDL) \\cite{aguilar2023ms5} integrates evidential deep learning into a continual learning framework to simultaneously perform incremental classification and OOD detection, a critical capability for systems facing evolving threats without catastrophic forgetting.\n\nIn conclusion, OOD detection is an indispensable and rapidly evolving field within cybersecurity and anomaly detection. It has progressed from basic statistical deviation measures to sophisticated, robust, and context-aware methodologies capable of addressing diverse data types and adversarial environments. While significant advancements have been made in developing methods for various data modalities, enhancing robustness against adversarial threats, and providing theoretical guarantees, several challenges persist. These include balancing the need for universal OOD solutions with the demonstrated benefits of domain-specific adaptations, developing scalable and theoretically sound methods that can handle the full spectrum of real-world distribution shifts without relying on scarce OOD training data, and rigorously aligning OOD detection with the ultimate goal of ensuring model safety and reliability in constantly changing, unpredictable digital environments. Future research must continue to bridge theoretical rigor with practical deployment, particularly in the face of increasingly sophisticated and adaptive cyber threats.\n\\subsection{Practical Deployment Considerations and Human-in-the-Loop}\n\\label{sec:6\\_4\\_practical\\_deployment\\_considerations\\_\\_and\\_\\_human-in-the-loop}\n\nThe successful transition of Out-of-Distribution (OOD) detection systems from controlled experimental settings to real-world applications hinges on addressing a critical set of practical deployment challenges. Beyond theoretical performance metrics, these systems must demonstrate computational efficiency, scalability, robustness to dynamic environments, provable guarantees on false detection rates, and the capacity for effective human-in-the-loop (HITL) interaction and interpretability. The overarching goal is to develop OOD solutions that are not only technically effective but also robust, efficient, interpretable, and ultimately practical for diverse operational settings, particularly in safety-critical domains.\n\nA foundational requirement for practical deployment, especially in latency-sensitive systems, is computational efficiency and scalability. Early OOD methods, particularly those relying on complex generative models, often incurred significant computational overhead \\cite{zisselman2020cmx}. Consequently, recent research has prioritized lightweight, post-hoc approaches that minimize inference time. Neural Mean Discrepancy (NMD) \\cite{dong2021swz}, for instance, leverages running average means from Batch Normalization layers to approximate training data statistics, enabling real-time detection with minimal computational burden. Similarly, GradOrth \\cite{behpour2023x13} offers an efficient gradient-based OOD detector by pre-computing a low-rank subspace of in-distribution data gradients, facilitating rapid OOD scoring during inference. While both methods offer efficiency gains, NMD's reliance on Batch Normalization statistics might limit its applicability to architectures without such layers or in scenarios where batch statistics are highly variable. GradOrth, conversely, requires gradient computations, which, while pre-computed, still adds a layer of complexity compared to simpler confidence-based scores. The computational burden of traditional kernel methods, such as Kernel PCA (KPCA), has also been significantly reduced by approaches like CoP and CoRP \\cite{fang2024lv2}, which devise explicit non-linear feature mappings to achieve state-of-the-art performance with $O(1)$ or $O(M)$ complexity, a substantial improvement over $O(N\\_{tr})$ for methods like k-Nearest Neighbors (KNN). For Cyber-Physical Systems (CPS) demanding real-time responses, \\cite{cai2020lsi} demonstrated efficient OOD detection by integrating learned nonconformity measures (from VAEs and Deep SVDD) into the Inductive Conformal Anomaly Detection (ICAD) framework, overcoming traditional conformal prediction's scalability limitations for high-dimensional sensor inputs. Furthermore, the efficiency challenge extends to large language models (LLMs) in natural language processing (NLP). \\cite{ouyang2023wxc} proposed PTO, an unsupervised prefix-tuning based OOD detection framework that offers a parameter-efficient alternative to costly fine-tuning, demonstrating comparable or superior performance with significantly reduced storage and computational requirements. These diverse approaches highlight a collective effort to balance detection efficacy with the stringent computational constraints of real-world deployment.\n\nBeyond raw efficiency, practical systems demand robustness to diverse OOD types and adversarial attacks, coupled with adaptive mechanisms for dynamic, non-stationary environments. Many methods improve intrinsic OOD robustness during training or representation learning (as discussed in Section 4), but deployment-time robustness necessitates adapting to unforeseen shifts. The conceptual shift from merely detecting \"out-of-distribution\" to \"Out-of-Model-Scope\" (OMS) detection \\cite{guerin202201y} is crucial, emphasizing the identification of inputs leading to \\textit{prediction errors} of the specific deployed model, rather than a generic notion of novelty. This perspective is further refined by the Model-Specific Out-of-Distribution (MS-OOD) framework \\cite{averly20239rv}, which unifies the detection of semantic shifts, covariate shifts, and even misclassified in-distribution examples based on the actual performance of a deployed classifier. This framework is vital for guiding adaptive behavior and dynamic thresholding, allowing systems to differentiate between inputs the model \\textit{can} handle despite a shift (e.g., a covariate shift it generalizes to) and those it \\textit{cannot} (e.g., a semantic shift or a covariate shift leading to misclassification). While MS-OOD provides a robust conceptual foundation, its practical implementation for continuous adaptation in dynamic environments remains an active area of research, often requiring continuous monitoring and re-calibration. Contributions like \\cite{chen20247p7}'s sparsity-regularized tuning framework enhance the generalizability of OOD score functions, making them less dependent on specific datasets and more capable of dynamic adaptation. A particularly innovative adaptive mechanism for handling unforeseen OOD in open-world scenarios is \\cite{cao20246gj}'s Envisioning Outlier Exposure (EOE). EOE leverages Large Language Models (LLMs) to synthetically generate potential outlier class labels based on visual similarity to in-distribution classes, effectively providing \"outlier exposure\" without requiring actual OOD data. This LLM-driven approach offers a scalable and flexible way to adapt to various OOD types (far, near, fine-grained) by dynamically envisioning new categories, thereby enhancing the model's ability to distinguish novel inputs in a zero-shot manner. However, the effectiveness of EOE relies heavily on the quality of LLM-generated prompts and the LLM's inherent knowledge, posing challenges for robust and unbiased outlier generation across all domains.\n\nA critical aspect of practical deployment, especially in safety-critical domains, is the ability to provide reliable uncertainty estimates and control false detection rates. This is paramount for building trust and ensuring regulatory compliance. Conformal Prediction (CP), as detailed in Section 7.2, offers a principled approach to this, providing provably valid false detection rates. For instance, \\cite{kaur2022cty} introduced iDECODe for single-point OOD detection with theoretically guaranteed bounded False Detection Rates (FDR). This work was significantly extended by \\cite{kaur20248t3} to time-series data in Cyber-Physical Systems, providing conformal guarantees for OOD detection in dynamic, dependent data streams. This is a crucial advancement, as many real-world applications involve sequential data where independence assumptions of traditional CP might not hold. While CP offers strong theoretical guarantees, its practical application often requires careful calibration and consideration of the exchangeability assumption, which can be challenging in highly non-stationary environments.\n\nDespite theoretical guarantees, managing false positives (FPs) in dynamic, open-world settings often requires human oversight, leading to the indispensable role of human-in-the-loop (HITL) approaches. HITL frameworks integrate human expert feedback to refine OOD detectors, manage trade-offs between safety and performance, and build trust. \\cite{vishwakarma2024z1m} directly addressed the problem of high False Positive Rates (FPR) in OOD detection by proposing a mathematically grounded HITL framework. This framework adaptively updates the detection threshold over time by integrating human feedback and employing an anytime-valid Upper Confidence Bound (UCB) based on the Law of Iterated Logarithm, guaranteeing FPR control below a desired level while maximizing True Positive Rate (TPR) (further theoretical details are in Section 7.2). This approach offers a robust mechanism for dynamic threshold adjustment, but its effectiveness depends on the availability and reliability of human feedback. Beyond direct threshold adjustment, HITL also plays a crucial role in data acquisition and model refinement. \\cite{schmidt2024syr} proposed SISOM, a unified approach for active learning and OOD detection. Active learning inherently involves human experts labeling uncertain or novel samples, thereby providing crucial feedback to improve both model performance and OOD detection capabilities. SISOM's self-deciding process for combining scores contributes to adaptive behavior, reducing the burden on human operators while maintaining robustness.\n\nFor HITL systems to be truly effective, building operator trust and ensuring practical utility requires OOD solutions that are not only effective but also interpretable and aligned with system safety goals. Human operators need to understand \\textit{why} a system flags an input as OOD to make informed decisions and foster confidence in AI systems. Methods that leverage intrinsic model properties or explanations can enhance this interpretability. For instance, Neuron Activation Coverage (NAC) \\cite{liu2023zb3} quantifies the \"coverage degree\" of neuron states by in-distribution data, offering insights into model behavior under OOD conditions. Similarly, GAIA \\cite{chen2023za1} detects OOD samples by quantifying \"abnormality in gradient-based attribution results,\" directly linking model explanations to OOD detection (these methods are detailed in Section 4.3). While these approaches provide valuable diagnostic information, translating complex neural network activations or gradient attributions into easily digestible and actionable insights for human operators remains a significant challenge. The interpretability must be tailored to the human's cognitive load and the specific decision-making context.\n\nIn conclusion, the literature demonstrates a clear trajectory towards OOD detection solutions that prioritize practical deployment. This involves a strong emphasis on computational efficiency for real-time operation, robustness and adaptive mechanisms for dynamic environments, and the provision of theoretical guarantees on false alarm rates. Crucially, the field is increasingly recognizing the indispensable role of human-in-the-loop approaches for adaptive thresholding, managing false positives, and building trust in AI systems. Future work will likely continue to explore more nuanced human-AI collaboration models, develop methods for handling highly dynamic and unforeseen OOD shifts with minimal human intervention, and strive for truly interpretable OOD explanations that align with human decision-making in safety-critical contexts, ultimately enabling the responsible and reliable deployment of AI.\n\n\n\\label{sec:ensuring_trustworthy_ood:_advanced_formalisms,_guarantees,_and_evaluation}\n\n\\section{Ensuring Trustworthy OOD: Advanced Formalisms, Guarantees, and Evaluation}\n\\label{sec:ensuring\\_trustworthy\\_ood:\\_advanced\\_formalisms,\\_guarantees,\\_\\_and\\_\\_evaluation}\n\n\\subsection{Evolving OOD Definitions and Granular Taxonomies}\n\\label{sec:7\\_1\\_evolving\\_ood\\_definitions\\_\\_and\\_\\_granular\\_taxonomies}\n\nThe conceptualization of Out-of-Distribution (OOD) detection has undergone a significant evolution, moving beyond a simplistic binary distinction between in-distribution (ID) and OOD data towards a more nuanced, granular, and context-aware understanding. This shift is critical for developing robust and trustworthy AI systems capable of operating reliably in complex real-world environments.\n\nInitially, OOD detection primarily focused on identifying samples from entirely novel semantic categories. However, this narrow view proved insufficient, leading to the introduction of more granular definitions. A pivotal development was the formal distinction between different types of distribution shifts. \\cite{yang2022it3} introduced the concept of \\textit{Full-Spectrum Out-of-Distribution (FS-OOD) Detection}, explicitly differentiating between \\textit{semantic shift} (novel classes) and \\textit{covariate shift} (label-preserving appearance changes like lighting or style). Their proposed Semantics score function (SEM) aimed to disentangle these shifts, demonstrating that existing methods often failed to robustly handle covariate-shifted ID data, treating it erroneously as OOD. Further complicating the landscape, \\cite{ming2021wu7} highlighted the critical impact of spurious correlations, formalizing \"spurious OOD\" where models rely on non-causal features, making detection challenging even for inputs that visually resemble ID data. This emphasized that OOD can arise not just from novel semantics or appearance, but also from the model's learned biases.\n\nThe need for more rigorous evaluation of these granular shifts quickly became apparent. \\cite{yang2023ckx} critically analyzed existing ImageNet-based OOD benchmarks, revealing issues such as ID contamination, semantic ambiguities, and unintended covariate shifts that hindered the accurate assessment of semantic OOD detection. To address this, they introduced \\texttt{ImageNet-OOD}, a meticulously human-curated dataset designed to isolate pure semantic shift by minimizing covariate variations. Building on this, \\cite{wang2024is1} provided a comprehensive cross-evaluation of OOD detection and Open-Set Recognition (OSR) methods, further disentangling semantic and covariate shifts on large-scale benchmarks and proposing a new \"Outlier-Aware Accuracy\" (OAA) metric to reconcile robustness to covariate shift with the ability to detect its presence. These works collectively underscored the importance of clean, disentangled evaluation for understanding what OOD algorithms truly detect.\n\nA significant conceptual re-framing of the OOD problem was introduced by \\cite{averly20239rv} with the \\textit{Model-Specific Out-of-Distribution (MS-OOD) Detection} framework. This paradigm shifted the definition of OOD from being purely based on data properties to being dependent on a \\textit{specific deployed model's performance and misclassification behavior}. Under MS-OOD, an example is considered OOD if the model cannot classify it correctly, unifying semantic shift, covariate shift, and even misclassified in-distribution examples under a single, performance-driven ground truth. This perspective acknowledges that what constitutes \"OOD\" can be subjective and model-dependent, moving towards a more practical, context-aware definition.\n\nThe binary nature of traditional OOD evaluation also faced scrutiny. \\cite{long2024os1} addressed the \"Sorites Paradox\" in OOD evaluation, arguing that a simple binary ID/OOD distinction fails to capture the continuous \\textit{degree} of semantic and covariate shifts. They introduced the \\textit{Incremental Shift OOD (IS-OOD)} benchmark and \\textit{Language Aligned Image feature Decomposition (LAID)}, a CLIP-based method to quantitatively decompose image features into distinct semantic and covariate components. This allowed for continuous measurement of shift degrees, providing a far more granular and informative evaluation of OOD detection performance as a function of shift intensity.\n\nAs the field matured and its problem definitions became increasingly complex, the need for structured organization emerged. \\cite{lang20237w3} provided the first comprehensive survey on OOD detection in Natural Language Processing (NLP), introducing a novel taxonomy based on the availability of OOD data during training and highlighting NLP-specific challenges. This reflects the emergence of task-oriented and domain-specific taxonomies to organize the field's growing complexity, moving beyond generic definitions to practical, application-driven categorizations. Complementing this, theoretical works like \\cite{du2024aea} and \\cite{fang20249gd} contribute to this maturing conceptual understanding by exploring the fundamental learnability of OOD detection and the role of in-distribution labels, implicitly influencing how OOD boundaries are conceptualized and defined under various conditions.\n\nIn conclusion, the evolution of OOD definitions has progressed from a rudimentary binary classification to a sophisticated, multi-faceted understanding. This trajectory, marked by the differentiation of semantic and covariate shifts, the adoption of model-specific perspectives, the development of continuous shift measurements, and the emergence of task-oriented taxonomies, collectively reflects a maturing conceptual understanding of OOD detection. However, challenges remain in developing scalable, universally applicable methods that can robustly handle the full spectrum of these granular shifts without relying on scarce OOD training data, particularly in diverse real-world applications.\n\\subsection{Certifiable OOD Detection: Provable Guarantees and Conformal Prediction}\n\\label{sec:7\\_2\\_certifiable\\_ood\\_detection:\\_provable\\_guarantees\\_\\_and\\_\\_conformal\\_prediction}\n\nThe deployment of machine learning systems in safety-critical applications necessitates not only high empirical performance but also strong theoretical guarantees regarding their reliability, particularly in identifying out-of-distribution (OOD) inputs. This subsection explores the critical advancements towards certifiable OOD detection, emphasizing methods that provide provable guarantees on false detection rates and leverage rigorous statistical frameworks like Conformal Prediction (CP).\n\nA cornerstone of certifiable OOD detection is the integration of Conformal Prediction (CP), which offers a robust, model-agnostic framework for controlling false detection rates with statistical validity. Early work by \\cite{cai2020lsi} introduced Inductive Conformal Anomaly Detection (ICAD) for real-time OOD detection in learning-enabled Cyber-Physical Systems (CPS). This approach overcame the scalability limitations of traditional CP by employing learned nonconformity measures (NCMs) based on Variational Autoencoders (VAEs) and Deep Support Vector Data Description (SVDD), ensuring a well-calibrated false alarm rate in high-dimensional settings. Building on this, \\cite{kaur2022cty} proposed iDECODe, a novel ICAD framework leveraging in-distribution equivariance as its NCM. By aggregating scores from multiple transformations, iDECODe provides a theoretically guaranteed bounded false detection rate, demonstrating state-of-the-art performance in single-point OOD detection. Extending these guarantees to dynamic environments, \\cite{kaur20248t3} developed CODiT, which applies conformal anomaly detection to dependent time-series data in CPS. CODiT uses deviation from in-distribution temporal equivariance as an NCM and combines predictions from multiple detectors via Fisher's method, offering bounded false alarms for both fixed-length windows and variable-length traces. These advancements collectively showcase CP's versatility in providing marginal coverage guarantees across diverse OOD scenarios, from static single-point detection to complex temporal data streams.\n\nBeyond merely providing detection guarantees, CP is also crucial for establishing statistically rigorous evaluation metrics for OOD detectors themselves. Traditional OOD evaluation metrics, such as AUROC and FPR@TPR95, are empirical approximations that can be overly optimistic and fluctuate significantly with finite test sample sizes, lacking robust, conservative guarantees. Addressing this, \\cite{novello2024yco} proposed a dual application of CP and OOD detection. They introduced \"conformal AUROC\" and \"conformal FPR\" metrics, which provide probabilistic conservativeness guarantees on the variability of these evaluation metrics. This ensures that the estimated performance of an OOD detector is conservative with high probability (e.g., $1-\\delta$), thereby making the \\textit{evaluation} of OOD systems certifiable and more trustworthy. Furthermore, \\cite{novello2024yco} demonstrated that sophisticated OOD scores, such as Mahalanobis distance or K-Nearest Neighbors (KNN) distance, can serve as highly effective non-conformity scores within the CP framework, often outperforming classical CP non-conformity scores in building prediction sets. This highlights a synergistic relationship where OOD methods can enhance CP, and CP can, in turn, provide robust evaluation for OOD.\n\nWhile CP provides statistical guarantees, real-world systems often require adaptive control and human oversight, especially when faced with evolving OOD distributions. Addressing this, \\cite{vishwakarma2024z1m} introduced a mathematically grounded human-in-the-loop framework for OOD detection that dynamically adjusts detection thresholds. This framework leverages importance sampling and an anytime-valid Upper Confidence Bound (UCB) based on the Law of Iterated Logarithm to provide provable guarantees on the false positive rate (FPR), even in the presence of distribution shifts. By taming false positives with minimal human feedback, this approach significantly enhances the practical deployability and trustworthiness of OOD systems in dynamic, open-world environments.\n\nBeyond statistical guarantees and adaptive control, a deeper theoretical understanding of OOD detection learnability and data utility is crucial for a trustworthy foundation. \\cite{du20248xe} made a significant contribution by providing the first framework that offers \\textit{provable guarantees} for leveraging unlabeled \"wild\" data in OOD detection. Their \"Separate And Learn\" (SAL) framework employs a novel gradient-based filtering mechanism and offers rigorous error bounds on outlier separability and classifier learnability, demonstrating how unlabeled data can provably enhance OOD awareness without requiring clean auxiliary OOD samples. Complementing this, \\cite{fang20249gd} delved into the fundamental learnability of OOD detection, establishing necessary and sufficient conditions for Probably Approximately Correct (PAC) learnability under various risk and AUC metrics. This theoretical work highlights that OOD detection is not universally learnable and depends critically on the characteristics of the data and hypothesis spaces, providing crucial insights into the theoretical limits and possibilities of certifiable OOD systems. The implications for CP are profound: while CP offers statistical guarantees \\textit{given} an OOD score, the inherent quality and effectiveness of that score, and thus the practical utility of the CP-based detection, are constrained by the underlying learnability conditions of the specific OOD problem. This underscores the need for OOD scores that are well-aligned with the learnable properties of the data distribution for CP to be truly effective in practice.\n\nIn conclusion, the pursuit of certifiable OOD detection is rapidly evolving, moving from foundational statistical guarantees offered by Conformal Prediction for detection and evaluation, to adaptive, human-in-the-loop frameworks for dynamic FPR control. Simultaneously, theoretical work is establishing the learnability and data utility principles, collectively shaping a more robust and trustworthy understanding of what it means for an AI system to be \"certifiably\" aware of its own limitations. Despite these advancements, challenges remain in developing universally applicable nonconformity measures for CP that can provide strong guarantees across all types of distribution shifts, scaling CP to increasingly large foundation models, and extending these guarantees to more complex adaptive or continually learning systems, all while ensuring that the underlying OOD problem is indeed theoretically learnable.\n\\subsection{Standardized Benchmarking and Unified Evaluation Frameworks}\n\\label{sec:7\\_3\\_st\\_and\\_ardized\\_benchmarking\\_\\_and\\_\\_unified\\_evaluation\\_frameworks}\n\nThe systematic and fair advancement of Out-of-Distribution (OOD) detection critically relies on the development of standardized benchmarks and unified evaluation frameworks. Historically, the field grappled with inconsistent definitions of OOD, ad-hoc datasets, and disparate evaluation protocols, severely hindering reproducible and comparable research. Early work by \\cite{ming2021wu7} highlighted this by formalizing the concept of \"spurious OOD,\" demonstrating how models' reliance on spurious correlations in training data could lead to high-confidence but unreliable predictions on OOD inputs, thus exposing a fundamental flaw in simplistic OOD definitions and evaluation. Similarly, \\cite{berger20214a3}'s comparative study revealed significant performance discrepancies of confidence-based OOD methods between general computer vision tasks and challenging medical imaging applications, underscoring the necessity for domain-specific and rigorous evaluation. The lack of a comprehensive review for OOD in Natural Language Processing (NLP) was addressed by \\cite{lang20237w3}, which provided a taxonomy and discussed NLP-specific evaluation challenges, while \\cite{hong2024xls} offered a systematic framework and taxonomy for OOD detection in medical image analysis, clarifying terminology and evaluation protocols for this critical domain. These initial efforts underscored the urgent need for a more structured and consistent approach to OOD evaluation.\n\nA pivotal development in OOD evaluation has been the effort to disentangle distinct types of distribution shifts, moving beyond a monolithic view of OOD (as discussed in detail in Section 7.1). To operationalize these nuanced definitions, researchers have meticulously curated datasets designed to isolate and evaluate performance on specific shifts. \\cite{yang2023ckx} meticulously curated \\textit{ImageNet-OOD}, a novel dataset specifically designed to isolate and evaluate performance on semantic shifts while minimizing confounding covariate shifts. This dataset addressed critical shortcomings of previous ImageNet-based benchmarks, such as ID contamination and semantic ambiguities. Its findings were impactful, demonstrating that many modern OOD algorithms are disproportionately sensitive to covariate shifts rather than genuine semantic novelty, often failing to detect truly novel classes. This revelation prompted a re-evaluation of existing methods and guided the development of more robust techniques. Furthering this disentanglement, \\cite{wang2024is1} provided a critical analysis of OOD detection and Open-Set Recognition (OSR) methods, introducing a new large-scale benchmark to systematically disentangle semantic and covariate shifts and proposing \"Outlier-Aware Accuracy\" as a more nuanced metric. Complementing these efforts, \\cite{long2024os1} introduced the \"Incremental Shift OOD\" (IS-OOD) benchmark, which categorizes OOD samples by their \\textit{degree} of semantic and covariate shift, moving beyond binary OOD definitions and utilizing a novel Language Aligned Image feature Decomposition (LAID) method to quantify these shifts, offering a more granular assessment of OOD robustness.\n\nBeyond specialized datasets, the field has seen the emergence of comprehensive, unified software frameworks that provide robust platforms for rigorous comparison across diverse methods and OOD scenarios, addressing the critical need for reproducible and scientifically sound assessments. A cornerstone in this regard is \\textbf{OOD-Bench} \\cite{huang2023ood}, which emerged to tackle the pervasive issues of inconsistent implementations and evaluation settings. OOD-Bench provides a modular and extensible platform that integrates a wide array of OOD detection methods, backbone architectures, and datasets, enabling researchers to conduct fair and reproducible comparisons. Its structured approach has significantly improved the reliability of reported results and fostered a more systematic advancement of the field. Similarly, \\cite{kirchheim20229jl} introduced \\textbf{PyTorch-OOD}, a Python library specifically designed to accelerate OOD detection research and improve reproducibility. By providing well-tested and documented implementations of OOD methods with a unified interface, along with benchmark datasets and utility functions, PyTorch-OOD lowers the barrier to entry for new researchers and ensures consistency across experiments.\n\nThe demand for standardized evaluation extends to diverse data modalities and complex learning scenarios. For graph-structured data, which presents unique challenges due to its non-Euclidean nature, \\cite{liu202227x} pioneered a benchmark dataset for unsupervised graph-level OOD detection. This was significantly expanded by \\cite{wang2024q01} with \\textbf{UB-GOLD}, a unified benchmark that integrates unsupervised graph-level anomaly detection and OOD detection across 35 datasets and four distinct scenarios. UB-GOLD provides a robust and comprehensive platform for rigorous comparison in this emerging domain, allowing for a deeper understanding of method performance under various graph OOD conditions. A recent survey by \\cite{cai2025ez2} further contributes to the standardization of graph OOD detection by providing a rigorous definition and systematically categorizing existing methods, clarifying distinctions with related fields and highlighting unique challenges. In medical imaging, where OOD detection is paramount for patient safety, \\cite{vasiliuk20233w9} developed a novel and diverse benchmark for 3D medical image segmentation OOD, which exposed the significant limitations of many state-of-the-art methods when confronted with the subtle, yet critical, OOD shifts inherent in medical data. Similarly, \\cite{anthony2023slf} contributed a new benchmark for OOD detection in medical imaging by manually annotating pacemakers and support devices in chest X-rays, enabling more targeted evaluation of methods like Mahalanobis distance against clinically relevant anomalies.\n\nFurthermore, as OOD detection integrates with more dynamic learning paradigms, specialized benchmarks become crucial. \\textbf{OpenCIL} \\cite{miao20246mk} addresses the critical challenge of OOD detection within Class-Incremental Learning (CIL). CIL models, designed to continuously learn new classes, often suffer from catastrophic forgetting, which severely impacts their ability to detect OOD samples reliably. OpenCIL is the first comprehensive benchmark for OOD detection in CIL, providing unified evaluation protocols and two principled frameworks (post-hoc and fine-tuning based) to integrate OOD methods into CIL models. This benchmark has been instrumental in identifying critical biases in CIL models towards OOD samples and newly added classes, offering crucial insights for designing future open-world CIL systems.\n\nIn conclusion, the evolution of OOD detection has seen a critical shift from ad-hoc evaluations to sophisticated, standardized benchmarking and unified evaluation frameworks. The development of meticulously curated datasets like \\textit{ImageNet-OOD} \\cite{yang2023ckx} has been indispensable for disentangling various types of distribution shifts, while comprehensive software platforms such as OOD-Bench \\cite{huang2023ood} and PyTorch-OOD \\cite{kirchheim20229jl} provide the necessary infrastructure for reproducible and fair comparisons. Specialized benchmarks like UB-GOLD \\cite{wang2024q01} for graph data, medical imaging benchmarks \\cite{vasiliuk20233w9, anthony2023slf}, and OpenCIL \\cite{miao20246mk} for CIL have expanded the field's evaluative rigor into complex domains. Despite these advancements, challenges remain in creating truly exhaustive benchmarks that capture the full spectrum of real-world OOD scenarios, particularly for dynamic and 'near-OOD' shifts, and in developing evaluation protocols that scale effectively for increasingly large foundation models. Future research must continue to bridge the gap between empirical performance and theoretical understanding, ensuring that benchmarks not only measure but also drive the development of truly robust and trustworthy OOD solutions.\n\n\n\\label{sec:conclusion_and_future_directions}\n\n\\section{Conclusion and Future Directions}\n\\label{sec:conclusion\\_\\_and\\_\\_future\\_directions}\n\n\\subsection{Synthesis of Key Trends and Contributions}\n\\label{sec:8\\_1\\_synthesis\\_of\\_key\\_trends\\_\\_and\\_\\_contributions}\n\nThe field of Out-of-Distribution (OOD) detection has undergone a profound transformation, evolving from rudimentary post-hoc scoring mechanisms to sophisticated, context-aware strategies that leverage advanced model architectures and rigorous theoretical foundations. This progression is driven by the imperative to build more reliable, adaptable, and trustworthy AI systems capable of operating effectively and safely in unpredictable, open-world environments. The collective research consolidates our understanding of how OOD detection has matured to address the growing demands for robust uncertainty quantification across diverse applications.\n\nInitially, research focused on extracting OOD signals from already trained models, often through feature engineering and statistical analysis. Early efforts explored the utility of reconstruction-based methods, with \\cite{zhou202250i} rethinking autoencoder-based OOD by introducing layerwise semantic reconstruction and a Normalized L2 Distance to make reconstruction error a more valid uncertainty measure. Complementing this, \\cite{zaeemzadeh2021lmh} proposed embedding in-distribution (ID) data into a union of 1-dimensional subspaces for compact representation and easier OOD detection. The analysis of feature properties also proved fruitful: \\cite{song2022f5d} introduced RankFeat, a post-hoc method that removes a dominant rank-1 component from high-level features based on spectral analysis, significantly improving performance. Similarly, \\cite{zhu2022oir} boosted OOD detection by rectifying features into their \"typical set\" using a Truncated Batch Normalization unit, mitigating the impact of extreme features. \\cite{yu2022egq} further explored feature norms, demonstrating that intermediate layers often provide better OOD separation than the final layer, and proposed a block selection method using pseudo OOD data. Challenging the prevailing reliance on simple output-based scores, \\cite{kuan2022qzl} revisited OOD baselines and strongly advocated for the effectiveness of k-Nearest Neighbor (KNN) distance on learned embeddings. More recently, \\cite{lu20249d4} advanced distance-based methods by modeling ID classes with a mixture of prototypes in a hyperspherical embedding space, capturing intra-class diversity, while \\cite{fang2024lv2} demonstrated the power of Kernel PCA with efficient explicit feature mappings for non-linear OOD separation. These methods collectively refined the ability to discern OOD samples from subtle cues within a model's internal representations, often without requiring additional training.\n\nA significant intellectual trajectory involved moving beyond passive post-hoc analysis to actively enhancing model robustness during training. This included adversarial training, as seen in \\cite{chen2020mbk}'s ALOE, which robustified OOD detectors against both adversarial in-distribution and OOD examples. A major paradigm shift was the widespread adoption and refinement of Outlier Exposure (OE), where auxiliary OOD data is used to regularize model training. \\cite{zhang20212tb} introduced Mixture Outlier Exposure (MixOE) to address fine-grained OOD by mixing ID and auxiliary data, creating a broader virtual outlier distribution. Providing theoretical grounding, \\cite{bitterwolf2022rw0} demonstrated that many OE methods are asymptotically equivalent to a binary discriminator, highlighting that differences often stem from estimation procedures. Subsequent work focused on optimizing the utility of auxiliary data: \\cite{jiang2023vzb} proposed Diverse Outlier Sampling (DOS) to select diverse and informative outliers, a concept further advanced by \\cite{yao2024epq}'s diverseMix, which provably enhances outlier diversity through semantic-level interpolation. Addressing practical challenges, \\cite{choi202367m} introduced a balanced energy regularization loss to account for class imbalance within auxiliary OOD data, while \\cite{hofmann2024gnx} leveraged Energy-based Hopfield Boosting for adaptive sampling of \"hard\" outliers. Complementing these data-centric strategies, methods like \\cite{cheng20233yi}'s Average of Pruning (AoP) tackled training instability and overfitting in OOD detection, a theme further explored by \\cite{chen2024kl7} with optimal parameter and neuron pruning based on gradient sensitivity. \\cite{wu20242p3} explicitly pursued feature separation based on Neural Collapse, constraining OOD features to an orthogonal subspace of ID features during fine-tuning. Concurrently, generative models also evolved: \\cite{zisselman2020cmx} introduced Deep Residual Flow for improved density modeling in feature activations, and \\cite{morningstar2020re9}'s Density of States Estimation (DoSE) shifted focus from direct likelihoods to the typicality of multiple summary statistics, overcoming the \"high likelihood for OOD\" pathology.\n\nThe field has also expanded dramatically to encompass complex data modalities, specialized learning paradigms, and the formidable capabilities of foundation models. For dense prediction tasks, \\cite{liu2022fdj} proposed Residual Pattern Learning (RPL) for pixel-wise OOD detection in semantic segmentation, decoupling it from the main task. \\cite{besnier2021jgn} further enhanced segmentation OOD by learning from local adversarial attacks to generate OOD-like training data, while \\cite{gao2023epm}'s ATTA introduced anomaly-aware test-time adaptation to handle domain shifts. For graph-structured data, \\cite{liu202227x} pioneered unsupervised graph-level OOD detection with GOOD-D, a hierarchical contrastive learning framework, a direction further advanced by \\cite{wang2025xwm}'s GOLD, which uses implicit adversarial latent generation to synthesize OOD samples without auxiliary data, and \\cite{wang2024es5}'s GOODAT for test-time graph OOD detection. The rise of Vision-Language Models (VLMs) and Large Language Models (LLMs) has opened new frontiers: \\cite{miyai2023591} introduced GL-MCM for zero-shot OOD detection by combining global and local CLIP features, while \\cite{li20245b6} learned transferable negative prompts for open-vocabulary OOD, and \\cite{yu20249dd} proposed Self-Calibrated Tuning to mitigate spurious OOD features in VLMs. Leveraging LLMs further, \\cite{dai2023mhn} explored their world knowledge for multimodal OOD, carefully calibrating for hallucination, and \\cite{cao20246gj} used LLMs for \"envisioned outlier exposure\" in zero-shot settings. Multimodal OOD itself gained a dedicated benchmark with \\cite{dong2024a8k}'s MultiOOD, which also proposed the Agree-to-Disagree (A2D) algorithm to amplify inter-modal prediction discrepancies. This was complemented by \\cite{li2024rs5}'s DPU, addressing intra-class variability in multimodal OOD. Diffusion models also found their niche, with \\cite{graham20232re} applying Latent Diffusion Models for unsupervised 3D medical OOD detection, and \\cite{gao2023kmk}'s DiffGuard using pre-trained diffusion models for semantic mismatch-guided OOD. The field also expanded to long-tailed recognition \\cite{miao2023brn, wei2023f15}, LiDAR-based 3D object detection \\cite{ksel20246fe}, and even mathematical reasoning in GLMs using embedding trajectories \\cite{wang2024rej}.\n\nCrucially, the field has placed an increasing emphasis on theoretical guarantees, robust evaluation, and a critical re-evaluation of fundamental definitions to build truly trustworthy AI. \\cite{yang2022it3} introduced the Full-Spectrum OOD (FS-OOD) problem, distinguishing between semantic and covariate shifts, and proposed the SEM score for robust detection. This was followed by rigorous benchmarking efforts: \\cite{zimmerer2022rv6} established the MOOD 2020 benchmark for medical imaging, \\cite{yang2023ckx} created ImageNet-OOD to disentangle semantic and covariate shifts, and \\cite{wang2024is1} critically dissected OOD and Open-Set Recognition (OSR) methods and benchmarks. The \"Sorites Paradox\" in OOD evaluation was addressed by \\cite{long2024os1}, proposing the Incremental Shift OOD (IS-OOD) benchmark to categorize samples by continuous shift degrees. Theoretical underpinnings have also solidified: \\cite{park2023n97} provided a principled explanation for why feature norm helps OOD detection, linking it to hidden classifier confidence, while \\cite{du2024aea} formally analyzed when and how in-distribution labels provably help OOD detection. \\cite{fang20249gd} investigated the fundamental learnability of OOD detection, establishing necessary and sufficient conditions. For safety-critical systems, the focus shifted to provable guarantees: \\cite{cai2020lsi} developed real-time OOD detection for Cyber-Physical Systems (CPS) with conformal guarantees using VAEs and Deep SVDD, a concept extended by \\cite{kaur2022cty}'s iDECODe, which leveraged in-distribution equivariance. \\cite{kaur20248t3} further extended this to dependent data in CPS with temporal equivariance. Critically, \\cite{guerin202201y} argued that \"OOD detection is not all you need,\" proposing Out-of-Model-Scope (OMS) detection as a more direct goal for identifying model errors, and \\cite{vishwakarma2024z1m} introduced a human-in-the-loop framework to tame false positives with theoretical FPR guarantees. These interconnected developments highlight a maturation of the field, moving towards comprehensive solutions that are not only performant but also interpretable, reliable, and adaptable to the complex demands of real-world AI deployment.\n\\subsection{Open Challenges and Future Research Avenues}\n\\label{sec:8\\_2\\_open\\_challenges\\_\\_and\\_\\_future\\_research\\_avenues}\n\nThe quest for truly robust and autonomous AI systems hinges critically on their ability to reliably detect and appropriately handle Out-of-Distribution (OOD) inputs. Despite significant advancements, the field of OOD detection continues to grapple with several profound challenges that define current research frontiers and pave the way for future innovation.\n\nOne persistent challenge is the \"near OOD\" problem, where subtle shifts in data distribution are difficult to distinguish from in-distribution (ID) variations. Models often exhibit overconfidence on these semantically similar, yet novel, inputs, leading to unreliable predictions \\cite{ming2021wu7}. Addressing this requires a multi-faceted approach. Some research focuses on \\textbf{data-centric strategies} to refine the ID/OOD boundary during training. For instance, Mixture Outlier Exposure (MixOE) \\cite{zhang20212tb} generates virtual outliers by mixing ID and auxiliary data, specifically targeting fine-grained OOD detection where samples share visual similarities with ID data. Similarly, Virtual Outlier Smoothing (VOSo) \\cite{nie2024ghv} constructs virtual outliers by perturbing semantic regions of ID samples, aiming to create smoother, more robust decision boundaries. However, a key challenge remains in generating truly representative and diverse near-OOD samples without inadvertently corrupting the ID manifold. Other efforts concentrate on \\textbf{representation-centric enhancements}, aiming to improve the inherent separability of ID and OOD features. Batch Normalization Assisted Typical Set Estimation (BATS) \\cite{zhu2022oir} rectifies extreme features, while Variational Rectified Activation (VRA) \\cite{xu2023767} proposes optimal activation functions to improve ID/OOD separability. Leveraging Neural Collapse properties, such as ID/OOD Orthogonality (NC5) \\cite{ammar2023pr1}, projects features onto principal component spaces for better OOD detection, inherently aiding in distinguishing subtle shifts (as discussed in Section 4.2). Neuron Activation Coverage (NAC) \\cite{liu2023zb3} provides a novel uncertainty measure sensitive to abnormal activation patterns caused by subtle OOD inputs by quantifying neuron behavior. From a theoretical perspective, \\cite{du2024aea} highlights the crucial role of ID labels in these near-OOD scenarios. Despite these advancements, a fundamental understanding of \\textit{what constitutes a \"near OOD\" boundary} and how to robustly generalize detection across diverse, subtly shifted domains remains an open problem, necessitating more robust benchmarks like ImageNet-OOD \\cite{yang2023ckx} and IS-OOD \\cite{long2024os1} that disentangle semantic and covariate shifts for accurate evaluation.\n\nAnother significant open challenge is the scalability of OOD detection methods, particularly for increasingly large foundation models like Vision-Language Models (VLMs) and Large Language Models (LLMs). While these models offer unprecedented representational power and open-vocabulary capabilities (as explored in Section 5.3), traditional OOD methods often struggle with their computational and data demands, or fail to leverage their rich representations effectively without prohibitive inference costs or extensive fine-tuning. Current research is making strides in adapting OOD detection to this new paradigm. Approaches include leveraging pre-trained features, such as GL-MCM \\cite{miyai2023591} which combines global and local CLIP features for zero-shot OOD detection, offering flexibility for multi-object scenes. \\textbf{Prompt engineering and virtual outlier generation} are also emerging as scalable solutions: Outlier Label Exposure (OLE) \\cite{ding20242m0} uses auxiliary outlier class labels as pseudo OOD text prompts for VLMs, and NegPrompt \\cite{li20245b6} learns transferable negative prompts from ID data alone to enhance OOD sensitivity without external outlier data. Self-Calibrated Tuning (SCT) \\cite{yu20249dd} adaptively adjusts ID classification and OOD regularization in VLMs to mitigate spurious OOD features. The potential of LLMs for generating synthetic outlier exposure is explored by \\cite{cao20246gj}, envisioning how LLM knowledge can create diverse outlier labels for zero-shot OOD detection. For multimodal foundation models, the MultiOOD benchmark and the Agree-to-Disagree (A2D) algorithm \\cite{dong2024a8k} leverage inter-modal prediction discrepancies, while Dynamic Prototype Updating (DPU) \\cite{li2024rs5} accounts for intra-class variability. However, the core challenge lies in developing OOD detection frameworks that are \\textit{inherently} scalable, efficient, and robust for models with billions of parameters, without requiring extensive retraining or sacrificing the model's generalizability. This includes tackling prohibitive inference costs, catastrophic forgetting during OOD-specific fine-tuning, and the theoretical understanding of OOD behavior in these complex architectures, as highlighted by \\cite{miyai20247ro}.\n\nLooking ahead, future research avenues are poised to develop more adaptive and dynamic OOD systems that can learn and adjust in real-time. This involves moving beyond static OOD detectors to systems capable of continuous monitoring and adaptation in dynamic environments, such as Cyber-Physical Systems (CPS). Building on the practical deployment considerations discussed in Section 6.4, methods like those pioneered by \\cite{cai2020lsi} use learned nonconformity measures within a conformal prediction framework to provide real-time OOD detection with statistical guarantees. Further advancements like iDECODe \\cite{kaur2022cty} leverage in-distribution equivariance for conformal OOD detection with bounded false detection rates, a concept extended to dependent time-series data in \\cite{kaur20248t3}. The challenge of adapting to domain shifts at test time for dense OOD detection in segmentation is addressed by ATTA \\cite{gao2023epm}, which uses a dual-level adaptation framework. Future work needs to focus on \\textbf{online OOD detection} that can continuously update its model of ID and OOD without full retraining, \\textbf{proactive adaptation} that anticipates shifts, and \\textbf{self-correcting AI systems} that can not only detect OOD but also intelligently propose mitigation strategies or request human intervention \\cite{vishwakarma2024z1m}. The concept of adaptive sampling of \"hard\" outliers during training, as demonstrated by Energy-based Hopfield Boosting \\cite{hofmann2024gnx}, also contributes to dynamic system adjustment.\n\nAnother promising direction involves exploring \\textbf{causal inference for OOD detection} to understand underlying mechanisms rather than merely identifying statistical anomalies. Traditional OOD methods often rely on statistical correlations, making them vulnerable to spurious associations that do not generalize across different environments. The work by \\cite{ming2021wu7} on the impact of spurious correlation for OOD detection underscores this limitation. Future research should focus on developing OOD detectors that are robust to such correlations by explicitly learning causal relationships. This could involve leveraging frameworks like Invariant Risk Minimization (IRM) \\cite{arjovsky2019invariant} or Structural Causal Models (SCMs) to disentangle causal (invariant) features from non-causal (environmental) ones. Specific research questions include: How can we design training objectives that promote the learning of causally invariant representations that are inherently more robust to OOD shifts? Can interventional or counterfactual reasoning be used to identify features that truly \\textit{cause} an input to be OOD, leading to more interpretable and generalizable OOD signals? Furthermore, exploring causal discovery techniques to model the underlying causal graph of ID data could enable the detection of OOD samples as deviations from this fundamental structure, offering a deeper, more principled understanding of novelty.\n\nFinally, fostering deeper integration with other machine learning tasks like active learning and continual learning is crucial for holistic, efficient, and robust AI solutions that can operate autonomously in complex environments. OOD detection naturally complements \\textbf{active learning (AL)}, as OOD samples represent regions of uncertainty where the model's competence is low, making them ideal candidates for human labeling. SISOM \\cite{schmidt2024syr} proposes a unified approach, demonstrating that OOD detection and AL can be addressed simultaneously by leveraging enriched feature space distance metrics. Future work could explore how OOD uncertainty can more effectively guide AL to discover truly novel classes or subtle shifts, rather than just ambiguous ID samples. Similarly, in \\textbf{continual learning (CL)}, OOD detection is vital for maintaining robustness to previously learned ID data while reliably identifying novel inputs without catastrophic forgetting. Continual Evidential Deep Learning (CEDL) \\cite{aguilar2023ms5} offers a solution for simultaneous incremental object classification and OOD detection. MIntOOD \\cite{zhang2024cx0} extends this to multimodal intent understanding. The challenge lies in developing OOD detectors that can dynamically evolve with the model in CL settings, updating their ID boundaries without re-exposing to all past data or confusing new ID classes with true OOD. These integrated approaches represent a significant step towards building AI systems that are not only aware of their limitations but can also actively learn, adapt, and operate safely in dynamic, open-world settings.\n\nUltimately, the future of OOD detection lies in a paradigm shift from reactive, isolated detectors to proactive, integrated, and self-monitoring AI systems. This grand vision entails models that continuously learn their own competence boundaries, adapt dynamically to evolving environments, leverage causal understanding for robust generalization, and seamlessly integrate with learning processes like active and continual learning. Such holistic, efficient, and robust AI solutions will be indispensable for building trustworthy systems that can operate autonomously and ethically in an increasingly complex and unpredictable world.\n\\subsection{Ethical Considerations and Societal Impact}\n\\label{sec:8\\_3\\_ethical\\_considerations\\_\\_and\\_\\_societal\\_impact}\n\nThe integration of Out-of-Distribution (OOD) detection mechanisms into real-world AI systems, particularly in high-stakes applications, necessitates a rigorous examination of their ethical implications and potential societal impacts. Failures in OOD detection can precipitate profound consequences, ranging from critical safety hazards in autonomous systems to the perpetuation of discriminatory outcomes in sensitive decision-making processes. Consequently, advancements in this domain must transcend mere technical performance, actively embedding principles of transparency, fairness, and accountability to foster responsible and human-centric AI deployment.\n\nA paramount ethical concern centers on the deployment of AI models in safety-critical Cyber-Physical Systems (CPS), where OOD failures can be catastrophic. For instance, autonomous vehicles and medical diagnostic tools rely heavily on robust OOD detection to prevent misinterpretations of novel inputs that could lead to severe accidents or incorrect diagnoses \\cite{cai2020lsi}. The ethical imperative here is to ensure not only high detection rates but also controlled error rates, particularly false positives and false negatives. While the technical details of certifiable OOD detection are elaborated in Section 7.2, it is ethically crucial that such systems provide statistically bounded false detection rates, as proposed by frameworks like conformal prediction \\cite{kaur2022cty, kaur20248t3}. These guarantees are vital safeguards against erroneous rejections (false positives) that could trigger unnecessary system shutdowns, or, conversely, undetected novelties (false negatives) leading to silent, dangerous failures. The challenge of managing false positives, which can erode user trust and increase human workload, is addressed by human-in-the-loop frameworks that adaptively control the False Positive Rate (FPR) with theoretical guarantees \\cite{vishwakarma2024z1m}. From a broader socio-technical perspective, the integration of human oversight in such systems also raises ethical questions about the cognitive load, potential for automation bias, and psychological impact on human supervisors, necessitating careful design of human-AI interfaces and clear protocols.\n\nBeyond error rates, the very definition of \"out-of-distribution\" carries significant ethical weight. \\cite{guerin202201y} critically argues that focusing solely on \"Out-of-Distribution Detection\" might be insufficient for safety, proposing \"Out-of-Model-Scope\" (OMS) detection as a more ethically aligned objective. OMS aims to identify inputs that would lead to actual model errors, rather than just distribution shifts, thereby directly addressing the imperative to abstain from unsafe predictions. Furthermore, the robustness of OOD detectors against malicious inputs is a critical safety concern, as adversarial attacks could manipulate detectors into making unsafe decisions \\cite{chen2020mbk}. The inherent difficulty in distinguishing harmless from potentially unsafe OOD events, particularly in dynamic environments like Reinforcement Learning, underscores the need for clear definitions of \"unknown events\" and robust safety assurance frameworks for ML components \\cite{haider20249q8}. This highlights the necessity for ethical guidelines and potentially regulatory standards to govern the certification and deployment of OOD-enabled AI systems.\n\nA particularly critical ethical dimension is the potential for bias in OOD detection, which can lead to unfair or discriminatory outcomes. If OOD models are trained on data reflecting societal biases, they can inadvertently amplify these biases. For instance, \\cite{ming2021wu7} demonstrates how spurious correlations in training data (e.g., associating certain backgrounds with specific classes) can severely degrade OOD detection performance. Models relying on these non-causal features might confidently misclassify inputs from underrepresented demographic groups as \"anomalous\" if those inputs exhibit features statistically correlated with OOD data in the training set. This can result in discriminatory rejections or differential treatment, where certain groups are disproportionately flagged as \"outliers.\" Such biases are not merely technical failures but ethical breaches, demanding fairness-aware OOD algorithms that explicitly analyze and mitigate performance disparities across demographic subgroups. While interpretability methods like GAIA, which uses gradient-based attribution abnormality \\cite{chen2023za1}, or Neuron Activation Coverage (NAC) \\cite{liu2023zb3}, are not direct fairness interventions, they are crucial tools for auditing models. By revealing \\textit{why} an input is deemed OOD, they enable practitioners to identify and address unintended biases in the OOD decision-making process. In multimodal contexts, where biases can exist across various data streams (e.g., text, video, audio), the challenge of ensuring fair OOD detection is further compounded \\cite{zhang2024cx0}.\n\nFinally, the societal impact of deploying AI models that may fail silently on novel inputs is a pervasive ethical concern. The fundamental purpose of OOD detection is to prevent such silent failures, enabling models to express uncertainty or abstain when confronted with unfamiliar data. Methods like DoSE \\cite{morningstar2020re9} directly tackle the \"high likelihood for OOD\" pathology, where generative models might assign high confidence to OOD data, thereby preventing a dangerous false sense of security. Furthermore, a deeper understanding of how in-distribution (ID) labels influence OOD detection, especially for \"near OOD\" scenarios where ethical risks are heightened \\cite{du2024aea}, is vital to avoid mischaracterizing subtle shifts as benign. The development of robust and comprehensive in-distribution representations, as exemplified by methods like MOODv2 \\cite{li2024n34}, inherently makes OOD detection more reliable and less prone to silent failures, as models gain a more accurate understanding of what constitutes \"normal\" data.\n\nIn conclusion, while significant technical advancements have propelled OOD detection forward, the ethical considerations and societal impact remain paramount. Future research must prioritize the development of robust safeguards, including statistical guarantees (as discussed in Section 7.2) and adaptive human-in-the-loop mechanisms \\cite{vishwakarma2024z1m}, to rigorously control false positives and negatives in safety-critical applications. Crucially, a concerted effort is needed to ensure fairness by investigating and mitigating potential biases, particularly those arising from spurious correlations \\cite{ming2021wu7}, through the development of transparent and interpretable methods \\cite{chen2023za1, liu2023zb3} that facilitate auditing and accountability. Ultimately, the goal is to cultivate a paradigm where AI systems not only achieve high performance but also operate responsibly, recognizing their limitations, communicating uncertainty effectively, and adhering to ethical guidelines, thereby fostering trust and enabling the safe and equitable integration of AI into society.\n\n\n\\newpage\n\\section*{References}\n\\addcontentsline{toc}{section}{References}\n\n\\begin{thebibliography}{186}\n\n\\bibitem{han2022ixj}\nTe Han, and Yanfang Li (2022). \\textit{Out-of-distribution detection-assisted trustworthy machinery fault diagnosis approach with uncertainty-aware deep ensembles}. Reliability Engineering & System Safety.\n\n\\bibitem{zhou202250i}\nYibo Zhou (2022). \\textit{Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{yang2022it3}\nJingkang Yang, Kaiyang Zhou, and Ziwei Liu (2022). \\textit{Full-Spectrum Out-of-Distribution Detection}. International Journal of Computer Vision.\n\n\\bibitem{zisselman2020cmx}\nE. Zisselman, and Aviv Tamar (2020). \\textit{Deep Residual Flow for Out of Distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{song2022f5d}\nYue Song, N. Sebe, and Wei Wang (2022). \\textit{RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{liu202227x}\nYixin Liu, Kaize Ding, Huan Liu, et al. (2022). \\textit{GOOD-D: On Unsupervised Graph Out-Of-Distribution Detection}. Web Search and Data Mining.\n\n\\bibitem{zaeemzadeh2021lmh}\nAlireza Zaeemzadeh, NiccolÃ³ Bisagno, Zeno Sambugaro, et al. (2021). \\textit{Out-of-Distribution Detection Using Union of 1-Dimensional Subspaces}. Computer Vision and Pattern Recognition.\n\n\\bibitem{ming2021wu7}\nYifei Ming, Hang Yin, and Yixuan Li (2021). \\textit{On the Impact of Spurious Correlation for Out-of-distribution Detection}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{zhu2022oir}\nYao Zhu, YueFeng Chen, Chuanlong Xie, et al. (2022). \\textit{Boosting Out-of-distribution Detection with Typical Features}. Neural Information Processing Systems.\n\n\\bibitem{jeong2020z5c}\nTaewon Jeong, and Heeyoung Kim (2020). \\textit{OOD-MAML: Meta-Learning for Few-Shot Out-of-Distribution Detection and Classification}. Neural Information Processing Systems.\n\n\\bibitem{chen2020mbk}\nJiefeng Chen, Yixuan Li, Xi Wu, et al. (2020). \\textit{Robust Out-of-distribution Detection for Neural Networks}. Unpublished manuscript.\n\n\\bibitem{morningstar2020re9}\nW. Morningstar, Cusuh Ham, Andrew Gallagher, et al. (2020). \\textit{Density of States Estimation for Out-of-Distribution Detection}. International Conference on Artificial Intelligence and Statistics.\n\n\\bibitem{li20227o1}\nZenan Li, Qitian Wu, Fan Nie, et al. (2022). \\textit{GraphDE: A Generative Framework for Debiased Learning and Out-of-Distribution Detection on Graphs}. Neural Information Processing Systems.\n\n\\bibitem{xie2023uki}\nW. Xie, Te Han, Zhong Pei, et al. (2023). \\textit{A unified out-of-distribution detection framework for trustworthy prognostics and health management in renewable energy systems}. Engineering applications of artificial intelligence.\n\n\\bibitem{liu2022fdj}\nYuyuan Liu, Choubo Ding, Yu Tian, et al. (2022). \\textit{Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection in Semantic Segmentation}. IEEE International Conference on Computer Vision.\n\n\\bibitem{zimmerer2022rv6}\nDavid Zimmerer, Peter M. Full, Fabian Isensee, et al. (2022). \\textit{MOOD 2020: A Public Benchmark for Out-of-Distribution Detection and Localization on Medical Images}. IEEE Transactions on Medical Imaging.\n\n\\bibitem{kaur2022cty}\nR. Kaur, Susmit Jha, Anirban Roy, et al. (2022). \\textit{iDECODe: In-distribution Equivariance for Conformal Out-of-distribution Detection}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{zhang20212tb}\nJingyang Zhang, Nathan Inkawhich, Randolph Linderman, et al. (2021). \\textit{Mixture Outlier Exposure: Towards Out-of-Distribution Detection in Fine-grained Environments}. IEEE Workshop/Winter Conference on Applications of Computer Vision.\n\n\\bibitem{dong2021swz}\nXin Dong, Junfeng Guo, Ang Li, et al. (2021). \\textit{Neural Mean Discrepancy for Efficient Out-of-Distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{cai2020lsi}\nFeiyang Cai, and X. Koutsoukos (2020). \\textit{Real-time Out-of-distribution Detection in Learning-Enabled Cyber-Physical Systems}. International Conference on Cyber-Physical Systems.\n\n\\bibitem{gawlikowski2022p4r}\nJ. Gawlikowski, Sudipan Saha, Anna M. Kruspe, et al. (2022). \\textit{An Advanced Dirichlet Prior Network for Out-of-Distribution Detection in Remote Sensing}. IEEE Transactions on Geoscience and Remote Sensing.\n\n\\bibitem{paper2020kkd}\nUnknown Authors (2020). \\textit{Hyperparameter-Free Out-of-Distribution Detection Using Cosine Similarity}. Asian Conference on Computer Vision.\n\n\\bibitem{kirchheim20229jl}\nKonstantin Kirchheim, Marco Filax, and F. Ortmeier (2022). \\textit{PyTorch-OOD: A Library for Out-of-Distribution Detection based on PyTorch}. 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW).\n\n\\bibitem{lang20237w3}\nHao Lang, Yinhe Zheng, Yixuan Li, et al. (2023). \\textit{A Survey on Out-of-Distribution Detection in NLP}. Trans. Mach. Learn. Res..\n\n\\bibitem{yu2022egq}\nYeonguk Yu, Sungho Shin, Seongju Lee, et al. (2022). \\textit{Block Selection Method for Using Feature Norm in Out-of-Distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{zhao20221ag}\nQingling Zhao, Mingqiang Chen, Zonghua Gu, et al. (2022). \\textit{CAN Bus Intrusion Detection Based on Auxiliary Classifier GAN and Out-of-distribution Detection}. ACM Transactions on Embedded Computing Systems.\n\n\\bibitem{ammar2023pr1}\nMouin Ben Ammar, Nacim Belkhir, Sebastian Popescu, et al. (2023). \\textit{NECO: NEural Collapse Based Out-of-distribution detection}. International Conference on Learning Representations.\n\n\\bibitem{besnier2021jgn}\nVictor Besnier, Andrei Bursuc, David Picard, et al. (2021). \\textit{Triggering Failures: Out-Of-Distribution detection by learning from local adversarial attacks in Semantic Segmentation}. IEEE International Conference on Computer Vision.\n\n\\bibitem{guerin202201y}\nJoris Gu'erin, Kevin Delmas, Raul Sena Ferreira, et al. (2022). \\textit{Out-Of-Distribution Detection Is Not All You Need}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{liu2023zb3}\nY. Liu, Chris Xing Tian, Haoliang Li, et al. (2023). \\textit{Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization}. International Conference on Learning Representations.\n\n\\bibitem{berger20214a3}\nChristoph Berger, Magdalini Paschali, Ben Glocker, et al. (2021). \\textit{Confidence-based Out-of-Distribution Detection: A Comparative Study and Analysis}. UNSURE/PIPPI@MICCAI.\n\n\\bibitem{yang2022ci8}\nYijun Yang, Ruiyuan Gao, and Qiang Xu (2022). \\textit{Out-of-Distribution Detection with Semantic Mismatch under Masking}. European Conference on Computer Vision.\n\n\\bibitem{lu2023i8o}\nFan Lu, Kai Zhu, Wei Zhai, et al. (2023). \\textit{Uncertainty-Aware Optimal Transport for Semantically Coherent Out-of-Distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{kim2024nhz}\nB. Kim, B. Kim, and Y. Hyun (2024). \\textit{Investigation of out-of-distribution detection across various models and training methodologies}. Neural Networks.\n\n\\bibitem{miao2023brn}\nWenjun Miao, Guansong Pang, Tianqi Li, et al. (2023). \\textit{Out-of-Distribution Detection in Long-Tailed Recognition with Calibrated Outlier Class Learning}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{wang2022mbf}\nQizhou Wang, Feng Liu, Yonggang Zhang, et al. (2022). \\textit{Watermarking for Out-of-distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{zhang202312h}\nJi Zhang, Lianli Gao, Bingguang Hao, et al. (2023). \\textit{From Global to Local: Multi-Scale Out-of-Distribution Detection}. IEEE Transactions on Image Processing.\n\n\\bibitem{kuan2022qzl}\nJo-Lan Kuan, and Jonas W. Mueller (2022). \\textit{Back to the Basics: Revisiting Out-of-Distribution Detection Baselines}. arXiv.org.\n\n\\bibitem{choi202367m}\nHyunjun Choi, Hawook Jeong, and Jin Young Choi (2023). \\textit{Balanced Energy Regularization Loss for Out-of-distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{liu2025wgr}\nBojun Liu, Jordan G Boysen, I. C. Unarta, et al. (2025). \\textit{Exploring transition states of protein conformational changes via out-of-distribution detection in the hyperspherical latent space}. Nature Communications.\n\n\\bibitem{miyai2023591}\nAtsuyuki Miyai, Qing Yu, Go Irie, et al. (2023). \\textit{GL-MCM: Global and Local Maximum Concept Matching for Zero-Shot Out-of-Distribution Detection}. International Journal of Computer Vision.\n\n\\bibitem{bitterwolf2022rw0}\nJulian Bitterwolf, Alexander Meinke, Maximilian Augustin, et al. (2022). \\textit{Breaking Down Out-of-Distribution Detection: Many Methods Based on OOD Training Data Estimate a Combination of the Same Core Quantities}. International Conference on Machine Learning.\n\n\\bibitem{gomes2022zyv}\nEduardo Dadalto Camara Gomes, F. Alberge, P. Duhamel, et al. (2022). \\textit{Igeood: An Information Geometry Approach to Out-of-Distribution Detection}. International Conference on Learning Representations.\n\n\\bibitem{gao2023kmk}\nRuiyuan Gao, Chenchen Zhao, Lanqing Hong, et al. (2023). \\textit{DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models}. IEEE International Conference on Computer Vision.\n\n\\bibitem{cao20224r3}\nSenqi Cao, and Zhongfei Zhang (2022). \\textit{Deep Hybrid Models for Out-of-Distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{wei2023f15}\nTong Wei, Bo-Lin Wang, and Min-Ling Zhang (2023). \\textit{EAT: Towards Long-Tailed Out-of-Distribution Detection}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{behpour2023x13}\nSima Behpour, T. Doan, Xin Li, et al. (2023). \\textit{GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients}. Neural Information Processing Systems.\n\n\\bibitem{wang2025xwm}\nDanny Wang, Ruihong Qiu, Guangdong Bai, et al. (2025). \\textit{GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation}. International Conference on Learning Representations.\n\n\\bibitem{graham20232re}\nM. Graham, W. H. Pinaya, P. Wright, et al. (2023). \\textit{Unsupervised 3D out-of-distribution detection with latent diffusion models}. International Conference on Medical Image Computing and Computer-Assisted Intervention.\n\n\\bibitem{bao2024kfh}\nTianyi Bao, Qitian Wu, Zetian Jiang, et al. (2024). \\textit{Graph Out-of-Distribution Detection Goes Neighborhood Shaping}. International Conference on Machine Learning.\n\n\\bibitem{park2023n97}\nJaewoo Park, Jacky Chen Long Chai, Jaeho Yoon, et al. (2023). \\textit{Understanding the Feature Norm for Out-of-Distribution Detection}. IEEE International Conference on Computer Vision.\n\n\\bibitem{haider2023vid}\nTom Haider, Karsten Roscher, Felippe Schmoeller da Roza, et al. (2023). \\textit{Out-of-Distribution Detection for Reinforcement Learning Agents with Probabilistic Dynamics Models}. Adaptive Agents and Multi-Agent Systems.\n\n\\bibitem{ghosal2023q20}\nSoumya Suvra Ghosal, Yiyou Sun, and Yixuan Li (2023). \\textit{How to Overcome Curse-of-Dimensionality for Out-of-Distribution Detection?}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{yang2023ckx}\nWilliam Yang, Byron Zhang, and Olga Russakovsky (2023). \\textit{ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms}. International Conference on Learning Representations.\n\n\\bibitem{chen2023tz9}\nSishuo Chen, Wenkai Yang, Xiaohan Bi, et al. (2023). \\textit{Fine-Tuning Deteriorates General Textual Out-of-Distribution Detection by Distorting Task-Agnostic Features}. Findings.\n\n\\bibitem{averly20239rv}\nReza Averly, and Wei-Lun Chao (2023). \\textit{Unified Out-Of-Distribution Detection: A Model-Specific Perspective}. IEEE International Conference on Computer Vision.\n\n\\bibitem{zhu2023u9p}\nJianing Zhu, Hengzhuang Li, Jiangchao Yao, et al. (2023). \\textit{Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection Capability}. International Conference on Machine Learning.\n\n\\bibitem{mishra20236n9}\nDivyanshu Mishra, He Zhao, Pramit Saha, et al. (2023). \\textit{Dual Conditioned Diffusion Models for Out-of-Distribution Detection: Application to Fetal Ultrasound Videos}. International Conference on Medical Image Computing and Computer-Assisted Intervention.\n\n\\bibitem{yu2023r3c}\nShuyang Yu, Junyuan Hong, Haotao Wang, et al. (2023). \\textit{Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection}. International Conference on Learning Representations.\n\n\\bibitem{dai2023mhn}\nYi Dai, Hao Lang, Kaisheng Zeng, et al. (2023). \\textit{Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection}. Conference on Empirical Methods in Natural Language Processing.\n\n\\bibitem{arajo2023dau}\nTeresa AraÃºjo, Guilherme Aresta, U. Schmidt-Erfurth, et al. (2023). \\textit{Few-shot out-of-distribution detection for automated screening in retinal OCT images using deep learning}. Scientific Reports.\n\n\\bibitem{xu2023767}\nMing Xu, Zheng Lian, B. Liu, et al. (2023). \\textit{VRA: Variational Rectified Activation for Out-of-distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{cheng20233yi}\nZhen Cheng, Fei Zhu, Xu-Yao Zhang, et al. (2023). \\textit{Average of Pruning: Improving Performance and Stability of Out-of-Distribution Detection}. IEEE Transactions on Neural Networks and Learning Systems.\n\n\\bibitem{vasiliuk20233w9}\nAnton Vasiliuk, Daria Frolova, M. Belyaev, et al. (2023). \\textit{Limitations of Out-of-Distribution Detection in 3D Medical Image Segmentation}. Journal of Imaging.\n\n\\bibitem{anthony2023slf}\nHarry Anthony, and K. Kamnitsas (2023). \\textit{On the use of Mahalanobis distance for out-of-distribution detection with neural networks for medical imaging}. UNSURE@MICCAI.\n\n\\bibitem{yang2023pre}\nTaocun Yang, Y. Huang, Yanlin Xie, et al. (2023). \\textit{MixOOD: Improving Out-of-distribution Detection with Enhanced Data Mixup}. ACM Trans. Multim. Comput. Commun. Appl..\n\n\\bibitem{liu2023i6i}\nBo Liu, Li-Ming Zhan, Zexin Lu, et al. (2023). \\textit{How Good Are LLMs at Out-of-Distribution Detection?}. International Conference on Language Resources and Evaluation.\n\n\\bibitem{guan2023dwv}\nXiaoyuan Guan, Zhouwu Liu, Weishi Zheng, et al. (2023). \\textit{Revisit PCA-based technique for Out-of-Distribution Detection}. IEEE International Conference on Computer Vision.\n\n\\bibitem{zhang2024mgg}\nZihan Zhang, Zhuo Xu, and Xiang Xiang (2024). \\textit{Vision-Language Dual-Pattern Matching for Out-of-Distribution Detection}. European Conference on Computer Vision.\n\n\\bibitem{liu20245e5}\nKai Liu, Zhihang Fu, Chao Chen, et al. (2024). \\textit{Category-Extensible Out-of-Distribution Detection via Hierarchical Context Descriptions}. Neural Information Processing Systems.\n\n\\bibitem{jia2024zld}\nYulong Jia, Jiaming Li, Ganlong Zhao, et al. (2024). \\textit{Enhancing out-of-distribution detection via diversified multi-prototype contrastive learning}. Pattern Recognition.\n\n\\bibitem{jiang2023vzb}\nWenyu Jiang, Hao Cheng, Mingcai Chen, et al. (2023). \\textit{DOS: Diverse Outlier Sampling for Out-of-Distribution Detection}. International Conference on Learning Representations.\n\n\\bibitem{gao2023epm}\nZhitong Gao, Shipeng Yan, and Xuming He (2023). \\textit{ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation}. Neural Information Processing Systems.\n\n\\bibitem{henriksson20233hb}\nJens Henriksson, Stig Ursing, Murat Erdogan, et al. (2023). \\textit{Out-of-Distribution Detection as Support for Autonomous Driving Safety Lifecycle}. Requirements Engineering: Foundation for Software Quality.\n\n\\bibitem{saadati2023i8u}\nM. Saadati, Aditya Balu, Shivani Chiranjeevi, et al. (2023). \\textit{Out-of-Distribution Detection Algorithms for Robust Insect Classification}. Plant Phenomics.\n\n\\bibitem{miao2023zf5}\nGongxun Miao, Guohua Wu, Zhen Zhang, et al. (2023). \\textit{SPN: A Method of Few-Shot Traffic Classification With Out-of-Distribution Detection Based on Siamese Prototypical Network}. IEEE Access.\n\n\\bibitem{chen2023za1}\nJinggang Chen, Junjie Li, Xiaoyang Qu, et al. (2023). \\textit{GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{aguilar2023ms5}\nEduardo Aguilar, B. Raducanu, P. Radeva, et al. (2023). \\textit{Continual Evidential Deep Learning for Out-of-Distribution Detection}. 2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW).\n\n\\bibitem{ouyang2023wxc}\nYawen Ouyang, Yongchang Cao, Yuan Gao, et al. (2023). \\textit{On Prefix-tuning for Lightweight Out-of-distribution Detection}. Annual Meeting of the Association for Computational Linguistics.\n\n\\bibitem{lafon2023w37}\nMarc Lafon, Elias Ramzi, ClÃ©ment Rambour, et al. (2023). \\textit{Hybrid Energy Based Model in the Feature Space for Out-of-Distribution Detection}. International Conference on Machine Learning.\n\n\\bibitem{ksel20246fe}\nMichael KÃ¶sel, M. Schreiber, Michael Ulrich, et al. (2024). \\textit{Revisiting Out-of-Distribution Detection in LiDAR-based 3D Object Detection}. 2024 IEEE Intelligent Vehicles Symposium (IV).\n\n\\bibitem{ding20242m0}\nChoubo Ding, and Guansong Pang (2024). \\textit{Zero-Shot Out-of-Distribution Detection with Outlier Label Exposure}. IEEE International Joint Conference on Neural Network.\n\n\\bibitem{zhang2024d24}\nYonggang Zhang, Jie Lu, Bo Peng, et al. (2024). \\textit{Learning to Shape In-distribution Feature Space for Out-of-distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{wu20242p3}\nYingwen Wu, Ruiji Yu, Xinwen Cheng, et al. (2024). \\textit{Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection}. International Conference on Learning Representations.\n\n\\bibitem{yao2024epq}\nHaiyu Yao, Zongbo Han, Huazhu Fu, et al. (2024). \\textit{Out-Of-Distribution Detection with Diversification (Provably)}. Neural Information Processing Systems.\n\n\\bibitem{chen2024kl7}\nChao Chen, Zhihang Fu, Kai Liu, et al. (2024). \\textit{Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{kaur20248t3}\nRamneet Kaur, Yahan Yang, O. Sokolsky, et al. (2024). \\textit{Out-of-distribution Detection in Dependent Data for Cyber-physical Systems with Conformal Guarantees}. ACM Trans. Cyber Phys. Syst..\n\n\\bibitem{zhang2024cx0}\nHanlei Zhang, Qianrui Zhou, Hua Xu, et al. (2024). \\textit{Multimodal Classification and Out-of-distribution Detection for Multimodal Intent Understanding}. arXiv.org.\n\n\\bibitem{schmidt2024syr}\nSebastian Schmidt, Leonard Schenk, Leo Schwinn, et al. (2024). \\textit{A Unified Approach Towards Active Learning and Out-of-Distribution Detection}. Trans. Mach. Learn. Res..\n\n\\bibitem{nie2024ghv}\nJun Nie, Yadan Luo, Shanshan Ye, et al. (2024). \\textit{Out-of-Distribution Detection with Virtual Outlier Smoothing}. International Journal of Computer Vision.\n\n\\bibitem{xu2025hom}\nHaoyan Xu, Zhengtao Yao, Yushun Dong, et al. (2025). \\textit{Few-Shot Graph Out-of-Distribution Detection with LLMs}. arXiv.org.\n\n\\bibitem{vojr2023ee1}\nTomÃ¡s VojÃ­r, Jan Sochman, Rahaf Aljundi, et al. (2023). \\textit{Calibrated Out-of-Distribution Detection with a Generic Representation}. 2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW).\n\n\\bibitem{lu20249d4}\nHaodong Lu, Dong Gong, Shuo Wang, et al. (2024). \\textit{Learning with Mixture of Prototypes for Out-of-Distribution Detection}. International Conference on Learning Representations.\n\n\\bibitem{nie20240bk}\nJun Nie, Yonggang Zhang, Zhen Fang, et al. (2024). \\textit{Out-of-Distribution Detection with Negative Prompts}. International Conference on Learning Representations.\n\n\\bibitem{du20248xe}\nXuefeng Du, Zhen Fang, Ilias Diakonikolas, et al. (2024). \\textit{How Does Unlabeled Data Provably Help Out-of-Distribution Detection?}. International Conference on Learning Representations.\n\n\\bibitem{li20245b6}\nTianqi Li, Guansong Pang, Xiaolong Bai, et al. (2024). \\textit{Learning Transferable Negative Prompts for Out-of-Distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{fang20248g5}\nXiang Fang, A. Easwaran, B. Genest, et al. (2024). \\textit{Your data is not perfect: Towards cross-domain out-of-distribution detection in class-imbalanced data}. Expert systems with applications.\n\n\\bibitem{linmans2024pi9}\nJ. Linmans, Gabriel Raya, J. Laak, et al. (2024). \\textit{Diffusion models for out-of-distribution detection in digital pathology}. Medical Image Anal..\n\n\\bibitem{chen20243na}\nJiaqi Chen, T. H. Teo, C. Kok, et al. (2024). \\textit{A Novel Single-Word Speech Recognition on Embedded Systems Using a Convolution Neuron Network with Improved Out-of-Distribution Detection}. Electronics.\n\n\\bibitem{dong2024a8k}\nHao Dong, Yue Zhao, Eleni Chatzi, et al. (2024). \\textit{MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities}. Neural Information Processing Systems.\n\n\\bibitem{miyai20247ro}\nAtsuyuki Miyai, Jingkang Yang, Jingyang Zhang, et al. (2024). \\textit{Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey}. Trans. Mach. Learn. Res..\n\n\\bibitem{zhang2024hh0}\nXiaochen Zhang, Chen Wang, Wei Zhou, et al. (2024). \\textit{Trustworthy Diagnostics With Out-of-Distribution Detection: A Novel Max-Consistency and Min-Similarity Guided Deep Ensembles for Uncertainty Estimation}. IEEE Internet of Things Journal.\n\n\\bibitem{cao20246gj}\nChentao Cao, Zhun Zhong, Zhanke Zhou, et al. (2024). \\textit{Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection}. International Conference on Machine Learning.\n\n\\bibitem{peng20243ji}\nBo Peng, Yadan Luo, Yonggang Zhang, et al. (2024). \\textit{ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection}. International Conference on Learning Representations.\n\n\\bibitem{wang2024es5}\nLuzhi Wang, Dongxiao He, He Zhang, et al. (2024). \\textit{GOODAT: Towards Test-time Graph Out-of-Distribution Detection}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{wang2024q01}\nYili Wang, Yixin Liu, Xu Shen, et al. (2024). \\textit{Unifying Unsupervised Graph-Level Anomaly Detection and Out-of-Distribution Detection: A Benchmark}. International Conference on Learning Representations.\n\n\\bibitem{wang2024rej}\nYiming Wang, Pei Zhang, Baosong Yang, et al. (2024). \\textit{Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning}. Neural Information Processing Systems.\n\n\\bibitem{hong2024xls}\nZesheng Hong, Yubiao Yue, Yubin Chen, et al. (2024). \\textit{Out-of-distribution Detection in Medical Image Analysis: A survey}. arXiv.org.\n\n\\bibitem{yu20249dd}\nGeng Yu, Jianing Zhu, Jiangchao Yao, et al. (2024). \\textit{Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{fan2024u9i}\nKe Fan, Tong Liu, Xingyu Qiu, et al. (2024). \\textit{Test-Time Linear Out-of-Distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{fang2024lv2}\nKun Fang, Qinghua Tao, Kexin Lv, et al. (2024). \\textit{Kernel PCA for Out-of-Distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{vojivr202444c}\nTom'avs Voj'ivr, Jan Sochman, and Jivr'i Matas (2024). \\textit{PixOOD: Pixel-Level Out-of-Distribution Detection}. European Conference on Computer Vision.\n\n\\bibitem{li2024rs5}\nLi Li, Huixian Gong, Hao Dong, et al. (2024). \\textit{DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection}. arXiv.org.\n\n\\bibitem{tang20243rx}\nKeke Tang, Chao Hou, Weilong Peng, et al. (2024). \\textit{CORES: Convolutional Response-based Score for Out-of-distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{li2024n34}\nJingyao Li, Pengguang Chen, Shaozuo Yu, et al. (2024). \\textit{MOODv2: Masked Image Modeling for Out-of-Distribution Detection}. IEEE Transactions on Pattern Analysis and Machine Intelligence.\n\n\\bibitem{hofmann2024gnx}\nClaus Hofmann, Simon Schmid, Bernhard Lehner, et al. (2024). \\textit{Energy-based Hopfield Boosting for Out-of-Distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{zhou20243bx}\nZhi Zhou, Ming Yang, Jiang-Xin Shi, et al. (2024). \\textit{DeCoOp: Robust Prompt Tuning with Out-of-Distribution Detection}. International Conference on Machine Learning.\n\n\\bibitem{vishwakarma2024z1m}\nHarit Vishwakarma, Heguang Lin, and Ramya Korlakai Vinayak (2024). \\textit{Taming False Positives in Out-of-Distribution Detection with Human Feedback}. International Conference on Artificial Intelligence and Statistics.\n\n\\bibitem{wang2024y55}\nKaizheng Wang, Fabio Cuzzolin, Keivan K1 Shariatmadar, et al. (2024). \\textit{Credal Wrapper of Model Averaging for Uncertainty Estimation on Out-Of-Distribution Detection}. arXiv.org.\n\n\\bibitem{xu2024ufg}\nRuiyao Xu, and Kaize Ding (2024). \\textit{Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey}. North American Chapter of the Association for Computational Linguistics.\n\n\\bibitem{du2024aea}\nXuefeng Du, Yiyou Sun, and Yixuan Li (2024). \\textit{When and How Does In-Distribution Label Help Out-of-Distribution Detection?}. International Conference on Machine Learning.\n\n\\bibitem{zamzmi20240s6}\nGhada Zamzmi, Kesavan Venkatesh, Brandon Nelson, et al. (2024). \\textit{Out-of-Distribution Detection and Radiological Data Monitoring Using Statistical Process Control}. Journal of imaging informatics in medicine.\n\n\\bibitem{zhu2024awk}\nArmando Zhu, Jiabei Liu, Keqin Li, et al. (2024). \\textit{Exploiting Diffusion Prior for Out-of-Distribution Detection}. Irish Interdisciplinary Journal of Science &amp; Research.\n\n\\bibitem{nasvytis2024mmr}\nL. Nasvytis, Kai Sandbrink, Jakob Foerster, et al. (2024). \\textit{Rethinking Out-of-Distribution Detection for Reinforcement Learning: Advancing Methods for Evaluation and Detection}. Adaptive Agents and Multi-Agent Systems.\n\n\\bibitem{yuan2024ug7}\nYue Yuan, Rundong He, Yicong Dong, et al. (2024). \\textit{Discriminability-Driven Channel Selection for Out-of-Distribution Detection}. Computer Vision and Pattern Recognition.\n\n\\bibitem{fang20249gd}\nZhen Fang, Yixuan Li, Feng Liu, et al. (2024). \\textit{On the Learnability of Out-of-distribution Detection}. Journal of machine learning research.\n\n\\bibitem{cao20250gu}\nYanan Cao, Fengzhao Shi, Qing Yu, et al. (2025). \\textit{IBPL: Information Bottleneck-based Prompt Learning for graph out-of-distribution detection}. Neural Networks.\n\n\\bibitem{heng2024fjd}\nAlvin Heng, A. ThiÃ©ry, and Harold Soh (2024). \\textit{Out-of-Distribution Detection with a Single Unconditional Diffusion Model}. Neural Information Processing Systems.\n\n\\bibitem{zhao2024u4m}\nQinyu Zhao, Ming Xu, Kartik Gupta, et al. (2024). \\textit{Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection}. International Conference on Learning Representations.\n\n\\bibitem{xu20242cq}\nChenhui Xu, Fuxun Yu, Zirui Xu, et al. (2024). \\textit{Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble}. International Conference on Machine Learning.\n\n\\bibitem{mirzaei2024dad}\nHossein Mirzaei, and Mackenzie W. Mathis (2024). \\textit{Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings}. International Conference on Learning Representations.\n\n\\bibitem{sharifi2024gok}\nSina Sharifi, Taha Entesari, Bardia Safaei, et al. (2024). \\textit{Gradient-Regularized Out-of-Distribution Detection}. European Conference on Computer Vision.\n\n\\bibitem{kirchheim20243gn}\nKonstantin Kirchheim, Tim Gonschorek, and F. Ortmeier (2024). \\textit{Out-of-Distribution Detection with Logical Reasoning}. IEEE Workshop/Winter Conference on Applications of Computer Vision.\n\n\\bibitem{shi2024rfk}\nXiangxi Shi, and Stefan Lee (2024). \\textit{Benchmarking Out-of-Distribution Detection in Visual Question Answering}. IEEE Workshop/Winter Conference on Applications of Computer Vision.\n\n\\bibitem{feng2024r4v}\nShuai Feng, and Chongjun Wang (2024). \\textit{When an extra rejection class meets out-of-distribution detection in long-tailed image classification}. Neural Networks.\n\n\\bibitem{li2024ypq}\nYixia Li, Boya Xiong, Guanhua Chen, et al. (2024). \\textit{SeTAR: Out-of-Distribution Detection with Selective Low-Rank Approximation}. Neural Information Processing Systems.\n\n\\bibitem{zeng2024bti}\nFanhu Zeng, Zhen Cheng, Fei Zhu, et al. (2024). \\textit{Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection}. International Conference on Learning Representations.\n\n\\bibitem{krumpl2024n1w}\nGerhard Krumpl, H. Avenhaus, Horst Possegger, et al. (2024). \\textit{ATS: Adaptive Temperature Scaling for Enhancing Out-of-Distribution Detection Methods}. IEEE Workshop/Winter Conference on Applications of Computer Vision.\n\n\\bibitem{hogeweg2024tw3}\nL. Hogeweg, Rajesh Gangireddy, Django Brunink, et al. (2024). \\textit{COOD: Combined out-of-distribution detection using multiple measures for anomaly & novel class detection in large-scale hierarchical classification}. 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW).\n\n\\bibitem{wang2024is1}\nHongjun Wang, S. Vaze, and Kai Han (2024). \\textit{Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks}. International Journal of Computer Vision.\n\n\\bibitem{lu2024j0n}\nShuo Lu, Yingsheng Wang, Lijun Sheng, et al. (2024). \\textit{Out-of-Distribution Detection: A Task-Oriented Survey of Recent Advances}. Unpublished manuscript.\n\n\\bibitem{tan2024oj5}\nQiaozhi Tan, Long Bai, Guan-Feng Wang, et al. (2024). \\textit{Endoood: Uncertainty-Aware Out-of-Distribution Detection in Capsule Endoscopy Diagnosis}. IEEE International Symposium on Biomedical Imaging.\n\n\\bibitem{ma202440a}\nLongfei Ma, Yiyou Sun, Kaize Ding, et al. (2024). \\textit{Revisiting Score Propagation in Graph Out-of-Distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{yang2025z62}\nShenzhi Yang, Bin Liang, An Liu, et al. (2025). \\textit{Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs}. International Conference on Machine Learning.\n\n\\bibitem{zhang2024z2g}\nYuhang Zhang, Jiani Hu, Dongchao Wen, et al. (2024). \\textit{Unsupervised evaluation for out-of-distribution detection}. Pattern Recognition.\n\n\\bibitem{abdi2024mvh}\nLemar Abdi, M. Valiuddin, Christiaan G. A. Viviers, et al. (2024). \\textit{Typicality Excels Likelihood for Unsupervised Out-of-Distribution Detection in Medical Imaging}. UNSURE@MICCAI.\n\n\\bibitem{haider20249q8}\nTom Haider, Karsten Roscher, Benjamin Herd, et al. (2024). \\textit{Can you trust your Agent? The Effect of Out-of-Distribution Detection on the Safety of Reinforcement Learning Systems}. ACM Symposium on Applied Computing.\n\n\\bibitem{qu202422m}\nJingen Qu, Yufei Chen, Xiaodong Yue, et al. (2024). \\textit{Hyper-opinion Evidential Deep Learning for Out-of-Distribution Detection}. Neural Information Processing Systems.\n\n\\bibitem{novello2024yco}\nPaul Novello, Joseba Dalmau, and L'eo Andeol (2024). \\textit{Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?)}. arXiv.org.\n\n\\bibitem{chen2024f28}\nJiankang Chen, Tong Zhang, Weishi Zheng, et al. (2024). \\textit{TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{miao2024318}\nWenjun Miao, Guansong Pang, Jingyi Zheng, et al. (2024). \\textit{Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation}. Neural Information Processing Systems.\n\n\\bibitem{oh2024opf}\nJi-Hun Oh, Kianoush Falahkheirkhah, and Rohit Bhargava (2024). \\textit{Are We Ready for Out-of-Distribution Detection in Digital Pathology?}. International Conference on Medical Image Computing and Computer-Assisted Intervention.\n\n\\bibitem{dong2024t8f}\nJiuqing Dong, Yifan Yao, Wei Jin, et al. (2024). \\textit{Enhancing Few-Shot Out-of-Distribution Detection With Pre-Trained Model Features}. IEEE Transactions on Image Processing.\n\n\\bibitem{feng2024ma3}\nShuai Feng, Pengsheng Jin, and Chongjun Wang (2024). \\textit{CASE: Exploiting Intra-class Compactness and Inter-class Separability of Feature Embeddings for Out-of-Distribution Detection}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{he2024e9z}\nRundong He, Yue Yuan, Zhongyi Han, et al. (2024). \\textit{Exploring Channel-Aware Typical Features for Out-of-Distribution Detection}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{gong2024n0t}\nMingrong Gong, Chaoqi Chen, Qingqiang Sun, et al. (2024). \\textit{Out-of-Distribution Detection with Prototypical Outlier Proxy}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{cook2024hyb}\nEvan D. Cook, Marc-Antoine Lavoie, and Steven L. Waslander (2024). \\textit{Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows}. Proceedings of the 21st Conference on Robots and Vision.\n\n\\bibitem{miao20246mk}\nWenjun Miao, Guansong Pang, Trong-Tung Nguyen, et al. (2024). \\textit{OpenCIL: Benchmarking Out-of-Distribution Detection in Class-Incremental Learning}. Pattern Recognition.\n\n\\bibitem{lee2025gu9}\nYuxiao Lee, Xiaofeng Cao, Jingcai Guo, et al. (2025). \\textit{Concept Matching with Agent for Out-of-Distribution Detection}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{wang2025v65}\nJinglong Wang, and Ridong Zhang (2025). \\textit{Open-Set Fault Diagnosis Based on 1D-ResNet With Fusion of Cross-Class and Extreme Information for Out-of-Distribution Detection}. IEEE Transactions on Instrumentation and Measurement.\n\n\\bibitem{he2024s9w}\nRundong He, Zhongyi Han, Xiushan Nie, et al. (2024). \\textit{Visual Out-of-Distribution Detection in Open-Set Noisy Environments}. International Journal of Computer Vision.\n\n\\bibitem{li2025jdt}\nXuhui Li, Zhen Fang, Yonggang Zhang, et al. (2025). \\textit{Characterizing Submanifold Region for Out-of-Distribution Detection}. IEEE Transactions on Knowledge and Data Engineering.\n\n\\bibitem{gulati2024dbi}\nAryan Gulati, Xingjian Dong, Carlos Hurtado, et al. (2024). \\textit{Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression}. Conference on Empirical Methods in Natural Language Processing.\n\n\\bibitem{osada20246an}\nGenki Osada, Tsubasa Takahashi, and Takashi Nishide (2024). \\textit{Understanding Likelihood of Normalizing Flow and Image Complexity through the Lens of Out-of-Distribution Detection}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{mei20248tm}\nYihan Mei, Xinyu Wang, De-Fu Zhang, et al. (2024). \\textit{Multi-Label Out-of-Distribution Detection with Spectral Normalized Joint Energy}. APWeb/WAIM.\n\n\\bibitem{kim2024vqc}\nJeonghyeon Kim, Jihyo Kim, and Sangheum Hwang (2024). \\textit{Comparison of Out-of-Distribution Detection Performance of CLIP-based Fine-Tuning Methods}. International Conference on Electronics, Information and Communications.\n\n\\bibitem{kahya2024ywf}\nSabri Mustafa Kahya, Boran Hamdi Sivrikaya, Muhammet Sami Yavuz, et al. (2024). \\textit{FOOD: Facial Authentication and Out-of-Distribution Detection with Short-Range FMCW Radar}. International Conference on Information Photonics.\n\n\\bibitem{ekim2024zwd}\nBurak Ekim, G. Tadesse, Caleb Robinson, et al. (2024). \\textit{Distribution Shifts at Scale: Out-of-distribution Detection in Earth Observation}. 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW).\n\n\\bibitem{shin2024lnf}\nDong Geun Shin, and Hye Won Chung (2024). \\textit{Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning}. Trans. Mach. Learn. Res..\n\n\\bibitem{du2024kj8}\nRenmingyue Du, Jixun Yao, Qiuqiang Kong, et al. (2024). \\textit{Towards Out-of-Distribution Detection in Vocoder Recognition via Latent Feature Reconstruction}. Unpublished manuscript.\n\n\\bibitem{mao20244lp}\nZhenjiang Mao, Dong-You Jhong, Ao Wang, et al. (2024). \\textit{Language-Enhanced Latent Representations for Out-of-Distribution Detection in Autonomous Driving}. arXiv.org.\n\n\\bibitem{borlino20245ku}\nFrancesco Cappio Borlino, L. Lu, and Tatiana Tommasi (2024). \\textit{Foundation Models and Fine-Tuning: A Benchmark for Out of Distribution Detection}. IEEE Access.\n\n\\bibitem{li2024tk8}\nSiCong Li, Ning Li, Min Jing, et al. (2024). \\textit{Evaluation of Ten Deep-Learning-Based Out-of-Distribution Detection Methods for Remote Sensing Image Scene Classification}. Remote Sensing.\n\n\\bibitem{chen20247p7}\nQichao Chen, Kuan Li, Zhiyuan Chen, et al. (2024). \\textit{Exploring feature sparsity for out-of-distribution detection}. Scientific Reports.\n\n\\bibitem{zhou2024ae1}\nJingqiu Zhou, Aojun Zhou, and Hongsheng Li (2024). \\textit{NODI: Out-Of-Distribution Detection with Noise from Diffusion}. arXiv.org.\n\n\\bibitem{galesso2024g7t}\nSilvio Galesso, Philipp SchrÃ¶ppel, Hssan Driss, et al. (2024). \\textit{Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond}. European Conference on Computer Vision.\n\n\\bibitem{chen202491k}\nYang Chen, Chih-Li Sung, A. Kusari, et al. (2024). \\textit{Uncertainty-Aware Out-of-Distribution Detection with Gaussian Processes}. arXiv.org.\n\n\\bibitem{long2024os1}\nXingming Long, Jie Zhang, Shiguang Shan, et al. (2024). \\textit{Rethinking the Evaluation of Out-of-Distribution Detection: A Sorites Paradox}. Neural Information Processing Systems.\n\n\\bibitem{cai2025ez2}\nTingyi Cai, Yunliang Jiang, Yixin Liu, et al. (2025). \\textit{Out-of-Distribution Detection on Graphs: A Survey}. arXiv.org.\n\n\\bibitem{liu2025m5u}\nMoru Liu, Hao Dong, Jessica Kelly, et al. (2025). \\textit{Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation}. arXiv.org.\n\n\\bibitem{li2025xv2}\nHengzhuang Li, and Teng Zhang (2025). \\textit{Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection}. International Conference on Learning Representations.\n\n\\bibitem{liu2024m2l}\nXixi Liu, and Christopher Zach (2024). \\textit{TAG: Text Prompt Augmentation for Zero-Shot Out-of-Distribution Detection}. European Conference on Computer Vision.\n\n\\bibitem{yu2024ez3}\nYeonguk Yu, Sungho Shin, Minhwan Ko, et al. (2024). \\textit{Exploring using jigsaw puzzles for out-of-distribution detection}. Computer Vision and Image Understanding.\n\n\\bibitem{ahsan20241ht}\nSyed Safwan Ahsan, Alireza Esmaeilzehi, and M. O. Ahmad (2024). \\textit{OODNet: A deep blind JPEG image compression deblocking network using out-of-distribution detection}. Journal of Visual Communication and Image Representation.\n\n\\bibitem{ma202473w}\nXinsong Ma, Xin Zou, and Weiwei Liu (2024). \\textit{A Provable Decision Rule for Out-of-Distribution Detection}. International Conference on Machine Learning.\n\n\\bibitem{isaku2025kiz}\nErblin Isaku, Hassan Sartaj, and Shaukat Ali (2025). \\textit{Digital Twin-based Out-of-Distribution Detection in Autonomous Vessels}. arXiv.org.\n\n\\end{thebibliography}\n\n\\end{document}",
  "generation_date": "2025-10-07T13:25:41.747241",
  "processed_papers_data": [
    {
      "success": true,
      "doc_id": "4104c43ee26a42973aa56b0c47c56a3a",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/098c12e7995675c1026d86d5f52843a035d3fa28.pdf",
      "citation_key": "han2022ixj",
      "metadata": {
        "title": "Out-of-distribution detection-assisted trustworthy machinery fault diagnosis approach with uncertainty-aware deep ensembles",
        "authors": [
          "Te Han",
          "Yanfang Li"
        ],
        "published_date": "2022",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/098c12e7995675c1026d86d5f52843a035d3fa28.pdf",
        "venue": "Reliability Engineering & System Safety",
        "citationCount": 188,
        "score": 62.666666666666664,
        "summary": "",
        "keywords": []
      },
      "file_name": "098c12e7995675c1026d86d5f52843a035d3fa28.pdf"
    },
    {
      "success": true,
      "doc_id": "3343d1f4fed5fd96cc4dad92a4e17b16",
      "summary": "Here's a focused summary of the paper \\cite{zhou202250i} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Detecting Out-of-Distribution (OoD) samples in deep learning classifiers, particularly for reconstruction autoencoder-based methods.\n    *   **Importance & Challenge:** Supervised classifiers operate under a closed-world assumption, failing in real-world scenarios where test data can be unknown. Neural networks can produce arbitrarily confident but erroneous predictions for unrecognizable inputs. While reconstruction autoencoders are a promising unsupervised approach, they often fail because they can effectively reconstruct various OoD samples, leading to poor performance in challenging multi-class OoD detection tasks.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches:** Many OoD methods rely on training with labeled OoD data (e.g., from other categories, adversaries, or leave-out subsets).\n    *   **Limitations of Previous Solutions:**\n        *   Supervised OoD methods struggle to generalize due to the intractability of covering the full, high-dimensional OoD space, leading to data selection bias.\n        *   Introducing OoD data with additional training objectives can negatively impact the classifier's accuracy on in-distribution (ID) images.\n        *   Traditional reconstruction autoencoders are known to accurately reconstruct OoD samples, contradicting their core assumption for OoD detection.\n        *   Previous methods like latent space autoregression \\cite{2} constrain autoencoders using parametric density estimators, which can be biased under restrictive assumptions.\n    *   **Positioning:** \\cite{zhou202250i} addresses the fundamental flaw of autoencoder-based OoD detection by re-evaluating the conditions under which reconstruction error is a valid uncertainty measure. It differentiates itself by seeking a *maximally compressed latent space* without relying on parametric density estimators, and by introducing a novel layerwise semantic reconstruction framework.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper formulates autoencoder-based OoD detection as a quadruplet domain translation problem. It proposes that for reconstruction error to be a valid data uncertainty measure, two preconditions must be met: 1) the latent feature lies within the domain of encoded ID samples, and 2) the decoder has adequate reconstructive power.\n    *   **Novelty:**\n        *   **Maximally Compressed Latent Space:** The approach aims to maximally condense the autoencoder's latent space while preserving its reconstructive power for ID data. This is achieved by minimizing a regularization loss to restrict ID latent features to a compact, known space, thereby improving the estimation of whether an input's latent feature is in the ID domain.\n        *   **Semantic Reconstruction:** Instead of reconstructing raw image pixels, the method reconstructs Activation Vector (AV) features (output of the penultimate layer of a pre-trained classifier). This reduces the expressiveness requirement of the latent space, as AVs are lower-dimensional, semantic, and task-relevant.\n        *   **Data Certainty Decomposition (Layerwise Semantic Reconstruction):** To overcome the challenge of recovering significant information loss from a highly compressed latent space, the paper factorizes the probability of an input being ID into a product of conditional probabilities. This allows for a series of decoders, each focusing on recovering information lost after *each individual encoding layer*, rather than a single decoder recovering all accumulated loss.\n        *   **Normalized L2 Distance (NL2):** A novel distance metric, `NL2(f, ~f) = ||f/||f|| - ~f/||f||||`, is introduced to evaluate reconstruction accuracy. This addresses the issue that neural networks tend to produce smaller activations for OoD samples, which can lead to misleadingly small L2 reconstruction errors. NL2 normalizes the reconstruction by the input's norm, eliminating the negative influence of feature magnitude.\n\n*   **Key Technical Contributions**\n    *   **Theoretical Insight:** Formalization of autoencoder-based OoD detection as quadruplet domain translation and the derivation of two preconditions for valid reconstruction error as a data uncertainty measure.\n    *   **Novel Framework:** The \"layerwise semantic reconstruction\" framework, which decomposes data certainty and employs multiple decoders for incremental information recovery.\n    *   **Novel Metric:** The Normalized L2 Distance (NL2) for robust reconstruction error evaluation, addressing the norm-correlation bias.\n    *   **System Design:** Utilizing Activation Vector (AV) features from a pre-trained classifier as the reconstruction target, simplifying the autoencoder's task and improving efficiency.\n    *   **Algorithmic Strategy:** Combining latent space compression, semantic reconstruction, data certainty decomposition, and NL2 distance to achieve state-of-the-art performance.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Comprehensive analysis, ablation studies, and robustness studies were performed.\n    *   **Key Performance Metrics & Comparison Results:** The method establishes state-of-the-art performance on various challenging benchmarks. For example, it achieves an FPR@95%TPR of 0.2% for CIFAR-100 vs. TinyImagenet-crop on a Wide-ResNet classifier.\n    *   **Key Findings:** The results demonstrate the efficacy of the proposed approach, indicating that the potential of autoencoder-based methods for OoD detection is significantly higher than previously thought.\n\n*   **Limitations & Scope**\n    *   **Technical Assumptions:** The theoretical proof for NL2 relies on activation functions being approximately linear in certain polytopes. The approach assumes the availability of a pre-trained classifier to extract AV features.\n    *   **Scope of Applicability:** The method operates in an unsupervised mode, requiring no additional OoD data, complex structures, or time-consuming pipelines. It is designed as an auxiliary module that does not harm the classification accuracy of known classes.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{zhou202250i} significantly advances the technical state-of-the-art in unsupervised OoD detection, particularly for autoencoder-based methods, by addressing their core limitations.\n    *   **Potential Impact:** The work provides a novel theoretical understanding and practical framework that can revitalize research into reconstruction-based OoD detection. Its efficiency, unsupervised nature, and strong performance without additional data make it highly impactful for real-world applications where OoD data is scarce or impossible to collect. The introduction of NL2 distance and semantic reconstruction offers valuable tools for future research in this domain.",
      "intriguing_abstract": "Deep learning classifiers, operating under a dangerous \"closed-world\" assumption, often fail catastrophically when confronted with Out-of-Distribution (OoD) samples. While reconstruction autoencoders offer a promising unsupervised solution, their inherent ability to reconstruct diverse OoD inputs fundamentally undermines their efficacy. This paper re-evaluates the core principles of autoencoder-based OoD detection, formalizing it as a quadruplet domain translation problem and deriving critical preconditions for reconstruction error to be a valid uncertainty measure.\n\nWe introduce a novel framework centered on **layerwise semantic reconstruction**. Instead of pixel-level reconstruction, our autoencoder targets highly semantic **Activation Vectors (AVs)** from a pre-trained classifier, significantly compressing the **latent space** for in-distribution data. To overcome information loss, we decompose data certainty, employing multiple decoders for incremental recovery across layers. Furthermore, we propose the **Normalized L2 Distance (NL2)**, a robust metric that eliminates norm-correlation bias in reconstruction error. This comprehensive approach achieves state-of-the-art performance in challenging multi-class OoD detection benchmarks, demonstrating the untapped potential of autoencoder-based methods. Our unsupervised framework offers a critical advancement for real-world deep learning applications where unknown unknowns are inevitable.",
      "keywords": [
        "Out-of-Distribution (OoD) detection",
        "reconstruction autoencoders",
        "unsupervised OoD detection",
        "maximally compressed latent space",
        "semantic reconstruction",
        "Activation Vector (AV) features",
        "layerwise semantic reconstruction",
        "data certainty decomposition",
        "Normalized L2 Distance (NL2)",
        "quadruplet domain translation",
        "deep learning classifiers",
        "state-of-the-art performance",
        "reconstruction error as uncertainty measure"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/60108b8e0d7204fa33f686b09128c7fc8489a224.pdf",
      "citation_key": "zhou202250i",
      "metadata": {
        "title": "Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection",
        "authors": [
          "Yibo Zhou"
        ],
        "published_date": "2022",
        "abstract": "In some scenarios, classifier requires detecting out-of-distribution samples far from its training data. With desirable characteristics, reconstruction autoencoder-based methods deal with this problem by using input reconstruction error as a metric of novelty vs. normality. We formulate the essence of such approach as a quadruplet domain translation with an intrinsic bias to only query for a proxy of conditional data uncertainty. Accordingly, an improvement direction is formalized as maximumly compressing the autoencoder's latent space while ensuring its reconstructive power for acting as a described domain translator. From it, strategies are introduced including semantic reconstruction, data certainty decomposition and normalized L2 distance to substantially improve original methods, which together establish state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method works without any additional data, hard-to-implement structure, time-consuming pipeline, and even harming the classification accuracy of known classes.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/60108b8e0d7204fa33f686b09128c7fc8489a224.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 70,
        "score": 23.333333333333332,
        "summary": "Here's a focused summary of the paper \\cite{zhou202250i} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Detecting Out-of-Distribution (OoD) samples in deep learning classifiers, particularly for reconstruction autoencoder-based methods.\n    *   **Importance & Challenge:** Supervised classifiers operate under a closed-world assumption, failing in real-world scenarios where test data can be unknown. Neural networks can produce arbitrarily confident but erroneous predictions for unrecognizable inputs. While reconstruction autoencoders are a promising unsupervised approach, they often fail because they can effectively reconstruct various OoD samples, leading to poor performance in challenging multi-class OoD detection tasks.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches:** Many OoD methods rely on training with labeled OoD data (e.g., from other categories, adversaries, or leave-out subsets).\n    *   **Limitations of Previous Solutions:**\n        *   Supervised OoD methods struggle to generalize due to the intractability of covering the full, high-dimensional OoD space, leading to data selection bias.\n        *   Introducing OoD data with additional training objectives can negatively impact the classifier's accuracy on in-distribution (ID) images.\n        *   Traditional reconstruction autoencoders are known to accurately reconstruct OoD samples, contradicting their core assumption for OoD detection.\n        *   Previous methods like latent space autoregression \\cite{2} constrain autoencoders using parametric density estimators, which can be biased under restrictive assumptions.\n    *   **Positioning:** \\cite{zhou202250i} addresses the fundamental flaw of autoencoder-based OoD detection by re-evaluating the conditions under which reconstruction error is a valid uncertainty measure. It differentiates itself by seeking a *maximally compressed latent space* without relying on parametric density estimators, and by introducing a novel layerwise semantic reconstruction framework.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper formulates autoencoder-based OoD detection as a quadruplet domain translation problem. It proposes that for reconstruction error to be a valid data uncertainty measure, two preconditions must be met: 1) the latent feature lies within the domain of encoded ID samples, and 2) the decoder has adequate reconstructive power.\n    *   **Novelty:**\n        *   **Maximally Compressed Latent Space:** The approach aims to maximally condense the autoencoder's latent space while preserving its reconstructive power for ID data. This is achieved by minimizing a regularization loss to restrict ID latent features to a compact, known space, thereby improving the estimation of whether an input's latent feature is in the ID domain.\n        *   **Semantic Reconstruction:** Instead of reconstructing raw image pixels, the method reconstructs Activation Vector (AV) features (output of the penultimate layer of a pre-trained classifier). This reduces the expressiveness requirement of the latent space, as AVs are lower-dimensional, semantic, and task-relevant.\n        *   **Data Certainty Decomposition (Layerwise Semantic Reconstruction):** To overcome the challenge of recovering significant information loss from a highly compressed latent space, the paper factorizes the probability of an input being ID into a product of conditional probabilities. This allows for a series of decoders, each focusing on recovering information lost after *each individual encoding layer*, rather than a single decoder recovering all accumulated loss.\n        *   **Normalized L2 Distance (NL2):** A novel distance metric, `NL2(f, ~f) = ||f/||f|| - ~f/||f||||`, is introduced to evaluate reconstruction accuracy. This addresses the issue that neural networks tend to produce smaller activations for OoD samples, which can lead to misleadingly small L2 reconstruction errors. NL2 normalizes the reconstruction by the input's norm, eliminating the negative influence of feature magnitude.\n\n*   **Key Technical Contributions**\n    *   **Theoretical Insight:** Formalization of autoencoder-based OoD detection as quadruplet domain translation and the derivation of two preconditions for valid reconstruction error as a data uncertainty measure.\n    *   **Novel Framework:** The \"layerwise semantic reconstruction\" framework, which decomposes data certainty and employs multiple decoders for incremental information recovery.\n    *   **Novel Metric:** The Normalized L2 Distance (NL2) for robust reconstruction error evaluation, addressing the norm-correlation bias.\n    *   **System Design:** Utilizing Activation Vector (AV) features from a pre-trained classifier as the reconstruction target, simplifying the autoencoder's task and improving efficiency.\n    *   **Algorithmic Strategy:** Combining latent space compression, semantic reconstruction, data certainty decomposition, and NL2 distance to achieve state-of-the-art performance.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Comprehensive analysis, ablation studies, and robustness studies were performed.\n    *   **Key Performance Metrics & Comparison Results:** The method establishes state-of-the-art performance on various challenging benchmarks. For example, it achieves an FPR@95%TPR of 0.2% for CIFAR-100 vs. TinyImagenet-crop on a Wide-ResNet classifier.\n    *   **Key Findings:** The results demonstrate the efficacy of the proposed approach, indicating that the potential of autoencoder-based methods for OoD detection is significantly higher than previously thought.\n\n*   **Limitations & Scope**\n    *   **Technical Assumptions:** The theoretical proof for NL2 relies on activation functions being approximately linear in certain polytopes. The approach assumes the availability of a pre-trained classifier to extract AV features.\n    *   **Scope of Applicability:** The method operates in an unsupervised mode, requiring no additional OoD data, complex structures, or time-consuming pipelines. It is designed as an auxiliary module that does not harm the classification accuracy of known classes.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{zhou202250i} significantly advances the technical state-of-the-art in unsupervised OoD detection, particularly for autoencoder-based methods, by addressing their core limitations.\n    *   **Potential Impact:** The work provides a novel theoretical understanding and practical framework that can revitalize research into reconstruction-based OoD detection. Its efficiency, unsupervised nature, and strong performance without additional data make it highly impactful for real-world applications where OoD data is scarce or impossible to collect. The introduction of NL2 distance and semantic reconstruction offers valuable tools for future research in this domain.",
        "keywords": [
          "Out-of-Distribution (OoD) detection",
          "reconstruction autoencoders",
          "unsupervised OoD detection",
          "maximally compressed latent space",
          "semantic reconstruction",
          "Activation Vector (AV) features",
          "layerwise semantic reconstruction",
          "data certainty decomposition",
          "Normalized L2 Distance (NL2)",
          "quadruplet domain translation",
          "deep learning classifiers",
          "state-of-the-art performance",
          "reconstruction error as uncertainty measure"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the **abstract** explicitly states: \"we formulate the essence of such approach as a quadruplet domain translation...\", \"an improvement direction is formalized...\", \"strategies are introduced including semantic reconstruction, data certainty decomposition and normalized l2 distance to substantially improve original methods...\", \"our method works...\", \"code has been released on github.\" these phrases strongly indicate the development and presentation of new methods and algorithms. it also mentions achieving \"state-of-the-art performance on various benchmarks,\" which is the result of applying these new technical contributions.\n*   the **introduction** sets up a technical problem (out-of-distribution detection) and discusses the limitations of existing methods, paving the way for the paper's proposed solution.\n\nthis aligns perfectly with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\". while it includes empirical results, those results are presented as validation of the *new technical methods* rather than being the sole focus of the study.\n\n**classification: technical**"
      },
      "file_name": "60108b8e0d7204fa33f686b09128c7fc8489a224.pdf"
    },
    {
      "success": true,
      "doc_id": "d55f0e96bfcc54876e12e79ba738f678",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses a critical limitation in existing Out-of-Distribution (OOD) detection: the lack of consensus and proper handling of **covariate shift** \\cite{yang2022it3}.\n    *   Current OOD detection literature primarily focuses on **semantic shift** (new classes) but either excludes covariate-shifted data from evaluation or incorrectly treats it as OOD.\n    *   This approach contradicts the fundamental machine learning goal of generalizing beyond the training distribution, making models untrustworthy in real-world deployments where appearance changes (e.g., lighting, viewpoint, contrast) are common.\n    *   The authors introduce **Full-Spectrum OOD (FS-OOD) detection**, a more realistic problem setting that requires detecting semantic shift while being robust and tolerant to covariate shift \\cite{yang2022it3}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods typically rely on score functions based on conditional probability (e.g., Maximum Softmax Probability (MSP) \\cite{yang2022it3}, ODIN \\cite{yang2022it3}) or marginal probability (e.g., energy-based EBO \\cite{yang2022it3}, Mahalanobis distance \\cite{yang2022it3}, generative models \\cite{yang2022it3}).\n    *   The primary limitation of these previous solutions is their failure to effectively distinguish between semantic shift and covariate shift. As demonstrated by the authors, state-of-the-art methods like EBO perform poorly in FS-OOD scenarios, often classifying both near-OOD and far-OOD samples as in-distribution when covariate shift is present \\cite{yang2022it3}.\n    *   This work positions itself by addressing a previously uninvestigated but critical scenario for real-world applications.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **SEM (Semantics score function)**, a simple feature-based score function designed to be sensitive only to semantic shift and robust to covariate shift \\cite{yang2022it3}.\n    *   SEM is formulated as `SEM(x) = log p(x) / p(xn)`, where `x` represents high-level features and `xn` represents non-semantic features.\n    *   **Novelty**: SEM leverages two probability measures:\n        *   `p(x)`: Based on high-level features from top CNN layers, capturing both semantic and non-semantic information. Modeled using a Gaussian Mixture Model (GMM) after a variant of PCA for dimension reduction.\n        *   `p(xn)`: Based on low-level feature statistics (means and standard deviations) from shallow CNN layers, which are shown to capture non-semantic image styles. Also modeled using a GMM.\n    *   By combining these measures as a ratio, the non-semantic part is effectively \"cancelled out,\" leaving a score primarily indicative of semantic information.\n    *   **Source-Awareness Enhancement**: A fine-tuning scheme is proposed to improve the estimation of `p(xn)`. This involves using negative data augmentation (e.g., Mixup \\cite{yang2022it3}) to synthesize OOD samples. A combined loss function (`Lcls` for classification and `Lsrc` to push OOD feature statistics away while making ID feature statistics more compact) is used to enhance the model's ability to differentiate non-semantic shifts.\n\n*   **Key Technical Contributions**\n    *   **Novel Problem Setting**: Introduction of the **Full-Spectrum OOD (FS-OOD) detection** problem, which considers both semantic and covariate shift for a more realistic evaluation \\cite{yang2022it3}.\n    *   **New Benchmarks**: Design of three comprehensive benchmarks (DIGITS, OBJECTS, COVID) with a fine-grained categorization of distributions: training ID, covariate-shifted ID, near-OOD, and far-OOD \\cite{yang2022it3}.\n    *   **Novel Algorithm**: Proposal of **SEM**, a simple yet effective feature-based semantics score function that explicitly disentangles semantic and non-semantic information for robust OOD detection \\cite{yang2022it3}.\n    *   **System Design**: A fine-tuning scheme incorporating negative data augmentation to enhance source-awareness in feature statistics.\n\n*   **Experimental Validation**\n    *   **Benchmarks**: Experiments were conducted on three newly designed FS-OOD benchmarks:\n        *   **DIGITS**: Based on MNIST, SVHN, USPS (covariate-shifted ID), notMNIST, FashionMNIST (near-OOD), and Texture, CIFAR-10, Tiny-ImageNet, Places365 (far-OOD).\n        *   **OBJECTS**: Based on CIFAR-10, ImageNet-10, CIFAR-10-C (covariate-shifted ID), CIFAR-100, Tiny-ImageNet (near-OOD), and MNIST, FashionMNIST, Texture, CIFAR-100-C (far-OOD).\n        *   **COVID**: A real-world medical imaging benchmark for COVID-19 diagnosis, using BIMCV (training ID), ACTUALMED, Hannover (covariate-shifted ID), RSNA Bone Age, COVID CT (near-OOD), and MNIST, CIFAR-10, Texture, Tiny-ImageNet (far-OOD).\n    *   **Metrics**: Performance was evaluated using False Positive Rate at 95% True Positive Rate (FPR95), Area Under the Receiver Operating Characteristic curve (AUROC), and Area Under the Precision-Recall curve (AUPR).\n    *   **Results**: Extensive experiments demonstrated that SEM significantly outperforms current state-of-the-art OOD detection methods across all three new benchmarks, particularly in distinguishing between covariate-shifted ID and true OOD samples \\cite{yang2022it3}.\n\n*   **Limitations & Scope**\n    *   The paper primarily highlights the limitations of *previous* OOD methods in handling covariate shift, rather than explicit limitations of SEM.\n    *   The scope of applicability is focused on **visual recognition tasks**, as evidenced by the image-based benchmarks.\n    *   The approach relies on the assumption that low-level feature statistics effectively capture non-semantic image styles, and that semantic and non-semantic features are generated independently.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by introducing a more comprehensive and realistic OOD detection problem setting (FS-OOD) that is crucial for deploying trustworthy AI systems in real-world scenarios.\n    *   The proposed SEM score function provides a novel and effective way to disentangle semantic and non-semantic information, leading to OOD detectors that are robust to covariate shift while accurately identifying semantic shifts.\n    *   The new benchmarks provide a standardized and challenging testbed for future research in OOD detection, encouraging the development of algorithms that can generalize better and handle diverse distribution shifts.\n    *   The findings have potential impact on future research by shifting the focus towards developing OOD methods that explicitly account for different types of distribution shifts, moving beyond purely semantic-based detection.",
      "intriguing_abstract": "Deploying AI in the real world demands robust Out-of-Distribution (OOD) detection, yet current methods critically falter when faced with **covariate shift** â€“ common appearance variations like lighting changes. Existing approaches often misclassify these benign shifts as true OOD, undermining model trustworthiness and hindering generalization.\n\nWe introduce **Full-Spectrum OOD (FS-OOD) detection**, a novel and realistic problem setting that requires models to detect genuine **semantic shift** while remaining tolerant to covariate shifts. To address this, we propose **SEM (Semantics score function)**, a pioneering feature-based algorithm. SEM ingeniously disentangles semantic and non-semantic information by leveraging a ratio of probability measures derived from high-level and low-level deep learning features, modeled via **Gaussian Mixture Models (GMMs)**. This unique approach effectively 'cancels out' non-semantic variations, ensuring the score is sensitive only to true semantic novelty.\n\nOur comprehensive experiments on three new FS-OOD benchmarks (DIGITS, OBJECTS, COVID) demonstrate that SEM significantly outperforms state-of-the-art OOD detectors, particularly in distinguishing covariate-shifted in-distribution samples from true OOD. This work establishes a crucial foundation for developing truly trustworthy and generalizable AI systems, setting a new standard for future OOD research.",
      "keywords": [
        "Full-Spectrum OOD (FS-OOD) detection",
        "covariate shift",
        "semantic shift",
        "SEM (Semantics score function)",
        "disentangling semantic and non-semantic information",
        "robustness to covariate shift",
        "novel OOD benchmarks",
        "Gaussian Mixture Model (GMM)",
        "Source-Awareness Enhancement",
        "Out-of-Distribution (OOD) detection",
        "real-world trustworthy AI",
        "visual recognition tasks"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/1007a43d42c7c92d765cdf614c98f6fc974aaf15.pdf",
      "citation_key": "yang2022it3",
      "metadata": {
        "title": "Full-Spectrum Out-of-Distribution Detection",
        "authors": [
          "Jingkang Yang",
          "Kaiyang Zhou",
          "Ziwei Liu"
        ],
        "published_date": "2022",
        "abstract": "Existing out-of-distribution (OOD) detection literature clearly defines semantic shift as a sign of OOD but does not have a consensus over covariate shift. Samples experiencing covariate shift but not semantic shift from the in-distribution (ID) are either excluded from the test set or treated as OOD, which contradicts the primary goal in machine learningâ€”being able to generalize beyond the training distribution. In this paper, we take into account both shift types and introduce full-spectrum OOD (F-OOD) detection, a more realistic problem setting that considers both detecting semantic shift and being tolerant to covariate shift; and design three benchmarks. These new benchmarks have a more fine-grained categorization of distributions ( i.e let@tokeneonedot, training ID, covariate-shifted ID, near-OOD, and far-OOD) for the purpose of more comprehensively evaluating the pros and cons of algorithms. To address the F-OOD detection problem, we propose SEM, a simple feature-based semantics score function. SEM is mainly composed of two probability measures: one is based on high-level features containing both semantic and non-semantic information, while the other is based on low-level feature statistics only capturing non-semantic image styles. With a simple combination, the non-semantic part is canceled out, which leaves only semantic information in SEM that can better handle F-OOD detection. Extensive experiments on the three new benchmarks show that SEM significantly outperforms current state-of-the-art methods. Our code and benchmarks are released in https://github.com/Jingkang50/OpenOOD .",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/1007a43d42c7c92d765cdf614c98f6fc974aaf15.pdf",
        "venue": "International Journal of Computer Vision",
        "citationCount": 68,
        "score": 22.666666666666664,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses a critical limitation in existing Out-of-Distribution (OOD) detection: the lack of consensus and proper handling of **covariate shift** \\cite{yang2022it3}.\n    *   Current OOD detection literature primarily focuses on **semantic shift** (new classes) but either excludes covariate-shifted data from evaluation or incorrectly treats it as OOD.\n    *   This approach contradicts the fundamental machine learning goal of generalizing beyond the training distribution, making models untrustworthy in real-world deployments where appearance changes (e.g., lighting, viewpoint, contrast) are common.\n    *   The authors introduce **Full-Spectrum OOD (FS-OOD) detection**, a more realistic problem setting that requires detecting semantic shift while being robust and tolerant to covariate shift \\cite{yang2022it3}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods typically rely on score functions based on conditional probability (e.g., Maximum Softmax Probability (MSP) \\cite{yang2022it3}, ODIN \\cite{yang2022it3}) or marginal probability (e.g., energy-based EBO \\cite{yang2022it3}, Mahalanobis distance \\cite{yang2022it3}, generative models \\cite{yang2022it3}).\n    *   The primary limitation of these previous solutions is their failure to effectively distinguish between semantic shift and covariate shift. As demonstrated by the authors, state-of-the-art methods like EBO perform poorly in FS-OOD scenarios, often classifying both near-OOD and far-OOD samples as in-distribution when covariate shift is present \\cite{yang2022it3}.\n    *   This work positions itself by addressing a previously uninvestigated but critical scenario for real-world applications.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **SEM (Semantics score function)**, a simple feature-based score function designed to be sensitive only to semantic shift and robust to covariate shift \\cite{yang2022it3}.\n    *   SEM is formulated as `SEM(x) = log p(x) / p(xn)`, where `x` represents high-level features and `xn` represents non-semantic features.\n    *   **Novelty**: SEM leverages two probability measures:\n        *   `p(x)`: Based on high-level features from top CNN layers, capturing both semantic and non-semantic information. Modeled using a Gaussian Mixture Model (GMM) after a variant of PCA for dimension reduction.\n        *   `p(xn)`: Based on low-level feature statistics (means and standard deviations) from shallow CNN layers, which are shown to capture non-semantic image styles. Also modeled using a GMM.\n    *   By combining these measures as a ratio, the non-semantic part is effectively \"cancelled out,\" leaving a score primarily indicative of semantic information.\n    *   **Source-Awareness Enhancement**: A fine-tuning scheme is proposed to improve the estimation of `p(xn)`. This involves using negative data augmentation (e.g., Mixup \\cite{yang2022it3}) to synthesize OOD samples. A combined loss function (`Lcls` for classification and `Lsrc` to push OOD feature statistics away while making ID feature statistics more compact) is used to enhance the model's ability to differentiate non-semantic shifts.\n\n*   **Key Technical Contributions**\n    *   **Novel Problem Setting**: Introduction of the **Full-Spectrum OOD (FS-OOD) detection** problem, which considers both semantic and covariate shift for a more realistic evaluation \\cite{yang2022it3}.\n    *   **New Benchmarks**: Design of three comprehensive benchmarks (DIGITS, OBJECTS, COVID) with a fine-grained categorization of distributions: training ID, covariate-shifted ID, near-OOD, and far-OOD \\cite{yang2022it3}.\n    *   **Novel Algorithm**: Proposal of **SEM**, a simple yet effective feature-based semantics score function that explicitly disentangles semantic and non-semantic information for robust OOD detection \\cite{yang2022it3}.\n    *   **System Design**: A fine-tuning scheme incorporating negative data augmentation to enhance source-awareness in feature statistics.\n\n*   **Experimental Validation**\n    *   **Benchmarks**: Experiments were conducted on three newly designed FS-OOD benchmarks:\n        *   **DIGITS**: Based on MNIST, SVHN, USPS (covariate-shifted ID), notMNIST, FashionMNIST (near-OOD), and Texture, CIFAR-10, Tiny-ImageNet, Places365 (far-OOD).\n        *   **OBJECTS**: Based on CIFAR-10, ImageNet-10, CIFAR-10-C (covariate-shifted ID), CIFAR-100, Tiny-ImageNet (near-OOD), and MNIST, FashionMNIST, Texture, CIFAR-100-C (far-OOD).\n        *   **COVID**: A real-world medical imaging benchmark for COVID-19 diagnosis, using BIMCV (training ID), ACTUALMED, Hannover (covariate-shifted ID), RSNA Bone Age, COVID CT (near-OOD), and MNIST, CIFAR-10, Texture, Tiny-ImageNet (far-OOD).\n    *   **Metrics**: Performance was evaluated using False Positive Rate at 95% True Positive Rate (FPR95), Area Under the Receiver Operating Characteristic curve (AUROC), and Area Under the Precision-Recall curve (AUPR).\n    *   **Results**: Extensive experiments demonstrated that SEM significantly outperforms current state-of-the-art OOD detection methods across all three new benchmarks, particularly in distinguishing between covariate-shifted ID and true OOD samples \\cite{yang2022it3}.\n\n*   **Limitations & Scope**\n    *   The paper primarily highlights the limitations of *previous* OOD methods in handling covariate shift, rather than explicit limitations of SEM.\n    *   The scope of applicability is focused on **visual recognition tasks**, as evidenced by the image-based benchmarks.\n    *   The approach relies on the assumption that low-level feature statistics effectively capture non-semantic image styles, and that semantic and non-semantic features are generated independently.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by introducing a more comprehensive and realistic OOD detection problem setting (FS-OOD) that is crucial for deploying trustworthy AI systems in real-world scenarios.\n    *   The proposed SEM score function provides a novel and effective way to disentangle semantic and non-semantic information, leading to OOD detectors that are robust to covariate shift while accurately identifying semantic shifts.\n    *   The new benchmarks provide a standardized and challenging testbed for future research in OOD detection, encouraging the development of algorithms that can generalize better and handle diverse distribution shifts.\n    *   The findings have potential impact on future research by shifting the focus towards developing OOD methods that explicitly account for different types of distribution shifts, moving beyond purely semantic-based detection.",
        "keywords": [
          "Full-Spectrum OOD (FS-OOD) detection",
          "covariate shift",
          "semantic shift",
          "SEM (Semantics score function)",
          "disentangling semantic and non-semantic information",
          "robustness to covariate shift",
          "novel OOD benchmarks",
          "Gaussian Mixture Model (GMM)",
          "Source-Awareness Enhancement",
          "Out-of-Distribution (OOD) detection",
          "real-world trustworthy AI",
          "visual recognition tasks"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n1.  **proposes new methods/systems:** the abstract explicitly states, \"we propose sem, a simple feature-based semantics score function.\" it also mentions \"designs three benchmarks\" for a new problem setting. the introduction further elaborates on introducing \"a more challenging yet realistic problem setting called full-spectrum out-of-distribution detection, or fs-ood detection.\"\n2.  **addresses a technical problem with a solution:** the paper identifies a \"critical problem in existing research of ood detection\" regarding covariate shift and then introduces a new problem setting (fs-ood) and a specific method (sem) to address it.\n3.  **empirical validation of proposed solution:** while it includes \"extensive experiments\" and \"significantly outperforms current state-of-the-art methods,\" this empirical work serves to validate the *proposed* technical solution (sem and the new benchmarks), rather than being the sole focus of studying existing data or phenomena. the primary contribution is the creation of the new problem setting, benchmarks, and the sem method."
      },
      "file_name": "1007a43d42c7c92d765cdf614c98f6fc974aaf15.pdf"
    },
    {
      "success": true,
      "doc_id": "5990f641b5d1ca7ae917e76ce8229afd",
      "summary": "The effective application of neural networks in the real-world relies on proficiently detecting out-of-distribution examples. Contemporary methods seek to model the distribution of feature activations in the training data for adequately distinguishing abnormalities, and the state-of-the-art method uses Gaussian distribution models. In this work, we present a novel approach that improves upon the state-of-the-art by leveraging an expressive density model based on normalizing flows. We introduce the residual flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution. Our model is general, and can be applied to any data that is approximately Gaussian. For out of distribution detection in image datasets, our approach provides a principled improvement over the state-of-the-art. Specifically, we demonstrate the effectiveness of our method in ResNet and DenseNet architectures trained on various image datasets. For example, on a ResNet trained on CIFAR-100 and evaluated on detection of out-of-distribution samples from the ImageNet dataset, holding the true positive rate (TPR) at 95%, we improve the true negative rate (TNR) from 56.7% (current state of-the-art) to 77.5% (ours).",
      "intriguing_abstract": "The effective application of neural networks in the real-world relies on proficiently detecting out-of-distribution examples. Contemporary methods seek to model the distribution of feature activations in the training data for adequately distinguishing abnormalities, and the state-of-the-art method uses Gaussian distribution models. In this work, we present a novel approach that improves upon the state-of-the-art by leveraging an expressive density model based on normalizing flows. We introduce the residual flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution. Our model is general, and can be applied to any data that is approximately Gaussian. For out of distribution detection in image datasets, our approach provides a principled improvement over the state-of-the-art. Specifically, we demonstrate the effectiveness of our method in ResNet and DenseNet architectures trained on various image datasets. For example, on a ResNet trained on CIFAR-100 and evaluated on detection of out-of-distribution samples from the ImageNet dataset, holding the true positive rate (TPR) at 95%, we improve the true negative rate (TNR) from 56.7% (current state of-the-art) to 77.5% (ours).",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/af5b1a35271efd17ff3d5ddd152bacc96dff0e81.pdf",
      "citation_key": "zisselman2020cmx",
      "metadata": {
        "title": "Deep Residual Flow for Out of Distribution Detection",
        "authors": [
          "E. Zisselman",
          "Aviv Tamar"
        ],
        "published_date": "2020",
        "abstract": "The effective application of neural networks in the real-world relies on proficiently detecting out-of-distribution examples. Contemporary methods seek to model the distribution of feature activations in the training data for adequately distinguishing abnormalities, and the state-of-the-art method uses Gaussian distribution models. In this work, we present a novel approach that improves upon the state-of-the-art by leveraging an expressive density model based on normalizing flows. We introduce the residual flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution. Our model is general, and can be applied to any data that is approximately Gaussian. For out of distribution detection in image datasets, our approach provides a principled improvement over the state-of-the-art. Specifically, we demonstrate the effectiveness of our method in ResNet and DenseNet architectures trained on various image datasets. For example, on a ResNet trained on CIFAR-100 and evaluated on detection of out-of-distribution samples from the ImageNet dataset, holding the true positive rate (TPR) at 95%, we improve the true negative rate (TNR) from 56.7% (current state of-the-art) to 77.5% (ours).",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/af5b1a35271efd17ff3d5ddd152bacc96dff0e81.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 106,
        "score": 21.200000000000003,
        "summary": "The effective application of neural networks in the real-world relies on proficiently detecting out-of-distribution examples. Contemporary methods seek to model the distribution of feature activations in the training data for adequately distinguishing abnormalities, and the state-of-the-art method uses Gaussian distribution models. In this work, we present a novel approach that improves upon the state-of-the-art by leveraging an expressive density model based on normalizing flows. We introduce the residual flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution. Our model is general, and can be applied to any data that is approximately Gaussian. For out of distribution detection in image datasets, our approach provides a principled improvement over the state-of-the-art. Specifically, we demonstrate the effectiveness of our method in ResNet and DenseNet architectures trained on various image datasets. For example, on a ResNet trained on CIFAR-100 and evaluated on detection of out-of-distribution samples from the ImageNet dataset, holding the true positive rate (TPR) at 95%, we improve the true negative rate (TNR) from 56.7% (current state of-the-art) to 77.5% (ours).",
        "keywords": []
      },
      "file_name": "af5b1a35271efd17ff3d5ddd152bacc96dff0e81.pdf"
    },
    {
      "success": true,
      "doc_id": "bebc547d54ffdaba7a24fa8fbb84d0e9",
      "summary": "Here's a focused summary of the paper \"RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection\" by Song, Sebe, and Wang \\cite{song2022f5d} for a literature review:\n\n---\n\n### Analysis of \"RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection\" \\cite{song2022f5d}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection, where machine learning models often make over-confident predictions for samples that do not belong to the training data distribution.\n    *   **Importance & Challenge**: Safe and reliable deployment of deep learning models in real-world applications necessitates understanding when a test sample is OOD. The main challenge is that current deep learning models are prone to giving high-confidence, yet incorrect, predictions for OOD data.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous OOD detection methods typically rely on feature distance, activation abnormality, or gradient norms.\n    *   **Limitations of Previous Solutions**: While not explicitly detailed as limitations of *all* previous solutions, the paper positions its work as tackling the problem from a novel perspective (spectral analysis) compared to these existing categories. It also highlights that methods like ReAct \\cite{song2022f5d} use manually defined thresholds and require statistics of the whole ID set, which can be sub-optimal and less direct.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{song2022f5d} proposes **RankFeat**, a simple yet effective post-hoc approach. It observes that OOD features tend to have a significantly larger dominant singular value compared to in-distribution (ID) features.\n        *   **Mechanism**: For a given high-level feature map `X`, RankFeat performs Singular Value Decomposition (SVD) to obtain `X = USV^T`. It then removes the rank-1 matrix formed by the largest singular value `s1` and its corresponding singular vectors `u1` and `v1` (i.e., `X' = X - s1u1v1^T`).\n        *   **Scoring**: The perturbed feature `X'` is fed into the rest of the network to generate new logits `y'`, from which an OOD score (specifically, the Energy score `log(sum(exp(y')))` is computed.\n    *   **Novelty/Difference**:\n        *   **Spectral Analysis**: The core innovation is the use of spectral analysis (SVD) of high-level features to identify and remove the dominant rank-1 component, which is observed to disproportionately influence OOD predictions.\n        *   **Direct Subtraction**: Unlike methods that clip activations, RankFeat directly subtracts the identified problematic rank-1 component.\n        *   **Acceleration**: It incorporates Power Iteration (PI) for efficient approximation of the dominant singular value and vectors, avoiding the computational cost of full SVD.\n        *   **Multi-scale Fusion**: Allows for combining scores from features at different network depths (e.g., Block 3 and Block 4) to leverage diverse semantic information.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm/Method**: Introduction of **RankFeat**, a post-hoc OOD detection method based on removing the rank-1 matrix from high-level features, motivated by observed differences in singular value distributions between ID and OOD data.\n    *   **Theoretical Insights**:\n        *   Demonstrates that removing a rank-1 feature with a larger `s1` reduces the upper bound of the RankFeat score more, explaining why it disproportionately affects OOD samples.\n        *   Shows, using Random Matrix Theory (RMT), that removing the rank-1 matrix makes the statistics of OOD features closer to random matrices, suggesting OOD features become less informative.\n        *   Provides a theoretical connection to ReAct \\cite{song2022f5d}, showing both methods optimize an upper bound determined by `s1`, but RankFeat does so directly by subtraction, while ReAct uses indirect clipping.\n    *   **System Design/Architectural Innovations**: Integration of Power Iteration for acceleration and multi-scale feature fusion strategies.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive evaluations were performed on large-scale ImageNet-1k \\cite{song2022f5d} as the ID dataset, with four challenging OOD datasets: iNaturalist, SUN, Places, and Textures \\cite{song2022f5d}. Additional validation was done on Species and CIFAR benchmarks. Ablation studies explored the impact of rank-1 vs. rank-n removal, application at various network depths, Power Iteration iterations, and fusion strategies.\n    *   **Key Performance Metrics**: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic Curve (AUROC).\n    *   **Comparison Results**:\n        *   RankFeat achieved state-of-the-art performance across benchmarks and models.\n        *   It reduced the average FPR95 by **17.90%** and improved the average AUROC by **5.44%** compared to the previous best method (ReAct \\cite{song2022f5d}) on the ImageNet-1k benchmark with ResNetv2-101.\n        *   The method was validated across different architectures, including ResNetv2-101, SqueezeNet, and T2T-ViT-24.\n        *   Power Iteration achieved competitive performance with full SVD but with significantly less time overhead.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   RankFeat is a **post-hoc** approach, meaning it does not modify the model training process.\n        *   It relies on the empirical observation that OOD features have a larger dominant singular value, and that removing this component effectively mitigates over-confidence.\n        *   The theoretical bounds provided are for \"improving understanding\" rather than \"strict guarantee\" of the score.\n    *   **Scope of Applicability**: Applicable to various deep learning architectures (ResNets, Vision Transformers) and effective on large-scale, realistic datasets.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: RankFeat significantly advances the technical state-of-the-art in post-hoc OOD detection, particularly on challenging large-scale benchmarks, by achieving substantial improvements in FPR95 and AUROC.\n    *   **Potential Impact**:\n        *   Introduces a novel perspective for OOD detection based on spectral properties of features, opening new avenues for research in understanding model behavior for OOD inputs.\n        *   Provides a simple, effective, and theoretically grounded method that can be easily integrated into existing deployed models without retraining.\n        *   The insights into the role of dominant singular values in OOD over-confidence could inspire further research into feature representation learning for OOD robustness.",
      "intriguing_abstract": "Deep learning models often make dangerously over-confident predictions for Out-of-Distribution (OOD) data, a critical challenge for safe AI deployment. We introduce **RankFeat**, a novel post-hoc OOD detection method that leverages a surprising spectral property of neural network features. Our core insight reveals that OOD samples exhibit a disproportionately large dominant singular value within their high-level feature maps.\n\nRankFeat capitalizes on this by performing Singular Value Decomposition (SVD) and precisely removing the rank-1 component corresponding to this dominant singular value. This direct subtraction, unlike prior activation clipping techniques, effectively mitigates OOD over-confidence. Theoretically grounded, we demonstrate how this rank-1 removal significantly reduces OOD scores and connect its behavior to Random Matrix Theory. Enhanced with Power Iteration for efficiency and multi-scale feature fusion, RankFeat achieves state-of-the-art performance. On challenging ImageNet-1k benchmarks, it reduced FPR95 by 17.90% and improved AUROC by 5.44% compared to previous methods. RankFeat offers a simple, effective, and theoretically insightful paradigm for robust deep learning, paving the way for more reliable AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "RankFeat",
        "Rank-1 Feature Removal",
        "Singular Value Decomposition (SVD)",
        "dominant singular value",
        "spectral analysis",
        "post-hoc approach",
        "Power Iteration",
        "Energy score",
        "Random Matrix Theory (RMT)",
        "multi-scale feature fusion",
        "state-of-the-art performance",
        "FPR95",
        "AUROC"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/8fe4a9aec9185a2f9da79571f8d239816d4a23d2.pdf",
      "citation_key": "song2022f5d",
      "metadata": {
        "title": "RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection",
        "authors": [
          "Yue Song",
          "N. Sebe",
          "Wei Wang"
        ],
        "published_date": "2022",
        "abstract": "The task of out-of-distribution (OOD) detection is crucial for deploying machine learning models in real-world settings. In this paper, we observe that the singular value distributions of the in-distribution (ID) and OOD features are quite different: the OOD feature matrix tends to have a larger dominant singular value than the ID feature, and the class predictions of OOD samples are largely determined by it. This observation motivates us to propose \\texttt{RankFeat}, a simple yet effective \\texttt{post hoc} approach for OOD detection by removing the rank-1 matrix composed of the largest singular value and the associated singular vectors from the high-level feature (\\emph{i.e.,} $\\mathbf{X}{-} \\mathbf{s}_{1}\\mathbf{u}_{1}\\mathbf{v}_{1}^{T}$). \\texttt{RankFeat} achieves the \\emph{state-of-the-art} performance and reduces the average false positive rate (FPR95) by 17.90\\% compared with the previous best method. Extensive ablation studies and comprehensive theoretical analyses are presented to support the empirical results.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/8fe4a9aec9185a2f9da79571f8d239816d4a23d2.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 63,
        "score": 21.0,
        "summary": "Here's a focused summary of the paper \"RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection\" by Song, Sebe, and Wang \\cite{song2022f5d} for a literature review:\n\n---\n\n### Analysis of \"RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection\" \\cite{song2022f5d}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection, where machine learning models often make over-confident predictions for samples that do not belong to the training data distribution.\n    *   **Importance & Challenge**: Safe and reliable deployment of deep learning models in real-world applications necessitates understanding when a test sample is OOD. The main challenge is that current deep learning models are prone to giving high-confidence, yet incorrect, predictions for OOD data.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous OOD detection methods typically rely on feature distance, activation abnormality, or gradient norms.\n    *   **Limitations of Previous Solutions**: While not explicitly detailed as limitations of *all* previous solutions, the paper positions its work as tackling the problem from a novel perspective (spectral analysis) compared to these existing categories. It also highlights that methods like ReAct \\cite{song2022f5d} use manually defined thresholds and require statistics of the whole ID set, which can be sub-optimal and less direct.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{song2022f5d} proposes **RankFeat**, a simple yet effective post-hoc approach. It observes that OOD features tend to have a significantly larger dominant singular value compared to in-distribution (ID) features.\n        *   **Mechanism**: For a given high-level feature map `X`, RankFeat performs Singular Value Decomposition (SVD) to obtain `X = USV^T`. It then removes the rank-1 matrix formed by the largest singular value `s1` and its corresponding singular vectors `u1` and `v1` (i.e., `X' = X - s1u1v1^T`).\n        *   **Scoring**: The perturbed feature `X'` is fed into the rest of the network to generate new logits `y'`, from which an OOD score (specifically, the Energy score `log(sum(exp(y')))` is computed.\n    *   **Novelty/Difference**:\n        *   **Spectral Analysis**: The core innovation is the use of spectral analysis (SVD) of high-level features to identify and remove the dominant rank-1 component, which is observed to disproportionately influence OOD predictions.\n        *   **Direct Subtraction**: Unlike methods that clip activations, RankFeat directly subtracts the identified problematic rank-1 component.\n        *   **Acceleration**: It incorporates Power Iteration (PI) for efficient approximation of the dominant singular value and vectors, avoiding the computational cost of full SVD.\n        *   **Multi-scale Fusion**: Allows for combining scores from features at different network depths (e.g., Block 3 and Block 4) to leverage diverse semantic information.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm/Method**: Introduction of **RankFeat**, a post-hoc OOD detection method based on removing the rank-1 matrix from high-level features, motivated by observed differences in singular value distributions between ID and OOD data.\n    *   **Theoretical Insights**:\n        *   Demonstrates that removing a rank-1 feature with a larger `s1` reduces the upper bound of the RankFeat score more, explaining why it disproportionately affects OOD samples.\n        *   Shows, using Random Matrix Theory (RMT), that removing the rank-1 matrix makes the statistics of OOD features closer to random matrices, suggesting OOD features become less informative.\n        *   Provides a theoretical connection to ReAct \\cite{song2022f5d}, showing both methods optimize an upper bound determined by `s1`, but RankFeat does so directly by subtraction, while ReAct uses indirect clipping.\n    *   **System Design/Architectural Innovations**: Integration of Power Iteration for acceleration and multi-scale feature fusion strategies.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive evaluations were performed on large-scale ImageNet-1k \\cite{song2022f5d} as the ID dataset, with four challenging OOD datasets: iNaturalist, SUN, Places, and Textures \\cite{song2022f5d}. Additional validation was done on Species and CIFAR benchmarks. Ablation studies explored the impact of rank-1 vs. rank-n removal, application at various network depths, Power Iteration iterations, and fusion strategies.\n    *   **Key Performance Metrics**: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic Curve (AUROC).\n    *   **Comparison Results**:\n        *   RankFeat achieved state-of-the-art performance across benchmarks and models.\n        *   It reduced the average FPR95 by **17.90%** and improved the average AUROC by **5.44%** compared to the previous best method (ReAct \\cite{song2022f5d}) on the ImageNet-1k benchmark with ResNetv2-101.\n        *   The method was validated across different architectures, including ResNetv2-101, SqueezeNet, and T2T-ViT-24.\n        *   Power Iteration achieved competitive performance with full SVD but with significantly less time overhead.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   RankFeat is a **post-hoc** approach, meaning it does not modify the model training process.\n        *   It relies on the empirical observation that OOD features have a larger dominant singular value, and that removing this component effectively mitigates over-confidence.\n        *   The theoretical bounds provided are for \"improving understanding\" rather than \"strict guarantee\" of the score.\n    *   **Scope of Applicability**: Applicable to various deep learning architectures (ResNets, Vision Transformers) and effective on large-scale, realistic datasets.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: RankFeat significantly advances the technical state-of-the-art in post-hoc OOD detection, particularly on challenging large-scale benchmarks, by achieving substantial improvements in FPR95 and AUROC.\n    *   **Potential Impact**:\n        *   Introduces a novel perspective for OOD detection based on spectral properties of features, opening new avenues for research in understanding model behavior for OOD inputs.\n        *   Provides a simple, effective, and theoretically grounded method that can be easily integrated into existing deployed models without retraining.\n        *   The insights into the role of dominant singular values in OOD over-confidence could inspire further research into feature representation learning for OOD robustness.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "RankFeat",
          "Rank-1 Feature Removal",
          "Singular Value Decomposition (SVD)",
          "dominant singular value",
          "spectral analysis",
          "post-hoc approach",
          "Power Iteration",
          "Energy score",
          "Random Matrix Theory (RMT)",
          "multi-scale feature fusion",
          "state-of-the-art performance",
          "FPR95",
          "AUROC"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **abstract mentions:** \"propose rankfeat\", \"removing the rank-1 matrix\" (describes a new method/algorithm), \"achieves the state-of-the-art performance\" (empirical results), \"extensive ablation studies and comprehensive theoretical analyses are presented\" (empirical and theoretical support).\n2.  **introduction discusses:** \"tackle the problem of ood detection from another perspective\", \"motivates us to remove the rank-1 matrix\" (describes the proposed solution).\n\nthe core contribution described is the **proposal of a new method/approach** (rankfeat) for ood detection, which is then supported by empirical results and theoretical analysis. this aligns perfectly with the definition of a **technical** paper.\n\ntherefore, the classification is: **technical**"
      },
      "file_name": "8fe4a9aec9185a2f9da79571f8d239816d4a23d2.pdf"
    },
    {
      "success": true,
      "doc_id": "4c9c58eac4a197e744890dff5d4c822c",
      "summary": "Here's a focused summary of the paper `\\cite{liu202227x}` for a literature review:\n\n### GOOD-D: On Unsupervised Graph Out-Of-Distribution Detection \\cite{liu202227x}\n\n1.  **Research Problem & Motivation**\n    *   **Problem**: Detecting Out-Of-Distribution (OOD) samples in graph-structured data, specifically at the graph level, without relying on any ground-truth labels (unsupervised setting).\n    *   **Importance**: Deep learning models are typically trained under a closed-world assumption (test data is i.i.d. with training data). However, in open-world deployments, models encounter OOD inputs, necessitating robust OOD detection for reliable systems.\n    *   **Challenges**:\n        *   Existing OOD detection primarily focuses on grid-structured data (images, text), with graph-structured data being largely under-explored.\n        *   Graph data labeling is expensive and labor-intensive, making unsupervised methods crucial.\n        *   Current graph self-supervised learning (especially Graph Contrastive Learning - GCL) often uses arbitrary data augmentations (e.g., feature/edge modification) that can inadvertently introduce OOD samples, making the model less sensitive to actual OOD data.\n        *   Existing GCL methods predominantly focus on instance-level contrast, which is not well-aligned with capturing diverse OOD patterns that may violate ID patterns at different granularities (node-level, graph-level, group-level).\n\n2.  **Related Work & Positioning**\n    *   **OOD Detection**: While extensive OOD methods exist for vision and language, graph OOD is nascent. `\\cite{liu202227x}` distinguishes itself by focusing on *unsupervised graph-level* OOD detection, unlike prior works that are often supervised, node-level, or focus on improving GNN generalization under distribution shifts rather than OOD identification. It also differentiates from graph anomaly detection by addressing a more general problem.\n    *   **Graph Contrastive Learning (GCL)**: Acknowledges GCL's effectiveness for unsupervised graph representation learning. However, `\\cite{liu202227x}` highlights limitations of conventional GCL augmentations (perturbation-based) that can hinder OOD detection and the lack of hierarchical contrastive mechanisms suitable for capturing multi-granularity OOD patterns.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Method**: `\\cite{liu202227x}` proposes GOOD-D, a novel graph contrastive learning framework for unsupervised graph-level OOD detection. It captures latent ID patterns and detects OOD graphs based on semantic inconsistency across different granularities.\n    *   **Perturbation-Free Graph Data Augmentation**: Instead of random perturbations, `\\cite{liu202227x}` constructs two fixed, distinct, and informative views for each graph:\n        *   **Feature View** (`G_f`): The original graph with its node features and adjacency matrix.\n        *   **Structure View** (`G_s`): The graph with its adjacency matrix and *structural encodings* replacing original node features. These structural encodings combine global (random walk diffusion) and local (node degrees) topological information. This avoids introducing OOD-like samples during augmentation.\n    *   **Hierarchical Graph Contrastive Learning**: `\\cite{liu202227x}` performs contrastive learning at three levels to learn expressive representations and consolidate the semantic manifold of ID data:\n        *   **Node-level contrast**: Maximizes agreement between node embeddings from the feature and structure views.\n        *   **Graph-level contrast**: Maximizes agreement between graph embeddings from the two views.\n        *   **Group-level contrast**: Enhances intra-cluster compactness and inter-cluster separability of ID data, crucial for detecting cluster-deviated OOD samples.\n    *   **OOD Scoring**: An adaptive scoring mechanism aggregates contrastive errors from these three levels to generate an OOD detection score.\n    *   **Adaptive Learning Loss**: The hierarchical contrastive learning component is equipped with an adaptive learning loss to automatically control the contribution of each granularity.\n\n4.  **Key Technical Contributions**\n    *   **Problem Formulation**: Formally defines and addresses the unsupervised graph-level OOD detection problem, a pioneering effort in this domain.\n    *   **Novel Framework (GOOD-D)**: Introduces a self-supervised framework that learns expressive ID distributions and measures OOD scores.\n    *   **Perturbation-Free Augmentation**: Designs a novel, principled graph data augmentation strategy that generates feature and structure views without introducing detrimental perturbations, a critical innovation for OOD detection.\n    *   **Hierarchical Contrastive Learning**: Proposes a multi-granularity contrastive learning approach (node, graph, group levels) to capture comprehensive ID patterns and semantic manifolds.\n    *   **Adaptive OOD Scoring**: Develops an adaptive mechanism to combine hierarchical contrastive errors into a robust OOD score.\n    *   **Benchmark Dataset**: Constructs a comprehensive benchmark for graph-level OOD detection using real-world datasets from diverse domains.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: `\\cite{liu202227x}` conducted extensive experiments on a range of benchmarks.\n    *   **Datasets**: Evaluated on real-world datasets from diverse domains.\n    *   **Comparison**: Compared the proposed approach with different state-of-the-art methods.\n    *   **Results**: The experimental results demonstrate the superiority of GOOD-D over various methods across different datasets. (Specific metrics and detailed comparison results are not provided in the abstract/introduction but are implied by \"superiority\").\n\n6.  **Limitations & Scope**\n    *   **Scope**: The work focuses specifically on *unsupervised graph-level* OOD detection. It does not address supervised settings or node-level OOD detection.\n    *   **Assumptions**: Assumes that structural encodings (random walk diffusion, node degrees) are sufficient to capture universal topological patterns for the structure view. The approach is agnostic to the specific definition of structural encoding, suggesting potential for future extensions with other encodings.\n    *   **Technical Limitations (Implicit)**: The complexity of combining three levels of contrast and an adaptive loss might introduce tuning challenges, though the adaptive loss aims to mitigate this.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: `\\cite{liu202227x}` makes the first attempt to solve unsupervised graph-level OOD detection, significantly advancing the technical state-of-the-art in graph machine learning and OOD detection.\n    *   **Pioneering Work**: It is a pioneering work in this specific problem domain, opening new avenues for research.\n    *   **Impact on Future Research**: The formal problem formulation, the proposed GOOD-D framework, and the established benchmark datasets are expected to shed light on and stimulate future research in graph OOD detection and trustworthy graph AI.\n    *   **Methodological Innovation**: The perturbation-free augmentation and hierarchical contrastive learning are novel methodological contributions applicable beyond OOD detection.",
      "intriguing_abstract": "Deep learning models, often trained under closed-world assumptions, face significant reliability challenges when deployed in open-world scenarios encountering Out-Of-Distribution (OOD) graph data. While crucial for robust systems, unsupervised graph-level OOD detection remains largely unexplored due to the inherent complexity of graph structures and the prohibitive cost of labeling. We introduce **GOOD-D**, a pioneering self-supervised framework designed to robustly identify OOD graphs by comprehensively learning intrinsic In-Distribution (ID) patterns.\n\nGOOD-D innovates with a novel **perturbation-free graph data augmentation** strategy, generating distinct feature and structure views (leveraging **structural encodings**) to avoid inadvertently creating OOD-like samples. This is coupled with a **hierarchical graph contrastive learning** mechanism that captures ID semantics across node, graph, and group levels, consolidating the ID semantic manifold. An adaptive scoring mechanism then precisely quantifies OOD deviations. Extensive experiments demonstrate GOOD-D's superior performance, establishing a new benchmark for trustworthy graph AI and paving the way for more reliable graph-based systems.",
      "keywords": [
        "Unsupervised Graph OOD Detection",
        "GOOD-D framework",
        "Graph Contrastive Learning",
        "Perturbation-Free Data Augmentation",
        "Hierarchical Contrastive Learning",
        "Graph-level OOD",
        "Structural Encodings",
        "Adaptive OOD Scoring",
        "Semantic Inconsistency",
        "Open-world deployments",
        "Trustworthy Graph AI",
        "Multi-granularity contrast",
        "Benchmark Dataset"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/305941292b59d808af1f6646993747ba0f76f4ac.pdf",
      "citation_key": "liu202227x",
      "metadata": {
        "title": "GOOD-D: On Unsupervised Graph Out-Of-Distribution Detection",
        "authors": [
          "Yixin Liu",
          "Kaize Ding",
          "Huan Liu",
          "Shirui Pan"
        ],
        "published_date": "2022",
        "abstract": "Most existing deep learning models are trained based on the closed-world assumption, where the test data is assumed to be drawn i.i.d. from the same distribution as the training data, known as in-distribution (ID). However, when models are deployed in an open-world scenario, test samples can be out-of-distribution (OOD) and therefore should be handled with caution. To detect such OOD samples drawn from unknown distribution, OOD detection has received increasing attention lately. However, current endeavors mostly focus on grid-structured data and its application for graph-structured data remains under-explored. Considering the fact that data labeling on graphs is commonly time-expensive and labor-intensive, in this work we study the problem of unsupervised graph OOD detection, aiming at detecting OOD graphs solely based on unlabeled ID data. To achieve this goal, we develop a new graph contrastive learning framework GOOD-D for detecting OOD graphs without using any ground-truth labels. By performing hierarchical contrastive learning on the augmented graphs generated by our perturbation-free graph data augmentation method, GOOD-D is able to capture the latent ID patterns and accurately detect OOD graphs based on the semantic inconsistency in different granularities (i.e., node-level, graph-level, and group-level). As a pioneering work in unsupervised graph-level OOD detection, we build a comprehensive benchmark to compare our proposed approach with different state-of-the-art methods. The experiment results demonstrate the superiority of our approach over different methods on various datasets.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/305941292b59d808af1f6646993747ba0f76f4ac.pdf",
        "venue": "Web Search and Data Mining",
        "citationCount": 63,
        "score": 21.0,
        "summary": "Here's a focused summary of the paper `\\cite{liu202227x}` for a literature review:\n\n### GOOD-D: On Unsupervised Graph Out-Of-Distribution Detection \\cite{liu202227x}\n\n1.  **Research Problem & Motivation**\n    *   **Problem**: Detecting Out-Of-Distribution (OOD) samples in graph-structured data, specifically at the graph level, without relying on any ground-truth labels (unsupervised setting).\n    *   **Importance**: Deep learning models are typically trained under a closed-world assumption (test data is i.i.d. with training data). However, in open-world deployments, models encounter OOD inputs, necessitating robust OOD detection for reliable systems.\n    *   **Challenges**:\n        *   Existing OOD detection primarily focuses on grid-structured data (images, text), with graph-structured data being largely under-explored.\n        *   Graph data labeling is expensive and labor-intensive, making unsupervised methods crucial.\n        *   Current graph self-supervised learning (especially Graph Contrastive Learning - GCL) often uses arbitrary data augmentations (e.g., feature/edge modification) that can inadvertently introduce OOD samples, making the model less sensitive to actual OOD data.\n        *   Existing GCL methods predominantly focus on instance-level contrast, which is not well-aligned with capturing diverse OOD patterns that may violate ID patterns at different granularities (node-level, graph-level, group-level).\n\n2.  **Related Work & Positioning**\n    *   **OOD Detection**: While extensive OOD methods exist for vision and language, graph OOD is nascent. `\\cite{liu202227x}` distinguishes itself by focusing on *unsupervised graph-level* OOD detection, unlike prior works that are often supervised, node-level, or focus on improving GNN generalization under distribution shifts rather than OOD identification. It also differentiates from graph anomaly detection by addressing a more general problem.\n    *   **Graph Contrastive Learning (GCL)**: Acknowledges GCL's effectiveness for unsupervised graph representation learning. However, `\\cite{liu202227x}` highlights limitations of conventional GCL augmentations (perturbation-based) that can hinder OOD detection and the lack of hierarchical contrastive mechanisms suitable for capturing multi-granularity OOD patterns.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Method**: `\\cite{liu202227x}` proposes GOOD-D, a novel graph contrastive learning framework for unsupervised graph-level OOD detection. It captures latent ID patterns and detects OOD graphs based on semantic inconsistency across different granularities.\n    *   **Perturbation-Free Graph Data Augmentation**: Instead of random perturbations, `\\cite{liu202227x}` constructs two fixed, distinct, and informative views for each graph:\n        *   **Feature View** (`G_f`): The original graph with its node features and adjacency matrix.\n        *   **Structure View** (`G_s`): The graph with its adjacency matrix and *structural encodings* replacing original node features. These structural encodings combine global (random walk diffusion) and local (node degrees) topological information. This avoids introducing OOD-like samples during augmentation.\n    *   **Hierarchical Graph Contrastive Learning**: `\\cite{liu202227x}` performs contrastive learning at three levels to learn expressive representations and consolidate the semantic manifold of ID data:\n        *   **Node-level contrast**: Maximizes agreement between node embeddings from the feature and structure views.\n        *   **Graph-level contrast**: Maximizes agreement between graph embeddings from the two views.\n        *   **Group-level contrast**: Enhances intra-cluster compactness and inter-cluster separability of ID data, crucial for detecting cluster-deviated OOD samples.\n    *   **OOD Scoring**: An adaptive scoring mechanism aggregates contrastive errors from these three levels to generate an OOD detection score.\n    *   **Adaptive Learning Loss**: The hierarchical contrastive learning component is equipped with an adaptive learning loss to automatically control the contribution of each granularity.\n\n4.  **Key Technical Contributions**\n    *   **Problem Formulation**: Formally defines and addresses the unsupervised graph-level OOD detection problem, a pioneering effort in this domain.\n    *   **Novel Framework (GOOD-D)**: Introduces a self-supervised framework that learns expressive ID distributions and measures OOD scores.\n    *   **Perturbation-Free Augmentation**: Designs a novel, principled graph data augmentation strategy that generates feature and structure views without introducing detrimental perturbations, a critical innovation for OOD detection.\n    *   **Hierarchical Contrastive Learning**: Proposes a multi-granularity contrastive learning approach (node, graph, group levels) to capture comprehensive ID patterns and semantic manifolds.\n    *   **Adaptive OOD Scoring**: Develops an adaptive mechanism to combine hierarchical contrastive errors into a robust OOD score.\n    *   **Benchmark Dataset**: Constructs a comprehensive benchmark for graph-level OOD detection using real-world datasets from diverse domains.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: `\\cite{liu202227x}` conducted extensive experiments on a range of benchmarks.\n    *   **Datasets**: Evaluated on real-world datasets from diverse domains.\n    *   **Comparison**: Compared the proposed approach with different state-of-the-art methods.\n    *   **Results**: The experimental results demonstrate the superiority of GOOD-D over various methods across different datasets. (Specific metrics and detailed comparison results are not provided in the abstract/introduction but are implied by \"superiority\").\n\n6.  **Limitations & Scope**\n    *   **Scope**: The work focuses specifically on *unsupervised graph-level* OOD detection. It does not address supervised settings or node-level OOD detection.\n    *   **Assumptions**: Assumes that structural encodings (random walk diffusion, node degrees) are sufficient to capture universal topological patterns for the structure view. The approach is agnostic to the specific definition of structural encoding, suggesting potential for future extensions with other encodings.\n    *   **Technical Limitations (Implicit)**: The complexity of combining three levels of contrast and an adaptive loss might introduce tuning challenges, though the adaptive loss aims to mitigate this.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: `\\cite{liu202227x}` makes the first attempt to solve unsupervised graph-level OOD detection, significantly advancing the technical state-of-the-art in graph machine learning and OOD detection.\n    *   **Pioneering Work**: It is a pioneering work in this specific problem domain, opening new avenues for research.\n    *   **Impact on Future Research**: The formal problem formulation, the proposed GOOD-D framework, and the established benchmark datasets are expected to shed light on and stimulate future research in graph OOD detection and trustworthy graph AI.\n    *   **Methodological Innovation**: The perturbation-free augmentation and hierarchical contrastive learning are novel methodological contributions applicable beyond OOD detection.",
        "keywords": [
          "Unsupervised Graph OOD Detection",
          "GOOD-D framework",
          "Graph Contrastive Learning",
          "Perturbation-Free Data Augmentation",
          "Hierarchical Contrastive Learning",
          "Graph-level OOD",
          "Structural Encodings",
          "Adaptive OOD Scoring",
          "Semantic Inconsistency",
          "Open-world deployments",
          "Trustworthy Graph AI",
          "Multi-granularity contrast",
          "Benchmark Dataset"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n*   **abstract keywords:** \"we **develop a new graph contrastive learning framework good-d**\", \"our **proposed approach**\", \"perturbation-free graph data **augmentation method**\". these directly align with the \"technical\" criteria of presenting new methods, algorithms, or systems.\n*   **introduction focus:** the introduction sets up a technical problem (ood detection in graph-structured data) and highlights the gap in existing solutions, leading to the need for the proposed solution.\n*   **empirical aspect:** while the abstract mentions \"experiment results demonstrate the superiority of our approach,\" this is the *validation* of the *new technical method*. the core contribution is the development of good-d, and the experiments serve to prove its effectiveness. many technical papers include an empirical evaluation of their proposed solution. the primary focus is on the creation of the new system/method."
      },
      "file_name": "305941292b59d808af1f6646993747ba0f76f4ac.pdf"
    },
    {
      "success": true,
      "doc_id": "f13f2325178f7891887216a46d7bcc6e",
      "summary": "The goal of out-of-distribution (OOD) detection is to handle the situations where the test samples are drawn from a different distribution than the training data. In this paper, we argue that OOD samples can be detected more easily if the training data is embedded into a low-dimensional space, such that the embedded training samples lie on a union of 1-dimensional subspaces. We show that such embedding of the in-distribution (ID) samples provides us with two main advantages. First, due to compact representation in the feature space, OOD samples are less likely to occupy the same region as the known classes. Second, the first singular vector of ID samples belonging to a 1-dimensional subspace can be used as their robust representative. Motivated by these observations, we train a deep neural network such that the ID samples are embedded onto a union of 1-dimensional subspaces. At the test time, employing sampling techniques used for approximate Bayesian inference in deep learning, input samples are detected as OOD if they occupy the region corresponding to the ID samples with probability 0. Spectral components of the ID samples are used as robust representative of this region. Our method does not have any hyperparameter to be tuned using extra information and it can be applied on different modalities with minimal change. The effectiveness of the proposed method is demonstrated on different benchmark datasets, both in the image and video classification domains.",
      "intriguing_abstract": "The goal of out-of-distribution (OOD) detection is to handle the situations where the test samples are drawn from a different distribution than the training data. In this paper, we argue that OOD samples can be detected more easily if the training data is embedded into a low-dimensional space, such that the embedded training samples lie on a union of 1-dimensional subspaces. We show that such embedding of the in-distribution (ID) samples provides us with two main advantages. First, due to compact representation in the feature space, OOD samples are less likely to occupy the same region as the known classes. Second, the first singular vector of ID samples belonging to a 1-dimensional subspace can be used as their robust representative. Motivated by these observations, we train a deep neural network such that the ID samples are embedded onto a union of 1-dimensional subspaces. At the test time, employing sampling techniques used for approximate Bayesian inference in deep learning, input samples are detected as OOD if they occupy the region corresponding to the ID samples with probability 0. Spectral components of the ID samples are used as robust representative of this region. Our method does not have any hyperparameter to be tuned using extra information and it can be applied on different modalities with minimal change. The effectiveness of the proposed method is demonstrated on different benchmark datasets, both in the image and video classification domains.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/a43f7d6a751a6ad8667272f1176d2f15dbd8feb6.pdf",
      "citation_key": "zaeemzadeh2021lmh",
      "metadata": {
        "title": "Out-of-Distribution Detection Using Union of 1-Dimensional Subspaces",
        "authors": [
          "Alireza Zaeemzadeh",
          "NiccolÃ³ Bisagno",
          "Zeno Sambugaro",
          "N. Conci",
          "Nazanin Rahnavard",
          "M. Shah"
        ],
        "published_date": "2021",
        "abstract": "The goal of out-of-distribution (OOD) detection is to handle the situations where the test samples are drawn from a different distribution than the training data. In this paper, we argue that OOD samples can be detected more easily if the training data is embedded into a low-dimensional space, such that the embedded training samples lie on a union of 1-dimensional subspaces. We show that such embedding of the in-distribution (ID) samples provides us with two main advantages. First, due to compact representation in the feature space, OOD samples are less likely to occupy the same region as the known classes. Second, the first singular vector of ID samples belonging to a 1-dimensional subspace can be used as their robust representative. Motivated by these observations, we train a deep neural network such that the ID samples are embedded onto a union of 1-dimensional subspaces. At the test time, employing sampling techniques used for approximate Bayesian inference in deep learning, input samples are detected as OOD if they occupy the region corresponding to the ID samples with probability 0. Spectral components of the ID samples are used as robust representative of this region. Our method does not have any hyperparameter to be tuned using extra information and it can be applied on different modalities with minimal change. The effectiveness of the proposed method is demonstrated on different benchmark datasets, both in the image and video classification domains.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/a43f7d6a751a6ad8667272f1176d2f15dbd8feb6.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 82,
        "score": 20.5,
        "summary": "The goal of out-of-distribution (OOD) detection is to handle the situations where the test samples are drawn from a different distribution than the training data. In this paper, we argue that OOD samples can be detected more easily if the training data is embedded into a low-dimensional space, such that the embedded training samples lie on a union of 1-dimensional subspaces. We show that such embedding of the in-distribution (ID) samples provides us with two main advantages. First, due to compact representation in the feature space, OOD samples are less likely to occupy the same region as the known classes. Second, the first singular vector of ID samples belonging to a 1-dimensional subspace can be used as their robust representative. Motivated by these observations, we train a deep neural network such that the ID samples are embedded onto a union of 1-dimensional subspaces. At the test time, employing sampling techniques used for approximate Bayesian inference in deep learning, input samples are detected as OOD if they occupy the region corresponding to the ID samples with probability 0. Spectral components of the ID samples are used as robust representative of this region. Our method does not have any hyperparameter to be tuned using extra information and it can be applied on different modalities with minimal change. The effectiveness of the proposed method is demonstrated on different benchmark datasets, both in the image and video classification domains.",
        "keywords": []
      },
      "file_name": "a43f7d6a751a6ad8667272f1176d2f15dbd8feb6.pdf"
    },
    {
      "success": true,
      "doc_id": "5c535ccc6adb3551074c6963b42f7faf",
      "summary": "Here is a focused summary of the technical paper for a literature review:\n\n### Analysis of \"ON THE IMPACT OF SPURIOUS CORRELATION FOR OUT-OF-DISTRIBUTION DETECTION\" \\cite{ming2021wu7}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Modern neural networks exhibit high confidence in predictions for out-of-distribution (OOD) inputs, posing reliability risks. A critical, often overlooked, aspect is the vague definition of OOD, particularly concerning the influence of spurious correlations in training data.\n    *   **Importance and Challenge**: The problem is important because OOD detection is crucial for safe and robust AI deployment. It is challenging because models can learn to rely on statistically informative but non-causal (spurious) features (e.g., background, gender) instead of invariant, semantic features. This reliance can lead to high-confidence predictions on OOD inputs that share these spurious features, making them difficult to detect.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: While much research focuses on designing new OOD detection methods, \\cite{ming2021wu7} highlights that these often operate under an oversimplified notion of OOD, typically viewing data with non-overlapping semantics as OOD.\n    *   **Limitations of Previous Solutions**: Prior work largely overlooks the impact of spurious correlations on OOD detection performance. Existing evaluation protocols for OOD detection often do not account for scenarios where OOD inputs share spurious features with in-distribution (ID) data, leading to an incomplete understanding of model robustness.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper introduces a new formalization of OOD data by explicitly modeling data shifts based on the separation of *invariant features* ($z_{inv}$, essential cues for labels) and *environmental (spurious) features* ($z_e$, non-essential but correlated cues).\n    *   **Novelty**: This formalization defines two distinct types of OOD:\n        *   **Spurious OOD**: Test samples containing environmental features but lacking invariant features essential for ID labels (e.g., a boat image with a \"water\" background, where \"water\" is a spurious feature for \"waterbird\").\n        *   **Non-spurious (Conventional) OOD**: Inputs lacking both environmental and invariant features (e.g., an image of an indoor cat for a waterbird/landbird classifier).\n        *   The paper then systematically investigates how increasing spurious correlation in the training set impacts the detection of both types of OOD.\n\n4.  **Key Technical Contributions**\n    *   **Novel Formalization**: A new formalization of OOD detection that explicitly accounts for invariant and environmental features, encapsulating both spurious and non-spurious OOD. This provides a complementary perspective for OOD evaluation.\n    *   **Systematic Investigation**: Comprehensive empirical studies demonstrating how the extent of spurious correlation in the training set significantly degrades OOD detection performance for both spurious and non-spurious OOD.\n    *   **Methodological Insights**: Identification of OOD detection solutions (specifically feature-based methods) that are more effective in mitigating the impact of spurious correlation, showing up to a 46.73% reduction in FPR95 for non-spurious OOD.\n    *   **Theoretical Analysis**: Provable demonstration that detecting spurious OOD samples remains challenging due to the model's reliance on environmental features, showing the existence of spurious OOD inputs with arbitrarily high confidence.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Models (ResNet-18) were trained using Empirical Risk Minimization (ERM) on datasets with controlled spurious correlations.\n        *   Evaluations were performed on three tasks: Waterbirds (background-label correlation), CelebA (gender-hair color correlation), and ColorMNIST (color-digit correlation, detailed in supplementary).\n        *   The degree of spurious correlation (`r`) in the training data was varied (e.g., `r` = 0.5, 0.7, 0.9 for Waterbirds).\n        *   Both spurious OOD (e.g., Places dataset images with water/land backgrounds for Waterbirds, bald male images for CelebA) and non-spurious OOD (iSUN, LSUN, SVHN) test sets were used.\n        *   A suite of common OOD scoring functions was evaluated: Maximum Softmax Probability (MSP), ODIN, Mahalanobis distance, Energy score, and Gram matrix-based score.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Metrics**: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC).\n        *   **Impact of Spurious Correlation**: Increased spurious correlation in training data severely worsened detection performance for both OOD types. For Waterbirds, FPR95 for spurious OOD increased from 59.89% (r=0.5) to 74.39% (r=0.9).\n        *   **Spurious vs. Non-spurious OOD**: Spurious OOD was consistently much harder to detect than non-spurious OOD (e.g., for Waterbirds with r=0.7, average FPR95 was 74.22% for spurious OOD vs. 37.35% for non-spurious OOD).\n        *   **Effectiveness of Detection Methods**: Feature-based methods (Mahalanobis distance, Gram Matrix score) generally outperformed output-based methods (MSP, ODIN, Energy score). Mahalanobis score, for instance, reduced FPR95 by 46.73% for non-spurious OOD on Waterbirds compared to MSP.\n        *   **Visualization**: Feature embeddings (t-SNE) showed that spurious OOD samples often overlap with ID clusters, while non-spurious OOD samples are clearly separated, explaining the difficulty.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations**: While feature-based methods improve non-spurious OOD detection, detecting spurious OOD remains a significant challenge, even with these advanced techniques. The theoretical analysis confirms the inherent difficulty of distinguishing spurious OOD from ID data when models rely on environmental features.\n    *   **Scope of Applicability**: The study focuses on image classification tasks and specific types of spurious correlations (background, gender, color). The formalization and findings are broadly applicable to scenarios where models might exploit non-causal correlations.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{ming2021wu7} significantly advances the understanding of OOD detection by formalizing the problem to include the impact of spurious correlations. It moves beyond simplistic OOD definitions, providing a more nuanced and realistic framework for evaluation.\n    *   **Potential Impact on Future Research**: The work provides strong implications for future research, emphasizing the need for OOD detection algorithms to be evaluated not just on standard benchmarks (which are often non-spurious) but also on challenging spurious OOD examples. This encourages the development of more robust OOD detection methods that are less susceptible to spurious correlations and inspires further research into OOD formalization and algorithmic solutions.",
      "intriguing_abstract": "Modern neural networks often exhibit dangerous overconfidence in out-of-distribution (OOD) predictions, a critical reliability risk for AI deployment. This paper uncovers a fundamental, yet overlooked, driver of this issue: the pervasive influence of **spurious correlations** in training data. We introduce a novel formalization of OOD, explicitly separating *invariant* and *environmental (spurious)* features, which defines two distinct OOD categories: **Spurious OOD** (inputs lacking essential invariant features but possessing environmental cues) and **Non-spurious OOD** (lacking both).\n\nOur systematic empirical and theoretical investigation reveals that increasing spurious correlation in training data drastically degrades OOD detection performance for both types. Crucially, Spurious OOD samples, where models rely on non-causal environmental features, are provably difficult to detect, often eliciting arbitrarily high confidence. While feature-based detection methods offer some mitigation for non-spurious OOD, the pervasive impact of spurious correlations demands a paradigm shift. This work provides a crucial, nuanced framework for understanding **OOD robustness**, urging the development of algorithms and evaluation protocols that explicitly account for spurious correlations to build truly safe and reliable AI systems.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "spurious correlation",
        "invariant features",
        "environmental features",
        "spurious OOD",
        "OOD formalization",
        "impact of spurious correlation",
        "feature-based OOD detection",
        "model robustness",
        "high-confidence OOD predictions",
        "FPR95",
        "Mahalanobis distance",
        "image classification",
        "theoretical analysis",
        "data shifts"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/aaedc4d1d19a1e82cd4880c1b414593e766a1f31.pdf",
      "citation_key": "ming2021wu7",
      "metadata": {
        "title": "On the Impact of Spurious Correlation for Out-of-distribution Detection",
        "authors": [
          "Yifei Ming",
          "Hang Yin",
          "Yixuan Li"
        ],
        "published_date": "2021",
        "abstract": "Modern neural networks can assign high confidence to inputs drawn from outside the training distribution, posing threats to models in real-world deployments. While much research attention has been placed on designing new out-of-distribution (OOD) detection methods, the precise definition of OOD is often left in vagueness and falls short of the desired notion of OOD in reality. In this paper, we present a new formalization and model the data shifts by taking into account both the invariant and environmental (spurious) features. Under such formalization, we systematically investigate how spurious correlation in the training set impacts OOD detection. Our results suggest that the detection performance is severely worsened when the correlation between spurious features and labels is increased in the training set. We further show insights on detection methods that are more effective in reducing the impact of spurious correlation, and provide theoretical analysis on why reliance on environmental features leads to high OOD detection error. Our work aims to facilitate better understanding of OOD samples and their formalization, as well as the exploration of methods that enhance OOD detection. Code is available at https://github.com/deeplearning-wisc/Spurious_OOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/aaedc4d1d19a1e82cd4880c1b414593e766a1f31.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 81,
        "score": 20.25,
        "summary": "Here is a focused summary of the technical paper for a literature review:\n\n### Analysis of \"ON THE IMPACT OF SPURIOUS CORRELATION FOR OUT-OF-DISTRIBUTION DETECTION\" \\cite{ming2021wu7}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Modern neural networks exhibit high confidence in predictions for out-of-distribution (OOD) inputs, posing reliability risks. A critical, often overlooked, aspect is the vague definition of OOD, particularly concerning the influence of spurious correlations in training data.\n    *   **Importance and Challenge**: The problem is important because OOD detection is crucial for safe and robust AI deployment. It is challenging because models can learn to rely on statistically informative but non-causal (spurious) features (e.g., background, gender) instead of invariant, semantic features. This reliance can lead to high-confidence predictions on OOD inputs that share these spurious features, making them difficult to detect.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: While much research focuses on designing new OOD detection methods, \\cite{ming2021wu7} highlights that these often operate under an oversimplified notion of OOD, typically viewing data with non-overlapping semantics as OOD.\n    *   **Limitations of Previous Solutions**: Prior work largely overlooks the impact of spurious correlations on OOD detection performance. Existing evaluation protocols for OOD detection often do not account for scenarios where OOD inputs share spurious features with in-distribution (ID) data, leading to an incomplete understanding of model robustness.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper introduces a new formalization of OOD data by explicitly modeling data shifts based on the separation of *invariant features* ($z_{inv}$, essential cues for labels) and *environmental (spurious) features* ($z_e$, non-essential but correlated cues).\n    *   **Novelty**: This formalization defines two distinct types of OOD:\n        *   **Spurious OOD**: Test samples containing environmental features but lacking invariant features essential for ID labels (e.g., a boat image with a \"water\" background, where \"water\" is a spurious feature for \"waterbird\").\n        *   **Non-spurious (Conventional) OOD**: Inputs lacking both environmental and invariant features (e.g., an image of an indoor cat for a waterbird/landbird classifier).\n        *   The paper then systematically investigates how increasing spurious correlation in the training set impacts the detection of both types of OOD.\n\n4.  **Key Technical Contributions**\n    *   **Novel Formalization**: A new formalization of OOD detection that explicitly accounts for invariant and environmental features, encapsulating both spurious and non-spurious OOD. This provides a complementary perspective for OOD evaluation.\n    *   **Systematic Investigation**: Comprehensive empirical studies demonstrating how the extent of spurious correlation in the training set significantly degrades OOD detection performance for both spurious and non-spurious OOD.\n    *   **Methodological Insights**: Identification of OOD detection solutions (specifically feature-based methods) that are more effective in mitigating the impact of spurious correlation, showing up to a 46.73% reduction in FPR95 for non-spurious OOD.\n    *   **Theoretical Analysis**: Provable demonstration that detecting spurious OOD samples remains challenging due to the model's reliance on environmental features, showing the existence of spurious OOD inputs with arbitrarily high confidence.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Models (ResNet-18) were trained using Empirical Risk Minimization (ERM) on datasets with controlled spurious correlations.\n        *   Evaluations were performed on three tasks: Waterbirds (background-label correlation), CelebA (gender-hair color correlation), and ColorMNIST (color-digit correlation, detailed in supplementary).\n        *   The degree of spurious correlation (`r`) in the training data was varied (e.g., `r` = 0.5, 0.7, 0.9 for Waterbirds).\n        *   Both spurious OOD (e.g., Places dataset images with water/land backgrounds for Waterbirds, bald male images for CelebA) and non-spurious OOD (iSUN, LSUN, SVHN) test sets were used.\n        *   A suite of common OOD scoring functions was evaluated: Maximum Softmax Probability (MSP), ODIN, Mahalanobis distance, Energy score, and Gram matrix-based score.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Metrics**: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC).\n        *   **Impact of Spurious Correlation**: Increased spurious correlation in training data severely worsened detection performance for both OOD types. For Waterbirds, FPR95 for spurious OOD increased from 59.89% (r=0.5) to 74.39% (r=0.9).\n        *   **Spurious vs. Non-spurious OOD**: Spurious OOD was consistently much harder to detect than non-spurious OOD (e.g., for Waterbirds with r=0.7, average FPR95 was 74.22% for spurious OOD vs. 37.35% for non-spurious OOD).\n        *   **Effectiveness of Detection Methods**: Feature-based methods (Mahalanobis distance, Gram Matrix score) generally outperformed output-based methods (MSP, ODIN, Energy score). Mahalanobis score, for instance, reduced FPR95 by 46.73% for non-spurious OOD on Waterbirds compared to MSP.\n        *   **Visualization**: Feature embeddings (t-SNE) showed that spurious OOD samples often overlap with ID clusters, while non-spurious OOD samples are clearly separated, explaining the difficulty.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations**: While feature-based methods improve non-spurious OOD detection, detecting spurious OOD remains a significant challenge, even with these advanced techniques. The theoretical analysis confirms the inherent difficulty of distinguishing spurious OOD from ID data when models rely on environmental features.\n    *   **Scope of Applicability**: The study focuses on image classification tasks and specific types of spurious correlations (background, gender, color). The formalization and findings are broadly applicable to scenarios where models might exploit non-causal correlations.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{ming2021wu7} significantly advances the understanding of OOD detection by formalizing the problem to include the impact of spurious correlations. It moves beyond simplistic OOD definitions, providing a more nuanced and realistic framework for evaluation.\n    *   **Potential Impact on Future Research**: The work provides strong implications for future research, emphasizing the need for OOD detection algorithms to be evaluated not just on standard benchmarks (which are often non-spurious) but also on challenging spurious OOD examples. This encourages the development of more robust OOD detection methods that are less susceptible to spurious correlations and inspires further research into OOD formalization and algorithmic solutions.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "spurious correlation",
          "invariant features",
          "environmental features",
          "spurious OOD",
          "OOD formalization",
          "impact of spurious correlation",
          "feature-based OOD detection",
          "model robustness",
          "high-confidence OOD predictions",
          "FPR95",
          "Mahalanobis distance",
          "image classification",
          "theoretical analysis",
          "data shifts"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **\"we present a new formalization and model the data shifts...\"** - this directly aligns with \"formal models\" under the **theoretical** category.\n2.  **\"under such formalization, we systematically investigate how spurious correlation... impacts ood detection.\"** - while \"investigate\" and \"impacts\" might suggest empirical, the investigation is explicitly conducted \"under such formalization,\" indicating it's driven by the theoretical framework.\n3.  **\"our results suggest that the detection performance is severely worsened...\"** - this indicates empirical findings, but they are presented as supporting the understanding derived from the formalization.\n4.  **\"and provide theoretical analysis on why reliance on environmental features leads to high ood detection error.\"** - this is a very strong indicator for **theoretical**, explicitly mentioning \"theoretical analysis\" and explaining underlying mechanisms (\"why\").\n5.  **\"our work aims to facilitate better understandings of ood samples and their formalization...\"** - this reinforces the focus on fundamental understanding and formalization.\n\nwhile the paper includes elements that could be considered empirical (investigation, results) and technical (new formalization, insights on methods), the explicit mention of a \"new formalization\" and \"theoretical analysis\" as core contributions, and the aim to provide a deeper understanding of *why* certain phenomena occur, strongly points to a **theoretical** classification. the empirical results appear to validate or illustrate the theoretical framework and analysis.\n\n**classification: theoretical**"
      },
      "file_name": "aaedc4d1d19a1e82cd4880c1b414593e766a1f31.pdf"
    },
    {
      "success": true,
      "doc_id": "4ba3cddd954932269bea2b89cd560087",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, which is crucial for the reliability and safety of deep neural networks in real-world applications \\cite{zhu2022oir}.\n    *   **Importance & Challenge**: Deep models often provide unreliable uncertainty estimations when encountering data not seen during training. Existing OOD detection methods primarily focus on designing OOD scores or introducing outlier examples for retraining, often overlooking \"obstacle factors\" within the model's internal mechanisms. Specifically, extreme features (those in low-probability regions of deep feature space) can lead to ambiguity and imprecise uncertainty estimation, as the classifier models them less effectively than typical features \\cite{zhu2022oir}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work is positioned within post-hoc OOD detection methods, which utilize pre-trained classifiers without retraining. Unlike most prior post-hoc methods (e.g., MSP \\cite{zhu2022oir}, ODIN \\cite{zhu2022oir}, Energy \\cite{zhu2022oir}, ReAct \\cite{zhu2022oir}, GradNorm \\cite{zhu2022oir}) that focus on designing new OOD scores, \\cite{zhu2022oir} provides a novel perspective by rectifying features into their \"typical set\" before calculating OOD scores.\n    *   **Limitations of Previous Solutions**: Previous score-based methods overlook the negative impact of extreme features on uncertainty estimation, which can lead to an underestimation of the reject region in hypothesis testing for OOD detection \\cite{zhu2022oir}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes to rectify deep features into their \"typical set\" and then calculate OOD scores using these typical features. This approach aims to make the model conservatively utilize typical features, mitigating the damage from extreme features \\cite{zhu2022oir}.\n    *   **Novelty**: The core innovation is the \"Batch Normalization Assisted Typical Set Estimation (BATS)\" method. It leverages the parameters (mean `Î¼`, standard deviation `Ïƒ`, learnable `Î³`, `Î²`) stored in pre-trained Batch Normalization (BN) layers to infer the typical set of features without explicit distribution estimation. A \"Truncated BN (TrBN)\" unit is introduced, which clamps feature activations outside a `[Î² - Î»Î³, Î² + Î»Î³]` interval, effectively rectifying extreme features to the boundaries of the typical set. This is a plug-and-play module that can enhance various existing OOD scores \\cite{zhu2022oir}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduces a novel perspective on OOD detection based on feature typicality and rectification.\n        *   Proposes Batch Normalization Assisted Typical Set Estimation (BATS) and the Truncated BN (TrBN) unit as a concise and effective way to select the feature's typical set \\cite{zhu2022oir}.\n    *   **Theoretical Insights**: Provides a theoretical analysis of the bias-variance trade-off introduced by BATS, demonstrating that a proper truncation threshold `Î»` can significantly reduce variance (improving reject region estimation) while introducing only a small, manageable bias \\cite{zhu2022oir}.\n    *   **System Design/Architectural Innovations**: BATS acts as a plug-and-play module, replacing standard BN units with TrBN units, making it easily integrable with existing pre-trained models and various OOD scoring functions \\cite{zhu2022oir}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive evaluations were performed on both commonly used CIFAR benchmarks (CIFAR-10/100 as ID, with SVHN, Tiny ImageNet, LSUN, Textures as OOD) and the more challenging large-scale ImageNet benchmark (ImageNet-1k as ID, with iNaturalist, Places, SUN, Textures as OOD) \\cite{zhu2022oir}. Ablation studies were conducted on the influence of applying rectification on different layers and the hyperparameter `Î»` \\cite{zhu2022oir}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **Metrics**: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC) \\cite{zhu2022oir}.\n        *   **Results**: BATS achieved state-of-the-art performance among post-hoc methods. Notably, it outperformed previous best methods by up to a 5.11% reduction in FPR95 and a 1.43% improvement in AUROC on the ImageNet benchmark. It also demonstrated the ability to boost the performance of various existing OOD scores and slightly improve the test accuracy and robustness of pre-trained models \\cite{zhu2022oir}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method introduces a bias term due to feature rectification, which needs to be carefully balanced with variance reduction via the hyperparameter `Î»`. An improper `Î»` can degrade performance \\cite{zhu2022oir}. The approach relies on the presence of Batch Normalization layers in the pre-trained model.\n    *   **Scope of Applicability**: BATS is a post-hoc method, meaning it does not require retraining the model. It is applicable to deep neural networks utilizing Batch Normalization layers and can be combined with various existing OOD scoring functions \\cite{zhu2022oir}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{zhu2022oir} significantly advances the state-of-the-art in post-hoc OOD detection, particularly on large-scale, high-resolution benchmarks like ImageNet, by addressing the often-overlooked issue of extreme features \\cite{zhu2022oir}.\n    *   **Potential Impact on Future Research**: The paper provides a novel perspective on OOD detection through feature typicality and rectification, opening new avenues for research into internal model mechanisms for uncertainty estimation. The plug-and-play nature of BATS makes it a valuable tool for improving existing OOD detection methods and could inspire further work on feature-level interventions for robust AI systems \\cite{zhu2022oir}.",
      "intriguing_abstract": "Deep neural networks often falter when encountering Out-of-Distribution (OOD) data, yielding dangerously unreliable uncertainty estimations crucial for real-world safety. A core challenge lies in \"extreme features\"â€”activations residing in low-probability regions of the feature spaceâ€”which introduce ambiguity and degrade OOD detection performance. We present a novel post-hoc approach that fundamentally rectifies this issue by ensuring models conservatively utilize only *typical* features.\n\nOur innovation, **Batch Normalization Assisted Typical Set Estimation (BATS)**, introduces a **Truncated BN (TrBN)** unit. This elegant, plug-and-play module leverages pre-trained Batch Normalization parameters to infer and clamp extreme features, effectively mapping them to the boundaries of their typical set without explicit distribution estimation or retraining. Theoretically, BATS significantly reduces variance in uncertainty estimation, improving the reject region.\n\nExtensive experiments on challenging benchmarks, including ImageNet, demonstrate BATS achieving state-of-the-art performance among post-hoc methods, with up to a 5.11% reduction in FPR95 and 1.43% AUROC improvement. It robustly boosts various existing OOD scores and even enhances model accuracy. This work offers a powerful, generalizable solution for building more reliable and trustworthy deep learning systems, opening new avenues for feature-level interventions in uncertainty quantification.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "deep neural networks reliability",
        "uncertainty estimation",
        "extreme features",
        "feature typicality",
        "feature rectification",
        "Batch Normalization Assisted Typical Set Estimation (BATS)",
        "Truncated BN (TrBN) unit",
        "post-hoc OOD detection",
        "plug-and-play module",
        "bias-variance trade-off",
        "state-of-the-art performance",
        "ImageNet benchmark"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/df8176027e3b9857e6bc6f45b3fc183351571fbd.pdf",
      "citation_key": "zhu2022oir",
      "metadata": {
        "title": "Boosting Out-of-distribution Detection with Typical Features",
        "authors": [
          "Yao Zhu",
          "YueFeng Chen",
          "Chuanlong Xie",
          "Xiaodan Li",
          "Rong Zhang",
          "Hui Xue",
          "Xiang Tian",
          "Bolun Zheng",
          "Yao-wu Chen"
        ],
        "published_date": "2022",
        "abstract": "Out-of-distribution (OOD) detection is a critical task for ensuring the reliability and safety of deep neural networks in real-world scenarios. Different from most previous OOD detection methods that focus on designing OOD scores or introducing diverse outlier examples to retrain the model, we delve into the obstacle factors in OOD detection from the perspective of typicality and regard the feature's high-probability region of the deep model as the feature's typical set. We propose to rectify the feature into its typical set and calculate the OOD score with the typical features to achieve reliable uncertainty estimation. The feature rectification can be conducted as a {plug-and-play} module with various OOD scores. We evaluate the superiority of our method on both the commonly used benchmark (CIFAR) and the more challenging high-resolution benchmark with large label space (ImageNet). Notably, our approach outperforms state-of-the-art methods by up to 5.11$\\%$ in the average FPR95 on the ImageNet benchmark.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/df8176027e3b9857e6bc6f45b3fc183351571fbd.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 59,
        "score": 19.666666666666664,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, which is crucial for the reliability and safety of deep neural networks in real-world applications \\cite{zhu2022oir}.\n    *   **Importance & Challenge**: Deep models often provide unreliable uncertainty estimations when encountering data not seen during training. Existing OOD detection methods primarily focus on designing OOD scores or introducing outlier examples for retraining, often overlooking \"obstacle factors\" within the model's internal mechanisms. Specifically, extreme features (those in low-probability regions of deep feature space) can lead to ambiguity and imprecise uncertainty estimation, as the classifier models them less effectively than typical features \\cite{zhu2022oir}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work is positioned within post-hoc OOD detection methods, which utilize pre-trained classifiers without retraining. Unlike most prior post-hoc methods (e.g., MSP \\cite{zhu2022oir}, ODIN \\cite{zhu2022oir}, Energy \\cite{zhu2022oir}, ReAct \\cite{zhu2022oir}, GradNorm \\cite{zhu2022oir}) that focus on designing new OOD scores, \\cite{zhu2022oir} provides a novel perspective by rectifying features into their \"typical set\" before calculating OOD scores.\n    *   **Limitations of Previous Solutions**: Previous score-based methods overlook the negative impact of extreme features on uncertainty estimation, which can lead to an underestimation of the reject region in hypothesis testing for OOD detection \\cite{zhu2022oir}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes to rectify deep features into their \"typical set\" and then calculate OOD scores using these typical features. This approach aims to make the model conservatively utilize typical features, mitigating the damage from extreme features \\cite{zhu2022oir}.\n    *   **Novelty**: The core innovation is the \"Batch Normalization Assisted Typical Set Estimation (BATS)\" method. It leverages the parameters (mean `Î¼`, standard deviation `Ïƒ`, learnable `Î³`, `Î²`) stored in pre-trained Batch Normalization (BN) layers to infer the typical set of features without explicit distribution estimation. A \"Truncated BN (TrBN)\" unit is introduced, which clamps feature activations outside a `[Î² - Î»Î³, Î² + Î»Î³]` interval, effectively rectifying extreme features to the boundaries of the typical set. This is a plug-and-play module that can enhance various existing OOD scores \\cite{zhu2022oir}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduces a novel perspective on OOD detection based on feature typicality and rectification.\n        *   Proposes Batch Normalization Assisted Typical Set Estimation (BATS) and the Truncated BN (TrBN) unit as a concise and effective way to select the feature's typical set \\cite{zhu2022oir}.\n    *   **Theoretical Insights**: Provides a theoretical analysis of the bias-variance trade-off introduced by BATS, demonstrating that a proper truncation threshold `Î»` can significantly reduce variance (improving reject region estimation) while introducing only a small, manageable bias \\cite{zhu2022oir}.\n    *   **System Design/Architectural Innovations**: BATS acts as a plug-and-play module, replacing standard BN units with TrBN units, making it easily integrable with existing pre-trained models and various OOD scoring functions \\cite{zhu2022oir}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive evaluations were performed on both commonly used CIFAR benchmarks (CIFAR-10/100 as ID, with SVHN, Tiny ImageNet, LSUN, Textures as OOD) and the more challenging large-scale ImageNet benchmark (ImageNet-1k as ID, with iNaturalist, Places, SUN, Textures as OOD) \\cite{zhu2022oir}. Ablation studies were conducted on the influence of applying rectification on different layers and the hyperparameter `Î»` \\cite{zhu2022oir}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **Metrics**: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC) \\cite{zhu2022oir}.\n        *   **Results**: BATS achieved state-of-the-art performance among post-hoc methods. Notably, it outperformed previous best methods by up to a 5.11% reduction in FPR95 and a 1.43% improvement in AUROC on the ImageNet benchmark. It also demonstrated the ability to boost the performance of various existing OOD scores and slightly improve the test accuracy and robustness of pre-trained models \\cite{zhu2022oir}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method introduces a bias term due to feature rectification, which needs to be carefully balanced with variance reduction via the hyperparameter `Î»`. An improper `Î»` can degrade performance \\cite{zhu2022oir}. The approach relies on the presence of Batch Normalization layers in the pre-trained model.\n    *   **Scope of Applicability**: BATS is a post-hoc method, meaning it does not require retraining the model. It is applicable to deep neural networks utilizing Batch Normalization layers and can be combined with various existing OOD scoring functions \\cite{zhu2022oir}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{zhu2022oir} significantly advances the state-of-the-art in post-hoc OOD detection, particularly on large-scale, high-resolution benchmarks like ImageNet, by addressing the often-overlooked issue of extreme features \\cite{zhu2022oir}.\n    *   **Potential Impact on Future Research**: The paper provides a novel perspective on OOD detection through feature typicality and rectification, opening new avenues for research into internal model mechanisms for uncertainty estimation. The plug-and-play nature of BATS makes it a valuable tool for improving existing OOD detection methods and could inspire further work on feature-level interventions for robust AI systems \\cite{zhu2022oir}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "deep neural networks reliability",
          "uncertainty estimation",
          "extreme features",
          "feature typicality",
          "feature rectification",
          "Batch Normalization Assisted Typical Set Estimation (BATS)",
          "Truncated BN (TrBN) unit",
          "post-hoc OOD detection",
          "plug-and-play module",
          "bias-variance trade-off",
          "state-of-the-art performance",
          "ImageNet benchmark"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** to rectify the feature into its typical set and calculate the ood score with the typical features...\" and \"we evaluate the superiority of **our method**...\".\n*   the introduction discusses a technical problem in ood detection (\"most of the existing research... overlooked the obstacle factors...\") and then introduces a new perspective and approach (\"in this paper, we rethink the ood detection from a perspective of feature typicality.\").\n*   the paper describes a \"plug-and-play module\" and presents a novel way to address ood detection.\n*   while it includes empirical evaluation (\"we evaluate the superiority of our method...\", \"outperforms state-of-the-art methods...\"), this evaluation serves to demonstrate the effectiveness of the *new method* being proposed. the core contribution is the development of this new method.\n\nthis aligns perfectly with the criteria for a **technical** paper.\n\n**classification:** technical"
      },
      "file_name": "df8176027e3b9857e6bc6f45b3fc183351571fbd.pdf"
    },
    {
      "success": true,
      "doc_id": "dba2faeeec030fc4c49eb329d00309f8",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/2b088b9b1abc84bb207396b440527219277e2718.pdf",
      "citation_key": "jeong2020z5c",
      "metadata": {
        "title": "OOD-MAML: Meta-Learning for Few-Shot Out-of-Distribution Detection and Classification",
        "authors": [
          "Taewon Jeong",
          "Heeyoung Kim"
        ],
        "published_date": "2020",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/2b088b9b1abc84bb207396b440527219277e2718.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 95,
        "score": 19.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "2b088b9b1abc84bb207396b440527219277e2718.pdf"
    },
    {
      "success": true,
      "doc_id": "34c9f1f37b7c7ce22131b441887b9120",
      "summary": "Here's a focused summary of the paper for a literature review, adhering to your citation requirements:\n\n*   **CITATION**: \\cite{chen2020mbk}\n\n---\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing out-of-distribution (OOD) detection mechanisms, critical for safe deep learning deployment, are extremely brittle and fail when faced with minimal adversarial perturbations on both in-distribution (ID) and OOD inputs.\n    *   **Importance & Challenge**: OOD detectors need to be robust to adversarial attacks to prevent severe consequences in real-world applications (e.g., an autonomous vehicle misclassifying a perturbed stop sign as OOD and ignoring it, or misclassifying a perturbed OOD object as an ID stop sign). Previous work primarily focused on adversarial OOD examples, neglecting adversarial ID examples that cause false rejections. The challenge lies in developing a unified approach to robustify OOD detectors against both types of semantic-preserving adversarial perturbations.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon established OOD detection methods like MSP, ODIN, Mahalanobis, and Outlier Exposure (OE). It also draws inspiration from adversarial robustness techniques, particularly adversarial training \\cite{madry2017towards}.\n    *   **Limitations of Previous Solutions**:\n        *   Most OOD detection methods are evaluated only on benign ID and OOD samples, making them vulnerable to adversarial attacks.\n        *   Prior work on robust OOD detection primarily focused on adversarial OOD examples (e.g., \\cite{sehwag2019adversarial, hein2019relu, meinke2019robustness}), which aim to make OOD inputs appear in-distribution.\n        *   Scant attention has been paid to adversarial *in-distribution* examples, which are perturbed ID inputs designed to be falsely rejected as OOD.\n        *   The paper demonstrates that state-of-the-art OOD detectors (MSP, ODIN, Mahalanobis, OE) fail drastically under small adversarial perturbations.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **ALOE (Adversarial Learning with inlier and Outlier Exposure)**, an algorithm that performs robust training by exposing the model to both adversarially crafted inlier and outlier examples. The overall training objective is formulated as a min-max game.\n    *   **Novelty/Difference**:\n        *   **Unified Robustness**: ALOE is the first method to explicitly consider and train against *both* adversarial in-distribution examples (perturbed ID inputs that should be accepted) and adversarial OOD examples (perturbed OOD inputs that should be rejected).\n        *   **Adversarial Outlier Exposure**: Unlike standard Outlier Exposure (OE) which uses clean auxiliary OOD data, ALOE generates *adversarial outliers* by searching within an $\\epsilon$-ball to maximize the KL-divergence between the model output and a uniform distribution.\n        *   **Adversarial Inlier Training**: For in-distribution data, ALOE creates adversarial inliers by maximizing the negative log-likelihood within an $\\epsilon$-ball, similar to standard adversarial training for classification.\n        *   **Flexible Integration**: The trained ALOE model can be flexibly combined with existing OOD detection approaches (e.g., MSP, ODIN) to further boost their robustness.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Formalization of the \"Robust Out-of-Distribution Detection\" problem, including the definition of adversarial in-distribution and OOD examples targeting the OOD detector G(x).\n        *   Development of white-box adversarial attack algorithms (Algorithm 1 for softmax-based, Algorithm 2 for Mahalanobis-based) to demonstrate the brittleness of existing OOD detectors.\n        *   Introduction of ALOE, a novel adversarial training objective (Equation 4) that incorporates both adversarial inlier and adversarial outlier exposure.\n    *   **Theoretical Insights/Analysis**: Empirically analyzes why common adversarial examples targeting the *classifier* f(x) with small perturbations should still be regarded as in-distribution rather than OOD.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Extensive evaluation of classic OOD detection methods (MSP, ODIN, Mahalanobis, OE, OE+ODIN) under the proposed adversarial attacks.\n        *   Comparison of ALOE against these baselines and its variants (ADV: adversarial training on inliers only; AOE: adversarial training on inliers + clean outlier exposure).\n        *   Ablation studies on the components of ALOE.\n        *   Evaluation of ALOE's compatibility with existing OOD methods (e.g., ALOE+ODIN).\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **Significant Robustness Improvement**: ALOE substantially improves the robustness of OOD detection under adversarial attacks.\n            *   58.4% AUROC improvement on CIFAR-10.\n            *   46.59% AUROC improvement on CIFAR-100.\n        *   **Baseline Vulnerability**: Classic OOD methods (ODIN, Mahalanobis, OE) fail drastically, with the false positive rate of OE increasing by 95.52% on CIFAR-10 under minimal attack strength ($\\epsilon=1/255$).\n        *   **Superiority of ALOE**: ALOE consistently outperforms its variants (ADV and AOE) in robust OOD detection.\n        *   **Maintained Clean Accuracy**: ALOE improves model robustness while maintaining almost the same classification accuracy on clean test inputs.\n        *   **Datasets**: In-distribution datasets included GTSRB, CIFAR-10, CIFAR-100. Auxiliary outlier data from 80 Million Tiny Images. OOD test datasets included SVHN, Textures, Places365, LSUN, iSUN.\n        *   **Architecture**: DenseNet (L=100, k=12) was used.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The adversarial attacks used for evaluation are white-box, assuming full knowledge of the model parameters.\n        *   Perturbations are constrained by L1-norm, a common but specific type of adversarial perturbation.\n        *   Relies on the availability of an auxiliary unlabeled dataset for outlier exposure.\n    *   **Scope of Applicability**: Primarily demonstrated on image classification tasks and common OOD detection benchmarks.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the state-of-the-art in robust OOD detection by being the first to comprehensively address robustness against *both* adversarial in-distribution and OOD examples.\n    *   **Potential Impact on Future Research**:\n        *   Highlights a critical vulnerability in existing OOD detectors, prompting further research into robust OOD detection.\n        *   Provides a novel and effective adversarial training framework (ALOE) that can serve as a strong baseline or component for future robust OOD methods.\n        *   The release of a comprehensive codebase facilitates reproducibility and encourages further community research in this area.\n        *   Opens avenues for exploring different types of adversarial attacks and defenses in the context of OOD detection.",
      "intriguing_abstract": "Deep learning models in safety-critical applications demand robust out-of-distribution (OOD) detection, yet current mechanisms are alarmingly brittle. We expose a critical vulnerability: state-of-the-art OOD detectors drastically fail under minimal adversarial perturbations, whether designed to cause false rejections of in-distribution inputs or false acceptances of OOD inputs. This paper introduces **ALOE (Adversarial Learning with inlier and Outlier Exposure)**, the first unified framework to robustify OOD detection against *both* types of semantic-preserving adversarial attacks. ALOE employs a novel min-max adversarial training objective, generating adversarial inliers and, uniquely, *adversarial outliers* from auxiliary data. Our extensive experiments demonstrate ALOE's profound impact, achieving up to a 58.4% AUROC improvement on CIFAR-10 over vulnerable baselines, which saw false positive rates increase by over 95%. ALOE significantly advances adversarial robustness for OOD detection, paving the way for safer and more reliable deep learning systems.",
      "keywords": [
        "Robust Out-of-Distribution Detection",
        "Adversarial Perturbations",
        "Adversarial In-distribution Examples",
        "Adversarial OOD Examples",
        "ALOE (Adversarial Learning with inlier and Outlier Exposure)",
        "Unified Robustness",
        "Adversarial Outlier Exposure",
        "Adversarial Training",
        "Deep Learning Safety",
        "Min-max Game",
        "White-box Adversarial Attacks",
        "Significant AUROC Improvement",
        "Baseline Vulnerability"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/558f6cfc2daa06fa6562084a566392b907fc1642.pdf",
      "citation_key": "chen2020mbk",
      "metadata": {
        "title": "Robust Out-of-distribution Detection for Neural Networks",
        "authors": [
          "Jiefeng Chen",
          "Yixuan Li",
          "Xi Wu",
          "Yingyu Liang",
          "S. Jha"
        ],
        "published_date": "2020",
        "abstract": "Detecting anomalous inputs is critical for safely deploying deep learning models in the real world. Existing approaches for detecting out-of-distribution (OOD) examples work well when evaluated on natural samples drawn from a sufficiently different distribution than the training data distribution. However, in this paper, we show that existing detection mechanisms can be extremely brittle when evaluating on inputs with minimal adversarial perturbations which don't change their semantics. Formally, we introduce a novel and challenging problem, Robust Out-of-Distribution Detection, and propose an algorithm that can fool existing OOD detectors by adding small perturbations to the inputs while preserving their semantics and thus the distributional membership. We take a first step to solve this challenge, and propose an effective algorithm called ALOE, which performs robust training by exposing the model to both adversarially crafted inlier and outlier examples. Our method can be flexibly combined with, and render existing methods robust. On common benchmark datasets, we show that ALOE substantially improves the robustness of state-of-the-art OOD detection, with 58.4% AUROC improvement on CIFAR-10 and 46.59% improvement on CIFAR-100. Finally, we provide theoretical analysis for our method, underpinning the empirical results above.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/558f6cfc2daa06fa6562084a566392b907fc1642.pdf",
        "venue": "",
        "citationCount": 91,
        "score": 18.2,
        "summary": "Here's a focused summary of the paper for a literature review, adhering to your citation requirements:\n\n*   **CITATION**: \\cite{chen2020mbk}\n\n---\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing out-of-distribution (OOD) detection mechanisms, critical for safe deep learning deployment, are extremely brittle and fail when faced with minimal adversarial perturbations on both in-distribution (ID) and OOD inputs.\n    *   **Importance & Challenge**: OOD detectors need to be robust to adversarial attacks to prevent severe consequences in real-world applications (e.g., an autonomous vehicle misclassifying a perturbed stop sign as OOD and ignoring it, or misclassifying a perturbed OOD object as an ID stop sign). Previous work primarily focused on adversarial OOD examples, neglecting adversarial ID examples that cause false rejections. The challenge lies in developing a unified approach to robustify OOD detectors against both types of semantic-preserving adversarial perturbations.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon established OOD detection methods like MSP, ODIN, Mahalanobis, and Outlier Exposure (OE). It also draws inspiration from adversarial robustness techniques, particularly adversarial training \\cite{madry2017towards}.\n    *   **Limitations of Previous Solutions**:\n        *   Most OOD detection methods are evaluated only on benign ID and OOD samples, making them vulnerable to adversarial attacks.\n        *   Prior work on robust OOD detection primarily focused on adversarial OOD examples (e.g., \\cite{sehwag2019adversarial, hein2019relu, meinke2019robustness}), which aim to make OOD inputs appear in-distribution.\n        *   Scant attention has been paid to adversarial *in-distribution* examples, which are perturbed ID inputs designed to be falsely rejected as OOD.\n        *   The paper demonstrates that state-of-the-art OOD detectors (MSP, ODIN, Mahalanobis, OE) fail drastically under small adversarial perturbations.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **ALOE (Adversarial Learning with inlier and Outlier Exposure)**, an algorithm that performs robust training by exposing the model to both adversarially crafted inlier and outlier examples. The overall training objective is formulated as a min-max game.\n    *   **Novelty/Difference**:\n        *   **Unified Robustness**: ALOE is the first method to explicitly consider and train against *both* adversarial in-distribution examples (perturbed ID inputs that should be accepted) and adversarial OOD examples (perturbed OOD inputs that should be rejected).\n        *   **Adversarial Outlier Exposure**: Unlike standard Outlier Exposure (OE) which uses clean auxiliary OOD data, ALOE generates *adversarial outliers* by searching within an $\\epsilon$-ball to maximize the KL-divergence between the model output and a uniform distribution.\n        *   **Adversarial Inlier Training**: For in-distribution data, ALOE creates adversarial inliers by maximizing the negative log-likelihood within an $\\epsilon$-ball, similar to standard adversarial training for classification.\n        *   **Flexible Integration**: The trained ALOE model can be flexibly combined with existing OOD detection approaches (e.g., MSP, ODIN) to further boost their robustness.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Formalization of the \"Robust Out-of-Distribution Detection\" problem, including the definition of adversarial in-distribution and OOD examples targeting the OOD detector G(x).\n        *   Development of white-box adversarial attack algorithms (Algorithm 1 for softmax-based, Algorithm 2 for Mahalanobis-based) to demonstrate the brittleness of existing OOD detectors.\n        *   Introduction of ALOE, a novel adversarial training objective (Equation 4) that incorporates both adversarial inlier and adversarial outlier exposure.\n    *   **Theoretical Insights/Analysis**: Empirically analyzes why common adversarial examples targeting the *classifier* f(x) with small perturbations should still be regarded as in-distribution rather than OOD.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Extensive evaluation of classic OOD detection methods (MSP, ODIN, Mahalanobis, OE, OE+ODIN) under the proposed adversarial attacks.\n        *   Comparison of ALOE against these baselines and its variants (ADV: adversarial training on inliers only; AOE: adversarial training on inliers + clean outlier exposure).\n        *   Ablation studies on the components of ALOE.\n        *   Evaluation of ALOE's compatibility with existing OOD methods (e.g., ALOE+ODIN).\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **Significant Robustness Improvement**: ALOE substantially improves the robustness of OOD detection under adversarial attacks.\n            *   58.4% AUROC improvement on CIFAR-10.\n            *   46.59% AUROC improvement on CIFAR-100.\n        *   **Baseline Vulnerability**: Classic OOD methods (ODIN, Mahalanobis, OE) fail drastically, with the false positive rate of OE increasing by 95.52% on CIFAR-10 under minimal attack strength ($\\epsilon=1/255$).\n        *   **Superiority of ALOE**: ALOE consistently outperforms its variants (ADV and AOE) in robust OOD detection.\n        *   **Maintained Clean Accuracy**: ALOE improves model robustness while maintaining almost the same classification accuracy on clean test inputs.\n        *   **Datasets**: In-distribution datasets included GTSRB, CIFAR-10, CIFAR-100. Auxiliary outlier data from 80 Million Tiny Images. OOD test datasets included SVHN, Textures, Places365, LSUN, iSUN.\n        *   **Architecture**: DenseNet (L=100, k=12) was used.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The adversarial attacks used for evaluation are white-box, assuming full knowledge of the model parameters.\n        *   Perturbations are constrained by L1-norm, a common but specific type of adversarial perturbation.\n        *   Relies on the availability of an auxiliary unlabeled dataset for outlier exposure.\n    *   **Scope of Applicability**: Primarily demonstrated on image classification tasks and common OOD detection benchmarks.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the state-of-the-art in robust OOD detection by being the first to comprehensively address robustness against *both* adversarial in-distribution and OOD examples.\n    *   **Potential Impact on Future Research**:\n        *   Highlights a critical vulnerability in existing OOD detectors, prompting further research into robust OOD detection.\n        *   Provides a novel and effective adversarial training framework (ALOE) that can serve as a strong baseline or component for future robust OOD methods.\n        *   The release of a comprehensive codebase facilitates reproducibility and encourages further community research in this area.\n        *   Opens avenues for exploring different types of adversarial attacks and defenses in the context of OOD detection.",
        "keywords": [
          "Robust Out-of-Distribution Detection",
          "Adversarial Perturbations",
          "Adversarial In-distribution Examples",
          "Adversarial OOD Examples",
          "ALOE (Adversarial Learning with inlier and Outlier Exposure)",
          "Unified Robustness",
          "Adversarial Outlier Exposure",
          "Adversarial Training",
          "Deep Learning Safety",
          "Min-max Game",
          "White-box Adversarial Attacks",
          "Significant AUROC Improvement",
          "Baseline Vulnerability"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **problem identification:** the paper identifies a significant problem: existing out-of-distribution (ood) detection mechanisms are brittle against adversarial perturbations.\n2.  **proposed solution:** the abstract explicitly states, \"to counteract these threats, we propose an effective algorithm called aloe...\" this is a clear indicator of presenting a new method or system.\n3.  **evaluation:** the paper then describes the evaluation of this proposed algorithm: \"on common benchmark datasets, we show that aloe substantially improves the robustness of state-of-the-art ood detection, with 58.4% auroc improvement on cifar-10 and 46.59% improvement on cifar-100.\" these are empirical results demonstrating the effectiveness of the proposed method.\n4.  **introduction context:** the introduction further emphasizes the problem of robust ood detection and highlights how their approach differs from previous works by considering both adversarial ood and in-distribution examples, setting the stage for their novel solution.\n\nwhile the paper includes strong empirical evaluation, its primary contribution is the **proposal of a new algorithm (aloe)** to address a specific technical challenge in robust ood detection. the empirical results serve to validate this proposed technical solution. therefore, the paper's core nature aligns best with the \"technical\" classification.\n\n**classification:** technical"
      },
      "file_name": "558f6cfc2daa06fa6562084a566392b907fc1642.pdf"
    },
    {
      "success": true,
      "doc_id": "a9090c8f1daa2c8d80e80d28757dacf9",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Recent studies have shown that probabilistic model likelihoods, particularly from deep generative models, often assign *higher* likelihoods to out-of-distribution (OOD) data than to in-distribution data \\cite{morningstar2020re9}. This makes them poor OOD detectors.\n    *   **Importance & Challenge**: OOD detection is critical for the reliability and safety of machine learning systems in real-world applications (e.g., autonomous driving, medical diagnoses). The challenge stems from the \"Gaussian Annulus Theorem\" phenomenon, where in high dimensions, the typical set of data may not intersect with the region of highest density, leading to counter-intuitive likelihood assignments \\cite{morningstar2020re9}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**:\n        *   **Unsupervised**: Historically, generative models used a one-sided threshold on log-likelihood \\cite{morningstar2020re9}. Later attempts tried to correct the \"high likelihood for OOD\" pathology using methods like WAIC (Choi et al. [2018]) or likelihood ratios (Ren et al. [2019]). Nalisnick et al. [2019b] proposed a typicality test based on batch means of log-likelihoods.\n        *   **Supervised**: Many methods leverage class labels or specific OOD examples during training (e.g., ODIN, ensembles, adversarial training, latent space mixture models) \\cite{morningstar2020re9}.\n    *   **Limitations of Previous Solutions**:\n        *   Direct log-likelihood: Fails egregiously in high dimensions, assigning higher likelihoods to OOD data \\cite{morningstar2020re9}.\n        *   WAIC/Likelihood ratio: Do not fundamentally address the high-dimensional likelihood issue \\cite{morningstar2020re9}.\n        *   Batch typicality tests: Performance degrades for single-sample OOD detection, and they may not use the most informative metrics \\cite{morningstar2020re9}.\n        *   Supervised methods: Require labeled data or known OOD examples, which are often unavailable in practice. They can also lead to models over-tuned to specific OOD sets and may discard useful OOD information \\cite{morningstar2020re9}.\n    *   **Positioning**: DoSE is an *unsupervised* method that does *not* require class labels or OOD examples during training, directly addressing the core failure mode of direct likelihood comparison by focusing on typicality across multiple statistics \\cite{morningstar2020re9}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: DoSE (Density of States Estimator) avoids direct comparison of model probabilities. Instead, it leverages the \"probability of the model probability\" or, more generally, the frequency (typicality) of *any reasonable summary statistic* derived from the generative model \\cite{morningstar2020re9}.\n    *   **Inspiration**: Draws on the statistical physics notion of \"density of states,\" which describes the number of configurations in a system that take on particular values of a given statistic \\cite{morningstar2020re9}. This concept helps identify atypical points even if they have high likelihoods.\n    *   **Mechanism**:\n        1.  A deep probabilistic model (e.g., $\\beta$-VAE, Glow) is trained on in-distribution data \\cite{morningstar2020re9}.\n        2.  Multiple summary statistics (e.g., negative log-likelihood, L2 norm, max coordinate value) are computed for the in-distribution training data \\cite{morningstar2020re9}.\n        3.  Nonparametric density estimators (e.g., Kernel Density Estimation (KDE) or one-class Support Vector Machine (SVM)) are trained on these statistics to estimate their \"density of states\" or typicality \\cite{morningstar2020re9}.\n        4.  For a new test point, its summary statistics are computed, and its typicality is evaluated using the trained DoSE. Points with low typicality across these statistics are flagged as OOD \\cite{morningstar2020re9}.\n    *   **Novelty**:\n        *   First to apply the \"density of states\" concept from statistical physics to OOD detection \\cite{morningstar2020re9}.\n        *   Shifts focus from direct model likelihoods to the typicality of *multiple* derived summary statistics \\cite{morningstar2020re9}.\n        *   Modular design allows trivial application to *any* existing, trained generative model without modification or retraining \\cite{morningstar2020re9}.\n        *   Operates in a fully unsupervised setting, requiring no OOD examples or class labels \\cite{morningstar2020re9}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of DoSE, an OOD detection method that jointly leverages multiple summary statistics from generative models, inspired by statistical physics and typicality \\cite{morningstar2020re9}.\n    *   **System Design/Architectural Innovations**: DoSE is modular and can be easily applied as a post-hoc OOD detector to any pre-trained generative model (demonstrated with $\\beta$-VAEs and Glow) \\cite{morningstar2020re9}.\n    *   **Theoretical Insights**: Provides a theoretical understanding of the shortcomings of MLE-fitted distributions for single-sample OOD detection through a bias/variance tradeoff for typicality (Theorem 3.1) \\cite{morningstar2020re9}.\n    *   **Practical Procedure**: Outlines a concrete 6-step procedure for constructing, calibrating, and applying DoSE for OOD detection, including using KDE or one-class SVMs for density estimation \\cite{morningstar2020re9}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Evaluated DoSE on established OOD detection benchmarks, comparing its performance against several unsupervised baselines \\cite{morningstar2020re9}. The procedure involved training generative models, constructing DoSEs on training data statistics, validating against a held-out set, and computing scores on in-distribution test sets and multiple OOD datasets \\cite{morningstar2020re9}.\n    *   **Key Performance Metrics**: Area Under the ROC Curve (AUROC) was used to measure OOD identification success \\cite{morningstar2020re9}.\n    *   **Comparison Results**: DoSE achieved state-of-the-art performance among unsupervised OOD detection methods and demonstrated comparable performance to state-of-the-art supervised methods \\cite{morningstar2020re9}. It significantly outperformed alternative methods that rely on only a single statistic \\cite{morningstar2020re9}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The theoretical bound (Theorem 3.1) is not directly computable due to unknown true entropy H[p], necessitating heuristic approximations \\cite{morningstar2020re9}.\n        *   When combining KDEs via product, it assumes independence between statistics, though this can be relaxed by using a one-class SVM on joint statistics \\cite{morningstar2020re9}.\n        *   While robust to uninformative statistics, the selection of effective summary statistics still involves some heuristic choice \\cite{morningstar2020re9}.\n    *   **Scope of Applicability**: DoSE is designed for unsupervised OOD detection scenarios where no class labels or specific OOD examples are available during model training. It is broadly applicable to any pre-trained deep probabilistic model \\cite{morningstar2020re9}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: DoSE provides a robust and effective unsupervised OOD detection method that directly addresses and overcomes the critical failure mode of direct likelihood comparison in high-dimensional data, a long-standing challenge in the field \\cite{morningstar2020re9}.\n    *   **Potential Impact on Future Research**:\n        *   Encourages a paradigm shift in OOD detection, moving beyond simple likelihood thresholds to a more nuanced understanding of \"typicality\" and the \"density of states\" \\cite{morningstar2020re9}.\n        *   Its modularity makes it a valuable tool for enhancing the reliability of existing generative models without requiring costly retraining or access to OOD data \\cite{morningstar2020re9}.\n        *   Opens new avenues for exploring diverse summary statistics and nonparametric density estimators for improved OOD detection performance \\cite{morningstar2020re9}.",
      "intriguing_abstract": "Deep generative models, despite their impressive capabilities, paradoxically assign higher likelihoods to out-of-distribution (OOD) data than to in-distribution data, critically undermining their reliability in real-world applications. This fundamental flaw, rooted in high-dimensional geometry and the \"Gaussian Annulus Theorem,\" renders direct likelihood comparisons ineffective for OOD detection. We introduce DoSE (Density of States Estimator), a novel unsupervised method that fundamentally redefines OOD detection.\n\nInspired by statistical physics, DoSE moves beyond direct model probabilities, instead leveraging the *typicality* of *multiple summary statistics* (e.g., negative log-likelihood, L2 norm) derived from any pre-trained generative model. By constructing nonparametric density estimators (e.g., Kernel Density Estimation, one-class SVM) on these statistics, DoSE accurately identifies atypical samples without requiring OOD examples or class labels. Our modular approach achieves state-of-the-art unsupervised performance, often matching supervised methods, and offers theoretical insights into typicality. DoSE provides a robust, post-hoc solution, paving the way for safer and more reliable machine learning systems by transforming how we perceive and detect OOD data.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "deep generative models",
        "probabilistic model likelihoods",
        "Gaussian Annulus Theorem",
        "unsupervised OOD detection",
        "DoSE (Density of States Estimator)",
        "summary statistics",
        "typicality",
        "density of states (statistical physics)",
        "nonparametric density estimators",
        "modular post-hoc detector",
        "high-dimensional data",
        "ML system reliability",
        "state-of-the-art performance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/4b83c2ec2c5119057979ae64cf4b5d1aef04466b.pdf",
      "citation_key": "morningstar2020re9",
      "metadata": {
        "title": "Density of States Estimation for Out-of-Distribution Detection",
        "authors": [
          "W. Morningstar",
          "Cusuh Ham",
          "Andrew Gallagher",
          "Balaji Lakshminarayanan",
          "Alexander A. Alemi",
          "Joshua V. Dillon"
        ],
        "published_date": "2020",
        "abstract": "Perhaps surprisingly, recent studies have shown probabilistic model likelihoods have poor specificity for out-of-distribution (OOD) detection and often assign higher likelihoods to OOD data than in-distribution data. To ameliorate this issue we propose DoSE, the density of states estimator. Drawing on the statistical physics notion of ``density of states,'' the DoSE decision rule avoids direct comparison of model probabilities, and instead utilizes the ``probability of the model probability,'' or indeed the frequency of any reasonable statistic. The frequency is calculated using nonparametric density estimators (e.g., KDE and one-class SVM) which measure the typicality of various model statistics given the training data and from which we can flag test points with low typicality as anomalous. Unlike many other methods, DoSE requires neither labeled data nor OOD examples. DoSE is modular and can be trivially applied to any existing, trained model. We demonstrate DoSE's state-of-the-art performance against other unsupervised OOD detectors on previously established ``hard'' benchmarks.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/4b83c2ec2c5119057979ae64cf4b5d1aef04466b.pdf",
        "venue": "International Conference on Artificial Intelligence and Statistics",
        "citationCount": 90,
        "score": 18.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Recent studies have shown that probabilistic model likelihoods, particularly from deep generative models, often assign *higher* likelihoods to out-of-distribution (OOD) data than to in-distribution data \\cite{morningstar2020re9}. This makes them poor OOD detectors.\n    *   **Importance & Challenge**: OOD detection is critical for the reliability and safety of machine learning systems in real-world applications (e.g., autonomous driving, medical diagnoses). The challenge stems from the \"Gaussian Annulus Theorem\" phenomenon, where in high dimensions, the typical set of data may not intersect with the region of highest density, leading to counter-intuitive likelihood assignments \\cite{morningstar2020re9}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**:\n        *   **Unsupervised**: Historically, generative models used a one-sided threshold on log-likelihood \\cite{morningstar2020re9}. Later attempts tried to correct the \"high likelihood for OOD\" pathology using methods like WAIC (Choi et al. [2018]) or likelihood ratios (Ren et al. [2019]). Nalisnick et al. [2019b] proposed a typicality test based on batch means of log-likelihoods.\n        *   **Supervised**: Many methods leverage class labels or specific OOD examples during training (e.g., ODIN, ensembles, adversarial training, latent space mixture models) \\cite{morningstar2020re9}.\n    *   **Limitations of Previous Solutions**:\n        *   Direct log-likelihood: Fails egregiously in high dimensions, assigning higher likelihoods to OOD data \\cite{morningstar2020re9}.\n        *   WAIC/Likelihood ratio: Do not fundamentally address the high-dimensional likelihood issue \\cite{morningstar2020re9}.\n        *   Batch typicality tests: Performance degrades for single-sample OOD detection, and they may not use the most informative metrics \\cite{morningstar2020re9}.\n        *   Supervised methods: Require labeled data or known OOD examples, which are often unavailable in practice. They can also lead to models over-tuned to specific OOD sets and may discard useful OOD information \\cite{morningstar2020re9}.\n    *   **Positioning**: DoSE is an *unsupervised* method that does *not* require class labels or OOD examples during training, directly addressing the core failure mode of direct likelihood comparison by focusing on typicality across multiple statistics \\cite{morningstar2020re9}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: DoSE (Density of States Estimator) avoids direct comparison of model probabilities. Instead, it leverages the \"probability of the model probability\" or, more generally, the frequency (typicality) of *any reasonable summary statistic* derived from the generative model \\cite{morningstar2020re9}.\n    *   **Inspiration**: Draws on the statistical physics notion of \"density of states,\" which describes the number of configurations in a system that take on particular values of a given statistic \\cite{morningstar2020re9}. This concept helps identify atypical points even if they have high likelihoods.\n    *   **Mechanism**:\n        1.  A deep probabilistic model (e.g., $\\beta$-VAE, Glow) is trained on in-distribution data \\cite{morningstar2020re9}.\n        2.  Multiple summary statistics (e.g., negative log-likelihood, L2 norm, max coordinate value) are computed for the in-distribution training data \\cite{morningstar2020re9}.\n        3.  Nonparametric density estimators (e.g., Kernel Density Estimation (KDE) or one-class Support Vector Machine (SVM)) are trained on these statistics to estimate their \"density of states\" or typicality \\cite{morningstar2020re9}.\n        4.  For a new test point, its summary statistics are computed, and its typicality is evaluated using the trained DoSE. Points with low typicality across these statistics are flagged as OOD \\cite{morningstar2020re9}.\n    *   **Novelty**:\n        *   First to apply the \"density of states\" concept from statistical physics to OOD detection \\cite{morningstar2020re9}.\n        *   Shifts focus from direct model likelihoods to the typicality of *multiple* derived summary statistics \\cite{morningstar2020re9}.\n        *   Modular design allows trivial application to *any* existing, trained generative model without modification or retraining \\cite{morningstar2020re9}.\n        *   Operates in a fully unsupervised setting, requiring no OOD examples or class labels \\cite{morningstar2020re9}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of DoSE, an OOD detection method that jointly leverages multiple summary statistics from generative models, inspired by statistical physics and typicality \\cite{morningstar2020re9}.\n    *   **System Design/Architectural Innovations**: DoSE is modular and can be easily applied as a post-hoc OOD detector to any pre-trained generative model (demonstrated with $\\beta$-VAEs and Glow) \\cite{morningstar2020re9}.\n    *   **Theoretical Insights**: Provides a theoretical understanding of the shortcomings of MLE-fitted distributions for single-sample OOD detection through a bias/variance tradeoff for typicality (Theorem 3.1) \\cite{morningstar2020re9}.\n    *   **Practical Procedure**: Outlines a concrete 6-step procedure for constructing, calibrating, and applying DoSE for OOD detection, including using KDE or one-class SVMs for density estimation \\cite{morningstar2020re9}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Evaluated DoSE on established OOD detection benchmarks, comparing its performance against several unsupervised baselines \\cite{morningstar2020re9}. The procedure involved training generative models, constructing DoSEs on training data statistics, validating against a held-out set, and computing scores on in-distribution test sets and multiple OOD datasets \\cite{morningstar2020re9}.\n    *   **Key Performance Metrics**: Area Under the ROC Curve (AUROC) was used to measure OOD identification success \\cite{morningstar2020re9}.\n    *   **Comparison Results**: DoSE achieved state-of-the-art performance among unsupervised OOD detection methods and demonstrated comparable performance to state-of-the-art supervised methods \\cite{morningstar2020re9}. It significantly outperformed alternative methods that rely on only a single statistic \\cite{morningstar2020re9}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The theoretical bound (Theorem 3.1) is not directly computable due to unknown true entropy H[p], necessitating heuristic approximations \\cite{morningstar2020re9}.\n        *   When combining KDEs via product, it assumes independence between statistics, though this can be relaxed by using a one-class SVM on joint statistics \\cite{morningstar2020re9}.\n        *   While robust to uninformative statistics, the selection of effective summary statistics still involves some heuristic choice \\cite{morningstar2020re9}.\n    *   **Scope of Applicability**: DoSE is designed for unsupervised OOD detection scenarios where no class labels or specific OOD examples are available during model training. It is broadly applicable to any pre-trained deep probabilistic model \\cite{morningstar2020re9}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: DoSE provides a robust and effective unsupervised OOD detection method that directly addresses and overcomes the critical failure mode of direct likelihood comparison in high-dimensional data, a long-standing challenge in the field \\cite{morningstar2020re9}.\n    *   **Potential Impact on Future Research**:\n        *   Encourages a paradigm shift in OOD detection, moving beyond simple likelihood thresholds to a more nuanced understanding of \"typicality\" and the \"density of states\" \\cite{morningstar2020re9}.\n        *   Its modularity makes it a valuable tool for enhancing the reliability of existing generative models without requiring costly retraining or access to OOD data \\cite{morningstar2020re9}.\n        *   Opens new avenues for exploring diverse summary statistics and nonparametric density estimators for improved OOD detection performance \\cite{morningstar2020re9}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "deep generative models",
          "probabilistic model likelihoods",
          "Gaussian Annulus Theorem",
          "unsupervised OOD detection",
          "DoSE (Density of States Estimator)",
          "summary statistics",
          "typicality",
          "density of states (statistical physics)",
          "nonparametric density estimators",
          "modular post-hoc detector",
          "high-dimensional data",
          "ML system reliability",
          "state-of-the-art performance"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n*   **abstract:**\n    *   explicitly states \"we **propose dose**, the density of states estimator.\" this is a direct indicator of presenting a new method or system.\n    *   describes the mechanism of dose: \"decision rule avoids direct comparison of model probabilities, and instead utilizes the 'probability of the model probability',\" \"calculated using nonparametric density estimators.\"\n    *   highlights features and advantages of the proposed method: \"requires neither labeled data nor ood examples,\" \"modular and can be trivially applied to any existing, trained model.\"\n    *   mentions evaluation: \"we **demonstrate doseâ€™s state-of-the-art performance** against other unsupervised ood detectors.\" this empirical validation supports the technical contribution.\n*   **introduction:**\n    *   sets up a technical problem: \"poor speciï¬city for out-of-distribution (ood) detection.\"\n    *   discusses existing approaches (supervised and unsupervised ood detection) to provide context for the proposed solution.\n\nthe core of the paper, as described in the abstract, is the introduction and detailed explanation of a new method (dose) to address a specific technical challenge (ood detection). while it includes empirical validation, the primary contribution is the method itself."
      },
      "file_name": "4b83c2ec2c5119057979ae64cf4b5d1aef04466b.pdf"
    },
    {
      "success": true,
      "doc_id": "1dd86ca6cdfec5a5a7b538bf3be0c879",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/301e14edd925fb191714ddfa13593e67c6e5b2fd.pdf",
      "citation_key": "li20227o1",
      "metadata": {
        "title": "GraphDE: A Generative Framework for Debiased Learning and Out-of-Distribution Detection on Graphs",
        "authors": [
          "Zenan Li",
          "Qitian Wu",
          "Fan Nie",
          "Junchi Yan"
        ],
        "published_date": "2022",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/301e14edd925fb191714ddfa13593e67c6e5b2fd.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 51,
        "score": 17.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "301e14edd925fb191714ddfa13593e67c6e5b2fd.pdf"
    },
    {
      "success": true,
      "doc_id": "4148dd6dbab861530c13032f9779cda9",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/216d626b054db15aa6a36dcc43a7fc75ac8ecc9d.pdf",
      "citation_key": "xie2023uki",
      "metadata": {
        "title": "A unified out-of-distribution detection framework for trustworthy prognostics and health management in renewable energy systems",
        "authors": [
          "W. Xie",
          "Te Han",
          "Zhong Pei",
          "Min Xie"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/216d626b054db15aa6a36dcc43a7fc75ac8ecc9d.pdf",
        "venue": "Engineering applications of artificial intelligence",
        "citationCount": 34,
        "score": 17.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "216d626b054db15aa6a36dcc43a7fc75ac8ecc9d.pdf"
    },
    {
      "success": true,
      "doc_id": "37a75a3b620cb554725a93608081191d",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION**: \\cite{liu2022fdj}\n\n### Technical Paper Analysis:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of pixel-wise Out-of-Distribution (OoD) detection in semantic segmentation models, particularly when deployed in open-world scenarios.\n    *   **Importance and Challenge**:\n        *   **Reliability in Open-World**: Semantic segmentation models must not only classify known (\"in-distribution\") pixels but also reliably detect unknown (\"OoD\") pixels to ensure safety and robustness in real-world applications (e.g., autonomous driving, where misclassifying an anomaly can be catastrophic).\n        *   **Limitations of Existing Approaches**:\n            *   Methods that *freeze* the inlier segmentation model (e.g., using entropy or logits) tend to produce low uncertainty for \"hard\" OoD pixels that share patterns with in-distribution objects, leading to unsatisfactory performance in complex scenes.\n            *   State-of-the-art (SOTA) methods that *re-train* the segmentation model with synthetic OoD data (Outlier Exposure) often degrade the in-distribution segmentation accuracy (e.g., misclassifying minority categories).\n            *   A critical issue for re-training methods is their \"narrow context reliability,\" meaning their OoD detection accuracy does not generalize well to new contexts (e.g., from city to country scenes), leading to false positives or missed anomalies.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{liu2022fdj} builds upon pixel-wise OoD detection methods, specifically those that aim to either freeze or re-train the segmentation model. It also draws inspiration from supervised contrastive learning.\n    *   **Limitations of Previous Solutions**:\n        *   **Frozen Segmentation Models**: While computationally efficient and preserving inlier accuracy, these methods (e.g., Maximum Softmax \\cite{liu2022fdj}, Mahalanobis \\cite{liu2022fdj}) show inaccurate OoD detection, especially for hard outliers. Approaches like Synboost \\cite{liu2022fdj} improved accuracy but introduced confirmation bias.\n        *   **Re-trained Segmentation Models**: Methods like Meta-OoD \\cite{liu2022fdj} and PEBAL \\cite{liu2022fdj} achieve promising OoD detection by re-training with outlier exposure. However, they often degrade closed-set segmentation accuracy and suffer from poor generalization to new contexts, as they optimize pixel-wise anomaly scores independently without considering context relationships. PEBAL, a previous SOTA, is shown to fail in detecting anomalies or mis-detect inliers when context changes (Fig. 1).\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**:\n        *   **Residual Pattern Learning (RPL) Module**: An external module attached to a *frozen* closed-set segmentation network. It learns residual patterns of anomalies from intermediate features of the backbone (e.g., FCN output) and induces the segmentation classifier to produce high uncertainty for potential anomalies.\n        *   **Context-robust Contrastive Learning (CoroCL)**: A novel contrastive learning approach that optimizes pixel-wise embeddings by exploring the relationship between anomalies and inliers in different contexts. It pulls together embeddings of the same category (inlier or OoD) and pushes apart those from different categories, using samples from both mixed-content (OE) and pure outlier datasets.\n        *   **Positive Energy Loss**: A new loss function used during RPL training that exclusively focuses on maximizing the energy score of OoD pixels.\n    *   **Novelty/Difference**:\n        *   **Decoupled OoD Detection**: Unlike re-training methods, RPL *freezes* the entire segmentation model, ensuring minimal degradation to inlier segmentation accuracy while still effectively detecting OoD pixels. This is a novel perspective for pixel-wise OoD detection.\n        *   **Intermediate Feature Utilization**: RPL leverages richer information from intermediate features (from `fÏ•fcn`) rather than just the segmentation model's output logits or probabilities, leading to more effective anomaly detection.\n        *   **Context Robustness**: CoroCL explicitly addresses the critical issue of context generalization by learning robust representations that understand the relationship between contexts and anomalous objects, a limitation of prior methods.\n        *   **Hyperparameter-Free Outlier Optimization**: The positive energy loss is simpler and more effective than previous hinge losses, as it has no hyperparameters and specifically targets the imbalanced distribution of inlier/outlier samples by focusing only on outlier energy.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   The Residual Pattern Learning (RPL) module for inducing anomaly detection without re-training the base segmentation model.\n        *   The Context-robust Contrastive Learning (CoroCL) framework for enhancing OoD detection generalization across diverse contexts.\n        *   A novel positive energy loss function designed to effectively optimize for anomalous pixels, addressing class imbalance and hyperparameter complexity.\n    *   **System Design or Architectural Innovations**: The integration of RPL as an *external* module between the FCN layers and the segmentation head of a frozen network, allowing for targeted anomaly learning.\n    *   **Theoretical Insights or Analysis**: The paper proposes that RPL effectively pushes OoD pixels towards an uncertainty region while minimally impacting the fixed inlier decision boundaries (Fig. 3c), and CoroCL enables consistent representations by understanding context-anomaly relationships.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Quantitative comparison with SOTA methods on standard pixel-wise OoD detection benchmarks.\n        *   Evaluation of inlier segmentation accuracy to demonstrate minimal degradation.\n        *   Ablation studies to validate the effectiveness of RPL and CoroCL components.\n    *   **Key Performance Metrics**: False Positive Rate (FPR), Area under the Precision-Recall Curve (AuPRC), Area Under the Receiver Operating Characteristic (AUROC), and F1* score for anomaly obstacle detection.\n    *   **Comparison Results**:\n        *   Achieves state-of-the-art performance, improving by approximately 10% FPR and 7% AuPRC over previous SOTA results.\n        *   Demonstrates superior performance across Fishyscapes (Static, L&F, Anomaly), Segment-Me-If-You-Can (SMIYC), and RoadAnomaly datasets.\n        *   Shows significantly improved stability and robustness in various scene contexts compared to prior SOTA methods like PEBAL (e.g., Fig. 1).\n        *   Maintains high inlier segmentation accuracy, confirming minimal deterioration.\n        *   The approach is shown to be easily integrable with other SOTAs (e.g., Meta-OoD, PEBAL) for potential further enhancements.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**:\n        *   The method relies on Outlier Exposure (OE) for training, which involves synthetically mixing OoD objects into inlier images. The quality and diversity of this synthetic data can influence performance.\n        *   The paper acknowledges that \"false positive anomaly detection (i.e., inliers located within the uncertain regions) is a side effect of the production of OoD masks that affects all OoD detectors,\" implying that while minimized, it's not entirely eliminated.\n    *   **Scope of Applicability**: Primarily focused on pixel-wise OoD detection in semantic segmentation for urban driving scenes, validated on datasets like Cityscapes, Fishyscapes, SMIYC, and RoadAnomaly.\n\n7.  **Technical Significance**\n    *   **Advance the Technical State-of-the-Art**: \\cite{liu2022fdj} significantly advances the state-of-the-art in pixel-wise OoD detection by achieving superior performance (10% FPR, 7% AuPRC improvement) and robustness across diverse contexts. It offers a novel paradigm by decoupling OoD detection from the core segmentation model, preserving inlier accuracy.\n    *   **Potential Impact on Future Research**:\n        *   **Reliable Open-World AI**: Enables more reliable and safer deployment of semantic segmentation models in safety-critical open-world applications like autonomous driving.\n        *   **Decoupled Learning**: The RPL module's concept of learning residual anomaly patterns without re-training the base model could inspire future research into modular and less intrusive OoD detection architectures.\n        *   **Context-Awareness**: CoroCL's explicit focus on context robustness provides a strong foundation for developing more generalizable OoD detectors that can adapt to unforeseen environmental shifts.\n        *   **Loss Function Design**: The positive energy loss offers a simpler, more effective approach to handling class imbalance in outlier detection, which could be adopted or extended in other anomaly detection tasks.",
      "intriguing_abstract": "Autonomous systems demand semantic segmentation models that not only accurately classify known objects but also reliably detect unforeseen anomalies in open-world environments. Current pixel-wise Out-of-Distribution (OoD) detection methods struggle, either degrading in-distribution accuracy or failing to generalize robustly across diverse contexts, posing significant safety risks. We introduce a novel paradigm that decouples OoD detection from the core segmentation task. Our Residual Pattern Learning (RPL) module, attached to a *frozen* segmentation network, precisely identifies anomalies by leveraging intermediate features without compromising inlier performance. Complementing this, Context-robust Contrastive Learning (CoroCL) explicitly learns generalizable representations that understand context-anomaly relationships, overcoming the \"narrow context reliability\" of prior state-of-the-art. Optimized with a novel positive energy loss, our approach achieves unprecedented robustness and significantly improves OoD detection, boosting FPR by ~10% and AuPRC by 7% across challenging benchmarks like Fishyscapes and RoadAnomaly. This work paves the way for safer, more reliable AI deployment in safety-critical applications.",
      "keywords": [
        "Pixel-wise Out-of-Distribution (OoD) detection",
        "semantic segmentation",
        "Residual Pattern Learning (RPL)",
        "Context-robust Contrastive Learning (CoroCL)",
        "positive energy loss",
        "decoupled OoD detection",
        "context robustness",
        "frozen segmentation network",
        "autonomous driving",
        "state-of-the-art performance",
        "minimal inlier degradation",
        "open-world AI reliability"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/48fe12e7ae26dc6541d6403e45b2a9397e2460a0.pdf",
      "citation_key": "liu2022fdj",
      "metadata": {
        "title": "Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection in Semantic Segmentation",
        "authors": [
          "Yuyuan Liu",
          "Choubo Ding",
          "Yu Tian",
          "Guansong Pang",
          "Vasileios Belagiannis",
          "I. Reid",
          "G. Carneiro"
        ],
        "published_date": "2022",
        "abstract": "Semantic segmentation models classify pixels into a set of known (\"in-distribution\") visual classes. When deployed in an open world, the reliability of these models depends on their ability to not only classify in-distribution pixels but also to detect out-of-distribution (OoD) pixels. Historically, the poor OoD detection performance of these models has motivated the design of methods based on model re-training using synthetic training images that include OoD visual objects. Although successful, these re-trained methods have two issues: 1) their in-distribution segmentation accuracy may drop during re-training, and 2) their OoD detection accuracy does not generalise well to new contexts outside the training set (e.g., from city to country context). In this paper, we mitigate these issues with: (i) a new residual pattern learning (RPL) module that assists the segmentation model to detect OoD pixels with minimal deterioration to inlier segmentation accuracy; and (ii) a novel context-robust contrastive learning (CoroCL) that enforces RPL to robustly detect OoD pixels in various contexts. Our approach improves by around 10% FPR and 7% AuPRC previous state-of-the-art in Fishyscapes, Segment-Me-If-You-Can, and RoadAnomaly datasets.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/48fe12e7ae26dc6541d6403e45b2a9397e2460a0.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 50,
        "score": 16.666666666666664,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION**: \\cite{liu2022fdj}\n\n### Technical Paper Analysis:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of pixel-wise Out-of-Distribution (OoD) detection in semantic segmentation models, particularly when deployed in open-world scenarios.\n    *   **Importance and Challenge**:\n        *   **Reliability in Open-World**: Semantic segmentation models must not only classify known (\"in-distribution\") pixels but also reliably detect unknown (\"OoD\") pixels to ensure safety and robustness in real-world applications (e.g., autonomous driving, where misclassifying an anomaly can be catastrophic).\n        *   **Limitations of Existing Approaches**:\n            *   Methods that *freeze* the inlier segmentation model (e.g., using entropy or logits) tend to produce low uncertainty for \"hard\" OoD pixels that share patterns with in-distribution objects, leading to unsatisfactory performance in complex scenes.\n            *   State-of-the-art (SOTA) methods that *re-train* the segmentation model with synthetic OoD data (Outlier Exposure) often degrade the in-distribution segmentation accuracy (e.g., misclassifying minority categories).\n            *   A critical issue for re-training methods is their \"narrow context reliability,\" meaning their OoD detection accuracy does not generalize well to new contexts (e.g., from city to country scenes), leading to false positives or missed anomalies.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{liu2022fdj} builds upon pixel-wise OoD detection methods, specifically those that aim to either freeze or re-train the segmentation model. It also draws inspiration from supervised contrastive learning.\n    *   **Limitations of Previous Solutions**:\n        *   **Frozen Segmentation Models**: While computationally efficient and preserving inlier accuracy, these methods (e.g., Maximum Softmax \\cite{liu2022fdj}, Mahalanobis \\cite{liu2022fdj}) show inaccurate OoD detection, especially for hard outliers. Approaches like Synboost \\cite{liu2022fdj} improved accuracy but introduced confirmation bias.\n        *   **Re-trained Segmentation Models**: Methods like Meta-OoD \\cite{liu2022fdj} and PEBAL \\cite{liu2022fdj} achieve promising OoD detection by re-training with outlier exposure. However, they often degrade closed-set segmentation accuracy and suffer from poor generalization to new contexts, as they optimize pixel-wise anomaly scores independently without considering context relationships. PEBAL, a previous SOTA, is shown to fail in detecting anomalies or mis-detect inliers when context changes (Fig. 1).\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**:\n        *   **Residual Pattern Learning (RPL) Module**: An external module attached to a *frozen* closed-set segmentation network. It learns residual patterns of anomalies from intermediate features of the backbone (e.g., FCN output) and induces the segmentation classifier to produce high uncertainty for potential anomalies.\n        *   **Context-robust Contrastive Learning (CoroCL)**: A novel contrastive learning approach that optimizes pixel-wise embeddings by exploring the relationship between anomalies and inliers in different contexts. It pulls together embeddings of the same category (inlier or OoD) and pushes apart those from different categories, using samples from both mixed-content (OE) and pure outlier datasets.\n        *   **Positive Energy Loss**: A new loss function used during RPL training that exclusively focuses on maximizing the energy score of OoD pixels.\n    *   **Novelty/Difference**:\n        *   **Decoupled OoD Detection**: Unlike re-training methods, RPL *freezes* the entire segmentation model, ensuring minimal degradation to inlier segmentation accuracy while still effectively detecting OoD pixels. This is a novel perspective for pixel-wise OoD detection.\n        *   **Intermediate Feature Utilization**: RPL leverages richer information from intermediate features (from `fÏ•fcn`) rather than just the segmentation model's output logits or probabilities, leading to more effective anomaly detection.\n        *   **Context Robustness**: CoroCL explicitly addresses the critical issue of context generalization by learning robust representations that understand the relationship between contexts and anomalous objects, a limitation of prior methods.\n        *   **Hyperparameter-Free Outlier Optimization**: The positive energy loss is simpler and more effective than previous hinge losses, as it has no hyperparameters and specifically targets the imbalanced distribution of inlier/outlier samples by focusing only on outlier energy.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   The Residual Pattern Learning (RPL) module for inducing anomaly detection without re-training the base segmentation model.\n        *   The Context-robust Contrastive Learning (CoroCL) framework for enhancing OoD detection generalization across diverse contexts.\n        *   A novel positive energy loss function designed to effectively optimize for anomalous pixels, addressing class imbalance and hyperparameter complexity.\n    *   **System Design or Architectural Innovations**: The integration of RPL as an *external* module between the FCN layers and the segmentation head of a frozen network, allowing for targeted anomaly learning.\n    *   **Theoretical Insights or Analysis**: The paper proposes that RPL effectively pushes OoD pixels towards an uncertainty region while minimally impacting the fixed inlier decision boundaries (Fig. 3c), and CoroCL enables consistent representations by understanding context-anomaly relationships.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Quantitative comparison with SOTA methods on standard pixel-wise OoD detection benchmarks.\n        *   Evaluation of inlier segmentation accuracy to demonstrate minimal degradation.\n        *   Ablation studies to validate the effectiveness of RPL and CoroCL components.\n    *   **Key Performance Metrics**: False Positive Rate (FPR), Area under the Precision-Recall Curve (AuPRC), Area Under the Receiver Operating Characteristic (AUROC), and F1* score for anomaly obstacle detection.\n    *   **Comparison Results**:\n        *   Achieves state-of-the-art performance, improving by approximately 10% FPR and 7% AuPRC over previous SOTA results.\n        *   Demonstrates superior performance across Fishyscapes (Static, L&F, Anomaly), Segment-Me-If-You-Can (SMIYC), and RoadAnomaly datasets.\n        *   Shows significantly improved stability and robustness in various scene contexts compared to prior SOTA methods like PEBAL (e.g., Fig. 1).\n        *   Maintains high inlier segmentation accuracy, confirming minimal deterioration.\n        *   The approach is shown to be easily integrable with other SOTAs (e.g., Meta-OoD, PEBAL) for potential further enhancements.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**:\n        *   The method relies on Outlier Exposure (OE) for training, which involves synthetically mixing OoD objects into inlier images. The quality and diversity of this synthetic data can influence performance.\n        *   The paper acknowledges that \"false positive anomaly detection (i.e., inliers located within the uncertain regions) is a side effect of the production of OoD masks that affects all OoD detectors,\" implying that while minimized, it's not entirely eliminated.\n    *   **Scope of Applicability**: Primarily focused on pixel-wise OoD detection in semantic segmentation for urban driving scenes, validated on datasets like Cityscapes, Fishyscapes, SMIYC, and RoadAnomaly.\n\n7.  **Technical Significance**\n    *   **Advance the Technical State-of-the-Art**: \\cite{liu2022fdj} significantly advances the state-of-the-art in pixel-wise OoD detection by achieving superior performance (10% FPR, 7% AuPRC improvement) and robustness across diverse contexts. It offers a novel paradigm by decoupling OoD detection from the core segmentation model, preserving inlier accuracy.\n    *   **Potential Impact on Future Research**:\n        *   **Reliable Open-World AI**: Enables more reliable and safer deployment of semantic segmentation models in safety-critical open-world applications like autonomous driving.\n        *   **Decoupled Learning**: The RPL module's concept of learning residual anomaly patterns without re-training the base model could inspire future research into modular and less intrusive OoD detection architectures.\n        *   **Context-Awareness**: CoroCL's explicit focus on context robustness provides a strong foundation for developing more generalizable OoD detectors that can adapt to unforeseen environmental shifts.\n        *   **Loss Function Design**: The positive energy loss offers a simpler, more effective approach to handling class imbalance in outlier detection, which could be adopted or extended in other anomaly detection tasks.",
        "keywords": [
          "Pixel-wise Out-of-Distribution (OoD) detection",
          "semantic segmentation",
          "Residual Pattern Learning (RPL)",
          "Context-robust Contrastive Learning (CoroCL)",
          "positive energy loss",
          "decoupled OoD detection",
          "context robustness",
          "frozen segmentation network",
          "autonomous driving",
          "state-of-the-art performance",
          "minimal inlier degradation",
          "open-world AI reliability"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"in this paper, we mitigate these issues with: (i) a new residual pattern learning (rpl) module... and (ii) a novel context-robust contrastive learning (corocl)...\" this clearly indicates the presentation of **new methods** and **algorithms**.\n*   the introduction discusses a **technical problem** (ood detection in semantic segmentation) and the limitations of existing **technical solutions**.\n*   the abstract also mentions experimental results (\"our approach improves by around 10% fpr and 7% auprc previous state-of-the-art in fishyscapes, segment-me-if-you-can, and roadanomaly datasets\"), which is characteristic of empirical work. however, the primary contribution described is the **development of new methods**, with the empirical results serving to validate these new methods.\n\ntherefore, the paper's core contribution aligns best with the **technical** classification.\n\n**classification: technical**"
      },
      "file_name": "48fe12e7ae26dc6541d6403e45b2a9397e2460a0.pdf"
    },
    {
      "success": true,
      "doc_id": "6f7e3b2ff5c4d260ca00c71c2a66beaa",
      "summary": "Detecting Out-of-Distribution (OoD) data is one of the greatest challenges in safe and robust deployment of machine learning algorithms in medicine. When the algorithms encounter cases that deviate from the distribution of the training data, they often produce incorrect and over-confident predictions. OoD detection algorithms aim to catch erroneous predictions in advance by analysing the data distribution and detecting potential instances of failure. Moreover, flagging OoD cases may support human readers in identifying incidental findings. Due to the increased interest in OoD algorithms, benchmarks for different domains have recently been established. In the medical imaging domain, for which reliable predictions are often essential, an open benchmark has been missing. We introduce the Medical-Out-Of-Distribution-Analysis-Challenge (MOOD) as an open, fair, and unbiased benchmark for OoD methods in the medical imaging domain. The analysis of the submitted algorithms shows that performance has a strong positive correlation with the perceived difficulty, and that all algorithms show a high variance for different anomalies, making it yet hard to recommend them for clinical practice. We also see a strong correlation between challenge ranking and performance on a simple toy test set, indicating that this might be a valuable addition as a proxy dataset during anomaly detection algorithm development.",
      "intriguing_abstract": "Detecting Out-of-Distribution (OoD) data is one of the greatest challenges in safe and robust deployment of machine learning algorithms in medicine. When the algorithms encounter cases that deviate from the distribution of the training data, they often produce incorrect and over-confident predictions. OoD detection algorithms aim to catch erroneous predictions in advance by analysing the data distribution and detecting potential instances of failure. Moreover, flagging OoD cases may support human readers in identifying incidental findings. Due to the increased interest in OoD algorithms, benchmarks for different domains have recently been established. In the medical imaging domain, for which reliable predictions are often essential, an open benchmark has been missing. We introduce the Medical-Out-Of-Distribution-Analysis-Challenge (MOOD) as an open, fair, and unbiased benchmark for OoD methods in the medical imaging domain. The analysis of the submitted algorithms shows that performance has a strong positive correlation with the perceived difficulty, and that all algorithms show a high variance for different anomalies, making it yet hard to recommend them for clinical practice. We also see a strong correlation between challenge ranking and performance on a simple toy test set, indicating that this might be a valuable addition as a proxy dataset during anomaly detection algorithm development.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/63ff7c225079eba3838d45b11bb15a58037f1415.pdf",
      "citation_key": "zimmerer2022rv6",
      "metadata": {
        "title": "MOOD 2020: A Public Benchmark for Out-of-Distribution Detection and Localization on Medical Images",
        "authors": [
          "David Zimmerer",
          "Peter M. Full",
          "Fabian Isensee",
          "Paul F. Jager",
          "T. Adler",
          "Jens Petersen",
          "Gregor Koehler",
          "T. Ross",
          "Annika Reinke",
          "Antanas Kascenas",
          "B. S. Jensen",
          "Alison Q. O'Neil",
          "Jeremy Tan",
          "Benjamin Hou",
          "James Batten",
          "Huaqi Qiu",
          "Bernhard Kainz",
          "Nina Shvetsova",
          "Irina Fedulova",
          "D. Dylov",
          "Baolun Yu",
          "Jianyang Zhai",
          "Jingtao Hu",
          "Runxuan Si",
          "Sihang Zhou",
          "Siqi Wang",
          "Xinyang Li",
          "Xuerun Chen",
          "Yang Zhao",
          "Sergio Naval Marimont",
          "G. Tarroni",
          "Victor Saase",
          "L. Maier-Hein",
          "K. Maier-Hein"
        ],
        "published_date": "2022",
        "abstract": "Detecting Out-of-Distribution (OoD) data is one of the greatest challenges in safe and robust deployment of machine learning algorithms in medicine. When the algorithms encounter cases that deviate from the distribution of the training data, they often produce incorrect and over-confident predictions. OoD detection algorithms aim to catch erroneous predictions in advance by analysing the data distribution and detecting potential instances of failure. Moreover, flagging OoD cases may support human readers in identifying incidental findings. Due to the increased interest in OoD algorithms, benchmarks for different domains have recently been established. In the medical imaging domain, for which reliable predictions are often essential, an open benchmark has been missing. We introduce the Medical-Out-Of-Distribution-Analysis-Challenge (MOOD) as an open, fair, and unbiased benchmark for OoD methods in the medical imaging domain. The analysis of the submitted algorithms shows that performance has a strong positive correlation with the perceived difficulty, and that all algorithms show a high variance for different anomalies, making it yet hard to recommend them for clinical practice. We also see a strong correlation between challenge ranking and performance on a simple toy test set, indicating that this might be a valuable addition as a proxy dataset during anomaly detection algorithm development.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/63ff7c225079eba3838d45b11bb15a58037f1415.pdf",
        "venue": "IEEE Transactions on Medical Imaging",
        "citationCount": 50,
        "score": 16.666666666666664,
        "summary": "Detecting Out-of-Distribution (OoD) data is one of the greatest challenges in safe and robust deployment of machine learning algorithms in medicine. When the algorithms encounter cases that deviate from the distribution of the training data, they often produce incorrect and over-confident predictions. OoD detection algorithms aim to catch erroneous predictions in advance by analysing the data distribution and detecting potential instances of failure. Moreover, flagging OoD cases may support human readers in identifying incidental findings. Due to the increased interest in OoD algorithms, benchmarks for different domains have recently been established. In the medical imaging domain, for which reliable predictions are often essential, an open benchmark has been missing. We introduce the Medical-Out-Of-Distribution-Analysis-Challenge (MOOD) as an open, fair, and unbiased benchmark for OoD methods in the medical imaging domain. The analysis of the submitted algorithms shows that performance has a strong positive correlation with the perceived difficulty, and that all algorithms show a high variance for different anomalies, making it yet hard to recommend them for clinical practice. We also see a strong correlation between challenge ranking and performance on a simple toy test set, indicating that this might be a valuable addition as a proxy dataset during anomaly detection algorithm development.",
        "keywords": []
      },
      "file_name": "63ff7c225079eba3838d45b11bb15a58037f1415.pdf"
    },
    {
      "success": true,
      "doc_id": "8b220723a443723cf2db2c3d6b45cc93",
      "summary": "Here's a focused summary of the technical paper \\cite{kaur2022cty} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Deep Neural Networks (DNNs) often produce overconfident and incorrect predictions when presented with inputs outside their training distribution (Out-of-Distribution, OOD) \\cite{kaur2022cty}.\n    *   This problem is critical in safety-critical domains (e.g., autonomous vehicles, medicine) where DNNs must reliably detect OOD data and abstain from making predictions \\cite{kaur2022cty}.\n    *   Existing OOD detection methods still have significant room for improvement, particularly in providing rigorous guarantees on false detection rates \\cite{kaur2022cty}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection techniques are broadly categorized into supervised, self-supervised, and unsupervised methods \\cite{kaur2022cty}.\n    *   **Supervised methods** (e.g., Lee et al. 2017, Hendrycks et al. 2019, Mahalanobis distance-based methods) require access to OOD data or a proxy during training, which may not generalize to unseen OOD data \\cite{kaur2022cty}.\n    *   **Self-supervised methods** (e.g., Golan & El-Yaniv 2018, Hendrycks et al. 2019) use transformations to create self-labeled datasets for an auxiliary task, but typically lack theoretical guarantees \\cite{kaur2022cty}.\n    *   **Unsupervised methods** (e.g., maximum softmax probability, ODIN, energy scores, likelihood ratio) use only in-distribution (iD) data for detection but generally do not provide theoretical guarantees on OOD detection performance \\cite{kaur2022cty}.\n    *   While Inductive Conformal Anomaly Detection (ICAD) has been explored for unsupervised detection (Cai & Koutsoukos 2020, Bates et al. 2021), \\cite{kaur2022cty} proposes a novel NCM and aggregation specifically for single-point OOD detection with bounded false detection rates.\n\n*   **Technical Approach & Innovation**\n    *   The core technical approach, named iDECODe, leverages in-distribution equivariance within the Inductive Conformal Anomaly Detection (ICAD) framework \\cite{kaur2022cty}.\n    *   **Novel Base Non-Conformity Measure (NCM):** The paper proposes a base NCM defined as the error in the expected behavior of transformation-equivariance learned by a model `M` for a set of transformations `G` on the proper training set. This is formalized as `A(Xtr; x; g) = L[M(g(x)); g'M(x)]`, where `L` is a loss function and `g'` is an output transform corresponding to `g` \\cite{kaur2022cty}.\n        *   Examples include using the squared L2 norm of the difference in label predictions `kM(g(x)) - M(x)k^2_2` for data augmentation-based equivariance, or the error in predicting the applied transformation `L[M(g(x)); g]` for auxiliary task-based equivariance \\cite{kaur2022cty}.\n    *   **Novel Aggregation Method:** Instead of a single transformation, iDECODe uses a vector of `n` base NCM scores, `V(x; Xtr; g1:n)`, computed from `n` independently and identically distributed (IID) transformations sampled from a distribution `Q_G` over `G` \\cite{kaur2022cty}. These scores are then aggregated by a function `F: R^n -> R` (e.g., summation) to form the final aggregated NCM score. This reduces noise and increases robustness, as OOD data is less likely to mimic iD behavior under multiple transformations \\cite{kaur2022cty}.\n\n*   **Key Technical Contributions**\n    *   **Novel Base NCM:** A new non-conformity measure based on the error in in-distribution equivariance with respect to a set of transformations `G` \\cite{kaur2022cty}.\n    *   **Novel Aggregation Method:** An innovative approach to combine multiple non-conformity scores, derived from different transformations, into a single, more robust aggregated NCM \\cite{kaur2022cty}.\n    *   **iDECODe Framework:** The integration of the aggregated NCM into the ICAD framework, providing a method for OOD detection with a theoretically guaranteed bounded false detection rate (FDR) \\cite{kaur2022cty}.\n    *   **Theoretical Guarantee:** A formal proof (Theorem 1 and Corollary 1) demonstrating that if the test datapoint is from the training distribution, the p-value is uniformly distributed, and the probability of false OOD detection is upper bounded by a user-defined significance level `alpha` \\cite{kaur2022cty}.\n\n*   **Experimental Validation**\n    *   \\cite{kaur2022cty} demonstrates the efficacy of iDECODe through experiments on both image and audio datasets.\n    *   The method achieves state-of-the-art (SOTA) results in OOD detection on these datasets.\n    *   Beyond general OOD detection, iDECODe is also shown to be effective in detecting adversarial examples.\n    *   (Specific datasets, metrics, and detailed comparison results are not provided in the excerpt, but the claim of SOTA and adversarial detection capability is made.)\n\n*   **Limitations & Scope**\n    *   The theoretical guarantee (Theorem 1) assumes that ties between aggregated NCM scores occur with zero probability, which holds under broad practical assumptions (e.g., absolutely continuous data distribution, strictly increasing aggregation function) \\cite{kaur2022cty}. Smoothed p-values can be used if ties are present.\n    *   The method is proposed for the detection of a single point as OOD, rather than batches of data \\cite{kaur2022cty}.\n    *   The performance depends on the choice of the loss function `L` for the base NCM; for instance, KL-divergence was found to perform poorly in experiments \\cite{kaur2022cty}.\n\n*   **Technical Significance**\n    *   iDECODe advances the technical state-of-the-art by providing a novel, theoretically grounded approach to OOD detection that offers a bounded false detection rate, a crucial property for safety-critical applications \\cite{kaur2022cty}.\n    *   By leveraging the inherent property of in-distribution equivariance, which is often learned by models through data augmentation or architectural choices (like CNNs), the method capitalizes on a desirable characteristic of robust models \\cite{kaur2022cty}.\n    *   The work opens avenues for future research in designing more effective base NCMs and aggregation functions, and potentially extending the theoretical guarantees to more complex OOD scenarios or batch detection. Its ability to detect adversarial examples also highlights its potential for improving model robustness against malicious inputs \\cite{kaur2022cty}.",
      "intriguing_abstract": "Deep Neural Networks (DNNs) often exhibit dangerous overconfidence when encountering Out-of-Distribution (OOD) data, a critical vulnerability in safety-critical domains like autonomous vehicles and medicine. Addressing the urgent need for reliable OOD detection with rigorous assurances, we introduce **iDECODe**, a novel framework that provides theoretically bounded false detection rates.\n\niDECODe innovatively leverages the inherent **in-distribution equivariance** of models. We propose a novel **Non-Conformity Measure (NCM)** that quantifies the error in a model's expected transformation-equivariance. To enhance robustness, this base NCM is then combined through a novel **aggregation method** across multiple independent transformations. Integrating this into the **Inductive Conformal Anomaly Detection (ICAD)** framework, iDECODe offers a formal proof guaranteeing an upper bound on the **False Detection Rate (FDR)** at a user-defined significance level. Our extensive experiments demonstrate state-of-the-art performance on image and audio datasets, and remarkably, its effectiveness in detecting **adversarial examples**. iDECODe represents a crucial advancement towards deploying trustworthy AI systems with verifiable safety guarantees.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Deep Neural Networks (DNNs)",
        "safety-critical domains",
        "iDECODe framework",
        "Inductive Conformal Anomaly Detection (ICAD)",
        "transformation-equivariance",
        "novel Non-Conformity Measure (NCM)",
        "novel aggregation method",
        "bounded false detection rate (FDR)",
        "theoretical guarantees",
        "state-of-the-art (SOTA) OOD detection",
        "adversarial example detection"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/34d35e460b39edb19581ef345c4b32ce45aa9eae.pdf",
      "citation_key": "kaur2022cty",
      "metadata": {
        "title": "iDECODe: In-distribution Equivariance for Conformal Out-of-distribution Detection",
        "authors": [
          "R. Kaur",
          "Susmit Jha",
          "Anirban Roy",
          "Sangdon Park",
          "Edgar Dobriban",
          "O. Sokolsky",
          "Insup Lee"
        ],
        "published_date": "2022",
        "abstract": "Machine learning methods such as deep neural networks (DNNs), despite their success across different domains, are known to often generate incorrect predictions with high confidence on inputs outside their training distribution. The deployment of DNNs in safety-critical domains requires detection of out-of-distribution (OOD) data so that DNNs can abstain from making predictions on those. A number of methods have been recently developed for OOD detection, but there is still room for improvement. We propose the new method iDECODe, leveraging in-distribution equivariance for conformal OOD detection. It relies on a novel base non-conformity measure and a new aggregation method, used in the inductive conformal anomaly detection framework, thereby guaranteeing a bounded false detection rate. We demonstrate the efficacy of iDECODe by experiments on image and audio datasets, obtaining state-of-the-art results. We also show that iDECODe can detect adversarial examples. Code, pre-trained models, and data are available at https://github.com/ramneetk/iDECODe.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/34d35e460b39edb19581ef345c4b32ce45aa9eae.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 49,
        "score": 16.333333333333332,
        "summary": "Here's a focused summary of the technical paper \\cite{kaur2022cty} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Deep Neural Networks (DNNs) often produce overconfident and incorrect predictions when presented with inputs outside their training distribution (Out-of-Distribution, OOD) \\cite{kaur2022cty}.\n    *   This problem is critical in safety-critical domains (e.g., autonomous vehicles, medicine) where DNNs must reliably detect OOD data and abstain from making predictions \\cite{kaur2022cty}.\n    *   Existing OOD detection methods still have significant room for improvement, particularly in providing rigorous guarantees on false detection rates \\cite{kaur2022cty}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection techniques are broadly categorized into supervised, self-supervised, and unsupervised methods \\cite{kaur2022cty}.\n    *   **Supervised methods** (e.g., Lee et al. 2017, Hendrycks et al. 2019, Mahalanobis distance-based methods) require access to OOD data or a proxy during training, which may not generalize to unseen OOD data \\cite{kaur2022cty}.\n    *   **Self-supervised methods** (e.g., Golan & El-Yaniv 2018, Hendrycks et al. 2019) use transformations to create self-labeled datasets for an auxiliary task, but typically lack theoretical guarantees \\cite{kaur2022cty}.\n    *   **Unsupervised methods** (e.g., maximum softmax probability, ODIN, energy scores, likelihood ratio) use only in-distribution (iD) data for detection but generally do not provide theoretical guarantees on OOD detection performance \\cite{kaur2022cty}.\n    *   While Inductive Conformal Anomaly Detection (ICAD) has been explored for unsupervised detection (Cai & Koutsoukos 2020, Bates et al. 2021), \\cite{kaur2022cty} proposes a novel NCM and aggregation specifically for single-point OOD detection with bounded false detection rates.\n\n*   **Technical Approach & Innovation**\n    *   The core technical approach, named iDECODe, leverages in-distribution equivariance within the Inductive Conformal Anomaly Detection (ICAD) framework \\cite{kaur2022cty}.\n    *   **Novel Base Non-Conformity Measure (NCM):** The paper proposes a base NCM defined as the error in the expected behavior of transformation-equivariance learned by a model `M` for a set of transformations `G` on the proper training set. This is formalized as `A(Xtr; x; g) = L[M(g(x)); g'M(x)]`, where `L` is a loss function and `g'` is an output transform corresponding to `g` \\cite{kaur2022cty}.\n        *   Examples include using the squared L2 norm of the difference in label predictions `kM(g(x)) - M(x)k^2_2` for data augmentation-based equivariance, or the error in predicting the applied transformation `L[M(g(x)); g]` for auxiliary task-based equivariance \\cite{kaur2022cty}.\n    *   **Novel Aggregation Method:** Instead of a single transformation, iDECODe uses a vector of `n` base NCM scores, `V(x; Xtr; g1:n)`, computed from `n` independently and identically distributed (IID) transformations sampled from a distribution `Q_G` over `G` \\cite{kaur2022cty}. These scores are then aggregated by a function `F: R^n -> R` (e.g., summation) to form the final aggregated NCM score. This reduces noise and increases robustness, as OOD data is less likely to mimic iD behavior under multiple transformations \\cite{kaur2022cty}.\n\n*   **Key Technical Contributions**\n    *   **Novel Base NCM:** A new non-conformity measure based on the error in in-distribution equivariance with respect to a set of transformations `G` \\cite{kaur2022cty}.\n    *   **Novel Aggregation Method:** An innovative approach to combine multiple non-conformity scores, derived from different transformations, into a single, more robust aggregated NCM \\cite{kaur2022cty}.\n    *   **iDECODe Framework:** The integration of the aggregated NCM into the ICAD framework, providing a method for OOD detection with a theoretically guaranteed bounded false detection rate (FDR) \\cite{kaur2022cty}.\n    *   **Theoretical Guarantee:** A formal proof (Theorem 1 and Corollary 1) demonstrating that if the test datapoint is from the training distribution, the p-value is uniformly distributed, and the probability of false OOD detection is upper bounded by a user-defined significance level `alpha` \\cite{kaur2022cty}.\n\n*   **Experimental Validation**\n    *   \\cite{kaur2022cty} demonstrates the efficacy of iDECODe through experiments on both image and audio datasets.\n    *   The method achieves state-of-the-art (SOTA) results in OOD detection on these datasets.\n    *   Beyond general OOD detection, iDECODe is also shown to be effective in detecting adversarial examples.\n    *   (Specific datasets, metrics, and detailed comparison results are not provided in the excerpt, but the claim of SOTA and adversarial detection capability is made.)\n\n*   **Limitations & Scope**\n    *   The theoretical guarantee (Theorem 1) assumes that ties between aggregated NCM scores occur with zero probability, which holds under broad practical assumptions (e.g., absolutely continuous data distribution, strictly increasing aggregation function) \\cite{kaur2022cty}. Smoothed p-values can be used if ties are present.\n    *   The method is proposed for the detection of a single point as OOD, rather than batches of data \\cite{kaur2022cty}.\n    *   The performance depends on the choice of the loss function `L` for the base NCM; for instance, KL-divergence was found to perform poorly in experiments \\cite{kaur2022cty}.\n\n*   **Technical Significance**\n    *   iDECODe advances the technical state-of-the-art by providing a novel, theoretically grounded approach to OOD detection that offers a bounded false detection rate, a crucial property for safety-critical applications \\cite{kaur2022cty}.\n    *   By leveraging the inherent property of in-distribution equivariance, which is often learned by models through data augmentation or architectural choices (like CNNs), the method capitalizes on a desirable characteristic of robust models \\cite{kaur2022cty}.\n    *   The work opens avenues for future research in designing more effective base NCMs and aggregation functions, and potentially extending the theoretical guarantees to more complex OOD scenarios or batch detection. Its ability to detect adversarial examples also highlights its potential for improving model robustness against malicious inputs \\cite{kaur2022cty}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Deep Neural Networks (DNNs)",
          "safety-critical domains",
          "iDECODe framework",
          "Inductive Conformal Anomaly Detection (ICAD)",
          "transformation-equivariance",
          "novel Non-Conformity Measure (NCM)",
          "novel aggregation method",
          "bounded false detection rate (FDR)",
          "theoretical guarantees",
          "state-of-the-art (SOTA) OOD detection",
          "adversarial example detection"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"**we propose the new method idecode**\", \"it relies on a **novel base non-conformity measure and a new aggregation method**\".\n*   the introduction reiterates: \"**in this paper, we propose idecode, a novel ood detection method**\".\n*   the paper discusses a \"technical problem\" (limitations of existing ood detection methods) and presents a \"proposed solution\" (idecode).\n*   while it also mentions \"demonstrate the efficacy of idecode by experiments\" (empirical), the core contribution highlighted is the *development and proposal of a new method*. the empirical evaluation serves to validate this new method.\n\ntherefore, the paper primarily fits the **technical** classification."
      },
      "file_name": "34d35e460b39edb19581ef345c4b32ce45aa9eae.pdf"
    },
    {
      "success": true,
      "doc_id": "26535d201776a2a0e1515e910efcc77e",
      "summary": "Here's a focused summary of the paper \\cite{zhang20212tb} for a literature review:\n\n### Technical Paper Analysis: Mixture Outlier Exposure: Towards Out-of-Distribution Detection in Fine-grained Environments \\cite{zhang20212tb}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addressing the challenge of Out-of-Distribution (OOD) detection in *fine-grained environments* for Deep Neural Network (DNN) recognition systems.\n    *   **Importance & Challenge**:\n        *   Many real-world DNN deployments (e.g., bird species, medical image classification) are inherently fine-grained.\n        *   OOD detection is crucial for safe and reliable AI systems.\n        *   The problem is particularly challenging because OOD inputs in these environments are often *highly granular* (e.g., a novel bird species) and share significant semantic/visual similarity with in-distribution (ID) data, making them difficult to distinguish.\n        *   Existing OOD detection methods, often evaluated on coarse-grained benchmarks, struggle significantly with these fine-grained OOD samples.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Builds upon methods that incorporate auxiliary outlier data during training, most closely related to Outlier Exposure (OE) \\cite{hendrycks2018deep}.\n        *   Differs from prior works that use mixing operations (e.g., Mixup \\cite{zhang2018mixup}, CutMix \\cite{yun2019cutmix}) by specifically applying them *between ID and outlier data* to construct a virtual outlier distribution, rather than solely within ID or outlier data.\n    *   **Limitations of Previous Solutions**:\n        *   Most state-of-the-art OOD detection methods (e.g., MSP \\cite{hendrycks2016baseline}, ODIN \\cite{liang2018enhancing}, Energy \\cite{liu2020energy}, OE \\cite{hendrycks2018deep}, OE-M \\cite{mohseni2020self}, EnergyOE \\cite{liu2020energy}) are shown to perform poorly on fine-grained OOD, often failing to outperform a simple baseline (MSP).\n        *   Methods utilizing auxiliary outlier data (OE-based) improve coarse-grained OOD detection but show limited impact on fine-grained OOD, as empirical outliers do not sufficiently cover the broad region where fine-grained OOD samples reside in the feature space.\n        *   Previous studies on fine-grained OOD detection were limited in scale (few ID classes) or made unrealistic assumptions (e.g., labeled outlier datasets overlapping with test OOD).\n        *   Mahalanobis detector \\cite{lee2018simple} was found to have scalability issues.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: **Mixture Outlier Exposure (MixOE)**.\n        *   **Virtual Outlier Generation**: MixOE generates \"virtual\" outlier samples by performing mixing operations (e.g., linear interpolation like Mixup \\cite{zhang2018mixup} or cut-paste like CutMix \\cite{yun2019cutmix}) between ID data and auxiliary training outlier data.\n        *   **Expanded Coverage**: These mixed samples span a broader region in the DNN's feature space, effectively covering areas both near to and far away from ID clusters, where fine-grained OOD samples are often located.\n        *   **Training Objective**: The model is trained such that its prediction confidence *linearly decays* as the input transitions from ID to OOD. This explicitly regularizes the model's behavior across a spectrum of OOD granularities.\n    *   **Novelty/Difference**:\n        *   Explicitly targets OOD detection in fine-grained environments, which was largely underexplored.\n        *   Introduces a novel way of leveraging mixing operations to create a comprehensive \"virtual\" outlier distribution by mixing ID and *outlier* data, rather than just ID data or just outlier data.\n        *   The linear decay of confidence provides a smooth regularization from ID to OOD, enabling detection of both coarse- and fine-grained OOD.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of **Mixture Outlier Exposure (MixOE)**, a training algorithm that uses mixed ID and outlier samples to induce regularization over a larger OOD region.\n    *   **System Design/Architectural Innovations**: The methodology focuses on a novel training procedure rather than architectural changes, enhancing existing DNNs for OOD detection.\n    *   **Theoretical Insights/Analysis**: Empirical analysis demonstrating that fine-grained OOD samples span a broader region and are closer to ID clusters in feature space, and that standard outlier exposure fails to cover this region. MixOE's design directly addresses this observation.\n    *   **Benchmarking**: Construction of four large-scale, fine-grained test environments (from FGVC-Aircraft, Stanford Cars, Butterfly, North American Birds datasets) to facilitate future research and provide realistic evaluation.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Initial evaluation of six state-of-the-art OOD detectors (MSP, ODIN, Energy, OE, OE-M, EnergyOE, Rotation) on the newly constructed fine-grained benchmarks.\n        *   Extensive experiments comparing MixOE against these baselines on the four fine-grained datasets (Aircraft, Car, Butterfly, Bird) for both fine-grained and coarse-grained OOD detection.\n        *   Ablation studies to understand the contribution of different components of MixOE (e.g., choice of mixing operation, mixing strategy).\n    *   **Key Performance Metrics**: True Negative Rate at 95% True Positive Rate (TNR95) and Area Under the Receiver Operating Characteristic curve (AUROC). TNR95 is highlighted as a more discriminative metric.\n    *   **Comparison Results**:\n        *   Existing methods struggle significantly with fine-grained OOD, with TNR95 often dropping below 30% on most datasets, even for methods using auxiliary outlier data.\n        *   MixOE consistently achieves notable improvements across all four benchmarks.\n        *   Crucially, MixOE demonstrates significant effectiveness against *fine-grained OOD*, where few current methods have any impact, while also maintaining competitive performance on coarse-grained OOD.\n        *   The visualization of feature spaces confirms that MixOE's mixed samples effectively cover the regions where fine-grained OOD data reside, unlike empirical outliers alone.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The current implementation of mixing operations uses simple pixel-level methods (linear interpolation, cut-paste), though the framework allows for more complex operations.\n        *   The method assumes the availability of auxiliary outlier data for training.\n    *   **Scope of Applicability**: Primarily focused on fine-grained *visual classification* tasks. The constructed benchmarks are derived from fine-grained visual classification (FGVC) datasets.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{zhang20212tb} significantly advances OOD detection by providing a robust solution for the challenging and previously underexplored domain of fine-grained environments. It moves beyond coarse-grained OOD detection, which is often insufficient for real-world applications.\n    *   **Potential Impact on Future Research**:\n        *   The constructed large-scale fine-grained benchmarks provide a crucial resource for future research in this area.\n        *   MixOE's approach of generating virtual outliers by mixing ID and outlier data, coupled with a confidence decay objective, offers a novel paradigm for OOD regularization.\n        *   Opens avenues for exploring more sophisticated mixing operations and further understanding the geometry of OOD data in feature spaces.\n        *   Contributes to building more reliable and safer DNN systems in complex, open-world scenarios.",
      "intriguing_abstract": "Deep Neural Networks face a critical challenge in Out-of-Distribution (OOD) detection, particularly in fine-grained environments like medical diagnostics or species identification. Existing methods falter because fine-grained OOD samples are often highly granular and semantically similar to in-distribution data, making them notoriously difficult to distinguish and posing significant safety risks for real-world AI deployments.\n\nWe introduce **Mixture Outlier Exposure (MixOE)**, a novel training paradigm that robustly addresses this underexplored problem. MixOE innovatively generates \"virtual\" outlier samples by performing mixing operations between in-distribution data and auxiliary outlier data, effectively expanding the model's understanding of the OOD feature space. This unique approach, coupled with a training objective that enforces a linear decay of prediction confidence from in-distribution to OOD, allows the model to learn a more comprehensive and nuanced OOD boundary. Evaluated on four newly constructed, large-scale fine-grained benchmarks, MixOE significantly outperforms state-of-the-art OOD detectors, achieving substantial gains in metrics like TNR95 and AUROC. This work represents a critical step towards building safer and more reliable AI systems capable of operating effectively in complex, open-world fine-grained scenarios.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "fine-grained environments",
        "Deep Neural Networks (DNNs)",
        "Mixture Outlier Exposure (MixOE)",
        "virtual outlier generation",
        "ID-outlier mixing operations",
        "linear confidence decay",
        "feature space regularization",
        "fine-grained visual classification",
        "large-scale fine-grained benchmarks",
        "OOD detection challenges",
        "reliable AI systems"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/7bdc1a737a8864b80c7abd5cca71c6514de25345.pdf",
      "citation_key": "zhang20212tb",
      "metadata": {
        "title": "Mixture Outlier Exposure: Towards Out-of-Distribution Detection in Fine-grained Environments",
        "authors": [
          "Jingyang Zhang",
          "Nathan Inkawhich",
          "Randolph Linderman",
          "Yiran Chen",
          "H. Li"
        ],
        "published_date": "2021",
        "abstract": "Many real-world scenarios in which DNN-based recognition systems are deployed have inherently fine-grained attributes (e.g., bird-species recognition, medical image classification). In addition to achieving reliable accuracy, a critical subtask for these models is to detect Out-of-distribution (OOD) inputs. Given the nature of the deployment environment, one may expect such OOD inputs to also be fine-grained w.r.t. the known classes (e.g., a novel bird species), which are thus extremely difficult to identify. Unfortunately, OOD detection in fine-grained scenarios remains largely underexplored. In this work, we aim to fill this gap by first carefully constructing four large-scale fine-grained test environments, in which existing methods are shown to have difficulties. Particularly, we find that even explicitly incorporating a diverse set of auxiliary outlier data during training does not provide sufficient coverage over the broad region where fine-grained OOD samples locate. We then propose Mixture Outlier Exposure (MixOE), which mixes ID data and training outliers to expand the coverage of different OOD granularities, and trains the model such that the prediction confidence linearly decays as the input transitions from ID to OOD. Extensive experiments and analyses demonstrate the effectiveness of MixOE for building up OOD detector in finegrained environments. The code is available at https://github.com/zjysteven/MixOE.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/7bdc1a737a8864b80c7abd5cca71c6514de25345.pdf",
        "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
        "citationCount": 65,
        "score": 16.25,
        "summary": "Here's a focused summary of the paper \\cite{zhang20212tb} for a literature review:\n\n### Technical Paper Analysis: Mixture Outlier Exposure: Towards Out-of-Distribution Detection in Fine-grained Environments \\cite{zhang20212tb}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addressing the challenge of Out-of-Distribution (OOD) detection in *fine-grained environments* for Deep Neural Network (DNN) recognition systems.\n    *   **Importance & Challenge**:\n        *   Many real-world DNN deployments (e.g., bird species, medical image classification) are inherently fine-grained.\n        *   OOD detection is crucial for safe and reliable AI systems.\n        *   The problem is particularly challenging because OOD inputs in these environments are often *highly granular* (e.g., a novel bird species) and share significant semantic/visual similarity with in-distribution (ID) data, making them difficult to distinguish.\n        *   Existing OOD detection methods, often evaluated on coarse-grained benchmarks, struggle significantly with these fine-grained OOD samples.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Builds upon methods that incorporate auxiliary outlier data during training, most closely related to Outlier Exposure (OE) \\cite{hendrycks2018deep}.\n        *   Differs from prior works that use mixing operations (e.g., Mixup \\cite{zhang2018mixup}, CutMix \\cite{yun2019cutmix}) by specifically applying them *between ID and outlier data* to construct a virtual outlier distribution, rather than solely within ID or outlier data.\n    *   **Limitations of Previous Solutions**:\n        *   Most state-of-the-art OOD detection methods (e.g., MSP \\cite{hendrycks2016baseline}, ODIN \\cite{liang2018enhancing}, Energy \\cite{liu2020energy}, OE \\cite{hendrycks2018deep}, OE-M \\cite{mohseni2020self}, EnergyOE \\cite{liu2020energy}) are shown to perform poorly on fine-grained OOD, often failing to outperform a simple baseline (MSP).\n        *   Methods utilizing auxiliary outlier data (OE-based) improve coarse-grained OOD detection but show limited impact on fine-grained OOD, as empirical outliers do not sufficiently cover the broad region where fine-grained OOD samples reside in the feature space.\n        *   Previous studies on fine-grained OOD detection were limited in scale (few ID classes) or made unrealistic assumptions (e.g., labeled outlier datasets overlapping with test OOD).\n        *   Mahalanobis detector \\cite{lee2018simple} was found to have scalability issues.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: **Mixture Outlier Exposure (MixOE)**.\n        *   **Virtual Outlier Generation**: MixOE generates \"virtual\" outlier samples by performing mixing operations (e.g., linear interpolation like Mixup \\cite{zhang2018mixup} or cut-paste like CutMix \\cite{yun2019cutmix}) between ID data and auxiliary training outlier data.\n        *   **Expanded Coverage**: These mixed samples span a broader region in the DNN's feature space, effectively covering areas both near to and far away from ID clusters, where fine-grained OOD samples are often located.\n        *   **Training Objective**: The model is trained such that its prediction confidence *linearly decays* as the input transitions from ID to OOD. This explicitly regularizes the model's behavior across a spectrum of OOD granularities.\n    *   **Novelty/Difference**:\n        *   Explicitly targets OOD detection in fine-grained environments, which was largely underexplored.\n        *   Introduces a novel way of leveraging mixing operations to create a comprehensive \"virtual\" outlier distribution by mixing ID and *outlier* data, rather than just ID data or just outlier data.\n        *   The linear decay of confidence provides a smooth regularization from ID to OOD, enabling detection of both coarse- and fine-grained OOD.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of **Mixture Outlier Exposure (MixOE)**, a training algorithm that uses mixed ID and outlier samples to induce regularization over a larger OOD region.\n    *   **System Design/Architectural Innovations**: The methodology focuses on a novel training procedure rather than architectural changes, enhancing existing DNNs for OOD detection.\n    *   **Theoretical Insights/Analysis**: Empirical analysis demonstrating that fine-grained OOD samples span a broader region and are closer to ID clusters in feature space, and that standard outlier exposure fails to cover this region. MixOE's design directly addresses this observation.\n    *   **Benchmarking**: Construction of four large-scale, fine-grained test environments (from FGVC-Aircraft, Stanford Cars, Butterfly, North American Birds datasets) to facilitate future research and provide realistic evaluation.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Initial evaluation of six state-of-the-art OOD detectors (MSP, ODIN, Energy, OE, OE-M, EnergyOE, Rotation) on the newly constructed fine-grained benchmarks.\n        *   Extensive experiments comparing MixOE against these baselines on the four fine-grained datasets (Aircraft, Car, Butterfly, Bird) for both fine-grained and coarse-grained OOD detection.\n        *   Ablation studies to understand the contribution of different components of MixOE (e.g., choice of mixing operation, mixing strategy).\n    *   **Key Performance Metrics**: True Negative Rate at 95% True Positive Rate (TNR95) and Area Under the Receiver Operating Characteristic curve (AUROC). TNR95 is highlighted as a more discriminative metric.\n    *   **Comparison Results**:\n        *   Existing methods struggle significantly with fine-grained OOD, with TNR95 often dropping below 30% on most datasets, even for methods using auxiliary outlier data.\n        *   MixOE consistently achieves notable improvements across all four benchmarks.\n        *   Crucially, MixOE demonstrates significant effectiveness against *fine-grained OOD*, where few current methods have any impact, while also maintaining competitive performance on coarse-grained OOD.\n        *   The visualization of feature spaces confirms that MixOE's mixed samples effectively cover the regions where fine-grained OOD data reside, unlike empirical outliers alone.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The current implementation of mixing operations uses simple pixel-level methods (linear interpolation, cut-paste), though the framework allows for more complex operations.\n        *   The method assumes the availability of auxiliary outlier data for training.\n    *   **Scope of Applicability**: Primarily focused on fine-grained *visual classification* tasks. The constructed benchmarks are derived from fine-grained visual classification (FGVC) datasets.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{zhang20212tb} significantly advances OOD detection by providing a robust solution for the challenging and previously underexplored domain of fine-grained environments. It moves beyond coarse-grained OOD detection, which is often insufficient for real-world applications.\n    *   **Potential Impact on Future Research**:\n        *   The constructed large-scale fine-grained benchmarks provide a crucial resource for future research in this area.\n        *   MixOE's approach of generating virtual outliers by mixing ID and outlier data, coupled with a confidence decay objective, offers a novel paradigm for OOD regularization.\n        *   Opens avenues for exploring more sophisticated mixing operations and further understanding the geometry of OOD data in feature spaces.\n        *   Contributes to building more reliable and safer DNN systems in complex, open-world scenarios.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "fine-grained environments",
          "Deep Neural Networks (DNNs)",
          "Mixture Outlier Exposure (MixOE)",
          "virtual outlier generation",
          "ID-outlier mixing operations",
          "linear confidence decay",
          "feature space regularization",
          "fine-grained visual classification",
          "large-scale fine-grained benchmarks",
          "OOD detection challenges",
          "reliable AI systems"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we then **propose** mixture outlier exposure (mixoe)...\" and describes its mechanism (\"which mixes id data and training outliers to expand the coverage... and trains the model such that the prediction confidence linearly decays...\").\n*   it also mentions \"extensive **experiments and analyses demonstrate the effectiveness of mixoe**\".\n*   the introduction sets up a technical problem (\"ood detection is particularly challenging in fine-grained scenarios\") and highlights a gap (\"ood detection in fine-grained environments remains largely underexplored\").\n\nthese points strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems. while it includes empirical evaluation, the core contribution is the proposed new method (mixoe).\n\n**classification: technical**"
      },
      "file_name": "7bdc1a737a8864b80c7abd5cca71c6514de25345.pdf"
    },
    {
      "success": true,
      "doc_id": "c11b02a2ddb2a9a37d95584e374624c0",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n---\n\n### Neural Mean Discrepancy for Efficient Out-of-Distribution Detection \\cite{dong2021swz}\n\n1.  **Research Problem & Motivation**\n    *   **Problem:** Deep Neural Networks (DNNs) operate under an Independent and Identically Distributed (i.i.d.) assumption, which is often violated in real-world deployments where Out-of-Distribution (OOD) examples are common. Detecting these OOD examples is crucial for reliable DNN deployment.\n    *   **Importance & Challenge:** The i.i.d. assumption is impractical. Existing OOD detection methods often incur significant computational overhead (e.g., model augmentation, fine-tuning, large batch sizes for kernel methods) or suffer from limited performance, making them challenging to deploy efficiently.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches:** Previous methods include augmenting models, input examples, training sets, and optimization objectives; enhancing DNN architectures or fine-tuning; and kernel density estimation or Integral Probability Metrics (IPMs) \\cite{dong2021swz}.\n    *   **Limitations of Previous Solutions:** Many methods incur significant computational and data processing overhead \\cite{dong2021swz}. Kernel-based and IPM-based methods often require large batch sizes (e.g., 50+) and numerous computation iterations, struggle with high-dimensional data, or fail to capture semantic information effectively \\cite{dong2021swz}.\n    *   **Positioning:** This work deviates by hypothesizing that standard off-the-shelf models already contain sufficient information about the training data distribution for reliable OOD detection, without requiring fine-tuning or complex augmentations \\cite{dong2021swz}. It leverages the DNN itself as an efficient and effective kernel for IPMs \\cite{dong2021swz}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:**\n        *   **Observation:** Empirical study revealed that activation means of OOD mini-batches consistently and clearly deviate more from those of the training data compared to in-distribution (ID) mini-batches \\cite{dong2021swz}.\n        *   **Neural Mean Discrepancy (NMD):** A novel metric that quantifies the difference between the neural means (average activations) of input examples and the training data, computed from specific channels across layers of an off-the-shelf model \\cite{dong2021swz}.\n        *   **Multi-layer NMD:** Combines NMDs from all channels across multiple layers to form a comprehensive NMD vector, capturing multi-level semantics and providing richer discriminatory power \\cite{dong2021swz}.\n        *   **\"Free Lunch\" from Batch Normalization (BN):** The running average mean stored in BN layers can be directly used to approximate the training data's neural mean, eliminating the need for explicit re-computation \\cite{dong2021swz}.\n        *   **Lightweight OOD Detector:** A simple parametric classifier (e.g., Logistic Regression or Multilayer Perceptron) is trained on the NMD vectors to predict OOD or ID, enhancing detection performance, especially for single-example detection \\cite{dong2021swz}.\n    *   **Novelty/Difference:**\n        *   Leverages the off-the-shelf DNN itself as an efficient kernel for IPMs, avoiding the need for separate kernel optimization, fine-tuning, or hyper-parameter search \\cite{dong2021swz}.\n        *   Achieves reliable OOD detection even with extremely small batch sizes (down to 1), a significant improvement over previous statistical/IPM methods \\cite{dong2021swz}.\n        *   Utilizes existing Batch Normalization layers to obtain training data statistics \"for free,\" greatly reducing computational overhead \\cite{dong2021swz}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Introduction of Neural Mean Discrepancy (NMD) as a simple, model-agnostic, and effective metric for OOD detection based on activation mean deviation \\cite{dong2021swz}.\n        *   A multi-layer NMD approach that combines channel-wise activation means from various depths of the DNN, enabling multi-scale OOD detection \\cite{dong2021swz}.\n        *   A lightweight, sensitivity-aware OOD detector that operates on NMD vectors, significantly boosting performance for single-example OOD detection \\cite{dong2021swz}.\n    *   **System Design/Architectural Innovations:**\n        *   A highly efficient pipeline that computes NMD via a standard forward pass of a pre-trained model, followed by a lightweight classifier, minimizing computational cost \\cite{dong2021swz}.\n        *   Innovative use of running averages from Batch Normalization layers to approximate training data statistics, providing a \"free lunch\" for NMD computation \\cite{dong2021swz}.\n    *   **Theoretical Insights/Analysis:**\n        *   Connects the empirical observation of activation mean deviation to Integral Probability Metrics (IPMs), framing the off-the-shelf DNN as an effective witness function \\cite{dong2021swz}.\n        *   Implicitly augments input batches by averaging across spatial positions within a channel, contributing to robust detection even with small batch sizes \\cite{dong2021swz}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Extensive evaluation across various datasets (CIFAR-10/100, SVHN, ImageNet, LSUN, iSUN, Texture) and OOD types (far- and near-OOD) \\cite{dong2021swz}.\n        *   Tested with diverse model architectures (ConvNet, ResNet, WideResNet, DenseNet, VGG, Vision Transformer) and pre-training types (supervised, self-supervised) \\cite{dong2021swz}.\n        *   Evaluated under different data access scenarios: Full access, Few-shot (25 ID/OOD examples), Zero-shot (ID only), and Transfer learning (trained on one OOD, tested on unseen OOD) \\cite{dong2021swz}.\n        *   Measured efficiency in terms of training cost and inference latency \\cite{dong2021swz}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Metrics:** True Negative Rate at 95% True Positive Rate (TNR95), Area Under the Receiver Operating Characteristic curve (AUROC), and Detection Accuracy (ACC) \\cite{dong2021swz}.\n        *   **Results:** NMD consistently outperforms state-of-the-art OOD approaches (e.g., ODIN, Energy-FT, Maha) in terms of both detection accuracy (AUROC, TNR95) and computational cost \\cite{dong2021swz}. It achieves superior performance even with small batch sizes (e.g., 99.9% AUROC with batch size 4 for the basic NMD, and state-of-the-art for single-example detection with the lightweight detector) \\cite{dong2021swz}. The training cost of the NMD detector is orders of magnitude faster, and inference latency is comparable to a standard forward pass \\cite{dong2021swz}. It demonstrates strong robustness and generalizability across various data circumstances \\cite{dong2021swz}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The \"free lunch\" from Batch Normalization relies on the presence of BN layers; for models without BN, training data's neural mean must be computed explicitly \\cite{dong2021swz}. The method assumes the pre-trained model has learned sufficient information about the in-distribution data.\n    *   **Scope of Applicability:** Applicable across a wide range of DNN architectures and pre-training types \\cite{dong2021swz}. Effective for both near-OOD and far-OOD tasks, and capable of robust detection even with single input examples \\cite{dong2021swz}.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art:** Provides a highly efficient and accurate OOD detection method that often surpasses existing techniques across diverse benchmarks and scenarios \\cite{dong2021swz}. It significantly reduces the computational overhead and data requirements, making OOD detection more practical for real-world deployment \\cite{dong2021swz}.\n    *   **Potential Impact on Future Research:** Challenges the need for extensive model modifications or fine-tuning for OOD detection, suggesting that intrinsic properties of pre-trained models are highly valuable \\cite{dong2021swz}. This could inspire further research into leveraging inherent model characteristics for various robustness tasks and facilitate the deployment of more reliable DNNs in critical applications \\cite{dong2021swz}.\n\n---",
      "intriguing_abstract": "Deep Neural Networks (DNNs) are notoriously brittle when encountering Out-of-Distribution (OOD) data, a critical challenge for real-world reliability. Existing OOD detection methods often demand significant computational overhead, extensive model fine-tuning, or large batch sizes, hindering practical deployment. We present a paradigm shift: **Neural Mean Discrepancy (NMD)**, a novel, highly efficient metric that leverages the intrinsic information already present in *off-the-shelf* pre-trained DNNs.\n\nNMD quantifies the deviation of input **activation means** from those of the training data, effectively transforming the DNN into an efficient kernel for **Integral Probability Metrics**. Our key innovation is a \"free lunch\" mechanism, utilizing the running averages stored in **Batch Normalization (BN)** layers to approximate training data statistics without any re-computation. This approach enables robust OOD detection with unprecedented efficiency, achieving state-of-the-art performance even with single-example inputs, a significant breakthrough for statistical methods. NMD consistently outperforms prior art across diverse architectures and OOD scenarios, drastically reducing computational cost and making reliable DNN deployment a practical reality. This work challenges the necessity for complex model augmentations, revealing the untapped potential within standard DNNs for enhanced robustness.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Deep Neural Networks (DNNs)",
        "Neural Mean Discrepancy (NMD)",
        "activation means",
        "Batch Normalization (BN) running averages",
        "computational efficiency",
        "small batch sizes",
        "off-the-shelf models",
        "Integral Probability Metrics (IPMs)",
        "lightweight OOD detector",
        "multi-layer NMD",
        "real-world DNN deployment",
        "state-of-the-art performance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/903966632e84a59ca49914ebbadbbfbfe84e7c29.pdf",
      "citation_key": "dong2021swz",
      "metadata": {
        "title": "Neural Mean Discrepancy for Efficient Out-of-Distribution Detection",
        "authors": [
          "Xin Dong",
          "Junfeng Guo",
          "Ang Li",
          "W. Ting",
          "Cong Liu",
          "H. Kung"
        ],
        "published_date": "2021",
        "abstract": "Various approaches have been proposed for out-of-distribution (OOD) detection by augmenting models, input examples, training sets, and optimization objectives. Deviating from existing work, we have a simple hypothesis that standard off-the-shelf models may already contain sufficient information about the training set distribution which can be leveraged for reliable OOD detection. Our empirical study on validating this hypothesis, which measures the model activation's mean for OOD and in-distribution (ID) minibatches, surprisingly finds that activation means of OOD mini-batches consistently deviate more from those of the training data. In addition, training data's activation means can be computed offline efficiently or retrieved from batch normalization layers as a â€˜free lunchâ€™. Based upon this observation, we propose a novel metric called Neural Mean Discrepancy (NMD), which compares neural means of the input examples and training data. Leveraging the simplicity of NMD, we propose an efficient OOD detector that computes neural means by a standard forward pass followed by a lightweight classifier. Extensive experiments show that NMD outperforms state-of-the-art OOD approaches across multiple datasets and model architectures in terms of both detection accuracy and computational cost.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/903966632e84a59ca49914ebbadbbfbfe84e7c29.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 65,
        "score": 16.25,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n---\n\n### Neural Mean Discrepancy for Efficient Out-of-Distribution Detection \\cite{dong2021swz}\n\n1.  **Research Problem & Motivation**\n    *   **Problem:** Deep Neural Networks (DNNs) operate under an Independent and Identically Distributed (i.i.d.) assumption, which is often violated in real-world deployments where Out-of-Distribution (OOD) examples are common. Detecting these OOD examples is crucial for reliable DNN deployment.\n    *   **Importance & Challenge:** The i.i.d. assumption is impractical. Existing OOD detection methods often incur significant computational overhead (e.g., model augmentation, fine-tuning, large batch sizes for kernel methods) or suffer from limited performance, making them challenging to deploy efficiently.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches:** Previous methods include augmenting models, input examples, training sets, and optimization objectives; enhancing DNN architectures or fine-tuning; and kernel density estimation or Integral Probability Metrics (IPMs) \\cite{dong2021swz}.\n    *   **Limitations of Previous Solutions:** Many methods incur significant computational and data processing overhead \\cite{dong2021swz}. Kernel-based and IPM-based methods often require large batch sizes (e.g., 50+) and numerous computation iterations, struggle with high-dimensional data, or fail to capture semantic information effectively \\cite{dong2021swz}.\n    *   **Positioning:** This work deviates by hypothesizing that standard off-the-shelf models already contain sufficient information about the training data distribution for reliable OOD detection, without requiring fine-tuning or complex augmentations \\cite{dong2021swz}. It leverages the DNN itself as an efficient and effective kernel for IPMs \\cite{dong2021swz}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:**\n        *   **Observation:** Empirical study revealed that activation means of OOD mini-batches consistently and clearly deviate more from those of the training data compared to in-distribution (ID) mini-batches \\cite{dong2021swz}.\n        *   **Neural Mean Discrepancy (NMD):** A novel metric that quantifies the difference between the neural means (average activations) of input examples and the training data, computed from specific channels across layers of an off-the-shelf model \\cite{dong2021swz}.\n        *   **Multi-layer NMD:** Combines NMDs from all channels across multiple layers to form a comprehensive NMD vector, capturing multi-level semantics and providing richer discriminatory power \\cite{dong2021swz}.\n        *   **\"Free Lunch\" from Batch Normalization (BN):** The running average mean stored in BN layers can be directly used to approximate the training data's neural mean, eliminating the need for explicit re-computation \\cite{dong2021swz}.\n        *   **Lightweight OOD Detector:** A simple parametric classifier (e.g., Logistic Regression or Multilayer Perceptron) is trained on the NMD vectors to predict OOD or ID, enhancing detection performance, especially for single-example detection \\cite{dong2021swz}.\n    *   **Novelty/Difference:**\n        *   Leverages the off-the-shelf DNN itself as an efficient kernel for IPMs, avoiding the need for separate kernel optimization, fine-tuning, or hyper-parameter search \\cite{dong2021swz}.\n        *   Achieves reliable OOD detection even with extremely small batch sizes (down to 1), a significant improvement over previous statistical/IPM methods \\cite{dong2021swz}.\n        *   Utilizes existing Batch Normalization layers to obtain training data statistics \"for free,\" greatly reducing computational overhead \\cite{dong2021swz}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Introduction of Neural Mean Discrepancy (NMD) as a simple, model-agnostic, and effective metric for OOD detection based on activation mean deviation \\cite{dong2021swz}.\n        *   A multi-layer NMD approach that combines channel-wise activation means from various depths of the DNN, enabling multi-scale OOD detection \\cite{dong2021swz}.\n        *   A lightweight, sensitivity-aware OOD detector that operates on NMD vectors, significantly boosting performance for single-example OOD detection \\cite{dong2021swz}.\n    *   **System Design/Architectural Innovations:**\n        *   A highly efficient pipeline that computes NMD via a standard forward pass of a pre-trained model, followed by a lightweight classifier, minimizing computational cost \\cite{dong2021swz}.\n        *   Innovative use of running averages from Batch Normalization layers to approximate training data statistics, providing a \"free lunch\" for NMD computation \\cite{dong2021swz}.\n    *   **Theoretical Insights/Analysis:**\n        *   Connects the empirical observation of activation mean deviation to Integral Probability Metrics (IPMs), framing the off-the-shelf DNN as an effective witness function \\cite{dong2021swz}.\n        *   Implicitly augments input batches by averaging across spatial positions within a channel, contributing to robust detection even with small batch sizes \\cite{dong2021swz}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Extensive evaluation across various datasets (CIFAR-10/100, SVHN, ImageNet, LSUN, iSUN, Texture) and OOD types (far- and near-OOD) \\cite{dong2021swz}.\n        *   Tested with diverse model architectures (ConvNet, ResNet, WideResNet, DenseNet, VGG, Vision Transformer) and pre-training types (supervised, self-supervised) \\cite{dong2021swz}.\n        *   Evaluated under different data access scenarios: Full access, Few-shot (25 ID/OOD examples), Zero-shot (ID only), and Transfer learning (trained on one OOD, tested on unseen OOD) \\cite{dong2021swz}.\n        *   Measured efficiency in terms of training cost and inference latency \\cite{dong2021swz}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Metrics:** True Negative Rate at 95% True Positive Rate (TNR95), Area Under the Receiver Operating Characteristic curve (AUROC), and Detection Accuracy (ACC) \\cite{dong2021swz}.\n        *   **Results:** NMD consistently outperforms state-of-the-art OOD approaches (e.g., ODIN, Energy-FT, Maha) in terms of both detection accuracy (AUROC, TNR95) and computational cost \\cite{dong2021swz}. It achieves superior performance even with small batch sizes (e.g., 99.9% AUROC with batch size 4 for the basic NMD, and state-of-the-art for single-example detection with the lightweight detector) \\cite{dong2021swz}. The training cost of the NMD detector is orders of magnitude faster, and inference latency is comparable to a standard forward pass \\cite{dong2021swz}. It demonstrates strong robustness and generalizability across various data circumstances \\cite{dong2021swz}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The \"free lunch\" from Batch Normalization relies on the presence of BN layers; for models without BN, training data's neural mean must be computed explicitly \\cite{dong2021swz}. The method assumes the pre-trained model has learned sufficient information about the in-distribution data.\n    *   **Scope of Applicability:** Applicable across a wide range of DNN architectures and pre-training types \\cite{dong2021swz}. Effective for both near-OOD and far-OOD tasks, and capable of robust detection even with single input examples \\cite{dong2021swz}.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art:** Provides a highly efficient and accurate OOD detection method that often surpasses existing techniques across diverse benchmarks and scenarios \\cite{dong2021swz}. It significantly reduces the computational overhead and data requirements, making OOD detection more practical for real-world deployment \\cite{dong2021swz}.\n    *   **Potential Impact on Future Research:** Challenges the need for extensive model modifications or fine-tuning for OOD detection, suggesting that intrinsic properties of pre-trained models are highly valuable \\cite{dong2021swz}. This could inspire further research into leveraging inherent model characteristics for various robustness tasks and facilitate the deployment of more reliable DNNs in critical applications \\cite{dong2021swz}.\n\n---",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Deep Neural Networks (DNNs)",
          "Neural Mean Discrepancy (NMD)",
          "activation means",
          "Batch Normalization (BN) running averages",
          "computational efficiency",
          "small batch sizes",
          "off-the-shelf models",
          "Integral Probability Metrics (IPMs)",
          "lightweight OOD detector",
          "multi-layer NMD",
          "real-world DNN deployment",
          "state-of-the-art performance"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n1.  **proposes a new method/metric:** the abstract explicitly states, \"we propose a novel metric called neural mean discrepancy (nmd)\" and \"we propose an efficient ood detector.\" this is a core characteristic of a technical paper.\n2.  **addresses a technical problem:** the introduction discusses the problem of out-of-distribution (ood) detection in deep neural networks and the limitations of existing approaches (computational overhead).\n3.  **presents a solution:** the paper introduces nmd and an ood detector as its proposed solution to this problem.\n4.  **empirical validation of the solution:** while the paper mentions an \"empirical study\" and \"extensive experiments,\" these are conducted to validate the *effectiveness* and *efficiency* of the *proposed* technical solution (nmd and the detector). the empirical work serves to support the technical contribution, rather than being the sole focus of studying an existing phenomenon. the title also emphasizes the new method: \"neural mean discrepancy for efficient out-of-distribution detection.\""
      },
      "file_name": "903966632e84a59ca49914ebbadbbfbfe84e7c29.pdf"
    },
    {
      "success": true,
      "doc_id": "de185a45f482186c7327aea2ffce4b17",
      "summary": "Here's a focused summary of the paper \\cite{cai2020lsi} for a literature review:\n\n---\n\n### Analysis of \\cite{cai2020lsi}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Efficiently detecting out-of-distribution (OOD) data in real-time within learning-enabled Cyber-Physical Systems (CPS) control systems.\n    *   **Importance and Challenge**:\n        *   Machine learning components (e.g., deep neural networks) in CPS introduce safety hazards because their behavior depends on runtime data that may differ from training data.\n        *   OOD data can lead to large errors, compromising system safety (e.g., in autonomous vehicles).\n        *   Detection must be robust (limiting false alarms), computationally efficient for real-time monitoring, and capable of handling high-dimensional sensor inputs (e.g., from cameras, LIDAR).\n        *   Traditional DNNs lack inherent capabilities to estimate if an input is in- or out-of-distribution.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Builds upon Conformal Prediction (CP) and Conformal Anomaly Detection (CAD), specifically Inductive Conformal Anomaly Detection (ICAD).\n        *   Relates to OOD detection in computer vision and mobile robotics.\n    *   **Limitations of Previous Solutions**:\n        *   Existing OOD detection techniques (e.g., in computer vision) often don't consider CPS dynamical behavior, can exhibit a large number of false alarms, and are not directly applicable to CPS.\n        *   Traditional CP/CAD methods (e.g., using k-Nearest Neighbors or Kernel Density Estimation for nonconformity measures) cannot scale efficiently to high-dimensional inputs common in CPS due to storage or computational demands.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The proposed approach leverages Inductive Conformal Prediction (ICP) and Inductive Conformal Anomaly Detection (ICAD) to provide a statistically sound framework for OOD detection with a well-calibrated false alarm rate.\n    *   **Novelty/Difference**:\n        *   To overcome the scalability limitations of traditional nonconformity measures for high-dimensional CPS inputs, \\cite{cai2020lsi} proposes using *learned models* based on **Variational Autoencoders (VAEs)** and **Deep Support Vector Data Description (SVDD)** to efficiently compute nonconformity scores.\n        *   **VAE-based nonconformity**: Utilizes the generative model (decoder) to sample IID examples from the latent space and uses reconstruction accuracy as a nonconformity measure, increasing detection robustness.\n        *   **Deep SVDD-based nonconformity**: Trains a deep neural network to map input data into a minimum-volume hypersphere, using the distance to the hypersphere's center as a nonconformity score. This is combined with a sliding window test for improved robustness.\n        *   The learned models encode the necessary information in their parameters, allowing real-time computation without storing the entire training dataset.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Integration of VAEs and Deep SVDD as efficient, learned nonconformity measures within the ICAD framework for high-dimensional inputs.\n        *   A robust detection mechanism for Deep SVDD that incorporates a sliding window test.\n    *   **System Design/Architectural Innovations**:\n        *   A real-time OOD detection method for learning-enabled CPS that can monitor inputs to perception or end-to-end control LECs.\n        *   The approach ensures a well-calibrated false alarm rate, a critical property for safety-critical CPS.\n    *   **Theoretical Insights/Analysis**:\n        *   Leverages the theoretical guarantees of ICAD, ensuring that the rate of detected conformal anomalies is well-calibrated (i.e., with high probability, it is less than or approximately equal to a predefined threshold `\\alpha`).\n        *   The use of martingales for online testing of p-value sequences to detect deviations from the exchangeability assumption.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The method was empirically evaluated using two realistic CPS scenarios implemented in CARLA, an open-source simulator for self-driving cars:\n        1.  **Advanced Emergency Braking System (AEBS)**: Uses a perception LEC to detect obstacles and estimate distance from camera images, feeding into a reinforcement learning controller.\n        2.  **Self-Driving End-to-End Controller (SDEC)**: A pre-existing CARLA controller.\n    *   **OOD Generation**:\n        *   For AEBS: OOD inputs were generated by varying a precipitation parameter in CARLA, introducing visual effects that cause large errors in distance estimation.\n        *   For SDEC: OOD inputs were simulated as physically realizable attacks (painted lines on the road) designed to cause the car to follow an unintended path.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **False Positives**: Demonstrated a \"very small number\" of false positives.\n        *   **Detection Delay**: Achieved a detection delay of \"less than 1 second\".\n        *   **Execution Time**: The execution time of the detection method was \"comparable to the execution time of the original machine learning components,\" demonstrating real-time applicability.\n        *   The method successfully detected OOD conditions in both AEBS (precipitation causing collision risk) and SDEC (physical attacks causing path deviation).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Relies on the exchangeability assumption for the data, which is weaker than IID but still an assumption about the data generation process.\n        *   While VAE and SVDD networks might exhibit different errors for OOD inputs, the robustness is improved by considering multiple input examples and comparing with calibration nonconformity scores.\n    *   **Scope of Applicability**:\n        *   Primarily focuses on OOD detection for high-dimensional inputs to DNNs and other learning-enabled components (LECs) in CPS.\n        *   The approach is generalizable to other LECs designed similarly.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**:\n        *   Provides a novel, robust, and computationally efficient solution for real-time OOD detection in safety-critical CPS, addressing a major challenge for the deployment of learning-enabled autonomy.\n        *   Overcomes the scalability issues of traditional conformal prediction methods for high-dimensional data by introducing learned nonconformity measures.\n        *   Offers a statistically sound approach with a guaranteed well-calibrated false alarm rate, which is crucial for trust and reliability in CPS.\n    *   **Potential Impact on Future Research**:\n        *   Enables safer integration of machine learning components into CPS by providing a runtime monitoring mechanism.\n        *   Facilitates decision-making in CPS when OOD conditions are detected (e.g., switching to a different control architecture or human supervision).\n        *   Opens avenues for further research into specialized learned nonconformity measures and their integration with formal verification techniques for CPS.",
      "intriguing_abstract": "The integration of machine learning into safety-critical Cyber-Physical Systems (CPS) presents a perilous frontier: the risk of out-of-distribution (OOD) data leading to catastrophic failures. Traditional OOD detection methods struggle with the real-time, high-dimensional demands of systems like autonomous vehicles, often sacrificing robustness or efficiency. This paper introduces a novel, statistically sound framework for real-time OOD detection in learning-enabled CPS, directly addressing these critical challenges.\n\nWe leverage Inductive Conformal Anomaly Detection (ICAD) and overcome its scalability limitations for high-dimensional inputs by proposing *learned nonconformity measures*. Specifically, we innovate by integrating Variational Autoencoders (VAEs) and Deep Support Vector Data Description (SVDD) to efficiently compute OOD scores. VAEs utilize reconstruction accuracy, while Deep SVDD maps data to a minimum-volume hypersphere, enhanced with a sliding window for robustness. This approach ensures a well-calibrated false alarm rate and real-time applicability, as validated in CARLA simulations for Advanced Emergency Braking Systems and end-to-end autonomous controllers. Our method significantly enhances the safety and trustworthiness of AI-driven CPS, paving the way for reliable deployment in complex, dynamic environments.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "Cyber-Physical Systems (CPS)",
        "Real-time monitoring",
        "Inductive Conformal Anomaly Detection (ICAD)",
        "Learned nonconformity measures",
        "Variational Autoencoders (VAEs)",
        "Deep Support Vector Data Description (Deep SVDD)",
        "High-dimensional inputs",
        "Well-calibrated false alarm rate",
        "Safety-critical systems",
        "Autonomous vehicles",
        "Scalability",
        "Sliding window test"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/ba39d83ec8b79f35d8195835f46cc4e36e5a4211.pdf",
      "citation_key": "cai2020lsi",
      "metadata": {
        "title": "Real-time Out-of-distribution Detection in Learning-Enabled Cyber-Physical Systems",
        "authors": [
          "Feiyang Cai",
          "X. Koutsoukos"
        ],
        "published_date": "2020",
        "abstract": "Cyber-physical systems (CPS) greatly benefit by using machine learning components that can handle the uncertainty and variability of the real-world. Typical components such as deep neural networks, however, introduce new types of hazards that may impact system safety. The system behavior depends on data that are available only during runtime and may be different than the data used for training. Out-of-distribution data may lead to a large error and compromise safety. The paper considers the problem of efficiently detecting out-of-distribution data in CPS control systems. Detection must be robust and limit the number of false alarms while being computational efficient for real-time monitoring. The proposed approach leverages inductive conformal prediction and anomaly detection for developing a method that has a well-calibrated false alarm rate. We use variational autoencoders and deep support vector data description to learn models that can be used efficiently compute the nonconformity of new inputs relative to the training set and enable realtime detection of out-of-distribution high-dimensional inputs. We demonstrate the method using an advanced emergency braking system and a self-driving end-to-end controller implemented in an open source simulator for self-driving cars. The simulation results show very small number of false positives and detection delay while the execution time is comparable to the execution time of the original machine learning components.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/ba39d83ec8b79f35d8195835f46cc4e36e5a4211.pdf",
        "venue": "International Conference on Cyber-Physical Systems",
        "citationCount": 80,
        "score": 16.0,
        "summary": "Here's a focused summary of the paper \\cite{cai2020lsi} for a literature review:\n\n---\n\n### Analysis of \\cite{cai2020lsi}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Efficiently detecting out-of-distribution (OOD) data in real-time within learning-enabled Cyber-Physical Systems (CPS) control systems.\n    *   **Importance and Challenge**:\n        *   Machine learning components (e.g., deep neural networks) in CPS introduce safety hazards because their behavior depends on runtime data that may differ from training data.\n        *   OOD data can lead to large errors, compromising system safety (e.g., in autonomous vehicles).\n        *   Detection must be robust (limiting false alarms), computationally efficient for real-time monitoring, and capable of handling high-dimensional sensor inputs (e.g., from cameras, LIDAR).\n        *   Traditional DNNs lack inherent capabilities to estimate if an input is in- or out-of-distribution.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Builds upon Conformal Prediction (CP) and Conformal Anomaly Detection (CAD), specifically Inductive Conformal Anomaly Detection (ICAD).\n        *   Relates to OOD detection in computer vision and mobile robotics.\n    *   **Limitations of Previous Solutions**:\n        *   Existing OOD detection techniques (e.g., in computer vision) often don't consider CPS dynamical behavior, can exhibit a large number of false alarms, and are not directly applicable to CPS.\n        *   Traditional CP/CAD methods (e.g., using k-Nearest Neighbors or Kernel Density Estimation for nonconformity measures) cannot scale efficiently to high-dimensional inputs common in CPS due to storage or computational demands.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The proposed approach leverages Inductive Conformal Prediction (ICP) and Inductive Conformal Anomaly Detection (ICAD) to provide a statistically sound framework for OOD detection with a well-calibrated false alarm rate.\n    *   **Novelty/Difference**:\n        *   To overcome the scalability limitations of traditional nonconformity measures for high-dimensional CPS inputs, \\cite{cai2020lsi} proposes using *learned models* based on **Variational Autoencoders (VAEs)** and **Deep Support Vector Data Description (SVDD)** to efficiently compute nonconformity scores.\n        *   **VAE-based nonconformity**: Utilizes the generative model (decoder) to sample IID examples from the latent space and uses reconstruction accuracy as a nonconformity measure, increasing detection robustness.\n        *   **Deep SVDD-based nonconformity**: Trains a deep neural network to map input data into a minimum-volume hypersphere, using the distance to the hypersphere's center as a nonconformity score. This is combined with a sliding window test for improved robustness.\n        *   The learned models encode the necessary information in their parameters, allowing real-time computation without storing the entire training dataset.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Integration of VAEs and Deep SVDD as efficient, learned nonconformity measures within the ICAD framework for high-dimensional inputs.\n        *   A robust detection mechanism for Deep SVDD that incorporates a sliding window test.\n    *   **System Design/Architectural Innovations**:\n        *   A real-time OOD detection method for learning-enabled CPS that can monitor inputs to perception or end-to-end control LECs.\n        *   The approach ensures a well-calibrated false alarm rate, a critical property for safety-critical CPS.\n    *   **Theoretical Insights/Analysis**:\n        *   Leverages the theoretical guarantees of ICAD, ensuring that the rate of detected conformal anomalies is well-calibrated (i.e., with high probability, it is less than or approximately equal to a predefined threshold `\\alpha`).\n        *   The use of martingales for online testing of p-value sequences to detect deviations from the exchangeability assumption.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The method was empirically evaluated using two realistic CPS scenarios implemented in CARLA, an open-source simulator for self-driving cars:\n        1.  **Advanced Emergency Braking System (AEBS)**: Uses a perception LEC to detect obstacles and estimate distance from camera images, feeding into a reinforcement learning controller.\n        2.  **Self-Driving End-to-End Controller (SDEC)**: A pre-existing CARLA controller.\n    *   **OOD Generation**:\n        *   For AEBS: OOD inputs were generated by varying a precipitation parameter in CARLA, introducing visual effects that cause large errors in distance estimation.\n        *   For SDEC: OOD inputs were simulated as physically realizable attacks (painted lines on the road) designed to cause the car to follow an unintended path.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **False Positives**: Demonstrated a \"very small number\" of false positives.\n        *   **Detection Delay**: Achieved a detection delay of \"less than 1 second\".\n        *   **Execution Time**: The execution time of the detection method was \"comparable to the execution time of the original machine learning components,\" demonstrating real-time applicability.\n        *   The method successfully detected OOD conditions in both AEBS (precipitation causing collision risk) and SDEC (physical attacks causing path deviation).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Relies on the exchangeability assumption for the data, which is weaker than IID but still an assumption about the data generation process.\n        *   While VAE and SVDD networks might exhibit different errors for OOD inputs, the robustness is improved by considering multiple input examples and comparing with calibration nonconformity scores.\n    *   **Scope of Applicability**:\n        *   Primarily focuses on OOD detection for high-dimensional inputs to DNNs and other learning-enabled components (LECs) in CPS.\n        *   The approach is generalizable to other LECs designed similarly.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**:\n        *   Provides a novel, robust, and computationally efficient solution for real-time OOD detection in safety-critical CPS, addressing a major challenge for the deployment of learning-enabled autonomy.\n        *   Overcomes the scalability issues of traditional conformal prediction methods for high-dimensional data by introducing learned nonconformity measures.\n        *   Offers a statistically sound approach with a guaranteed well-calibrated false alarm rate, which is crucial for trust and reliability in CPS.\n    *   **Potential Impact on Future Research**:\n        *   Enables safer integration of machine learning components into CPS by providing a runtime monitoring mechanism.\n        *   Facilitates decision-making in CPS when OOD conditions are detected (e.g., switching to a different control architecture or human supervision).\n        *   Opens avenues for further research into specialized learned nonconformity measures and their integration with formal verification techniques for CPS.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "Cyber-Physical Systems (CPS)",
          "Real-time monitoring",
          "Inductive Conformal Anomaly Detection (ICAD)",
          "Learned nonconformity measures",
          "Variational Autoencoders (VAEs)",
          "Deep Support Vector Data Description (Deep SVDD)",
          "High-dimensional inputs",
          "Well-calibrated false alarm rate",
          "Safety-critical systems",
          "Autonomous vehicles",
          "Scalability",
          "Sliding window test"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"the **proposed approach leverages** inductive conformal prediction and anomaly detection for **developing a method** that has a well-calibrated false alarm rate. **we use** variational autoencoders and deep support vector data description to **learn models**...\"\n*   the introduction (which seems to continue from the abstract) reiterates: \"...for **developing a method** that has a well-calibrated false alarm rate. **we use** variational autoencoders and deep support vector data description to **learn models**...\"\n*   it then describes the demonstration and results of this method: \"we **demonstrate the method** using an advanced emergency braking system... the simulation results show very small number of false positives...\"\n\nthese phrases strongly align with the criteria for a **technical** paper, which \"presents new methods, algorithms, or systems\" and discusses a \"technical problem, proposed solution.\" while there is an empirical evaluation, its purpose is to demonstrate and validate the *new method* being proposed, making the core contribution technical.\n\n**classification: technical**"
      },
      "file_name": "ba39d83ec8b79f35d8195835f46cc4e36e5a4211.pdf"
    },
    {
      "success": true,
      "doc_id": "b8f139553958a3542db8d59fd2d8416b",
      "summary": "Remote sensing deals with a plethora of sensors, a large number of classes/categories, and a huge variation in geography. Owing to the difficulty of collecting labeled data uniformly representing all scenarios, data-hungry deep learning models are often trained with labeled data in a source domain that is limited in the above-mentioned aspects. However during test/inference phase, such deep learning models are often subjected to a distributional shift, also called out-of-distribution (OOD) samples, in the form of unseen classes, geographic differences, and multi-sensor differences. Deep learning models can behave in an unexpected manner when subjected to such distributional uncertainties. Vulnerability to OOD data severely reduces the reliability of deep learning models and trusting on such predictions in absence of any reliability indicator may lead to wrong policy decisions or mishaps in time-bound remote sensing applications. Motivated by this, in this work, we propose a Dirichlet Prior Network-based model to quantify distributional uncertainty of deep learning-based remote sensing models. The approach seeks to maximize the representation gap between the in-domain and OOD examples for better segregation of OOD samples at test time. Extensive experiments on several remote sensing image classification data sets demonstrate that the proposed model can quantify distributional uncertainty. To the best of our knowledge this is the first work to elaborately study distributional uncertainty in context of remote sensing. The codes are publicly available at.",
      "intriguing_abstract": "Remote sensing deals with a plethora of sensors, a large number of classes/categories, and a huge variation in geography. Owing to the difficulty of collecting labeled data uniformly representing all scenarios, data-hungry deep learning models are often trained with labeled data in a source domain that is limited in the above-mentioned aspects. However during test/inference phase, such deep learning models are often subjected to a distributional shift, also called out-of-distribution (OOD) samples, in the form of unseen classes, geographic differences, and multi-sensor differences. Deep learning models can behave in an unexpected manner when subjected to such distributional uncertainties. Vulnerability to OOD data severely reduces the reliability of deep learning models and trusting on such predictions in absence of any reliability indicator may lead to wrong policy decisions or mishaps in time-bound remote sensing applications. Motivated by this, in this work, we propose a Dirichlet Prior Network-based model to quantify distributional uncertainty of deep learning-based remote sensing models. The approach seeks to maximize the representation gap between the in-domain and OOD examples for better segregation of OOD samples at test time. Extensive experiments on several remote sensing image classification data sets demonstrate that the proposed model can quantify distributional uncertainty. To the best of our knowledge this is the first work to elaborately study distributional uncertainty in context of remote sensing. The codes are publicly available at.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/b9bf34d2ab4666d042a0a949bfefdfee617d002f.pdf",
      "citation_key": "gawlikowski2022p4r",
      "metadata": {
        "title": "An Advanced Dirichlet Prior Network for Out-of-Distribution Detection in Remote Sensing",
        "authors": [
          "J. Gawlikowski",
          "Sudipan Saha",
          "Anna M. Kruspe",
          "Xiao Xiang Zhu"
        ],
        "published_date": "2022",
        "abstract": "Remote sensing deals with a plethora of sensors, a large number of classes/categories, and a huge variation in geography. Owing to the difficulty of collecting labeled data uniformly representing all scenarios, data-hungry deep learning models are often trained with labeled data in a source domain that is limited in the above-mentioned aspects. However during test/inference phase, such deep learning models are often subjected to a distributional shift, also called out-of-distribution (OOD) samples, in the form of unseen classes, geographic differences, and multi-sensor differences. Deep learning models can behave in an unexpected manner when subjected to such distributional uncertainties. Vulnerability to OOD data severely reduces the reliability of deep learning models and trusting on such predictions in absence of any reliability indicator may lead to wrong policy decisions or mishaps in time-bound remote sensing applications. Motivated by this, in this work, we propose a Dirichlet Prior Network-based model to quantify distributional uncertainty of deep learning-based remote sensing models. The approach seeks to maximize the representation gap between the in-domain and OOD examples for better segregation of OOD samples at test time. Extensive experiments on several remote sensing image classification data sets demonstrate that the proposed model can quantify distributional uncertainty. To the best of our knowledge this is the first work to elaborately study distributional uncertainty in context of remote sensing. The codes are publicly available at.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b9bf34d2ab4666d042a0a949bfefdfee617d002f.pdf",
        "venue": "IEEE Transactions on Geoscience and Remote Sensing",
        "citationCount": 47,
        "score": 15.666666666666666,
        "summary": "Remote sensing deals with a plethora of sensors, a large number of classes/categories, and a huge variation in geography. Owing to the difficulty of collecting labeled data uniformly representing all scenarios, data-hungry deep learning models are often trained with labeled data in a source domain that is limited in the above-mentioned aspects. However during test/inference phase, such deep learning models are often subjected to a distributional shift, also called out-of-distribution (OOD) samples, in the form of unseen classes, geographic differences, and multi-sensor differences. Deep learning models can behave in an unexpected manner when subjected to such distributional uncertainties. Vulnerability to OOD data severely reduces the reliability of deep learning models and trusting on such predictions in absence of any reliability indicator may lead to wrong policy decisions or mishaps in time-bound remote sensing applications. Motivated by this, in this work, we propose a Dirichlet Prior Network-based model to quantify distributional uncertainty of deep learning-based remote sensing models. The approach seeks to maximize the representation gap between the in-domain and OOD examples for better segregation of OOD samples at test time. Extensive experiments on several remote sensing image classification data sets demonstrate that the proposed model can quantify distributional uncertainty. To the best of our knowledge this is the first work to elaborately study distributional uncertainty in context of remote sensing. The codes are publicly available at.",
        "keywords": []
      },
      "file_name": "b9bf34d2ab4666d042a0a949bfefdfee617d002f.pdf"
    },
    {
      "success": true,
      "doc_id": "2c61adb827fee6a62300a5186cbe8e9a",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/71ea4fce29a64843f1c3de747e1b4cb31bb2bedc.pdf",
      "citation_key": "paper2020kkd",
      "metadata": {
        "title": "Hyperparameter-Free Out-of-Distribution Detection Using Cosine Similarity",
        "authors": [],
        "published_date": "2020",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/71ea4fce29a64843f1c3de747e1b4cb31bb2bedc.pdf",
        "venue": "Asian Conference on Computer Vision",
        "citationCount": 74,
        "score": 14.8,
        "summary": "",
        "keywords": []
      },
      "file_name": "71ea4fce29a64843f1c3de747e1b4cb31bb2bedc.pdf"
    },
    {
      "success": true,
      "doc_id": "6699617999854ccd6ba0b14254c7f326",
      "summary": "Machine Learning models based on Deep Neural Networks behave unpredictably when presented with inputs that do not stem from the training distribution and sometimes make egregiously wrong predictions with high confidence. This property undermines the trustworthiness of systems depending on such models and potentially threatens the safety of their users. Out-of-Distribution (OOD) detection mechanisms can be used to prevent errors by detecting inputs that are so dissimilar from the training set that the model can not be expected to make reliable predictions. In this paper, we present PyTorch-OOD, a Python library for OOD detection based on PyTorch. Its primary goals are to accelerate OOD detection research and improve the reproducibility and comparability of experiments. PyTorch-OOD provides well-tested and documented implementations of OOD detection methods with a unified interface, as well as training and benchmark datasets, architectures, pre-trained models, and utility functions. The library is available online 1 under the permissive Apache 2.0 license and can be installed via Python Package Index (PyPI).",
      "intriguing_abstract": "Machine Learning models based on Deep Neural Networks behave unpredictably when presented with inputs that do not stem from the training distribution and sometimes make egregiously wrong predictions with high confidence. This property undermines the trustworthiness of systems depending on such models and potentially threatens the safety of their users. Out-of-Distribution (OOD) detection mechanisms can be used to prevent errors by detecting inputs that are so dissimilar from the training set that the model can not be expected to make reliable predictions. In this paper, we present PyTorch-OOD, a Python library for OOD detection based on PyTorch. Its primary goals are to accelerate OOD detection research and improve the reproducibility and comparability of experiments. PyTorch-OOD provides well-tested and documented implementations of OOD detection methods with a unified interface, as well as training and benchmark datasets, architectures, pre-trained models, and utility functions. The library is available online 1 under the permissive Apache 2.0 license and can be installed via Python Package Index (PyPI).",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/fb1dd165f12c7cf03dd75bfd7d96a755674a09bc.pdf",
      "citation_key": "kirchheim20229jl",
      "metadata": {
        "title": "PyTorch-OOD: A Library for Out-of-Distribution Detection based on PyTorch",
        "authors": [
          "Konstantin Kirchheim",
          "Marco Filax",
          "F. Ortmeier"
        ],
        "published_date": "2022",
        "abstract": "Machine Learning models based on Deep Neural Networks behave unpredictably when presented with inputs that do not stem from the training distribution and sometimes make egregiously wrong predictions with high confidence. This property undermines the trustworthiness of systems depending on such models and potentially threatens the safety of their users. Out-of-Distribution (OOD) detection mechanisms can be used to prevent errors by detecting inputs that are so dissimilar from the training set that the model can not be expected to make reliable predictions. In this paper, we present PyTorch-OOD, a Python library for OOD detection based on PyTorch. Its primary goals are to accelerate OOD detection research and improve the reproducibility and comparability of experiments. PyTorch-OOD provides well-tested and documented implementations of OOD detection methods with a unified interface, as well as training and benchmark datasets, architectures, pre-trained models, and utility functions. The library is available online 1 under the permissive Apache 2.0 license and can be installed via Python Package Index (PyPI).",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/fb1dd165f12c7cf03dd75bfd7d96a755674a09bc.pdf",
        "venue": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
        "citationCount": 43,
        "score": 14.333333333333332,
        "summary": "Machine Learning models based on Deep Neural Networks behave unpredictably when presented with inputs that do not stem from the training distribution and sometimes make egregiously wrong predictions with high confidence. This property undermines the trustworthiness of systems depending on such models and potentially threatens the safety of their users. Out-of-Distribution (OOD) detection mechanisms can be used to prevent errors by detecting inputs that are so dissimilar from the training set that the model can not be expected to make reliable predictions. In this paper, we present PyTorch-OOD, a Python library for OOD detection based on PyTorch. Its primary goals are to accelerate OOD detection research and improve the reproducibility and comparability of experiments. PyTorch-OOD provides well-tested and documented implementations of OOD detection methods with a unified interface, as well as training and benchmark datasets, architectures, pre-trained models, and utility functions. The library is available online 1 under the permissive Apache 2.0 license and can be installed via Python Package Index (PyPI).",
        "keywords": []
      },
      "file_name": "fb1dd165f12c7cf03dd75bfd7d96a755674a09bc.pdf"
    },
    {
      "success": true,
      "doc_id": "ddf9cac87a7c034d3ce60019b017fb6b",
      "summary": "This paper, \"A Survey on Out-of-Distribution Detection in NLP\" by Lang et al., provides the first comprehensive review of OOD detection specifically tailored for Natural Language Processing.\n\nHere's a focused summary for literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addresses the critical challenge of Out-of-Distribution (OOD) detection in Natural Language Processing (NLP) systems. This involves identifying samples during deployment that originate from distributions not encountered during the training phase \\cite{lang20237w3}. The primary focus is on *semantic shifts*, where OOD samples come from unknown categories with different label spaces.\n    *   **Importance and Challenge**: NLP models are typically built under a \"closed-world assumption\" (training and testing data from the same distribution), which is often violated in real-world \"open-world\" deployments. For instance, dialogue systems encounter an endless variety of user inputs, including unsupported intents. Reliable and safe NLP systems must not only perform well on In-Distribution (ID) samples but also accurately detect OOD samples for proper handling. Even large language models (LLMs) require OOD detection as the world and tasks constantly evolve beyond their knowledge cut-off dates. Applying OOD detection to NLP presents unique challenges due to discrete input spaces, complex output structures, and the need to consider contextual information \\cite{lang20237w3}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work positions itself as the *first comprehensive survey* specifically on OOD detection in NLP \\cite{lang20237w3}.\n    *   **Limitations of Previous Solutions**: While surveys exist for OOD generalization (Wang et al., 2022) and OOD detection in computer vision (Yang et al., 2021), a dedicated and comprehensive review for NLP was lacking. Previous work did not thoroughly discuss NLP-specific considerations like discrete inputs, complex output structures, and contextual information.\n    *   **Distinction from Related Fields**: The paper formally distinguishes OOD detection from related areas:\n        *   **Domain Generalization (DG) / Domain Adaptation (DA)**: These focus on *non-semantic shifts* (same label space, different input distributions), whereas OOD detection handles *semantic shifts* (different label spaces).\n        *   **Zero-shot Learning**: Aims to *classify* unseen classes, while OOD detection primarily needs to *detect* them without necessarily assigning a specific label.\n        *   **Meta-learning, Positive-unlabeled Learning, Transfer Learning**: While ideas from these fields can be leveraged, OOD detection has distinct objectives.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: As a survey, the core \"method\" is a novel categorization and comprehensive review of existing OOD detection algorithms in NLP.\n    *   **Novelty**:\n        *   Proposes a novel taxonomy for OOD detection methods based on the availability of OOD data during training: (1) OOD data available (extensive or few), (2) OOD data unavailable + ID label available, and (3) OOD data unavailable + ID label unavailable \\cite{lang20237w3}.\n        *   Identifies and discusses specific differences and considerations for OOD detection in NLP compared to computer vision.\n        *   Systematically reviews datasets, applications, metrics, and future research directions pertinent to OOD detection in NLP.\n\n4.  **Key Technical Contributions**\n    *   **Novel Taxonomy and Categorization**:\n        *   **OOD Data Available**:\n            *   *Extensive OOD Data*: Approaches include formulating OOD detection as a (K+1)-way or binary classification problem, and using outlier exposure (OE) loss to encourage uniform or high-entropy predictions for OOD samples \\cite{lang20237w3}.\n            *   *Few OOD Data*: Focuses on generating pseudo-OOD samples, for example, from auxiliary datasets or through adversarial perturbations in the latent space \\cite{lang20237w3}.\n        *   **OOD Data Unavailable + ID Label Available**: This is a major research focus.\n            *   *Learn Representations Then Detect*: Involves a representation extractor and an OOD scoring function.\n                *   **Representation Learning**: Emphasizes the efficacy of pre-trained transformer models (e.g., BERT, RoBERTa) due to diverse corpora and self-supervised training, noting that better-calibrated models generally yield higher OOD detection performance. Fine-tuning strategies include large margin cosine loss (LMCL), semantic-enhanced Gaussian mixture models, and various contrastive learning schemes (supervised, margin-based, self-supervised, KNN-based, reassigned) to increase inter-class discrepancy and mitigate over-confidence. Regularized fine-tuning (e.g., off-manifold regularization, domain-regularized modules) also addresses over-confidence \\cite{lang20237w3}.\n                *   **OOD Scoring**:\n                    *   *Output-based*: Maximum Softmax Probability (MSP), temperature scaling, K-vs-rest Sigmoid classifiers, and energy scores \\cite{lang20237w3}.\n                    *   *Feature-based*: Utilizes features from intermediate layers with methods like nearest-neighbor distances (e.g., Mahalanobis distance, non-parametric KNN), local outlier factor, adaptive decision boundaries (ADB), and averaging token representations \\cite{lang20237w3}. For conditional language generation, it includes calculating distances to a background model in feature space.\n                    *   *Ensemble-based*: Leverages predictive uncertainty from multiple models (e.g., dropout-based Bayesian approximation, deep ensembles, heterogeneous ensembles) \\cite{lang20237w3}.\n            *   *Generate Pseudo OOD Samples*: Acknowledges this as a strategy to overcome the lack of OOD training data.\n\n5.  **Experimental Validation**\n    *   As a survey, the paper synthesizes findings from existing literature rather than presenting new experimental results.\n    *   It highlights empirical observations from other works:\n        *   Pre-trained models (e.g., transformers) consistently outperform other representation extractors (bag-of-words, ConvNets, LSTMs) for OOD detection \\cite{lang20237w3}.\n        *   Better-calibrated models generally lead to higher OOD detection performance, with larger pre-trained models often being better calibrated \\cite{lang20237w3}.\n        *   Recent findings suggest that pre-trained models *without* fine-tuning on ID data can sometimes outperform fine-tuned counterparts when there's a significant distribution difference between ID and OOD data \\cite{lang20237w3}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The survey primarily focuses on detecting OOD samples with *semantic shifts* (where the label space changes), acknowledging but not deeply exploring non-semantic shifts (domain, sub-population, style changes) \\cite{lang20237w3}. The provided excerpt does not extensively detail methods for the \"OOD data unavailable + ID label unavailable\" category.\n    *   **Scope of Applicability**: The scope is strictly limited to OOD detection within *Natural Language Processing*, emphasizing its unique challenges and solutions compared to other domains like computer vision.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: Provides the first structured and comprehensive overview of OOD detection in NLP, consolidating diverse research and highlighting NLP-specific challenges and advancements. This serves as a foundational resource for the field \\cite{lang20237w3}.\n    *   **Potential Impact**:\n        *   Offers a valuable taxonomy that can guide future research and development in OOD detection for NLP.\n        *   Clarifies the distinctions and specific requirements for OOD detection in NLP versus other domains.\n        *   Summarizes key datasets, applications, and evaluation metrics, facilitating standardized research.\n        *   Crucially contributes to the development of more reliable, robust, and safe NLP systems, especially as LLMs become more prevalent in open-world applications \\cite{lang20237w3}.",
      "intriguing_abstract": "The pervasive \"closed-world assumption\" in NLP models crumbles in real-world \"open-world\" deployments, demanding robust solutions for Out-of-Distribution (OOD) detection. This paper presents the first comprehensive survey specifically tailored to OOD detection in Natural Language Processing, addressing the critical challenge of identifying samples from unknown categories or \"semantic shifts.\" We unveil a novel taxonomy, categorizing methods based on OOD data availability during training: extensive, few-shot, or unavailable.\n\nOur review delves into NLP-specific complexities like discrete inputs and contextual information, highlighting advancements in representation learning using pre-trained transformers, contrastive learning, and diverse OOD scoring techniques (output-based, feature-based, ensemble-based). We synthesize empirical insights, emphasizing the role of model calibration and the surprising efficacy of non-fine-tuned transformers in certain OOD scenarios. This foundational work clarifies distinctions from related fields and provides a vital roadmap for developing safer, more reliable NLP systems, particularly crucial for the evolving landscape of Large Language Models facing ever-new tasks and knowledge gaps. It serves as an indispensable resource for researchers aiming to build truly adaptive and resilient AI.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Natural Language Processing (NLP)",
        "semantic shifts",
        "comprehensive survey",
        "novel taxonomy",
        "pre-trained transformer models",
        "representation learning",
        "OOD scoring functions",
        "model calibration",
        "open-world deployment",
        "Large Language Models (LLMs)",
        "reliable and safe NLP systems",
        "outlier exposure",
        "contrastive learning"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/dcfca93185c49811ec6cf7c995eea58cf88c7bb3.pdf",
      "citation_key": "lang20237w3",
      "metadata": {
        "title": "A Survey on Out-of-Distribution Detection in NLP",
        "authors": [
          "Hao Lang",
          "Yinhe Zheng",
          "Yixuan Li",
          "Jian Sun",
          "Feiling Huang",
          "Yongbin Li"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection is essential for the reliable and safe deployment of machine learning systems in the real world. Great progress has been made over the past years. This paper presents the first review of recent advances in OOD detection with a particular focus on natural language processing approaches. First, we provide a formal definition of OOD detection and discuss several related fields. We then categorize recent algorithms into three classes according to the data they used: (1) OOD data available, (2) OOD data unavailable + in-distribution (ID) label available, and (3) OOD data unavailable + ID label unavailable. Third, we introduce datasets, applications, and metrics. Finally, we summarize existing work and present potential future research topics.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/dcfca93185c49811ec6cf7c995eea58cf88c7bb3.pdf",
        "venue": "Trans. Mach. Learn. Res.",
        "citationCount": 27,
        "score": 13.5,
        "summary": "This paper, \"A Survey on Out-of-Distribution Detection in NLP\" by Lang et al., provides the first comprehensive review of OOD detection specifically tailored for Natural Language Processing.\n\nHere's a focused summary for literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addresses the critical challenge of Out-of-Distribution (OOD) detection in Natural Language Processing (NLP) systems. This involves identifying samples during deployment that originate from distributions not encountered during the training phase \\cite{lang20237w3}. The primary focus is on *semantic shifts*, where OOD samples come from unknown categories with different label spaces.\n    *   **Importance and Challenge**: NLP models are typically built under a \"closed-world assumption\" (training and testing data from the same distribution), which is often violated in real-world \"open-world\" deployments. For instance, dialogue systems encounter an endless variety of user inputs, including unsupported intents. Reliable and safe NLP systems must not only perform well on In-Distribution (ID) samples but also accurately detect OOD samples for proper handling. Even large language models (LLMs) require OOD detection as the world and tasks constantly evolve beyond their knowledge cut-off dates. Applying OOD detection to NLP presents unique challenges due to discrete input spaces, complex output structures, and the need to consider contextual information \\cite{lang20237w3}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work positions itself as the *first comprehensive survey* specifically on OOD detection in NLP \\cite{lang20237w3}.\n    *   **Limitations of Previous Solutions**: While surveys exist for OOD generalization (Wang et al., 2022) and OOD detection in computer vision (Yang et al., 2021), a dedicated and comprehensive review for NLP was lacking. Previous work did not thoroughly discuss NLP-specific considerations like discrete inputs, complex output structures, and contextual information.\n    *   **Distinction from Related Fields**: The paper formally distinguishes OOD detection from related areas:\n        *   **Domain Generalization (DG) / Domain Adaptation (DA)**: These focus on *non-semantic shifts* (same label space, different input distributions), whereas OOD detection handles *semantic shifts* (different label spaces).\n        *   **Zero-shot Learning**: Aims to *classify* unseen classes, while OOD detection primarily needs to *detect* them without necessarily assigning a specific label.\n        *   **Meta-learning, Positive-unlabeled Learning, Transfer Learning**: While ideas from these fields can be leveraged, OOD detection has distinct objectives.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: As a survey, the core \"method\" is a novel categorization and comprehensive review of existing OOD detection algorithms in NLP.\n    *   **Novelty**:\n        *   Proposes a novel taxonomy for OOD detection methods based on the availability of OOD data during training: (1) OOD data available (extensive or few), (2) OOD data unavailable + ID label available, and (3) OOD data unavailable + ID label unavailable \\cite{lang20237w3}.\n        *   Identifies and discusses specific differences and considerations for OOD detection in NLP compared to computer vision.\n        *   Systematically reviews datasets, applications, metrics, and future research directions pertinent to OOD detection in NLP.\n\n4.  **Key Technical Contributions**\n    *   **Novel Taxonomy and Categorization**:\n        *   **OOD Data Available**:\n            *   *Extensive OOD Data*: Approaches include formulating OOD detection as a (K+1)-way or binary classification problem, and using outlier exposure (OE) loss to encourage uniform or high-entropy predictions for OOD samples \\cite{lang20237w3}.\n            *   *Few OOD Data*: Focuses on generating pseudo-OOD samples, for example, from auxiliary datasets or through adversarial perturbations in the latent space \\cite{lang20237w3}.\n        *   **OOD Data Unavailable + ID Label Available**: This is a major research focus.\n            *   *Learn Representations Then Detect*: Involves a representation extractor and an OOD scoring function.\n                *   **Representation Learning**: Emphasizes the efficacy of pre-trained transformer models (e.g., BERT, RoBERTa) due to diverse corpora and self-supervised training, noting that better-calibrated models generally yield higher OOD detection performance. Fine-tuning strategies include large margin cosine loss (LMCL), semantic-enhanced Gaussian mixture models, and various contrastive learning schemes (supervised, margin-based, self-supervised, KNN-based, reassigned) to increase inter-class discrepancy and mitigate over-confidence. Regularized fine-tuning (e.g., off-manifold regularization, domain-regularized modules) also addresses over-confidence \\cite{lang20237w3}.\n                *   **OOD Scoring**:\n                    *   *Output-based*: Maximum Softmax Probability (MSP), temperature scaling, K-vs-rest Sigmoid classifiers, and energy scores \\cite{lang20237w3}.\n                    *   *Feature-based*: Utilizes features from intermediate layers with methods like nearest-neighbor distances (e.g., Mahalanobis distance, non-parametric KNN), local outlier factor, adaptive decision boundaries (ADB), and averaging token representations \\cite{lang20237w3}. For conditional language generation, it includes calculating distances to a background model in feature space.\n                    *   *Ensemble-based*: Leverages predictive uncertainty from multiple models (e.g., dropout-based Bayesian approximation, deep ensembles, heterogeneous ensembles) \\cite{lang20237w3}.\n            *   *Generate Pseudo OOD Samples*: Acknowledges this as a strategy to overcome the lack of OOD training data.\n\n5.  **Experimental Validation**\n    *   As a survey, the paper synthesizes findings from existing literature rather than presenting new experimental results.\n    *   It highlights empirical observations from other works:\n        *   Pre-trained models (e.g., transformers) consistently outperform other representation extractors (bag-of-words, ConvNets, LSTMs) for OOD detection \\cite{lang20237w3}.\n        *   Better-calibrated models generally lead to higher OOD detection performance, with larger pre-trained models often being better calibrated \\cite{lang20237w3}.\n        *   Recent findings suggest that pre-trained models *without* fine-tuning on ID data can sometimes outperform fine-tuned counterparts when there's a significant distribution difference between ID and OOD data \\cite{lang20237w3}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The survey primarily focuses on detecting OOD samples with *semantic shifts* (where the label space changes), acknowledging but not deeply exploring non-semantic shifts (domain, sub-population, style changes) \\cite{lang20237w3}. The provided excerpt does not extensively detail methods for the \"OOD data unavailable + ID label unavailable\" category.\n    *   **Scope of Applicability**: The scope is strictly limited to OOD detection within *Natural Language Processing*, emphasizing its unique challenges and solutions compared to other domains like computer vision.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: Provides the first structured and comprehensive overview of OOD detection in NLP, consolidating diverse research and highlighting NLP-specific challenges and advancements. This serves as a foundational resource for the field \\cite{lang20237w3}.\n    *   **Potential Impact**:\n        *   Offers a valuable taxonomy that can guide future research and development in OOD detection for NLP.\n        *   Clarifies the distinctions and specific requirements for OOD detection in NLP versus other domains.\n        *   Summarizes key datasets, applications, and evaluation metrics, facilitating standardized research.\n        *   Crucially contributes to the development of more reliable, robust, and safe NLP systems, especially as LLMs become more prevalent in open-world applications \\cite{lang20237w3}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Natural Language Processing (NLP)",
          "semantic shifts",
          "comprehensive survey",
          "novel taxonomy",
          "pre-trained transformer models",
          "representation learning",
          "OOD scoring functions",
          "model calibration",
          "open-world deployment",
          "Large Language Models (LLMs)",
          "reliable and safe NLP systems",
          "outlier exposure",
          "contrastive learning"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the **abstract** explicitly states: \"this paper presents the first **review** of recent advances in ood detection...\" it also mentions providing a \"formal definition,\" \"categorize recent algorithms,\" \"introduce datasets, applications, and metrics,\" and \"summarize existing work and present potential future research topics.\" these are all strong indicators of a survey paper.\n*   the **introduction** sets the context for the problem of ood detection in nlp, explaining its importance and challenges, which is typical for a survey introducing the field it will review.\n\nthese elements directly align with the criteria for a **survey** paper:\n*   abstract mentions: \"review\", \"comprehensive analysis\" (implied by categorization and summary), \"state-of-the-art\" (implied by \"recent advances\").\n*   introduction discusses: literature organization (implied by categorization in abstract), classification schemes (explicitly mentioned in abstract: \"categorize recent algorithms into three classes\").\n\ntherefore, the paper is a: **survey**"
      },
      "file_name": "dcfca93185c49811ec6cf7c995eea58cf88c7bb3.pdf"
    },
    {
      "success": true,
      "doc_id": "bacebe132c62f49e04d21325863ed5f2",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of detecting out-of-distribution (OOD) inputs during the inference stage of neural networks \\cite{yu2022egq}.\n    *   This problem is important for safely deploying neural networks in real-world applications (e.g., autonomous cars, medical diagnosis), where encountering unseen inputs can lead to dangerous consequences if not recognized as \"unknown\" \\cite{yu2022egq}.\n    *   The challenge lies in effectively distinguishing inputs semantically or non-semantically different from the training data (in-distribution, ID) using a scoring function \\cite{yu2022egq}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods commonly rely on network outputs like softmax probability \\cite{yu2022egq}, calibrated probability \\cite{yu2022egq}, or energy scores \\cite{yu2022egq}, often derived from highly activated feature maps, typically from the last block.\n    *   The paper positions itself by revealing a limitation: the last block of neural networks can suffer from an \"overconfidence issue,\" where OOD images might highly activate its filters (large norm), making ID and OOD separation difficult \\cite{yu2022egq}. In contrast, the norm of feature maps from *earlier* blocks (e.g., penultimate) can be more separable for ID and OOD \\cite{yu2022egq}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a simple, effective OOD detection framework consisting of `FeatureNorm` and `NormRatio` \\cite{yu2022egq}.\n    *   **`FeatureNorm`**: This is defined as the channel-wise averaged L2-norm of the rectified feature map from a specific block, serving as an indicator of the activation level for a given image \\cite{yu2022egq}.\n    *   **`NormRatio`**: This is a ratio of `FeatureNorm` for ID and pseudo OOD samples, used to measure a block's suitability for OOD detection \\cite{yu2022egq}. A suitable block will exhibit a large `FeatureNorm` for ID and a small one for OOD.\n    *   **Block Selection**: To select the optimal block without access to real OOD data, the framework generates \"pseudo OOD\" images by creating Jigsaw puzzles from ID training samples \\cite{yu2022egq}. `NormRatio` is then calculated for all blocks using these pseudo OODs, and the block yielding the largest `NormRatio` is selected \\cite{yu2022egq}.\n    *   **Inference**: During inference, the `FeatureNorm` from the selected block is used as the OOD score. If this score falls below a learned threshold, the input is classified as OOD \\cite{yu2022egq}.\n    *   This approach is novel because it is the first to explore and demonstrate the utility of feature map norms for OOD detection and introduces a practical, OOD-data-free method for selecting the most effective intermediate block \\cite{yu2022egq}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of `FeatureNorm` as a robust OOD indicator and `NormRatio` for quantifying block suitability \\cite{yu2022egq}.\n    *   **System Design/Architectural Innovations**: A framework for selecting the optimal convolutional block for OOD detection using pseudo OOD generated via Jigsaw puzzles, eliminating the need for real OOD data during development \\cite{yu2022egq}.\n    *   **Theoretical Insights/Analysis**: Empirical and theoretical analysis demonstrating that intermediate blocks, rather than just the last block, can provide superior OOD separation due to the \"overconfidence\" issue in deeper layers \\cite{yu2022egq}.\n\n*   **Experimental Validation**\n    *   **Experiments**: Conducted on common OOD detection benchmarks using CIFAR10 (ID) with SVHN, Textures, LSUN(c/r), iSUN, Places365 (OOD), and ImageNet (ID) with iNaturalist, SUN, PLACES, Textures (OOD) \\cite{yu2022egq}.\n    *   **Architectures**: Evaluated across various CNNs including ResNet18, WRN28, VGG11 (for CIFAR10), and ResNet50, VGG16, MobileNetV3 (for ImageNet) \\cite{yu2022egq}.\n    *   **Metrics**: Performance was measured using AUROC (Area Under Receiver Operating Characteristic curve) and FPR95 (False Positive Rate at 95% True Positive Rate) \\cite{yu2022egq}.\n    *   **Comparison Results**:\n        *   The proposed `FeatureNorm` method consistently outperformed state-of-the-art post-hoc OOD detection methods (MSP, ODIN, Energy, Energy+ReAct, Energy+DICE) \\cite{yu2022egq}.\n        *   Achieved significant reductions in FPR95: up to 52.77% on CIFAR10 (WRN28) and up to 48.53% on ImageNet (VGG16) compared to the second-best baselines \\cite{yu2022egq}.\n        *   The selected blocks were consistently *not* the last block, supporting the paper's core observation (e.g., Block 4.1 for ResNet18, Layer 7 for VGG11, Block 4.2 for ResNet50) \\cite{yu2022egq}.\n        *   Demonstrated stronger performance on \"low complexity\" OOD datasets (SVHN, Textures, LSUN(c)) and \"far-OOD\" (Textures) \\cite{yu2022egq}.\n\n*   **Limitations & Scope**\n    *   The method showed less effectiveness on the ResNet50 architecture for ImageNet, which the authors attribute to the block structure with batch normalization potentially reducing the separation gap between ID and OOD samples \\cite{yu2022egq}.\n    *   Performance can vary depending on the complexity and semantic similarity of the OOD dataset to the ID data (e.g., weaker on Places365 for CIFAR10, which has similar complexity but is semantically shifted) \\cite{yu2022egq}.\n    *   The scope is limited to post-hoc OOD detection methods, meaning it does not modify the network training process \\cite{yu2022egq}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in post-hoc OOD detection by introducing a simple yet highly effective framework \\cite{yu2022egq}.\n    *   It challenges the conventional wisdom of relying solely on the last layer's output for OOD detection, highlighting the crucial role of intermediate feature representations \\cite{yu2022egq}.\n    *   The proposed block selection mechanism, utilizing pseudo OOD, offers a practical solution for deploying OOD detectors without requiring access to real OOD data during development \\cite{yu2022egq}.\n    *   The findings provide valuable insights into the behavior of different network layers concerning ID and OOD inputs, potentially guiding future research in designing more robust neural networks and OOD detection strategies \\cite{yu2022egq}.",
      "intriguing_abstract": "Ensuring the safe and reliable deployment of neural networks hinges on their ability to recognize out-of-distribution (OOD) inputs. Current post-hoc OOD detection methods often rely on outputs from the final network layers, which we reveal can suffer from an \"overconfidence issue,\" making ID and OOD separation challenging. This paper introduces a novel framework that leverages the often-overlooked discriminative power of *intermediate convolutional blocks*.\n\nWe propose `FeatureNorm`, the channel-wise L2-norm of rectified feature maps, as a robust OOD indicator. Crucially, we develop `NormRatio` and an innovative pseudo OOD generation strategy using Jigsaw puzzles to automatically select the optimal intermediate block *without requiring real OOD data*. Our empirical and theoretical analysis demonstrates that these earlier blocks offer superior OOD separation. Extensive experiments across diverse benchmarks and architectures show `FeatureNorm` consistently outperforms state-of-the-art methods, achieving significant FPR95 reductions (up to 52.77%). This work challenges conventional wisdom, providing a practical, highly effective solution for robust OOD detection and paving the way for safer AI systems.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "neural network inference",
        "FeatureNorm",
        "NormRatio",
        "feature map norms",
        "intermediate blocks",
        "overconfidence issue (neural networks)",
        "pseudo OOD generation via Jigsaw puzzles",
        "OOD-data-free block selection",
        "post-hoc OOD detection",
        "state-of-the-art performance",
        "real-world safety applications",
        "AUROC",
        "FPR95"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/7d826dfb184be983018590c64cfb4a79349472a4.pdf",
      "citation_key": "yu2022egq",
      "metadata": {
        "title": "Block Selection Method for Using Feature Norm in Out-of-Distribution Detection",
        "authors": [
          "Yeonguk Yu",
          "Sungho Shin",
          "Seongju Lee",
          "C. Jun",
          "Kyoobin Lee"
        ],
        "published_date": "2022",
        "abstract": "Detecting out-of-distribution (OOD) inputs during the inference stage is crucial for deploying neural networks in the real world. Previous methods typically relied on the highly activated feature map outputted by the network. In this study, we revealed that the norm of the feature map obtained from a block other than the last block can serve as a better indicator for OOD detection. To leverage this insight, we propose a simple framework that comprises two metrics: FeatureNorm, which computes the norm of the feature map, and NormRatio, which calculates the ratio of FeatureNorm for ID and OOD samples to evaluate the OOD detection performance of each block. To identify the block that provides the largest difference between FeatureNorm of ID and FeatureNorm of OOD, we create jigsaw puzzles as pseudo OOD from ID training samples and compute NormRatio, selecting the block with the highest value. After identifying the suitable block, OOD detection using FeatureNorm outperforms other methods by reducing FPR95 by up to 52.77% on CIFAR10 benchmark and up to 48.53% on ImageNet benchmark. We demonstrate that our framework can generalize to various architectures and highlight the significance of block selection, which can also improve previous OOD detection methods. Our code is available at https://github.com/gistailab/block-selection-for-OOD-detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/7d826dfb184be983018590c64cfb4a79349472a4.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 40,
        "score": 13.333333333333332,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of detecting out-of-distribution (OOD) inputs during the inference stage of neural networks \\cite{yu2022egq}.\n    *   This problem is important for safely deploying neural networks in real-world applications (e.g., autonomous cars, medical diagnosis), where encountering unseen inputs can lead to dangerous consequences if not recognized as \"unknown\" \\cite{yu2022egq}.\n    *   The challenge lies in effectively distinguishing inputs semantically or non-semantically different from the training data (in-distribution, ID) using a scoring function \\cite{yu2022egq}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods commonly rely on network outputs like softmax probability \\cite{yu2022egq}, calibrated probability \\cite{yu2022egq}, or energy scores \\cite{yu2022egq}, often derived from highly activated feature maps, typically from the last block.\n    *   The paper positions itself by revealing a limitation: the last block of neural networks can suffer from an \"overconfidence issue,\" where OOD images might highly activate its filters (large norm), making ID and OOD separation difficult \\cite{yu2022egq}. In contrast, the norm of feature maps from *earlier* blocks (e.g., penultimate) can be more separable for ID and OOD \\cite{yu2022egq}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a simple, effective OOD detection framework consisting of `FeatureNorm` and `NormRatio` \\cite{yu2022egq}.\n    *   **`FeatureNorm`**: This is defined as the channel-wise averaged L2-norm of the rectified feature map from a specific block, serving as an indicator of the activation level for a given image \\cite{yu2022egq}.\n    *   **`NormRatio`**: This is a ratio of `FeatureNorm` for ID and pseudo OOD samples, used to measure a block's suitability for OOD detection \\cite{yu2022egq}. A suitable block will exhibit a large `FeatureNorm` for ID and a small one for OOD.\n    *   **Block Selection**: To select the optimal block without access to real OOD data, the framework generates \"pseudo OOD\" images by creating Jigsaw puzzles from ID training samples \\cite{yu2022egq}. `NormRatio` is then calculated for all blocks using these pseudo OODs, and the block yielding the largest `NormRatio` is selected \\cite{yu2022egq}.\n    *   **Inference**: During inference, the `FeatureNorm` from the selected block is used as the OOD score. If this score falls below a learned threshold, the input is classified as OOD \\cite{yu2022egq}.\n    *   This approach is novel because it is the first to explore and demonstrate the utility of feature map norms for OOD detection and introduces a practical, OOD-data-free method for selecting the most effective intermediate block \\cite{yu2022egq}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of `FeatureNorm` as a robust OOD indicator and `NormRatio` for quantifying block suitability \\cite{yu2022egq}.\n    *   **System Design/Architectural Innovations**: A framework for selecting the optimal convolutional block for OOD detection using pseudo OOD generated via Jigsaw puzzles, eliminating the need for real OOD data during development \\cite{yu2022egq}.\n    *   **Theoretical Insights/Analysis**: Empirical and theoretical analysis demonstrating that intermediate blocks, rather than just the last block, can provide superior OOD separation due to the \"overconfidence\" issue in deeper layers \\cite{yu2022egq}.\n\n*   **Experimental Validation**\n    *   **Experiments**: Conducted on common OOD detection benchmarks using CIFAR10 (ID) with SVHN, Textures, LSUN(c/r), iSUN, Places365 (OOD), and ImageNet (ID) with iNaturalist, SUN, PLACES, Textures (OOD) \\cite{yu2022egq}.\n    *   **Architectures**: Evaluated across various CNNs including ResNet18, WRN28, VGG11 (for CIFAR10), and ResNet50, VGG16, MobileNetV3 (for ImageNet) \\cite{yu2022egq}.\n    *   **Metrics**: Performance was measured using AUROC (Area Under Receiver Operating Characteristic curve) and FPR95 (False Positive Rate at 95% True Positive Rate) \\cite{yu2022egq}.\n    *   **Comparison Results**:\n        *   The proposed `FeatureNorm` method consistently outperformed state-of-the-art post-hoc OOD detection methods (MSP, ODIN, Energy, Energy+ReAct, Energy+DICE) \\cite{yu2022egq}.\n        *   Achieved significant reductions in FPR95: up to 52.77% on CIFAR10 (WRN28) and up to 48.53% on ImageNet (VGG16) compared to the second-best baselines \\cite{yu2022egq}.\n        *   The selected blocks were consistently *not* the last block, supporting the paper's core observation (e.g., Block 4.1 for ResNet18, Layer 7 for VGG11, Block 4.2 for ResNet50) \\cite{yu2022egq}.\n        *   Demonstrated stronger performance on \"low complexity\" OOD datasets (SVHN, Textures, LSUN(c)) and \"far-OOD\" (Textures) \\cite{yu2022egq}.\n\n*   **Limitations & Scope**\n    *   The method showed less effectiveness on the ResNet50 architecture for ImageNet, which the authors attribute to the block structure with batch normalization potentially reducing the separation gap between ID and OOD samples \\cite{yu2022egq}.\n    *   Performance can vary depending on the complexity and semantic similarity of the OOD dataset to the ID data (e.g., weaker on Places365 for CIFAR10, which has similar complexity but is semantically shifted) \\cite{yu2022egq}.\n    *   The scope is limited to post-hoc OOD detection methods, meaning it does not modify the network training process \\cite{yu2022egq}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in post-hoc OOD detection by introducing a simple yet highly effective framework \\cite{yu2022egq}.\n    *   It challenges the conventional wisdom of relying solely on the last layer's output for OOD detection, highlighting the crucial role of intermediate feature representations \\cite{yu2022egq}.\n    *   The proposed block selection mechanism, utilizing pseudo OOD, offers a practical solution for deploying OOD detectors without requiring access to real OOD data during development \\cite{yu2022egq}.\n    *   The findings provide valuable insights into the behavior of different network layers concerning ID and OOD inputs, potentially guiding future research in designing more robust neural networks and OOD detection strategies \\cite{yu2022egq}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "neural network inference",
          "FeatureNorm",
          "NormRatio",
          "feature map norms",
          "intermediate blocks",
          "overconfidence issue (neural networks)",
          "pseudo OOD generation via Jigsaw puzzles",
          "OOD-data-free block selection",
          "post-hoc OOD detection",
          "state-of-the-art performance",
          "real-world safety applications",
          "AUROC",
          "FPR95"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we propose a simple framework consisting of featurenorm... and normratio...\" and describes the process of selecting a block. this indicates the development of a new method or system.\n*   the abstract also mentions \"outperforms other ood detection methods by reducing fpr95 by up to 52.77% on cifar10 benchmark and by up to 48.53% on imagenet benchmark,\" which are empirical results validating the proposed method.\n*   the introduction discusses a technical problem (ood detection) and sets the stage for a proposed solution.\n*   the title \"block selection method for using feature norm in out-of-distribution detection\" clearly points to a new method.\n\nwhile the paper includes significant empirical evaluation, its core contribution is the *proposal* and *description* of a new method/framework. the empirical results are used to demonstrate the effectiveness of this technical contribution.\n\ntherefore, the most appropriate classification is **technical**."
      },
      "file_name": "7d826dfb184be983018590c64cfb4a79349472a4.pdf"
    },
    {
      "success": true,
      "doc_id": "588e706ebbc3a8277220dcda16d88d15",
      "summary": "The Controller Area Network (CAN) is a ubiquitous bus protocol present in the Electrical/Electronic (E/E) systems of almost all vehicles. It is vulnerable to a range of attacks once the attacker gains access to the bus through the vehicleâ€™s attack surface. We address the problem of Intrusion Detection on the CAN bus and present a series of methods based on two classifiers trained with Auxiliary Classifier Generative Adversarial Network (ACGAN) to detect and assign fine-grained labels to Known Attacks and also detect the Unknown Attack class in a dataset containing a mixture of (Normal + Known Attacks + Unknown Attack) messages. The most effective method is a cascaded two-stage classification architecture, with the multi-class Auxiliary Classifier in the first stage for classification of Normal and Known Attacks, passing Out-of-Distribution (OOD) samples to the binary Real-Fake Classifier in the second stage for detection of the Unknown Attack class. Performance evaluation demonstrates that our method achieves both high classification accuracy and low runtime overhead, making it suitable for deployment in the resource-constrained in-vehicle environment.",
      "intriguing_abstract": "The Controller Area Network (CAN) is a ubiquitous bus protocol present in the Electrical/Electronic (E/E) systems of almost all vehicles. It is vulnerable to a range of attacks once the attacker gains access to the bus through the vehicleâ€™s attack surface. We address the problem of Intrusion Detection on the CAN bus and present a series of methods based on two classifiers trained with Auxiliary Classifier Generative Adversarial Network (ACGAN) to detect and assign fine-grained labels to Known Attacks and also detect the Unknown Attack class in a dataset containing a mixture of (Normal + Known Attacks + Unknown Attack) messages. The most effective method is a cascaded two-stage classification architecture, with the multi-class Auxiliary Classifier in the first stage for classification of Normal and Known Attacks, passing Out-of-Distribution (OOD) samples to the binary Real-Fake Classifier in the second stage for detection of the Unknown Attack class. Performance evaluation demonstrates that our method achieves both high classification accuracy and low runtime overhead, making it suitable for deployment in the resource-constrained in-vehicle environment.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/9b603cd88dd40a4982a145a0ca8cde03dbb18d20.pdf",
      "citation_key": "zhao20221ag",
      "metadata": {
        "title": "CAN Bus Intrusion Detection Based on Auxiliary Classifier GAN and Out-of-distribution Detection",
        "authors": [
          "Qingling Zhao",
          "Mingqiang Chen",
          "Zonghua Gu",
          "Siyu Luan",
          "Haibo Zeng",
          "Samarjit Chakrabory"
        ],
        "published_date": "2022",
        "abstract": "The Controller Area Network (CAN) is a ubiquitous bus protocol present in the Electrical/Electronic (E/E) systems of almost all vehicles. It is vulnerable to a range of attacks once the attacker gains access to the bus through the vehicleâ€™s attack surface. We address the problem of Intrusion Detection on the CAN bus and present a series of methods based on two classifiers trained with Auxiliary Classifier Generative Adversarial Network (ACGAN) to detect and assign fine-grained labels to Known Attacks and also detect the Unknown Attack class in a dataset containing a mixture of (Normal + Known Attacks + Unknown Attack) messages. The most effective method is a cascaded two-stage classification architecture, with the multi-class Auxiliary Classifier in the first stage for classification of Normal and Known Attacks, passing Out-of-Distribution (OOD) samples to the binary Real-Fake Classifier in the second stage for detection of the Unknown Attack class. Performance evaluation demonstrates that our method achieves both high classification accuracy and low runtime overhead, making it suitable for deployment in the resource-constrained in-vehicle environment.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/9b603cd88dd40a4982a145a0ca8cde03dbb18d20.pdf",
        "venue": "ACM Transactions on Embedded Computing Systems",
        "citationCount": 40,
        "score": 13.333333333333332,
        "summary": "The Controller Area Network (CAN) is a ubiquitous bus protocol present in the Electrical/Electronic (E/E) systems of almost all vehicles. It is vulnerable to a range of attacks once the attacker gains access to the bus through the vehicleâ€™s attack surface. We address the problem of Intrusion Detection on the CAN bus and present a series of methods based on two classifiers trained with Auxiliary Classifier Generative Adversarial Network (ACGAN) to detect and assign fine-grained labels to Known Attacks and also detect the Unknown Attack class in a dataset containing a mixture of (Normal + Known Attacks + Unknown Attack) messages. The most effective method is a cascaded two-stage classification architecture, with the multi-class Auxiliary Classifier in the first stage for classification of Normal and Known Attacks, passing Out-of-Distribution (OOD) samples to the binary Real-Fake Classifier in the second stage for detection of the Unknown Attack class. Performance evaluation demonstrates that our method achieves both high classification accuracy and low runtime overhead, making it suitable for deployment in the resource-constrained in-vehicle environment.",
        "keywords": []
      },
      "file_name": "9b603cd88dd40a4982a145a0ca8cde03dbb18d20.pdf"
    },
    {
      "success": true,
      "doc_id": "aceb52ec1ffeb2a07e66642c1a54d5a9",
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n### NECO: NEURAL COLLAPSE BASED OUT-OF-DISTRIBUTION DETECTION \\cite{ammar2023pr1}\n\n*   **Research Problem & Motivation**\n    *   **Problem**: Deep learning models exhibit unwarranted overconfidence when confronted with Out-of-Distribution (OOD) inputs, failing to recognize data outside their training distribution.\n    *   **Importance & Challenge**: This vulnerability poses significant safety implications in critical applications like medical imaging, industrial inspection, and autonomous driving, where models must not only classify known In-Distribution (ID) samples but also reliably flag OOD inputs as \"unknown.\" The challenge lies in developing effective, post-hoc OOD detection methods that do not alter the network training or harm performance.\n\n*   **Related Work & Positioning**\n    *   **Existing OOD Approaches**: The paper categorizes existing OOD detection methods into confidence-based (e.g., Softmax, Energy, ODIN), features/logits-based, and distance/density-based (e.g., Mahalanobis, nearest-neighbor). It specifically focuses on *post-hoc (unsupervised)* methods, which are desirable for seamless integration into production models without increased training cost.\n    *   **Neural Collapse (NC)**: Previous studies have identified \"Neural Collapse\" (NC) as a phenomenon in DNNs trained beyond loss convergence, characterized by within-class variability collapse (NC1), convergence of class means to a Simplex Equiangular Tight Frame (ETF) (NC2), self-duality (NC3), and simplification to nearest class-center classification (NC4).\n    *   **Limitations of Previous NC-OOD Work**: While Haas et al. (2023) demonstrated that collapsed models exhibit improved OOD detection, no prior work has directly leveraged the emergent geometric properties of NC for OOD detection.\n    *   **Positioning NECO**: NECO falls within the feature/logit-based post-hoc OOD methods. It relates to methods like NuSA and ViM, which also leverage principal/null spaces for OOD detection, but introduces a novel approach based on a newly observed NC property.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: NECO (NEural Collapse-based Out-of-distribution detection) is a novel post-hoc OOD detection method that leverages the geometric properties of Neural Collapse, particularly a newly identified property, and principal component spaces.\n    *   **Novel Observation (NC5)**: The paper introduces and empirically validates a novel property of Neural Collapse: **ID/OOD Orthogonality (NC5)**. This property states that as training progresses, OOD and ID data tend to become increasingly orthogonal to each other, meaning OOD data clusters become more perpendicular to the Simplex ETF configuration adopted by ID data. Mathematically, `âˆ€c,âŸ¨Âµc, ÂµOOD_GâŸ© / (âˆ¥Âµcâˆ¥2âˆ¥ÂµOOD_Gâˆ¥2) â†’ 0`.\n    *   **NECO Score Calculation**: Building on NC5, NECO computes an OOD score for a sample `x` by calculating the relative norm of its feature vector `hÏ‰(x)` within the subspace occupied by the Simplex ETF structure. This is achieved by projecting `hÏ‰(x)` onto the principal component space derived from the ID training data's feature covariance matrix.\n        *   `NECO(x) = âˆ¥P hÏ‰(x)âˆ¥ / âˆ¥hÏ‰(x)âˆ¥ = sqrt(hÏ‰(x)âŠ¤ PPâŠ¤ hÏ‰(x)) / sqrt(hÏ‰(x)âŠ¤ hÏ‰(x))`\n        *   Here, `P` is the projection matrix onto the `d` principal components extracted from the ID data's feature space `H`.\n    *   **Innovation over Related Work**: Unlike NuSA and ViM, which identify and utilize the *null space* (the component of the feature vector that does not directly impact classification) for OOD detection, NECO directly leverages the *principal component space* of the ID data. The hypothesis is that if NC1, NC2, and NC5 hold, OOD data, being orthogonal to ID data, will have a near-null projection onto the ID-derived principal space, while ID data will have a significant projection.\n\n*   **Key Technical Contributions**\n    *   **Novel Theoretical Insight**: Introduction and empirical validation of the **ID/OOD Orthogonality (NC5)** property of Neural Collapse, demonstrating that OOD data becomes increasingly orthogonal to ID data's class means during the Terminal Phase of Training.\n    *   **Novel Algorithm/Method**: Proposal of **NECO**, a straightforward yet highly efficient post-hoc OOD detection method that directly leverages the geometric implications of Neural Collapse and the principal component space of ID data.\n    *   **Theoretical Analysis**: The paper provides a theoretical explanation for the effectiveness of NECO in OOD detection, linking its mechanism to the established and newly proposed NC properties.\n\n*   **Experimental Validation**\n    *   **Validation of NC5**: Experiments were conducted to validate the ID/OOD orthogonality (NC5) using CIFAR-10 as the ID dataset and CIFAR-100/SVHN as OOD datasets, employing ResNet-18 and ViT architectures. Results (Figure 1) show the `OrthoDev classes âˆ’OOD` metric consistently decreasing towards zero, confirming the convergence to ID/OOD orthogonality during training.\n    *   **NECO Performance**: The abstract states that NECO achieves **state-of-the-art results** on both small and large-scale OOD detection tasks.\n    *   **Generalization**: NECO exhibits **strong generalization capabilities** across different network architectures, including ResNet-18 on CIFAR10/CIFAR100 and Vision Transformer (ViT) networks on ImageNet-1K.\n    *   **Key Metrics**: While specific metrics are not detailed in the provided text, OOD detection performance is typically evaluated using metrics like AUROC, AUPR, and FPR@95%TPR.\n\n*   **Limitations & Scope**\n    *   **Scope**: The method is specifically designed as a *post-hoc (unsupervised)* OOD detection approach, meaning it does not require modifications to the network training procedure or access to OOD samples during training.\n    *   **Technical Limitations/Assumptions**: The effectiveness of NECO relies on the assumption that the underlying DNN exhibits Neural Collapse properties (NC1, NC2) and the newly proposed ID/OOD orthogonality (NC5). The paper does not explicitly state other technical limitations in the provided text.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: NECO advances the technical state-of-the-art in post-hoc OOD detection by introducing a novel, theoretically grounded approach that leverages the intrinsic geometric properties of deep neural networks during their terminal training phase.\n    *   **Impact on Future Research**: The discovery and empirical validation of ID/OOD orthogonality (NC5) provide a new fundamental insight into DNN behavior in the presence of OOD data, potentially opening new avenues for research in OOD detection, robustness, and understanding deep learning generalization. Its simplicity and efficiency make it a promising candidate for integration into safety-critical applications.",
      "intriguing_abstract": "Deep learning models excel at known tasks, yet their unwarranted overconfidence when encountering Out-of-Distribution (OOD) inputs poses a critical safety challenge in autonomous systems and medical diagnostics. This paper unveils a profound geometric property of deep neural networks during their terminal training phase: **ID/OOD Orthogonality (NC5)**. We empirically demonstrate that as Neural Collapse (NC) progresses, OOD data becomes increasingly orthogonal to the Simplex Equiangular Tight Frame (ETF) formed by In-Distribution (ID) class means.\n\nLeveraging this novel insight, we introduce **NECO** (NEural Collapse-based Out-of-distribution detection), a simple, efficient, and powerful *post-hoc* OOD detection method. NECO calculates an OOD score by projecting a sample's feature vector onto the principal component space derived from ID training data. This unique approach, distinct from null-space methods, posits that OOD samples, due to NC5, will exhibit a near-null projection onto this ID-centric subspace.\n\nNECO achieves **state-of-the-art performance** across various architectures (ResNet, ViT) and scales (CIFAR, ImageNet-1K), showcasing strong generalization. Our work not only provides a new fundamental understanding of DNN behavior but also offers a robust, theoretically grounded solution crucial for deploying trustworthy AI in safety-critical applications.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Neural Collapse (NC)",
        "ID/OOD Orthogonality (NC5)",
        "NECO (NEural Collapse-based OOD detection)",
        "Post-hoc OOD detection",
        "Geometric properties of Neural Collapse",
        "Principal component space",
        "State-of-the-art OOD detection",
        "Safety-critical applications",
        "Deep learning models",
        "Simplex Equiangular Tight Frame (ETF)",
        "Strong generalization",
        "Terminal Phase of Training",
        "Feature covariance matrix"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/ff29bf27e1c4e95c4eec448ed1d4adfa81983302.pdf",
      "citation_key": "ammar2023pr1",
      "metadata": {
        "title": "NECO: NEural Collapse Based Out-of-distribution detection",
        "authors": [
          "Mouin Ben Ammar",
          "Nacim Belkhir",
          "Sebastian Popescu",
          "Antoine Manzanera",
          "Gianni Franchi"
        ],
        "published_date": "2023",
        "abstract": "Detecting out-of-distribution (OOD) data is a critical challenge in machine learning due to model overconfidence, often without awareness of their epistemological limits. We hypothesize that ``neural collapse'', a phenomenon affecting in-distribution data for models trained beyond loss convergence, also influences OOD data. To benefit from this interplay, we introduce NECO, a novel post-hoc method for OOD detection, which leverages the geometric properties of ``neural collapse'' and of principal component spaces to identify OOD data. Our extensive experiments demonstrate that NECO achieves state-of-the-art results on both small and large-scale OOD detection tasks while exhibiting strong generalization capabilities across different network architectures. Furthermore, we provide a theoretical explanation for the effectiveness of our method in OOD detection. Code is available at https://gitlab.com/drti/neco",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/ff29bf27e1c4e95c4eec448ed1d4adfa81983302.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 25,
        "score": 12.5,
        "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n### NECO: NEURAL COLLAPSE BASED OUT-OF-DISTRIBUTION DETECTION \\cite{ammar2023pr1}\n\n*   **Research Problem & Motivation**\n    *   **Problem**: Deep learning models exhibit unwarranted overconfidence when confronted with Out-of-Distribution (OOD) inputs, failing to recognize data outside their training distribution.\n    *   **Importance & Challenge**: This vulnerability poses significant safety implications in critical applications like medical imaging, industrial inspection, and autonomous driving, where models must not only classify known In-Distribution (ID) samples but also reliably flag OOD inputs as \"unknown.\" The challenge lies in developing effective, post-hoc OOD detection methods that do not alter the network training or harm performance.\n\n*   **Related Work & Positioning**\n    *   **Existing OOD Approaches**: The paper categorizes existing OOD detection methods into confidence-based (e.g., Softmax, Energy, ODIN), features/logits-based, and distance/density-based (e.g., Mahalanobis, nearest-neighbor). It specifically focuses on *post-hoc (unsupervised)* methods, which are desirable for seamless integration into production models without increased training cost.\n    *   **Neural Collapse (NC)**: Previous studies have identified \"Neural Collapse\" (NC) as a phenomenon in DNNs trained beyond loss convergence, characterized by within-class variability collapse (NC1), convergence of class means to a Simplex Equiangular Tight Frame (ETF) (NC2), self-duality (NC3), and simplification to nearest class-center classification (NC4).\n    *   **Limitations of Previous NC-OOD Work**: While Haas et al. (2023) demonstrated that collapsed models exhibit improved OOD detection, no prior work has directly leveraged the emergent geometric properties of NC for OOD detection.\n    *   **Positioning NECO**: NECO falls within the feature/logit-based post-hoc OOD methods. It relates to methods like NuSA and ViM, which also leverage principal/null spaces for OOD detection, but introduces a novel approach based on a newly observed NC property.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: NECO (NEural Collapse-based Out-of-distribution detection) is a novel post-hoc OOD detection method that leverages the geometric properties of Neural Collapse, particularly a newly identified property, and principal component spaces.\n    *   **Novel Observation (NC5)**: The paper introduces and empirically validates a novel property of Neural Collapse: **ID/OOD Orthogonality (NC5)**. This property states that as training progresses, OOD and ID data tend to become increasingly orthogonal to each other, meaning OOD data clusters become more perpendicular to the Simplex ETF configuration adopted by ID data. Mathematically, `âˆ€c,âŸ¨Âµc, ÂµOOD_GâŸ© / (âˆ¥Âµcâˆ¥2âˆ¥ÂµOOD_Gâˆ¥2) â†’ 0`.\n    *   **NECO Score Calculation**: Building on NC5, NECO computes an OOD score for a sample `x` by calculating the relative norm of its feature vector `hÏ‰(x)` within the subspace occupied by the Simplex ETF structure. This is achieved by projecting `hÏ‰(x)` onto the principal component space derived from the ID training data's feature covariance matrix.\n        *   `NECO(x) = âˆ¥P hÏ‰(x)âˆ¥ / âˆ¥hÏ‰(x)âˆ¥ = sqrt(hÏ‰(x)âŠ¤ PPâŠ¤ hÏ‰(x)) / sqrt(hÏ‰(x)âŠ¤ hÏ‰(x))`\n        *   Here, `P` is the projection matrix onto the `d` principal components extracted from the ID data's feature space `H`.\n    *   **Innovation over Related Work**: Unlike NuSA and ViM, which identify and utilize the *null space* (the component of the feature vector that does not directly impact classification) for OOD detection, NECO directly leverages the *principal component space* of the ID data. The hypothesis is that if NC1, NC2, and NC5 hold, OOD data, being orthogonal to ID data, will have a near-null projection onto the ID-derived principal space, while ID data will have a significant projection.\n\n*   **Key Technical Contributions**\n    *   **Novel Theoretical Insight**: Introduction and empirical validation of the **ID/OOD Orthogonality (NC5)** property of Neural Collapse, demonstrating that OOD data becomes increasingly orthogonal to ID data's class means during the Terminal Phase of Training.\n    *   **Novel Algorithm/Method**: Proposal of **NECO**, a straightforward yet highly efficient post-hoc OOD detection method that directly leverages the geometric implications of Neural Collapse and the principal component space of ID data.\n    *   **Theoretical Analysis**: The paper provides a theoretical explanation for the effectiveness of NECO in OOD detection, linking its mechanism to the established and newly proposed NC properties.\n\n*   **Experimental Validation**\n    *   **Validation of NC5**: Experiments were conducted to validate the ID/OOD orthogonality (NC5) using CIFAR-10 as the ID dataset and CIFAR-100/SVHN as OOD datasets, employing ResNet-18 and ViT architectures. Results (Figure 1) show the `OrthoDev classes âˆ’OOD` metric consistently decreasing towards zero, confirming the convergence to ID/OOD orthogonality during training.\n    *   **NECO Performance**: The abstract states that NECO achieves **state-of-the-art results** on both small and large-scale OOD detection tasks.\n    *   **Generalization**: NECO exhibits **strong generalization capabilities** across different network architectures, including ResNet-18 on CIFAR10/CIFAR100 and Vision Transformer (ViT) networks on ImageNet-1K.\n    *   **Key Metrics**: While specific metrics are not detailed in the provided text, OOD detection performance is typically evaluated using metrics like AUROC, AUPR, and FPR@95%TPR.\n\n*   **Limitations & Scope**\n    *   **Scope**: The method is specifically designed as a *post-hoc (unsupervised)* OOD detection approach, meaning it does not require modifications to the network training procedure or access to OOD samples during training.\n    *   **Technical Limitations/Assumptions**: The effectiveness of NECO relies on the assumption that the underlying DNN exhibits Neural Collapse properties (NC1, NC2) and the newly proposed ID/OOD orthogonality (NC5). The paper does not explicitly state other technical limitations in the provided text.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: NECO advances the technical state-of-the-art in post-hoc OOD detection by introducing a novel, theoretically grounded approach that leverages the intrinsic geometric properties of deep neural networks during their terminal training phase.\n    *   **Impact on Future Research**: The discovery and empirical validation of ID/OOD orthogonality (NC5) provide a new fundamental insight into DNN behavior in the presence of OOD data, potentially opening new avenues for research in OOD detection, robustness, and understanding deep learning generalization. Its simplicity and efficiency make it a promising candidate for integration into safety-critical applications.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Neural Collapse (NC)",
          "ID/OOD Orthogonality (NC5)",
          "NECO (NEural Collapse-based OOD detection)",
          "Post-hoc OOD detection",
          "Geometric properties of Neural Collapse",
          "Principal component space",
          "State-of-the-art OOD detection",
          "Safety-critical applications",
          "Deep learning models",
          "Simplex Equiangular Tight Frame (ETF)",
          "Strong generalization",
          "Terminal Phase of Training",
          "Feature covariance matrix"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"we introduce neco, a novel post-hoc method for ood detection\", \"leverages the geometric properties...\", \"theoretical explanation for the effectiveness of our method\". these phrases directly align with the \"technical\" criteria of presenting new methods, algorithms, or systems.\n*   **introduction discusses:** the problem of ood detection, its significance, and mentions existing approaches, setting the stage for the proposed solution.\n*   while the paper also includes \"extensive experiments\" and \"state-of-the-art results\" (which are characteristics of an **empirical** paper), these experiments are conducted to *demonstrate the effectiveness* of the *new method* (neco). the core contribution is the development and presentation of this novel method. the empirical validation and theoretical explanation support the technical contribution."
      },
      "file_name": "ff29bf27e1c4e95c4eec448ed1d4adfa81983302.pdf"
    },
    {
      "success": true,
      "doc_id": "672940f9ced801427fdfc60ba9be908c",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of detecting out-of-distribution (OOD) objects in semantic segmentation.\n    *   This problem is important and challenging because real-world decision systems, such as autonomous vehicles, require high reliability, robustness, and safety. Deep Neural Networks (DNNs) are often overconfident on OOD data, and existing OOD detection methods are typically either accurate *or* fast, but rarely both, which severely limits their practical usability in real-time applications \\cite{besnier2021jgn}.\n\n*   **Related Work & Positioning**\n    *   This work positions itself by revisiting the two-stage approach, where an auxiliary module is trained to predict errors or confidence, aiming to overcome the limitations of previous solutions.\n    *   Limitations of previous solutions include:\n        *   **Ensemble methods (e.g., DeepEnsemble \\cite{besnier2021jgn})**: Achieve outstanding performance but are computationally demanding for both training and testing, making them prohibitive for real-time on-vehicle usage.\n        *   **Auxiliary error prediction modules (e.g., ConfiNet \\cite{besnier2021jgn})**: Computationally lighter but suffer from a lack of sufficient negative samples (failures) to train properly, as the main DNNs make few mistakes on in-distribution data.\n        *   **Bayesian approaches (e.g., MC Dropout \\cite{besnier2021jgn})**: Do not scale well and require multiple forward passes, increasing computational cost.\n        *   **Test-time adversarial attacks (e.g., ODIN \\cite{besnier2021jgn})**: Computationally intensive at test time, requiring perturbations for each pixel, and have not been shown effective for structured output tasks like semantic segmentation.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a new OOD detection architecture called **ObsNet** combined with a dedicated training scheme based on **Local Adversarial Attacks (LAA)** \\cite{besnier2021jgn}.\n    *   This approach is novel and different due to four key design principles:\n        1.  **Decoupling OOD detection from the segmentation task**: This prevents negative impacts on the segmentation network's accuracy and allows the use of off-the-shelf pre-trained segmentation models.\n        2.  **Observing the entire segmentation network**: Instead of just its output, ObsNet attends to the input, output, and *intermediate feature maps* (skip connections) of the segmentation network, leveraging internal network behavior for improved OOD detection.\n        3.  **Generating training data for the OOD detector**: This is achieved by leveraging \"blind spots\" in the segmentation network through adversarial attacks, addressing the lack of OOD training data.\n        4.  **Focusing generated data on localized regions**: Local Adversarial Attacks (LAA) are applied within random shapes in the image to simulate unknown objects, making the generated failures more relevant to OOD detection in a segmentation context \\cite{besnier2021jgn}.\n\n*   **Key Technical Contributions**\n    *   **Novel Architecture (ObsNet)**: A dedicated observer network designed to monitor the internal states (feature maps) of a frozen, pre-trained segmentation network, enabling accurate OOD detection without altering the primary task's performance.\n    *   **Novel Training Scheme (Local Adversarial Attacks - LAA)**: A method to generate synthetic OOD-like training data by applying localized adversarial perturbations (using FGSM within random shapes) to trigger specific failure modes in the segmentation network. This effectively creates \"negative samples\" for the OOD detector, overcoming the data scarcity problem.\n    *   **System Design**: A two-stage approach that allows ObsNet to be trained as an auxiliary module without requiring retraining or fine-tuning of the main segmentation network, making it highly adaptable and efficient.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive ablation studies were performed to validate each design principle. The method was compared against ten diverse state-of-the-art OOD detection methods from the literature.\n    *   **Key Performance Metrics**: Performance was evaluated using AuRoc (Area Under the Receiver Operating Characteristic curve) for accuracy and TFLOPs for computational cost (speed).\n    *   **Comparison Results**:\n        *   ObsNet+LAA achieved top performance in *both* accuracy (AuRoc) and speed (low TFLOPs) on three different semantic segmentation datasets: CamVid OOD, StreetHazards, and BDD-Anomaly \\cite{besnier2021jgn}.\n        *   It was shown to be significantly faster (e.g., 21 times faster than MC Dropout with 50 forward passes on a GeForce RTX 2080 Ti) while simultaneously outperforming these methods in OOD detection accuracy.\n        *   Ablation studies empirically validated the effectiveness of decoupling, observing the full network, and using localized adversarial attacks with random shapes for generating training data.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The pre-trained segmentation network must allow for adversarial attacks. ObsNet introduces a memory/computation overhead equivalent to that of the segmentation network, which, while significantly less than ensemble methods, might still be a consideration for extremely constrained real-time applications \\cite{besnier2021jgn}.\n    *   **Scope of Applicability**: The method is specifically designed for OOD detection in semantic segmentation and can be readily applied to any pre-trained deep neural network used for this task.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing an OOD detection method for semantic segmentation that is simultaneously accurate and fast, addressing a critical gap in existing solutions \\cite{besnier2021jgn}.\n    *   The novel approach of training an observer network with localized adversarial attacks to generate OOD-like samples offers a powerful paradigm for improving the reliability of DNNs. This has potential impact on future research in robust AI, particularly for safety-critical applications like autonomous driving, by enabling effective detection of \"unknown unknowns\" without compromising real-time performance.",
      "intriguing_abstract": "Autonomous vehicles demand infallible perception, yet Deep Neural Networks often fail catastrophically on out-of-distribution (OOD) objects, posing significant safety risks. Current OOD detection methods for semantic segmentation face a critical dilemma: they are either accurate but too computationally demanding for real-time applications, or fast but unreliable. We introduce **ObsNet**, a novel observer network, coupled with a groundbreaking training scheme based on **Local Adversarial Attacks (LAA)**, to overcome this fundamental limitation.\n\nObsNet uniquely decouples OOD detection from the primary segmentation task, allowing it to monitor the *entire* frozen segmentation network, including its crucial intermediate feature maps and skip connections, for rich contextual cues. To address the pervasive scarcity of OOD training data, LAA strategically generates realistic \"blind spots\" by applying localized adversarial perturbations within random image regions, effectively synthesizing challenging OOD-like samples. Our extensive experiments demonstrate that ObsNet+LAA achieves state-of-the-art performance in *both* OOD detection accuracy (AuRoc) and computational speed (TFLOPs) across diverse datasets, significantly outperforming existing methods. This breakthrough offers a robust, real-time solution for enhancing the reliability and safety of Deep Neural Networks in safety-critical applications like autonomous driving, paving the way for truly trustworthy AI.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "semantic segmentation",
        "ObsNet architecture",
        "Local Adversarial Attacks (LAA)",
        "real-time applications",
        "autonomous vehicles",
        "decoupling OOD detection",
        "intermediate feature maps",
        "generating synthetic OOD training data",
        "simultaneously accurate and fast",
        "robust AI",
        "two-stage approach"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/393e0b8459eb1608b6b35d6057da4ddb09957555.pdf",
      "citation_key": "besnier2021jgn",
      "metadata": {
        "title": "Triggering Failures: Out-Of-Distribution detection by learning from local adversarial attacks in Semantic Segmentation",
        "authors": [
          "Victor Besnier",
          "Andrei Bursuc",
          "David Picard",
          "Alexandre Briot"
        ],
        "published_date": "2021",
        "abstract": "In this paper, we tackle the detection of out-of-distribution (OOD) objects in semantic segmentation. By analyzing the literature, we found that current methods are either accurate or fast but not both which limits their usability in real world applications. To get the best of both aspects, we propose to mitigate the common shortcomings by following four design principles: decoupling the OOD detection from the segmentation task, observing the entire segmentation network instead of just its output, generating training data for the OOD detector by leveraging blind spots in the segmentation network and focusing the generated data on localized regions in the image to simulate OOD objects. Our main contribution is a new OOD detection architecture called ObsNet associated with a dedicated training scheme based on Local Adversarial Attacks (LAA). We validate the soundness of our approach across numerous ablation studies. We also show it obtains top performances both in speed and accuracy when compared to ten recent methods of the literature on three different datasets.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/393e0b8459eb1608b6b35d6057da4ddb09957555.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 50,
        "score": 12.5,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of detecting out-of-distribution (OOD) objects in semantic segmentation.\n    *   This problem is important and challenging because real-world decision systems, such as autonomous vehicles, require high reliability, robustness, and safety. Deep Neural Networks (DNNs) are often overconfident on OOD data, and existing OOD detection methods are typically either accurate *or* fast, but rarely both, which severely limits their practical usability in real-time applications \\cite{besnier2021jgn}.\n\n*   **Related Work & Positioning**\n    *   This work positions itself by revisiting the two-stage approach, where an auxiliary module is trained to predict errors or confidence, aiming to overcome the limitations of previous solutions.\n    *   Limitations of previous solutions include:\n        *   **Ensemble methods (e.g., DeepEnsemble \\cite{besnier2021jgn})**: Achieve outstanding performance but are computationally demanding for both training and testing, making them prohibitive for real-time on-vehicle usage.\n        *   **Auxiliary error prediction modules (e.g., ConfiNet \\cite{besnier2021jgn})**: Computationally lighter but suffer from a lack of sufficient negative samples (failures) to train properly, as the main DNNs make few mistakes on in-distribution data.\n        *   **Bayesian approaches (e.g., MC Dropout \\cite{besnier2021jgn})**: Do not scale well and require multiple forward passes, increasing computational cost.\n        *   **Test-time adversarial attacks (e.g., ODIN \\cite{besnier2021jgn})**: Computationally intensive at test time, requiring perturbations for each pixel, and have not been shown effective for structured output tasks like semantic segmentation.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a new OOD detection architecture called **ObsNet** combined with a dedicated training scheme based on **Local Adversarial Attacks (LAA)** \\cite{besnier2021jgn}.\n    *   This approach is novel and different due to four key design principles:\n        1.  **Decoupling OOD detection from the segmentation task**: This prevents negative impacts on the segmentation network's accuracy and allows the use of off-the-shelf pre-trained segmentation models.\n        2.  **Observing the entire segmentation network**: Instead of just its output, ObsNet attends to the input, output, and *intermediate feature maps* (skip connections) of the segmentation network, leveraging internal network behavior for improved OOD detection.\n        3.  **Generating training data for the OOD detector**: This is achieved by leveraging \"blind spots\" in the segmentation network through adversarial attacks, addressing the lack of OOD training data.\n        4.  **Focusing generated data on localized regions**: Local Adversarial Attacks (LAA) are applied within random shapes in the image to simulate unknown objects, making the generated failures more relevant to OOD detection in a segmentation context \\cite{besnier2021jgn}.\n\n*   **Key Technical Contributions**\n    *   **Novel Architecture (ObsNet)**: A dedicated observer network designed to monitor the internal states (feature maps) of a frozen, pre-trained segmentation network, enabling accurate OOD detection without altering the primary task's performance.\n    *   **Novel Training Scheme (Local Adversarial Attacks - LAA)**: A method to generate synthetic OOD-like training data by applying localized adversarial perturbations (using FGSM within random shapes) to trigger specific failure modes in the segmentation network. This effectively creates \"negative samples\" for the OOD detector, overcoming the data scarcity problem.\n    *   **System Design**: A two-stage approach that allows ObsNet to be trained as an auxiliary module without requiring retraining or fine-tuning of the main segmentation network, making it highly adaptable and efficient.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive ablation studies were performed to validate each design principle. The method was compared against ten diverse state-of-the-art OOD detection methods from the literature.\n    *   **Key Performance Metrics**: Performance was evaluated using AuRoc (Area Under the Receiver Operating Characteristic curve) for accuracy and TFLOPs for computational cost (speed).\n    *   **Comparison Results**:\n        *   ObsNet+LAA achieved top performance in *both* accuracy (AuRoc) and speed (low TFLOPs) on three different semantic segmentation datasets: CamVid OOD, StreetHazards, and BDD-Anomaly \\cite{besnier2021jgn}.\n        *   It was shown to be significantly faster (e.g., 21 times faster than MC Dropout with 50 forward passes on a GeForce RTX 2080 Ti) while simultaneously outperforming these methods in OOD detection accuracy.\n        *   Ablation studies empirically validated the effectiveness of decoupling, observing the full network, and using localized adversarial attacks with random shapes for generating training data.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The pre-trained segmentation network must allow for adversarial attacks. ObsNet introduces a memory/computation overhead equivalent to that of the segmentation network, which, while significantly less than ensemble methods, might still be a consideration for extremely constrained real-time applications \\cite{besnier2021jgn}.\n    *   **Scope of Applicability**: The method is specifically designed for OOD detection in semantic segmentation and can be readily applied to any pre-trained deep neural network used for this task.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing an OOD detection method for semantic segmentation that is simultaneously accurate and fast, addressing a critical gap in existing solutions \\cite{besnier2021jgn}.\n    *   The novel approach of training an observer network with localized adversarial attacks to generate OOD-like samples offers a powerful paradigm for improving the reliability of DNNs. This has potential impact on future research in robust AI, particularly for safety-critical applications like autonomous driving, by enabling effective detection of \"unknown unknowns\" without compromising real-time performance.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "semantic segmentation",
          "ObsNet architecture",
          "Local Adversarial Attacks (LAA)",
          "real-time applications",
          "autonomous vehicles",
          "decoupling OOD detection",
          "intermediate feature maps",
          "generating synthetic OOD training data",
          "simultaneously accurate and fast",
          "robust AI",
          "two-stage approach"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** to mitigate the common shortcomings...\", \"our main contribution is a **new ood detection architecture called obsnet associated with a dedicated training scheme** based on local adversarial attacks (laa).\"\n*   the introduction discusses a technical problem (limitations of current ood detection methods in semantic segmentation, specifically the speed-accuracy trade-off) and immediately presents their proposed solution (obsnet+laa) as shown in figure 1.\n*   the paper focuses on developing and presenting a novel system/method. while it includes empirical validation (\"numerous ablation studies,\" \"top performances... compared to ten recent methods... on three different datasets\"), the core contribution is the *creation* of this new technical solution.\n\nthis aligns perfectly with the criteria for a **technical** paper.\n\n**classification: technical**"
      },
      "file_name": "393e0b8459eb1608b6b35d6057da4ddb09957555.pdf"
    },
    {
      "success": true,
      "doc_id": "d73f72200db01ef68dfdb44f83caa957",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of guaranteeing the correct behavior of deep neural networks (DNNs) in safety-critical systems by identifying and discarding unsafe predictions at runtime. It specifically questions the suitability of Out-Of-Distribution (OOD) detection as the primary framework for designing and evaluating these runtime monitors.\n    *   **Importance & Challenge**: This problem is crucial for deploying DNNs in high-stakes applications like self-driving cars and surgical robots, where incorrect predictions can lead to catastrophic consequences. The challenge lies in effectively identifying \"unsafe\" data instances at inference time, often in an unsupervised setting where examples of unsafe inputs are not available during monitor training.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The paper positions itself by distinguishing between two paradigms in runtime monitoring:\n        *   **Out-Of-Distribution (OOD) detection**: Aims to identify inputs not from the training distribution (e.g., ODIN, energy score, ReAct, Mahalanobis, Outside-the-Box, methods for covariate shift and adversarial attack detection).\n        *   **Out-of-Model-Scope (OMS) detection**: Aims to identify inputs that lead to *errors* of the monitored DNN (e.g., DOCTOR, DISSECTOR, object detection assertion techniques).\n    *   **Limitations of Previous Solutions**: The core argument of \\cite{guerin202201y} is that OOD detection, while widely studied, is an ambiguous and often misleading proxy for the true goal of runtime monitoring. It highlights that:\n        *   The definition of \"in-distribution\" (ID) is often fuzzy and subjective, especially in high-dimensional data spaces.\n        *   OOD detection does not fully capture the concept of model errors; a DNN can be correct on OOD data (model generalization) or incorrect on ID data (in-distribution errors), both of which are critical for safety but not directly addressed by OOD.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: The paper's primary innovation is not a new monitoring algorithm, but rather a **conceptual re-framing and evaluation framework**. It formally defines **Out-of-Model-Scope (OMS) detection** as the unambiguous and correct objective for DNN runtime monitors, where the goal is to identify inputs leading to *prediction errors* of the specific DNN model.\n    *   **Novelty/Difference**:\n        *   It explicitly argues that OOD detection is *not* all that is needed, challenging the prevailing focus in the literature.\n        *   It provides a detailed discussion of the conceptual differences between OOD and OMS, illustrating how OOD can lead to false positives (rejecting correct OOD predictions) and false negatives (accepting incorrect ID predictions).\n        *   It proposes a practical \"good practice\" for training monitors: removing erroneous samples from the DNN training dataset when fitting the one-class classifier that serves as the monitor.\n\n*   **Key Technical Contributions**\n    *   **Theoretical Insights/Analysis**: Formalization and clear distinction between Out-of-Model-Scope (OMS) and Out-Of-Distribution (OOD) detection, arguing for OMS as the appropriate and unambiguous goal for DNN runtime monitoring.\n    *   **Critique of OOD Paradigm**: Comprehensive analysis of the limitations of OOD detection, including its ambiguous definition and its inability to fully represent the model's scope of correct behavior.\n    *   **Empirical Demonstration**: Extensive experimental validation showing that OOD performance metrics can be misleading indicators of a monitor's ability to detect actual DNN errors.\n    *   **Novel Training Practice**: Introduction and experimental validation of a \"good practice\" for monitor training: improving monitor performance by excluding misclassified training data samples during the monitor's fitting phase.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: \\cite{guerin202201y} conducted extensive experiments across:\n        *   **27 OOD datasets**: Using CIFAR10, CIFAR100, and SVHN as in-distribution (ID) datasets, combined with 9 distinct OOD sets (3 novelty tasks, 3 covariate shift tasks like brightness/blur/pixelization, and 3 adversarial attacks like FGSM/DeepFool/PGD).\n        *   **2 DNN architectures**: DenseNet and ResNet, leading to 54 OOD scenarios.\n        *   **6 monitoring approaches**: Mahalanobis, Outside-the-Box, Maximum Softmax Probability (MSP), Energy score, ReAct, and ODIN.\n    *   **Key Performance Metrics**: Evaluated both OOD detection performance (using AUROC, AUPR-in, AUPR-out, FPR@95TPR) and OMS detection performance (using Recall, Precision, and F1-score).\n    *   **Comparison Results**:\n        *   **Misleading OOD Results**: Showed that monitors achieving very good OOD detection results (e.g., high AUROC) often exhibit poor performance in detecting actual model errors (OMS), leading to a false sense of safety.\n        *   **OOD vs. OMS Performance Discrepancy**: Demonstrated that the monitor performing best under OOD metrics is not necessarily the best for OMS detection, highlighting that OOD evaluation does not reliably identify the most effective monitor for safety.\n        *   **Impact of Erroneous Training Data**: Experimentally proved that removing misclassified samples from the training data used to fit the monitor significantly improves its OMS detection performance (e.g., higher F1-score and better precision-recall curves).\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study primarily focuses on classification tasks and image datasets. While the conceptual framework is general, its empirical validation is within this scope. The proposed training trick applies to the monitor's training, not the main DNN's training.\n    *   **Scope of Applicability**: The findings are highly relevant for the design and evaluation of runtime monitors for DNNs in safety-critical systems, particularly where the distinction between \"out-of-distribution\" and \"model error\" is crucial.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{guerin202201y} significantly advances the technical state-of-the-art by challenging the long-standing reliance on OOD detection for DNN safety. It provides a more rigorous and direct framework (OMS) for evaluating the true safety capabilities of runtime monitors.\n    *   **Potential Impact on Future Research**:\n        *   It is likely to shift research focus towards developing and evaluating monitoring techniques specifically optimized for OMS detection, rather than just OOD.\n        *   It encourages a more critical assessment of existing OOD benchmarks and metrics when applied to safety-critical contexts.\n        *   The proposed \"good practice\" of cleaning monitor training data offers an immediate, practical improvement for monitor development.\n        *   It could inspire new theoretical work on the relationship between data distribution, model generalization, and prediction errors.",
      "intriguing_abstract": "Ensuring the trustworthy deployment of Deep Neural Networks (DNNs) in safety-critical systems hinges on reliably identifying and rejecting unsafe predictions at runtime. Current paradigms heavily rely on Out-Of-Distribution (OOD) detection, but is this truly sufficient for guaranteeing safety? This paper fundamentally challenges the suitability of OOD as the primary framework for designing and evaluating DNN runtime monitors. We formally introduce and advocate for **Out-of-Model-Scope (OMS) detection**, defining it as the unambiguous objective: identifying inputs that lead to *prediction errors* of the specific monitored DNN.\n\nOur comprehensive analysis reveals that OOD detection is an ambiguous and often misleading proxy for safety, failing to capture critical in-distribution errors or correctly generalize to OOD data. Through extensive experiments across diverse datasets and architectures, we empirically demonstrate that monitors excelling in OOD metrics often perform poorly in detecting actual model errors, creating a false sense of security. Furthermore, we propose and validate a novel training practice that significantly boosts OMS detection performance by excluding misclassified samples during monitor fitting. This work redefines the pursuit of DNN safety, urging a critical shift from OOD to OMS, thereby paving the way for more robust and trustworthy AI systems.",
      "keywords": [
        "Deep Neural Networks (DNNs)",
        "safety-critical systems",
        "runtime monitors",
        "Out-Of-Distribution (OOD) detection",
        "Out-of-Model-Scope (OMS) detection",
        "prediction errors",
        "conceptual re-framing",
        "evaluation framework",
        "misleading OOD metrics",
        "monitor training data cleaning",
        "adversarial attacks",
        "covariate shift",
        "model generalization",
        "false sense of safety"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e.pdf",
      "citation_key": "guerin202201y",
      "metadata": {
        "title": "Out-Of-Distribution Detection Is Not All You Need",
        "authors": [
          "Joris Gu'erin",
          "Kevin Delmas",
          "Raul Sena Ferreira",
          "JÃ©rÃ©mie Guiochet"
        ],
        "published_date": "2022",
        "abstract": "The usage of deep neural networks in safety-critical systems is limited by our ability to guarantee their correct behavior. Runtime monitors are components aiming to identify unsafe predictions and discard them before they can lead to catastrophic consequences. Several recent works on runtime monitoring have focused on out-of-distribution (OOD) detection, i.e., identifying inputs that are different from the training data. In this work, we argue that OOD detection is not a well-suited framework to design efficient runtime monitors and that it is more relevant to evaluate monitors based on their ability to discard incorrect predictions. We call this setting out-of-model-scope detection and discuss the conceptual differences with OOD. We also conduct extensive experiments on popular datasets from the literature to show that studying monitors in the OOD setting can be misleading: 1. very good OOD results can give a false impression of safety, 2. comparison under the OOD setting does not allow identifying the best monitor to detect errors. Finally, we also show that removing erroneous training data samples helps to train better monitors.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 37,
        "score": 12.333333333333332,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of guaranteeing the correct behavior of deep neural networks (DNNs) in safety-critical systems by identifying and discarding unsafe predictions at runtime. It specifically questions the suitability of Out-Of-Distribution (OOD) detection as the primary framework for designing and evaluating these runtime monitors.\n    *   **Importance & Challenge**: This problem is crucial for deploying DNNs in high-stakes applications like self-driving cars and surgical robots, where incorrect predictions can lead to catastrophic consequences. The challenge lies in effectively identifying \"unsafe\" data instances at inference time, often in an unsupervised setting where examples of unsafe inputs are not available during monitor training.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The paper positions itself by distinguishing between two paradigms in runtime monitoring:\n        *   **Out-Of-Distribution (OOD) detection**: Aims to identify inputs not from the training distribution (e.g., ODIN, energy score, ReAct, Mahalanobis, Outside-the-Box, methods for covariate shift and adversarial attack detection).\n        *   **Out-of-Model-Scope (OMS) detection**: Aims to identify inputs that lead to *errors* of the monitored DNN (e.g., DOCTOR, DISSECTOR, object detection assertion techniques).\n    *   **Limitations of Previous Solutions**: The core argument of \\cite{guerin202201y} is that OOD detection, while widely studied, is an ambiguous and often misleading proxy for the true goal of runtime monitoring. It highlights that:\n        *   The definition of \"in-distribution\" (ID) is often fuzzy and subjective, especially in high-dimensional data spaces.\n        *   OOD detection does not fully capture the concept of model errors; a DNN can be correct on OOD data (model generalization) or incorrect on ID data (in-distribution errors), both of which are critical for safety but not directly addressed by OOD.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: The paper's primary innovation is not a new monitoring algorithm, but rather a **conceptual re-framing and evaluation framework**. It formally defines **Out-of-Model-Scope (OMS) detection** as the unambiguous and correct objective for DNN runtime monitors, where the goal is to identify inputs leading to *prediction errors* of the specific DNN model.\n    *   **Novelty/Difference**:\n        *   It explicitly argues that OOD detection is *not* all that is needed, challenging the prevailing focus in the literature.\n        *   It provides a detailed discussion of the conceptual differences between OOD and OMS, illustrating how OOD can lead to false positives (rejecting correct OOD predictions) and false negatives (accepting incorrect ID predictions).\n        *   It proposes a practical \"good practice\" for training monitors: removing erroneous samples from the DNN training dataset when fitting the one-class classifier that serves as the monitor.\n\n*   **Key Technical Contributions**\n    *   **Theoretical Insights/Analysis**: Formalization and clear distinction between Out-of-Model-Scope (OMS) and Out-Of-Distribution (OOD) detection, arguing for OMS as the appropriate and unambiguous goal for DNN runtime monitoring.\n    *   **Critique of OOD Paradigm**: Comprehensive analysis of the limitations of OOD detection, including its ambiguous definition and its inability to fully represent the model's scope of correct behavior.\n    *   **Empirical Demonstration**: Extensive experimental validation showing that OOD performance metrics can be misleading indicators of a monitor's ability to detect actual DNN errors.\n    *   **Novel Training Practice**: Introduction and experimental validation of a \"good practice\" for monitor training: improving monitor performance by excluding misclassified training data samples during the monitor's fitting phase.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: \\cite{guerin202201y} conducted extensive experiments across:\n        *   **27 OOD datasets**: Using CIFAR10, CIFAR100, and SVHN as in-distribution (ID) datasets, combined with 9 distinct OOD sets (3 novelty tasks, 3 covariate shift tasks like brightness/blur/pixelization, and 3 adversarial attacks like FGSM/DeepFool/PGD).\n        *   **2 DNN architectures**: DenseNet and ResNet, leading to 54 OOD scenarios.\n        *   **6 monitoring approaches**: Mahalanobis, Outside-the-Box, Maximum Softmax Probability (MSP), Energy score, ReAct, and ODIN.\n    *   **Key Performance Metrics**: Evaluated both OOD detection performance (using AUROC, AUPR-in, AUPR-out, FPR@95TPR) and OMS detection performance (using Recall, Precision, and F1-score).\n    *   **Comparison Results**:\n        *   **Misleading OOD Results**: Showed that monitors achieving very good OOD detection results (e.g., high AUROC) often exhibit poor performance in detecting actual model errors (OMS), leading to a false sense of safety.\n        *   **OOD vs. OMS Performance Discrepancy**: Demonstrated that the monitor performing best under OOD metrics is not necessarily the best for OMS detection, highlighting that OOD evaluation does not reliably identify the most effective monitor for safety.\n        *   **Impact of Erroneous Training Data**: Experimentally proved that removing misclassified samples from the training data used to fit the monitor significantly improves its OMS detection performance (e.g., higher F1-score and better precision-recall curves).\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study primarily focuses on classification tasks and image datasets. While the conceptual framework is general, its empirical validation is within this scope. The proposed training trick applies to the monitor's training, not the main DNN's training.\n    *   **Scope of Applicability**: The findings are highly relevant for the design and evaluation of runtime monitors for DNNs in safety-critical systems, particularly where the distinction between \"out-of-distribution\" and \"model error\" is crucial.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{guerin202201y} significantly advances the technical state-of-the-art by challenging the long-standing reliance on OOD detection for DNN safety. It provides a more rigorous and direct framework (OMS) for evaluating the true safety capabilities of runtime monitors.\n    *   **Potential Impact on Future Research**:\n        *   It is likely to shift research focus towards developing and evaluating monitoring techniques specifically optimized for OMS detection, rather than just OOD.\n        *   It encourages a more critical assessment of existing OOD benchmarks and metrics when applied to safety-critical contexts.\n        *   The proposed \"good practice\" of cleaning monitor training data offers an immediate, practical improvement for monitor development.\n        *   It could inspire new theoretical work on the relationship between data distribution, model generalization, and prediction errors.",
        "keywords": [
          "Deep Neural Networks (DNNs)",
          "safety-critical systems",
          "runtime monitors",
          "Out-Of-Distribution (OOD) detection",
          "Out-of-Model-Scope (OMS) detection",
          "prediction errors",
          "conceptual re-framing",
          "evaluation framework",
          "misleading OOD metrics",
          "monitor training data cleaning",
          "adversarial attacks",
          "covariate shift",
          "model generalization",
          "false sense of safety"
        ],
        "paper_type": "the paper type is **position**.\n\n**reasoning:**\n\n1.  **abstract analysis:**\n    *   the abstract explicitly states: \"in this work, we **argue** that ood detection is not a well-suited framework... and that it is more relevant to evaluate monitors based on their ability to discard incorrect predictions.\" this is a direct statement of a viewpoint or argument.\n    *   it proposes a new concept: \"we call this setting out-of-model-scope detection and discuss the conceptual differences with ood.\" this is part of establishing a new perspective.\n    *   it then describes \"extensive experiments\" conducted to \"show that studying monitors in the ood setting can be misleading\" and to support their argument. while empirical, these experiments serve to validate the paper's central position.\n\n2.  **introduction analysis:**\n    *   the introduction sets the context by discussing the problem with dnns in safety-critical systems and the role of runtime monitors.\n    *   it highlights the current focus in literature on out-of-distribution (ood) detection, which the abstract then critiques.\n\n3.  **classification criteria match:**\n    *   **position**: the abstract directly uses \"argue\" and discusses current problems (limitations of ood detection) and proposes a new direction/viewpoint (\"out-of-model-scope detection\" and a different evaluation metric). the empirical work is presented as evidence to support this position.\n    *   **empirical**: while the paper *does* conduct \"extensive experiments\" and presents \"findings,\" the primary purpose of these experiments, as stated in the abstract, is to *support the argument* that ood detection is misleading and to advocate for a new approach. the empirical work is a strong component, but it serves the overarching position. if the paper were purely empirical, it might focus more on the methodology and results of the experiments themselves as the main contribution, rather than using them to \"argue\" a point about an existing framework.\n\ngiven the explicit \"we argue\" and the critique of an existing paradigm with a proposed alternative, the paper's core contribution is to take a stance and advocate for a new perspective, making it a position paper. the empirical evidence strengthens this position."
      },
      "file_name": "2fdf63af2c04ac613b2acaf628d4a5dc60e84c8e.pdf"
    },
    {
      "success": true,
      "doc_id": "8ba6bbdd3a7814782e45e72e2882d472",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the Out-of-Distribution (OOD) problem, where neural networks encounter data significantly different from their training (in-distribution, InD) data, leading to performance degradation. It specifically tackles both OOD detection (identifying OOD inputs) and OOD generalization (building models robust to OOD data).\n    *   **Importance & Challenge:** The OOD problem is prevalent in real-world applications, as the assumption of identical training and test data distributions rarely holds. Existing OOD solutions often lack fundamental insights into the root causes and mitigation strategies. Prior neuron-based approaches either modify network architectures (potentially harming InD accuracy) or oversimplify neuron states, discarding valuable distributional information \\cite{liu2023zb3}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work relates to two main categories of OOD research: OOD detection methods (e.g., OpenMax, ODIN, ViM) and OOD generalization techniques.\n    *   **Limitations of Previous Solutions:** The paper argues that existing methods often fail to provide deep insights into the fundamental causes of OOD issues. Specifically, previous neuron-centric studies either involve network modifications that can compromise classification ability or rely on simplistic binary neuron activation states, which lose crucial information about neuron behavior distributions \\cite{liu2023zb3}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:**\n        *   **Neuron Activation State (Ë†z):** The paper first formulates a novel neuron activation state `Ë†z` by considering both the neuron's raw output (`z`) and its influence on model decisions. This influence is quantified using gradients derived from the Kullback-Leibler (KL) divergence between the network's output and a uniform vector. This formulation effectively combines the neuron's contribution to predictions (similar to `InputâŠ™Gradient`) with the model's confidence in the input data \\cite{liu2023zb3}.\n        *   **Neuron Activation Coverage (NAC):** Inspired by coverage analysis in system testing, NAC is introduced as a simple statistical measure. It quantifies the \"coverage degree\" of neuron states under InD training data by deriving a function from the probability density function (PDF) of `Ë†z`. A higher NAC score for a neuron state indicates it is frequently activated by InD data, suggesting fewer underlying defects in that state \\cite{liu2023zb3}.\n        *   **NAC for Uncertainty Estimation (NAC-UE):** For OOD detection, NAC-UE directly averages the NAC scores across all neurons for a given test sample. OOD data is hypothesized to trigger abnormal neuron behaviors, resulting in lower average NAC scores, which serve as an uncertainty measure \\cite{liu2023zb3}.\n        *   **NAC for Model Evaluation (NAC-ME):** For OOD generalization, NAC-ME measures model robustness by integrating the coverage distribution of all neurons. The hypothesis is that a larger coverage area (higher integral of NAC distribution) correlates with increased network robustness \\cite{liu2023zb3}.\n    *   **Novelty:** The primary innovation lies in rethinking OOD problems from a neuron activation perspective, introducing a sophisticated yet interpretable formulation of neuron activation state, and proposing NAC as a novel, statistically grounded measure to characterize neuron behavior. This allows for a unified approach to both OOD detection and generalization, leveraging insights from software testing \\cite{liu2023zb3}.\n\n*   **Key Technical Contributions**\n    *   **Novel Formulation of Neuron Activation State:** A new method to define neuron activation (`Ë†z`) that incorporates both raw output and its influence on model decisions via KL divergence gradients, capturing both neuron contribution and model confidence \\cite{liu2023zb3}.\n    *   **Introduction of Neuron Activation Coverage (NAC):** A novel statistical measure that quantifies how well neuron states are \"covered\" by in-distribution training data, providing a direct indicator of potential defects or abnormal behavior \\cite{liu2023zb3}.\n    *   **Algorithmic Frameworks for OOD Tasks:** Development of NAC-UE for state-of-the-art OOD detection and NAC-ME for robust OOD generalization evaluation, both built upon the NAC concept \\cite{liu2023zb3}.\n    *   **Theoretical Insight:** The establishment of a positive correlation between NAC and model generalization ability, providing a principled criterion for evaluating model robustness \\cite{liu2023zb3}.\n\n*   **Experimental Validation**\n    *   **OOD Detection (NAC-UE):**\n        *   **Experiments:** Evaluated on three benchmarks: CIFAR-10, CIFAR-100, and ImageNet-1k, using various OOD datasets (e.g., MNIST, SVHN, Textures, Places365, iNaturalist, OpenImage-O).\n        *   **Models:** ResNet-18 (for CIFAR), ResNet-50, and Vit-b16 (for ImageNet).\n        *   **Metrics:** FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve).\n        *   **Key Results:** NAC-UE achieved new state-of-the-art performance, significantly outperforming 21 previous best OOD detection methods. For instance, on CIFAR-100, it showed a 10.60% improvement on FPR95 and a 4.58% gain on AUROC over the competitive ViM. The NAC function was efficiently built using less than 5% of the InD training set \\cite{liu2023zb3}.\n    *   **OOD Generalization (NAC-ME):**\n        *   **Experiments:** Conducted on DomainBed.\n        *   **Key Results:** Demonstrated a consistent positive correlation between NAC and model generalization ability across different architectures and datasets. NAC-ME was shown to select more robust models and exhibited an 11.61% stronger rank correlation with OOD test accuracy (on Vit-b16) compared to prevalent InD validation criteria \\cite{liu2023zb3}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The effectiveness of NAC depends on the choice of the parameter `r` (lower bound for full coverage), which needs careful tuning to avoid dominance by noisy activations or vulnerability to data biases. The current implementation uses a histogram-based approximation for PDF, which might have implications for very fine-grained distributions \\cite{liu2023zb3}.\n    *   **Scope of Applicability:** The research primarily focuses on multi-class image classification tasks. While the underlying neuron-centric concepts are general, direct applicability and performance in other domains (e.g., natural language processing, time series) or different model architectures (e.g., generative models) would require further investigation.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art:** Significantly pushes the state-of-the-art in OOD detection, providing a highly effective and interpretable method.\n    *   **Novel Conceptual Framework:** Introduces a novel, neuron-centric framework for understanding and addressing OOD problems, offering a deeper insight into how models behave under distribution shifts \\cite{liu2023zb3}.\n    *   **Unified Solution:** Provides a unified approach (NAC) that is applicable to both OOD detection and OOD generalization, suggesting a common underlying mechanism for these challenges.\n    *   **Impact on Future Research:** Opens new avenues for research in model robustness, interpretability, and generalization by focusing on the statistical properties of neuron activation patterns, potentially leading to more principled and robust AI systems \\cite{liu2023zb3}.",
      "intriguing_abstract": "The pervasive Out-of-Distribution (OOD) problem severely compromises neural network reliability in real-world applications, yet existing solutions often lack fundamental insights into its root causes. We introduce a novel, neuron-centric framework that redefines how we understand and mitigate OOD challenges. Our approach begins with a sophisticated **Neuron Activation State (Ë†z)**, which uniquely combines a neuron's raw output with its influence on model decisions, quantified via **Kullback-Leibler divergence gradients**. Building on this, we propose **Neuron Activation Coverage (NAC)**, a statistically grounded measure inspired by software testing, to quantify how well neuron states are covered by in-distribution data.\n\nNAC provides a unified, interpretable lens for both **OOD detection** and **OOD generalization**. Our **NAC-UE** algorithm achieves new state-of-the-art performance in OOD detection, significantly outperforming 21 prior methods on major benchmarks (e.g., 10.60% FPR95 improvement on CIFAR-100). Furthermore, **NAC-ME** offers a principled criterion for evaluating model robustness, demonstrating a strong positive correlation with OOD generalization ability and superior model selection. This work not only advances the state-of-the-art but also offers deeper insights into neural network behavior under distribution shifts, paving the way for more robust and interpretable deep learning systems.",
      "keywords": [
        "Out-of-Distribution (OOD) problem",
        "OOD detection",
        "OOD generalization",
        "neuron activation state (Ë†z)",
        "Kullback-Leibler (KL) divergence",
        "Neuron Activation Coverage (NAC)",
        "uncertainty estimation",
        "model robustness evaluation",
        "statistical measure",
        "neuron-centric framework",
        "unified approach",
        "state-of-the-art performance",
        "model generalization ability",
        "distribution shifts"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d.pdf",
      "citation_key": "liu2023zb3",
      "metadata": {
        "title": "Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization",
        "authors": [
          "Y. Liu",
          "Chris Xing Tian",
          "Haoliang Li",
          "Lei Ma",
          "Shiqi Wang"
        ],
        "published_date": "2023",
        "abstract": "The out-of-distribution (OOD) problem generally arises when neural networks encounter data that significantly deviates from the training data distribution, i.e., in-distribution (InD). In this paper, we study the OOD problem from a neuron activation view. We first formulate neuron activation states by considering both the neuron output and its influence on model decisions. Then, to characterize the relationship between neurons and OOD issues, we introduce the \\textit{neuron activation coverage} (NAC) -- a simple measure for neuron behaviors under InD data. Leveraging our NAC, we show that 1) InD and OOD inputs can be largely separated based on the neuron behavior, which significantly eases the OOD detection problem and beats the 21 previous methods over three benchmarks (CIFAR-10, CIFAR-100, and ImageNet-1K). 2) a positive correlation between NAC and model generalization ability consistently holds across architectures and datasets, which enables a NAC-based criterion for evaluating model robustness. Compared to prevalent InD validation criteria, we show that NAC not only can select more robust models, but also has a stronger correlation with OOD test performance.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 24,
        "score": 12.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the Out-of-Distribution (OOD) problem, where neural networks encounter data significantly different from their training (in-distribution, InD) data, leading to performance degradation. It specifically tackles both OOD detection (identifying OOD inputs) and OOD generalization (building models robust to OOD data).\n    *   **Importance & Challenge:** The OOD problem is prevalent in real-world applications, as the assumption of identical training and test data distributions rarely holds. Existing OOD solutions often lack fundamental insights into the root causes and mitigation strategies. Prior neuron-based approaches either modify network architectures (potentially harming InD accuracy) or oversimplify neuron states, discarding valuable distributional information \\cite{liu2023zb3}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work relates to two main categories of OOD research: OOD detection methods (e.g., OpenMax, ODIN, ViM) and OOD generalization techniques.\n    *   **Limitations of Previous Solutions:** The paper argues that existing methods often fail to provide deep insights into the fundamental causes of OOD issues. Specifically, previous neuron-centric studies either involve network modifications that can compromise classification ability or rely on simplistic binary neuron activation states, which lose crucial information about neuron behavior distributions \\cite{liu2023zb3}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:**\n        *   **Neuron Activation State (Ë†z):** The paper first formulates a novel neuron activation state `Ë†z` by considering both the neuron's raw output (`z`) and its influence on model decisions. This influence is quantified using gradients derived from the Kullback-Leibler (KL) divergence between the network's output and a uniform vector. This formulation effectively combines the neuron's contribution to predictions (similar to `InputâŠ™Gradient`) with the model's confidence in the input data \\cite{liu2023zb3}.\n        *   **Neuron Activation Coverage (NAC):** Inspired by coverage analysis in system testing, NAC is introduced as a simple statistical measure. It quantifies the \"coverage degree\" of neuron states under InD training data by deriving a function from the probability density function (PDF) of `Ë†z`. A higher NAC score for a neuron state indicates it is frequently activated by InD data, suggesting fewer underlying defects in that state \\cite{liu2023zb3}.\n        *   **NAC for Uncertainty Estimation (NAC-UE):** For OOD detection, NAC-UE directly averages the NAC scores across all neurons for a given test sample. OOD data is hypothesized to trigger abnormal neuron behaviors, resulting in lower average NAC scores, which serve as an uncertainty measure \\cite{liu2023zb3}.\n        *   **NAC for Model Evaluation (NAC-ME):** For OOD generalization, NAC-ME measures model robustness by integrating the coverage distribution of all neurons. The hypothesis is that a larger coverage area (higher integral of NAC distribution) correlates with increased network robustness \\cite{liu2023zb3}.\n    *   **Novelty:** The primary innovation lies in rethinking OOD problems from a neuron activation perspective, introducing a sophisticated yet interpretable formulation of neuron activation state, and proposing NAC as a novel, statistically grounded measure to characterize neuron behavior. This allows for a unified approach to both OOD detection and generalization, leveraging insights from software testing \\cite{liu2023zb3}.\n\n*   **Key Technical Contributions**\n    *   **Novel Formulation of Neuron Activation State:** A new method to define neuron activation (`Ë†z`) that incorporates both raw output and its influence on model decisions via KL divergence gradients, capturing both neuron contribution and model confidence \\cite{liu2023zb3}.\n    *   **Introduction of Neuron Activation Coverage (NAC):** A novel statistical measure that quantifies how well neuron states are \"covered\" by in-distribution training data, providing a direct indicator of potential defects or abnormal behavior \\cite{liu2023zb3}.\n    *   **Algorithmic Frameworks for OOD Tasks:** Development of NAC-UE for state-of-the-art OOD detection and NAC-ME for robust OOD generalization evaluation, both built upon the NAC concept \\cite{liu2023zb3}.\n    *   **Theoretical Insight:** The establishment of a positive correlation between NAC and model generalization ability, providing a principled criterion for evaluating model robustness \\cite{liu2023zb3}.\n\n*   **Experimental Validation**\n    *   **OOD Detection (NAC-UE):**\n        *   **Experiments:** Evaluated on three benchmarks: CIFAR-10, CIFAR-100, and ImageNet-1k, using various OOD datasets (e.g., MNIST, SVHN, Textures, Places365, iNaturalist, OpenImage-O).\n        *   **Models:** ResNet-18 (for CIFAR), ResNet-50, and Vit-b16 (for ImageNet).\n        *   **Metrics:** FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve).\n        *   **Key Results:** NAC-UE achieved new state-of-the-art performance, significantly outperforming 21 previous best OOD detection methods. For instance, on CIFAR-100, it showed a 10.60% improvement on FPR95 and a 4.58% gain on AUROC over the competitive ViM. The NAC function was efficiently built using less than 5% of the InD training set \\cite{liu2023zb3}.\n    *   **OOD Generalization (NAC-ME):**\n        *   **Experiments:** Conducted on DomainBed.\n        *   **Key Results:** Demonstrated a consistent positive correlation between NAC and model generalization ability across different architectures and datasets. NAC-ME was shown to select more robust models and exhibited an 11.61% stronger rank correlation with OOD test accuracy (on Vit-b16) compared to prevalent InD validation criteria \\cite{liu2023zb3}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The effectiveness of NAC depends on the choice of the parameter `r` (lower bound for full coverage), which needs careful tuning to avoid dominance by noisy activations or vulnerability to data biases. The current implementation uses a histogram-based approximation for PDF, which might have implications for very fine-grained distributions \\cite{liu2023zb3}.\n    *   **Scope of Applicability:** The research primarily focuses on multi-class image classification tasks. While the underlying neuron-centric concepts are general, direct applicability and performance in other domains (e.g., natural language processing, time series) or different model architectures (e.g., generative models) would require further investigation.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art:** Significantly pushes the state-of-the-art in OOD detection, providing a highly effective and interpretable method.\n    *   **Novel Conceptual Framework:** Introduces a novel, neuron-centric framework for understanding and addressing OOD problems, offering a deeper insight into how models behave under distribution shifts \\cite{liu2023zb3}.\n    *   **Unified Solution:** Provides a unified approach (NAC) that is applicable to both OOD detection and OOD generalization, suggesting a common underlying mechanism for these challenges.\n    *   **Impact on Future Research:** Opens new avenues for research in model robustness, interpretability, and generalization by focusing on the statistical properties of neuron activation patterns, potentially leading to more principled and robust AI systems \\cite{liu2023zb3}.",
        "keywords": [
          "Out-of-Distribution (OOD) problem",
          "OOD detection",
          "OOD generalization",
          "neuron activation state (Ë†z)",
          "Kullback-Leibler (KL) divergence",
          "Neuron Activation Coverage (NAC)",
          "uncertainty estimation",
          "model robustness evaluation",
          "statistical measure",
          "neuron-centric framework",
          "unified approach",
          "state-of-the-art performance",
          "model generalization ability",
          "distribution shifts"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n1.  **presents new methods/concepts:** the abstract explicitly states, \"we first formulate neuron activation states... then, to characterize the relationship between neurons and ood issues, we introduce the neuron activation coverage (nac) â€“ a simple measure for neuron behaviors...\" and later, \"leveraging our nac, we show that...\" the introduction further emphasizes, \"we first propose to formulate the neuron activation state...\" and \"we introduce the concept of neuron activation coverage (nac)...\" this clearly indicates the development and presentation of new methods and concepts (neuron activation state formulation, nac, nac-ue, nac-me).\n2.  **addresses a technical problem with a proposed solution:** the paper identifies the \"out-of-distribution (ood) problem\" as a significant challenge and proposes nac as a solution for both ood detection and generalization.\n3.  **empirical validation of the new method:** while the paper includes extensive empirical results (\"beats the 21 previous methods over three benchmarks,\" \"establishing new state-of-the-art performance\"), these experiments serve to validate the effectiveness of the *new methods* (nac-ue and nac-me) that are being proposed. the core contribution is the novel approach, not just a data-driven study of existing phenomena or methods.\n\nthe keywords and phrases align most strongly with the \"technical\" classification criteria."
      },
      "file_name": "5d73ce0b2f017ed141aaaa3fdfee90d2098d1b2d.pdf"
    },
    {
      "success": true,
      "doc_id": "aa4d76e413d414b3264816a39ca4b920",
      "summary": "Here is a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of detecting out-of-distribution (OOD) inputs in image classification models, particularly for high-stakes applications like clinical decision-making \\cite{berger20214a3}.\n    *   This problem is important because modern classification models often exhibit overconfidence, even when presented with inputs far outside their training distribution, leading to a false sense of competence and potential risks in critical scenarios (e.g., misdiagnosing unseen pathologies in medical imaging) \\cite{berger20214a3}. The challenge lies in enabling models to \"know their capabilities\" and signal uncertainty for OOD inputs.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods generally fall into two categories: those that build dedicated OOD models (e.g., density estimation, decision boundary learning, reconstruction-based) and those that enhance a task-specific model to detect OOD inputs, often based on prediction confidence \\cite{berger20214a3}.\n    *   Limitations of previous solutions include the difficulty of accurately learning data density, the challenge of collecting or synthesizing diverse OOD data for dedicated models, and the limited performance of reconstruction-based methods for complex tasks \\cite{berger20214a3}.\n    *   This work specifically focuses on the second categoryâ€”confidence-based OOD detection methodsâ€”which are compact, integrated into existing models, and operate in the task-specific feature or output space. It positions itself by highlighting the limited investigation of these methods' potential for medical imaging, despite their importance \\cite{berger20214a3}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical approach is a comprehensive comparative study and in-depth analysis of various state-of-the-art confidence-based OOD detection methods: Maximum Class Probability (MCP), Mahalanobis Distance, Out-of-Distribution Detector for Neural Networks (ODIN), Deep Ensembles, Monte Carlo Dropout (MCDP), and Deterministic Uncertainty Quantification (DUQ) \\cite{berger20214a3}.\n    *   The innovation lies in:\n        *   Re-implementing and comparing these diverse methods in a common test-bed for fair evaluation \\cite{berger20214a3}.\n        *   Evaluating their performance not only on a standard computer vision (CV) benchmark but critically, on a challenging real-world medical imaging task (chest X-rays) \\cite{berger20214a3}.\n        *   Conducting an empirical analysis to identify factors influencing performance discrepancies between CV and medical tasks, providing insights for future OOD method development \\cite{berger20214a3}.\n\n*   **Key Technical Contributions**\n    *   **Comprehensive Comparative Study**: A systematic evaluation of prominent confidence-based OOD detection methods, establishing a benchmark for their performance across different domains \\cite{berger20214a3}.\n    *   **Domain-Specific Performance Discrepancy**: Demonstrating that high OOD detection performance on a general computer vision task does not directly translate to accuracy in a medical imaging task, highlighting the need for domain-specific validation \\cite{berger20214a3}.\n    *   **Identification of Robust Method**: Identifying ODIN as a consistently high-performing OOD detection method across both CV and challenging medical imaging tasks, often by a considerable margin \\cite{berger20214a3}.\n    *   **Analysis of ODIN's Mechanism**: Empirically showing that ODIN's effectiveness is primarily attributed to its input perturbation mechanism, which enhances the separation of in-distribution (ID) and OOD samples in the feature space \\cite{berger20214a3}.\n    *   **Insights into Mahalanobis Failure**: Providing an analysis of why Mahalanobis distance, a top performer in CV, fails in the medical imaging context, attributing it to less separable ID/OOD clusters in the feature space, making Gaussian fitting challenging \\cite{berger20214a3}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   **Computer Vision Benchmark**: OOD detection on CIFAR10 (ID) vs. SVHN (OOD) using a WideResNet 28x10 model \\cite{berger20214a3}.\n        *   **Medical Imaging Benchmark**: OOD detection on the CheXpert chest X-ray dataset, simulating two clinical settings with different ID/OOD class combinations, using a WideResNet 100x2 model \\cite{berger20214a3}.\n        *   **Ablation Studies**: Investigating the individual contributions of ODIN's perturbation and temperature scaling components, and the effect of dimensionality reduction for Mahalanobis distance \\cite{berger20214a3}.\n        *   **Visualization**: T-SNE plots of feature embeddings to analyze ID/OOD separability \\cite{berger20214a3}.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic (AUROC), Area Under the Precision-Recall Curve (AUCPR), ID Accuracy (Acc), and Expected Calibration Error (ECE) \\cite{berger20214a3}.\n    *   **Comparison Results**:\n        *   On CIFAR10 vs SVHN, Mahalanobis distance (single model and ensemble) achieved the highest AUROC (0.984 and 0.987, respectively), followed by ODIN (0.964) and Deep Ensembles (0.960) \\cite{berger20214a3}. DUQ showed unstable training and poor performance (0.833 AUROC) \\cite{berger20214a3}.\n        *   On CheXpert, ODIN significantly outperformed all other methods in both settings, achieving AUROCs of 0.841 and 0.862, respectively, with its input perturbation being the primary driver of this performance \\cite{berger20214a3}.\n        *   Mahalanobis distance, despite its strong CV performance, performed worse than the baseline MCP in one medical setting (0.580 vs 0.678 AUROC) and only showed modest improvement in the other \\cite{berger20214a3}.\n        *   The study confirmed that performance does not directly translate between CV and medical tasks, with medical tasks being significantly more challenging for OOD detection \\cite{berger20214a3}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: Mahalanobis distance was found to be ineffective in the medical imaging task due to less separable ID and OOD clusters in the feature space, making the assumption of Gaussian class-conditional distributions challenging \\cite{berger20214a3}. DUQ faced difficulties with stable training and convergence on the WideResNet architecture used \\cite{berger20214a3}.\n    *   **Scope of Applicability**: The study focused specifically on confidence-based OOD detection methods and evaluated them on image classification tasks using specific datasets (CIFAR10, SVHN, CheXpert) and model architectures (WideResNet) \\cite{berger20214a3}. The findings are particularly relevant for medical imaging applications but suggest broader implications for domain transfer of OOD methods.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a rigorous comparative analysis of confidence-based OOD detection methods, specifically highlighting their varying reliability across different data domains \\cite{berger20214a3}.\n    *   It offers crucial insights for developing the next generation of OOD detection methods, particularly for critical applications like medical AI, by demonstrating that CV performance does not guarantee success in medical tasks \\cite{berger20214a3}.\n    *   The identification of ODIN's input perturbation as a key mechanism for enhancing ID/OOD separation provides a valuable direction for future research into robust OOD detection techniques \\cite{berger20214a3}.\n    *   The study underscores the importance of domain-specific evaluation and analysis for OOD detection methods, moving beyond generic benchmarks to ensure practical applicability and reliability in real-world deployments \\cite{berger20214a3}.",
      "intriguing_abstract": "Ensuring the trustworthiness of deep learning models in high-stakes applications, such as clinical decision-making, hinges on their ability to detect out-of-distribution (OOD) inputs. Modern neural networks often exhibit dangerous overconfidence when presented with data outside their training distribution, posing significant risks. This paper presents a comprehensive comparative study of state-of-the-art *confidence-based OOD detection methods*, critically evaluating their performance not only on standard computer vision benchmarks but, uniquely, on challenging *real-world medical imaging* (chest X-rays).\n\nOur rigorous analysis reveals a stark *domain-specific performance discrepancy*: methods excelling in generic tasks often fail in medical contexts. We identify *ODIN* as a consistently robust performer, achieving superior *AUROC* scores in medical imaging by a considerable margin. Crucially, we empirically demonstrate that *ODIN's effectiveness stems primarily from its input perturbation mechanism*, which significantly enhances the separation of in-distribution and OOD samples in the *feature space*. In contrast, methods like *Mahalanobis distance*, top-tier in CV, prove ineffective for medical OOD detection due to less separable feature clusters. These findings provide vital insights for developing reliable *deep learning* systems, underscoring the imperative for *domain-specific validation* and guiding the design of next-generation OOD techniques for truly trustworthy AI in critical applications.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "medical imaging",
        "confidence-based OOD methods",
        "comparative study",
        "ODIN",
        "input perturbation",
        "Mahalanobis Distance",
        "domain-specific performance discrepancy",
        "feature space separation",
        "image classification",
        "clinical decision-making",
        "uncertainty quantification",
        "AUROC"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/3430707312d8d9192f2f4b967f541f96618ba393.pdf",
      "citation_key": "berger20214a3",
      "metadata": {
        "title": "Confidence-based Out-of-Distribution Detection: A Comparative Study and Analysis",
        "authors": [
          "Christoph Berger",
          "Magdalini Paschali",
          "Ben Glocker",
          "K. Kamnitsas"
        ],
        "published_date": "2021",
        "abstract": "Image classification models deployed in the real world may receive inputs outside the intended data distribution. For critical applications such as clinical decision making, it is important that a model can detect such out-of-distribution (OOD) inputs and express its uncertainty. In this work, we assess the capability of various state-of-the-art approaches for confidence-based OOD detection through a comparative study and in-depth analysis. First, we leverage a computer vision benchmark to reproduce and compare multiple OOD detection methods. We then evaluate their capabilities on the challenging task of disease classification using chest X-rays. Our study shows that high performance in a computer vision task does not directly translate to accuracy in a medical imaging task. We analyse factors that affect performance of the methods between the two tasks. Our results provide useful insights for developing the next generation of OOD detection methods.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/3430707312d8d9192f2f4b967f541f96618ba393.pdf",
        "venue": "UNSURE/PIPPI@MICCAI",
        "citationCount": 47,
        "score": 11.75,
        "summary": "Here is a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of detecting out-of-distribution (OOD) inputs in image classification models, particularly for high-stakes applications like clinical decision-making \\cite{berger20214a3}.\n    *   This problem is important because modern classification models often exhibit overconfidence, even when presented with inputs far outside their training distribution, leading to a false sense of competence and potential risks in critical scenarios (e.g., misdiagnosing unseen pathologies in medical imaging) \\cite{berger20214a3}. The challenge lies in enabling models to \"know their capabilities\" and signal uncertainty for OOD inputs.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods generally fall into two categories: those that build dedicated OOD models (e.g., density estimation, decision boundary learning, reconstruction-based) and those that enhance a task-specific model to detect OOD inputs, often based on prediction confidence \\cite{berger20214a3}.\n    *   Limitations of previous solutions include the difficulty of accurately learning data density, the challenge of collecting or synthesizing diverse OOD data for dedicated models, and the limited performance of reconstruction-based methods for complex tasks \\cite{berger20214a3}.\n    *   This work specifically focuses on the second categoryâ€”confidence-based OOD detection methodsâ€”which are compact, integrated into existing models, and operate in the task-specific feature or output space. It positions itself by highlighting the limited investigation of these methods' potential for medical imaging, despite their importance \\cite{berger20214a3}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical approach is a comprehensive comparative study and in-depth analysis of various state-of-the-art confidence-based OOD detection methods: Maximum Class Probability (MCP), Mahalanobis Distance, Out-of-Distribution Detector for Neural Networks (ODIN), Deep Ensembles, Monte Carlo Dropout (MCDP), and Deterministic Uncertainty Quantification (DUQ) \\cite{berger20214a3}.\n    *   The innovation lies in:\n        *   Re-implementing and comparing these diverse methods in a common test-bed for fair evaluation \\cite{berger20214a3}.\n        *   Evaluating their performance not only on a standard computer vision (CV) benchmark but critically, on a challenging real-world medical imaging task (chest X-rays) \\cite{berger20214a3}.\n        *   Conducting an empirical analysis to identify factors influencing performance discrepancies between CV and medical tasks, providing insights for future OOD method development \\cite{berger20214a3}.\n\n*   **Key Technical Contributions**\n    *   **Comprehensive Comparative Study**: A systematic evaluation of prominent confidence-based OOD detection methods, establishing a benchmark for their performance across different domains \\cite{berger20214a3}.\n    *   **Domain-Specific Performance Discrepancy**: Demonstrating that high OOD detection performance on a general computer vision task does not directly translate to accuracy in a medical imaging task, highlighting the need for domain-specific validation \\cite{berger20214a3}.\n    *   **Identification of Robust Method**: Identifying ODIN as a consistently high-performing OOD detection method across both CV and challenging medical imaging tasks, often by a considerable margin \\cite{berger20214a3}.\n    *   **Analysis of ODIN's Mechanism**: Empirically showing that ODIN's effectiveness is primarily attributed to its input perturbation mechanism, which enhances the separation of in-distribution (ID) and OOD samples in the feature space \\cite{berger20214a3}.\n    *   **Insights into Mahalanobis Failure**: Providing an analysis of why Mahalanobis distance, a top performer in CV, fails in the medical imaging context, attributing it to less separable ID/OOD clusters in the feature space, making Gaussian fitting challenging \\cite{berger20214a3}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   **Computer Vision Benchmark**: OOD detection on CIFAR10 (ID) vs. SVHN (OOD) using a WideResNet 28x10 model \\cite{berger20214a3}.\n        *   **Medical Imaging Benchmark**: OOD detection on the CheXpert chest X-ray dataset, simulating two clinical settings with different ID/OOD class combinations, using a WideResNet 100x2 model \\cite{berger20214a3}.\n        *   **Ablation Studies**: Investigating the individual contributions of ODIN's perturbation and temperature scaling components, and the effect of dimensionality reduction for Mahalanobis distance \\cite{berger20214a3}.\n        *   **Visualization**: T-SNE plots of feature embeddings to analyze ID/OOD separability \\cite{berger20214a3}.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic (AUROC), Area Under the Precision-Recall Curve (AUCPR), ID Accuracy (Acc), and Expected Calibration Error (ECE) \\cite{berger20214a3}.\n    *   **Comparison Results**:\n        *   On CIFAR10 vs SVHN, Mahalanobis distance (single model and ensemble) achieved the highest AUROC (0.984 and 0.987, respectively), followed by ODIN (0.964) and Deep Ensembles (0.960) \\cite{berger20214a3}. DUQ showed unstable training and poor performance (0.833 AUROC) \\cite{berger20214a3}.\n        *   On CheXpert, ODIN significantly outperformed all other methods in both settings, achieving AUROCs of 0.841 and 0.862, respectively, with its input perturbation being the primary driver of this performance \\cite{berger20214a3}.\n        *   Mahalanobis distance, despite its strong CV performance, performed worse than the baseline MCP in one medical setting (0.580 vs 0.678 AUROC) and only showed modest improvement in the other \\cite{berger20214a3}.\n        *   The study confirmed that performance does not directly translate between CV and medical tasks, with medical tasks being significantly more challenging for OOD detection \\cite{berger20214a3}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: Mahalanobis distance was found to be ineffective in the medical imaging task due to less separable ID and OOD clusters in the feature space, making the assumption of Gaussian class-conditional distributions challenging \\cite{berger20214a3}. DUQ faced difficulties with stable training and convergence on the WideResNet architecture used \\cite{berger20214a3}.\n    *   **Scope of Applicability**: The study focused specifically on confidence-based OOD detection methods and evaluated them on image classification tasks using specific datasets (CIFAR10, SVHN, CheXpert) and model architectures (WideResNet) \\cite{berger20214a3}. The findings are particularly relevant for medical imaging applications but suggest broader implications for domain transfer of OOD methods.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a rigorous comparative analysis of confidence-based OOD detection methods, specifically highlighting their varying reliability across different data domains \\cite{berger20214a3}.\n    *   It offers crucial insights for developing the next generation of OOD detection methods, particularly for critical applications like medical AI, by demonstrating that CV performance does not guarantee success in medical tasks \\cite{berger20214a3}.\n    *   The identification of ODIN's input perturbation as a key mechanism for enhancing ID/OOD separation provides a valuable direction for future research into robust OOD detection techniques \\cite{berger20214a3}.\n    *   The study underscores the importance of domain-specific evaluation and analysis for OOD detection methods, moving beyond generic benchmarks to ensure practical applicability and reliability in real-world deployments \\cite{berger20214a3}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "medical imaging",
          "confidence-based OOD methods",
          "comparative study",
          "ODIN",
          "input perturbation",
          "Mahalanobis Distance",
          "domain-specific performance discrepancy",
          "feature space separation",
          "image classification",
          "clinical decision-making",
          "uncertainty quantification",
          "AUROC"
        ],
        "paper_type": "based on the abstract and introduction, this paper best fits the **empirical** type.\n\nhere's why:\n\n*   **abstract mentions:**\n    *   \"assess the capability of various state-of-the-art approaches... through a comparative study and in-depth analysis.\" (implies data-driven evaluation)\n    *   \"leverage a computer vision benchmark to reproduce and compare multiple ood detection methods.\" (explicitly describes an experiment/study using data)\n    *   \"evaluate their capabilities on the challenging task of disease classification using chest x-rays.\" (more data-driven evaluation)\n    *   \"our study shows that...\" (directly refers to findings from their study)\n    *   \"we analyse factors that affect performance...\" (statistical analysis of results)\n    *   \"our results provide useful insights...\" (findings from the empirical work)\n*   **introduction discusses:**\n    *   \"in this work, we first explore confidence- and distance-based approaches for out-of-distribution (ood) detection on a standard computer vision (cv) task and afterwards evaluate the best ood detection methods on a medical benchmark dataset.\" (clearly outlines the methodology of their data-driven study)\n    *   \"moreover, we provide a set of useful insights for leveraging ood approaches from computer vision to challenging medical datasets.\" (highlights the practical findings from their empirical evaluation)\n\nwhile it compares existing methods, which might have a \"survey-like\" element, the core of the paper is the *reproduction, evaluation, and analysis* of these methods through *new experiments on specific datasets*, leading to *new findings*. this is the hallmark of an empirical study."
      },
      "file_name": "3430707312d8d9192f2f4b967f541f96618ba393.pdf"
    },
    {
      "success": true,
      "doc_id": "bd7ec5c080c7b1f4cae6f826710e3021",
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep Neural Networks (DNNs) operate under a \"close-world\" assumption, making them vulnerable to Out-of-Distribution (OOD) samples in real-world \"open-world\" deployments. OOD samples can lead to highly confident but incorrect predictions, posing significant safety and reliability challenges for DNNs \\cite{yang2022ci8}.\n    *   **Importance and Challenge**: Distinguishing OOD samples from in-distribution (In-D) data is crucial for safe DNN deployment. Existing methods face challenges: feature-sharing strategies often trade off In-D accuracy for OOD detection, density-based methods' probabilistic measures can be untrustworthy (assigning high likelihood to OODs), and reconstruction-based methods may faithfully reconstruct OODs, leading to misjudgments \\cite{yang2022ci8}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: MoodCat \\cite{yang2022ci8} is positioned as a novel distance-based OOD detection framework, distinct from classification-based, density-based, and traditional reconstruction-based methods. It is inspired by adversarial example detection but adapts the concept for OODs, which are semantically different rather than imperceptibly perturbed In-D samples.\n    *   **Limitations of Previous Solutions**:\n        *   **Classification-based**: Often alter the original classifier's training, reducing In-D accuracy \\cite{yang2022ci8}.\n        *   **Density-based**: Learned density models may assign high likelihood to OODs, as measures can be dominated by low-level features rather than high-level semantics \\cite{yang2022ci8}.\n        *   **Reconstruction-based**: Assume OODs cannot be well-reconstructed, but this is not always true, as they don't explicitly consider semantics. They focus on pixel-level quality degradation, which isn't guaranteed for OODs \\cite{yang2022ci8}.\n        *   **Open Set Recognition (OSR)**: While some OSR methods use generative models, they differ significantly; e.g., some use GANs for data augmentation, others identify outliers based on reconstruction errors requiring K-time inference, or detect in latent space, whereas MoodCat detects in image space based on semantic contradiction \\cite{yang2022ci8}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: MoodCat \\cite{yang2022ci8} operates in three stages:\n        1.  **Random Masking**: A random portion of the input image `x` is masked to create `xm`. This removes redundant information and encourages the generative model to synthesize new content.\n        2.  **Generative Synthesis**: A generative model `G` (an Encoder-Decoder architecture) synthesizes a new image `x'` from `xm`, *conditioned on the classification result `y`* (predicted label from the target classifier). The encoder extracts low-level features, and the decoder uses class-conditional batch normalization to ensure `x'` aligns with the semantic meaning of `y`.\n        3.  **Anomalous Scoring**: An anomalous scoring model measures the semantic difference between the original image `x` and the synthesized image `x'` for OOD detection.\n    *   **Novelty/Difference**:\n        *   **Semantic Mismatch under Masking**: The core innovation is leveraging the semantic mismatch that arises when an OOD sample (with an irrelevant predicted label) is used to conditionally synthesize a masked image. For In-D, the synthesis is faithful; for OOD, the synthesis dramatically differs from the original, spotlighting the contradiction \\cite{yang2022ci8}.\n        *   **Conditional Synthesis vs. Reconstruction**: Unlike reconstruction-based methods, MoodCat *synthesizes* an image consistent with a *given label* rather than merely reconstructing the input. This aligns with the generative model's objective and highlights semantic discrepancies \\cite{yang2022ci8}.\n        *   **Plug-and-Play**: MoodCat is a standalone detector that does not require fine-tuning the original classifier, preserving its accuracy and allowing easy integration \\cite{yang2022ci8}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Framework**: Introduction of MoodCat, a novel OOD detection framework that explicitly considers semantic information by identifying semantic mismatch under masking \\cite{yang2022ci8}.\n    *   **Masking and Conditional Synthesis Flow**: A novel flow involving random masking of input images and conditional synthesis using a generative model (Encoder-Decoder with class-conditional batch normalization) to highlight semantic contradictions \\cite{yang2022ci8}.\n    *   **Anomalous Scoring Model**: Development of a scoring model composed of:\n        *   A newly-proposed **conditional binary classifier**: Trained to identify semantic mismatch using In-D samples with ground truth labels (positive pairs) and In-D samples with randomly mismatched labels (negative pairs) to simulate OOD behavior. It is conditioned on the semantic label via a projection layer for fine-grained decision boundaries \\cite{yang2022ci8}.\n        *   Various **Image Quality Assessment (IQA) metrics**: Such as DISTS and LPIPS, to evaluate the perceptual quality difference between the original and synthesized images \\cite{yang2022ci8}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: Comprehensive evaluations were performed on standard OOD detection benchmarks, utilizing six datasets and four detection settings \\cite{yang2022ci8}.\n    *   **Key Performance Metrics and Comparison Results**: The paper claims that MoodCat significantly outperforms state-of-the-art (SOTA) OOD detection solutions by a large margin. While specific metrics (e.g., AUROC, FPR95) are not detailed in the provided abstract/introduction, the overall claim is strong empirical superiority \\cite{yang2022ci8}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the predicted label from the classifier. While it can leverage unlabeled extra data for training the conditional binary classifier, it does not inherently address scenarios where the classifier's initial prediction for an OOD sample is highly uncertain or completely random \\cite{yang2022ci8}.\n    *   **Scope of Applicability**: MoodCat is designed for image classifiers and functions as a plug-and-play detector, meaning it can be combined with any classifier without affecting its accuracy. Its effectiveness is demonstrated on standard image datasets \\cite{yang2022ci8}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: MoodCat \\cite{yang2022ci8} advances the technical state-of-the-art by being the first work to explicitly consider semantic information for OOD detection through its novel masking and conditional synthesis strategy. Its ability to significantly outperform SOTA solutions indicates a substantial improvement in detection capabilities.\n    *   **Potential Impact**: By providing a robust, plug-and-play OOD detection capability without compromising the original classifier's accuracy, MoodCat can greatly enhance the deployment safety and reliability of DNNs in open-world environments, fostering more trustworthy AI systems \\cite{yang2022ci8}.",
      "intriguing_abstract": "Deep Neural Networks, while powerful, remain critically vulnerable to Out-of-Distribution (OOD) samples in real-world \"open-world\" deployments. This vulnerability leads to confident yet erroneous predictions, posing significant safety and reliability challenges. Robust OOD detection is paramount, yet existing methods often compromise in-distribution accuracy or fail to capture true semantic discrepancies.\n\nWe introduce MoodCat, a novel plug-and-play OOD detection framework that explicitly identifies semantic mismatch. Unlike traditional reconstruction-based approaches, MoodCat employs a unique three-stage process: random masking of input images, followed by conditional synthesis using a generative Encoder-Decoder model. This model synthesizes a new image *conditioned on the classifier's predicted label*. For OOD samples, this conditioning leads to a dramatic semantic contradiction between the original and synthesized images, which is then precisely quantified by an anomalous scoring model, including a novel conditional binary classifier. MoodCat significantly outperforms state-of-the-art solutions across diverse benchmarks, preserving classifier accuracy and paving the way for more reliable and trustworthy AI systems in open-world scenarios.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Deep Neural Networks (DNNs)",
        "open-world deployments",
        "MoodCat framework",
        "semantic mismatch",
        "conditional synthesis",
        "random masking",
        "generative models",
        "class-conditional batch normalization",
        "anomalous scoring",
        "conditional binary classifier",
        "plug-and-play",
        "state-of-the-art (SOTA) performance",
        "deployment safety and reliability"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/977384045381a2c45dfac4797196d34658d8a44f.pdf",
      "citation_key": "yang2022ci8",
      "metadata": {
        "title": "Out-of-Distribution Detection with Semantic Mismatch under Masking",
        "authors": [
          "Yijun Yang",
          "Ruiyuan Gao",
          "Qiang Xu"
        ],
        "published_date": "2022",
        "abstract": "This paper proposes a novel out-of-distribution (OOD) detection framework named MoodCat for image classifiers. MoodCat masks a random portion of the input image and uses a generative model to synthesize the masked image to a new image conditioned on the classification result. It then calculates the semantic difference between the original image and the synthesized one for OOD detection. Compared to existing solutions, MoodCat naturally learns the semantic information of the in-distribution data with the proposed mask and conditional synthesis strategy, which is critical to identifying OODs. Experimental results demonstrate that MoodCat outperforms state-of-the-art OOD detection solutions by a large margin.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/977384045381a2c45dfac4797196d34658d8a44f.pdf",
        "venue": "European Conference on Computer Vision",
        "citationCount": 35,
        "score": 11.666666666666666,
        "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep Neural Networks (DNNs) operate under a \"close-world\" assumption, making them vulnerable to Out-of-Distribution (OOD) samples in real-world \"open-world\" deployments. OOD samples can lead to highly confident but incorrect predictions, posing significant safety and reliability challenges for DNNs \\cite{yang2022ci8}.\n    *   **Importance and Challenge**: Distinguishing OOD samples from in-distribution (In-D) data is crucial for safe DNN deployment. Existing methods face challenges: feature-sharing strategies often trade off In-D accuracy for OOD detection, density-based methods' probabilistic measures can be untrustworthy (assigning high likelihood to OODs), and reconstruction-based methods may faithfully reconstruct OODs, leading to misjudgments \\cite{yang2022ci8}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: MoodCat \\cite{yang2022ci8} is positioned as a novel distance-based OOD detection framework, distinct from classification-based, density-based, and traditional reconstruction-based methods. It is inspired by adversarial example detection but adapts the concept for OODs, which are semantically different rather than imperceptibly perturbed In-D samples.\n    *   **Limitations of Previous Solutions**:\n        *   **Classification-based**: Often alter the original classifier's training, reducing In-D accuracy \\cite{yang2022ci8}.\n        *   **Density-based**: Learned density models may assign high likelihood to OODs, as measures can be dominated by low-level features rather than high-level semantics \\cite{yang2022ci8}.\n        *   **Reconstruction-based**: Assume OODs cannot be well-reconstructed, but this is not always true, as they don't explicitly consider semantics. They focus on pixel-level quality degradation, which isn't guaranteed for OODs \\cite{yang2022ci8}.\n        *   **Open Set Recognition (OSR)**: While some OSR methods use generative models, they differ significantly; e.g., some use GANs for data augmentation, others identify outliers based on reconstruction errors requiring K-time inference, or detect in latent space, whereas MoodCat detects in image space based on semantic contradiction \\cite{yang2022ci8}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: MoodCat \\cite{yang2022ci8} operates in three stages:\n        1.  **Random Masking**: A random portion of the input image `x` is masked to create `xm`. This removes redundant information and encourages the generative model to synthesize new content.\n        2.  **Generative Synthesis**: A generative model `G` (an Encoder-Decoder architecture) synthesizes a new image `x'` from `xm`, *conditioned on the classification result `y`* (predicted label from the target classifier). The encoder extracts low-level features, and the decoder uses class-conditional batch normalization to ensure `x'` aligns with the semantic meaning of `y`.\n        3.  **Anomalous Scoring**: An anomalous scoring model measures the semantic difference between the original image `x` and the synthesized image `x'` for OOD detection.\n    *   **Novelty/Difference**:\n        *   **Semantic Mismatch under Masking**: The core innovation is leveraging the semantic mismatch that arises when an OOD sample (with an irrelevant predicted label) is used to conditionally synthesize a masked image. For In-D, the synthesis is faithful; for OOD, the synthesis dramatically differs from the original, spotlighting the contradiction \\cite{yang2022ci8}.\n        *   **Conditional Synthesis vs. Reconstruction**: Unlike reconstruction-based methods, MoodCat *synthesizes* an image consistent with a *given label* rather than merely reconstructing the input. This aligns with the generative model's objective and highlights semantic discrepancies \\cite{yang2022ci8}.\n        *   **Plug-and-Play**: MoodCat is a standalone detector that does not require fine-tuning the original classifier, preserving its accuracy and allowing easy integration \\cite{yang2022ci8}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Framework**: Introduction of MoodCat, a novel OOD detection framework that explicitly considers semantic information by identifying semantic mismatch under masking \\cite{yang2022ci8}.\n    *   **Masking and Conditional Synthesis Flow**: A novel flow involving random masking of input images and conditional synthesis using a generative model (Encoder-Decoder with class-conditional batch normalization) to highlight semantic contradictions \\cite{yang2022ci8}.\n    *   **Anomalous Scoring Model**: Development of a scoring model composed of:\n        *   A newly-proposed **conditional binary classifier**: Trained to identify semantic mismatch using In-D samples with ground truth labels (positive pairs) and In-D samples with randomly mismatched labels (negative pairs) to simulate OOD behavior. It is conditioned on the semantic label via a projection layer for fine-grained decision boundaries \\cite{yang2022ci8}.\n        *   Various **Image Quality Assessment (IQA) metrics**: Such as DISTS and LPIPS, to evaluate the perceptual quality difference between the original and synthesized images \\cite{yang2022ci8}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: Comprehensive evaluations were performed on standard OOD detection benchmarks, utilizing six datasets and four detection settings \\cite{yang2022ci8}.\n    *   **Key Performance Metrics and Comparison Results**: The paper claims that MoodCat significantly outperforms state-of-the-art (SOTA) OOD detection solutions by a large margin. While specific metrics (e.g., AUROC, FPR95) are not detailed in the provided abstract/introduction, the overall claim is strong empirical superiority \\cite{yang2022ci8}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the predicted label from the classifier. While it can leverage unlabeled extra data for training the conditional binary classifier, it does not inherently address scenarios where the classifier's initial prediction for an OOD sample is highly uncertain or completely random \\cite{yang2022ci8}.\n    *   **Scope of Applicability**: MoodCat is designed for image classifiers and functions as a plug-and-play detector, meaning it can be combined with any classifier without affecting its accuracy. Its effectiveness is demonstrated on standard image datasets \\cite{yang2022ci8}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: MoodCat \\cite{yang2022ci8} advances the technical state-of-the-art by being the first work to explicitly consider semantic information for OOD detection through its novel masking and conditional synthesis strategy. Its ability to significantly outperform SOTA solutions indicates a substantial improvement in detection capabilities.\n    *   **Potential Impact**: By providing a robust, plug-and-play OOD detection capability without compromising the original classifier's accuracy, MoodCat can greatly enhance the deployment safety and reliability of DNNs in open-world environments, fostering more trustworthy AI systems \\cite{yang2022ci8}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Deep Neural Networks (DNNs)",
          "open-world deployments",
          "MoodCat framework",
          "semantic mismatch",
          "conditional synthesis",
          "random masking",
          "generative models",
          "class-conditional batch normalization",
          "anomalous scoring",
          "conditional binary classifier",
          "plug-and-play",
          "state-of-the-art (SOTA) performance",
          "deployment safety and reliability"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the **abstract** explicitly states: \"this paper proposes a novel out-of-distribution (ood) detection framework named moodcat...\" and then describes its mechanism (\"masks a random portion...\", \"uses a generative model to synthesize...\", \"calculates the semantic difference...\"). it also mentions \"experimental results demonstrate that moodcat outperforms state-of-the-art...\".\n*   the **introduction** sets up a technical problem (ood samples misleading dnns) and briefly reviews existing technical approaches and their limitations, paving the way for a new solution.\n\nthis content strongly aligns with the **technical** classification criteria:\n*   abstract mentions: \"propose\", \"develop\" (implicitly, a framework is developed), \"present\" (a framework), \"algorithm\" (implicitly, the framework involves algorithms), \"method\".\n*   introduction discusses: \"technical problem\", \"proposed solution\" (implied, as it critiques existing ones and sets the stage for its own).\n\nwhile it includes \"experimental results\" (which points to empirical), the core contribution is the *novel framework* and its underlying *methodology*. the experiments serve to validate this new technical contribution.\n\ntherefore, the paper type is **technical**."
      },
      "file_name": "977384045381a2c45dfac4797196d34658d8a44f.pdf"
    },
    {
      "success": true,
      "doc_id": "63b247c2bc5b692f79390db0a5957daa",
      "summary": "Semantically coherent out-of-distribution (SCOOD) detection aims to discern outliers from the intended data distribution with access to unlabeled extra set. The coexistence of in-distribution and out-of-distribution samples will exacerbate the model overfitting when no distinction is made. To address this problem, we propose a novel uncertainty-aware optimal transport scheme. Our scheme consists of an energy-based transport (ET) mechanism that estimates the fluctuating cost of uncertainty to promote the assignment of semantic-agnostic representation, and an inter-cluster extension strategy that enhances the discrimination of semantic property among different clusters by widening the corresponding margin distance. Furthermore, a T-energy score is presented to mitigate the magnitude gap between the parallel transport and classifier branches. Extensive experiments on two standard SCOOD benchmarks demonstrate the above-par OOD detection performance, outperforming the state-of-the-art methods by a margin of 27.69% and 34.4% on FPR@95, respectively. Code is available at https://github.com/LuFan3/IET-OOD.",
      "intriguing_abstract": "Semantically coherent out-of-distribution (SCOOD) detection aims to discern outliers from the intended data distribution with access to unlabeled extra set. The coexistence of in-distribution and out-of-distribution samples will exacerbate the model overfitting when no distinction is made. To address this problem, we propose a novel uncertainty-aware optimal transport scheme. Our scheme consists of an energy-based transport (ET) mechanism that estimates the fluctuating cost of uncertainty to promote the assignment of semantic-agnostic representation, and an inter-cluster extension strategy that enhances the discrimination of semantic property among different clusters by widening the corresponding margin distance. Furthermore, a T-energy score is presented to mitigate the magnitude gap between the parallel transport and classifier branches. Extensive experiments on two standard SCOOD benchmarks demonstrate the above-par OOD detection performance, outperforming the state-of-the-art methods by a margin of 27.69% and 34.4% on FPR@95, respectively. Code is available at https://github.com/LuFan3/IET-OOD.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/b585f1739cbbbca7b2695ce2e9f780ea625f9cef.pdf",
      "citation_key": "lu2023i8o",
      "metadata": {
        "title": "Uncertainty-Aware Optimal Transport for Semantically Coherent Out-of-Distribution Detection",
        "authors": [
          "Fan Lu",
          "Kai Zhu",
          "Wei Zhai",
          "Kecheng Zheng",
          "Yang Cao"
        ],
        "published_date": "2023",
        "abstract": "Semantically coherent out-of-distribution (SCOOD) detection aims to discern outliers from the intended data distribution with access to unlabeled extra set. The coexistence of in-distribution and out-of-distribution samples will exacerbate the model overfitting when no distinction is made. To address this problem, we propose a novel uncertainty-aware optimal transport scheme. Our scheme consists of an energy-based transport (ET) mechanism that estimates the fluctuating cost of uncertainty to promote the assignment of semantic-agnostic representation, and an inter-cluster extension strategy that enhances the discrimination of semantic property among different clusters by widening the corresponding margin distance. Furthermore, a T-energy score is presented to mitigate the magnitude gap between the parallel transport and classifier branches. Extensive experiments on two standard SCOOD benchmarks demonstrate the above-par OOD detection performance, outperforming the state-of-the-art methods by a margin of 27.69% and 34.4% on FPR@95, respectively. Code is available at https://github.com/LuFan3/IET-OOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b585f1739cbbbca7b2695ce2e9f780ea625f9cef.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 23,
        "score": 11.5,
        "summary": "Semantically coherent out-of-distribution (SCOOD) detection aims to discern outliers from the intended data distribution with access to unlabeled extra set. The coexistence of in-distribution and out-of-distribution samples will exacerbate the model overfitting when no distinction is made. To address this problem, we propose a novel uncertainty-aware optimal transport scheme. Our scheme consists of an energy-based transport (ET) mechanism that estimates the fluctuating cost of uncertainty to promote the assignment of semantic-agnostic representation, and an inter-cluster extension strategy that enhances the discrimination of semantic property among different clusters by widening the corresponding margin distance. Furthermore, a T-energy score is presented to mitigate the magnitude gap between the parallel transport and classifier branches. Extensive experiments on two standard SCOOD benchmarks demonstrate the above-par OOD detection performance, outperforming the state-of-the-art methods by a margin of 27.69% and 34.4% on FPR@95, respectively. Code is available at https://github.com/LuFan3/IET-OOD.",
        "keywords": []
      },
      "file_name": "b585f1739cbbbca7b2695ce2e9f780ea625f9cef.pdf"
    },
    {
      "success": true,
      "doc_id": "f523004d59e1927b4c8a165b6620740b",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/b6dc9a38916cefcb81245e2d1fb6c00dcfc584b0.pdf",
      "citation_key": "kim2024nhz",
      "metadata": {
        "title": "Investigation of out-of-distribution detection across various models and training methodologies",
        "authors": [
          "B. Kim",
          "B. Kim",
          "Y. Hyun"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b6dc9a38916cefcb81245e2d1fb6c00dcfc584b0.pdf",
        "venue": "Neural Networks",
        "citationCount": 11,
        "score": 11.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "b6dc9a38916cefcb81245e2d1fb6c00dcfc584b0.pdf"
    },
    {
      "success": true,
      "doc_id": "6ae57cde02bb96f6a0bcce3781eb2f2e",
      "summary": "Here's a focused summary of the technical paper \\cite{miao2023brn} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing Out-of-Distribution (OOD) detection methods, successful on balanced datasets, become ineffective in Long-Tailed Recognition (LTR) scenarios. This ineffectiveness manifests in two key issues: 1) OOD samples are frequently misclassified into head (majority) classes, and 2) tail (minority) class samples are often erroneously treated as OOD samples \\cite{miao2023brn}.\n    *   **Importance and Challenge**: This problem is critical for real-world applications like autonomous driving and medical diagnosis, where both class imbalance and unknown inputs are common. Current LTR OOD approaches attempt to fit a prior distribution of auxiliary/pseudo OOD data to the long-tailed in-distribution (ID) data. However, obtaining an accurate prior distribution is challenging due to the inherent unknowability of real OOD samples and the severe class imbalance in LTR datasets \\cite{miao2023brn}. A straightforward solution of learning an outlier class faces the core challenge of distinguishing OOD samples from both head and tail ID classes.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself against general OOD detection methods (e.g., Outlier Exposure (OE) \\cite{miao2023brn}, EnergyOE, UDG) which are primarily designed for balanced ID datasets. It also differentiates from traditional LTR methods (e.g., re-sampling, re-weighting, two-stage methods, logit adjustment) that focus solely on ID classification accuracy without explicit OOD handling \\cite{miao2023brn}.\n    *   **Limitations of Previous Solutions**: Prior OOD detection methods in LTR (e.g., PASCL, Open sampling, and recent studies fitting OOD data to a long-tailed distribution) rely on estimating an accurate prior distribution for OOD data, which is difficult to obtain. \\cite{miao2023brn} empirically demonstrates that Outlier Class Learning (OCL) is generally more effective than OE for LTR because OE's uniform prediction probability prior does not hold in long-tailed settings. However, even OCL alone struggles with the confusion between OOD, head, and tail samples.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{miao2023brn} introduces Calibrated Outlier Class Learning (COCL), a novel approach that extends the label space with an explicit outlier class to encapsulate OOD samples. COCL addresses the OOD/head/tail confusion through two main components:\n        1.  **Debiased Large Margin Learning (Training Stage)**: Designed to reduce biases towards head classes (preventing OOD misclassification as head) and OOD samples (preventing tail misclassification as OOD) in the representation space.\n        2.  **Outlier-Class-Aware Logit Calibration (Inference Stage)**: Utilizes the logit of the outlier class to calibrate ID prediction probabilities, enhancing both OOD detection and long-tailed classification confidence.\n    *   **Novelty/Difference**: The novelty lies in the specific design of the debiased large margin learning, which includes:\n        *   **OOD-Aware Tail Class Prototype Learning**: Uses learnable prototypes for tail classes, pulling tail samples closer to their respective prototypes while pushing OOD samples and other tail prototypes away. This directly tackles the issue of tail samples being mistaken for OOD.\n        *   **Debiased Head Class Learning**: Employs a semi-supervised one-class learning approach for OOD samples, using OOD samples as anchors, distant OOD samples as positives, and random head samples as negatives. This aims to create a large, distinct outlier-class description region to alleviate the dominant influence of head classes on OOD samples.\n        *   The integration of these training-time representation learning strategies with an inference-time logit calibration method, specifically leveraging the learned outlier class logit, is also a key innovation.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduction of Calibrated Outlier Class Learning (COCL) as a comprehensive framework for OOD detection in LTR.\n        *   Debiased Large Margin Learning, comprising:\n            *   OOD-Aware Tail Class Prototype Learning (Eq. 3, 4) to improve tail class representation and separation from OOD.\n            *   Debiased Head Class Learning (Eq. 5, 6) for robust one-class learning of OOD samples, mitigating head class bias.\n        *   Outlier-Class-Aware Logit Calibration for enhancing inference-time OOD detection and ID classification confidence.\n    *   **System Design/Architectural Innovations**: The paper demonstrates that Outlier Class Learning (OCL) is inherently more effective for OOD detection in LTR than Outlier Exposure (OE) when auxiliary OOD data is available, shifting the foundational approach for this problem.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive empirical evaluations were performed on three popular long-tailed benchmarks: CIFAR10-LT, CIFAR100-LT, and ImageNet-LT \\cite{miao2023brn}. The OOD detection performance was assessed against six diverse OOD test sets (CIFAR, Texture, SVHN, LSUN, Places365, TinyImagenet) for the CIFAR-LT datasets.\n    *   **Key Performance Metrics**: Performance was measured using standard OOD detection metrics: Area Under the Receiver Operating Characteristic Curve (AUC), Average Precision for In-distribution (AP-in), Average Precision for Out-of-distribution (AP-out), False Positive Rate at 95% True Positive Rate (FPR95), and In-distribution Classification Accuracy (ACC) \\cite{miao2023brn}.\n    *   **Comparison Results**: COCL substantially outperforms state-of-the-art OOD detection methods in LTR. For instance, on CIFAR10-LT, COCL achieved an AUC of 93.28, FPR95 of 30.88, and ACC of 81.56, significantly surpassing the best OCL baseline (OCL+LA: AUC 91.56, FPR95 36.50, ACC 76.67) and OE baselines (OE+LA: AUC 89.46, FPR95 53.38, ACC 73.93) \\cite{miao2023brn}. The results consistently show COCL's superiority across all metrics and datasets, demonstrating its ability to improve both OOD detection performance and ID classification accuracy simultaneously.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the availability of auxiliary OOD data during training. The effectiveness might be influenced by the quality and diversity of this auxiliary data. The paper does not explicitly discuss the sensitivity to hyperparameters (e.g., `Î³`, `t`, `margin`).\n    *   **Scope of Applicability**: The approach is specifically designed for OOD detection in scenarios where the in-distribution data exhibits a long-tailed class distribution. While effective in this domain, its direct applicability or comparative advantage in balanced ID OOD detection scenarios is not the primary focus.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{miao2023brn} significantly advances the technical state-of-the-art for OOD detection in LTR by effectively mitigating the critical biases that plague existing methods (OOD samples misclassified as head, tail samples misclassified as OOD). It provides a robust framework that simultaneously improves both OOD detection and ID classification accuracy.\n    *   **Potential Impact on Future Research**: The work highlights the superior effectiveness of Outlier Class Learning over Outlier Exposure in LTR, potentially guiding future research towards OCL-based approaches. The proposed debiased large margin learning and outlier-class-aware logit calibration offer novel components that can be adapted or extended in other OOD detection or imbalanced learning contexts. It opens avenues for exploring more sophisticated representation learning techniques tailored to the unique challenges of long-tailed data distributions in safety-critical applications.",
      "intriguing_abstract": "Real-world AI systems grapple with a crippling challenge: reliably detecting Out-of-Distribution (OOD) inputs amidst Long-Tailed Recognition (LTR) scenarios. Existing methods falter, frequently misclassifying critical OOD samples as dominant head classes, while erroneously flagging minority tail class samples as OOD. This fundamental confusion undermines trust in applications from autonomous driving to medical diagnosis.\n\nWe introduce Calibrated Outlier Class Learning (COCL), a pioneering framework that explicitly addresses this intricate OOD/head/tail dilemma. COCL innovates with a two-pronged approach: **Debiased Large Margin Learning** at the training stage, featuring novel OOD-Aware Tail Class Prototype Learning and Debiased Head Class Learning to forge robust, disentangled representations. This is complemented by **Outlier-Class-Aware Logit Calibration** during inference, which leverages the learned outlier class logit to enhance both OOD detection and in-distribution classification confidence.\n\nExtensive experiments on CIFAR-LT and ImageNet-LT benchmarks demonstrate COCL's unprecedented performance, significantly outperforming state-of-the-art OOD detection methods in LTR across AUC, FPR95, and classification accuracy. COCL not only sets a new benchmark but also redefines the efficacy of Outlier Class Learning for long-tailed data, paving the way for safer, more reliable AI in complex, imbalanced environments.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Long-Tailed Recognition (LTR)",
        "Calibrated Outlier Class Learning (COCL)",
        "Debiased Large Margin Learning",
        "OOD-Aware Tail Class Prototype Learning",
        "Debiased Head Class Learning",
        "Outlier-Class-Aware Logit Calibration",
        "Class imbalance",
        "Outlier Class Learning (OCL)",
        "State-of-the-art performance",
        "Simultaneous OOD detection and ID classification",
        "Real-world applications",
        "Representation space"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/f0f220240fc752b6b3c56464d96aeb322f221ef0.pdf",
      "citation_key": "miao2023brn",
      "metadata": {
        "title": "Out-of-Distribution Detection in Long-Tailed Recognition with Calibrated Outlier Class Learning",
        "authors": [
          "Wenjun Miao",
          "Guansong Pang",
          "Tianqi Li",
          "Xiaolong Bai",
          "Jingyi Zheng"
        ],
        "published_date": "2023",
        "abstract": "Existing out-of-distribution (OOD) methods have shown great success on balanced datasets but become ineffective in long-tailed recognition (LTR) scenarios where 1) OOD samples are often wrongly classified into head classes and/or 2) tail-class samples are treated as OOD samples. To address these issues, current studies fit a prior distribution of auxiliary/pseudo OOD data to the long-tailed in-distribution (ID) data. However, it is difficult to obtain such an accurate prior distribution given the unknowingness of real OOD samples and heavy class imbalance in LTR. A straightforward solution to avoid the requirement of this prior is to learn an outlier class to encapsulate the OOD samples. The main challenge is then to tackle the aforementioned confusion between OOD samples and head/tail-class samples when learning the outlier class. To this end, we introduce a novel calibrated outlier class learning (COCL) approach, in which 1) a debiased large margin learning method is introduced in the outlier class learning to distinguish OOD samples from both head and tail classes in the representation space and 2) an outlier-class-aware logit calibration method is defined to enhance the long-tailed classification confidence. Extensive empirical results on three popular benchmarks CIFAR10-LT, CIFAR100-LT, and ImageNet-LT demonstrate that COCL substantially outperforms existing state-of-the-art OOD detection methods in LTR while being able to improve the classification accuracy on ID data. Code is available at https://github.com/mala-lab/COCL.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/f0f220240fc752b6b3c56464d96aeb322f221ef0.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 22,
        "score": 11.0,
        "summary": "Here's a focused summary of the technical paper \\cite{miao2023brn} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing Out-of-Distribution (OOD) detection methods, successful on balanced datasets, become ineffective in Long-Tailed Recognition (LTR) scenarios. This ineffectiveness manifests in two key issues: 1) OOD samples are frequently misclassified into head (majority) classes, and 2) tail (minority) class samples are often erroneously treated as OOD samples \\cite{miao2023brn}.\n    *   **Importance and Challenge**: This problem is critical for real-world applications like autonomous driving and medical diagnosis, where both class imbalance and unknown inputs are common. Current LTR OOD approaches attempt to fit a prior distribution of auxiliary/pseudo OOD data to the long-tailed in-distribution (ID) data. However, obtaining an accurate prior distribution is challenging due to the inherent unknowability of real OOD samples and the severe class imbalance in LTR datasets \\cite{miao2023brn}. A straightforward solution of learning an outlier class faces the core challenge of distinguishing OOD samples from both head and tail ID classes.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself against general OOD detection methods (e.g., Outlier Exposure (OE) \\cite{miao2023brn}, EnergyOE, UDG) which are primarily designed for balanced ID datasets. It also differentiates from traditional LTR methods (e.g., re-sampling, re-weighting, two-stage methods, logit adjustment) that focus solely on ID classification accuracy without explicit OOD handling \\cite{miao2023brn}.\n    *   **Limitations of Previous Solutions**: Prior OOD detection methods in LTR (e.g., PASCL, Open sampling, and recent studies fitting OOD data to a long-tailed distribution) rely on estimating an accurate prior distribution for OOD data, which is difficult to obtain. \\cite{miao2023brn} empirically demonstrates that Outlier Class Learning (OCL) is generally more effective than OE for LTR because OE's uniform prediction probability prior does not hold in long-tailed settings. However, even OCL alone struggles with the confusion between OOD, head, and tail samples.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{miao2023brn} introduces Calibrated Outlier Class Learning (COCL), a novel approach that extends the label space with an explicit outlier class to encapsulate OOD samples. COCL addresses the OOD/head/tail confusion through two main components:\n        1.  **Debiased Large Margin Learning (Training Stage)**: Designed to reduce biases towards head classes (preventing OOD misclassification as head) and OOD samples (preventing tail misclassification as OOD) in the representation space.\n        2.  **Outlier-Class-Aware Logit Calibration (Inference Stage)**: Utilizes the logit of the outlier class to calibrate ID prediction probabilities, enhancing both OOD detection and long-tailed classification confidence.\n    *   **Novelty/Difference**: The novelty lies in the specific design of the debiased large margin learning, which includes:\n        *   **OOD-Aware Tail Class Prototype Learning**: Uses learnable prototypes for tail classes, pulling tail samples closer to their respective prototypes while pushing OOD samples and other tail prototypes away. This directly tackles the issue of tail samples being mistaken for OOD.\n        *   **Debiased Head Class Learning**: Employs a semi-supervised one-class learning approach for OOD samples, using OOD samples as anchors, distant OOD samples as positives, and random head samples as negatives. This aims to create a large, distinct outlier-class description region to alleviate the dominant influence of head classes on OOD samples.\n        *   The integration of these training-time representation learning strategies with an inference-time logit calibration method, specifically leveraging the learned outlier class logit, is also a key innovation.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduction of Calibrated Outlier Class Learning (COCL) as a comprehensive framework for OOD detection in LTR.\n        *   Debiased Large Margin Learning, comprising:\n            *   OOD-Aware Tail Class Prototype Learning (Eq. 3, 4) to improve tail class representation and separation from OOD.\n            *   Debiased Head Class Learning (Eq. 5, 6) for robust one-class learning of OOD samples, mitigating head class bias.\n        *   Outlier-Class-Aware Logit Calibration for enhancing inference-time OOD detection and ID classification confidence.\n    *   **System Design/Architectural Innovations**: The paper demonstrates that Outlier Class Learning (OCL) is inherently more effective for OOD detection in LTR than Outlier Exposure (OE) when auxiliary OOD data is available, shifting the foundational approach for this problem.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive empirical evaluations were performed on three popular long-tailed benchmarks: CIFAR10-LT, CIFAR100-LT, and ImageNet-LT \\cite{miao2023brn}. The OOD detection performance was assessed against six diverse OOD test sets (CIFAR, Texture, SVHN, LSUN, Places365, TinyImagenet) for the CIFAR-LT datasets.\n    *   **Key Performance Metrics**: Performance was measured using standard OOD detection metrics: Area Under the Receiver Operating Characteristic Curve (AUC), Average Precision for In-distribution (AP-in), Average Precision for Out-of-distribution (AP-out), False Positive Rate at 95% True Positive Rate (FPR95), and In-distribution Classification Accuracy (ACC) \\cite{miao2023brn}.\n    *   **Comparison Results**: COCL substantially outperforms state-of-the-art OOD detection methods in LTR. For instance, on CIFAR10-LT, COCL achieved an AUC of 93.28, FPR95 of 30.88, and ACC of 81.56, significantly surpassing the best OCL baseline (OCL+LA: AUC 91.56, FPR95 36.50, ACC 76.67) and OE baselines (OE+LA: AUC 89.46, FPR95 53.38, ACC 73.93) \\cite{miao2023brn}. The results consistently show COCL's superiority across all metrics and datasets, demonstrating its ability to improve both OOD detection performance and ID classification accuracy simultaneously.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the availability of auxiliary OOD data during training. The effectiveness might be influenced by the quality and diversity of this auxiliary data. The paper does not explicitly discuss the sensitivity to hyperparameters (e.g., `Î³`, `t`, `margin`).\n    *   **Scope of Applicability**: The approach is specifically designed for OOD detection in scenarios where the in-distribution data exhibits a long-tailed class distribution. While effective in this domain, its direct applicability or comparative advantage in balanced ID OOD detection scenarios is not the primary focus.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{miao2023brn} significantly advances the technical state-of-the-art for OOD detection in LTR by effectively mitigating the critical biases that plague existing methods (OOD samples misclassified as head, tail samples misclassified as OOD). It provides a robust framework that simultaneously improves both OOD detection and ID classification accuracy.\n    *   **Potential Impact on Future Research**: The work highlights the superior effectiveness of Outlier Class Learning over Outlier Exposure in LTR, potentially guiding future research towards OCL-based approaches. The proposed debiased large margin learning and outlier-class-aware logit calibration offer novel components that can be adapted or extended in other OOD detection or imbalanced learning contexts. It opens avenues for exploring more sophisticated representation learning techniques tailored to the unique challenges of long-tailed data distributions in safety-critical applications.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Long-Tailed Recognition (LTR)",
          "Calibrated Outlier Class Learning (COCL)",
          "Debiased Large Margin Learning",
          "OOD-Aware Tail Class Prototype Learning",
          "Debiased Head Class Learning",
          "Outlier-Class-Aware Logit Calibration",
          "Class imbalance",
          "Outlier Class Learning (OCL)",
          "State-of-the-art performance",
          "Simultaneous OOD detection and ID classification",
          "Real-world applications",
          "Representation space"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **problem identification:** the paper identifies a problem with existing out-of-distribution (ood) methods in long-tailed recognition (ltr) scenarios.\n2.  **proposed solution:** the abstract explicitly states, \"to this end, we introduce a novel calibrated outlier class learning (cocl) approach,\" and details its components (debiased large margin learning, outlier-class-aware logit calibration). this directly aligns with presenting new methods or algorithms.\n3.  **evaluation:** the abstract mentions \"extensive empirical results on three popular benchmarks... demonstrate that cocl substantially outperforms state-of-the-art ood detection methods.\" this indicates an empirical evaluation.\n\nwhile the paper clearly includes strong empirical results, its core contribution is the **introduction of a novel method (cocl)** to address a specific technical challenge. the empirical results serve to validate the effectiveness of this new technical approach. therefore, the primary classification leans towards **technical**.\n\n**classification:** **technical**"
      },
      "file_name": "f0f220240fc752b6b3c56464d96aeb322f221ef0.pdf"
    },
    {
      "success": true,
      "doc_id": "284349f44baac4cb34534d64936c345d",
      "summary": "Here's a focused summary of the paper \"Watermarking for Out-of-distribution Detection\" \\cite{wang2022mbf} for a literature review:\n\n**1. Research Problem & Motivation**\n\n*   **Specific Technical Problem:** Existing Out-of-Distribution (OOD) detection methods largely overlook the \"reprogramming property\" of deep models, failing to fully exploit their inherent capabilities. Deep models often exhibit overconfidence in OOD inputs, which is critical to address in safety-critical applications.\n*   **Importance and Challenge:** OOD detection is crucial for reliable deep learning systems in open-world scenarios. The problem is challenging because acquiring true OOD data for training is difficult and costly, and re-training large deep models is often prohibitively expensive. The paper aims to address these challenges by repurposing existing, well-trained models without modifying their parameters.\n\n**2. Related Work & Positioning**\n\n*   **Relation to Existing Approaches:**\n    *   The work builds upon classification-based OOD detection methods that use scoring functions derived from well-trained models (e.g., softmax, free energy).\n    *   It draws inspiration from \"model reprogramming,\" a technique that repurposes pre-trained models for new tasks via data-level manipulation (e.g., static padding patterns) without altering model parameters, previously applied in image classification and time-series analysis.\n*   **Limitations of Previous Solutions:**\n    *   Prior OOD detection methods primarily rely on adjusting a detection threshold, which is insufficient when ID and OOD score distributions overlap significantly.\n    *   Other OOD approaches (density-based, distance-based) often face computational complexity and optimization difficulties.\n    *   Crucially, previous OOD detection research has not explored the potential of the \"reprogramming property\" of deep models for this task.\n    *   Methods like ODIN \\cite{liang2018enhancing} use instance-specific perturbations requiring extra test-time computation and are often tied to specific scoring functions, unlike the proposed static, universal watermark.\n\n**3. Technical Approach & Innovation**\n\n*   **Core Technical Method:** The paper proposes \"watermarking\" \\cite{wang2022mbf}, a novel methodology that reprograms a well-trained classification model for OOD detection. It involves learning a *unified, static pattern* (the watermark `w`) that is superimposed onto original inputs (`x + w`) at test time. This data-level manipulation aims to enhance pre-defined OOD scoring functions by enlarging the score gap between ID and OOD data.\n*   **Novelty/Difference:**\n    *   **First Application of Reprogramming to OOD Detection:** This is the primary innovation, demonstrating a new paradigm for OOD detection by leveraging a model's intrinsic capabilities without parameter modification.\n    *   **Learning a Universal, Static Watermark:** Unlike dynamic, instance-specific perturbations, the watermark is learned once and applied universally, eliminating test-time computational overhead.\n    *   **Learning Strategy without Explicit OOD Data:** The watermark is learned by optimizing two objectives: (1) making the model produce high scores for watermarked in-distribution (ID) data, and (2) regularizing the watermark such that the model returns low scores when only the watermark (or watermark + noise) is perceived, simulating OOD conditions where no ID pattern is recognized.\n    *   **Robust Optimization with SAM:** The learning process incorporates Sharpness-Aware Minimization (SAM) \\cite{foret2020sharpness} to find watermarks that lead to a smoother loss landscape, improving robustness and generalization.\n    *   **Generalizability:** The approach is designed to be compatible with various classification-based scoring functions (e.g., softmax, free energy), offering broad applicability.\n\n**4. Key Technical Contributions**\n\n*   **Novel Methodology:** Introduction of \"watermarking\" as a data-level reprogramming strategy for OOD detection, exploiting the inherent capabilities of pre-trained deep models.\n*   **Principled Learning Framework:** A framework for learning effective watermarks without requiring explicit OOD data, using distinct loss functions for ID (maximizing scores for `x+w`) and OOD (minimizing scores for `epsilon+w`, where `epsilon` is noise) scenarios.\n*   **Advanced Optimization:** Integration of Sharpness-Aware Minimization (SAM) \\cite{foret2020sharpness} with signum gradient updates for robust and efficient watermark learning, aiming for solutions with smooth loss landscapes.\n*   **Adaptable Loss Functions:** Specific realizations of loss functions for popular OOD scoring methods (softmax-based and free-energy-based watermarking), demonstrating the method's versatility.\n\n**5. Experimental Validation**\n\n*   **Experiments Conducted:** Extensive experiments were performed to validate the effectiveness of watermarking across a wide range of OOD evaluation benchmarks.\n*   **ID Datasets:** CIFAR-10, CIFAR-100, and ImageNet.\n*   **OOD Datasets:** Textures \\cite{cimpoi2014describing}, SVHN \\cite{netzer2011reading}, Places365 \\cite{zhou2017places}, LSUN \\cite{yu2015lsun}, and iSUN \\cite{xu2015turkergaze}.\n*   **Backbone Model:** WideResNet (WRN-40-2) was used as the backbone classifier.\n*   **Key Performance Metrics:** The performance was measured using threshold-independent metrics: False Positive Rate at 95% True Positive Rate (FPR95), Area Under the Receiver Operating Characteristic curve (AUROC), and Area Under the Precision-Recall curve (AUPR).\n*   **Comparison Results:** The experiments consistently verified the effectiveness of watermarking, demonstrating that it significantly enlarges the distribution gap between ID and OOD scores (as shown in Figure 2), leading to improved OOD detection performance across various benchmarks. The code is publicly available.\n\n**6. Limitations & Scope**\n\n*   **Technical Limitations/Assumptions:**\n    *   The method's success relies on the underlying \"reprogramming property\" of the deep model being sufficiently strong for OOD detection.\n    *   The watermark learning process, while low-dimensional, is a post-hoc optimization that requires computational resources.\n    *   Hyperparameters such as the trade-off parameter `lambda` and the SAM constraint `rho` need careful tuning.\n    *   The use of Gaussian noise for the OOD loss term is a specific choice, and other noise models could be explored.\n*   **Scope of Applicability:**\n    *   Primarily demonstrated for classification-based OOD detection methods.\n    *   Applicable in scenarios where modifying the parameters of a pre-trained model is undesirable, costly, or restricted.\n    *   The concept is generalizable across various domains where deep models are employed, particularly in image classification.\n\n**7. Technical Significance**\n\n*   **Advancement of State-of-the-Art:**\n    *   Introduces a novel and effective paradigm for OOD detection by being the first to leverage the \"reprogramming property\" of deep models, offering a new direction beyond traditional OOD methods.\n    *   Provides a method that significantly improves OOD detection performance without altering the original model parameters or requiring access to real OOD data during training.\n    *   Develops a robust learning framework for static, universal perturbations, which is more efficient at test time compared to dynamic, instance-specific methods.\n*   **Potential Impact on Future Research:**\n    *   Opens up a new avenue for OOD detection research, encouraging further exploration of model reprogramming and data-level manipulations.\n    *   Could inspire novel approaches to adapt pre-trained models for various downstream tasks where parameter modification is constrained.\n    *   The concept of learning universal, static patterns for model adaptation has potential applications in other challenging machine learning problems.\n    *   Emphasizes the importance of understanding and exploiting the intrinsic, often hidden, properties of deep neural networks.",
      "intriguing_abstract": "Deep learning models often exhibit dangerous overconfidence when encountering Out-of-Distribution (OOD) inputs, a critical challenge for reliable AI in safety-critical applications. Traditional OOD detection methods struggle with overlapping score distributions and the prohibitive cost of acquiring OOD data or retraining large models. This paper introduces a novel paradigm: **watermarking** for OOD detection, which uniquely leverages the inherent \"reprogramming property\" of deep neural networks.\n\nWe propose learning a *unified, static pattern* (the watermark) that is superimposed onto inputs at test time. This data-level manipulation drastically enlarges the score gap between in-distribution (ID) and OOD data, without altering the pre-trained model's parameters. Crucially, our method learns this robust watermark without requiring explicit OOD data, optimizing distinct objectives for ID and simulated OOD conditions. Enhanced by Sharpness-Aware Minimization (SAM), this approach offers a highly efficient, generalizable solution compatible with various scoring functions. Extensive experiments on CIFAR and ImageNet benchmarks demonstrate significant improvements in OOD detection metrics (FPR95, AUROC), establishing watermarking as a pivotal advancement for building safer, more reliable deep learning systems in open-world environments.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Deep models",
        "Model reprogramming",
        "Watermarking (OOD detection)",
        "Universal static watermark",
        "Data-level manipulation",
        "Learning without OOD data",
        "Sharpness-Aware Minimization (SAM)",
        "Parameter-free model adaptation",
        "Improved OOD detection performance",
        "Test-time efficiency",
        "Overconfidence in OOD inputs",
        "Classification-based scoring functions"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/41e68a78f5bd266b1ae54d521ebd0be0e9314cd8.pdf",
      "citation_key": "wang2022mbf",
      "metadata": {
        "title": "Watermarking for Out-of-distribution Detection",
        "authors": [
          "Qizhou Wang",
          "Feng Liu",
          "Yonggang Zhang",
          "Jing Zhang",
          "Chen Gong",
          "Tongliang Liu",
          "Bo Han"
        ],
        "published_date": "2022",
        "abstract": "Out-of-distribution (OOD) detection aims to identify OOD data based on representations extracted from well-trained deep models. However, existing methods largely ignore the reprogramming property of deep models and thus may not fully unleash their intrinsic strength: without modifying parameters of a well-trained deep model, we can reprogram this model for a new purpose via data-level manipulation (e.g., adding a specific feature perturbation to the data). This property motivates us to reprogram a classification model to excel at OOD detection (a new task), and thus we propose a general methodology named watermarking in this paper. Specifically, we learn a unified pattern that is superimposed onto features of original data, and the model's detection capability is largely boosted after watermarking. Extensive experiments verify the effectiveness of watermarking, demonstrating the significance of the reprogramming property of deep models in OOD detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/41e68a78f5bd266b1ae54d521ebd0be0e9314cd8.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 33,
        "score": 11.0,
        "summary": "Here's a focused summary of the paper \"Watermarking for Out-of-distribution Detection\" \\cite{wang2022mbf} for a literature review:\n\n**1. Research Problem & Motivation**\n\n*   **Specific Technical Problem:** Existing Out-of-Distribution (OOD) detection methods largely overlook the \"reprogramming property\" of deep models, failing to fully exploit their inherent capabilities. Deep models often exhibit overconfidence in OOD inputs, which is critical to address in safety-critical applications.\n*   **Importance and Challenge:** OOD detection is crucial for reliable deep learning systems in open-world scenarios. The problem is challenging because acquiring true OOD data for training is difficult and costly, and re-training large deep models is often prohibitively expensive. The paper aims to address these challenges by repurposing existing, well-trained models without modifying their parameters.\n\n**2. Related Work & Positioning**\n\n*   **Relation to Existing Approaches:**\n    *   The work builds upon classification-based OOD detection methods that use scoring functions derived from well-trained models (e.g., softmax, free energy).\n    *   It draws inspiration from \"model reprogramming,\" a technique that repurposes pre-trained models for new tasks via data-level manipulation (e.g., static padding patterns) without altering model parameters, previously applied in image classification and time-series analysis.\n*   **Limitations of Previous Solutions:**\n    *   Prior OOD detection methods primarily rely on adjusting a detection threshold, which is insufficient when ID and OOD score distributions overlap significantly.\n    *   Other OOD approaches (density-based, distance-based) often face computational complexity and optimization difficulties.\n    *   Crucially, previous OOD detection research has not explored the potential of the \"reprogramming property\" of deep models for this task.\n    *   Methods like ODIN \\cite{liang2018enhancing} use instance-specific perturbations requiring extra test-time computation and are often tied to specific scoring functions, unlike the proposed static, universal watermark.\n\n**3. Technical Approach & Innovation**\n\n*   **Core Technical Method:** The paper proposes \"watermarking\" \\cite{wang2022mbf}, a novel methodology that reprograms a well-trained classification model for OOD detection. It involves learning a *unified, static pattern* (the watermark `w`) that is superimposed onto original inputs (`x + w`) at test time. This data-level manipulation aims to enhance pre-defined OOD scoring functions by enlarging the score gap between ID and OOD data.\n*   **Novelty/Difference:**\n    *   **First Application of Reprogramming to OOD Detection:** This is the primary innovation, demonstrating a new paradigm for OOD detection by leveraging a model's intrinsic capabilities without parameter modification.\n    *   **Learning a Universal, Static Watermark:** Unlike dynamic, instance-specific perturbations, the watermark is learned once and applied universally, eliminating test-time computational overhead.\n    *   **Learning Strategy without Explicit OOD Data:** The watermark is learned by optimizing two objectives: (1) making the model produce high scores for watermarked in-distribution (ID) data, and (2) regularizing the watermark such that the model returns low scores when only the watermark (or watermark + noise) is perceived, simulating OOD conditions where no ID pattern is recognized.\n    *   **Robust Optimization with SAM:** The learning process incorporates Sharpness-Aware Minimization (SAM) \\cite{foret2020sharpness} to find watermarks that lead to a smoother loss landscape, improving robustness and generalization.\n    *   **Generalizability:** The approach is designed to be compatible with various classification-based scoring functions (e.g., softmax, free energy), offering broad applicability.\n\n**4. Key Technical Contributions**\n\n*   **Novel Methodology:** Introduction of \"watermarking\" as a data-level reprogramming strategy for OOD detection, exploiting the inherent capabilities of pre-trained deep models.\n*   **Principled Learning Framework:** A framework for learning effective watermarks without requiring explicit OOD data, using distinct loss functions for ID (maximizing scores for `x+w`) and OOD (minimizing scores for `epsilon+w`, where `epsilon` is noise) scenarios.\n*   **Advanced Optimization:** Integration of Sharpness-Aware Minimization (SAM) \\cite{foret2020sharpness} with signum gradient updates for robust and efficient watermark learning, aiming for solutions with smooth loss landscapes.\n*   **Adaptable Loss Functions:** Specific realizations of loss functions for popular OOD scoring methods (softmax-based and free-energy-based watermarking), demonstrating the method's versatility.\n\n**5. Experimental Validation**\n\n*   **Experiments Conducted:** Extensive experiments were performed to validate the effectiveness of watermarking across a wide range of OOD evaluation benchmarks.\n*   **ID Datasets:** CIFAR-10, CIFAR-100, and ImageNet.\n*   **OOD Datasets:** Textures \\cite{cimpoi2014describing}, SVHN \\cite{netzer2011reading}, Places365 \\cite{zhou2017places}, LSUN \\cite{yu2015lsun}, and iSUN \\cite{xu2015turkergaze}.\n*   **Backbone Model:** WideResNet (WRN-40-2) was used as the backbone classifier.\n*   **Key Performance Metrics:** The performance was measured using threshold-independent metrics: False Positive Rate at 95% True Positive Rate (FPR95), Area Under the Receiver Operating Characteristic curve (AUROC), and Area Under the Precision-Recall curve (AUPR).\n*   **Comparison Results:** The experiments consistently verified the effectiveness of watermarking, demonstrating that it significantly enlarges the distribution gap between ID and OOD scores (as shown in Figure 2), leading to improved OOD detection performance across various benchmarks. The code is publicly available.\n\n**6. Limitations & Scope**\n\n*   **Technical Limitations/Assumptions:**\n    *   The method's success relies on the underlying \"reprogramming property\" of the deep model being sufficiently strong for OOD detection.\n    *   The watermark learning process, while low-dimensional, is a post-hoc optimization that requires computational resources.\n    *   Hyperparameters such as the trade-off parameter `lambda` and the SAM constraint `rho` need careful tuning.\n    *   The use of Gaussian noise for the OOD loss term is a specific choice, and other noise models could be explored.\n*   **Scope of Applicability:**\n    *   Primarily demonstrated for classification-based OOD detection methods.\n    *   Applicable in scenarios where modifying the parameters of a pre-trained model is undesirable, costly, or restricted.\n    *   The concept is generalizable across various domains where deep models are employed, particularly in image classification.\n\n**7. Technical Significance**\n\n*   **Advancement of State-of-the-Art:**\n    *   Introduces a novel and effective paradigm for OOD detection by being the first to leverage the \"reprogramming property\" of deep models, offering a new direction beyond traditional OOD methods.\n    *   Provides a method that significantly improves OOD detection performance without altering the original model parameters or requiring access to real OOD data during training.\n    *   Develops a robust learning framework for static, universal perturbations, which is more efficient at test time compared to dynamic, instance-specific methods.\n*   **Potential Impact on Future Research:**\n    *   Opens up a new avenue for OOD detection research, encouraging further exploration of model reprogramming and data-level manipulations.\n    *   Could inspire novel approaches to adapt pre-trained models for various downstream tasks where parameter modification is constrained.\n    *   The concept of learning universal, static patterns for model adaptation has potential applications in other challenging machine learning problems.\n    *   Emphasizes the importance of understanding and exploiting the intrinsic, often hidden, properties of deep neural networks.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Deep models",
          "Model reprogramming",
          "Watermarking (OOD detection)",
          "Universal static watermark",
          "Data-level manipulation",
          "Learning without OOD data",
          "Sharpness-Aware Minimization (SAM)",
          "Parameter-free model adaptation",
          "Improved OOD detection performance",
          "Test-time efficiency",
          "Overconfidence in OOD inputs",
          "Classification-based scoring functions"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we propose a general methodology named watermarking in this paper.\" and \"speciï¬cally, we learn a uniï¬ed pattern...\". this indicates the development of a new method or system.\n*   it also mentions: \"extensive experiments verify the effectiveness of watermarking...\", which points to empirical validation of the proposed method.\n*   the introduction sets up a technical problem (ood detection) and discusses existing approaches, leading to the motivation for the proposed solution.\n\nthe primary contribution described is the **proposal and development of a new methodology (\"watermarking\")** for ood detection. the experiments serve to validate this new technical contribution.\n\ntherefore, the paper type is **technical**."
      },
      "file_name": "41e68a78f5bd266b1ae54d521ebd0be0e9314cd8.pdf"
    },
    {
      "success": true,
      "doc_id": "e9d99d8d8ff5f91d6966328d7c0dd365",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the technical problem of improving Out-of-Distribution (OOD) detection, particularly for distance-based methods that rely on global image representations.\n    *   This problem is important because modern ML systems can produce overconfident and untrustworthy predictions for \"unknown\" OOD inputs, which is critical in safety-sensitive applications like autonomous driving.\n    *   It is challenging because inevitable background clutter and intra-class variation can cause global, image-level representations from the same in-distribution (ID) class to be far apart in a representation space, making it difficult to distinguish ID from OOD data effectively \\cite{zhang202312h}. Furthermore, existing models pretrained with standard losses are often incompetent at capturing valuable local representations for OOD detection due to scale-discrepancy between training and detection.\n\n*   **Related Work & Positioning**\n    *   This work relates to existing distance-based OOD detection methods, such as KNN \\cite{zhang202312h}, which use global image representations (e.g., penultimate layer features) and distance metrics to classify ID/OOD.\n    *   Previous solutions, including Mahalanobis distance-based methods and KNN, primarily rely on single-scale global representations. The limitation is that these global representations can be compromised by background clutter and intra-class variation, leading to sub-optimal ID-OOD separability \\cite{zhang202312h}. Many prior works also focus solely on test-time decision functions, neglecting training-time representation learning for OOD.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is Multi-scale OOD DEtection (MODE), a framework that leverages both global visual information and local region details of images for OOD detection \\cite{zhang202312h}.\n    *   **Attention-based Local PropAgation (ALPA)**: A trainable objective proposed for ID training. It uses a cross-attention mechanism within a contrastive learning framework to align and highlight the local regions of target objects for pairwise examples, encouraging locally discriminative representations.\n    *   **Cross-Scale Decision (CSD)**: A function devised for test-time OOD detection that explores the most discriminative multi-scale representations (global and local) to distinguish ID/OOD data more faithfully.\n    *   The approach is novel because it is the first to exploit multi-scale representations (global and local) for OOD detection, and ALPA specifically addresses the scale-discrepancy issue in learning local representations for this task.\n\n*   **Key Technical Contributions**\n    *   **Novel Framework**: MODE, the first framework to leverage multi-scale (global and local) representations for OOD detection \\cite{zhang202312h}.\n    *   **Novel Training Objective**: ALPA, an end-to-end, plug-and-play, cross-attention based learning objective designed to encourage locally discriminative representations during ID training specifically for OOD detection.\n    *   **Novel Decision Function**: CSD, a simple, effective, and multi-scale representation-based ID-OOD decision function for test-time detection.\n    *   **Empirical Validation**: Comprehensive experimental results demonstrating significant performance improvements over state-of-the-art methods.\n\n*   **Experimental Validation**\n    *   Experiments were conducted on several benchmarks, comparing MODE against a broad spectrum of baseline methods and various network structures (e.g., ResNet-34).\n    *   Key performance metrics include False Positive Rate (FPR) and Area Under the Receiver Operating Characteristic (AUROC).\n    *   MODE significantly outperforms the previous state-of-the-art (KNN \\cite{zhang202312h}) by up to 19.24% in FPR and 2.77% in AUROC on average.\n    *   Even when performing test-time OOD detection based on only 5% of ID training data, MODE still exhibits superior performance, outperforming KNN (which uses 100% ID data) by 6.08% in FPR and 0.68% in AUROC.\n\n*   **Limitations & Scope**\n    *   The paper implicitly acknowledges the challenge that learned multi-scale representations, relying only on ID training data, may not be generalizable enough to recognize parts, objects, and context of diverse OOD data \\cite{zhang202312h}.\n    *   The sample space of potential OOD data can be prohibitively large and overlap with ID categories, making it difficult to establish a robust decision boundary on multi-scale representations.\n    *   The scope of applicability is primarily image-based OOD detection, leveraging deep learning backbones.\n\n*   **Technical Significance**\n    *   MODE significantly advances the technical state-of-the-art in OOD detection by introducing the novel concept of multi-scale representation learning (global and local) for this task \\cite{zhang202312h}.\n    *   The proposed ALPA and CSD components provide a flexible and effective framework that can be integrated with existing models and training procedures.\n    *   Its strong empirical performance, especially with limited ID training data, highlights its practical utility and potential to inspire future research into more robust and generalizable OOD detection methods that move beyond single-scale global features.",
      "intriguing_abstract": "The trustworthiness of AI in safety-critical applications hinges on robust Out-of-Distribution (OOD) detection, yet current methods struggle with overconfident predictions for unknown inputs. Existing distance-based techniques, relying on single-scale global image representations, are often compromised by background clutter and intra-class variation, leading to sub-optimal ID-OOD separability. We introduce Multi-scale OOD DEtection (MODE), a pioneering framework that fundamentally shifts OOD detection by leveraging both global visual information and crucial local region details.\n\nMODE features two novel components: Attention-based Local PropAgation (ALPA), an end-to-end cross-attention based contrastive learning objective that encourages locally discriminative representations during in-distribution training, addressing the critical scale-discrepancy issue. Complementing this is Cross-Scale Decision (CSD), a powerful test-time function that explores these multi-scale representations for faithful ID-OOD distinction. MODE significantly outperforms state-of-the-art methods, achieving up to 19.24% lower FPR and 2.77% higher AUROC, even with limited training data. This work represents a significant leap towards more reliable and generalizable OOD detection, paving the way for truly trustworthy AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "multi-scale representations",
        "global and local representations",
        "Multi-scale OOD DEtection (MODE)",
        "Attention-based Local PropAgation (ALPA)",
        "Cross-Scale Decision (CSD)",
        "distance-based OOD detection",
        "locally discriminative representations",
        "scale-discrepancy",
        "contrastive learning",
        "safety-sensitive applications",
        "significant performance improvements",
        "limited ID training data",
        "image-based OOD detection"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/4c1601f2582b351aea86a1d56dfd20f59a9f44ba.pdf",
      "citation_key": "zhang202312h",
      "metadata": {
        "title": "From Global to Local: Multi-Scale Out-of-Distribution Detection",
        "authors": [
          "Ji Zhang",
          "Lianli Gao",
          "Bingguang Hao",
          "Hao Huang",
          "Jingkuan Song",
          "H. Shen"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection aims to detect â€œunknownâ€ data whose labels have not been seen during the in-distribution (ID) training process. Recent progress in representation learning gives rise to distance-based OOD detection that recognizes inputs as ID/OOD according to their relative distances to the training data of ID classes. Previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal as the inevitable background clutter and intra-class variation may drive image-level representations from the same ID class far apart in a given representation space. In this work, we overcome this challenge by proposing Multi-scale OOD DEtection (MODE), a first framework leveraging both global visual information and local region details of images to maximally benefit OOD detection. Specifically, we first find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation ( $\\mathtt {ALPA}$ ), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision ( $\\mathtt {CSD}$ ) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks â€“ on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/4c1601f2582b351aea86a1d56dfd20f59a9f44ba.pdf",
        "venue": "IEEE Transactions on Image Processing",
        "citationCount": 21,
        "score": 10.5,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the technical problem of improving Out-of-Distribution (OOD) detection, particularly for distance-based methods that rely on global image representations.\n    *   This problem is important because modern ML systems can produce overconfident and untrustworthy predictions for \"unknown\" OOD inputs, which is critical in safety-sensitive applications like autonomous driving.\n    *   It is challenging because inevitable background clutter and intra-class variation can cause global, image-level representations from the same in-distribution (ID) class to be far apart in a representation space, making it difficult to distinguish ID from OOD data effectively \\cite{zhang202312h}. Furthermore, existing models pretrained with standard losses are often incompetent at capturing valuable local representations for OOD detection due to scale-discrepancy between training and detection.\n\n*   **Related Work & Positioning**\n    *   This work relates to existing distance-based OOD detection methods, such as KNN \\cite{zhang202312h}, which use global image representations (e.g., penultimate layer features) and distance metrics to classify ID/OOD.\n    *   Previous solutions, including Mahalanobis distance-based methods and KNN, primarily rely on single-scale global representations. The limitation is that these global representations can be compromised by background clutter and intra-class variation, leading to sub-optimal ID-OOD separability \\cite{zhang202312h}. Many prior works also focus solely on test-time decision functions, neglecting training-time representation learning for OOD.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is Multi-scale OOD DEtection (MODE), a framework that leverages both global visual information and local region details of images for OOD detection \\cite{zhang202312h}.\n    *   **Attention-based Local PropAgation (ALPA)**: A trainable objective proposed for ID training. It uses a cross-attention mechanism within a contrastive learning framework to align and highlight the local regions of target objects for pairwise examples, encouraging locally discriminative representations.\n    *   **Cross-Scale Decision (CSD)**: A function devised for test-time OOD detection that explores the most discriminative multi-scale representations (global and local) to distinguish ID/OOD data more faithfully.\n    *   The approach is novel because it is the first to exploit multi-scale representations (global and local) for OOD detection, and ALPA specifically addresses the scale-discrepancy issue in learning local representations for this task.\n\n*   **Key Technical Contributions**\n    *   **Novel Framework**: MODE, the first framework to leverage multi-scale (global and local) representations for OOD detection \\cite{zhang202312h}.\n    *   **Novel Training Objective**: ALPA, an end-to-end, plug-and-play, cross-attention based learning objective designed to encourage locally discriminative representations during ID training specifically for OOD detection.\n    *   **Novel Decision Function**: CSD, a simple, effective, and multi-scale representation-based ID-OOD decision function for test-time detection.\n    *   **Empirical Validation**: Comprehensive experimental results demonstrating significant performance improvements over state-of-the-art methods.\n\n*   **Experimental Validation**\n    *   Experiments were conducted on several benchmarks, comparing MODE against a broad spectrum of baseline methods and various network structures (e.g., ResNet-34).\n    *   Key performance metrics include False Positive Rate (FPR) and Area Under the Receiver Operating Characteristic (AUROC).\n    *   MODE significantly outperforms the previous state-of-the-art (KNN \\cite{zhang202312h}) by up to 19.24% in FPR and 2.77% in AUROC on average.\n    *   Even when performing test-time OOD detection based on only 5% of ID training data, MODE still exhibits superior performance, outperforming KNN (which uses 100% ID data) by 6.08% in FPR and 0.68% in AUROC.\n\n*   **Limitations & Scope**\n    *   The paper implicitly acknowledges the challenge that learned multi-scale representations, relying only on ID training data, may not be generalizable enough to recognize parts, objects, and context of diverse OOD data \\cite{zhang202312h}.\n    *   The sample space of potential OOD data can be prohibitively large and overlap with ID categories, making it difficult to establish a robust decision boundary on multi-scale representations.\n    *   The scope of applicability is primarily image-based OOD detection, leveraging deep learning backbones.\n\n*   **Technical Significance**\n    *   MODE significantly advances the technical state-of-the-art in OOD detection by introducing the novel concept of multi-scale representation learning (global and local) for this task \\cite{zhang202312h}.\n    *   The proposed ALPA and CSD components provide a flexible and effective framework that can be integrated with existing models and training procedures.\n    *   Its strong empirical performance, especially with limited ID training data, highlights its practical utility and potential to inspire future research into more robust and generalizable OOD detection methods that move beyond single-scale global features.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "multi-scale representations",
          "global and local representations",
          "Multi-scale OOD DEtection (MODE)",
          "Attention-based Local PropAgation (ALPA)",
          "Cross-Scale Decision (CSD)",
          "distance-based OOD detection",
          "locally discriminative representations",
          "scale-discrepancy",
          "contrastive learning",
          "safety-sensitive applications",
          "significant performance improvements",
          "limited ID training data",
          "image-based OOD detection"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"in this work, we overcome this challenge by **proposing multi-scale ood detection (mode)**, a first framework leveraging both global visual information and local region details...\"\n*   the introduction further details: \"**we propose attention-based local propagation (alpa)**, a trainable objective...\", and \"a **cross-scale decision (csd) function is further devised**...\"\n*   the paper identifies a technical problem (\"previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal...\") and presents a proposed solution (mode, alpa, csd).\n*   it then demonstrates the effectiveness of these proposed methods through benchmarks, which is typical for technical papers validating their new contributions.\n\nthese phrases strongly align with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and discusses \"technical problem, proposed solution.\"\n\n**classification: technical**"
      },
      "file_name": "4c1601f2582b351aea86a1d56dfd20f59a9f44ba.pdf"
    },
    {
      "success": true,
      "doc_id": "c0ec5083f146db94e355cc1299b07940",
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of Out-of-Distribution (OOD) detection in machine learning systems \\cite{kuan2022qzl}.\n    *   This problem is important because ML models often produce unreliable and overconfident predictions for inputs that differ from their training distribution, posing a significant challenge to the reliability and trustworthiness of deployed systems \\cite{kuan2022qzl}. A reliable system should recognize its uncertainty when encountering OOD inputs.\n\n*   **Related Work & Positioning**\n    *   Previous OOD detection approaches often relied on density estimation, generative modeling (e.g., normalizing flows, GANs, autoencoders), or methods based solely on classifier predictions like Maximum Softmax Probability (MSP) \\cite{kuan2022qzl}.\n    *   Limitations of prior solutions include being highly model-specific, requiring cumbersome tuning (especially for generative models where OOD ground truth is scarce), and the surprising finding that simple prediction-based methods like MSP were considered effective despite not quantifying epistemic uncertainty \\cite{kuan2022qzl}. The paper challenges the universal applicability of MSP as a strong baseline.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method proposed and advocated is a \"dead-simple approach\" called **KNN Distance** \\cite{kuan2022qzl}. This method flags images as OOD if their average distance to their K-nearest neighbors (KNN) in the representation space of an already trained image classifier is large \\cite{kuan2022qzl}.\n    *   This approach is novel in its simplicity and its explicit focus on leveraging learned intermediate representations (embeddings) from *any* pre-trained classification model, rather than relying on complex generative models or solely on final prediction probabilities \\cite{kuan2022qzl}. It uses cosine distance as an effective similarity metric for learned representations and can be accelerated via approximate KNN algorithms \\cite{kuan2022qzl}.\n\n*   **Key Technical Contributions**\n    *   **Novel Method**: Reintroduction and strong advocacy for the KNN Distance method for OOD detection, highlighting its effectiveness when applied to learned embeddings from standard image classifiers \\cite{kuan2022qzl}.\n    *   **Empirical Challenge to Baselines**: Demonstrating that methods solely considering model predictions (like MSP and Entropy) are reliably outperformed by methods leveraging learned representations, challenging previous findings that championed MSP \\cite{kuan2022qzl}.\n    *   **Insight on Representation Utility**: Showing that learned embeddings contain valuable information for OOD detection that is not fully captured by final predictions, and that concatenating predictions with embeddings (KNN DistPred) offers little additional value over using embeddings alone \\cite{kuan2022qzl}.\n\n*   **Experimental Validation**\n    *   **Experiments**: The authors conducted extensive experiments evaluating various OOD detection methods (MSP, Entropy, Mahalanobis, RMD, Isolation Forest, KNN Distance, KNN DistPred, KNN Prediction) \\cite{kuan2022qzl}.\n    *   **Datasets**: Experiments used diverse in-distribution vs. OOD dataset pairs, including color images (cifar-10, cifar-100) and grayscale images (mnist, fashion-mnist, roman-numeral) \\cite{kuan2022qzl}.\n    *   **Models**: Two state-of-the-art image classification models were used: ResNet-50 and Swin Transformer, trained on each in-distribution dataset \\cite{kuan2022qzl}.\n    *   **Metrics & Results**: Performance was measured using AUROC curves.\n        *   **Key Finding**: KNN Distance consistently performed best or among the best methods, especially with the Swin Transformer model \\cite{kuan2022qzl}.\n        *   MSP and Entropy were reliably outperformed by methods leveraging intermediate representations \\cite{kuan2022qzl}.\n        *   The choice of K for KNN methods showed stable performance across a range of values \\cite{kuan2022qzl}.\n\n*   **Limitations & Scope**\n    *   The study focuses on a standard OOD detection setting where methods only access training data during training and an unlabeled test example at a time for scoring \\cite{kuan2022qzl}.\n    *   The applicability is broad for image classification tasks where a pre-trained classifier is available \\cite{kuan2022qzl}.\n    *   The paper implicitly assumes the availability of a sufficiently diverse in-distribution training set to form meaningful neighborhoods in the embedding space.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by demonstrating that a conceptually simple and computationally efficient method (KNN Distance on learned embeddings) can outperform more complex or previously lauded baselines for OOD image detection \\cite{kuan2022qzl}.\n    *   It provides strong empirical evidence that leveraging learned representations from standard classifiers is crucial for effective OOD detection, challenging the notion that simple prediction-based scores are universally sufficient \\cite{kuan2022qzl}.\n    *   The findings have potential impact on future research by advocating for a \"back to basics\" approach, encouraging researchers to revisit and further explore the utility of simple, representation-based methods, and potentially simplifying OOD detection pipelines in practical applications \\cite{kuan2022qzl}.",
      "intriguing_abstract": "Machine learning models often produce dangerously overconfident predictions for Out-of-Distribution (OOD) inputs, critically undermining the reliability and trustworthiness of deployed systems. While complex generative models and simple prediction-based scores like Maximum Softmax Probability (MSP) have been widely explored for OOD detection, their limitations in generalizability and true epistemic uncertainty quantification persist. This paper reintroduces and champions a \"dead-simple\" yet remarkably effective approach: **KNN Distance** applied directly to the learned intermediate representations (embeddings) of standard image classifiers.\n\nWe demonstrate that by leveraging the rich information embedded within these features, KNN Distance consistently and significantly outperforms prediction-only methods, including MSP and Entropy, across diverse datasets and state-of-the-art architectures like ResNet-50 and Swin Transformer. Our extensive empirical validation, using AUROC as the primary metric, reveals that learned embeddings contain crucial OOD signals often missed by final predictions. This work challenges prevailing assumptions, advocating for a return to fundamental representation-based methods, offering a robust, efficient, and easily deployable solution for enhancing the trustworthiness of real-world ML systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "KNN Distance method",
        "learned embeddings",
        "image classification",
        "Maximum Softmax Probability (MSP)",
        "challenging baselines",
        "empirical validation",
        "ResNet-50",
        "Swin Transformer",
        "cosine distance",
        "approximate KNN algorithms",
        "system reliability",
        "AUROC performance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/6f136ee16da4f01f30b267478d5127699c983e20.pdf",
      "citation_key": "kuan2022qzl",
      "metadata": {
        "title": "Back to the Basics: Revisiting Out-of-Distribution Detection Baselines",
        "authors": [
          "Jo-Lan Kuan",
          "Jonas W. Mueller"
        ],
        "published_date": "2022",
        "abstract": "We study simple methods for out-of-distribution (OOD) image detection that are compatible with any already trained classifier, relying on only its predictions or learned representations. Evaluating the OOD detection performance of various methods when utilized with ResNet-50 and Swin Transformer models, we find methods that solely consider the model's predictions can be easily outperformed by also considering the learned representations. Based on our analysis, we advocate for a dead-simple approach that has been neglected in other studies: simply flag as OOD images whose average distance to their K nearest neighbors is large (in the representation space of an image classifier trained on the in-distribution data).",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/6f136ee16da4f01f30b267478d5127699c983e20.pdf",
        "venue": "arXiv.org",
        "citationCount": 31,
        "score": 10.333333333333332,
        "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of Out-of-Distribution (OOD) detection in machine learning systems \\cite{kuan2022qzl}.\n    *   This problem is important because ML models often produce unreliable and overconfident predictions for inputs that differ from their training distribution, posing a significant challenge to the reliability and trustworthiness of deployed systems \\cite{kuan2022qzl}. A reliable system should recognize its uncertainty when encountering OOD inputs.\n\n*   **Related Work & Positioning**\n    *   Previous OOD detection approaches often relied on density estimation, generative modeling (e.g., normalizing flows, GANs, autoencoders), or methods based solely on classifier predictions like Maximum Softmax Probability (MSP) \\cite{kuan2022qzl}.\n    *   Limitations of prior solutions include being highly model-specific, requiring cumbersome tuning (especially for generative models where OOD ground truth is scarce), and the surprising finding that simple prediction-based methods like MSP were considered effective despite not quantifying epistemic uncertainty \\cite{kuan2022qzl}. The paper challenges the universal applicability of MSP as a strong baseline.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method proposed and advocated is a \"dead-simple approach\" called **KNN Distance** \\cite{kuan2022qzl}. This method flags images as OOD if their average distance to their K-nearest neighbors (KNN) in the representation space of an already trained image classifier is large \\cite{kuan2022qzl}.\n    *   This approach is novel in its simplicity and its explicit focus on leveraging learned intermediate representations (embeddings) from *any* pre-trained classification model, rather than relying on complex generative models or solely on final prediction probabilities \\cite{kuan2022qzl}. It uses cosine distance as an effective similarity metric for learned representations and can be accelerated via approximate KNN algorithms \\cite{kuan2022qzl}.\n\n*   **Key Technical Contributions**\n    *   **Novel Method**: Reintroduction and strong advocacy for the KNN Distance method for OOD detection, highlighting its effectiveness when applied to learned embeddings from standard image classifiers \\cite{kuan2022qzl}.\n    *   **Empirical Challenge to Baselines**: Demonstrating that methods solely considering model predictions (like MSP and Entropy) are reliably outperformed by methods leveraging learned representations, challenging previous findings that championed MSP \\cite{kuan2022qzl}.\n    *   **Insight on Representation Utility**: Showing that learned embeddings contain valuable information for OOD detection that is not fully captured by final predictions, and that concatenating predictions with embeddings (KNN DistPred) offers little additional value over using embeddings alone \\cite{kuan2022qzl}.\n\n*   **Experimental Validation**\n    *   **Experiments**: The authors conducted extensive experiments evaluating various OOD detection methods (MSP, Entropy, Mahalanobis, RMD, Isolation Forest, KNN Distance, KNN DistPred, KNN Prediction) \\cite{kuan2022qzl}.\n    *   **Datasets**: Experiments used diverse in-distribution vs. OOD dataset pairs, including color images (cifar-10, cifar-100) and grayscale images (mnist, fashion-mnist, roman-numeral) \\cite{kuan2022qzl}.\n    *   **Models**: Two state-of-the-art image classification models were used: ResNet-50 and Swin Transformer, trained on each in-distribution dataset \\cite{kuan2022qzl}.\n    *   **Metrics & Results**: Performance was measured using AUROC curves.\n        *   **Key Finding**: KNN Distance consistently performed best or among the best methods, especially with the Swin Transformer model \\cite{kuan2022qzl}.\n        *   MSP and Entropy were reliably outperformed by methods leveraging intermediate representations \\cite{kuan2022qzl}.\n        *   The choice of K for KNN methods showed stable performance across a range of values \\cite{kuan2022qzl}.\n\n*   **Limitations & Scope**\n    *   The study focuses on a standard OOD detection setting where methods only access training data during training and an unlabeled test example at a time for scoring \\cite{kuan2022qzl}.\n    *   The applicability is broad for image classification tasks where a pre-trained classifier is available \\cite{kuan2022qzl}.\n    *   The paper implicitly assumes the availability of a sufficiently diverse in-distribution training set to form meaningful neighborhoods in the embedding space.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by demonstrating that a conceptually simple and computationally efficient method (KNN Distance on learned embeddings) can outperform more complex or previously lauded baselines for OOD image detection \\cite{kuan2022qzl}.\n    *   It provides strong empirical evidence that leveraging learned representations from standard classifiers is crucial for effective OOD detection, challenging the notion that simple prediction-based scores are universally sufficient \\cite{kuan2022qzl}.\n    *   The findings have potential impact on future research by advocating for a \"back to basics\" approach, encouraging researchers to revisit and further explore the utility of simple, representation-based methods, and potentially simplifying OOD detection pipelines in practical applications \\cite{kuan2022qzl}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "KNN Distance method",
          "learned embeddings",
          "image classification",
          "Maximum Softmax Probability (MSP)",
          "challenging baselines",
          "empirical validation",
          "ResNet-50",
          "Swin Transformer",
          "cosine distance",
          "approximate KNN algorithms",
          "system reliability",
          "AUROC performance"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we study simple methods for out-of-distribution (ood) image detection...\", \"evaluating the ood detection performance of various methods when utilized with resnet-50 and swin transformer models, we find methods...\", and \"based on our analysis, we advocate for a dead-simple approach...\".\n*   these phrases indicate a study involving the **evaluation of methods**, **performance measurement** with specific models (resnet-50, swin transformer), and **drawing conclusions/findings** from this evaluation. this is characteristic of a data-driven study with statistical analysis (implied by performance evaluation).\n*   while it does \"advocate for a dead-simple approach,\" this advocacy is a *conclusion* derived from the empirical findings, rather than the sole purpose of the paper as in a pure position paper.\n\ntherefore, the paper is best classified as **empirical**."
      },
      "file_name": "6f136ee16da4f01f30b267478d5127699c983e20.pdf"
    },
    {
      "success": true,
      "doc_id": "77cbeb3b9773c97e5a6307c86745711a",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: Balanced Energy Regularization Loss for Out-of-distribution Detection \\cite{choi202367m}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep neural networks often exhibit high confidence in Out-of-Distribution (OOD) samples, posing a significant challenge for their deployment in safety-critical applications (e.g., autonomous driving, medical diagnosis). Existing OOD detection methods that leverage auxiliary OOD data (e.g., Outlier Exposure, EnergyOE) apply an equal regularization loss to all auxiliary samples, failing to account for variations among them \\cite{choi202367m}.\n    *   **Importance & Challenge**: This problem is critical because misclassifying OOD samples with high confidence can lead to dangerous failures. The challenge lies in the observed class imbalance within auxiliary OOD data, particularly in real-world scenarios like semantic segmentation, which previous methods overlook \\cite{choi202367m}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon methods that use auxiliary data for OOD detection, such as Outlier Exposure (OE) and Energy-based OOD detection (EnergyOE) in image classification, and Meta-OOD and PEBAL in semantic segmentation \\cite{choi202367m}. It also positions itself within the context of OOD detection in long-tailed image classification, comparing against methods like PASCL \\cite{choi202367m}.\n    *   **Limitations of Previous Solutions**: Prior methods, including OE, EnergyOE, Meta-OOD, and PEBAL, do not consider the imbalanced distribution of auxiliary OOD data across classes. They apply a uniform regularization loss, which is suboptimal when auxiliary data samples exhibit significant class-wise variations \\cite{choi202367m}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel \"balanced energy regularization loss\" designed to address the class imbalance in auxiliary OOD data. The core idea is to apply a larger regularization to auxiliary samples from majority classes compared to those from minority classes \\cite{choi202367m}.\n    *   **Novelty**:\n        *   **`ZÎ³` Term**: Introduces a metric `Z` (generalized to `ZÎ³` with hyperparameter `Î³`) that quantifies the likelihood of an auxiliary sample belonging to a majority class. `Z` is computed as a weighted sum of posterior probabilities (softmax outputs) where weights are estimated prior probabilities of OOD classes, derived from inference on a pre-trained model \\cite{choi202367m}.\n        *   **Adaptive Loss Components**: The balanced energy regularization loss (`Lenergy,bal`) incorporates `ZÎ³` through two adaptive components:\n            *   **Adaptive loss margin**: Adds an `Î±Â·ZÎ³` proportional margin to the squared hinge loss for auxiliary data.\n            *   **Adaptive loss weight**: Multiplies the squared hinge loss by `ZÎ³`.\n        *   This adaptive mechanism ensures that auxiliary samples more likely to be from majority classes receive a stronger energy constraint and a higher loss weight \\cite{choi202367m}.\n        *   **Two-step Training**: The approach involves an initial inference step on the auxiliary OOD dataset to estimate class prior probabilities, followed by a fine-tuning step using the proposed balanced energy regularization loss \\cite{choi202367m}.\n\n4.  **Key Technical Contributions**\n    *   Identification and explanation of the imbalanced distribution of auxiliary OOD data, a previously overlooked issue, through empirical observation on pre-trained models \\cite{choi202367m}.\n    *   Introduction of the \"balanced energy regularization loss\" that adaptively regularizes auxiliary OOD samples based on their estimated class-wise prior probabilities \\cite{choi202367m}.\n    *   Development of the `ZÎ³` term and its integration into adaptive loss margin and weight components, providing a principled way to differentiate regularization strength \\cite{choi202367m}.\n    *   Demonstration of superior OOD detection performance across various tasks compared to existing energy regularization loss methods \\cite{choi202367m}.\n    *   Achievement of state-of-the-art (SOTA) performance in OOD detection for semantic segmentation and long-tailed image classification \\cite{choi202367m}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The proposed method was validated across three distinct OOD detection tasks: semantic segmentation, long-tailed image classification, and standard image classification \\cite{choi202367m}.\n    *   **Datasets & Models**:\n        *   Semantic Segmentation: Cityscapes (ID), COCO (auxiliary), Fishyscapes and Road Anomaly (OOD test) using Deeplabv3+ with WideResNet38 \\cite{choi202367m}.\n        *   Long-tailed Image Classification: CIFAR 10-LT, CIFAR 100-LT (ID), TinyImages 80M (auxiliary), and SC-OOD benchmark datasets (OOD test) using ResNet18 and WideResNet (WRN-40-2) \\cite{choi202367m}.\n        *   Image Classification: CIFAR10, CIFAR100 (ID), same auxiliary and OOD test as long-tailed, using ResNet18 \\cite{choi202367m}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **Semantic Segmentation**: Achieved SOTA performance, outperforming PEBAL on Fishyscapes Lost&Found (AP: 51.83 vs 44.17, FPR: 3.76 vs 7.58) and Fishyscapes Static (AP: 94.62 vs 92.38, FPR: 0.99 vs 1.73) \\cite{choi202367m}.\n        *   **Long-tailed Image Classification**: Demonstrated superior OOD performance against OE, EnergyOE, and the previous SOTA, PASCL \\cite{choi202367m}.\n        *   **Image Classification**: Showed improved performance over OE and EnergyOE \\cite{choi202367m}.\n        *   The results consistently indicate that the proposed loss is \"simple but generally effective for a variety of tasks\" \\cite{choi202367m}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the availability of auxiliary OOD data and a pre-trained model. The effectiveness of the balanced regularization is dependent on the accuracy of the prior probability estimation from the pre-trained model and appropriate tuning of hyperparameters (`Î±`, `Î³`) \\cite{choi202367m}. The paper does not explicitly discuss scenarios where auxiliary data might not be representative or where prior estimation is unreliable.\n    *   **Scope of Applicability**: The approach is primarily validated for OOD detection in image-based tasks (classification and semantic segmentation) where auxiliary OOD data can be leveraged \\cite{choi202367m}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The paper significantly advances the technical state-of-the-art by achieving SOTA performance in two challenging OOD detection tasks: semantic segmentation and long-tailed image classification \\cite{choi202367m}.\n    *   **Novel Insight & Impact**: It introduces a crucial insight into the class imbalance within auxiliary OOD data and provides a novel, principled solution through adaptive regularization. This nuanced approach to OOD data handling can lead to more robust and reliable OOD detection systems, particularly in real-world, safety-critical applications where diverse and imbalanced OOD samples are common \\cite{choi202367m}. The general effectiveness of the proposed loss suggests its potential for broader adoption in various OOD detection contexts.",
      "intriguing_abstract": "Deep neural networks often exhibit dangerous overconfidence when encountering Out-of-Distribution (OOD) samples, a critical challenge for safety-critical applications. While auxiliary OOD data can improve detection, existing methods overlook a pervasive flaw: the inherent class imbalance within this auxiliary data, leading to suboptimal regularization. We introduce a novel **balanced energy regularization loss** that fundamentally rethinks how auxiliary OOD samples are treated. Our approach adaptively applies stronger regularization to samples more likely to belong to majority classes, leveraging a new metric, `ZÎ³`, derived from estimated class prior probabilities. This adaptive mechanism, integrated through both loss margin and weight, ensures a nuanced and effective energy constraint. Our method achieves state-of-the-art performance in challenging OOD detection tasks, including **semantic segmentation** and **long-tailed image classification**, significantly outperforming prior energy-based methods. This work offers a principled solution to a critical, previously overlooked problem, paving the way for more robust and reliable deep learning systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "deep neural networks",
        "auxiliary OOD data",
        "class imbalance",
        "balanced energy regularization loss",
        "adaptive regularization",
        "`ZÎ³` term",
        "semantic segmentation",
        "long-tailed image classification",
        "energy-based OOD detection",
        "prior probability estimation",
        "two-step training",
        "state-of-the-art (SOTA) performance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/091ef8678781d1b53a5a07643ae37e3d44f9ed61.pdf",
      "citation_key": "choi202367m",
      "metadata": {
        "title": "Balanced Energy Regularization Loss for Out-of-distribution Detection",
        "authors": [
          "Hyunjun Choi",
          "Hawook Jeong",
          "Jin Young Choi"
        ],
        "published_date": "2023",
        "abstract": "In the field of out-of-distribution (OOD) detection, a previous method that use auxiliary data as OOD data has shown promising performance. However, the method provides an equal loss to all auxiliary data to differentiate them from inliers. However, based on our observation, in various tasks, there is a general imbalance in the distribution of the auxiliary OOD data across classes. We propose a balanced energy regularization loss that is simple but generally effective for a variety of tasks. Our balanced energy regularization loss utilizes class-wise different prior probabilities for auxiliary data to address the class imbalance in OOD data. The main concept is to regularize auxiliary samples from majority classes, more heavily than those from minority classes. Our approach performs better for OOD detection in semantic segmentation, long-tailed image classification, and image classification than the prior energy regularization loss. Furthermore, our approach achieves state-of-the-art performance in two tasks: OOD detection in semantic segmentation and long-tailed image classification.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/091ef8678781d1b53a5a07643ae37e3d44f9ed61.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 20,
        "score": 10.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: Balanced Energy Regularization Loss for Out-of-distribution Detection \\cite{choi202367m}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep neural networks often exhibit high confidence in Out-of-Distribution (OOD) samples, posing a significant challenge for their deployment in safety-critical applications (e.g., autonomous driving, medical diagnosis). Existing OOD detection methods that leverage auxiliary OOD data (e.g., Outlier Exposure, EnergyOE) apply an equal regularization loss to all auxiliary samples, failing to account for variations among them \\cite{choi202367m}.\n    *   **Importance & Challenge**: This problem is critical because misclassifying OOD samples with high confidence can lead to dangerous failures. The challenge lies in the observed class imbalance within auxiliary OOD data, particularly in real-world scenarios like semantic segmentation, which previous methods overlook \\cite{choi202367m}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon methods that use auxiliary data for OOD detection, such as Outlier Exposure (OE) and Energy-based OOD detection (EnergyOE) in image classification, and Meta-OOD and PEBAL in semantic segmentation \\cite{choi202367m}. It also positions itself within the context of OOD detection in long-tailed image classification, comparing against methods like PASCL \\cite{choi202367m}.\n    *   **Limitations of Previous Solutions**: Prior methods, including OE, EnergyOE, Meta-OOD, and PEBAL, do not consider the imbalanced distribution of auxiliary OOD data across classes. They apply a uniform regularization loss, which is suboptimal when auxiliary data samples exhibit significant class-wise variations \\cite{choi202367m}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel \"balanced energy regularization loss\" designed to address the class imbalance in auxiliary OOD data. The core idea is to apply a larger regularization to auxiliary samples from majority classes compared to those from minority classes \\cite{choi202367m}.\n    *   **Novelty**:\n        *   **`ZÎ³` Term**: Introduces a metric `Z` (generalized to `ZÎ³` with hyperparameter `Î³`) that quantifies the likelihood of an auxiliary sample belonging to a majority class. `Z` is computed as a weighted sum of posterior probabilities (softmax outputs) where weights are estimated prior probabilities of OOD classes, derived from inference on a pre-trained model \\cite{choi202367m}.\n        *   **Adaptive Loss Components**: The balanced energy regularization loss (`Lenergy,bal`) incorporates `ZÎ³` through two adaptive components:\n            *   **Adaptive loss margin**: Adds an `Î±Â·ZÎ³` proportional margin to the squared hinge loss for auxiliary data.\n            *   **Adaptive loss weight**: Multiplies the squared hinge loss by `ZÎ³`.\n        *   This adaptive mechanism ensures that auxiliary samples more likely to be from majority classes receive a stronger energy constraint and a higher loss weight \\cite{choi202367m}.\n        *   **Two-step Training**: The approach involves an initial inference step on the auxiliary OOD dataset to estimate class prior probabilities, followed by a fine-tuning step using the proposed balanced energy regularization loss \\cite{choi202367m}.\n\n4.  **Key Technical Contributions**\n    *   Identification and explanation of the imbalanced distribution of auxiliary OOD data, a previously overlooked issue, through empirical observation on pre-trained models \\cite{choi202367m}.\n    *   Introduction of the \"balanced energy regularization loss\" that adaptively regularizes auxiliary OOD samples based on their estimated class-wise prior probabilities \\cite{choi202367m}.\n    *   Development of the `ZÎ³` term and its integration into adaptive loss margin and weight components, providing a principled way to differentiate regularization strength \\cite{choi202367m}.\n    *   Demonstration of superior OOD detection performance across various tasks compared to existing energy regularization loss methods \\cite{choi202367m}.\n    *   Achievement of state-of-the-art (SOTA) performance in OOD detection for semantic segmentation and long-tailed image classification \\cite{choi202367m}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The proposed method was validated across three distinct OOD detection tasks: semantic segmentation, long-tailed image classification, and standard image classification \\cite{choi202367m}.\n    *   **Datasets & Models**:\n        *   Semantic Segmentation: Cityscapes (ID), COCO (auxiliary), Fishyscapes and Road Anomaly (OOD test) using Deeplabv3+ with WideResNet38 \\cite{choi202367m}.\n        *   Long-tailed Image Classification: CIFAR 10-LT, CIFAR 100-LT (ID), TinyImages 80M (auxiliary), and SC-OOD benchmark datasets (OOD test) using ResNet18 and WideResNet (WRN-40-2) \\cite{choi202367m}.\n        *   Image Classification: CIFAR10, CIFAR100 (ID), same auxiliary and OOD test as long-tailed, using ResNet18 \\cite{choi202367m}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **Semantic Segmentation**: Achieved SOTA performance, outperforming PEBAL on Fishyscapes Lost&Found (AP: 51.83 vs 44.17, FPR: 3.76 vs 7.58) and Fishyscapes Static (AP: 94.62 vs 92.38, FPR: 0.99 vs 1.73) \\cite{choi202367m}.\n        *   **Long-tailed Image Classification**: Demonstrated superior OOD performance against OE, EnergyOE, and the previous SOTA, PASCL \\cite{choi202367m}.\n        *   **Image Classification**: Showed improved performance over OE and EnergyOE \\cite{choi202367m}.\n        *   The results consistently indicate that the proposed loss is \"simple but generally effective for a variety of tasks\" \\cite{choi202367m}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the availability of auxiliary OOD data and a pre-trained model. The effectiveness of the balanced regularization is dependent on the accuracy of the prior probability estimation from the pre-trained model and appropriate tuning of hyperparameters (`Î±`, `Î³`) \\cite{choi202367m}. The paper does not explicitly discuss scenarios where auxiliary data might not be representative or where prior estimation is unreliable.\n    *   **Scope of Applicability**: The approach is primarily validated for OOD detection in image-based tasks (classification and semantic segmentation) where auxiliary OOD data can be leveraged \\cite{choi202367m}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The paper significantly advances the technical state-of-the-art by achieving SOTA performance in two challenging OOD detection tasks: semantic segmentation and long-tailed image classification \\cite{choi202367m}.\n    *   **Novel Insight & Impact**: It introduces a crucial insight into the class imbalance within auxiliary OOD data and provides a novel, principled solution through adaptive regularization. This nuanced approach to OOD data handling can lead to more robust and reliable OOD detection systems, particularly in real-world, safety-critical applications where diverse and imbalanced OOD samples are common \\cite{choi202367m}. The general effectiveness of the proposed loss suggests its potential for broader adoption in various OOD detection contexts.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "deep neural networks",
          "auxiliary OOD data",
          "class imbalance",
          "balanced energy regularization loss",
          "adaptive regularization",
          "`ZÎ³` term",
          "semantic segmentation",
          "long-tailed image classification",
          "energy-based OOD detection",
          "prior probability estimation",
          "two-step training",
          "state-of-the-art (SOTA) performance"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we propose a balanced energy regularization loss that is simple but generally effective for a variety of tasks.\" it then describes the mechanism of this new loss and its improved performance compared to prior methods.\n*   the introduction sets up a technical problem (ood detection in deep neural networks), discusses existing approaches, and identifies a limitation in a previous method.\n*   the paper's core contribution is the introduction of a novel method (a new loss function) to address a specific technical challenge. the mention of \"performs better\" and \"achieves state-of-the-art performance\" indicates empirical validation of this new method.\n\nthis aligns perfectly with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and discusses a \"technical problem, proposed solution.\"\n\n**classification: technical**"
      },
      "file_name": "091ef8678781d1b53a5a07643ae37e3d44f9ed61.pdf"
    },
    {
      "success": true,
      "doc_id": "fc48fedf25406cfc0e5cf640b3e942cf",
      "summary": "Identifying transitional states is crucial for understanding protein conformational changes that underlie numerous biological processes. Markov state models (MSMs), built from Molecular Dynamics (MD) simulations, capture these dynamics through transitions among metastable conformational states, and have demonstrated success in studying protein conformational changes. However, MSMs face challenges in identifying transition states, as they partition MD conformations into discrete metastable states (or free energy minima), lacking description of transition states located at the free energy barriers. Here, we introduce Transition State identification via Dispersion and vAriational principle Regularized neural networks (TS-DAR), a deep learning framework inspired by out-of-distribution (OOD) detection in trustworthy artificial intelligence (AI). TS-DAR offers an end-to-end pipeline that can simultaneously detect all transition states between multiple free minima from MD simulations using the regularized hyperspherical embeddings in latent space. The key insight of TS-DAR lies in treating transition state structures as OOD data, recognizing that they are sparsely populated and exhibit a distributional shift from metastable states. We demonstrate the power of TS-DAR by applying it to a 2D potential, alanine dipeptide, and the translocation of a DNA motor protein on DNA, where it outperforms previous methods in identifying transition states.",
      "intriguing_abstract": "Identifying transitional states is crucial for understanding protein conformational changes that underlie numerous biological processes. Markov state models (MSMs), built from Molecular Dynamics (MD) simulations, capture these dynamics through transitions among metastable conformational states, and have demonstrated success in studying protein conformational changes. However, MSMs face challenges in identifying transition states, as they partition MD conformations into discrete metastable states (or free energy minima), lacking description of transition states located at the free energy barriers. Here, we introduce Transition State identification via Dispersion and vAriational principle Regularized neural networks (TS-DAR), a deep learning framework inspired by out-of-distribution (OOD) detection in trustworthy artificial intelligence (AI). TS-DAR offers an end-to-end pipeline that can simultaneously detect all transition states between multiple free minima from MD simulations using the regularized hyperspherical embeddings in latent space. The key insight of TS-DAR lies in treating transition state structures as OOD data, recognizing that they are sparsely populated and exhibit a distributional shift from metastable states. We demonstrate the power of TS-DAR by applying it to a 2D potential, alanine dipeptide, and the translocation of a DNA motor protein on DNA, where it outperforms previous methods in identifying transition states.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/858959613d37a64f6f634b0c5a1b5063c29929fe.pdf",
      "citation_key": "liu2025wgr",
      "metadata": {
        "title": "Exploring transition states of protein conformational changes via out-of-distribution detection in the hyperspherical latent space",
        "authors": [
          "Bojun Liu",
          "Jordan G Boysen",
          "I. C. Unarta",
          "Xuefeng Du",
          "Yixuan Li",
          "Xuhui Huang"
        ],
        "published_date": "2025",
        "abstract": "Identifying transitional states is crucial for understanding protein conformational changes that underlie numerous biological processes. Markov state models (MSMs), built from Molecular Dynamics (MD) simulations, capture these dynamics through transitions among metastable conformational states, and have demonstrated success in studying protein conformational changes. However, MSMs face challenges in identifying transition states, as they partition MD conformations into discrete metastable states (or free energy minima), lacking description of transition states located at the free energy barriers. Here, we introduce Transition State identification via Dispersion and vAriational principle Regularized neural networks (TS-DAR), a deep learning framework inspired by out-of-distribution (OOD) detection in trustworthy artificial intelligence (AI). TS-DAR offers an end-to-end pipeline that can simultaneously detect all transition states between multiple free minima from MD simulations using the regularized hyperspherical embeddings in latent space. The key insight of TS-DAR lies in treating transition state structures as OOD data, recognizing that they are sparsely populated and exhibit a distributional shift from metastable states. We demonstrate the power of TS-DAR by applying it to a 2D potential, alanine dipeptide, and the translocation of a DNA motor protein on DNA, where it outperforms previous methods in identifying transition states.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/858959613d37a64f6f634b0c5a1b5063c29929fe.pdf",
        "venue": "Nature Communications",
        "citationCount": 10,
        "score": 10.0,
        "summary": "Identifying transitional states is crucial for understanding protein conformational changes that underlie numerous biological processes. Markov state models (MSMs), built from Molecular Dynamics (MD) simulations, capture these dynamics through transitions among metastable conformational states, and have demonstrated success in studying protein conformational changes. However, MSMs face challenges in identifying transition states, as they partition MD conformations into discrete metastable states (or free energy minima), lacking description of transition states located at the free energy barriers. Here, we introduce Transition State identification via Dispersion and vAriational principle Regularized neural networks (TS-DAR), a deep learning framework inspired by out-of-distribution (OOD) detection in trustworthy artificial intelligence (AI). TS-DAR offers an end-to-end pipeline that can simultaneously detect all transition states between multiple free minima from MD simulations using the regularized hyperspherical embeddings in latent space. The key insight of TS-DAR lies in treating transition state structures as OOD data, recognizing that they are sparsely populated and exhibit a distributional shift from metastable states. We demonstrate the power of TS-DAR by applying it to a 2D potential, alanine dipeptide, and the translocation of a DNA motor protein on DNA, where it outperforms previous methods in identifying transition states.",
        "keywords": []
      },
      "file_name": "858959613d37a64f6f634b0c5a1b5063c29929fe.pdf"
    },
    {
      "success": true,
      "doc_id": "1d1d3f5669ac02845e5d4c10a640da5b",
      "summary": "Here's a focused summary of the paper \\cite{miyai2023591} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses zero-shot out-of-distribution (OOD) detection, specifically the challenge of detecting OOD images during inference using only in-distribution (ID) class names.\n    *   **Importance & Challenge:** Existing zero-shot OOD methods, particularly those based on Vision-Language Models like CLIP, typically assume ID images contain a single, centered object. This assumption is unrealistic for real-world scenarios where images frequently contain multiple objects, including both ID and OOD entities. Users require flexibility to define what constitutes an \"ID image\" (e.g., an image containing *any* ID object, regardless of other OOD objects present), which current methods lack.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon CLIP-based zero-shot OOD detection, specifically extending the Maximum Concept Matching (MCM) method \\cite{ming2022maximum}.\n    *   **Limitations of Previous Solutions:**\n        *   **Supervised OOD methods:** Require extensive computational resources and annotation costs for training.\n        *   **Existing CLIP-based zero-shot OOD methods (e.g., MCM):** Primarily rely on global image features. When OOD objects are present in an image, these global features become \"contaminated,\" leading to incorrect OOD classification. They lack the flexibility to adapt to different definitions of ID images (e.g., multi-object scenes).\n        *   **Other recent zero-shot OOD methods (e.g., ZeroOE, ZOC, NegLabel, EOE, CLIPN):** Often require additional training or negative prompts, which can reduce their scalability and flexibility, making them difficult to integrate with other techniques like few-shot learning.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes Global-Local Maximum Concept Matching (GL-MCM).\n        *   It introduces **Local Maximum Concept Matching (L-MCM)**, which applies softmax scaling to CLIP's local visual-text alignments to enhance the separability of local features for OOD detection.\n        *   **GL-MCM** then combines the global scores from MCM and the local scores from L-MCM using a simple ensemble function: `S_GL-MCM = S_MCM + Î» * S_L-MCM`.\n    *   **Novelty:**\n        *   GL-MCM is novel in its exploration and effective utilization of CLIP's local features for OOD detection, bridging the gap between CLIP-based localization and OOD detection.\n        *   The simplicity of its ensemble score function, controlled by a single weighting parameter `Î»`, provides unprecedented flexibility for users to define the target type of ID images (e.g., ID-dominant vs. multi-object ID images).\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Introduction of L-MCM, a method for OOD detection leveraging CLIP's local visual-text alignments with softmax scaling.\n        *   Proposal of GL-MCM, an ensemble method that effectively combines global and local concept matching scores.\n    *   **System Design/Architectural Innovations:** A simple, yet effective, score function design that allows for flexible control over ID image detection characteristics via a single hyperparameter `Î»`.\n    *   **Theoretical Insights/Analysis:** Highlights the crucial role of softmax scaling for local features in improving separability between ID and OOD, drawing inspiration from its proven benefits for global features.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Evaluated on standard ImageNet OOD benchmarks (iNaturalist, SUN, PLACES, TEXTURE).\n        *   Evaluated on curated multi-object benchmarks (MS-COCO, Pascal-VOC) designed to reflect realistic scenarios.\n        *   Compared against zero-shot baselines (MCM) and several fully-supervised OOD detection methods.\n        *   Demonstrated scalability by boosting the performance of few-shot learning methods (CoOp, LoCoOp).\n        *   Ablation studies were performed on the `Î»` parameter to showcase its flexibility in controlling ID image types.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   GL-MCM consistently outperformed the baseline zero-shot method (MCM) across most ImageNet and multi-object benchmarks (MS-COCO, Pascal-VOC) in terms of FPR95 and AUROC.\n        *   GL-MCM achieved performance comparable to fully supervised methods on ImageNet and, when combined with few-shot learning, even surpassed them.\n        *   It significantly boosted the performance of few-shot learning methods, particularly LoCoOp.\n        *   The `Î»` parameter was empirically shown to effectively adjust the detection preference between ID-dominant and multi-object ID images, demonstrating high flexibility.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** While generally strong, GL-MCM showed performance degradation on the Texture OOD dataset in some ImageNet settings. The paper prioritizes scalability and flexibility, thus focusing comparisons on MCM rather than other recent zero-shot OOD methods that might require additional training or negative prompts.\n    *   **Scope of Applicability:** Primarily applicable to zero-shot OOD detection in image classification tasks, especially beneficial for real-world datasets containing complex, multi-object scenes. It also demonstrates strong compatibility and performance gains when integrated with few-shot learning techniques.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art:** GL-MCM significantly advances the technical state-of-the-art in zero-shot OOD detection by effectively addressing the realistic multi-object scenario, outperforming existing zero-shot methods, and achieving competitive results with supervised approaches without requiring additional training.\n    *   **Potential Impact on Future Research:**\n        *   Opens new research directions by demonstrating the untapped potential of CLIP's local features for OOD detection, fostering integration between vision-language models, localization, and OOD tasks.\n        *   Provides a highly flexible and scalable framework that can be easily adapted to diverse user needs and integrated with other learning paradigms (e.g., few-shot learning), making it valuable for real-world ML deployments.",
      "intriguing_abstract": "Real-world images rarely contain single, isolated objects, posing a critical challenge for zero-shot out-of-distribution (OOD) detection. Current Vision-Language Model (VLM) approaches, such as CLIP-based Maximum Concept Matching (MCM), falter in multi-object scenes because global image features become 'contaminated' by OOD entities, leading to unreliable classification. We introduce Global-Local Maximum Concept Matching (GL-MCM), a novel framework that fundamentally redefines zero-shot OOD detection by effectively harnessing CLIP's often-overlooked local visual-text alignments.\n\nGL-MCM pioneers Local Maximum Concept Matching (L-MCM), applying softmax scaling to local features to dramatically enhance their separability for OOD detection. By innovatively ensembling global MCM scores with these refined local scores through a simple, single-parameter weighting ($\\lambda$), GL-MCM offers unprecedented flexibility. This allows users to precisely define in-distribution images, from ID-dominant to complex multi-object scenarios. Extensive experiments confirm GL-MCM consistently outperforms zero-shot baselines, achieves competitive performance with supervised methods, and significantly boosts few-shot learning. This scalable and flexible approach bridges the critical gap between VLM localization and OOD detection, paving the way for robust, adaptable AI systems in complex environments.",
      "keywords": [
        "zero-shot out-of-distribution (OOD) detection",
        "Vision-Language Models (CLIP)",
        "multi-object scenes",
        "Global-Local Maximum Concept Matching (GL-MCM)",
        "CLIP's local features",
        "softmax scaling",
        "ensemble score function",
        "hyperparameter Î»",
        "Maximum Concept Matching (MCM)",
        "real-world scenarios",
        "few-shot learning integration",
        "flexible OOD definition",
        "image classification"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/3f9f3ca7832f36285fbb0a65c221ded5e32382a1.pdf",
      "citation_key": "miyai2023591",
      "metadata": {
        "title": "GL-MCM: Global and Local Maximum Concept Matching for Zero-Shot Out-of-Distribution Detection",
        "authors": [
          "Atsuyuki Miyai",
          "Qing Yu",
          "Go Irie",
          "K. Aizawa"
        ],
        "published_date": "2023",
        "abstract": "\n Zero-shot OOD detection is a task that detects OOD images during inference with only in-distribution (ID) class names. Existing methods assume ID images contain a single, centered object, and do not consider the more realistic multi-object scenarios, where both ID and OOD objects are present. To meet the needs of many users, the detection method must have the flexibility to adapt the type of ID images. To this end, we present Global-Local Maximum Concept Matching (GL-MCM), which incorporates local image scores as an auxiliary score to enhance the separability of global and local visual features. Due to the simple ensemble score function design, GL-MCM can control the type of ID images with a single weight parameter. Experiments on ImageNet and multi-object benchmarks demonstrate that GL-MCM outperforms baseline zero-shot methods and is comparable to fully supervised methods. Furthermore, GL-MCM offers strong flexibility in adjusting the target type of ID images. The code is available via https://github.com/AtsuMiyai/GL-MCM.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/3f9f3ca7832f36285fbb0a65c221ded5e32382a1.pdf",
        "venue": "International Journal of Computer Vision",
        "citationCount": 20,
        "score": 10.0,
        "summary": "Here's a focused summary of the paper \\cite{miyai2023591} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses zero-shot out-of-distribution (OOD) detection, specifically the challenge of detecting OOD images during inference using only in-distribution (ID) class names.\n    *   **Importance & Challenge:** Existing zero-shot OOD methods, particularly those based on Vision-Language Models like CLIP, typically assume ID images contain a single, centered object. This assumption is unrealistic for real-world scenarios where images frequently contain multiple objects, including both ID and OOD entities. Users require flexibility to define what constitutes an \"ID image\" (e.g., an image containing *any* ID object, regardless of other OOD objects present), which current methods lack.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon CLIP-based zero-shot OOD detection, specifically extending the Maximum Concept Matching (MCM) method \\cite{ming2022maximum}.\n    *   **Limitations of Previous Solutions:**\n        *   **Supervised OOD methods:** Require extensive computational resources and annotation costs for training.\n        *   **Existing CLIP-based zero-shot OOD methods (e.g., MCM):** Primarily rely on global image features. When OOD objects are present in an image, these global features become \"contaminated,\" leading to incorrect OOD classification. They lack the flexibility to adapt to different definitions of ID images (e.g., multi-object scenes).\n        *   **Other recent zero-shot OOD methods (e.g., ZeroOE, ZOC, NegLabel, EOE, CLIPN):** Often require additional training or negative prompts, which can reduce their scalability and flexibility, making them difficult to integrate with other techniques like few-shot learning.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes Global-Local Maximum Concept Matching (GL-MCM).\n        *   It introduces **Local Maximum Concept Matching (L-MCM)**, which applies softmax scaling to CLIP's local visual-text alignments to enhance the separability of local features for OOD detection.\n        *   **GL-MCM** then combines the global scores from MCM and the local scores from L-MCM using a simple ensemble function: `S_GL-MCM = S_MCM + Î» * S_L-MCM`.\n    *   **Novelty:**\n        *   GL-MCM is novel in its exploration and effective utilization of CLIP's local features for OOD detection, bridging the gap between CLIP-based localization and OOD detection.\n        *   The simplicity of its ensemble score function, controlled by a single weighting parameter `Î»`, provides unprecedented flexibility for users to define the target type of ID images (e.g., ID-dominant vs. multi-object ID images).\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Introduction of L-MCM, a method for OOD detection leveraging CLIP's local visual-text alignments with softmax scaling.\n        *   Proposal of GL-MCM, an ensemble method that effectively combines global and local concept matching scores.\n    *   **System Design/Architectural Innovations:** A simple, yet effective, score function design that allows for flexible control over ID image detection characteristics via a single hyperparameter `Î»`.\n    *   **Theoretical Insights/Analysis:** Highlights the crucial role of softmax scaling for local features in improving separability between ID and OOD, drawing inspiration from its proven benefits for global features.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Evaluated on standard ImageNet OOD benchmarks (iNaturalist, SUN, PLACES, TEXTURE).\n        *   Evaluated on curated multi-object benchmarks (MS-COCO, Pascal-VOC) designed to reflect realistic scenarios.\n        *   Compared against zero-shot baselines (MCM) and several fully-supervised OOD detection methods.\n        *   Demonstrated scalability by boosting the performance of few-shot learning methods (CoOp, LoCoOp).\n        *   Ablation studies were performed on the `Î»` parameter to showcase its flexibility in controlling ID image types.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   GL-MCM consistently outperformed the baseline zero-shot method (MCM) across most ImageNet and multi-object benchmarks (MS-COCO, Pascal-VOC) in terms of FPR95 and AUROC.\n        *   GL-MCM achieved performance comparable to fully supervised methods on ImageNet and, when combined with few-shot learning, even surpassed them.\n        *   It significantly boosted the performance of few-shot learning methods, particularly LoCoOp.\n        *   The `Î»` parameter was empirically shown to effectively adjust the detection preference between ID-dominant and multi-object ID images, demonstrating high flexibility.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** While generally strong, GL-MCM showed performance degradation on the Texture OOD dataset in some ImageNet settings. The paper prioritizes scalability and flexibility, thus focusing comparisons on MCM rather than other recent zero-shot OOD methods that might require additional training or negative prompts.\n    *   **Scope of Applicability:** Primarily applicable to zero-shot OOD detection in image classification tasks, especially beneficial for real-world datasets containing complex, multi-object scenes. It also demonstrates strong compatibility and performance gains when integrated with few-shot learning techniques.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art:** GL-MCM significantly advances the technical state-of-the-art in zero-shot OOD detection by effectively addressing the realistic multi-object scenario, outperforming existing zero-shot methods, and achieving competitive results with supervised approaches without requiring additional training.\n    *   **Potential Impact on Future Research:**\n        *   Opens new research directions by demonstrating the untapped potential of CLIP's local features for OOD detection, fostering integration between vision-language models, localization, and OOD tasks.\n        *   Provides a highly flexible and scalable framework that can be easily adapted to diverse user needs and integrated with other learning paradigms (e.g., few-shot learning), making it valuable for real-world ML deployments.",
        "keywords": [
          "zero-shot out-of-distribution (OOD) detection",
          "Vision-Language Models (CLIP)",
          "multi-object scenes",
          "Global-Local Maximum Concept Matching (GL-MCM)",
          "CLIP's local features",
          "softmax scaling",
          "ensemble score function",
          "hyperparameter Î»",
          "Maximum Concept Matching (MCM)",
          "real-world scenarios",
          "few-shot learning integration",
          "flexible OOD definition",
          "image classification"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"to this end, we present global-local maximum concept matching (gl-mcm), which incorporates local image scores as an auxiliary score...\" this directly aligns with presenting a new method or system.\n*   it describes the technical details of gl-mcm and its design (\"simple ensemble score function design\").\n*   the introduction discusses a technical problem (limitations of existing ood detection methods in multi-object scenarios) and sets the stage for a proposed solution.\n*   while it mentions \"experiments on imagenet and multi-object benchmarks demonstrate...\", the experiments are used to validate the *new method* being presented, making the empirical aspect a component of a technical paper, rather than the primary classification.\n\ntherefore, the paper is best classified as **technical**."
      },
      "file_name": "3f9f3ca7832f36285fbb0a65c221ded5e32382a1.pdf"
    },
    {
      "success": true,
      "doc_id": "e4630f963aa88d77828a55aaca9a82d0",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Problem**: Deep learning models often make overconfident predictions for Out-of-Distribution (OOD) inputs, which are unrelated to the in-distribution task. This poses a significant challenge for trustworthy machine learning, especially in safety-critical applications (e.g., medical diagnosis, autonomous driving) where misclassifying an OOD input can have severe consequences \\cite{bitterwolf2022rw0}.\n    *   **Motivation**: Despite numerous OOD detection methods proposed, there's a lack of theoretical understanding regarding their common objectives, implicit scoring functions, and underlying principles. This paper aims to provide a solid theoretical basis to advance the field beyond purely empirical performance comparisons \\cite{bitterwolf2022rw0}. The focus is on methods that use surrogate OOD data during training to learn a detection score that generalizes to unseen out-distributions at test time \\cite{bitterwolf2022rw0}.\n\n*   **2. Related Work & Positioning**\n    *   **Relationship**: The paper analyzes a sub-class of OOD detection methods that leverage surrogate OOD data during training, including Outlier Exposure (OE), Energy-Based OOD Detection, and methods using an extra background class \\cite{bitterwolf2022rw0}. It also examines density estimation approaches.\n    *   **Limitations of Previous Solutions**: Most existing OOD detection papers primarily focus on achieving superior empirical detection performance, offering limited theoretical insight into the differences and similarities between methods. This makes it difficult to understand if performance gains stem from fundamentally different principles or more efficient estimation techniques for similar underlying criteria \\cite{bitterwolf2022rw0}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper establishes a theoretical framework based on Bayesian decision theory to analyze the Bayes-optimal scoring functions of various OOD detection methods. It defines an equivalence relation for scoring functions based on their invariance to strictly monotonous transformations, meaning only the ranking induced by the score matters for metrics like AUC and FPR@qTPR \\cite{bitterwolf2022rw0}.\n    *   **Novelty**: The core innovation is demonstrating that many seemingly distinct OOD detection methods, particularly those using surrogate OOD data, are asymptotically equivalent to a simple binary discriminator between in-distribution and a (training) out-distribution. Differences primarily arise from the choice of training out-distribution and the estimation procedure, rather than fundamentally different theoretical principles \\cite{bitterwolf2022rw0}. The paper also rigorously derives the *implicit scoring functions* for prominent methods like Outlier Exposure's confidence loss and background class approaches, revealing how they integrate classification-specific information and deviate from the theoretically optimal `p(i|x)` score \\cite{bitterwolf2022rw0}.\n\n*   **4. Key Technical Contributions**\n    *   **Theoretical Framework**: Introduction of a formal definition of scoring function equivalence based on AUC and FPR@qTPR invariance, characterized by strictly monotonous transformations \\cite{bitterwolf2022rw0}.\n    *   **Equivalence Proofs**: Showing that Bayes-optimal solutions for density estimation, likelihood ratios, and several labeled-data OOD methods (e.g., background class, Outlier Exposure) are equivalent to a binary discriminator between in- and (surrogate) out-distributions \\cite{bitterwolf2022rw0}.\n    *   **Implicit Scoring Function Derivations**: Explicit derivation of the Bayes-optimal predictive distributions and implicit scoring functions for Outlier Exposure's confidence loss (`s3(x)`) and the maximal probability from a background class classifier (`s2(x)`). It highlights that `s2(x)` and `s3(x)` are generally not equivalent to the theoretically optimal `p(i|x)` (which is optimal if training and test OOD are identical), indicating a bias \\cite{bitterwolf2022rw0}.\n    *   **Simplified Baseline**: Demonstration that a binary discriminator, when trained in a shared fashion with a standard classifier, can achieve OOD detection performance competitive with state-of-the-art methods based on surrogate OOD data \\cite{bitterwolf2022rw0}.\n    *   **Explanation for Density Estimation Weakness**: Theoretical proof that direct density estimation for OOD detection is equivalent to discriminating against uniform noise, explaining its observed poor performance on complex image domains \\cite{bitterwolf2022rw0}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: The paper states that \"all of our findings are supported by extensive experiments on CIFAR-10 and CIFAR-100 with evaluation on various challenging out-of-distribution test datasets\" \\cite{bitterwolf2022rw0}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   A binary discriminator trained in a shared fashion with a standard classifier achieves OOD detection performance \"similar to that of Outlier Exposure\" \\cite{bitterwolf2022rw0}.\n        *   In practice, when trained in \"exactly the same way, all these methods perform similarly\" \\cite{bitterwolf2022rw0}.\n        *   Experimental comparisons in the appendix show that density-based methods and their binary discriminator equivalents perform \"similarly poorly compared to the methods using labeled data\" \\cite{bitterwolf2022rw0}.\n        *   The experiments empirically validate the theoretical equivalences and the competitive performance of the simpler binary discriminator baseline \\cite{bitterwolf2022rw0}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations**: The theoretical equivalences are \"asymptotic statements\" based on Bayes optimal solutions. The paper acknowledges that \"convergence to the Bayes optimal solution can be infinitely slow and that the methods can have implicit inductive biases\" in practical implementations \\cite{bitterwolf2022rw0}.\n    *   **Scope of Applicability**: The analysis primarily focuses on the sub-class of OOD detection methods that utilize surrogate OOD data during training. It assumes access to such surrogate data but not necessarily that it is related to the OOD inputs encountered at test time \\cite{bitterwolf2022rw0}. The derived scoring functions `s2` and `s3` are shown to introduce a bias as they are not equivalent to `p(i|x)` even when training and test OOD distributions are identical \\cite{bitterwolf2022rw0}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the theoretical understanding of OOD detection by identifying common underlying principles across diverse methods. It shifts the focus from purely empirical performance to a deeper analysis of implicit scoring functions and their relationship to optimal OOD criteria \\cite{bitterwolf2022rw0}.\n    *   **Potential Impact on Future Research**: By demonstrating that a simple binary discriminator can be competitive with state-of-the-art methods, the paper suggests that future research could focus more on robust and efficient estimation procedures for these core quantities, rather than searching for entirely new theoretical principles. It provides a strong theoretical foundation for comparing and designing OOD detection methods, potentially leading to more principled and effective solutions \\cite{bitterwolf2022rw0}.",
      "intriguing_abstract": "Deep learning's overconfident predictions on Out-of-Distribution (OOD) inputs pose a critical challenge for trustworthy AI, particularly in safety-critical applications. Despite a proliferation of OOD detection methods, a unifying theoretical understanding of their underlying principles remains elusive, hindering principled advancement. This paper introduces a novel Bayesian decision theory framework to rigorously analyze OOD detection, focusing on methods leveraging surrogate OOD data during training.\n\nOur groundbreaking analysis reveals a surprising asymptotic equivalence: many seemingly distinct OOD detection techniques, including Outlier Exposure and background class approaches, fundamentally converge to a simple binary discriminator between in-distribution and a training out-distribution. We formally define scoring function equivalence based on AUC and FPR@qTPR invariance and derive the implicit scoring functions for prominent methods, exposing how they integrate classification-specific information and deviate from theoretically optimal scores. Crucially, we demonstrate that a shared binary discriminator achieves competitive OOD detection performance, shifting the research paradigm from seeking entirely new principles to focusing on robust estimation. This work provides a vital theoretical foundation, guiding the design of more principled and effective OOD detection solutions for truly trustworthy machine learning.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Deep learning models",
        "Trustworthy machine learning",
        "Safety-critical applications",
        "Theoretical framework",
        "Bayesian decision theory",
        "Bayes-optimal scoring functions",
        "Asymptotic equivalence",
        "Implicit scoring functions",
        "Binary discriminator",
        "Surrogate OOD data",
        "Outlier Exposure",
        "Density estimation"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/ca9974ac55dacf8db6eb4a57f489756068797cab.pdf",
      "citation_key": "bitterwolf2022rw0",
      "metadata": {
        "title": "Breaking Down Out-of-Distribution Detection: Many Methods Based on OOD Training Data Estimate a Combination of the Same Core Quantities",
        "authors": [
          "Julian Bitterwolf",
          "Alexander Meinke",
          "Maximilian Augustin",
          "Matthias Hein"
        ],
        "published_date": "2022",
        "abstract": "It is an important problem in trustworthy machine learning to recognize out-of-distribution (OOD) inputs which are inputs unrelated to the in-distribution task. Many out-of-distribution detection methods have been suggested in recent years. The goal of this paper is to recognize common objectives as well as to identify the implicit scoring functions of different OOD detection methods. We focus on the sub-class of methods that use surrogate OOD data during training in order to learn an OOD detection score that generalizes to new unseen out-distributions at test time. We show that binary discrimination between in- and (different) out-distributions is equivalent to several distinct formulations of the OOD detection problem. When trained in a shared fashion with a standard classifier, this binary discriminator reaches an OOD detection performance similar to that of Outlier Exposure. Moreover, we show that the confidence loss which is used by Outlier Exposure has an implicit scoring function which differs in a non-trivial fashion from the theoretically optimal scoring function in the case where training and test out-distribution are the same, which again is similar to the one used when training an Energy-Based OOD detector or when adding a background class. In practice, when trained in exactly the same way, all these methods perform similarly.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/ca9974ac55dacf8db6eb4a57f489756068797cab.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 29,
        "score": 9.666666666666666,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Problem**: Deep learning models often make overconfident predictions for Out-of-Distribution (OOD) inputs, which are unrelated to the in-distribution task. This poses a significant challenge for trustworthy machine learning, especially in safety-critical applications (e.g., medical diagnosis, autonomous driving) where misclassifying an OOD input can have severe consequences \\cite{bitterwolf2022rw0}.\n    *   **Motivation**: Despite numerous OOD detection methods proposed, there's a lack of theoretical understanding regarding their common objectives, implicit scoring functions, and underlying principles. This paper aims to provide a solid theoretical basis to advance the field beyond purely empirical performance comparisons \\cite{bitterwolf2022rw0}. The focus is on methods that use surrogate OOD data during training to learn a detection score that generalizes to unseen out-distributions at test time \\cite{bitterwolf2022rw0}.\n\n*   **2. Related Work & Positioning**\n    *   **Relationship**: The paper analyzes a sub-class of OOD detection methods that leverage surrogate OOD data during training, including Outlier Exposure (OE), Energy-Based OOD Detection, and methods using an extra background class \\cite{bitterwolf2022rw0}. It also examines density estimation approaches.\n    *   **Limitations of Previous Solutions**: Most existing OOD detection papers primarily focus on achieving superior empirical detection performance, offering limited theoretical insight into the differences and similarities between methods. This makes it difficult to understand if performance gains stem from fundamentally different principles or more efficient estimation techniques for similar underlying criteria \\cite{bitterwolf2022rw0}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper establishes a theoretical framework based on Bayesian decision theory to analyze the Bayes-optimal scoring functions of various OOD detection methods. It defines an equivalence relation for scoring functions based on their invariance to strictly monotonous transformations, meaning only the ranking induced by the score matters for metrics like AUC and FPR@qTPR \\cite{bitterwolf2022rw0}.\n    *   **Novelty**: The core innovation is demonstrating that many seemingly distinct OOD detection methods, particularly those using surrogate OOD data, are asymptotically equivalent to a simple binary discriminator between in-distribution and a (training) out-distribution. Differences primarily arise from the choice of training out-distribution and the estimation procedure, rather than fundamentally different theoretical principles \\cite{bitterwolf2022rw0}. The paper also rigorously derives the *implicit scoring functions* for prominent methods like Outlier Exposure's confidence loss and background class approaches, revealing how they integrate classification-specific information and deviate from the theoretically optimal `p(i|x)` score \\cite{bitterwolf2022rw0}.\n\n*   **4. Key Technical Contributions**\n    *   **Theoretical Framework**: Introduction of a formal definition of scoring function equivalence based on AUC and FPR@qTPR invariance, characterized by strictly monotonous transformations \\cite{bitterwolf2022rw0}.\n    *   **Equivalence Proofs**: Showing that Bayes-optimal solutions for density estimation, likelihood ratios, and several labeled-data OOD methods (e.g., background class, Outlier Exposure) are equivalent to a binary discriminator between in- and (surrogate) out-distributions \\cite{bitterwolf2022rw0}.\n    *   **Implicit Scoring Function Derivations**: Explicit derivation of the Bayes-optimal predictive distributions and implicit scoring functions for Outlier Exposure's confidence loss (`s3(x)`) and the maximal probability from a background class classifier (`s2(x)`). It highlights that `s2(x)` and `s3(x)` are generally not equivalent to the theoretically optimal `p(i|x)` (which is optimal if training and test OOD are identical), indicating a bias \\cite{bitterwolf2022rw0}.\n    *   **Simplified Baseline**: Demonstration that a binary discriminator, when trained in a shared fashion with a standard classifier, can achieve OOD detection performance competitive with state-of-the-art methods based on surrogate OOD data \\cite{bitterwolf2022rw0}.\n    *   **Explanation for Density Estimation Weakness**: Theoretical proof that direct density estimation for OOD detection is equivalent to discriminating against uniform noise, explaining its observed poor performance on complex image domains \\cite{bitterwolf2022rw0}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: The paper states that \"all of our findings are supported by extensive experiments on CIFAR-10 and CIFAR-100 with evaluation on various challenging out-of-distribution test datasets\" \\cite{bitterwolf2022rw0}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   A binary discriminator trained in a shared fashion with a standard classifier achieves OOD detection performance \"similar to that of Outlier Exposure\" \\cite{bitterwolf2022rw0}.\n        *   In practice, when trained in \"exactly the same way, all these methods perform similarly\" \\cite{bitterwolf2022rw0}.\n        *   Experimental comparisons in the appendix show that density-based methods and their binary discriminator equivalents perform \"similarly poorly compared to the methods using labeled data\" \\cite{bitterwolf2022rw0}.\n        *   The experiments empirically validate the theoretical equivalences and the competitive performance of the simpler binary discriminator baseline \\cite{bitterwolf2022rw0}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations**: The theoretical equivalences are \"asymptotic statements\" based on Bayes optimal solutions. The paper acknowledges that \"convergence to the Bayes optimal solution can be infinitely slow and that the methods can have implicit inductive biases\" in practical implementations \\cite{bitterwolf2022rw0}.\n    *   **Scope of Applicability**: The analysis primarily focuses on the sub-class of OOD detection methods that utilize surrogate OOD data during training. It assumes access to such surrogate data but not necessarily that it is related to the OOD inputs encountered at test time \\cite{bitterwolf2022rw0}. The derived scoring functions `s2` and `s3` are shown to introduce a bias as they are not equivalent to `p(i|x)` even when training and test OOD distributions are identical \\cite{bitterwolf2022rw0}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the theoretical understanding of OOD detection by identifying common underlying principles across diverse methods. It shifts the focus from purely empirical performance to a deeper analysis of implicit scoring functions and their relationship to optimal OOD criteria \\cite{bitterwolf2022rw0}.\n    *   **Potential Impact on Future Research**: By demonstrating that a simple binary discriminator can be competitive with state-of-the-art methods, the paper suggests that future research could focus more on robust and efficient estimation procedures for these core quantities, rather than searching for entirely new theoretical principles. It provides a strong theoretical foundation for comparing and designing OOD detection methods, potentially leading to more principled and effective solutions \\cite{bitterwolf2022rw0}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Deep learning models",
          "Trustworthy machine learning",
          "Safety-critical applications",
          "Theoretical framework",
          "Bayesian decision theory",
          "Bayes-optimal scoring functions",
          "Asymptotic equivalence",
          "Implicit scoring functions",
          "Binary discriminator",
          "Surrogate OOD data",
          "Outlier Exposure",
          "Density estimation"
        ],
        "paper_type": "based on the abstract and introduction:\n\nthe abstract states the paper's goal is \"to recognize common objectives as well as to identify the implicit scoring functions of different ood detection methods.\" it then proceeds to \"show that binary discrimination... is equivalent to several distinct formulations\" and \"show that the conï¬dence loss... has an implicit scoring func-tion which differs in a non-trivial fashion from the theoretically optimal scoring function.\" these phrases strongly indicate a focus on **mathematical analysis, formal models, and proving equivalences or properties** of existing methods. while it also mentions empirical findings (\"reaches an ood detection performance similar,\" \"all these methods perform similarly\"), these appear to be validations or consequences of the theoretical insights, rather than the primary contribution. the core contribution is the analytical breakdown and understanding of the underlying mechanisms.\n\ntherefore, the paper is best classified as **theoretical**."
      },
      "file_name": "ca9974ac55dacf8db6eb4a57f489756068797cab.pdf"
    },
    {
      "success": true,
      "doc_id": "3c9b97fcafd99088b888fa910a6c273d",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the critical problem of Out-of-Distribution (OOD) detection in deep neural networks (DNNs). DNNs often fail to generalize reliably to data whose distribution differs from the training set, leading to overconfident predictions on OOD samples.\n    *   **Importance & Challenge:** This problem is fundamental for deploying safer and more reliable machine learning systems, especially in mission-critical applications (e.g., autonomous systems, healthcare). It's challenging because real-world data distributions are often non-stationary and unpredictable, and existing OOD detection methods (e.g., softmax confidence, generative model likelihoods) can be unreliable or require specific assumptions (e.g., OOD samples for training, specific model architectures).\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** \\cite{gomes2022zyv} positions itself against existing OOD detection methods, categorizing them by access level to the ML model:\n        *   **Black-Box:** Methods relying only on softmax outputs (e.g., Maximum Softmax Probability (MSP) \\cite{hendrycks2017baseline}, temperature scaling in ODIN \\cite{liang2018enhancing}, energy-based scores \\cite{liu2020energy}).\n        *   **Grey-Box:** Black-Box methods augmented with input pre-processing (e.g., adversarial perturbations in ODIN \\cite{liang2018enhancing}).\n        *   **White-Box:** Methods leveraging intermediate layer features (e.g., Mahalanobis distance on latent features \\cite{lee2018simple}, Gram matrices \\cite{sastry2020detecting}).\n    *   **Limitations of Previous Solutions:** Many methods suffer from DNNs assigning high confidence to OOD samples. Some require retraining with OOD data, which \\cite{gomes2022zyv} avoids comparing against. White-box methods like Mahalanobis distance often assume class-conditional Gaussian distributions with tied covariance matrices, which may not hold universally.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** \\cite{gomes2022zyv} introduces IGEOOD, a unified OOD detection method based on **Information Geometry**, specifically the **Fisher-Rao distance**. This distance measures the dissimilarity between probability distributions as the geodesic length on a manifold.\n    *   **Novelty:**\n        *   **Information Geometry for OOD:** This is the first work to apply information geometry tools, particularly the Fisher-Rao distance, to devise a unified metric for OOD detection.\n        *   **Flexible Framework:** IGEOOD adapts to various levels of access to the DNN:\n            *   **Black-Box/Grey-Box:** Applies Fisher-Rao distance to temperature-scaled softmax probabilities. It computes class-conditional centroids in the logits space using Fisher-Rao and defines an OOD score as the sum of distances to these centroids. For Grey-Box, it incorporates FGSM-style input pre-processing.\n            *   **White-Box:** Leverages latent features from intermediate layers. It models these pre-trained latent representations as a mixture of Gaussian PDFs with *diagonal* covariance matrices. The OOD score is derived from the Fisher-Rao distance between the test sample's conditional PDF and the closest in-distribution class's PDF.\n        *   **No OOD Sample Requirement:** The method does not strictly require OOD samples for training or validation, though it can benefit if they are available.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:** Introduction of IGEOOD, an OOD detection method leveraging the Fisher-Rao distance on both softmax outputs and latent features.\n    *   **Theoretical Insights/Analysis:** Derivation of explicit characterizations of the Fisher-Rao distance for softmax probabilities and multivariate Gaussian PDFs (under diagonal covariance assumption).\n    *   **System Design/Architectural Innovations:** A flexible, unified framework that works with any pre-trained neural network and adapts to different levels of model access (Black-Box, Grey-Box, White-Box).\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Experiments were performed across Black-Box, Grey-Box, and White-Box setups.\n    *   **Architectures & Datasets:** Evaluated on two DNN architectures, three in-distribution datasets, and nine OOD datasets.\n    *   **Key Performance Metrics:** The primary metric used is the True Negative Rate (TNR) at 95% True Positive Rate (TPR).\n    *   **Comparison Results:** IGEOOD consistently outperforms competing state-of-the-art methods. Specifically, in the White-Box setting, it increased the average TNR at 95% TPR by 11.2% (with OOD data tuning) and by 2.5% (with adversarial data tuning) compared to the Mahalanobis-based method by Lee et al. (2018).\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The White-Box approach assumes that latent features can be effectively modeled as a mixture of Gaussian PDFs with *diagonal* covariance matrices. While empirically supported as diagonal dominant, this is a simplifying assumption.\n        *   The method can benefit from OOD samples if available, implying that performance might be further optimized with such data, even if not strictly required.\n    *   **Scope of Applicability:** IGEOOD is applicable to any pre-trained neural network classifier and works under various degrees of access to the ML model (from just logits to all intermediate layers).\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{gomes2022zyv} significantly advances the technical state-of-the-art in OOD detection by introducing a novel information-geometric perspective, offering a more robust and theoretically grounded approach than many existing methods.\n    *   **Potential Impact:** This work opens new avenues for research into applying information geometry for building more reliable and robust ML systems. Its flexibility and strong empirical performance make it a promising candidate for improving OOD detection in real-world, mission-critical applications, enhancing the safety and trustworthiness of AI.",
      "intriguing_abstract": "Deep neural networks excel, yet their vulnerability to Out-of-Distribution (OOD) data, leading to overconfident and erroneous predictions, remains a critical barrier to reliable AI deployment in safety-critical applications. Addressing this fundamental challenge, we introduce IGEOOD, a pioneering OOD detection framework that leverages the powerful principles of **Information Geometry**, specifically the **Fisher-Rao distance**.\n\nThis novel approach quantifies the dissimilarity between probability distributions as geodesic lengths on a statistical manifold, offering a theoretically grounded and robust metric for OOD detection. IGEOOD presents a unified, flexible solution adaptable across various model access levels: from **Black-Box** analysis of temperature-scaled **softmax probabilities** to **White-Box** examination of **latent features** modeled as Gaussian mixtures. Crucially, it achieves state-of-the-art performance without strictly requiring OOD samples for training. Our comprehensive experiments demonstrate IGEOOD's consistent superiority over existing methods, significantly boosting **True Negative Rate** (e.g., 11.2% improvement in White-Box settings). This work not only advances the technical state-of-the-art but also opens new avenues for building inherently safer and more trustworthy machine learning systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "deep neural networks (DNNs)",
        "Information Geometry",
        "Fisher-Rao distance",
        "IGEOOD",
        "unified OOD detection framework",
        "Black-Box Grey-Box White-Box access",
        "softmax probabilities",
        "latent features",
        "no OOD sample requirement",
        "mission-critical applications",
        "state-of-the-art performance",
        "robust machine learning systems",
        "Gaussian PDFs diagonal covariance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/2815a5e7ba661ae278aa7c19e08ac884cde17bf7.pdf",
      "citation_key": "gomes2022zyv",
      "metadata": {
        "title": "Igeood: An Information Geometry Approach to Out-of-Distribution Detection",
        "authors": [
          "Eduardo Dadalto Camara Gomes",
          "F. Alberge",
          "P. Duhamel",
          "P. Piantanida"
        ],
        "published_date": "2022",
        "abstract": "Reliable out-of-distribution (OOD) detection is fundamental to implementing safer modern machine learning (ML) systems. In this paper, we introduce Igeood, an effective method for detecting OOD samples. Igeood applies to any pre-trained neural network, works under various degrees of access to the ML model, does not require OOD samples or assumptions on the OOD data but can also benefit (if available) from OOD samples. By building on the geodesic (Fisher-Rao) distance between the underlying data distributions, our discriminator can combine confidence scores from the logits outputs and the learned features of a deep neural network. Empirically, we show that Igeood outperforms competing state-of-the-art methods on a variety of network architectures and datasets.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/2815a5e7ba661ae278aa7c19e08ac884cde17bf7.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 29,
        "score": 9.666666666666666,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the critical problem of Out-of-Distribution (OOD) detection in deep neural networks (DNNs). DNNs often fail to generalize reliably to data whose distribution differs from the training set, leading to overconfident predictions on OOD samples.\n    *   **Importance & Challenge:** This problem is fundamental for deploying safer and more reliable machine learning systems, especially in mission-critical applications (e.g., autonomous systems, healthcare). It's challenging because real-world data distributions are often non-stationary and unpredictable, and existing OOD detection methods (e.g., softmax confidence, generative model likelihoods) can be unreliable or require specific assumptions (e.g., OOD samples for training, specific model architectures).\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** \\cite{gomes2022zyv} positions itself against existing OOD detection methods, categorizing them by access level to the ML model:\n        *   **Black-Box:** Methods relying only on softmax outputs (e.g., Maximum Softmax Probability (MSP) \\cite{hendrycks2017baseline}, temperature scaling in ODIN \\cite{liang2018enhancing}, energy-based scores \\cite{liu2020energy}).\n        *   **Grey-Box:** Black-Box methods augmented with input pre-processing (e.g., adversarial perturbations in ODIN \\cite{liang2018enhancing}).\n        *   **White-Box:** Methods leveraging intermediate layer features (e.g., Mahalanobis distance on latent features \\cite{lee2018simple}, Gram matrices \\cite{sastry2020detecting}).\n    *   **Limitations of Previous Solutions:** Many methods suffer from DNNs assigning high confidence to OOD samples. Some require retraining with OOD data, which \\cite{gomes2022zyv} avoids comparing against. White-box methods like Mahalanobis distance often assume class-conditional Gaussian distributions with tied covariance matrices, which may not hold universally.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** \\cite{gomes2022zyv} introduces IGEOOD, a unified OOD detection method based on **Information Geometry**, specifically the **Fisher-Rao distance**. This distance measures the dissimilarity between probability distributions as the geodesic length on a manifold.\n    *   **Novelty:**\n        *   **Information Geometry for OOD:** This is the first work to apply information geometry tools, particularly the Fisher-Rao distance, to devise a unified metric for OOD detection.\n        *   **Flexible Framework:** IGEOOD adapts to various levels of access to the DNN:\n            *   **Black-Box/Grey-Box:** Applies Fisher-Rao distance to temperature-scaled softmax probabilities. It computes class-conditional centroids in the logits space using Fisher-Rao and defines an OOD score as the sum of distances to these centroids. For Grey-Box, it incorporates FGSM-style input pre-processing.\n            *   **White-Box:** Leverages latent features from intermediate layers. It models these pre-trained latent representations as a mixture of Gaussian PDFs with *diagonal* covariance matrices. The OOD score is derived from the Fisher-Rao distance between the test sample's conditional PDF and the closest in-distribution class's PDF.\n        *   **No OOD Sample Requirement:** The method does not strictly require OOD samples for training or validation, though it can benefit if they are available.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:** Introduction of IGEOOD, an OOD detection method leveraging the Fisher-Rao distance on both softmax outputs and latent features.\n    *   **Theoretical Insights/Analysis:** Derivation of explicit characterizations of the Fisher-Rao distance for softmax probabilities and multivariate Gaussian PDFs (under diagonal covariance assumption).\n    *   **System Design/Architectural Innovations:** A flexible, unified framework that works with any pre-trained neural network and adapts to different levels of model access (Black-Box, Grey-Box, White-Box).\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Experiments were performed across Black-Box, Grey-Box, and White-Box setups.\n    *   **Architectures & Datasets:** Evaluated on two DNN architectures, three in-distribution datasets, and nine OOD datasets.\n    *   **Key Performance Metrics:** The primary metric used is the True Negative Rate (TNR) at 95% True Positive Rate (TPR).\n    *   **Comparison Results:** IGEOOD consistently outperforms competing state-of-the-art methods. Specifically, in the White-Box setting, it increased the average TNR at 95% TPR by 11.2% (with OOD data tuning) and by 2.5% (with adversarial data tuning) compared to the Mahalanobis-based method by Lee et al. (2018).\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The White-Box approach assumes that latent features can be effectively modeled as a mixture of Gaussian PDFs with *diagonal* covariance matrices. While empirically supported as diagonal dominant, this is a simplifying assumption.\n        *   The method can benefit from OOD samples if available, implying that performance might be further optimized with such data, even if not strictly required.\n    *   **Scope of Applicability:** IGEOOD is applicable to any pre-trained neural network classifier and works under various degrees of access to the ML model (from just logits to all intermediate layers).\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{gomes2022zyv} significantly advances the technical state-of-the-art in OOD detection by introducing a novel information-geometric perspective, offering a more robust and theoretically grounded approach than many existing methods.\n    *   **Potential Impact:** This work opens new avenues for research into applying information geometry for building more reliable and robust ML systems. Its flexibility and strong empirical performance make it a promising candidate for improving OOD detection in real-world, mission-critical applications, enhancing the safety and trustworthiness of AI.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "deep neural networks (DNNs)",
          "Information Geometry",
          "Fisher-Rao distance",
          "IGEOOD",
          "unified OOD detection framework",
          "Black-Box Grey-Box White-Box access",
          "softmax probabilities",
          "latent features",
          "no OOD sample requirement",
          "mission-critical applications",
          "state-of-the-art performance",
          "robust machine learning systems",
          "Gaussian PDFs diagonal covariance"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **\"in this paper, we introduce igeood, an effective method for detecting ood samples.\"** - this directly indicates the proposal of a new method or system.\n2.  **\"by building on the geodesic (fisher-rao) distance between the underlying data distributions, our discriminator can combine conï¬dence scores...\"** - this describes the technical approach and mechanism of the proposed method.\n3.  **\"empirically, we show that igeood outperforms competing state-of-the-art methods on a variety of network architectures and datasets.\"** - while this indicates an empirical evaluation, it is the *validation* of the *new method* being proposed. the primary contribution is the method itself, and the empirical results demonstrate its effectiveness.\n\nthe paper's core contribution is the development and presentation of a new method (igeood). the empirical evaluation serves to demonstrate the efficacy of this new technical contribution.\n\ntherefore, this paper is best classified as **technical**."
      },
      "file_name": "2815a5e7ba661ae278aa7c19e08ac884cde17bf7.pdf"
    },
    {
      "success": true,
      "doc_id": "6a139ead6cd78cf0122f3d65d623df07",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n### DIFFGUARD : Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models \\cite{gao2023kmk}\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem:** Detecting semantic Out-of-Distribution (OOD) samples for image classifiers, where the content of OOD samples semantically differs from all known classes.\n    *   **Why it's important and challenging:** Deep learning models' effectiveness relies on the i.i.d. data assumption, which often fails in real-world scenarios, necessitating OOD detection to prevent system performance degradation. Existing OOD detection methods face limitations:\n        *   Classification-based methods often have a trade-off between InD classification accuracy and over-confidence on OODs.\n        *   Auxiliary module-based methods (reconstruction quality, data density) tend to have low OOD detection capability, and their underlying assumptions may not always hold.\n        *   Previous semantic mismatch-guided approaches (e.g., MoodCat using cGANs) are not scalable to large datasets like ImageNet due to the inherent difficulty in training cGANs with both input images and labels as conditions.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches:**\n        *   **Classification-based:** Differs from methods utilizing classifier outputs (e.g., ODIN, ViM, MLS, KNN) or modifying classifier training (e.g., new losses, data augmentation, self-supervised learning).\n        *   **Generation-based:** Contrasts with methods focusing on reconstruction quality or data density, which often make assumptions that may not hold.\n        *   **Semantic Mismatch-guided:** Builds upon the concept of semantic mismatch modeling introduced by MoodCat \\cite{gao2023kmk}, but replaces cGANs with more stable and flexible diffusion models.\n        *   **Diffusion for OOD (prior work):** Unlike previous diffusion-based OOD methods that primarily leverage reconstruction ability, \\cite{gao2023kmk} utilizes the conditional generation capability of diffusion models to highlight semantic mismatch.\n    *   **Limitations of previous solutions:**\n        *   Classification-based methods struggle with the trade-off between InD accuracy and OOD over-confidence.\n        *   Reconstruction/density-based generative methods' assumptions about OODs may not be universally true.\n        *   MoodCat's cGAN-based approach is not practical for large-scale datasets (e.g., ImageNet) due to cGAN training complexities with multiple conditions.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method:** DIFFGUARD \\cite{gao2023kmk} proposes using pre-trained diffusion models for semantic mismatch-guided OOD detection. Given an input image and its predicted label from a classifier, it synthesizes a new image conditioned on both. OOD samples are identified by measuring the dissimilarity between the original input and the synthesized image.\n    *   **What makes this approach novel or different:**\n        *   Leverages the superior training stability and conditioning flexibility of diffusion models compared to cGANs for semantic mismatch-guided OOD detection, making it applicable to large-scale datasets.\n        *   Addresses the non-trivial challenge of effectively applying and balancing two conditions (input image and predicted label) in diffusion models for OOD detection.\n        *   Introduces several test-time techniques to strengthen semantic differences and improve conditioning effectiveness without requiring fine-tuning of the diffusion model.\n\n4.  **Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques:**\n        *   A diffusion-based framework for semantic mismatch-guided OOD detection that is scalable to ImageNet-scale datasets.\n        *   **For Classifier Guidance:**\n            *   **Clean Grad:** Replaces the noisy classifier traditionally used in classifier guidance with the *classifier-under-protection* by calculating gradients on an estimated clean image (`Ë†x0`). This provides more accurate semantic guidance.\n            *   Incorporates random cutout augmentation during gradient calculation to produce sharper, higher-amplitude gradients, leading to more effective semantic changes during synthesis.\n            *   **Adaptive Early-Stop (AES):** Adaptively stops the DDIM inversion process based on the quality degradation (e.g., PSNR, DISTS) of the diffused image. This balances consistency (faithful reconstruction) and controllability (semantic change), exploiting different quality degradation patterns between InD and OOD samples.\n        *   **For Classifier-Free Guidance:**\n            *   **CAM-guided Guidance Scale (CGS):** Utilizes Class Activation Maps (CAM) from the classifier-under-protection to adaptively adjust the guidance scale (`Ï‰`) for different image regions, applying stronger label guidance to semantically relevant areas.\n            *   **Multi-step Guidance (MSG):** Applies guidance at multiple intermediate steps of the DDIM inversion process to improve reconstruction quality and semantic consistency.\n    *   **System design or architectural innovations:** Provides a plug-and-play OOD detection capability for any classifier, compatible with pre-trained diffusion models without additional fine-tuning.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted:** Evaluated the proposed framework on the standard OpenOOD benchmark.\n        *   In-distribution (InD) datasets: CIFAR-10 and ImageNet.\n        *   OOD datasets: Various datasets used for OOD evaluation.\n        *   Qualitative analysis includes gradient visualizations and ablation studies on proposed techniques (e.g., cutout).\n    *   **Key performance metrics and comparison results:**\n        *   DIFFGUARD \\cite{gao2023kmk} outperforms or is on par with existing OOD detection solutions.\n        *   Achieves state-of-the-art (SOTA) performance on CIFAR-10.\n        *   Demonstrates strong differentiation ability on hard OOD samples of ImageNet.\n        *   Can be easily combined with existing OOD detection techniques to further enhance performance and achieve SOTA results.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations/assumptions:** The core challenge addressed is effectively applying and balancing the input image and label conditions in diffusion models. The proposed techniques aim to mitigate issues like the mismatch between noisy classifier guidance and the classifier-under-protection, and the need for effective semantic guidance.\n    *   **Scope of applicability:** Primarily focused on semantic OOD detection for image classifiers. Applicable to both small (CIFAR-10) and large-scale (ImageNet) datasets.\n\n7.  **Technical Significance**\n    *   **How this advances the technical state-of-the-art:** DIFFGUARD \\cite{gao2023kmk} provides a robust and scalable solution for semantic mismatch-guided OOD detection, overcoming the limitations of previous cGAN-based methods by leveraging the advancements in diffusion models. It introduces novel techniques to effectively integrate classifier information and balance conditional guidance.\n    *   **Potential impact on future research:**\n        *   Opens new avenues for leveraging the powerful conditional generation capabilities of diffusion models for various robustness tasks beyond OOD detection.\n        *   Offers a practical, plug-and-play OOD detection solution that can be easily integrated into existing deep learning systems without extensive retraining.\n        *   The proposed techniques for balancing conditions and utilizing classifier information can inspire further research into more effective guidance mechanisms in generative models.",
      "intriguing_abstract": "Deep learning models face a critical challenge in real-world applications: detecting Out-of-Distribution (OOD) samples, particularly those exhibiting novel semantics. Existing OOD detection methods often struggle with scalability, over-confidence on OODs, or limited semantic differentiation. We introduce **DIFFGUARD**, a pioneering framework that leverages the advanced conditional generation capabilities of **pre-trained diffusion models** for **semantic mismatch-guided OOD detection**, making it scalable to large datasets like ImageNet.\n\nUnlike prior generative approaches, DIFFGUARD synthesizes images conditioned on both the input and its predicted label. OOD samples are then identified by measuring the dissimilarity between the original and synthesized images. Our novel test-time techniquesâ€”including **Clean Grad**, **Adaptive Early-Stop (AES)**, **CAM-guided Guidance Scale (CGS)**, and **Multi-step Guidance (MSG)**â€”effectively balance image consistency and semantic controllability without requiring diffusion model fine-tuning. DIFFGUARD achieves **state-of-the-art (SOTA)** performance on CIFAR-10 and strong differentiation on challenging ImageNet OODs. This plug-and-play solution significantly enhances **deep learning robustness** and opens new avenues for leveraging diffusion models in AI safety and reliability.",
      "keywords": [
        "Semantic Out-of-Distribution (OOD) detection",
        "pre-trained diffusion models",
        "semantic mismatch-guided",
        "DIFFGUARD framework",
        "conditional generation",
        "classifier guidance",
        "classifier-free guidance",
        "Clean Grad",
        "Adaptive Early-Stop (AES)",
        "CAM-guided Guidance Scale (CGS)",
        "scalable OOD detection",
        "state-of-the-art performance",
        "plug-and-play OOD detection"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/57f4b117744112e4000894a5f939e114f1907719.pdf",
      "citation_key": "gao2023kmk",
      "metadata": {
        "title": "DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models",
        "authors": [
          "Ruiyuan Gao",
          "Chenchen Zhao",
          "Lanqing Hong",
          "Q. Xu"
        ],
        "published_date": "2023",
        "abstract": "Given a classifier, the inherent property of semantic Out-of-Distribution (OOD) samples is that their contents differ from all legal classes in terms of semantics, namely semantic mismatch. There is a recent work that directly applies it to OOD detection, which employs a conditional Generative Adversarial Network (cGAN) to enlarge semantic mismatch in the image space. While achieving remarkable OOD detection performance on small datasets, it is not applicable to ImageNet-scale datasets due to the difficulty in training cGANs with both input images and labels as conditions.As diffusion models are much easier to train and amenable to various conditions compared to cGANs, in this work, we propose to directly use pre-trained diffusion models for semantic mismatch-guided OOD detection, named DiffGuard. Specifically, given an OOD input image and the predicted label from the classifier, we try to enlarge the semantic difference between the reconstructed OOD image under these conditions and the original input image. We also present several test-time techniques to further strengthen such differences. Experimental results show that DiffGuard is effective on both Cifar-10 and hard cases of the large-scale ImageNet, and it can be easily combined with existing OOD detection techniques to achieve state-of-the-art OOD detection results.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/57f4b117744112e4000894a5f939e114f1907719.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 19,
        "score": 9.5,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n### DIFFGUARD : Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models \\cite{gao2023kmk}\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem:** Detecting semantic Out-of-Distribution (OOD) samples for image classifiers, where the content of OOD samples semantically differs from all known classes.\n    *   **Why it's important and challenging:** Deep learning models' effectiveness relies on the i.i.d. data assumption, which often fails in real-world scenarios, necessitating OOD detection to prevent system performance degradation. Existing OOD detection methods face limitations:\n        *   Classification-based methods often have a trade-off between InD classification accuracy and over-confidence on OODs.\n        *   Auxiliary module-based methods (reconstruction quality, data density) tend to have low OOD detection capability, and their underlying assumptions may not always hold.\n        *   Previous semantic mismatch-guided approaches (e.g., MoodCat using cGANs) are not scalable to large datasets like ImageNet due to the inherent difficulty in training cGANs with both input images and labels as conditions.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches:**\n        *   **Classification-based:** Differs from methods utilizing classifier outputs (e.g., ODIN, ViM, MLS, KNN) or modifying classifier training (e.g., new losses, data augmentation, self-supervised learning).\n        *   **Generation-based:** Contrasts with methods focusing on reconstruction quality or data density, which often make assumptions that may not hold.\n        *   **Semantic Mismatch-guided:** Builds upon the concept of semantic mismatch modeling introduced by MoodCat \\cite{gao2023kmk}, but replaces cGANs with more stable and flexible diffusion models.\n        *   **Diffusion for OOD (prior work):** Unlike previous diffusion-based OOD methods that primarily leverage reconstruction ability, \\cite{gao2023kmk} utilizes the conditional generation capability of diffusion models to highlight semantic mismatch.\n    *   **Limitations of previous solutions:**\n        *   Classification-based methods struggle with the trade-off between InD accuracy and OOD over-confidence.\n        *   Reconstruction/density-based generative methods' assumptions about OODs may not be universally true.\n        *   MoodCat's cGAN-based approach is not practical for large-scale datasets (e.g., ImageNet) due to cGAN training complexities with multiple conditions.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method:** DIFFGUARD \\cite{gao2023kmk} proposes using pre-trained diffusion models for semantic mismatch-guided OOD detection. Given an input image and its predicted label from a classifier, it synthesizes a new image conditioned on both. OOD samples are identified by measuring the dissimilarity between the original input and the synthesized image.\n    *   **What makes this approach novel or different:**\n        *   Leverages the superior training stability and conditioning flexibility of diffusion models compared to cGANs for semantic mismatch-guided OOD detection, making it applicable to large-scale datasets.\n        *   Addresses the non-trivial challenge of effectively applying and balancing two conditions (input image and predicted label) in diffusion models for OOD detection.\n        *   Introduces several test-time techniques to strengthen semantic differences and improve conditioning effectiveness without requiring fine-tuning of the diffusion model.\n\n4.  **Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques:**\n        *   A diffusion-based framework for semantic mismatch-guided OOD detection that is scalable to ImageNet-scale datasets.\n        *   **For Classifier Guidance:**\n            *   **Clean Grad:** Replaces the noisy classifier traditionally used in classifier guidance with the *classifier-under-protection* by calculating gradients on an estimated clean image (`Ë†x0`). This provides more accurate semantic guidance.\n            *   Incorporates random cutout augmentation during gradient calculation to produce sharper, higher-amplitude gradients, leading to more effective semantic changes during synthesis.\n            *   **Adaptive Early-Stop (AES):** Adaptively stops the DDIM inversion process based on the quality degradation (e.g., PSNR, DISTS) of the diffused image. This balances consistency (faithful reconstruction) and controllability (semantic change), exploiting different quality degradation patterns between InD and OOD samples.\n        *   **For Classifier-Free Guidance:**\n            *   **CAM-guided Guidance Scale (CGS):** Utilizes Class Activation Maps (CAM) from the classifier-under-protection to adaptively adjust the guidance scale (`Ï‰`) for different image regions, applying stronger label guidance to semantically relevant areas.\n            *   **Multi-step Guidance (MSG):** Applies guidance at multiple intermediate steps of the DDIM inversion process to improve reconstruction quality and semantic consistency.\n    *   **System design or architectural innovations:** Provides a plug-and-play OOD detection capability for any classifier, compatible with pre-trained diffusion models without additional fine-tuning.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted:** Evaluated the proposed framework on the standard OpenOOD benchmark.\n        *   In-distribution (InD) datasets: CIFAR-10 and ImageNet.\n        *   OOD datasets: Various datasets used for OOD evaluation.\n        *   Qualitative analysis includes gradient visualizations and ablation studies on proposed techniques (e.g., cutout).\n    *   **Key performance metrics and comparison results:**\n        *   DIFFGUARD \\cite{gao2023kmk} outperforms or is on par with existing OOD detection solutions.\n        *   Achieves state-of-the-art (SOTA) performance on CIFAR-10.\n        *   Demonstrates strong differentiation ability on hard OOD samples of ImageNet.\n        *   Can be easily combined with existing OOD detection techniques to further enhance performance and achieve SOTA results.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations/assumptions:** The core challenge addressed is effectively applying and balancing the input image and label conditions in diffusion models. The proposed techniques aim to mitigate issues like the mismatch between noisy classifier guidance and the classifier-under-protection, and the need for effective semantic guidance.\n    *   **Scope of applicability:** Primarily focused on semantic OOD detection for image classifiers. Applicable to both small (CIFAR-10) and large-scale (ImageNet) datasets.\n\n7.  **Technical Significance**\n    *   **How this advances the technical state-of-the-art:** DIFFGUARD \\cite{gao2023kmk} provides a robust and scalable solution for semantic mismatch-guided OOD detection, overcoming the limitations of previous cGAN-based methods by leveraging the advancements in diffusion models. It introduces novel techniques to effectively integrate classifier information and balance conditional guidance.\n    *   **Potential impact on future research:**\n        *   Opens new avenues for leveraging the powerful conditional generation capabilities of diffusion models for various robustness tasks beyond OOD detection.\n        *   Offers a practical, plug-and-play OOD detection solution that can be easily integrated into existing deep learning systems without extensive retraining.\n        *   The proposed techniques for balancing conditions and utilizing classifier information can inspire further research into more effective guidance mechanisms in generative models.",
        "keywords": [
          "Semantic Out-of-Distribution (OOD) detection",
          "pre-trained diffusion models",
          "semantic mismatch-guided",
          "DIFFGUARD framework",
          "conditional generation",
          "classifier guidance",
          "classifier-free guidance",
          "Clean Grad",
          "Adaptive Early-Stop (AES)",
          "CAM-guided Guidance Scale (CGS)",
          "scalable OOD detection",
          "state-of-the-art performance",
          "plug-and-play OOD detection"
        ],
        "paper_type": "based on the abstract and introduction:\n\nthe paper clearly states: \"we propose to directly use pre-trained diffusion models for semantic mismatch-guided ood detection, named diffguard.\" it then describes the specific mechanism of this proposed method and mentions \"we also present several test-time techniques.\" the introduction sets up a technical problem (ood detection limitations) and discusses existing solutions and their shortcomings, implying the need for a new, improved solution. the experimental results are presented as validation of this new method.\n\nthis aligns perfectly with the **technical** classification criteria:\n*   abstract mentions: \"propose\", \"present\", \"method\" (implicitly by describing diffguard).\n*   introduction discusses: \"technical problem\" (ood detection), \"proposed solution\" (implied by the abstract's proposal of diffguard).\n\ntherefore, the paper type is **technical**."
      },
      "file_name": "57f4b117744112e4000894a5f939e114f1907719.pdf"
    },
    {
      "success": true,
      "doc_id": "0359d18a78e34c7e30545b209c4ecb05",
      "summary": "We propose a principled and practical method for out-of-distribution (OoD) detection with deep hybrid models (DHMs), which model the joint density p(x, y) of features and labels with a single forward pass. By factorizing the joint density p(x, y) into three sources of uncertainty, we show that our approach has the ability to identify samples semantically different from the training data. To ensure computational scalability, we add a weight normalization step during training, which enables us to plug in state-of-the-art (SoTA) deep neural network (DNN) architectures for approximately modeling and inferring expressive probability distributions. Our method provides an efficient, general, and flexible framework for predictive uncertainty estimation with promising results and theoretical support. To our knowledge, this is the first work to reach 100% in OoD detection tasks on both vision and language datasets, especially on notably difficult dataset pairs such as CIFAR -10 vs. SVHN and CIFAR-100 vs. CIFAR-10. This work is a step towards enabling DNNs in real-world deployment for safety-critical applications.",
      "intriguing_abstract": "We propose a principled and practical method for out-of-distribution (OoD) detection with deep hybrid models (DHMs), which model the joint density p(x, y) of features and labels with a single forward pass. By factorizing the joint density p(x, y) into three sources of uncertainty, we show that our approach has the ability to identify samples semantically different from the training data. To ensure computational scalability, we add a weight normalization step during training, which enables us to plug in state-of-the-art (SoTA) deep neural network (DNN) architectures for approximately modeling and inferring expressive probability distributions. Our method provides an efficient, general, and flexible framework for predictive uncertainty estimation with promising results and theoretical support. To our knowledge, this is the first work to reach 100% in OoD detection tasks on both vision and language datasets, especially on notably difficult dataset pairs such as CIFAR -10 vs. SVHN and CIFAR-100 vs. CIFAR-10. This work is a step towards enabling DNNs in real-world deployment for safety-critical applications.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/8ef5a28955ce4fbd170e4dddbd37930e025edb69.pdf",
      "citation_key": "cao20224r3",
      "metadata": {
        "title": "Deep Hybrid Models for Out-of-Distribution Detection",
        "authors": [
          "Senqi Cao",
          "Zhongfei Zhang"
        ],
        "published_date": "2022",
        "abstract": "We propose a principled and practical method for out-of-distribution (OoD) detection with deep hybrid models (DHMs), which model the joint density p(x, y) of features and labels with a single forward pass. By factorizing the joint density p(x, y) into three sources of uncertainty, we show that our approach has the ability to identify samples semantically different from the training data. To ensure computational scalability, we add a weight normalization step during training, which enables us to plug in state-of-the-art (SoTA) deep neural network (DNN) architectures for approximately modeling and inferring expressive probability distributions. Our method provides an efficient, general, and flexible framework for predictive uncertainty estimation with promising results and theoretical support. To our knowledge, this is the first work to reach 100% in OoD detection tasks on both vision and language datasets, especially on notably difficult dataset pairs such as CIFAR -10 vs. SVHN and CIFAR-100 vs. CIFAR-10. This work is a step towards enabling DNNs in real-world deployment for safety-critical applications.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/8ef5a28955ce4fbd170e4dddbd37930e025edb69.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 28,
        "score": 9.333333333333332,
        "summary": "We propose a principled and practical method for out-of-distribution (OoD) detection with deep hybrid models (DHMs), which model the joint density p(x, y) of features and labels with a single forward pass. By factorizing the joint density p(x, y) into three sources of uncertainty, we show that our approach has the ability to identify samples semantically different from the training data. To ensure computational scalability, we add a weight normalization step during training, which enables us to plug in state-of-the-art (SoTA) deep neural network (DNN) architectures for approximately modeling and inferring expressive probability distributions. Our method provides an efficient, general, and flexible framework for predictive uncertainty estimation with promising results and theoretical support. To our knowledge, this is the first work to reach 100% in OoD detection tasks on both vision and language datasets, especially on notably difficult dataset pairs such as CIFAR -10 vs. SVHN and CIFAR-100 vs. CIFAR-10. This work is a step towards enabling DNNs in real-world deployment for safety-critical applications.",
        "keywords": []
      },
      "file_name": "8ef5a28955ce4fbd170e4dddbd37930e025edb69.pdf"
    },
    {
      "success": true,
      "doc_id": "22f2b449b22f3931b7a24571560db593",
      "summary": "Here's a focused summary of the paper \"EAT: Towards Long-Tailed Out-of-Distribution Detection\" by Wei et al. \\cite{wei2023f15} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenging task of Out-of-Distribution (OOD) detection when the in-distribution training data follows a long-tailed class distribution.\n    *   **Importance and Challenge**: Most existing OOD detection methods assume class-balanced in-distribution datasets, which is rarely true in real-world scenarios. The main difficulty lies in effectively distinguishing OOD data from samples belonging to the under-represented tail classes, as a classifier's OOD detection ability is not strongly correlated with its in-distribution accuracy.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{wei2023f15} builds upon existing OOD detection methods (e.g., Outlier Exposure, Energy, SOFL, ATOM) and long-tailed learning techniques (e.g., data re-balancing, output adjustment, loss modification). It also relates to recent long-tailed OOD detection efforts like PASCL, HOD, and OLTR.\n    *   **Limitations of Previous Solutions**:\n        *   Current OOD detectors are typically trained on class-balanced data and perform poorly on long-tailed distributions.\n        *   Existing long-tailed learning methods primarily aim to boost in-distribution classification performance and cannot directly detect OOD data.\n        *   Prior long-tailed OOD methods like PASCL \\cite{wei2023f15} optimize contrastive objectives or use logit adjustment, while HOD \\cite{wei2023f15} assumes labeled OOD data, and OLTR \\cite{wei2023f15} is outperformed by state-of-the-art OOD detection methods.\n        *   \\cite{wei2023f15} explicitly challenges the notion that a classifier performing well on in-distribution data automatically excels as an OOD detector.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method (EAT Framework)**: \\cite{wei2023f15} proposes EAT, a novel framework composed of two key ingredients:\n        1.  **Dynamic Virtual Labels**: Expands the classification space by introducing multiple abstention classes for OOD data. OOD samples are dynamically assigned \"virtual labels\" to these abstention classes during training, allowing the model to learn clear decision boundaries between in-distribution and OOD data. This differs from methods that maximize predictive uncertainty or use a single abstention class.\n        2.  **Context-rich Tail Class Augmentation**: Augments tail-class images by overlaying them onto context-rich OOD data (or head-class images) using a tailored CutMix technique. This encourages the model to focus on discriminative foreground features of tail classes and improves generalization by diversifying contexts.\n    *   **Additional Components**: The framework integrates an ensemble of classifiers for improved OOD separation and employs a fine-tuning stage using a class-balanced loss (Logits Adjustment) to enhance inlier classification performance.\n    *   **Novelty**: \\cite{wei2023f15} is the first to adapt CutMix specifically for long-tailed OOD detection. The dynamic assignment of multiple virtual labels for OOD samples, guided by the model's predictions, is a novel approach compared to static uncertainty maximization or single abstention classes.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   A novel approach for training OOD data using dynamic virtual labels assigned to multiple abstention classes, specifically designed for long-tailed data.\n        *   Context-rich Tail Class Augmentation, which leverages OOD data as backgrounds to enhance tail-class generalization and OOD distinction.\n    *   **Theoretical Insights**: Provides an analysis of gradient noise induced by virtual labels, demonstrating that the dynamic direction of this noise helps escape local minima during optimization and encourages more conservative in-distribution predictions for OOD samples.\n    *   **Challenges Existing Paradigms**: Empirically validates that a strong inlier classifier does not necessarily imply good OOD detection performance, contradicting previous arguments.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on benchmark long-tailed datasets: CIFAR10-LT, CIFAR100-LT, and ImageNet-LT for in-distribution data. OOD training data was sourced from TinyImages80M, and OOD test data included Textures, SVHN, Tiny ImageNet, LSUN, and Places365.\n    *   **Key Performance Metrics & Results**:\n        *   \\cite{wei2023f15} demonstrates that its method outperforms current state-of-the-art approaches.\n        *   Achieves an average boost of 2.0% AUROC (Area Under the Receiver Operating Characteristic curve) for OOD detection.\n        *   Shows an average improvement of 2.9% inlier classification accuracy compared to the previous state-of-the-art.\n        *   The method can be used as a versatile add-on for existing long-tail learning approaches, significantly enhancing their OOD detection performance.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The tailored CutMix can introduce label noise, which \\cite{wei2023f15} mitigates by assigning lower sample weights to generated images. The method focuses on leveraging unlabeled OOD data, unlike some prior works that assume labeled OOD data.\n    *   **Scope of Applicability**: The method is specifically designed for and validated on long-tailed OOD detection tasks, where the in-distribution data exhibits a skewed class distribution.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{wei2023f15} tackles the challenging and under-explored problem of long-tailed OOD detection, providing innovative solutions that significantly advance the technical state-of-the-art in this domain.\n    *   **Potential Impact on Future Research**: The proposed EAT framework, particularly the concepts of dynamic virtual labels and context-rich tail class augmentation, offers a new direction for OOD detection in imbalanced data settings. Its ability to serve as an add-on for existing long-tail learning methods makes it highly practical and impactful, potentially influencing future research in robust and reliable AI systems operating in real-world, imbalanced data environments.",
      "intriguing_abstract": "Real-world data is inherently imbalanced, presenting a critical challenge for robust AI: Out-of-Distribution (OOD) detection in long-tailed class distributions. Existing OOD methods falter on skewed data, while conventional long-tailed learning techniques neglect OOD distinction. We introduce EAT, a novel framework that fundamentally rethinks OOD detection in these complex scenarios, challenging the paradigm that strong inlier classification guarantees OOD detection prowess.\n\nEAT's innovation lies in two core components: **Dynamic Virtual Labels** and **Context-rich Tail Class Augmentation**. Instead of static uncertainty, we dynamically assign OOD samples to multiple virtual abstention classes, learning explicit decision boundaries between in-distribution and OOD data. Complementarily, our tailored CutMix technique augments tail-class images with OOD backgrounds, forcing models to focus on discriminative foreground features and enhancing generalization.\n\nExtensive experiments on benchmark long-tailed datasets (CIFAR-LT, ImageNet-LT) demonstrate EAT's unprecedented performance, achieving an average 2.0% AUROC boost for OOD detection and 2.9% inlier classification accuracy improvement over state-of-the-art methods. EAT serves as a versatile add-on, significantly advancing robust OOD detection in imbalanced data environments and paving the way for more reliable real-world AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "long-tailed class distribution",
        "EAT framework",
        "Dynamic Virtual Labels",
        "multiple abstention classes",
        "Context-rich Tail Class Augmentation",
        "adapted CutMix technique",
        "unlabeled OOD data",
        "AUROC",
        "improved OOD detection performance",
        "enhanced inlier classification accuracy",
        "add-on for long-tail learning",
        "gradient noise analysis",
        "challenging OOD detection paradigms"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba.pdf",
      "citation_key": "wei2023f15",
      "metadata": {
        "title": "EAT: Towards Long-Tailed Out-of-Distribution Detection",
        "authors": [
          "Tong Wei",
          "Bo-Lin Wang",
          "Min-Ling Zhang"
        ],
        "published_date": "2023",
        "abstract": "Despite recent advancements in out-of-distribution (OOD) detection, most current studies assume a class-balanced in-distribution training dataset, which is rarely the case in real-world scenarios. This paper addresses the challenging task of long-tailed OOD detection, where the in-distribution data follows a long-tailed class distribution. The main difficulty lies in distinguishing OOD data from samples belonging to the tail classes, as the ability of a classifier to detect OOD instances is not strongly correlated with its accuracy on the in-distribution classes. To overcome this issue, we propose two simple ideas: (1) Expanding the in-distribution class space by introducing multiple abstention classes. This approach allows us to build a detector with clear decision boundaries by training on OOD data using virtual labels. (2) Augmenting the context-limited tail classes by overlaying images onto the context-rich OOD data. This technique encourages the model to pay more attention to the discriminative features of the tail classes. We provide a clue for separating in-distribution and OOD data by analyzing gradient noise. Through extensive experiments, we demonstrate that our method outperforms the current state-of-the-art on various benchmark datasets. Moreover, our method can be used as an add-on for existing long-tail learning approaches, significantly enhancing their OOD detection performance. Code is available at: https://github.com/Stomach-ache/Long-Tailed-OOD-Detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 18,
        "score": 9.0,
        "summary": "Here's a focused summary of the paper \"EAT: Towards Long-Tailed Out-of-Distribution Detection\" by Wei et al. \\cite{wei2023f15} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenging task of Out-of-Distribution (OOD) detection when the in-distribution training data follows a long-tailed class distribution.\n    *   **Importance and Challenge**: Most existing OOD detection methods assume class-balanced in-distribution datasets, which is rarely true in real-world scenarios. The main difficulty lies in effectively distinguishing OOD data from samples belonging to the under-represented tail classes, as a classifier's OOD detection ability is not strongly correlated with its in-distribution accuracy.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{wei2023f15} builds upon existing OOD detection methods (e.g., Outlier Exposure, Energy, SOFL, ATOM) and long-tailed learning techniques (e.g., data re-balancing, output adjustment, loss modification). It also relates to recent long-tailed OOD detection efforts like PASCL, HOD, and OLTR.\n    *   **Limitations of Previous Solutions**:\n        *   Current OOD detectors are typically trained on class-balanced data and perform poorly on long-tailed distributions.\n        *   Existing long-tailed learning methods primarily aim to boost in-distribution classification performance and cannot directly detect OOD data.\n        *   Prior long-tailed OOD methods like PASCL \\cite{wei2023f15} optimize contrastive objectives or use logit adjustment, while HOD \\cite{wei2023f15} assumes labeled OOD data, and OLTR \\cite{wei2023f15} is outperformed by state-of-the-art OOD detection methods.\n        *   \\cite{wei2023f15} explicitly challenges the notion that a classifier performing well on in-distribution data automatically excels as an OOD detector.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method (EAT Framework)**: \\cite{wei2023f15} proposes EAT, a novel framework composed of two key ingredients:\n        1.  **Dynamic Virtual Labels**: Expands the classification space by introducing multiple abstention classes for OOD data. OOD samples are dynamically assigned \"virtual labels\" to these abstention classes during training, allowing the model to learn clear decision boundaries between in-distribution and OOD data. This differs from methods that maximize predictive uncertainty or use a single abstention class.\n        2.  **Context-rich Tail Class Augmentation**: Augments tail-class images by overlaying them onto context-rich OOD data (or head-class images) using a tailored CutMix technique. This encourages the model to focus on discriminative foreground features of tail classes and improves generalization by diversifying contexts.\n    *   **Additional Components**: The framework integrates an ensemble of classifiers for improved OOD separation and employs a fine-tuning stage using a class-balanced loss (Logits Adjustment) to enhance inlier classification performance.\n    *   **Novelty**: \\cite{wei2023f15} is the first to adapt CutMix specifically for long-tailed OOD detection. The dynamic assignment of multiple virtual labels for OOD samples, guided by the model's predictions, is a novel approach compared to static uncertainty maximization or single abstention classes.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   A novel approach for training OOD data using dynamic virtual labels assigned to multiple abstention classes, specifically designed for long-tailed data.\n        *   Context-rich Tail Class Augmentation, which leverages OOD data as backgrounds to enhance tail-class generalization and OOD distinction.\n    *   **Theoretical Insights**: Provides an analysis of gradient noise induced by virtual labels, demonstrating that the dynamic direction of this noise helps escape local minima during optimization and encourages more conservative in-distribution predictions for OOD samples.\n    *   **Challenges Existing Paradigms**: Empirically validates that a strong inlier classifier does not necessarily imply good OOD detection performance, contradicting previous arguments.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on benchmark long-tailed datasets: CIFAR10-LT, CIFAR100-LT, and ImageNet-LT for in-distribution data. OOD training data was sourced from TinyImages80M, and OOD test data included Textures, SVHN, Tiny ImageNet, LSUN, and Places365.\n    *   **Key Performance Metrics & Results**:\n        *   \\cite{wei2023f15} demonstrates that its method outperforms current state-of-the-art approaches.\n        *   Achieves an average boost of 2.0% AUROC (Area Under the Receiver Operating Characteristic curve) for OOD detection.\n        *   Shows an average improvement of 2.9% inlier classification accuracy compared to the previous state-of-the-art.\n        *   The method can be used as a versatile add-on for existing long-tail learning approaches, significantly enhancing their OOD detection performance.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The tailored CutMix can introduce label noise, which \\cite{wei2023f15} mitigates by assigning lower sample weights to generated images. The method focuses on leveraging unlabeled OOD data, unlike some prior works that assume labeled OOD data.\n    *   **Scope of Applicability**: The method is specifically designed for and validated on long-tailed OOD detection tasks, where the in-distribution data exhibits a skewed class distribution.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{wei2023f15} tackles the challenging and under-explored problem of long-tailed OOD detection, providing innovative solutions that significantly advance the technical state-of-the-art in this domain.\n    *   **Potential Impact on Future Research**: The proposed EAT framework, particularly the concepts of dynamic virtual labels and context-rich tail class augmentation, offers a new direction for OOD detection in imbalanced data settings. Its ability to serve as an add-on for existing long-tail learning methods makes it highly practical and impactful, potentially influencing future research in robust and reliable AI systems operating in real-world, imbalanced data environments.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "long-tailed class distribution",
          "EAT framework",
          "Dynamic Virtual Labels",
          "multiple abstention classes",
          "Context-rich Tail Class Augmentation",
          "adapted CutMix technique",
          "unlabeled OOD data",
          "AUROC",
          "improved OOD detection performance",
          "enhanced inlier classification accuracy",
          "add-on for long-tail learning",
          "gradient noise analysis",
          "challenging OOD detection paradigms"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"we propose two simple ideas\", \"our method outperforms the current state-of-the-art\". this directly aligns with presenting new methods/algorithms and demonstrating their effectiveness.\n*   **introduction discusses:** it identifies a specific technical problem (\"long-tailed ood detection\" where \"in-distribution data is class-balanced, which is usually violated in real-world tasks\") and sets the stage for the proposed solution (implied by \"in this paper,\" followed by the abstract's \"we propose\").\n*   while it includes empirical evaluation (\"extensive experiments, we demonstrate that our method outperforms...\"), the core contribution described is the *development and proposal* of new techniques (\"expanding the in-distribution class space\", \"augmenting the context-limited tail classes\") to solve a specific technical challenge. empirical results are used to validate the proposed technical solution."
      },
      "file_name": "7ea7ff3ab79705d3b7336ef9243b7c81d3b003ba.pdf"
    },
    {
      "success": true,
      "doc_id": "e6b2abc09a771e1644edeb6194e0b32c",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Detecting out-of-distribution (OOD) data to ensure safe and reliable deployment of machine learning models \\cite{behpour2023x13}.\n    *   **Importance and Challenge**: Deep Neural Networks (DNNs) often produce overconfident predictions on OOD inputs, making it difficult to distinguish them from in-distribution (ID) data. This poses significant risks in safety-critical applications (e.g., healthcare, autonomous vehicles) \\cite{behpour2023x13}. Existing OOD detection methods often neglect the role of the most important parameters of pre-trained networks over ID data, or rely on noisy full gradient space information \\cite{behpour2023x13}.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**:\n        *   Calculating OOD uncertainty from the activation space (model output or feature representations) \\cite{behpour2023x13}.\n        *   Leveraging gradient information (e.g., ODIN, GradNorm, ExGrad) \\cite{behpour2023x13}.\n        *   Employing network parameter sparsification (e.g., DICE, ASH) \\cite{behpour2023x13}.\n    *   **Limitations of Previous Solutions**:\n        *   GradNorm considers the full gradient space, which can be noisy and lead to sub-optimal solutions \\cite{behpour2023x13}.\n        *   ASH removes a majority of activations, potentially diminishing performance due to the partial removal of critical parameters, and lacks a principled sparsification method \\cite{behpour2023x13}.\n        *   Many existing methods overlook the crucial role of the most important parameters of the pre-trained network over ID data \\cite{behpour2023x13}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (GradOrth)**:\n        *   Based on the observation that important features for OOD data identification reside in the lower-rank subspace of in-distribution (ID) data \\cite{behpour2023x13}.\n        *   Identifies OOD data by computing the norm of the gradient projection onto subspaces deemed important for ID data \\cite{behpour2023x13}.\n        *   A large orthogonal projection value (i.e., a small projection value) indicates an OOD sample, signifying a weak correlation with ID data \\cite{behpour2023x13}.\n        *   **Process**:\n            1.  **Pre-trained Network Subspace Computation**: Uses Singular Value Decomposition (SVD) on the last-layer activations of a small, randomly selected subset of ID data to derive a low-rank subspace (SL) that captures the most significant ID representations \\cite{behpour2023x13}.\n            2.  **Inference with OOD Data**: Computes the gradient of the OOD sample at the last layer of the pre-trained network \\cite{behpour2023x13}.\n            3.  **Detector Construction**: Calculates the OOD score as the norm of the projection of the sample's gradient onto the pre-computed ID subspace (SL) \\cite{behpour2023x13}.\n    *   **Novelty and Differentiation**:\n        *   Pioneering work in investigating and demonstrating the efficacy of the *subspace of a DNNâ€™s gradients* for OOD detection \\cite{behpour2023x13}.\n        *   Leverages low-rank factorization principles to focus on the *most important parameter space* of a pre-trained network, addressing the limitations of full gradient space or empirical sparsification methods \\cite{behpour2023x13}.\n        *   The method is simple yet effective, requiring only a one-time subspace computation and gradient calculation during inference, without additional training or hyper-parameter tuning \\cite{behpour2023x13}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of GradOrth, an efficient OOD detection method that leverages the low-rank subspace of gradients from a pre-trained network's most important parameters \\cite{behpour2023x13}.\n    *   **Theoretical Insight**: Proposes that crucial discriminative features for OOD data reside within the gradient subspace of ID data, supported by the observation that stochastic gradient descent (SGD) updates lie in the span of input data points \\cite{behpour2023x13}.\n    *   **System Design**: A post-hoc OOD detection framework that uses SVD to identify a compact, relevant ID subspace from network activations, and then measures OODness by projecting test sample gradients onto this subspace \\cite{behpour2023x13}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments on two widely-used benchmarks:\n        *   **ImageNet Benchmark**: ResNet-50 pre-trained on ImageNet-1k (ID), evaluated against OOD datasets including iNaturalist, SUN, Places, and Textures \\cite{behpour2023x13}.\n        *   **CIFAR Benchmark**: DenseNet-101 pre-trained on CIFAR-10/100 (ID), evaluated against OOD datasets like Textures, SVHN, Places365, LSUN-Crop, LSUN-Resize, and iSUN \\cite{behpour2023x13}.\n        *   Subspace computation used 10 (ImageNet) or 5 (CIFAR) random samples per class with an SVD threshold of 0.97, applied to the last fully connected layer \\cite{behpour2023x13}.\n    *   **Key Performance Metrics**: AUROC (Area Under the Receiver Operating Characteristic curve) and FPR95 (False Positive Rate at 95% True Positive Rate) \\cite{behpour2023x13}.\n    *   **Comparison Results**:\n        *   GradOrth achieved a notable reduction in average FPR95 of up to 8% compared to current state-of-the-art methods \\cite{behpour2023x13}.\n        *   **ImageNet**: Surpassed ASH-S, ASH-B, and ASH-S by 0.45%, 2.47%, and 0.93% in FPR95 on iNaturalist, SUN, and Textures, respectively. Achieved an average FPR95 of 18.57%, outperforming ASH-B by 3.98% \\cite{behpour2023x13}.\n        *   Demonstrated competitive performance, reaching state-of-the-art levels, while maintaining high accuracy in classifying ID data \\cite{behpour2023x13}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The approach relies on the intrinsic property that stochastic gradient descent (SGD) updates lie within the span of input data points \\cite{behpour2023x13}. While applicable across all layers, experimental investigations showed optimal performance at the last layer, which might imply sensitivity to layer choice \\cite{behpour2023x13}.\n    *   **Scope of Applicability**: Primarily designed for post-hoc OOD detection using pre-trained networks, without requiring modifications to network parameters during the OOD detection phase \\cite{behpour2023x13}.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: GradOrth significantly advances OOD detection by providing a simple, efficient, and highly performant method that notably reduces false positive rates compared to existing baselines \\cite{behpour2023x13}.\n    *   **Potential Impact**:\n        *   Offers a computationally lightweight solution for OOD detection, making it practical for large-scale datasets and real-world deployment due to its one-time subspace computation and lack of hyper-parameter tuning \\cite{behpour2023x13}.\n        *   Opens new research directions by highlighting the efficacy of low-rank gradient subspaces for OOD detection, potentially inspiring further exploration into the intrinsic dimensionality of model parameters for robustness and uncertainty quantification \\cite{behpour2023x13}.\n        *   Contributes to enhancing the safety and reliability of machine learning models in critical applications by providing a robust mechanism to identify anomalous inputs \\cite{behpour2023x13}.",
      "intriguing_abstract": "Deep Neural Networks (DNNs) excel in complex tasks, yet their overconfident predictions on Out-of-Distribution (OOD) inputs pose significant risks in safety-critical applications like autonomous vehicles and healthcare. Current OOD detection methods often struggle, either relying on noisy full gradient information or empirically sparsifying network parameters without principled guidance.\n\nWe introduce GradOrth, a novel and highly effective post-hoc OOD detection framework that redefines how we identify anomalous data. Our core insight is that crucial discriminative features for OOD data reside within the *low-rank gradient subspace* of in-distribution (ID) data. By leveraging Singular Value Decomposition (SVD) on a small subset of ID activations, GradOrth efficiently constructs a compact, relevant ID subspace. OOD samples are then identified by computing the norm of their gradient projection onto this pre-computed subspace; a large orthogonal projection value signals weak correlation with ID data. This elegant approach is computationally lightweight, requiring only a one-time subspace computation and no additional training or hyper-parameter tuning.\n\nExtensive experiments on ImageNet and CIFAR benchmarks demonstrate GradOrth's superior performance, achieving up to an 8% reduction in average FPR95 compared to state-of-the-art methods, while maintaining high ID accuracy. GradOrth not only significantly advances the reliability of ML systems but also opens new research avenues into the intrinsic dimensionality of model parameters for robust uncertainty quantification. This work offers a practical, high-performance solution for safer AI deployment.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "Deep Neural Networks (DNNs)",
        "GradOrth algorithm",
        "DNN gradient subspace",
        "low-rank factorization",
        "Singular Value Decomposition (SVD)",
        "post-hoc OOD detection",
        "safety-critical applications",
        "state-of-the-art performance",
        "FPR95 reduction",
        "computationally lightweight",
        "no hyper-parameter tuning"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/6db1cc71f6cfad8d7a9e09882711c722766562b6.pdf",
      "citation_key": "behpour2023x13",
      "metadata": {
        "title": "GradOrth: A Simple yet Efficient Out-of-Distribution Detection with Orthogonal Projection of Gradients",
        "authors": [
          "Sima Behpour",
          "T. Doan",
          "Xin Li",
          "Wenbin He",
          "Liangke Gou",
          "Liu Ren"
        ],
        "published_date": "2023",
        "abstract": "Detecting out-of-distribution (OOD) data is crucial for ensuring the safe deployment of machine learning models in real-world applications. However, existing OOD detection approaches primarily rely on the feature maps or the full gradient space information to derive OOD scores neglecting the role of most important parameters of the pre-trained network over in-distribution (ID) data. In this study, we propose a novel approach called GradOrth to facilitate OOD detection based on one intriguing observation that the important features to identify OOD data lie in the lower-rank subspace of in-distribution (ID) data. In particular, we identify OOD data by computing the norm of gradient projection on the subspaces considered important for the in-distribution data. A large orthogonal projection value (i.e. a small projection value) indicates the sample as OOD as it captures a weak correlation of the ID data. This simple yet effective method exhibits outstanding performance, showcasing a notable reduction in the average false positive rate at a 95% true positive rate (FPR95) of up to 8% when compared to the current state-of-the-art methods.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/6db1cc71f6cfad8d7a9e09882711c722766562b6.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 18,
        "score": 9.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Detecting out-of-distribution (OOD) data to ensure safe and reliable deployment of machine learning models \\cite{behpour2023x13}.\n    *   **Importance and Challenge**: Deep Neural Networks (DNNs) often produce overconfident predictions on OOD inputs, making it difficult to distinguish them from in-distribution (ID) data. This poses significant risks in safety-critical applications (e.g., healthcare, autonomous vehicles) \\cite{behpour2023x13}. Existing OOD detection methods often neglect the role of the most important parameters of pre-trained networks over ID data, or rely on noisy full gradient space information \\cite{behpour2023x13}.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**:\n        *   Calculating OOD uncertainty from the activation space (model output or feature representations) \\cite{behpour2023x13}.\n        *   Leveraging gradient information (e.g., ODIN, GradNorm, ExGrad) \\cite{behpour2023x13}.\n        *   Employing network parameter sparsification (e.g., DICE, ASH) \\cite{behpour2023x13}.\n    *   **Limitations of Previous Solutions**:\n        *   GradNorm considers the full gradient space, which can be noisy and lead to sub-optimal solutions \\cite{behpour2023x13}.\n        *   ASH removes a majority of activations, potentially diminishing performance due to the partial removal of critical parameters, and lacks a principled sparsification method \\cite{behpour2023x13}.\n        *   Many existing methods overlook the crucial role of the most important parameters of the pre-trained network over ID data \\cite{behpour2023x13}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (GradOrth)**:\n        *   Based on the observation that important features for OOD data identification reside in the lower-rank subspace of in-distribution (ID) data \\cite{behpour2023x13}.\n        *   Identifies OOD data by computing the norm of the gradient projection onto subspaces deemed important for ID data \\cite{behpour2023x13}.\n        *   A large orthogonal projection value (i.e., a small projection value) indicates an OOD sample, signifying a weak correlation with ID data \\cite{behpour2023x13}.\n        *   **Process**:\n            1.  **Pre-trained Network Subspace Computation**: Uses Singular Value Decomposition (SVD) on the last-layer activations of a small, randomly selected subset of ID data to derive a low-rank subspace (SL) that captures the most significant ID representations \\cite{behpour2023x13}.\n            2.  **Inference with OOD Data**: Computes the gradient of the OOD sample at the last layer of the pre-trained network \\cite{behpour2023x13}.\n            3.  **Detector Construction**: Calculates the OOD score as the norm of the projection of the sample's gradient onto the pre-computed ID subspace (SL) \\cite{behpour2023x13}.\n    *   **Novelty and Differentiation**:\n        *   Pioneering work in investigating and demonstrating the efficacy of the *subspace of a DNNâ€™s gradients* for OOD detection \\cite{behpour2023x13}.\n        *   Leverages low-rank factorization principles to focus on the *most important parameter space* of a pre-trained network, addressing the limitations of full gradient space or empirical sparsification methods \\cite{behpour2023x13}.\n        *   The method is simple yet effective, requiring only a one-time subspace computation and gradient calculation during inference, without additional training or hyper-parameter tuning \\cite{behpour2023x13}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of GradOrth, an efficient OOD detection method that leverages the low-rank subspace of gradients from a pre-trained network's most important parameters \\cite{behpour2023x13}.\n    *   **Theoretical Insight**: Proposes that crucial discriminative features for OOD data reside within the gradient subspace of ID data, supported by the observation that stochastic gradient descent (SGD) updates lie in the span of input data points \\cite{behpour2023x13}.\n    *   **System Design**: A post-hoc OOD detection framework that uses SVD to identify a compact, relevant ID subspace from network activations, and then measures OODness by projecting test sample gradients onto this subspace \\cite{behpour2023x13}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments on two widely-used benchmarks:\n        *   **ImageNet Benchmark**: ResNet-50 pre-trained on ImageNet-1k (ID), evaluated against OOD datasets including iNaturalist, SUN, Places, and Textures \\cite{behpour2023x13}.\n        *   **CIFAR Benchmark**: DenseNet-101 pre-trained on CIFAR-10/100 (ID), evaluated against OOD datasets like Textures, SVHN, Places365, LSUN-Crop, LSUN-Resize, and iSUN \\cite{behpour2023x13}.\n        *   Subspace computation used 10 (ImageNet) or 5 (CIFAR) random samples per class with an SVD threshold of 0.97, applied to the last fully connected layer \\cite{behpour2023x13}.\n    *   **Key Performance Metrics**: AUROC (Area Under the Receiver Operating Characteristic curve) and FPR95 (False Positive Rate at 95% True Positive Rate) \\cite{behpour2023x13}.\n    *   **Comparison Results**:\n        *   GradOrth achieved a notable reduction in average FPR95 of up to 8% compared to current state-of-the-art methods \\cite{behpour2023x13}.\n        *   **ImageNet**: Surpassed ASH-S, ASH-B, and ASH-S by 0.45%, 2.47%, and 0.93% in FPR95 on iNaturalist, SUN, and Textures, respectively. Achieved an average FPR95 of 18.57%, outperforming ASH-B by 3.98% \\cite{behpour2023x13}.\n        *   Demonstrated competitive performance, reaching state-of-the-art levels, while maintaining high accuracy in classifying ID data \\cite{behpour2023x13}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The approach relies on the intrinsic property that stochastic gradient descent (SGD) updates lie within the span of input data points \\cite{behpour2023x13}. While applicable across all layers, experimental investigations showed optimal performance at the last layer, which might imply sensitivity to layer choice \\cite{behpour2023x13}.\n    *   **Scope of Applicability**: Primarily designed for post-hoc OOD detection using pre-trained networks, without requiring modifications to network parameters during the OOD detection phase \\cite{behpour2023x13}.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: GradOrth significantly advances OOD detection by providing a simple, efficient, and highly performant method that notably reduces false positive rates compared to existing baselines \\cite{behpour2023x13}.\n    *   **Potential Impact**:\n        *   Offers a computationally lightweight solution for OOD detection, making it practical for large-scale datasets and real-world deployment due to its one-time subspace computation and lack of hyper-parameter tuning \\cite{behpour2023x13}.\n        *   Opens new research directions by highlighting the efficacy of low-rank gradient subspaces for OOD detection, potentially inspiring further exploration into the intrinsic dimensionality of model parameters for robustness and uncertainty quantification \\cite{behpour2023x13}.\n        *   Contributes to enhancing the safety and reliability of machine learning models in critical applications by providing a robust mechanism to identify anomalous inputs \\cite{behpour2023x13}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "Deep Neural Networks (DNNs)",
          "GradOrth algorithm",
          "DNN gradient subspace",
          "low-rank factorization",
          "Singular Value Decomposition (SVD)",
          "post-hoc OOD detection",
          "safety-critical applications",
          "state-of-the-art performance",
          "FPR95 reduction",
          "computationally lightweight",
          "no hyper-parameter tuning"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose a novel approach called gradorth** to facilitate ood detection...\" and describes the mechanism: \"we identify ood data by computing the norm of gradient projection...\" it also mentions \"this simple yet effective method exhibits outstanding performance, showcasing a notable reduction in the average false positive rate... when compared to the current state-of-the-art methods.\"\n*   the introduction discusses the problem of ood detection and the goal to \"develop methods that can accurately detect when a model encounters ood data.\" it also reviews existing approaches, setting the stage for their proposed solution.\n\nthese points strongly align with the criteria for a **technical** paper, which \"presents new methods, algorithms, or systems.\" while it also includes empirical results to validate the proposed method, the primary contribution is the development and presentation of the new gradorth approach.\n\n**classification: technical**"
      },
      "file_name": "6db1cc71f6cfad8d7a9e09882711c722766562b6.pdf"
    },
    {
      "success": true,
      "doc_id": "ac8bcad40eed33d5e672537d313a10b0",
      "summary": "Here's a focused summary of the paper \\cite{wang2025xwm} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Graph Neural Networks (GNNs) face significant challenges when encountering out-of-distribution (OOD) test instances, leading to inaccurate predictions in critical applications.\n    *   One effective OOD detection technique, OOD exposure, requires an additional OOD node-set, which is often difficult or impossible to obtain in real-world graph data scenarios.\n    *   Existing OOD synthesis methods, prevalent in image data, rely on pre-trained generative models (e.g., Stable Diffusion) and vast auxiliary data, which are not available or easily adaptable for graph-structured data.\n    *   The core problem is: How to enhance graph OOD detection by exposing the model to OOD scenarios *without* auxiliary OOD data or pre-trained generative models.\n\n*   **Related Work & Positioning**\n    *   **General OOD detection methods:** Train detectors solely with in-distribution (ID) data, often by fine-tuning classifiers and learning graph representations. Limitations: Less effective than exposure-based methods.\n    *   **OOD exposure methods:** Utilize additional real OOD samples during training to discriminate ID from OOD data. Limitations: Requires auxiliary OOD datasets, which are often unavailable, and the exposed OOD data might not accurately represent future OOD test distributions.\n    *   **OOD synthesis methods (for image data):** Leverage pre-trained generative models to create OOD samples. Limitations: Not directly applicable to graph data due to the lack of \"one-for-all\" pre-trained generative models for graphs and the need for substantial auxiliary data.\n    *   \\cite{wang2025xwm} positions itself as a novel OOD synthesis-based approach that overcomes the limitations of both OOD exposure (no real OOD data needed) and existing OOD synthesis (no pre-trained models or auxiliary data needed for graphs).\n\n*   **Technical Approach & Innovation**\n    *   \\cite{wang2025xwm} proposes **GOLD (Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation)**, an implicit adversarial learning framework for synthetic OOD exposure without pre-trained models.\n    *   **Core Idea:** Generate pseudo-OOD samples solely based on ID training data by implicitly transforming synthetic embeddings into OOD instances.\n    *   **Two-step Alternating Optimization Framework:**\n        1.  **Latent Generative Model (LGM) Training (Step 1):** An LGM (e.g., LDM or VAE) is trained to *imitate* the in-distribution (ID) embeddings produced by an evolving GNN encoder. This ensures the generated embeddings are initially meaningful and close to ID data.\n        2.  **GNN Encoder & OOD Detector Training (Step 2):** The GNN encoder and an OOD detector are trained to:\n            *   Accurately classify ID data (using `LCLS`).\n            *   *Increase the energy divergence* between the ID embeddings and the LGM's synthetic embeddings. This is achieved through novel loss functions.\n    *   **Implicit Adversarial Process:** The LGM tries to generate ID-like embeddings, while the GNN/detector pushes the *energy scores* of these generated embeddings away from ID data. This gradient flow implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, simulating OOD exposure.\n\n*   **Key Technical Contributions**\n    *   **Novel Implicit Adversarial Training Paradigm:** A unique alternating optimization framework that synthesizes pseudo-OOD data without auxiliary OOD samples or pre-trained generative models for graphs.\n    *   **Latent Generative Model (LGM) for Pseudo-OOD Synthesis:** Utilizes an LGM (e.g., LDM or VAE) to generate latent embeddings that initially mimic ID representations, which are then implicitly diverged.\n    *   **Enhanced OOD Detector with Divergence Regularization:** Introduces an MLP-based detector trained with an uncertainty loss (`LUnc`) and a novel divergence regularisation (`LDReg`) that transforms and separates energy scores more effectively.\n    *   **Proposition 1:** Provides theoretical insight into how the combination of `LUnc` and `LDReg` decreases (increases) transformed energy for ID (pseudo-OOD) instances, enhancing separability.\n    *   **Energy Propagation for Graph Data:** Leverages and integrates energy propagation (from GNN-SAFE) to facilitate energy scores for graph data within the OOD detector.\n\n*   **Experimental Validation**\n    *   **Datasets:** Extensive OOD detection experiments conducted on five benchmark graph datasets.\n    *   **Metrics:** Key performance metrics include FPR95 (False Positive Rate at 95% True Positive Rate).\n    *   **Results:** GOLD achieves superior performance compared to state-of-the-art OOD exposure and non-exposure baselines *without using real OOD data*.\n    *   **Quantified Improvement:** Demonstrated a significant reduction in FPR95, with the best improvement from 33.57% to 1.78%.\n    *   **Efficiency:** The generative model is not involved during inference, ensuring GOLD achieves the same inference time as SOTA baselines.\n\n*   **Limitations & Scope**\n    *   The primary scope of \\cite{wang2025xwm} is node-level OOD detection in graph-structured data.\n    *   The method's strength lies in its ability to operate *without auxiliary OOD data*, addressing a major practical limitation of previous OOD exposure methods.\n    *   The paper does not explicitly state technical limitations of the GOLD framework itself, but rather focuses on solving the limitations of existing OOD detection paradigms for graphs.\n\n*   **Technical Significance**\n    *   \\cite{wang2025xwm} significantly advances the technical state-of-the-art in graph OOD detection by providing a practical solution to the critical problem of lacking real OOD data for training.\n    *   The novel implicit adversarial learning framework and alternating optimization strategy offer a new paradigm for OOD synthesis in complex data structures like graphs, where pre-trained generative models are scarce.\n    *   The proposed method's ability to achieve state-of-the-art performance without relying on external OOD datasets makes it highly impactful for real-world applications where OOD data acquisition is challenging.\n    *   It opens avenues for future research into implicit adversarial generation techniques for other data modalities facing similar OOD data scarcity issues.",
      "intriguing_abstract": "The Achilles' heel of Graph Neural Networks (GNNs) in real-world applications is their vulnerability to out-of-distribution (OOD) data, where acquiring auxiliary OOD samples for robust detection is often impossible. Existing OOD synthesis methods, reliant on pre-trained generative models and vast auxiliary data, are ill-suited for complex graph structures. We introduce **GOLD (Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation)**, a novel framework that revolutionizes graph OOD detection by synthesizing pseudo-OOD samples *without* any real OOD data or pre-trained graph generative models.\n\nGOLD employs an implicit adversarial learning paradigm with a two-step alternating optimization. A Latent Generative Model (LGM) first mimics in-distribution (ID) embeddings, while an evolving GNN encoder and OOD detector adversarially push the energy scores of these generated embeddings away from ID, implicitly transforming them into pseudo-OOD instances. This process leverages novel divergence regularization and energy propagation to effectively separate ID from OOD. Extensive experiments on five graph datasets demonstrate GOLD's superior performance, significantly reducing FPR95 compared to state-of-the-art baselines. GOLD provides a practical, efficient, and impactful solution, advancing the reliability of GNNs in critical applications and opening new avenues for OOD synthesis in data-scarce domains.",
      "keywords": [
        "Graph Neural Networks (GNNs)",
        "Out-of-Distribution (OOD) Detection",
        "GOLD (Graph OOD Detection via Implicit Adversarial Latent Generation)",
        "Implicit Adversarial Learning",
        "Pseudo-OOD Synthesis",
        "Alternating Optimization Framework",
        "Latent Generative Model (LGM)",
        "Energy Scores",
        "Divergence Regularization",
        "Synthetic OOD Exposure",
        "Node-level OOD Detection",
        "Without Auxiliary OOD Data",
        "Superior OOD Detection Performance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/a1ce596ef67f28f433f3de1001774211d00b54f0.pdf",
      "citation_key": "wang2025xwm",
      "metadata": {
        "title": "GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation",
        "authors": [
          "Danny Wang",
          "Ruihong Qiu",
          "Guangdong Bai",
          "Zi Huang"
        ],
        "published_date": "2025",
        "abstract": "Despite graph neural networks' (GNNs) great success in modelling graph-structured data, out-of-distribution (OOD) test instances still pose a great challenge for current GNNs. One of the most effective techniques to detect OOD nodes is to expose the detector model with an additional OOD node-set, yet the extra OOD instances are often difficult to obtain in practice. Recent methods for image data address this problem using OOD data synthesis, typically relying on pre-trained generative models like Stable Diffusion. However, these approaches require vast amounts of additional data, as well as one-for-all pre-trained generative models, which are not available for graph data. Therefore, we propose the GOLD framework for graph OOD detection, an implicit adversarial learning pipeline with synthetic OOD exposure without pre-trained models. The implicit adversarial training process employs a novel alternating optimisation framework by training: (1) a latent generative model to regularly imitate the in-distribution (ID) embeddings from an evolving GNN, and (2) a GNN encoder and an OOD detector to accurately classify ID data while increasing the energy divergence between the ID embeddings and the generative model's synthetic embeddings. This novel approach implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, effectively simulating exposure to OOD scenarios without auxiliary data. Extensive OOD detection experiments are conducted on five benchmark graph datasets, verifying the superior performance of GOLD without using real OOD data compared with the state-of-the-art OOD exposure and non-exposure baselines.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/a1ce596ef67f28f433f3de1001774211d00b54f0.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Here's a focused summary of the paper \\cite{wang2025xwm} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Graph Neural Networks (GNNs) face significant challenges when encountering out-of-distribution (OOD) test instances, leading to inaccurate predictions in critical applications.\n    *   One effective OOD detection technique, OOD exposure, requires an additional OOD node-set, which is often difficult or impossible to obtain in real-world graph data scenarios.\n    *   Existing OOD synthesis methods, prevalent in image data, rely on pre-trained generative models (e.g., Stable Diffusion) and vast auxiliary data, which are not available or easily adaptable for graph-structured data.\n    *   The core problem is: How to enhance graph OOD detection by exposing the model to OOD scenarios *without* auxiliary OOD data or pre-trained generative models.\n\n*   **Related Work & Positioning**\n    *   **General OOD detection methods:** Train detectors solely with in-distribution (ID) data, often by fine-tuning classifiers and learning graph representations. Limitations: Less effective than exposure-based methods.\n    *   **OOD exposure methods:** Utilize additional real OOD samples during training to discriminate ID from OOD data. Limitations: Requires auxiliary OOD datasets, which are often unavailable, and the exposed OOD data might not accurately represent future OOD test distributions.\n    *   **OOD synthesis methods (for image data):** Leverage pre-trained generative models to create OOD samples. Limitations: Not directly applicable to graph data due to the lack of \"one-for-all\" pre-trained generative models for graphs and the need for substantial auxiliary data.\n    *   \\cite{wang2025xwm} positions itself as a novel OOD synthesis-based approach that overcomes the limitations of both OOD exposure (no real OOD data needed) and existing OOD synthesis (no pre-trained models or auxiliary data needed for graphs).\n\n*   **Technical Approach & Innovation**\n    *   \\cite{wang2025xwm} proposes **GOLD (Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation)**, an implicit adversarial learning framework for synthetic OOD exposure without pre-trained models.\n    *   **Core Idea:** Generate pseudo-OOD samples solely based on ID training data by implicitly transforming synthetic embeddings into OOD instances.\n    *   **Two-step Alternating Optimization Framework:**\n        1.  **Latent Generative Model (LGM) Training (Step 1):** An LGM (e.g., LDM or VAE) is trained to *imitate* the in-distribution (ID) embeddings produced by an evolving GNN encoder. This ensures the generated embeddings are initially meaningful and close to ID data.\n        2.  **GNN Encoder & OOD Detector Training (Step 2):** The GNN encoder and an OOD detector are trained to:\n            *   Accurately classify ID data (using `LCLS`).\n            *   *Increase the energy divergence* between the ID embeddings and the LGM's synthetic embeddings. This is achieved through novel loss functions.\n    *   **Implicit Adversarial Process:** The LGM tries to generate ID-like embeddings, while the GNN/detector pushes the *energy scores* of these generated embeddings away from ID data. This gradient flow implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, simulating OOD exposure.\n\n*   **Key Technical Contributions**\n    *   **Novel Implicit Adversarial Training Paradigm:** A unique alternating optimization framework that synthesizes pseudo-OOD data without auxiliary OOD samples or pre-trained generative models for graphs.\n    *   **Latent Generative Model (LGM) for Pseudo-OOD Synthesis:** Utilizes an LGM (e.g., LDM or VAE) to generate latent embeddings that initially mimic ID representations, which are then implicitly diverged.\n    *   **Enhanced OOD Detector with Divergence Regularization:** Introduces an MLP-based detector trained with an uncertainty loss (`LUnc`) and a novel divergence regularisation (`LDReg`) that transforms and separates energy scores more effectively.\n    *   **Proposition 1:** Provides theoretical insight into how the combination of `LUnc` and `LDReg` decreases (increases) transformed energy for ID (pseudo-OOD) instances, enhancing separability.\n    *   **Energy Propagation for Graph Data:** Leverages and integrates energy propagation (from GNN-SAFE) to facilitate energy scores for graph data within the OOD detector.\n\n*   **Experimental Validation**\n    *   **Datasets:** Extensive OOD detection experiments conducted on five benchmark graph datasets.\n    *   **Metrics:** Key performance metrics include FPR95 (False Positive Rate at 95% True Positive Rate).\n    *   **Results:** GOLD achieves superior performance compared to state-of-the-art OOD exposure and non-exposure baselines *without using real OOD data*.\n    *   **Quantified Improvement:** Demonstrated a significant reduction in FPR95, with the best improvement from 33.57% to 1.78%.\n    *   **Efficiency:** The generative model is not involved during inference, ensuring GOLD achieves the same inference time as SOTA baselines.\n\n*   **Limitations & Scope**\n    *   The primary scope of \\cite{wang2025xwm} is node-level OOD detection in graph-structured data.\n    *   The method's strength lies in its ability to operate *without auxiliary OOD data*, addressing a major practical limitation of previous OOD exposure methods.\n    *   The paper does not explicitly state technical limitations of the GOLD framework itself, but rather focuses on solving the limitations of existing OOD detection paradigms for graphs.\n\n*   **Technical Significance**\n    *   \\cite{wang2025xwm} significantly advances the technical state-of-the-art in graph OOD detection by providing a practical solution to the critical problem of lacking real OOD data for training.\n    *   The novel implicit adversarial learning framework and alternating optimization strategy offer a new paradigm for OOD synthesis in complex data structures like graphs, where pre-trained generative models are scarce.\n    *   The proposed method's ability to achieve state-of-the-art performance without relying on external OOD datasets makes it highly impactful for real-world applications where OOD data acquisition is challenging.\n    *   It opens avenues for future research into implicit adversarial generation techniques for other data modalities facing similar OOD data scarcity issues.",
        "keywords": [
          "Graph Neural Networks (GNNs)",
          "Out-of-Distribution (OOD) Detection",
          "GOLD (Graph OOD Detection via Implicit Adversarial Latent Generation)",
          "Implicit Adversarial Learning",
          "Pseudo-OOD Synthesis",
          "Alternating Optimization Framework",
          "Latent Generative Model (LGM)",
          "Energy Scores",
          "Divergence Regularization",
          "Synthetic OOD Exposure",
          "Node-level OOD Detection",
          "Without Auxiliary OOD Data",
          "Superior OOD Detection Performance"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"therefore, we **propose** the gold **framework** for graph ood detection, an implicit adversarial learning **pipeline**...\"\n*   it then details the components and mechanism of this proposed framework: \"the implicit adversarial training process employs a novel alternating optimisation framework by training: (1) a latent generative model... and (2) a gnn encoder and an ood detector...\"\n*   the introduction reiterates this proposal and describes the \"novel approach.\"\n*   it mentions \"extensive ood detection experiments are conducted on five benchmark graph datasets, verifying the superior performance of gold...\" which indicates empirical validation of the proposed method.\n\nthese phrases strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems. while it includes empirical evaluation, the core contribution is the development and proposal of the \"gold framework\" and its underlying \"implicit adversarial learning pipeline.\"\n\n**classification: technical**"
      },
      "file_name": "a1ce596ef67f28f433f3de1001774211d00b54f0.pdf"
    },
    {
      "success": true,
      "doc_id": "3dd8d7e07522ffb6675f1958fd630cc5",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of **unsupervised 3D out-of-distribution (OOD) detection** for high-resolution medical data \\cite{graham20232re}.\n    *   This problem is crucial for deploying real-world clinical deep learning systems, as neural networks can produce unreliable results when encountering data outside their training distribution (OOD data) \\cite{graham20232re}.\n    *   The challenge lies in developing methods that can detect both **far-OOD data** (e.g., different organs/modalities) and **near-OOD data** (e.g., corrupted in-distribution data) in high-resolution 3D volumes, without requiring OOD labels or data during training \\cite{graham20232re}.\n\n*   **Related Work & Positioning**\n    *   **Latent Transformer Models (LTMs)** have been proposed for 3D anomaly detection and OOD detection in medical data, using a VQ-VAE/VQ-GAN for compression followed by an autoregressive Transformer \\cite{graham20232re}.\n    *   **Limitations of previous solutions (LTMs)**:\n        *   **Likelihood-based weaknesses**: LTMs, being likelihood models, are sensitive to the quality of the underlying latent representation and can fail when lower compression levels are used, focusing on low-level features \\cite{graham20232re}.\n        *   **Memory scaling**: Transformers have high memory requirements, making them infeasible for very high-resolution 3D medical data (e.g., whole-body CT) even with high compression rates \\cite{graham20232re}.\n        *   **Low-resolution anomaly maps**: LTMs produce anomaly maps in the latent space, resulting in lower resolution and often failing to accurately localize anomalies, especially for missing signal regions \\cite{graham20232re}.\n    *   **Denoising Diffusion Probabilistic Models (DDPMs)** have shown promise for OOD detection on 2D data but do not trivially scale to high-resolution 3D data \\cite{graham20232re}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method proposes using **Latent Diffusion Models (LDMs)** to enable DDPMs to scale to high-resolution 3D medical data for OOD detection \\cite{graham20232re}.\n    *   **Two-stage approach**:\n        1.  A **VQ-GAN** is trained as a first-stage model to compress the 3D input image into a latent representation \\cite{graham20232re}.\n        2.  A **DDPM** is then trained on these compressed latent representations to learn to sample from their distribution through iterative denoising \\cite{graham20232re}.\n    *   **OOD detection mechanism**: An input image is noised to various levels in the latent space, then denoised by the LDM. The similarity between the decoded denoised output and the original input (measured in the original image space using MSE and perceptual similarity) is used to determine OOD scores \\cite{graham20232re}.\n    *   **Spatial anomaly maps**: Pixel-wise mean absolute error (MAE) maps from multiple reconstructions are z-scored and averaged to produce high-resolution spatial anomaly maps \\cite{graham20232re}.\n    *   **Novelty**: This approach is novel in applying LDMs for 3D OOD detection, specifically addressing the scaling limitations of 2D DDPMs and overcoming the key disadvantages of LTMs (likelihood-based issues, memory constraints, and low-resolution anomaly maps) \\cite{graham20232re}. It leverages the reconstruction capabilities of DDPMs in a compressed latent space, then evaluates similarity in the original image space.\n\n*   **Key Technical Contributions**\n    *   **Novel method**: Introduction of an LDM-based framework for unsupervised 3D OOD detection, effectively scaling DDPMs to high-resolution volumetric data \\cite{graham20232re}.\n    *   **Robustness to latent representation**: The LDM approach is less sensitive to the quality of the underlying VQ-GAN latent representation compared to likelihood-based LTMs, requiring only good reconstruction quality from the VQ-GAN \\cite{graham20232re}.\n    *   **Improved memory scaling**: DDPMs (specifically the UNet architecture used in LDMs) exhibit more favorable memory scaling than Transformers, allowing training on higher-dimensional latent representations and thus higher-resolution input data \\cite{graham20232re}.\n    *   **High-resolution and accurate spatial anomaly maps**: LDMs produce anomaly maps directly in the original image space, leading to higher resolution and more accurate localization of anomalies compared to LTMs \\cite{graham20232re}.\n\n*   **Experimental Validation**\n    *   **Datasets**: Validated on the CROMIS dataset (683 head CTs) for training/validation, KCH dataset (47 head CTs) for in-distribution testing \\cite{graham20232re}.\n    *   **Near-OOD**: Generated by applying various corruptions (Gaussian noise, background value changes, image inversions, chunk removal, skull-stripping, intensity scaling errors) to the KCH dataset, yielding 705 near-OOD images \\cite{graham20232re}.\n    *   **Far-OOD**: Used 220 images (22 from each of ten classes) from the Decathlon dataset (various 3D imaging volumes not head CTs) \\cite{graham20232re}.\n    *   **Comparison**: Compared the proposed LDM approach against LTMs using VQ-GANs with different compression levels (l=2, 3, 4) \\cite{graham20232re}.\n    *   **Key performance metrics**: Area Under the Curve (AUC) scores for OOD detection, and qualitative assessment of spatial anomaly maps \\cite{graham20232re}.\n    *   **Comparison results**:\n        *   LDMs achieved **statistically significant better performance** (higher AUC scores) than LTMs, particularly at lower compression levels (e.g., 3-level VQ-GAN) where LTM performance degraded significantly \\cite{graham20232re}.\n        *   LDMs demonstrated **less sensitivity to the underlying latent representation**, maintaining high performance even when LTMs failed (e.g., 3-level LTM vs. 3-level LDM) \\cite{graham20232re}.\n        *   LDMs showed **more favorable memory scaling**, enabling training on 2-level VQ-GAN embeddings (higher resolution latent space) where LTMs could not be trained due to memory constraints \\cite{graham20232re}.\n        *   LDMs produced **higher resolution and more accurate spatial anomaly maps**, effectively localizing anomalies, whereas LTM maps were lower resolution and often failed to localize or even misidentified anomalies (e.g., flagging blank areas as low-anomaly) \\cite{graham20232re}.\n\n*   **Limitations & Scope**\n    *   **Technical limitations**: The 2-level LDM showed reduced performance on specific OOD classes (Hippocampal MR, Scaling 1%) where many pixels had intensities close to zero. This is attributed to the effective SNR increasing at higher resolutions with a constant noise schedule, allowing the LDM to reconstruct these OOD classes with low error \\cite{graham20232re}.\n    *   **Scope of applicability**: The method is primarily validated for 3D medical imaging data, specifically CT scans, but its principles are generalizable to other 3D data types where OOD detection is critical \\cite{graham20232re}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in 3D OOD detection by providing a robust, scalable, and effective method for high-resolution volumetric data \\cite{graham20232re}.\n    *   It offers a superior alternative to existing LTM-based approaches, overcoming their limitations in representation sensitivity, memory footprint, and anomaly map quality \\cite{graham20232re}.\n    *   The improved memory scaling of LDMs makes them feasible for extremely high-resolution medical data (e.g., whole-body CTs), which was previously intractable for Transformer-based methods \\cite{graham20232re}.\n    *   The ability to produce accurate, high-resolution spatial anomaly maps is particularly valuable for clinical applications, enabling precise localization of abnormalities \\cite{graham20232re}.\n    *   This research has a high potential impact on future research in robust deep learning for medical imaging, enabling safer and more reliable deployment of AI systems in clinical settings \\cite{graham20232re}.",
      "intriguing_abstract": "The reliable deployment of deep learning in clinical settings hinges on robust detection of out-of-distribution (OOD) data, especially for high-resolution 3D medical volumes. Current unsupervised methods, particularly Latent Transformer Models (LTMs), struggle with memory scalability, sensitivity to latent representations, and generating low-resolution anomaly maps, rendering them impractical for truly high-resolution data like whole-body CTs. We introduce a novel framework leveraging **Latent Diffusion Models (LDMs)** for unsupervised 3D OOD detection, effectively scaling Denoising Diffusion Probabilistic Models (DDPMs) to volumetric data.\n\nOur two-stage approach employs a VQ-GAN for efficient latent compression, followed by a DDPM trained on these latent representations. OOD detection is achieved by assessing reconstruction fidelity in the original image space, yielding high-resolution, pixel-wise spatial anomaly maps. This LDM-based method significantly outperforms LTMs, demonstrating superior memory scaling, reduced sensitivity to latent quality, and producing statistically more accurate OOD detection (higher AUC scores) and precise anomaly localization. This breakthrough enables robust and scalable OOD detection for critical medical applications, paving the way for safer and more trustworthy AI in healthcare.",
      "keywords": [
        "Unsupervised 3D OOD detection",
        "Latent Diffusion Models (LDMs)",
        "High-resolution medical imaging",
        "Denoising Diffusion Probabilistic Models (DDPMs)",
        "VQ-GAN",
        "Latent Transformer Models (LTMs)",
        "Improved memory scaling",
        "High-resolution spatial anomaly maps",
        "Latent representation robustness",
        "Far-OOD and near-OOD data",
        "Clinical deep learning systems"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/4ec3a01aee0ae0e4d334e552373ccd74ca66b76e.pdf",
      "citation_key": "graham20232re",
      "metadata": {
        "title": "Unsupervised 3D out-of-distribution detection with latent diffusion models",
        "authors": [
          "M. Graham",
          "W. H. Pinaya",
          "P. Wright",
          "Petru-Daniel Tudosiu",
          "Y. Mah",
          "J. Teo",
          "H. JÃ¤ger",
          "D. Werring",
          "P. Nachev",
          "S. Ourselin",
          "M. Cardoso"
        ],
        "published_date": "2023",
        "abstract": "Methods for out-of-distribution (OOD) detection that scale to 3D data are crucial components of any real-world clinical deep learning system. Classic denoising diffusion probabilistic models (DDPMs) have been recently proposed as a robust way to perform reconstruction-based OOD detection on 2D datasets, but do not trivially scale to 3D data. In this work, we propose to use Latent Diffusion Models (LDMs), which enable the scaling of DDPMs to high-resolution 3D medical data. We validate the proposed approach on near- and far-OOD datasets and compare it to a recently proposed, 3D-enabled approach using Latent Transformer Models (LTMs). Not only does the proposed LDM-based approach achieve statistically significant better performance, it also shows less sensitivity to the underlying latent representation, more favourable memory scaling, and produces better spatial anomaly maps. Code is available at https://github.com/marksgraham/ddpm-ood",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/4ec3a01aee0ae0e4d334e552373ccd74ca66b76e.pdf",
        "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
        "citationCount": 17,
        "score": 8.5,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of **unsupervised 3D out-of-distribution (OOD) detection** for high-resolution medical data \\cite{graham20232re}.\n    *   This problem is crucial for deploying real-world clinical deep learning systems, as neural networks can produce unreliable results when encountering data outside their training distribution (OOD data) \\cite{graham20232re}.\n    *   The challenge lies in developing methods that can detect both **far-OOD data** (e.g., different organs/modalities) and **near-OOD data** (e.g., corrupted in-distribution data) in high-resolution 3D volumes, without requiring OOD labels or data during training \\cite{graham20232re}.\n\n*   **Related Work & Positioning**\n    *   **Latent Transformer Models (LTMs)** have been proposed for 3D anomaly detection and OOD detection in medical data, using a VQ-VAE/VQ-GAN for compression followed by an autoregressive Transformer \\cite{graham20232re}.\n    *   **Limitations of previous solutions (LTMs)**:\n        *   **Likelihood-based weaknesses**: LTMs, being likelihood models, are sensitive to the quality of the underlying latent representation and can fail when lower compression levels are used, focusing on low-level features \\cite{graham20232re}.\n        *   **Memory scaling**: Transformers have high memory requirements, making them infeasible for very high-resolution 3D medical data (e.g., whole-body CT) even with high compression rates \\cite{graham20232re}.\n        *   **Low-resolution anomaly maps**: LTMs produce anomaly maps in the latent space, resulting in lower resolution and often failing to accurately localize anomalies, especially for missing signal regions \\cite{graham20232re}.\n    *   **Denoising Diffusion Probabilistic Models (DDPMs)** have shown promise for OOD detection on 2D data but do not trivially scale to high-resolution 3D data \\cite{graham20232re}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method proposes using **Latent Diffusion Models (LDMs)** to enable DDPMs to scale to high-resolution 3D medical data for OOD detection \\cite{graham20232re}.\n    *   **Two-stage approach**:\n        1.  A **VQ-GAN** is trained as a first-stage model to compress the 3D input image into a latent representation \\cite{graham20232re}.\n        2.  A **DDPM** is then trained on these compressed latent representations to learn to sample from their distribution through iterative denoising \\cite{graham20232re}.\n    *   **OOD detection mechanism**: An input image is noised to various levels in the latent space, then denoised by the LDM. The similarity between the decoded denoised output and the original input (measured in the original image space using MSE and perceptual similarity) is used to determine OOD scores \\cite{graham20232re}.\n    *   **Spatial anomaly maps**: Pixel-wise mean absolute error (MAE) maps from multiple reconstructions are z-scored and averaged to produce high-resolution spatial anomaly maps \\cite{graham20232re}.\n    *   **Novelty**: This approach is novel in applying LDMs for 3D OOD detection, specifically addressing the scaling limitations of 2D DDPMs and overcoming the key disadvantages of LTMs (likelihood-based issues, memory constraints, and low-resolution anomaly maps) \\cite{graham20232re}. It leverages the reconstruction capabilities of DDPMs in a compressed latent space, then evaluates similarity in the original image space.\n\n*   **Key Technical Contributions**\n    *   **Novel method**: Introduction of an LDM-based framework for unsupervised 3D OOD detection, effectively scaling DDPMs to high-resolution volumetric data \\cite{graham20232re}.\n    *   **Robustness to latent representation**: The LDM approach is less sensitive to the quality of the underlying VQ-GAN latent representation compared to likelihood-based LTMs, requiring only good reconstruction quality from the VQ-GAN \\cite{graham20232re}.\n    *   **Improved memory scaling**: DDPMs (specifically the UNet architecture used in LDMs) exhibit more favorable memory scaling than Transformers, allowing training on higher-dimensional latent representations and thus higher-resolution input data \\cite{graham20232re}.\n    *   **High-resolution and accurate spatial anomaly maps**: LDMs produce anomaly maps directly in the original image space, leading to higher resolution and more accurate localization of anomalies compared to LTMs \\cite{graham20232re}.\n\n*   **Experimental Validation**\n    *   **Datasets**: Validated on the CROMIS dataset (683 head CTs) for training/validation, KCH dataset (47 head CTs) for in-distribution testing \\cite{graham20232re}.\n    *   **Near-OOD**: Generated by applying various corruptions (Gaussian noise, background value changes, image inversions, chunk removal, skull-stripping, intensity scaling errors) to the KCH dataset, yielding 705 near-OOD images \\cite{graham20232re}.\n    *   **Far-OOD**: Used 220 images (22 from each of ten classes) from the Decathlon dataset (various 3D imaging volumes not head CTs) \\cite{graham20232re}.\n    *   **Comparison**: Compared the proposed LDM approach against LTMs using VQ-GANs with different compression levels (l=2, 3, 4) \\cite{graham20232re}.\n    *   **Key performance metrics**: Area Under the Curve (AUC) scores for OOD detection, and qualitative assessment of spatial anomaly maps \\cite{graham20232re}.\n    *   **Comparison results**:\n        *   LDMs achieved **statistically significant better performance** (higher AUC scores) than LTMs, particularly at lower compression levels (e.g., 3-level VQ-GAN) where LTM performance degraded significantly \\cite{graham20232re}.\n        *   LDMs demonstrated **less sensitivity to the underlying latent representation**, maintaining high performance even when LTMs failed (e.g., 3-level LTM vs. 3-level LDM) \\cite{graham20232re}.\n        *   LDMs showed **more favorable memory scaling**, enabling training on 2-level VQ-GAN embeddings (higher resolution latent space) where LTMs could not be trained due to memory constraints \\cite{graham20232re}.\n        *   LDMs produced **higher resolution and more accurate spatial anomaly maps**, effectively localizing anomalies, whereas LTM maps were lower resolution and often failed to localize or even misidentified anomalies (e.g., flagging blank areas as low-anomaly) \\cite{graham20232re}.\n\n*   **Limitations & Scope**\n    *   **Technical limitations**: The 2-level LDM showed reduced performance on specific OOD classes (Hippocampal MR, Scaling 1%) where many pixels had intensities close to zero. This is attributed to the effective SNR increasing at higher resolutions with a constant noise schedule, allowing the LDM to reconstruct these OOD classes with low error \\cite{graham20232re}.\n    *   **Scope of applicability**: The method is primarily validated for 3D medical imaging data, specifically CT scans, but its principles are generalizable to other 3D data types where OOD detection is critical \\cite{graham20232re}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in 3D OOD detection by providing a robust, scalable, and effective method for high-resolution volumetric data \\cite{graham20232re}.\n    *   It offers a superior alternative to existing LTM-based approaches, overcoming their limitations in representation sensitivity, memory footprint, and anomaly map quality \\cite{graham20232re}.\n    *   The improved memory scaling of LDMs makes them feasible for extremely high-resolution medical data (e.g., whole-body CTs), which was previously intractable for Transformer-based methods \\cite{graham20232re}.\n    *   The ability to produce accurate, high-resolution spatial anomaly maps is particularly valuable for clinical applications, enabling precise localization of abnormalities \\cite{graham20232re}.\n    *   This research has a high potential impact on future research in robust deep learning for medical imaging, enabling safer and more reliable deployment of AI systems in clinical settings \\cite{graham20232re}.",
        "keywords": [
          "Unsupervised 3D OOD detection",
          "Latent Diffusion Models (LDMs)",
          "High-resolution medical imaging",
          "Denoising Diffusion Probabilistic Models (DDPMs)",
          "VQ-GAN",
          "Latent Transformer Models (LTMs)",
          "Improved memory scaling",
          "High-resolution spatial anomaly maps",
          "Latent representation robustness",
          "Far-OOD and near-OOD data",
          "Clinical deep learning systems"
        ],
        "paper_type": "the paper type is **technical**.\n\n**reasoning:**\n\n*   the abstract explicitly states: \"in this work, we **propose** to use latent diffusion models (ldms), which enable the scaling of ddpms to high-resolution 3d medical data.\" this directly aligns with the \"technical\" criterion of presenting new methods or algorithms.\n*   it discusses a \"technical problem\" (scaling ood detection to 3d data) and offers a \"proposed solution\" (using ldms).\n*   while it also includes empirical validation (\"we validate the proposed approach...\", \"achieve statistically significant better performance\"), the core contribution is the *development and proposal* of a new method/system, with the empirical results serving to demonstrate its effectiveness."
      },
      "file_name": "4ec3a01aee0ae0e4d334e552373ccd74ca66b76e.pdf"
    },
    {
      "success": true,
      "doc_id": "9962acbcc7f9df44a958b895ac54fa12",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/571062267e70a4e667704104dd74cbf66374d2f4.pdf",
      "citation_key": "bao2024kfh",
      "metadata": {
        "title": "Graph Out-of-Distribution Detection Goes Neighborhood Shaping",
        "authors": [
          "Tianyi Bao",
          "Qitian Wu",
          "Zetian Jiang",
          "Yiting Chen",
          "Jiawei Sun",
          "Junchi Yan"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/571062267e70a4e667704104dd74cbf66374d2f4.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 8,
        "score": 8.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "571062267e70a4e667704104dd74cbf66374d2f4.pdf"
    },
    {
      "success": true,
      "doc_id": "ddc8cf3e64c5745d246252e0b68bc2a0",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Problem**: Neural networks often exhibit a higher vector norm of hidden layer features for in-distribution (ID) samples and lower norms for out-of-distribution (OOD) samples. Despite this phenomenon being utilized in many applications, its underlying cause has not been thoroughly investigated \\cite{park2023n97}.\n    *   **Importance & Challenge**: Deep learning models are vulnerable to OOD inputs in safety-critical applications (e.g., autonomous driving, medical diagnosis), leading to confident but invalid predictions. Understanding the fundamental mechanisms behind OOD detection signals, like feature norm, is crucial for developing robust and reliable systems \\cite{park2023n97}. Previous explanations for feature norm behavior were often empirical or lacked generality.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**: The paper acknowledges various OOD detection methods, including maximum softmax probability (MSP), energy scores, distance-based methods (Mahalanobis, SSD, ViM, CSI, KNN), and perturbation-based techniques \\cite{park2023n97}.\n    *   **Limitations of Previous Solutions**: While the empirical observation of feature norm's OOD detection capability has been reported in several works \\cite{park2023n97}, no systematic theoretical explanation of its underlying mechanism existed. A preliminary attempt in [45] was deemed not general enough, as it failed to account for scenarios like weight decay where overall feature norm decreases but ID/OOD separation persists \\cite{park2023n97}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper demystifies the feature norm's OOD detection capability by theoretically and empirically demonstrating that the feature norm (specifically, the l1-norm of the feature vector) is equivalent to the maximum logit (a confidence value) of a *hidden classifier* within the corresponding layer \\cite{park2023n97}. This hidden classifier is derived by binarizing the network weights.\n    *   **Novelty**:\n        *   **Theoretical Link**: Providing a principled, theoretical explanation for *why* feature norm separates ID from OOD, linking it directly to classifier confidence \\cite{park2023n97}.\n        *   **Class Agnosticity**: Demonstrating that this property holds regardless of the specific class label space, making feature norm applicable to diverse discriminative models, including self-supervised ones \\cite{park2023n97}.\n        *   **Negative-Aware Norm (NAN)**: Proposing a novel norm that addresses a limitation of conventional feature norms by capturing both the *activation* and *deactivation* tendencies of hidden layer neurons, which is crucial for accurate ID/OOD distinction \\cite{park2023n97}.\n\n4.  **Key Technical Contributions**\n    *   **Theoretical Insight**: Proving that the l1-norm of a hidden layer feature vector converges to the maximum logit of a hidden classifier, thereby establishing feature norm as a confidence measure for OOD detection (Theorem 3, Corollary 4) \\cite{park2023n97}.\n    *   **Fundamental Property**: Revealing and empirically validating the *class-agnostic* nature of feature norm, showing its OOD detection capability is independent of specific class types and is influenced by inter-class (memorization) and intra-class (generalization) learning, as well as activation entropy \\cite{park2023n97}.\n    *   **Novel Algorithm**: Introducing the Negative-Aware Norm (NAN), a hyperparameter-free, label-free, and bank-set-free OOD detection score that overcomes the limitations of conventional norms by accounting for both activated and deactivated neurons \\cite{park2023n97}.\n\n5.  **Experimental Validation**\n    *   **Verification of Theory**: Empirical verification using a 5-layer MLP on CIFAR-10 showed that hidden classifiers increase prediction accuracy and reduce uncertainty, and discriminative training aligns feature vector signs with class weights, reducing the gap between feature norm and maximum hidden classifier confidence \\cite{park2023n97}.\n    *   **Class Agnosticity Validation**: ResNet-18 experiments on CIFAR-10 against various OOD datasets (LSUN, iSUN, CIFAR-100, SVHN, Texture, Places) with different labeling schemes (supervised, instance-discrimination, random, non-discriminative) demonstrated:\n        *   Inter-class learning (even with random labels) enables OOD detection from the training ID fold \\cite{park2023n97}.\n        *   Intra-class learning with semantic relations generalizes detection to the test ID fold \\cite{park2023n97}.\n        *   A positive correlation between feature norm's OOD detection performance (AUROC) and the entropy of activation for discriminative models, supporting its class-agnostic nature \\cite{park2023n97}.\n    *   **NAN Efficacy**: Extensive experiments on NAN demonstrated its efficacy across OOD benchmarks, its compatibility with several state-of-the-art OOD detectors, and its capability in label-free environments, including unsupervised settings with self-supervised models and one-class classification benchmarks \\cite{park2023n97}.\n\n6.  **Limitations & Scope**\n    *   **Conventional Norm Limitation**: The paper identifies a key limitation of the conventional feature norm: its failure to capture the *deactivation* tendencies of hidden layer neurons, which can lead to misidentifying ID samples as OOD \\cite{park2023n97}.\n    *   **NAN Scope**: The proposed NAN is designed to be highly versatile, being hyperparameter-free, label-free, and bank-set-free. This makes it readily deployable in scenarios where class labels are unavailable or expensive to obtain, such as unsupervised learning or one-class classification \\cite{park2023n97}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work provides the first systematic theoretical explanation for the widely observed, yet poorly understood, OOD detection capability of feature norms, significantly advancing the fundamental understanding of neural network behavior regarding OOD inputs \\cite{park2023n97}.\n    *   **Impact on Future Research**: The theoretical insights and the introduction of NAN open new avenues for developing more robust and versatile OOD detection methods. Its class-agnostic and label-free properties make it particularly impactful for research in unsupervised OOD detection, self-supervised learning, and applications where labeled OOD data is scarce or non-existent \\cite{park2023n97}.",
      "intriguing_abstract": "Despite the widespread empirical success of feature norms in distinguishing in-distribution (ID) from out-of-distribution (OOD) samples, the fundamental mechanism driving this phenomenon has remained an elusive mystery. This paper finally demystifies this pivotal behavior, revealing a profound theoretical link: the l1-norm of a hidden layer feature vector is demonstrably equivalent to the maximum logit of a *hidden classifier* embedded within the neural network.\n\nOur work provides the first principled explanation for feature norm's OOD detection capability, proving its inherent connection to classifier confidence. Crucially, we demonstrate this property is *class-agnostic*, holding true irrespective of specific class labels and extending its applicability to diverse discriminative models, including self-supervised architectures. Building on this insight, we introduce the **Negative-Aware Norm (NAN)**, a novel, hyperparameter-free, and label-free OOD detection score that overcomes limitations of conventional norms by capturing both activation and deactivation tendencies. Extensive experiments validate our theory and showcase NAN's superior efficacy across benchmarks, particularly in unsupervised and one-class classification settings. This research not only advances our fundamental understanding of neural network robustness but also paves the way for developing more reliable and versatile OOD detection systems for safety-critical AI applications.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "feature norm",
        "hidden layer features",
        "theoretical explanation",
        "hidden classifier",
        "maximum logit",
        "class agnosticity",
        "Negative-Aware Norm (NAN)",
        "confidence measure",
        "unsupervised OOD detection",
        "self-supervised models",
        "activation and deactivation tendencies",
        "robust AI systems"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/0e3a01e0bd1beff9e77d8809629db24fc706c085.pdf",
      "citation_key": "park2023n97",
      "metadata": {
        "title": "Understanding the Feature Norm for Out-of-Distribution Detection",
        "authors": [
          "Jaewoo Park",
          "Jacky Chen Long Chai",
          "Jaeho Yoon",
          "Andrew Beng Jin Teoh"
        ],
        "published_date": "2023",
        "abstract": "A neural network trained on a classification dataset often exhibits a higher vector norm of hidden layer features for in-distribution (ID) samples, while producing relatively lower norm values on unseen instances from out-of-distribution (OOD). Despite this intriguing phenomenon being utilized in many applications, the underlying cause has not been thoroughly investigated. In this study, we demystify this very phenomenon by scrutinizing the discriminative structures concealed in the intermediate layers of a neural network. Our analysis leads to the following discoveries: (1) The feature norm is a confidence value of a classifier hidden in the network layer, specifically its maximum logit. Hence, the feature norm distinguishes OOD from ID in the same manner that a classifier confidence does. (2) The feature norm is class-agnostic, thus it can detect OOD samples across diverse discriminative models. (3) The conventional feature norm fails to capture the deactivation tendency of hidden layer neurons, which may lead to misidentification of ID samples as OOD instances. To resolve this drawback, we propose a novel negative-aware norm (NAN) that can capture both the activation and deactivation tendencies of hidden layer neurons. We conduct extensive experiments on NAN, demonstrating its efficacy and compatibility with existing OOD detectors, as well as its capability in label-free environments.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/0e3a01e0bd1beff9e77d8809629db24fc706c085.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 16,
        "score": 8.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Problem**: Neural networks often exhibit a higher vector norm of hidden layer features for in-distribution (ID) samples and lower norms for out-of-distribution (OOD) samples. Despite this phenomenon being utilized in many applications, its underlying cause has not been thoroughly investigated \\cite{park2023n97}.\n    *   **Importance & Challenge**: Deep learning models are vulnerable to OOD inputs in safety-critical applications (e.g., autonomous driving, medical diagnosis), leading to confident but invalid predictions. Understanding the fundamental mechanisms behind OOD detection signals, like feature norm, is crucial for developing robust and reliable systems \\cite{park2023n97}. Previous explanations for feature norm behavior were often empirical or lacked generality.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**: The paper acknowledges various OOD detection methods, including maximum softmax probability (MSP), energy scores, distance-based methods (Mahalanobis, SSD, ViM, CSI, KNN), and perturbation-based techniques \\cite{park2023n97}.\n    *   **Limitations of Previous Solutions**: While the empirical observation of feature norm's OOD detection capability has been reported in several works \\cite{park2023n97}, no systematic theoretical explanation of its underlying mechanism existed. A preliminary attempt in [45] was deemed not general enough, as it failed to account for scenarios like weight decay where overall feature norm decreases but ID/OOD separation persists \\cite{park2023n97}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper demystifies the feature norm's OOD detection capability by theoretically and empirically demonstrating that the feature norm (specifically, the l1-norm of the feature vector) is equivalent to the maximum logit (a confidence value) of a *hidden classifier* within the corresponding layer \\cite{park2023n97}. This hidden classifier is derived by binarizing the network weights.\n    *   **Novelty**:\n        *   **Theoretical Link**: Providing a principled, theoretical explanation for *why* feature norm separates ID from OOD, linking it directly to classifier confidence \\cite{park2023n97}.\n        *   **Class Agnosticity**: Demonstrating that this property holds regardless of the specific class label space, making feature norm applicable to diverse discriminative models, including self-supervised ones \\cite{park2023n97}.\n        *   **Negative-Aware Norm (NAN)**: Proposing a novel norm that addresses a limitation of conventional feature norms by capturing both the *activation* and *deactivation* tendencies of hidden layer neurons, which is crucial for accurate ID/OOD distinction \\cite{park2023n97}.\n\n4.  **Key Technical Contributions**\n    *   **Theoretical Insight**: Proving that the l1-norm of a hidden layer feature vector converges to the maximum logit of a hidden classifier, thereby establishing feature norm as a confidence measure for OOD detection (Theorem 3, Corollary 4) \\cite{park2023n97}.\n    *   **Fundamental Property**: Revealing and empirically validating the *class-agnostic* nature of feature norm, showing its OOD detection capability is independent of specific class types and is influenced by inter-class (memorization) and intra-class (generalization) learning, as well as activation entropy \\cite{park2023n97}.\n    *   **Novel Algorithm**: Introducing the Negative-Aware Norm (NAN), a hyperparameter-free, label-free, and bank-set-free OOD detection score that overcomes the limitations of conventional norms by accounting for both activated and deactivated neurons \\cite{park2023n97}.\n\n5.  **Experimental Validation**\n    *   **Verification of Theory**: Empirical verification using a 5-layer MLP on CIFAR-10 showed that hidden classifiers increase prediction accuracy and reduce uncertainty, and discriminative training aligns feature vector signs with class weights, reducing the gap between feature norm and maximum hidden classifier confidence \\cite{park2023n97}.\n    *   **Class Agnosticity Validation**: ResNet-18 experiments on CIFAR-10 against various OOD datasets (LSUN, iSUN, CIFAR-100, SVHN, Texture, Places) with different labeling schemes (supervised, instance-discrimination, random, non-discriminative) demonstrated:\n        *   Inter-class learning (even with random labels) enables OOD detection from the training ID fold \\cite{park2023n97}.\n        *   Intra-class learning with semantic relations generalizes detection to the test ID fold \\cite{park2023n97}.\n        *   A positive correlation between feature norm's OOD detection performance (AUROC) and the entropy of activation for discriminative models, supporting its class-agnostic nature \\cite{park2023n97}.\n    *   **NAN Efficacy**: Extensive experiments on NAN demonstrated its efficacy across OOD benchmarks, its compatibility with several state-of-the-art OOD detectors, and its capability in label-free environments, including unsupervised settings with self-supervised models and one-class classification benchmarks \\cite{park2023n97}.\n\n6.  **Limitations & Scope**\n    *   **Conventional Norm Limitation**: The paper identifies a key limitation of the conventional feature norm: its failure to capture the *deactivation* tendencies of hidden layer neurons, which can lead to misidentifying ID samples as OOD \\cite{park2023n97}.\n    *   **NAN Scope**: The proposed NAN is designed to be highly versatile, being hyperparameter-free, label-free, and bank-set-free. This makes it readily deployable in scenarios where class labels are unavailable or expensive to obtain, such as unsupervised learning or one-class classification \\cite{park2023n97}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work provides the first systematic theoretical explanation for the widely observed, yet poorly understood, OOD detection capability of feature norms, significantly advancing the fundamental understanding of neural network behavior regarding OOD inputs \\cite{park2023n97}.\n    *   **Impact on Future Research**: The theoretical insights and the introduction of NAN open new avenues for developing more robust and versatile OOD detection methods. Its class-agnostic and label-free properties make it particularly impactful for research in unsupervised OOD detection, self-supervised learning, and applications where labeled OOD data is scarce or non-existent \\cite{park2023n97}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "feature norm",
          "hidden layer features",
          "theoretical explanation",
          "hidden classifier",
          "maximum logit",
          "class agnosticity",
          "Negative-Aware Norm (NAN)",
          "confidence measure",
          "unsupervised OOD detection",
          "self-supervised models",
          "activation and deactivation tendencies",
          "robust AI systems"
        ],
        "paper_type": "the paper can be classified as **technical**.\n\nhere's why:\n\n1.  **proposes a new method/algorithm:** the abstract explicitly states, \"to resolve this drawback, we **propose a novel negative-aware norm (nan)** that can capture both the activation and de-activation tendencies of hidden layer neurons.\" this directly aligns with the \"technical\" criterion: \"presents new methods, algorithms, or systems\" and \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\".\n2.  **addresses a technical problem:** the introduction highlights the vulnerability of deep models to out-of-distribution (ood) samples and the importance of ood detection, which is a significant technical challenge in deep learning.\n3.  **validation of the proposed solution:** the abstract mentions, \"we conduct extensive experiments on nan, demonstrating its efficacy and compatibility with existing ood detectors...\" while this indicates an empirical component, the experiments are conducted to validate the *newly proposed method*, which is characteristic of a technical paper.\n4.  **underlying analysis informs the technical solution:** the paper first \"demystifies\" an existing phenomenon through analysis, leading to \"discoveries.\" this theoretical understanding then directly informs the design and necessity of the \"novel negative-aware norm (nan).\" the analysis serves as the foundation for the technical contribution.\n\nwhile the paper contains elements of theoretical analysis (understanding the feature norm) and empirical validation (extensive experiments), its core contribution is the **proposal and evaluation of a novel method (nan)** to improve ood detection, making \"technical\" the most fitting classification."
      },
      "file_name": "0e3a01e0bd1beff9e77d8809629db24fc706c085.pdf"
    },
    {
      "success": true,
      "doc_id": "0f422c5567cd2aecd39fa3234760bc4c",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/c1e39900745c2b93fbe28a92140a0896a30f72ec.pdf",
      "citation_key": "haider2023vid",
      "metadata": {
        "title": "Out-of-Distribution Detection for Reinforcement Learning Agents with Probabilistic Dynamics Models",
        "authors": [
          "Tom Haider",
          "Karsten Roscher",
          "Felippe Schmoeller da Roza",
          "Stephan GÃ¼nnemann"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/c1e39900745c2b93fbe28a92140a0896a30f72ec.pdf",
        "venue": "Adaptive Agents and Multi-Agent Systems",
        "citationCount": 15,
        "score": 7.5,
        "summary": "",
        "keywords": []
      },
      "file_name": "c1e39900745c2b93fbe28a92140a0896a30f72ec.pdf"
    },
    {
      "success": true,
      "doc_id": "fe2dc8c8a9c21198b112e1439e72d3c2",
      "summary": "Machine learning models deployed in the wild can be challenged by out-of-distribution (OOD) data from unknown classes. Recent advances in OOD detection rely on distance measures to distinguish samples that are relatively far away from the in-distribution (ID) data. Despite the promise, distance-based methods can suffer from the curse-of-dimensionality problem, which limits the efficacy in high dimensional feature space. To combat this problem, we propose a novel framework, Subspace Nearest Neighbor (SNN), for OOD detection. In training, our method regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e. subspace). The subspace learning yields highly distinguishable distance measures between ID and OOD data. We provide comprehensive experiments and ablations to validate the efficacy of SNN. Compared to the current best distance-based method, SNN reduces the average FPR95 by 15.96% on the CIFAR-100 benchmark.",
      "intriguing_abstract": "Machine learning models deployed in the wild can be challenged by out-of-distribution (OOD) data from unknown classes. Recent advances in OOD detection rely on distance measures to distinguish samples that are relatively far away from the in-distribution (ID) data. Despite the promise, distance-based methods can suffer from the curse-of-dimensionality problem, which limits the efficacy in high dimensional feature space. To combat this problem, we propose a novel framework, Subspace Nearest Neighbor (SNN), for OOD detection. In training, our method regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e. subspace). The subspace learning yields highly distinguishable distance measures between ID and OOD data. We provide comprehensive experiments and ablations to validate the efficacy of SNN. Compared to the current best distance-based method, SNN reduces the average FPR95 by 15.96% on the CIFAR-100 benchmark.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/0e384284e75751084bf44a5ef787f1c40eb24502.pdf",
      "citation_key": "ghosal2023q20",
      "metadata": {
        "title": "How to Overcome Curse-of-Dimensionality for Out-of-Distribution Detection?",
        "authors": [
          "Soumya Suvra Ghosal",
          "Yiyou Sun",
          "Yixuan Li"
        ],
        "published_date": "2023",
        "abstract": "Machine learning models deployed in the wild can be challenged by out-of-distribution (OOD) data from unknown classes. Recent advances in OOD detection rely on distance measures to distinguish samples that are relatively far away from the in-distribution (ID) data. Despite the promise, distance-based methods can suffer from the curse-of-dimensionality problem, which limits the efficacy in high dimensional feature space. To combat this problem, we propose a novel framework, Subspace Nearest Neighbor (SNN), for OOD detection. In training, our method regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e. subspace). The subspace learning yields highly distinguishable distance measures between ID and OOD data. We provide comprehensive experiments and ablations to validate the efficacy of SNN. Compared to the current best distance-based method, SNN reduces the average FPR95 by 15.96% on the CIFAR-100 benchmark.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/0e384284e75751084bf44a5ef787f1c40eb24502.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 15,
        "score": 7.5,
        "summary": "Machine learning models deployed in the wild can be challenged by out-of-distribution (OOD) data from unknown classes. Recent advances in OOD detection rely on distance measures to distinguish samples that are relatively far away from the in-distribution (ID) data. Despite the promise, distance-based methods can suffer from the curse-of-dimensionality problem, which limits the efficacy in high dimensional feature space. To combat this problem, we propose a novel framework, Subspace Nearest Neighbor (SNN), for OOD detection. In training, our method regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e. subspace). The subspace learning yields highly distinguishable distance measures between ID and OOD data. We provide comprehensive experiments and ablations to validate the efficacy of SNN. Compared to the current best distance-based method, SNN reduces the average FPR95 by 15.96% on the CIFAR-100 benchmark.",
        "keywords": []
      },
      "file_name": "0e384284e75751084bf44a5ef787f1c40eb24502.pdf"
    },
    {
      "success": true,
      "doc_id": "6c7310d1db41d9f1a22b191511f68cfe",
      "summary": "Here's a focused summary of the paper \\cite{yang2023ckx} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the ill-defined nature of out-of-distribution (OOD) detection, particularly the entanglement and differential impact of \"semantic shift\" (new classes) and \"covariate shift\" (label-preserving data changes) on modern OOD detection algorithms. It questions what these algorithms are truly detecting, given their poor performance on \"failure detection\" benchmarks compared to simple baselines.\n    *   **Importance and Challenge**: Properly evaluating OOD detectors requires datasets that can decouple semantic and covariate shifts. Existing OOD datasets, especially those using ImageNet-1K as in-distribution (ID), suffer from significant shortcomings: ID contamination, semantic ambiguities (e.g., hypernyms/hyponyms), visual ambiguities, and the introduction of unintended covariate shifts due to diverse data sources or collection processes \\cite{yang2023ckx}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself against two main OOD detection paradigms: \"new-class detection\" (identifying novel categories) and \"failure detection\" (identifying misclassified examples).\n    *   **Limitations of Previous Solutions**:\n        *   Under the \"failure detection\" framework, complex modern OOD detectors often perform no better than, or even worse than, the simple Maximum Softmax Probability (MSP) baseline \\cite{yang2023ckx}.\n        *   Many existing ImageNet-based OOD datasets (e.g., ImageNet-O, C-OOD, Species) contain ID contamination, semantic ambiguities (e.g., \"pastry dough\" being a hyponym of \"dough\"), or visual ambiguities (e.g., \"basin\" vs. \"lakeside\" images being indistinguishable) \\cite{yang2023ckx}.\n        *   Datasets using external sources like iNaturalist or SUN introduce unforeseen covariate shifts, hindering the assessment of pure semantic shift detection \\cite{yang2023ckx}.\n        *   Smaller datasets (CIFAR, MNIST) do not generalize to real-world, high-resolution, diverse scenarios \\cite{yang2023ckx}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper's core innovation is the design and construction of `ImageNet-OOD`, a novel, clean semantic shift dataset.\n    *   **Novelty/Difference**:\n        *   `ImageNet-OOD` is manually curated from ImageNet-21K, ensuring minimal covariate shift by maintaining the same data collection process as ImageNet-1K \\cite{yang2023ckx}.\n        *   It systematically removes semantic ambiguities by excluding ImageNet-1K classes, their hypernyms, and hyponyms from the OOD set \\cite{yang2023ckx}.\n        *   It addresses inconsistencies in the WordNet hierarchy (e.g., \"Organism\" hyponyms) and mitigates \"semantically-grounded covariate shifts\" by redefining ID classes based on general decision boundaries \\cite{yang2023ckx}.\n        *   Extensive human verification (20+6 hours) was conducted to resolve visual ambiguities and filter out mislabeled images, ensuring a truly distinct OOD set \\cite{yang2023ckx}.\n\n*   **Key Technical Contributions**\n    *   **Novel Dataset**: Introduction of `ImageNet-OOD`, a carefully curated dataset of 31,807 images from 637 classes, specifically designed to isolate semantic shift detection from covariate shift for ImageNet-1K as ID \\cite{yang2023ckx}.\n    *   **Systematic Dataset Construction Methodology**: A robust methodology for creating clean OOD benchmarks by addressing various sources of ambiguity and contamination (semantic, visual, hierarchical, covariate) \\cite{yang2023ckx}.\n    *   **Empirical Insights**: Provides critical empirical evidence demonstrating the disproportionate sensitivity of modern OOD detectors to covariate shifts over semantic shifts \\cite{yang2023ckx}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Compared OOD detection performance on `ImageNet-OOD` (semantic shift) against ImageNet-R (covariate shift) using self-supervised features (PASS dataset) to quantify visual distance to ID \\cite{yang2023ckx}.\n        *   Evaluated nine OOD detection algorithms (including MSP, Energy, ViM, ReAct) across 13 network architectures (e.g., ResNet-50) using `ImageNet-OOD` and three ImageNet-1K-based covariate shift datasets (ImageNet-C, ImageNet-R, ImageNet-Sketch) \\cite{yang2023ckx}.\n        *   Performed a sanity check by applying elementary transformations (e.g., zoom) to ID images to observe OOD score changes \\cite{yang2023ckx}.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic curve (AUROC) was used as a threshold-free metric \\cite{yang2023ckx}.\n    *   **Comparison Results**:\n        *   Modern OOD detection algorithms are significantly more sensitive to covariate shifts (e.g., ImageNet-R) than to semantic shifts (`ImageNet-OOD`), even when visual distances to ID are similar \\cite{yang2023ckx}.\n        *   On `ImageNet-OOD`, which minimizes covariate shift, modern OOD algorithms show *minimal improvement* over the simple MSP baseline for new-class detection \\cite{yang2023ckx}.\n        *   The observed performance gains of modern OOD algorithms on previous benchmarks are often due to their ability to ignore *incorrectly classified ID examples* rather than effectively detecting true OOD examples, leading to a disparity between new-class and failure detection tasks \\cite{yang2023ckx}.\n        *   For instance, a simple zoom on an ImageNet-1K \"Ostrich\" image, which didn't change the model's correct classification, drastically decreased the OOD ranking of ViM and ReAct scores by 38.4% and 39.6% respectively, highlighting their sensitivity to minor covariate shifts \\cite{yang2023ckx}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The dataset construction, while thorough, is labor-intensive due to manual curation. The focus is on ImageNet-based datasets, which may not cover all possible domains or types of distribution shifts.\n    *   **Scope of Applicability**: The findings are primarily applicable to computer vision OOD detection, specifically within the context of ImageNet-scale datasets and current deep learning models.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `ImageNet-OOD` provides a critically needed, clean benchmark that enables researchers to accurately assess OOD detection algorithms' performance on semantic shifts, disentangled from covariate shifts \\cite{yang2023ckx}.\n    *   **Potential Impact on Future Research**:\n        *   Challenges the current understanding of \"state-of-the-art\" OOD detectors, suggesting that many complex methods primarily exploit covariate shifts rather than genuine semantic novelty \\cite{yang2023ckx}.\n        *   Offers crucial insights to guide the design of future OOD detectors, emphasizing the need for algorithms that are truly robust to covariate shifts and genuinely sensitive to semantic shifts \\cite{yang2023ckx}.\n        *   Underscores the importance of rigorous dataset construction and evaluation methodologies in OOD research \\cite{yang2023ckx}.",
      "intriguing_abstract": "Are deep learning models truly discerning semantic novelty, or are they merely reacting to subtle distribution shifts? We reveal that the efficacy of out-of-distribution (OOD) detection is fundamentally obscured by the entanglement of semantic and covariate shifts in existing benchmarks. Current ImageNet-based OOD datasets suffer from pervasive contamination and ambiguities, making it unclear what algorithms truly detect. To address this, we introduce `ImageNet-OOD`, a meticulously curated dataset of 31,807 images from 637 novel classes, specifically designed to isolate *pure semantic shift* for ImageNet-1K as in-distribution. Our rigorous methodology systematically removes semantic and visual ambiguities, ensuring minimal covariate shift. Empirical evaluation of nine OOD algorithms across 13 architectures on `ImageNet-OOD` yields a striking insight: modern OOD detectors are disproportionately sensitive to minor covariate shifts (e.g., ImageNet-R) and show *minimal improvement* over the simple Maximum Softmax Probability (MSP) baseline for genuine new-class detection. This challenges the prevailing understanding of state-of-the-art OOD performance, suggesting many complex methods primarily exploit covariate shifts or ignore misclassified in-distribution examples. `ImageNet-OOD` provides a critical benchmark to guide the development of future OOD detectors truly robust to covariate shifts and genuinely sensitive to semantic novelty.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "semantic shift",
        "covariate shift",
        "ImageNet-OOD dataset",
        "dataset construction methodology",
        "decoupling semantic and covariate shifts",
        "Maximum Softmax Probability (MSP)",
        "modern OOD detectors sensitivity to covariate shifts",
        "manual curation",
        "human verification",
        "new-class detection",
        "empirical insights",
        "ambiguity resolution"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/69c2808097e7dfd357856f1ae82dcb6ce1bf64df.pdf",
      "citation_key": "yang2023ckx",
      "metadata": {
        "title": "ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms",
        "authors": [
          "William Yang",
          "Byron Zhang",
          "Olga Russakovsky"
        ],
        "published_date": "2023",
        "abstract": "The task of out-of-distribution (OOD) detection is notoriously ill-defined. Earlier works focused on new-class detection, aiming to identify label-altering data distribution shifts, also known as\"semantic shift.\"However, recent works argue for a focus on failure detection, expanding the OOD evaluation framework to account for label-preserving data distribution shifts, also known as\"covariate shift.\"Intriguingly, under this new framework, complex OOD detectors that were previously considered state-of-the-art now perform similarly to, or even worse than the simple maximum softmax probability baseline. This raises the question: what are the latest OOD detectors actually detecting? Deciphering the behavior of OOD detection algorithms requires evaluation datasets that decouples semantic shift and covariate shift. To aid our investigations, we present ImageNet-OOD, a clean semantic shift dataset that minimizes the interference of covariate shift. Through comprehensive experiments, we show that OOD detectors are more sensitive to covariate shift than to semantic shift, and the benefits of recent OOD detection algorithms on semantic shift detection is minimal. Our dataset and analyses provide important insights for guiding the design of future OOD detectors.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/69c2808097e7dfd357856f1ae82dcb6ce1bf64df.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 15,
        "score": 7.5,
        "summary": "Here's a focused summary of the paper \\cite{yang2023ckx} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the ill-defined nature of out-of-distribution (OOD) detection, particularly the entanglement and differential impact of \"semantic shift\" (new classes) and \"covariate shift\" (label-preserving data changes) on modern OOD detection algorithms. It questions what these algorithms are truly detecting, given their poor performance on \"failure detection\" benchmarks compared to simple baselines.\n    *   **Importance and Challenge**: Properly evaluating OOD detectors requires datasets that can decouple semantic and covariate shifts. Existing OOD datasets, especially those using ImageNet-1K as in-distribution (ID), suffer from significant shortcomings: ID contamination, semantic ambiguities (e.g., hypernyms/hyponyms), visual ambiguities, and the introduction of unintended covariate shifts due to diverse data sources or collection processes \\cite{yang2023ckx}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself against two main OOD detection paradigms: \"new-class detection\" (identifying novel categories) and \"failure detection\" (identifying misclassified examples).\n    *   **Limitations of Previous Solutions**:\n        *   Under the \"failure detection\" framework, complex modern OOD detectors often perform no better than, or even worse than, the simple Maximum Softmax Probability (MSP) baseline \\cite{yang2023ckx}.\n        *   Many existing ImageNet-based OOD datasets (e.g., ImageNet-O, C-OOD, Species) contain ID contamination, semantic ambiguities (e.g., \"pastry dough\" being a hyponym of \"dough\"), or visual ambiguities (e.g., \"basin\" vs. \"lakeside\" images being indistinguishable) \\cite{yang2023ckx}.\n        *   Datasets using external sources like iNaturalist or SUN introduce unforeseen covariate shifts, hindering the assessment of pure semantic shift detection \\cite{yang2023ckx}.\n        *   Smaller datasets (CIFAR, MNIST) do not generalize to real-world, high-resolution, diverse scenarios \\cite{yang2023ckx}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper's core innovation is the design and construction of `ImageNet-OOD`, a novel, clean semantic shift dataset.\n    *   **Novelty/Difference**:\n        *   `ImageNet-OOD` is manually curated from ImageNet-21K, ensuring minimal covariate shift by maintaining the same data collection process as ImageNet-1K \\cite{yang2023ckx}.\n        *   It systematically removes semantic ambiguities by excluding ImageNet-1K classes, their hypernyms, and hyponyms from the OOD set \\cite{yang2023ckx}.\n        *   It addresses inconsistencies in the WordNet hierarchy (e.g., \"Organism\" hyponyms) and mitigates \"semantically-grounded covariate shifts\" by redefining ID classes based on general decision boundaries \\cite{yang2023ckx}.\n        *   Extensive human verification (20+6 hours) was conducted to resolve visual ambiguities and filter out mislabeled images, ensuring a truly distinct OOD set \\cite{yang2023ckx}.\n\n*   **Key Technical Contributions**\n    *   **Novel Dataset**: Introduction of `ImageNet-OOD`, a carefully curated dataset of 31,807 images from 637 classes, specifically designed to isolate semantic shift detection from covariate shift for ImageNet-1K as ID \\cite{yang2023ckx}.\n    *   **Systematic Dataset Construction Methodology**: A robust methodology for creating clean OOD benchmarks by addressing various sources of ambiguity and contamination (semantic, visual, hierarchical, covariate) \\cite{yang2023ckx}.\n    *   **Empirical Insights**: Provides critical empirical evidence demonstrating the disproportionate sensitivity of modern OOD detectors to covariate shifts over semantic shifts \\cite{yang2023ckx}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Compared OOD detection performance on `ImageNet-OOD` (semantic shift) against ImageNet-R (covariate shift) using self-supervised features (PASS dataset) to quantify visual distance to ID \\cite{yang2023ckx}.\n        *   Evaluated nine OOD detection algorithms (including MSP, Energy, ViM, ReAct) across 13 network architectures (e.g., ResNet-50) using `ImageNet-OOD` and three ImageNet-1K-based covariate shift datasets (ImageNet-C, ImageNet-R, ImageNet-Sketch) \\cite{yang2023ckx}.\n        *   Performed a sanity check by applying elementary transformations (e.g., zoom) to ID images to observe OOD score changes \\cite{yang2023ckx}.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic curve (AUROC) was used as a threshold-free metric \\cite{yang2023ckx}.\n    *   **Comparison Results**:\n        *   Modern OOD detection algorithms are significantly more sensitive to covariate shifts (e.g., ImageNet-R) than to semantic shifts (`ImageNet-OOD`), even when visual distances to ID are similar \\cite{yang2023ckx}.\n        *   On `ImageNet-OOD`, which minimizes covariate shift, modern OOD algorithms show *minimal improvement* over the simple MSP baseline for new-class detection \\cite{yang2023ckx}.\n        *   The observed performance gains of modern OOD algorithms on previous benchmarks are often due to their ability to ignore *incorrectly classified ID examples* rather than effectively detecting true OOD examples, leading to a disparity between new-class and failure detection tasks \\cite{yang2023ckx}.\n        *   For instance, a simple zoom on an ImageNet-1K \"Ostrich\" image, which didn't change the model's correct classification, drastically decreased the OOD ranking of ViM and ReAct scores by 38.4% and 39.6% respectively, highlighting their sensitivity to minor covariate shifts \\cite{yang2023ckx}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The dataset construction, while thorough, is labor-intensive due to manual curation. The focus is on ImageNet-based datasets, which may not cover all possible domains or types of distribution shifts.\n    *   **Scope of Applicability**: The findings are primarily applicable to computer vision OOD detection, specifically within the context of ImageNet-scale datasets and current deep learning models.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `ImageNet-OOD` provides a critically needed, clean benchmark that enables researchers to accurately assess OOD detection algorithms' performance on semantic shifts, disentangled from covariate shifts \\cite{yang2023ckx}.\n    *   **Potential Impact on Future Research**:\n        *   Challenges the current understanding of \"state-of-the-art\" OOD detectors, suggesting that many complex methods primarily exploit covariate shifts rather than genuine semantic novelty \\cite{yang2023ckx}.\n        *   Offers crucial insights to guide the design of future OOD detectors, emphasizing the need for algorithms that are truly robust to covariate shifts and genuinely sensitive to semantic shifts \\cite{yang2023ckx}.\n        *   Underscores the importance of rigorous dataset construction and evaluation methodologies in OOD research \\cite{yang2023ckx}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "semantic shift",
          "covariate shift",
          "ImageNet-OOD dataset",
          "dataset construction methodology",
          "decoupling semantic and covariate shifts",
          "Maximum Softmax Probability (MSP)",
          "modern OOD detectors sensitivity to covariate shifts",
          "manual curation",
          "human verification",
          "new-class detection",
          "empirical insights",
          "ambiguity resolution"
        ],
        "paper_type": "the paper classifies as **empirical**.\n\nhere's why:\n\n1.  **data-driven studies with statistical analysis:** the abstract explicitly states, \"through comprehensive experiments, we show that ood detectors are more sensitive to covariate shift than to semantic shift...\" and the introduction details, \"we perform extensive experiments on nine ood detection algorithms across 13 network architectures... to make the following findings.\" this is a clear indication of a data-driven study involving experimentation and analysis of results.\n2.  **research questions, methodology, findings:** the paper poses a central research question: \"what are the latest ood detectors actually detecting?\" it then describes its methodology, which includes creating a new dataset (imagenet-ood) specifically for evaluation, and using it along with other datasets to conduct experiments. the paper then presents \"findings\" derived from these experiments.\n3.  **new dataset as a tool for empirical study:** while the paper introduces a new dataset (imagenet-ood), its primary purpose is not just to present the dataset, but to *use* this dataset (and others) to conduct a thorough empirical investigation into the behavior of existing ood detection algorithms. the dataset is a crucial *component* of the empirical methodology."
      },
      "file_name": "69c2808097e7dfd357856f1ae82dcb6ce1bf64df.pdf"
    },
    {
      "success": true,
      "doc_id": "aa4a389cca6fbb00a5b0898b35b976a4",
      "summary": "Detecting out-of-distribution (OOD) inputs is crucial for the safe deployment of natural language processing (NLP) models. Though existing methods, especially those based on the statistics in the feature space of fine-tuned pre-trained language models (PLMs), are claimed to be effective, their effectiveness on different types of distribution shifts remains underexplored. In this work, we take the first step to comprehensively evaluate the mainstream textual OOD detection methods for detecting semantic and non-semantic shifts. We find that: (1) no existing method behaves well in both settings; (2) fine-tuning PLMs on in-distribution data benefits detecting semantic shifts but severely deteriorates detecting non-semantic shifts, which can be attributed to the distortion of task-agnostic features. To alleviate the issue, we present a simple yet effective general OOD score named GNOME that integrates the confidence scores derived from the task-agnostic and task-specific representations. Experiments show that GNOME works well in both semantic and non-semantic shift scenarios, and further brings significant improvement on two cross-task benchmarks where both kinds of shifts simultaneously take place. Our code is available at https://github.com/lancopku/GNOME.",
      "intriguing_abstract": "Detecting out-of-distribution (OOD) inputs is crucial for the safe deployment of natural language processing (NLP) models. Though existing methods, especially those based on the statistics in the feature space of fine-tuned pre-trained language models (PLMs), are claimed to be effective, their effectiveness on different types of distribution shifts remains underexplored. In this work, we take the first step to comprehensively evaluate the mainstream textual OOD detection methods for detecting semantic and non-semantic shifts. We find that: (1) no existing method behaves well in both settings; (2) fine-tuning PLMs on in-distribution data benefits detecting semantic shifts but severely deteriorates detecting non-semantic shifts, which can be attributed to the distortion of task-agnostic features. To alleviate the issue, we present a simple yet effective general OOD score named GNOME that integrates the confidence scores derived from the task-agnostic and task-specific representations. Experiments show that GNOME works well in both semantic and non-semantic shift scenarios, and further brings significant improvement on two cross-task benchmarks where both kinds of shifts simultaneously take place. Our code is available at https://github.com/lancopku/GNOME.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/96a219acb0acdca790f7f9f7f30c507a47a06754.pdf",
      "citation_key": "chen2023tz9",
      "metadata": {
        "title": "Fine-Tuning Deteriorates General Textual Out-of-Distribution Detection by Distorting Task-Agnostic Features",
        "authors": [
          "Sishuo Chen",
          "Wenkai Yang",
          "Xiaohan Bi",
          "Xu Sun"
        ],
        "published_date": "2023",
        "abstract": "Detecting out-of-distribution (OOD) inputs is crucial for the safe deployment of natural language processing (NLP) models. Though existing methods, especially those based on the statistics in the feature space of fine-tuned pre-trained language models (PLMs), are claimed to be effective, their effectiveness on different types of distribution shifts remains underexplored. In this work, we take the first step to comprehensively evaluate the mainstream textual OOD detection methods for detecting semantic and non-semantic shifts. We find that: (1) no existing method behaves well in both settings; (2) fine-tuning PLMs on in-distribution data benefits detecting semantic shifts but severely deteriorates detecting non-semantic shifts, which can be attributed to the distortion of task-agnostic features. To alleviate the issue, we present a simple yet effective general OOD score named GNOME that integrates the confidence scores derived from the task-agnostic and task-specific representations. Experiments show that GNOME works well in both semantic and non-semantic shift scenarios, and further brings significant improvement on two cross-task benchmarks where both kinds of shifts simultaneously take place. Our code is available at https://github.com/lancopku/GNOME.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/96a219acb0acdca790f7f9f7f30c507a47a06754.pdf",
        "venue": "Findings",
        "citationCount": 15,
        "score": 7.5,
        "summary": "Detecting out-of-distribution (OOD) inputs is crucial for the safe deployment of natural language processing (NLP) models. Though existing methods, especially those based on the statistics in the feature space of fine-tuned pre-trained language models (PLMs), are claimed to be effective, their effectiveness on different types of distribution shifts remains underexplored. In this work, we take the first step to comprehensively evaluate the mainstream textual OOD detection methods for detecting semantic and non-semantic shifts. We find that: (1) no existing method behaves well in both settings; (2) fine-tuning PLMs on in-distribution data benefits detecting semantic shifts but severely deteriorates detecting non-semantic shifts, which can be attributed to the distortion of task-agnostic features. To alleviate the issue, we present a simple yet effective general OOD score named GNOME that integrates the confidence scores derived from the task-agnostic and task-specific representations. Experiments show that GNOME works well in both semantic and non-semantic shift scenarios, and further brings significant improvement on two cross-task benchmarks where both kinds of shifts simultaneously take place. Our code is available at https://github.com/lancopku/GNOME.",
        "keywords": []
      },
      "file_name": "96a219acb0acdca790f7f9f7f30c507a47a06754.pdf"
    },
    {
      "success": true,
      "doc_id": "787010fa300f4dbf9e53bd8292e7706a",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing Out-of-Distribution (OOD) detection methods primarily focus on semantic shift (unseen categories), neglecting other crucial causes like covariate shift (e.g., different image domains or styles). This narrow scope limits their applicability in uncontrolled real-world environments.\n    *   **Importance & Challenge**: Reliable machine learning models must identify \"what they do not know\" to prevent unreliable predictions. The challenge lies in unifying the detection of diverse OOD examples (semantic vs. covariate shift) and misclassified in-distribution (ID) examples under a single, practical framework, especially since covariate-shifted examples might still be correctly classified by a robust model, making a blanket rejection undesirable.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Conventional OOD Detection**: Focuses solely on semantic shift (S-OOD) \\cite{averly20239rv}.\n        *   **OOD Generalization/Robustness**: Treats covariate shift (C-OOD) as in-distribution, aiming to classify them robustly rather than detect them as OOD \\cite{averly20239rv}.\n        *   **G-ODIN Framework \\cite{16}**: Aims to detect *all* C-OOD examples as OOD \\cite{averly20239rv}.\n        *   **SEM Framework \\cite{52}**: Aims to accept *all* ID and C-OOD examples \\cite{averly20239rv}.\n        *   **Selective Classification \\cite{9} / SCOD \\cite{48}**: Focuses on rejecting uncertain or misclassified ID examples, with SCOD extending to semantic shift data \\cite{averly20239rv}.\n    *   **Limitations of Previous Solutions**:\n        *   Most works ignore covariate shift or treat it inconsistently (either always OOD or always ID), failing to account for cases where a model *can* correctly classify C-OOD examples \\cite{averly20239rv}.\n        *   Existing frameworks do not provide a unified perspective that considers both semantic and covariate shifts, alongside misclassified ID examples, based on the *actual performance* of a deployed model \\cite{averly20239rv}.\n        *   The dilemma between OOD detection (rejecting C-OOD) and OOD generalization (accepting C-OOD) remains unresolved in prior work \\cite{averly20239rv}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel, unifying framework called **Model-Specific Out-of-Distribution (MS-OOD) Detection** \\cite{averly20239rv}. Instead of detecting OOD examples from a particular cause, it defines OOD detection based on whether a *deployed machine learning model* (e.g., an image classifier) is unable to predict an example correctly.\n    *   **Novelty**:\n        *   **Model-Specific Perspective**: Whether an example should be detected and rejected is \"model-specific,\" determined by the classifier's actual misclassification \\cite{averly20239rv}.\n        *   **Unified Ground-Truth Labeling**: Every test example (ID, C-OOD, S-OOD) is deterministically assigned a ground-truth label (+1 for correctly classified, -1 for misclassified) based on the deployed model's output \\cite{averly20239rv}.\n        *   **Acceptance/Rejection Regions**: Defines \"Model-specific acceptance (MS-A)\" (correctly classified ID and C-OOD) and \"Model-specific rejection (MS-R)\" (misclassified ID, misclassified C-OOD, and all S-OOD) \\cite{averly20239rv}. The goal is to differentiate MS-A from MS-R.\n        *   This framework unifies the detection of OOD examples caused by semantic shift and covariate shift, and also incorporates misclassified ID examples, generalizing prior concepts like selective classification \\cite{averly20239rv}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Framework**: Introduction of the MS-OOD Detection framework \\cite{averly20239rv}, which provides a principled and unified way to study OOD detection across various types of distribution shifts (semantic and covariate) and misclassifications, based on a model's performance.\n    *   **Formal Problem Definition**: A clear definition of ground-truth labels for MS-OOD, enabling systematic evaluation of OOD detection methods in a broader context \\cite{averly20239rv}.\n    *   **Extensive Empirical Analysis**: A comprehensive study involving diverse models, OOD sources, and detection methods, revealing novel insights and re-validating existing ones in a unified setting \\cite{averly20239rv}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: An extensive empirical study across three dimensions:\n        1.  **Sources of OOD Examples**: Both semantic shift (S-OOD) and covariate shift (C-OOD) \\cite{averly20239rv}.\n        2.  **Deployed Classifiers**: Various neural network architectures and training strategies \\cite{averly20239rv}.\n        3.  **OOD Detection Methods**: Representative post-hoc approaches including Maximum Softmax Probabilities (MSP) \\cite{13}, Energy Score \\cite{23}, Maximum Logit Score (MLS) \\cite{42}, Virtual-logit Matching (ViM) \\cite{44}, and GradNorm \\cite{18} \\cite{averly20239rv}.\n    *   **Key Performance Metrics**:\n        *   FPR(S-OOD)@TPR(ID+)=95: False Positive Rate for accepting S-OOD data, at 95% True Positive Rate for accepting correctly classified ID data.\n        *   FPR(ID-)@TPR(ID+)=95: False Positive Rate for accepting misclassified ID data, at 95% TPR for correctly classified ID data.\n        *   F1-Score(C-OOD)@TPR(ID+)=95: F1-Score for identifying correctly classified C-OOD data from all C-OOD data, at 95% TPR for correctly classified ID data \\cite{averly20239rv}.\n    *   **Comparison Results & Insights**:\n        *   The optimal detection methods for S-OOD, misclassified C-OOD, and misclassified ID data are inconsistent and \"model-specific\" \\cite{averly20239rv}.\n        *   More robust classifiers (higher C-OOD accuracy) make misclassified C-OOD examples easier to detect \\cite{averly20239rv}.\n        *   Stronger classifiers (higher ID accuracy) generally make S-OOD examples easier to detect, though exceptions exist with specific methods/classifiers \\cite{averly20239rv}.\n        *   Misclassified ID examples typically have lower confidence scores, allowing for higher S-OOD rejection rates without sacrificing correctly classified ID acceptance \\cite{averly20239rv}.\n        *   The baseline MSP method \\cite{13} performs surprisingly well for detecting misclassified ID and C-OOD examples, often outperforming more advanced methods \\cite{averly20239rv}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study focuses exclusively on post-hoc OOD detection methods, excluding training-based methods like outlier exposure \\cite{14} which require access to OOD examples during training \\cite{averly20239rv}.\n    *   **Scope of Applicability**: The MS-OOD framework is primarily an evaluation and unification framework, not a new OOD scoring algorithm itself. Its definition of \"OOD\" is inherently tied to the performance of a *specific deployed classifier* \\cite{averly20239rv}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: The MS-OOD Detection framework \\cite{averly20239rv} significantly advances the technical state-of-the-art by providing a unified and more realistic perspective on OOD detection that accounts for both semantic and covariate shifts, as well as model misclassifications. It resolves a long-standing dilemma in how to treat covariate shift in OOD detection.\n    *   **Potential Impact on Future Research**: This work offers a robust experimental platform and a \"manual\" for researchers and practitioners to select appropriate OOD methods for diverse use cases \\cite{averly20239rv}. The insights gained (e.g., model-specific effectiveness, performance of MSP) can guide the development of more effective and context-aware OOD detection algorithms and foster a more comprehensive understanding of OOD phenomena in uncontrolled environments.",
      "intriguing_abstract": "The Achilles' heel of deployed machine learning models is their susceptibility to unseen data, often leading to unreliable predictions. Current Out-of-Distribution (OOD) detection primarily addresses semantic novelty, largely overlooking critical challenges like covariate shift and even misclassified in-distribution examples. This narrow scope leaves a significant gap in real-world reliability.\n\nWe introduce **Model-Specific Out-of-Distribution (MS-OOD) Detection**, a novel, unifying framework that redefines OOD based on the *actual misclassification performance* of a deployed model. Unlike prior work, MS-OOD deterministically labels every example (semantic OOD, covariate OOD, in-distribution) as either correctly classified or misclassified by the target model, resolving the long-standing dilemma of how to treat covariate-shifted data. This principled approach provides a unified ground-truth for evaluating OOD methods across diverse distribution shifts and misclassifications. Our extensive empirical analysis, spanning various neural networks and post-hoc detection techniques, reveals that optimal OOD strategies are highly model-specific and highlights the surprising efficacy of baseline methods like Maximum Softmax Probability (MSP) for certain OOD types. MS-OOD offers a robust platform for future research, guiding the development and selection of truly reliable OOD detection systems for real-world AI deployment.",
      "keywords": [
        "Model-Specific Out-of-Distribution (MS-OOD) Detection",
        "unified OOD detection framework",
        "semantic shift",
        "covariate shift",
        "misclassified in-distribution examples",
        "model-specific performance",
        "post-hoc OOD detection methods",
        "empirical analysis",
        "reliable machine learning models",
        "Maximum Softmax Probabilities (MSP)",
        "ground-truth labeling",
        "robust classifiers"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/8f53788139d97189af8204a36b109473a0a2b61f.pdf",
      "citation_key": "averly20239rv",
      "metadata": {
        "title": "Unified Out-Of-Distribution Detection: A Model-Specific Perspective",
        "authors": [
          "Reza Averly",
          "Wei-Lun Chao"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection aims to identify test examples that do not belong to the training distribution and are thus unlikely to be predicted reliably. Despite a plethora of existing works, most of them focused only on the scenario where OOD examples come from semantic shift (e.g., unseen categories), ignoring other possible causes (e.g., covariate shift). In this paper, we present a novel, unifying framework to study OOD detection in a broader scope. Instead of detecting OOD examples from a particular cause, we propose to detect examples that a deployed machine learning model (e.g., an image classifier) is unable to predict correctly. That is, whether a test example should be detected and rejected or not is \"model-specific\". We show that this framework unifies the detection of OOD examples caused by semantic shift and covariate shift, and closely addresses the concern of applying a machine learning model to uncontrolled environments. We provide an extensive analysis that involves a variety of models (e.g., different architectures and training strategies), sources of OOD examples, and OOD detection approaches, and reveal several insights into improving and understanding OOD detection in uncontrolled environments.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/8f53788139d97189af8204a36b109473a0a2b61f.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 15,
        "score": 7.5,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing Out-of-Distribution (OOD) detection methods primarily focus on semantic shift (unseen categories), neglecting other crucial causes like covariate shift (e.g., different image domains or styles). This narrow scope limits their applicability in uncontrolled real-world environments.\n    *   **Importance & Challenge**: Reliable machine learning models must identify \"what they do not know\" to prevent unreliable predictions. The challenge lies in unifying the detection of diverse OOD examples (semantic vs. covariate shift) and misclassified in-distribution (ID) examples under a single, practical framework, especially since covariate-shifted examples might still be correctly classified by a robust model, making a blanket rejection undesirable.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Conventional OOD Detection**: Focuses solely on semantic shift (S-OOD) \\cite{averly20239rv}.\n        *   **OOD Generalization/Robustness**: Treats covariate shift (C-OOD) as in-distribution, aiming to classify them robustly rather than detect them as OOD \\cite{averly20239rv}.\n        *   **G-ODIN Framework \\cite{16}**: Aims to detect *all* C-OOD examples as OOD \\cite{averly20239rv}.\n        *   **SEM Framework \\cite{52}**: Aims to accept *all* ID and C-OOD examples \\cite{averly20239rv}.\n        *   **Selective Classification \\cite{9} / SCOD \\cite{48}**: Focuses on rejecting uncertain or misclassified ID examples, with SCOD extending to semantic shift data \\cite{averly20239rv}.\n    *   **Limitations of Previous Solutions**:\n        *   Most works ignore covariate shift or treat it inconsistently (either always OOD or always ID), failing to account for cases where a model *can* correctly classify C-OOD examples \\cite{averly20239rv}.\n        *   Existing frameworks do not provide a unified perspective that considers both semantic and covariate shifts, alongside misclassified ID examples, based on the *actual performance* of a deployed model \\cite{averly20239rv}.\n        *   The dilemma between OOD detection (rejecting C-OOD) and OOD generalization (accepting C-OOD) remains unresolved in prior work \\cite{averly20239rv}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel, unifying framework called **Model-Specific Out-of-Distribution (MS-OOD) Detection** \\cite{averly20239rv}. Instead of detecting OOD examples from a particular cause, it defines OOD detection based on whether a *deployed machine learning model* (e.g., an image classifier) is unable to predict an example correctly.\n    *   **Novelty**:\n        *   **Model-Specific Perspective**: Whether an example should be detected and rejected is \"model-specific,\" determined by the classifier's actual misclassification \\cite{averly20239rv}.\n        *   **Unified Ground-Truth Labeling**: Every test example (ID, C-OOD, S-OOD) is deterministically assigned a ground-truth label (+1 for correctly classified, -1 for misclassified) based on the deployed model's output \\cite{averly20239rv}.\n        *   **Acceptance/Rejection Regions**: Defines \"Model-specific acceptance (MS-A)\" (correctly classified ID and C-OOD) and \"Model-specific rejection (MS-R)\" (misclassified ID, misclassified C-OOD, and all S-OOD) \\cite{averly20239rv}. The goal is to differentiate MS-A from MS-R.\n        *   This framework unifies the detection of OOD examples caused by semantic shift and covariate shift, and also incorporates misclassified ID examples, generalizing prior concepts like selective classification \\cite{averly20239rv}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Framework**: Introduction of the MS-OOD Detection framework \\cite{averly20239rv}, which provides a principled and unified way to study OOD detection across various types of distribution shifts (semantic and covariate) and misclassifications, based on a model's performance.\n    *   **Formal Problem Definition**: A clear definition of ground-truth labels for MS-OOD, enabling systematic evaluation of OOD detection methods in a broader context \\cite{averly20239rv}.\n    *   **Extensive Empirical Analysis**: A comprehensive study involving diverse models, OOD sources, and detection methods, revealing novel insights and re-validating existing ones in a unified setting \\cite{averly20239rv}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: An extensive empirical study across three dimensions:\n        1.  **Sources of OOD Examples**: Both semantic shift (S-OOD) and covariate shift (C-OOD) \\cite{averly20239rv}.\n        2.  **Deployed Classifiers**: Various neural network architectures and training strategies \\cite{averly20239rv}.\n        3.  **OOD Detection Methods**: Representative post-hoc approaches including Maximum Softmax Probabilities (MSP) \\cite{13}, Energy Score \\cite{23}, Maximum Logit Score (MLS) \\cite{42}, Virtual-logit Matching (ViM) \\cite{44}, and GradNorm \\cite{18} \\cite{averly20239rv}.\n    *   **Key Performance Metrics**:\n        *   FPR(S-OOD)@TPR(ID+)=95: False Positive Rate for accepting S-OOD data, at 95% True Positive Rate for accepting correctly classified ID data.\n        *   FPR(ID-)@TPR(ID+)=95: False Positive Rate for accepting misclassified ID data, at 95% TPR for correctly classified ID data.\n        *   F1-Score(C-OOD)@TPR(ID+)=95: F1-Score for identifying correctly classified C-OOD data from all C-OOD data, at 95% TPR for correctly classified ID data \\cite{averly20239rv}.\n    *   **Comparison Results & Insights**:\n        *   The optimal detection methods for S-OOD, misclassified C-OOD, and misclassified ID data are inconsistent and \"model-specific\" \\cite{averly20239rv}.\n        *   More robust classifiers (higher C-OOD accuracy) make misclassified C-OOD examples easier to detect \\cite{averly20239rv}.\n        *   Stronger classifiers (higher ID accuracy) generally make S-OOD examples easier to detect, though exceptions exist with specific methods/classifiers \\cite{averly20239rv}.\n        *   Misclassified ID examples typically have lower confidence scores, allowing for higher S-OOD rejection rates without sacrificing correctly classified ID acceptance \\cite{averly20239rv}.\n        *   The baseline MSP method \\cite{13} performs surprisingly well for detecting misclassified ID and C-OOD examples, often outperforming more advanced methods \\cite{averly20239rv}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study focuses exclusively on post-hoc OOD detection methods, excluding training-based methods like outlier exposure \\cite{14} which require access to OOD examples during training \\cite{averly20239rv}.\n    *   **Scope of Applicability**: The MS-OOD framework is primarily an evaluation and unification framework, not a new OOD scoring algorithm itself. Its definition of \"OOD\" is inherently tied to the performance of a *specific deployed classifier* \\cite{averly20239rv}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: The MS-OOD Detection framework \\cite{averly20239rv} significantly advances the technical state-of-the-art by providing a unified and more realistic perspective on OOD detection that accounts for both semantic and covariate shifts, as well as model misclassifications. It resolves a long-standing dilemma in how to treat covariate shift in OOD detection.\n    *   **Potential Impact on Future Research**: This work offers a robust experimental platform and a \"manual\" for researchers and practitioners to select appropriate OOD methods for diverse use cases \\cite{averly20239rv}. The insights gained (e.g., model-specific effectiveness, performance of MSP) can guide the development of more effective and context-aware OOD detection algorithms and foster a more comprehensive understanding of OOD phenomena in uncontrolled environments.",
        "keywords": [
          "Model-Specific Out-of-Distribution (MS-OOD) Detection",
          "unified OOD detection framework",
          "semantic shift",
          "covariate shift",
          "misclassified in-distribution examples",
          "model-specific performance",
          "post-hoc OOD detection methods",
          "empirical analysis",
          "reliable machine learning models",
          "Maximum Softmax Probabilities (MSP)",
          "ground-truth labeling",
          "robust classifiers"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **\"we present a novel, unifying framework\"**: this indicates the development of a new system or approach.\n2.  **\"we propose to detect examples that a deployed machine learning model... is unable to predict correctly.\"**: this describes a new method or algorithm for detection.\n3.  the introduction sets up a technical problem (ood detection, covariate/semantic shift) and then introduces their proposed solution/framework (\"model-specific out-of-distribution (ms-ood) detection\").\n4.  while it includes \"extensive analysis\" (suggesting empirical elements) and argues for a \"model-specific\" perspective (suggesting position), the core contribution is the *creation and presentation* of a \"novel, unifying framework\" and a *proposed method* for detection. the analysis serves to validate and explore this technical contribution.\n\ntherefore, the paper primarily fits the **technical** classification."
      },
      "file_name": "8f53788139d97189af8204a36b109473a0a2b61f.pdf"
    },
    {
      "success": true,
      "doc_id": "3ddad721e5ccf2d4709bf9ac70eb62eb",
      "summary": "Here's a focused summary of the paper \"Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection Capability\" \\cite{zhu2023u9p} for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, which is crucial for deploying secure and reliable AI models in real-world, open-world scenarios.\n    *   **Importance & Challenge**: While existing methods focus on designing better scoring functions or utilizing auxiliary outlier data, they often overlook the *intrinsic* OOD detection capability of a given, well-trained model. The authors empirically observe that models often exhibit *higher* OOD detection performance at an *intermediate* training stage than at their final, fully-trained stage. This \"overlaid\" capability is lost due to the model memorizing \"atypical samples\" during later training phases, leading to overconfidence on OOD inputs. The challenge is to restore this lost intrinsic capability without relying on auxiliary OOD data.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous work primarily falls into two categories: (1) designing scoring functions (e.g., MSP, ODIN, Energy) applied to well-trained models, and (2) fine-tuning models with auxiliary outlier data (e.g., Outlier Exposure - OE).\n    *   **Limitations of Previous Solutions**: These methods often treat the final well-trained model as the optimal basis for OOD detection, despite a \"target-oriented discrepancy\" (models are trained for classification, not OOD detection). They pay limited attention to whether the given model's *intrinsic* OOD discriminative capability is fully leveraged or even preserved. The paper argues that the final model might not be the most appropriate for OOD detection due to its memorization of atypical in-distribution (ID) samples.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **Unleashing Mask (UM)** and its practical variant **UMAP (Unleashing Mask Adopts Pruning)**. The core idea is to restore the OOD discriminative capabilities of a well-trained model by identifying and \"forgetting\" memorized atypical ID samples.\n    *   **Novelty/Difference**:\n        *   **Discovery of Overlaid Capability**: The fundamental innovation is the empirical discovery and in-depth analysis of the \"overlaid OOD detection capability\" â€“ that an intermediate training stage often outperforms the final stage in OOD detection, attributed to memorizing atypical samples.\n        *   **Atypical Sample Mining with Mask**: UM introduces a novel mechanism to identify these atypical samples. It initializes a layer-wise mask with a specific cutting rate to construct parameter discrepancy. Atypical samples are found to be more sensitive to these parameter changes, allowing the mask to effectively \"mine\" them.\n        *   **Model Forgetting with Constrained Gradient Ascent**: To \"forget\" these identified atypical samples, UM employs a constrained gradient ascent objective: `min LUM = min mÎ´âˆˆ[0,1]n|â„“CE(f)âˆ’bâ„“CE(mÎ´âŠ™fâˆ—)| + bâ„“CE(mÎ´âŠ™fâˆ—)`. This objective encourages the model to stabilize around an optimal stage by minimizing the absolute difference between the current model's Cross-Entropy (CE) loss and a baseline CE loss estimated from the masked outputs of a fixed pretrained model. This prevents greedy updates and preserves discriminative features.\n        *   **UMAP for Practicality**: UMAP is a variant that integrates pruning with the mask, tuning the mask itself with a new objective to alleviate atypical sample memorization while minimizing the sacrifice of original ID task performance.\n\n*   **Key Technical Contributions**\n    *   **Conceptual Shift**: Introduces a new perspective on OOD detection by exploring the intrinsic capabilities of models without auxiliary outliers, focusing on backtracking to an optimal intermediate training phase.\n    *   **Empirical Insight**: Empirically reveals the existence of an intermediate training stage with superior OOD detection and identifies \"memorizing atypical samples\" as a critical data-level attribution for the degradation of OOD performance in the final model.\n    *   **Novel Algorithms/Methods**:\n        *   **Unleashing Mask (UM)**: A novel method for identifying atypical samples via constructed parameter discrepancy using a layer-wise mask and then \"forgetting\" them through a constrained gradient ascent objective.\n        *   **UMAP**: A practical variant that leverages pruning on the mask to achieve forgetting while maintaining ID performance.\n    *   **Framework Design**: A two-component framework involving mask initialization for discrepancy construction and subsequent adjustment (finetuning or pruning) for forgetting.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Extensive empirical verification of the \"intermediate stage\" phenomenon across various OOD/ID datasets (CIFAR-10, CIFAR-100, SVHN, Textures, iNaturalist), different learning rate schedules, and model structures (DenseNet-101, WRN-40-4).\n        *   In-depth analysis using training/testing loss and accuracy curves, ID/OOD score distributions, margin values, and TSNE visualizations of feature embeddings to confirm the role of atypical samples.\n        *   Comprehensive evaluation of UM and UMAP on OOD detection benchmarks.\n        *   Ablation studies to understand the contribution of different components.\n        *   Verification of effectiveness on ImageNet pretrained models.\n    *   **Key Performance Metrics**: Primarily False Positive Rate at 95% True Positive Rate (FPR95) for OOD detection.\n    *   **Comparison Results**: UM and UMAP consistently demonstrate significant improvements in OOD detection performance, leading to a substantial reduction in averaged FPR95 compared to baseline well-trained models. The methods are shown to be compatible with existing scoring functions (MSP, ODIN, Energy) and can serve as a better initialization for outlier exposure methods.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the assumption that atypical samples are more sensitive to parameter changes, which might not universally hold across all data types or model architectures. The precise determination of the masking rate and the balance in the forgetting objective are critical hyperparameters.\n    *   **Scope of Applicability**: The primary validation is on image classification tasks. While promising, its generalizability to other data modalities (e.g., text, time series) or more complex deep learning architectures and tasks would require further investigation. The method focuses on *restoring* intrinsic capabilities from *already trained* models, rather than designing OOD-aware training from scratch.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{zhu2023u9p} significantly advances the technical state-of-the-art by shifting the focus of OOD detection from external regularization or scoring functions to leveraging and restoring the *intrinsic* OOD discriminative capabilities of deep learning models. It provides a novel, data-centric mechanism to improve OOD detection by \"unlearning\" specific memorized data.\n    *   **Potential Impact**: This work opens a new paradigm for OOD detection by exploiting the training dynamics of deep models. It offers a practical approach to enhance the robustness and security of AI systems, potentially reducing the reliance on auxiliary OOD data which is often unavailable or difficult to curate. The ability to extract better OOD detectors from existing, well-trained models makes it highly relevant for real-world deployments and inspires future research into \"forgetting\" mechanisms for various robustness and generalization tasks.",
      "intriguing_abstract": "Deep learning models, crucial for real-world AI, often paradoxically *lose* their optimal Out-of-Distribution (OOD) detection capabilities as training progresses. We uncover a surprising phenomenon: models frequently exhibit superior OOD detection at an *intermediate* training stage, a capability \"overlaid\" and subsequently degraded by memorizing \"atypical in-distribution samples\" during later phases, leading to overconfidence on OOD inputs.\n\nThis paper introduces **Unleashing Mask (UM)** and its practical variant, **UMAP**, novel methods designed to restore this lost intrinsic OOD discriminative power without auxiliary outlier data. UM identifies these problematic atypical samples by constructing parameter discrepancy with a layer-wise mask, then systematically \"forgets\" them using a constrained gradient ascent objective. UMAP further refines this with pruning for efficiency. Our extensive experiments demonstrate that UM and UMAP significantly reduce the False Positive Rate at 95% True Positive Rate (FPR95) across diverse benchmarks, outperforming well-trained baselines. This work offers a new paradigm for OOD detection, leveraging intrinsic model dynamics to enhance AI robustness and security, making it a critical step towards reliable open-world AI deployment.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "intrinsic OOD detection capability",
        "Unleashing Mask (UM)",
        "UMAP (Unleashing Mask Adopts Pruning)",
        "atypical samples",
        "intermediate training stage",
        "model forgetting",
        "layer-wise mask",
        "constrained gradient ascent",
        "FPR95",
        "training dynamics",
        "robustness of AI systems",
        "overlaid OOD detection capability"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/8505cb57677d296351a1b86d15c843410778daca.pdf",
      "citation_key": "zhu2023u9p",
      "metadata": {
        "title": "Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection Capability",
        "authors": [
          "Jianing Zhu",
          "Hengzhuang Li",
          "Jiangchao Yao",
          "Tongliang Liu",
          "Jianliang Xu",
          "Bo Han"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection is an indispensable aspect of secure AI when deploying machine learning models in real-world applications. Previous paradigms either explore better scoring functions or utilize the knowledge of outliers to equip the models with the ability of OOD detection. However, few of them pay attention to the intrinsic OOD detection capability of the given model. In this work, we generally discover the existence of an intermediate stage of a model trained on in-distribution (ID) data having higher OOD detection performance than that of its final stage across different settings, and further identify one critical data-level attribution to be learning with the atypical samples. Based on such insights, we propose a novel method, Unleashing Mask, which aims to restore the OOD discriminative capabilities of the well-trained model with ID data. Our method utilizes a mask to figure out the memorized atypical samples, and then finetune the model or prune it with the introduced mask to forget them. Extensive experiments and analysis demonstrate the effectiveness of our method. The code is available at: https://github.com/tmlr-group/Unleashing-Mask.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/8505cb57677d296351a1b86d15c843410778daca.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 15,
        "score": 7.5,
        "summary": "Here's a focused summary of the paper \"Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection Capability\" \\cite{zhu2023u9p} for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, which is crucial for deploying secure and reliable AI models in real-world, open-world scenarios.\n    *   **Importance & Challenge**: While existing methods focus on designing better scoring functions or utilizing auxiliary outlier data, they often overlook the *intrinsic* OOD detection capability of a given, well-trained model. The authors empirically observe that models often exhibit *higher* OOD detection performance at an *intermediate* training stage than at their final, fully-trained stage. This \"overlaid\" capability is lost due to the model memorizing \"atypical samples\" during later training phases, leading to overconfidence on OOD inputs. The challenge is to restore this lost intrinsic capability without relying on auxiliary OOD data.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous work primarily falls into two categories: (1) designing scoring functions (e.g., MSP, ODIN, Energy) applied to well-trained models, and (2) fine-tuning models with auxiliary outlier data (e.g., Outlier Exposure - OE).\n    *   **Limitations of Previous Solutions**: These methods often treat the final well-trained model as the optimal basis for OOD detection, despite a \"target-oriented discrepancy\" (models are trained for classification, not OOD detection). They pay limited attention to whether the given model's *intrinsic* OOD discriminative capability is fully leveraged or even preserved. The paper argues that the final model might not be the most appropriate for OOD detection due to its memorization of atypical in-distribution (ID) samples.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **Unleashing Mask (UM)** and its practical variant **UMAP (Unleashing Mask Adopts Pruning)**. The core idea is to restore the OOD discriminative capabilities of a well-trained model by identifying and \"forgetting\" memorized atypical ID samples.\n    *   **Novelty/Difference**:\n        *   **Discovery of Overlaid Capability**: The fundamental innovation is the empirical discovery and in-depth analysis of the \"overlaid OOD detection capability\" â€“ that an intermediate training stage often outperforms the final stage in OOD detection, attributed to memorizing atypical samples.\n        *   **Atypical Sample Mining with Mask**: UM introduces a novel mechanism to identify these atypical samples. It initializes a layer-wise mask with a specific cutting rate to construct parameter discrepancy. Atypical samples are found to be more sensitive to these parameter changes, allowing the mask to effectively \"mine\" them.\n        *   **Model Forgetting with Constrained Gradient Ascent**: To \"forget\" these identified atypical samples, UM employs a constrained gradient ascent objective: `min LUM = min mÎ´âˆˆ[0,1]n|â„“CE(f)âˆ’bâ„“CE(mÎ´âŠ™fâˆ—)| + bâ„“CE(mÎ´âŠ™fâˆ—)`. This objective encourages the model to stabilize around an optimal stage by minimizing the absolute difference between the current model's Cross-Entropy (CE) loss and a baseline CE loss estimated from the masked outputs of a fixed pretrained model. This prevents greedy updates and preserves discriminative features.\n        *   **UMAP for Practicality**: UMAP is a variant that integrates pruning with the mask, tuning the mask itself with a new objective to alleviate atypical sample memorization while minimizing the sacrifice of original ID task performance.\n\n*   **Key Technical Contributions**\n    *   **Conceptual Shift**: Introduces a new perspective on OOD detection by exploring the intrinsic capabilities of models without auxiliary outliers, focusing on backtracking to an optimal intermediate training phase.\n    *   **Empirical Insight**: Empirically reveals the existence of an intermediate training stage with superior OOD detection and identifies \"memorizing atypical samples\" as a critical data-level attribution for the degradation of OOD performance in the final model.\n    *   **Novel Algorithms/Methods**:\n        *   **Unleashing Mask (UM)**: A novel method for identifying atypical samples via constructed parameter discrepancy using a layer-wise mask and then \"forgetting\" them through a constrained gradient ascent objective.\n        *   **UMAP**: A practical variant that leverages pruning on the mask to achieve forgetting while maintaining ID performance.\n    *   **Framework Design**: A two-component framework involving mask initialization for discrepancy construction and subsequent adjustment (finetuning or pruning) for forgetting.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Extensive empirical verification of the \"intermediate stage\" phenomenon across various OOD/ID datasets (CIFAR-10, CIFAR-100, SVHN, Textures, iNaturalist), different learning rate schedules, and model structures (DenseNet-101, WRN-40-4).\n        *   In-depth analysis using training/testing loss and accuracy curves, ID/OOD score distributions, margin values, and TSNE visualizations of feature embeddings to confirm the role of atypical samples.\n        *   Comprehensive evaluation of UM and UMAP on OOD detection benchmarks.\n        *   Ablation studies to understand the contribution of different components.\n        *   Verification of effectiveness on ImageNet pretrained models.\n    *   **Key Performance Metrics**: Primarily False Positive Rate at 95% True Positive Rate (FPR95) for OOD detection.\n    *   **Comparison Results**: UM and UMAP consistently demonstrate significant improvements in OOD detection performance, leading to a substantial reduction in averaged FPR95 compared to baseline well-trained models. The methods are shown to be compatible with existing scoring functions (MSP, ODIN, Energy) and can serve as a better initialization for outlier exposure methods.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the assumption that atypical samples are more sensitive to parameter changes, which might not universally hold across all data types or model architectures. The precise determination of the masking rate and the balance in the forgetting objective are critical hyperparameters.\n    *   **Scope of Applicability**: The primary validation is on image classification tasks. While promising, its generalizability to other data modalities (e.g., text, time series) or more complex deep learning architectures and tasks would require further investigation. The method focuses on *restoring* intrinsic capabilities from *already trained* models, rather than designing OOD-aware training from scratch.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{zhu2023u9p} significantly advances the technical state-of-the-art by shifting the focus of OOD detection from external regularization or scoring functions to leveraging and restoring the *intrinsic* OOD discriminative capabilities of deep learning models. It provides a novel, data-centric mechanism to improve OOD detection by \"unlearning\" specific memorized data.\n    *   **Potential Impact**: This work opens a new paradigm for OOD detection by exploiting the training dynamics of deep models. It offers a practical approach to enhance the robustness and security of AI systems, potentially reducing the reliance on auxiliary OOD data which is often unavailable or difficult to curate. The ability to extract better OOD detectors from existing, well-trained models makes it highly relevant for real-world deployments and inspires future research into \"forgetting\" mechanisms for various robustness and generalization tasks.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "intrinsic OOD detection capability",
          "Unleashing Mask (UM)",
          "UMAP (Unleashing Mask Adopts Pruning)",
          "atypical samples",
          "intermediate training stage",
          "model forgetting",
          "layer-wise mask",
          "constrained gradient ascent",
          "FPR95",
          "training dynamics",
          "robustness of AI systems",
          "overlaid OOD detection capability"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **survey**: not a survey. it discusses previous work but doesn't aim to comprehensively review or organize literature.\n2.  **technical**: the abstract explicitly states: \"we propose a novel method, unleashing mask\", \"our method utilizes a mask\". the introduction sets up a technical problem (ood detection) and discusses limitations of previous approaches, leading to the proposed solution. this strongly aligns with the criteria for a technical paper.\n3.  **theoretical**: there are no mentions of proofs, theorems, or formal mathematical models as the primary contribution.\n4.  **empirical**: the abstract mentions \"extensive experiments and analysis demonstrate the effectiveness of our method.\" while the paper clearly includes empirical work, its primary contribution is the *proposal of a novel method*. the experiments are used to validate this method. many technical papers include empirical validation.\n5.  **case_study**: it mentions \"real-world applications\" but does not focus on a detailed analysis of a specific application or case.\n6.  **position**: it identifies a gap and proposes a solution, but it's not primarily an argument for a viewpoint or a future direction. it presents a concrete method.\n7.  **short**: the venue (icml) and the description of \"extensive experiments\" suggest it's not a short paper or work-in-progress.\n\nthe most fitting classification is **technical** because the core contribution is the proposal of a new method (\"unleashing mask\") to address a technical problem (ood detection).\n\n**classification: technical**"
      },
      "file_name": "8505cb57677d296351a1b86d15c843410778daca.pdf"
    },
    {
      "success": true,
      "doc_id": "ada7e1ee23aa1593809ac2091f748b94",
      "summary": "Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. Detecting OOD samples effectively in certain tasks can pose a challenge because of the substantial heterogeneity within the in-distribution (ID), and the high structural similarity between ID and OOD classes. For instance, when detecting heart views in fetal ultrasound videos there is a high structural similarity between the heart and other anatomies such as the abdomen, and large in-distribution variance as a heart has 5 distinct views and structural variations within each view. To detect OOD samples in this context, the resulting model should generalise to the intra-anatomy variations while rejecting similar OOD samples. In this paper, we introduce dual-conditioned diffusion models (DCDM) where we condition the model on in-distribution class information and latent features of the input image for reconstruction-based OOD detection. This constrains the generative manifold of the model to generate images structurally and semantically similar to those within the in-distribution. The proposed model outperforms reference methods with a 12% improvement in accuracy, 22% higher precision, and an 8% better F1 score.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. Detecting OOD samples effectively in certain tasks can pose a challenge because of the substantial heterogeneity within the in-distribution (ID), and the high structural similarity between ID and OOD classes. For instance, when detecting heart views in fetal ultrasound videos there is a high structural similarity between the heart and other anatomies such as the abdomen, and large in-distribution variance as a heart has 5 distinct views and structural variations within each view. To detect OOD samples in this context, the resulting model should generalise to the intra-anatomy variations while rejecting similar OOD samples. In this paper, we introduce dual-conditioned diffusion models (DCDM) where we condition the model on in-distribution class information and latent features of the input image for reconstruction-based OOD detection. This constrains the generative manifold of the model to generate images structurally and semantically similar to those within the in-distribution. The proposed model outperforms reference methods with a 12% improvement in accuracy, 22% higher precision, and an 8% better F1 score.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/9d90a5e3d332fe13b82661e463cc6856ed40bd6a.pdf",
      "citation_key": "mishra20236n9",
      "metadata": {
        "title": "Dual Conditioned Diffusion Models for Out-of-Distribution Detection: Application to Fetal Ultrasound Videos",
        "authors": [
          "Divyanshu Mishra",
          "He Zhao",
          "Pramit Saha",
          "Aris T. Papageorghiou",
          "J. Noble"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. Detecting OOD samples effectively in certain tasks can pose a challenge because of the substantial heterogeneity within the in-distribution (ID), and the high structural similarity between ID and OOD classes. For instance, when detecting heart views in fetal ultrasound videos there is a high structural similarity between the heart and other anatomies such as the abdomen, and large in-distribution variance as a heart has 5 distinct views and structural variations within each view. To detect OOD samples in this context, the resulting model should generalise to the intra-anatomy variations while rejecting similar OOD samples. In this paper, we introduce dual-conditioned diffusion models (DCDM) where we condition the model on in-distribution class information and latent features of the input image for reconstruction-based OOD detection. This constrains the generative manifold of the model to generate images structurally and semantically similar to those within the in-distribution. The proposed model outperforms reference methods with a 12% improvement in accuracy, 22% higher precision, and an 8% better F1 score.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/9d90a5e3d332fe13b82661e463cc6856ed40bd6a.pdf",
        "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
        "citationCount": 15,
        "score": 7.5,
        "summary": "Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. Detecting OOD samples effectively in certain tasks can pose a challenge because of the substantial heterogeneity within the in-distribution (ID), and the high structural similarity between ID and OOD classes. For instance, when detecting heart views in fetal ultrasound videos there is a high structural similarity between the heart and other anatomies such as the abdomen, and large in-distribution variance as a heart has 5 distinct views and structural variations within each view. To detect OOD samples in this context, the resulting model should generalise to the intra-anatomy variations while rejecting similar OOD samples. In this paper, we introduce dual-conditioned diffusion models (DCDM) where we condition the model on in-distribution class information and latent features of the input image for reconstruction-based OOD detection. This constrains the generative manifold of the model to generate images structurally and semantically similar to those within the in-distribution. The proposed model outperforms reference methods with a 12% improvement in accuracy, 22% higher precision, and an 8% better F1 score.",
        "keywords": []
      },
      "file_name": "9d90a5e3d332fe13b82661e463cc6856ed40bd6a.pdf"
    },
    {
      "success": true,
      "doc_id": "1e0ad65265c822fdbebe59f5ff1869cf",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/195d86d6b6a8420e9553fdbfc67cdfa4c87179aa.pdf",
      "citation_key": "yu2023r3c",
      "metadata": {
        "title": "Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection",
        "authors": [
          "Shuyang Yu",
          "Junyuan Hong",
          "Haotao Wang",
          "Zhangyang Wang",
          "Jiayu Zhou"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/195d86d6b6a8420e9553fdbfc67cdfa4c87179aa.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 14,
        "score": 7.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "195d86d6b6a8420e9553fdbfc67cdfa4c87179aa.pdf"
    },
    {
      "success": true,
      "doc_id": "c2f283531b796ed51d5376d397e36afc",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{dai2023mhn}\" when referencing this paper.\n\n---\n\n**TECHNICAL PAPER ANALYSIS**:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addressing multi-modal Out-of-Distribution (OOD) detection, specifically enhancing it by leveraging the rich contextual \"world knowledge\" encoded in Large Language Models (LLMs).\n    *   **Importance and Challenge**: OOD detection is crucial for reliable and trustworthy machine learning systems deployed in real-world, open-set environments. The challenge lies in the inherent tendency of LLMs to \"hallucinate\" or generate unfaithful descriptive features for in-distribution (ID) classes. Indiscriminately using such knowledge can catastrophically damage OOD detection performance by creating \"collisions\" between OOD samples and augmented ID classes in an unbounded feature space.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Builds upon recent multi-modal OOD detection methods that leverage textual information from ID class names (e.g., using pre-trained vision-language models like CLIP). It also relates to general OOD detection (single-modal) and the broader application of LLMs as knowledge bases for vision tasks.\n    *   **Limitations of Previous Solutions**:\n        *   Existing multi-modal OOD detection methods neglect the rich contextual \"world knowledge\" available in LLMs.\n        *   While LLMs can aid vision tasks, their effective and safe integration into multi-modal OOD detection, especially concerning their hallucination tendencies, is largely underexplored.\n        *   Uncertainty calibration for LLMs generating long-form, open-ended text (like descriptive features) is an underdeveloped area.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a multi-modal OOD detection framework that selectively integrates world knowledge from LLMs. It involves four main steps:\n        1.  **Descriptor Generation**: Prompting LLMs (e.g., text-davinci-003) to generate descriptive features for each ID class name.\n        2.  **Uncertainty Calibration**: A novel consistency-based method to estimate a confidence score for each generated descriptor set, mitigating LLM hallucinations. This involves:\n            *   Sampling multiple descriptor sets for each class.\n            *   Clustering these sets based on \"descriptor consistency,\" which is defined by the overlap of top-k images retrieved from a fixed unlabeled image set using the descriptor sets.\n            *   Calculating a confidence score (p(c)) for a descriptor set based on the size of the largest consistent group.\n        3.  **Visual Object Detection**: Employing a general object detector to identify and represent visual objects (concepts) within the input image, providing additional contextual information in the textual space.\n        4.  **OOD Detection Scoring**:\n            *   Selectively augmenting ID class representations with descriptors: only high-confidence descriptor sets (p(c) â‰¥ Î³) are used.\n            *   Computing a class-wise matching score (sc(x)) that combines similarities between: (a) image visual features and class textual features, and (b) detected image objects' textual representations and class textual features (including descriptors).\n            *   The maximum class matching score (smax(x)) is then used to determine if an input is ID or OOD.\n    *   **Novelty/Difference**:\n        *   First work to apply LLM-derived world knowledge to multi-modal OOD detection.\n        *   Introduces a unique *consistency-based uncertainty calibration method* tailored for long-form, open-ended LLM generations, which is crucial for safely integrating LLM knowledge by addressing hallucinations. This method leverages retrieval feedback from unlabeled images to assess consistency.\n        *   Integrates visual object detection to further enrich the contextual understanding of images, matching detected concepts with ID class descriptors.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   A selective generation framework for LLM-generated descriptive features, specifically designed to counter the detrimental effects of LLM hallucinations in OOD detection.\n        *   A novel consistency-based uncertainty calibration method for LLMs, which quantifies the reliability of generated open-ended text by analyzing the consistency of their retrieval results on an unlabeled image dataset.\n        *   An enhanced OOD detection scoring function that effectively combines selectively generated LLM descriptors and visual object detections from images within a vision-language model framework.\n    *   **Theoretical Insights/Analysis**: Provides empirical evidence and analysis demonstrating that naive integration of LLM-generated descriptors can *degrade* OOD detection performance, highlighting the critical need for selective generation and uncertainty calibration.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed across various large-scale and realistic datasets.\n        *   ID datasets: ImageNet-1k, CUB-200, Stanford-Cars, Food-101, Oxford-Pet.\n        *   OOD datasets: iNaturalist, SUN, Places, Texture.\n        *   Comparison of baseline CLIP, CLIP with indiscriminately used descriptors (CLIP+Desp.), and the proposed method.\n        *   Comparison against competitive OOD detection baselines (e.g., MOS, Fort et al., Energy, MSP, MCM).\n    *   **Key Performance Metrics**: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC) for OOD detection. Classification accuracy was also used to illustrate the problem with naive descriptor use.\n    *   **Comparison Results**:\n        *   Initial analysis showed that while LLM descriptors improved classification accuracy, they *degenerated* OOD detection performance (higher FPR95) when used indiscriminately, validating the paper's core hypothesis about hallucinations.\n        *   The proposed method consistently and significantly outperforms state-of-the-art multi-modal OOD detection baselines across the evaluated datasets.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Relies on the quality of the underlying LLM for descriptor generation and the VLM for vision-language embeddings.\n        *   The consistency-based calibration requires a sufficiently large and diverse unlabeled image set.\n        *   The effectiveness of the method is dependent on the chosen thresholds (e.g., for confidence score Î³, similarity Î·, and OOD decision Î»).\n    *   **Scope of Applicability**: Primarily applicable to multi-modal OOD detection tasks where ID class names are available and LLM-generated descriptive features can provide valuable contextual information. It is designed for open-world scenarios where unseen data is expected.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: Represents a significant advancement in multi-modal OOD detection by successfully harnessing the vast world knowledge of LLMs while effectively mitigating the critical challenge of LLM hallucinations. It provides a robust and practical framework for integrating LLM knowledge into trustworthy machine learning systems.\n    *   **Potential Impact on Future Research**: Opens new research directions for the safe and effective integration of LLMs into various robust AI applications, particularly those requiring uncertainty quantification and open-set recognition. The novel consistency-based calibration method could inspire similar approaches for evaluating and trusting LLM outputs in other complex, open-ended generation tasks.",
      "intriguing_abstract": "Deploying machine learning in open-set environments demands robust Out-of-Distribution (OOD) detection, a challenge amplified in multi-modal settings. Large Language Models (LLMs) offer a vast reservoir of \"world knowledge\" that could significantly enhance OOD detection by enriching in-distribution class representations. However, indiscriminately integrating LLM-generated descriptive features is perilous; their inherent \"hallucination\" tendencies can catastrophically degrade performance by creating false positives and feature collisions.\n\nWe introduce a novel multi-modal OOD detection framework that safely harnesses LLM knowledge. Our core innovation is a *consistency-based uncertainty calibration method* for LLM-generated open-ended text. This method quantifies descriptor reliability by analyzing retrieval consistency on unlabeled image datasets, allowing for the *selective integration* of only high-confidence LLM descriptors. Coupled with visual object detection, our approach enriches contextual understanding. Extensive experiments demonstrate that our framework consistently and significantly outperforms state-of-the-art baselines, transforming LLM-derived knowledge from a liability into a powerful asset for trustworthy OOD detection and advancing open-set recognition.",
      "keywords": [
        "Multi-modal OOD detection",
        "Large Language Models (LLMs)",
        "LLM hallucinations",
        "World knowledge integration",
        "Consistency-based uncertainty calibration",
        "Selective descriptor generation",
        "Visual object detection",
        "Open-set recognition",
        "Trustworthy machine learning",
        "Degradation of OOD performance",
        "State-of-the-art performance",
        "Retrieval feedback",
        "Robust AI applications"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/23bbd94f93e360f373f78ce20f61ec3486b1923d.pdf",
      "citation_key": "dai2023mhn",
      "metadata": {
        "title": "Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection",
        "authors": [
          "Yi Dai",
          "Hao Lang",
          "Kaisheng Zeng",
          "Fei Huang",
          "Yongbin Li"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection is essential for reliable and trustworthy machine learning. Recent multi-modal OOD detection leverages textual information from in-distribution (ID) class names for visual OOD detection, yet it currently neglects the rich contextual information of ID classes. Large language models (LLMs) encode a wealth of world knowledge and can be prompted to generate descriptive features for each class. Indiscriminately using such knowledge causes catastrophic damage to OOD detection due to LLMs' hallucinations, as is observed by our analysis. In this paper, we propose to apply world knowledge to enhance OOD detection performance through selective generation from LLMs. Specifically, we introduce a consistency-based uncertainty calibration method to estimate the confidence score of each generation. We further extract visual objects from each image to fully capitalize on the aforementioned world knowledge. Extensive experiments demonstrate that our method consistently outperforms the state-of-the-art.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/23bbd94f93e360f373f78ce20f61ec3486b1923d.pdf",
        "venue": "Conference on Empirical Methods in Natural Language Processing",
        "citationCount": 14,
        "score": 7.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{dai2023mhn}\" when referencing this paper.\n\n---\n\n**TECHNICAL PAPER ANALYSIS**:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addressing multi-modal Out-of-Distribution (OOD) detection, specifically enhancing it by leveraging the rich contextual \"world knowledge\" encoded in Large Language Models (LLMs).\n    *   **Importance and Challenge**: OOD detection is crucial for reliable and trustworthy machine learning systems deployed in real-world, open-set environments. The challenge lies in the inherent tendency of LLMs to \"hallucinate\" or generate unfaithful descriptive features for in-distribution (ID) classes. Indiscriminately using such knowledge can catastrophically damage OOD detection performance by creating \"collisions\" between OOD samples and augmented ID classes in an unbounded feature space.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Builds upon recent multi-modal OOD detection methods that leverage textual information from ID class names (e.g., using pre-trained vision-language models like CLIP). It also relates to general OOD detection (single-modal) and the broader application of LLMs as knowledge bases for vision tasks.\n    *   **Limitations of Previous Solutions**:\n        *   Existing multi-modal OOD detection methods neglect the rich contextual \"world knowledge\" available in LLMs.\n        *   While LLMs can aid vision tasks, their effective and safe integration into multi-modal OOD detection, especially concerning their hallucination tendencies, is largely underexplored.\n        *   Uncertainty calibration for LLMs generating long-form, open-ended text (like descriptive features) is an underdeveloped area.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a multi-modal OOD detection framework that selectively integrates world knowledge from LLMs. It involves four main steps:\n        1.  **Descriptor Generation**: Prompting LLMs (e.g., text-davinci-003) to generate descriptive features for each ID class name.\n        2.  **Uncertainty Calibration**: A novel consistency-based method to estimate a confidence score for each generated descriptor set, mitigating LLM hallucinations. This involves:\n            *   Sampling multiple descriptor sets for each class.\n            *   Clustering these sets based on \"descriptor consistency,\" which is defined by the overlap of top-k images retrieved from a fixed unlabeled image set using the descriptor sets.\n            *   Calculating a confidence score (p(c)) for a descriptor set based on the size of the largest consistent group.\n        3.  **Visual Object Detection**: Employing a general object detector to identify and represent visual objects (concepts) within the input image, providing additional contextual information in the textual space.\n        4.  **OOD Detection Scoring**:\n            *   Selectively augmenting ID class representations with descriptors: only high-confidence descriptor sets (p(c) â‰¥ Î³) are used.\n            *   Computing a class-wise matching score (sc(x)) that combines similarities between: (a) image visual features and class textual features, and (b) detected image objects' textual representations and class textual features (including descriptors).\n            *   The maximum class matching score (smax(x)) is then used to determine if an input is ID or OOD.\n    *   **Novelty/Difference**:\n        *   First work to apply LLM-derived world knowledge to multi-modal OOD detection.\n        *   Introduces a unique *consistency-based uncertainty calibration method* tailored for long-form, open-ended LLM generations, which is crucial for safely integrating LLM knowledge by addressing hallucinations. This method leverages retrieval feedback from unlabeled images to assess consistency.\n        *   Integrates visual object detection to further enrich the contextual understanding of images, matching detected concepts with ID class descriptors.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   A selective generation framework for LLM-generated descriptive features, specifically designed to counter the detrimental effects of LLM hallucinations in OOD detection.\n        *   A novel consistency-based uncertainty calibration method for LLMs, which quantifies the reliability of generated open-ended text by analyzing the consistency of their retrieval results on an unlabeled image dataset.\n        *   An enhanced OOD detection scoring function that effectively combines selectively generated LLM descriptors and visual object detections from images within a vision-language model framework.\n    *   **Theoretical Insights/Analysis**: Provides empirical evidence and analysis demonstrating that naive integration of LLM-generated descriptors can *degrade* OOD detection performance, highlighting the critical need for selective generation and uncertainty calibration.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed across various large-scale and realistic datasets.\n        *   ID datasets: ImageNet-1k, CUB-200, Stanford-Cars, Food-101, Oxford-Pet.\n        *   OOD datasets: iNaturalist, SUN, Places, Texture.\n        *   Comparison of baseline CLIP, CLIP with indiscriminately used descriptors (CLIP+Desp.), and the proposed method.\n        *   Comparison against competitive OOD detection baselines (e.g., MOS, Fort et al., Energy, MSP, MCM).\n    *   **Key Performance Metrics**: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC) for OOD detection. Classification accuracy was also used to illustrate the problem with naive descriptor use.\n    *   **Comparison Results**:\n        *   Initial analysis showed that while LLM descriptors improved classification accuracy, they *degenerated* OOD detection performance (higher FPR95) when used indiscriminately, validating the paper's core hypothesis about hallucinations.\n        *   The proposed method consistently and significantly outperforms state-of-the-art multi-modal OOD detection baselines across the evaluated datasets.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Relies on the quality of the underlying LLM for descriptor generation and the VLM for vision-language embeddings.\n        *   The consistency-based calibration requires a sufficiently large and diverse unlabeled image set.\n        *   The effectiveness of the method is dependent on the chosen thresholds (e.g., for confidence score Î³, similarity Î·, and OOD decision Î»).\n    *   **Scope of Applicability**: Primarily applicable to multi-modal OOD detection tasks where ID class names are available and LLM-generated descriptive features can provide valuable contextual information. It is designed for open-world scenarios where unseen data is expected.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: Represents a significant advancement in multi-modal OOD detection by successfully harnessing the vast world knowledge of LLMs while effectively mitigating the critical challenge of LLM hallucinations. It provides a robust and practical framework for integrating LLM knowledge into trustworthy machine learning systems.\n    *   **Potential Impact on Future Research**: Opens new research directions for the safe and effective integration of LLMs into various robust AI applications, particularly those requiring uncertainty quantification and open-set recognition. The novel consistency-based calibration method could inspire similar approaches for evaluating and trusting LLM outputs in other complex, open-ended generation tasks.",
        "keywords": [
          "Multi-modal OOD detection",
          "Large Language Models (LLMs)",
          "LLM hallucinations",
          "World knowledge integration",
          "Consistency-based uncertainty calibration",
          "Selective descriptor generation",
          "Visual object detection",
          "Open-set recognition",
          "Trustworthy machine learning",
          "Degradation of OOD performance",
          "State-of-the-art performance",
          "Retrieval feedback",
          "Robust AI applications"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"in this paper, we **propose** to apply world knowledge to enhance ood detection performance through selective generation from llms.\" and \"specifically, we **introduce a consistency-based uncertainty calibration method** to estimate the confidence score of each generation.\" it also mentions extracting visual objects. these phrases directly align with presenting new methods or systems.\n*   the introduction discusses a technical problem (ood detection, limitations of current multi-modal ood) and sets the stage for their proposed solution using llms.\n*   while the abstract also mentions \"extensive experiments demonstrate that our method consistently outperforms the state-of-the-art,\" which is an empirical aspect, this is the validation of the *proposed method*. the primary contribution described is the development and introduction of this new method. many technical papers include empirical validation of their proposed solutions.\n\ntherefore, the paper primarily presents a new method and system.\n\n**classification:** **technical**"
      },
      "file_name": "23bbd94f93e360f373f78ce20f61ec3486b1923d.pdf"
    },
    {
      "success": true,
      "doc_id": "1196e0c2cf788cd2efb6879b464356ee",
      "summary": "Deep neural networks have been increasingly proposed for automated screening and diagnosis of retinal diseases from optical coherence tomography (OCT), but often provide high-confidence predictions on out-of-distribution (OOD) cases, compromising their clinical usage. With this in mind, we performed an in-depth comparative analysis of the state-of-the-art uncertainty estimation methods for OOD detection in retinal OCT imaging. The analysis was performed within the use-case of automated screening and staging of age-related macular degeneration (AMD), one of the leading causes of blindness worldwide, where we achieved a macro-average area under the curve (AUC) of 0.981 for AMD classification. We focus on a few-shot Outlier Exposure (OE) method and the detection of near-OOD cases that share pathomorphological characteristics with the inlier AMD classes. Scoring the OOD case based on the Cosine distance in the feature space from the penultimate network layer proved to be a robust approach for OOD detection, especially in combination with the OE. Using Cosine distance and only 8 outliers exposed per class, we were able to improve the near-OOD detection performance of the OE with Reject Bucket method by $$\\approx$$ â‰ˆ 10% compared to without OE, reaching an AUC of 0.937. The Cosine distance served as a robust metric for OOD detection of both known and unknown classes and should thus be considered as an alternative to the reject bucket class probability in OE approaches, especially in the few-shot scenario. The inclusion of these methodologies did not come at the expense of classification performance, and can substantially improve the reliability and trustworthiness of the resulting deep learning-based diagnostic systems in the context of retinal OCT.",
      "intriguing_abstract": "Deep neural networks have been increasingly proposed for automated screening and diagnosis of retinal diseases from optical coherence tomography (OCT), but often provide high-confidence predictions on out-of-distribution (OOD) cases, compromising their clinical usage. With this in mind, we performed an in-depth comparative analysis of the state-of-the-art uncertainty estimation methods for OOD detection in retinal OCT imaging. The analysis was performed within the use-case of automated screening and staging of age-related macular degeneration (AMD), one of the leading causes of blindness worldwide, where we achieved a macro-average area under the curve (AUC) of 0.981 for AMD classification. We focus on a few-shot Outlier Exposure (OE) method and the detection of near-OOD cases that share pathomorphological characteristics with the inlier AMD classes. Scoring the OOD case based on the Cosine distance in the feature space from the penultimate network layer proved to be a robust approach for OOD detection, especially in combination with the OE. Using Cosine distance and only 8 outliers exposed per class, we were able to improve the near-OOD detection performance of the OE with Reject Bucket method by $$\\approx$$ â‰ˆ 10% compared to without OE, reaching an AUC of 0.937. The Cosine distance served as a robust metric for OOD detection of both known and unknown classes and should thus be considered as an alternative to the reject bucket class probability in OE approaches, especially in the few-shot scenario. The inclusion of these methodologies did not come at the expense of classification performance, and can substantially improve the reliability and trustworthiness of the resulting deep learning-based diagnostic systems in the context of retinal OCT.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/e880782a4a4de3e56b12035a4c6aa3dae7638a06.pdf",
      "citation_key": "arajo2023dau",
      "metadata": {
        "title": "Few-shot out-of-distribution detection for automated screening in retinal OCT images using deep learning",
        "authors": [
          "Teresa AraÃºjo",
          "Guilherme Aresta",
          "U. Schmidt-Erfurth",
          "H. BogunoviÄ‡"
        ],
        "published_date": "2023",
        "abstract": "Deep neural networks have been increasingly proposed for automated screening and diagnosis of retinal diseases from optical coherence tomography (OCT), but often provide high-confidence predictions on out-of-distribution (OOD) cases, compromising their clinical usage. With this in mind, we performed an in-depth comparative analysis of the state-of-the-art uncertainty estimation methods for OOD detection in retinal OCT imaging. The analysis was performed within the use-case of automated screening and staging of age-related macular degeneration (AMD), one of the leading causes of blindness worldwide, where we achieved a macro-average area under the curve (AUC) of 0.981 for AMD classification. We focus on a few-shot Outlier Exposure (OE) method and the detection of near-OOD cases that share pathomorphological characteristics with the inlier AMD classes. Scoring the OOD case based on the Cosine distance in the feature space from the penultimate network layer proved to be a robust approach for OOD detection, especially in combination with the OE. Using Cosine distance and only 8 outliers exposed per class, we were able to improve the near-OOD detection performance of the OE with Reject Bucket method by $$\\approx$$ â‰ˆ 10% compared to without OE, reaching an AUC of 0.937. The Cosine distance served as a robust metric for OOD detection of both known and unknown classes and should thus be considered as an alternative to the reject bucket class probability in OE approaches, especially in the few-shot scenario. The inclusion of these methodologies did not come at the expense of classification performance, and can substantially improve the reliability and trustworthiness of the resulting deep learning-based diagnostic systems in the context of retinal OCT.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/e880782a4a4de3e56b12035a4c6aa3dae7638a06.pdf",
        "venue": "Scientific Reports",
        "citationCount": 14,
        "score": 7.0,
        "summary": "Deep neural networks have been increasingly proposed for automated screening and diagnosis of retinal diseases from optical coherence tomography (OCT), but often provide high-confidence predictions on out-of-distribution (OOD) cases, compromising their clinical usage. With this in mind, we performed an in-depth comparative analysis of the state-of-the-art uncertainty estimation methods for OOD detection in retinal OCT imaging. The analysis was performed within the use-case of automated screening and staging of age-related macular degeneration (AMD), one of the leading causes of blindness worldwide, where we achieved a macro-average area under the curve (AUC) of 0.981 for AMD classification. We focus on a few-shot Outlier Exposure (OE) method and the detection of near-OOD cases that share pathomorphological characteristics with the inlier AMD classes. Scoring the OOD case based on the Cosine distance in the feature space from the penultimate network layer proved to be a robust approach for OOD detection, especially in combination with the OE. Using Cosine distance and only 8 outliers exposed per class, we were able to improve the near-OOD detection performance of the OE with Reject Bucket method by $$\\approx$$ â‰ˆ 10% compared to without OE, reaching an AUC of 0.937. The Cosine distance served as a robust metric for OOD detection of both known and unknown classes and should thus be considered as an alternative to the reject bucket class probability in OE approaches, especially in the few-shot scenario. The inclusion of these methodologies did not come at the expense of classification performance, and can substantially improve the reliability and trustworthiness of the resulting deep learning-based diagnostic systems in the context of retinal OCT.",
        "keywords": []
      },
      "file_name": "e880782a4a4de3e56b12035a4c6aa3dae7638a06.pdf"
    },
    {
      "success": true,
      "doc_id": "12a0d2a7194fc4f348f804d64908b929",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the critical problem of Out-of-Distribution (OOD) detection in machine learning systems. Specifically, it aims to reduce model overconfidence when encountering data from distributions not seen during training.\n    *   **Importance and Challenge:** OOD detection is crucial for building reliable and safe AI systems, especially in high-stakes applications like autonomous driving and medical diagnosis, where models tend to make overconfident predictions on unfamiliar inputs. The challenge lies in effectively distinguishing in-distribution (ID) data from unknown OOD data, particularly with post-hoc strategies that do not require retraining the model.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work is positioned within post-hoc OOD detection strategies, which are favored for their ease of implementation compared to methods requiring training-time regularization or external OOD samples.\n    *   **Limitations of Previous Solutions:** The paper specifically highlights ReAct \\cite{xu2023767}, a typical and effective post-hoc technique that truncates abnormally high activations to increase the gap between ID and OOD. The core limitation identified is whether ReAct's operation (only suppressing high activations) is the *optimal* choice for maximizing this gap.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper leverages the variational method to derive an optimal activation function, `g*(z) = z + Î» * (1 - pout(z)/pin(z))`, that maximizes the gap between ID and OOD while minimizing modifications to the original activations.\n    *   **Novelty/Difference:**\n        *   **Theoretical Derivation:** Unlike heuristic approaches, the paper provides a theoretical foundation for the optimal activation function using variational calculus.\n        *   **Generalized Rectification:** The theoretical analysis reveals that the optimal operation `g*` necessitates not only suppressing abnormally high activations (as in ReAct \\cite{xu2023767}) but also suppressing abnormally low activations and amplifying intermediate activations.\n        *   **VRA (Variational Rectified Activation):** Based on these insights, the paper proposes VRA, a novel piecewise activation function that mimics these suppression and amplification operations. VRA is a generalization of ReAct \\cite{xu2023767}, allowing for truncation at both lower (`Î±`) and upper (`Î²`) thresholds.\n        *   **VRA+:** An enhanced variant, VRA+, further introduces a hyper-parameter `Î´` to control the degree of amplification for intermediate activations, moving closer to the theoretically optimal function.\n        *   **Adaptive Thresholds:** VRA employs an adaptive strategy to determine `Î±` and `Î²` based on quantiles of activations estimated on ID data, making it robust across different features.\n\n*   **4. Key Technical Contributions**\n    *   **Theoretical Insights:** Derivation of the optimal activation function `g*(z)` using the variational method, theoretically demonstrating the necessity of suppressing both abnormally low and high activations and amplifying intermediate activations for maximizing the ID-OOD gap.\n    *   **Novel Algorithms/Methods:** Introduction of Variational Rectified Activation (VRA) and its variant VRA+, which are simple yet effective post-hoc strategies implemented as piecewise functions.\n    *   **System Design/Architectural Innovations:** VRA is designed to be compatible with various existing scoring functions (e.g., MSP, Energy, ODIN) and network architectures (e.g., DenseNet, ResNet), making it a versatile plug-and-play module.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were performed on multiple benchmark datasets: CIFAR-10/100 (ID) with six OOD datasets (Textures, SVHN, Places365, LSUN-Crop/Resize, iSUN), and ImageNet (ID) with four OOD datasets (iNaturalist, SUN, Places, Textures).\n    *   **Key Performance Metrics:** FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve).\n    *   **Comparison Results:**\n        *   VRA-based methods consistently achieved Top3 performance and often set new state-of-the-art records among existing post-hoc strategies.\n        *   VRA+ generally outperformed VRA, supporting the benefit of amplifying intermediate activations.\n        *   VRA-based methods demonstrated superior performance even compared to some methods requiring training (e.g., MOS, VOS), despite being post-hoc.\n        *   VRA showed strong compatibility, improving performance across different scoring functions (MSP, Energy, ODIN).\n        *   An \"upper bound analysis\" with VRA-True (using ideal `pin` and `pout` estimates) achieved near-perfect results, validating the theoretical optimal function's potential.\n        *   Parameter sensitivity analysis highlighted the importance of proper threshold selection, and the adaptive adjustment strategy was shown to be more effective than fixed thresholds.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The practical implementation of VRA relies on approximating the optimal function `g*` with piecewise functions, as estimating the exact `pin` and `pout` for unknown OOD distributions remains challenging. The current VRA and VRA+ are approximations, and further research into better functional forms for `g*` is suggested.\n    *   **Scope of Applicability:** VRA is a post-hoc strategy, meaning it operates on pre-trained models without requiring additional training. It is compatible with various scoring functions and network architectures, making it broadly applicable to existing classification models for OOD detection.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:** The paper significantly advances the technical state-of-the-art in post-hoc OOD detection by providing a theoretical foundation for optimal activation rectification, moving beyond heuristic approaches like ReAct \\cite{xu2023767}. It demonstrates that a more comprehensive rectification (suppressing both low and high, amplifying intermediate) leads to superior performance.\n    *   **Potential Impact on Future Research:** The theoretical derivation of `g*` and the empirical success of VRA/VRA+ open new avenues for research into designing more effective and theoretically grounded activation functions for OOD detection. It encourages exploring more sophisticated functional approximations of `g*` and potentially integrating density estimation techniques to better estimate `pin` and `pout` for even higher performance. The compatibility with existing scoring functions also suggests its potential as a foundational component for future OOD detection systems.",
      "intriguing_abstract": "Deep learning models often exhibit dangerous overconfidence when encountering Out-of-Distribution (OOD) data, posing a critical challenge for reliable AI in high-stakes applications like autonomous driving and medical diagnosis. Current post-hoc OOD detection strategies, while practical, largely rely on heuristic activation rectification, leaving the question of optimality unanswered.\n\nThis paper presents a groundbreaking theoretical framework, leveraging the **variational method**, to derive the *optimal* **activation function** for maximizing the separation between in-distribution (ID) and OOD data. Our analysis reveals that optimal rectification necessitates not only suppressing abnormally high activations (as in methods like **ReAct**) but also suppressing abnormally low ones and, crucially, amplifying intermediate activations. Based on these profound insights, we introduce **Variational Rectified Activation (VRA)** and its enhanced variant, **VRA+**. These novel **piecewise functions** generalize existing rectification techniques, employing **adaptive thresholds** to dynamically adjust activations. Extensive experiments across diverse benchmarks demonstrate that VRA-based methods consistently achieve **state-of-the-art** performance in **post-hoc OOD detection**, significantly improving metrics like **FPR95** and **AUROC**. VRA's plug-and-play compatibility and superior performance underscore its potential to fundamentally enhance the safety and trustworthiness of machine learning systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "model overconfidence reduction",
        "variational method",
        "optimal activation function",
        "theoretical derivation",
        "generalized rectification",
        "Variational Rectified Activation (VRA)",
        "VRA+",
        "adaptive thresholds",
        "suppressing low/high activations",
        "amplifying intermediate activations",
        "post-hoc OOD detection strategies",
        "state-of-the-art performance",
        "plug-and-play module"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/f911f3b51fcc88f2240def8f38ed8dff1da2e605.pdf",
      "citation_key": "xu2023767",
      "metadata": {
        "title": "VRA: Variational Rectified Activation for Out-of-distribution Detection",
        "authors": [
          "Ming Xu",
          "Zheng Lian",
          "B. Liu",
          "Jianhua Tao"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection is critical to building reliable machine learning systems in the open world. Researchers have proposed various strategies to reduce model overconfidence on OOD data. Among them, ReAct is a typical and effective technique to deal with model overconfidence, which truncates high activations to increase the gap between in-distribution and OOD. Despite its promising results, is this technique the best choice for widening the gap? To answer this question, we leverage the variational method to find the optimal operation and verify the necessity of suppressing abnormally low and high activations and amplifying intermediate activations in OOD detection, rather than focusing only on high activations like ReAct. This motivates us to propose a novel technique called ``Variational Rectified Activation (VRA)'', which simulates these suppression and amplification operations using piecewise functions. Experimental results on multiple benchmark datasets demonstrate that our method outperforms existing post-hoc strategies. Meanwhile, VRA is compatible with different scoring functions and network architectures. \\textcolor[rgb]{0.93,0.0,0.47}{Our code can be found in Supplementary Material}.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/f911f3b51fcc88f2240def8f38ed8dff1da2e605.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 13,
        "score": 6.5,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the critical problem of Out-of-Distribution (OOD) detection in machine learning systems. Specifically, it aims to reduce model overconfidence when encountering data from distributions not seen during training.\n    *   **Importance and Challenge:** OOD detection is crucial for building reliable and safe AI systems, especially in high-stakes applications like autonomous driving and medical diagnosis, where models tend to make overconfident predictions on unfamiliar inputs. The challenge lies in effectively distinguishing in-distribution (ID) data from unknown OOD data, particularly with post-hoc strategies that do not require retraining the model.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work is positioned within post-hoc OOD detection strategies, which are favored for their ease of implementation compared to methods requiring training-time regularization or external OOD samples.\n    *   **Limitations of Previous Solutions:** The paper specifically highlights ReAct \\cite{xu2023767}, a typical and effective post-hoc technique that truncates abnormally high activations to increase the gap between ID and OOD. The core limitation identified is whether ReAct's operation (only suppressing high activations) is the *optimal* choice for maximizing this gap.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper leverages the variational method to derive an optimal activation function, `g*(z) = z + Î» * (1 - pout(z)/pin(z))`, that maximizes the gap between ID and OOD while minimizing modifications to the original activations.\n    *   **Novelty/Difference:**\n        *   **Theoretical Derivation:** Unlike heuristic approaches, the paper provides a theoretical foundation for the optimal activation function using variational calculus.\n        *   **Generalized Rectification:** The theoretical analysis reveals that the optimal operation `g*` necessitates not only suppressing abnormally high activations (as in ReAct \\cite{xu2023767}) but also suppressing abnormally low activations and amplifying intermediate activations.\n        *   **VRA (Variational Rectified Activation):** Based on these insights, the paper proposes VRA, a novel piecewise activation function that mimics these suppression and amplification operations. VRA is a generalization of ReAct \\cite{xu2023767}, allowing for truncation at both lower (`Î±`) and upper (`Î²`) thresholds.\n        *   **VRA+:** An enhanced variant, VRA+, further introduces a hyper-parameter `Î´` to control the degree of amplification for intermediate activations, moving closer to the theoretically optimal function.\n        *   **Adaptive Thresholds:** VRA employs an adaptive strategy to determine `Î±` and `Î²` based on quantiles of activations estimated on ID data, making it robust across different features.\n\n*   **4. Key Technical Contributions**\n    *   **Theoretical Insights:** Derivation of the optimal activation function `g*(z)` using the variational method, theoretically demonstrating the necessity of suppressing both abnormally low and high activations and amplifying intermediate activations for maximizing the ID-OOD gap.\n    *   **Novel Algorithms/Methods:** Introduction of Variational Rectified Activation (VRA) and its variant VRA+, which are simple yet effective post-hoc strategies implemented as piecewise functions.\n    *   **System Design/Architectural Innovations:** VRA is designed to be compatible with various existing scoring functions (e.g., MSP, Energy, ODIN) and network architectures (e.g., DenseNet, ResNet), making it a versatile plug-and-play module.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were performed on multiple benchmark datasets: CIFAR-10/100 (ID) with six OOD datasets (Textures, SVHN, Places365, LSUN-Crop/Resize, iSUN), and ImageNet (ID) with four OOD datasets (iNaturalist, SUN, Places, Textures).\n    *   **Key Performance Metrics:** FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve).\n    *   **Comparison Results:**\n        *   VRA-based methods consistently achieved Top3 performance and often set new state-of-the-art records among existing post-hoc strategies.\n        *   VRA+ generally outperformed VRA, supporting the benefit of amplifying intermediate activations.\n        *   VRA-based methods demonstrated superior performance even compared to some methods requiring training (e.g., MOS, VOS), despite being post-hoc.\n        *   VRA showed strong compatibility, improving performance across different scoring functions (MSP, Energy, ODIN).\n        *   An \"upper bound analysis\" with VRA-True (using ideal `pin` and `pout` estimates) achieved near-perfect results, validating the theoretical optimal function's potential.\n        *   Parameter sensitivity analysis highlighted the importance of proper threshold selection, and the adaptive adjustment strategy was shown to be more effective than fixed thresholds.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The practical implementation of VRA relies on approximating the optimal function `g*` with piecewise functions, as estimating the exact `pin` and `pout` for unknown OOD distributions remains challenging. The current VRA and VRA+ are approximations, and further research into better functional forms for `g*` is suggested.\n    *   **Scope of Applicability:** VRA is a post-hoc strategy, meaning it operates on pre-trained models without requiring additional training. It is compatible with various scoring functions and network architectures, making it broadly applicable to existing classification models for OOD detection.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:** The paper significantly advances the technical state-of-the-art in post-hoc OOD detection by providing a theoretical foundation for optimal activation rectification, moving beyond heuristic approaches like ReAct \\cite{xu2023767}. It demonstrates that a more comprehensive rectification (suppressing both low and high, amplifying intermediate) leads to superior performance.\n    *   **Potential Impact on Future Research:** The theoretical derivation of `g*` and the empirical success of VRA/VRA+ open new avenues for research into designing more effective and theoretically grounded activation functions for OOD detection. It encourages exploring more sophisticated functional approximations of `g*` and potentially integrating density estimation techniques to better estimate `pin` and `pout` for even higher performance. The compatibility with existing scoring functions also suggests its potential as a foundational component for future OOD detection systems.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "model overconfidence reduction",
          "variational method",
          "optimal activation function",
          "theoretical derivation",
          "generalized rectification",
          "Variational Rectified Activation (VRA)",
          "VRA+",
          "adaptive thresholds",
          "suppressing low/high activations",
          "amplifying intermediate activations",
          "post-hoc OOD detection strategies",
          "state-of-the-art performance",
          "plug-and-play module"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"this motivates us to **propose a novel technique called â€œvariational rectified activation (vra)â€**\".\n*   it describes the mechanism of this new technique: \"which simulates these suppression and amplification operations using piecewise functions.\"\n*   it mentions \"experimental results on multiple benchmark datasets demonstrate that our method outperforms existing post-hoc strategies,\" indicating the validation of the proposed method.\n*   the introduction sets up a technical problem (ood detection, limitations of existing methods like react) which the proposed solution (vra) aims to address.\n\nthese points strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems.\n\n**classification: technical**"
      },
      "file_name": "f911f3b51fcc88f2240def8f38ed8dff1da2e605.pdf"
    },
    {
      "success": true,
      "doc_id": "5102d8de2baf917117eac115c378bfc2",
      "summary": "Here's a focused summary of the paper \"Average of Pruning: Improving Performance and Stability of Out-of-Distribution Detection\" by Cheng et al. for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the unstable behavior of Out-of-Distribution (OOD) detection performance during neural network training. It identifies two key issues: 1) OOD detection performance can decrease (overfit) even when training error is near zero, and 2) performance varies sharply (instability) in the final stages of training \\cite{cheng20233yi}.\n    *   **Importance and Challenge:** OOD detection is crucial for deploying neural networks reliably in open-world, safety-critical applications (e.g., autonomous driving). The observed overfit-like behavior and instability make the choice of the final model unreliable and significantly harm OOD detection performance, a phenomenon largely neglected by previous research \\cite{cheng20233yi}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon existing OOD detection methods (e.g., MSP, ODIN, Mahalanobis, Energy score, Outlier Exposure) by focusing on the training dynamics rather than solely on post-hoc scoring functions or architectural improvements \\cite{cheng20233yi}. It also leverages established techniques like model averaging (e.g., SWA) and network pruning (e.g., LTH), but applies them specifically to address OOD detection challenges.\n    *   **Limitations of Previous Solutions:** Prior methods have largely overlooked the \"chaotic behavior of OOD detection along the optimization trajectory during training,\" failing to analyze how OOD metrics (like AUROC) evolve and fluctuate during the training process \\cite{cheng20233yi}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes **Average of Pruning (AoP)**, a method combining model averaging and network pruning to mitigate the identified instability and overfitting in OOD detection \\cite{cheng20233yi}.\n        *   **Model Averaging (MA):** Utilizes an exponential moving average of model parameters (similar to Stochastic Weight Averaging, SWA) to achieve stable OOD detection performance by smoothing the loss landscape and finding wider optima \\cite{cheng20233yi}.\n        *   **Pruning:** Employs a global sparsity constraint, specifically the Lottery Ticket Hypothesis (LTH) with weight rewinding, to eliminate overfitting. This is motivated by the idea that overparameterized models learn redundant and noisy features that cause overlap between in-distribution (ID) and OOD data, and pruning helps remove these \\cite{cheng20233yi}.\n    *   **Novelty:** The novelty lies in systematically identifying and characterizing the instability and overfitting issues in OOD detection during training, and then proposing a combined, pluggable solution (AoP) that leverages model averaging for stability and pruning for overfitting reduction. The theoretical analysis connecting sparsity to OOD detection risk is also a novel contribution \\cite{cheng20233yi}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Uncovering and empirically verifying the phenomena of instability and overfitting in OOD detection performance during neural network training \\cite{cheng20233yi}.\n        *   Proposing **Average of Pruning (AoP)**, a novel combined approach of model averaging and pruning, specifically designed to improve OOD detection stability and performance \\cite{cheng20233yi}.\n        *   Demonstrating that model averaging effectively stabilizes OOD detection by leading to flatter loss landscapes and wider optima \\cite{cheng20233yi}.\n        *   Showing that network pruning (via LTH) alleviates OOD detection overfitting by reducing the learning of noisy and redundant features \\cite{cheng20233yi}.\n    *   **Theoretical Insights:**\n        *   A theoretical analysis using a linear model demonstrates how an increasing number of \"common features\" (features shared between ID and OOD data) can significantly increase OOD detection risk while only slowly decreasing ID classification risk \\cite{cheng20233yi}.\n        *   Theoretical proof that LASSO regularization can effectively reduce OOD detection risk by promoting sparsity and eliminating these common features in a linear model setting \\cite{cheng20233yi}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Extensive empirical analysis of AUROC curves during training to visualize and confirm the overfitting and instability phenomena \\cite{cheng20233yi}.\n        *   Visualization of AUROC and FPR95 landscapes under weight perturbations, demonstrating that model averaging leads to wider, more stable optima \\cite{cheng20233yi}.\n        *   Experiments on WideResNet-28 with varying width factors to show that overparameterization exacerbates OOD detection overfitting \\cite{cheng20233yi}.\n        *   Comprehensive experiments across various in-distribution datasets (CIFAR-10, CIFAR-100), OOD datasets (LSUN, iSUN, Places365, Textures, SVHN, TinyImageNet), and network architectures (ResNet-18, WideResNet-28) \\cite{cheng20233yi}.\n    *   **Key Performance Metrics and Comparison Results:** The method is evaluated using standard OOD detection metrics: AUROC (Area Under Receiver Operating Characteristic), AUPR (Area Under Precision-Recall curve), FPR95 (False Positive Rate at 95% True Positive Rate), and ID classification accuracy \\cite{cheng20233yi}. AoP consistently achieves significant improvements over strong baseline OOD detection methods (e.g., MSP, ODIN, Energy) across all evaluated benchmarks, demonstrating its effectiveness and robustness \\cite{cheng20233yi}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The theoretical analysis for pruning's effect is based on a simplified linear model, which provides intuition but is an approximation for complex deep neural networks \\cite{cheng20233yi}. While LTH is used for pruning, the generalizability to all pruning methods is implied rather than explicitly proven.\n    *   **Scope of Applicability:** AoP is designed as a \"simple module readily pluggable into any existing method in OOD detection\" \\cite{cheng20233yi}. This suggests broad applicability to various OOD scoring functions and training setups, enhancing their performance and stability.\n\n*   **7. Technical Significance**\n    *   **Advance State-of-the-Art:** This paper significantly advances the technical state-of-the-art by being the first to systematically analyze and address the critical issues of instability and overfitting in OOD detection during training \\cite{cheng20233yi}. It provides a practical and effective solution (AoP) that consistently boosts OOD detection performance and reliability across diverse settings \\cite{cheng20233yi}.\n    *   **Potential Impact on Future Research:** The work opens new avenues for research into the training dynamics of OOD detection models, encouraging a shift from purely post-hoc analysis to understanding and optimizing the entire training trajectory \\cite{cheng20233yi}. It also highlights an additional, crucial benefit of network pruning (improved OOD detection) beyond just model compression, potentially influencing future model design and training strategies for robust AI systems \\cite{cheng20233yi}.",
      "intriguing_abstract": "Reliable Out-of-Distribution (OOD) detection is paramount for deploying neural networks in safety-critical applications, yet its training dynamics remain surprisingly underexplored. We uncover a critical, overlooked phenomenon: OOD detection performance exhibits significant instability and overfitting during neural network training, leading to unreliable model selection and suboptimal results, even as in-distribution accuracy improves. This \"chaotic behavior\" of OOD metrics like AUROC along the optimization trajectory poses a fundamental challenge to robust AI.\n\nTo address this, we introduce **Average of Pruning (AoP)**, a novel, pluggable method that synergistically combines model averaging and network pruning. Our theoretical and empirical analysis demonstrates that model averaging effectively stabilizes OOD detection by navigating to wider, flatter optima in the loss landscape. Concurrently, pruning, inspired by the Lottery Ticket Hypothesis, mitigates overfitting by eliminating redundant and noisy features that blur the distinction between in-distribution and OOD data. AoP consistently achieves substantial improvements in OOD detection performance (AUROC, FPR95) and stability across diverse benchmarks and architectures, significantly advancing the state-of-the-art. This work not only provides a practical solution but also opens new avenues for understanding and optimizing the training trajectories of robust OOD detectors.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "instability and overfitting",
        "neural network training dynamics",
        "Average of Pruning (AoP)",
        "model averaging",
        "network pruning",
        "Lottery Ticket Hypothesis (LTH)",
        "sparsity",
        "OOD detection risk",
        "loss landscape",
        "wider optima",
        "overparameterization",
        "AUROC",
        "FPR95"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/955dd252793ea3f07de81b2f61165b6a822e07d5.pdf",
      "citation_key": "cheng20233yi",
      "metadata": {
        "title": "Average of Pruning: Improving Performance and Stability of Out-of-Distribution Detection",
        "authors": [
          "Zhen Cheng",
          "Fei Zhu",
          "Xu-Yao Zhang",
          "Cheng-Lin Liu"
        ],
        "published_date": "2023",
        "abstract": "Detecting out-of-distribution (OOD) inputs has been a critical issue for neural networks in the open world. However, the unstable behavior of OOD detection along the optimization trajectory during training has not been explored clearly. In this article, we first find the performance of OOD detection suffers from overfitting and instability during training: 1) the performance could decrease when the training error is near zero and 2) the performance would vary sharply in the final stage of training. Based on our findings, we propose an average of pruning (AoP), consisting of model averaging (MA) and pruning, to mitigate the unstable behaviors. Specifically, MA can help achieve a stable performance by smoothing the landscape, and pruning is theoretically and empirically verified to eliminate overfitting by avoiding redundant features. Comprehensive experiments on various datasets and architectures are conducted to verify the effectiveness of our method.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/955dd252793ea3f07de81b2f61165b6a822e07d5.pdf",
        "venue": "IEEE Transactions on Neural Networks and Learning Systems",
        "citationCount": 13,
        "score": 6.5,
        "summary": "Here's a focused summary of the paper \"Average of Pruning: Improving Performance and Stability of Out-of-Distribution Detection\" by Cheng et al. for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the unstable behavior of Out-of-Distribution (OOD) detection performance during neural network training. It identifies two key issues: 1) OOD detection performance can decrease (overfit) even when training error is near zero, and 2) performance varies sharply (instability) in the final stages of training \\cite{cheng20233yi}.\n    *   **Importance and Challenge:** OOD detection is crucial for deploying neural networks reliably in open-world, safety-critical applications (e.g., autonomous driving). The observed overfit-like behavior and instability make the choice of the final model unreliable and significantly harm OOD detection performance, a phenomenon largely neglected by previous research \\cite{cheng20233yi}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon existing OOD detection methods (e.g., MSP, ODIN, Mahalanobis, Energy score, Outlier Exposure) by focusing on the training dynamics rather than solely on post-hoc scoring functions or architectural improvements \\cite{cheng20233yi}. It also leverages established techniques like model averaging (e.g., SWA) and network pruning (e.g., LTH), but applies them specifically to address OOD detection challenges.\n    *   **Limitations of Previous Solutions:** Prior methods have largely overlooked the \"chaotic behavior of OOD detection along the optimization trajectory during training,\" failing to analyze how OOD metrics (like AUROC) evolve and fluctuate during the training process \\cite{cheng20233yi}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes **Average of Pruning (AoP)**, a method combining model averaging and network pruning to mitigate the identified instability and overfitting in OOD detection \\cite{cheng20233yi}.\n        *   **Model Averaging (MA):** Utilizes an exponential moving average of model parameters (similar to Stochastic Weight Averaging, SWA) to achieve stable OOD detection performance by smoothing the loss landscape and finding wider optima \\cite{cheng20233yi}.\n        *   **Pruning:** Employs a global sparsity constraint, specifically the Lottery Ticket Hypothesis (LTH) with weight rewinding, to eliminate overfitting. This is motivated by the idea that overparameterized models learn redundant and noisy features that cause overlap between in-distribution (ID) and OOD data, and pruning helps remove these \\cite{cheng20233yi}.\n    *   **Novelty:** The novelty lies in systematically identifying and characterizing the instability and overfitting issues in OOD detection during training, and then proposing a combined, pluggable solution (AoP) that leverages model averaging for stability and pruning for overfitting reduction. The theoretical analysis connecting sparsity to OOD detection risk is also a novel contribution \\cite{cheng20233yi}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Uncovering and empirically verifying the phenomena of instability and overfitting in OOD detection performance during neural network training \\cite{cheng20233yi}.\n        *   Proposing **Average of Pruning (AoP)**, a novel combined approach of model averaging and pruning, specifically designed to improve OOD detection stability and performance \\cite{cheng20233yi}.\n        *   Demonstrating that model averaging effectively stabilizes OOD detection by leading to flatter loss landscapes and wider optima \\cite{cheng20233yi}.\n        *   Showing that network pruning (via LTH) alleviates OOD detection overfitting by reducing the learning of noisy and redundant features \\cite{cheng20233yi}.\n    *   **Theoretical Insights:**\n        *   A theoretical analysis using a linear model demonstrates how an increasing number of \"common features\" (features shared between ID and OOD data) can significantly increase OOD detection risk while only slowly decreasing ID classification risk \\cite{cheng20233yi}.\n        *   Theoretical proof that LASSO regularization can effectively reduce OOD detection risk by promoting sparsity and eliminating these common features in a linear model setting \\cite{cheng20233yi}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Extensive empirical analysis of AUROC curves during training to visualize and confirm the overfitting and instability phenomena \\cite{cheng20233yi}.\n        *   Visualization of AUROC and FPR95 landscapes under weight perturbations, demonstrating that model averaging leads to wider, more stable optima \\cite{cheng20233yi}.\n        *   Experiments on WideResNet-28 with varying width factors to show that overparameterization exacerbates OOD detection overfitting \\cite{cheng20233yi}.\n        *   Comprehensive experiments across various in-distribution datasets (CIFAR-10, CIFAR-100), OOD datasets (LSUN, iSUN, Places365, Textures, SVHN, TinyImageNet), and network architectures (ResNet-18, WideResNet-28) \\cite{cheng20233yi}.\n    *   **Key Performance Metrics and Comparison Results:** The method is evaluated using standard OOD detection metrics: AUROC (Area Under Receiver Operating Characteristic), AUPR (Area Under Precision-Recall curve), FPR95 (False Positive Rate at 95% True Positive Rate), and ID classification accuracy \\cite{cheng20233yi}. AoP consistently achieves significant improvements over strong baseline OOD detection methods (e.g., MSP, ODIN, Energy) across all evaluated benchmarks, demonstrating its effectiveness and robustness \\cite{cheng20233yi}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The theoretical analysis for pruning's effect is based on a simplified linear model, which provides intuition but is an approximation for complex deep neural networks \\cite{cheng20233yi}. While LTH is used for pruning, the generalizability to all pruning methods is implied rather than explicitly proven.\n    *   **Scope of Applicability:** AoP is designed as a \"simple module readily pluggable into any existing method in OOD detection\" \\cite{cheng20233yi}. This suggests broad applicability to various OOD scoring functions and training setups, enhancing their performance and stability.\n\n*   **7. Technical Significance**\n    *   **Advance State-of-the-Art:** This paper significantly advances the technical state-of-the-art by being the first to systematically analyze and address the critical issues of instability and overfitting in OOD detection during training \\cite{cheng20233yi}. It provides a practical and effective solution (AoP) that consistently boosts OOD detection performance and reliability across diverse settings \\cite{cheng20233yi}.\n    *   **Potential Impact on Future Research:** The work opens new avenues for research into the training dynamics of OOD detection models, encouraging a shift from purely post-hoc analysis to understanding and optimizing the entire training trajectory \\cite{cheng20233yi}. It also highlights an additional, crucial benefit of network pruning (improved OOD detection) beyond just model compression, potentially influencing future model design and training strategies for robust AI systems \\cite{cheng20233yi}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "instability and overfitting",
          "neural network training dynamics",
          "Average of Pruning (AoP)",
          "model averaging",
          "network pruning",
          "Lottery Ticket Hypothesis (LTH)",
          "sparsity",
          "OOD detection risk",
          "loss landscape",
          "wider optima",
          "overparameterization",
          "AUROC",
          "FPR95"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we propose average of pruning (aop), consisting of model averaging and pruning, to mitigate the unstable behaviors.\" it then mentions \"comprehensive experiments... are conducted to verify the effectiveness of our method.\"\n*   the introduction sets up a technical problem (ood detection vulnerability and instability) and discusses existing \"scoring functions\" and \"methods.\"\n\nthis clearly indicates the paper's primary contribution is the development and presentation of a new method or system (aop) to solve a technical problem. while it includes empirical validation, the core focus is on the proposed solution.\n\ntherefore, this paper is best classified as **technical**."
      },
      "file_name": "955dd252793ea3f07de81b2f61165b6a822e07d5.pdf"
    },
    {
      "success": true,
      "doc_id": "bd48ebac514259547cf14fd0695bf63a",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   Deep Learning (DL) models perform unreliably when encountering out-of-distribution (OOD) data, which is a significant concern in critical applications like medical imaging.\n    *   The paper specifically addresses the poorly explored area of OOD detection in 3D medical image segmentation.\n    *   This problem is crucial because OOD data (e.g., changes in population, acquisition parameters, or new modalities) can lead to erroneous predictions, compromising patient safety and hindering the safe clinical deployment of DL models.\n    *   Existing research in 3D OOD detection is limited by a lack of correctly designed datasets and benchmarks, often relying on private data, simulating unrealistic anomalies, or focusing on narrow distribution shifts or method types \\cite{vasiliuk20233w9}.\n\n*   **2. Related Work & Positioning**\n    *   OOD detection is a well-researched area in natural images and 2D medical images, with established benchmarks. This work extends these efforts to the more challenging domain of 3D medical images.\n    *   The paper positions itself by addressing the gaps in prior 3D OOD detection studies, which often used private data, simulated synthetic anomalies, or were limited to single distribution shifts or specific method types (e.g., uncertainty estimation or unsupervised anomaly detection) \\cite{vasiliuk20233w9}.\n    *   It explicitly excludes reconstruction-based anomaly detection methods (e.g., auto-encoders) due to their documented inferior performance compared to self-supervised learning approaches in similar contexts \\cite{vasiliuk20233w9}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Evaluated Methods:** `\\cite{vasiliuk20233w9}` evaluates six state-of-the-art OOD detection methods adapted for 3D medical image segmentation: Entropy, Deep Ensemble, Monte-Carlo Dropout (MCD), Singular Value Decomposition (SVD) on network features, Generalized ODIN (G-ODIN), and MOOD-1 (a top-performing solution from the MOOD 2022 challenge).\n    *   **Novel Benchmark Design:** The authors design and release a novel, diverse benchmark for 3D medical image OOD detection. This benchmark uses publicly available CT and MRI in-distribution (ID) datasets with segmentation tasks and includes diverse OOD datasets simulating clinically occurring anomaly sources (scanner, patient population, anatomical region changes) and synthetic artifacts (e.g., image noise, elastic transforms, K-space noise, motion).\n    *   **Intensity Histogram Features (IHF):** `\\cite{vasiliuk20233w9}` proposes a simple, unsupervised, and computationally negligible method called Intensity Histogram Features (IHF). IHF uses image intensity histograms as embeddings, hypothesizing that domain-specific information can be extracted directly from the raw image (analogous to the \"zeroth network layer\"). OOD scores are derived from the distance of a sample's histogram to the ID histogram distribution.\n\n*   **4. Key Technical Contributions**\n    *   **Demonstration of Limitations:** `\\cite{vasiliuk20233w9}` provides a comprehensive demonstration of the severe limitations of existing OOD detection methods when applied to 3D medical images.\n    *   **Novel Benchmark:** Design and release of a publicly available benchmark for 3D medical image OOD detection, which includes diverse, clinically relevant challenges and a downstream segmentation task.\n    *   **Novel Baseline Method (IHF):** Introduction of IHF, a simple, unsupervised, and highly effective histogram-based method proposed as a solid baseline for future OOD detection research in 3D medical imaging.\n    *   **Practical Criteria:** Formulation of practical criteria to test the generalization capabilities of OOD detection methods beyond the proposed benchmark.\n\n*   **5. Experimental Validation**\n    *   **Experiments:** The study conducted extensive experiments on the newly designed benchmark, which includes 6 CT challenges and 7 MRI challenges, simulating various real-world and synthetic OOD scenarios.\n    *   **Metrics:** Performance was primarily measured using the mean False Positive Rate (FPR) at 95% True Positive Rate (TPR), where lower FPR indicates better performance.\n    *   **Key Results:**\n        *   Methods not specifically designed for segmentation (Entropy, Ensemble, MCD, G-ODIN) performed poorly, with the best mean FPR of 0.59 (close to random guessing's 0.95 FPR).\n        *   Segmentation-dedicated methods (SVD, MOOD-1) showed improved but still suboptimal performance, with the best mean FPR of 0.31.\n        *   The proposed **Intensity Histogram Features (IHF)** method significantly outperformed all evaluated DL-based methods, achieving a mean FPR of 0.25.\n        *   IHF achieved 0 FPR in multiple challenges, indicating that simple image intensity histograms can effectively detect certain distribution shifts that DL-based methods often miss.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations:** The study focuses on OOD detection for *segmentation* tasks in 3D medical images. While the benchmark is diverse, it represents a curated set of OOD challenges, and generalization to entirely unforeseen anomalies remains an open problem.\n    *   **Scope of Applicability:** The findings and proposed benchmark are highly relevant for researchers and developers working on robust and safe DL models for 3D medical image analysis, particularly in segmentation.\n\n*   **7. Technical Significance**\n    *   `\\cite{vasiliuk20233w9}` significantly advances the technical state-of-the-art by providing the first comprehensive evaluation of OOD detection methods for 3D medical image segmentation, revealing the substantial limitations of current DL-based approaches.\n    *   The release of a robust, publicly available benchmark addresses a critical gap, enabling standardized evaluation and fostering the development of more effective OOD detection algorithms.\n    *   The IHF method demonstrates that simple, computationally efficient approaches can serve as powerful baselines and even outperform complex DL models for certain OOD shifts, suggesting that current DL methods may not be fully leveraging all available domain-specific information.\n    *   This work has the potential to impact future research by guiding the development of more robust, generalizable, and clinically reliable DL models for medical imaging, ultimately contributing to safer AI deployment in healthcare.",
      "intriguing_abstract": "The unreliable performance of Deep Learning models on Out-of-Distribution (OOD) data poses a critical threat to patient safety in medical imaging, particularly in 3D segmentation tasks where robust OOD detection remains poorly explored. We address this crucial gap by introducing the first comprehensive, publicly available benchmark for 3D medical image OOD detection, featuring diverse, clinically relevant distribution shifts and synthetic anomalies. Our extensive evaluation of six state-of-the-art OOD detection methods reveals their severe limitations, with even dedicated segmentation approaches yielding suboptimal performance (mean FPR 0.31). Strikingly, we propose Intensity Histogram Features (IHF), a simple, unsupervised, and computationally negligible method that leverages raw image intensity histograms. IHF dramatically outperforms all evaluated Deep Learning-based methods, achieving a superior mean FPR of 0.25 and even perfect detection in several challenges. This work not only provides a much-needed standardized benchmark but also demonstrates that fundamental image properties can surprisingly surpass complex models for OOD detection, challenging current paradigms and paving the way for more robust and clinically deployable AI in healthcare.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "3D medical image segmentation",
        "Deep Learning reliability",
        "novel OOD benchmark",
        "Intensity Histogram Features (IHF)",
        "unsupervised histogram-based method",
        "state-of-the-art OOD methods",
        "clinically relevant anomalies",
        "False Positive Rate (FPR)",
        "limitations of DL models",
        "publicly available benchmark",
        "clinical deployment of AI"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/65e63d2d9168fa3cca6cd8bc083612b5f6cecc84.pdf",
      "citation_key": "vasiliuk20233w9",
      "metadata": {
        "title": "Limitations of Out-of-Distribution Detection in 3D Medical Image Segmentation",
        "authors": [
          "Anton Vasiliuk",
          "Daria Frolova",
          "M. Belyaev",
          "B. Shirokikh"
        ],
        "published_date": "2023",
        "abstract": "Deep learning models perform unreliably when the data come from a distribution different from the training one. In critical applications such as medical imaging, out-of-distribution (OOD) detection methods help to identify such data samples, preventing erroneous predictions. In this paper, we further investigate OOD detection effectiveness when applied to 3D medical image segmentation. We designed several OOD challenges representing clinically occurring cases and found that none of the methods achieved acceptable performance. Methods not dedicated to segmentation severely failed to perform in the designed setups; the best mean false-positive rate at a 95% true-positive rate (FPR) was 0.59. Segmentation-dedicated methods still achieved suboptimal performance, with the best mean FPR being 0.31 (lower is better). To indicate this suboptimality, we developed a simple method called Intensity Histogram Features (IHF), which performed comparably or better in the same challenges, with a mean FPR of 0.25. Our findings highlight the limitations of the existing OOD detection methods with 3D medical images and present a promising avenue for improving them. To facilitate research in this area, we release the designed challenges as a publicly available benchmark and formulate practical criteria to test the generalization of OOD detection beyond the suggested benchmark. We also propose IHF as a solid baseline to contest emerging methods.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/65e63d2d9168fa3cca6cd8bc083612b5f6cecc84.pdf",
        "venue": "Journal of Imaging",
        "citationCount": 13,
        "score": 6.5,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   Deep Learning (DL) models perform unreliably when encountering out-of-distribution (OOD) data, which is a significant concern in critical applications like medical imaging.\n    *   The paper specifically addresses the poorly explored area of OOD detection in 3D medical image segmentation.\n    *   This problem is crucial because OOD data (e.g., changes in population, acquisition parameters, or new modalities) can lead to erroneous predictions, compromising patient safety and hindering the safe clinical deployment of DL models.\n    *   Existing research in 3D OOD detection is limited by a lack of correctly designed datasets and benchmarks, often relying on private data, simulating unrealistic anomalies, or focusing on narrow distribution shifts or method types \\cite{vasiliuk20233w9}.\n\n*   **2. Related Work & Positioning**\n    *   OOD detection is a well-researched area in natural images and 2D medical images, with established benchmarks. This work extends these efforts to the more challenging domain of 3D medical images.\n    *   The paper positions itself by addressing the gaps in prior 3D OOD detection studies, which often used private data, simulated synthetic anomalies, or were limited to single distribution shifts or specific method types (e.g., uncertainty estimation or unsupervised anomaly detection) \\cite{vasiliuk20233w9}.\n    *   It explicitly excludes reconstruction-based anomaly detection methods (e.g., auto-encoders) due to their documented inferior performance compared to self-supervised learning approaches in similar contexts \\cite{vasiliuk20233w9}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Evaluated Methods:** `\\cite{vasiliuk20233w9}` evaluates six state-of-the-art OOD detection methods adapted for 3D medical image segmentation: Entropy, Deep Ensemble, Monte-Carlo Dropout (MCD), Singular Value Decomposition (SVD) on network features, Generalized ODIN (G-ODIN), and MOOD-1 (a top-performing solution from the MOOD 2022 challenge).\n    *   **Novel Benchmark Design:** The authors design and release a novel, diverse benchmark for 3D medical image OOD detection. This benchmark uses publicly available CT and MRI in-distribution (ID) datasets with segmentation tasks and includes diverse OOD datasets simulating clinically occurring anomaly sources (scanner, patient population, anatomical region changes) and synthetic artifacts (e.g., image noise, elastic transforms, K-space noise, motion).\n    *   **Intensity Histogram Features (IHF):** `\\cite{vasiliuk20233w9}` proposes a simple, unsupervised, and computationally negligible method called Intensity Histogram Features (IHF). IHF uses image intensity histograms as embeddings, hypothesizing that domain-specific information can be extracted directly from the raw image (analogous to the \"zeroth network layer\"). OOD scores are derived from the distance of a sample's histogram to the ID histogram distribution.\n\n*   **4. Key Technical Contributions**\n    *   **Demonstration of Limitations:** `\\cite{vasiliuk20233w9}` provides a comprehensive demonstration of the severe limitations of existing OOD detection methods when applied to 3D medical images.\n    *   **Novel Benchmark:** Design and release of a publicly available benchmark for 3D medical image OOD detection, which includes diverse, clinically relevant challenges and a downstream segmentation task.\n    *   **Novel Baseline Method (IHF):** Introduction of IHF, a simple, unsupervised, and highly effective histogram-based method proposed as a solid baseline for future OOD detection research in 3D medical imaging.\n    *   **Practical Criteria:** Formulation of practical criteria to test the generalization capabilities of OOD detection methods beyond the proposed benchmark.\n\n*   **5. Experimental Validation**\n    *   **Experiments:** The study conducted extensive experiments on the newly designed benchmark, which includes 6 CT challenges and 7 MRI challenges, simulating various real-world and synthetic OOD scenarios.\n    *   **Metrics:** Performance was primarily measured using the mean False Positive Rate (FPR) at 95% True Positive Rate (TPR), where lower FPR indicates better performance.\n    *   **Key Results:**\n        *   Methods not specifically designed for segmentation (Entropy, Ensemble, MCD, G-ODIN) performed poorly, with the best mean FPR of 0.59 (close to random guessing's 0.95 FPR).\n        *   Segmentation-dedicated methods (SVD, MOOD-1) showed improved but still suboptimal performance, with the best mean FPR of 0.31.\n        *   The proposed **Intensity Histogram Features (IHF)** method significantly outperformed all evaluated DL-based methods, achieving a mean FPR of 0.25.\n        *   IHF achieved 0 FPR in multiple challenges, indicating that simple image intensity histograms can effectively detect certain distribution shifts that DL-based methods often miss.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations:** The study focuses on OOD detection for *segmentation* tasks in 3D medical images. While the benchmark is diverse, it represents a curated set of OOD challenges, and generalization to entirely unforeseen anomalies remains an open problem.\n    *   **Scope of Applicability:** The findings and proposed benchmark are highly relevant for researchers and developers working on robust and safe DL models for 3D medical image analysis, particularly in segmentation.\n\n*   **7. Technical Significance**\n    *   `\\cite{vasiliuk20233w9}` significantly advances the technical state-of-the-art by providing the first comprehensive evaluation of OOD detection methods for 3D medical image segmentation, revealing the substantial limitations of current DL-based approaches.\n    *   The release of a robust, publicly available benchmark addresses a critical gap, enabling standardized evaluation and fostering the development of more effective OOD detection algorithms.\n    *   The IHF method demonstrates that simple, computationally efficient approaches can serve as powerful baselines and even outperform complex DL models for certain OOD shifts, suggesting that current DL methods may not be fully leveraging all available domain-specific information.\n    *   This work has the potential to impact future research by guiding the development of more robust, generalizable, and clinically reliable DL models for medical imaging, ultimately contributing to safer AI deployment in healthcare.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "3D medical image segmentation",
          "Deep Learning reliability",
          "novel OOD benchmark",
          "Intensity Histogram Features (IHF)",
          "unsupervised histogram-based method",
          "state-of-the-art OOD methods",
          "clinically relevant anomalies",
          "False Positive Rate (FPR)",
          "limitations of DL models",
          "publicly available benchmark",
          "clinical deployment of AI"
        ],
        "paper_type": "based on the abstract and introduction, this paper is best classified as **empirical**.\n\nhere's why:\n\n*   **abstract mentions:** \"we further investigate the ood detection effectiveness,\" \"we design several ood challenges,\" \"show that none of these methods achieve acceptable performance,\" \"methods not dedicated to segmentation severely fail,\" \"segmentation-dedicated ones still achieve suboptimal performance,\" \"best mean false positive rate,\" \"our findings highlight the limitations.\" these phrases clearly indicate a data-driven study, experimentation, and the presentation of statistical findings.\n*   **introduction discusses:** \"our findings highlight the limitations of the existing ood detection methods,\" \"release the designed challenges as a publicly available benchmark,\" \"propose ihf as a solid baseline to contest the emerging methods.\" this reinforces the idea of a study that evaluates existing methods, presents findings, and offers a new baseline based on those findings.\n*   while the paper *does* \"develop a simple method called intensity histogram features (ihf),\" this development is presented within the context of an empirical investigation, primarily to \"indicate this suboptimality\" of existing methods and serve as a \"solid baseline\" for future research, rather than being the sole focus of presenting a novel algorithm. the core emphasis is on the *study* of limitations and the *findings* from experiments."
      },
      "file_name": "65e63d2d9168fa3cca6cd8bc083612b5f6cecc84.pdf"
    },
    {
      "success": true,
      "doc_id": "4443b8a98e943f6169f167f43edf7c5b",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Neural networks exhibit unreliable generalization on out-of-distribution (OOD) data, which is particularly critical in medical imaging where mispredictions can have severe clinical consequences \\cite{anthony2023slf}.\n    *   The paper addresses the challenge of developing robust OOD detection methods to act as a safeguard, informing users when input data significantly differs from training data, thereby preventing unreliable predictions and enabling safer deployment of AI in high-risk applications \\cite{anthony2023slf}.\n    *   Specifically, it investigates Mahalanobis distance, a promising but inconsistently performing OOD detection method, challenging the prevailing assumption that there is a single optimal layer or combination of layers for detecting *any* OOD pattern \\cite{anthony2023slf}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods include external models (e.g., reconstruction models, classifiers, probabilistic models) and confidence-based methods (e.g., softmax-based like MCP, MCDropout, ODIN, or latent space distance-based) \\cite{anthony2023slf}.\n    *   Mahalanobis distance is a commonly studied distance-based method, but its performance has been mixed in literature \\cite{anthony2023slf}.\n    *   Previous work explored optimal layers for Mahalanobis distance, but this paper argues that the common practice of applying it at the last hidden layer (LHL) or using a single weighted combination of layers is sub-optimal and overlooks the method's true potential \\cite{anthony2023slf}.\n\n*   **Technical Approach & Innovation**\n    *   The core method involves calculating the Mahalanobis score (DM) as the minimum Mahalanobis distance between a test input's embedding and the class centroids of the training data in the latent space \\cite{anthony2023slf}.\n    *   **Innovation 1: Layer-wise Analysis:** The paper systematically measures DM after *every* network module (convolution, BN, ReLU, pooling, etc.) to precisely identify where different OOD patterns are best detected \\cite{anthony2023slf}.\n    *   **Innovation 2: Multi-branch Mahalanobis (MBM):** Based on the finding that optimal detection layers vary, the paper proposes MBM, a novel system with *multiple OOD detectors* operating at different depths (branches, separated by downsampling operations) of the network. Each branch combines normalized Mahalanobis scores from its constituent modules \\cite{anthony2023slf}.\n    *   The approach also investigates the impact of Fast Gradient Sign Method (FGSM) perturbations and the specific benefit of using only Mahalanobis scores derived after ReLU modules \\cite{anthony2023slf}.\n\n*   **Key Technical Contributions**\n    *   **Novel Method:** Introduction of the Multi-branch Mahalanobis (MBM) framework, which significantly enhances OOD detection robustness by employing multiple depth-specific detectors \\cite{anthony2023slf}.\n    *   **Theoretical Insight:** Demonstrates empirically that the optimal network depth for Mahalanobis distance-based OOD detection is highly dependent on the specific OOD pattern, challenging the \"one-fits-all\" layer assumption \\cite{anthony2023slf}.\n    *   **Best Practices:** Identifies that the last hidden layer (LHL) is often sub-optimal for Mahalanobis OOD detection and that performance generally improves after ReLU modules \\cite{anthony2023slf}.\n    *   **Dataset Contribution:** Created a new benchmark for OOD detection in medical imaging by manually annotating pacemakers and support devices in 50% of CheXpert frontal scans \\cite{anthony2023slf}.\n\n*   **Experimental Validation**\n    *   **Synthetic Artefacts:** Experiments used ResNet18 on CheXpert, generating OOD by adding synthetic grey squares and white rings. This showed larger squares were easier to detect in earlier layers, and different artefacts peaked at different depths \\cite{anthony2023slf}.\n    *   **Real-world Artefacts:** Validated on two medical imaging OOD tasks using ResNet18 and VGG16 on CheXpert: detecting unseen pacemakers and unseen sex \\cite{anthony2023slf}.\n    *   **Metrics:** AUROC (Area Under the Receiver Operating Characteristic curve) and Balanced Accuracy were used \\cite{anthony2023slf}.\n    *   **Key Results:**\n        *   Layer-wise analysis confirmed that optimal detection depths varied for different real-world OOD patterns (e.g., pacemakers at module 51, sex at module 44 for ResNet18) and that LHL performance was poor \\cite{anthony2023slf}.\n        *   MBM (especially MBM with only ReLUs and FGSM) consistently outperformed traditional Mahalanobis (LHL, weighted combination) and other softmax-based baselines (MCP, MCDropout, Deep Ensembles, ODIN) across both ResNet18 and VGG16 for both unseen pacemaker and unseen sex OOD tasks \\cite{anthony2023slf}.\n        *   For example, MBM (only ReLUs) + FGSM achieved AUROCs of 76.8% (ResNet18) and 77.0% (VGG16) for unseen pacemakers, and 72.1% (ResNet18) and 78.0% (VGG16) for unseen sex, often surpassing even the \"optimal layer - oracle\" \\cite{anthony2023slf}.\n        *   A multi-detector MBM system with optimized thresholds achieved higher balanced accuracy (71.40%) for simultaneous detection of two OOD patterns compared to single-detector systems (67.64% and 68.14%) \\cite{anthony2023slf}.\n\n*   **Limitations & Scope**\n    *   The primary technical limitation is the challenge of determining optimal thresholds for multiple OOD detectors in complex, unpredictable real-world settings, although the paper demonstrates its theoretical feasibility \\cite{anthony2023slf}.\n    *   The scope of applicability is primarily demonstrated within medical imaging (chest X-rays) and specific OOD patterns, suggesting further validation across diverse domains and OOD types would be beneficial \\cite{anthony2023slf}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in OOD detection by fundamentally re-evaluating and improving the application of Mahalanobis distance \\cite{anthony2023slf}.\n    *   It provides crucial insights into the depth-dependency of OOD pattern detectability, leading to the more robust Multi-branch Mahalanobis (MBM) framework \\cite{anthony2023slf}.\n    *   The findings inform best practices for Mahalanobis score application, moving away from sub-optimal common implementations \\cite{anthony2023slf}.\n    *   The paper's insights and the proposed MBM framework have the potential to inspire future research into practical multi-detector OOD systems and more sophisticated thresholding strategies, ultimately leading to safer and more reliable deployment of neural networks in critical applications \\cite{anthony2023slf}.",
      "intriguing_abstract": "Neural networks' unreliable generalization on out-of-distribution (OOD) data poses severe risks, particularly in high-stakes domains like medical imaging. While Mahalanobis distance is a promising OOD detection method, its inconsistent performance has been a persistent challenge, often stemming from sub-optimal application. We fundamentally re-evaluate this approach, challenging the prevailing assumption that a single network layer or combination suffices for detecting diverse OOD patterns.\n\nOur systematic layer-wise analysis empirically reveals that the optimal network depth for Mahalanobis-based OOD detection is highly pattern-dependent, demonstrating that the Last Hidden Layer (LHL) is frequently sub-optimal. Based on this crucial insight, we introduce **Multi-branch Mahalanobis (MBM)**, a novel framework employing multiple depth-specific OOD detectors. MBM significantly outperforms traditional Mahalanobis and state-of-the-art softmax-based baselines (e.g., ODIN, MCDropout) across real-world medical imaging tasks (e.g., unseen pacemakers, sex detection on CheXpert), achieving superior AUROC scores. This work provides critical best practices for Mahalanobis score application and paves the way for more robust, multi-detector OOD systems, enhancing the safety and trustworthiness of AI deployment in critical environments.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "neural networks",
        "medical imaging",
        "Mahalanobis distance",
        "layer-wise analysis",
        "Multi-branch Mahalanobis (MBM)",
        "depth-dependent OOD detection",
        "robust generalization",
        "optimal detection layers",
        "CheXpert dataset",
        "real-world artefacts",
        "FGSM perturbations",
        "AUROC",
        "safer AI deployment"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/b723d4e9fbe81890624d11c873acb63ddf21b64b.pdf",
      "citation_key": "anthony2023slf",
      "metadata": {
        "title": "On the use of Mahalanobis distance for out-of-distribution detection with neural networks for medical imaging",
        "authors": [
          "Harry Anthony",
          "K. Kamnitsas"
        ],
        "published_date": "2023",
        "abstract": "Implementing neural networks for clinical use in medical applications necessitates the ability for the network to detect when input data differs significantly from the training data, with the aim of preventing unreliable predictions. The community has developed several methods for out-of-distribution (OOD) detection, within which distance-based approaches - such as Mahalanobis distance - have shown potential. This paper challenges the prevailing community understanding that there is an optimal layer, or combination of layers, of a neural network for applying Mahalanobis distance for detection of any OOD pattern. Using synthetic artefacts to emulate OOD patterns, this paper shows the optimum layer to apply Mahalanobis distance changes with the type of OOD pattern, showing there is no one-fits-all solution. This paper also shows that separating this OOD detector into multiple detectors at different depths of the network can enhance the robustness for detecting different OOD patterns. These insights were validated on real-world OOD tasks, training models on CheXpert chest X-rays with no support devices, then using scans with unseen pacemakers (we manually labelled 50% of CheXpert for this research) and unseen sex as OOD cases. The results inform best-practices for the use of Mahalanobis distance for OOD detection. The manually annotated pacemaker labels and the project's code are available at: https://github.com/HarryAnthony/Mahalanobis-OOD-detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b723d4e9fbe81890624d11c873acb63ddf21b64b.pdf",
        "venue": "UNSURE@MICCAI",
        "citationCount": 13,
        "score": 6.5,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Neural networks exhibit unreliable generalization on out-of-distribution (OOD) data, which is particularly critical in medical imaging where mispredictions can have severe clinical consequences \\cite{anthony2023slf}.\n    *   The paper addresses the challenge of developing robust OOD detection methods to act as a safeguard, informing users when input data significantly differs from training data, thereby preventing unreliable predictions and enabling safer deployment of AI in high-risk applications \\cite{anthony2023slf}.\n    *   Specifically, it investigates Mahalanobis distance, a promising but inconsistently performing OOD detection method, challenging the prevailing assumption that there is a single optimal layer or combination of layers for detecting *any* OOD pattern \\cite{anthony2023slf}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods include external models (e.g., reconstruction models, classifiers, probabilistic models) and confidence-based methods (e.g., softmax-based like MCP, MCDropout, ODIN, or latent space distance-based) \\cite{anthony2023slf}.\n    *   Mahalanobis distance is a commonly studied distance-based method, but its performance has been mixed in literature \\cite{anthony2023slf}.\n    *   Previous work explored optimal layers for Mahalanobis distance, but this paper argues that the common practice of applying it at the last hidden layer (LHL) or using a single weighted combination of layers is sub-optimal and overlooks the method's true potential \\cite{anthony2023slf}.\n\n*   **Technical Approach & Innovation**\n    *   The core method involves calculating the Mahalanobis score (DM) as the minimum Mahalanobis distance between a test input's embedding and the class centroids of the training data in the latent space \\cite{anthony2023slf}.\n    *   **Innovation 1: Layer-wise Analysis:** The paper systematically measures DM after *every* network module (convolution, BN, ReLU, pooling, etc.) to precisely identify where different OOD patterns are best detected \\cite{anthony2023slf}.\n    *   **Innovation 2: Multi-branch Mahalanobis (MBM):** Based on the finding that optimal detection layers vary, the paper proposes MBM, a novel system with *multiple OOD detectors* operating at different depths (branches, separated by downsampling operations) of the network. Each branch combines normalized Mahalanobis scores from its constituent modules \\cite{anthony2023slf}.\n    *   The approach also investigates the impact of Fast Gradient Sign Method (FGSM) perturbations and the specific benefit of using only Mahalanobis scores derived after ReLU modules \\cite{anthony2023slf}.\n\n*   **Key Technical Contributions**\n    *   **Novel Method:** Introduction of the Multi-branch Mahalanobis (MBM) framework, which significantly enhances OOD detection robustness by employing multiple depth-specific detectors \\cite{anthony2023slf}.\n    *   **Theoretical Insight:** Demonstrates empirically that the optimal network depth for Mahalanobis distance-based OOD detection is highly dependent on the specific OOD pattern, challenging the \"one-fits-all\" layer assumption \\cite{anthony2023slf}.\n    *   **Best Practices:** Identifies that the last hidden layer (LHL) is often sub-optimal for Mahalanobis OOD detection and that performance generally improves after ReLU modules \\cite{anthony2023slf}.\n    *   **Dataset Contribution:** Created a new benchmark for OOD detection in medical imaging by manually annotating pacemakers and support devices in 50% of CheXpert frontal scans \\cite{anthony2023slf}.\n\n*   **Experimental Validation**\n    *   **Synthetic Artefacts:** Experiments used ResNet18 on CheXpert, generating OOD by adding synthetic grey squares and white rings. This showed larger squares were easier to detect in earlier layers, and different artefacts peaked at different depths \\cite{anthony2023slf}.\n    *   **Real-world Artefacts:** Validated on two medical imaging OOD tasks using ResNet18 and VGG16 on CheXpert: detecting unseen pacemakers and unseen sex \\cite{anthony2023slf}.\n    *   **Metrics:** AUROC (Area Under the Receiver Operating Characteristic curve) and Balanced Accuracy were used \\cite{anthony2023slf}.\n    *   **Key Results:**\n        *   Layer-wise analysis confirmed that optimal detection depths varied for different real-world OOD patterns (e.g., pacemakers at module 51, sex at module 44 for ResNet18) and that LHL performance was poor \\cite{anthony2023slf}.\n        *   MBM (especially MBM with only ReLUs and FGSM) consistently outperformed traditional Mahalanobis (LHL, weighted combination) and other softmax-based baselines (MCP, MCDropout, Deep Ensembles, ODIN) across both ResNet18 and VGG16 for both unseen pacemaker and unseen sex OOD tasks \\cite{anthony2023slf}.\n        *   For example, MBM (only ReLUs) + FGSM achieved AUROCs of 76.8% (ResNet18) and 77.0% (VGG16) for unseen pacemakers, and 72.1% (ResNet18) and 78.0% (VGG16) for unseen sex, often surpassing even the \"optimal layer - oracle\" \\cite{anthony2023slf}.\n        *   A multi-detector MBM system with optimized thresholds achieved higher balanced accuracy (71.40%) for simultaneous detection of two OOD patterns compared to single-detector systems (67.64% and 68.14%) \\cite{anthony2023slf}.\n\n*   **Limitations & Scope**\n    *   The primary technical limitation is the challenge of determining optimal thresholds for multiple OOD detectors in complex, unpredictable real-world settings, although the paper demonstrates its theoretical feasibility \\cite{anthony2023slf}.\n    *   The scope of applicability is primarily demonstrated within medical imaging (chest X-rays) and specific OOD patterns, suggesting further validation across diverse domains and OOD types would be beneficial \\cite{anthony2023slf}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in OOD detection by fundamentally re-evaluating and improving the application of Mahalanobis distance \\cite{anthony2023slf}.\n    *   It provides crucial insights into the depth-dependency of OOD pattern detectability, leading to the more robust Multi-branch Mahalanobis (MBM) framework \\cite{anthony2023slf}.\n    *   The findings inform best practices for Mahalanobis score application, moving away from sub-optimal common implementations \\cite{anthony2023slf}.\n    *   The paper's insights and the proposed MBM framework have the potential to inspire future research into practical multi-detector OOD systems and more sophisticated thresholding strategies, ultimately leading to safer and more reliable deployment of neural networks in critical applications \\cite{anthony2023slf}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "neural networks",
          "medical imaging",
          "Mahalanobis distance",
          "layer-wise analysis",
          "Multi-branch Mahalanobis (MBM)",
          "depth-dependent OOD detection",
          "robust generalization",
          "optimal detection layers",
          "CheXpert dataset",
          "real-world artefacts",
          "FGSM perturbations",
          "AUROC",
          "safer AI deployment"
        ],
        "paper_type": "based on the abstract and introduction:\n\nthe paper clearly describes a study that:\n*   **challenges a prevailing understanding** (\"challenges the prevailing community understanding that there is an optimal layer...\")\n*   **presents findings based on evidence** (\"this paper shows the optimum layer... changes...\", \"this paper also shows that separating this ood detector... can enhance...\")\n*   **validates these findings using data and experiments** (\"these insights were validated on real-world ood tasks, training models on chexpert chest x-rays...\", \"using scans with unseen pacemakers... and unseen sex as ood cases.\")\n*   **mentions data collection/annotation** (\"we manually labelled 50% of chexpert for this research\")\n*   **aims to inform best practices based on results** (\"the results inform best-practices...\")\n\nthese elements strongly align with the criteria for an **empirical** paper: \"data-driven studies with statistical analysis\" (implied by \"results\" and \"validated\"), \"experiment\", \"data\", \"findings\".\n\ntherefore, the classification is: **empirical**"
      },
      "file_name": "b723d4e9fbe81890624d11c873acb63ddf21b64b.pdf"
    },
    {
      "success": true,
      "doc_id": "8c43b73c10cf92d8a467781652a09882",
      "summary": "Detecting out-of-distribution (OOD) inputs for deep learning models is a critical task when models are deployed in real-world environments. Recently, a large number of works have been dedicated to tackling the OOD detection problem. One of the most straightforward and effective ways is OOD training, which adds heterogeneous auxiliary data in the training stage. However, the extra auxiliary data cannot be involved arbitrarily. A high-quality and powerful auxiliary dataset must contain samples that belong to OOD but are close to in-distribution (ID), which can teach the model to learn more information about OOD samples, furthermore, distinguish OOD from ID. The key issue for this problem is how to simply acquire such distinctive OOD samples. In this article, we propose an enhanced Mixup-based OOD (MixOOD) detection strategy that can be attached to any threshold-based OOD detecting method. Different from the traditional Mixup designed for ID data augmentation, our proposed MixOOD generates augmented images with deliberately modified Mixup and then uses them as auxiliary OOD data to leverage the OOD detection. We test our method with classical OOD detecting approaches like Maximum Softmax Probability, Energy Score, and Out-of-distribution detector for Neural networks. Experiments show that models with MixOOD can better distinguish in- and out-of-distribution samples than the original version of each approach.",
      "intriguing_abstract": "Detecting out-of-distribution (OOD) inputs for deep learning models is a critical task when models are deployed in real-world environments. Recently, a large number of works have been dedicated to tackling the OOD detection problem. One of the most straightforward and effective ways is OOD training, which adds heterogeneous auxiliary data in the training stage. However, the extra auxiliary data cannot be involved arbitrarily. A high-quality and powerful auxiliary dataset must contain samples that belong to OOD but are close to in-distribution (ID), which can teach the model to learn more information about OOD samples, furthermore, distinguish OOD from ID. The key issue for this problem is how to simply acquire such distinctive OOD samples. In this article, we propose an enhanced Mixup-based OOD (MixOOD) detection strategy that can be attached to any threshold-based OOD detecting method. Different from the traditional Mixup designed for ID data augmentation, our proposed MixOOD generates augmented images with deliberately modified Mixup and then uses them as auxiliary OOD data to leverage the OOD detection. We test our method with classical OOD detecting approaches like Maximum Softmax Probability, Energy Score, and Out-of-distribution detector for Neural networks. Experiments show that models with MixOOD can better distinguish in- and out-of-distribution samples than the original version of each approach.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/ecd30803a587687db2e5a2ff659391e56b792714.pdf",
      "citation_key": "yang2023pre",
      "metadata": {
        "title": "MixOOD: Improving Out-of-distribution Detection with Enhanced Data Mixup",
        "authors": [
          "Taocun Yang",
          "Y. Huang",
          "Yanlin Xie",
          "Junbo Liu",
          "Shengchun Wang"
        ],
        "published_date": "2023",
        "abstract": "Detecting out-of-distribution (OOD) inputs for deep learning models is a critical task when models are deployed in real-world environments. Recently, a large number of works have been dedicated to tackling the OOD detection problem. One of the most straightforward and effective ways is OOD training, which adds heterogeneous auxiliary data in the training stage. However, the extra auxiliary data cannot be involved arbitrarily. A high-quality and powerful auxiliary dataset must contain samples that belong to OOD but are close to in-distribution (ID), which can teach the model to learn more information about OOD samples, furthermore, distinguish OOD from ID. The key issue for this problem is how to simply acquire such distinctive OOD samples. In this article, we propose an enhanced Mixup-based OOD (MixOOD) detection strategy that can be attached to any threshold-based OOD detecting method. Different from the traditional Mixup designed for ID data augmentation, our proposed MixOOD generates augmented images with deliberately modified Mixup and then uses them as auxiliary OOD data to leverage the OOD detection. We test our method with classical OOD detecting approaches like Maximum Softmax Probability, Energy Score, and Out-of-distribution detector for Neural networks. Experiments show that models with MixOOD can better distinguish in- and out-of-distribution samples than the original version of each approach.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/ecd30803a587687db2e5a2ff659391e56b792714.pdf",
        "venue": "ACM Trans. Multim. Comput. Commun. Appl.",
        "citationCount": 13,
        "score": 6.5,
        "summary": "Detecting out-of-distribution (OOD) inputs for deep learning models is a critical task when models are deployed in real-world environments. Recently, a large number of works have been dedicated to tackling the OOD detection problem. One of the most straightforward and effective ways is OOD training, which adds heterogeneous auxiliary data in the training stage. However, the extra auxiliary data cannot be involved arbitrarily. A high-quality and powerful auxiliary dataset must contain samples that belong to OOD but are close to in-distribution (ID), which can teach the model to learn more information about OOD samples, furthermore, distinguish OOD from ID. The key issue for this problem is how to simply acquire such distinctive OOD samples. In this article, we propose an enhanced Mixup-based OOD (MixOOD) detection strategy that can be attached to any threshold-based OOD detecting method. Different from the traditional Mixup designed for ID data augmentation, our proposed MixOOD generates augmented images with deliberately modified Mixup and then uses them as auxiliary OOD data to leverage the OOD detection. We test our method with classical OOD detecting approaches like Maximum Softmax Probability, Energy Score, and Out-of-distribution detector for Neural networks. Experiments show that models with MixOOD can better distinguish in- and out-of-distribution samples than the original version of each approach.",
        "keywords": []
      },
      "file_name": "ecd30803a587687db2e5a2ff659391e56b792714.pdf"
    },
    {
      "success": true,
      "doc_id": "141e1d02c440553c86f38c9966db496b",
      "summary": "Out-of-distribution (OOD) detection plays a vital role in enhancing the reliability of machine learning models. As large language models (LLMs) become more prevalent, the applicability of prior research on OOD detection that utilized smaller-scale Transformers such as BERT, RoBERTa, and GPT-2 may be challenged, due to the significant differences in the scale of these models, their pre-training objectives, and the paradigms used for inference. This paper initiates a pioneering empirical investigation into the OOD detection capabilities of LLMs, focusing on the LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate commonly used OOD detectors, examining their performance in both zero-grad and fine-tuning scenarios. Notably, we alter previous discriminative in-distribution fine-tuning into generative fine-tuning, aligning the pre-training objective of LLMs with downstream tasks. Our findings unveil that a simple cosine distance OOD detector demonstrates superior efficacy, outperforming other OOD detectors. We provide an intriguing explanation for this phenomenon by highlighting the isotropic nature of the embedding spaces of LLMs, which distinctly contrasts with the anisotropic property observed in smaller BERT family models. The new insight enhances our understanding of how LLMs detect OOD data, thereby enhancing their adaptability and reliability in dynamic environments. We have released the source code at https://github.com/Awenbocc/LLM-OOD for other researchers to reproduce our results.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection plays a vital role in enhancing the reliability of machine learning models. As large language models (LLMs) become more prevalent, the applicability of prior research on OOD detection that utilized smaller-scale Transformers such as BERT, RoBERTa, and GPT-2 may be challenged, due to the significant differences in the scale of these models, their pre-training objectives, and the paradigms used for inference. This paper initiates a pioneering empirical investigation into the OOD detection capabilities of LLMs, focusing on the LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate commonly used OOD detectors, examining their performance in both zero-grad and fine-tuning scenarios. Notably, we alter previous discriminative in-distribution fine-tuning into generative fine-tuning, aligning the pre-training objective of LLMs with downstream tasks. Our findings unveil that a simple cosine distance OOD detector demonstrates superior efficacy, outperforming other OOD detectors. We provide an intriguing explanation for this phenomenon by highlighting the isotropic nature of the embedding spaces of LLMs, which distinctly contrasts with the anisotropic property observed in smaller BERT family models. The new insight enhances our understanding of how LLMs detect OOD data, thereby enhancing their adaptability and reliability in dynamic environments. We have released the source code at https://github.com/Awenbocc/LLM-OOD for other researchers to reproduce our results.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/3e04193d5110288b776edd5724aeca2229d2d182.pdf",
      "citation_key": "liu2023i6i",
      "metadata": {
        "title": "How Good Are LLMs at Out-of-Distribution Detection?",
        "authors": [
          "Bo Liu",
          "Li-Ming Zhan",
          "Zexin Lu",
          "Yu Feng",
          "Lei Xue",
          "Xiao-Ming Wu"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection plays a vital role in enhancing the reliability of machine learning models. As large language models (LLMs) become more prevalent, the applicability of prior research on OOD detection that utilized smaller-scale Transformers such as BERT, RoBERTa, and GPT-2 may be challenged, due to the significant differences in the scale of these models, their pre-training objectives, and the paradigms used for inference. This paper initiates a pioneering empirical investigation into the OOD detection capabilities of LLMs, focusing on the LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate commonly used OOD detectors, examining their performance in both zero-grad and fine-tuning scenarios. Notably, we alter previous discriminative in-distribution fine-tuning into generative fine-tuning, aligning the pre-training objective of LLMs with downstream tasks. Our findings unveil that a simple cosine distance OOD detector demonstrates superior efficacy, outperforming other OOD detectors. We provide an intriguing explanation for this phenomenon by highlighting the isotropic nature of the embedding spaces of LLMs, which distinctly contrasts with the anisotropic property observed in smaller BERT family models. The new insight enhances our understanding of how LLMs detect OOD data, thereby enhancing their adaptability and reliability in dynamic environments. We have released the source code at https://github.com/Awenbocc/LLM-OOD for other researchers to reproduce our results.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/3e04193d5110288b776edd5724aeca2229d2d182.pdf",
        "venue": "International Conference on Language Resources and Evaluation",
        "citationCount": 13,
        "score": 6.5,
        "summary": "Out-of-distribution (OOD) detection plays a vital role in enhancing the reliability of machine learning models. As large language models (LLMs) become more prevalent, the applicability of prior research on OOD detection that utilized smaller-scale Transformers such as BERT, RoBERTa, and GPT-2 may be challenged, due to the significant differences in the scale of these models, their pre-training objectives, and the paradigms used for inference. This paper initiates a pioneering empirical investigation into the OOD detection capabilities of LLMs, focusing on the LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate commonly used OOD detectors, examining their performance in both zero-grad and fine-tuning scenarios. Notably, we alter previous discriminative in-distribution fine-tuning into generative fine-tuning, aligning the pre-training objective of LLMs with downstream tasks. Our findings unveil that a simple cosine distance OOD detector demonstrates superior efficacy, outperforming other OOD detectors. We provide an intriguing explanation for this phenomenon by highlighting the isotropic nature of the embedding spaces of LLMs, which distinctly contrasts with the anisotropic property observed in smaller BERT family models. The new insight enhances our understanding of how LLMs detect OOD data, thereby enhancing their adaptability and reliability in dynamic environments. We have released the source code at https://github.com/Awenbocc/LLM-OOD for other researchers to reproduce our results.",
        "keywords": []
      },
      "file_name": "3e04193d5110288b776edd5724aeca2229d2d182.pdf"
    },
    {
      "success": true,
      "doc_id": "a44b14290f3793abb5696ca5086d8721",
      "summary": "Out-of-distribution (OOD) detection is a desired ability to ensure the reliability and safety of intelligent systems. A scoring function is often designed to measure the degree of any new data being an OOD sample. While most designed scoring functions are based on a single source of information (e.g., the classifierâ€™s output, logits, or feature vector), recent studies demonstrate that fusion of multiple sources may help better detect OOD data. In this study, after detailed analysis of the issue in OOD detection by the conventional principal component analysis (PCA), we propose fusing a simple regularized PCA-based reconstruction error with other source of scoring function to further improve OOD detection performance. In particular, when combined with a strong energy score-based OOD method, the regularized reconstruction error helps achieve new state-of the-art OOD detection results on multiple standard benchmarks. The code is available at https://github.com/SYSUMIA-GROUP/pca-based-out-of-distribution-detection.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection is a desired ability to ensure the reliability and safety of intelligent systems. A scoring function is often designed to measure the degree of any new data being an OOD sample. While most designed scoring functions are based on a single source of information (e.g., the classifierâ€™s output, logits, or feature vector), recent studies demonstrate that fusion of multiple sources may help better detect OOD data. In this study, after detailed analysis of the issue in OOD detection by the conventional principal component analysis (PCA), we propose fusing a simple regularized PCA-based reconstruction error with other source of scoring function to further improve OOD detection performance. In particular, when combined with a strong energy score-based OOD method, the regularized reconstruction error helps achieve new state-of the-art OOD detection results on multiple standard benchmarks. The code is available at https://github.com/SYSUMIA-GROUP/pca-based-out-of-distribution-detection.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/350b00baaddd9f42dd3689f475bea3139e24099d.pdf",
      "citation_key": "guan2023dwv",
      "metadata": {
        "title": "Revisit PCA-based technique for Out-of-Distribution Detection",
        "authors": [
          "Xiaoyuan Guan",
          "Zhouwu Liu",
          "Weishi Zheng",
          "Yuren Zhou",
          "Ruixuan Wang"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection is a desired ability to ensure the reliability and safety of intelligent systems. A scoring function is often designed to measure the degree of any new data being an OOD sample. While most designed scoring functions are based on a single source of information (e.g., the classifierâ€™s output, logits, or feature vector), recent studies demonstrate that fusion of multiple sources may help better detect OOD data. In this study, after detailed analysis of the issue in OOD detection by the conventional principal component analysis (PCA), we propose fusing a simple regularized PCA-based reconstruction error with other source of scoring function to further improve OOD detection performance. In particular, when combined with a strong energy score-based OOD method, the regularized reconstruction error helps achieve new state-of the-art OOD detection results on multiple standard benchmarks. The code is available at https://github.com/SYSUMIA-GROUP/pca-based-out-of-distribution-detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/350b00baaddd9f42dd3689f475bea3139e24099d.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 12,
        "score": 6.0,
        "summary": "Out-of-distribution (OOD) detection is a desired ability to ensure the reliability and safety of intelligent systems. A scoring function is often designed to measure the degree of any new data being an OOD sample. While most designed scoring functions are based on a single source of information (e.g., the classifierâ€™s output, logits, or feature vector), recent studies demonstrate that fusion of multiple sources may help better detect OOD data. In this study, after detailed analysis of the issue in OOD detection by the conventional principal component analysis (PCA), we propose fusing a simple regularized PCA-based reconstruction error with other source of scoring function to further improve OOD detection performance. In particular, when combined with a strong energy score-based OOD method, the regularized reconstruction error helps achieve new state-of the-art OOD detection results on multiple standard benchmarks. The code is available at https://github.com/SYSUMIA-GROUP/pca-based-out-of-distribution-detection.",
        "keywords": []
      },
      "file_name": "350b00baaddd9f42dd3689f475bea3139e24099d.pdf"
    },
    {
      "success": true,
      "doc_id": "4ecd9d7b1b4979059098de4594e6f096",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/40f68559e2fc055aaa1ed677c64b1dcc61bcaabe.pdf",
      "citation_key": "zhang2024mgg",
      "metadata": {
        "title": "Vision-Language Dual-Pattern Matching for Out-of-Distribution Detection",
        "authors": [
          "Zihan Zhang",
          "Zhuo Xu",
          "Xiang Xiang"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/40f68559e2fc055aaa1ed677c64b1dcc61bcaabe.pdf",
        "venue": "European Conference on Computer Vision",
        "citationCount": 6,
        "score": 6.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "40f68559e2fc055aaa1ed677c64b1dcc61bcaabe.pdf"
    },
    {
      "success": true,
      "doc_id": "e2fae87153ed33feba421b3749dc0113",
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n### Technical Paper Analysis: \"Category-Extensible Out-of-Distribution Detection via Hierarchical Context Descriptions\" \\cite{liu20245e5}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, specifically focusing on constructing precise category descriptions within vision-language models (VLMs) to accurately distinguish in-distribution (ID) from OOD samples, especially when dealing with unseen categories.\n    *   **Importance and Challenge**:\n        *   OOD detection is crucial for robust AI systems, preventing overconfident predictions on novel inputs.\n        *   The key challenge lies in two aspects: (1) achieving generalized feature representations that can broadly separate different categories, and (2) acquiring precise decision boundaries for each ID category.\n        *   While VLMs like CLIP offer powerful generalized features and prior knowledge, constructing *precise* category descriptions for OOD detection remains difficult due to the inherent absence of unseen categories during training. Existing CLIP-based methods either limit zero-shot performance or sacrifice the VLM's generalization capacity by fine-tuning encoders.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon recent advancements in CLIP-based OOD detection methods (e.g., MCM \\cite{liu20245e5}, NPOS \\cite{liu20245e5}) that leverage large-scale pre-trained VLMs for their generalized feature representations.\n    *   **Limitations of Previous Solutions**:\n        *   Zero-shot CLIP-based OOD methods are limited because simply using category names as text prompts constrains the VLM's full discriminative potential.\n        *   Fine-tuning CLIP's encoder, while boosting performance, sacrifices the generalization of multi-modal feature representation, impairing the model's ability to resist data shifts.\n        *   Previous methods struggle to construct precise category descriptions via multi-modal features, particularly for semantically similar OOD samples, often leading to overconfident predictions.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper introduces **hierarchical contexts** (perceptual and spurious) for each ID category, learned through **automatic prompt tuning** while keeping the VLM's image and text encoders frozen.\n        *   **Perceptual Context**: Learns to perceive inter-category differences for the current ID classification task, roughly classifying samples into known categories.\n        *   **Spurious Context**: Hierarchically identifies \"spurious\" OOD samples that are semantically similar to an ID category but are not truly ID (e.g., \"cats vs panthers\"). This context defines a stricter boundary for each category.\n        *   **Hierarchical Description**: The two contexts jointly construct a precise category description: first, a rough classification by the perceptual context, then a delicate identification by the spurious context to determine if it's truly ID or a spurious OOD.\n        *   **Perturbation Guidance for Spurious Synthesis**: A novel strategy to generate high-quality adversarial (spurious) samples for training the spurious context. It leverages the VLM's prior knowledge by perturbing word embeddings within the perceptual context (e.g., masking) to create \"perturbed text features.\" Samples that are more similar to these perturbed features than the original ID category are selected as spurious syntheses.\n    *   **Novelty/Differentiation**:\n        *   **Hierarchical Contexts**: This dual-context approach provides a more nuanced and precise definition of category boundaries than single-context methods.\n        *   **Frozen Encoders + Prompt Tuning**: Maintains the VLM's generalized feature representation while adapting to specific OOD tasks, avoiding the trade-off seen in fine-tuning approaches.\n        *   **Perturbation-Guided Spurious Synthesis**: A targeted and intelligent way to generate challenging OOD samples for training, improving the quality of the spurious context.\n        *   **Category-Extensible (CATEX) Framework**: The learned hierarchical contexts are designed to be mergeable across different sub-task settings, allowing for efficient extension of recognizable categories without retraining.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduction of **perceptual and spurious contexts** for hierarchical category description in OOD detection.\n        *   A **perturbation-guided sampling strategy** for synthesizing high-quality spurious OOD samples to train the spurious context.\n        *   An **integrated inference mechanism** that regularizes vanilla image-text similarities using both contexts to alleviate overconfidence on OOD samples.\n    *   **System Design/Architectural Innovations**:\n        *   The **CATegory-EXtensible (CATEX) OOD detection framework**, which allows for efficient scaling of recognizable categories by merging learned hierarchical contexts.\n    *   **Theoretical Insights/Analysis**:\n        *   Offers new insights into efficiently scaling up prompt engineering in VLMs for thousands of categories.\n        *   Demonstrates how to incorporate large language models (LLMs) like GPT-3 to boost zero-shot applications by implicitly constructing spurious contexts.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments across four practical scenarios:\n        1.  Standard OOD detection.\n        2.  ID-shifted OOD detection (to test robustness).\n        3.  Category-extended ID classification and OOD detection (to validate CATEX's extensibility).\n        4.  Zero-shot ID classification.\n    *   **Datasets**:\n        *   **In-Distribution (ID)**: Large-scale ImageNet-1K \\cite{liu20245e5}.\n        *   **Out-of-Distribution (OOD)**: iNaturalist \\cite{liu20245e5}, SUN \\cite{liu20245e5}, Places \\cite{liu20245e5}, and Texture \\cite{liu20245e5} (categories disjoint from ID).\n    *   **Key Performance Metrics**:\n        *   **OOD Detection**: FPR95 (False Positive Rate at 95% True Positive Rate for ID samples) and AUROC (Area Under the Receiver Operating Characteristic curve).\n        *   **ID Classification**: Mean Accuracy (ACC).\n    *   **Comparison Results**:\n        *   **Superior Performance**: CATEX consistently surpasses state-of-the-art rivals by a large margin on the challenging ImageNet-1K benchmark, achieving an **8.27% decrease in FPR95**.\n        *   **Robustness**: Demonstrates stable robustness on both ID classification and OOD tasks even when data shifts occur, showing comparable or better generalization than remarkable zero-shot methods.\n        *   **Category-Extensibility**: Competitive results when merging contexts learned from different task data and testing on the union ID setting, illustrating cross-task applicability. Successfully extended to ImageNet-21K categories at acceptable GPU memory cost, outperforming rivals.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the strong prior knowledge and generalized representations provided by large-scale pre-trained VLMs like CLIP. The effectiveness of perturbation guidance is tied to the quality of word embeddings and their ability to capture visual characteristics.\n    *   **Scope of Applicability**: Primarily demonstrated for image-based OOD detection and classification tasks within the VLM framework. While insights for LLMs are mentioned, the core implementation is VLM-centric. The extensibility is shown for merging contexts, but the computational cost for extremely large numbers of categories or highly diverse contexts might still be a consideration.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: Significantly advances OOD detection by providing a more precise, robust, and extensible method for defining category boundaries in VLMs, particularly for handling semantically similar OOD samples. The substantial reduction in FPR95 on ImageNet-1K highlights its practical impact.\n    *   **Potential Impact on Future Research**:\n        *   Offers a novel paradigm for scaling prompt engineering in VLMs to recognize thousands of object categories efficiently.\n        *   Provides a foundation for incorporating LLMs to enhance zero-shot applications, suggesting new avenues for leveraging multi-modal and large language models in OOD detection and beyond.\n        *   The concept of hierarchical contexts could inspire similar approaches for other tasks requiring fine-grained boundary definitions or robustness against subtle distribution shifts.",
      "intriguing_abstract": "Out-of-Distribution (OOD) detection is critical for robust AI, yet precisely defining category boundaries, especially for semantically similar OOD samples, remains an elusive challenge for Vision-Language Models (VLMs). Existing CLIP-based methods often compromise VLM generalization by fine-tuning encoders or lack the precision for nuanced OOD distinction.\n\nThis paper introduces a pioneering **Category-Extensible (CATEX)** framework that revolutionizes OOD detection by constructing **hierarchical contexts** for each in-distribution category. Our approach leverages **automatic prompt tuning** on frozen VLM encoders, preserving their powerful generalized features. We define a **perceptual context** for broad classification and a novel **spurious context** to meticulously identify OOD samples that are semantically close to ID categories. A **perturbation-guided sampling strategy** synthesizes high-quality spurious samples, enhancing boundary precision. CATEX achieves unprecedented performance, reducing FPR95 by 8.27% on ImageNet-1K, significantly outperforming state-of-the-art. Its category-extensible design allows efficient scaling to thousands of categories, offering a robust and scalable solution for real-world AI applications.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Vision-language models (VLMs)",
        "Hierarchical contexts",
        "Automatic prompt tuning",
        "Frozen VLM encoders",
        "Perturbation-guided spurious synthesis",
        "Category-Extensible (CATEX) framework",
        "Precise category descriptions",
        "Semantically similar OOD samples",
        "Robustness against data shifts",
        "ImageNet-1K benchmark",
        "FPR95 reduction",
        "Efficient prompt engineering scaling"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/4de791464e08ba25d2466abf78fd9b529ce6d2d5.pdf",
      "citation_key": "liu20245e5",
      "metadata": {
        "title": "Category-Extensible Out-of-Distribution Detection via Hierarchical Context Descriptions",
        "authors": [
          "Kai Liu",
          "Zhihang Fu",
          "Chao Chen",
          "Sheng Jin",
          "Ze Chen",
          "Mingyuan Tao",
          "Rongxin Jiang",
          "Jieping Ye"
        ],
        "published_date": "2024",
        "abstract": "The key to OOD detection has two aspects: generalized feature representation and precise category description. Recently, vision-language models such as CLIP provide significant advances in both two issues, but constructing precise category descriptions is still in its infancy due to the absence of unseen categories. This work introduces two hierarchical contexts, namely perceptual context and spurious context, to carefully describe the precise category boundary through automatic prompt tuning. Specifically, perceptual contexts perceive the inter-category difference (e.g., cats vs apples) for current classification tasks, while spurious contexts further identify spurious (similar but exactly not) OOD samples for every single category (e.g., cats vs panthers, apples vs peaches). The two contexts hierarchically construct the precise description for a certain category, which is, first roughly classifying a sample to the predicted category and then delicately identifying whether it is truly an ID sample or actually OOD. Moreover, the precise descriptions for those categories within the vision-language framework present a novel application: CATegory-EXtensible OOD detection (CATEX). One can efficiently extend the set of recognizable categories by simply merging the hierarchical contexts learned under different sub-task settings. And extensive experiments are conducted to demonstrate CATEX's effectiveness, robustness, and category-extensibility. For instance, CATEX consistently surpasses the rivals by a large margin with several protocols on the challenging ImageNet-1K dataset. In addition, we offer new insights on how to efficiently scale up the prompt engineering in vision-language models to recognize thousands of object categories, as well as how to incorporate large language models (like GPT-3) to boost zero-shot applications. Code is publicly available at https://github.com/alibaba/catex.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/4de791464e08ba25d2466abf78fd9b529ce6d2d5.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 6,
        "score": 6.0,
        "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n### Technical Paper Analysis: \"Category-Extensible Out-of-Distribution Detection via Hierarchical Context Descriptions\" \\cite{liu20245e5}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, specifically focusing on constructing precise category descriptions within vision-language models (VLMs) to accurately distinguish in-distribution (ID) from OOD samples, especially when dealing with unseen categories.\n    *   **Importance and Challenge**:\n        *   OOD detection is crucial for robust AI systems, preventing overconfident predictions on novel inputs.\n        *   The key challenge lies in two aspects: (1) achieving generalized feature representations that can broadly separate different categories, and (2) acquiring precise decision boundaries for each ID category.\n        *   While VLMs like CLIP offer powerful generalized features and prior knowledge, constructing *precise* category descriptions for OOD detection remains difficult due to the inherent absence of unseen categories during training. Existing CLIP-based methods either limit zero-shot performance or sacrifice the VLM's generalization capacity by fine-tuning encoders.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon recent advancements in CLIP-based OOD detection methods (e.g., MCM \\cite{liu20245e5}, NPOS \\cite{liu20245e5}) that leverage large-scale pre-trained VLMs for their generalized feature representations.\n    *   **Limitations of Previous Solutions**:\n        *   Zero-shot CLIP-based OOD methods are limited because simply using category names as text prompts constrains the VLM's full discriminative potential.\n        *   Fine-tuning CLIP's encoder, while boosting performance, sacrifices the generalization of multi-modal feature representation, impairing the model's ability to resist data shifts.\n        *   Previous methods struggle to construct precise category descriptions via multi-modal features, particularly for semantically similar OOD samples, often leading to overconfident predictions.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper introduces **hierarchical contexts** (perceptual and spurious) for each ID category, learned through **automatic prompt tuning** while keeping the VLM's image and text encoders frozen.\n        *   **Perceptual Context**: Learns to perceive inter-category differences for the current ID classification task, roughly classifying samples into known categories.\n        *   **Spurious Context**: Hierarchically identifies \"spurious\" OOD samples that are semantically similar to an ID category but are not truly ID (e.g., \"cats vs panthers\"). This context defines a stricter boundary for each category.\n        *   **Hierarchical Description**: The two contexts jointly construct a precise category description: first, a rough classification by the perceptual context, then a delicate identification by the spurious context to determine if it's truly ID or a spurious OOD.\n        *   **Perturbation Guidance for Spurious Synthesis**: A novel strategy to generate high-quality adversarial (spurious) samples for training the spurious context. It leverages the VLM's prior knowledge by perturbing word embeddings within the perceptual context (e.g., masking) to create \"perturbed text features.\" Samples that are more similar to these perturbed features than the original ID category are selected as spurious syntheses.\n    *   **Novelty/Differentiation**:\n        *   **Hierarchical Contexts**: This dual-context approach provides a more nuanced and precise definition of category boundaries than single-context methods.\n        *   **Frozen Encoders + Prompt Tuning**: Maintains the VLM's generalized feature representation while adapting to specific OOD tasks, avoiding the trade-off seen in fine-tuning approaches.\n        *   **Perturbation-Guided Spurious Synthesis**: A targeted and intelligent way to generate challenging OOD samples for training, improving the quality of the spurious context.\n        *   **Category-Extensible (CATEX) Framework**: The learned hierarchical contexts are designed to be mergeable across different sub-task settings, allowing for efficient extension of recognizable categories without retraining.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduction of **perceptual and spurious contexts** for hierarchical category description in OOD detection.\n        *   A **perturbation-guided sampling strategy** for synthesizing high-quality spurious OOD samples to train the spurious context.\n        *   An **integrated inference mechanism** that regularizes vanilla image-text similarities using both contexts to alleviate overconfidence on OOD samples.\n    *   **System Design/Architectural Innovations**:\n        *   The **CATegory-EXtensible (CATEX) OOD detection framework**, which allows for efficient scaling of recognizable categories by merging learned hierarchical contexts.\n    *   **Theoretical Insights/Analysis**:\n        *   Offers new insights into efficiently scaling up prompt engineering in VLMs for thousands of categories.\n        *   Demonstrates how to incorporate large language models (LLMs) like GPT-3 to boost zero-shot applications by implicitly constructing spurious contexts.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments across four practical scenarios:\n        1.  Standard OOD detection.\n        2.  ID-shifted OOD detection (to test robustness).\n        3.  Category-extended ID classification and OOD detection (to validate CATEX's extensibility).\n        4.  Zero-shot ID classification.\n    *   **Datasets**:\n        *   **In-Distribution (ID)**: Large-scale ImageNet-1K \\cite{liu20245e5}.\n        *   **Out-of-Distribution (OOD)**: iNaturalist \\cite{liu20245e5}, SUN \\cite{liu20245e5}, Places \\cite{liu20245e5}, and Texture \\cite{liu20245e5} (categories disjoint from ID).\n    *   **Key Performance Metrics**:\n        *   **OOD Detection**: FPR95 (False Positive Rate at 95% True Positive Rate for ID samples) and AUROC (Area Under the Receiver Operating Characteristic curve).\n        *   **ID Classification**: Mean Accuracy (ACC).\n    *   **Comparison Results**:\n        *   **Superior Performance**: CATEX consistently surpasses state-of-the-art rivals by a large margin on the challenging ImageNet-1K benchmark, achieving an **8.27% decrease in FPR95**.\n        *   **Robustness**: Demonstrates stable robustness on both ID classification and OOD tasks even when data shifts occur, showing comparable or better generalization than remarkable zero-shot methods.\n        *   **Category-Extensibility**: Competitive results when merging contexts learned from different task data and testing on the union ID setting, illustrating cross-task applicability. Successfully extended to ImageNet-21K categories at acceptable GPU memory cost, outperforming rivals.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the strong prior knowledge and generalized representations provided by large-scale pre-trained VLMs like CLIP. The effectiveness of perturbation guidance is tied to the quality of word embeddings and their ability to capture visual characteristics.\n    *   **Scope of Applicability**: Primarily demonstrated for image-based OOD detection and classification tasks within the VLM framework. While insights for LLMs are mentioned, the core implementation is VLM-centric. The extensibility is shown for merging contexts, but the computational cost for extremely large numbers of categories or highly diverse contexts might still be a consideration.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: Significantly advances OOD detection by providing a more precise, robust, and extensible method for defining category boundaries in VLMs, particularly for handling semantically similar OOD samples. The substantial reduction in FPR95 on ImageNet-1K highlights its practical impact.\n    *   **Potential Impact on Future Research**:\n        *   Offers a novel paradigm for scaling prompt engineering in VLMs to recognize thousands of object categories efficiently.\n        *   Provides a foundation for incorporating LLMs to enhance zero-shot applications, suggesting new avenues for leveraging multi-modal and large language models in OOD detection and beyond.\n        *   The concept of hierarchical contexts could inspire similar approaches for other tasks requiring fine-grained boundary definitions or robustness against subtle distribution shifts.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Vision-language models (VLMs)",
          "Hierarchical contexts",
          "Automatic prompt tuning",
          "Frozen VLM encoders",
          "Perturbation-guided spurious synthesis",
          "Category-Extensible (CATEX) framework",
          "Precise category descriptions",
          "Semantically similar OOD samples",
          "Robustness against data shifts",
          "ImageNet-1K benchmark",
          "FPR95 reduction",
          "Efficient prompt engineering scaling"
        ],
        "paper_type": "this paper is a **technical** type.\n\nhere's why:\n\n*   **presents new methods/algorithms/systems:** the abstract explicitly states, \"this work introduces two hierarchical contexts... to carefully describe the precise category boundary through automatic prompt tuning.\" it then details these contexts (perceptual and spurious) and presents a \"novel application: category-extensible ood detection (catex).\" the introduction also refers to \"our method\" and compares it to \"previous approaches.\"\n*   **discusses technical problem and proposed solution:** the introduction sets up the technical problem of ood detection and the challenges of generalized feature representation and precise category description, then immediately introduces the paper's solution.\n*   **empirical validation of a new method:** while the abstract mentions \"extensive experiments are conducted to demonstrate catexâ€™s effectiveness, robustness, and category-extensibility\" and specific datasets like \"imagenet-1k,\" these experiments are performed to validate the *new method* being proposed, rather than being the sole focus of the paper (e.g., analyzing existing data or a known phenomenon). the empirical results support the technical contribution.\n*   **code availability:** \"code is publicly available\" further indicates a practical, implemented technical contribution."
      },
      "file_name": "4de791464e08ba25d2466abf78fd9b529ce6d2d5.pdf"
    },
    {
      "success": true,
      "doc_id": "44b633215ff7192579a3132e39be42a0",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/62a63607647b48e1da0f8bac0c24d06ce15f2ef8.pdf",
      "citation_key": "jia2024zld",
      "metadata": {
        "title": "Enhancing out-of-distribution detection via diversified multi-prototype contrastive learning",
        "authors": [
          "Yulong Jia",
          "Jiaming Li",
          "Ganlong Zhao",
          "Shuangyin Liu",
          "Weijun Sun",
          "Liang Lin",
          "Guanbin Li"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/62a63607647b48e1da0f8bac0c24d06ce15f2ef8.pdf",
        "venue": "Pattern Recognition",
        "citationCount": 6,
        "score": 6.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "62a63607647b48e1da0f8bac0c24d06ce15f2ef8.pdf"
    },
    {
      "success": true,
      "doc_id": "186778c3e3e29c021944bb5261590c47",
      "summary": "Here's a focused summary of the paper \"DOS: Diverse Outlier Sampling FOR OUT-OF-DISTRIBUTION DETECTION\" \\cite{jiang2023vzb} for a literature review:\n\n### Technical Paper Analysis: DOS: Diverse Outlier Sampling FOR OUT-OF-DISTRIBUTION DETECTION \\cite{jiang2023vzb}\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem**: Modern neural networks exhibit overconfident predictions for Out-of-Distribution (OOD) inputs, leading to unreliable behavior in real-world deployments. While using auxiliary OOD datasets for regularization during training is common, existing sampling strategies are suboptimal.\n    *   **Importance and challenge**: Reliable OOD detection is crucial for safe and robust machine learning systems. Current methods either randomly sample outliers (inefficient) or greedily select based on predictive uncertainty (biased), failing to capture the full diversity of potential OOD inputs. This bias leads to locally compact decision boundaries, hindering effective differentiation between in-distribution (ID) and OOD data.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches**:\n        *   Builds upon Outlier Exposure (OE) methods that leverage auxiliary OOD datasets during training.\n        *   Contrasts with random sampling strategies (e.g., \\cite{hendrycks2019deep, mohseni2020self, liu2020energy}) which are often inefficient.\n        *   Directly addresses limitations of greedy sampling strategies (e.g., NTOM \\cite{chen2021atom}, \\cite{li2020greedy}) that select \"hard negative examples\" based solely on predictive uncertainty.\n    *   **Limitations of previous solutions**:\n        *   Random sampling: Incorporates many uninformative outliers, leading to loose decision boundaries (Figure 1b).\n        *   Uncertainty-based greedy sampling: Samples are biased towards specific regions or types of outliers, failing to represent the full OOD distribution. This results in locally compact decision boundaries (Figure 1c) and suboptimal OOD detection performance, as empirically shown by \\cite{jiang2023vzb} (Figure 2a, 2b).\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method**: The paper proposes **Diverse Outlier Sampling (DOS)** \\cite{jiang2023vzb}, a novel sampling strategy that selects diverse and informative outliers from an auxiliary OOD dataset.\n    *   **Novelty/Difference**: DOS \\cite{jiang2023vzb} addresses the bias of uncertainty-based sampling by explicitly incorporating diversity. It combines two key steps:\n        1.  **Clustering with Normalized Features**: Candidate OOD samples are partitioned into `k` clusters using K-means on their *normalized* latent representations. Feature normalization is crucial to mitigate bias towards features with larger scales, ensuring more effective clustering.\n        2.  **Active Sampling in Each Cluster**: From each cluster, the *most informative* outlier is selected. Informativeness is defined by the highest inverse absent category probability (i.e., lowest predictive uncertainty for the (K+1)-th \"absent\" class), following the principle of hard negative mining.\n    *   This combined approach aims to shape a globally compact decision boundary between ID and OOD data (Figure 1d), overcoming the local compactness issue of prior greedy methods. A mini-batch scheme is also employed for efficient processing of large auxiliary datasets.\n\n4.  **Key Technical Contributions**\n    *   **Novel sampling strategy (DOS)**: A principled approach that integrates both diversity (via clustering) and informativeness (via uncertainty-based selection) for outlier sampling, addressing the limitations of prior greedy methods.\n    *   **Feature normalization for clustering**: Introduces and validates the use of normalized latent features for K-means clustering of outliers, improving clustering quality by mitigating scale bias.\n    *   **Empirical demonstration of diversity's importance**: Provides empirical evidence that diversity is a critical factor in designing effective outlier sampling strategies for OOD detection.\n    *   **Efficient mini-batch scheme**: Enables practical application of the clustering and sampling process with large auxiliary OOD datasets.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted**: Extensive experiments were performed on common and large-scale OOD detection benchmarks.\n        *   **ID datasets**: CIFAR-100 and ImageNet-1K.\n        *   **Auxiliary OOD training datasets**: TI-300K and INRCS.\n        *   **OOD test datasets**: SVHN, LSUN-C, DTD, Places, LSUN-R, iSUN.\n        *   **Comparisons**: Evaluated against numerous state-of-the-art methods, including those without auxiliary OOD data (e.g., ODIN, Maha, EnergyScore) and those with auxiliary OOD data (e.g., OE, EnergyLoss, NTOM, Share, POEM).\n        *   **Ablation studies**: Investigated the effect of the number of clustering centers, choice of clustering algorithm, and the benefits of feature normalization.\n        *   **Further analysis**: Explored convergence speed and the method's applicability to large models like CLIP.\n    *   **Key performance metrics and comparison results**:\n        *   DOS \\cite{jiang2023vzb} consistently achieved state-of-the-art performance across various benchmarks.\n        *   On CIFAR-100 with TI-300K, DOS \\cite{jiang2023vzb} reduced the average FPR95 (False Positive Rate at 95% True Positive Rate) by up to 25.79% (from 50.15% to 24.36%) compared to the NTOM method.\n        *   Demonstrated consistent superiority over other sampling strategies and regularization terms (e.g., energy loss).\n        *   Showed robust performance with varying scales of auxiliary OOD datasets.\n        *   Analysis indicated faster convergence during training despite the clustering overhead.\n        *   Successfully boosted the OOD detection performance of CLIP, highlighting its value in the era of large models.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations**: The clustering step introduces extra computational overhead, although the paper notes that this can be offset by faster convergence during training.\n    *   **Assumptions**: The method assumes access to a large auxiliary unlabeled OOD training dataset.\n    *   **Scope of applicability**: Primarily demonstrated and validated in the context of supervised multi-class image classification for OOD detection. While the core idea of combining diversity and informativeness might be generalizable, its direct applicability to other domains or OOD settings (e.g., anomaly detection without auxiliary data) is not explicitly explored.\n\n7.  **Technical Significance**\n    *   **Advances the technical state-of-the-art**: DOS \\cite{jiang2023vzb} significantly improves OOD detection performance by providing a more effective way to utilize auxiliary OOD training data, particularly in terms of FPR95.\n    *   **New paradigm for outlier sampling**: Shifts the focus from purely uncertainty-based greedy sampling to a more holistic approach that explicitly considers and enforces diversity in the sampled outliers. This is critical for shaping a globally compact and robust decision boundary.\n    *   **Potential impact on future research**: The insights provided by \\cite{jiang2023vzb} regarding the importance of diversity and the effectiveness of normalized feature clustering can inspire future research into more sophisticated and efficient sampling strategies for OOD detection, especially as models become larger and OOD robustness becomes increasingly vital for real-world applications.",
      "intriguing_abstract": "Neural networks' overconfidence on Out-of-Distribution (OOD) inputs poses a challenge for reliable AI. Existing outlier sampling strategies for auxiliary OOD datasets are inefficient or biased, failing to capture full OOD diversity and yielding suboptimal decision boundaries.\n\nWe introduce **Diverse Outlier Sampling (DOS)**, a novel, principled strategy integrating **diversity** and **informativeness** to select outliers. DOS first clusters candidate OOD samples using K-means on *normalized latent features* to mitigate scale bias. From each cluster, the most informative \"hard negative\" is actively sampled based on predictive uncertainty. This combined approach shapes a globally compact and robust decision boundary, overcoming prior greedy methods' local compactness.\n\nDOS achieves state-of-the-art OOD detection performance, significantly reducing FPR95 by up to 25.79%. Its effectiveness extends to boosting OOD detection for large models like CLIP, underscoring its impact and establishing diversity as a cornerstone for safer, more reliable ML.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Diverse Outlier Sampling (DOS)",
        "Outlier Exposure (OE)",
        "sampling strategies",
        "clustering",
        "feature normalization",
        "predictive uncertainty",
        "hard negative mining",
        "globally compact decision boundary",
        "state-of-the-art performance",
        "FPR95",
        "large models (CLIP)",
        "auxiliary OOD datasets"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/913d26360f1a715f6ae80f5a775f398aa2f66c9d.pdf",
      "citation_key": "jiang2023vzb",
      "metadata": {
        "title": "DOS: Diverse Outlier Sampling for Out-of-Distribution Detection",
        "authors": [
          "Wenyu Jiang",
          "Hao Cheng",
          "Mingcai Chen",
          "Chongjun Wang",
          "Hongxin Wei"
        ],
        "published_date": "2023",
        "abstract": "Modern neural networks are known to give overconfident prediction for out-of-distribution inputs when deployed in the open world. It is common practice to leverage a surrogate outlier dataset to regularize the model during training, and recent studies emphasize the role of uncertainty in designing the sampling strategy for outlier dataset. However, the OOD samples selected solely based on predictive uncertainty can be biased towards certain types, which may fail to capture the full outlier distribution. In this work, we empirically show that diversity is critical in sampling outliers for OOD detection performance. Motivated by the observation, we propose a straightforward and novel sampling strategy named DOS (Diverse Outlier Sampling) to select diverse and informative outliers. Specifically, we cluster the normalized features at each iteration, and the most informative outlier from each cluster is selected for model training with absent category loss. With DOS, the sampled outliers efficiently shape a globally compact decision boundary between ID and OOD data. Extensive experiments demonstrate the superiority of DOS, reducing the average FPR95 by up to 25.79% on CIFAR-100 with TI-300K.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/913d26360f1a715f6ae80f5a775f398aa2f66c9d.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 12,
        "score": 6.0,
        "summary": "Here's a focused summary of the paper \"DOS: Diverse Outlier Sampling FOR OUT-OF-DISTRIBUTION DETECTION\" \\cite{jiang2023vzb} for a literature review:\n\n### Technical Paper Analysis: DOS: Diverse Outlier Sampling FOR OUT-OF-DISTRIBUTION DETECTION \\cite{jiang2023vzb}\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem**: Modern neural networks exhibit overconfident predictions for Out-of-Distribution (OOD) inputs, leading to unreliable behavior in real-world deployments. While using auxiliary OOD datasets for regularization during training is common, existing sampling strategies are suboptimal.\n    *   **Importance and challenge**: Reliable OOD detection is crucial for safe and robust machine learning systems. Current methods either randomly sample outliers (inefficient) or greedily select based on predictive uncertainty (biased), failing to capture the full diversity of potential OOD inputs. This bias leads to locally compact decision boundaries, hindering effective differentiation between in-distribution (ID) and OOD data.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches**:\n        *   Builds upon Outlier Exposure (OE) methods that leverage auxiliary OOD datasets during training.\n        *   Contrasts with random sampling strategies (e.g., \\cite{hendrycks2019deep, mohseni2020self, liu2020energy}) which are often inefficient.\n        *   Directly addresses limitations of greedy sampling strategies (e.g., NTOM \\cite{chen2021atom}, \\cite{li2020greedy}) that select \"hard negative examples\" based solely on predictive uncertainty.\n    *   **Limitations of previous solutions**:\n        *   Random sampling: Incorporates many uninformative outliers, leading to loose decision boundaries (Figure 1b).\n        *   Uncertainty-based greedy sampling: Samples are biased towards specific regions or types of outliers, failing to represent the full OOD distribution. This results in locally compact decision boundaries (Figure 1c) and suboptimal OOD detection performance, as empirically shown by \\cite{jiang2023vzb} (Figure 2a, 2b).\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method**: The paper proposes **Diverse Outlier Sampling (DOS)** \\cite{jiang2023vzb}, a novel sampling strategy that selects diverse and informative outliers from an auxiliary OOD dataset.\n    *   **Novelty/Difference**: DOS \\cite{jiang2023vzb} addresses the bias of uncertainty-based sampling by explicitly incorporating diversity. It combines two key steps:\n        1.  **Clustering with Normalized Features**: Candidate OOD samples are partitioned into `k` clusters using K-means on their *normalized* latent representations. Feature normalization is crucial to mitigate bias towards features with larger scales, ensuring more effective clustering.\n        2.  **Active Sampling in Each Cluster**: From each cluster, the *most informative* outlier is selected. Informativeness is defined by the highest inverse absent category probability (i.e., lowest predictive uncertainty for the (K+1)-th \"absent\" class), following the principle of hard negative mining.\n    *   This combined approach aims to shape a globally compact decision boundary between ID and OOD data (Figure 1d), overcoming the local compactness issue of prior greedy methods. A mini-batch scheme is also employed for efficient processing of large auxiliary datasets.\n\n4.  **Key Technical Contributions**\n    *   **Novel sampling strategy (DOS)**: A principled approach that integrates both diversity (via clustering) and informativeness (via uncertainty-based selection) for outlier sampling, addressing the limitations of prior greedy methods.\n    *   **Feature normalization for clustering**: Introduces and validates the use of normalized latent features for K-means clustering of outliers, improving clustering quality by mitigating scale bias.\n    *   **Empirical demonstration of diversity's importance**: Provides empirical evidence that diversity is a critical factor in designing effective outlier sampling strategies for OOD detection.\n    *   **Efficient mini-batch scheme**: Enables practical application of the clustering and sampling process with large auxiliary OOD datasets.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted**: Extensive experiments were performed on common and large-scale OOD detection benchmarks.\n        *   **ID datasets**: CIFAR-100 and ImageNet-1K.\n        *   **Auxiliary OOD training datasets**: TI-300K and INRCS.\n        *   **OOD test datasets**: SVHN, LSUN-C, DTD, Places, LSUN-R, iSUN.\n        *   **Comparisons**: Evaluated against numerous state-of-the-art methods, including those without auxiliary OOD data (e.g., ODIN, Maha, EnergyScore) and those with auxiliary OOD data (e.g., OE, EnergyLoss, NTOM, Share, POEM).\n        *   **Ablation studies**: Investigated the effect of the number of clustering centers, choice of clustering algorithm, and the benefits of feature normalization.\n        *   **Further analysis**: Explored convergence speed and the method's applicability to large models like CLIP.\n    *   **Key performance metrics and comparison results**:\n        *   DOS \\cite{jiang2023vzb} consistently achieved state-of-the-art performance across various benchmarks.\n        *   On CIFAR-100 with TI-300K, DOS \\cite{jiang2023vzb} reduced the average FPR95 (False Positive Rate at 95% True Positive Rate) by up to 25.79% (from 50.15% to 24.36%) compared to the NTOM method.\n        *   Demonstrated consistent superiority over other sampling strategies and regularization terms (e.g., energy loss).\n        *   Showed robust performance with varying scales of auxiliary OOD datasets.\n        *   Analysis indicated faster convergence during training despite the clustering overhead.\n        *   Successfully boosted the OOD detection performance of CLIP, highlighting its value in the era of large models.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations**: The clustering step introduces extra computational overhead, although the paper notes that this can be offset by faster convergence during training.\n    *   **Assumptions**: The method assumes access to a large auxiliary unlabeled OOD training dataset.\n    *   **Scope of applicability**: Primarily demonstrated and validated in the context of supervised multi-class image classification for OOD detection. While the core idea of combining diversity and informativeness might be generalizable, its direct applicability to other domains or OOD settings (e.g., anomaly detection without auxiliary data) is not explicitly explored.\n\n7.  **Technical Significance**\n    *   **Advances the technical state-of-the-art**: DOS \\cite{jiang2023vzb} significantly improves OOD detection performance by providing a more effective way to utilize auxiliary OOD training data, particularly in terms of FPR95.\n    *   **New paradigm for outlier sampling**: Shifts the focus from purely uncertainty-based greedy sampling to a more holistic approach that explicitly considers and enforces diversity in the sampled outliers. This is critical for shaping a globally compact and robust decision boundary.\n    *   **Potential impact on future research**: The insights provided by \\cite{jiang2023vzb} regarding the importance of diversity and the effectiveness of normalized feature clustering can inspire future research into more sophisticated and efficient sampling strategies for OOD detection, especially as models become larger and OOD robustness becomes increasingly vital for real-world applications.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Diverse Outlier Sampling (DOS)",
          "Outlier Exposure (OE)",
          "sampling strategies",
          "clustering",
          "feature normalization",
          "predictive uncertainty",
          "hard negative mining",
          "globally compact decision boundary",
          "state-of-the-art performance",
          "FPR95",
          "large models (CLIP)",
          "auxiliary OOD datasets"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n*   **abstract:** explicitly states, \"we propose a straightforward and novel sampling strategy named dos (diverse outlier sampling) to select diverse and informative outliers.\" it then describes the mechanism of this strategy (\"specifically, we cluster the normalized features...\").\n*   **introduction:** reinforces this by repeating, \"we propose a straightforward and novel sampling strategy named dos (di-verse outlier sampling) to select diverse and informative outliers.\" it also details the mechanism and highlights the benefits of this new strategy.\n*   **keywords from criteria:** the abstract and introduction clearly mention \"propose\" and describe a \"sampling strategy\" which is a type of \"method\" or \"algorithm.\"\n*   **empirical evidence:** while the paper mentions \"we empirically show that diversity is critical\" and \"extensive experiments demonstrate the superiority of dos,\" these empirical findings and evaluations serve to validate the *new method* being proposed. the core contribution is the development of dos, not solely an observation or analysis of existing data. papers that propose new methods and then evaluate them empirically are primarily classified as technical."
      },
      "file_name": "913d26360f1a715f6ae80f5a775f398aa2f66c9d.pdf"
    },
    {
      "success": true,
      "doc_id": "884379f497e5befa361799e7228e2595",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n**CITATION**: \\cite{gao2023epm}\n\n---\n\n*   **Research Problem & Motivation**\n    *   Existing dense Out-of-Distribution (OOD) detection models for semantic segmentation primarily assume no domain shift between training and testing data.\n    *   In real-world scenarios, domain shift (e.g., weather, lighting changes) is prevalent and significantly degrades the accuracy of current OOD detection models.\n    *   State-of-the-art OOD models often fail to distinguish between domain shift (covariant shift) and semantic shift (novel classes), leading to over-confident predictions for unknown objects and high uncertainty scores for inlier-class pixels under domain shift.\n    *   Applying traditional Test-Time Adaptation (TTA) methods to dense OOD detection is challenging because:\n        *   They often assume all test data are under domain shift, whereas OOD detection requires handling both seen and unseen domains without prior knowledge. This can lead to performance degradation on non-shifted data (e.g., Transductive Batch Normalization - TBN).\n        *   The presence of novel classes (semantic shift) can cause unsupervised TTA losses (e.g., entropy minimization) to indiscriminately reduce uncertainty for these novel classes, impairing OOD detection accuracy.\n    *   The core problem is designing an effective test-time adaptation strategy for general dense OOD detection in \"the wild,\" accounting for both domain-level and semantic-level distribution shifts.\n\n*   **Related Work & Positioning**\n    *   **Dense OOD Detection**: Unlike prior work that focuses on designing specialized OOD functions or incorporating additional training data/objectives, this paper aims for a model-agnostic method that enhances OOD detection at test time using online unlabeled data, specifically addressing the unaddressed challenge of domain shift.\n    *   **Test-Time Domain Adaptation (TTA)**: While existing TTA methods adapt BN statistics or model parameters via self-training, this work distinguishes itself by tackling a more general \"open-world scenario\" where test data can originate from seen or unseen domains, and novel objects may exist. It explicitly designs a method to jointly handle both domain and semantic shifts.\n    *   **Novel Class in Unseen Domain**: Unlike Open Set Domain Adaptation (rejecting novel classes during training) or Zero-shot learning with domain shift (requiring domain generalization during training), this work focuses on semantic segmentation (more complex shifts) and operates without additional data or prior knowledge of the test domain during training.\n\n*   **Technical Approach & Innovation**\n    *   Proposes **ATTA (Anomaly-aware Test-Time Adaptation)**, a novel dual-level TTA framework that simultaneously detects and adapts to both domain and semantic shifts in an online, selective manner.\n    *   **Dual-level Detection**:\n        *   **First level (Domain Shift)**: Leverages global low-level feature statistics (from Batch Normalization layers) to determine if an image exhibits domain shift.\n        *   **Second level (Semantic Shift)**: Utilizes dense high-level semantic representations to identify pixels corresponding to novel classes.\n    *   **Cascaded Modular Framework**: Consists of two main stages:\n        *   **A. Selective Batch Normalization (SBN)**:\n            *   Estimates the probability of an input image being from an unknown domain by calculating the Kullbackâ€“Leibler (KL) divergence between the test-time BN statistics and the training-time BN statistics across all BN layers.\n            *   Uses a sigmoid function to normalize this distance into a domain-shift probability `P(zd=1|x)`.\n            *   Dynamically updates BN statistics as a weighted mixture of test-time and training-time statistics, where the weights are based on the inferred domain-shift probability. This selectively adapts BN only when a domain shift is detected, preventing degradation on non-shifted data.\n        *   **B. Anomaly-aware Self-training (AST)**:\n            *   Performs online self-training for the entire segmentation model using an \"anomaly-aware prediction entropy loss.\"\n            *   The loss function minimizes a re-balanced uncertainty of pixel-wise predictions, promoting confidence for both inlier-class predictions and outlier detection.\n            *   Introduces class weights `wc` (with `Î» > 1` for the outlier class) to address class imbalance between inlier and outlier pixels.\n            *   **Key Innovation**: To estimate pixel-wise outlier probability `PÎ¸(Zo_i=1|x)` from unnormalized OOD scores `Gi`, it fits a two-component Mixture of Gaussian (GMM) distribution to the empirical distribution of pixel-wise OOD scores. The GMM components represent inlier and outlier modes.\n            *   A sample-dependent Platt scaling function (sigmoid) is then used, with calibration parameters derived from the GMM fitting, to convert OOD scores into robust outlier probabilities.\n\n*   **Key Technical Contributions**\n    *   **Problem Formulation**: Proposes and highlights the critical problem of dense OOD detection under joint domain and semantic shifts, revealing limitations of existing methods in real-world \"wild\" settings.\n    *   **Dual-Level Adaptation Framework**: Introduces a novel framework that explicitly and jointly tackles both domain-level (image-wide) and semantic-level (pixel-wise) distribution shifts.\n    *   **Selective Batch Normalization (SBN)**: A novel mechanism for dynamically adapting BN statistics based on an estimated domain-shift probability, ensuring adaptation only when necessary and preventing performance degradation on non-shifted data.\n    *   **Anomaly-aware Self-training (AST)**: A robust self-training procedure that incorporates a re-balanced entropy loss and a data-driven, GMM-based Platt scaling approach to accurately estimate pixel-wise outlier probabilities, enhancing novel-class detection capacity.\n    *   **Model-Agnostic Design**: The framework is designed to be applicable to any pretrained segmentation model with an OOD detection head, making it broadly useful.\n\n*   **Experimental Validation**\n    *   **Benchmarks**: Validated on several OOD segmentation benchmarks, including those with and without significant domain shifts: FS Static, FS Lost&Found, RoadAnomaly, and SMIYC.\n    *   **Performance Metrics**: Key performance metric mentioned is AUPRC (Area Under the Precision-Recall Curve).\n    *   **Comparison**: Demonstrated consistent performance improvements across various baseline models (e.g., PEBAL) and compared favorably against existing test-time adaptation methods like TBN and Tent.\n    *   **Results**: Achieves new state-of-the-art performance on the benchmarks, particularly showing significant gains in settings with severe domain shifts.\n\n*   **Limitations & Scope**\n    *   **Scope**: Focused on dense OOD detection in semantic segmentation under real-world conditions with both domain and semantic shifts, applicable to any pretrained segmentation model with an OOD detection head.\n    *   **Assumptions**: The Anomaly-aware Self-training stage relies on the assumption that the empirical distribution of pixel-wise OOD scores is bimodal and can be effectively modeled by a two-component Gaussian Mixture Model to distinguish inliers from outliers.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: Significantly advances the state-of-the-art in dense OOD detection by providing a robust solution for the challenging problem of joint domain and semantic shifts, a critical gap in previous research.\n    *   **Enhanced Reliability**: Enables more reliable deployment of semantic segmentation models in safety-critical applications (e.g., autonomous driving) where environmental variations and novel objects are common, by allowing models to adapt dynamically at test time.\n    *   **Foundational Framework**: Offers a novel, model-agnostic framework that can be integrated with existing OOD detection baselines, providing a strong foundation for future research in adaptive OOD detection and test-time adaptation in complex, open-world environments.",
      "intriguing_abstract": "Deploying semantic segmentation in the wild demands robust Out-of-Distribution (OOD) detection, yet current models falter under prevalent domain shifts and struggle to distinguish novel objects from environmental variations. We introduce **ATTA (Anomaly-aware Test-Time Adaptation)**, a novel dual-level framework designed to dynamically adapt dense OOD detection to both domain and semantic shifts online. ATTA features **Selective Batch Normalization (SBN)**, which intelligently adapts model statistics only when domain shift is detected, preventing performance degradation on non-shifted data. Complementing this is **Anomaly-aware Self-training (AST)**, a robust procedure that leverages a re-balanced entropy loss and a data-driven, Gaussian Mixture Model (GMM)-based Platt scaling to accurately estimate pixel-wise outlier probabilities, significantly enhancing novel-class detection. This model-agnostic approach achieves state-of-the-art performance across challenging OOD segmentation benchmarks, particularly excelling in scenarios with severe domain shifts. ATTA marks a critical step towards enabling reliable, adaptive semantic segmentation for safety-critical applications like autonomous driving, where unseen conditions and objects are inevitable.",
      "keywords": [
        "Dense Out-of-Distribution (OOD) detection",
        "semantic segmentation",
        "domain shift",
        "semantic shift",
        "Test-Time Adaptation (TTA)",
        "joint domain and semantic shifts",
        "Anomaly-aware Test-Time Adaptation (ATTA)",
        "dual-level adaptation framework",
        "Selective Batch Normalization (SBN)",
        "Anomaly-aware Self-training (AST)",
        "Mixture of Gaussian (GMM)",
        "model-agnostic framework",
        "state-of-the-art performance",
        "autonomous driving"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f.pdf",
      "citation_key": "gao2023epm",
      "metadata": {
        "title": "ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation",
        "authors": [
          "Zhitong Gao",
          "Shipeng Yan",
          "Xuming He"
        ],
        "published_date": "2023",
        "abstract": "Recent advancements in dense out-of-distribution (OOD) detection have primarily focused on scenarios where the training and testing datasets share a similar domain, with the assumption that no domain shift exists between them. However, in real-world situations, domain shift often exits and significantly affects the accuracy of existing out-of-distribution (OOD) detection models. In this work, we propose a dual-level OOD detection framework to handle domain shift and semantic shift jointly. The first level distinguishes whether domain shift exists in the image by leveraging global low-level features, while the second level identifies pixels with semantic shift by utilizing dense high-level feature maps. In this way, we can selectively adapt the model to unseen domains as well as enhance model's capacity in detecting novel classes. We validate the efficacy of our proposed method on several OOD segmentation benchmarks, including those with significant domain shifts and those without, observing consistent performance improvements across various baseline models. Code is available at ${\\href{https://github.com/gaozhitong/ATTA}{https://github.com/gaozhitong/ATTA}}$.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 12,
        "score": 6.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n**CITATION**: \\cite{gao2023epm}\n\n---\n\n*   **Research Problem & Motivation**\n    *   Existing dense Out-of-Distribution (OOD) detection models for semantic segmentation primarily assume no domain shift between training and testing data.\n    *   In real-world scenarios, domain shift (e.g., weather, lighting changes) is prevalent and significantly degrades the accuracy of current OOD detection models.\n    *   State-of-the-art OOD models often fail to distinguish between domain shift (covariant shift) and semantic shift (novel classes), leading to over-confident predictions for unknown objects and high uncertainty scores for inlier-class pixels under domain shift.\n    *   Applying traditional Test-Time Adaptation (TTA) methods to dense OOD detection is challenging because:\n        *   They often assume all test data are under domain shift, whereas OOD detection requires handling both seen and unseen domains without prior knowledge. This can lead to performance degradation on non-shifted data (e.g., Transductive Batch Normalization - TBN).\n        *   The presence of novel classes (semantic shift) can cause unsupervised TTA losses (e.g., entropy minimization) to indiscriminately reduce uncertainty for these novel classes, impairing OOD detection accuracy.\n    *   The core problem is designing an effective test-time adaptation strategy for general dense OOD detection in \"the wild,\" accounting for both domain-level and semantic-level distribution shifts.\n\n*   **Related Work & Positioning**\n    *   **Dense OOD Detection**: Unlike prior work that focuses on designing specialized OOD functions or incorporating additional training data/objectives, this paper aims for a model-agnostic method that enhances OOD detection at test time using online unlabeled data, specifically addressing the unaddressed challenge of domain shift.\n    *   **Test-Time Domain Adaptation (TTA)**: While existing TTA methods adapt BN statistics or model parameters via self-training, this work distinguishes itself by tackling a more general \"open-world scenario\" where test data can originate from seen or unseen domains, and novel objects may exist. It explicitly designs a method to jointly handle both domain and semantic shifts.\n    *   **Novel Class in Unseen Domain**: Unlike Open Set Domain Adaptation (rejecting novel classes during training) or Zero-shot learning with domain shift (requiring domain generalization during training), this work focuses on semantic segmentation (more complex shifts) and operates without additional data or prior knowledge of the test domain during training.\n\n*   **Technical Approach & Innovation**\n    *   Proposes **ATTA (Anomaly-aware Test-Time Adaptation)**, a novel dual-level TTA framework that simultaneously detects and adapts to both domain and semantic shifts in an online, selective manner.\n    *   **Dual-level Detection**:\n        *   **First level (Domain Shift)**: Leverages global low-level feature statistics (from Batch Normalization layers) to determine if an image exhibits domain shift.\n        *   **Second level (Semantic Shift)**: Utilizes dense high-level semantic representations to identify pixels corresponding to novel classes.\n    *   **Cascaded Modular Framework**: Consists of two main stages:\n        *   **A. Selective Batch Normalization (SBN)**:\n            *   Estimates the probability of an input image being from an unknown domain by calculating the Kullbackâ€“Leibler (KL) divergence between the test-time BN statistics and the training-time BN statistics across all BN layers.\n            *   Uses a sigmoid function to normalize this distance into a domain-shift probability `P(zd=1|x)`.\n            *   Dynamically updates BN statistics as a weighted mixture of test-time and training-time statistics, where the weights are based on the inferred domain-shift probability. This selectively adapts BN only when a domain shift is detected, preventing degradation on non-shifted data.\n        *   **B. Anomaly-aware Self-training (AST)**:\n            *   Performs online self-training for the entire segmentation model using an \"anomaly-aware prediction entropy loss.\"\n            *   The loss function minimizes a re-balanced uncertainty of pixel-wise predictions, promoting confidence for both inlier-class predictions and outlier detection.\n            *   Introduces class weights `wc` (with `Î» > 1` for the outlier class) to address class imbalance between inlier and outlier pixels.\n            *   **Key Innovation**: To estimate pixel-wise outlier probability `PÎ¸(Zo_i=1|x)` from unnormalized OOD scores `Gi`, it fits a two-component Mixture of Gaussian (GMM) distribution to the empirical distribution of pixel-wise OOD scores. The GMM components represent inlier and outlier modes.\n            *   A sample-dependent Platt scaling function (sigmoid) is then used, with calibration parameters derived from the GMM fitting, to convert OOD scores into robust outlier probabilities.\n\n*   **Key Technical Contributions**\n    *   **Problem Formulation**: Proposes and highlights the critical problem of dense OOD detection under joint domain and semantic shifts, revealing limitations of existing methods in real-world \"wild\" settings.\n    *   **Dual-Level Adaptation Framework**: Introduces a novel framework that explicitly and jointly tackles both domain-level (image-wide) and semantic-level (pixel-wise) distribution shifts.\n    *   **Selective Batch Normalization (SBN)**: A novel mechanism for dynamically adapting BN statistics based on an estimated domain-shift probability, ensuring adaptation only when necessary and preventing performance degradation on non-shifted data.\n    *   **Anomaly-aware Self-training (AST)**: A robust self-training procedure that incorporates a re-balanced entropy loss and a data-driven, GMM-based Platt scaling approach to accurately estimate pixel-wise outlier probabilities, enhancing novel-class detection capacity.\n    *   **Model-Agnostic Design**: The framework is designed to be applicable to any pretrained segmentation model with an OOD detection head, making it broadly useful.\n\n*   **Experimental Validation**\n    *   **Benchmarks**: Validated on several OOD segmentation benchmarks, including those with and without significant domain shifts: FS Static, FS Lost&Found, RoadAnomaly, and SMIYC.\n    *   **Performance Metrics**: Key performance metric mentioned is AUPRC (Area Under the Precision-Recall Curve).\n    *   **Comparison**: Demonstrated consistent performance improvements across various baseline models (e.g., PEBAL) and compared favorably against existing test-time adaptation methods like TBN and Tent.\n    *   **Results**: Achieves new state-of-the-art performance on the benchmarks, particularly showing significant gains in settings with severe domain shifts.\n\n*   **Limitations & Scope**\n    *   **Scope**: Focused on dense OOD detection in semantic segmentation under real-world conditions with both domain and semantic shifts, applicable to any pretrained segmentation model with an OOD detection head.\n    *   **Assumptions**: The Anomaly-aware Self-training stage relies on the assumption that the empirical distribution of pixel-wise OOD scores is bimodal and can be effectively modeled by a two-component Gaussian Mixture Model to distinguish inliers from outliers.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: Significantly advances the state-of-the-art in dense OOD detection by providing a robust solution for the challenging problem of joint domain and semantic shifts, a critical gap in previous research.\n    *   **Enhanced Reliability**: Enables more reliable deployment of semantic segmentation models in safety-critical applications (e.g., autonomous driving) where environmental variations and novel objects are common, by allowing models to adapt dynamically at test time.\n    *   **Foundational Framework**: Offers a novel, model-agnostic framework that can be integrated with existing OOD detection baselines, providing a strong foundation for future research in adaptive OOD detection and test-time adaptation in complex, open-world environments.",
        "keywords": [
          "Dense Out-of-Distribution (OOD) detection",
          "semantic segmentation",
          "domain shift",
          "semantic shift",
          "Test-Time Adaptation (TTA)",
          "joint domain and semantic shifts",
          "Anomaly-aware Test-Time Adaptation (ATTA)",
          "dual-level adaptation framework",
          "Selective Batch Normalization (SBN)",
          "Anomaly-aware Self-training (AST)",
          "Mixture of Gaussian (GMM)",
          "model-agnostic framework",
          "state-of-the-art performance",
          "autonomous driving"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** a dual-level ood detection framework\" and \"we validate the efficacy of our **method**\".\n*   the introduction discusses a technical problem (dense ood detection under domain shift) and the abstract outlines the proposed solution (a dual-level framework).\n*   the validation on \"several ood segmentation benchmarks\" confirms the evaluation of a new method or system.\n\nthese points align perfectly with the criteria for a **technical** paper.\n\n**classification: technical**"
      },
      "file_name": "f72c1bfe25d68a7d6d008b0d500d2670ebe2bf4f.pdf"
    },
    {
      "success": true,
      "doc_id": "6938ae0f323df30a7ba20b8ab11e1c12",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/89e108b5822004ddeee6e2b17e9096f8e4d74f12.pdf",
      "citation_key": "henriksson20233hb",
      "metadata": {
        "title": "Out-of-Distribution Detection as Support for Autonomous Driving Safety Lifecycle",
        "authors": [
          "Jens Henriksson",
          "Stig Ursing",
          "Murat Erdogan",
          "Fredrik Warg",
          "Anders ThorsÃ©n",
          "Johan Jaxing",
          "Ola Ã–rsmark",
          "Mathias Ã–rtenberg ToftÃ¥s"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/89e108b5822004ddeee6e2b17e9096f8e4d74f12.pdf",
        "venue": "Requirements Engineering: Foundation for Software Quality",
        "citationCount": 12,
        "score": 6.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "89e108b5822004ddeee6e2b17e9096f8e4d74f12.pdf"
    },
    {
      "success": true,
      "doc_id": "b8ddada2d8366694def1daeebca98a60",
      "summary": "Plants encounter a variety of beneficial and harmful insects during their growth cycle. Accurate identification (i.e., detecting insectsâ€™ presence) and classification (i.e., determining the type or class) of these insect species is critical for implementing prompt and suitable mitigation strategies. Such timely actions carry substantial economic and environmental implications. Deep learning-based approaches have produced models with good insect classification accuracy. Researchers aim to implement identification and classification models in agriculture, facing challenges when input images markedly deviate from the training distribution (e.g., images like vehicles, humans, or a blurred image or insect class that is not yet trained on). Out-of-distribution (OOD) detection algorithms provide an exciting avenue to overcome these challenges as they ensure that a model abstains from making incorrect classification predictions on images that belong to non-insect and/or untrained insect classes. As far as we know, no prior in-depth exploration has been conducted on the role of the OOD detection algorithms in addressing agricultural issues. Here, we generate and evaluate the performance of state-of-the-art OOD algorithms on insect detection classifiers. These algorithms represent a diversity of methods for addressing an OOD problem. Specifically, we focus on extrusive algorithms, i.e., algorithms that wrap around a well-trained classifier without the need for additional co-training. We compared three OOD detection algorithms: (a) maximum softmax probability, which uses the softmax value as a confidence score; (b) Mahalanobis distance (MAH)-based algorithm, which uses a generative classification approach; and (c) energy-based algorithm, which maps the input data to a scalar value, called energy. We performed an extensive series of evaluations of these OOD algorithms across three performance axes: (a) Base model accuracy: How does the accuracy of the classifier impact OOD performance? (b) How does the level of dissimilarity to the domain impact OOD performance? (c) Data imbalance: How sensitive is OOD performance to the imbalance in per-class sample size? Evaluating OOD algorithms across these performance axes provides practical guidelines to ensure the robust performance of well-trained models in the wild, which is a key consideration for agricultural applications. Based on this analysis, we proposed the most effective OOD algorithm as wrapper for the insect classifier with highest accuracy. We presented the results of its OOD detection performance in the paper. Our results indicate that OOD detection algorithms can significantly enhance user trust in insect pest classification by abstaining classification under uncertain conditions.",
      "intriguing_abstract": "Plants encounter a variety of beneficial and harmful insects during their growth cycle. Accurate identification (i.e., detecting insectsâ€™ presence) and classification (i.e., determining the type or class) of these insect species is critical for implementing prompt and suitable mitigation strategies. Such timely actions carry substantial economic and environmental implications. Deep learning-based approaches have produced models with good insect classification accuracy. Researchers aim to implement identification and classification models in agriculture, facing challenges when input images markedly deviate from the training distribution (e.g., images like vehicles, humans, or a blurred image or insect class that is not yet trained on). Out-of-distribution (OOD) detection algorithms provide an exciting avenue to overcome these challenges as they ensure that a model abstains from making incorrect classification predictions on images that belong to non-insect and/or untrained insect classes. As far as we know, no prior in-depth exploration has been conducted on the role of the OOD detection algorithms in addressing agricultural issues. Here, we generate and evaluate the performance of state-of-the-art OOD algorithms on insect detection classifiers. These algorithms represent a diversity of methods for addressing an OOD problem. Specifically, we focus on extrusive algorithms, i.e., algorithms that wrap around a well-trained classifier without the need for additional co-training. We compared three OOD detection algorithms: (a) maximum softmax probability, which uses the softmax value as a confidence score; (b) Mahalanobis distance (MAH)-based algorithm, which uses a generative classification approach; and (c) energy-based algorithm, which maps the input data to a scalar value, called energy. We performed an extensive series of evaluations of these OOD algorithms across three performance axes: (a) Base model accuracy: How does the accuracy of the classifier impact OOD performance? (b) How does the level of dissimilarity to the domain impact OOD performance? (c) Data imbalance: How sensitive is OOD performance to the imbalance in per-class sample size? Evaluating OOD algorithms across these performance axes provides practical guidelines to ensure the robust performance of well-trained models in the wild, which is a key consideration for agricultural applications. Based on this analysis, we proposed the most effective OOD algorithm as wrapper for the insect classifier with highest accuracy. We presented the results of its OOD detection performance in the paper. Our results indicate that OOD detection algorithms can significantly enhance user trust in insect pest classification by abstaining classification under uncertain conditions.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/94f7e9837b598b619ffeb26ee90ba59ff4a8ffff.pdf",
      "citation_key": "saadati2023i8u",
      "metadata": {
        "title": "Out-of-Distribution Detection Algorithms for Robust Insect Classification",
        "authors": [
          "M. Saadati",
          "Aditya Balu",
          "Shivani Chiranjeevi",
          "T. Jubery",
          "Ashutosh Kumar Singh",
          "S. Sarkar",
          "Arti Singh",
          "B. Ganapathysubramanian"
        ],
        "published_date": "2023",
        "abstract": "Plants encounter a variety of beneficial and harmful insects during their growth cycle. Accurate identification (i.e., detecting insectsâ€™ presence) and classification (i.e., determining the type or class) of these insect species is critical for implementing prompt and suitable mitigation strategies. Such timely actions carry substantial economic and environmental implications. Deep learning-based approaches have produced models with good insect classification accuracy. Researchers aim to implement identification and classification models in agriculture, facing challenges when input images markedly deviate from the training distribution (e.g., images like vehicles, humans, or a blurred image or insect class that is not yet trained on). Out-of-distribution (OOD) detection algorithms provide an exciting avenue to overcome these challenges as they ensure that a model abstains from making incorrect classification predictions on images that belong to non-insect and/or untrained insect classes. As far as we know, no prior in-depth exploration has been conducted on the role of the OOD detection algorithms in addressing agricultural issues. Here, we generate and evaluate the performance of state-of-the-art OOD algorithms on insect detection classifiers. These algorithms represent a diversity of methods for addressing an OOD problem. Specifically, we focus on extrusive algorithms, i.e., algorithms that wrap around a well-trained classifier without the need for additional co-training. We compared three OOD detection algorithms: (a) maximum softmax probability, which uses the softmax value as a confidence score; (b) Mahalanobis distance (MAH)-based algorithm, which uses a generative classification approach; and (c) energy-based algorithm, which maps the input data to a scalar value, called energy. We performed an extensive series of evaluations of these OOD algorithms across three performance axes: (a) Base model accuracy: How does the accuracy of the classifier impact OOD performance? (b) How does the level of dissimilarity to the domain impact OOD performance? (c) Data imbalance: How sensitive is OOD performance to the imbalance in per-class sample size? Evaluating OOD algorithms across these performance axes provides practical guidelines to ensure the robust performance of well-trained models in the wild, which is a key consideration for agricultural applications. Based on this analysis, we proposed the most effective OOD algorithm as wrapper for the insect classifier with highest accuracy. We presented the results of its OOD detection performance in the paper. Our results indicate that OOD detection algorithms can significantly enhance user trust in insect pest classification by abstaining classification under uncertain conditions.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/94f7e9837b598b619ffeb26ee90ba59ff4a8ffff.pdf",
        "venue": "Plant Phenomics",
        "citationCount": 12,
        "score": 6.0,
        "summary": "Plants encounter a variety of beneficial and harmful insects during their growth cycle. Accurate identification (i.e., detecting insectsâ€™ presence) and classification (i.e., determining the type or class) of these insect species is critical for implementing prompt and suitable mitigation strategies. Such timely actions carry substantial economic and environmental implications. Deep learning-based approaches have produced models with good insect classification accuracy. Researchers aim to implement identification and classification models in agriculture, facing challenges when input images markedly deviate from the training distribution (e.g., images like vehicles, humans, or a blurred image or insect class that is not yet trained on). Out-of-distribution (OOD) detection algorithms provide an exciting avenue to overcome these challenges as they ensure that a model abstains from making incorrect classification predictions on images that belong to non-insect and/or untrained insect classes. As far as we know, no prior in-depth exploration has been conducted on the role of the OOD detection algorithms in addressing agricultural issues. Here, we generate and evaluate the performance of state-of-the-art OOD algorithms on insect detection classifiers. These algorithms represent a diversity of methods for addressing an OOD problem. Specifically, we focus on extrusive algorithms, i.e., algorithms that wrap around a well-trained classifier without the need for additional co-training. We compared three OOD detection algorithms: (a) maximum softmax probability, which uses the softmax value as a confidence score; (b) Mahalanobis distance (MAH)-based algorithm, which uses a generative classification approach; and (c) energy-based algorithm, which maps the input data to a scalar value, called energy. We performed an extensive series of evaluations of these OOD algorithms across three performance axes: (a) Base model accuracy: How does the accuracy of the classifier impact OOD performance? (b) How does the level of dissimilarity to the domain impact OOD performance? (c) Data imbalance: How sensitive is OOD performance to the imbalance in per-class sample size? Evaluating OOD algorithms across these performance axes provides practical guidelines to ensure the robust performance of well-trained models in the wild, which is a key consideration for agricultural applications. Based on this analysis, we proposed the most effective OOD algorithm as wrapper for the insect classifier with highest accuracy. We presented the results of its OOD detection performance in the paper. Our results indicate that OOD detection algorithms can significantly enhance user trust in insect pest classification by abstaining classification under uncertain conditions.",
        "keywords": []
      },
      "file_name": "94f7e9837b598b619ffeb26ee90ba59ff4a8ffff.pdf"
    },
    {
      "success": true,
      "doc_id": "a092e4e94b36d7da61e67983c3f04594",
      "summary": "Traffic classification has always been one of the important research directions in the field of cyber security. Achieving rapid traffic classification and detecting unknown traffic are critical for preventing network attacks, malicious software, transaction fraud, and other types of cyber security threats. However, most existing models are based on large-scale data and are unable to quickly learn and recognize unknown traffic. Some methods based on few-shot learning solve the problem of rapidly learning new types of traffic, but they cannot detect out-of-distribution samples. Based on this, this paper proposes a few-shot traffic multi-classification method that supports out-of-distribution detection, named SPN. It improves the performance by integrating twin networks into the meta-learning framework based on the idea of metric learning, and introduces margin loss to ensure detection performance. We conduct two types of experiments, and compare them with the relevant baseline methods. The results show that SPN has excellent performance in implementing few-shot multi-classification and out-of-distribution detection, and performs well in intrusion detection.",
      "intriguing_abstract": "Traffic classification has always been one of the important research directions in the field of cyber security. Achieving rapid traffic classification and detecting unknown traffic are critical for preventing network attacks, malicious software, transaction fraud, and other types of cyber security threats. However, most existing models are based on large-scale data and are unable to quickly learn and recognize unknown traffic. Some methods based on few-shot learning solve the problem of rapidly learning new types of traffic, but they cannot detect out-of-distribution samples. Based on this, this paper proposes a few-shot traffic multi-classification method that supports out-of-distribution detection, named SPN. It improves the performance by integrating twin networks into the meta-learning framework based on the idea of metric learning, and introduces margin loss to ensure detection performance. We conduct two types of experiments, and compare them with the relevant baseline methods. The results show that SPN has excellent performance in implementing few-shot multi-classification and out-of-distribution detection, and performs well in intrusion detection.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/7da7d9d38b964a70396fa842bf69f9a897111c26.pdf",
      "citation_key": "miao2023zf5",
      "metadata": {
        "title": "SPN: A Method of Few-Shot Traffic Classification With Out-of-Distribution Detection Based on Siamese Prototypical Network",
        "authors": [
          "Gongxun Miao",
          "Guohua Wu",
          "Zhen Zhang",
          "Yongjie Tong",
          "Bing Lu"
        ],
        "published_date": "2023",
        "abstract": "Traffic classification has always been one of the important research directions in the field of cyber security. Achieving rapid traffic classification and detecting unknown traffic are critical for preventing network attacks, malicious software, transaction fraud, and other types of cyber security threats. However, most existing models are based on large-scale data and are unable to quickly learn and recognize unknown traffic. Some methods based on few-shot learning solve the problem of rapidly learning new types of traffic, but they cannot detect out-of-distribution samples. Based on this, this paper proposes a few-shot traffic multi-classification method that supports out-of-distribution detection, named SPN. It improves the performance by integrating twin networks into the meta-learning framework based on the idea of metric learning, and introduces margin loss to ensure detection performance. We conduct two types of experiments, and compare them with the relevant baseline methods. The results show that SPN has excellent performance in implementing few-shot multi-classification and out-of-distribution detection, and performs well in intrusion detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/7da7d9d38b964a70396fa842bf69f9a897111c26.pdf",
        "venue": "IEEE Access",
        "citationCount": 11,
        "score": 5.5,
        "summary": "Traffic classification has always been one of the important research directions in the field of cyber security. Achieving rapid traffic classification and detecting unknown traffic are critical for preventing network attacks, malicious software, transaction fraud, and other types of cyber security threats. However, most existing models are based on large-scale data and are unable to quickly learn and recognize unknown traffic. Some methods based on few-shot learning solve the problem of rapidly learning new types of traffic, but they cannot detect out-of-distribution samples. Based on this, this paper proposes a few-shot traffic multi-classification method that supports out-of-distribution detection, named SPN. It improves the performance by integrating twin networks into the meta-learning framework based on the idea of metric learning, and introduces margin loss to ensure detection performance. We conduct two types of experiments, and compare them with the relevant baseline methods. The results show that SPN has excellent performance in implementing few-shot multi-classification and out-of-distribution detection, and performs well in intrusion detection.",
        "keywords": []
      },
      "file_name": "7da7d9d38b964a70396fa842bf69f9a897111c26.pdf"
    },
    {
      "success": true,
      "doc_id": "c8a8efdf4be381abc73bc4f2eabc654c",
      "summary": "Here's a focused summary of the paper \"GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection\" \\cite{chen2023za1} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem:** Deep neural networks deployed in real-world scenarios often encounter out-of-distribution (OOD) inputs, leading to unreliable and potentially overconfident predictions. Detecting these OOD examples is crucial for ensuring model safety and reliability.\n    *   **Motivation:** The authors observe that gradient-based attribution methods, which explain model decisions, struggle to assign meaningful feature importance to OOD data. This results in \"divergent explanation patterns\" or \"meaningless attribution results\" for OOD samples, unlike the clear explanations for in-distribution (ID) data. This unreliability in explanations is proposed as a novel signal for OOD detection.\n\n*   **Related Work & Positioning**\n    *   **Relation:** This work contributes to the field of post-hoc OOD detection.\n    *   **Limitations of previous solutions:** Most prior OOD detection approaches focus on defining uncertainty measures using model outputs (e.g., softmax scores, energy scores) or feature representations (e.g., Mahalanobis distance). While some gradient-based methods exist, they primarily utilize *parameter* gradients. This paper highlights the \"limited attention to the in-depth exploration of gradients related to the inputs (i.e., attribution gradients)\" in existing OOD detection literature.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes **GAIA (Gradient Abnormality Inspection and Aggregation)**, a framework that quantifies the \"abnormality\" in gradient-based attribution results to detect OOD samples.\n    *   **Novelty/Innovation:**\n        *   **Novel Perspective:** It introduces a new paradigm for OOD detection by leveraging the uncertainty inherent in model explanations (specifically, attribution gradients) rather than just predictive outputs or feature embeddings.\n        *   **Two Forms of Abnormality:**\n            *   **Zero-deflation abnormality (GAIA-Z):** Observes that OOD samples lead to a significantly lower quantity of zero partial derivatives in attribution gradients, resulting in \"dense gradient matrices\" and abnormal non-zero density, especially in deeper layers.\n            *   **Channel-wise average abnormality (GAIA-A):** Notes that OOD samples produce noisier and more abnormal outliers in the distribution of channel-wise average attribution gradients compared to ID samples.\n        *   **Aggregation Strategy:** These abnormalities are aggregated across multiple layers and channels into a global OOD score using the Frobenius norm.\n        *   **Efficiency:** GAIA is designed as a lightweight, plug-and-play, post-hoc method that is hyperparameter-free, training-free, and requires no ID data or outliers for estimation.\n\n*   **Key Technical Contributions**\n    *   **Theoretical Insight:** Provides a theoretical explanation for attribution abnormality based on Taylor expansion, linking zero attribution gradients to zero importance (Null-player axiom) and explaining why OOD data leads to intricate non-zero attributions.\n    *   **Novel Abnormality Metrics:** Introduces two specific, quantifiable metrics for OOD detection: the non-zero density of attribution gradients (Eq. 10 for GAIA-Z) and a ratio of inner-component to output-component average attribution gradients (Eq. 11 for GAIA-A).\n    *   **Aggregation Framework:** Develops the GAIA framework for systematically inspecting and aggregating these gradient-based abnormalities across network layers and channels (Eq. 12) to produce a robust OOD score.\n    *   **Practicality:** The proposed method is post-hoc, requiring no model retraining or fine-tuning, making it highly practical for existing deployed models.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Comprehensive experiments were performed on both commonly utilized benchmarks (CIFAR10, CIFAR100 with ResNet34 and WRN40) and a large-scale, challenging benchmark (ImageNet-1K). OOD datasets included SVHN, TinyImageNet, LSUN, Places, and Textures.\n    *   **Key Performance Metrics:** False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC).\n    *   **Comparison Results:** GAIA was compared against advanced post-hoc methods such as MSP, ODIN, Energy, Mahalanobis, ReAct, GradNorm, KNN, and ASH-P@70.\n        *   **CIFAR Benchmarks:** GAIA-Z demonstrated superior performance, reducing the average FPR95 by **23.10% on CIFAR10** and by **45.41% on CIFAR100** compared to advanced post-hoc methods.\n        *   **ImageNet-1K Benchmark:** GAIA-A performed well, reducing FPR95 by **17.28%** compared to the advanced gradient-based detection method GradNorm.\n        *   Overall, GAIA consistently surpassed most advanced post-hoc methods across various benchmarks.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The paper does not explicitly list limitations. However, the approach is specifically tailored to gradient-based attribution methods and their observed abnormalities. Its applicability might be limited to models where such attribution gradients are meaningful and calculable. The theoretical explanation relies on Taylor expansion, which is an approximation.\n    *   **Scope of Applicability:** The method is designed for post-hoc OOD detection in deep neural networks, primarily validated on image classification tasks. It is applicable to scenarios where model explanations can be derived from attribution gradients.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** GAIA significantly advances the technical state-of-the-art in post-hoc OOD detection, particularly on challenging benchmarks like CIFAR and ImageNet-1K, by achieving substantial reductions in FPR95.\n    *   **Potential Impact:** It introduces a novel and promising direction for OOD detection by bridging the gap between model explainability and uncertainty estimation. This opens new avenues for research into how the \"interpretability\" of a model's decision can directly inform its reliability, potentially leading to more robust and trustworthy AI systems. The simplicity and efficiency of GAIA make it a highly practical solution for real-world deployment.",
      "intriguing_abstract": "The Achilles' heel of deep neural networks lies in their overconfident failures when confronted with out-of-distribution (OOD) inputs, demanding robust detection mechanisms for safe AI deployment. This paper unveils a fundamental anomaly: gradient-based attribution methods, designed to explain model decisions, yield profoundly 'meaningless' and divergent patterns for OOD data, unlike the clear explanations for in-distribution samples. Leveraging this insight, we introduce **GAIA (Gradient Abnormality Inspection and Aggregation)**, a novel post-hoc framework that quantifies these inherent uncertainties in model explanations for OOD detection. GAIA pioneers a new paradigm by focusing on two distinct forms of attribution abnormality: **zero-deflation abnormality (GAIA-Z)**, where OOD inputs lead to abnormally dense gradient matrices, and **channel-wise average abnormality (GAIA-A)**, revealing noisier, outlying channel-wise gradient distributions. Aggregating these signals, GAIA is a lightweight, training-free, and hyperparameter-free solution that significantly outperforms state-of-the-art post-hoc OOD detectors. Our extensive experiments demonstrate substantial reductions in FPR95, including **23.10% on CIFAR10** and **45.41% on CIFAR100**, and **17.28% on ImageNet-1K** against advanced gradient-based methods. GAIA bridges the critical gap between model explainability and uncertainty estimation, paving the way for more trustworthy and reliable AI systems.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "Gradient-based attribution abnormality",
        "Attribution gradients",
        "GAIA framework",
        "Model explainability",
        "Uncertainty estimation",
        "Zero-deflation abnormality (GAIA-Z)",
        "Channel-wise average abnormality (GAIA-A)",
        "Post-hoc OOD detection",
        "Novel OOD signal",
        "Theoretical insight (Taylor expansion)",
        "FPR95 reduction",
        "Robust AI systems"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/08925eef04eada4dd46dd3a33ea35f05795b12a9.pdf",
      "citation_key": "chen2023za1",
      "metadata": {
        "title": "GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection",
        "authors": [
          "Jinggang Chen",
          "Junjie Li",
          "Xiaoyang Qu",
          "Jianzong Wang",
          "Jiguang Wan",
          "Jing Xiao"
        ],
        "published_date": "2023",
        "abstract": "Detecting out-of-distribution (OOD) examples is crucial to guarantee the reliability and safety of deep neural networks in real-world settings. In this paper, we offer an innovative perspective on quantifying the disparities between in-distribution (ID) and OOD data -- analyzing the uncertainty that arises when models attempt to explain their predictive decisions. This perspective is motivated by our observation that gradient-based attribution methods encounter challenges in assigning feature importance to OOD data, thereby yielding divergent explanation patterns. Consequently, we investigate how attribution gradients lead to uncertain explanation outcomes and introduce two forms of abnormalities for OOD detection: the zero-deflation abnormality and the channel-wise average abnormality. We then propose GAIA, a simple and effective approach that incorporates Gradient Abnormality Inspection and Aggregation. The effectiveness of GAIA is validated on both commonly utilized (CIFAR) and large-scale (ImageNet-1k) benchmarks. Specifically, GAIA reduces the average FPR95 by 23.10% on CIFAR10 and by 45.41% on CIFAR100 compared to advanced post-hoc methods.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/08925eef04eada4dd46dd3a33ea35f05795b12a9.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 11,
        "score": 5.5,
        "summary": "Here's a focused summary of the paper \"GAIA: Delving into Gradient-based Attribution Abnormality for Out-of-distribution Detection\" \\cite{chen2023za1} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem:** Deep neural networks deployed in real-world scenarios often encounter out-of-distribution (OOD) inputs, leading to unreliable and potentially overconfident predictions. Detecting these OOD examples is crucial for ensuring model safety and reliability.\n    *   **Motivation:** The authors observe that gradient-based attribution methods, which explain model decisions, struggle to assign meaningful feature importance to OOD data. This results in \"divergent explanation patterns\" or \"meaningless attribution results\" for OOD samples, unlike the clear explanations for in-distribution (ID) data. This unreliability in explanations is proposed as a novel signal for OOD detection.\n\n*   **Related Work & Positioning**\n    *   **Relation:** This work contributes to the field of post-hoc OOD detection.\n    *   **Limitations of previous solutions:** Most prior OOD detection approaches focus on defining uncertainty measures using model outputs (e.g., softmax scores, energy scores) or feature representations (e.g., Mahalanobis distance). While some gradient-based methods exist, they primarily utilize *parameter* gradients. This paper highlights the \"limited attention to the in-depth exploration of gradients related to the inputs (i.e., attribution gradients)\" in existing OOD detection literature.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes **GAIA (Gradient Abnormality Inspection and Aggregation)**, a framework that quantifies the \"abnormality\" in gradient-based attribution results to detect OOD samples.\n    *   **Novelty/Innovation:**\n        *   **Novel Perspective:** It introduces a new paradigm for OOD detection by leveraging the uncertainty inherent in model explanations (specifically, attribution gradients) rather than just predictive outputs or feature embeddings.\n        *   **Two Forms of Abnormality:**\n            *   **Zero-deflation abnormality (GAIA-Z):** Observes that OOD samples lead to a significantly lower quantity of zero partial derivatives in attribution gradients, resulting in \"dense gradient matrices\" and abnormal non-zero density, especially in deeper layers.\n            *   **Channel-wise average abnormality (GAIA-A):** Notes that OOD samples produce noisier and more abnormal outliers in the distribution of channel-wise average attribution gradients compared to ID samples.\n        *   **Aggregation Strategy:** These abnormalities are aggregated across multiple layers and channels into a global OOD score using the Frobenius norm.\n        *   **Efficiency:** GAIA is designed as a lightweight, plug-and-play, post-hoc method that is hyperparameter-free, training-free, and requires no ID data or outliers for estimation.\n\n*   **Key Technical Contributions**\n    *   **Theoretical Insight:** Provides a theoretical explanation for attribution abnormality based on Taylor expansion, linking zero attribution gradients to zero importance (Null-player axiom) and explaining why OOD data leads to intricate non-zero attributions.\n    *   **Novel Abnormality Metrics:** Introduces two specific, quantifiable metrics for OOD detection: the non-zero density of attribution gradients (Eq. 10 for GAIA-Z) and a ratio of inner-component to output-component average attribution gradients (Eq. 11 for GAIA-A).\n    *   **Aggregation Framework:** Develops the GAIA framework for systematically inspecting and aggregating these gradient-based abnormalities across network layers and channels (Eq. 12) to produce a robust OOD score.\n    *   **Practicality:** The proposed method is post-hoc, requiring no model retraining or fine-tuning, making it highly practical for existing deployed models.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Comprehensive experiments were performed on both commonly utilized benchmarks (CIFAR10, CIFAR100 with ResNet34 and WRN40) and a large-scale, challenging benchmark (ImageNet-1K). OOD datasets included SVHN, TinyImageNet, LSUN, Places, and Textures.\n    *   **Key Performance Metrics:** False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC).\n    *   **Comparison Results:** GAIA was compared against advanced post-hoc methods such as MSP, ODIN, Energy, Mahalanobis, ReAct, GradNorm, KNN, and ASH-P@70.\n        *   **CIFAR Benchmarks:** GAIA-Z demonstrated superior performance, reducing the average FPR95 by **23.10% on CIFAR10** and by **45.41% on CIFAR100** compared to advanced post-hoc methods.\n        *   **ImageNet-1K Benchmark:** GAIA-A performed well, reducing FPR95 by **17.28%** compared to the advanced gradient-based detection method GradNorm.\n        *   Overall, GAIA consistently surpassed most advanced post-hoc methods across various benchmarks.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The paper does not explicitly list limitations. However, the approach is specifically tailored to gradient-based attribution methods and their observed abnormalities. Its applicability might be limited to models where such attribution gradients are meaningful and calculable. The theoretical explanation relies on Taylor expansion, which is an approximation.\n    *   **Scope of Applicability:** The method is designed for post-hoc OOD detection in deep neural networks, primarily validated on image classification tasks. It is applicable to scenarios where model explanations can be derived from attribution gradients.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** GAIA significantly advances the technical state-of-the-art in post-hoc OOD detection, particularly on challenging benchmarks like CIFAR and ImageNet-1K, by achieving substantial reductions in FPR95.\n    *   **Potential Impact:** It introduces a novel and promising direction for OOD detection by bridging the gap between model explainability and uncertainty estimation. This opens new avenues for research into how the \"interpretability\" of a model's decision can directly inform its reliability, potentially leading to more robust and trustworthy AI systems. The simplicity and efficiency of GAIA make it a highly practical solution for real-world deployment.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "Gradient-based attribution abnormality",
          "Attribution gradients",
          "GAIA framework",
          "Model explainability",
          "Uncertainty estimation",
          "Zero-deflation abnormality (GAIA-Z)",
          "Channel-wise average abnormality (GAIA-A)",
          "Post-hoc OOD detection",
          "Novel OOD signal",
          "Theoretical insight (Taylor expansion)",
          "FPR95 reduction",
          "Robust AI systems"
        ],
        "paper_type": "this paper is best classified as **technical**.\n\nhere's why:\n\n*   **abstract:** explicitly states \"we investigate how attribution gradients lead to uncertain explanation outcomes and introduce two forms of abnormalities for ood detection\" and \"we then propose gaia, a simple and effective approach that incorporates gradient abnormality inspection and aggregation.\" this clearly indicates the development and presentation of new methods and concepts.\n*   **introduction:** discusses a \"technical problem\" (ood detection, limitations of prior gradient-based methods) and sets the stage for the \"proposed solution\" (gaia, as mentioned in the abstract).\n*   **empirical evidence:** while the abstract also mentions \"the effectiveness of gaia is validated on both commonly utilized (cifar) and large-scale (imagenet-1k) benchmarks\" and provides specific quantitative results, this empirical validation serves to demonstrate the efficacy of the *proposed technical method*. the primary contribution is the method itself."
      },
      "file_name": "08925eef04eada4dd46dd3a33ea35f05795b12a9.pdf"
    },
    {
      "success": true,
      "doc_id": "bc5f55adcae90fb9ae66cf3e3ecb4731",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific technical problem**: The paper addresses the challenge of simultaneously performing incremental object classification and out-of-distribution (OOD) detection in a continual learning (CL) setting. Existing evidential deep learning (EDL) methods, effective for OOD detection, typically assume data is independently and identically distributed (i.i.d.) and available jointly, which is unrealistic for sequential data streams.\n    *   **Importance and Challenge**: In real-world applications, data arrives sequentially, leading to distribution shifts over time. Models must continually learn new knowledge without catastrophically forgetting old knowledge (the plasticity-stability dilemma) while also reliably identifying novel, unseen (OOD) data. Integrating uncertainty estimation, specifically evidential deep learning, into this dynamic, open-world CL scenario is crucial for robust and trustworthy AI but has not been thoroughly explored.\n\n*   **Related Work & Positioning**\n    *   **Relation to existing approaches**: This work builds upon Evidential Deep Learning (EDL) for uncertainty estimation and various Continual Learning (CL) strategies (regularization, rehearsal). It also relates to recent efforts in Continual OOD detection.\n    *   **Limitations of previous solutions**:\n        *   Standard EDL methods assume i.i.d. data, making them unsuitable for sequential learning in CL.\n        *   Most CL methods focus on classification in a closed-world setting, often using standard cross-entropy loss, and do not inherently handle OOD detection.\n        *   While some uncertainty-aware CL methods exist (e.g., Bayesian approaches), they haven't deeply explored the integration of EDL for simultaneous incremental classification and OOD detection.\n        *   Previous continual OOD detection works exist, but none, to the authors' knowledge, have explored continual evidential deep learning in depth for this dual purpose.\n\n*   **Technical Approach & Innovation**\n    *   **Core technical method**: The paper proposes **Continual Evidential Deep Learning (CEDL)**, which integrates an evidential deep learning method into a continual learning framework.\n        *   It combines exemplar rehearsal and knowledge distillation to mitigate catastrophic forgetting.\n        *   A novel loss function is introduced: `L = Î»1LECE + Î»2LEKL + Î»3LKD`.\n            *   `LECE` is the evidential cross-entropy loss for classification.\n            *   `LEKL` is a KL-divergence regularization term, adapted to focus on new classes for uncertainty capture in the CL setting.\n            *   `LKD` is a knowledge distillation loss to transfer knowledge from the old model to the new one.\n        *   The softmax activation in the output layer is replaced by an Exponential (Exp) activation, which is found to be more stable than ReLU for EDL.\n        *   A Weight Aligning (WA) method (bias correction) is applied during inference to reduce prediction bias towards new classes.\n    *   **Novelty**: This is the first work to integrate evidential deep learning into a continual learning approach to simultaneously perform incremental object classification and OOD detection \\cite{aguilar2023ms5}. The proposed loss function and the analysis of evidential uncertainty measures (vacuity and dissonance) in this specific context are novel.\n\n*   **Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques**:\n        *   Introduction of **CEDL**, a novel method for integrating evidential deep learning into a continual learning framework.\n        *   A new loss function `L=Î»1LECE+Î»2LEKL +Î»3LKD` that effectively combines evidential classification, uncertainty regularization (adapted for new classes), and knowledge distillation for continual learning.\n        *   The use of Exponential activation for EDL in a CL setting, noted for its stability.\n        *   Integration of a bias correction (Weight Aligning) method to improve OOD detection in CL.\n    *   **Theoretical insights or analysis**:\n        *   Analysis of the ability of evidential uncertainty measures, specifically vacuity and dissonance, to differentiate between in-distribution data (old classes) and OOD data. The study found that vacuity provides a good measure for OOD detection, while dissonance struggles to distinguish in-distribution (previous classes) data from unseen classes \\cite{aguilar2023ms5}.\n\n*   **Experimental Validation**\n    *   **Experiments conducted**:\n        *   Evaluated on the CIFAR-100 dataset, a common benchmark for continual learning.\n        *   Two class-incremental settings were tested: 5 tasks (20 base classes, 20 incremental classes per task) and 10 tasks (10 base classes, 10 incremental classes per task).\n        *   CEDL was compared against several state-of-the-art *posthoc* OOD detection methods (MSP, ODIN, Energy, Entropy, MSP BCCE) applied on a strong continual learning baseline model \\cite{aguilar2023ms5}.\n        *   ResNet32 was used as the backbone architecture.\n    *   **Key performance metrics and comparison results**:\n        *   **Classification**: CEDL achieved comparable average classification accuracy (ACA) and average incremental accuracy (AIA) to the baseline continual learning method. For example, in the 10-task setting, CEDL achieved 51.07% ACA compared to the baseline's 50.96% \\cite{aguilar2023ms5}.\n        *   **OOD Detection**: CEDL *largely outperformed* the several state-of-the-art *posthoc* OOD detection methods across three evaluation metrics: AUROC, AUPR, and FPR95 \\cite{aguilar2023ms5}.\n        *   **Uncertainty Measures**: Experimental results confirmed that vacuity is a good indicator for OOD data detection, while dissonance is less effective at distinguishing old in-distribution data from OOD data \\cite{aguilar2023ms5}.\n\n*   **Limitations & Scope**\n    *   **Technical limitations or assumptions**: The paper does not explicitly list technical limitations, but the empirical setting of loss weighting parameters (`Î»1, Î»2, Î»3`) could imply a sensitivity to hyperparameter tuning. The specific findings regarding dissonance's limitations in distinguishing certain data types are also a noted technical characteristic.\n    *   **Scope of applicability**: The method is primarily applicable to class-incremental learning scenarios for object classification where simultaneous OOD detection is required. The evaluation was conducted on a standard image classification dataset (CIFAR-100).\n\n*   **Technical Significance**\n    *   **Advances the technical state-of-the-art**: This work represents the first successful integration of evidential deep learning into a continual learning framework for *simultaneous* incremental classification and OOD detection \\cite{aguilar2023ms5}. It provides a robust method that maintains classification performance while significantly enhancing OOD detection capabilities compared to existing *posthoc* approaches.\n    *   **Potential impact on future research**: CEDL paves the way for developing more trustworthy and robust AI systems capable of learning continuously in open-world environments. It encourages further research into combining uncertainty quantification with continual learning, especially for applications requiring reliable detection of novel data, and offers insights into the utility of different evidential uncertainty measures in dynamic learning settings.",
      "intriguing_abstract": "Real-world AI systems demand continuous learning in dynamic environments, requiring models to not only assimilate new knowledge without forgetting old but also reliably detect novel, out-of-distribution (OOD) data. Existing evidential deep learning (EDL) methods excel at OOD detection but assume static, i.i.d. data, while continual learning (CL) often overlooks inherent uncertainty. This paper introduces **Continual Evidential Deep Learning (CEDL)**, the first framework to seamlessly integrate EDL into a CL setting for *simultaneous* incremental object classification and OOD detection.\n\nCEDL employs a novel loss function combining evidential cross-entropy, uncertainty regularization for new classes, and knowledge distillation, alongside exemplar rehearsal to mitigate catastrophic forgetting. We also incorporate an Exponential activation and Weight Aligning for enhanced stability and bias correction. Evaluated on CIFAR-100, CEDL achieves comparable classification accuracy to state-of-the-art CL baselines while *significantly outperforming* posthoc OOD detection methods across AUROC, AUPR, and FPR95. Our analysis further reveals vacuity as a robust indicator for OOD data. CEDL represents a crucial step towards building truly robust and trustworthy AI capable of operating reliably in open-world, evolving scenarios.",
      "keywords": [
        "Continual Learning (CL)",
        "Evidential Deep Learning (EDL)",
        "Out-of-Distribution (OOD) detection",
        "Continual Evidential Deep Learning (CEDL)",
        "Incremental object classification",
        "Catastrophic forgetting mitigation",
        "Uncertainty estimation",
        "Novel combined loss function",
        "Exemplar rehearsal",
        "Knowledge distillation",
        "Vacuity",
        "Dissonance",
        "Simultaneous classification and OOD detection",
        "Trustworthy AI"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/4fc9a9046cab45de423cadb2db887881cd0972e8.pdf",
      "citation_key": "aguilar2023ms5",
      "metadata": {
        "title": "Continual Evidential Deep Learning for Out-of-Distribution Detection",
        "authors": [
          "Eduardo Aguilar",
          "B. Raducanu",
          "P. Radeva",
          "Joost van de Weijer"
        ],
        "published_date": "2023",
        "abstract": "Uncertainty-based deep learning models have attracted a great deal of interest for their ability to provide accurate and reliable predictions. Evidential deep learning stands out achieving remarkable performance in detecting out-of-distribution (OOD) data with a single deterministic neural network. Motivated by this fact, in this paper we propose the integration of an evidential deep learning method into a continual learning framework in order to perform simultaneously incremental object classification and OOD detection. Moreover, we analyze the ability of vacuity and dissonance to differentiate between in-distribution data belonging to old classes and OOD data. The proposed method 1, called CEDL, is evaluated on CIFAR-100 considering two settings consisting of 5 and 10 tasks, respectively. From the obtained results, we could appreciate that the proposed method, in addition to provide comparable results in object classification with respect to the baseline, largely outperforms OOD detection compared to several posthoc methods on three evaluation metrics: AUROC, AUPR and FPR95.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/4fc9a9046cab45de423cadb2db887881cd0972e8.pdf",
        "venue": "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)",
        "citationCount": 11,
        "score": 5.5,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific technical problem**: The paper addresses the challenge of simultaneously performing incremental object classification and out-of-distribution (OOD) detection in a continual learning (CL) setting. Existing evidential deep learning (EDL) methods, effective for OOD detection, typically assume data is independently and identically distributed (i.i.d.) and available jointly, which is unrealistic for sequential data streams.\n    *   **Importance and Challenge**: In real-world applications, data arrives sequentially, leading to distribution shifts over time. Models must continually learn new knowledge without catastrophically forgetting old knowledge (the plasticity-stability dilemma) while also reliably identifying novel, unseen (OOD) data. Integrating uncertainty estimation, specifically evidential deep learning, into this dynamic, open-world CL scenario is crucial for robust and trustworthy AI but has not been thoroughly explored.\n\n*   **Related Work & Positioning**\n    *   **Relation to existing approaches**: This work builds upon Evidential Deep Learning (EDL) for uncertainty estimation and various Continual Learning (CL) strategies (regularization, rehearsal). It also relates to recent efforts in Continual OOD detection.\n    *   **Limitations of previous solutions**:\n        *   Standard EDL methods assume i.i.d. data, making them unsuitable for sequential learning in CL.\n        *   Most CL methods focus on classification in a closed-world setting, often using standard cross-entropy loss, and do not inherently handle OOD detection.\n        *   While some uncertainty-aware CL methods exist (e.g., Bayesian approaches), they haven't deeply explored the integration of EDL for simultaneous incremental classification and OOD detection.\n        *   Previous continual OOD detection works exist, but none, to the authors' knowledge, have explored continual evidential deep learning in depth for this dual purpose.\n\n*   **Technical Approach & Innovation**\n    *   **Core technical method**: The paper proposes **Continual Evidential Deep Learning (CEDL)**, which integrates an evidential deep learning method into a continual learning framework.\n        *   It combines exemplar rehearsal and knowledge distillation to mitigate catastrophic forgetting.\n        *   A novel loss function is introduced: `L = Î»1LECE + Î»2LEKL + Î»3LKD`.\n            *   `LECE` is the evidential cross-entropy loss for classification.\n            *   `LEKL` is a KL-divergence regularization term, adapted to focus on new classes for uncertainty capture in the CL setting.\n            *   `LKD` is a knowledge distillation loss to transfer knowledge from the old model to the new one.\n        *   The softmax activation in the output layer is replaced by an Exponential (Exp) activation, which is found to be more stable than ReLU for EDL.\n        *   A Weight Aligning (WA) method (bias correction) is applied during inference to reduce prediction bias towards new classes.\n    *   **Novelty**: This is the first work to integrate evidential deep learning into a continual learning approach to simultaneously perform incremental object classification and OOD detection \\cite{aguilar2023ms5}. The proposed loss function and the analysis of evidential uncertainty measures (vacuity and dissonance) in this specific context are novel.\n\n*   **Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques**:\n        *   Introduction of **CEDL**, a novel method for integrating evidential deep learning into a continual learning framework.\n        *   A new loss function `L=Î»1LECE+Î»2LEKL +Î»3LKD` that effectively combines evidential classification, uncertainty regularization (adapted for new classes), and knowledge distillation for continual learning.\n        *   The use of Exponential activation for EDL in a CL setting, noted for its stability.\n        *   Integration of a bias correction (Weight Aligning) method to improve OOD detection in CL.\n    *   **Theoretical insights or analysis**:\n        *   Analysis of the ability of evidential uncertainty measures, specifically vacuity and dissonance, to differentiate between in-distribution data (old classes) and OOD data. The study found that vacuity provides a good measure for OOD detection, while dissonance struggles to distinguish in-distribution (previous classes) data from unseen classes \\cite{aguilar2023ms5}.\n\n*   **Experimental Validation**\n    *   **Experiments conducted**:\n        *   Evaluated on the CIFAR-100 dataset, a common benchmark for continual learning.\n        *   Two class-incremental settings were tested: 5 tasks (20 base classes, 20 incremental classes per task) and 10 tasks (10 base classes, 10 incremental classes per task).\n        *   CEDL was compared against several state-of-the-art *posthoc* OOD detection methods (MSP, ODIN, Energy, Entropy, MSP BCCE) applied on a strong continual learning baseline model \\cite{aguilar2023ms5}.\n        *   ResNet32 was used as the backbone architecture.\n    *   **Key performance metrics and comparison results**:\n        *   **Classification**: CEDL achieved comparable average classification accuracy (ACA) and average incremental accuracy (AIA) to the baseline continual learning method. For example, in the 10-task setting, CEDL achieved 51.07% ACA compared to the baseline's 50.96% \\cite{aguilar2023ms5}.\n        *   **OOD Detection**: CEDL *largely outperformed* the several state-of-the-art *posthoc* OOD detection methods across three evaluation metrics: AUROC, AUPR, and FPR95 \\cite{aguilar2023ms5}.\n        *   **Uncertainty Measures**: Experimental results confirmed that vacuity is a good indicator for OOD data detection, while dissonance is less effective at distinguishing old in-distribution data from OOD data \\cite{aguilar2023ms5}.\n\n*   **Limitations & Scope**\n    *   **Technical limitations or assumptions**: The paper does not explicitly list technical limitations, but the empirical setting of loss weighting parameters (`Î»1, Î»2, Î»3`) could imply a sensitivity to hyperparameter tuning. The specific findings regarding dissonance's limitations in distinguishing certain data types are also a noted technical characteristic.\n    *   **Scope of applicability**: The method is primarily applicable to class-incremental learning scenarios for object classification where simultaneous OOD detection is required. The evaluation was conducted on a standard image classification dataset (CIFAR-100).\n\n*   **Technical Significance**\n    *   **Advances the technical state-of-the-art**: This work represents the first successful integration of evidential deep learning into a continual learning framework for *simultaneous* incremental classification and OOD detection \\cite{aguilar2023ms5}. It provides a robust method that maintains classification performance while significantly enhancing OOD detection capabilities compared to existing *posthoc* approaches.\n    *   **Potential impact on future research**: CEDL paves the way for developing more trustworthy and robust AI systems capable of learning continuously in open-world environments. It encourages further research into combining uncertainty quantification with continual learning, especially for applications requiring reliable detection of novel data, and offers insights into the utility of different evidential uncertainty measures in dynamic learning settings.",
        "keywords": [
          "Continual Learning (CL)",
          "Evidential Deep Learning (EDL)",
          "Out-of-Distribution (OOD) detection",
          "Continual Evidential Deep Learning (CEDL)",
          "Incremental object classification",
          "Catastrophic forgetting mitigation",
          "Uncertainty estimation",
          "Novel combined loss function",
          "Exemplar rehearsal",
          "Knowledge distillation",
          "Vacuity",
          "Dissonance",
          "Simultaneous classification and OOD detection",
          "Trustworthy AI"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **\"in this paper we propose the integration of an evidential deep learning method into a continual learning framework\"**: this explicitly states the development of a new method.\n2.  **\"the proposed method, called cedl, is evaluated on cifar-100...\"**: this indicates an empirical evaluation of the newly proposed method.\n3.  **\"...largely outperforms ood detection compared to several posthoc methods on three evaluation metrics: auroc, aupr and fpr95.\"**: these are empirical findings and statistical analysis.\n\nwhile the paper clearly involves significant empirical evaluation, its primary contribution, as stated in the abstract, is the **proposal and development of a new method (cedl)**. the empirical results serve to validate the effectiveness of this technical contribution. therefore, the paper's core nature is the presentation of a new system/algorithm.\n\n**classification:** technical"
      },
      "file_name": "4fc9a9046cab45de423cadb2db887881cd0972e8.pdf"
    },
    {
      "success": true,
      "doc_id": "56b7430419a0d88a621febbec35a86e9",
      "summary": "Out-of-distribution (OOD) detection, a fundamental task vexing real-world applications, has attracted growing attention in the NLP community. Recently fine-tuning based methods have made promising progress. However, it could be costly to store fine-tuned models for each scenario. In this paper, we depart from the classic fine-tuning based OOD detection toward a parameter-efficient alternative, and propose an unsupervised prefix-tuning based OOD detection framework termed PTO. Additionally, to take advantage of optional training data labels and targeted OOD data, two practical extensions of PTO are further proposed. Overall, PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified. Experimental results show that our methods perform comparably to, even better than, existing fine-tuning based OOD detection approaches under a wide range of metrics, detection settings, and OOD types.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection, a fundamental task vexing real-world applications, has attracted growing attention in the NLP community. Recently fine-tuning based methods have made promising progress. However, it could be costly to store fine-tuned models for each scenario. In this paper, we depart from the classic fine-tuning based OOD detection toward a parameter-efficient alternative, and propose an unsupervised prefix-tuning based OOD detection framework termed PTO. Additionally, to take advantage of optional training data labels and targeted OOD data, two practical extensions of PTO are further proposed. Overall, PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified. Experimental results show that our methods perform comparably to, even better than, existing fine-tuning based OOD detection approaches under a wide range of metrics, detection settings, and OOD types.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/92bb8140695007bc68ba87d51a6dfe563504f3a1.pdf",
      "citation_key": "ouyang2023wxc",
      "metadata": {
        "title": "On Prefix-tuning for Lightweight Out-of-distribution Detection",
        "authors": [
          "Yawen Ouyang",
          "Yongchang Cao",
          "Yuan Gao",
          "Zhanghua Wu",
          "Jianbing Zhang",
          "Xinyu Dai"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection, a fundamental task vexing real-world applications, has attracted growing attention in the NLP community. Recently fine-tuning based methods have made promising progress. However, it could be costly to store fine-tuned models for each scenario. In this paper, we depart from the classic fine-tuning based OOD detection toward a parameter-efficient alternative, and propose an unsupervised prefix-tuning based OOD detection framework termed PTO. Additionally, to take advantage of optional training data labels and targeted OOD data, two practical extensions of PTO are further proposed. Overall, PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified. Experimental results show that our methods perform comparably to, even better than, existing fine-tuning based OOD detection approaches under a wide range of metrics, detection settings, and OOD types.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/92bb8140695007bc68ba87d51a6dfe563504f3a1.pdf",
        "venue": "Annual Meeting of the Association for Computational Linguistics",
        "citationCount": 11,
        "score": 5.5,
        "summary": "Out-of-distribution (OOD) detection, a fundamental task vexing real-world applications, has attracted growing attention in the NLP community. Recently fine-tuning based methods have made promising progress. However, it could be costly to store fine-tuned models for each scenario. In this paper, we depart from the classic fine-tuning based OOD detection toward a parameter-efficient alternative, and propose an unsupervised prefix-tuning based OOD detection framework termed PTO. Additionally, to take advantage of optional training data labels and targeted OOD data, two practical extensions of PTO are further proposed. Overall, PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified. Experimental results show that our methods perform comparably to, even better than, existing fine-tuning based OOD detection approaches under a wide range of metrics, detection settings, and OOD types.",
        "keywords": []
      },
      "file_name": "92bb8140695007bc68ba87d51a6dfe563504f3a1.pdf"
    },
    {
      "success": true,
      "doc_id": "3a89379e43e73affa6a4e32340479ab7",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection for deep neural networks \\cite{lafon2023w37}.\n    *   **Importance and challenge**: OOD detection is a major safety requirement for deploying deep learning models in critical applications (e.g., healthcare, autonomous systems) to prevent arbitrary or unreliable predictions when encountering data outside the training distribution. State-of-the-art deep neural networks often struggle with this, and post-hoc strategies, which leverage pre-trained models, are preferred for real-world applicability and computational efficiency \\cite{lafon2023w37}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches**: This work builds upon existing post-hoc OOD detection methods that estimate the density of in-distribution (ID) features in the latent space of a pre-trained network \\cite{lafon2023w37}. These include approaches based on Gaussian Mixture Models (GMMs) \\cite{lafon2023w37}, nearest neighbors \\cite{lafon2023w37}, and energy logits (EL) \\cite{lafon2023w37}.\n    *   **Limitations of previous solutions**:\n        *   Existing methods often exhibit biases, performing well on either \"far-OOD\" (e.g., GMMs) or \"near-OOD\" (e.g., EL) but struggling with the other, leading to coarse boundaries between ID and OOD \\cite{lafon2023w37}.\n        *   Some methods, like Outlier Exposure, rely on external OOD samples, which are difficult to collect representatively and can bias the detector \\cite{lafon2023w37}.\n        *   Energy-Based Models (EBMs) for OOD detection have not yet matched the performance of feature-space methods \\cite{lafon2023w37}.\n        *   Prior residual learning approaches (e.g., ResFlow, ViM) have limitations such as requiring invertible mappings (for Normalizing Flows) or modeling residuals on linear manifolds, which limit their expressive power \\cite{lafon2023w37}.\n        *   Ensembling multiple networks, while effective, incurs significant computational overhead at inference time \\cite{lafon2023w37}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method**: The paper introduces HEAT (Hybrid Energy Based Model in the Feature Space), a novel post-hoc OOD detection method \\cite{lafon2023w37}. HEAT estimates the density of ID samples by employing hybrid EBMs in the feature space of a fixed, pre-trained backbone network \\cite{lafon2023w37}.\n    *   **Novelty/Difference**:\n        *   **Energy-based correction of prior OOD detectors**: HEAT refines existing prior density estimators (e.g., GMMs, EL) by complementing them with a data-driven residual EBM. This allows for accurate and robust ID density estimation, leveraging the generalization properties of priors while correcting their inherent modeling biases \\cite{lafon2023w37}.\n        *   **Hybrid density estimation via energy function composition**: The EBM framework is used to provide a unified density estimation and to compose several energy terms from different refined priors. This composition requires only a single hyper-parameter ($\\beta$) and introduces no computational overhead at inference, as it's applied at a single network layer \\cite{lafon2023w37}.\n        *   Unlike some prior residual methods, HEAT learns a non-linear residual, enhancing ID density modeling \\cite{lafon2023w37}.\n        *   HEAT does not require any OOD samples for training, relying solely on proper EBM training to estimate ID feature density \\cite{lafon2023w37}.\n\n4.  **Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques**:\n        *   **Hybrid EBM density estimation**: A novel formulation `ph_Î¸k(z) = (1/Z(Î¸k)) * pr_Î¸k(z) * qk(z)` where `qk(z)` is a prior density and `pr_Î¸k(z)` is a residual EBM `exp(-EÎ¸k(z))`. This results in a hybrid energy `Eh_Î¸k(z) = Eqk(z) + EÎ¸k(z)` \\cite{lafon2023w37}.\n        *   **Controlled residual learning**: An additional loss term `LC(Î¸k)` is introduced to prevent the residual EBM from overly dominating the prior, ensuring a balanced cooperation between the prior and the residual. The total loss is `LTot(Î¸k) = LMLE(Î¸k) + Î»LC(Î¸k)` \\cite{lafon2023w37}.\n        *   **EBM-based composition function**: A principled composition function `EÎ²_HEAT = (1/Î²) * log(Î£_k exp(Î² * Eh_Î¸k))` is proposed to combine multiple refined hybrid energies, with `Î²` offering a clear interpretation (e.g., sum of energies, logsumexp) \\cite{lafon2023w37}.\n    *   **System design or architectural innovations**: HEAT operates as a post-hoc method in the feature space of a pre-trained model, applying its energy-based correction and composition at a single network layer, ensuring computational efficiency \\cite{lafon2023w37}.\n    *   **Theoretical insights or analysis**: The EBM framework provides a sound theoretical basis for both the residual correction and the composition of energy functions, offering a principled way to combine different OOD detection signals \\cite{lafon2023w37}.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted**: Extensive experiments were performed on standard benchmarks including CIFAR-10, CIFAR-100, and the large-scale ImageNet dataset \\cite{lafon2023w37}. The method was validated using ResNet-34 (for CIFAR) and ResNet-50 (for ImageNet) backbones, demonstrating its agnosticism to the prediction backbone (e.g., ResNet, ViT) and effectiveness in low-data regimes \\cite{lafon2023w37}.\n    *   **Key performance metrics and comparison results**: The performance was evaluated using standard metrics: Area Under the Receiver Operating Characteristic curve (AUC) and False Positive Rate at 95% True Positive Rate (FPR95) \\cite{lafon2023w37}.\n        *   HEAT achieved new state-of-the-art OOD detection results on CIFAR-10/CIFAR-100 and ImageNet \\cite{lafon2023w37}.\n        *   Illustrative results (Fig. 1) show significant improvements: GMM's FPR on near-OOD reduced by -4.7 percentage points, and EL's FPR on near-OOD by -3.2 pts and far-OOD by -1.2 pts after energy-correction. The final HEAT composition further improved detection for both near and far-OOD regimes \\cite{lafon2023w37}.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations or assumptions**: The method requires prior OOD scorers to be expressible as EBMs and differentiable to facilitate Stochastic Gradient Langevin Dynamics (SGLD) sampling during training \\cite{lafon2023w37}. Extending HEAT to other state-of-the-art OOD detectors (e.g., soft-KNN, ViM) is noted as future work \\cite{lafon2023w37}.\n    *   **Scope of applicability**: HEAT is a post-hoc OOD detection method designed for the feature space of pre-trained deep neural networks. It is applicable across various backbone architectures and remains effective even in low-data scenarios, without requiring external OOD samples for training \\cite{lafon2023w37}.\n\n7.  **Technical Significance**\n    *   **Advances the technical state-of-the-art**: HEAT sets new state-of-the-art OOD detection performance on major benchmarks, demonstrating its superior ability to handle both near and far-OOD samples simultaneously \\cite{lafon2023w37}.\n    *   **Potential impact on future research**: The proposed hybrid EBM framework, with its principled energy-based correction and composition strategy, offers a versatile and efficient approach to combine and refine existing OOD detectors. This could inspire future research into more robust and adaptable OOD detection methods, particularly for critical real-world applications where reliable uncertainty estimation is paramount \\cite{lafon2023w37}.",
      "intriguing_abstract": "Reliable Out-of-Distribution (OOD) detection is paramount for deploying deep neural networks in safety-critical applications, yet current methods often falter, exhibiting biases towards either near-OOD or far-OOD samples. We unveil HEAT (Hybrid Energy Based Model in the Feature Space), a pioneering post-hoc OOD detection framework that redefines the state-of-the-art by robustly handling both regimes simultaneously without requiring external OOD samples.\n\nHEAT introduces a novel approach: it refines existing prior in-distribution (ID) density estimators in the latent space by complementing them with a data-driven, non-linear residual Energy-Based Model (EBM). This energy-based correction precisely models complex ID boundaries, overcoming the inherent biases of traditional methods like GMMs or Energy Logits. Furthermore, HEAT proposes a principled EBM-based composition function to seamlessly combine multiple refined hybrid energies, offering a unified and computationally efficient solution. Trained via Stochastic Gradient Langevin Dynamics (SGLD), HEAT achieves unprecedented OOD detection performance on CIFAR-10/100 and ImageNet benchmarks, significantly improving AUC and FPR95 metrics. This work presents a versatile and theoretically sound framework for robust uncertainty quantification, paving the way for safer and more reliable AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "deep neural networks",
        "post-hoc OOD detection",
        "Hybrid Energy Based Model (HEAT)",
        "feature space",
        "energy-based correction",
        "hybrid density estimation",
        "energy function composition",
        "controlled residual learning",
        "near-OOD and far-OOD",
        "state-of-the-art performance",
        "critical applications",
        "no OOD samples required"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/e75e08851675eb506ea0149b0403828b6fb24900.pdf",
      "citation_key": "lafon2023w37",
      "metadata": {
        "title": "Hybrid Energy Based Model in the Feature Space for Out-of-Distribution Detection",
        "authors": [
          "Marc Lafon",
          "Elias Ramzi",
          "ClÃ©ment Rambour",
          "Nicolas Thome"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution (OOD) detection is a critical requirement for the deployment of deep neural networks. This paper introduces the HEAT model, a new post-hoc OOD detection method estimating the density of in-distribution (ID) samples using hybrid energy-based models (EBM) in the feature space of a pre-trained backbone. HEAT complements prior density estimators of the ID density, e.g. parametric models like the Gaussian Mixture Model (GMM), to provide an accurate yet robust density estimation. A second contribution is to leverage the EBM framework to provide a unified density estimation and to compose several energy terms. Extensive experiments demonstrate the significance of the two contributions. HEAT sets new state-of-the-art OOD detection results on the CIFAR-10 / CIFAR-100 benchmark as well as on the large-scale Imagenet benchmark. The code is available at: https://github.com/MarcLafon/heatood.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/e75e08851675eb506ea0149b0403828b6fb24900.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 11,
        "score": 5.5,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection for deep neural networks \\cite{lafon2023w37}.\n    *   **Importance and challenge**: OOD detection is a major safety requirement for deploying deep learning models in critical applications (e.g., healthcare, autonomous systems) to prevent arbitrary or unreliable predictions when encountering data outside the training distribution. State-of-the-art deep neural networks often struggle with this, and post-hoc strategies, which leverage pre-trained models, are preferred for real-world applicability and computational efficiency \\cite{lafon2023w37}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches**: This work builds upon existing post-hoc OOD detection methods that estimate the density of in-distribution (ID) features in the latent space of a pre-trained network \\cite{lafon2023w37}. These include approaches based on Gaussian Mixture Models (GMMs) \\cite{lafon2023w37}, nearest neighbors \\cite{lafon2023w37}, and energy logits (EL) \\cite{lafon2023w37}.\n    *   **Limitations of previous solutions**:\n        *   Existing methods often exhibit biases, performing well on either \"far-OOD\" (e.g., GMMs) or \"near-OOD\" (e.g., EL) but struggling with the other, leading to coarse boundaries between ID and OOD \\cite{lafon2023w37}.\n        *   Some methods, like Outlier Exposure, rely on external OOD samples, which are difficult to collect representatively and can bias the detector \\cite{lafon2023w37}.\n        *   Energy-Based Models (EBMs) for OOD detection have not yet matched the performance of feature-space methods \\cite{lafon2023w37}.\n        *   Prior residual learning approaches (e.g., ResFlow, ViM) have limitations such as requiring invertible mappings (for Normalizing Flows) or modeling residuals on linear manifolds, which limit their expressive power \\cite{lafon2023w37}.\n        *   Ensembling multiple networks, while effective, incurs significant computational overhead at inference time \\cite{lafon2023w37}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method**: The paper introduces HEAT (Hybrid Energy Based Model in the Feature Space), a novel post-hoc OOD detection method \\cite{lafon2023w37}. HEAT estimates the density of ID samples by employing hybrid EBMs in the feature space of a fixed, pre-trained backbone network \\cite{lafon2023w37}.\n    *   **Novelty/Difference**:\n        *   **Energy-based correction of prior OOD detectors**: HEAT refines existing prior density estimators (e.g., GMMs, EL) by complementing them with a data-driven residual EBM. This allows for accurate and robust ID density estimation, leveraging the generalization properties of priors while correcting their inherent modeling biases \\cite{lafon2023w37}.\n        *   **Hybrid density estimation via energy function composition**: The EBM framework is used to provide a unified density estimation and to compose several energy terms from different refined priors. This composition requires only a single hyper-parameter ($\\beta$) and introduces no computational overhead at inference, as it's applied at a single network layer \\cite{lafon2023w37}.\n        *   Unlike some prior residual methods, HEAT learns a non-linear residual, enhancing ID density modeling \\cite{lafon2023w37}.\n        *   HEAT does not require any OOD samples for training, relying solely on proper EBM training to estimate ID feature density \\cite{lafon2023w37}.\n\n4.  **Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques**:\n        *   **Hybrid EBM density estimation**: A novel formulation `ph_Î¸k(z) = (1/Z(Î¸k)) * pr_Î¸k(z) * qk(z)` where `qk(z)` is a prior density and `pr_Î¸k(z)` is a residual EBM `exp(-EÎ¸k(z))`. This results in a hybrid energy `Eh_Î¸k(z) = Eqk(z) + EÎ¸k(z)` \\cite{lafon2023w37}.\n        *   **Controlled residual learning**: An additional loss term `LC(Î¸k)` is introduced to prevent the residual EBM from overly dominating the prior, ensuring a balanced cooperation between the prior and the residual. The total loss is `LTot(Î¸k) = LMLE(Î¸k) + Î»LC(Î¸k)` \\cite{lafon2023w37}.\n        *   **EBM-based composition function**: A principled composition function `EÎ²_HEAT = (1/Î²) * log(Î£_k exp(Î² * Eh_Î¸k))` is proposed to combine multiple refined hybrid energies, with `Î²` offering a clear interpretation (e.g., sum of energies, logsumexp) \\cite{lafon2023w37}.\n    *   **System design or architectural innovations**: HEAT operates as a post-hoc method in the feature space of a pre-trained model, applying its energy-based correction and composition at a single network layer, ensuring computational efficiency \\cite{lafon2023w37}.\n    *   **Theoretical insights or analysis**: The EBM framework provides a sound theoretical basis for both the residual correction and the composition of energy functions, offering a principled way to combine different OOD detection signals \\cite{lafon2023w37}.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted**: Extensive experiments were performed on standard benchmarks including CIFAR-10, CIFAR-100, and the large-scale ImageNet dataset \\cite{lafon2023w37}. The method was validated using ResNet-34 (for CIFAR) and ResNet-50 (for ImageNet) backbones, demonstrating its agnosticism to the prediction backbone (e.g., ResNet, ViT) and effectiveness in low-data regimes \\cite{lafon2023w37}.\n    *   **Key performance metrics and comparison results**: The performance was evaluated using standard metrics: Area Under the Receiver Operating Characteristic curve (AUC) and False Positive Rate at 95% True Positive Rate (FPR95) \\cite{lafon2023w37}.\n        *   HEAT achieved new state-of-the-art OOD detection results on CIFAR-10/CIFAR-100 and ImageNet \\cite{lafon2023w37}.\n        *   Illustrative results (Fig. 1) show significant improvements: GMM's FPR on near-OOD reduced by -4.7 percentage points, and EL's FPR on near-OOD by -3.2 pts and far-OOD by -1.2 pts after energy-correction. The final HEAT composition further improved detection for both near and far-OOD regimes \\cite{lafon2023w37}.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations or assumptions**: The method requires prior OOD scorers to be expressible as EBMs and differentiable to facilitate Stochastic Gradient Langevin Dynamics (SGLD) sampling during training \\cite{lafon2023w37}. Extending HEAT to other state-of-the-art OOD detectors (e.g., soft-KNN, ViM) is noted as future work \\cite{lafon2023w37}.\n    *   **Scope of applicability**: HEAT is a post-hoc OOD detection method designed for the feature space of pre-trained deep neural networks. It is applicable across various backbone architectures and remains effective even in low-data scenarios, without requiring external OOD samples for training \\cite{lafon2023w37}.\n\n7.  **Technical Significance**\n    *   **Advances the technical state-of-the-art**: HEAT sets new state-of-the-art OOD detection performance on major benchmarks, demonstrating its superior ability to handle both near and far-OOD samples simultaneously \\cite{lafon2023w37}.\n    *   **Potential impact on future research**: The proposed hybrid EBM framework, with its principled energy-based correction and composition strategy, offers a versatile and efficient approach to combine and refine existing OOD detectors. This could inspire future research into more robust and adaptable OOD detection methods, particularly for critical real-world applications where reliable uncertainty estimation is paramount \\cite{lafon2023w37}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "deep neural networks",
          "post-hoc OOD detection",
          "Hybrid Energy Based Model (HEAT)",
          "feature space",
          "energy-based correction",
          "hybrid density estimation",
          "energy function composition",
          "controlled residual learning",
          "near-OOD and far-OOD",
          "state-of-the-art performance",
          "critical applications",
          "no OOD samples required"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"this paper introduces the heat model, a new post-hoc ood detection method...\" and \"a second contribution is to leverage the ebm framework to provide a unified density estimation and to compose several energy terms.\" these phrases clearly indicate the development and presentation of a new method/system.\n*   the abstract also mentions: \"extensive experiments demonstrate the significance of the two contributions. heat sets new state-of-the-art ood detection results on the cifar-10 / cifar-100 benchmark as well as on the large-scale imagenet benchmark.\" this indicates a strong empirical component, where the proposed method is evaluated.\n\nwhile there is a significant empirical component, the primary contribution described is the **introduction of a new method (heat model)**. in machine learning, papers that propose a novel algorithm, system, or technique and then validate it through experiments are typically classified as **technical**. the empirical evaluation serves to demonstrate the efficacy of the technical contribution.\n\ntherefore, the most fitting classification is **technical**."
      },
      "file_name": "e75e08851675eb506ea0149b0403828b6fb24900.pdf"
    },
    {
      "success": true,
      "doc_id": "102e223831d51036c50e4e3b90683e38",
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n---\n\n### Analysis of \"Revisiting Out-of-Distribution Detection in LiDAR-based 3D Object Detection\" \\cite{ksel20246fe}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical challenge of detecting Out-of-Distribution (OOD) objects in LiDAR-based 3D object detection systems. These are object types not present in the original training data.\n    *   **Importance and Challenge**: OOD objects can be erroneously classified as known (in-distribution, ID) objects with high confidence, posing significant safety risks and reliability issues for automated vehicles. LiDAR-based OOD detection is particularly challenging due to the complexity and sparsity of point cloud data, and it has been largely understudied compared to image-based OOD detection.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon advancements in OOD detection from image classification and image-based object detection, adapting these concepts to the LiDAR domain. It is a post-hoc method, similar to SAFE \\cite{ksel20246fe}, extending a fixed 3D object detector.\n    *   **Limitations of Previous Solutions**:\n        *   Prior LiDAR-based OOD detection work (e.g., Huang et al. \\cite{ksel20246fe}) often relies on unsupervised learning and evaluates by synthetically inserting objects from other datasets into point clouds.\n        *   `\\cite{ksel20246fe}` argues that this synthetic insertion approach introduces a \"domain gap\" (e.g., differences in intensities, unrealistic occlusion patterns), leading to an inauthentic evaluation of real-world OOD detection performance.\n        *   Image-based OOD object detection methods often evaluate by treating entire datasets as either ID or OOD, neglecting scenarios where both ID and OOD objects coexist in the same scene.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: `\\cite{ksel20246fe}` proposes a lightweight, post-hoc OOD detection method that extends a pre-trained and fixed 3D object detector with a simple multilayer perceptron (MLP).\n    *   **Novelty/Differentiation**:\n        *   **Synthetic OOD Data Generation**: Instead of requiring real OOD objects or inserting objects from other datasets, `\\cite{ksel20246fe}` generates synthetic OOD objects by perturbing known ID object categories. This is achieved by randomly applying unusual scaling factors (0.1-0.5 for smaller, 1.5-3 for larger) independently to the length, width, and height of existing annotated ID objects. This creates varied OOD objects that share geometric similarities with ID objects but are distinct enough to be OOD.\n        *   **Comprehensive Feature Extraction**: Features for the MLP are extracted from multiple sources of the fixed object detector:\n            *   Backbone feature maps (at object center using bilinear interpolation).\n            *   Encoded bounding box parameters (center, dimensions, rotation).\n            *   Concatenated raw output logits and one-hot encoded predicted classes.\n            This multi-modal feature fusion aims to exploit discrepancies (e.g., inconsistent predicted class/logits, anomalous box dimensions) that signal OOD instances.\n        *   **Novel Evaluation Protocol**: `\\cite{ksel20246fe}` introduces a new evaluation protocol for LiDAR-based OOD object detection that allows using existing datasets without modifying point clouds. It considers rare classes within existing datasets as OOD, better reflecting real-world scenarios where ID and OOD objects coexist.\n\n4.  **Key Technical Contributions**\n    *   **Novel Method**: A lightweight, post-hoc OOD detection approach for LiDAR-based 3D object detection that integrates information from the feature space, bounding box parameters, and output logits of a fixed object detector.\n    *   **Synthetic OOD Generation Strategy**: An effective method for synthesizing OOD objects by randomly and independently scaling existing ID objects, addressing the scarcity of real OOD data.\n    *   **Novel Evaluation Protocol**: A new, more realistic evaluation protocol for OOD detection in 3D object detection, which leverages existing datasets by designating rare classes as OOD, avoiding artificial object insertion.\n    *   **Benchmark Creation**: The establishment of the nuScenes OOD benchmark based on their proposed evaluation protocol.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Experiments were conducted on the newly proposed nuScenes OOD benchmark. The base 3D object detector used was CenterPoint \\cite{ksel20246fe}.\n    *   **Key Performance Metrics and Comparison Results**: The paper demonstrates the effectiveness of their approach by showing \"significantly improved OOD detection performances\" compared to prior work on the nuScenes OOD benchmark. While specific metrics (e.g., AUROC, AUPR) are not detailed in the abstract, the claim is of superior performance in correctly classifying OOD objects.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method is post-hoc and relies on a pre-trained, fixed object detector, meaning it does not involve end-to-end training of the detector and OOD module. The effectiveness is tied to the quality of features extracted by the base detector and the specific synthetic OOD generation strategy.\n    *   **Scope of Applicability**: The method is specifically designed for LiDAR-based 3D object detection in autonomous driving contexts. The synthetic OOD generation is tailored to geometric perturbations of known objects.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `\\cite{ksel20246fe}` significantly advances the technical state-of-the-art in LiDAR-based OOD object detection by providing a practical, effective, and realistically evaluable solution. It addresses critical gaps in both methodology (synthetic OOD data, multi-modal feature fusion) and evaluation (realistic benchmark).\n    *   **Potential Impact**: This work has the potential to greatly enhance the safety and reliability of automated driving systems by enabling them to identify and appropriately handle unknown foreground objects. The proposed evaluation protocol and benchmark can serve as a standard for future research in this crucial area.",
      "intriguing_abstract": "Autonomous vehicles face a critical safety challenge: reliably detecting Out-of-Distribution (OOD) objects, especially in complex LiDAR point clouds, where unknown entities can be misclassified with dangerous confidence. Existing LiDAR-based OOD methods often struggle with data scarcity or unrealistic evaluation protocols, hindering real-world deployment.\n\nWe introduce a novel, lightweight post-hoc OOD detection framework for LiDAR-based 3D object detectors that significantly advances the state-of-the-art. Our approach innovatively generates synthetic OOD objects by geometrically perturbing in-distribution instances, overcoming the need for scarce real OOD data and avoiding domain gaps inherent in cross-dataset insertions. This allows us to train a simple Multilayer Perceptron (MLP) that leverages a rich fusion of features from the fixed 3D detector's backbone, bounding box parameters, and output logits. This multi-modal input effectively captures subtle inconsistencies indicative of OOD instances. Furthermore, we propose a more realistic evaluation protocol that designates rare classes within existing datasets as OOD, establishing the challenging nuScenes OOD benchmark. Experiments demonstrate significantly improved OOD detection performance, paving the way for safer and more robust autonomous driving systems by enabling proactive handling of unforeseen scenarios.",
      "keywords": [
        "LiDAR-based 3D object detection",
        "Out-of-Distribution (OOD) detection",
        "post-hoc OOD method",
        "synthetic OOD data generation",
        "object scaling perturbation",
        "multi-modal feature fusion",
        "novel evaluation protocol",
        "nuScenes OOD benchmark",
        "automated driving safety",
        "point cloud data challenges",
        "MLP-based OOD classifier",
        "feature maps",
        "bounding box parameters",
        "output logits",
        "improved OOD detection performance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/2f615dc49f38928fb08534b6edd1ad2c0102243a.pdf",
      "citation_key": "ksel20246fe",
      "metadata": {
        "title": "Revisiting Out-of-Distribution Detection in LiDAR-based 3D Object Detection",
        "authors": [
          "Michael KÃ¶sel",
          "M. Schreiber",
          "Michael Ulrich",
          "Claudius GlÃ¤ser",
          "Klaus C. J. Dietmayer"
        ],
        "published_date": "2024",
        "abstract": "LiDAR-based 3D object detection has become an essential part of automated driving due to its ability to localize and classify objects precisely in 3D. However, object detectors face a critical challenge when dealing with unknown foreground objects, particularly those that were not present in their original training data. These out-of-distribution (OOD) objects can lead to misclassifications, posing a significant risk to the safety and reliability of automated vehicles. Currently, LiDAR-based OOD object detection has not been well studied. We address this problem by generating synthetic training data for OOD objects by perturbing known object categories. Our idea is that these synthetic OOD objects produce different responses in the feature map of an object detector compared to in-distribution (ID) objects. We then extract features using a pre-trained and fixed object detector and train a simple multilayer perceptron (MLP) to classify each detection as either ID or OOD. In addition, we propose a new evaluation protocol that allows the use of existing datasets without modifying the point cloud, ensuring a more authentic evaluation of real-world scenarios. The effectiveness of our method is validated through experiments on the newly proposed nuScenes OOD benchmark. The source code is available at https://github.com/uulm-mrm/mmood3d.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/2f615dc49f38928fb08534b6edd1ad2c0102243a.pdf",
        "venue": "2024 IEEE Intelligent Vehicles Symposium (IV)",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n---\n\n### Analysis of \"Revisiting Out-of-Distribution Detection in LiDAR-based 3D Object Detection\" \\cite{ksel20246fe}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical challenge of detecting Out-of-Distribution (OOD) objects in LiDAR-based 3D object detection systems. These are object types not present in the original training data.\n    *   **Importance and Challenge**: OOD objects can be erroneously classified as known (in-distribution, ID) objects with high confidence, posing significant safety risks and reliability issues for automated vehicles. LiDAR-based OOD detection is particularly challenging due to the complexity and sparsity of point cloud data, and it has been largely understudied compared to image-based OOD detection.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon advancements in OOD detection from image classification and image-based object detection, adapting these concepts to the LiDAR domain. It is a post-hoc method, similar to SAFE \\cite{ksel20246fe}, extending a fixed 3D object detector.\n    *   **Limitations of Previous Solutions**:\n        *   Prior LiDAR-based OOD detection work (e.g., Huang et al. \\cite{ksel20246fe}) often relies on unsupervised learning and evaluates by synthetically inserting objects from other datasets into point clouds.\n        *   `\\cite{ksel20246fe}` argues that this synthetic insertion approach introduces a \"domain gap\" (e.g., differences in intensities, unrealistic occlusion patterns), leading to an inauthentic evaluation of real-world OOD detection performance.\n        *   Image-based OOD object detection methods often evaluate by treating entire datasets as either ID or OOD, neglecting scenarios where both ID and OOD objects coexist in the same scene.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: `\\cite{ksel20246fe}` proposes a lightweight, post-hoc OOD detection method that extends a pre-trained and fixed 3D object detector with a simple multilayer perceptron (MLP).\n    *   **Novelty/Differentiation**:\n        *   **Synthetic OOD Data Generation**: Instead of requiring real OOD objects or inserting objects from other datasets, `\\cite{ksel20246fe}` generates synthetic OOD objects by perturbing known ID object categories. This is achieved by randomly applying unusual scaling factors (0.1-0.5 for smaller, 1.5-3 for larger) independently to the length, width, and height of existing annotated ID objects. This creates varied OOD objects that share geometric similarities with ID objects but are distinct enough to be OOD.\n        *   **Comprehensive Feature Extraction**: Features for the MLP are extracted from multiple sources of the fixed object detector:\n            *   Backbone feature maps (at object center using bilinear interpolation).\n            *   Encoded bounding box parameters (center, dimensions, rotation).\n            *   Concatenated raw output logits and one-hot encoded predicted classes.\n            This multi-modal feature fusion aims to exploit discrepancies (e.g., inconsistent predicted class/logits, anomalous box dimensions) that signal OOD instances.\n        *   **Novel Evaluation Protocol**: `\\cite{ksel20246fe}` introduces a new evaluation protocol for LiDAR-based OOD object detection that allows using existing datasets without modifying point clouds. It considers rare classes within existing datasets as OOD, better reflecting real-world scenarios where ID and OOD objects coexist.\n\n4.  **Key Technical Contributions**\n    *   **Novel Method**: A lightweight, post-hoc OOD detection approach for LiDAR-based 3D object detection that integrates information from the feature space, bounding box parameters, and output logits of a fixed object detector.\n    *   **Synthetic OOD Generation Strategy**: An effective method for synthesizing OOD objects by randomly and independently scaling existing ID objects, addressing the scarcity of real OOD data.\n    *   **Novel Evaluation Protocol**: A new, more realistic evaluation protocol for OOD detection in 3D object detection, which leverages existing datasets by designating rare classes as OOD, avoiding artificial object insertion.\n    *   **Benchmark Creation**: The establishment of the nuScenes OOD benchmark based on their proposed evaluation protocol.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Experiments were conducted on the newly proposed nuScenes OOD benchmark. The base 3D object detector used was CenterPoint \\cite{ksel20246fe}.\n    *   **Key Performance Metrics and Comparison Results**: The paper demonstrates the effectiveness of their approach by showing \"significantly improved OOD detection performances\" compared to prior work on the nuScenes OOD benchmark. While specific metrics (e.g., AUROC, AUPR) are not detailed in the abstract, the claim is of superior performance in correctly classifying OOD objects.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method is post-hoc and relies on a pre-trained, fixed object detector, meaning it does not involve end-to-end training of the detector and OOD module. The effectiveness is tied to the quality of features extracted by the base detector and the specific synthetic OOD generation strategy.\n    *   **Scope of Applicability**: The method is specifically designed for LiDAR-based 3D object detection in autonomous driving contexts. The synthetic OOD generation is tailored to geometric perturbations of known objects.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `\\cite{ksel20246fe}` significantly advances the technical state-of-the-art in LiDAR-based OOD object detection by providing a practical, effective, and realistically evaluable solution. It addresses critical gaps in both methodology (synthetic OOD data, multi-modal feature fusion) and evaluation (realistic benchmark).\n    *   **Potential Impact**: This work has the potential to greatly enhance the safety and reliability of automated driving systems by enabling them to identify and appropriately handle unknown foreground objects. The proposed evaluation protocol and benchmark can serve as a standard for future research in this crucial area.",
        "keywords": [
          "LiDAR-based 3D object detection",
          "Out-of-Distribution (OOD) detection",
          "post-hoc OOD method",
          "synthetic OOD data generation",
          "object scaling perturbation",
          "multi-modal feature fusion",
          "novel evaluation protocol",
          "nuScenes OOD benchmark",
          "automated driving safety",
          "point cloud data challenges",
          "MLP-based OOD classifier",
          "feature maps",
          "bounding box parameters",
          "output logits",
          "improved OOD detection performance"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract states: \"we address this problem by generating synthetic training data for ood objects...\", \"we then extract features... and train a simple multilayer perceptron (mlp) to classify each detection...\".\n*   the introduction further elaborates: \"we address this problem by generating synthetic training data...\", \"we propose a new evaluation protocol...\", \"the effectiveness of our method is validated through experiments...\".\n*   keywords like \"generating synthetic training data\", \"train a simple multilayer perceptron (mlp)\", \"propose a new evaluation protocol\", and \"our method\" strongly indicate the development and presentation of a new approach or system.\n\nthese phrases directly align with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and uses keywords like \"propose\", \"develop\", \"present\", \"algorithm\", \"method\". while it includes empirical validation, the core contribution is the proposed technical solution.\n\n**classification: technical**"
      },
      "file_name": "2f615dc49f38928fb08534b6edd1ad2c0102243a.pdf"
    },
    {
      "success": true,
      "doc_id": "ca908b02bbf15e5fa7e42c20cb753635",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical problem of Out-of-Distribution (OOD) detection in the zero-shot setting, particularly for Vision-Language Models (VLMs) like CLIP \\cite{ding20242m0}.\n    *   This problem is crucial for ensuring the safe and reliable deployment of VLMs, as they are often applied to zero-shot tasks and can make overconfident predictions on unknown (OOD) inputs.\n    *   Existing zero-shot OOD detectors, primarily relying on In-Distribution (ID) class labels, lack explicit knowledge about OOD data, leading to high false positives, especially for \"hard\" or near-OOD samples \\cite{ding20242m0}.\n\n*   **Related Work & Positioning**\n    *   Traditional OOD detection methods are inapplicable as they require training ID images, which are unavailable in zero-shot settings \\cite{ding20242m0}.\n    *   Previous zero-shot OOD detection approaches include:\n        *   **ZOC \\cite{ding20242m0}**: Uses an auxiliary text generator for OOD labels, but its effectiveness is limited by the generator's reliability, especially for large-scale ID datasets.\n        *   **MCM \\cite{ding20242m0}**: Recalibrates similarity scores in CLIP but often produces high false positives due to the lack of OOD knowledge.\n        *   **CLIPN \\cite{ding20242m0}**: Augments CLIP with a trained 'no' text encoder to learn negation semantics. While achieving state-of-the-art, it still struggles with the overconfidence issue as it primarily uses ID class label representations.\n    *   The proposed OLE \\cite{ding20242m0} complements these methods by explicitly leveraging auxiliary outlier class labels to provide OOD knowledge, positioning itself as a lightweight solution without computationally expensive extra modules.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method, **Outlier Label Exposure (OLE)** \\cite{ding20242m0}, proposes to use a large set of diverse auxiliary outlier class labels as pseudo OOD text prompts for VLMs. The key intuition is that ID images should exhibit lower similarity to these outlier prompts than OOD images.\n    *   **Outlier Prototype Learning (OPL)**: To address noise and scale issues with raw outlier labels, OPL learns a small set of pivotal outlier prototypes. This involves:\n        1.  Unsupervised clustering (using Gaussian Mixture Model, GMM) of raw outlier class prompt embeddings to derive initial prototypes (cluster centroids).\n        2.  Refining these prototypes by filtering out those that overlap significantly with ID class prompt embeddings, using a similarity-based threshold \\cite{ding20242m0}.\n    *   **Hard Outlier Prototype Generation (HOPG)**: To tackle inseparable decision regions caused by loosely coupled ID and outlier prototypes, HOPG generates \"in-between\" outlier prototypes. This is achieved by:\n        1.  Identifying \"fringe\" ID class prompt embeddings by clustering ID embeddings and selecting the most distant ones within each cluster.\n        2.  Mixing these fringe ID embeddings with the refined outlier prototypes (from OPL) using a prompt embedding mix method (inspired by mixup) to create pseudo hard outlier prototypes that calibrate the decision boundary \\cite{ding20242m0}.\n\n*   **Key Technical Contributions**\n    *   A novel approach, OLE \\cite{ding20242m0}, that cost-effectively leverages easily accessible outlier class labels to prompt VLMs for OOD knowledge in zero-shot settings.\n    *   The Outlier Prototype Learning (OPL) module, which compresses large-scale, potentially noisy, raw outlier class labels into a refined, small set of pivotal outlier prototypes.\n    *   The Hard Outlier Prototype Generation (HOPG) module, which synthesizes \"in-between\" outlier prototypes by mixing learned OOD prototypes with fringe ID class embeddings to improve decision boundary calibration.\n    *   Demonstrated significant enhancement of state-of-the-art models (like CLIPN) for both large-scale and hard OOD detection.\n\n*   **Experimental Validation**\n    *   Extensive experiments were conducted on \"two popular benchmarks\" for large-scale OOD detection and hard OOD detection \\cite{ding20242m0}.\n    *   The paper claims that OLE substantially improves detection performance and achieves new state-of-the-art performance on these benchmarks.\n    *   Specifically, it \"significantly enhance[s] the SotA model CLIPN\" \\cite{ding20242m0}. (Specific metrics like AUROC, FPR95, etc., are not detailed in the abstract but are implied by \"detection performance\").\n\n*   **Limitations & Scope**\n    *   The effectiveness of OLE \\cite{ding20242m0} relies on the availability and diversity of a large set of auxiliary outlier class labels.\n    *   The performance of OPL and HOPG depends on the choice of clustering algorithm (GMM), filtering threshold (Î»), and the method for identifying fringe ID classes.\n    *   The approach assumes that the auxiliary outlier label set `Youtlier` does not overlap with the ground truth class labels of the actual OOD distribution `Pout` to simulate real-world unknown OOD scenarios \\cite{ding20242m0}.\n    *   The scope is limited to zero-shot OOD detection using pre-trained Vision-Language Models.\n\n*   **Technical Significance**\n    *   OLE \\cite{ding20242m0} advances the technical state-of-the-art in zero-shot OOD detection by providing a novel, lightweight, and cost-effective solution that explicitly incorporates OOD knowledge through textual prompts.\n    *   It offers a generalizable framework for leveraging readily available textual information to enhance VLM safety without requiring extensive training or complex architectural modifications.\n    *   The proposed prototype learning and generation modules provide innovative strategies for handling noisy and complex label spaces, which could inspire future research in zero-shot learning and OOD detection.",
      "intriguing_abstract": "The safe and reliable deployment of Vision-Language Models (VLMs) like CLIP critically depends on their ability to detect Out-of-Distribution (OOD) inputs, especially in zero-shot settings where they often make overconfident predictions. Current zero-shot OOD detectors struggle with high false positives due to their inherent lack of explicit OOD knowledge. We introduce **Outlier Label Exposure (OLE)**, a novel and lightweight framework that cost-effectively imbues VLMs with crucial OOD awareness by leveraging readily available auxiliary outlier class labels as pseudo OOD text prompts. OLE comprises two innovative modules: **Outlier Prototype Learning (OPL)**, which compresses noisy raw outlier labels into a refined set of pivotal outlier prototypes, and **Hard Outlier Prototype Generation (HOPG)**, which synthesizes \"in-between\" prototypes by strategically mixing fringe in-distribution embeddings with learned OOD prototypes. This unique approach effectively calibrates decision boundaries, significantly reducing false positives. Extensive experiments demonstrate that OLE substantially enhances state-of-the-art models, achieving new benchmarks in large-scale and hard OOD detection. Our training-free solution offers a generalizable framework, critically advancing the reliability and safety of zero-shot VLM applications.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "zero-shot setting",
        "Vision-Language Models (VLMs)",
        "CLIP",
        "Outlier Label Exposure (OLE)",
        "Outlier Prototype Learning (OPL)",
        "Hard Outlier Prototype Generation (HOPG)",
        "auxiliary outlier class labels",
        "OOD knowledge",
        "decision boundary calibration",
        "prompt embeddings",
        "unsupervised clustering",
        "state-of-the-art enhancement",
        "lightweight solution"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/7466087f3748165181b0463153008d39879d5879.pdf",
      "citation_key": "ding20242m0",
      "metadata": {
        "title": "Zero-Shot Out-of-Distribution Detection with Outlier Label Exposure",
        "authors": [
          "Choubo Ding",
          "Guansong Pang"
        ],
        "published_date": "2024",
        "abstract": "As vision-language models like CLIP are widely applied to zero-shot tasks and gain remarkable performance on in-distribution (ID) data, detecting and rejecting out-of-distribution (OOD) inputs in the zero-shot setting have become crucial for ensuring the safety of using such models on the fly. Most existing zero-shot OOD detectors rely on ID class label-based prompts to guide CLIP in classifying ID images and rejecting OOD images. In this work we instead propose to leverage a large set of diverse auxiliary outlier class labels as pseudo OOD class text prompts to CLIP for enhancing zero-shot OOD detection, an approach we called Outlier Label Exposure (OLE). The key intuition is that ID images are expected to have lower similarity to these outlier class prompts than OOD images. One issue is that raw class labels often include noise labels, e.g., synonyms of ID labels, rendering raw OLE-based detection ineffective. To address this issue, we introduce an outlier prototype learning module that utilizes the prompt embeddings of the outlier labels to learn a small set of pivotal outlier prototypes for an embedding similarity-based OOD scoring. Additionally, the outlier classes and their prototypes can be loosely coupled with the ID classes, leading to an inseparable decision region between them. Thus, we also introduce an outlier label generation module that synthesizes our outlier prototypes and ID class embeddings to generate in-between outlier prototypes to further calibrate the detection in OLE. Despite its simplicity, extensive experiments show that OLE substantially improves detection performance and achieves new state-of-the-art performance in large-scale OOD and hard OOD detection benchmarks. Code is available at https://github.com/Choubo/OLE",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/7466087f3748165181b0463153008d39879d5879.pdf",
        "venue": "IEEE International Joint Conference on Neural Network",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical problem of Out-of-Distribution (OOD) detection in the zero-shot setting, particularly for Vision-Language Models (VLMs) like CLIP \\cite{ding20242m0}.\n    *   This problem is crucial for ensuring the safe and reliable deployment of VLMs, as they are often applied to zero-shot tasks and can make overconfident predictions on unknown (OOD) inputs.\n    *   Existing zero-shot OOD detectors, primarily relying on In-Distribution (ID) class labels, lack explicit knowledge about OOD data, leading to high false positives, especially for \"hard\" or near-OOD samples \\cite{ding20242m0}.\n\n*   **Related Work & Positioning**\n    *   Traditional OOD detection methods are inapplicable as they require training ID images, which are unavailable in zero-shot settings \\cite{ding20242m0}.\n    *   Previous zero-shot OOD detection approaches include:\n        *   **ZOC \\cite{ding20242m0}**: Uses an auxiliary text generator for OOD labels, but its effectiveness is limited by the generator's reliability, especially for large-scale ID datasets.\n        *   **MCM \\cite{ding20242m0}**: Recalibrates similarity scores in CLIP but often produces high false positives due to the lack of OOD knowledge.\n        *   **CLIPN \\cite{ding20242m0}**: Augments CLIP with a trained 'no' text encoder to learn negation semantics. While achieving state-of-the-art, it still struggles with the overconfidence issue as it primarily uses ID class label representations.\n    *   The proposed OLE \\cite{ding20242m0} complements these methods by explicitly leveraging auxiliary outlier class labels to provide OOD knowledge, positioning itself as a lightweight solution without computationally expensive extra modules.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method, **Outlier Label Exposure (OLE)** \\cite{ding20242m0}, proposes to use a large set of diverse auxiliary outlier class labels as pseudo OOD text prompts for VLMs. The key intuition is that ID images should exhibit lower similarity to these outlier prompts than OOD images.\n    *   **Outlier Prototype Learning (OPL)**: To address noise and scale issues with raw outlier labels, OPL learns a small set of pivotal outlier prototypes. This involves:\n        1.  Unsupervised clustering (using Gaussian Mixture Model, GMM) of raw outlier class prompt embeddings to derive initial prototypes (cluster centroids).\n        2.  Refining these prototypes by filtering out those that overlap significantly with ID class prompt embeddings, using a similarity-based threshold \\cite{ding20242m0}.\n    *   **Hard Outlier Prototype Generation (HOPG)**: To tackle inseparable decision regions caused by loosely coupled ID and outlier prototypes, HOPG generates \"in-between\" outlier prototypes. This is achieved by:\n        1.  Identifying \"fringe\" ID class prompt embeddings by clustering ID embeddings and selecting the most distant ones within each cluster.\n        2.  Mixing these fringe ID embeddings with the refined outlier prototypes (from OPL) using a prompt embedding mix method (inspired by mixup) to create pseudo hard outlier prototypes that calibrate the decision boundary \\cite{ding20242m0}.\n\n*   **Key Technical Contributions**\n    *   A novel approach, OLE \\cite{ding20242m0}, that cost-effectively leverages easily accessible outlier class labels to prompt VLMs for OOD knowledge in zero-shot settings.\n    *   The Outlier Prototype Learning (OPL) module, which compresses large-scale, potentially noisy, raw outlier class labels into a refined, small set of pivotal outlier prototypes.\n    *   The Hard Outlier Prototype Generation (HOPG) module, which synthesizes \"in-between\" outlier prototypes by mixing learned OOD prototypes with fringe ID class embeddings to improve decision boundary calibration.\n    *   Demonstrated significant enhancement of state-of-the-art models (like CLIPN) for both large-scale and hard OOD detection.\n\n*   **Experimental Validation**\n    *   Extensive experiments were conducted on \"two popular benchmarks\" for large-scale OOD detection and hard OOD detection \\cite{ding20242m0}.\n    *   The paper claims that OLE substantially improves detection performance and achieves new state-of-the-art performance on these benchmarks.\n    *   Specifically, it \"significantly enhance[s] the SotA model CLIPN\" \\cite{ding20242m0}. (Specific metrics like AUROC, FPR95, etc., are not detailed in the abstract but are implied by \"detection performance\").\n\n*   **Limitations & Scope**\n    *   The effectiveness of OLE \\cite{ding20242m0} relies on the availability and diversity of a large set of auxiliary outlier class labels.\n    *   The performance of OPL and HOPG depends on the choice of clustering algorithm (GMM), filtering threshold (Î»), and the method for identifying fringe ID classes.\n    *   The approach assumes that the auxiliary outlier label set `Youtlier` does not overlap with the ground truth class labels of the actual OOD distribution `Pout` to simulate real-world unknown OOD scenarios \\cite{ding20242m0}.\n    *   The scope is limited to zero-shot OOD detection using pre-trained Vision-Language Models.\n\n*   **Technical Significance**\n    *   OLE \\cite{ding20242m0} advances the technical state-of-the-art in zero-shot OOD detection by providing a novel, lightweight, and cost-effective solution that explicitly incorporates OOD knowledge through textual prompts.\n    *   It offers a generalizable framework for leveraging readily available textual information to enhance VLM safety without requiring extensive training or complex architectural modifications.\n    *   The proposed prototype learning and generation modules provide innovative strategies for handling noisy and complex label spaces, which could inspire future research in zero-shot learning and OOD detection.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "zero-shot setting",
          "Vision-Language Models (VLMs)",
          "CLIP",
          "Outlier Label Exposure (OLE)",
          "Outlier Prototype Learning (OPL)",
          "Hard Outlier Prototype Generation (HOPG)",
          "auxiliary outlier class labels",
          "OOD knowledge",
          "decision boundary calibration",
          "prompt embeddings",
          "unsupervised clustering",
          "state-of-the-art enhancement",
          "lightweight solution"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"we instead **propose** to leverage...\", \"an approach we called outlier label exposure (ole)\", \"we **introduce** an outlier prototype learning module\", \"we also **introduce** an outlier label generation module\". these phrases directly indicate the development and presentation of new methods and systems.\n*   **introduction discusses:** it elaborates on the proposed \"outlier prototype learning module\" and \"outlier label generation module,\" which are components of the new solution. it also frames the context as a technical problem (\"out-of-distribution (ood) detection is crucial for securing the safe deployment of deep learning models\").\n*   **keywords:** \"out-of-distribution detection, zero-shot detection, prompt engineering\" are all technical domains.\n*   **outcome:** \"extensive experiments show that ole substantially improves detection performance and achieves new state-of-the-art performance\" indicates the evaluation of the *newly proposed method*.\n\nthe paper's primary contribution is a novel method (ole) and its components to address a specific technical challenge (zero-shot ood detection)."
      },
      "file_name": "7466087f3748165181b0463153008d39879d5879.pdf"
    },
    {
      "success": true,
      "doc_id": "6e2b657b0c0922562f584c6d9058928a",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/dd48cfe3b7debf56ff74c4e3cf61d3d0d7aed9b8.pdf",
      "citation_key": "zhang2024d24",
      "metadata": {
        "title": "Learning to Shape In-distribution Feature Space for Out-of-distribution Detection",
        "authors": [
          "Yonggang Zhang",
          "Jie Lu",
          "Bo Peng",
          "Zhen Fang",
          "Yiu-ming Cheung"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/dd48cfe3b7debf56ff74c4e3cf61d3d0d7aed9b8.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 5,
        "score": 5.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "dd48cfe3b7debf56ff74c4e3cf61d3d0d7aed9b8.pdf"
    },
    {
      "success": true,
      "doc_id": "5b818ed78e47443341c6e97d22a42ac5",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Problem**: Detecting Out-of-Distribution (OOD) data is crucial for reliable deep neural networks (DNNs) in open-world scenarios, especially in safety-critical applications.\n    *   **Challenge**: Models trained solely on in-distribution (ID) data often make over-confident predictions on OOD data, and OOD features tend to intermingle with ID features. Existing methods that use auxiliary OOD datasets primarily focus on amplifying differences in the *output space*, neglecting the *feature space*. Designing effective feature separation losses for diverse OOD samples is difficult due to their varied and dispersed feature distributions.\n\n*   **2. Related Work & Positioning**\n    *   **Relation**: This work builds upon methods that utilize auxiliary OOD datasets to fine-tune models, such as Outlier Exposure (OE) \\cite{wu20242p3} and Energy-based methods \\cite{wu20242p3}.\n    *   **Limitations of Previous Solutions**: Previous approaches (e.g., OE, Energy method) primarily focus on increasing the *output discrepancy* between ID and OOD samples. None of these studies explicitly consider enhancing separability in the *feature space*, which is argued to be more effective. Traditional feature separation losses (e.g., dispersion loss, KL divergence) are unsuitable for OOD data due to their inherent diversity and dispersed feature distributions.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{wu20242p3} proposes a novel \"Separation Loss\" (`LSep`) to explicitly separate ID and OOD features in the feature space.\n    *   **Innovation**: The approach leverages the \"Neural Collapse (NC)\" property \\cite{wu20242p3} of ID features, which states that penultimate features of ID samples within a class are nearly identical to the last layer weight of the corresponding class.\n    *   **Mechanism**: Based on NC, \\cite{wu20242p3} constrains OOD features to lie in a subspace *orthogonal* to the principal subspace of ID features (which is spanned by the FC layer weights). This ensures ID and OOD features are separated by different dimensions.\n    *   **Loss Formulation**: The `LSep` calculates the average absolute value of the cosine similarity between normalized OOD features and the normalized weights of the final FC layer, aiming to minimize this to zero.\n    *   **Assistant Loss**: An additional \"Clustering Loss\" (`LClu`) is introduced for ID data, encouraging ID features within a class to align closely with their corresponding FC weight, thereby promoting the Neural Collapse phenomenon and making ID features more clustered.\n    *   **Overall Objective**: The final training objective combines standard cross-entropy for ID data, Outlier Exposure loss for auxiliary OOD data, and the proposed `LClu` and `LSep` losses.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Concept**: First to propose the concept of *feature separation* when fine-tuning models with auxiliary OOD data, shifting the focus from output separation.\n    *   **Novel Loss Function**: Introduction of the `Separation Loss` (`LSep`) that leverages the Neural Collapse property of ID features to constrain OOD features to an orthogonal subspace.\n    *   **Assistant Loss**: Development of the `Clustering Loss` (`LClu`) to enhance ID feature compactness and reinforce Neural Collapse.\n    *   **Methodological Framework**: Provides a simple yet effective framework that can be widely applied as a stronger baseline and seamlessly integrated with existing auxiliary OOD data approaches.\n\n*   **5. Experimental Validation**\n    *   **Experiments**: Extensive experiments were conducted on representative OOD detection setups.\n    *   **Benchmarks**: Evaluated on CIFAR10, CIFAR100, and ImageNet datasets.\n    *   **Key Metrics**: Performance was measured using FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve).\n    *   **Results**: Achieves State-of-the-Art (SOTA) performance without requiring additional data augmentation or sampling algorithms.\n        *   For example, on the CIFAR100 benchmark, \\cite{wu20242p3} achieved an average FPR95 of 29.58% and AUROC of 94.01%, outperforming the traditional Outlier Exposure (OE) method by 8.19% on FPR95.\n    *   **Visualizations**: Feature visualizations (e.g., Figure 2) empirically demonstrate that the proposed method significantly increases the separability between ID and OOD features compared to vanilla and OE-trained models.\n\n*   **6. Limitations & Scope**\n    *   **Technical Assumptions**: The method's effectiveness relies on the Neural Collapse property holding for the ID data and model architecture.\n    *   **Scope of Applicability**: Primarily applicable to scenarios where auxiliary OOD datasets are available for fine-tuning. It can serve as a stronger baseline for methods that currently use OE loss.\n\n*   **7. Technical Significance**\n    *   **Advancement**: Advances the technical state-of-the-art in OOD detection by achieving SOTA performance on standard benchmarks.\n    *   **New Insights**: Provides new insights into OOD detection by demonstrating the critical importance of feature separation over mere output separation.\n    *   **Future Research Impact**: The proposed feature separation loss can serve as a stronger and more effective baseline for future research in OOD detection, particularly for methods utilizing auxiliary OOD data. It opens avenues for exploring feature space manipulation guided by ID data properties.",
      "intriguing_abstract": "The reliability of deep neural networks (DNNs) in open-world scenarios hinges on robust Out-of-Distribution (OOD) detection, a critical challenge in safety-critical applications. Existing methods, primarily focusing on output space discrepancies, often fail to prevent DNNs from making over-confident predictions on novel OOD data due to intermingling features. We introduce a novel framework that fundamentally shifts this paradigm by explicitly enforcing feature space separation.\n\nOur core innovation is the \"Separation Loss\" (`LSep`), which leverages the inherent Neural Collapse (NC) property of in-distribution (ID) features. `LSep` strategically constrains OOD features to lie in a subspace orthogonal to the principal subspace of ID features, effectively pushing them apart. An accompanying \"Clustering Loss\" (`LClu`) further enhances ID feature compactness. This simple yet powerful approach achieves State-of-the-Art (SOTA) performance on major OOD detection benchmarks (e.g., CIFAR10, ImageNet), demonstrating significant improvements in FPR95 and AUROC over traditional methods like Outlier Exposure. Our work provides critical new insights, establishing a stronger baseline for future research and paving the way for more reliable and trustworthy DNNs.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "deep neural networks",
        "feature separation",
        "Neural Collapse property",
        "Separation Loss (LSep)",
        "Clustering Loss (LClu)",
        "auxiliary OOD datasets",
        "orthogonal subspace",
        "State-of-the-Art (SOTA) performance",
        "safety-critical applications",
        "fine-tuning models",
        "FPR95",
        "AUROC",
        "feature visualizations"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/8529e0bbf80f36998f9b65b11bc0177099f11b07.pdf",
      "citation_key": "wu20242p3",
      "metadata": {
        "title": "Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection",
        "authors": [
          "Yingwen Wu",
          "Ruiji Yu",
          "Xinwen Cheng",
          "Zhengbao He",
          "Xiaolin Huang"
        ],
        "published_date": "2024",
        "abstract": "In the open world, detecting out-of-distribution (OOD) data, whose labels are disjoint with those of in-distribution (ID) samples, is important for reliable deep neural networks (DNNs). To achieve better detection performance, one type of approach proposes to fine-tune the model with auxiliary OOD datasets to amplify the difference between ID and OOD data through a separation loss defined on model outputs. However, none of these studies consider enlarging the feature disparity, which should be more effective compared to outputs. The main difficulty lies in the diversity of OOD samples, which makes it hard to describe their feature distribution, let alone design losses to separate them from ID features. In this paper, we neatly fence off the problem based on an aggregation property of ID features named Neural Collapse (NC). NC means that the penultimate features of ID samples within a class are nearly identical to the last layer weight of the corresponding class. Based on this property, we propose a simple but effective loss called Separation Loss, which binds the features of OOD data in a subspace orthogonal to the principal subspace of ID features formed by NC. In this way, the features of ID and OOD samples are separated by different dimensions. By optimizing the feature separation loss rather than purely enlarging output differences, our detection achieves SOTA performance on CIFAR10, CIFAR100 and ImageNet benchmarks without any additional data augmentation or sampling, demonstrating the importance of feature separation in OOD detection. Code is available at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/8529e0bbf80f36998f9b65b11bc0177099f11b07.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Problem**: Detecting Out-of-Distribution (OOD) data is crucial for reliable deep neural networks (DNNs) in open-world scenarios, especially in safety-critical applications.\n    *   **Challenge**: Models trained solely on in-distribution (ID) data often make over-confident predictions on OOD data, and OOD features tend to intermingle with ID features. Existing methods that use auxiliary OOD datasets primarily focus on amplifying differences in the *output space*, neglecting the *feature space*. Designing effective feature separation losses for diverse OOD samples is difficult due to their varied and dispersed feature distributions.\n\n*   **2. Related Work & Positioning**\n    *   **Relation**: This work builds upon methods that utilize auxiliary OOD datasets to fine-tune models, such as Outlier Exposure (OE) \\cite{wu20242p3} and Energy-based methods \\cite{wu20242p3}.\n    *   **Limitations of Previous Solutions**: Previous approaches (e.g., OE, Energy method) primarily focus on increasing the *output discrepancy* between ID and OOD samples. None of these studies explicitly consider enhancing separability in the *feature space*, which is argued to be more effective. Traditional feature separation losses (e.g., dispersion loss, KL divergence) are unsuitable for OOD data due to their inherent diversity and dispersed feature distributions.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{wu20242p3} proposes a novel \"Separation Loss\" (`LSep`) to explicitly separate ID and OOD features in the feature space.\n    *   **Innovation**: The approach leverages the \"Neural Collapse (NC)\" property \\cite{wu20242p3} of ID features, which states that penultimate features of ID samples within a class are nearly identical to the last layer weight of the corresponding class.\n    *   **Mechanism**: Based on NC, \\cite{wu20242p3} constrains OOD features to lie in a subspace *orthogonal* to the principal subspace of ID features (which is spanned by the FC layer weights). This ensures ID and OOD features are separated by different dimensions.\n    *   **Loss Formulation**: The `LSep` calculates the average absolute value of the cosine similarity between normalized OOD features and the normalized weights of the final FC layer, aiming to minimize this to zero.\n    *   **Assistant Loss**: An additional \"Clustering Loss\" (`LClu`) is introduced for ID data, encouraging ID features within a class to align closely with their corresponding FC weight, thereby promoting the Neural Collapse phenomenon and making ID features more clustered.\n    *   **Overall Objective**: The final training objective combines standard cross-entropy for ID data, Outlier Exposure loss for auxiliary OOD data, and the proposed `LClu` and `LSep` losses.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Concept**: First to propose the concept of *feature separation* when fine-tuning models with auxiliary OOD data, shifting the focus from output separation.\n    *   **Novel Loss Function**: Introduction of the `Separation Loss` (`LSep`) that leverages the Neural Collapse property of ID features to constrain OOD features to an orthogonal subspace.\n    *   **Assistant Loss**: Development of the `Clustering Loss` (`LClu`) to enhance ID feature compactness and reinforce Neural Collapse.\n    *   **Methodological Framework**: Provides a simple yet effective framework that can be widely applied as a stronger baseline and seamlessly integrated with existing auxiliary OOD data approaches.\n\n*   **5. Experimental Validation**\n    *   **Experiments**: Extensive experiments were conducted on representative OOD detection setups.\n    *   **Benchmarks**: Evaluated on CIFAR10, CIFAR100, and ImageNet datasets.\n    *   **Key Metrics**: Performance was measured using FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve).\n    *   **Results**: Achieves State-of-the-Art (SOTA) performance without requiring additional data augmentation or sampling algorithms.\n        *   For example, on the CIFAR100 benchmark, \\cite{wu20242p3} achieved an average FPR95 of 29.58% and AUROC of 94.01%, outperforming the traditional Outlier Exposure (OE) method by 8.19% on FPR95.\n    *   **Visualizations**: Feature visualizations (e.g., Figure 2) empirically demonstrate that the proposed method significantly increases the separability between ID and OOD features compared to vanilla and OE-trained models.\n\n*   **6. Limitations & Scope**\n    *   **Technical Assumptions**: The method's effectiveness relies on the Neural Collapse property holding for the ID data and model architecture.\n    *   **Scope of Applicability**: Primarily applicable to scenarios where auxiliary OOD datasets are available for fine-tuning. It can serve as a stronger baseline for methods that currently use OE loss.\n\n*   **7. Technical Significance**\n    *   **Advancement**: Advances the technical state-of-the-art in OOD detection by achieving SOTA performance on standard benchmarks.\n    *   **New Insights**: Provides new insights into OOD detection by demonstrating the critical importance of feature separation over mere output separation.\n    *   **Future Research Impact**: The proposed feature separation loss can serve as a stronger and more effective baseline for future research in OOD detection, particularly for methods utilizing auxiliary OOD data. It opens avenues for exploring feature space manipulation guided by ID data properties.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "deep neural networks",
          "feature separation",
          "Neural Collapse property",
          "Separation Loss (LSep)",
          "Clustering Loss (LClu)",
          "auxiliary OOD datasets",
          "orthogonal subspace",
          "State-of-the-Art (SOTA) performance",
          "safety-critical applications",
          "fine-tuning models",
          "FPR95",
          "AUROC",
          "feature visualizations"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"we propose a simple but effective loss called separation loss\", \"our detection achieves sota performance\", \"demonstrating the importance of feature separation in ood detection.\"\n*   **introduction discusses:** \"we propose that it is crucial to separate the features between id and ood data\", \"we propose to constrain the features of ood data on dimensions orthogonal...\", \"we introduce a loss function named separation loss\", \"our approach utilizes the nc property...\", \"we conduct extensive experiments over representative ood detection setups, achieving the sota performance\". section 3 is explicitly titled \"method\".\n\nthe paper clearly presents a new method (separation loss and overall framework) to address a technical problem (out-of-distribution detection) and validates its effectiveness through experiments."
      },
      "file_name": "8529e0bbf80f36998f9b65b11bc0177099f11b07.pdf"
    },
    {
      "success": true,
      "doc_id": "1b36ea76916996beb71896b3787dc436",
      "summary": "Here's a focused summary of the paper \\cite{yao2024epq} for a literature review:\n\n### Technical Paper Analysis: Out-Of-Distribution Detection with Diversification\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, specifically the limited generalization capability of existing methods to *unknown* OOD data, even when utilizing easily accessible auxiliary outliers during training \\cite{yao2024epq}.\n    *   **Importance and Challenge**: OOD detection is crucial for the reliable deployment of machine learning models in safety-critical applications (e.g., autonomous driving, medical diagnosis) \\cite{yao2024epq}. Current auxiliary-outlier-based methods often overfit to the *limited diversity* of collected auxiliary outliers, failing to identify OOD samples that significantly deviate from the training distribution \\cite{yao2024epq}. Collecting sufficiently diverse real-world auxiliary outliers is difficult and costly in practice \\cite{yao2024epq}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Auxiliary-Outlier-Free Methods**: Early works like maximum softmax probability \\cite{yao2024epq}, ODIN \\cite{yao2024epq}, energy score \\cite{yao2024epq}, ReAct \\cite{yao2024epq}, Mahalanobis distance \\cite{yao2024epq} operate without auxiliary data, but generally show poorer performance \\cite{yao2024epq}.\n        *   **Auxiliary-Outlier-Based Methods**: Recent advancements incorporate auxiliary outliers for model regularization, including Outlier Exposure (OE) \\cite{yao2024epq}, Energy-based learning \\cite{yao2024epq}, ATOM \\cite{yao2024epq}, POEM \\cite{yao2024epq}, and DOS \\cite{yao2024epq} (improving sampling strategies), and DivOE \\cite{yao2024epq} and DAL \\cite{yao2024epq} (improving outlier quality in learnable ways) \\cite{yao2024epq}.\n        *   **Mixup-based OOD Methods**: MixOE \\cite{yao2024epq} and OpenMix \\cite{yao2024epq} perform mixup between in-distribution (ID) data and outliers, while MixOOD \\cite{yao2024epq} uses mixup on ID data to generate outliers \\cite{yao2024epq}.\n    *   **Limitations of Previous Solutions**: While auxiliary outliers improve performance, existing methods struggle with generalization due to the *limited diversity* of the collected auxiliary outliers, leading to overfitting \\cite{yao2024epq}. Previous mixup-based methods primarily focus on refining the mixup strategy or regularization, but *lack a theoretical emphasis on the significance of auxiliary outlier diversity* for generalization \\cite{yao2024epq}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**:\n        *   **Theoretical Analysis of Generalization**: The paper first provides a theoretical analysis demonstrating how the distribution shift between auxiliary outlier training data and test OOD data affects the generalization capability of OOD detectors. It establishes a generalization bound that highlights the critical role of auxiliary outlier diversity in reducing this distribution shift error \\cite{yao2024epq}.\n        *   **Diversity-induced Mixup (diverseMix)**: Inspired by the theoretical insights, the paper proposes `diverseMix`, a novel mixup strategy designed to efficiently enhance the diversity of the auxiliary outlier set during training \\cite{yao2024epq}.\n        *   **Semantic-level Interpolation**: `diverseMix` generates mixed samples through semantic-level interpolation, creating new outliers that are significantly distinct from their original counterparts \\cite{yao2024epq}.\n        *   **Dynamic Interpolation Adjustment**: The method dynamically adjusts its interpolation strategy based on original samples. This ensures that the generated outliers are novel and distinct from those the model has already learned to detect, thereby continuously enhancing diversity throughout the training process \\cite{yao2024epq}.\n    *   **Novelty/Difference**: `diverseMix` is novel in its explicit focus on *enhancing the diversity of auxiliary outliers* through a theoretically-guaranteed mixup strategy, rather than merely using mixup for regularization or generating simple transitions. The dynamic adjustment mechanism further ensures the *novelty* and *usefulness* of the generated diverse outliers \\cite{yao2024epq}.\n\n4.  **Key Technical Contributions**\n    *   **Theoretical Framework**: The paper provides a theoretical analysis establishing a generalization error bound for OOD detectors trained with auxiliary outliers. It formally demonstrates that a more diverse set of auxiliary outliers significantly reduces the distribution shift error and lowers the upper bound of the OOD detection error (Theorem 1 and Theorem 2) \\cite{yao2024epq}.\n    *   **Provable Diversity Enhancement**: It theoretically proves that semantic interpolation via mixup (under a reasonable assumption) enhances the diversity of outliers, leading to a reduction in generalization error (Lemma 1 and Theorem 3) \\cite{yao2024epq}.\n    *   **diverseMix Algorithm**: A simple yet effective, theoretically-guaranteed method, `diverseMix`, is proposed to practically enhance auxiliary outlier diversity by dynamically generating novel mixed outliers through semantic interpolation \\cite{yao2024epq}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on commonly used and recent challenging large-scale benchmarks to validate `diverseMix`'s performance \\cite{yao2024epq}. The paper includes illustrative examples (Figure 1) showing OOD scores for different training strategies, demonstrating the impact of outlier diversity \\cite{yao2024epq}.\n    *   **Key Performance Metrics and Results**:\n        *   `diverseMix` achieves superior OOD detection performance, outperforming existing state-of-the-art methods \\cite{yao2024epq}.\n        *   It shows significant relative performance improvements of 24.4% and 43.8% (in terms of FPR95) on the CIFAR-10 and CIFAR-100 datasets, respectively, over advanced methods \\cite{yao2024epq}.\n        *   Experimental results confirm that increased auxiliary outlier diversity (both real and generated by `diverseMix`) leads to improved OOD detection capabilities \\cite{yao2024epq}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The theoretical guarantees rely on the \"Semantic Change under Mixup\" assumption (Assumption 1), which posits that semantic-level interpolation between samples of distinct semantics creates new, distinct semantics \\cite{yao2024epq}.\n    *   **Scope of Applicability**: The method is primarily applicable to OOD detection scenarios where some auxiliary outliers are available, but their inherent diversity is limited, and the goal is to improve generalization to truly unknown OOD data.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The paper significantly advances the technical state-of-the-art by providing a robust theoretical foundation for the importance of auxiliary outlier diversity in OOD detection generalization. It then offers a practical, theoretically-guaranteed method (`diverseMix`) to achieve this diversity efficiently \\cite{yao2024epq}.\n    *   **Potential Impact**: This work can guide future research in OOD detection to focus more on explicit diversity enhancement strategies. It offers a cost-effective way to improve the reliability and safety of machine learning models in real-world applications by enhancing their ability to detect novel OOD samples without the prohibitive cost of collecting vast amounts of diverse real-world outliers \\cite{yao2024epq}.",
      "intriguing_abstract": "Reliable deployment of machine learning models hinges on robust Out-of-Distribution (OOD) detection, yet current methods struggle with generalizing to truly unknown OOD data. This limitation often stems from the insufficient diversity of easily accessible auxiliary outliers, leading to models that overfit and fail in safety-critical scenarios. We present a groundbreaking theoretical framework that formally establishes the critical role of auxiliary outlier diversity in OOD generalization, proving that enhanced diversity significantly reduces distribution shift error and improves detection performance.\n\nInspired by this, we introduce `diverseMix`, a novel mixup strategy designed for provable diversity enhancement. `diverseMix` employs semantic-level interpolation to dynamically generate significantly distinct, novel outliers, continuously enriching the training distribution. Extensive experiments demonstrate that `diverseMix` achieves state-of-the-art OOD detection, with remarkable FPR95 improvements of 24.4% on CIFAR-10 and 43.8% on CIFAR-100 over advanced methods. Our work provides a theoretically-guaranteed, cost-effective solution to boost OOD detector generalization, paving the way for more reliable and safe AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "auxiliary outliers",
        "generalization capability",
        "limited diversity",
        "theoretical analysis",
        "generalization bound",
        "distribution shift error",
        "diverseMix",
        "semantic-level interpolation",
        "dynamic interpolation adjustment",
        "provable diversity enhancement",
        "state-of-the-art OOD performance",
        "safety-critical applications"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/565d5a9038154fbbcba3d4a6f17671af9515fbcc.pdf",
      "citation_key": "yao2024epq",
      "metadata": {
        "title": "Out-Of-Distribution Detection with Diversification (Provably)",
        "authors": [
          "Haiyu Yao",
          "Zongbo Han",
          "Huazhu Fu",
          "Xi Peng",
          "Qinghua Hu",
          "Changqing Zhang"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is crucial for ensuring reliable deployment of machine learning models. Recent advancements focus on utilizing easily accessible auxiliary outliers (e.g., data from the web or other datasets) in training. However, we experimentally reveal that these methods still struggle to generalize their detection capabilities to unknown OOD data, due to the limited diversity of the auxiliary outliers collected. Therefore, we thoroughly examine this problem from the generalization perspective and demonstrate that a more diverse set of auxiliary outliers is essential for enhancing the detection capabilities. However, in practice, it is difficult and costly to collect sufficiently diverse auxiliary outlier data. Therefore, we propose a simple yet practical approach with a theoretical guarantee, termed Diversity-induced Mixup for OOD detection (diverseMix), which enhances the diversity of auxiliary outlier set for training in an efficient way. Extensive experiments show that diverseMix achieves superior performance on commonly used and recent challenging large-scale benchmarks, which further confirm the importance of the diversity of auxiliary outliers.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/565d5a9038154fbbcba3d4a6f17671af9515fbcc.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Here's a focused summary of the paper \\cite{yao2024epq} for a literature review:\n\n### Technical Paper Analysis: Out-Of-Distribution Detection with Diversification\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, specifically the limited generalization capability of existing methods to *unknown* OOD data, even when utilizing easily accessible auxiliary outliers during training \\cite{yao2024epq}.\n    *   **Importance and Challenge**: OOD detection is crucial for the reliable deployment of machine learning models in safety-critical applications (e.g., autonomous driving, medical diagnosis) \\cite{yao2024epq}. Current auxiliary-outlier-based methods often overfit to the *limited diversity* of collected auxiliary outliers, failing to identify OOD samples that significantly deviate from the training distribution \\cite{yao2024epq}. Collecting sufficiently diverse real-world auxiliary outliers is difficult and costly in practice \\cite{yao2024epq}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Auxiliary-Outlier-Free Methods**: Early works like maximum softmax probability \\cite{yao2024epq}, ODIN \\cite{yao2024epq}, energy score \\cite{yao2024epq}, ReAct \\cite{yao2024epq}, Mahalanobis distance \\cite{yao2024epq} operate without auxiliary data, but generally show poorer performance \\cite{yao2024epq}.\n        *   **Auxiliary-Outlier-Based Methods**: Recent advancements incorporate auxiliary outliers for model regularization, including Outlier Exposure (OE) \\cite{yao2024epq}, Energy-based learning \\cite{yao2024epq}, ATOM \\cite{yao2024epq}, POEM \\cite{yao2024epq}, and DOS \\cite{yao2024epq} (improving sampling strategies), and DivOE \\cite{yao2024epq} and DAL \\cite{yao2024epq} (improving outlier quality in learnable ways) \\cite{yao2024epq}.\n        *   **Mixup-based OOD Methods**: MixOE \\cite{yao2024epq} and OpenMix \\cite{yao2024epq} perform mixup between in-distribution (ID) data and outliers, while MixOOD \\cite{yao2024epq} uses mixup on ID data to generate outliers \\cite{yao2024epq}.\n    *   **Limitations of Previous Solutions**: While auxiliary outliers improve performance, existing methods struggle with generalization due to the *limited diversity* of the collected auxiliary outliers, leading to overfitting \\cite{yao2024epq}. Previous mixup-based methods primarily focus on refining the mixup strategy or regularization, but *lack a theoretical emphasis on the significance of auxiliary outlier diversity* for generalization \\cite{yao2024epq}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**:\n        *   **Theoretical Analysis of Generalization**: The paper first provides a theoretical analysis demonstrating how the distribution shift between auxiliary outlier training data and test OOD data affects the generalization capability of OOD detectors. It establishes a generalization bound that highlights the critical role of auxiliary outlier diversity in reducing this distribution shift error \\cite{yao2024epq}.\n        *   **Diversity-induced Mixup (diverseMix)**: Inspired by the theoretical insights, the paper proposes `diverseMix`, a novel mixup strategy designed to efficiently enhance the diversity of the auxiliary outlier set during training \\cite{yao2024epq}.\n        *   **Semantic-level Interpolation**: `diverseMix` generates mixed samples through semantic-level interpolation, creating new outliers that are significantly distinct from their original counterparts \\cite{yao2024epq}.\n        *   **Dynamic Interpolation Adjustment**: The method dynamically adjusts its interpolation strategy based on original samples. This ensures that the generated outliers are novel and distinct from those the model has already learned to detect, thereby continuously enhancing diversity throughout the training process \\cite{yao2024epq}.\n    *   **Novelty/Difference**: `diverseMix` is novel in its explicit focus on *enhancing the diversity of auxiliary outliers* through a theoretically-guaranteed mixup strategy, rather than merely using mixup for regularization or generating simple transitions. The dynamic adjustment mechanism further ensures the *novelty* and *usefulness* of the generated diverse outliers \\cite{yao2024epq}.\n\n4.  **Key Technical Contributions**\n    *   **Theoretical Framework**: The paper provides a theoretical analysis establishing a generalization error bound for OOD detectors trained with auxiliary outliers. It formally demonstrates that a more diverse set of auxiliary outliers significantly reduces the distribution shift error and lowers the upper bound of the OOD detection error (Theorem 1 and Theorem 2) \\cite{yao2024epq}.\n    *   **Provable Diversity Enhancement**: It theoretically proves that semantic interpolation via mixup (under a reasonable assumption) enhances the diversity of outliers, leading to a reduction in generalization error (Lemma 1 and Theorem 3) \\cite{yao2024epq}.\n    *   **diverseMix Algorithm**: A simple yet effective, theoretically-guaranteed method, `diverseMix`, is proposed to practically enhance auxiliary outlier diversity by dynamically generating novel mixed outliers through semantic interpolation \\cite{yao2024epq}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on commonly used and recent challenging large-scale benchmarks to validate `diverseMix`'s performance \\cite{yao2024epq}. The paper includes illustrative examples (Figure 1) showing OOD scores for different training strategies, demonstrating the impact of outlier diversity \\cite{yao2024epq}.\n    *   **Key Performance Metrics and Results**:\n        *   `diverseMix` achieves superior OOD detection performance, outperforming existing state-of-the-art methods \\cite{yao2024epq}.\n        *   It shows significant relative performance improvements of 24.4% and 43.8% (in terms of FPR95) on the CIFAR-10 and CIFAR-100 datasets, respectively, over advanced methods \\cite{yao2024epq}.\n        *   Experimental results confirm that increased auxiliary outlier diversity (both real and generated by `diverseMix`) leads to improved OOD detection capabilities \\cite{yao2024epq}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The theoretical guarantees rely on the \"Semantic Change under Mixup\" assumption (Assumption 1), which posits that semantic-level interpolation between samples of distinct semantics creates new, distinct semantics \\cite{yao2024epq}.\n    *   **Scope of Applicability**: The method is primarily applicable to OOD detection scenarios where some auxiliary outliers are available, but their inherent diversity is limited, and the goal is to improve generalization to truly unknown OOD data.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The paper significantly advances the technical state-of-the-art by providing a robust theoretical foundation for the importance of auxiliary outlier diversity in OOD detection generalization. It then offers a practical, theoretically-guaranteed method (`diverseMix`) to achieve this diversity efficiently \\cite{yao2024epq}.\n    *   **Potential Impact**: This work can guide future research in OOD detection to focus more on explicit diversity enhancement strategies. It offers a cost-effective way to improve the reliability and safety of machine learning models in real-world applications by enhancing their ability to detect novel OOD samples without the prohibitive cost of collecting vast amounts of diverse real-world outliers \\cite{yao2024epq}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "auxiliary outliers",
          "generalization capability",
          "limited diversity",
          "theoretical analysis",
          "generalization bound",
          "distribution shift error",
          "diverseMix",
          "semantic-level interpolation",
          "dynamic interpolation adjustment",
          "provable diversity enhancement",
          "state-of-the-art OOD performance",
          "safety-critical applications"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **proposes a new method/approach:** the abstract explicitly states, \"therefore, we propose a simple yet practical approach with a theoretical guarantee, termed diversity-induced mixup for ood detection (diversemix)...\" this is a strong indicator for a **technical** paper, as it presents a new system or algorithm.\n2.  **theoretical guarantee:** the title includes \"(provably)\" and the abstract mentions \"with a theoretical guarantee.\" this points to a **theoretical** component.\n3.  **empirical evaluation:** the abstract mentions, \"we experimentally reveal that these methods still struggle...\" and \"extensive experiments show that diversemix achieves superior performance on commonly used and recent challenging large-scale benchmarks...\" the introduction also states, \"we experimentally find that while the use of outlier datasets can enhance performance...\" these are strong indicators for an **empirical** paper.\n\nthe paper clearly combines elements of technical, theoretical, and empirical research. however, the core contribution is the **proposal of a new method (diversemix)**. the theoretical guarantees and extensive experiments serve to validate and demonstrate the effectiveness of this proposed technical solution. when a paper introduces a novel method, algorithm, or system, it is primarily classified as **technical**, with theoretical and empirical aspects often supporting its development and validation.\n\ntherefore, the most fitting classification is **technical**."
      },
      "file_name": "565d5a9038154fbbcba3d4a6f17671af9515fbcc.pdf"
    },
    {
      "success": true,
      "doc_id": "17ff0a7368dc494d1beb24f4773776ed",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep neural networks often produce overconfident predictions for out-of-distribution (OOD) samples, making it challenging to distinguish them from in-distribution (ID) data. This poses a significant safety risk when deploying models in real-world scenarios \\cite{chen2024kl7}.\n    *   **Importance and Challenge**: Detecting OOD samples is indispensable for safe and reliable AI systems. Existing OOD detection methods face limitations: training-based approaches are costly and require OOD samples (which are often unavailable), while training-free (post-hoc) methods struggle to effectively utilize prior information from training data and trained models \\cite{chen2024kl7}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work focuses on post-hoc OOD detection, which is training-free and does not require additional OOD samples. It builds upon the observation that overparameterized networks suffer from redundant parameters and neurons, leading to overconfident predictions \\cite{chen2024kl7}.\n    *   **Limitations of Previous Solutions**:\n        *   Training-based methods are expensive and depend on the availability of OOD samples \\cite{chen2024kl7}.\n        *   Most training-free methods do not efficiently leverage prior information from the training data \\cite{chen2024kl7}.\n        *   While some methods like DICE \\cite{chen2024kl7} also use pruning, OPNP differs by removing *both* the most sensitive and least sensitive parameters/neurons, and employs a distinct gradient-based sensitivity measure \\cite{chen2024kl7}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes Optimal Parameter and Neuron Pruning (OPNP), a two-step training-free approach \\cite{chen2024kl7}.\n        1.  **Sensitivity Estimation**: It evaluates the sensitivity of model parameters and neurons by averaging the magnitude of gradients of the energy score with respect to these parameters/neurons over all training samples \\cite{chen2024kl7}.\n        2.  **Pruning**: Parameters and neurons with *exceptionally large* or *close to zero* sensitivities are identified and removed for prediction. This is achieved by applying minimum and maximum sensitivity thresholds (e.g., based on percentiles) \\cite{chen2024kl7}.\n    *   **Novelty**: OPNP is novel because it is training-free, compatible with other post-hoc methods, and uniquely leverages prior information from *all training data* to identify and prune both redundant (low sensitivity) and risky (high sensitivity) components that contribute to over-fitting and overconfident predictions \\cite{chen2024kl7}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   A gradient-based approach to estimate the sensitivity of parameters and neurons in deep models, specifically using the energy score gradient, which is well-aligned with OOD detection metrics \\cite{chen2024kl7}.\n        *   OPNP: A simple yet effective training-free pruning method that significantly improves OOD detection performance by removing weights and neurons with exceptionally large or close to zero sensitivities \\cite{chen2024kl7}.\n    *   **Theoretical Insights/Analysis**: The paper provides three remarks justifying OPNP's effectiveness \\cite{chen2024kl7}:\n        *   Parameter and neuron pruning acts as a post-regularization technique, reducing model complexity and avoiding overconfident predictions (similar to L1/L2 regularization or targeted dropout) \\cite{chen2024kl7}.\n        *   Pruning the least sensitive parameters and neurons improves separability between ID and OOD samples by causing a larger logit reduction for OOD samples compared to ID samples \\cite{chen2024kl7}.\n        *   Pruning the most sensitive parameters and neurons improves model generalization by leading to a flatter function landscape \\cite{chen2024kl7}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on multiple OOD detection tasks and various model architectures, including ResNet and Vision Transformer (ViT) \\cite{chen2024kl7}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   OPNP achieved a 32.5% FPR95 (False Positive Rate at 95% True Positive Rate) reduction on a large-scale ImageNet-1k benchmark compared to the baseline model \\cite{chen2024kl7}.\n        *   It consistently outperformed existing state-of-the-art post-hoc OOD detection methods by 5.5% in FPR95 \\cite{chen2024kl7}.\n        *   Ablation studies demonstrated the method's effectiveness and insights. OPNP was also shown to be compatible with other post-hoc methods and beneficial for model calibration \\cite{chen2024kl7}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper notes a trade-off: pruning the most sensitive parameters can improve generalization but may slightly hurt ID-OOD separability, suggesting an optimal pruning ratio exists \\cite{chen2024kl7}. The method primarily focuses on pruning the last fully-connected layer, though it states the strategy can be applied to other layers \\cite{chen2024kl7}.\n    *   **Scope of Applicability**: OPNP is designed for post-hoc OOD detection in deep neural networks, offering a plug-and-play solution for pre-trained models without requiring further training or OOD samples \\cite{chen2024kl7}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: OPNP significantly advances the technical state-of-the-art in post-hoc OOD detection by providing a highly effective, training-free method that leverages gradient-based sensitivity for optimal parameter and neuron pruning \\cite{chen2024kl7}.\n    *   **Potential Impact on Future Research**: The insights into how parameter and neuron sensitivities relate to over-fitting, generalization, and ID-OOD separability could inspire future research in model robustness, OOD detection, and efficient model deployment, particularly in developing more sophisticated pruning strategies or understanding model behavior in open-world scenarios \\cite{chen2024kl7}.",
      "intriguing_abstract": "Deep neural networks often exhibit dangerous overconfidence when encountering out-of-distribution (OOD) samples, a critical challenge for deploying safe and reliable AI systems. Existing OOD detection methods are either computationally expensive, require unavailable OOD data, or fail to fully leverage prior information. We introduce **Optimal Parameter and Neuron Pruning (OPNP)**, a novel, training-free, and post-hoc approach that significantly enhances OOD detection performance.\n\nOPNP uniquely addresses overconfidence by estimating the sensitivity of model parameters and neurons using the average magnitude of energy score gradients across all training data. Crucially, it then prunes *both* the most and least sensitive components. This dual-pruning strategy acts as a powerful post-regularization, improving ID-OOD separability by reducing logits for OOD samples and enhancing model generalization through a flatter loss landscape.\n\nOur extensive experiments demonstrate OPNP's superior efficacy, achieving a remarkable 32.5% FPR95 reduction on ImageNet-1k and consistently outperforming state-of-the-art post-hoc methods by 5.5% FPR95. OPNP offers a plug-and-play solution, making deep learning models more robust and trustworthy in real-world scenarios, paving the way for safer AI deployment.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "deep neural networks",
        "overconfident predictions",
        "Optimal Parameter and Neuron Pruning (OPNP)",
        "training-free OOD detection",
        "gradient-based sensitivity",
        "energy score gradient",
        "parameter and neuron pruning",
        "ID-OOD separability",
        "model generalization",
        "FPR95 reduction",
        "model calibration",
        "redundant and risky components"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/590659832401c015e20a264cfdd7e0e4097b478b.pdf",
      "citation_key": "chen2024kl7",
      "metadata": {
        "title": "Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection",
        "authors": [
          "Chao Chen",
          "Zhihang Fu",
          "Kai Liu",
          "Ze Chen",
          "Mingyuan Tao",
          "Jieping Ye"
        ],
        "published_date": "2024",
        "abstract": "For a machine learning model deployed in real world scenarios, the ability of detecting out-of-distribution (OOD) samples is indispensable and challenging. Most existing OOD detection methods focused on exploring advanced training skills or training-free tricks to prevent the model from yielding overconfident confidence score for unknown samples. The training-based methods require expensive training cost and rely on OOD samples which are not always available, while most training-free methods can not efficiently utilize the prior information from the training data. In this work, we propose an \\textbf{O}ptimal \\textbf{P}arameter and \\textbf{N}euron \\textbf{P}runing (\\textbf{OPNP}) approach, which aims to identify and remove those parameters and neurons that lead to over-fitting. The main method is divided into two steps. In the first step, we evaluate the sensitivity of the model parameters and neurons by averaging gradients over all training samples. In the second step, the parameters and neurons with exceptionally large or close to zero sensitivities are removed for prediction. Our proposal is training-free, compatible with other post-hoc methods, and exploring the information from all training data. Extensive experiments are performed on multiple OOD detection tasks and model architectures, showing that our proposed OPNP consistently outperforms the existing methods by a large margin.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/590659832401c015e20a264cfdd7e0e4097b478b.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep neural networks often produce overconfident predictions for out-of-distribution (OOD) samples, making it challenging to distinguish them from in-distribution (ID) data. This poses a significant safety risk when deploying models in real-world scenarios \\cite{chen2024kl7}.\n    *   **Importance and Challenge**: Detecting OOD samples is indispensable for safe and reliable AI systems. Existing OOD detection methods face limitations: training-based approaches are costly and require OOD samples (which are often unavailable), while training-free (post-hoc) methods struggle to effectively utilize prior information from training data and trained models \\cite{chen2024kl7}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work focuses on post-hoc OOD detection, which is training-free and does not require additional OOD samples. It builds upon the observation that overparameterized networks suffer from redundant parameters and neurons, leading to overconfident predictions \\cite{chen2024kl7}.\n    *   **Limitations of Previous Solutions**:\n        *   Training-based methods are expensive and depend on the availability of OOD samples \\cite{chen2024kl7}.\n        *   Most training-free methods do not efficiently leverage prior information from the training data \\cite{chen2024kl7}.\n        *   While some methods like DICE \\cite{chen2024kl7} also use pruning, OPNP differs by removing *both* the most sensitive and least sensitive parameters/neurons, and employs a distinct gradient-based sensitivity measure \\cite{chen2024kl7}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes Optimal Parameter and Neuron Pruning (OPNP), a two-step training-free approach \\cite{chen2024kl7}.\n        1.  **Sensitivity Estimation**: It evaluates the sensitivity of model parameters and neurons by averaging the magnitude of gradients of the energy score with respect to these parameters/neurons over all training samples \\cite{chen2024kl7}.\n        2.  **Pruning**: Parameters and neurons with *exceptionally large* or *close to zero* sensitivities are identified and removed for prediction. This is achieved by applying minimum and maximum sensitivity thresholds (e.g., based on percentiles) \\cite{chen2024kl7}.\n    *   **Novelty**: OPNP is novel because it is training-free, compatible with other post-hoc methods, and uniquely leverages prior information from *all training data* to identify and prune both redundant (low sensitivity) and risky (high sensitivity) components that contribute to over-fitting and overconfident predictions \\cite{chen2024kl7}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   A gradient-based approach to estimate the sensitivity of parameters and neurons in deep models, specifically using the energy score gradient, which is well-aligned with OOD detection metrics \\cite{chen2024kl7}.\n        *   OPNP: A simple yet effective training-free pruning method that significantly improves OOD detection performance by removing weights and neurons with exceptionally large or close to zero sensitivities \\cite{chen2024kl7}.\n    *   **Theoretical Insights/Analysis**: The paper provides three remarks justifying OPNP's effectiveness \\cite{chen2024kl7}:\n        *   Parameter and neuron pruning acts as a post-regularization technique, reducing model complexity and avoiding overconfident predictions (similar to L1/L2 regularization or targeted dropout) \\cite{chen2024kl7}.\n        *   Pruning the least sensitive parameters and neurons improves separability between ID and OOD samples by causing a larger logit reduction for OOD samples compared to ID samples \\cite{chen2024kl7}.\n        *   Pruning the most sensitive parameters and neurons improves model generalization by leading to a flatter function landscape \\cite{chen2024kl7}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on multiple OOD detection tasks and various model architectures, including ResNet and Vision Transformer (ViT) \\cite{chen2024kl7}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   OPNP achieved a 32.5% FPR95 (False Positive Rate at 95% True Positive Rate) reduction on a large-scale ImageNet-1k benchmark compared to the baseline model \\cite{chen2024kl7}.\n        *   It consistently outperformed existing state-of-the-art post-hoc OOD detection methods by 5.5% in FPR95 \\cite{chen2024kl7}.\n        *   Ablation studies demonstrated the method's effectiveness and insights. OPNP was also shown to be compatible with other post-hoc methods and beneficial for model calibration \\cite{chen2024kl7}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper notes a trade-off: pruning the most sensitive parameters can improve generalization but may slightly hurt ID-OOD separability, suggesting an optimal pruning ratio exists \\cite{chen2024kl7}. The method primarily focuses on pruning the last fully-connected layer, though it states the strategy can be applied to other layers \\cite{chen2024kl7}.\n    *   **Scope of Applicability**: OPNP is designed for post-hoc OOD detection in deep neural networks, offering a plug-and-play solution for pre-trained models without requiring further training or OOD samples \\cite{chen2024kl7}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: OPNP significantly advances the technical state-of-the-art in post-hoc OOD detection by providing a highly effective, training-free method that leverages gradient-based sensitivity for optimal parameter and neuron pruning \\cite{chen2024kl7}.\n    *   **Potential Impact on Future Research**: The insights into how parameter and neuron sensitivities relate to over-fitting, generalization, and ID-OOD separability could inspire future research in model robustness, OOD detection, and efficient model deployment, particularly in developing more sophisticated pruning strategies or understanding model behavior in open-world scenarios \\cite{chen2024kl7}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "deep neural networks",
          "overconfident predictions",
          "Optimal Parameter and Neuron Pruning (OPNP)",
          "training-free OOD detection",
          "gradient-based sensitivity",
          "energy score gradient",
          "parameter and neuron pruning",
          "ID-OOD separability",
          "model generalization",
          "FPR95 reduction",
          "model calibration",
          "redundant and risky components"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"in this work, we **propose** an optimal parameter and neuron pruning (opnp) **approach**...\" and then details \"the main **method** is divided into two steps.\" it describes the technical steps involved in this new approach.\n*   the introduction sets up a technical problem (out-of-distribution detection, overconfident predictions) that the proposed method aims to solve.\n*   the abstract mentions \"extensive **experiments are performed**... showing that our proposed opnp consistently outperforms the existing methods,\" indicating empirical validation of the proposed method. however, the primary contribution is the **new method** itself, with the experiments serving to demonstrate its effectiveness.\n\nthis aligns best with the **technical** classification criteria: \"presents new methods, algorithms, or systems\" and \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\".\n\n**classification: technical**"
      },
      "file_name": "590659832401c015e20a264cfdd7e0e4097b478b.pdf"
    },
    {
      "success": true,
      "doc_id": "8013cd42bc4fbc18933c6820c389b555",
      "summary": "Uncertainty in the predictions of learning-enabled components hinders their deployment in safety-critical cyber-physical systems (CPS). A shift from the training distribution of a learning-enabled component (LEC) is one source of uncertainty in the LECâ€™s predictions. Detection of this shift or out-of-distribution (OOD) detection on individual datapoints has therefore gained attention recently. But in many applications, inputs to CPS form a temporal sequence. Existing techniques for OOD detection in time-series data for CPS either do not exploit temporal relationships in the sequence or do not provide any guarantees on detection. We propose using deviation from the in-distribution temporal equivariance as the non-conformity measure in conformal anomaly detection framework for OOD detection in time-series data for CPS. Computing independent predictions from multiple conformal detectors based on the proposed measure and combining these predictions by Fisherâ€™s method leads to the proposed detector CODiT with bounded false alarms. CODiT performs OOD detection on fixed-length windows of consecutive time-series datapoints by using Fisher value of the input window. We further propose performing OOD detection on real-time time-series traces of variable lengths with bounded false alarms. This can be done by using CODiT to compute Fisher values of the sliding windows in the input trace and combining these values by a merging function. Merging functions such as Harmonic Mean, Arithmetic Mean, Geometric Mean, Bonferroni Method, and so on, can be used to combine Fisher values of the sliding windows in the input trace, and the combined value can be used for OOD detection on the trace with bounded false alarm rate guarantees. We illustrate the efficacy of CODiT by achieving state-of-the-art results in two case studies for OOD detection on fixed-length windows. The first one is on an autonomous driving system with perception (or vision) LEC. The second case study is on a medical CPS for walking pattern or GAIT analysis where physiological (non-vision) data is collected with force-sensitive resistors attached to the subjectâ€™s body. For OOD detection on variable length traces, we consider the same case studies on the autonomous driving system and medical CPS for GAIT analysis. We report our results with four merging functions on the Fisher values computed by CODiT on the sliding windows of the input trace. We also compare the false alarm rate guarantees by these four merging functions in the autonomous driving system case study. Code, data, and trained models are available at https://github.com/kaustubhsridhar/time-series-OOD.",
      "intriguing_abstract": "Uncertainty in the predictions of learning-enabled components hinders their deployment in safety-critical cyber-physical systems (CPS). A shift from the training distribution of a learning-enabled component (LEC) is one source of uncertainty in the LECâ€™s predictions. Detection of this shift or out-of-distribution (OOD) detection on individual datapoints has therefore gained attention recently. But in many applications, inputs to CPS form a temporal sequence. Existing techniques for OOD detection in time-series data for CPS either do not exploit temporal relationships in the sequence or do not provide any guarantees on detection. We propose using deviation from the in-distribution temporal equivariance as the non-conformity measure in conformal anomaly detection framework for OOD detection in time-series data for CPS. Computing independent predictions from multiple conformal detectors based on the proposed measure and combining these predictions by Fisherâ€™s method leads to the proposed detector CODiT with bounded false alarms. CODiT performs OOD detection on fixed-length windows of consecutive time-series datapoints by using Fisher value of the input window. We further propose performing OOD detection on real-time time-series traces of variable lengths with bounded false alarms. This can be done by using CODiT to compute Fisher values of the sliding windows in the input trace and combining these values by a merging function. Merging functions such as Harmonic Mean, Arithmetic Mean, Geometric Mean, Bonferroni Method, and so on, can be used to combine Fisher values of the sliding windows in the input trace, and the combined value can be used for OOD detection on the trace with bounded false alarm rate guarantees. We illustrate the efficacy of CODiT by achieving state-of-the-art results in two case studies for OOD detection on fixed-length windows. The first one is on an autonomous driving system with perception (or vision) LEC. The second case study is on a medical CPS for walking pattern or GAIT analysis where physiological (non-vision) data is collected with force-sensitive resistors attached to the subjectâ€™s body. For OOD detection on variable length traces, we consider the same case studies on the autonomous driving system and medical CPS for GAIT analysis. We report our results with four merging functions on the Fisher values computed by CODiT on the sliding windows of the input trace. We also compare the false alarm rate guarantees by these four merging functions in the autonomous driving system case study. Code, data, and trained models are available at https://github.com/kaustubhsridhar/time-series-OOD.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/1fd384324d878cdb770a51cd333b7451b2fe5bcc.pdf",
      "citation_key": "kaur20248t3",
      "metadata": {
        "title": "Out-of-distribution Detection in Dependent Data for Cyber-physical Systems with Conformal Guarantees",
        "authors": [
          "Ramneet Kaur",
          "Yahan Yang",
          "O. Sokolsky",
          "Insup Lee"
        ],
        "published_date": "2024",
        "abstract": "Uncertainty in the predictions of learning-enabled components hinders their deployment in safety-critical cyber-physical systems (CPS). A shift from the training distribution of a learning-enabled component (LEC) is one source of uncertainty in the LECâ€™s predictions. Detection of this shift or out-of-distribution (OOD) detection on individual datapoints has therefore gained attention recently. But in many applications, inputs to CPS form a temporal sequence. Existing techniques for OOD detection in time-series data for CPS either do not exploit temporal relationships in the sequence or do not provide any guarantees on detection. We propose using deviation from the in-distribution temporal equivariance as the non-conformity measure in conformal anomaly detection framework for OOD detection in time-series data for CPS. Computing independent predictions from multiple conformal detectors based on the proposed measure and combining these predictions by Fisherâ€™s method leads to the proposed detector CODiT with bounded false alarms. CODiT performs OOD detection on fixed-length windows of consecutive time-series datapoints by using Fisher value of the input window. We further propose performing OOD detection on real-time time-series traces of variable lengths with bounded false alarms. This can be done by using CODiT to compute Fisher values of the sliding windows in the input trace and combining these values by a merging function. Merging functions such as Harmonic Mean, Arithmetic Mean, Geometric Mean, Bonferroni Method, and so on, can be used to combine Fisher values of the sliding windows in the input trace, and the combined value can be used for OOD detection on the trace with bounded false alarm rate guarantees. We illustrate the efficacy of CODiT by achieving state-of-the-art results in two case studies for OOD detection on fixed-length windows. The first one is on an autonomous driving system with perception (or vision) LEC. The second case study is on a medical CPS for walking pattern or GAIT analysis where physiological (non-vision) data is collected with force-sensitive resistors attached to the subjectâ€™s body. For OOD detection on variable length traces, we consider the same case studies on the autonomous driving system and medical CPS for GAIT analysis. We report our results with four merging functions on the Fisher values computed by CODiT on the sliding windows of the input trace. We also compare the false alarm rate guarantees by these four merging functions in the autonomous driving system case study. Code, data, and trained models are available at https://github.com/kaustubhsridhar/time-series-OOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/1fd384324d878cdb770a51cd333b7451b2fe5bcc.pdf",
        "venue": "ACM Trans. Cyber Phys. Syst.",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Uncertainty in the predictions of learning-enabled components hinders their deployment in safety-critical cyber-physical systems (CPS). A shift from the training distribution of a learning-enabled component (LEC) is one source of uncertainty in the LECâ€™s predictions. Detection of this shift or out-of-distribution (OOD) detection on individual datapoints has therefore gained attention recently. But in many applications, inputs to CPS form a temporal sequence. Existing techniques for OOD detection in time-series data for CPS either do not exploit temporal relationships in the sequence or do not provide any guarantees on detection. We propose using deviation from the in-distribution temporal equivariance as the non-conformity measure in conformal anomaly detection framework for OOD detection in time-series data for CPS. Computing independent predictions from multiple conformal detectors based on the proposed measure and combining these predictions by Fisherâ€™s method leads to the proposed detector CODiT with bounded false alarms. CODiT performs OOD detection on fixed-length windows of consecutive time-series datapoints by using Fisher value of the input window. We further propose performing OOD detection on real-time time-series traces of variable lengths with bounded false alarms. This can be done by using CODiT to compute Fisher values of the sliding windows in the input trace and combining these values by a merging function. Merging functions such as Harmonic Mean, Arithmetic Mean, Geometric Mean, Bonferroni Method, and so on, can be used to combine Fisher values of the sliding windows in the input trace, and the combined value can be used for OOD detection on the trace with bounded false alarm rate guarantees. We illustrate the efficacy of CODiT by achieving state-of-the-art results in two case studies for OOD detection on fixed-length windows. The first one is on an autonomous driving system with perception (or vision) LEC. The second case study is on a medical CPS for walking pattern or GAIT analysis where physiological (non-vision) data is collected with force-sensitive resistors attached to the subjectâ€™s body. For OOD detection on variable length traces, we consider the same case studies on the autonomous driving system and medical CPS for GAIT analysis. We report our results with four merging functions on the Fisher values computed by CODiT on the sliding windows of the input trace. We also compare the false alarm rate guarantees by these four merging functions in the autonomous driving system case study. Code, data, and trained models are available at https://github.com/kaustubhsridhar/time-series-OOD.",
        "keywords": []
      },
      "file_name": "1fd384324d878cdb770a51cd333b7451b2fe5bcc.pdf"
    },
    {
      "success": true,
      "doc_id": "59046dc3c2e94a7e6ca564292ad5861b",
      "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses two main challenges in multimodal intent understanding: 1) existing methods struggle to capture nuanced, high-level semantics for complex in-distribution (ID) multimodal intents, and 2) they exhibit poor generalization when encountering unseen out-of-distribution (OOD) data in real-world conversational scenarios \\cite{zhang2024cx0}.\n    *   **Importance & Challenge:** Multimodal intent understanding is crucial for applications like virtual humans and chatbots. The problem is challenging because it requires effective fusion of diverse modalities (text, video, audio) and learning discriminative representations for both fine-grained ID classification and robust detection of entirely novel, unseen OOD intents, which are common in open-world interactions. Previous OOD detection methods primarily focus on single modalities, and adapting existing multimodal fusion techniques often leads to overfitting on ID classes \\cite{zhang2024cx0}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon recent advancements in multimodal intent understanding (e.g., MIntRec dataset \\cite{zhang2024cx0}) and multimodal fusion techniques (e.g., transformer-based methods \\cite{zhang2024cx0}). It also relates to OOD detection research, which has focused on learning robust representations or designing scoring functions, primarily in single-modality contexts (e.g., text or vision) \\cite{zhang2024cx0}.\n    *   **Limitations of Previous Solutions:** Existing multimodal intent methods (e.g., TCL-MAP \\cite{zhang2024cx0}) are limited in learning discriminative representations for fine-grained ID classes and demonstrate poor generalization on unseen OOD data. Most OOD detection methods are modality-specific and fail to effectively leverage multiple modalities for cooperative representation learning. When adapted, existing multimodal fusion methods tend to overfit ID classes and lack robustness against OOD samples \\cite{zhang2024cx0}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The proposed method, MIntOOD, integrates a weighted feature fusion network with a multi-granularity representation learning strategy. It first extracts features using advanced backbones (BERT for text, Swin Transformer for video, WavLM for audio). A key innovation is the generation of pseudo-OOD data through convex combinations of ID features from at least two distinct classes, following a Dirichlet distribution \\cite{zhang2024cx0}.\n    *   **Novelty:**\n        *   **Weighted Feature Fusion Network:** Dynamically learns the importance of each modality by assigning adaptive weights via neural networks, performing a weighted summation of encoded representations \\cite{zhang2024cx0}.\n        *   **Multi-Granularity Representation Learning:** Optimizes learning objectives from three perspectives:\n            1.  **Coarse-grained:** A binary classifier distinguishes between ID and OOD samples.\n            2.  **Fine-grained (ID):** A cosine classifier enhances discrimination among specific ID classes by focusing on angular deviations, improving class separability.\n            3.  **Fine-grained (Instance-level):** Contrastive learning pulls ID samples of the same class together, pushes different ID classes apart, and crucially, forces *each OOD sample to separate from any other samples* (ID or OOD) to enhance generalization to unseen OOD data \\cite{zhang2024cx0}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:** Introduction of MIntOOD, the first multimodal method to achieve strong generalization on unseen OOD data while maintaining high ID classification performance \\cite{zhang2024cx0}.\n    *   **System Design/Architectural Innovations:** A simple yet effective weighted feature fusion network that dynamically learns modality importance scores. A novel strategy for synthesizing pseudo-OOD data from ID embeddings to facilitate OOD detection training without real OOD samples \\cite{zhang2024cx0}.\n    *   **Theoretical Insights/Analysis:** The multi-granularity learning objectives (coarse-grained binary, fine-grained ID, and fine-grained instance-level contrastive learning) provide a comprehensive framework for learning robust and discriminative multimodal representations for both tasks \\cite{zhang2024cx0}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were conducted on three multimodal intent datasets: MIntRec, MELD-DA, and IEMOCAP-DA. The authors established baselines for these datasets and created a dedicated OOD benchmark \\cite{zhang2024cx0}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **OOD Detection:** MIntOOD significantly improved OOD detection performance, achieving a 3% to 10% increase in AUROC (Area Under the Receiver Operating Characteristic curve) scores over the best-performing baselines \\cite{zhang2024cx0}.\n        *   **ID Classification:** The method also achieved new state-of-the-art results in ID classification \\cite{zhang2024cx0}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The method relies on the generation of pseudo-OOD data from existing ID samples. While effective, the characteristics of synthetically generated OOD might not perfectly mirror all types of real-world OOD data. The performance is also dependent on the quality of the chosen backbone feature extractors (BERT, Swin Transformer, WavLM) \\cite{zhang2024cx0}.\n    *   **Scope of Applicability:** The approach is specifically designed for multimodal intent understanding in conversational settings involving text, video, and audio modalities. Its direct applicability to other multimodal tasks or different combinations of modalities would require adaptation \\cite{zhang2024cx0}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** MIntOOD significantly advances the technical state-of-the-art by being the first multimodal method to effectively address both ID classification and OOD detection simultaneously, demonstrating strong generalization capabilities on unseen OOD data \\cite{zhang2024cx0}.\n    *   **Potential Impact:** The novel pseudo-OOD data generation strategy and the multi-granularity representation learning framework offer a robust solution for real-world open-world multimodal systems. This work establishes a new benchmark and provides a strong foundation for future research in multimodal OOD detection and robust multimodal understanding, particularly in conversational AI and human-computer interaction \\cite{zhang2024cx0}.",
      "intriguing_abstract": "The aspiration for truly intelligent conversational AI is often hampered by systems that struggle with both nuanced in-distribution (ID) multimodal intents and the unpredictable challenge of unseen out-of-distribution (OOD) data. We introduce MIntOOD, a pioneering framework that redefines multimodal intent understanding by simultaneously achieving state-of-the-art ID classification and robust OOD detection.\n\nMIntOOD's innovation lies in its novel architecture: a dynamic weighted feature fusion network adaptively combines text, video, and audio modalities. Crucially, we propose a unique pseudo-OOD data generation strategy, synthesizing diverse OOD samples from existing ID features via convex combinations following a Dirichlet distribution, circumventing the need for real OOD data. This fuels our multi-granularity representation learning, which integrates coarse-grained binary classification, fine-grained cosine classification for ID, and an instance-level contrastive learning objective that robustly separates OOD samples from all others.\n\nExtensive experiments on MIntRec, MELD-DA, and IEMOCAP-DA demonstrate MIntOOD's superior generalization, boosting OOD AUROC by 3-10% and setting new benchmarks for ID classification. This work offers a robust solution for open-world multimodal systems, paving the way for more resilient and adaptable virtual humans and chatbots.",
      "keywords": [
        "Multimodal intent understanding",
        "Out-of-distribution (OOD) detection",
        "MIntOOD",
        "Weighted feature fusion network",
        "Multi-granularity representation learning",
        "Pseudo-OOD data generation",
        "Contrastive learning",
        "Discriminative multimodal representations",
        "Enhanced generalization capabilities",
        "Conversational AI",
        "In-distribution (ID) classification",
        "AUROC scores",
        "State-of-the-art performance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/4f292e3e9d34471631203d222e597912ae936a05.pdf",
      "citation_key": "zhang2024cx0",
      "metadata": {
        "title": "Multimodal Classification and Out-of-distribution Detection for Multimodal Intent Understanding",
        "authors": [
          "Hanlei Zhang",
          "Qianrui Zhou",
          "Hua Xu",
          "Jianhua Su",
          "Roberto Evans",
          "Kai Gao"
        ],
        "published_date": "2024",
        "abstract": "Multimodal intent understanding is a significant research area that requires effective leveraging of multiple modalities to analyze human language. Existing methods face two main challenges in this domain. Firstly, they have limitations in capturing the nuanced and high-level semantics underlying complex in-distribution (ID) multimodal intents. Secondly, they exhibit poor generalization when confronted with unseen out-of-distribution (OOD) data in real-world scenarios. To address these issues, we propose a novel method for both ID classification and OOD detection (MIntOOD). We first introduce a weighted feature fusion network that models multimodal representations. This network dynamically learns the importance of each modality, adapting to multimodal contexts. To develop discriminative representations for both tasks, we synthesize pseudo-OOD data from convex combinations of ID data and engage in multimodal representation learning from both coarse-grained and fine-grained perspectives. The coarse-grained perspective focuses on distinguishing between ID and OOD binary classes, while the fine-grained perspective not only enhances the discrimination between different ID classes but also captures instance-level interactions between ID and OOD samples, promoting proximity among similar instances and separation from dissimilar ones. We establish baselines for three multimodal intent datasets and build an OOD benchmark. Extensive experiments on these datasets demonstrate that our method significantly improves OOD detection performance with a 3~10% increase in AUROC scores while achieving new state-of-the-art results in ID classification. Data and codes are available at https://github.com/thuiar/MIntOOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/4f292e3e9d34471631203d222e597912ae936a05.pdf",
        "venue": "arXiv.org",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses two main challenges in multimodal intent understanding: 1) existing methods struggle to capture nuanced, high-level semantics for complex in-distribution (ID) multimodal intents, and 2) they exhibit poor generalization when encountering unseen out-of-distribution (OOD) data in real-world conversational scenarios \\cite{zhang2024cx0}.\n    *   **Importance & Challenge:** Multimodal intent understanding is crucial for applications like virtual humans and chatbots. The problem is challenging because it requires effective fusion of diverse modalities (text, video, audio) and learning discriminative representations for both fine-grained ID classification and robust detection of entirely novel, unseen OOD intents, which are common in open-world interactions. Previous OOD detection methods primarily focus on single modalities, and adapting existing multimodal fusion techniques often leads to overfitting on ID classes \\cite{zhang2024cx0}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon recent advancements in multimodal intent understanding (e.g., MIntRec dataset \\cite{zhang2024cx0}) and multimodal fusion techniques (e.g., transformer-based methods \\cite{zhang2024cx0}). It also relates to OOD detection research, which has focused on learning robust representations or designing scoring functions, primarily in single-modality contexts (e.g., text or vision) \\cite{zhang2024cx0}.\n    *   **Limitations of Previous Solutions:** Existing multimodal intent methods (e.g., TCL-MAP \\cite{zhang2024cx0}) are limited in learning discriminative representations for fine-grained ID classes and demonstrate poor generalization on unseen OOD data. Most OOD detection methods are modality-specific and fail to effectively leverage multiple modalities for cooperative representation learning. When adapted, existing multimodal fusion methods tend to overfit ID classes and lack robustness against OOD samples \\cite{zhang2024cx0}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The proposed method, MIntOOD, integrates a weighted feature fusion network with a multi-granularity representation learning strategy. It first extracts features using advanced backbones (BERT for text, Swin Transformer for video, WavLM for audio). A key innovation is the generation of pseudo-OOD data through convex combinations of ID features from at least two distinct classes, following a Dirichlet distribution \\cite{zhang2024cx0}.\n    *   **Novelty:**\n        *   **Weighted Feature Fusion Network:** Dynamically learns the importance of each modality by assigning adaptive weights via neural networks, performing a weighted summation of encoded representations \\cite{zhang2024cx0}.\n        *   **Multi-Granularity Representation Learning:** Optimizes learning objectives from three perspectives:\n            1.  **Coarse-grained:** A binary classifier distinguishes between ID and OOD samples.\n            2.  **Fine-grained (ID):** A cosine classifier enhances discrimination among specific ID classes by focusing on angular deviations, improving class separability.\n            3.  **Fine-grained (Instance-level):** Contrastive learning pulls ID samples of the same class together, pushes different ID classes apart, and crucially, forces *each OOD sample to separate from any other samples* (ID or OOD) to enhance generalization to unseen OOD data \\cite{zhang2024cx0}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:** Introduction of MIntOOD, the first multimodal method to achieve strong generalization on unseen OOD data while maintaining high ID classification performance \\cite{zhang2024cx0}.\n    *   **System Design/Architectural Innovations:** A simple yet effective weighted feature fusion network that dynamically learns modality importance scores. A novel strategy for synthesizing pseudo-OOD data from ID embeddings to facilitate OOD detection training without real OOD samples \\cite{zhang2024cx0}.\n    *   **Theoretical Insights/Analysis:** The multi-granularity learning objectives (coarse-grained binary, fine-grained ID, and fine-grained instance-level contrastive learning) provide a comprehensive framework for learning robust and discriminative multimodal representations for both tasks \\cite{zhang2024cx0}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were conducted on three multimodal intent datasets: MIntRec, MELD-DA, and IEMOCAP-DA. The authors established baselines for these datasets and created a dedicated OOD benchmark \\cite{zhang2024cx0}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **OOD Detection:** MIntOOD significantly improved OOD detection performance, achieving a 3% to 10% increase in AUROC (Area Under the Receiver Operating Characteristic curve) scores over the best-performing baselines \\cite{zhang2024cx0}.\n        *   **ID Classification:** The method also achieved new state-of-the-art results in ID classification \\cite{zhang2024cx0}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The method relies on the generation of pseudo-OOD data from existing ID samples. While effective, the characteristics of synthetically generated OOD might not perfectly mirror all types of real-world OOD data. The performance is also dependent on the quality of the chosen backbone feature extractors (BERT, Swin Transformer, WavLM) \\cite{zhang2024cx0}.\n    *   **Scope of Applicability:** The approach is specifically designed for multimodal intent understanding in conversational settings involving text, video, and audio modalities. Its direct applicability to other multimodal tasks or different combinations of modalities would require adaptation \\cite{zhang2024cx0}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** MIntOOD significantly advances the technical state-of-the-art by being the first multimodal method to effectively address both ID classification and OOD detection simultaneously, demonstrating strong generalization capabilities on unseen OOD data \\cite{zhang2024cx0}.\n    *   **Potential Impact:** The novel pseudo-OOD data generation strategy and the multi-granularity representation learning framework offer a robust solution for real-world open-world multimodal systems. This work establishes a new benchmark and provides a strong foundation for future research in multimodal OOD detection and robust multimodal understanding, particularly in conversational AI and human-computer interaction \\cite{zhang2024cx0}.",
        "keywords": [
          "Multimodal intent understanding",
          "Out-of-distribution (OOD) detection",
          "MIntOOD",
          "Weighted feature fusion network",
          "Multi-granularity representation learning",
          "Pseudo-OOD data generation",
          "Contrastive learning",
          "Discriminative multimodal representations",
          "Enhanced generalization capabilities",
          "Conversational AI",
          "In-distribution (ID) classification",
          "AUROC scores",
          "State-of-the-art performance"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"to address these issues, we **propose a novel method** for both id classification and ood detection (mintood). we first **introduce a weighted feature fusion network**...\". it then details the technical components and approach.\n*   the introduction continues to describe the technical aspects of the proposed method, such as \"synthesize pseudo-ood data\" and \"multimodal representation learning from both coarse-grained and fine-grained perspectives.\"\n*   the paper also mentions \"extensive experiments on these datasets demonstrate that our method significantly improves...\" which indicates strong empirical validation, but the core contribution is the *development and proposal* of the new method.\n\nthis aligns perfectly with the criteria for a **technical** paper.\n\n**classification: technical**"
      },
      "file_name": "4f292e3e9d34471631203d222e597912ae936a05.pdf"
    },
    {
      "success": true,
      "doc_id": "f935390234be3ad6f53f6a3082ada0a6",
      "summary": "Here's a focused summary of the paper \"A Unified Approach Towards Active Learning and Out-of-Distribution Detection\" by Schmidt et al. for a literature review:\n\n*   **CITATION**: \\cite{schmidt2024syr}\n\n---\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Deep learning models in open-world scenarios face two critical, yet separately addressed, challenges: (1) the need for vast amounts of labeled data (addressed by Active Learning - AL) and (2) unpredictable behavior when encountering data outside the training distribution (Out-of-Distribution - OOD detection) \\cite{schmidt2024syr}.\n    *   **Importance & Challenge:** Both AL and OOD detection are crucial for robust real-world applications (e.g., mobile robotic perception). While they share common underlying metrics (uncertainty, latent space distances), current research investigates them in isolation. A simple migration of methods between tasks is ineffective due to domain-specific challenges (e.g., OOD training schemes, AL batch diversification). The paper argues for a unified approach, as real-world applications frequently necessitate concurrent consideration of both problems \\cite{schmidt2024syr}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   **Active Learning (AL):** Existing AL methods primarily focus on pool-based scenarios, selecting samples based on prediction uncertainty (e.g., Monte Carlo Dropout, ensembles), latent space diversity (e.g., CoreSet, coverage-based), or auxiliary models (e.g., loss estimation, autoencoders) \\cite{schmidt2024syr}.\n        *   **Out-of-Distribution (OOD) Detection:** OOD detection encompasses various techniques, including preprocessing (e.g., data augmentation) and postprocessing methods. Postprocessing includes logit-based approaches (e.g., energy scores, temperature scaling), and methods relying on feature space distances (e.g., Mahalanobis distance, k-NN) or gradients \\cite{schmidt2024syr}.\n    *   **Limitations of Previous Solutions:** The primary limitation is the \"disentanglement\" of AL and OOD detection. No existing method has been designed or tested for both scenarios simultaneously, despite their conceptual connections and practical co-occurrence in real-world applications \\cite{schmidt2024syr}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (SISOM - Simultaneous Informative Sampling and Outlier Mining):** \\cite{schmidt2024syr}\n        *   **Unified Solution:** SISOM is introduced as the first unified solution for both AL and OOD detection, leveraging enriched feature space distance metrics.\n        *   **Coverage:** Employs neural coverage techniques by concatenating latent spaces from multiple layers to identify unexplored regions (for diversity in AL or OOD samples) and decision boundary regions (for refining AL and detecting near-OOD).\n        *   **Feature Enhancement:** Enriches feature representations by weighting neurons based on their gradient contribution to the KL divergence between a uniform distribution and the model's softmax output. This gradient acts as a saliency weighting, prioritizing influential neurons.\n        *   **Distance Ratio:** Computes a ratio of inner-class distance (minimal distance to a known sample of the same pseudo-class) to outer-class distance (minimal distance to a known sample of a different pseudo-class) in the gradient-enhanced feature space. This guides sample selection towards decision boundaries and unexplored regions. A representative subset of labeled samples is used for efficiency.\n        *   **Feature Space Analysis:** Introduces a self-deciding process that combines the distance ratio score with an uncertainty-based energy score. The weighting between these two scores is dynamically determined by `ravg`, the average distance ratio of known samples, which estimates the separability of the feature space. If `ravg` is high (poor separation), the energy score is prioritized; if low (good separation), the distance ratio is prioritized.\n        *   **Sigmoid Steepness (Optional):** Allows for further refinement of feature space representations by introducing a layer-wise steepness parameter `Î±j` for the sigmoid function used in Feature Enhancement, which can be optimized to minimize `ravg(Î±)`.\n    *   **Novelty/Difference:** SISOM is novel as the first unified approach to AL and OOD detection. It innovatively combines neural coverage, gradient-based feature weighting, a refined distance ratio metric, and a self-adaptive mechanism (Feature Space Analysis) to robustly handle varying feature space separability \\cite{schmidt2024syr}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   **SISOM:** A novel unified framework for Simultaneous Informative Sampling and Outlier Mining, addressing both AL and OOD detection \\cite{schmidt2024syr}.\n        *   **Gradient-enhanced feature representation:** A technique that weights neuron activations based on their contribution to KL divergence, improving feature saliency for both tasks \\cite{schmidt2024syr}.\n        *   **Distance Ratio metric:** A refined metric leveraging inner-to-outer class distances in the enhanced feature space for precise sample selection and outlier identification \\cite{schmidt2024syr}.\n        *   **Feature Space Analysis:** A self-deciding process that dynamically combines distance-based and uncertainty-based scores, adapting to the separability of the feature space \\cite{schmidt2024syr}.\n        *   **Sigmoid Steepness optimization:** An optional method to fine-tune feature representations for improved separability \\cite{schmidt2024syr}.\n    *   **System Design/Architectural Innovations:** Proposes a compound framework that integrates the AL training phase and the OOD detection operation phase, illustrating their concurrent application in real-world scenarios \\cite{schmidt2024syr}.\n    *   **Theoretical Insights/Analysis:** Explores the fundamental connection between AL and OOD detection, demonstrating that a simple migration of methods is insufficient and a unified approach is beneficial. It also highlights the dependence of feature space metrics on latent space separation \\cite{schmidt2024syr}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were conducted to assess SISOM's performance on both AL and OOD detection tasks individually. The AL evaluation used the standard pool-based scenario, while OOD detection followed the OpenOOD benchmarking framework. The paper also investigated the problems arising from migrating methods between tasks \\cite{schmidt2024syr}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **OOD Detection:** SISOM achieved first place in two of the widely used OpenOOD benchmarks and second place in the remaining one \\cite{schmidt2024syr}.\n        *   **Active Learning:** SISOM outperformed other methods, delivering top-1 performance in three benchmarks, demonstrating its effectiveness in AL \\cite{schmidt2024syr}.\n        *   Comparisons were made against several AL baselines (e.g., CoreSet, Badge) and an adapted OOD method (NAC) for AL \\cite{schmidt2024syr}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The performance of feature space metrics, including SISOM's distance ratio, is highly dependent on a \"well-defined latent space\" with good feature separation. The computational cost of distance calculations is mitigated by using a representative subset of labeled samples \\cite{schmidt2024syr}.\n    *   **Scope of Applicability:** The approach is primarily designed for deep learning models in open-world scenarios, with evaluations conducted on image classification tasks using standard AL and OpenOOD benchmarks \\cite{schmidt2024syr}.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art:** SISOM represents a significant advancement by introducing the first unified solution for AL and OOD detection, addressing a critical gap in current research. Its state-of-the-art performance in both domains demonstrates the effectiveness of this integrated approach \\cite{schmidt2024syr}. The self-adaptive Feature Space Analysis mechanism enhances practical robustness \\cite{schmidt2024syr}.\n    *   **Potential Impact on Future Research:** This work opens new research avenues for developing combined AL and OOD detection strategies, moving beyond their traditional separate investigation. It encourages further exploration of dynamic feature space adaptation and the interplay between data selection and anomaly detection for more robust and efficient deep learning deployments in real-world settings \\cite{schmidt2024syr}.",
      "intriguing_abstract": "Deep learning models face a critical dilemma in open-world scenarios: the insatiable demand for labeled data (Active Learning - AL) and unpredictable behavior when encountering novel inputs (Out-of-Distribution - OOD detection). While both are crucial for robust AI, current research addresses them in isolation, leading to fragmented and inefficient solutions. We introduce **SISOM (Simultaneous Informative Sampling and Outlier Mining)**, the first unified framework designed to concurrently tackle AL and OOD detection with unprecedented efficacy.\n\nSISOM innovates through a novel **gradient-enhanced feature representation**, weighting neuron activations based on their saliency to KL divergence, and a refined **distance ratio metric** within this enriched **latent space**. Crucially, our **Feature Space Analysis** dynamically adapts its sampling strategy by combining distance-based and uncertainty-based scores, self-deciding based on feature separability. This adaptive mechanism, coupled with **neural coverage** for exploring decision boundaries and novel regions, enables SISOM to achieve state-of-the-art performance across diverse AL and OOD benchmarks. This work bridges a significant research gap, paving the way for more robust, efficient, and autonomous deep learning systems in real-world applications.",
      "keywords": [
        "Active Learning (AL)",
        "Out-of-Distribution (OOD) detection",
        "Unified approach",
        "SISOM (Simultaneous Informative Sampling and Outlier Mining)",
        "Gradient-enhanced feature representation",
        "Distance Ratio metric",
        "Feature Space Analysis",
        "Latent space separation",
        "Neural coverage",
        "Open-world scenarios",
        "State-of-the-art performance",
        "Deep learning"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/726cf970e8dc6642bb6064f78e7279cee50a9222.pdf",
      "citation_key": "schmidt2024syr",
      "metadata": {
        "title": "A Unified Approach Towards Active Learning and Out-of-Distribution Detection",
        "authors": [
          "Sebastian Schmidt",
          "Leonard Schenk",
          "Leo Schwinn",
          "Stephan GÃ¼nnemann"
        ],
        "published_date": "2024",
        "abstract": "When applying deep learning models in open-world scenarios, active learning (AL) strategies are crucial for identifying label candidates from a nearly infinite amount of unlabeled data. In this context, robust out-of-distribution (OOD) detection mechanisms are essential for handling data outside the target distribution of the application. However, current works investigate both problems separately. In this work, we introduce SISOM as the first unified solution for both AL and OOD detection. By leveraging feature space distance metrics SISOM combines the strengths of the currently independent tasks to solve both effectively. We conduct extensive experiments showing the problems arising when migrating between both tasks. In these evaluations SISOM underlined its effectiveness by achieving first place in two of the widely used OpenOOD benchmarks and second place in the remaining one. In AL, SISOM outperforms others and delivers top-1 performance in three benchmarks",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/726cf970e8dc6642bb6064f78e7279cee50a9222.pdf",
        "venue": "Trans. Mach. Learn. Res.",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Here's a focused summary of the paper \"A Unified Approach Towards Active Learning and Out-of-Distribution Detection\" by Schmidt et al. for a literature review:\n\n*   **CITATION**: \\cite{schmidt2024syr}\n\n---\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Deep learning models in open-world scenarios face two critical, yet separately addressed, challenges: (1) the need for vast amounts of labeled data (addressed by Active Learning - AL) and (2) unpredictable behavior when encountering data outside the training distribution (Out-of-Distribution - OOD detection) \\cite{schmidt2024syr}.\n    *   **Importance & Challenge:** Both AL and OOD detection are crucial for robust real-world applications (e.g., mobile robotic perception). While they share common underlying metrics (uncertainty, latent space distances), current research investigates them in isolation. A simple migration of methods between tasks is ineffective due to domain-specific challenges (e.g., OOD training schemes, AL batch diversification). The paper argues for a unified approach, as real-world applications frequently necessitate concurrent consideration of both problems \\cite{schmidt2024syr}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   **Active Learning (AL):** Existing AL methods primarily focus on pool-based scenarios, selecting samples based on prediction uncertainty (e.g., Monte Carlo Dropout, ensembles), latent space diversity (e.g., CoreSet, coverage-based), or auxiliary models (e.g., loss estimation, autoencoders) \\cite{schmidt2024syr}.\n        *   **Out-of-Distribution (OOD) Detection:** OOD detection encompasses various techniques, including preprocessing (e.g., data augmentation) and postprocessing methods. Postprocessing includes logit-based approaches (e.g., energy scores, temperature scaling), and methods relying on feature space distances (e.g., Mahalanobis distance, k-NN) or gradients \\cite{schmidt2024syr}.\n    *   **Limitations of Previous Solutions:** The primary limitation is the \"disentanglement\" of AL and OOD detection. No existing method has been designed or tested for both scenarios simultaneously, despite their conceptual connections and practical co-occurrence in real-world applications \\cite{schmidt2024syr}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (SISOM - Simultaneous Informative Sampling and Outlier Mining):** \\cite{schmidt2024syr}\n        *   **Unified Solution:** SISOM is introduced as the first unified solution for both AL and OOD detection, leveraging enriched feature space distance metrics.\n        *   **Coverage:** Employs neural coverage techniques by concatenating latent spaces from multiple layers to identify unexplored regions (for diversity in AL or OOD samples) and decision boundary regions (for refining AL and detecting near-OOD).\n        *   **Feature Enhancement:** Enriches feature representations by weighting neurons based on their gradient contribution to the KL divergence between a uniform distribution and the model's softmax output. This gradient acts as a saliency weighting, prioritizing influential neurons.\n        *   **Distance Ratio:** Computes a ratio of inner-class distance (minimal distance to a known sample of the same pseudo-class) to outer-class distance (minimal distance to a known sample of a different pseudo-class) in the gradient-enhanced feature space. This guides sample selection towards decision boundaries and unexplored regions. A representative subset of labeled samples is used for efficiency.\n        *   **Feature Space Analysis:** Introduces a self-deciding process that combines the distance ratio score with an uncertainty-based energy score. The weighting between these two scores is dynamically determined by `ravg`, the average distance ratio of known samples, which estimates the separability of the feature space. If `ravg` is high (poor separation), the energy score is prioritized; if low (good separation), the distance ratio is prioritized.\n        *   **Sigmoid Steepness (Optional):** Allows for further refinement of feature space representations by introducing a layer-wise steepness parameter `Î±j` for the sigmoid function used in Feature Enhancement, which can be optimized to minimize `ravg(Î±)`.\n    *   **Novelty/Difference:** SISOM is novel as the first unified approach to AL and OOD detection. It innovatively combines neural coverage, gradient-based feature weighting, a refined distance ratio metric, and a self-adaptive mechanism (Feature Space Analysis) to robustly handle varying feature space separability \\cite{schmidt2024syr}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   **SISOM:** A novel unified framework for Simultaneous Informative Sampling and Outlier Mining, addressing both AL and OOD detection \\cite{schmidt2024syr}.\n        *   **Gradient-enhanced feature representation:** A technique that weights neuron activations based on their contribution to KL divergence, improving feature saliency for both tasks \\cite{schmidt2024syr}.\n        *   **Distance Ratio metric:** A refined metric leveraging inner-to-outer class distances in the enhanced feature space for precise sample selection and outlier identification \\cite{schmidt2024syr}.\n        *   **Feature Space Analysis:** A self-deciding process that dynamically combines distance-based and uncertainty-based scores, adapting to the separability of the feature space \\cite{schmidt2024syr}.\n        *   **Sigmoid Steepness optimization:** An optional method to fine-tune feature representations for improved separability \\cite{schmidt2024syr}.\n    *   **System Design/Architectural Innovations:** Proposes a compound framework that integrates the AL training phase and the OOD detection operation phase, illustrating their concurrent application in real-world scenarios \\cite{schmidt2024syr}.\n    *   **Theoretical Insights/Analysis:** Explores the fundamental connection between AL and OOD detection, demonstrating that a simple migration of methods is insufficient and a unified approach is beneficial. It also highlights the dependence of feature space metrics on latent space separation \\cite{schmidt2024syr}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were conducted to assess SISOM's performance on both AL and OOD detection tasks individually. The AL evaluation used the standard pool-based scenario, while OOD detection followed the OpenOOD benchmarking framework. The paper also investigated the problems arising from migrating methods between tasks \\cite{schmidt2024syr}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **OOD Detection:** SISOM achieved first place in two of the widely used OpenOOD benchmarks and second place in the remaining one \\cite{schmidt2024syr}.\n        *   **Active Learning:** SISOM outperformed other methods, delivering top-1 performance in three benchmarks, demonstrating its effectiveness in AL \\cite{schmidt2024syr}.\n        *   Comparisons were made against several AL baselines (e.g., CoreSet, Badge) and an adapted OOD method (NAC) for AL \\cite{schmidt2024syr}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The performance of feature space metrics, including SISOM's distance ratio, is highly dependent on a \"well-defined latent space\" with good feature separation. The computational cost of distance calculations is mitigated by using a representative subset of labeled samples \\cite{schmidt2024syr}.\n    *   **Scope of Applicability:** The approach is primarily designed for deep learning models in open-world scenarios, with evaluations conducted on image classification tasks using standard AL and OpenOOD benchmarks \\cite{schmidt2024syr}.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art:** SISOM represents a significant advancement by introducing the first unified solution for AL and OOD detection, addressing a critical gap in current research. Its state-of-the-art performance in both domains demonstrates the effectiveness of this integrated approach \\cite{schmidt2024syr}. The self-adaptive Feature Space Analysis mechanism enhances practical robustness \\cite{schmidt2024syr}.\n    *   **Potential Impact on Future Research:** This work opens new research avenues for developing combined AL and OOD detection strategies, moving beyond their traditional separate investigation. It encourages further exploration of dynamic feature space adaptation and the interplay between data selection and anomaly detection for more robust and efficient deep learning deployments in real-world settings \\cite{schmidt2024syr}.",
        "keywords": [
          "Active Learning (AL)",
          "Out-of-Distribution (OOD) detection",
          "Unified approach",
          "SISOM (Simultaneous Informative Sampling and Outlier Mining)",
          "Gradient-enhanced feature representation",
          "Distance Ratio metric",
          "Feature Space Analysis",
          "Latent space separation",
          "Neural coverage",
          "Open-world scenarios",
          "State-of-the-art performance",
          "Deep learning"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we introduce sisom as the first unified solution for both al and ood detection.\" and \"by leveraging feature space distance metrics sisom combines the strengths...\". this indicates the proposal of a new method or system.\n*   the introduction sets up a technical problem (al and ood detection being handled separately) that the paper's proposed solution aims to address.\n*   while the paper clearly involves extensive experiments and empirical evaluation (\"we conduct extensive experiments\", \"achieving first place\", \"outperforms others\"), the core contribution is the *development and presentation of a new unified solution* (sisom). empirical evaluation is a means to demonstrate the effectiveness of this technical contribution.\n\ntherefore, the paper primarily falls under the **technical** classification."
      },
      "file_name": "726cf970e8dc6642bb6064f78e7279cee50a9222.pdf"
    },
    {
      "success": true,
      "doc_id": "c07cdaf6cfd3790ef38b39cd01b07645",
      "summary": "Here's a focused summary of the paper \"Out-of-Distribution Detection with Virtual Outlier Smoothing\" \\cite{nie2024ghv} for a literature review:\n\n### Technical Paper Analysis: Out-of-Distribution Detection with Virtual Outlier Smoothing \\cite{nie2024ghv}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep Neural Networks (DNNs) exhibit overconfidence in Out-of-Distribution (OOD) samples, making them unreliable in real-world deployments where unseen classes can appear. Existing methods, particularly those relying on auxiliary OOD samples during training (Outlier Exposure, OE), struggle to identify effective outliers that share patterns with in-distribution (ID) samples.\n    *   **Importance & Challenge**: OOD detection is crucial for DNN reliability. The challenge lies in mitigating DNN overconfidence for OOD inputs, especially when OOD samples bear intrinsic pattern similarities to ID samples. Traditional OE methods often assign uniform labels to all auxiliary OOD samples, which is an oversimplification and can lead to suboptimal OOD detection performance.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{nie2024ghv} builds upon the Outlier Exposure (OE) paradigm, which uses auxiliary OOD samples to regularize model training. It also relates to methods that generate virtual outliers.\n    *   **Limitations of Previous Solutions**:\n        *   **Score-based methods (e.g., MSP)**: Tend to produce overly confident predictions for OOD samples and are \"after-the-fact fixes\" that can increase detection time.\n        *   **Traditional Outlier Exposure (OE)**: Relies on the selection of auxiliary OOD samples, which is challenging, especially for outliers that resemble ID samples. It typically assigns a uniform likelihood to all OOD classes, which is considered inappropriate for virtual outliers that may retain ID patterns.\n        *   **Virtual outlier generation in feature space (e.g., VOS, NPOS)**: These methods synthesize virtual outliers by sampling around ID margin features in the feature space. However, their effectiveness is heavily dependent on the quality of the feature space, and the generated boundaries may not accurately reflect true OOD boundaries.\n        *   **Generative/Reconstruction-based methods**: Often introduce more detection time and rely on assumptions about generative models' inability to reconstruct OOD samples, which may not always hold.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{nie2024ghv} proposes **Virtual Outlier Smoothing (VOSo)**, a novel training strategy that constructs auxiliary OOD samples directly from ID samples and assigns them dynamic soft labels.\n    *   **Novelty/Difference**:\n        *   **Virtual Outlier Construction in Image Space**: Unlike prior work that samples in feature space, VOSo constructs virtual outliers by perturbing *semantic regions* of ID samples in the *image space*. This avoids reliance on feature space quality and potential training instability of generative models. Class Activation Maps (CAMs) are used to identify these semantic regions.\n        *   **Dynamic Label Assignment (Virtual Outlier Smoothing)**: Instead of assigning a uniform distribution to all virtual outliers (as in traditional OE), VOSo assigns *soft labels* that vary based on two factors:\n            1.  The *type of injected pattern* (e.g., injecting zeros, mixing with another ID sample).\n            2.  The *extent of semantic region perturbation* (controlled by a threshold `t` sampled from a Beta distribution). This creates a smoother transition in the decision boundary between ID and OOD, aligning with human intuition that an outlier partially resembling an ID class should have a label related to that class.\n\n4.  **Key Technical Contributions**\n    *   **Novel Method**: Introduction of Virtual Outlier Smoothing (VOSo) for OOD detection, which generates auxiliary outliers from ID samples.\n    *   **Innovative Outlier Construction**: A method for creating virtual outliers by perturbing semantic regions of ID samples in the pixel space, leveraging CAMs for region identification.\n    *   **Dynamic Soft Labeling Strategy**: A novel approach to assign soft labels to virtual outliers, where the label is a function of the perturbation extent and the injected pattern, moving beyond uniform OOD labels.\n    *   **Smoother Decision Boundaries**: The dynamic labeling strategy encourages a smoother transition between ID and OOD, enhancing uncertainty estimation.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on diverse OOD detection benchmarks.\n    *   **Key Performance Metrics & Comparison Results**: The paper demonstrates the effectiveness of the proposed VOSo strategy, showing significant improvements in OOD uncertainty estimation. An ablation study was also conducted to understand the efficacy of VOSo's components. (Specific datasets and metrics are not detailed in the provided abstract/introduction but are implied by \"diverse OOD detection benchmarks\" and \"greatly improves the OOD uncertainty estimation\").\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the effectiveness of CAMs for identifying semantic regions. The choice of perturbation patterns (`z1`, `z2`, `z3`) and the design of the `epsilon1(t)` function are specific to the proposed approach. The hyperparameter `T` (temperature coefficient) in the label assignment also needs tuning.\n    *   **Scope of Applicability**: Primarily applicable to image-based OOD detection tasks where semantic regions can be identified. The core idea of constructing virtual outliers from ID data and dynamically labeling them could potentially be extended to other data modalities, but the current implementation focuses on image perturbation.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{nie2024ghv} advances the technical state-of-the-art in OOD detection by offering a practical and effective way to generate relevant auxiliary OOD samples without needing external OOD datasets. Its dynamic soft labeling strategy provides a more nuanced and effective regularization than traditional uniform labeling.\n    *   **Potential Impact on Future Research**: This work opens new avenues for research into generating synthetic OOD data and designing more sophisticated regularization techniques for OOD detection. The concept of \"virtual outlier smoothing\" and dynamic label assignment could inspire further exploration into how models learn to distinguish between ID and OOD, particularly in scenarios where OOD samples are semantically close to ID data.",
      "intriguing_abstract": "Deep Neural Networks (DNNs) often exhibit dangerous overconfidence when confronted with Out-of-Distribution (OOD) samples, posing a critical challenge for their reliable deployment in real-world scenarios. Existing Outlier Exposure (OE) methods struggle with identifying effective auxiliary outliers, especially those subtly resembling in-distribution data, and typically assign simplistic uniform labels, leading to suboptimal OOD detection.\n\nWe introduce **Virtual Outlier Smoothing (VOSo)**, a novel training strategy that significantly advances OOD detection. Unlike prior work generating virtual outliers in abstract feature spaces, VOSo directly constructs auxiliary OOD samples by perturbing *semantic regions* of in-distribution images within the *pixel space*, leveraging Class Activation Maps (CAMs). Crucially, VOSo assigns *dynamic soft labels* to these virtual outliers, which vary based on the perturbation type and extent, moving beyond uniform OOD assignments. This innovative approach fosters smoother decision boundaries, greatly enhancing OOD uncertainty estimation. VOSo offers a robust and practical solution, advancing the state-of-the-art for building more trustworthy and reliable DNNs.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "DNN overconfidence",
        "Virtual Outlier Smoothing (VOSo)",
        "Outlier Exposure (OE)",
        "virtual outlier construction",
        "image space perturbation",
        "semantic regions",
        "Class Activation Maps (CAMs)",
        "dynamic soft labels",
        "uncertainty estimation",
        "smoother decision boundaries",
        "auxiliary OOD samples"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/4ae78016f21de53032cba4d7327e21b12fe1dcf5.pdf",
      "citation_key": "nie2024ghv",
      "metadata": {
        "title": "Out-of-Distribution Detection with Virtual Outlier Smoothing",
        "authors": [
          "Jun Nie",
          "Yadan Luo",
          "Shanshan Ye",
          "Yonggang Zhang",
          "Xinmei Tian",
          "Zhen Fang"
        ],
        "published_date": "2024",
        "abstract": "Detecting out-of-distribution (OOD) inputs plays a crucial role in guaranteeing the reliability of deep neural networks (DNNs) when deployed in real-world scenarios. However, DNNs typically exhibit overconfidence in OOD samples, which is attributed to the similarity in patterns between OOD and in-distribution (ID) samples. To mitigate this overconfidence, advanced approaches suggest the incorporation of auxiliary OOD samples during model training, where the outliers are assigned with an equal likelihood of belonging to any category. However, identifying outliers that share patterns with ID samples poses a significant challenge. To address the challenge, we propose a novel method, Virtual Outlier Smoothing (VOSo), which constructs auxiliary outliers using ID samples, thereby eliminating the need to search for OOD samples. Specifically, VOSo creates these virtual outliers by perturbing the semantic regions of ID samples and infusing patterns from other ID samples. For instance, a virtual outlier might consist of a catâ€™s face with a dogâ€™s nose, where the catâ€™s face serves as the semantic feature for model prediction. Meanwhile, VOSo adjusts the labels of virtual OOD samples based on the extent of semantic region perturbation, aligning with the notion that virtual outliers may contain ID patterns. Extensive experiments are conducted on diverse OOD detection benchmarks, demonstrating the effectiveness of the proposed VOSo. Our code will be available at https://github.com/junz-debug/VOSo.\n",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/4ae78016f21de53032cba4d7327e21b12fe1dcf5.pdf",
        "venue": "International Journal of Computer Vision",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Here's a focused summary of the paper \"Out-of-Distribution Detection with Virtual Outlier Smoothing\" \\cite{nie2024ghv} for a literature review:\n\n### Technical Paper Analysis: Out-of-Distribution Detection with Virtual Outlier Smoothing \\cite{nie2024ghv}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep Neural Networks (DNNs) exhibit overconfidence in Out-of-Distribution (OOD) samples, making them unreliable in real-world deployments where unseen classes can appear. Existing methods, particularly those relying on auxiliary OOD samples during training (Outlier Exposure, OE), struggle to identify effective outliers that share patterns with in-distribution (ID) samples.\n    *   **Importance & Challenge**: OOD detection is crucial for DNN reliability. The challenge lies in mitigating DNN overconfidence for OOD inputs, especially when OOD samples bear intrinsic pattern similarities to ID samples. Traditional OE methods often assign uniform labels to all auxiliary OOD samples, which is an oversimplification and can lead to suboptimal OOD detection performance.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{nie2024ghv} builds upon the Outlier Exposure (OE) paradigm, which uses auxiliary OOD samples to regularize model training. It also relates to methods that generate virtual outliers.\n    *   **Limitations of Previous Solutions**:\n        *   **Score-based methods (e.g., MSP)**: Tend to produce overly confident predictions for OOD samples and are \"after-the-fact fixes\" that can increase detection time.\n        *   **Traditional Outlier Exposure (OE)**: Relies on the selection of auxiliary OOD samples, which is challenging, especially for outliers that resemble ID samples. It typically assigns a uniform likelihood to all OOD classes, which is considered inappropriate for virtual outliers that may retain ID patterns.\n        *   **Virtual outlier generation in feature space (e.g., VOS, NPOS)**: These methods synthesize virtual outliers by sampling around ID margin features in the feature space. However, their effectiveness is heavily dependent on the quality of the feature space, and the generated boundaries may not accurately reflect true OOD boundaries.\n        *   **Generative/Reconstruction-based methods**: Often introduce more detection time and rely on assumptions about generative models' inability to reconstruct OOD samples, which may not always hold.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{nie2024ghv} proposes **Virtual Outlier Smoothing (VOSo)**, a novel training strategy that constructs auxiliary OOD samples directly from ID samples and assigns them dynamic soft labels.\n    *   **Novelty/Difference**:\n        *   **Virtual Outlier Construction in Image Space**: Unlike prior work that samples in feature space, VOSo constructs virtual outliers by perturbing *semantic regions* of ID samples in the *image space*. This avoids reliance on feature space quality and potential training instability of generative models. Class Activation Maps (CAMs) are used to identify these semantic regions.\n        *   **Dynamic Label Assignment (Virtual Outlier Smoothing)**: Instead of assigning a uniform distribution to all virtual outliers (as in traditional OE), VOSo assigns *soft labels* that vary based on two factors:\n            1.  The *type of injected pattern* (e.g., injecting zeros, mixing with another ID sample).\n            2.  The *extent of semantic region perturbation* (controlled by a threshold `t` sampled from a Beta distribution). This creates a smoother transition in the decision boundary between ID and OOD, aligning with human intuition that an outlier partially resembling an ID class should have a label related to that class.\n\n4.  **Key Technical Contributions**\n    *   **Novel Method**: Introduction of Virtual Outlier Smoothing (VOSo) for OOD detection, which generates auxiliary outliers from ID samples.\n    *   **Innovative Outlier Construction**: A method for creating virtual outliers by perturbing semantic regions of ID samples in the pixel space, leveraging CAMs for region identification.\n    *   **Dynamic Soft Labeling Strategy**: A novel approach to assign soft labels to virtual outliers, where the label is a function of the perturbation extent and the injected pattern, moving beyond uniform OOD labels.\n    *   **Smoother Decision Boundaries**: The dynamic labeling strategy encourages a smoother transition between ID and OOD, enhancing uncertainty estimation.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on diverse OOD detection benchmarks.\n    *   **Key Performance Metrics & Comparison Results**: The paper demonstrates the effectiveness of the proposed VOSo strategy, showing significant improvements in OOD uncertainty estimation. An ablation study was also conducted to understand the efficacy of VOSo's components. (Specific datasets and metrics are not detailed in the provided abstract/introduction but are implied by \"diverse OOD detection benchmarks\" and \"greatly improves the OOD uncertainty estimation\").\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the effectiveness of CAMs for identifying semantic regions. The choice of perturbation patterns (`z1`, `z2`, `z3`) and the design of the `epsilon1(t)` function are specific to the proposed approach. The hyperparameter `T` (temperature coefficient) in the label assignment also needs tuning.\n    *   **Scope of Applicability**: Primarily applicable to image-based OOD detection tasks where semantic regions can be identified. The core idea of constructing virtual outliers from ID data and dynamically labeling them could potentially be extended to other data modalities, but the current implementation focuses on image perturbation.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{nie2024ghv} advances the technical state-of-the-art in OOD detection by offering a practical and effective way to generate relevant auxiliary OOD samples without needing external OOD datasets. Its dynamic soft labeling strategy provides a more nuanced and effective regularization than traditional uniform labeling.\n    *   **Potential Impact on Future Research**: This work opens new avenues for research into generating synthetic OOD data and designing more sophisticated regularization techniques for OOD detection. The concept of \"virtual outlier smoothing\" and dynamic label assignment could inspire further exploration into how models learn to distinguish between ID and OOD, particularly in scenarios where OOD samples are semantically close to ID data.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "DNN overconfidence",
          "Virtual Outlier Smoothing (VOSo)",
          "Outlier Exposure (OE)",
          "virtual outlier construction",
          "image space perturbation",
          "semantic regions",
          "Class Activation Maps (CAMs)",
          "dynamic soft labels",
          "uncertainty estimation",
          "smoother decision boundaries",
          "auxiliary OOD samples"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"**we propose a novel method, virtual outlier smoothing (voso)**\". it then describes how this method works (\"constructs auxiliary outliers,\" \"creates these virtual outliers,\" \"adjusts the labels\").\n*   the introduction sets up a technical problem (dnns' overconfidence in ood samples) and hints at their proposed solution (generating virtual outliers by perturbing id samples, as shown in fig. 1).\n*   while \"extensive experiments are conducted... demonstrating the effectiveness\" indicates an empirical component, the core contribution is the *development and presentation of a new method*. the experiments serve to validate this new method.\n\nthis aligns perfectly with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\".\n\n**classification: technical**"
      },
      "file_name": "4ae78016f21de53032cba4d7327e21b12fe1dcf5.pdf"
    },
    {
      "success": true,
      "doc_id": "6af15a3ee3f9c600301656f8de69b017",
      "summary": "Existing methods for graph out-of-distribution (OOD) detection typically depend on training graph neural network (GNN) classifiers using a substantial amount of labeled in-distribution (ID) data. However, acquiring high-quality labeled nodes in text-attributed graphs (TAGs) is challenging and costly due to their complex textual and structural characteristics. Large language models (LLMs), known for their powerful zero-shot capabilities in textual tasks, show promise but struggle to naturally capture the critical structural information inherent to TAGs, limiting their direct effectiveness. To address these challenges, we propose LLM-GOOD, a general framework that effectively combines the strengths of LLMs and GNNs to enhance data efficiency in graph OOD detection. Specifically, we first leverage LLMs' strong zero-shot capabilities to filter out likely OOD nodes, significantly reducing the human annotation burden. To minimize the usage and cost of the LLM, we employ it only to annotate a small subset of unlabeled nodes. We then train a lightweight GNN filter using these noisy labels, enabling efficient predictions of ID status for all other unlabeled nodes by leveraging both textual and structural information. After obtaining node embeddings from the GNN filter, we can apply informativeness-based methods to select the most valuable nodes for precise human annotation. Finally, we train the target ID classifier using these accurately annotated ID nodes. Extensive experiments on four real-world TAG datasets demonstrate that LLM-GOOD significantly reduces human annotation costs and outperforms state-of-the-art baselines in terms of both ID classification accuracy and OOD detection performance.",
      "intriguing_abstract": "Existing methods for graph out-of-distribution (OOD) detection typically depend on training graph neural network (GNN) classifiers using a substantial amount of labeled in-distribution (ID) data. However, acquiring high-quality labeled nodes in text-attributed graphs (TAGs) is challenging and costly due to their complex textual and structural characteristics. Large language models (LLMs), known for their powerful zero-shot capabilities in textual tasks, show promise but struggle to naturally capture the critical structural information inherent to TAGs, limiting their direct effectiveness. To address these challenges, we propose LLM-GOOD, a general framework that effectively combines the strengths of LLMs and GNNs to enhance data efficiency in graph OOD detection. Specifically, we first leverage LLMs' strong zero-shot capabilities to filter out likely OOD nodes, significantly reducing the human annotation burden. To minimize the usage and cost of the LLM, we employ it only to annotate a small subset of unlabeled nodes. We then train a lightweight GNN filter using these noisy labels, enabling efficient predictions of ID status for all other unlabeled nodes by leveraging both textual and structural information. After obtaining node embeddings from the GNN filter, we can apply informativeness-based methods to select the most valuable nodes for precise human annotation. Finally, we train the target ID classifier using these accurately annotated ID nodes. Extensive experiments on four real-world TAG datasets demonstrate that LLM-GOOD significantly reduces human annotation costs and outperforms state-of-the-art baselines in terms of both ID classification accuracy and OOD detection performance.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/b585a0efc97216c5ed2f13945cdd58af74d7f183.pdf",
      "citation_key": "xu2025hom",
      "metadata": {
        "title": "Few-Shot Graph Out-of-Distribution Detection with LLMs",
        "authors": [
          "Haoyan Xu",
          "Zhengtao Yao",
          "Yushun Dong",
          "Ziyi Wang",
          "Ryan A. Rossi",
          "Mengyuan Li",
          "Yue Zhao"
        ],
        "published_date": "2025",
        "abstract": "Existing methods for graph out-of-distribution (OOD) detection typically depend on training graph neural network (GNN) classifiers using a substantial amount of labeled in-distribution (ID) data. However, acquiring high-quality labeled nodes in text-attributed graphs (TAGs) is challenging and costly due to their complex textual and structural characteristics. Large language models (LLMs), known for their powerful zero-shot capabilities in textual tasks, show promise but struggle to naturally capture the critical structural information inherent to TAGs, limiting their direct effectiveness. To address these challenges, we propose LLM-GOOD, a general framework that effectively combines the strengths of LLMs and GNNs to enhance data efficiency in graph OOD detection. Specifically, we first leverage LLMs' strong zero-shot capabilities to filter out likely OOD nodes, significantly reducing the human annotation burden. To minimize the usage and cost of the LLM, we employ it only to annotate a small subset of unlabeled nodes. We then train a lightweight GNN filter using these noisy labels, enabling efficient predictions of ID status for all other unlabeled nodes by leveraging both textual and structural information. After obtaining node embeddings from the GNN filter, we can apply informativeness-based methods to select the most valuable nodes for precise human annotation. Finally, we train the target ID classifier using these accurately annotated ID nodes. Extensive experiments on four real-world TAG datasets demonstrate that LLM-GOOD significantly reduces human annotation costs and outperforms state-of-the-art baselines in terms of both ID classification accuracy and OOD detection performance.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b585a0efc97216c5ed2f13945cdd58af74d7f183.pdf",
        "venue": "arXiv.org",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Existing methods for graph out-of-distribution (OOD) detection typically depend on training graph neural network (GNN) classifiers using a substantial amount of labeled in-distribution (ID) data. However, acquiring high-quality labeled nodes in text-attributed graphs (TAGs) is challenging and costly due to their complex textual and structural characteristics. Large language models (LLMs), known for their powerful zero-shot capabilities in textual tasks, show promise but struggle to naturally capture the critical structural information inherent to TAGs, limiting their direct effectiveness. To address these challenges, we propose LLM-GOOD, a general framework that effectively combines the strengths of LLMs and GNNs to enhance data efficiency in graph OOD detection. Specifically, we first leverage LLMs' strong zero-shot capabilities to filter out likely OOD nodes, significantly reducing the human annotation burden. To minimize the usage and cost of the LLM, we employ it only to annotate a small subset of unlabeled nodes. We then train a lightweight GNN filter using these noisy labels, enabling efficient predictions of ID status for all other unlabeled nodes by leveraging both textual and structural information. After obtaining node embeddings from the GNN filter, we can apply informativeness-based methods to select the most valuable nodes for precise human annotation. Finally, we train the target ID classifier using these accurately annotated ID nodes. Extensive experiments on four real-world TAG datasets demonstrate that LLM-GOOD significantly reduces human annotation costs and outperforms state-of-the-art baselines in terms of both ID classification accuracy and OOD detection performance.",
        "keywords": []
      },
      "file_name": "b585a0efc97216c5ed2f13945cdd58af74d7f183.pdf"
    },
    {
      "success": true,
      "doc_id": "e5386ec63df68937abd1fbef9cdc0c8b",
      "summary": "Here's a focused summary of the paper \\cite{vojr2023ee1} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical problem of Out-of-Distribution (OOD) detection in vision models, which is essential for reliable deployment, especially in safety-critical applications.\n    *   This problem is challenging because models trained on in-distribution (ID) data often make arbitrary and overconfident predictions for OOD inputs, leading to potentially severe real-world consequences. The ubiquity of OOD data in practice necessitates robust detection capabilities.\n\n*   **Related Work & Positioning**\n    *   Most existing OOD detection solutions focus on improving the OOD robustness of classification models trained exclusively on in-distribution (ID) data, often involving complex training schemes, regularization, or leveraging auxiliary OOD data \\cite{vojr2023ee1}.\n    *   Previous methods, such as those based on maximum softmax probability (MSP), energy scores, or Mahalanobis/KNN distances, often suffer from mis-calibrated scores, making it difficult to set a single, reliable global threshold for OOD rejection across different classes \\cite{vojr2023ee1}.\n    *   \\cite{vojr2023ee1} takes a different approach by leveraging generic pre-trained representations (e.g., from self-supervised learning) rather than training or fine-tuning feature extractors on specific ID training sets. It also avoids the need for OOD data during its adaptation process.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method, called GROOD (Generic Representation based OOD detection), formulates OOD detection as a Neyman-Pearson task \\cite{vojr2023ee1}.\n    *   It utilizes a generic pre-trained representation and combines the responses of two simple, complementary classifiers: a Linear Probe (LP) and a Nearest Mean (NM) classifier, both trained trivially on ID data. These classifiers provide discriminative and distance-based scores, respectively.\n    *   The innovation lies in modeling the in-distribution (ID) data as a 2D Gaussian distribution in the joint space of LP and NM scores. A \"general\" OOD distribution is also modeled as a Normal distribution with a zero mean and large variances.\n    *   This formulation allows for the derivation of well-calibrated rejection scores, enabling the definition of a global threshold that incurs a user-specified, pre-defined error rate (false negative rate) consistently across all ID classes \\cite{vojr2023ee1}.\n\n*   **Key Technical Contributions**\n    *   Demonstrates that using a generic pre-trained representation with simple classifiers (LP, NM) achieves state-of-the-art OOD performance \\cite{vojr2023ee1}.\n    *   Proposes a novel formulation of OOD detection as a Neyman-Pearson task in the 2D space of LP and NM scores, leading to well-calibrated classification scores and a global, class-consistent rejection threshold \\cite{vojr2023ee1}.\n    *   Introduces GROOD, a simple, general, efficient, and calibrated method with few hyper-parameters, requiring only trivial training for adaptation to specific problems \\cite{vojr2023ee1}.\n\n*   **Experimental Validation**\n    *   Experiments were conducted on a wide range of OOD benchmarks, categorized by the presence/absence of domain shift (DS) and semantic shift (SS), including 6-vs-4 splits for MNIST, SVHN, CIFAR10, and CIFAR+10/50 experiments \\cite{vojr2023ee1}.\n    *   Key performance metrics (e.g., ROC curves, AUPRC) were used to compare GROOD against state-of-the-art methods.\n    *   GROOD achieved state-of-the-art performance, often by a large margin, on most problems and reached near-perfect performance on several commonly used benchmarks \\cite{vojr2023ee1}. The experiments confirmed the superiority of using generic representations over problem-specific approaches.\n\n*   **Limitations & Scope**\n    *   The method assumes the ID distribution can be reasonably modeled as a bi-variate Normal distribution in the LP-NM score space, though it notes that more complex models could be used if needed \\cite{vojr2023ee1}.\n    *   The current implementation uses a 2D space for scores, which might be a simplification for highly complex ID distributions.\n    *   The method does not require any information about OOD data (e.g., examples of anomalies) during its adaptation, making it broadly applicable to standard OOD and Open Set Recognition (OSR) problems \\cite{vojr2023ee1}.\n\n*   **Technical Significance**\n    *   \\cite{vojr2023ee1} significantly advances the technical state-of-the-art in OOD detection by demonstrating the power of generic pre-trained representations combined with a formally well-defined, calibrated decision strategy.\n    *   Its simplicity, efficiency, and strong performance, coupled with well-calibrated scores, make it highly practical for real-world deployment.\n    *   The work highlights the potential of leveraging powerful self-supervised representations for downstream tasks like OOD detection, potentially influencing future research towards more general and less task-specific OOD solutions.",
      "intriguing_abstract": "The reliability of AI in real-world, safety-critical applications hinges on its ability to detect Out-of-Distribution (OOD) inputs, a persistent challenge where models often make overconfident, erroneous predictions. We introduce GROOD (Generic Representation based OOD detection), a novel and highly effective framework that redefines OOD detection by leveraging the power of generic pre-trained representations, eliminating the need for task-specific feature extractor training or auxiliary OOD data.\n\nGROOD formulates OOD detection as a Neyman-Pearson task, combining scores from trivially trained Linear Probe (LP) and Nearest Mean (NM) classifiers. By modeling in-distribution data as a 2D Gaussian in this joint score space, we derive inherently well-calibrated rejection scores. This innovative approach enables the definition of a single, global threshold that guarantees a user-specified false negative rate consistently across all classes, overcoming a major limitation of prior methods plagued by mis-calibrated scores. Extensive experiments across diverse OOD benchmarks demonstrate GROOD's state-of-the-art performance, often by a significant margin, achieving near-perfect results on several common datasets. GROOD offers a simple, efficient, and robust solution, paving the way for truly reliable and deployable vision models.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "generic pre-trained representations",
        "GROOD",
        "Neyman-Pearson task formulation",
        "Linear Probe and Nearest Mean classifiers",
        "well-calibrated scores",
        "global class-consistent threshold",
        "self-supervised learning",
        "2D Gaussian distribution modeling",
        "state-of-the-art OOD performance",
        "safety-critical applications",
        "Open Set Recognition (OSR)",
        "domain and semantic shift"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/eb332d020cb8877358157b7810e949d8f0256b1e.pdf",
      "citation_key": "vojr2023ee1",
      "metadata": {
        "title": "Calibrated Out-of-Distribution Detection with a Generic Representation",
        "authors": [
          "TomÃ¡s VojÃ­r",
          "Jan Sochman",
          "Rahaf Aljundi",
          "Juan E. Sala Matas"
        ],
        "published_date": "2023",
        "abstract": "Out-of-distribution detection is a common issue in deploying vision models in practice and solving it is an essential building block in safety critical applications. Most of the existing OOD detection solutions focus on improving the OOD robustness of a classification model trained exclusively on in-distribution (ID) data. In this work, we take a different approach and propose to leverage generic pre-trained representation. We propose a novel OOD method, called GROOD, that formulates the OOD detection as a Neyman-Pearson task with well calibrated scores and which achieves excellent performance, predicated by the use of a good generic representation. Only a trivial training process is required for adapting GROOD to a particular problem. The method is simple, general, efficient, calibrated and with only a few hyper-parameters. The method achieves state-of-the-art performance on a number of OOD benchmarks, reaching near perfect performance on several of them. The source code is available at https://github.com/vojirt/GROOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/eb332d020cb8877358157b7810e949d8f0256b1e.pdf",
        "venue": "2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)",
        "citationCount": 10,
        "score": 5.0,
        "summary": "Here's a focused summary of the paper \\cite{vojr2023ee1} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical problem of Out-of-Distribution (OOD) detection in vision models, which is essential for reliable deployment, especially in safety-critical applications.\n    *   This problem is challenging because models trained on in-distribution (ID) data often make arbitrary and overconfident predictions for OOD inputs, leading to potentially severe real-world consequences. The ubiquity of OOD data in practice necessitates robust detection capabilities.\n\n*   **Related Work & Positioning**\n    *   Most existing OOD detection solutions focus on improving the OOD robustness of classification models trained exclusively on in-distribution (ID) data, often involving complex training schemes, regularization, or leveraging auxiliary OOD data \\cite{vojr2023ee1}.\n    *   Previous methods, such as those based on maximum softmax probability (MSP), energy scores, or Mahalanobis/KNN distances, often suffer from mis-calibrated scores, making it difficult to set a single, reliable global threshold for OOD rejection across different classes \\cite{vojr2023ee1}.\n    *   \\cite{vojr2023ee1} takes a different approach by leveraging generic pre-trained representations (e.g., from self-supervised learning) rather than training or fine-tuning feature extractors on specific ID training sets. It also avoids the need for OOD data during its adaptation process.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method, called GROOD (Generic Representation based OOD detection), formulates OOD detection as a Neyman-Pearson task \\cite{vojr2023ee1}.\n    *   It utilizes a generic pre-trained representation and combines the responses of two simple, complementary classifiers: a Linear Probe (LP) and a Nearest Mean (NM) classifier, both trained trivially on ID data. These classifiers provide discriminative and distance-based scores, respectively.\n    *   The innovation lies in modeling the in-distribution (ID) data as a 2D Gaussian distribution in the joint space of LP and NM scores. A \"general\" OOD distribution is also modeled as a Normal distribution with a zero mean and large variances.\n    *   This formulation allows for the derivation of well-calibrated rejection scores, enabling the definition of a global threshold that incurs a user-specified, pre-defined error rate (false negative rate) consistently across all ID classes \\cite{vojr2023ee1}.\n\n*   **Key Technical Contributions**\n    *   Demonstrates that using a generic pre-trained representation with simple classifiers (LP, NM) achieves state-of-the-art OOD performance \\cite{vojr2023ee1}.\n    *   Proposes a novel formulation of OOD detection as a Neyman-Pearson task in the 2D space of LP and NM scores, leading to well-calibrated classification scores and a global, class-consistent rejection threshold \\cite{vojr2023ee1}.\n    *   Introduces GROOD, a simple, general, efficient, and calibrated method with few hyper-parameters, requiring only trivial training for adaptation to specific problems \\cite{vojr2023ee1}.\n\n*   **Experimental Validation**\n    *   Experiments were conducted on a wide range of OOD benchmarks, categorized by the presence/absence of domain shift (DS) and semantic shift (SS), including 6-vs-4 splits for MNIST, SVHN, CIFAR10, and CIFAR+10/50 experiments \\cite{vojr2023ee1}.\n    *   Key performance metrics (e.g., ROC curves, AUPRC) were used to compare GROOD against state-of-the-art methods.\n    *   GROOD achieved state-of-the-art performance, often by a large margin, on most problems and reached near-perfect performance on several commonly used benchmarks \\cite{vojr2023ee1}. The experiments confirmed the superiority of using generic representations over problem-specific approaches.\n\n*   **Limitations & Scope**\n    *   The method assumes the ID distribution can be reasonably modeled as a bi-variate Normal distribution in the LP-NM score space, though it notes that more complex models could be used if needed \\cite{vojr2023ee1}.\n    *   The current implementation uses a 2D space for scores, which might be a simplification for highly complex ID distributions.\n    *   The method does not require any information about OOD data (e.g., examples of anomalies) during its adaptation, making it broadly applicable to standard OOD and Open Set Recognition (OSR) problems \\cite{vojr2023ee1}.\n\n*   **Technical Significance**\n    *   \\cite{vojr2023ee1} significantly advances the technical state-of-the-art in OOD detection by demonstrating the power of generic pre-trained representations combined with a formally well-defined, calibrated decision strategy.\n    *   Its simplicity, efficiency, and strong performance, coupled with well-calibrated scores, make it highly practical for real-world deployment.\n    *   The work highlights the potential of leveraging powerful self-supervised representations for downstream tasks like OOD detection, potentially influencing future research towards more general and less task-specific OOD solutions.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "generic pre-trained representations",
          "GROOD",
          "Neyman-Pearson task formulation",
          "Linear Probe and Nearest Mean classifiers",
          "well-calibrated scores",
          "global class-consistent threshold",
          "self-supervised learning",
          "2D Gaussian distribution modeling",
          "state-of-the-art OOD performance",
          "safety-critical applications",
          "Open Set Recognition (OSR)",
          "domain and semantic shift"
        ],
        "paper_type": "**technical**\n\n**reasoning:**\n\n*   **abstract:** explicitly states \"we **propose** to leverage generic pre-trained representation,\" and \"we **propose a novel ood method, called grood**.\" it describes the method's formulation (\"formulates the ood detection as a neyman-pearson task\"), its characteristics (\"simple, general, efficient, calibrated\"), and its performance (\"achieves state-of-the-art performance\"). the availability of source code also points to a technical contribution.\n*   **introduction:** sets up a technical problem (out-of-distribution detection), discusses its importance and existing challenges (\"prior art has mainly developed ood detection models by supervised training\"), which is typical for papers introducing a new technical solution to an existing problem.\n*   **classification criteria match:** the abstract directly uses keywords like \"propose\" and \"method,\" and the content describes a \"proposed solution\" to a \"technical problem,\" which are key indicators for the \"technical\" classification. while it mentions \"state-of-the-art performance\" (empirical), this is the *validation* of the *new method*, making the primary classification \"technical.\""
      },
      "file_name": "eb332d020cb8877358157b7810e949d8f0256b1e.pdf"
    },
    {
      "success": true,
      "doc_id": "74cd0c1e5f61fe0341ad3b654bdf444b",
      "summary": "Here's a focused summary of the paper \\cite{lu20249d4} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing distance-based Out-of-Distribution (OOD) detection methods, while promising, rely on oversimplified data assumptions, specifically modeling each in-distribution (ID) class with a single centroid or prototype. This overlooks the natural diversity within real-world data.\n    *   **Importance & Challenge**: OOD detection is crucial for the safe and reliable deployment of machine learning models in open-world scenarios. The challenge lies in accurately distinguishing unseen OOD samples from ID data, especially when ID classes themselves exhibit significant internal variations that a single prototype cannot adequately capture, leading to inadequate modeling and diminished OOD detection performance.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{lu20249d4} builds upon distance-based OOD detection methods that leverage deep representation learning and identify OOD samples by measuring distances to ID class prototypes. It also draws from contrastive learning and prototypical learning paradigms.\n    *   **Limitations of Previous Solutions**: Prior distance-based methods, particularly those modeling data with von Mises-Fisher (vMF) distributions (e.g., \\cite{ming2023, du2022a}), enforce all samples of a class to be compact around a *single* prototype. This \"naive enforcement\" restricts modeling capability, fails to represent diverse patterns within each class, and can lead to confusion between ID and OOD samples, ultimately reducing detection performance.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{lu20249d4} proposes Prototypic AlLearning with a Mixture of prototypes (PALM), which models each ID class with *multiple* prototypes using a mixture of vMF distributions in a hyperspherical embedding space.\n    *   **Novelty**:\n        *   **Mixture Prototype Modeling**: Instead of a single prototype per class, PALM uses multiple prototypes per class to capture intra-class diversity, leading to more faithful and compact sample embeddings.\n        *   **Automatic Prototype Identification & Dynamic Update**: Prototypes are automatically identified and dynamically updated throughout training.\n        *   **Reciprocal Neighbor Soft Assignment**: Each sample is softly assigned to a subset of prototypes via specifically designed reciprocal neighbor assignment weights, allowing flexible association.\n        *   **Dual Loss Optimization**: PALM optimizes a Maximum Likelihood Estimation (MLE) loss to encourage sample embeddings to be compact around their associated prototypes, and a novel *prototype contrastive loss* to enhance intra-class compactness at the prototype level and inter-class discrimination between prototypes of different classes.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of a mixture-of-prototypes model for OOD detection, specifically using vMF distributions in a hyperspherical embedding space.\n    *   **Novel Techniques**: A prototypical learning framework with automatic and dynamic prototype updates, incorporating reciprocal neighbor soft assignment weights.\n    *   **Novel Loss Functions**: A combined objective function comprising an MLE loss tailored for mixture prototypes and a novel prototype contrastive loss for prototype-level regularization.\n    *   **Extended Applicability**: The automatic prototype learning mechanism enables PALM to be extended to challenging unsupervised OOD detection settings with unlabelled ID data.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed to demonstrate PALM's effectiveness on OOD detection benchmarks. The paper specifically highlights results on the challenging CIFAR-100 dataset. It also evaluates the method's performance in unsupervised OOD detection settings.\n    *   **Key Performance Metrics & Results**: PALM achieved state-of-the-art average AUROC (Area Under the Receiver Operating Characteristic) performance of 93.82 on the CIFAR-100 benchmark, demonstrating superiority over previous methods. The experiments also showed promising results for unsupervised OOD detection.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method primarily operates within the framework of hyperspherical embeddings and vMF distributions. While effective, its direct applicability might be limited to scenarios where such embedding spaces are suitable. The core method assumes labelled ID data, though an extension for unlabelled data is presented.\n    *   **Scope of Applicability**: PALM is designed for distance-based OOD detection, particularly in scenarios where ID classes exhibit significant internal diversity. Its primary focus is on improving representation learning for better ID-OOD discrimination.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{lu20249d4} significantly advances the technical state-of-the-art in distance-based OOD detection by addressing the critical limitation of oversimplified ID data modeling. By introducing mixture prototypes and a sophisticated learning framework, it enables more accurate and reliable OOD detection.\n    *   **Potential Impact**: The proposed mixture prototype modeling and dual-loss optimization strategy offer a more robust way to learn discriminative representations, which can inspire future research in representation learning for OOD detection. Its extension to unsupervised OOD detection also opens new avenues for deploying OOD-aware systems in settings where labels are scarce.",
      "intriguing_abstract": "The promise of robust AI hinges on its ability to detect Out-of-Distribution (OOD) samples, yet prevailing distance-based methods falter by oversimplifying the rich diversity within in-distribution (ID) data, modeling each class with a single, inadequate prototype. We introduce Prototypic AlLearning with a Mixture of prototypes (PALM), a novel framework that revolutionizes OOD detection by modeling each ID class with *multiple* prototypes using von Mises-Fisher (vMF) distributions in a hyperspherical embedding space. PALM dynamically identifies and updates these prototypes, employing a reciprocal neighbor soft assignment for flexible sample association. Its dual optimization strategy combines a Maximum Likelihood Estimation loss with a novel *prototype contrastive loss* to ensure both intra-class compactness and superior inter-class discrimination at the prototype level. This sophisticated approach overcomes the limitations of single-prototype models, achieving state-of-the-art OOD detection performance, exemplified by an impressive 93.82 AUROC on the challenging CIFAR-100 benchmark. Furthermore, PALM's automatic prototype learning extends its applicability to unsupervised OOD detection, paving the way for safer, more adaptable machine learning systems in real-world, label-scarce environments.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Prototypic AlLearning with a Mixture of prototypes (PALM)",
        "Mixture Prototype Modeling",
        "Intra-class diversity",
        "Hyperspherical embedding space",
        "von Mises-Fisher (vMF) distributions",
        "Prototype contrastive loss",
        "Automatic and dynamic prototype updates",
        "Reciprocal neighbor soft assignment",
        "Unsupervised OOD detection",
        "State-of-the-art AUROC",
        "Distance-based OOD detection",
        "Representation learning"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/79c72327dd14466c4db3865902c8317f74bb4c56.pdf",
      "citation_key": "lu20249d4",
      "metadata": {
        "title": "Learning with Mixture of Prototypes for Out-of-Distribution Detection",
        "authors": [
          "Haodong Lu",
          "Dong Gong",
          "Shuo Wang",
          "Jason Xue",
          "Lina Yao",
          "Kristen Moore"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection aims to detect testing samples far away from the in-distribution (ID) training data, which is crucial for the safe deployment of machine learning models in the real world. Distance-based OOD detection methods have emerged with enhanced deep representation learning. They identify unseen OOD samples by measuring their distances from ID class centroids or prototypes. However, existing approaches learn the representation relying on oversimplified data assumptions, e.g, modeling ID data of each class with one centroid class prototype or using loss functions not designed for OOD detection, which overlook the natural diversities within the data. Naively enforcing data samples of each class to be compact around only one prototype leads to inadequate modeling of realistic data and limited performance. To tackle these issues, we propose PrototypicAl Learning with a Mixture of prototypes (PALM) which models each class with multiple prototypes to capture the sample diversities, and learns more faithful and compact samples embeddings to enhance OOD detection. Our method automatically identifies and dynamically updates prototypes, assigning each sample to a subset of prototypes via reciprocal neighbor soft assignment weights. PALM optimizes a maximum likelihood estimation (MLE) loss to encourage the sample embeddings to be compact around the associated prototypes, as well as a contrastive loss on all prototypes to enhance intra-class compactness and inter-class discrimination at the prototype level. Moreover, the automatic estimation of prototypes enables our approach to be extended to the challenging OOD detection task with unlabelled ID data. Extensive experiments demonstrate the superiority of PALM, achieving state-of-the-art average AUROC performance of 93.82 on the challenging CIFAR-100 benchmark. Code is available at https://github.com/jeff024/PALM.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/79c72327dd14466c4db3865902c8317f74bb4c56.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 37,
        "score": 37.0,
        "summary": "Here's a focused summary of the paper \\cite{lu20249d4} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing distance-based Out-of-Distribution (OOD) detection methods, while promising, rely on oversimplified data assumptions, specifically modeling each in-distribution (ID) class with a single centroid or prototype. This overlooks the natural diversity within real-world data.\n    *   **Importance & Challenge**: OOD detection is crucial for the safe and reliable deployment of machine learning models in open-world scenarios. The challenge lies in accurately distinguishing unseen OOD samples from ID data, especially when ID classes themselves exhibit significant internal variations that a single prototype cannot adequately capture, leading to inadequate modeling and diminished OOD detection performance.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{lu20249d4} builds upon distance-based OOD detection methods that leverage deep representation learning and identify OOD samples by measuring distances to ID class prototypes. It also draws from contrastive learning and prototypical learning paradigms.\n    *   **Limitations of Previous Solutions**: Prior distance-based methods, particularly those modeling data with von Mises-Fisher (vMF) distributions (e.g., \\cite{ming2023, du2022a}), enforce all samples of a class to be compact around a *single* prototype. This \"naive enforcement\" restricts modeling capability, fails to represent diverse patterns within each class, and can lead to confusion between ID and OOD samples, ultimately reducing detection performance.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{lu20249d4} proposes Prototypic AlLearning with a Mixture of prototypes (PALM), which models each ID class with *multiple* prototypes using a mixture of vMF distributions in a hyperspherical embedding space.\n    *   **Novelty**:\n        *   **Mixture Prototype Modeling**: Instead of a single prototype per class, PALM uses multiple prototypes per class to capture intra-class diversity, leading to more faithful and compact sample embeddings.\n        *   **Automatic Prototype Identification & Dynamic Update**: Prototypes are automatically identified and dynamically updated throughout training.\n        *   **Reciprocal Neighbor Soft Assignment**: Each sample is softly assigned to a subset of prototypes via specifically designed reciprocal neighbor assignment weights, allowing flexible association.\n        *   **Dual Loss Optimization**: PALM optimizes a Maximum Likelihood Estimation (MLE) loss to encourage sample embeddings to be compact around their associated prototypes, and a novel *prototype contrastive loss* to enhance intra-class compactness at the prototype level and inter-class discrimination between prototypes of different classes.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of a mixture-of-prototypes model for OOD detection, specifically using vMF distributions in a hyperspherical embedding space.\n    *   **Novel Techniques**: A prototypical learning framework with automatic and dynamic prototype updates, incorporating reciprocal neighbor soft assignment weights.\n    *   **Novel Loss Functions**: A combined objective function comprising an MLE loss tailored for mixture prototypes and a novel prototype contrastive loss for prototype-level regularization.\n    *   **Extended Applicability**: The automatic prototype learning mechanism enables PALM to be extended to challenging unsupervised OOD detection settings with unlabelled ID data.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed to demonstrate PALM's effectiveness on OOD detection benchmarks. The paper specifically highlights results on the challenging CIFAR-100 dataset. It also evaluates the method's performance in unsupervised OOD detection settings.\n    *   **Key Performance Metrics & Results**: PALM achieved state-of-the-art average AUROC (Area Under the Receiver Operating Characteristic) performance of 93.82 on the CIFAR-100 benchmark, demonstrating superiority over previous methods. The experiments also showed promising results for unsupervised OOD detection.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method primarily operates within the framework of hyperspherical embeddings and vMF distributions. While effective, its direct applicability might be limited to scenarios where such embedding spaces are suitable. The core method assumes labelled ID data, though an extension for unlabelled data is presented.\n    *   **Scope of Applicability**: PALM is designed for distance-based OOD detection, particularly in scenarios where ID classes exhibit significant internal diversity. Its primary focus is on improving representation learning for better ID-OOD discrimination.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{lu20249d4} significantly advances the technical state-of-the-art in distance-based OOD detection by addressing the critical limitation of oversimplified ID data modeling. By introducing mixture prototypes and a sophisticated learning framework, it enables more accurate and reliable OOD detection.\n    *   **Potential Impact**: The proposed mixture prototype modeling and dual-loss optimization strategy offer a more robust way to learn discriminative representations, which can inspire future research in representation learning for OOD detection. Its extension to unsupervised OOD detection also opens new avenues for deploying OOD-aware systems in settings where labels are scarce.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Prototypic AlLearning with a Mixture of prototypes (PALM)",
          "Mixture Prototype Modeling",
          "Intra-class diversity",
          "Hyperspherical embedding space",
          "von Mises-Fisher (vMF) distributions",
          "Prototype contrastive loss",
          "Automatic and dynamic prototype updates",
          "Reciprocal neighbor soft assignment",
          "Unsupervised OOD detection",
          "State-of-the-art AUROC",
          "Distance-based OOD detection",
          "Representation learning"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** prototypic allearning with a mixture of prototypes (palm) which models each class with multiple prototypes...\"\n*   the introduction further details: \"we **propose** prototypic allearning with a mixture of prototypes (palm) which models each class with multiple prototypes...\", \"our method automatically identifies and dynamically updates prototypes...\", \"palm optimizes a maximum likelihood estimation (mle) loss... as well as a contrastive loss...\"\n*   the introduction also mentions: \"extensive **experiments demonstrate the superiority of palm** over previous methods, achieving state-of-the-art average auroc perfor-mance...\" this indicates an empirical evaluation of the *proposed* method.\n\nthe primary focus is on presenting a **new method/algorithm (palm)** and describing its technical details and components. the experiments serve to validate this new technical contribution.\n\ntherefore, the paper is best classified as **technical**."
      },
      "file_name": "79c72327dd14466c4db3865902c8317f74bb4c56.pdf"
    },
    {
      "success": true,
      "doc_id": "fb14cbb7299fba2254eb13f086d5120a",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/522513df46de56f4eeaca95b0a8196dae065f75e.pdf",
      "citation_key": "nie20240bk",
      "metadata": {
        "title": "Out-of-Distribution Detection with Negative Prompts",
        "authors": [
          "Jun Nie",
          "Yonggang Zhang",
          "Zhen Fang",
          "Tongliang Liu",
          "Bo Han",
          "Xinmei Tian"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/522513df46de56f4eeaca95b0a8196dae065f75e.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 32,
        "score": 32.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "522513df46de56f4eeaca95b0a8196dae065f75e.pdf"
    },
    {
      "success": true,
      "doc_id": "4100b32384fbd482df0ed2d19be1b23f",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, particularly how to effectively and *provably* leverage unlabeled \"wild\" data to improve model safety and reliability.\n    *   **Importance & Challenge**: Neural networks are known to be brittle and lack awareness of OOD data. Identifying OOD inputs is crucial but difficult because models are not explicitly trained on unknown distributions. The key challenge with unlabeled wild data is its heterogeneous mixture of In-Distribution (ID) and OOD samples (modeled as a Huber contamination model), making it non-trivial to extract useful OOD information without clean OOD labels. A formal understanding of how unlabeled data helps OOD detection has been lacking.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds on the idea of using unlabeled data for regularization in OOD detection, similar to approaches like Katz-Samuels et al. (2022).\n    *   **Limitations of Previous Solutions**: Existing methods often lack formal theoretical guarantees on how unlabeled data aids OOD detection. Some approaches, like Outlier Exposure \\cite{hendrycks2019deep}, require a *clean* set of auxiliary unlabeled data, an assumption that \\cite{du20248xe} explicitly avoids, offering greater flexibility. The paper positions itself by bridging the gap in formally understanding and provably justifying the use of unlabeled data.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{du20248xe} introduces SAL (Separate And Learn), a new learning framework with two main components:\n        1.  **Filtering**: Separates candidate outliers from the unlabeled wild data. This is achieved by performing Singular Value Decomposition (SVD) on a *gradient matrix* `G`. The gradients are computed for all unlabeled data points based on a classification model `h_w` trained on labeled ID data, after subtracting a reference gradient `Â¯âˆ‡`. A filtering score `Ï„_i` for each unlabeled sample `Ëœx_i` is defined as the `â„“2` norm of its projected gradient onto the top singular vector `v` of `G`. Candidate outliers `S_T` are identified as samples where `Ï„_i` exceeds a threshold `T`.\n        2.  **Classification**: Trains a binary OOD classifier `g_Î¸` using the labeled ID data and the (potentially noisy) candidate outlier set `S_T`. The training objective optimizes for separability between ID and candidate outlier data, using a binary sigmoid loss as a smooth approximation.\n    *   **Novelty**: The core innovation lies in providing *both strong theoretical guarantees and empirical effectiveness* for leveraging unlabeled data in OOD detection. The gradient-based filtering mechanism using SVD is novel for identifying candidate outliers from noisy mixtures without requiring clean auxiliary OOD data. The paper offers a formal theoretical justification for the separability and learnability aspects of its approach.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: The SAL framework itself, with its two-stage \"Separate And Learn\" approach, and the specific gradient-based filtering score `Ï„_i` derived from SVD of the gradient matrix `G`.\n    *   **Theoretical Insights/Analysis**:\n        *   **Theorem 1**: Provides rigorous error bounds for the filtering procedure (ERR_in and ERR_out), quantifying the separability of outliers from unlabeled wild data. It shows that under mild conditions and sufficient data, these error rates can be bounded by small values related to the optimal ID risk.\n        *   **Theorem 2**: Demonstrates that the main error term `Î´(T)` from Theorem 1 can be driven close to zero under practical conditions, such as sufficient discrepancy between the wild and ID data distributions.\n        *   **Theorem 3**: Establishes a generalization error bound for the learned OOD classifier `g_Î¸`, quantifying its learnability on ID data and the noisy set of candidate outliers.\n        *   Collectively, these theorems formally justify how unlabeled data *provably* helps OOD detection, a significant theoretical advancement.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: \\cite{du20248xe} extensively evaluates SAL on common OOD detection tasks, including comparisons with methods trained solely on ID data and those using unlabeled data. Synthetic simulations are also used to visually demonstrate the filtering effectiveness.\n    *   **Key Performance Metrics**: The primary metric used is FPR95 (False Positive Rate at 95% True Positive Rate).\n    *   **Comparison Results**:\n        *   SAL achieves state-of-the-art performance on common benchmarks.\n        *   On CIFAR-100, SAL outperforms KNN+ \\cite{sun2022knn} (a strong baseline using only ID data) by 44.52% (FPR95) on average.\n        *   Compared to WOODS \\cite{katz-samuels2022learning} (a closely related baseline), SAL reduces FPR95 from 7.80% to 1.88% on CIFAR-100, demonstrating \"near-perfect results.\"\n        *   Crucially, these strong empirical results are achieved *without* assuming a clean set of auxiliary unlabeled data, unlike some prior methods.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The theoretical guarantees rely on \"mild conditions,\" including smoothness of the loss function, specific discrepancy properties of the wild data distribution, and sufficiently large labeled ID and unlabeled data sizes. The framework assumes a Huber contamination model for the wild data. The filtering threshold `T` needs to be chosen, typically based on ID data performance.\n    *   **Scope of Applicability**: The SAL framework is broadly applicable to non-convex models, including modern neural networks.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{du20248xe} significantly advances the technical state-of-the-art by providing the first framework that offers *provable guarantees* for leveraging unlabeled data in OOD detection, addressing a critical theoretical gap. It also delivers empirically superior performance.\n    *   **Potential Impact on Future Research**: This work establishes a formal foundation for understanding the role of unlabeled data in OOD detection. It opens new avenues for developing theoretically grounded OOD methods, especially in realistic scenarios where unlabeled \"wild\" data is noisy and heterogeneous. The framework's ability to improve OOD awareness without clean auxiliary data has direct implications for enhancing the safety and reliability of machine learning models in real-world deployments.",
      "intriguing_abstract": "The brittleness of neural networks to Out-of-Distribution (OOD) data poses a critical challenge for reliable AI, yet harnessing abundant unlabeled \"wild\" data for OOD detection remains largely unproven. We introduce SAL (Separate And Learn), a novel framework that offers the *first rigorous theoretical guarantees* for effectively leveraging noisy, heterogeneous unlabeled data to enhance OOD awareness.\n\nSAL innovatively tackles the Huber contamination problem by employing Singular Value Decomposition (SVD) on a *gradient matrix* to provably filter candidate outliers from the unlabeled pool. This gradient-based separation mechanism, coupled with a robust classification stage, allows us to extract valuable OOD information where prior methods falter without clean auxiliary data. Our theoretical contributions provide tight error bounds for both the filtering process and the generalization of the learned OOD classifier, formally justifying the utility of unlabeled data.\n\nEmpirically, SAL achieves state-of-the-art performance, dramatically reducing False Positive Rate at 95% True Positive Rate (FPR95) on challenging benchmarks like CIFAR-100, outperforming strong baselines by significant margins. This work not only bridges a fundamental theoretical gap but also delivers a practical, high-impact solution for building safer, more reliable machine learning systems in real-world, data-rich environments.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "unlabeled wild data",
        "provable guarantees",
        "SAL (Separate And Learn) framework",
        "gradient-based filtering",
        "Singular Value Decomposition (SVD)",
        "Huber contamination model",
        "theoretical error bounds",
        "generalization error",
        "model safety and reliability",
        "state-of-the-art performance",
        "heterogeneous data mixtures",
        "without clean auxiliary data"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/bea84d4f28799628fa91585690088c00e8dca827.pdf",
      "citation_key": "du20248xe",
      "metadata": {
        "title": "How Does Unlabeled Data Provably Help Out-of-Distribution Detection?",
        "authors": [
          "Xuefeng Du",
          "Zhen Fang",
          "Ilias Diakonikolas",
          "Yixuan Li"
        ],
        "published_date": "2024",
        "abstract": "Using unlabeled data to regularize the machine learning models has demonstrated promise for improving safety and reliability in detecting out-of-distribution (OOD) data. Harnessing the power of unlabeled in-the-wild data is non-trivial due to the heterogeneity of both in-distribution (ID) and OOD data. This lack of a clean set of OOD samples poses significant challenges in learning an optimal OOD classifier. Currently, there is a lack of research on formally understanding how unlabeled data helps OOD detection. This paper bridges the gap by introducing a new learning framework SAL (Separate And Learn) that offers both strong theoretical guarantees and empirical effectiveness. The framework separates candidate outliers from the unlabeled data and then trains an OOD classifier using the candidate outliers and the labeled ID data. Theoretically, we provide rigorous error bounds from the lens of separability and learnability, formally justifying the two components in our algorithm. Our theory shows that SAL can separate the candidate outliers with small error rates, which leads to a generalization guarantee for the learned OOD classifier. Empirically, SAL achieves state-of-the-art performance on common benchmarks, reinforcing our theoretical insights. Code is publicly available at https://github.com/deeplearning-wisc/sal.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/bea84d4f28799628fa91585690088c00e8dca827.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 31,
        "score": 31.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, particularly how to effectively and *provably* leverage unlabeled \"wild\" data to improve model safety and reliability.\n    *   **Importance & Challenge**: Neural networks are known to be brittle and lack awareness of OOD data. Identifying OOD inputs is crucial but difficult because models are not explicitly trained on unknown distributions. The key challenge with unlabeled wild data is its heterogeneous mixture of In-Distribution (ID) and OOD samples (modeled as a Huber contamination model), making it non-trivial to extract useful OOD information without clean OOD labels. A formal understanding of how unlabeled data helps OOD detection has been lacking.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds on the idea of using unlabeled data for regularization in OOD detection, similar to approaches like Katz-Samuels et al. (2022).\n    *   **Limitations of Previous Solutions**: Existing methods often lack formal theoretical guarantees on how unlabeled data aids OOD detection. Some approaches, like Outlier Exposure \\cite{hendrycks2019deep}, require a *clean* set of auxiliary unlabeled data, an assumption that \\cite{du20248xe} explicitly avoids, offering greater flexibility. The paper positions itself by bridging the gap in formally understanding and provably justifying the use of unlabeled data.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{du20248xe} introduces SAL (Separate And Learn), a new learning framework with two main components:\n        1.  **Filtering**: Separates candidate outliers from the unlabeled wild data. This is achieved by performing Singular Value Decomposition (SVD) on a *gradient matrix* `G`. The gradients are computed for all unlabeled data points based on a classification model `h_w` trained on labeled ID data, after subtracting a reference gradient `Â¯âˆ‡`. A filtering score `Ï„_i` for each unlabeled sample `Ëœx_i` is defined as the `â„“2` norm of its projected gradient onto the top singular vector `v` of `G`. Candidate outliers `S_T` are identified as samples where `Ï„_i` exceeds a threshold `T`.\n        2.  **Classification**: Trains a binary OOD classifier `g_Î¸` using the labeled ID data and the (potentially noisy) candidate outlier set `S_T`. The training objective optimizes for separability between ID and candidate outlier data, using a binary sigmoid loss as a smooth approximation.\n    *   **Novelty**: The core innovation lies in providing *both strong theoretical guarantees and empirical effectiveness* for leveraging unlabeled data in OOD detection. The gradient-based filtering mechanism using SVD is novel for identifying candidate outliers from noisy mixtures without requiring clean auxiliary OOD data. The paper offers a formal theoretical justification for the separability and learnability aspects of its approach.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: The SAL framework itself, with its two-stage \"Separate And Learn\" approach, and the specific gradient-based filtering score `Ï„_i` derived from SVD of the gradient matrix `G`.\n    *   **Theoretical Insights/Analysis**:\n        *   **Theorem 1**: Provides rigorous error bounds for the filtering procedure (ERR_in and ERR_out), quantifying the separability of outliers from unlabeled wild data. It shows that under mild conditions and sufficient data, these error rates can be bounded by small values related to the optimal ID risk.\n        *   **Theorem 2**: Demonstrates that the main error term `Î´(T)` from Theorem 1 can be driven close to zero under practical conditions, such as sufficient discrepancy between the wild and ID data distributions.\n        *   **Theorem 3**: Establishes a generalization error bound for the learned OOD classifier `g_Î¸`, quantifying its learnability on ID data and the noisy set of candidate outliers.\n        *   Collectively, these theorems formally justify how unlabeled data *provably* helps OOD detection, a significant theoretical advancement.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: \\cite{du20248xe} extensively evaluates SAL on common OOD detection tasks, including comparisons with methods trained solely on ID data and those using unlabeled data. Synthetic simulations are also used to visually demonstrate the filtering effectiveness.\n    *   **Key Performance Metrics**: The primary metric used is FPR95 (False Positive Rate at 95% True Positive Rate).\n    *   **Comparison Results**:\n        *   SAL achieves state-of-the-art performance on common benchmarks.\n        *   On CIFAR-100, SAL outperforms KNN+ \\cite{sun2022knn} (a strong baseline using only ID data) by 44.52% (FPR95) on average.\n        *   Compared to WOODS \\cite{katz-samuels2022learning} (a closely related baseline), SAL reduces FPR95 from 7.80% to 1.88% on CIFAR-100, demonstrating \"near-perfect results.\"\n        *   Crucially, these strong empirical results are achieved *without* assuming a clean set of auxiliary unlabeled data, unlike some prior methods.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The theoretical guarantees rely on \"mild conditions,\" including smoothness of the loss function, specific discrepancy properties of the wild data distribution, and sufficiently large labeled ID and unlabeled data sizes. The framework assumes a Huber contamination model for the wild data. The filtering threshold `T` needs to be chosen, typically based on ID data performance.\n    *   **Scope of Applicability**: The SAL framework is broadly applicable to non-convex models, including modern neural networks.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{du20248xe} significantly advances the technical state-of-the-art by providing the first framework that offers *provable guarantees* for leveraging unlabeled data in OOD detection, addressing a critical theoretical gap. It also delivers empirically superior performance.\n    *   **Potential Impact on Future Research**: This work establishes a formal foundation for understanding the role of unlabeled data in OOD detection. It opens new avenues for developing theoretically grounded OOD methods, especially in realistic scenarios where unlabeled \"wild\" data is noisy and heterogeneous. The framework's ability to improve OOD awareness without clean auxiliary data has direct implications for enhancing the safety and reliability of machine learning models in real-world deployments.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "unlabeled wild data",
          "provable guarantees",
          "SAL (Separate And Learn) framework",
          "gradient-based filtering",
          "Singular Value Decomposition (SVD)",
          "Huber contamination model",
          "theoretical error bounds",
          "generalization error",
          "model safety and reliability",
          "state-of-the-art performance",
          "heterogeneous data mixtures",
          "without clean auxiliary data"
        ],
        "paper_type": "based on the abstract and introduction, this paper is best classified as **theoretical**.\n\nhere's why:\n\n*   **strong emphasis on \"theoretical guarantees\"**: the abstract explicitly states, \"this paper bridges the gap by introducing a new learning framework sal (separate and learn) that offers both strong theoretical guarantees and empirical effectiveness.\" this is reiterated in the introduction.\n*   **focus on \"rigorous error bounds\" and \"formal justification\"**: the abstract mentions, \"theoretically, we provide rigorous error bounds from the lens of separability and learnability, formally justifying the two components in our alg.\" the introduction further elaborates, \"our theory shows that sal can separate the candidate outliers with small error rates, which leads to a generalization guarantee for the learned ood classifier.\"\n*   **title includes \"provably\"**: the title \"how does unlabeled data **provably** help out-of-distribution detection?\" directly indicates a focus on formal proofs and theoretical understanding.\n*   **empirical results reinforce theory**: while empirical effectiveness is mentioned, it's presented as \"reinforcing our theoretical insights,\" suggesting the primary contribution is the theoretical understanding, with empirical validation supporting it.\n\nwhile the paper introduces a new framework (sal), which has a technical aspect, and includes empirical results, the core contribution and the language used to describe it overwhelmingly point to a deep dive into the mathematical analysis, formal models, and proofs behind *how* unlabeled data helps, rather than just presenting a new system or a data-driven study."
      },
      "file_name": "bea84d4f28799628fa91585690088c00e8dca827.pdf"
    },
    {
      "success": true,
      "doc_id": "707cf583e20be4f43641b324df2a065d",
      "summary": "Here's a focused summary of the paper \"Learning Transferable Negative Prompts for Out-of-Distribution Detection\" \\cite{li20245b6} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Existing prompt learning methods for Out-of-Distribution (OOD) detection suffer from a high false positive rate because their training lacks OOD images, leading to mismatches between OOD images and In-Distribution (ID) categories. Additionally, current methods assume the availability of samples for *all* ID classes during training, rendering them ineffective in open-vocabulary learning scenarios where novel ID classes appear at inference.\n    *   **Importance & Challenge:** OOD detection is critical for the reliability and safety of AI systems. Vision-Language Models (VLMs) like CLIP \\cite{li20245b6} are powerful but tend to be overconfident, often misclassifying OOD data as ID with high confidence. Developing methods that can effectively detect OOD samples without explicit OOD training data, and that can generalize to novel ID classes, is a significant challenge.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** `NegPrompt` \\cite{li20245b6} builds upon prompt learning techniques for VLMs (e.g., CoOp \\cite{li20245b6}) but specifically addresses their shortcomings in OOD detection. It is most closely related to VLM-driven OOD detection methods like CLIPN \\cite{li20245b6} and LoCoOp \\cite{li20245b6}.\n    *   **Limitations of Previous Solutions:**\n        *   **General Prompt Learning (e.g., CoOp \\cite{li20245b6}):** While enhancing VLM perception for target datasets, these methods struggle with unknown OOD samples during inference.\n        *   **CLIPN \\cite{li20245b6}:** Trains an additional 'no' text encoder using a large-scale auxiliary dataset, making it computationally expensive and increasing network parameters, deviating from the lightweight nature of prompt learning.\n        *   **LoCoOp \\cite{li20245b6}:** Utilizes ID training data to capture local features, which can compromise the global perception capability of CLIP and reduce ID classification accuracy. It also lacks explicit knowledge about OOD samples, leading to high detection errors for boundary ID/OOD images.\n        *   **Zero-shot methods (e.g., MCM \\cite{li20245b6}, ZOC \\cite{li20245b6}):** Lack adaptation to the target dataset, often misidentifying unusual ID images as OOD.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** `NegPrompt` \\cite{li20245b6} introduces a novel OOD detection method that learns a set of \"negative prompts\" for each ID class. Each negative prompt represents a negative connotation or characteristics contrary to a given ID class label. The method aims to delineate boundaries between ID and OOD images by making OOD samples exhibit higher similarity to these negative prompts than to the positive prompts (standard class embeddings).\n    *   **Novelty/Difference:**\n        *   **ID-only Training:** `NegPrompt` \\cite{li20245b6} learns these negative prompts using *only* ID training data and their corresponding positive prompts (e.g., from CoOp \\cite{li20245b6}), eliminating the need for any external outlier data or additional encoders.\n        *   **Transferable Negative Prompts:** The learned negative prompts are designed to be transferable to novel class labels. This enables open-vocabulary OOD detection, where the model can detect OOD samples even for ID classes not present during training, by simply replacing the `[class name]` in the prompts.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm/Method:** Proposes `NegPrompt` \\cite{li20245b6}, a prompt learning-based OOD detection approach that learns negative semantics relative to specific ID classes, thereby enhancing VLMs' sensitivity to unknown samples.\n    *   **System Design/Architectural Innovations:** It is a lightweight method that does not require training extra encoders on external data, unlike related methods such as CLIPN \\cite{li20245b6}.\n    *   **Theoretical Insights/Analysis:** Introduces the concept of learning \"negative connotations\" for ID classes to implicitly define OOD boundaries, leveraging the generalization ability of pre-trained VLMs.\n    *   **Open-Vocabulary Capability:** `NegPrompt` \\cite{li20245b6} possesses an open-vocabulary capability due to the transferability of its negative prompts. This allows OOD detection on test data with all ID classes (including novel ones) by training with images from only a small subset of ID classes and using the class names of all IDs. This is a novel capability for fine-tuning OOD detection methods.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were conducted on various ImageNet-based benchmarks. The method was evaluated in both conventional (closed-vocabulary) and hard OOD detection settings, as well as open-vocabulary classification scenarios.\n    *   **Key Performance Metrics & Comparison Results:** `NegPrompt` \\cite{li20245b6} consistently outperforms current state-of-the-art prompt-learning-based OOD detection methods. It maintains a consistent lead, particularly in hard OOD detection and open-vocabulary classification scenarios.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The method relies on the strong generalization ability of pre-trained VLMs like CLIP \\cite{li20245b6} and the effectiveness of existing positive prompt learning methods (e.g., CoOp \\cite{li20245b6}) to provide initial positive prompts. The snippet does not explicitly state limitations of `NegPrompt` itself, but rather highlights how it overcomes limitations of prior work.\n    *   **Scope of Applicability:** `NegPrompt` \\cite{li20245b6} is designed for OOD detection in image classification tasks, particularly leveraging VLMs. It is applicable in scenarios with limited ID training data (e.g., 16 samples per class) and excels in open-vocabulary settings where only a subset of ID classes are available during training.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** `NegPrompt` \\cite{li20245b6} significantly advances the technical state-of-the-art in VLM-driven OOD detection by providing a more effective, lightweight, and data-efficient solution. Its superior performance in hard OOD and open-vocabulary settings addresses critical challenges in the field.\n    *   **Potential Impact on Future Research:** The concept of learning transferable \"negative prompts\" using only ID data opens new avenues for research in OOD detection, anomaly detection, and robust machine learning, especially in resource-constrained or dynamic environments. It demonstrates a powerful way to leverage the semantic understanding of VLMs for safety-critical applications without requiring explicit OOD examples.",
      "intriguing_abstract": "Vision-Language Models (VLMs) like CLIP are powerful, yet their inherent overconfidence poses a critical challenge for reliable Out-of-Distribution (OOD) detection, often leading to high false positive rates and misclassification of unknown data. Current prompt learning methods for OOD detection typically lack explicit OOD knowledge or require extensive auxiliary data, hindering their efficiency and open-vocabulary capabilities, especially when encountering novel in-distribution (ID) classes.\n\nWe introduce `NegPrompt`, a novel prompt learning approach that revolutionizes OOD detection by learning *transferable negative prompts* for each ID class. Unlike prior methods, `NegPrompt` achieves robust OOD detection using *only* ID training data, eliminating the need for any external outlier samples or additional network parameters. These negative prompts effectively delineate OOD boundaries, making unknown samples exhibit higher similarity to negative connotations than to positive class embeddings. This innovative design enables unprecedented open-vocabulary OOD detection, allowing generalization to entirely novel ID classes at inference. Extensive experiments demonstrate `NegPrompt` consistently outperforms state-of-the-art VLM-driven OOD methods, particularly in challenging hard OOD and open-vocabulary scenarios. Our lightweight, data-efficient method significantly enhances the safety and reliability of AI systems, paving the way for more robust and adaptable VLM applications.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "prompt learning",
        "Vision-Language Models (VLMs)",
        "NegPrompt",
        "negative prompts",
        "transferable negative prompts",
        "open-vocabulary OOD detection",
        "ID-only training",
        "false positive rate reduction",
        "lightweight OOD detection",
        "AI systems reliability",
        "hard OOD detection",
        "semantic understanding of VLMs"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/531762d327ac99a898f4976181c1c69e2e3076cb.pdf",
      "citation_key": "li20245b6",
      "metadata": {
        "title": "Learning Transferable Negative Prompts for Out-of-Distribution Detection",
        "authors": [
          "Tianqi Li",
          "Guansong Pang",
          "Xiaolong Bai",
          "Wenjun Miao",
          "Jingyi Zheng"
        ],
        "published_date": "2024",
        "abstract": "Existing prompt learning methods have shown certain capabilities in Out-of-Distribution (OOD) detection, but the lack of OOD images in the target dataset in their training can lead to mismatches between OOD images and In-Distribution (ID) categories, resulting in a high false positive rate. To address this issue, we introduce a novel OOD detection method, named â€˜NegPromptâ€™, to learn a set of negative prompts, each representing a negative connotation of a given class label, for delineating the boundaries between ID and OOD images. It learns such negative prompts with ID data only, without any reliance on external out-lier data. Further, current methods assume the availability of samples of all ID classes, rendering them ineffective in open-vocabulary learning scenarios where the inference stage can contain novel ID classes not present during training. In contrast, our learned negative prompts are transferable to novel class labels. Experiments on various ImageNet benchmarks show that NegPrompt surpasses state-of-the-art prompt-learning-based OOD detection methods and maintains a consistent lead in hard OOD detection in closed- and open-vocabulary classification scenarios. Code is available at https://github.com/mala-lab/negprompt.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/531762d327ac99a898f4976181c1c69e2e3076cb.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 30,
        "score": 30.0,
        "summary": "Here's a focused summary of the paper \"Learning Transferable Negative Prompts for Out-of-Distribution Detection\" \\cite{li20245b6} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Existing prompt learning methods for Out-of-Distribution (OOD) detection suffer from a high false positive rate because their training lacks OOD images, leading to mismatches between OOD images and In-Distribution (ID) categories. Additionally, current methods assume the availability of samples for *all* ID classes during training, rendering them ineffective in open-vocabulary learning scenarios where novel ID classes appear at inference.\n    *   **Importance & Challenge:** OOD detection is critical for the reliability and safety of AI systems. Vision-Language Models (VLMs) like CLIP \\cite{li20245b6} are powerful but tend to be overconfident, often misclassifying OOD data as ID with high confidence. Developing methods that can effectively detect OOD samples without explicit OOD training data, and that can generalize to novel ID classes, is a significant challenge.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** `NegPrompt` \\cite{li20245b6} builds upon prompt learning techniques for VLMs (e.g., CoOp \\cite{li20245b6}) but specifically addresses their shortcomings in OOD detection. It is most closely related to VLM-driven OOD detection methods like CLIPN \\cite{li20245b6} and LoCoOp \\cite{li20245b6}.\n    *   **Limitations of Previous Solutions:**\n        *   **General Prompt Learning (e.g., CoOp \\cite{li20245b6}):** While enhancing VLM perception for target datasets, these methods struggle with unknown OOD samples during inference.\n        *   **CLIPN \\cite{li20245b6}:** Trains an additional 'no' text encoder using a large-scale auxiliary dataset, making it computationally expensive and increasing network parameters, deviating from the lightweight nature of prompt learning.\n        *   **LoCoOp \\cite{li20245b6}:** Utilizes ID training data to capture local features, which can compromise the global perception capability of CLIP and reduce ID classification accuracy. It also lacks explicit knowledge about OOD samples, leading to high detection errors for boundary ID/OOD images.\n        *   **Zero-shot methods (e.g., MCM \\cite{li20245b6}, ZOC \\cite{li20245b6}):** Lack adaptation to the target dataset, often misidentifying unusual ID images as OOD.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** `NegPrompt` \\cite{li20245b6} introduces a novel OOD detection method that learns a set of \"negative prompts\" for each ID class. Each negative prompt represents a negative connotation or characteristics contrary to a given ID class label. The method aims to delineate boundaries between ID and OOD images by making OOD samples exhibit higher similarity to these negative prompts than to the positive prompts (standard class embeddings).\n    *   **Novelty/Difference:**\n        *   **ID-only Training:** `NegPrompt` \\cite{li20245b6} learns these negative prompts using *only* ID training data and their corresponding positive prompts (e.g., from CoOp \\cite{li20245b6}), eliminating the need for any external outlier data or additional encoders.\n        *   **Transferable Negative Prompts:** The learned negative prompts are designed to be transferable to novel class labels. This enables open-vocabulary OOD detection, where the model can detect OOD samples even for ID classes not present during training, by simply replacing the `[class name]` in the prompts.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm/Method:** Proposes `NegPrompt` \\cite{li20245b6}, a prompt learning-based OOD detection approach that learns negative semantics relative to specific ID classes, thereby enhancing VLMs' sensitivity to unknown samples.\n    *   **System Design/Architectural Innovations:** It is a lightweight method that does not require training extra encoders on external data, unlike related methods such as CLIPN \\cite{li20245b6}.\n    *   **Theoretical Insights/Analysis:** Introduces the concept of learning \"negative connotations\" for ID classes to implicitly define OOD boundaries, leveraging the generalization ability of pre-trained VLMs.\n    *   **Open-Vocabulary Capability:** `NegPrompt` \\cite{li20245b6} possesses an open-vocabulary capability due to the transferability of its negative prompts. This allows OOD detection on test data with all ID classes (including novel ones) by training with images from only a small subset of ID classes and using the class names of all IDs. This is a novel capability for fine-tuning OOD detection methods.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were conducted on various ImageNet-based benchmarks. The method was evaluated in both conventional (closed-vocabulary) and hard OOD detection settings, as well as open-vocabulary classification scenarios.\n    *   **Key Performance Metrics & Comparison Results:** `NegPrompt` \\cite{li20245b6} consistently outperforms current state-of-the-art prompt-learning-based OOD detection methods. It maintains a consistent lead, particularly in hard OOD detection and open-vocabulary classification scenarios.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The method relies on the strong generalization ability of pre-trained VLMs like CLIP \\cite{li20245b6} and the effectiveness of existing positive prompt learning methods (e.g., CoOp \\cite{li20245b6}) to provide initial positive prompts. The snippet does not explicitly state limitations of `NegPrompt` itself, but rather highlights how it overcomes limitations of prior work.\n    *   **Scope of Applicability:** `NegPrompt` \\cite{li20245b6} is designed for OOD detection in image classification tasks, particularly leveraging VLMs. It is applicable in scenarios with limited ID training data (e.g., 16 samples per class) and excels in open-vocabulary settings where only a subset of ID classes are available during training.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** `NegPrompt` \\cite{li20245b6} significantly advances the technical state-of-the-art in VLM-driven OOD detection by providing a more effective, lightweight, and data-efficient solution. Its superior performance in hard OOD and open-vocabulary settings addresses critical challenges in the field.\n    *   **Potential Impact on Future Research:** The concept of learning transferable \"negative prompts\" using only ID data opens new avenues for research in OOD detection, anomaly detection, and robust machine learning, especially in resource-constrained or dynamic environments. It demonstrates a powerful way to leverage the semantic understanding of VLMs for safety-critical applications without requiring explicit OOD examples.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "prompt learning",
          "Vision-Language Models (VLMs)",
          "NegPrompt",
          "negative prompts",
          "transferable negative prompts",
          "open-vocabulary OOD detection",
          "ID-only training",
          "false positive rate reduction",
          "lightweight OOD detection",
          "AI systems reliability",
          "hard OOD detection",
          "semantic understanding of VLMs"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\n**reasoning:**\n\n*   **abstract:** explicitly states, \"we introduce a novel ood detection method, named â€˜negpromptâ€™,\" and describes its mechanism (\"to learn a set of negative prompts\"). it highlights the problem with existing methods and how the proposed method addresses it. while it mentions \"experiments... show that negprompt surpasses state-of-the-art,\" this empirical evaluation is presented as validation for the *new method* being proposed.\n*   **introduction:** sets the stage by discussing the evolution of image recognition models and the capabilities of vlms, leading up to the problem that the new method will solve.\n*   **keywords match:** the abstract heavily uses keywords associated with \"technical\" papers: \"introduce,\" \"novel method,\" \"learn,\" \"algorithm\" (implied by method description). the empirical results serve to demonstrate the effectiveness of this new technical contribution."
      },
      "file_name": "531762d327ac99a898f4976181c1c69e2e3076cb.pdf"
    },
    {
      "success": true,
      "doc_id": "1ea4f4e6340d6ebaf0d79d3a632546a7",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/5ad0eb12bedd86b88181cea5a9669d2a8e39cda1.pdf",
      "citation_key": "fang20248g5",
      "metadata": {
        "title": "Your data is not perfect: Towards cross-domain out-of-distribution detection in class-imbalanced data",
        "authors": [
          "Xiang Fang",
          "A. Easwaran",
          "B. Genest",
          "P. Suganthan"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/5ad0eb12bedd86b88181cea5a9669d2a8e39cda1.pdf",
        "venue": "Expert systems with applications",
        "citationCount": 28,
        "score": 28.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "5ad0eb12bedd86b88181cea5a9669d2a8e39cda1.pdf"
    },
    {
      "success": true,
      "doc_id": "6b7af5cf2cf0c1d3f7cdf2ff7f529e39",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/89b2a10540611860c4f48f5e6b412b8a17dfb036.pdf",
      "citation_key": "linmans2024pi9",
      "metadata": {
        "title": "Diffusion models for out-of-distribution detection in digital pathology",
        "authors": [
          "J. Linmans",
          "Gabriel Raya",
          "J. Laak",
          "G. Litjens"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/89b2a10540611860c4f48f5e6b412b8a17dfb036.pdf",
        "venue": "Medical Image Anal.",
        "citationCount": 27,
        "score": 27.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "89b2a10540611860c4f48f5e6b412b8a17dfb036.pdf"
    },
    {
      "success": true,
      "doc_id": "1571a14e190c5083e930eeead8658a44",
      "summary": "Advancements in AI have elevated speech recognition, with convolutional neural networks (CNNs) proving effective in processing spectrogram-transformed speech signals. CNNs, with lower parameters and higher accuracy compared to traditional models, are particularly efficient for deployment on storage-limited embedded devices. Artificial neural networks excel in predicting inputs within their expected output range but struggle with anomalies. This is usually harmful to a speech recognition system. In this paper, the neural network classifier for speech recognition is trained with a â€œnegative branchâ€ method, incorporating directional regularization with out-of-distribution training data, allowing it to maintain a high confidence score to the input within distribution while expressing a low confidence score to the anomaly input. It can enhance the performance of anomaly detection of the classifier, addressing issues like misclassifying the speech command that is out of the distribution. The result of the experiment suggests that the accuracy of the CNN model will not be affected by the regularization of the â€œnegative branchâ€, and the performance of abnormal detection will be improved as the number of kernels of the convolutional layer increases.",
      "intriguing_abstract": "Advancements in AI have elevated speech recognition, with convolutional neural networks (CNNs) proving effective in processing spectrogram-transformed speech signals. CNNs, with lower parameters and higher accuracy compared to traditional models, are particularly efficient for deployment on storage-limited embedded devices. Artificial neural networks excel in predicting inputs within their expected output range but struggle with anomalies. This is usually harmful to a speech recognition system. In this paper, the neural network classifier for speech recognition is trained with a â€œnegative branchâ€ method, incorporating directional regularization with out-of-distribution training data, allowing it to maintain a high confidence score to the input within distribution while expressing a low confidence score to the anomaly input. It can enhance the performance of anomaly detection of the classifier, addressing issues like misclassifying the speech command that is out of the distribution. The result of the experiment suggests that the accuracy of the CNN model will not be affected by the regularization of the â€œnegative branchâ€, and the performance of abnormal detection will be improved as the number of kernels of the convolutional layer increases.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/67dabdc0b1250d43641ea79869554741431c4b76.pdf",
      "citation_key": "chen20243na",
      "metadata": {
        "title": "A Novel Single-Word Speech Recognition on Embedded Systems Using a Convolution Neuron Network with Improved Out-of-Distribution Detection",
        "authors": [
          "Jiaqi Chen",
          "T. H. Teo",
          "C. Kok",
          "Yit Yan Koh"
        ],
        "published_date": "2024",
        "abstract": "Advancements in AI have elevated speech recognition, with convolutional neural networks (CNNs) proving effective in processing spectrogram-transformed speech signals. CNNs, with lower parameters and higher accuracy compared to traditional models, are particularly efficient for deployment on storage-limited embedded devices. Artificial neural networks excel in predicting inputs within their expected output range but struggle with anomalies. This is usually harmful to a speech recognition system. In this paper, the neural network classifier for speech recognition is trained with a â€œnegative branchâ€ method, incorporating directional regularization with out-of-distribution training data, allowing it to maintain a high confidence score to the input within distribution while expressing a low confidence score to the anomaly input. It can enhance the performance of anomaly detection of the classifier, addressing issues like misclassifying the speech command that is out of the distribution. The result of the experiment suggests that the accuracy of the CNN model will not be affected by the regularization of the â€œnegative branchâ€, and the performance of abnormal detection will be improved as the number of kernels of the convolutional layer increases.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/67dabdc0b1250d43641ea79869554741431c4b76.pdf",
        "venue": "Electronics",
        "citationCount": 23,
        "score": 23.0,
        "summary": "Advancements in AI have elevated speech recognition, with convolutional neural networks (CNNs) proving effective in processing spectrogram-transformed speech signals. CNNs, with lower parameters and higher accuracy compared to traditional models, are particularly efficient for deployment on storage-limited embedded devices. Artificial neural networks excel in predicting inputs within their expected output range but struggle with anomalies. This is usually harmful to a speech recognition system. In this paper, the neural network classifier for speech recognition is trained with a â€œnegative branchâ€ method, incorporating directional regularization with out-of-distribution training data, allowing it to maintain a high confidence score to the input within distribution while expressing a low confidence score to the anomaly input. It can enhance the performance of anomaly detection of the classifier, addressing issues like misclassifying the speech command that is out of the distribution. The result of the experiment suggests that the accuracy of the CNN model will not be affected by the regularization of the â€œnegative branchâ€, and the performance of abnormal detection will be improved as the number of kernels of the convolutional layer increases.",
        "keywords": []
      },
      "file_name": "67dabdc0b1250d43641ea79869554741431c4b76.pdf"
    },
    {
      "success": true,
      "doc_id": "33e7f9fbc3543d7566fe7cadce8c7adb",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing Out-of-Distribution (OOD) detection research predominantly focuses on unimodal scenarios, primarily image data. However, real-world safety-critical applications (e.g., autonomous driving, robot-assisted surgery) are inherently multimodal, and current methods fail to effectively leverage complementary information from multiple modalities to enhance OOD detection efficacy \\cite{dong2024a8k}.\n    *   **Importance and Challenge**: OOD detection is crucial for deploying machine learning models robustly and safely in open-world scenarios. The lack of dedicated multimodal OOD benchmarks and algorithms tailored to exploit inter-modal interactions makes it challenging to develop effective solutions for realistic applications \\cite{dong2024a8k}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous OOD detection algorithms include classification-based methods (e.g., MSP, Energy, logit normalization, outlier synthesis) and distance-based methods (e.g., Mahalanobis), as well as density estimation and reconstruction techniques \\cite{dong2024a8k}.\n    *   **Limitations of Previous Solutions**: These methods are primarily designed for unimodal settings. While some recent works explore vision-language models, their evaluations are still limited to image-only benchmarks, thus not fully leveraging diverse modalities like LiDAR, camera, video, audio, and optical flow. Simple fusion of modalities shows improvement, but dedicated algorithms are needed to account for their interaction and complementary nature \\cite{dong2024a8k}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**:\n        *   **MultiOOD Benchmark**: Introduction of the first-of-its-kind benchmark for Multimodal OOD Detection, comprising five video datasets with diverse sizes (3k to 57k clips) and varying modality combinations (video, optical flow, audio) \\cite{dong2024a8k}. It includes both Near-OOD (semantic shifts within the same domain) and Far-OOD (semantic and domain shifts) setups.\n        *   **Modality Prediction Discrepancy (MPD)**: Identification and illustration of a phenomenon where softmax predictions across different modalities show negligible discrepancies for in-distribution (ID) data but significant variability for OOD data. This discrepancy is strongly correlated with OOD detection performance \\cite{dong2024a8k}.\n        *   **Agree-to-Disagree (A2D) Algorithm**: A novel training algorithm motivated by MPD. A2D encourages different modalities to \"Agree\" on the prediction of the ground-truth class while simultaneously \"Disagreeing\" on other classes by maximizing the distance (e.g., Hellinger distance) between their predictions \\cite{dong2024a8k}.\n        *   **Nearest Neighbor Prototype-based Mixup (NP-Mix)**: A novel outlier synthesis method that complements A2D. It generates outliers by leveraging information from nearest neighbor classes, exploring broader feature spaces compared to existing outlier synthesis techniques which typically generate outliers near ID data \\cite{dong2024a8k}.\n    *   **Novelty/Difference**: The paper introduces the first dedicated benchmark for multimodal OOD detection. The A2D algorithm is novel in its approach to explicitly amplify inter-modal prediction discrepancies for OOD data during training. NP-Mix innovates outlier synthesis by exploring wider feature spaces through nearest neighbor prototypes \\cite{dong2024a8k}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Benchmark**: `MultiOOD`, the first benchmark for Multimodal OOD Detection, featuring diverse datasets and modality combinations (video, optical flow, audio) for both Near-OOD and Far-OOD scenarios \\cite{dong2024a8k}.\n    *   **Theoretical Insight**: Identification and empirical validation of the `Modality Prediction Discrepancy` phenomenon and its strong correlation with OOD detection performance \\cite{dong2024a8k}.\n    *   **Novel Algorithm**: `Agree-to-Disagree (A2D)` training algorithm, designed to enhance multimodal prediction discrepancies for OOD data by encouraging agreement on ground-truth and disagreement on other classes \\cite{dong2024a8k}.\n    *   **Novel Technique**: `Nearest Neighbor Prototype-based Mixup (NP-Mix)`, an outlier synthesis method that generates outliers in broader feature spaces by utilizing nearest neighbor class prototypes \\cite{dong2024a8k}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: Comprehensive evaluations of existing unimodal OOD algorithms on the `MultiOOD` benchmark, followed by extensive experiments demonstrating the superiority of `A2D` and `NP-Mix` \\cite{dong2024a8k}.\n    *   **Key Performance Metrics**: FPR95 (False Positive Rate at 95% True Positive Rate, lower is better), AUROC (Area Under the Receiver Operating Characteristic curve, higher is better), and ID ACC (In-Distribution Accuracy) \\cite{dong2024a8k}.\n    *   **Comparison Results**:\n        *   Even simple fusion of modalities (e.g., video and optical flow) substantially improves OOD detection performance over unimodal baselines, highlighting the importance of multimodal information \\cite{dong2024a8k}.\n        *   Training with `A2D` and `NP-Mix` yields considerable performance enhancements over existing unimodal OOD detection algorithms. For instance, on the UCF101 dataset, the approach reduced FPR95 for the ASH method from 32.14% to 10.68%, an absolute improvement of 21.46% \\cite{dong2024a8k}.\n        *   `A2D` training successfully amplifies the Modality Prediction Discrepancy, which is shown to be highly correlated with improved OOD performance \\cite{dong2024a8k}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations**: The paper primarily focuses on the benefits of the proposed methods. While it highlights the limitations of existing unimodal methods in multimodal settings, it does not explicitly detail specific technical limitations or assumptions of `A2D` or `NP-Mix` beyond their design choices.\n    *   **Scope of Applicability**: The `MultiOOD` benchmark and experiments are focused on action recognition tasks using video, optical flow, and audio modalities. While the principles of `A2D` and `NP-Mix` could be generalized, their direct applicability and performance on other multimodal tasks (e.g., autonomous driving with LiDAR, radar, camera) or different modality types would require further investigation \\cite{dong2024a8k}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: `MultiOOD` establishes a crucial foundation for future research in Multimodal OOD Detection, shifting the research paradigm from unimodal to more realistic multimodal scenarios. The `A2D` and `NP-Mix` algorithms significantly advance the technical state-of-the-art by providing effective strategies to leverage multimodal information for robust OOD detection \\cite{dong2024a8k}.\n    *   **Potential Impact**: This work has the potential to significantly impact the deployment of machine learning models in safety-critical applications by enabling more reliable detection of unknown inputs when multiple sensor streams are available. The public release of the `MultiOOD` benchmark and source code will facilitate and accelerate future research in this vital area \\cite{dong2024a8k}.",
      "intriguing_abstract": "The robust deployment of AI in safety-critical applications like autonomous driving hinges on effective Out-of-Distribution (OOD) detection, yet current research predominantly focuses on unimodal scenarios. We address this critical gap by introducing **MultiOOD**, the first comprehensive benchmark for multimodal OOD detection, featuring diverse video, optical flow, and audio datasets for both Near- and Far-OOD challenges.\n\nOur research unveils a fundamental insight: **Modality Prediction Discrepancy (MPD)**, where in-distribution data yields consistent predictions across modalities, while OOD inputs provoke significant disagreement. Leveraging this discovery, we propose the novel **Agree-to-Disagree (A2D)** training algorithm, which explicitly amplifies inter-modal prediction discrepancies for OOD data. Complementing A2D, our **Nearest Neighbor Prototype-based Mixup (NP-Mix)** method generates more effective outliers by exploring broader feature spaces.\n\nExperiments on MultiOOD demonstrate substantial improvements, with A2D and NP-Mix significantly outperforming existing unimodal OOD detection algorithms (e.g., reducing FPR95 by over 21% on UCF101). This work establishes a new paradigm for multimodal OOD detection, paving the way for safer and more reliable machine learning systems in real-world, open-world environments. The public release of MultiOOD and our code will accelerate future research in this vital area.",
      "keywords": [
        "Multimodal Out-of-Distribution (OOD) detection",
        "MultiOOD benchmark",
        "Modality Prediction Discrepancy (MPD)",
        "Agree-to-Disagree (A2D) algorithm",
        "Nearest Neighbor Prototype-based Mixup (NP-Mix)",
        "inter-modal interactions",
        "outlier synthesis",
        "safety-critical applications",
        "Near-OOD and Far-OOD",
        "video optical flow audio modalities",
        "FPR95 AUROC"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/f9ac68dc1fdd070a65a71c739e7135361c0d3006.pdf",
      "citation_key": "dong2024a8k",
      "metadata": {
        "title": "MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities",
        "authors": [
          "Hao Dong",
          "Yue Zhao",
          "Eleni Chatzi",
          "Olga Fink"
        ],
        "published_date": "2024",
        "abstract": "Detecting out-of-distribution (OOD) samples is important for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. Existing research has mainly focused on unimodal scenarios on image data. However, real-world applications are inherently multimodal, which makes it essential to leverage information from multiple modalities to enhance the efficacy of OOD detection. To establish a foundation for more realistic Multimodal OOD Detection, we introduce the first-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes and varying modality combinations. We first evaluate existing unimodal OOD detection algorithms on MultiOOD, observing that the mere inclusion of additional modalities yields substantial improvements. This underscores the importance of utilizing multiple modalities for OOD detection. Based on the observation of Modality Prediction Discrepancy between in-distribution (ID) and OOD data, and its strong correlation with OOD performance, we propose the Agree-to-Disagree (A2D) algorithm to encourage such discrepancy during training. Moreover, we introduce a novel outlier synthesis method, NP-Mix, which explores broader feature spaces by leveraging the information from nearest neighbor classes and complements A2D to strengthen OOD detection performance. Extensive experiments on MultiOOD demonstrate that training with A2D and NP-Mix improves existing OOD detection algorithms by a large margin. Our source code and MultiOOD benchmark are available at https://github.com/donghao51/MultiOOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/f9ac68dc1fdd070a65a71c739e7135361c0d3006.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 21,
        "score": 21.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing Out-of-Distribution (OOD) detection research predominantly focuses on unimodal scenarios, primarily image data. However, real-world safety-critical applications (e.g., autonomous driving, robot-assisted surgery) are inherently multimodal, and current methods fail to effectively leverage complementary information from multiple modalities to enhance OOD detection efficacy \\cite{dong2024a8k}.\n    *   **Importance and Challenge**: OOD detection is crucial for deploying machine learning models robustly and safely in open-world scenarios. The lack of dedicated multimodal OOD benchmarks and algorithms tailored to exploit inter-modal interactions makes it challenging to develop effective solutions for realistic applications \\cite{dong2024a8k}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous OOD detection algorithms include classification-based methods (e.g., MSP, Energy, logit normalization, outlier synthesis) and distance-based methods (e.g., Mahalanobis), as well as density estimation and reconstruction techniques \\cite{dong2024a8k}.\n    *   **Limitations of Previous Solutions**: These methods are primarily designed for unimodal settings. While some recent works explore vision-language models, their evaluations are still limited to image-only benchmarks, thus not fully leveraging diverse modalities like LiDAR, camera, video, audio, and optical flow. Simple fusion of modalities shows improvement, but dedicated algorithms are needed to account for their interaction and complementary nature \\cite{dong2024a8k}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**:\n        *   **MultiOOD Benchmark**: Introduction of the first-of-its-kind benchmark for Multimodal OOD Detection, comprising five video datasets with diverse sizes (3k to 57k clips) and varying modality combinations (video, optical flow, audio) \\cite{dong2024a8k}. It includes both Near-OOD (semantic shifts within the same domain) and Far-OOD (semantic and domain shifts) setups.\n        *   **Modality Prediction Discrepancy (MPD)**: Identification and illustration of a phenomenon where softmax predictions across different modalities show negligible discrepancies for in-distribution (ID) data but significant variability for OOD data. This discrepancy is strongly correlated with OOD detection performance \\cite{dong2024a8k}.\n        *   **Agree-to-Disagree (A2D) Algorithm**: A novel training algorithm motivated by MPD. A2D encourages different modalities to \"Agree\" on the prediction of the ground-truth class while simultaneously \"Disagreeing\" on other classes by maximizing the distance (e.g., Hellinger distance) between their predictions \\cite{dong2024a8k}.\n        *   **Nearest Neighbor Prototype-based Mixup (NP-Mix)**: A novel outlier synthesis method that complements A2D. It generates outliers by leveraging information from nearest neighbor classes, exploring broader feature spaces compared to existing outlier synthesis techniques which typically generate outliers near ID data \\cite{dong2024a8k}.\n    *   **Novelty/Difference**: The paper introduces the first dedicated benchmark for multimodal OOD detection. The A2D algorithm is novel in its approach to explicitly amplify inter-modal prediction discrepancies for OOD data during training. NP-Mix innovates outlier synthesis by exploring wider feature spaces through nearest neighbor prototypes \\cite{dong2024a8k}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Benchmark**: `MultiOOD`, the first benchmark for Multimodal OOD Detection, featuring diverse datasets and modality combinations (video, optical flow, audio) for both Near-OOD and Far-OOD scenarios \\cite{dong2024a8k}.\n    *   **Theoretical Insight**: Identification and empirical validation of the `Modality Prediction Discrepancy` phenomenon and its strong correlation with OOD detection performance \\cite{dong2024a8k}.\n    *   **Novel Algorithm**: `Agree-to-Disagree (A2D)` training algorithm, designed to enhance multimodal prediction discrepancies for OOD data by encouraging agreement on ground-truth and disagreement on other classes \\cite{dong2024a8k}.\n    *   **Novel Technique**: `Nearest Neighbor Prototype-based Mixup (NP-Mix)`, an outlier synthesis method that generates outliers in broader feature spaces by utilizing nearest neighbor class prototypes \\cite{dong2024a8k}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: Comprehensive evaluations of existing unimodal OOD algorithms on the `MultiOOD` benchmark, followed by extensive experiments demonstrating the superiority of `A2D` and `NP-Mix` \\cite{dong2024a8k}.\n    *   **Key Performance Metrics**: FPR95 (False Positive Rate at 95% True Positive Rate, lower is better), AUROC (Area Under the Receiver Operating Characteristic curve, higher is better), and ID ACC (In-Distribution Accuracy) \\cite{dong2024a8k}.\n    *   **Comparison Results**:\n        *   Even simple fusion of modalities (e.g., video and optical flow) substantially improves OOD detection performance over unimodal baselines, highlighting the importance of multimodal information \\cite{dong2024a8k}.\n        *   Training with `A2D` and `NP-Mix` yields considerable performance enhancements over existing unimodal OOD detection algorithms. For instance, on the UCF101 dataset, the approach reduced FPR95 for the ASH method from 32.14% to 10.68%, an absolute improvement of 21.46% \\cite{dong2024a8k}.\n        *   `A2D` training successfully amplifies the Modality Prediction Discrepancy, which is shown to be highly correlated with improved OOD performance \\cite{dong2024a8k}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations**: The paper primarily focuses on the benefits of the proposed methods. While it highlights the limitations of existing unimodal methods in multimodal settings, it does not explicitly detail specific technical limitations or assumptions of `A2D` or `NP-Mix` beyond their design choices.\n    *   **Scope of Applicability**: The `MultiOOD` benchmark and experiments are focused on action recognition tasks using video, optical flow, and audio modalities. While the principles of `A2D` and `NP-Mix` could be generalized, their direct applicability and performance on other multimodal tasks (e.g., autonomous driving with LiDAR, radar, camera) or different modality types would require further investigation \\cite{dong2024a8k}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: `MultiOOD` establishes a crucial foundation for future research in Multimodal OOD Detection, shifting the research paradigm from unimodal to more realistic multimodal scenarios. The `A2D` and `NP-Mix` algorithms significantly advance the technical state-of-the-art by providing effective strategies to leverage multimodal information for robust OOD detection \\cite{dong2024a8k}.\n    *   **Potential Impact**: This work has the potential to significantly impact the deployment of machine learning models in safety-critical applications by enabling more reliable detection of unknown inputs when multiple sensor streams are available. The public release of the `MultiOOD` benchmark and source code will facilitate and accelerate future research in this vital area \\cite{dong2024a8k}.",
        "keywords": [
          "Multimodal Out-of-Distribution (OOD) detection",
          "MultiOOD benchmark",
          "Modality Prediction Discrepancy (MPD)",
          "Agree-to-Disagree (A2D) algorithm",
          "Nearest Neighbor Prototype-based Mixup (NP-Mix)",
          "inter-modal interactions",
          "outlier synthesis",
          "safety-critical applications",
          "Near-OOD and Far-OOD",
          "video optical flow audio modalities",
          "FPR95 AUROC"
        ],
        "paper_type": "this paper should be classified as **technical**.\n\nhere's why:\n\n1.  **new methods/algorithms:** the abstract explicitly states: \"we propose the agree-to-disagree (a2d) algorithm\" and \"we introduce a novel outlier synthesis method, np-mix\". this is a direct match for the \"technical\" criterion: \"presents new methods, algorithms, or systems.\"\n2.  **new system/benchmark:** the paper introduces \"the first-of-its-kind benchmark, multiood\". a benchmark can be considered a system or a significant technical artifact that enables further research.\n3.  **problem and proposed solution:** the introduction sets up a technical problem (multimodal ood detection gap), and the abstract details the proposed solutions (a2d, np-mix, multiood benchmark).\n4.  **empirical validation:** while the paper includes \"extensive experiments\" (an empirical aspect), these experiments are primarily to \"demonstrate that training with a2d and np-mix improves existing ood detection algorithms.\" the empirical work serves to validate the *technical contributions* (the new algorithms and benchmark), rather than being a standalone data-driven study of an existing phenomenon. many technical papers include empirical validation."
      },
      "file_name": "f9ac68dc1fdd070a65a71c739e7135361c0d3006.pdf"
    },
    {
      "success": true,
      "doc_id": "6b3cf3a581c49a59d9f7599e9a216353",
      "summary": "This paper, \"Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey\" by Miyai et al., provides a comprehensive analysis of Out-of-Distribution (OOD) detection and related fields in the context of Vision Language Models (VLMs) and Large Vision Language Models (LVLMs) \\cite{miyai20247ro}.\n\nHere's a focused summary for literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the increasing confusion and blurred boundaries between OOD detection and closely related problems (Anomaly Detection (AD), Novelty Detection (ND), Open Set Recognition (OSR), and Outlier Detection (OD)) due to the paradigm shift introduced by Vision Language Models (VLMs) like CLIP \\cite{miyai20247ro}.\n    *   **Importance and Challenge**: Detecting OOD samples is crucial for the safety and reliability of machine learning systems in real-world applications (e.g., autonomous driving). The challenge lies in the lack of a clear, unified understanding and taxonomy for these related tasks in the VLM era, hindering research direction and collaborative efforts \\cite{miyai20247ro}. Most existing ML models operate under a closed-world assumption, making OOD detection a critical open problem \\cite{miyai20247ro}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds upon and extends the previous \"generalized OOD detection framework\" proposed by Yang et al. (2024), which taxonomically categorized the five problems based on criteria like distribution shift type, ID data type, necessity of ID classification, and learning setting \\cite{miyai20247ro}.\n    *   **Limitations of Previous Solutions**: The prior framework, while providing clear definitions, did not account for the significant paradigm shift and blurring of boundaries caused by the advent of VLMs \\cite{miyai20247ro}. This left researchers confused about the optimal direction for each community in the VLM era \\cite{miyai20247ro}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper's core approach is a systematic and comprehensive survey methodology. It involves reviewing the use of VLMs across the five problem areas, tracing their development, and analyzing research activity in top venues from 2021 to April 2025 \\cite{miyai20247ro}.\n    *   **Novelty/Difference**: The primary innovation is the proposal of **Generalized OOD Detection v2** \\cite{miyai20247ro}. This new unified framework encapsulates the evolution of these fields in the VLM era, identifying which fields have become inactive or integrated, and highlighting the most demanding challenges (AD and OOD detection) \\cite{miyai20247ro}. It also features a comprehensive review of VLM-based methodologies for OOD detection and related tasks, clarifying their relationships \\cite{miyai20247ro}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Framework**: Introduction of \"Generalized OOD Detection v2,\" which analyzes the progression of AD, ND, OSR, OOD detection, and OD in the VLM era, revealing field inactivity/integration and identifying AD and OOD detection as the demanding challenges \\cite{miyai20247ro}.\n    *   **Extensive Survey**: A comprehensive review of VLM-based OOD detection and AD methods, categorizing them by training strategies and prompt usage, particularly in zero-shot and few-shot settings \\cite{miyai20247ro}. This is presented as the first comprehensive review of VLM-based OOD detection methods \\cite{miyai20247ro}.\n    *   **LVLM Era Introduction**: An early introduction to the evolution of these problems in the emerging Large Vision Language Model (LVLM) era (e.g., GPT-4V, LLaVA), summarizing definitions, findings, and future challenges \\cite{miyai20247ro}.\n    *   **Open Challenges & Future Directions**: Discussion of open challenges and future research directions, including a comparative analysis between AD and OOD fields to identify key areas for advancing VLM-based OOD detection \\cite{miyai20247ro}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: As a survey paper, the \"validation\" involves a systematic investigation of research activity. The authors comprehensively investigated papers utilizing VLMs from top venues (NeurIPS, AAAI, ICLR, CVPR, ICML, ICCV, ECCV, IJCAI, ACMMM, TPAMI, IJCV, TMLR) from 2021 to April 2025 \\cite{miyai20247ro}.\n    *   **Key Performance Metrics/Results**: The primary \"metric\" is the number of VLM-based papers published in each field (summarized in Table 1 of the paper), which objectively defines research activity \\cite{miyai20247ro}. This analysis revealed that Semantic AD/ND and OD have become largely inactive, OSR has integrated into hard OOD detection, while Sensory AD and OOD detection remain highly active research areas in the VLM era \\cite{miyai20247ro}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The survey's analysis of research activity is based on papers published in specific \"top venues\" and manually counted by examining titles and content, which might have minor subjective biases \\cite{miyai20247ro}.\n    *   **Scope of Applicability**: The survey focuses specifically on OOD detection and its closely related tasks (AD, ND, OSR, OD). It explicitly excludes tasks like open-vocabulary segmentation and referring segmentation, as their goal is to generalize to unseen classes when the class name is known, rather than detecting entirely new, unknown data \\cite{miyai20247ro}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This survey significantly advances the technical state-of-the-art by providing the first comprehensive framework (Generalized OOD Detection v2) that clarifies the definitions, problem settings, and interrelations of OOD detection and related tasks in the VLM era \\cite{miyai20247ro}. It resolves confusion caused by VLM-induced paradigm shifts \\cite{miyai20247ro}.\n    *   **Potential Impact on Future Research**: By identifying the most active and demanding challenges (AD and OOD detection) and outlining open problems and future directions, the paper serves as a valuable reference \\cite{miyai20247ro}. It is expected to foster collaborative efforts among different communities and inspire future advancements in VLM-based OOD detection and related fields, particularly in the nascent LVLM era \\cite{miyai20247ro}.",
      "intriguing_abstract": "The rapid evolution of Vision Language Models (VLMs) has profoundly reshaped machine learning, yet it has simultaneously blurred the lines in critical safety domains like Out-of-Distribution (OOD) detection. This survey unravels the growing confusion surrounding OOD detection and its closely related problemsâ€”Anomaly Detection (AD), Novelty Detection (ND), Open Set Recognition (OSR), and Outlier Detection (OD)â€”in the VLM and emerging Large Vision Language Model (LVLM) eras. We introduce **Generalized OOD Detection v2**, a novel, unified framework that systematically redefines and categorizes these tasks, accounting for the VLM-induced paradigm shift. Our comprehensive analysis, based on research activity in top venues, reveals that while some fields like Semantic AD/ND have become inactive, others like Sensory AD and OOD detection remain demanding challenges. We provide the first extensive review of VLM-based OOD and AD methodologies, clarifying their interrelationships and categorizing training strategies and prompt usage. By offering a clear taxonomy, identifying active research frontiers, and outlining future directions, this work serves as a critical guide for researchers, fostering collaborative efforts and advancing the safety and reliability of VLM-powered AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Vision Language Models (VLMs)",
        "Large Vision Language Models (LVLMs)",
        "Generalized OOD Detection v2",
        "Anomaly Detection (AD)",
        "Unified framework",
        "Research taxonomy",
        "VLM-based OOD detection methods",
        "Paradigm shift",
        "Closed-world assumption",
        "Field integration and inactivity",
        "Open challenges",
        "Safety and reliability"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/2e6813cad2e41c683277aa2d400dc2a2761309a2.pdf",
      "citation_key": "miyai20247ro",
      "metadata": {
        "title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey",
        "authors": [
          "Atsuyuki Miyai",
          "Jingkang Yang",
          "Jingyang Zhang",
          "Yifei Ming",
          "Yueqian Lin",
          "Qing Yu",
          "Go Irie",
          "Shafiq R. Joty",
          "Yixuan Li",
          "Hai Li",
          "Ziwei Liu",
          "T. Yamasaki",
          "Kiyoharu Aizawa"
        ],
        "published_date": "2024",
        "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety of machine learning systems and has shaped the field of OOD detection. Meanwhile, several other problems are closely related to OOD detection, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD). To unify these problems, a generalized OOD detection framework was proposed, taxonomically categorizing these five problems. However, Vision Language Models (VLMs) such as CLIP have significantly changed the paradigm and blurred the boundaries between these fields, again confusing researchers. In this survey, we first present a generalized OOD detection v2, encapsulating the evolution of these fields in the VLM era. Our framework reveals that, with some field inactivity and integration, the demanding challenges have become OOD detection and AD. Then, we highlight the significant shift in the definition, problem settings, and benchmarks; we thus feature a comprehensive review of the methodology for OOD detection and related tasks to clarify their relationship to OOD detection. Finally, we explore the advancements in the emerging Large Vision Language Model (LVLM) era, such as GPT-4V. We conclude with open challenges and future directions. The resource is available at https://github.com/AtsuMiyai/Awesome-OOD-VLM.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/2e6813cad2e41c683277aa2d400dc2a2761309a2.pdf",
        "venue": "Trans. Mach. Learn. Res.",
        "citationCount": 20,
        "score": 20.0,
        "summary": "This paper, \"Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey\" by Miyai et al., provides a comprehensive analysis of Out-of-Distribution (OOD) detection and related fields in the context of Vision Language Models (VLMs) and Large Vision Language Models (LVLMs) \\cite{miyai20247ro}.\n\nHere's a focused summary for literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the increasing confusion and blurred boundaries between OOD detection and closely related problems (Anomaly Detection (AD), Novelty Detection (ND), Open Set Recognition (OSR), and Outlier Detection (OD)) due to the paradigm shift introduced by Vision Language Models (VLMs) like CLIP \\cite{miyai20247ro}.\n    *   **Importance and Challenge**: Detecting OOD samples is crucial for the safety and reliability of machine learning systems in real-world applications (e.g., autonomous driving). The challenge lies in the lack of a clear, unified understanding and taxonomy for these related tasks in the VLM era, hindering research direction and collaborative efforts \\cite{miyai20247ro}. Most existing ML models operate under a closed-world assumption, making OOD detection a critical open problem \\cite{miyai20247ro}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds upon and extends the previous \"generalized OOD detection framework\" proposed by Yang et al. (2024), which taxonomically categorized the five problems based on criteria like distribution shift type, ID data type, necessity of ID classification, and learning setting \\cite{miyai20247ro}.\n    *   **Limitations of Previous Solutions**: The prior framework, while providing clear definitions, did not account for the significant paradigm shift and blurring of boundaries caused by the advent of VLMs \\cite{miyai20247ro}. This left researchers confused about the optimal direction for each community in the VLM era \\cite{miyai20247ro}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper's core approach is a systematic and comprehensive survey methodology. It involves reviewing the use of VLMs across the five problem areas, tracing their development, and analyzing research activity in top venues from 2021 to April 2025 \\cite{miyai20247ro}.\n    *   **Novelty/Difference**: The primary innovation is the proposal of **Generalized OOD Detection v2** \\cite{miyai20247ro}. This new unified framework encapsulates the evolution of these fields in the VLM era, identifying which fields have become inactive or integrated, and highlighting the most demanding challenges (AD and OOD detection) \\cite{miyai20247ro}. It also features a comprehensive review of VLM-based methodologies for OOD detection and related tasks, clarifying their relationships \\cite{miyai20247ro}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Framework**: Introduction of \"Generalized OOD Detection v2,\" which analyzes the progression of AD, ND, OSR, OOD detection, and OD in the VLM era, revealing field inactivity/integration and identifying AD and OOD detection as the demanding challenges \\cite{miyai20247ro}.\n    *   **Extensive Survey**: A comprehensive review of VLM-based OOD detection and AD methods, categorizing them by training strategies and prompt usage, particularly in zero-shot and few-shot settings \\cite{miyai20247ro}. This is presented as the first comprehensive review of VLM-based OOD detection methods \\cite{miyai20247ro}.\n    *   **LVLM Era Introduction**: An early introduction to the evolution of these problems in the emerging Large Vision Language Model (LVLM) era (e.g., GPT-4V, LLaVA), summarizing definitions, findings, and future challenges \\cite{miyai20247ro}.\n    *   **Open Challenges & Future Directions**: Discussion of open challenges and future research directions, including a comparative analysis between AD and OOD fields to identify key areas for advancing VLM-based OOD detection \\cite{miyai20247ro}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: As a survey paper, the \"validation\" involves a systematic investigation of research activity. The authors comprehensively investigated papers utilizing VLMs from top venues (NeurIPS, AAAI, ICLR, CVPR, ICML, ICCV, ECCV, IJCAI, ACMMM, TPAMI, IJCV, TMLR) from 2021 to April 2025 \\cite{miyai20247ro}.\n    *   **Key Performance Metrics/Results**: The primary \"metric\" is the number of VLM-based papers published in each field (summarized in Table 1 of the paper), which objectively defines research activity \\cite{miyai20247ro}. This analysis revealed that Semantic AD/ND and OD have become largely inactive, OSR has integrated into hard OOD detection, while Sensory AD and OOD detection remain highly active research areas in the VLM era \\cite{miyai20247ro}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The survey's analysis of research activity is based on papers published in specific \"top venues\" and manually counted by examining titles and content, which might have minor subjective biases \\cite{miyai20247ro}.\n    *   **Scope of Applicability**: The survey focuses specifically on OOD detection and its closely related tasks (AD, ND, OSR, OD). It explicitly excludes tasks like open-vocabulary segmentation and referring segmentation, as their goal is to generalize to unseen classes when the class name is known, rather than detecting entirely new, unknown data \\cite{miyai20247ro}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This survey significantly advances the technical state-of-the-art by providing the first comprehensive framework (Generalized OOD Detection v2) that clarifies the definitions, problem settings, and interrelations of OOD detection and related tasks in the VLM era \\cite{miyai20247ro}. It resolves confusion caused by VLM-induced paradigm shifts \\cite{miyai20247ro}.\n    *   **Potential Impact on Future Research**: By identifying the most active and demanding challenges (AD and OOD detection) and outlining open problems and future directions, the paper serves as a valuable reference \\cite{miyai20247ro}. It is expected to foster collaborative efforts among different communities and inspire future advancements in VLM-based OOD detection and related fields, particularly in the nascent LVLM era \\cite{miyai20247ro}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Vision Language Models (VLMs)",
          "Large Vision Language Models (LVLMs)",
          "Generalized OOD Detection v2",
          "Anomaly Detection (AD)",
          "Unified framework",
          "Research taxonomy",
          "VLM-based OOD detection methods",
          "Paradigm shift",
          "Closed-world assumption",
          "Field integration and inactivity",
          "Open challenges",
          "Safety and reliability"
        ],
        "paper_type": "**survey**\n\n**reasoning:**\n\nthe abstract explicitly states:\n*   \"in this **survey**, we first present a generalized ood detection v2...\"\n*   \"...we thus feature a **comprehensive review** of the methodology for ood detection and related tasks...\"\n*   it discusses \"encapsulating the evolution of these fields,\" \"highlight the significant shift in the definition, problem settings, and benchmarks,\" and \"explore the advancements.\"\n*   it concludes with \"open challenges and future directions,\" which is typical for survey papers.\n\nthese phrases directly align with the criteria for a **survey** paper: \"reviews existing literature comprehensively,\" \"abstract mentions: 'survey', 'review', 'comprehensive analysis', 'state-of-the-art'.\""
      },
      "file_name": "2e6813cad2e41c683277aa2d400dc2a2761309a2.pdf"
    },
    {
      "success": true,
      "doc_id": "833e52d9d72e8f1bf3912541d6959a35",
      "summary": "The unknown fault diagnosis technology in industrial systems implies significant engineering application value and opportunities. The difficulty stems from the fact that the unknown fault samples frequently originate from the diagnostic modelâ€™s unknow distribution, leading to an out-of-distribution (OOD) problem. An incorrect diagnosis in the diagnostic model might readily arise from this. To deal with this problem, this article proposes a novel trustworthy fault diagnosis with OOD detection which can be applied on industrial systems and equipment. First, deep base learners (DBLs) with different activation functions are designed to construct the deep ensemble model. After that, use in-distribution (ID) inputs to train the initial deep ensemble model. Then, with the proposed max consistency and min similarity guided criterion, the DBLs of the initial ensemble model are chosen to reconstruct the ensemble model. Finally, the diagnostic resultsâ€™ uncertainty of the reconstruct ensemble model is estimated to accurately determine the type of the sample to be diagnosed. To verify the effectiveness of the proposed method, two gearbox data sets were used to test the proposed method and the max consistency and min similarity guided criterion. The experimental results demonstrate that the proposed approach can accurately identify unknown fault samples in the gearbox.",
      "intriguing_abstract": "The unknown fault diagnosis technology in industrial systems implies significant engineering application value and opportunities. The difficulty stems from the fact that the unknown fault samples frequently originate from the diagnostic modelâ€™s unknow distribution, leading to an out-of-distribution (OOD) problem. An incorrect diagnosis in the diagnostic model might readily arise from this. To deal with this problem, this article proposes a novel trustworthy fault diagnosis with OOD detection which can be applied on industrial systems and equipment. First, deep base learners (DBLs) with different activation functions are designed to construct the deep ensemble model. After that, use in-distribution (ID) inputs to train the initial deep ensemble model. Then, with the proposed max consistency and min similarity guided criterion, the DBLs of the initial ensemble model are chosen to reconstruct the ensemble model. Finally, the diagnostic resultsâ€™ uncertainty of the reconstruct ensemble model is estimated to accurately determine the type of the sample to be diagnosed. To verify the effectiveness of the proposed method, two gearbox data sets were used to test the proposed method and the max consistency and min similarity guided criterion. The experimental results demonstrate that the proposed approach can accurately identify unknown fault samples in the gearbox.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/9c841ab87d2801029b831643153ebc539dd62892.pdf",
      "citation_key": "zhang2024hh0",
      "metadata": {
        "title": "Trustworthy Diagnostics With Out-of-Distribution Detection: A Novel Max-Consistency and Min-Similarity Guided Deep Ensembles for Uncertainty Estimation",
        "authors": [
          "Xiaochen Zhang",
          "Chen Wang",
          "Wei Zhou",
          "Jiajia Xu",
          "Te Han"
        ],
        "published_date": "2024",
        "abstract": "The unknown fault diagnosis technology in industrial systems implies significant engineering application value and opportunities. The difficulty stems from the fact that the unknown fault samples frequently originate from the diagnostic modelâ€™s unknow distribution, leading to an out-of-distribution (OOD) problem. An incorrect diagnosis in the diagnostic model might readily arise from this. To deal with this problem, this article proposes a novel trustworthy fault diagnosis with OOD detection which can be applied on industrial systems and equipment. First, deep base learners (DBLs) with different activation functions are designed to construct the deep ensemble model. After that, use in-distribution (ID) inputs to train the initial deep ensemble model. Then, with the proposed max consistency and min similarity guided criterion, the DBLs of the initial ensemble model are chosen to reconstruct the ensemble model. Finally, the diagnostic resultsâ€™ uncertainty of the reconstruct ensemble model is estimated to accurately determine the type of the sample to be diagnosed. To verify the effectiveness of the proposed method, two gearbox data sets were used to test the proposed method and the max consistency and min similarity guided criterion. The experimental results demonstrate that the proposed approach can accurately identify unknown fault samples in the gearbox.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/9c841ab87d2801029b831643153ebc539dd62892.pdf",
        "venue": "IEEE Internet of Things Journal",
        "citationCount": 19,
        "score": 19.0,
        "summary": "The unknown fault diagnosis technology in industrial systems implies significant engineering application value and opportunities. The difficulty stems from the fact that the unknown fault samples frequently originate from the diagnostic modelâ€™s unknow distribution, leading to an out-of-distribution (OOD) problem. An incorrect diagnosis in the diagnostic model might readily arise from this. To deal with this problem, this article proposes a novel trustworthy fault diagnosis with OOD detection which can be applied on industrial systems and equipment. First, deep base learners (DBLs) with different activation functions are designed to construct the deep ensemble model. After that, use in-distribution (ID) inputs to train the initial deep ensemble model. Then, with the proposed max consistency and min similarity guided criterion, the DBLs of the initial ensemble model are chosen to reconstruct the ensemble model. Finally, the diagnostic resultsâ€™ uncertainty of the reconstruct ensemble model is estimated to accurately determine the type of the sample to be diagnosed. To verify the effectiveness of the proposed method, two gearbox data sets were used to test the proposed method and the max consistency and min similarity guided criterion. The experimental results demonstrate that the proposed approach can accurately identify unknown fault samples in the gearbox.",
        "keywords": []
      },
      "file_name": "9c841ab87d2801029b831643153ebc539dd62892.pdf"
    },
    {
      "success": true,
      "doc_id": "d918a871fec76ff70d33dd13c590bab4",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n### Analysis of \"Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection\" \\cite{cao20246gj}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Existing zero-shot Out-of-Distribution (OOD) detection methods, particularly those leveraging Vision-Language Models (VLMs) like CLIP, are limited by relying solely on closed-set in-distribution (ID) labels. This restriction hinders their ability to recognize samples from a large, open label space and effectively distinguish \"hard\" OOD samples.\n    *   **Importance & Challenge:** OOD detection is crucial for deploying machine learning models safely and reliably in open-world scenarios (e.g., autonomous driving) where encountering unknown data is common. The challenge lies in improving OOD detection performance without access to actual OOD data during training or inference, as such data is inherently unknown and unavailable in practical settings. The paper highlights that while incorporating actual OOD class labels significantly boosts VLM performance, these are practically inaccessible.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   Builds upon zero-shot OOD detection methods like MCM (Ming et al., 2022) that use VLMs (CLIP) and only ID class labels.\n        *   Relates to methods like ZOC (Esmaeilpour et al., 2022) and CLIPN (Wang et al., 2023) which also attempt to generate \"NOT ID\" classes.\n    *   **Limitations of Previous Solutions:**\n        *   Most existing OOD detection methods depend on a well-trained ID classifier and are constrained to specific ID datasets, ignoring the connection between visual and textual labels.\n        *   Zero-shot methods like MCM, while leveraging VLMs, often fail when encountering hard OOD samples because they exclusively rely on closed-set ID classes.\n        *   ZOC requires additional training on a text-based image description generator.\n        *   CLIPN necessitates a large dataset to train an extra CLIP encoder.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes **Envisioning Outlier Exposure (EOE)**, a knowledge-enhanced approach that leverages Large Language Models (LLMs) to generate potential outlier class labels without access to any actual OOD data. This is then integrated with a VLM (CLIP) for improved OOD detection.\n    *   **Novelty/Difference:**\n        *   **LLM-driven Outlier Generation:** EOE is novel in using the expert knowledge and reasoning capabilities of LLMs to *envision* potential outlier classes based on visual similarity to ID classes. This circumvents the need for actual OOD data or auxiliary datasets for training.\n        *   **Task-Specific LLM Prompts:** It designs specific LLM prompts tailored for different OOD detection tasks:\n            *   **Far OOD:** Prompts LLM to summarize ID classes into broad categories and then suggest visually similar outlier classes unrelated to these categories.\n            *   **Near OOD:** Prompts LLM to suggest visually similar outlier classes for *each* ID class that are not directly related or from the same primary group.\n            *   **Fine-grained OOD:** Prompts LLM to list distinct subclasses within the same major category that are not present in the ID dataset.\n        *   **Novel OOD Score Function:** Introduces a new score function, `SEOE(x)`, which penalizes similarity to the *envisioned outlier classes*. This function combines the normalized maximum similarity to ID classes with a subtracted term representing the normalized maximum similarity to the generated outlier classes, weighted by a hyperparameter `Î²`. This explicitly sharpens the distinction between ID and OOD samples.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   A novel framework, EOE, that integrates LLMs with VLMs for zero-shot OOD detection by generating synthetic outlier exposure.\n        *   A set of carefully designed LLM prompts (for far, near, and fine-grained OOD) that guide the LLM to generate relevant potential outlier class labels based on visual similarity to ID classes.\n        *   A new OOD detection score function, `SEOE(x)`, which incorporates a \"potential outlier penalty\" to effectively differentiate hard OOD samples from ID samples.\n    *   **Theoretical Insights/Analysis:** The work demonstrates that the inherent capability of VLMs (like CLIP) can be significantly unlocked for OOD detection by providing \"outlier exposure,\" even if this exposure is synthetically generated by an LLM, thereby addressing the practical unavailability of true OOD labels.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Evaluated EOE across three types of OOD detection tasks: Far OOD, Near OOD, and Fine-grained OOD.\n        *   **Far OOD:** ID datasets included CUB-200-2011, STANFORD-CARS, Food-101, Oxford-IIIT Pet, and ImageNet-1K. OOD datasets included iNaturalist, SUN, Places, and Texture.\n        *   **Near OOD:** Used ImageNet-10 as ID and ImageNet-20 (semantically similar classes) as OOD.\n        *   **Fine-grained OOD:** Split CUB-200-2011, STANFORD-CARS, Food-101, and Oxford-IIIT Pet into non-overlapping ID and OOD halves.\n        *   Compared EOE against state-of-the-art zero-shot OOD methods (CLIPN, Energy, MaxLogit, MCM) and a theoretical \"Ground Truth\" scenario (using actual OOD labels, which are unavailable in practice).\n    *   **Key Performance Metrics & Comparison Results:**\n        *   Metrics: FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve). Lower FPR95 and higher AUROC indicate better performance.\n        *   **Overall Superiority:** EOE consistently achieved state-of-the-art performance across all evaluated OOD tasks.\n        *   **Far OOD (Table 1):** EOE achieved an average FPR95 of **0.21%** and AUROC of **99.92%**, significantly outperforming MCM (2.68% FPR95, 99.40% AUROC), CLIPN (0.67% FPR95, 99.80% AUROC), Energy (1.01% FPR95, 99.72% AUROC), and MaxLogit (0.69% FPR95, 99.79% AUROC). In many cases, EOE's performance approached or even surpassed the \"Ground Truth\" baseline.\n        *   **Quantified Improvements:** EOE achieved improvements of 2.47% (far OOD), 2.13% (near OOD), 3.59% (fine-grained OOD), and 12.68% (ImageNet-1K far OOD) in terms of FPR95.\n        *   **Scalability:** Demonstrated effective scalability to large-scale datasets like ImageNet-1K.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The effectiveness of EOE relies on the quality and relevance of the outlier class labels generated by the LLM, which in turn depends on the LLM's inherent knowledge and the careful design of prompts. While the paper shows strong results, the sensitivity to prompt engineering and LLM capabilities is an implicit assumption. The hyperparameter `Î²` in the score function needs to be tuned.\n    *   **Scope of Applicability:** EOE is designed for zero-shot OOD detection scenarios where no actual OOD data is available. It is particularly well-suited for open-world settings and can generalize across far, near, and fine-grained OOD detection tasks. It leverages pre-trained VLMs (like CLIP) and LLMs, making it applicable where such foundation models are available.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** EOE significantly advances the technical state-of-the-art in zero-shot OOD detection by introducing a novel paradigm of \"envisioned outlier exposure.\" It demonstrates that LLMs can effectively bridge the gap between the theoretical benefit of knowing OOD classes and the practical reality of their unavailability.\n    *   **Potential Impact on Future Research:**\n        *   Opens new avenues for leveraging the reasoning and knowledge capabilities of LLMs to enhance various machine learning tasks, especially in open-set and uncertainty-aware scenarios.\n        *   Suggests that future OOD detection research could focus on more sophisticated LLM prompting strategies or adaptive mechanisms for generating outlier exposure.\n        *   Could inspire hybrid VLM-LLM architectures for other tasks requiring robust generalization to unseen categories or distributions.\n        *   The concept of \"synthetic outlier exposure\" could be extended to other domains beyond vision, such as natural language processing or time series analysis.",
      "intriguing_abstract": "Deploying AI safely in open-world scenarios demands robust Out-of-Distribution (OOD) detection, yet current zero-shot methods leveraging Vision-Language Models (VLMs) like CLIP are severely limited by the inherent unavailability of true OOD data. We introduce **Envisioning Outlier Exposure (EOE)**, a novel framework that harnesses the advanced reasoning capabilities of Large Language Models (LLMs) to synthetically generate potential outlier class labels. EOE circumvents the need for actual OOD samples by prompting LLMs to *envision* visually similar outliers, tailored for Far, Near, and Fine-grained OOD detection tasks.\n\nIntegrated with VLMs, our approach introduces a new OOD score function, SEOE(x), which explicitly penalizes similarity to these LLM-generated outlier concepts. EOE achieves state-of-the-art performance across diverse benchmarks, significantly outperforming existing zero-shot methods with an average FPR95 of 0.21% and AUROC of 99.92% for Far OOD, often surpassing theoretical \"Ground Truth\" baselines. This work pioneers a new paradigm for zero-shot OOD detection, unlocking VLM potential through LLM-driven synthetic outlier exposure and paving the way for more reliable and generalizable AI systems.",
      "keywords": [
        "Envisioning Outlier Exposure (EOE)",
        "Zero-shot OOD detection",
        "Large Language Models (LLMs)",
        "Vision-Language Models (VLMs)",
        "LLM-driven outlier generation",
        "Synthetic outlier exposure",
        "Novel OOD score function",
        "Task-specific LLM prompts",
        "Far Near Fine-grained OOD",
        "Open-world scenarios",
        "State-of-the-art performance",
        "Hybrid VLM-LLM architectures"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/14cfe2588311870325e2770c5159d3100d7031ea.pdf",
      "citation_key": "cao20246gj",
      "metadata": {
        "title": "Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection",
        "authors": [
          "Chentao Cao",
          "Zhun Zhong",
          "Zhanke Zhou",
          "Yang Liu",
          "Tongliang Liu",
          "Bo Han"
        ],
        "published_date": "2024",
        "abstract": "Detecting out-of-distribution (OOD) samples is essential when deploying machine learning models in open-world scenarios. Zero-shot OOD detection, requiring no training on in-distribution (ID) data, has been possible with the advent of vision-language models like CLIP. Existing methods build a text-based classifier with only closed-set labels. However, this largely restricts the inherent capability of CLIP to recognize samples from large and open label space. In this paper, we propose to tackle this constraint by leveraging the expert knowledge and reasoning capability of large language models (LLM) to Envision potential Outlier Exposure, termed EOE, without access to any actual OOD data. Owing to better adaptation to open-world scenarios, EOE can be generalized to different tasks, including far, near, and fine-grained OOD detection. Technically, we design (1) LLM prompts based on visual similarity to generate potential outlier class labels specialized for OOD detection, as well as (2) a new score function based on potential outlier penalty to distinguish hard OOD samples effectively. Empirically, EOE achieves state-of-the-art performance across different OOD tasks and can be effectively scaled to the ImageNet-1K dataset. The code is publicly available at: https://github.com/tmlr-group/EOE.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/14cfe2588311870325e2770c5159d3100d7031ea.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 18,
        "score": 18.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n### Analysis of \"Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection\" \\cite{cao20246gj}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Existing zero-shot Out-of-Distribution (OOD) detection methods, particularly those leveraging Vision-Language Models (VLMs) like CLIP, are limited by relying solely on closed-set in-distribution (ID) labels. This restriction hinders their ability to recognize samples from a large, open label space and effectively distinguish \"hard\" OOD samples.\n    *   **Importance & Challenge:** OOD detection is crucial for deploying machine learning models safely and reliably in open-world scenarios (e.g., autonomous driving) where encountering unknown data is common. The challenge lies in improving OOD detection performance without access to actual OOD data during training or inference, as such data is inherently unknown and unavailable in practical settings. The paper highlights that while incorporating actual OOD class labels significantly boosts VLM performance, these are practically inaccessible.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   Builds upon zero-shot OOD detection methods like MCM (Ming et al., 2022) that use VLMs (CLIP) and only ID class labels.\n        *   Relates to methods like ZOC (Esmaeilpour et al., 2022) and CLIPN (Wang et al., 2023) which also attempt to generate \"NOT ID\" classes.\n    *   **Limitations of Previous Solutions:**\n        *   Most existing OOD detection methods depend on a well-trained ID classifier and are constrained to specific ID datasets, ignoring the connection between visual and textual labels.\n        *   Zero-shot methods like MCM, while leveraging VLMs, often fail when encountering hard OOD samples because they exclusively rely on closed-set ID classes.\n        *   ZOC requires additional training on a text-based image description generator.\n        *   CLIPN necessitates a large dataset to train an extra CLIP encoder.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes **Envisioning Outlier Exposure (EOE)**, a knowledge-enhanced approach that leverages Large Language Models (LLMs) to generate potential outlier class labels without access to any actual OOD data. This is then integrated with a VLM (CLIP) for improved OOD detection.\n    *   **Novelty/Difference:**\n        *   **LLM-driven Outlier Generation:** EOE is novel in using the expert knowledge and reasoning capabilities of LLMs to *envision* potential outlier classes based on visual similarity to ID classes. This circumvents the need for actual OOD data or auxiliary datasets for training.\n        *   **Task-Specific LLM Prompts:** It designs specific LLM prompts tailored for different OOD detection tasks:\n            *   **Far OOD:** Prompts LLM to summarize ID classes into broad categories and then suggest visually similar outlier classes unrelated to these categories.\n            *   **Near OOD:** Prompts LLM to suggest visually similar outlier classes for *each* ID class that are not directly related or from the same primary group.\n            *   **Fine-grained OOD:** Prompts LLM to list distinct subclasses within the same major category that are not present in the ID dataset.\n        *   **Novel OOD Score Function:** Introduces a new score function, `SEOE(x)`, which penalizes similarity to the *envisioned outlier classes*. This function combines the normalized maximum similarity to ID classes with a subtracted term representing the normalized maximum similarity to the generated outlier classes, weighted by a hyperparameter `Î²`. This explicitly sharpens the distinction between ID and OOD samples.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   A novel framework, EOE, that integrates LLMs with VLMs for zero-shot OOD detection by generating synthetic outlier exposure.\n        *   A set of carefully designed LLM prompts (for far, near, and fine-grained OOD) that guide the LLM to generate relevant potential outlier class labels based on visual similarity to ID classes.\n        *   A new OOD detection score function, `SEOE(x)`, which incorporates a \"potential outlier penalty\" to effectively differentiate hard OOD samples from ID samples.\n    *   **Theoretical Insights/Analysis:** The work demonstrates that the inherent capability of VLMs (like CLIP) can be significantly unlocked for OOD detection by providing \"outlier exposure,\" even if this exposure is synthetically generated by an LLM, thereby addressing the practical unavailability of true OOD labels.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Evaluated EOE across three types of OOD detection tasks: Far OOD, Near OOD, and Fine-grained OOD.\n        *   **Far OOD:** ID datasets included CUB-200-2011, STANFORD-CARS, Food-101, Oxford-IIIT Pet, and ImageNet-1K. OOD datasets included iNaturalist, SUN, Places, and Texture.\n        *   **Near OOD:** Used ImageNet-10 as ID and ImageNet-20 (semantically similar classes) as OOD.\n        *   **Fine-grained OOD:** Split CUB-200-2011, STANFORD-CARS, Food-101, and Oxford-IIIT Pet into non-overlapping ID and OOD halves.\n        *   Compared EOE against state-of-the-art zero-shot OOD methods (CLIPN, Energy, MaxLogit, MCM) and a theoretical \"Ground Truth\" scenario (using actual OOD labels, which are unavailable in practice).\n    *   **Key Performance Metrics & Comparison Results:**\n        *   Metrics: FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve). Lower FPR95 and higher AUROC indicate better performance.\n        *   **Overall Superiority:** EOE consistently achieved state-of-the-art performance across all evaluated OOD tasks.\n        *   **Far OOD (Table 1):** EOE achieved an average FPR95 of **0.21%** and AUROC of **99.92%**, significantly outperforming MCM (2.68% FPR95, 99.40% AUROC), CLIPN (0.67% FPR95, 99.80% AUROC), Energy (1.01% FPR95, 99.72% AUROC), and MaxLogit (0.69% FPR95, 99.79% AUROC). In many cases, EOE's performance approached or even surpassed the \"Ground Truth\" baseline.\n        *   **Quantified Improvements:** EOE achieved improvements of 2.47% (far OOD), 2.13% (near OOD), 3.59% (fine-grained OOD), and 12.68% (ImageNet-1K far OOD) in terms of FPR95.\n        *   **Scalability:** Demonstrated effective scalability to large-scale datasets like ImageNet-1K.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The effectiveness of EOE relies on the quality and relevance of the outlier class labels generated by the LLM, which in turn depends on the LLM's inherent knowledge and the careful design of prompts. While the paper shows strong results, the sensitivity to prompt engineering and LLM capabilities is an implicit assumption. The hyperparameter `Î²` in the score function needs to be tuned.\n    *   **Scope of Applicability:** EOE is designed for zero-shot OOD detection scenarios where no actual OOD data is available. It is particularly well-suited for open-world settings and can generalize across far, near, and fine-grained OOD detection tasks. It leverages pre-trained VLMs (like CLIP) and LLMs, making it applicable where such foundation models are available.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** EOE significantly advances the technical state-of-the-art in zero-shot OOD detection by introducing a novel paradigm of \"envisioned outlier exposure.\" It demonstrates that LLMs can effectively bridge the gap between the theoretical benefit of knowing OOD classes and the practical reality of their unavailability.\n    *   **Potential Impact on Future Research:**\n        *   Opens new avenues for leveraging the reasoning and knowledge capabilities of LLMs to enhance various machine learning tasks, especially in open-set and uncertainty-aware scenarios.\n        *   Suggests that future OOD detection research could focus on more sophisticated LLM prompting strategies or adaptive mechanisms for generating outlier exposure.\n        *   Could inspire hybrid VLM-LLM architectures for other tasks requiring robust generalization to unseen categories or distributions.\n        *   The concept of \"synthetic outlier exposure\" could be extended to other domains beyond vision, such as natural language processing or time series analysis.",
        "keywords": [
          "Envisioning Outlier Exposure (EOE)",
          "Zero-shot OOD detection",
          "Large Language Models (LLMs)",
          "Vision-Language Models (VLMs)",
          "LLM-driven outlier generation",
          "Synthetic outlier exposure",
          "Novel OOD score function",
          "Task-specific LLM prompts",
          "Far Near Fine-grained OOD",
          "Open-world scenarios",
          "State-of-the-art performance",
          "Hybrid VLM-LLM architectures"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** to tackle this constraint by leveraging... llm to envision potential outlier exposure, termed eoe...\"\n*   it further details: \"technically, we **design** (1) llm prompts... as well as (2) a new score function...\"\n*   it mentions empirical evaluation: \"empirically, eoe achieves state-of-the-art performance...\" and \"the code is publicly available\".\n*   the introduction sets up a technical problem (ood detection limitations) and hints at the proposed solution.\n\nthese phrases strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems, and then typically evaluates them. while there are empirical results, they are presented as validation of the proposed technical solution, making the primary classification \"technical.\"\n\n**classification: technical**"
      },
      "file_name": "14cfe2588311870325e2770c5159d3100d7031ea.pdf"
    },
    {
      "success": true,
      "doc_id": "4fa75e9aa70e825aa9ba14011a4df9af",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of accurate density estimation for post-hoc out-of-distribution (OOD) detection. Existing methods often fail to accurately reflect true data density or impose impractical constraints.\n    *   **Importance & Challenge**: OOD data can severely undermine machine learning model stability and performance in real-world applications. Accurately estimating the in-distribution (ID) data density is crucial for OOD detection, but it's non-trivial due to the computational cost and intractability of normalization constants (partition functions) and the reliance on strong, often unproven, distributional assumptions (e.g., Gaussian, Gibbs-Boltzmann) in prior work \\cite{peng20243ji}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work provides a unified theoretical framework that bridges existing post-hoc OOD approaches (logit-based, distance-based, density-based) by considering an expansive exponential family of distributions \\cite{peng20243ji}.\n    *   **Limitations of Previous Solutions**:\n        *   **Logit-based (e.g., Energy-based, MSP)**: Energy-based methods assume constant partition functions across classes, which may not hold. Maximum Softmax Probability (MSP) is not directly proportional to true data density, leading to suboptimal OOD detection \\cite{peng20243ji}.\n        *   **Distance-based (e.g., Mahalanobis)**: These methods use distance as a proxy for density but are not directly proportional to true data density, bypassing partition function estimation at the cost of density accuracy \\cite{peng20243ji}.\n        *   **Density-based (e.g., GEM)**: While directly estimating density, methods like GEM rely on strict Gaussian assumptions for class-conditional densities, which limits their generalization ability and may not align with true data distributions (e.g., Gamma distributions) \\cite{peng20243ji}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel theoretical framework grounded in Bregman divergence, extending density considerations to the exponential family of distributions. Leveraging a conjugation constraint revealed by their theorem, they introduce the **CONJNORM** method \\cite{peng20243ji}.\n    *   **Novelty**:\n        *   **Unified Framework**: It unifies density function design for OOD detection by connecting the exponential family of distributions with Bregman divergence through conjugate Legendre functions \\cite{peng20243ji}.\n        *   **CONJNORM Method**: Reframes the density function design as a search for the optimal norm coefficient `p` (specifically using `l_p` norms) for a given dataset, simplifying the selection of appropriate density functions \\cite{peng20243ji}.\n        *   **Tractable Partition Function Estimation**: To overcome the computational challenges of normalization, `CONJNORM` devises an unbiased and analytically tractable estimator for the partition function using a Monte Carlo-based importance sampling technique \\cite{peng20243ji}.\n\n*   **Key Technical Contributions**\n    *   **Novel Theoretical Framework**: A Bregman divergence-based framework that unifies density function design within the exponential family of distributions, providing a principled way to design `g_theta(z,k)` \\cite{peng20243ji}.\n    *   **CONJNORM Method**: A practical method that leverages the `l_p` and `l_q` norm conjugation to determine the optimal density function by searching for a suitable norm coefficient `p` \\cite{peng20243ji}.\n    *   **Unbiased Partition Function Estimator**: An importance sampling-based approach that provides an analytically tractable and theoretically unbiased estimate of the partition function `Phi(k)`, addressing a long-standing challenge in density-based OOD detection without strong distributional assumptions \\cite{peng20243ji}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were conducted across various OOD detection benchmarks, including CIFAR-10, CIFAR-100, and ImageNet-1K, comparing `CONJNORM` against state-of-the-art methods \\cite{peng20243ji}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   The primary metrics used were FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve) \\cite{peng20243ji}.\n        *   `CONJNORM` established a new state-of-the-art, outperforming the current best method by up to 13.25% and 28.19% (FPR95) on CIFAR-100 and ImageNet-1K, respectively \\cite{peng20243ji}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The framework assumes the `g_phi(z)` term (agnostic to `mu(eta_k)`) can be treated as a constant and excluded from consideration. The optimal norm coefficient `p` is treated as a hyperparameter to be searched within a range \\cite{peng20243ji}.\n    *   **Scope of Applicability**: The work focuses specifically on post-hoc OOD detection strategies, where a pre-trained model is used without requiring resource-intensive re-training processes \\cite{peng20243ji}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `CONJNORM` significantly advances the technical state-of-the-art in density-based OOD detection by providing a more principled and flexible approach to density function design and estimation, leading to superior empirical performance \\cite{peng20243ji}.\n    *   **Potential Impact on Future Research**: The proposed Bregman divergence-based theoretical framework and the importance sampling technique for partition function estimation offer a unified and robust foundation for future research in OOD detection, potentially inspiring new methods that are less reliant on restrictive distributional assumptions and more capable of accurately reflecting true data densities \\cite{peng20243ji}.",
      "intriguing_abstract": "The pervasive challenge of out-of-distribution (OOD) detection critically impacts machine learning reliability, often hindered by inaccurate density estimation, intractable normalization constants, and restrictive distributional assumptions. We introduce a novel, unified theoretical framework grounded in **Bregman divergence** that extends density function design to the expansive **exponential family of distributions**, bridging disparate existing OOD approaches. Leveraging a conjugation constraint, we propose **CONJNORM**, a principled method that reframes density function design as a search for the optimal norm coefficient `p`. Crucially, CONJNORM devises an unbiased and analytically tractable **importance sampling** estimator for the elusive **partition function**, overcoming a long-standing barrier in density-based OOD detection without strong assumptions. Our approach establishes a new **state-of-the-art** in **post-hoc OOD detection**, achieving significant improvements (e.g., up to 28.19% FPR95 on ImageNet-1K) over leading methods across various benchmarks. This work provides a robust and flexible foundation for future research, enhancing the trustworthiness and deployment of ML models in real-world applications.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "density estimation",
        "exponential family of distributions",
        "Bregman divergence",
        "CONJNORM method",
        "unified theoretical framework",
        "partition function estimation",
        "unbiased partition function estimator",
        "importance sampling",
        "l_p norms",
        "post-hoc OOD detection",
        "state-of-the-art performance",
        "machine learning model stability"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/f9cf8d53b1a157ab9dee16f03290d28865f3089a.pdf",
      "citation_key": "peng20243ji",
      "metadata": {
        "title": "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection",
        "authors": [
          "Bo Peng",
          "Yadan Luo",
          "Yonggang Zhang",
          "Yixuan Li",
          "Zhen Fang"
        ],
        "published_date": "2024",
        "abstract": "Post-hoc out-of-distribution (OOD) detection has garnered intensive attention in reliable machine learning. Many efforts have been dedicated to deriving score functions based on logits, distances, or rigorous data distribution assumptions to identify low-scoring OOD samples. Nevertheless, these estimate scores may fail to accurately reflect the true data density or impose impractical constraints. To provide a unified perspective on density-based score design, we propose a novel theoretical framework grounded in Bregman divergence, which extends distribution considerations to encompass an exponential family of distributions. Leveraging the conjugation constraint revealed in our theorem, we introduce a \\textsc{ConjNorm} method, reframing density function design as a search for the optimal norm coefficient $p$ against the given dataset. In light of the computational challenges of normalization, we devise an unbiased and analytically tractable estimator of the partition function using the Monte Carlo-based importance sampling technique. Extensive experiments across OOD detection benchmarks empirically demonstrate that our proposed \\textsc{ConjNorm} has established a new state-of-the-art in a variety of OOD detection setups, outperforming the current best method by up to 13.25$\\%$ and 28.19$\\%$ (FPR95) on CIFAR-100 and ImageNet-1K, respectively.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/f9cf8d53b1a157ab9dee16f03290d28865f3089a.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 17,
        "score": 17.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of accurate density estimation for post-hoc out-of-distribution (OOD) detection. Existing methods often fail to accurately reflect true data density or impose impractical constraints.\n    *   **Importance & Challenge**: OOD data can severely undermine machine learning model stability and performance in real-world applications. Accurately estimating the in-distribution (ID) data density is crucial for OOD detection, but it's non-trivial due to the computational cost and intractability of normalization constants (partition functions) and the reliance on strong, often unproven, distributional assumptions (e.g., Gaussian, Gibbs-Boltzmann) in prior work \\cite{peng20243ji}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work provides a unified theoretical framework that bridges existing post-hoc OOD approaches (logit-based, distance-based, density-based) by considering an expansive exponential family of distributions \\cite{peng20243ji}.\n    *   **Limitations of Previous Solutions**:\n        *   **Logit-based (e.g., Energy-based, MSP)**: Energy-based methods assume constant partition functions across classes, which may not hold. Maximum Softmax Probability (MSP) is not directly proportional to true data density, leading to suboptimal OOD detection \\cite{peng20243ji}.\n        *   **Distance-based (e.g., Mahalanobis)**: These methods use distance as a proxy for density but are not directly proportional to true data density, bypassing partition function estimation at the cost of density accuracy \\cite{peng20243ji}.\n        *   **Density-based (e.g., GEM)**: While directly estimating density, methods like GEM rely on strict Gaussian assumptions for class-conditional densities, which limits their generalization ability and may not align with true data distributions (e.g., Gamma distributions) \\cite{peng20243ji}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel theoretical framework grounded in Bregman divergence, extending density considerations to the exponential family of distributions. Leveraging a conjugation constraint revealed by their theorem, they introduce the **CONJNORM** method \\cite{peng20243ji}.\n    *   **Novelty**:\n        *   **Unified Framework**: It unifies density function design for OOD detection by connecting the exponential family of distributions with Bregman divergence through conjugate Legendre functions \\cite{peng20243ji}.\n        *   **CONJNORM Method**: Reframes the density function design as a search for the optimal norm coefficient `p` (specifically using `l_p` norms) for a given dataset, simplifying the selection of appropriate density functions \\cite{peng20243ji}.\n        *   **Tractable Partition Function Estimation**: To overcome the computational challenges of normalization, `CONJNORM` devises an unbiased and analytically tractable estimator for the partition function using a Monte Carlo-based importance sampling technique \\cite{peng20243ji}.\n\n*   **Key Technical Contributions**\n    *   **Novel Theoretical Framework**: A Bregman divergence-based framework that unifies density function design within the exponential family of distributions, providing a principled way to design `g_theta(z,k)` \\cite{peng20243ji}.\n    *   **CONJNORM Method**: A practical method that leverages the `l_p` and `l_q` norm conjugation to determine the optimal density function by searching for a suitable norm coefficient `p` \\cite{peng20243ji}.\n    *   **Unbiased Partition Function Estimator**: An importance sampling-based approach that provides an analytically tractable and theoretically unbiased estimate of the partition function `Phi(k)`, addressing a long-standing challenge in density-based OOD detection without strong distributional assumptions \\cite{peng20243ji}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were conducted across various OOD detection benchmarks, including CIFAR-10, CIFAR-100, and ImageNet-1K, comparing `CONJNORM` against state-of-the-art methods \\cite{peng20243ji}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   The primary metrics used were FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve) \\cite{peng20243ji}.\n        *   `CONJNORM` established a new state-of-the-art, outperforming the current best method by up to 13.25% and 28.19% (FPR95) on CIFAR-100 and ImageNet-1K, respectively \\cite{peng20243ji}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The framework assumes the `g_phi(z)` term (agnostic to `mu(eta_k)`) can be treated as a constant and excluded from consideration. The optimal norm coefficient `p` is treated as a hyperparameter to be searched within a range \\cite{peng20243ji}.\n    *   **Scope of Applicability**: The work focuses specifically on post-hoc OOD detection strategies, where a pre-trained model is used without requiring resource-intensive re-training processes \\cite{peng20243ji}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `CONJNORM` significantly advances the technical state-of-the-art in density-based OOD detection by providing a more principled and flexible approach to density function design and estimation, leading to superior empirical performance \\cite{peng20243ji}.\n    *   **Potential Impact on Future Research**: The proposed Bregman divergence-based theoretical framework and the importance sampling technique for partition function estimation offer a unified and robust foundation for future research in OOD detection, potentially inspiring new methods that are less reliant on restrictive distributional assumptions and more capable of accurately reflecting true data densities \\cite{peng20243ji}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "density estimation",
          "exponential family of distributions",
          "Bregman divergence",
          "CONJNORM method",
          "unified theoretical framework",
          "partition function estimation",
          "unbiased partition function estimator",
          "importance sampling",
          "l_p norms",
          "post-hoc OOD detection",
          "state-of-the-art performance",
          "machine learning model stability"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n1.  **presents new methods, algorithms, or systems:** the abstract explicitly states, \"we **propose a novel theoretical framework** grounded in bregman divergence... we **introduce a conjnorm method**... we **devise an unbiased and analytically tractable estimator** of the partition function using the monte carlo-based importance sampling technique.\" the introduction reiterates this, mentioning \"introduce an innovative bregman divergence-based theoretical framework\" and \"propose the conjnorm method\" and \"put forward a monte carlo-based importance sampling technique.\" these are all clear indicators of presenting new technical contributions.\n2.  **discusses technical problem, proposed solution:** the paper identifies the technical problem of accurately reflecting true data density and the computational challenges of normalization in ood detection. it then presents its theoretical framework, the conjnorm method, and the importance sampling estimator as its proposed solutions.\n3.  **empirical validation is secondary to the proposed method:** while \"extensive experiments\" and \"empirically demonstrate\" are mentioned, these experiments serve to validate the effectiveness of the *proposed* conjnorm method and estimator. the core contribution is the development of the new method and its underlying theory, not merely a study of existing data or methods.\n\nalthough it has strong theoretical foundations and extensive empirical validation, the primary purpose and contribution are the **development and presentation of a new method and its components**."
      },
      "file_name": "f9cf8d53b1a157ab9dee16f03290d28865f3089a.pdf"
    },
    {
      "success": true,
      "doc_id": "961684bdea111c9223312831acf54858",
      "summary": "Here's a focused summary of the paper `GOODAT: Towards Test-time Graph Out-of-Distribution Detection` \\cite{wang2024es5} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Graph Neural Networks (GNNs) perform poorly and make unreliable predictions when encountering Out-of-Distribution (OOD) graph samples, which are common in real-world deployments.\n    *   **Importance and Challenge**: Existing graph OOD detection methods are computationally expensive, require access to the original training data, or necessitate modifications to the GNN architecture. These limitations restrict their universality, especially in scenarios with privacy concerns, inaccessible training data (e.g., federated learning), or fixed model architectures. Developing a test-time, training data-independent, and plug-and-play solution is challenging due to: 1) inconsistent learning objectives (GNNs are trained for classification, not OOD detection), 2) absence of labels at test time, and 3) unavailability of training data.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Previous graph OOD detection methods include GNN-based detectors trained from scratch (e.g., \\cite{liu2023a}) and data-centric approaches that modify input data using additional networks (e.g., AAGOD \\cite{guo2023}) on top of well-trained GNNs.\n    *   **Limitations of Previous Solutions**: These methods fundamentally rely on the training dataset, leading to high computational costs, requiring access to and modification of the GNN architecture, and being inapplicable in scenarios where training data or model parameters are inaccessible.\n    *   **Positioning**: `GOODAT` \\cite{wang2024es5} distinguishes itself by pioneering a \"test-time\" graph OOD detection paradigm. Unlike prior work, it operates solely on test data, is independent of training data, and does not require modifying the well-trained GNN architecture, offering a lightweight, unsupervised, and plug-and-play solution.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: `GOODAT` \\cite{wang2024es5} is a data-centric, unsupervised, and plug-and-play method that integrates a lightweight graph masker with any well-trained GNN at test time. This masker, composed of parameterized matrices (`MX`, `MA`), learns to extract informative subgraphs from input test samples.\n    *   **Novelty**:\n        *   **Test-time Operation**: `GOODAT` \\cite{wang2024es5} is the first to address graph OOD detection exclusively at inference time, without needing training data or GNN architecture modifications.\n        *   **Graph Information Bottleneck (GIB) Principle**: It leverages the GIB principle to guide the graph masker. By initially assuming all test graphs are In-Distribution (ID) to generate surrogate ID labels, the masker is optimized to capture compact yet highly informative subgraphs that can distinguish OOD from ID patterns.\n        *   **Three GIB-boosted Unsupervised Objective Functions**: To optimize the graph masker without ground truth labels, `GOODAT` \\cite{wang2024es5} meticulously designs three unsupervised loss functions:\n            1.  **Subgraph GIB Loss (`Ls`)**: Facilitates factual reasoning by maximizing the mutual information between the extracted subgraph and the surrogate label, while minimizing information between the subgraph and the original graph, ensuring the subgraph is both informative and compressed.\n            2.  **Masked Graph GIB Loss (`Lm`)**: Enables counterfactual reasoning by ensuring the remaining \"masked\" part of the graph is irrelevant to the label, preventing the extracted subgraph from being merely sufficient but not necessary.\n            3.  **Graph Distribution Separating Loss (`Ld`)**: Further enhances the distinctness between the extracted subgraph and the masked graph by statistically separating their distributions using Copula theory, aiming for minimal overlap.\n\n*   **Key Technical Contributions**\n    *   **Novel Learning Paradigm**: Introduction of the \"test-time graph OOD detection\" paradigm, providing a lightweight, training data-independent, and plug-and-play solution for GNNs.\n    *   **Innovative Method (`GOODAT`)**: A simple yet effective method that leverages the Graph Information Bottleneck (GIB) principle to capture informative subgraphs for accurate OOD identification.\n    *   **GIB-boosted Unsupervised Loss Functions**: Design of three novel loss functions (`Ls`, `Lm`, `Ld`) that collectively guide the graph masker to extract compact, informative, and distinct subgraphs for OOD detection without requiring ground truth labels or training data.\n    *   **Lightweight Graph Masker**: A parameterized graph masker that seamlessly integrates with existing GNNs without requiring architectural modifications.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Comprehensive evaluations were performed across a variety of real-world datasets and scenarios.\n    *   **Key Performance Metrics and Comparison Results**: While specific metrics are not detailed in the abstract/introduction, the paper states that `GOODAT` \\cite{wang2024es5} consistently outperforms state-of-the-art benchmarks, demonstrating significant improvements in graph OOD detection tasks.\n\n*   **Limitations & Scope**\n    *   **Technical Assumption**: `GOODAT` \\cite{wang2024es5} operates under the assumption that all graphs in the initial test dataset are inherently ID to generate surrogate ID labels for the unsupervised learning process. This assumption might be a simplification in highly adversarial or diverse test environments.\n    *   **Scope of Applicability**: The method is designed to be universally applicable to any well-trained GNN model, irrespective of its architecture or the characteristics of its original training data, due to its plug-and-play and training data-independent nature.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: `GOODAT` \\cite{wang2024es5} significantly advances the technical state-of-the-art by introducing the first test-time graph OOD detection paradigm, effectively addressing critical limitations of existing methods related to resource intensity, data dependency, and architectural constraints.\n    *   **Potential Impact**: This work enables more robust and reliable deployment of GNNs in open-world scenarios where OOD data is prevalent and access to training data or model internals is restricted. It opens new avenues for research into lightweight, unsupervised, and adaptive OOD detection methods for graph data, particularly beneficial for applications in privacy-preserving or federated learning settings.",
      "intriguing_abstract": "Graph Neural Networks (GNNs) face a critical challenge: their performance plummets when encountering Out-of-Distribution (OOD) samples, common in real-world deployments. Existing graph OOD detection methods are computationally expensive, demand access to sensitive training data, or necessitate GNN architectural modifications, severely limiting their applicability in privacy-sensitive or federated learning environments. We introduce `GOODAT`, a pioneering framework that redefines graph OOD detection. `GOODAT` is the first *test-time*, *training data-independent*, and *plug-and-play* solution, seamlessly integrating a lightweight graph masker with any pre-trained GNN. Our innovation lies in leveraging the *Graph Information Bottleneck (GIB)* principle, guided by three novel unsupervised objective functions, to extract compact, informative subgraphs for robust OOD identification. These functions enable both factual and counterfactual reasoning, statistically separating OOD patterns without ground truth labels. `GOODAT` consistently outperforms state-of-the-art benchmarks, offering a transformative approach for deploying reliable GNNs in open-world scenarios, fostering advancements in secure and adaptive graph learning.",
      "keywords": [
        "Graph Neural Networks (GNNs)",
        "Out-of-Distribution (OOD) detection",
        "test-time graph OOD detection",
        "training data-independent",
        "plug-and-play solution",
        "unsupervised learning",
        "Graph Information Bottleneck (GIB)",
        "graph masker",
        "GIB-boosted unsupervised loss functions",
        "GOODAT",
        "robust GNN deployment",
        "federated learning",
        "privacy-preserving learning"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/2902a67f9aebb115fc2b6cdf611910e72e896bdd.pdf",
      "citation_key": "wang2024es5",
      "metadata": {
        "title": "GOODAT: Towards Test-time Graph Out-of-Distribution Detection",
        "authors": [
          "Luzhi Wang",
          "Dongxiao He",
          "He Zhang",
          "Yixin Liu",
          "Wenjie Wang",
          "Shirui Pan",
          "Di Jin",
          "Tat-Seng Chua"
        ],
        "published_date": "2024",
        "abstract": "Graph neural networks (GNNs) have found widespread application in modeling graph data across diverse domains. While GNNs excel in scenarios where the testing data shares the distribution of their training counterparts (in distribution, ID), they often exhibit incorrect predictions when confronted with samples from an unfamiliar distribution (out-of-distribution, OOD). To identify and reject OOD samples with GNNs, recent studies have explored graph OOD detection, often focusing on training a specific model or modifying the data on top of a well-trained GNN. Despite their effectiveness, these methods come with heavy training resources and costs, as they need to optimize the GNN-based models on training data. Moreover, their reliance on modifying the original GNNs and accessing training data further restricts their universality. To this end, this paper introduces a method to detect Graph Out-of-Distribution At Test-time (namely GOODAT), a data-centric, unsupervised, and plug-and-play solution that operates independently of training data and modifications of GNN architecture. With a lightweight graph masker, GOODAT can learn informative subgraphs from test samples, enabling the capture of distinct graph patterns between OOD and ID samples. To optimize the graph masker, we meticulously design three unsupervised objective functions based on the graph information bottleneck principle, motivating the masker to capture compact yet informative subgraphs for OOD detection. Comprehensive evaluations confirm that our GOODAT method outperforms state-of-the-art benchmarks across a variety of real-world datasets.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/2902a67f9aebb115fc2b6cdf611910e72e896bdd.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 16,
        "score": 16.0,
        "summary": "Here's a focused summary of the paper `GOODAT: Towards Test-time Graph Out-of-Distribution Detection` \\cite{wang2024es5} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Graph Neural Networks (GNNs) perform poorly and make unreliable predictions when encountering Out-of-Distribution (OOD) graph samples, which are common in real-world deployments.\n    *   **Importance and Challenge**: Existing graph OOD detection methods are computationally expensive, require access to the original training data, or necessitate modifications to the GNN architecture. These limitations restrict their universality, especially in scenarios with privacy concerns, inaccessible training data (e.g., federated learning), or fixed model architectures. Developing a test-time, training data-independent, and plug-and-play solution is challenging due to: 1) inconsistent learning objectives (GNNs are trained for classification, not OOD detection), 2) absence of labels at test time, and 3) unavailability of training data.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Previous graph OOD detection methods include GNN-based detectors trained from scratch (e.g., \\cite{liu2023a}) and data-centric approaches that modify input data using additional networks (e.g., AAGOD \\cite{guo2023}) on top of well-trained GNNs.\n    *   **Limitations of Previous Solutions**: These methods fundamentally rely on the training dataset, leading to high computational costs, requiring access to and modification of the GNN architecture, and being inapplicable in scenarios where training data or model parameters are inaccessible.\n    *   **Positioning**: `GOODAT` \\cite{wang2024es5} distinguishes itself by pioneering a \"test-time\" graph OOD detection paradigm. Unlike prior work, it operates solely on test data, is independent of training data, and does not require modifying the well-trained GNN architecture, offering a lightweight, unsupervised, and plug-and-play solution.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: `GOODAT` \\cite{wang2024es5} is a data-centric, unsupervised, and plug-and-play method that integrates a lightweight graph masker with any well-trained GNN at test time. This masker, composed of parameterized matrices (`MX`, `MA`), learns to extract informative subgraphs from input test samples.\n    *   **Novelty**:\n        *   **Test-time Operation**: `GOODAT` \\cite{wang2024es5} is the first to address graph OOD detection exclusively at inference time, without needing training data or GNN architecture modifications.\n        *   **Graph Information Bottleneck (GIB) Principle**: It leverages the GIB principle to guide the graph masker. By initially assuming all test graphs are In-Distribution (ID) to generate surrogate ID labels, the masker is optimized to capture compact yet highly informative subgraphs that can distinguish OOD from ID patterns.\n        *   **Three GIB-boosted Unsupervised Objective Functions**: To optimize the graph masker without ground truth labels, `GOODAT` \\cite{wang2024es5} meticulously designs three unsupervised loss functions:\n            1.  **Subgraph GIB Loss (`Ls`)**: Facilitates factual reasoning by maximizing the mutual information between the extracted subgraph and the surrogate label, while minimizing information between the subgraph and the original graph, ensuring the subgraph is both informative and compressed.\n            2.  **Masked Graph GIB Loss (`Lm`)**: Enables counterfactual reasoning by ensuring the remaining \"masked\" part of the graph is irrelevant to the label, preventing the extracted subgraph from being merely sufficient but not necessary.\n            3.  **Graph Distribution Separating Loss (`Ld`)**: Further enhances the distinctness between the extracted subgraph and the masked graph by statistically separating their distributions using Copula theory, aiming for minimal overlap.\n\n*   **Key Technical Contributions**\n    *   **Novel Learning Paradigm**: Introduction of the \"test-time graph OOD detection\" paradigm, providing a lightweight, training data-independent, and plug-and-play solution for GNNs.\n    *   **Innovative Method (`GOODAT`)**: A simple yet effective method that leverages the Graph Information Bottleneck (GIB) principle to capture informative subgraphs for accurate OOD identification.\n    *   **GIB-boosted Unsupervised Loss Functions**: Design of three novel loss functions (`Ls`, `Lm`, `Ld`) that collectively guide the graph masker to extract compact, informative, and distinct subgraphs for OOD detection without requiring ground truth labels or training data.\n    *   **Lightweight Graph Masker**: A parameterized graph masker that seamlessly integrates with existing GNNs without requiring architectural modifications.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Comprehensive evaluations were performed across a variety of real-world datasets and scenarios.\n    *   **Key Performance Metrics and Comparison Results**: While specific metrics are not detailed in the abstract/introduction, the paper states that `GOODAT` \\cite{wang2024es5} consistently outperforms state-of-the-art benchmarks, demonstrating significant improvements in graph OOD detection tasks.\n\n*   **Limitations & Scope**\n    *   **Technical Assumption**: `GOODAT` \\cite{wang2024es5} operates under the assumption that all graphs in the initial test dataset are inherently ID to generate surrogate ID labels for the unsupervised learning process. This assumption might be a simplification in highly adversarial or diverse test environments.\n    *   **Scope of Applicability**: The method is designed to be universally applicable to any well-trained GNN model, irrespective of its architecture or the characteristics of its original training data, due to its plug-and-play and training data-independent nature.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: `GOODAT` \\cite{wang2024es5} significantly advances the technical state-of-the-art by introducing the first test-time graph OOD detection paradigm, effectively addressing critical limitations of existing methods related to resource intensity, data dependency, and architectural constraints.\n    *   **Potential Impact**: This work enables more robust and reliable deployment of GNNs in open-world scenarios where OOD data is prevalent and access to training data or model internals is restricted. It opens new avenues for research into lightweight, unsupervised, and adaptive OOD detection methods for graph data, particularly beneficial for applications in privacy-preserving or federated learning settings.",
        "keywords": [
          "Graph Neural Networks (GNNs)",
          "Out-of-Distribution (OOD) detection",
          "test-time graph OOD detection",
          "training data-independent",
          "plug-and-play solution",
          "unsupervised learning",
          "Graph Information Bottleneck (GIB)",
          "graph masker",
          "GIB-boosted unsupervised loss functions",
          "GOODAT",
          "robust GNN deployment",
          "federated learning",
          "privacy-preserving learning"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"this paper introduces a method to detect graph out-of-distribution attest-time (namely goodat), a data-centric, unsupervised, and plug-and-play solution...\" it then describes the components of this method (\"lightweight graph masker,\" \"three unsupervised objective functions\").\n*   the introduction further elaborates on the problem and immediately introduces \"our test-time ood detector\" (goodat) in comparison to existing methods.\n*   while it mentions \"comprehensive evaluations confirm that our goodat method outperforms state-of-the-art benchmarks,\" this empirical evaluation serves to validate the *new method* being proposed, rather than being the primary focus of studying an existing phenomenon or dataset.\n\nthis strongly aligns with the criteria for a **technical** paper, which presents new methods, algorithms, or systems.\n\n**classification: technical**"
      },
      "file_name": "2902a67f9aebb115fc2b6cdf611910e72e896bdd.pdf"
    },
    {
      "success": true,
      "doc_id": "5fd3414f6def53e1f8f4533bd329fb5a",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Unsupervised graph-level anomaly detection (GLAD) and unsupervised graph-level out-of-distribution (GLOD) detection, despite sharing the same objective of identifying anomalous or out-of-distribution graphs, have been studied independently with distinct evaluation setups. This creates a significant gap that hinders cross-application and comprehensive evaluation of methods from one domain to the other \\cite{wang2024q01}.\n    *   **Importance and Challenge**: Building safe and reliable graph machine learning systems necessitates robust GLAD and GLOD capabilities. The universality of distribution shifts in real-world graph data (e.g., drug discovery, cyber-attack detection) makes these tasks crucial. The challenge lies in the lack of a unified framework to systematically compare and understand the strengths and limitations of existing methods across these conceptually linked problems \\cite{wang2024q01}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself within the broader context of \"generalized OOD detection,\" acknowledging that GLAD and GLOD are two branches of this concept. Existing GLAD methods primarily focus on unsupervised paradigms due to the scarcity of labeled anomalies. GLOD methods exist as both post-hoc detectors (requiring trained GNN classifiers and labeled ID data) and unsupervised OOD-specific models (trained only on unlabeled ID data) \\cite{wang2024q01}.\n    *   **Limitations of Previous Solutions**: Previous GLAD and GLOD studies suffer from distinct evaluation setups, making direct comparison and understanding of their generalizability difficult. Many GLOD methods rely on labeled ID data for training backbone GNNs, limiting their applicability in unsupervised scenarios. The lack of a unified benchmark prevents a holistic understanding of method performance across diverse anomaly and OOD scenarios \\cite{wang2024q01}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper introduces UB-GOLD (Unified Benchmark for unsupervised Graph-level OOD and anoma LyDetection), a comprehensive evaluation framework that unifies GLAD and GLOD under the concept of \"generalized graph-level OOD detection\" \\cite{wang2024q01}.\n    *   **Novelty/Difference**: UB-GOLD's innovation lies in its unification of these two previously separate fields. It defines four practical anomaly and OOD detection scenarios:\n        1.  **Intrinsic Anomaly (Type I)**: Datasets with naturally occurring semantic anomalies (e.g., toxic molecules).\n        2.  **Class-based Anomaly (Type II)**: Datasets where a minority or distinct class is designated as anomalous.\n        3.  **Inter-Dataset Shift (Type III)**: Simulating distribution shifts by drawing ID and OOD samples from different datasets within the same domain.\n        4.  **Intra-Dataset Shift (Type IV)**: Datasets with intrinsic distribution shifts regarding graph sizes, molecular scaffolds, or protein targets \\cite{wang2024q01}.\n        This unified framework allows for a fair and comprehensive comparison of diverse methods.\n\n*   **Key Technical Contributions**\n    *   **Novel Benchmark**: Introduction of UB-GOLD, the first comprehensive and unified benchmark for unsupervised GLAD and GLOD, encompassing 35 datasets across four distinct anomaly and OOD detection scenarios \\cite{wang2024q01}.\n    *   **Multi-dimensional Analysis Framework**: Development and execution of a systematic analysis framework to evaluate existing methods across multiple dimensions: effectiveness on different datasets, OOD sensitivity spectrum (near-OOD vs. far-OOD), robustness against unreliable training data (noisy ID data), and efficiency (time and memory usage) \\cite{wang2024q01}.\n    *   **Unified Codebase and Future Directions**: Provision of an open-source codebase for UB-GOLD to foster reproducible research and outlining potential future research directions based on the benchmark's insights \\cite{wang2024q01}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The benchmark facilitates the comparison of 18 representative GLAD/GLOD methods (including two-step methods like graph kernels with detectors, SSL with detectors, and end-to-end GNN-based GLAD/GLOD methods) across 35 datasets spanning the four defined scenarios. Multi-dimensional analyses were performed to assess OOD sensitivity, robustness to noisy training data, and efficiency \\cite{wang2024q01}.\n    *   **Key Performance Metrics and Results**: While specific metrics (e.g., AUC-ROC) are implied for anomaly/OOD detection, the paper highlights key observations:\n        *   SOTA GLAD/GLOD methods show excellent performance across tasks.\n        *   Near-OOD samples are consistently harder to detect than far-OOD samples.\n        *   Most methods are vulnerable to perturbations in training sets (i.e., noisy ID data).\n        *   Certain end-to-end methods demonstrate superior performance and computational efficiency compared to two-step methods \\cite{wang2024q01}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The benchmark primarily focuses on *unsupervised* graph-level anomaly and OOD detection, aligning with real-world scenarios where labeled data is scarce. It does not extensively cover supervised or semi-supervised paradigms \\cite{wang2024q01}.\n    *   **Scope of Applicability**: UB-GOLD's scenarios cover intrinsic anomalies, class-based anomalies, and inter/intra-dataset distribution shifts, providing a broad but not exhaustive coverage of all possible anomaly or OOD types. The selection of 18 methods, while representative, does not include every single GLAD/GLOD method ever proposed \\cite{wang2024q01}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: UB-GOLD significantly advances the technical state-of-the-art by bridging the conceptual and practical gap between GLAD and GLOD. It provides a standardized, unified framework for rigorous evaluation, enabling a clearer understanding of method capabilities and limitations across diverse scenarios \\cite{wang2024q01}.\n    *   **Potential Impact on Future Research**: The benchmark's multi-dimensional analyses and key findings offer critical insights, guiding future research towards developing more robust, efficient, and sensitive GLAD/GLOD methods. The open-source codebase promotes reproducible research and facilitates rapid prototyping and comparison of new approaches, fostering innovation in building safer and more reliable graph machine learning systems \\cite{wang2024q01}.",
      "intriguing_abstract": "Despite shared objectives, the independent study of unsupervised graph-level anomaly detection (GLAD) and graph-level out-of-distribution (GLOD) has created a critical chasm, severely impeding progress in building robust graph machine learning systems vital for applications like drug discovery and cyber-security. We bridge this divide by introducing UB-GOLD, the first comprehensive and unified benchmark for *generalized graph-level OOD detection*.\n\nUB-GOLD unifies GLAD and GLOD under a single framework, defining four practical scenarios: intrinsic anomalies, class-based anomalies, and inter/intra-dataset distribution shifts. Spanning 35 diverse datasets, our benchmark facilitates rigorous, multi-dimensional analysis of 18 representative methods, evaluating effectiveness, OOD sensitivity (near-OOD vs. far-OOD), robustness to noisy ID data, and efficiency. Our findings reveal that near-OOD samples are consistently harder to detect and that most methods are vulnerable to training data perturbations. UB-GOLD provides an open-source codebase, offering unprecedented insights and a standardized platform to accelerate the development of more resilient and sensitive graph-level anomaly and OOD detection methods. This work is crucial for advancing safe and reliable graph AI.",
      "keywords": [
        "Unsupervised graph-level anomaly detection (GLAD)",
        "unsupervised graph-level out-of-distribution (GLOD) detection",
        "generalized graph-level OOD detection",
        "UB-GOLD",
        "unified evaluation framework",
        "distribution shifts",
        "graph machine learning systems",
        "four anomaly/OOD detection scenarios",
        "multi-dimensional analysis",
        "noisy ID data robustness",
        "near-OOD detection",
        "end-to-end GNN methods",
        "open-source codebase"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/d212c555293b81f845b3c99af4e922b0fcdb4290.pdf",
      "citation_key": "wang2024q01",
      "metadata": {
        "title": "Unifying Unsupervised Graph-Level Anomaly Detection and Out-of-Distribution Detection: A Benchmark",
        "authors": [
          "Yili Wang",
          "Yixin Liu",
          "Xu Shen",
          "Chenyu Li",
          "Kaize Ding",
          "Rui Miao",
          "Ying Wang",
          "Shirui Pan",
          "Xin Wang"
        ],
        "published_date": "2024",
        "abstract": "To build safe and reliable graph machine learning systems, unsupervised graph-level anomaly detection (GLAD) and unsupervised graph-level out-of-distribution (OOD) detection (GLOD) have received significant attention in recent years. Though those two lines of research indeed share the same objective, they have been studied independently in the community due to distinct evaluation setups, creating a gap that hinders the application and evaluation of methods from one to the other. To bridge the gap, in this work, we present a \\underline{\\textbf{U}}nified \\underline{\\textbf{B}}enchmark for unsupervised \\underline{\\textbf{G}}raph-level \\underline{\\textbf{O}}OD and anoma\\underline{\\textbf{L}}y \\underline{\\textbf{D}}etection (\\ourmethod), a comprehensive evaluation framework that unifies GLAD and GLOD under the concept of generalized graph-level OOD detection. Our benchmark encompasses 35 datasets spanning four practical anomaly and OOD detection scenarios, facilitating the comparison of 18 representative GLAD/GLOD methods. We conduct multi-dimensional analyses to explore the effectiveness, OOD sensitivity spectrum, robustness, and efficiency of existing methods, shedding light on their strengths and limitations. Furthermore, we provide an open-source codebase (https://github.com/UB-GOLD/UB-GOLD) of \\ourmethod to foster reproducible research and outline potential directions for future investigations based on our insights.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/d212c555293b81f845b3c99af4e922b0fcdb4290.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 14,
        "score": 14.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Unsupervised graph-level anomaly detection (GLAD) and unsupervised graph-level out-of-distribution (GLOD) detection, despite sharing the same objective of identifying anomalous or out-of-distribution graphs, have been studied independently with distinct evaluation setups. This creates a significant gap that hinders cross-application and comprehensive evaluation of methods from one domain to the other \\cite{wang2024q01}.\n    *   **Importance and Challenge**: Building safe and reliable graph machine learning systems necessitates robust GLAD and GLOD capabilities. The universality of distribution shifts in real-world graph data (e.g., drug discovery, cyber-attack detection) makes these tasks crucial. The challenge lies in the lack of a unified framework to systematically compare and understand the strengths and limitations of existing methods across these conceptually linked problems \\cite{wang2024q01}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself within the broader context of \"generalized OOD detection,\" acknowledging that GLAD and GLOD are two branches of this concept. Existing GLAD methods primarily focus on unsupervised paradigms due to the scarcity of labeled anomalies. GLOD methods exist as both post-hoc detectors (requiring trained GNN classifiers and labeled ID data) and unsupervised OOD-specific models (trained only on unlabeled ID data) \\cite{wang2024q01}.\n    *   **Limitations of Previous Solutions**: Previous GLAD and GLOD studies suffer from distinct evaluation setups, making direct comparison and understanding of their generalizability difficult. Many GLOD methods rely on labeled ID data for training backbone GNNs, limiting their applicability in unsupervised scenarios. The lack of a unified benchmark prevents a holistic understanding of method performance across diverse anomaly and OOD scenarios \\cite{wang2024q01}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper introduces UB-GOLD (Unified Benchmark for unsupervised Graph-level OOD and anoma LyDetection), a comprehensive evaluation framework that unifies GLAD and GLOD under the concept of \"generalized graph-level OOD detection\" \\cite{wang2024q01}.\n    *   **Novelty/Difference**: UB-GOLD's innovation lies in its unification of these two previously separate fields. It defines four practical anomaly and OOD detection scenarios:\n        1.  **Intrinsic Anomaly (Type I)**: Datasets with naturally occurring semantic anomalies (e.g., toxic molecules).\n        2.  **Class-based Anomaly (Type II)**: Datasets where a minority or distinct class is designated as anomalous.\n        3.  **Inter-Dataset Shift (Type III)**: Simulating distribution shifts by drawing ID and OOD samples from different datasets within the same domain.\n        4.  **Intra-Dataset Shift (Type IV)**: Datasets with intrinsic distribution shifts regarding graph sizes, molecular scaffolds, or protein targets \\cite{wang2024q01}.\n        This unified framework allows for a fair and comprehensive comparison of diverse methods.\n\n*   **Key Technical Contributions**\n    *   **Novel Benchmark**: Introduction of UB-GOLD, the first comprehensive and unified benchmark for unsupervised GLAD and GLOD, encompassing 35 datasets across four distinct anomaly and OOD detection scenarios \\cite{wang2024q01}.\n    *   **Multi-dimensional Analysis Framework**: Development and execution of a systematic analysis framework to evaluate existing methods across multiple dimensions: effectiveness on different datasets, OOD sensitivity spectrum (near-OOD vs. far-OOD), robustness against unreliable training data (noisy ID data), and efficiency (time and memory usage) \\cite{wang2024q01}.\n    *   **Unified Codebase and Future Directions**: Provision of an open-source codebase for UB-GOLD to foster reproducible research and outlining potential future research directions based on the benchmark's insights \\cite{wang2024q01}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The benchmark facilitates the comparison of 18 representative GLAD/GLOD methods (including two-step methods like graph kernels with detectors, SSL with detectors, and end-to-end GNN-based GLAD/GLOD methods) across 35 datasets spanning the four defined scenarios. Multi-dimensional analyses were performed to assess OOD sensitivity, robustness to noisy training data, and efficiency \\cite{wang2024q01}.\n    *   **Key Performance Metrics and Results**: While specific metrics (e.g., AUC-ROC) are implied for anomaly/OOD detection, the paper highlights key observations:\n        *   SOTA GLAD/GLOD methods show excellent performance across tasks.\n        *   Near-OOD samples are consistently harder to detect than far-OOD samples.\n        *   Most methods are vulnerable to perturbations in training sets (i.e., noisy ID data).\n        *   Certain end-to-end methods demonstrate superior performance and computational efficiency compared to two-step methods \\cite{wang2024q01}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The benchmark primarily focuses on *unsupervised* graph-level anomaly and OOD detection, aligning with real-world scenarios where labeled data is scarce. It does not extensively cover supervised or semi-supervised paradigms \\cite{wang2024q01}.\n    *   **Scope of Applicability**: UB-GOLD's scenarios cover intrinsic anomalies, class-based anomalies, and inter/intra-dataset distribution shifts, providing a broad but not exhaustive coverage of all possible anomaly or OOD types. The selection of 18 methods, while representative, does not include every single GLAD/GLOD method ever proposed \\cite{wang2024q01}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: UB-GOLD significantly advances the technical state-of-the-art by bridging the conceptual and practical gap between GLAD and GLOD. It provides a standardized, unified framework for rigorous evaluation, enabling a clearer understanding of method capabilities and limitations across diverse scenarios \\cite{wang2024q01}.\n    *   **Potential Impact on Future Research**: The benchmark's multi-dimensional analyses and key findings offer critical insights, guiding future research towards developing more robust, efficient, and sensitive GLAD/GLOD methods. The open-source codebase promotes reproducible research and facilitates rapid prototyping and comparison of new approaches, fostering innovation in building safer and more reliable graph machine learning systems \\cite{wang2024q01}.",
        "keywords": [
          "Unsupervised graph-level anomaly detection (GLAD)",
          "unsupervised graph-level out-of-distribution (GLOD) detection",
          "generalized graph-level OOD detection",
          "UB-GOLD",
          "unified evaluation framework",
          "distribution shifts",
          "graph machine learning systems",
          "four anomaly/OOD detection scenarios",
          "multi-dimensional analysis",
          "noisy ID data robustness",
          "near-OOD detection",
          "end-to-end GNN methods",
          "open-source codebase"
        ],
        "paper_type": "the paper introduces a \"unified benchmark for unsupervised graph-level ood and anomaly detection (ub-gold),\" which is described as a \"comprehensive evaluation framework.\" while the creation of this framework could be seen as a technical contribution (a new system/methodology), the abstract and introduction heavily emphasize the *application* of this benchmark.\n\nkey phrases supporting an **empirical** classification:\n*   \"benchmark encompasses 35 datasets\"\n*   \"facilitating the comparison of 18 representative glad/glod methods\"\n*   \"we conduct multi-dimensional analyses to explore the effectiveness, ood sensitivity spectrum, robustness, and efficiency of existing methods, shedding light on their strengths and limitations.\"\n*   this directly aligns with the \"empirical\" criteria: \"data-driven studies with statistical analysis,\" \"experiment,\" \"data,\" and \"findings.\" the paper is performing a large-scale, data-driven study to evaluate and compare existing methods using the newly proposed benchmark.\n\nwhile the benchmark itself is a technical artifact, the primary focus described in the abstract and introduction is on the *results and insights derived from using it* to conduct a comprehensive study of existing methods.\n\nthe final classification is **empirical**."
      },
      "file_name": "d212c555293b81f845b3c99af4e922b0fcdb4290.pdf"
    },
    {
      "success": true,
      "doc_id": "0d3d553957697ef0ae4507874994a708",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of **Out-of-Distribution (OOD) detection in Generative Language Models (GLMs) specifically for mathematical reasoning tasks** \\cite{wang2024rej}.\n    *   This problem is important because OOD data poses security threats to deep networks, leading to unexpected performance deterioration and harmful outcomes in real-world GLM applications \\cite{wang2024rej}.\n    *   It is particularly challenging in mathematical reasoning due to unique phenomena:\n        *   **Vague clustering features in the input space**, making it difficult for embeddings to capture question complexity \\cite{wang2024rej}.\n        *   **High-density characteristics and significant overlap (\"Pattern Collapse\") in the output space** \\cite{wang2024rej}. Mathematical outputs are symbolic, compressing the search space and increasing overlap, while shared mathematical tokens (digits, symbols) lack diverse linguistic features for distinction \\cite{wang2024rej}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods for GLMs primarily focus on traditional text generation (e.g., summarization, translation) and fall into two categories: **uncertainty estimation** and **embedding distance measurement** \\cite{wang2024rej}.\n    *   Embedding-based methods, like calculating Mahalanobis Distance in static input/output spaces, have been shown effective for traditional text generation \\cite{wang2024rej}.\n    *   However, these **traditional embedding-based methods are rendered inapplicable** in mathematical reasoning due to the \"Pattern Collapse\" phenomenon in the output space, where distinct samples converge to a high-density region, making static embedding distances less discriminative \\cite{wang2024rej}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **TV Score (Trajectory Volatility Score)**, which shifts focus from static embedding space to the **dynamic embedding trajectory** \\cite{wang2024rej}.\n    *   The approach leverages the insight that \"pattern collapse\" in mathematical reasoning causes significant trajectory differences between samples, even if their endpoints converge \\cite{wang2024rej}.\n    *   It defines **embedding trajectory** as a progressive chain of average embeddings across GLM layers ($y_0 \\to y_1 \\to \\dots \\to y_L$) \\cite{wang2024rej}.\n    *   The TV Score is calculated by:\n        1.  Fitting ID embeddings at each layer to a Gaussian distribution ($G_l = N(\\mu_l, \\Sigma_l)$) \\cite{wang2024rej}.\n        2.  Mapping a new sample's embedding at each layer ($y_l$) to its Mahalanobis Distance ($f(y_l)$) with respect to $G_l$ \\cite{wang2024rej}.\n        3.  Averaging the absolute differences of these Mahalanobis Distances between adjacent layers ($|f(y_l) - f(y_{l-1})|$) to get the final TV Score \\cite{wang2024rej}.\n    *   An enhanced version, **TV Score w/ DiSmo (Differential Smoothing)**, is introduced to mitigate the impact of trajectory outliers by applying higher-order differential smoothing techniques to the embeddings before calculating the Mahalanobis Distances \\cite{wang2024rej}.\n\n*   **Key Technical Contributions**\n    *   **Novel OOD detection algorithm (TV Score)** specifically designed for mathematical reasoning in GLMs, leveraging dynamic embedding trajectories rather than static embeddings \\cite{wang2024rej}.\n    *   **Theoretical insight and proof** (Theorem 2.1) demonstrating that \"pattern collapse\" in the output space increases the probability of trajectory volatility differences across samples, providing a foundation for the method \\cite{wang2024rej}.\n    *   **Empirical discovery of \"Early Stabilization\"**: ID samples exhibit a pattern where GLMs largely complete reasoning in mid-to-late stages, followed by suppressed embedding changes, while OOD samples maintain high volatility, indicating incomplete reasoning \\cite{wang2024rej}. This phenomenon provides direct evidence for the efficacy of trajectory-based measures.\n    *   Introduction of **Differential Smoothing** to enhance trajectory smoothness and robustness against outliers \\cite{wang2024rej}.\n\n*   **Experimental Validation**\n    *   Experiments were conducted using **Llama2-7B** as the backbone GLM \\cite{wang2024rej}.\n    *   **MultiArith** was used as the in-distribution (ID) dataset \\cite{wang2024rej}.\n    *   A diverse set of OOD datasets were used, covering:\n        *   **Far-shift OOD scenarios**: MATH dataset (Algebra, Geometry, Counting and Probability, Number Theory, Precalculus) \\cite{wang2024rej}.\n        *   **Near-shift OOD scenarios**: GSM8K, SVAMP, AddSub, SingleEq, SingleOp \\cite{wang2024rej}.\n    *   The paper reports that the **TV Score method outperforms all traditional OOD detection algorithms** on GLMs under mathematical reasoning scenarios \\cite{wang2024rej}.\n    *   The method's effectiveness was also demonstrated in the challenging scenario of OOD quality estimation \\cite{wang2024rej}.\n\n*   **Limitations & Scope**\n    *   The paper implicitly assumes the existence of \"high-density features in output spaces\" as a condition for its applicability, which is characteristic of mathematical reasoning \\cite{wang2024rej}.\n    *   While effective for mathematical reasoning, the method's direct applicability to tasks without \"pattern collapse\" or high-density output features might require further investigation.\n    *   The scope of applicability is explicitly extended to **other applications with high-density features in output spaces, such as multiple-choice questions** \\cite{wang2024rej}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a **novel and effective OOD detection solution for GLMs in complex generative tasks like mathematical reasoning**, where traditional methods fail \\cite{wang2024rej}.\n    *   It introduces the **concept of embedding trajectory volatility** as a powerful discriminative feature, moving beyond static embedding analysis \\cite{wang2024rej}.\n    *   The theoretical and empirical insights into \"pattern collapse\" and \"early stabilization\" offer a deeper understanding of GLM behavior in mathematical reasoning, potentially impacting future research in robust GLM design and OOD detection for other challenging domains \\cite{wang2024rej}.",
      "intriguing_abstract": "Generative Language Models (GLMs) face significant security and reliability risks from Out-of-Distribution (OOD) inputs, particularly in critical domains like mathematical reasoning. Traditional OOD detection methods, relying on static embedding distances, catastrophically fail here due to a unique phenomenon we term \"Pattern Collapse\"â€”where diverse mathematical outputs converge into a high-density, indistinguishable region in the embedding space.\n\nWe introduce **TV Score (Trajectory Volatility Score)**, a novel OOD detection algorithm that fundamentally shifts focus from static embeddings to the *dynamic embedding trajectory* across GLM layers. Our method leverages the critical insight that even when output embeddings collapse, the *volatility* of their intermediate layer-wise trajectories remains highly discriminative. We theoretically prove this phenomenon and empirically discover \"Early Stabilization\" in in-distribution samples, contrasting with sustained volatility in OOD samples. TV Score calculates the average absolute Mahalanobis Distance differences between adjacent layer embeddings, further enhanced by **Differential Smoothing (DiSmo)** for robustness.\n\nEvaluated on Llama2-7B across diverse mathematical reasoning datasets, TV Score dramatically outperforms all existing OOD detection algorithms. This work not only provides a robust solution for OOD detection in mathematical GLMs but also offers profound insights into their internal reasoning processes, with implications for other high-density output tasks like multiple-choice questions.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Generative Language Models (GLMs)",
        "mathematical reasoning tasks",
        "Pattern Collapse",
        "embedding trajectory",
        "TV Score (Trajectory Volatility Score)",
        "Differential Smoothing (DiSmo)",
        "Early Stabilization",
        "dynamic embedding analysis",
        "high-density output features",
        "Mahalanobis Distance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/d2d056e705902d33d769206489d53e0659e376cc.pdf",
      "citation_key": "wang2024rej",
      "metadata": {
        "title": "Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning",
        "authors": [
          "Yiming Wang",
          "Pei Zhang",
          "Baosong Yang",
          "Derek F. Wong",
          "Zhuosheng Zhang",
          "Rui Wang"
        ],
        "published_date": "2024",
        "abstract": "Real-world data deviating from the independent and identically distributed (i.i.d.) assumption of in-distribution training data poses security threats to deep networks, thus advancing out-of-distribution (OOD) detection algorithms. Detection methods in generative language models (GLMs) mainly focus on uncertainty estimation and embedding distance measurement, with the latter proven to be most effective in traditional linguistic tasks like summarization and translation. However, another complex generative scenario mathematical reasoning poses significant challenges to embedding-based methods due to its high-density feature of output spaces, but this feature causes larger discrepancies in the embedding shift trajectory between different samples in latent spaces. Hence, we propose a trajectory-based method TV score, which uses trajectory volatility for OOD detection in mathematical reasoning. Experiments show that our method outperforms all traditional algorithms on GLMs under mathematical reasoning scenarios and can be extended to more applications with high-density features in output spaces, such as multiple-choice questions.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/d2d056e705902d33d769206489d53e0659e376cc.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 12,
        "score": 12.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of **Out-of-Distribution (OOD) detection in Generative Language Models (GLMs) specifically for mathematical reasoning tasks** \\cite{wang2024rej}.\n    *   This problem is important because OOD data poses security threats to deep networks, leading to unexpected performance deterioration and harmful outcomes in real-world GLM applications \\cite{wang2024rej}.\n    *   It is particularly challenging in mathematical reasoning due to unique phenomena:\n        *   **Vague clustering features in the input space**, making it difficult for embeddings to capture question complexity \\cite{wang2024rej}.\n        *   **High-density characteristics and significant overlap (\"Pattern Collapse\") in the output space** \\cite{wang2024rej}. Mathematical outputs are symbolic, compressing the search space and increasing overlap, while shared mathematical tokens (digits, symbols) lack diverse linguistic features for distinction \\cite{wang2024rej}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods for GLMs primarily focus on traditional text generation (e.g., summarization, translation) and fall into two categories: **uncertainty estimation** and **embedding distance measurement** \\cite{wang2024rej}.\n    *   Embedding-based methods, like calculating Mahalanobis Distance in static input/output spaces, have been shown effective for traditional text generation \\cite{wang2024rej}.\n    *   However, these **traditional embedding-based methods are rendered inapplicable** in mathematical reasoning due to the \"Pattern Collapse\" phenomenon in the output space, where distinct samples converge to a high-density region, making static embedding distances less discriminative \\cite{wang2024rej}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **TV Score (Trajectory Volatility Score)**, which shifts focus from static embedding space to the **dynamic embedding trajectory** \\cite{wang2024rej}.\n    *   The approach leverages the insight that \"pattern collapse\" in mathematical reasoning causes significant trajectory differences between samples, even if their endpoints converge \\cite{wang2024rej}.\n    *   It defines **embedding trajectory** as a progressive chain of average embeddings across GLM layers ($y_0 \\to y_1 \\to \\dots \\to y_L$) \\cite{wang2024rej}.\n    *   The TV Score is calculated by:\n        1.  Fitting ID embeddings at each layer to a Gaussian distribution ($G_l = N(\\mu_l, \\Sigma_l)$) \\cite{wang2024rej}.\n        2.  Mapping a new sample's embedding at each layer ($y_l$) to its Mahalanobis Distance ($f(y_l)$) with respect to $G_l$ \\cite{wang2024rej}.\n        3.  Averaging the absolute differences of these Mahalanobis Distances between adjacent layers ($|f(y_l) - f(y_{l-1})|$) to get the final TV Score \\cite{wang2024rej}.\n    *   An enhanced version, **TV Score w/ DiSmo (Differential Smoothing)**, is introduced to mitigate the impact of trajectory outliers by applying higher-order differential smoothing techniques to the embeddings before calculating the Mahalanobis Distances \\cite{wang2024rej}.\n\n*   **Key Technical Contributions**\n    *   **Novel OOD detection algorithm (TV Score)** specifically designed for mathematical reasoning in GLMs, leveraging dynamic embedding trajectories rather than static embeddings \\cite{wang2024rej}.\n    *   **Theoretical insight and proof** (Theorem 2.1) demonstrating that \"pattern collapse\" in the output space increases the probability of trajectory volatility differences across samples, providing a foundation for the method \\cite{wang2024rej}.\n    *   **Empirical discovery of \"Early Stabilization\"**: ID samples exhibit a pattern where GLMs largely complete reasoning in mid-to-late stages, followed by suppressed embedding changes, while OOD samples maintain high volatility, indicating incomplete reasoning \\cite{wang2024rej}. This phenomenon provides direct evidence for the efficacy of trajectory-based measures.\n    *   Introduction of **Differential Smoothing** to enhance trajectory smoothness and robustness against outliers \\cite{wang2024rej}.\n\n*   **Experimental Validation**\n    *   Experiments were conducted using **Llama2-7B** as the backbone GLM \\cite{wang2024rej}.\n    *   **MultiArith** was used as the in-distribution (ID) dataset \\cite{wang2024rej}.\n    *   A diverse set of OOD datasets were used, covering:\n        *   **Far-shift OOD scenarios**: MATH dataset (Algebra, Geometry, Counting and Probability, Number Theory, Precalculus) \\cite{wang2024rej}.\n        *   **Near-shift OOD scenarios**: GSM8K, SVAMP, AddSub, SingleEq, SingleOp \\cite{wang2024rej}.\n    *   The paper reports that the **TV Score method outperforms all traditional OOD detection algorithms** on GLMs under mathematical reasoning scenarios \\cite{wang2024rej}.\n    *   The method's effectiveness was also demonstrated in the challenging scenario of OOD quality estimation \\cite{wang2024rej}.\n\n*   **Limitations & Scope**\n    *   The paper implicitly assumes the existence of \"high-density features in output spaces\" as a condition for its applicability, which is characteristic of mathematical reasoning \\cite{wang2024rej}.\n    *   While effective for mathematical reasoning, the method's direct applicability to tasks without \"pattern collapse\" or high-density output features might require further investigation.\n    *   The scope of applicability is explicitly extended to **other applications with high-density features in output spaces, such as multiple-choice questions** \\cite{wang2024rej}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a **novel and effective OOD detection solution for GLMs in complex generative tasks like mathematical reasoning**, where traditional methods fail \\cite{wang2024rej}.\n    *   It introduces the **concept of embedding trajectory volatility** as a powerful discriminative feature, moving beyond static embedding analysis \\cite{wang2024rej}.\n    *   The theoretical and empirical insights into \"pattern collapse\" and \"early stabilization\" offer a deeper understanding of GLM behavior in mathematical reasoning, potentially impacting future research in robust GLM design and OOD detection for other challenging domains \\cite{wang2024rej}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Generative Language Models (GLMs)",
          "mathematical reasoning tasks",
          "Pattern Collapse",
          "embedding trajectory",
          "TV Score (Trajectory Volatility Score)",
          "Differential Smoothing (DiSmo)",
          "Early Stabilization",
          "dynamic embedding analysis",
          "high-density output features",
          "Mahalanobis Distance"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the **abstract** explicitly states: \"hence, we **propose** a trajectory-based method tv score, which uses trajectory volatility for ood detection in mathematical reasoning. experiments show that our method outperforms all traditional algorithms...\"\n*   the **introduction** sets up a technical problem (ood detection in glms, especially for mathematical reasoning) and discusses the limitations of existing methods, paving the way for a new solution.\n\nthese elements strongly indicate that the paper presents a new method or algorithm.\n\ntherefore, the paper type is: **technical**"
      },
      "file_name": "d2d056e705902d33d769206489d53e0659e376cc.pdf"
    },
    {
      "success": true,
      "doc_id": "31bf48bbdb15ab13692e0b216a6ad0b6",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Deep learning models in medical image analysis often fail silently when encountering out-of-distribution (OOD) samples, as they are typically trained under the assumption that test data comes from the same distribution as training data. This leads to unreliable predictions and potential misdiagnosis in real-world clinical scenarios.\n    *   **Importance & Challenge:** The problem is critical for developing trustworthy medical AI systems that can identify unsuitable inputs and defer to human experts. The challenge lies in the diverse nature of distributional shifts in medical imaging, the lack of a systematic framework to categorize these shifts and existing solutions, and inconsistent terminology in the literature \\cite{hong2024xls}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper acknowledges foundational OOD detection methods (e.g., Maximum Probability Score \\cite{hong2024xls}, Mahalanobis distance \\cite{hong2024xls}, Outlier Exposure \\cite{hong2024xls}, energy score \\cite{hong2024xls}) and recent advancements (e.g., vision transformers \\cite{hong2024xls}, multi-modal learning \\cite{hong2024xls}).\n    *   **Limitations of Previous Solutions/Surveys:**\n        *   Existing general OOD detection frameworks (e.g., \\cite{hong2024xls}) overlook medical image analysis.\n        *   Prior medical image OOD reviews (e.g., \\cite{hong2024xls}) are deemed \"excessively incomprehensive,\" lacking a robust problem formulation, a well-organized solution framework, and discussions on evaluation protocols, challenges, and future directions.\n        *   Surveys on Anomaly Detection (AD) in medical imaging often treat AD as a base task rather than an auxiliary function for OOD detection.\n        *   Uncertainty Quantification (UQ) surveys are broader, and many UQ methods are shown to fail in detecting OOD samples or degrade under distributional shifts \\cite{hong2024xls}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method (of the survey):** The paper proposes a systematic framework for understanding and categorizing OOD detection in medical image analysis. This involves:\n        *   Identifying seven key factors that cause distributional shifts in clinical scenarios (Modality, Area of concern, Imaging view, Image quality, Acquisition protocols and pre-processing, Class of target, Patient population).\n        *   Defining three types of distributional shiftsâ€”semantic shift, covariate shift, and contextual shiftâ€”based on these factors, expanding a generalized OOD detection framework \\cite{hong2024xls} to the medical domain.\n        *   Suggesting a solution framework to organize existing research based on methodology taxonomy and its association with the base task model.\n    *   **Novelty:** The primary innovation is the creation of a comprehensive and structured problem formulation and taxonomy specifically tailored for OOD detection in medical image analysis. This addresses the current ambiguity and lack of systematic organization in the field, providing clear definitions and distinctions between OOD, AD, and UQ in this context \\cite{hong2024xls}.\n\n*   **Key Technical Contributions**\n    *   **Novel Problem Formulation:** Definition of seven critical distributional shift factors in medical imaging and the proposal of three distinct OOD types (semantic, covariate, contextual shift) derived from these factors, extending existing OOD frameworks \\cite{hong2024xls}.\n    *   **System Design/Architectural Innovations (for the field):** A proposed solution framework to categorize and feature existing OOD detection solutions based on methodology taxonomy and their relationship with the base task model.\n    *   **Systematic Review:** A systematic review of existing studies, focusing on technical details and experimental settings (though the detailed review content is not provided in the excerpt, the *contribution* is the systematic review itself).\n    *   **Evaluation Protocols & Metrics Summary:** A summary of evaluation protocols, metrics, and corresponding test samples used in previous studies for the three proposed OOD types.\n    *   **Identification of Challenges and Future Directions:** Discussion of current challenges and identification of under-explored research avenues.\n\n*   **Experimental Validation**\n    *   As a survey paper, it does not present its own experimental validation of new OOD detection algorithms.\n    *   Instead, a key contribution is the *summary and analysis of experimental validation* from the reviewed literature. The paper explicitly states it will summarize \"evaluation protocols, metrics, and test samples corresponding to three proposed OOD types used in the previous studies\" \\cite{hong2024xls}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The survey's scope is limited to OOD detection in supervised medical image classification and medical image segmentation tasks.\n    *   **Scope of Applicability:** It explicitly excludes \"Anomaly Detection (AD)-based pathology detection\" where AD is the base task, and \"Uncertainty Quantification (UQ)\" research that does not explicitly consider OOD detection, arguing these are distinct concepts \\cite{hong2024xls}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This survey significantly advances the technical state-of-the-art by providing the first systematic and comprehensive framework for OOD detection in medical image analysis. It clarifies ambiguous terminology, distinguishes OOD from related concepts, and offers a structured approach to understanding distributional shifts in this critical domain \\cite{hong2024xls}.\n    *   **Potential Impact on Future Research:** By defining clear problem formulations, categorizing shift types, and summarizing evaluation practices, the paper lays a robust foundation for future research. It guides researchers in developing more effective and trustworthy medical AI systems by highlighting key challenges and under-explored directions, ultimately aiming to improve diagnostic reliability and patient safety \\cite{hong2024xls}.",
      "intriguing_abstract": "Deep learning models in medical image analysis face a critical bottleneck: their silent failures when encountering out-of-distribution (OOD) samples, leading to unreliable predictions and potential misdiagnosis. Addressing the urgent need for trustworthy medical AI, this paper presents the first comprehensive and systematic framework for OOD detection in this challenging domain. We meticulously identify seven key factors driving distributional shifts in clinical scenarios and propose a novel taxonomy of three distinct OOD types: semantic, covariate, and contextual shifts. Our framework provides unprecedented clarity, distinguishing OOD detection from related concepts like Anomaly Detection (AD) and Uncertainty Quantification (UQ). Through a systematic review, we categorize existing solutions and summarize evaluation protocols, offering a structured understanding of the field. This work lays a robust foundation for developing reliable medical AI systems, guiding researchers toward more effective OOD detection methods, ultimately enhancing diagnostic accuracy and patient safety.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "medical image analysis",
        "distributional shifts",
        "systematic framework",
        "novel problem formulation",
        "taxonomy",
        "semantic covariate contextual shifts",
        "trustworthy medical AI",
        "solution framework",
        "evaluation protocols",
        "deep learning reliability",
        "clinical misdiagnosis prevention",
        "Anomaly Detection (AD) and Uncertainty Quantification (UQ) distinction"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/70da774b2b30397ee2f7e2abc819ed126641a70d.pdf",
      "citation_key": "hong2024xls",
      "metadata": {
        "title": "Out-of-distribution Detection in Medical Image Analysis: A survey",
        "authors": [
          "Zesheng Hong",
          "Yubiao Yue",
          "Yubin Chen",
          "Huanjie Lin",
          "Yuanmei Luo",
          "Mini Han Wang",
          "Weidong Wang",
          "Jialong Xu",
          "Xiaoqi Yang",
          "Zhenzhang Li",
          "Sihong Xie"
        ],
        "published_date": "2024",
        "abstract": "Computer-aided diagnostics has benefited from the development of deep learning-based computer vision techniques in these years. Traditional supervised deep learning methods assume that the test sample is drawn from the identical distribution as the training data. However, it is possible to encounter out-of-distribution samples in real-world clinical scenarios, which may cause silent failure in deep learning-based medical image analysis tasks. Recently, research has explored various out-of-distribution (OOD) detection situations and techniques to enable a trustworthy medical AI system. In this survey, we systematically review the recent advances in OOD detection in medical image analysis. We first explore several factors that may cause a distributional shift when using a deep-learning-based model in clinic scenarios, with three different types of distributional shift well defined on top of these factors. Then a framework is suggested to categorize and feature existing solutions, while the previous studies are reviewed based on the methodology taxonomy. Our discussion also includes evaluation protocols and metrics, as well as the challenge and a research direction lack of exploration.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/70da774b2b30397ee2f7e2abc819ed126641a70d.pdf",
        "venue": "arXiv.org",
        "citationCount": 12,
        "score": 12.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Deep learning models in medical image analysis often fail silently when encountering out-of-distribution (OOD) samples, as they are typically trained under the assumption that test data comes from the same distribution as training data. This leads to unreliable predictions and potential misdiagnosis in real-world clinical scenarios.\n    *   **Importance & Challenge:** The problem is critical for developing trustworthy medical AI systems that can identify unsuitable inputs and defer to human experts. The challenge lies in the diverse nature of distributional shifts in medical imaging, the lack of a systematic framework to categorize these shifts and existing solutions, and inconsistent terminology in the literature \\cite{hong2024xls}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper acknowledges foundational OOD detection methods (e.g., Maximum Probability Score \\cite{hong2024xls}, Mahalanobis distance \\cite{hong2024xls}, Outlier Exposure \\cite{hong2024xls}, energy score \\cite{hong2024xls}) and recent advancements (e.g., vision transformers \\cite{hong2024xls}, multi-modal learning \\cite{hong2024xls}).\n    *   **Limitations of Previous Solutions/Surveys:**\n        *   Existing general OOD detection frameworks (e.g., \\cite{hong2024xls}) overlook medical image analysis.\n        *   Prior medical image OOD reviews (e.g., \\cite{hong2024xls}) are deemed \"excessively incomprehensive,\" lacking a robust problem formulation, a well-organized solution framework, and discussions on evaluation protocols, challenges, and future directions.\n        *   Surveys on Anomaly Detection (AD) in medical imaging often treat AD as a base task rather than an auxiliary function for OOD detection.\n        *   Uncertainty Quantification (UQ) surveys are broader, and many UQ methods are shown to fail in detecting OOD samples or degrade under distributional shifts \\cite{hong2024xls}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method (of the survey):** The paper proposes a systematic framework for understanding and categorizing OOD detection in medical image analysis. This involves:\n        *   Identifying seven key factors that cause distributional shifts in clinical scenarios (Modality, Area of concern, Imaging view, Image quality, Acquisition protocols and pre-processing, Class of target, Patient population).\n        *   Defining three types of distributional shiftsâ€”semantic shift, covariate shift, and contextual shiftâ€”based on these factors, expanding a generalized OOD detection framework \\cite{hong2024xls} to the medical domain.\n        *   Suggesting a solution framework to organize existing research based on methodology taxonomy and its association with the base task model.\n    *   **Novelty:** The primary innovation is the creation of a comprehensive and structured problem formulation and taxonomy specifically tailored for OOD detection in medical image analysis. This addresses the current ambiguity and lack of systematic organization in the field, providing clear definitions and distinctions between OOD, AD, and UQ in this context \\cite{hong2024xls}.\n\n*   **Key Technical Contributions**\n    *   **Novel Problem Formulation:** Definition of seven critical distributional shift factors in medical imaging and the proposal of three distinct OOD types (semantic, covariate, contextual shift) derived from these factors, extending existing OOD frameworks \\cite{hong2024xls}.\n    *   **System Design/Architectural Innovations (for the field):** A proposed solution framework to categorize and feature existing OOD detection solutions based on methodology taxonomy and their relationship with the base task model.\n    *   **Systematic Review:** A systematic review of existing studies, focusing on technical details and experimental settings (though the detailed review content is not provided in the excerpt, the *contribution* is the systematic review itself).\n    *   **Evaluation Protocols & Metrics Summary:** A summary of evaluation protocols, metrics, and corresponding test samples used in previous studies for the three proposed OOD types.\n    *   **Identification of Challenges and Future Directions:** Discussion of current challenges and identification of under-explored research avenues.\n\n*   **Experimental Validation**\n    *   As a survey paper, it does not present its own experimental validation of new OOD detection algorithms.\n    *   Instead, a key contribution is the *summary and analysis of experimental validation* from the reviewed literature. The paper explicitly states it will summarize \"evaluation protocols, metrics, and test samples corresponding to three proposed OOD types used in the previous studies\" \\cite{hong2024xls}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The survey's scope is limited to OOD detection in supervised medical image classification and medical image segmentation tasks.\n    *   **Scope of Applicability:** It explicitly excludes \"Anomaly Detection (AD)-based pathology detection\" where AD is the base task, and \"Uncertainty Quantification (UQ)\" research that does not explicitly consider OOD detection, arguing these are distinct concepts \\cite{hong2024xls}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This survey significantly advances the technical state-of-the-art by providing the first systematic and comprehensive framework for OOD detection in medical image analysis. It clarifies ambiguous terminology, distinguishes OOD from related concepts, and offers a structured approach to understanding distributional shifts in this critical domain \\cite{hong2024xls}.\n    *   **Potential Impact on Future Research:** By defining clear problem formulations, categorizing shift types, and summarizing evaluation practices, the paper lays a robust foundation for future research. It guides researchers in developing more effective and trustworthy medical AI systems by highlighting key challenges and under-explored directions, ultimately aiming to improve diagnostic reliability and patient safety \\cite{hong2024xls}.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "medical image analysis",
          "distributional shifts",
          "systematic framework",
          "novel problem formulation",
          "taxonomy",
          "semantic covariate contextual shifts",
          "trustworthy medical AI",
          "solution framework",
          "evaluation protocols",
          "deep learning reliability",
          "clinical misdiagnosis prevention",
          "Anomaly Detection (AD) and Uncertainty Quantification (UQ) distinction"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **survey**.\n\nhere's why:\n*   the **title** explicitly states: \"out-of-distribution detection in medical image analysis: a **survey**\"\n*   the **abstract** explicitly states: \"in this **survey**, we systematically **review** the recent advances in ood detection in medical image analysis.\"\n*   the **introduction** (which is a repeat of the abstract in the provided text) also states: \"in this **survey**, we systematically **review** the recent advances in ood detection in medical image analysis.\"\n*   it further mentions: \"then a framework is suggested to categorize and feature existing solutions, while the previous studies are reviewed based on the methodology taxonomy.\" this aligns perfectly with the \"literature organization, classification schemes\" mentioned in the criteria for a survey paper."
      },
      "file_name": "70da774b2b30397ee2f7e2abc819ed126641a70d.pdf"
    },
    {
      "success": true,
      "doc_id": "6379d548a8fdaa5a6fb80a0b8e5af558",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the challenge of Out-of-Distribution (OOD) detection using Vision-Language Models (VLMs), specifically focusing on the issue of **spurious OOD features** extracted from in-distribution (ID) data \\cite{yu20249dd}.\n    *   This problem is critical because deep neural networks are often overconfident on OOD data, posing risks in safety-critical applications. Existing CLIP-based OOD detection methods, which use prompt tuning and regularize with ID-irrelevant local context as surrogate OOD data, suffer from **imperfect foreground-background decomposition** by VLMs. This leads to unreliable OOD features, limiting detection performance \\cite{yu20249dd}.\n\n*   **Related Work & Positioning**\n    *   This work builds upon recent advances in prompt tuning for VLMs (e.g., CoOp) and VLM-based OOD detection methods like LoCoOp \\cite{yu20249dd} and IDLike \\cite{yu20249dd}.\n    *   Previous prompt tuning based OOD detection methods, such as LoCoOp \\cite{yu20249dd} and IDLike \\cite{yu20249dd}, are limited by the quality of surrogate OOD features. They suffer from **spurious OOD features** due to the imperfect foreground-background decomposition capabilities of VLMs, which can degrade OOD detection performance \\cite{yu20249dd}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **Self-Calibrated Tuning (SCT)** \\cite{yu20249dd}, a novel learning framework designed to mitigate the problem of spurious OOD features.\n    *   SCT introduces **modulating factors** (Ï• and Ïˆ) to adaptively adjust the importance of the two components of the original learning objective: the ID classification loss (Cross-Entropy) and the OOD regularization loss (negative entropy) \\cite{yu20249dd}.\n    *   The innovation lies in dynamically directing the optimization process based on the **prediction uncertainty** of ID data. When the model's prediction confidence for an ID sample is low, SCT emphasizes the ID classification task. Conversely, when confidence is high, it prioritizes OOD regularization. This mechanism calibrates the influence of potentially unreliable OOD features \\cite{yu20249dd}.\n    *   The proposed loss function is `LSCT = E(x,y)~Din [â„“CE(p(y|x;Ï‰), y) * Ï•(p(y|x;Ï‰)) + Î»â„“OOD(p(ËœX;Ï‰)) * Ïˆ(p(y|x;Ï‰))]` \\cite{yu20249dd}. A simple, effective instantiation uses `Ï•(p(y|x;Ï‰)) = (1 - p(y|x;Ï‰))` and `Ïˆ(p(y|x;Ï‰)) = p(y|x;Ï‰)`, introducing no extra hyperparameters \\cite{yu20249dd}.\n\n*   **Key Technical Contributions**\n    *   **Novel Learning Framework**: SCT \\cite{yu20249dd} provides an adaptive mechanism to balance ID classification and OOD regularization during prompt tuning, specifically addressing the issue of imperfect OOD features.\n    *   **Adaptive Weighting Scheme**: The introduction of uncertainty-based modulating factors allows for a self-calibrating optimization process, making the model more robust to noisy or spurious OOD regularization signals \\cite{yu20249dd}.\n    *   **Empirical Observation**: The paper conceptually investigates and empirically demonstrates that ID data with different prediction uncertainties distinctively influence OOD regularization, motivating the SCT design \\cite{yu202499dd}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed to characterize and demonstrate SCT's effectiveness, including comparisons with state-of-the-art prompt tuning based OOD detection methods and ablation studies \\cite{yu20249dd}.\n    *   **Key Performance Metrics**: The primary metric used is the False Positive Rate at 95% True Positive Rate (FPR95) \\cite{yu20249dd}.\n    *   **Comparison Results**: SCT significantly improves OOD detection performance, achieving a **3% improvement in FPR95** compared to the previous best method on the large-scale ImageNet-1k benchmark \\cite{yu20249dd}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The effectiveness relies on the accuracy of sample uncertainty estimation. While the chosen modulating functions are simple and effective, more complex relationships might exist (though other instantiations are explored in the appendix) \\cite{yu20249dd}. The method mitigates, rather than fundamentally solves, the underlying VLM calibration issue for foreground-background decomposition.\n    *   **Scope of Applicability**: SCT is compatible with many existing prompt tuning based OOD detection methods and is particularly relevant for scenarios with only few-shot ID data \\cite{yu20249dd}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: SCT significantly pushes the technical state-of-the-art in VLM-based OOD detection by providing a robust mechanism to handle the inherent unreliability of surrogate OOD features extracted from ID data \\cite{yu20249dd}.\n    *   **Potential Impact**: This self-calibrating approach offers a valuable paradigm for improving the reliability of machine learning models in open-world applications, especially where auxiliary OOD data is scarce or feature extraction is imperfect. It could inspire similar adaptive learning strategies in other domains facing data quality or feature uncertainty challenges \\cite{yu20249dd}.",
      "intriguing_abstract": "The pervasive overconfidence of deep neural networks on Out-of-Distribution (OOD) data poses significant risks, particularly in safety-critical Vision-Language Model (VLM) applications. Existing VLM-based **OOD detection** methods, relying on **prompt tuning** and ID-irrelevant local context for regularization, are severely hampered by **spurious OOD features** stemming from imperfect **foreground-background decomposition**. This fundamental limitation degrades detection performance.\n\nWe introduce **Self-Calibrated Tuning (SCT)**, a novel learning framework that dynamically mitigates this challenge. SCT employs adaptive **modulating factors** to intelligently balance ID classification and OOD regularization based on the model's **prediction uncertainty** for in-distribution data. When confidence is low, ID classification is prioritized; when high, OOD regularization takes precedence, effectively calibrating the influence of potentially unreliable OOD features. This self-calibrating mechanism significantly enhances robustness.\n\nEmpirical results demonstrate SCT's superiority, achieving a remarkable **3% improvement in FPR95** on ImageNet-1k compared to state-of-the-art methods. SCT provides a crucial advancement for reliable OOD detection, offering a vital paradigm for building trustworthy AI systems in open-world scenarios where data quality and feature uncertainty are paramount.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Vision-Language Models (VLMs)",
        "spurious OOD features",
        "Self-Calibrated Tuning (SCT)",
        "prompt tuning",
        "imperfect foreground-background decomposition",
        "prediction uncertainty",
        "adaptive weighting scheme",
        "OOD regularization",
        "modulating factors",
        "FPR95",
        "3% FPR95 improvement",
        "machine learning model reliability"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/be422ce2f64425f5c7bedf9a8498ab1e993060cc.pdf",
      "citation_key": "yu20249dd",
      "metadata": {
        "title": "Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection",
        "authors": [
          "Geng Yu",
          "Jianing Zhu",
          "Jiangchao Yao",
          "Bo Han"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is crucial for deploying reliable machine learning models in open-world applications. Recent advances in CLIP-based OOD detection have shown promising results via regularizing prompt tuning with OOD features extracted from ID data. However, the irrelevant context mined from ID data can be spurious due to the inaccurate foreground-background decomposition, thus limiting the OOD detection performance. In this work, we propose a novel framework, namely, Self-Calibrated Tuning (SCT), to mitigate this problem for effective OOD detection with only the given few-shot ID data. Specifically, SCT introduces modulating factors respectively on the two components of the original learning objective. It adaptively directs the optimization process between the two tasks during training on data with different prediction uncertainty to calibrate the influence of OOD regularization, which is compatible with many prompt tuning based OOD detection methods. Extensive experiments and analyses have been conducted to characterize and demonstrate the effectiveness of the proposed SCT. The code is publicly available.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/be422ce2f64425f5c7bedf9a8498ab1e993060cc.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 11,
        "score": 11.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the challenge of Out-of-Distribution (OOD) detection using Vision-Language Models (VLMs), specifically focusing on the issue of **spurious OOD features** extracted from in-distribution (ID) data \\cite{yu20249dd}.\n    *   This problem is critical because deep neural networks are often overconfident on OOD data, posing risks in safety-critical applications. Existing CLIP-based OOD detection methods, which use prompt tuning and regularize with ID-irrelevant local context as surrogate OOD data, suffer from **imperfect foreground-background decomposition** by VLMs. This leads to unreliable OOD features, limiting detection performance \\cite{yu20249dd}.\n\n*   **Related Work & Positioning**\n    *   This work builds upon recent advances in prompt tuning for VLMs (e.g., CoOp) and VLM-based OOD detection methods like LoCoOp \\cite{yu20249dd} and IDLike \\cite{yu20249dd}.\n    *   Previous prompt tuning based OOD detection methods, such as LoCoOp \\cite{yu20249dd} and IDLike \\cite{yu20249dd}, are limited by the quality of surrogate OOD features. They suffer from **spurious OOD features** due to the imperfect foreground-background decomposition capabilities of VLMs, which can degrade OOD detection performance \\cite{yu20249dd}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **Self-Calibrated Tuning (SCT)** \\cite{yu20249dd}, a novel learning framework designed to mitigate the problem of spurious OOD features.\n    *   SCT introduces **modulating factors** (Ï• and Ïˆ) to adaptively adjust the importance of the two components of the original learning objective: the ID classification loss (Cross-Entropy) and the OOD regularization loss (negative entropy) \\cite{yu20249dd}.\n    *   The innovation lies in dynamically directing the optimization process based on the **prediction uncertainty** of ID data. When the model's prediction confidence for an ID sample is low, SCT emphasizes the ID classification task. Conversely, when confidence is high, it prioritizes OOD regularization. This mechanism calibrates the influence of potentially unreliable OOD features \\cite{yu20249dd}.\n    *   The proposed loss function is `LSCT = E(x,y)~Din [â„“CE(p(y|x;Ï‰), y) * Ï•(p(y|x;Ï‰)) + Î»â„“OOD(p(ËœX;Ï‰)) * Ïˆ(p(y|x;Ï‰))]` \\cite{yu20249dd}. A simple, effective instantiation uses `Ï•(p(y|x;Ï‰)) = (1 - p(y|x;Ï‰))` and `Ïˆ(p(y|x;Ï‰)) = p(y|x;Ï‰)`, introducing no extra hyperparameters \\cite{yu20249dd}.\n\n*   **Key Technical Contributions**\n    *   **Novel Learning Framework**: SCT \\cite{yu20249dd} provides an adaptive mechanism to balance ID classification and OOD regularization during prompt tuning, specifically addressing the issue of imperfect OOD features.\n    *   **Adaptive Weighting Scheme**: The introduction of uncertainty-based modulating factors allows for a self-calibrating optimization process, making the model more robust to noisy or spurious OOD regularization signals \\cite{yu20249dd}.\n    *   **Empirical Observation**: The paper conceptually investigates and empirically demonstrates that ID data with different prediction uncertainties distinctively influence OOD regularization, motivating the SCT design \\cite{yu202499dd}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed to characterize and demonstrate SCT's effectiveness, including comparisons with state-of-the-art prompt tuning based OOD detection methods and ablation studies \\cite{yu20249dd}.\n    *   **Key Performance Metrics**: The primary metric used is the False Positive Rate at 95% True Positive Rate (FPR95) \\cite{yu20249dd}.\n    *   **Comparison Results**: SCT significantly improves OOD detection performance, achieving a **3% improvement in FPR95** compared to the previous best method on the large-scale ImageNet-1k benchmark \\cite{yu20249dd}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The effectiveness relies on the accuracy of sample uncertainty estimation. While the chosen modulating functions are simple and effective, more complex relationships might exist (though other instantiations are explored in the appendix) \\cite{yu20249dd}. The method mitigates, rather than fundamentally solves, the underlying VLM calibration issue for foreground-background decomposition.\n    *   **Scope of Applicability**: SCT is compatible with many existing prompt tuning based OOD detection methods and is particularly relevant for scenarios with only few-shot ID data \\cite{yu20249dd}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: SCT significantly pushes the technical state-of-the-art in VLM-based OOD detection by providing a robust mechanism to handle the inherent unreliability of surrogate OOD features extracted from ID data \\cite{yu20249dd}.\n    *   **Potential Impact**: This self-calibrating approach offers a valuable paradigm for improving the reliability of machine learning models in open-world applications, especially where auxiliary OOD data is scarce or feature extraction is imperfect. It could inspire similar adaptive learning strategies in other domains facing data quality or feature uncertainty challenges \\cite{yu20249dd}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Vision-Language Models (VLMs)",
          "spurious OOD features",
          "Self-Calibrated Tuning (SCT)",
          "prompt tuning",
          "imperfect foreground-background decomposition",
          "prediction uncertainty",
          "adaptive weighting scheme",
          "OOD regularization",
          "modulating factors",
          "FPR95",
          "3% FPR95 improvement",
          "machine learning model reliability"
        ],
        "paper_type": "**technical**"
      },
      "file_name": "be422ce2f64425f5c7bedf9a8498ab1e993060cc.pdf"
    },
    {
      "success": true,
      "doc_id": "7493cc0d29e877e6d4d3b84ebadd4357",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/b515fa73815185cc3d6559f2c6c0a1e122eb4786.pdf",
      "citation_key": "fan2024u9i",
      "metadata": {
        "title": "Test-Time Linear Out-of-Distribution Detection",
        "authors": [
          "Ke Fan",
          "Tong Liu",
          "Xingyu Qiu",
          "Yikai Wang",
          "Lian Huai",
          "Zeyu Shangguan",
          "Shuang Gou",
          "Fengjian Liu",
          "Yu Fu",
          "Yanwei Fu",
          "Xingqun Jiang"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b515fa73815185cc3d6559f2c6c0a1e122eb4786.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 11,
        "score": 11.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "b515fa73815185cc3d6559f2c6c0a1e122eb4786.pdf"
    },
    {
      "success": true,
      "doc_id": "851f7832500cd6decaa11a13ecc7fe8e",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: Deep Neural Networks (DNNs) are unreliable when encountering Out-of-Distribution (OoD) data, posing risks in sensitive applications. Existing Principal Component Analysis (PCA) methods applied directly to DNN features fail to effectively detect OoD data because In-Distribution (InD) and OoD features are not linearly separable in the original feature space.\n    *   **Motivation**: There is a critical need for robust OoD detection to ensure the trustworthiness and safe deployment of DNNs. The observed failure of linear PCA suggests that non-linear mappings are required to achieve better separability between InD and OoD features.\n\n*   **Related Work & Positioning**\n    *   **Relation**: This work builds upon feature-based OoD detection methods, specifically addressing the limitations of PCA reconstruction error approaches (e.g., as explored in [8]).\n    *   **Limitations of Previous Solutions**:\n        *   **PCA on raw features**: PCA applied directly to penultimate DNN features (z-space) yields poor OoD detection performance due to the linear inseparability of InD and OoD data \\cite{fang2024lv2}. Previous work [8] acknowledged this but resorted to fusion tricks rather than investigating the underlying non-linearity.\n        *   **General Kernel PCA (KPCA)**: Traditional KPCA faces significant computational challenges for large-scale data, requiring O(Ntr^2) space and O(Ntr^3) time complexity for kernel matrix operations, where Ntr is the number of training samples \\cite{fang2024lv2}. It also struggles with the non-trivial task of finding appropriate kernels without prior knowledge.\n        *   **k-Nearest Neighbors (KNN)**: While effective, KNN [7] has a high inference complexity of O(Ntr) because it requires storing and iterating through all training features for each new sample \\cite{fang2024lv2}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method**: The paper leverages Kernel PCA (KPCA) for OoD detection by applying specific non-linear feature mappings to the penultimate DNN features before performing PCA. The OoD score is then derived from the reconstruction error in this mapped space.\n    *   **Novelty & Innovation**:\n        *   **Task-Specific Kernels/Explicit Mappings**: The authors devise two effective non-linear feature mappings, inspired by a kernel perspective on the KNN detector [7]:\n            *   **Cosine Mapping (CoP)**: Recognizes that the `â„“2`-normalization crucial for KNN's success [7] induces a cosine kernel. PCA is then performed on these `â„“2`-normalized features `Ï•cos(z) = z/âˆ¥zâˆ¥2`.\n            *   **Cosine-Gaussian Mapping (CoRP)**: Further enhances separability by applying Random Fourier Features (RFFs) [13] to approximate a Gaussian kernel *on top of* the cosine-mapped features, i.e., `Î¦(z) = Ï•RFF(Ï•cos(z))`. This exploits `â„“2` distance relationships beyond the `Ï•cos`-space.\n        *   **Efficient Explicit Feature Mappings**: Instead of computing and storing large kernel matrices, the approach uses explicit feature mappings (especially RFFs for the Gaussian kernel) to transform features. This allows for efficient calculation of KPCA reconstruction errors for new test samples, overcoming the computational bottleneck of traditional KPCA for large datasets \\cite{fang2024lv2}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: First work to explore suitable kernels to capture non-linearity in InD and OoD features in a post-hoc manner on well-trained DNNs \\cite{fang2024lv2}.\n    *   **System Design/Architectural Innovations**: Introduction of two carefully devised task-specific kernels (cosine and cosine-Gaussian) and their explicit feature mappings (CoP and CoRP) for KPCA, leading to significantly improved separability of reconstruction errors.\n    *   **Efficiency**: Achieves remarkably reduced inference time complexity: O(1) for CoP and O(M) for CoRP (where M is the number of RFFs and M â‰ª Ntr), significantly outperforming KNN's O(Ntr) complexity \\cite{fang2024lv2}.\n    *   **Theoretical Insights**: Provides a kernel perspective on the effectiveness of `â„“2`-normalization and `â„“2` distance in distinguishing OoD data, guiding the design of the proposed kernels.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed, comparing CoP and CoRP against KNN [7], regularized PCA reconstruction error [8], and various other prevailing OoD detection methods (logits-based, gradients-based, other feature-based).\n    *   **Key Performance Metrics & Results**:\n        *   The proposed KPCA detectors (CoP and CoRP) achieve state-of-the-art (SOTA) OoD detection performance across multiple OoD datasets and network structures \\cite{fang2024lv2}.\n        *   They demonstrate stronger detection performance and significantly cheaper computation costs compared to KNN [7] and other baselines.\n        *   Figure 1 visually confirms that the explicit feature mapping `Î¦(z)` alleviates linear inseparability, leading to much more distinguishable reconstruction errors for InD and OoD data.\n        *   The O(1) and O(M) inference complexities of CoP and CoRP, respectively, are empirically shown to significantly outperform the O(Ntr) complexity of KNN \\cite{fang2024lv2}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: While the paper proposes effective kernels, finding an appropriate kernel or feature mapping that universally adapts to unknown non-linear data distributions remains a general challenge for KPCA \\cite{fang2024lv2}. The choice of `q` (number of principal components) is a hyperparameter that needs tuning.\n    *   **Scope of Applicability**: The method is designed for post-hoc OoD detection on features from *well-trained* DNNs, specifically utilizing penultimate layer features.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art in feature-based OoD detection by effectively addressing the linear inseparability problem of PCA through principled non-linear kernel mappings, achieving SOTA performance with high efficiency \\cite{fang2024lv2}.\n    *   **Potential Impact**: It introduces a valuable kernel perspective for understanding and improving OoD detection, and the devised task-specific kernels could serve as beneficial priors for future research in exploring and learning more powerful kernels for OoD detection. The computational efficiency makes it highly practical for large-scale applications.",
      "intriguing_abstract": "Deep Neural Networks (DNNs) are notoriously unreliable with Out-of-Distribution (OoD) data, a critical challenge for safety-critical applications where existing PCA-based detection methods fail due to linearly inseparable features. This paper introduces a novel approach leveraging Kernel PCA (KPCA) with carefully designed, task-specific non-linear feature mappings to overcome this fundamental limitation.\n\nWe propose two innovative explicit mappings: Cosine Mapping (CoP) and Cosine-Gaussian Mapping (CoRP). CoP utilizes `â„“2`-normalization, while CoRP enhances separability by approximating a Gaussian kernel using Random Fourier Features (RFFs) on the cosine-mapped space. This pioneering use of explicit feature mappings bypasses traditional KPCA's prohibitive computational complexity, achieving remarkable O(1) and O(M) inference complexities for CoP and CoRP, respectivelyâ€”a drastic improvement over O(Ntr) methods like k-Nearest Neighbors (KNN).\n\nExtensive experiments demonstrate our KPCA detectors achieve state-of-the-art (SOTA) OoD detection performance across diverse datasets and network architectures. By transforming linearly inseparable features, our method delivers superior accuracy and sets a new benchmark for computational efficiency in post-hoc OoD detection, paving the way for more robust and trustworthy DNN deployments.",
      "keywords": [
        "Out-of-Distribution (OoD) detection",
        "Deep Neural Networks (DNNs)",
        "Kernel PCA (KPCA)",
        "non-linear feature mappings",
        "Cosine Mapping (CoP)",
        "Cosine-Gaussian Mapping (CoRP)",
        "explicit feature mappings",
        "reconstruction error",
        "`â„“2`-normalization",
        "Random Fourier Features (RFFs)",
        "computational efficiency",
        "state-of-the-art performance",
        "linear inseparability",
        "task-specific kernels"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/1f24e041e10239cba8ff26ffcff4902343e55cab.pdf",
      "citation_key": "fang2024lv2",
      "metadata": {
        "title": "Kernel PCA for Out-of-Distribution Detection",
        "authors": [
          "Kun Fang",
          "Qinghua Tao",
          "Kexin Lv",
          "M. He",
          "Xiaolin Huang",
          "Jie Yang"
        ],
        "published_date": "2024",
        "abstract": "Out-of-Distribution (OoD) detection is vital for the reliability of Deep Neural Networks (DNNs). Existing works have shown the insufficiency of Principal Component Analysis (PCA) straightforwardly applied on the features of DNNs in detecting OoD data from In-Distribution (InD) data. The failure of PCA suggests that the network features residing in OoD and InD are not well separated by simply proceeding in a linear subspace, which instead can be resolved through proper non-linear mappings. In this work, we leverage the framework of Kernel PCA (KPCA) for OoD detection, and seek suitable non-linear kernels that advocate the separability between InD and OoD data in the subspace spanned by the principal components. Besides, explicit feature mappings induced from the devoted task-specific kernels are adopted so that the KPCA reconstruction error for new test samples can be efficiently obtained with large-scale data. Extensive theoretical and empirical results on multiple OoD data sets and network structures verify the superiority of our KPCA detector in efficiency and efficacy with state-of-the-art detection performance.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/1f24e041e10239cba8ff26ffcff4902343e55cab.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 11,
        "score": 11.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: Deep Neural Networks (DNNs) are unreliable when encountering Out-of-Distribution (OoD) data, posing risks in sensitive applications. Existing Principal Component Analysis (PCA) methods applied directly to DNN features fail to effectively detect OoD data because In-Distribution (InD) and OoD features are not linearly separable in the original feature space.\n    *   **Motivation**: There is a critical need for robust OoD detection to ensure the trustworthiness and safe deployment of DNNs. The observed failure of linear PCA suggests that non-linear mappings are required to achieve better separability between InD and OoD features.\n\n*   **Related Work & Positioning**\n    *   **Relation**: This work builds upon feature-based OoD detection methods, specifically addressing the limitations of PCA reconstruction error approaches (e.g., as explored in [8]).\n    *   **Limitations of Previous Solutions**:\n        *   **PCA on raw features**: PCA applied directly to penultimate DNN features (z-space) yields poor OoD detection performance due to the linear inseparability of InD and OoD data \\cite{fang2024lv2}. Previous work [8] acknowledged this but resorted to fusion tricks rather than investigating the underlying non-linearity.\n        *   **General Kernel PCA (KPCA)**: Traditional KPCA faces significant computational challenges for large-scale data, requiring O(Ntr^2) space and O(Ntr^3) time complexity for kernel matrix operations, where Ntr is the number of training samples \\cite{fang2024lv2}. It also struggles with the non-trivial task of finding appropriate kernels without prior knowledge.\n        *   **k-Nearest Neighbors (KNN)**: While effective, KNN [7] has a high inference complexity of O(Ntr) because it requires storing and iterating through all training features for each new sample \\cite{fang2024lv2}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method**: The paper leverages Kernel PCA (KPCA) for OoD detection by applying specific non-linear feature mappings to the penultimate DNN features before performing PCA. The OoD score is then derived from the reconstruction error in this mapped space.\n    *   **Novelty & Innovation**:\n        *   **Task-Specific Kernels/Explicit Mappings**: The authors devise two effective non-linear feature mappings, inspired by a kernel perspective on the KNN detector [7]:\n            *   **Cosine Mapping (CoP)**: Recognizes that the `â„“2`-normalization crucial for KNN's success [7] induces a cosine kernel. PCA is then performed on these `â„“2`-normalized features `Ï•cos(z) = z/âˆ¥zâˆ¥2`.\n            *   **Cosine-Gaussian Mapping (CoRP)**: Further enhances separability by applying Random Fourier Features (RFFs) [13] to approximate a Gaussian kernel *on top of* the cosine-mapped features, i.e., `Î¦(z) = Ï•RFF(Ï•cos(z))`. This exploits `â„“2` distance relationships beyond the `Ï•cos`-space.\n        *   **Efficient Explicit Feature Mappings**: Instead of computing and storing large kernel matrices, the approach uses explicit feature mappings (especially RFFs for the Gaussian kernel) to transform features. This allows for efficient calculation of KPCA reconstruction errors for new test samples, overcoming the computational bottleneck of traditional KPCA for large datasets \\cite{fang2024lv2}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: First work to explore suitable kernels to capture non-linearity in InD and OoD features in a post-hoc manner on well-trained DNNs \\cite{fang2024lv2}.\n    *   **System Design/Architectural Innovations**: Introduction of two carefully devised task-specific kernels (cosine and cosine-Gaussian) and their explicit feature mappings (CoP and CoRP) for KPCA, leading to significantly improved separability of reconstruction errors.\n    *   **Efficiency**: Achieves remarkably reduced inference time complexity: O(1) for CoP and O(M) for CoRP (where M is the number of RFFs and M â‰ª Ntr), significantly outperforming KNN's O(Ntr) complexity \\cite{fang2024lv2}.\n    *   **Theoretical Insights**: Provides a kernel perspective on the effectiveness of `â„“2`-normalization and `â„“2` distance in distinguishing OoD data, guiding the design of the proposed kernels.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed, comparing CoP and CoRP against KNN [7], regularized PCA reconstruction error [8], and various other prevailing OoD detection methods (logits-based, gradients-based, other feature-based).\n    *   **Key Performance Metrics & Results**:\n        *   The proposed KPCA detectors (CoP and CoRP) achieve state-of-the-art (SOTA) OoD detection performance across multiple OoD datasets and network structures \\cite{fang2024lv2}.\n        *   They demonstrate stronger detection performance and significantly cheaper computation costs compared to KNN [7] and other baselines.\n        *   Figure 1 visually confirms that the explicit feature mapping `Î¦(z)` alleviates linear inseparability, leading to much more distinguishable reconstruction errors for InD and OoD data.\n        *   The O(1) and O(M) inference complexities of CoP and CoRP, respectively, are empirically shown to significantly outperform the O(Ntr) complexity of KNN \\cite{fang2024lv2}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: While the paper proposes effective kernels, finding an appropriate kernel or feature mapping that universally adapts to unknown non-linear data distributions remains a general challenge for KPCA \\cite{fang2024lv2}. The choice of `q` (number of principal components) is a hyperparameter that needs tuning.\n    *   **Scope of Applicability**: The method is designed for post-hoc OoD detection on features from *well-trained* DNNs, specifically utilizing penultimate layer features.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art in feature-based OoD detection by effectively addressing the linear inseparability problem of PCA through principled non-linear kernel mappings, achieving SOTA performance with high efficiency \\cite{fang2024lv2}.\n    *   **Potential Impact**: It introduces a valuable kernel perspective for understanding and improving OoD detection, and the devised task-specific kernels could serve as beneficial priors for future research in exploring and learning more powerful kernels for OoD detection. The computational efficiency makes it highly practical for large-scale applications.",
        "keywords": [
          "Out-of-Distribution (OoD) detection",
          "Deep Neural Networks (DNNs)",
          "Kernel PCA (KPCA)",
          "non-linear feature mappings",
          "Cosine Mapping (CoP)",
          "Cosine-Gaussian Mapping (CoRP)",
          "explicit feature mappings",
          "reconstruction error",
          "`â„“2`-normalization",
          "Random Fourier Features (RFFs)",
          "computational efficiency",
          "state-of-the-art performance",
          "linear inseparability",
          "task-specific kernels"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"in this work, we leverage the framework of kernel pca (kpca) for ood detection, and seek suitable non-linear kernels...\" and \"verify the superiority of **our kpca detector**\". this indicates the development and presentation of a new method or system.\n*   the introduction sets up a technical problem (ood detection, limitations of pca) and then states \"in this work, we address ood detection from a perspective of utilizing the feature spaces learned by the backbone of dnns.\" which leads into their proposed technical solution.\n*   the keywords \"propose\", \"develop\", \"present\", \"algorithm\", \"method\" are strongly implied by phrases like \"we leverage the framework...\", \"seek suitable non-linear kernels\", and \"our kpca detector\".\n*   while it mentions \"theoretical and empirical results\", these are used to *verify* the proposed detector, making them supporting elements of a technical contribution, rather than the primary focus of the paper itself (which would be the case for a purely theoretical or empirical paper).\n\ntherefore, the paper best fits the **technical** classification."
      },
      "file_name": "1f24e041e10239cba8ff26ffcff4902343e55cab.pdf"
    },
    {
      "success": true,
      "doc_id": "f0aa701aa510b86932aaaf627ea021cd",
      "summary": "Here's a focused summary of the paper `\\cite{vojivr202444c}` for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of **pixel-level out-of-distribution (OOD) detection** in computer vision systems \\cite{vojivr202444c}.\n    *   This problem is important because real-world deployments inevitably encounter domain shifts and OOD data, leading to unreliable or potentially disastrous system outputs if not recognized \\cite{vojivr202444c}.\n    *   It is challenging because traditional machine learning assumes identical data distributions between training and test sets, and existing OOD methods often require training on samples of anomalous data or are designed for specific applications, introducing biases \\cite{vojivr202444c}. The goal is a general approach with minimal assumptions about unseen OOD data.\n\n*   **Related Work & Positioning**\n    *   Existing OOD methods are broadly categorized into those using real/synthetic OOD data and those that do not; `\\cite{vojivr202444c}` falls into the latter, aiming for wider applicability by avoiding task-specific biases from auxiliary OOD data \\cite{vojivr202444c}.\n    *   Previous solutions in road anomaly detection include reconstruction-based methods (often overtaken), energy-based models, and region-based methods (less common in other domains like industrial inspection) \\cite{vojivr202444c}. Industrial anomaly detection has seen reconstruction, likelihood modeling, and nearest-neighbor approaches, with a recent trend towards general models \\cite{vojivr202444c}.\n    *   `\\cite{vojivr202444c}` is inspired by GROOD \\cite{vojivr202444c} for image-level OOD but addresses its key limitations for pixel-level tasks: (i) GROOD's lack of pixel-level generalization and (ii) its limited capability for modeling complex intra-class variability, which is crucial for pixel-level decisions \\cite{vojivr202444c}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method, PixOOD, is a general pixel-level OOD detection framework comprising three components: (i) extraction of pixel/patch feature representations (e.g., using DINOv2 encoder), (ii) building a two-dimensional projection space, and (iii) finding an optimal and calibrated ID/OOD decision strategy \\cite{vojivr202444c}.\n    *   The primary innovation lies in the **2D projection space** and a **novel incremental soft-to-hard data condensation algorithm** \\cite{vojivr202444c}. Unlike GROOD's simple projections, PixOOD uses a Multi-layer Perceptron (MLP) for logit scores and the proposed condensation algorithm to find distances to multiple class etalons, enabling rich intra-class appearance modeling \\cite{vojivr202444c}.\n    *   The decision strategy formulates OOD detection as a Neyman-Pearson task, minimizing false positives while bounding false negatives, and generates a calibrated OOD score based on likelihood ratios \\cite{vojivr202444c}.\n\n*   **Key Technical Contributions**\n    *   **Novel pixel-level OOD detection method (PixOOD):** A general approach that does not require OOD training samples (real or synthetic) \\cite{vojivr202444c}.\n    *   **Novel data condensation algorithm:** Formulated as a stochastic optimization with a new loss function and a re-initialization mechanism, making it more robust than standard K-means and trainable via SGD \\cite{vojivr202444c}. This algorithm effectively models complex intra-class variability using multiple etalons with adaptive scale parameters \\cite{vojivr202444c}.\n    *   **Theoretical insights:** The paper theoretically shows the relation of the condensation loss function to a lower bound of the complete data log-likelihood optimization within an EM algorithm for a mixture of spherical Laplace distributions \\cite{vojivr202444c}.\n    *   **System design/architectural innovations:** Introduction of MLP and the condensation algorithm into the projection space to accommodate pixel-level decision requirements and complex distributions \\cite{vojivr202444c}.\n\n*   **Experimental Validation**\n    *   `\\cite{vojivr202444c}` evaluated PixOOD on a wide range of problems across three diverse benchmarks: MVTec AD (industrial anomaly detection), SMIYC (road anomaly detection with three sub-tracks), and LaRS (maritime obstacle segmentation) \\cite{vojivr202444c}.\n    *   The method achieved **state-of-the-art results on four out of seven datasets** and was competitive on the remaining ones \\cite{vojivr202444c}.\n    *   Examples demonstrate PixOOD's ability to identify anomalies not explicitly labeled in standard benchmarks, such as power cables, spilled content, or scratches \\cite{vojivr202444c}. An ablation study confirmed the necessity of the proposed condensation algorithm for handling complex intra-class variations at the pixel level \\cite{vojivr202444c}.\n\n*   **Limitations & Scope**\n    *   The method's theoretical relation to EM involves an approximation of the optimal variational distribution, which \"in principle breaks the EM monotonicity convergence property,\" though practically it avoids numerical instability \\cite{vojivr202444c}.\n    *   Like K-means and EM, the condensation algorithm can converge to local optima, necessitating the proposed re-initialization strategy \\cite{vojivr202444c}.\n    *   The scope of applicability is broad, covering general pixel-level OOD detection across diverse domains (road, maritime, industrial) without requiring specific application knowledge or OOD training data \\cite{vojivr202444c}.\n\n*   **Technical Significance**\n    *   `\\cite{vojivr202444c}` significantly advances the technical state-of-the-art in pixel-level OOD detection by providing a general, application-agnostic method that does not rely on anomalous training data \\cite{vojivr202444c}.\n    *   The novel incremental soft-to-hard data condensation algorithm, with its theoretical grounding and robustness, is a key contribution that can find uses beyond PixOOD \\cite{vojivr202444c}.\n    *   By effectively modeling complex intra-class variability and achieving state-of-the-art performance on diverse benchmarks, PixOOD enables more robust and reliable computer vision systems in real-world scenarios \\cite{vojivr202444c}.\n    *   Its ability to identify novel, unseen data at a fine-grained level has potential impact on future research in anomaly detection, open-set recognition, and human-in-the-loop systems \\cite{vojivr202444c}.",
      "intriguing_abstract": "Real-world computer vision systems face a critical challenge: reliably detecting out-of-distribution (OOD) data at the pixel level, where unseen anomalies can lead to catastrophic failures. Traditional methods often require biased OOD training samples or struggle with complex intra-class variability. We introduce PixOOD, a novel, general framework for **pixel-level OOD detection** that operates entirely without auxiliary OOD data.\n\nOur core innovation lies in a unique **2D projection space** coupled with an **incremental soft-to-hard data condensation algorithm**. This algorithm, theoretically grounded in EM for mixture models, robustly models intricate **intra-class appearance variations** using multiple adaptive etalonsâ€”a significant advancement over prior art. By formulating OOD detection as a **Neyman-Pearson task**, PixOOD generates highly calibrated anomaly scores from deep features (e.g., DINOv2). Evaluated across diverse benchmarks including MVTec AD, SMIYC, and LaRS, PixOOD achieves **state-of-the-art performance** on four out of seven datasets. This breakthrough enables significantly more robust and trustworthy AI deployments in safety-critical domains, pushing the boundaries of **anomaly detection** and **open-set recognition**.",
      "keywords": [
        "Pixel-level OOD detection",
        "PixOOD framework",
        "incremental soft-to-hard data condensation",
        "no OOD training samples required",
        "intra-class variability modeling",
        "2D projection space",
        "Neyman-Pearson decision strategy",
        "stochastic optimization",
        "state-of-the-art performance",
        "industrial anomaly detection",
        "road anomaly detection",
        "maritime obstacle segmentation",
        "application-agnostic method",
        "mixture of Laplace distributions",
        "robust computer vision systems"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/06436653774a7cb8d53005d3f25af2a7229c1f8b.pdf",
      "citation_key": "vojivr202444c",
      "metadata": {
        "title": "PixOOD: Pixel-Level Out-of-Distribution Detection",
        "authors": [
          "Tom'avs Voj'ivr",
          "Jan Sochman",
          "Jivr'i Matas"
        ],
        "published_date": "2024",
        "abstract": "We propose a dense image prediction out-of-distribution detection algorithm, called PixOOD, which does not require training on samples of anomalous data and is not designed for a specific application which avoids traditional training biases. In order to model the complex intra-class variability of the in-distribution data at the pixel level, we propose an online data condensation algorithm which is more robust than standard K-means and is easily trainable through SGD. We evaluate PixOOD on a wide range of problems. It achieved state-of-the-art results on four out of seven datasets, while being competitive on the rest. The source code is available at https://github.com/vojirt/PixOOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/06436653774a7cb8d53005d3f25af2a7229c1f8b.pdf",
        "venue": "European Conference on Computer Vision",
        "citationCount": 11,
        "score": 11.0,
        "summary": "Here's a focused summary of the paper `\\cite{vojivr202444c}` for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of **pixel-level out-of-distribution (OOD) detection** in computer vision systems \\cite{vojivr202444c}.\n    *   This problem is important because real-world deployments inevitably encounter domain shifts and OOD data, leading to unreliable or potentially disastrous system outputs if not recognized \\cite{vojivr202444c}.\n    *   It is challenging because traditional machine learning assumes identical data distributions between training and test sets, and existing OOD methods often require training on samples of anomalous data or are designed for specific applications, introducing biases \\cite{vojivr202444c}. The goal is a general approach with minimal assumptions about unseen OOD data.\n\n*   **Related Work & Positioning**\n    *   Existing OOD methods are broadly categorized into those using real/synthetic OOD data and those that do not; `\\cite{vojivr202444c}` falls into the latter, aiming for wider applicability by avoiding task-specific biases from auxiliary OOD data \\cite{vojivr202444c}.\n    *   Previous solutions in road anomaly detection include reconstruction-based methods (often overtaken), energy-based models, and region-based methods (less common in other domains like industrial inspection) \\cite{vojivr202444c}. Industrial anomaly detection has seen reconstruction, likelihood modeling, and nearest-neighbor approaches, with a recent trend towards general models \\cite{vojivr202444c}.\n    *   `\\cite{vojivr202444c}` is inspired by GROOD \\cite{vojivr202444c} for image-level OOD but addresses its key limitations for pixel-level tasks: (i) GROOD's lack of pixel-level generalization and (ii) its limited capability for modeling complex intra-class variability, which is crucial for pixel-level decisions \\cite{vojivr202444c}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method, PixOOD, is a general pixel-level OOD detection framework comprising three components: (i) extraction of pixel/patch feature representations (e.g., using DINOv2 encoder), (ii) building a two-dimensional projection space, and (iii) finding an optimal and calibrated ID/OOD decision strategy \\cite{vojivr202444c}.\n    *   The primary innovation lies in the **2D projection space** and a **novel incremental soft-to-hard data condensation algorithm** \\cite{vojivr202444c}. Unlike GROOD's simple projections, PixOOD uses a Multi-layer Perceptron (MLP) for logit scores and the proposed condensation algorithm to find distances to multiple class etalons, enabling rich intra-class appearance modeling \\cite{vojivr202444c}.\n    *   The decision strategy formulates OOD detection as a Neyman-Pearson task, minimizing false positives while bounding false negatives, and generates a calibrated OOD score based on likelihood ratios \\cite{vojivr202444c}.\n\n*   **Key Technical Contributions**\n    *   **Novel pixel-level OOD detection method (PixOOD):** A general approach that does not require OOD training samples (real or synthetic) \\cite{vojivr202444c}.\n    *   **Novel data condensation algorithm:** Formulated as a stochastic optimization with a new loss function and a re-initialization mechanism, making it more robust than standard K-means and trainable via SGD \\cite{vojivr202444c}. This algorithm effectively models complex intra-class variability using multiple etalons with adaptive scale parameters \\cite{vojivr202444c}.\n    *   **Theoretical insights:** The paper theoretically shows the relation of the condensation loss function to a lower bound of the complete data log-likelihood optimization within an EM algorithm for a mixture of spherical Laplace distributions \\cite{vojivr202444c}.\n    *   **System design/architectural innovations:** Introduction of MLP and the condensation algorithm into the projection space to accommodate pixel-level decision requirements and complex distributions \\cite{vojivr202444c}.\n\n*   **Experimental Validation**\n    *   `\\cite{vojivr202444c}` evaluated PixOOD on a wide range of problems across three diverse benchmarks: MVTec AD (industrial anomaly detection), SMIYC (road anomaly detection with three sub-tracks), and LaRS (maritime obstacle segmentation) \\cite{vojivr202444c}.\n    *   The method achieved **state-of-the-art results on four out of seven datasets** and was competitive on the remaining ones \\cite{vojivr202444c}.\n    *   Examples demonstrate PixOOD's ability to identify anomalies not explicitly labeled in standard benchmarks, such as power cables, spilled content, or scratches \\cite{vojivr202444c}. An ablation study confirmed the necessity of the proposed condensation algorithm for handling complex intra-class variations at the pixel level \\cite{vojivr202444c}.\n\n*   **Limitations & Scope**\n    *   The method's theoretical relation to EM involves an approximation of the optimal variational distribution, which \"in principle breaks the EM monotonicity convergence property,\" though practically it avoids numerical instability \\cite{vojivr202444c}.\n    *   Like K-means and EM, the condensation algorithm can converge to local optima, necessitating the proposed re-initialization strategy \\cite{vojivr202444c}.\n    *   The scope of applicability is broad, covering general pixel-level OOD detection across diverse domains (road, maritime, industrial) without requiring specific application knowledge or OOD training data \\cite{vojivr202444c}.\n\n*   **Technical Significance**\n    *   `\\cite{vojivr202444c}` significantly advances the technical state-of-the-art in pixel-level OOD detection by providing a general, application-agnostic method that does not rely on anomalous training data \\cite{vojivr202444c}.\n    *   The novel incremental soft-to-hard data condensation algorithm, with its theoretical grounding and robustness, is a key contribution that can find uses beyond PixOOD \\cite{vojivr202444c}.\n    *   By effectively modeling complex intra-class variability and achieving state-of-the-art performance on diverse benchmarks, PixOOD enables more robust and reliable computer vision systems in real-world scenarios \\cite{vojivr202444c}.\n    *   Its ability to identify novel, unseen data at a fine-grained level has potential impact on future research in anomaly detection, open-set recognition, and human-in-the-loop systems \\cite{vojivr202444c}.",
        "keywords": [
          "Pixel-level OOD detection",
          "PixOOD framework",
          "incremental soft-to-hard data condensation",
          "no OOD training samples required",
          "intra-class variability modeling",
          "2D projection space",
          "Neyman-Pearson decision strategy",
          "stochastic optimization",
          "state-of-the-art performance",
          "industrial anomaly detection",
          "road anomaly detection",
          "maritime obstacle segmentation",
          "application-agnostic method",
          "mixture of Laplace distributions",
          "robust computer vision systems"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the **abstract** explicitly states: \"we **propose** a pixel-level out-of-distribution detection **algorithm**, called pixood...\", and \"we **propose** an online data condensation **algorithm**\". it also mentions evaluating this algorithm and achieving state-of-the-art results.\n*   the **introduction** sets up a technical problem: the unavoidable encounter of out-of-distribution (ood) data in real-world computer vision systems and the need for robust methods to address it. the figures and examples illustrate the application of their proposed method.\n\nthese elements strongly align with the **technical** classification criteria: \"presents new methods, algorithms, or systems\" and \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\". while it includes empirical evaluation, the core contribution is the development and presentation of a novel algorithm.\n\n**classification: technical**"
      },
      "file_name": "06436653774a7cb8d53005d3f25af2a7229c1f8b.pdf"
    },
    {
      "success": true,
      "doc_id": "045611be0132ca248002ea9f126305e5",
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your citation requirements:\n\n### Technical Paper Analysis: DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection \\cite{li2024rs5}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of Out-of-Distribution (OOD) detection in multimodal machine learning models. Specifically, it tackles the issue that existing multimodal OOD detection methods often neglect intra-class variability within In-Distribution (ID) data. They assume perfect cohesion among samples of the same class, leading to performance degradation when prediction discrepancies are uniformly amplified across all samples \\cite{li2024rs5}.\n    *   **Importance and Challenge:** OOD detection is crucial for the safety and robustness of machine learning models in critical applications like autonomous driving and medical imaging. While multimodal models offer potential for improved detection, effectively leveraging diverse modalities (e.g., video, optical flow, audio) and accounting for the natural variations within real-world ID classes remains an open and significant challenge \\cite{li2024rs5}. Uniformly intensifying discrepancies can confuse class-center samples, weakening class cohesion and degrading ID prediction accuracy.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Traditional OOD detection focused on single-modality inputs (e.g., images). Recent efforts extend to multimodal contexts, particularly vision-language systems \\cite{li2024rs5}. Dong et al. \\cite{li2024rs5} introduced a multimodal OOD benchmark and identified \"modality prediction discrepancy\" as a signal, amplifying it to improve performance.\n    *   **Limitations of Previous Solutions:** Existing multimodal OOD methods, including those that leverage prediction discrepancies, typically overlook the rich contextual information provided by modalities and, critically, assume perfect intra-class cohesion. This assumption fails in real-world scenarios where intra-class variability is common, leading to performance degradation when discrepancy intensification is applied indiscriminately \\cite{li2024rs5}. The paper positions DPU as uniquely addressing this intra-class variability to enhance existing base OOD detection methods.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes Dynamic Prototype Updating (DPU), a novel plug-and-play framework for multimodal OOD detection. DPU dynamically adjusts multimodal prediction discrepancy intensification based on each sample's similarity to its class prototype, balancing intra-class cohesion with inter-class separation \\cite{li2024rs5}.\n    *   **Novelty/Difference:** DPU's novelty lies in its dynamic, sample-specific adjustment of class center representations (prototypes) and prediction discrepancy intensification. Unlike previous methods that apply uniform intensification, DPU accounts for intra-class variations by:\n        1.  **Cohesive-Separate Contrastive Training (CSCT):** Constructs a robust representation space by applying marginal contrastive learning to strengthen intra-class cohesion and inter-class separation, while also minimizing class-wise variances within batches \\cite{li2024rs5}.\n        2.  **Dynamic Prototype Approximation (DPA):** Adaptively refines class prototypes using a moving average approach. The update rate is dynamically controlled by the variance of samples within each batch, reducing the influence of outliers and ensuring prototypes accurately represent class features \\cite{li2024rs5}.\n        3.  **Pro-ratio Discrepancy Intensification (PDI):** Scales the multimodal prediction discrepancy for each sample based on its similarity to its dynamically updated class prototype. Samples near the class center maintain low discrepancy, preserving cohesion, while distant samples experience higher discrepancy to increase sensitivity to outlying patterns \\cite{li2024rs5}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   **Cohesive-Separate Contrastive Training (CSCT):** A new training procedure combining robust marginal contrastive learning with a variance representation control term (`Lirm`) to create a representation space with strong intra-class cohesion and inter-class separation \\cite{li2024rs5}.\n        *   **Dynamic Prototype Approximation (DPA):** An adaptive mechanism for updating class prototypes based on batch-wise variance, ensuring prototypes remain representative despite class outliers \\cite{li2024rs5}.\n        *   **Pro-ratio Discrepancy Intensification (PDI):** A method to dynamically adjust the amplification of multimodal prediction discrepancies based on sample-prototype similarity, enhancing OOD detection while preserving ID accuracy \\cite{li2024rs5}.\n    *   **System Design/Architectural Innovations:** DPU is designed as a flexible, plug-and-play framework, making it compatible with various existing OOD detection models and capable of enhancing their performance \\cite{li2024rs5}.\n    *   **Theoretical Insights/Analysis:** The paper identifies and explores the negative impact of intra-class variations within ID data, a previously overlooked aspect in multimodal OOD detection, providing a new perspective on improving model robustness \\cite{li2024rs5}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were performed across two OOD detection tasks (Near-OOD and Far-OOD detection) \\cite{li2024rs5}.\n    *   **Datasets:** The method was evaluated on five datasets, including HMDB51 (as ID) and Kinetics600 (as OOD) for multimodal Far-OOD detection \\cite{li2024rs5}.\n    *   **Performance Metrics:** Key performance metrics include AUROC (Area Under the Receiver Operating Characteristic curve) and FPR95 (False Positive Rate at 95% True Positive Rate) \\cite{li2024rs5}.\n    *   **Comparison Results:** DPU was applied to and compared against nine base OOD algorithms. The results demonstrate that DPU significantly improves the performance of all benchmark models, achieving new state-of-the-art results. Specifically, it showed improvements of around 10% across all metrics for Near-OOD detection and up to 80% for Far-OOD detection. For instance, in Multimodal Far-OOD detection (HMDB51 ID, Kinetics600 OOD), DPU enhanced base methods by +8.1 AUROC and -34.3 FPR95 \\cite{li2024rs5}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** While DPU is model-agnostic, its effectiveness might depend on the specific base OOD method and the nature of the modalities involved. The paper focuses on video, optical flow, and audio modalities. The complexity of tuning multiple hyperparameters (e.g., `lambda`, `beta`, `gamma`, `mu`) for optimal performance across diverse scenarios could be a practical consideration. The \"adaptive outlier synthesis\" is mentioned but not fully detailed in the provided abstract/introduction, which might limit a complete understanding of its technical implementation \\cite{li2024rs5}.\n    *   **Scope of Applicability:** DPU is primarily designed for multimodal OOD detection where intra-class variability is a significant factor. Its direct applicability to single-modality OOD detection or scenarios without significant intra-class variations might be less impactful, though the underlying principles of robust representation learning could still be relevant.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** DPU significantly advances the technical state-of-the-art in multimodal OOD detection by being the first to explicitly identify and address the critical issue of intra-class variations within ID data. It provides a robust and adaptive framework that consistently outperforms existing methods across various benchmarks \\cite{li2024rs5}.\n    *   **Potential Impact on Future Research:** The framework's plug-and-play nature and its focus on dynamic prototype updating and adaptive discrepancy intensification offer a new paradigm for designing more robust and generalizable OOD detection systems. It opens avenues for future research into more sophisticated methods for modeling intra-class variability, dynamic prototype learning, and adaptive OOD scoring in complex multimodal environments \\cite{li2024rs5}.",
      "intriguing_abstract": "Multimodal Out-of-Distribution (OOD) detection is paramount for robust and safe AI, yet current methods critically falter by overlooking the inherent intra-class variability within In-Distribution (ID) data. This oversight leads to indiscriminate amplification of prediction discrepancies, degrading performance. We introduce **Dynamic Prototype Updating (DPU)**, a novel, plug-and-play framework that revolutionizes multimodal OOD detection by dynamically adapting to these crucial intra-class nuances.\n\nDPU integrates three innovative components: **Cohesive-Separate Contrastive Training (CSCT)**, which constructs a robust representation space; **Dynamic Prototype Approximation (DPA)**, adaptively refining class prototypes with variance-controlled updates; and **Pro-ratio Discrepancy Intensification (PDI)**, which scales multimodal prediction discrepancies based on sample-prototype similarity. This dynamic approach ensures class-center samples maintain cohesion while outliers trigger heightened OOD sensitivity. Extensive experiments demonstrate DPU's superior performance, significantly boosting nine base OOD algorithms by up to +8.1 AUROC and -34.3 FPR95 for Far-OOD detection, establishing new state-of-the-art. DPU offers a critical advancement for developing truly robust and reliable multimodal systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "multimodal machine learning",
        "intra-class variability",
        "Dynamic Prototype Updating (DPU)",
        "class prototypes",
        "prediction discrepancy intensification",
        "Cohesive-Separate Contrastive Training (CSCT)",
        "Dynamic Prototype Approximation (DPA)",
        "Pro-ratio Discrepancy Intensification (PDI)",
        "plug-and-play framework",
        "robust representation learning",
        "state-of-the-art performance",
        "autonomous driving",
        "medical imaging"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/28582980cc55e3ed002fae2cf0e9b9b92714694b.pdf",
      "citation_key": "li2024rs5",
      "metadata": {
        "title": "DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection",
        "authors": [
          "Li Li",
          "Huixian Gong",
          "Hao Dong",
          "Tiankai Yang",
          "Zhengzhong Tu",
          "Yue Zhao"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is essential for ensuring the robustness of machine learning models by identifying samples that deviate from the training distribution. While traditional OOD detection has primarily focused on single-modality inputs, such as images, recent advances in multimodal models have demonstrated the potential of leveraging multiple modalities (e.g., video, optical flow, audio) to enhance detection performance. However, existing methods often overlook intra-class variability within in-distribution (ID) data, assuming that samples of the same class are perfectly cohesive and consistent. This assumption can lead to performance degradation, especially when prediction discrepancies are uniformly amplified across all samples. To address this issue, we propose Dynamic Prototype Updating (DPU), a novel plug-and-play framework for multimodal OOD detection that accounts for intra-class variations. Our method dynamically updates class center representations for each class by measuring the variance of similar samples within each batch, enabling adaptive adjustments. This approach allows us to amplify prediction discrepancies based on the updated class centers, thereby improving the model's robustness and generalization across different modalities. Extensive experiments on two tasks, five datasets, and nine base OOD algorithms demonstrate that DPU significantly improves OOD detection performance, setting a new state-of-the-art in multimodal OOD detection, with improvements of up to 80 percent in Far-OOD detection. To facilitate accessibility and reproducibility, our code is publicly available on GitHub.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/28582980cc55e3ed002fae2cf0e9b9b92714694b.pdf",
        "venue": "arXiv.org",
        "citationCount": 11,
        "score": 11.0,
        "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your citation requirements:\n\n### Technical Paper Analysis: DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection \\cite{li2024rs5}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of Out-of-Distribution (OOD) detection in multimodal machine learning models. Specifically, it tackles the issue that existing multimodal OOD detection methods often neglect intra-class variability within In-Distribution (ID) data. They assume perfect cohesion among samples of the same class, leading to performance degradation when prediction discrepancies are uniformly amplified across all samples \\cite{li2024rs5}.\n    *   **Importance and Challenge:** OOD detection is crucial for the safety and robustness of machine learning models in critical applications like autonomous driving and medical imaging. While multimodal models offer potential for improved detection, effectively leveraging diverse modalities (e.g., video, optical flow, audio) and accounting for the natural variations within real-world ID classes remains an open and significant challenge \\cite{li2024rs5}. Uniformly intensifying discrepancies can confuse class-center samples, weakening class cohesion and degrading ID prediction accuracy.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Traditional OOD detection focused on single-modality inputs (e.g., images). Recent efforts extend to multimodal contexts, particularly vision-language systems \\cite{li2024rs5}. Dong et al. \\cite{li2024rs5} introduced a multimodal OOD benchmark and identified \"modality prediction discrepancy\" as a signal, amplifying it to improve performance.\n    *   **Limitations of Previous Solutions:** Existing multimodal OOD methods, including those that leverage prediction discrepancies, typically overlook the rich contextual information provided by modalities and, critically, assume perfect intra-class cohesion. This assumption fails in real-world scenarios where intra-class variability is common, leading to performance degradation when discrepancy intensification is applied indiscriminately \\cite{li2024rs5}. The paper positions DPU as uniquely addressing this intra-class variability to enhance existing base OOD detection methods.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes Dynamic Prototype Updating (DPU), a novel plug-and-play framework for multimodal OOD detection. DPU dynamically adjusts multimodal prediction discrepancy intensification based on each sample's similarity to its class prototype, balancing intra-class cohesion with inter-class separation \\cite{li2024rs5}.\n    *   **Novelty/Difference:** DPU's novelty lies in its dynamic, sample-specific adjustment of class center representations (prototypes) and prediction discrepancy intensification. Unlike previous methods that apply uniform intensification, DPU accounts for intra-class variations by:\n        1.  **Cohesive-Separate Contrastive Training (CSCT):** Constructs a robust representation space by applying marginal contrastive learning to strengthen intra-class cohesion and inter-class separation, while also minimizing class-wise variances within batches \\cite{li2024rs5}.\n        2.  **Dynamic Prototype Approximation (DPA):** Adaptively refines class prototypes using a moving average approach. The update rate is dynamically controlled by the variance of samples within each batch, reducing the influence of outliers and ensuring prototypes accurately represent class features \\cite{li2024rs5}.\n        3.  **Pro-ratio Discrepancy Intensification (PDI):** Scales the multimodal prediction discrepancy for each sample based on its similarity to its dynamically updated class prototype. Samples near the class center maintain low discrepancy, preserving cohesion, while distant samples experience higher discrepancy to increase sensitivity to outlying patterns \\cite{li2024rs5}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   **Cohesive-Separate Contrastive Training (CSCT):** A new training procedure combining robust marginal contrastive learning with a variance representation control term (`Lirm`) to create a representation space with strong intra-class cohesion and inter-class separation \\cite{li2024rs5}.\n        *   **Dynamic Prototype Approximation (DPA):** An adaptive mechanism for updating class prototypes based on batch-wise variance, ensuring prototypes remain representative despite class outliers \\cite{li2024rs5}.\n        *   **Pro-ratio Discrepancy Intensification (PDI):** A method to dynamically adjust the amplification of multimodal prediction discrepancies based on sample-prototype similarity, enhancing OOD detection while preserving ID accuracy \\cite{li2024rs5}.\n    *   **System Design/Architectural Innovations:** DPU is designed as a flexible, plug-and-play framework, making it compatible with various existing OOD detection models and capable of enhancing their performance \\cite{li2024rs5}.\n    *   **Theoretical Insights/Analysis:** The paper identifies and explores the negative impact of intra-class variations within ID data, a previously overlooked aspect in multimodal OOD detection, providing a new perspective on improving model robustness \\cite{li2024rs5}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were performed across two OOD detection tasks (Near-OOD and Far-OOD detection) \\cite{li2024rs5}.\n    *   **Datasets:** The method was evaluated on five datasets, including HMDB51 (as ID) and Kinetics600 (as OOD) for multimodal Far-OOD detection \\cite{li2024rs5}.\n    *   **Performance Metrics:** Key performance metrics include AUROC (Area Under the Receiver Operating Characteristic curve) and FPR95 (False Positive Rate at 95% True Positive Rate) \\cite{li2024rs5}.\n    *   **Comparison Results:** DPU was applied to and compared against nine base OOD algorithms. The results demonstrate that DPU significantly improves the performance of all benchmark models, achieving new state-of-the-art results. Specifically, it showed improvements of around 10% across all metrics for Near-OOD detection and up to 80% for Far-OOD detection. For instance, in Multimodal Far-OOD detection (HMDB51 ID, Kinetics600 OOD), DPU enhanced base methods by +8.1 AUROC and -34.3 FPR95 \\cite{li2024rs5}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** While DPU is model-agnostic, its effectiveness might depend on the specific base OOD method and the nature of the modalities involved. The paper focuses on video, optical flow, and audio modalities. The complexity of tuning multiple hyperparameters (e.g., `lambda`, `beta`, `gamma`, `mu`) for optimal performance across diverse scenarios could be a practical consideration. The \"adaptive outlier synthesis\" is mentioned but not fully detailed in the provided abstract/introduction, which might limit a complete understanding of its technical implementation \\cite{li2024rs5}.\n    *   **Scope of Applicability:** DPU is primarily designed for multimodal OOD detection where intra-class variability is a significant factor. Its direct applicability to single-modality OOD detection or scenarios without significant intra-class variations might be less impactful, though the underlying principles of robust representation learning could still be relevant.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** DPU significantly advances the technical state-of-the-art in multimodal OOD detection by being the first to explicitly identify and address the critical issue of intra-class variations within ID data. It provides a robust and adaptive framework that consistently outperforms existing methods across various benchmarks \\cite{li2024rs5}.\n    *   **Potential Impact on Future Research:** The framework's plug-and-play nature and its focus on dynamic prototype updating and adaptive discrepancy intensification offer a new paradigm for designing more robust and generalizable OOD detection systems. It opens avenues for future research into more sophisticated methods for modeling intra-class variability, dynamic prototype learning, and adaptive OOD scoring in complex multimodal environments \\cite{li2024rs5}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "multimodal machine learning",
          "intra-class variability",
          "Dynamic Prototype Updating (DPU)",
          "class prototypes",
          "prediction discrepancy intensification",
          "Cohesive-Separate Contrastive Training (CSCT)",
          "Dynamic Prototype Approximation (DPA)",
          "Pro-ratio Discrepancy Intensification (PDI)",
          "plug-and-play framework",
          "robust representation learning",
          "state-of-the-art performance",
          "autonomous driving",
          "medical imaging"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **\"we propose dynamic prototype updating (dpu), a novel plug-and-play framework\"**: this directly aligns with the \"technical\" criterion of presenting new methods, algorithms, or systems.\n2.  **\"our method dynamically updates class center representations...\"**: reinforces the presentation of a new method.\n3.  **\"extensive experiments on two tasks, five datasets, and nine base ood algorithms demonstrate that dpu significantly improves ood detection performances...\"**: this indicates a strong empirical component, as it involves data-driven studies and statistical analysis of findings.\n\nwhile the paper clearly has a significant empirical component to validate its claims, its core contribution is the introduction and description of a **new method/framework (dpu)**. the experiments serve to demonstrate the effectiveness of this proposed technical solution. therefore, the primary classification leans towards **technical**.\n\nthe final classification is: **technical**"
      },
      "file_name": "28582980cc55e3ed002fae2cf0e9b9b92714694b.pdf"
    },
    {
      "success": true,
      "doc_id": "399018c84bca036b8411789a396d0ec6",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/646de295e8680bee891d359fce2e2ef201a411a3.pdf",
      "citation_key": "tang20243rx",
      "metadata": {
        "title": "CORES: Convolutional Response-based Score for Out-of-distribution Detection",
        "authors": [
          "Keke Tang",
          "Chao Hou",
          "Weilong Peng",
          "Runnan Chen",
          "Peican Zhu",
          "Wenping Wang",
          "Zhihong Tian"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/646de295e8680bee891d359fce2e2ef201a411a3.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 11,
        "score": 11.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "646de295e8680bee891d359fce2e2ef201a411a3.pdf"
    },
    {
      "success": true,
      "doc_id": "43ff91684beb56fd979d59c6bc1c686e",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The core problem is effective Out-of-Distribution (OOD) detection, which requires acquiring a robust in-distribution (ID) representation that is distinct from OOD samples.\n    *   This problem is critical for safety-critical applications (e.g., medical diagnosis, autonomous driving).\n    *   Existing recognition-based methods (classification, contrastive learning) often suffer from \"shortcut learning,\" where models learn only specific distinguishable patterns for classification rather than comprehensive, pixel-level ID representations. This leads to misclassifying OOD samples that share superficial similarities with ID data (e.g., a fox with pointed ears being classified as a cat) \\cite{li2024n34}.\n\n*   **Related Work & Positioning**\n    *   Previous OOD detection methods primarily rely on probability-based, logit-based, or feature-based score functions, often derived from models pre-trained via classification or contrastive learning \\cite{li2024n34}.\n    *   The limitation of these existing approaches, including prior self-supervised methods like contrastive learning, is their tendency to learn category-specific patterns rather than intrinsic ID representations, making them less effective for robust OOD detection \\cite{li2024n34}.\n    *   `\\cite{li2024n34}` positions itself by addressing this fundamental limitation, proposing a reconstruction-based pretext task to learn more comprehensive ID representations. It also improves upon its previous version, MOODv1, by eliminating the need for fine-tuning on each ID dataset, integrating more advanced pretraining techniques and score functions, and using a wider range of unnatural OOD datasets to avoid overlap with pre-training data \\cite{li2024n34}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is employing a **Masked Image Modeling (MIM)** pretext task for pre-training, which `\\cite{li2024n34}` names MOODv2.\n    *   This approach forces the network to learn pixel-level feature representations by reconstructing masked portions of images, rather than just classifying them based on superficial patterns \\cite{li2024n34}.\n    *   The novelty lies in leveraging the reconstruction process to acquire a more representative ID feature space. `\\cite{li2024n34}` demonstrates that models pre-trained with MIM effectively reconstruct ID images but show clear domain discrepancies when attempting to reconstruct OOD images (e.g., applying natural image lighting/shadows to textured images, or smoothing/brightening sketch images), creating a distinct domain gap that is highly beneficial for OOD detection \\cite{li2024n34}.\n    *   MOODv2 is a lightweight, training-free method, meaning it does not require retraining the model for OOD detection, preserving ID classification accuracy \\cite{li2024n34}.\n\n*   **Key Technical Contributions**\n    *   **Novel Pretext Task Application**: Demonstrating that Masked Image Modeling (MIM) is a superior pretext task for learning robust ID representations for OOD detection compared to classification or contrastive learning \\cite{li2024n34}.\n    *   **Enhanced Feature Representation**: The MIM-based pre-training yields a more comprehensive, pixel-level ID feature representation that inherently creates a larger and more exploitable domain gap between ID and OOD samples \\cite{li2024n34}.\n    *   **Reduced Score Function Disparity**: The improved ID representation significantly narrows the performance gap among various OOD score functions, allowing even simple score functions to achieve performance comparable to more complex ones \\cite{li2024n34}.\n    *   **Streamlined Framework**: MOODv2 offers a general framework that does not require fine-tuning on specific ID datasets, making it more resource-efficient and broadly applicable \\cite{li2024n34}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: `\\cite{li2024n34}` conducted comprehensive experiments comparing MIM-pretrained models (BEiT, BEiTv2) against classification-pretrained (ViT) and contrastive learning-pretrained (MoCov3, DINOv2) models. They evaluated performance across various mainstream OOD score functions (probability-based, logits-based, features-based, and hybrid methods) \\cite{li2024n34}.\n    *   **Datasets**: ImageNet and CIFAR-10 were used as in-distribution (ID) datasets. OOD detection was evaluated on challenging unnatural OOD datasets, including OpenImage-O, Texture, iNaturalist, and ImageNet-O, to ensure no overlap with training data \\cite{li2024n34}.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic curve (AUROC) and False Positive Rate at 95% True Positive Rate (FPR95) were used \\cite{li2024n34}.\n    *   **Comparison Results**:\n        *   MOODv2 (MIM-based) significantly enhanced OOD detection performance, achieving a 14.30% AUROC increase to 95.68% on ImageNet and an impressive 99.98% AUROC on CIFAR-10 (a 0.35% enhancement over previous state-of-the-art) \\cite{li2024n34}.\n        *   MIM pretext tasks consistently surpassed classification and contrastive learning across all tested score functions, showing an average AUROC improvement of 15.96% \\cite{li2024n34}.\n        *   Statistical analysis showed that MIM-pretrained models (BEiT, BEiTv2) exhibited significantly lower standard deviations for logit-based methods (e.g., 0.13% and 0.01%) compared to other pre-training methods (e.g., 4.76% for ViT), indicating greater robustness and consistency across score functions \\cite{li2024n34}.\n        *   On CIFAR-10, MOODv2 achieved 99.99% AUROC and a mere 0.03% FPR95 \\cite{li2024n34}.\n\n*   **Limitations & Scope**\n    *   The paper primarily focuses on image data and vision models (ViT architecture).\n    *   While MOODv2 is training-free for OOD detection, it still relies on a pre-trained MIM model, which requires significant computational resources for initial training \\cite{li2024n34}.\n    *   The effectiveness is demonstrated on specific OOD datasets, primarily \"unnatural\" ones, which are designed to be distinct from natural image distributions \\cite{li2024n34}.\n\n*   **Technical Significance**\n    *   `\\cite{li2024n34}` significantly advances the technical state-of-the-art in OOD detection by demonstrating the superior efficacy of reconstruction-based pre-training (MIM) for learning robust ID representations.\n    *   It challenges the conventional reliance on classification-centric pre-training for OOD tasks, highlighting the pitfalls of \"shortcut learning\" \\cite{li2024n34}.\n    *   The finding that effective ID representation can make simple OOD score functions perform on par with complex ones simplifies future OOD system design and reduces computational overhead \\cite{li2024n34}.\n    *   This work has the potential to impact future research by shifting focus towards more intrinsic, pixel-level representation learning for OOD detection, potentially inspiring new self-supervised tasks beyond MIM that further enhance ID-OOD separability \\cite{li2024n34}.",
      "intriguing_abstract": "The Achilles' heel of AI in safety-critical applications is its vulnerability to Out-of-Distribution (OOD) inputs, often due to models learning superficial 'shortcut' patterns. We introduce MOODv2, a novel framework leveraging **Masked Image Modeling (MIM)** as a self-supervised pretext task to acquire robust, pixel-level in-distribution (ID) representations. Unlike classification or contrastive learning, MIM forces comprehensive feature learning, inherently creating a profound **domain gap**: ID samples are accurately reconstructed, while OOD samples exhibit clear reconstruction discrepancies.\n\nMOODv2 achieves unprecedented OOD detection performance, boosting AUROC by 14.30% to 95.68% on ImageNet and reaching 99.98% AUROC on CIFAR-10, setting a new state-of-the-art. This enhanced ID representation significantly narrows the performance disparity among OOD score functions, simplifying system design. Our work challenges conventional classification-centric pre-training, demonstrating MIM's superior efficacy for robust OOD detection, offering a lightweight, training-free approach for more reliable AI.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "In-distribution (ID) representation",
        "Masked Image Modeling (MIM)",
        "MOODv2 framework",
        "reconstruction-based pretext task",
        "pixel-level feature learning",
        "domain gap exploitation",
        "shortcut learning mitigation",
        "self-supervised pre-training",
        "safety-critical applications",
        "enhanced OOD detection performance",
        "training-free OOD detection",
        "reduced OOD score function disparity",
        "AUROC",
        "FPR95"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/6618d8b3643745d60772d4ec522ad76204522f7d.pdf",
      "citation_key": "li2024n34",
      "metadata": {
        "title": "MOODv2: Masked Image Modeling for Out-of-Distribution Detection",
        "authors": [
          "Jingyao Li",
          "Pengguang Chen",
          "Shaozuo Yu",
          "Shu Liu",
          "Jiaya Jia"
        ],
        "published_date": "2024",
        "abstract": "The crux of effective out-of-distribution (OOD) detection lies in acquiring a robust in-distribution (ID) representation, distinct from OOD samples. While previous methods predominantly leaned on recognition-based techniques for this purpose, they often resulted in shortcut learning, lacking comprehensive representations. In our study, we conducted a comprehensive analysis, exploring distinct pretraining tasks and employing various OOD score functions. The results highlight that the feature representations pre-trained through reconstruction yield a notable enhancement and narrow the performance gap among various score functions. This suggests that even simple score functions can rival complex ones when leveraging reconstruction-based pretext tasks. Reconstruction-based pretext tasks adapt well to various score functions. As such, it holds promising potential for further expansion. Our OOD detection framework, MOODv2, employs the masked image modeling pretext task. Without bells and whistles, MOODv2 impressively enhances 14.30% AUROC to 95.68% on ImageNet and achieves 99.98% on CIFAR-10.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/6618d8b3643745d60772d4ec522ad76204522f7d.pdf",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "citationCount": 10,
        "score": 10.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The core problem is effective Out-of-Distribution (OOD) detection, which requires acquiring a robust in-distribution (ID) representation that is distinct from OOD samples.\n    *   This problem is critical for safety-critical applications (e.g., medical diagnosis, autonomous driving).\n    *   Existing recognition-based methods (classification, contrastive learning) often suffer from \"shortcut learning,\" where models learn only specific distinguishable patterns for classification rather than comprehensive, pixel-level ID representations. This leads to misclassifying OOD samples that share superficial similarities with ID data (e.g., a fox with pointed ears being classified as a cat) \\cite{li2024n34}.\n\n*   **Related Work & Positioning**\n    *   Previous OOD detection methods primarily rely on probability-based, logit-based, or feature-based score functions, often derived from models pre-trained via classification or contrastive learning \\cite{li2024n34}.\n    *   The limitation of these existing approaches, including prior self-supervised methods like contrastive learning, is their tendency to learn category-specific patterns rather than intrinsic ID representations, making them less effective for robust OOD detection \\cite{li2024n34}.\n    *   `\\cite{li2024n34}` positions itself by addressing this fundamental limitation, proposing a reconstruction-based pretext task to learn more comprehensive ID representations. It also improves upon its previous version, MOODv1, by eliminating the need for fine-tuning on each ID dataset, integrating more advanced pretraining techniques and score functions, and using a wider range of unnatural OOD datasets to avoid overlap with pre-training data \\cite{li2024n34}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is employing a **Masked Image Modeling (MIM)** pretext task for pre-training, which `\\cite{li2024n34}` names MOODv2.\n    *   This approach forces the network to learn pixel-level feature representations by reconstructing masked portions of images, rather than just classifying them based on superficial patterns \\cite{li2024n34}.\n    *   The novelty lies in leveraging the reconstruction process to acquire a more representative ID feature space. `\\cite{li2024n34}` demonstrates that models pre-trained with MIM effectively reconstruct ID images but show clear domain discrepancies when attempting to reconstruct OOD images (e.g., applying natural image lighting/shadows to textured images, or smoothing/brightening sketch images), creating a distinct domain gap that is highly beneficial for OOD detection \\cite{li2024n34}.\n    *   MOODv2 is a lightweight, training-free method, meaning it does not require retraining the model for OOD detection, preserving ID classification accuracy \\cite{li2024n34}.\n\n*   **Key Technical Contributions**\n    *   **Novel Pretext Task Application**: Demonstrating that Masked Image Modeling (MIM) is a superior pretext task for learning robust ID representations for OOD detection compared to classification or contrastive learning \\cite{li2024n34}.\n    *   **Enhanced Feature Representation**: The MIM-based pre-training yields a more comprehensive, pixel-level ID feature representation that inherently creates a larger and more exploitable domain gap between ID and OOD samples \\cite{li2024n34}.\n    *   **Reduced Score Function Disparity**: The improved ID representation significantly narrows the performance gap among various OOD score functions, allowing even simple score functions to achieve performance comparable to more complex ones \\cite{li2024n34}.\n    *   **Streamlined Framework**: MOODv2 offers a general framework that does not require fine-tuning on specific ID datasets, making it more resource-efficient and broadly applicable \\cite{li2024n34}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: `\\cite{li2024n34}` conducted comprehensive experiments comparing MIM-pretrained models (BEiT, BEiTv2) against classification-pretrained (ViT) and contrastive learning-pretrained (MoCov3, DINOv2) models. They evaluated performance across various mainstream OOD score functions (probability-based, logits-based, features-based, and hybrid methods) \\cite{li2024n34}.\n    *   **Datasets**: ImageNet and CIFAR-10 were used as in-distribution (ID) datasets. OOD detection was evaluated on challenging unnatural OOD datasets, including OpenImage-O, Texture, iNaturalist, and ImageNet-O, to ensure no overlap with training data \\cite{li2024n34}.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic curve (AUROC) and False Positive Rate at 95% True Positive Rate (FPR95) were used \\cite{li2024n34}.\n    *   **Comparison Results**:\n        *   MOODv2 (MIM-based) significantly enhanced OOD detection performance, achieving a 14.30% AUROC increase to 95.68% on ImageNet and an impressive 99.98% AUROC on CIFAR-10 (a 0.35% enhancement over previous state-of-the-art) \\cite{li2024n34}.\n        *   MIM pretext tasks consistently surpassed classification and contrastive learning across all tested score functions, showing an average AUROC improvement of 15.96% \\cite{li2024n34}.\n        *   Statistical analysis showed that MIM-pretrained models (BEiT, BEiTv2) exhibited significantly lower standard deviations for logit-based methods (e.g., 0.13% and 0.01%) compared to other pre-training methods (e.g., 4.76% for ViT), indicating greater robustness and consistency across score functions \\cite{li2024n34}.\n        *   On CIFAR-10, MOODv2 achieved 99.99% AUROC and a mere 0.03% FPR95 \\cite{li2024n34}.\n\n*   **Limitations & Scope**\n    *   The paper primarily focuses on image data and vision models (ViT architecture).\n    *   While MOODv2 is training-free for OOD detection, it still relies on a pre-trained MIM model, which requires significant computational resources for initial training \\cite{li2024n34}.\n    *   The effectiveness is demonstrated on specific OOD datasets, primarily \"unnatural\" ones, which are designed to be distinct from natural image distributions \\cite{li2024n34}.\n\n*   **Technical Significance**\n    *   `\\cite{li2024n34}` significantly advances the technical state-of-the-art in OOD detection by demonstrating the superior efficacy of reconstruction-based pre-training (MIM) for learning robust ID representations.\n    *   It challenges the conventional reliance on classification-centric pre-training for OOD tasks, highlighting the pitfalls of \"shortcut learning\" \\cite{li2024n34}.\n    *   The finding that effective ID representation can make simple OOD score functions perform on par with complex ones simplifies future OOD system design and reduces computational overhead \\cite{li2024n34}.\n    *   This work has the potential to impact future research by shifting focus towards more intrinsic, pixel-level representation learning for OOD detection, potentially inspiring new self-supervised tasks beyond MIM that further enhance ID-OOD separability \\cite{li2024n34}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "In-distribution (ID) representation",
          "Masked Image Modeling (MIM)",
          "MOODv2 framework",
          "reconstruction-based pretext task",
          "pixel-level feature learning",
          "domain gap exploitation",
          "shortcut learning mitigation",
          "self-supervised pre-training",
          "safety-critical applications",
          "enhanced OOD detection performance",
          "training-free OOD detection",
          "reduced OOD score function disparity",
          "AUROC",
          "FPR95"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\n**reasoning:**\n\n1.  **proposes a new method/framework:** the abstract explicitly states, \"our ood detection framework, moodv2, employs the masked image modeling pretext task.\" the introduction further elaborates on this, stating, \"to remedy this issue, we introduce the reconstruction-based pretext task. specifically, we adopt the masked image modeling (mim) [12] as our self-supervised pretext task...\" this clearly indicates the development and presentation of a novel technical solution.\n2.  **addresses a technical problem with a proposed solution:** the paper identifies a limitation of previous recognition-based ood detection methods (shortcut learning) and proposes a reconstruction-based approach using masked image modeling as a solution.\n3.  **presents quantitative results and performance improvements:** the abstract highlights significant performance enhancements: \"moodv2 impressively enhances 14.30% auroc to 95.68% on imagenet and achieves 99.98% on cifar-10.\" this is characteristic of technical papers demonstrating the efficacy of their proposed system or algorithm.\n4.  **empirical validation supports the technical contribution:** while the paper involves extensive \"study,\" \"analysis,\" and \"experiments\" (making it also strongly empirical), these empirical findings are primarily used to validate the effectiveness of the *new technical framework* (moodv2) and its underlying method. the core contribution is the method itself, not just an observation of existing phenomena."
      },
      "file_name": "6618d8b3643745d60772d4ec522ad76204522f7d.pdf"
    },
    {
      "success": true,
      "doc_id": "82666ddb71f31d223c27d75959640085",
      "summary": "Here is a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: Energy-based Hopfield Boosting for Out-of-Distribution Detection \\cite{hofmann2024gnx}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection in machine learning models, particularly when deploying them in real-world scenarios.\n    *   **Importance and Challenge**: Deployed models inevitably encounter inputs that deviate from their training distribution. Without robust OOD detection, this can lead to overly confident, erratic, or completely wrong predictions, making ML systems unreliable and potentially dangerous. The challenge lies in effectively distinguishing between in-distribution (ID) and OOD data, especially when OOD samples are semantically similar or \"hard\" to distinguish.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{hofmann2024gnx} positions itself within the \"outlier exposure (OE)\" category of OOD detection methods, which incorporate auxiliary outlier (AUX) data during training. It also builds upon the concept of Modern Hopfield Networks (MHNs) and their energy function (MHE) for OOD detection, similar to Zhang et al. (2023a), but extends it significantly.\n    *   **Limitations of Previous Solutions**:\n        *   **Post-hoc methods (e.g., MSP)**: Intrinsically limited as they often rely on classifier statistics (p(y|x)) rather than directly modeling data density (p(x)), and their performance heavily depends on the underlying model.\n        *   **General Outlier Exposure (OE)**: While effective, many OE approaches use large, diverse AUX datasets where most samples are easily distinguishable from ID data. Recent OE methods (e.g., POEM) try to find informative samples, but \\cite{hofmann2024gnx} proposes a novel boosting mechanism for this.\n        *   **Prior MHE for OOD (Zhang et al., 2023a)**: These were post-hoc methods (HE, SHE) that only used ID patterns and did not leverage AUX data or modify the training process to learn a better ID-OOD boundary.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{hofmann2024gnx} introduces **Hopfield Boosting**, a novel boosting framework that leverages the Modern Hopfield Energy (MHE) to sharpen the decision boundary between ID and OOD data. It adaptively samples \"weak learners\" from an auxiliary outlier dataset (AUX) that are hard to distinguish from ID data.\n    *   **Novelty/Difference**:\n        *   **MHE-based Energy Function for Boosting**: A novel energy function, `Eb(Î¾;X,O)`, is defined using MHE that quantifies how \"weak\" a learner (an AUX sample) is, peaking at the decision boundary between ID and AUX data. This function is fully differentiable, enabling end-to-end training of neural networks.\n        *   **Adaptive Outlier Sampling**: Similar to AdaBoost, \\cite{hofmann2024gnx} assigns weights to AUX data points based on their `Eb` energy, giving higher weights to samples close to the ID-OOD decision boundary. These \"hard\" samples are then sampled more frequently during training.\n        *   **Integrated Training Loss**: The method incorporates `Eb` directly into the training loss (`LOOD`) alongside the standard cross-entropy loss (`LCE`), explicitly minimizing this energy to refine the ID-OOD boundary.\n        *   **Novel Inference Score**: A new OOD score `s(Î¾) = lse(Î²,XTÎ¾) - lse(Î²,OTÎ¾)` is proposed, utilizing information from both ID and AUX memories.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of Hopfield Boosting, an OOD detection approach that integrates modern Hopfield energy with an adaptive boosting framework for sampling informative outliers.\n    *   **Novel Energy Function**: Development of `Eb(Î¾;X,O)`, a differentiable MHE-based energy function that identifies hard-to-distinguish auxiliary outlier examples and is used for both adaptive sampling and as a component of the training loss.\n    *   **Theoretical Background**: Provides theoretical motivation for Hopfield Boosting, showing that `Eb` relates to the log-odds of class-conditional densities when modeling ID and AUX data as mixtures of Gaussian distributions.\n    *   **State-of-the-Art Performance**: Achieves new state-of-the-art results in OOD detection with outlier exposure.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Experiments were performed on standard OOD detection benchmarks using various ID datasets (CIFAR-10, CIFAR-100, ImageNet-1K) and auxiliary outlier datasets. The method was integrated with a ResNet backbone.\n    *   **Key Performance Metrics**: The primary metric used is the False Positive Rate at 95% True Positives (FPR95), along with AUROC.\n    *   **Comparison Results**: \\cite{hofmann2024gnx} significantly improved upon previous state-of-the-art methods:\n        *   **CIFAR-10**: FPR95 improved from 2.28 to 0.92.\n        *   **CIFAR-100**: FPR95 improved from 11.76 to 7.94.\n        *   **ImageNet-1K**: FPR95 improved from 50.74 to 36.60.\n    *   **Inference Overhead**: The inference step, which uses 50,000 random samples from ID and AUX datasets, incurs a moderate computational overhead (e.g., 7.5% for ResNet-18 on an NVIDIA Titan V GPU).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The inference step, while moderate, does introduce some computational overhead compared to methods that do not store and query large memory patterns.\n        *   The method relies on the availability of an auxiliary outlier dataset for training.\n        *   The choice of `Î²` (inverse temperature) and `Î»` (hyperparameter for `LOOD`) are important for performance.\n    *   **Scope of Applicability**: The method is primarily designed for OOD detection tasks where auxiliary outlier data can be leveraged during training. It is particularly effective in scenarios where distinguishing hard OOD examples is crucial.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{hofmann2024gnx} sets a new state-of-the-art in OOD detection with outlier exposure, demonstrating substantial improvements across diverse datasets.\n    *   **Potential Impact on Future Research**:\n        *   Introduces a novel paradigm for training deep neural networks using Hopfield networks and their energy functions, opening new avenues for energy-based model training.\n        *   Provides a principled way to identify and leverage \"hard\" outlier examples for OOD detection, which could inspire further research into adaptive sampling and curriculum learning for robustness.\n        *   The differentiable nature of the proposed energy function allows for end-to-end optimization, potentially leading to more integrated and powerful OOD detection systems.",
      "intriguing_abstract": "Machine learning models deployed in the real world inevitably encounter Out-of-Distribution (OOD) data, leading to unreliable and potentially dangerous predictions. Addressing this critical challenge, we introduce **Hopfield Boosting**, a novel framework that significantly advances OOD detection with outlier exposure. Our method leverages the powerful Modern Hopfield Energy (MHE) to sharpen the decision boundary between in-distribution and OOD data. We propose a novel, fully differentiable MHE-based energy function, `Eb`, which adaptively identifies and weights \"hard\" auxiliary outlier samples that are semantically close to in-distribution data. By integrating `Eb` directly into the training loss and employing an adaptive sampling mechanism, Hopfield Boosting explicitly minimizes this energy, refining the ID-OOD boundary. This principled approach achieves new state-of-the-art results, drastically reducing the False Positive Rate at 95% True Positives (FPR95) on benchmarks like CIFAR-10 (from 2.28 to 0.92). This work not only enhances the robustness and safety of AI systems but also opens new avenues for energy-based model training and adaptive learning for OOD detection.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Hopfield Boosting",
        "Modern Hopfield Networks",
        "Modern Hopfield Energy",
        "outlier exposure",
        "adaptive outlier sampling",
        "differentiable energy function",
        "state-of-the-art performance",
        "real-world ML deployment",
        "integrated training loss",
        "novel inference score",
        "FPR95",
        "hard OOD examples"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0.pdf",
      "citation_key": "hofmann2024gnx",
      "metadata": {
        "title": "Energy-based Hopfield Boosting for Out-of-Distribution Detection",
        "authors": [
          "Claus Hofmann",
          "Simon Schmid",
          "Bernhard Lehner",
          "Daniel Klotz",
          "Sepp Hochreiter"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is critical when deploying machine learning models in the real world. Outlier exposure methods, which incorporate auxiliary outlier data in the training process, can drastically improve OOD detection performance compared to approaches without advanced training strategies. We introduce Hopfield Boosting, a boosting approach, which leverages modern Hopfield energy (MHE) to sharpen the decision boundary between the in-distribution and OOD data. Hopfield Boosting encourages the model to concentrate on hard-to-distinguish auxiliary outlier examples that lie close to the decision boundary between in-distribution and auxiliary outlier data. Our method achieves a new state-of-the-art in OOD detection with outlier exposure, improving the FPR95 metric from 2.28 to 0.92 on CIFAR-10 and from 11.76 to 7.94 on CIFAR-100.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 10,
        "score": 10.0,
        "summary": "Here is a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: Energy-based Hopfield Boosting for Out-of-Distribution Detection \\cite{hofmann2024gnx}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection in machine learning models, particularly when deploying them in real-world scenarios.\n    *   **Importance and Challenge**: Deployed models inevitably encounter inputs that deviate from their training distribution. Without robust OOD detection, this can lead to overly confident, erratic, or completely wrong predictions, making ML systems unreliable and potentially dangerous. The challenge lies in effectively distinguishing between in-distribution (ID) and OOD data, especially when OOD samples are semantically similar or \"hard\" to distinguish.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{hofmann2024gnx} positions itself within the \"outlier exposure (OE)\" category of OOD detection methods, which incorporate auxiliary outlier (AUX) data during training. It also builds upon the concept of Modern Hopfield Networks (MHNs) and their energy function (MHE) for OOD detection, similar to Zhang et al. (2023a), but extends it significantly.\n    *   **Limitations of Previous Solutions**:\n        *   **Post-hoc methods (e.g., MSP)**: Intrinsically limited as they often rely on classifier statistics (p(y|x)) rather than directly modeling data density (p(x)), and their performance heavily depends on the underlying model.\n        *   **General Outlier Exposure (OE)**: While effective, many OE approaches use large, diverse AUX datasets where most samples are easily distinguishable from ID data. Recent OE methods (e.g., POEM) try to find informative samples, but \\cite{hofmann2024gnx} proposes a novel boosting mechanism for this.\n        *   **Prior MHE for OOD (Zhang et al., 2023a)**: These were post-hoc methods (HE, SHE) that only used ID patterns and did not leverage AUX data or modify the training process to learn a better ID-OOD boundary.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{hofmann2024gnx} introduces **Hopfield Boosting**, a novel boosting framework that leverages the Modern Hopfield Energy (MHE) to sharpen the decision boundary between ID and OOD data. It adaptively samples \"weak learners\" from an auxiliary outlier dataset (AUX) that are hard to distinguish from ID data.\n    *   **Novelty/Difference**:\n        *   **MHE-based Energy Function for Boosting**: A novel energy function, `Eb(Î¾;X,O)`, is defined using MHE that quantifies how \"weak\" a learner (an AUX sample) is, peaking at the decision boundary between ID and AUX data. This function is fully differentiable, enabling end-to-end training of neural networks.\n        *   **Adaptive Outlier Sampling**: Similar to AdaBoost, \\cite{hofmann2024gnx} assigns weights to AUX data points based on their `Eb` energy, giving higher weights to samples close to the ID-OOD decision boundary. These \"hard\" samples are then sampled more frequently during training.\n        *   **Integrated Training Loss**: The method incorporates `Eb` directly into the training loss (`LOOD`) alongside the standard cross-entropy loss (`LCE`), explicitly minimizing this energy to refine the ID-OOD boundary.\n        *   **Novel Inference Score**: A new OOD score `s(Î¾) = lse(Î²,XTÎ¾) - lse(Î²,OTÎ¾)` is proposed, utilizing information from both ID and AUX memories.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of Hopfield Boosting, an OOD detection approach that integrates modern Hopfield energy with an adaptive boosting framework for sampling informative outliers.\n    *   **Novel Energy Function**: Development of `Eb(Î¾;X,O)`, a differentiable MHE-based energy function that identifies hard-to-distinguish auxiliary outlier examples and is used for both adaptive sampling and as a component of the training loss.\n    *   **Theoretical Background**: Provides theoretical motivation for Hopfield Boosting, showing that `Eb` relates to the log-odds of class-conditional densities when modeling ID and AUX data as mixtures of Gaussian distributions.\n    *   **State-of-the-Art Performance**: Achieves new state-of-the-art results in OOD detection with outlier exposure.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Experiments were performed on standard OOD detection benchmarks using various ID datasets (CIFAR-10, CIFAR-100, ImageNet-1K) and auxiliary outlier datasets. The method was integrated with a ResNet backbone.\n    *   **Key Performance Metrics**: The primary metric used is the False Positive Rate at 95% True Positives (FPR95), along with AUROC.\n    *   **Comparison Results**: \\cite{hofmann2024gnx} significantly improved upon previous state-of-the-art methods:\n        *   **CIFAR-10**: FPR95 improved from 2.28 to 0.92.\n        *   **CIFAR-100**: FPR95 improved from 11.76 to 7.94.\n        *   **ImageNet-1K**: FPR95 improved from 50.74 to 36.60.\n    *   **Inference Overhead**: The inference step, which uses 50,000 random samples from ID and AUX datasets, incurs a moderate computational overhead (e.g., 7.5% for ResNet-18 on an NVIDIA Titan V GPU).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The inference step, while moderate, does introduce some computational overhead compared to methods that do not store and query large memory patterns.\n        *   The method relies on the availability of an auxiliary outlier dataset for training.\n        *   The choice of `Î²` (inverse temperature) and `Î»` (hyperparameter for `LOOD`) are important for performance.\n    *   **Scope of Applicability**: The method is primarily designed for OOD detection tasks where auxiliary outlier data can be leveraged during training. It is particularly effective in scenarios where distinguishing hard OOD examples is crucial.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{hofmann2024gnx} sets a new state-of-the-art in OOD detection with outlier exposure, demonstrating substantial improvements across diverse datasets.\n    *   **Potential Impact on Future Research**:\n        *   Introduces a novel paradigm for training deep neural networks using Hopfield networks and their energy functions, opening new avenues for energy-based model training.\n        *   Provides a principled way to identify and leverage \"hard\" outlier examples for OOD detection, which could inspire further research into adaptive sampling and curriculum learning for robustness.\n        *   The differentiable nature of the proposed energy function allows for end-to-end optimization, potentially leading to more integrated and powerful OOD detection systems.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Hopfield Boosting",
          "Modern Hopfield Networks",
          "Modern Hopfield Energy",
          "outlier exposure",
          "adaptive outlier sampling",
          "differentiable energy function",
          "state-of-the-art performance",
          "real-world ML deployment",
          "integrated training loss",
          "novel inference score",
          "FPR95",
          "hard OOD examples"
        ],
        "paper_type": "the paper type is **technical**.\n\n**reasoning:**\n\n*   the abstract explicitly states: \"we introduce hopfield boosting, a boosting approach...\" and \"our method achieves a new state-of-the-art...\".\n*   the introduction states: \"in this paper we propose hopfield boosting, a novel ood detection method...\"\n*   these phrases directly align with the \"technical\" classification criteria: \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\" and \"introduction discusses: technical problem, proposed solution\".\n*   while the paper also presents empirical results (\"improving the fpr95 from...\"), these results serve to validate the effectiveness of the *new method* being proposed, making the primary contribution the method itself rather than solely a data-driven study of existing phenomena."
      },
      "file_name": "9a169c3f4b86bfd4b5c2c6825a6ca652fbd6c9a0.pdf"
    },
    {
      "success": true,
      "doc_id": "deac73061d9b2d5f5814449dd289da01",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the \"Open-world Prompt Tuning (OPT)\" problem, where vision-language models (VLMs) are tuned on base classes but evaluated on a mixture of both base and *new* (unseen during training) classes \\cite{zhou20243bx}.\n    *   **Importance and Challenge**: Existing prompt tuning methods are typically evaluated by assessing performance on base and new classes *separately*, or using a harmonic mean (H-metric). This lacks practicality for real-world applications where the class origin of test data is unknown. Current methods often improve base-class performance but degrade \"base-to-new discriminability\" (distinguishing between known and unknown classes) and \"new-class discriminability\" (classifying within new classes) \\cite{zhou20243bx}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Builds upon few-shot prompt tuning methods for VLMs (e.g., CLIP-based approaches) that fine-tune learnable prompts with limited labeled data \\cite{zhou20243bx}.\n    *   **Limitations of Previous Solutions**: Previous prompt tuning methods (like CoOp, SHIP) are shown to decrease base-to-new discriminability and new-class discriminability compared to zero-shot baselines. The H-metric, while comprehensive for separate evaluation, is unsuitable for practical open-world scenarios as it doesn't measure base-to-new discriminability directly \\cite{zhou20243bx}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes the Decomposed Prompt Tuning (DEPT) framework, which theoretically demonstrates that the OPT problem can be solved by incorporating Out-of-Distribution (OOD) detection into prompt tuning to enhance base-to-new discriminability \\cite{zhou20243bx}.\n    *   **Novelty**:\n        *   **DEPT Framework**: Decomposes the classification problem into an OOD detection task (distinguishing base from new classes) and two classification tasks (one for base, one for new classes), leveraging the strengths of both prompt tuning (for base classes) and zero-shot baselines (for new classes and OOD detection) \\cite{zhou20243bx}.\n        *   **DECOOP Approach**: Builds on DEPT by introducing:\n            *   **Ensemble New-Class Detectors**: Trained using a novel \"leave-out strategy\" that partitions base classes into simulated base and new classes, optimized with entropy loss to encourage low entropy on simulated base and high entropy on simulated new classes. An ensemble of K detectors covers the entire base class space \\cite{zhou20243bx}.\n            *   **Specialized Sub-Classifiers**: Each detector has a corresponding sub-classifier, trained to specialize in a specific base class space, further enhancing discriminability \\cite{zhou20243bx}.\n            *   **Router Mechanism**: Dynamically combines predictions from the sub-classifiers and a zero-shot classifier based on the OOD scores from the new-class detectors \\cite{zhou20243bx}.\n\n*   **Key Technical Contributions**\n    *   Formalization and exploration of the practical Open-world Prompt Tuning (OPT) problem \\cite{zhou20243bx}.\n    *   Introduction of the Decomposed Prompt Tuning (DEPT) framework, theoretically proving its effectiveness in improving performance by integrating OOD detection \\cite{zhou20243bx}.\n    *   Development of Decomposed Context Optimization (DECOOP), a novel prompt tuning approach featuring:\n        *   An ensemble of new-class detectors utilizing a leave-out strategy and entropy loss for robust base-to-new discriminability \\cite{zhou20243bx}.\n        *   Specialized sub-classifiers to enhance base-class and new-class discriminability \\cite{zhou20243bx}.\n        *   A dynamic router for intelligent prediction combination \\cite{zhou20243bx}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Comprehensive experiments were performed on 11 benchmark datasets \\cite{zhou20243bx}.\n    *   **Key Performance Metrics**: Overall accuracy on the mixed base and new classes was the primary metric \\cite{zhou20243bx}.\n    *   **Comparison Results**: DECOOP significantly outperforms current state-of-the-art comparison methods, achieving a notable 2% average accuracy improvement. The effectiveness of the underlying DEPT framework was also validated \\cite{zhou20243bx}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The new-class detectors in DECOOP leverage the knowledge of *new class names* during the testing stage, which is a specific assumption for the \"open-world\" setting explored. The effectiveness of the leave-out strategy and ensemble might be sensitive to the choice of K and the partitioning strategy \\cite{zhou20243bx}.\n    *   **Scope of Applicability**: Primarily applicable to scenarios where new classes are encountered at test time, and their names (or at least the concept of \"newness\") can be leveraged, even if no training data for them is available \\cite{zhou20243bx}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: DECOOP sets a new state-of-the-art in robust prompt tuning for open-world scenarios, demonstrating significant performance gains over existing methods \\cite{zhou20243bx}.\n    *   **Potential Impact**: Introduces a crucial paradigm shift in evaluating and designing prompt tuning methods for real-world applications by explicitly addressing the challenge of mixed base and new classes. It highlights the critical role of OOD detection in enhancing the robustness and practicality of VLMs \\cite{zhou20243bx}.",
      "intriguing_abstract": "The real world is dynamic, yet current vision-language models (VLMs) falter in Open-world Prompt Tuning (OPT), where models trained on known \"base\" classes must robustly classify both base and previously unseen \"new\" classes. Existing prompt tuning methods often degrade the critical ability to distinguish between known and unknown classes, hindering practical deployment. We introduce Decomposed Prompt Tuning (DEPT), a novel theoretical framework proving that integrating Out-of-Distribution (OOD) detection is fundamental to solving OPT.\n\nBuilding on DEPT, our Decomposed Context Optimization (DECOOP) method revolutionizes open-world VLM adaptation. DECOOP features an innovative ensemble of new-class detectors, trained with a unique leave-out strategy and entropy loss, to robustly identify OOD samples. Complementing this, specialized sub-classifiers and a dynamic router mechanism intelligently combine predictions, leveraging both prompt-tuned and zero-shot capabilities. Extensive experiments across 11 datasets demonstrate DECOOP's superior performance, achieving a significant 2% average accuracy improvement over state-of-the-art methods. This work establishes a new paradigm for designing practical, robust VLMs by explicitly addressing the open-world challenge through principled OOD integration.",
      "keywords": [
        "Open-world Prompt Tuning (OPT)",
        "Vision-Language Models (VLMs)",
        "Prompt Tuning",
        "Out-of-Distribution (OOD) Detection",
        "Decomposed Prompt Tuning (DEPT) framework",
        "DECOOP approach",
        "Base-to-New Discriminability",
        "Ensemble New-Class Detectors",
        "Leave-out Strategy",
        "Specialized Sub-Classifiers",
        "Dynamic Router Mechanism",
        "Real-world Open-world Scenarios",
        "State-of-the-art Accuracy Improvement"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/bcbee683ff34f87675448471d780541f7ae25ce9.pdf",
      "citation_key": "zhou20243bx",
      "metadata": {
        "title": "DeCoOp: Robust Prompt Tuning with Out-of-Distribution Detection",
        "authors": [
          "Zhi Zhou",
          "Ming Yang",
          "Jiang-Xin Shi",
          "Lan-Zhe Guo",
          "Yu-Feng Li"
        ],
        "published_date": "2024",
        "abstract": "Vision-language models (VLMs), such as CLIP, have demonstrated impressive zero-shot capabilities for various downstream tasks. Their performance can be further enhanced through few-shot prompt tuning methods. However, current studies evaluate the performance of learned prompts separately on base and new classes. This evaluation lacks practicality for real-world applications since downstream tasks cannot determine whether the data belongs to base or new classes in advance. In this paper, we explore a problem setting called Open-world Prompt Tuning (OPT), which involves tuning prompts on base classes and evaluating on a combination of base and new classes. By introducing Decomposed Prompt Tuning framework (DePT), we theoretically demonstrate that OPT can be solved by incorporating out-of-distribution detection into prompt tuning, thereby enhancing the base-to-new discriminability. Based on DePT, we present a novel prompt tuning approach, namely, Decomposed Context Optimization (DeCoOp), which introduces new-class detectors and sub-classifiers to further enhance the base-class and new-class discriminability. Experimental results on 11 benchmark datasets validate the effectiveness of DePT and demonstrate that DeCoOp outperforms current state-of-the-art methods, providing a significant 2% average accuracy improvement.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/bcbee683ff34f87675448471d780541f7ae25ce9.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the \"Open-world Prompt Tuning (OPT)\" problem, where vision-language models (VLMs) are tuned on base classes but evaluated on a mixture of both base and *new* (unseen during training) classes \\cite{zhou20243bx}.\n    *   **Importance and Challenge**: Existing prompt tuning methods are typically evaluated by assessing performance on base and new classes *separately*, or using a harmonic mean (H-metric). This lacks practicality for real-world applications where the class origin of test data is unknown. Current methods often improve base-class performance but degrade \"base-to-new discriminability\" (distinguishing between known and unknown classes) and \"new-class discriminability\" (classifying within new classes) \\cite{zhou20243bx}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Builds upon few-shot prompt tuning methods for VLMs (e.g., CLIP-based approaches) that fine-tune learnable prompts with limited labeled data \\cite{zhou20243bx}.\n    *   **Limitations of Previous Solutions**: Previous prompt tuning methods (like CoOp, SHIP) are shown to decrease base-to-new discriminability and new-class discriminability compared to zero-shot baselines. The H-metric, while comprehensive for separate evaluation, is unsuitable for practical open-world scenarios as it doesn't measure base-to-new discriminability directly \\cite{zhou20243bx}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes the Decomposed Prompt Tuning (DEPT) framework, which theoretically demonstrates that the OPT problem can be solved by incorporating Out-of-Distribution (OOD) detection into prompt tuning to enhance base-to-new discriminability \\cite{zhou20243bx}.\n    *   **Novelty**:\n        *   **DEPT Framework**: Decomposes the classification problem into an OOD detection task (distinguishing base from new classes) and two classification tasks (one for base, one for new classes), leveraging the strengths of both prompt tuning (for base classes) and zero-shot baselines (for new classes and OOD detection) \\cite{zhou20243bx}.\n        *   **DECOOP Approach**: Builds on DEPT by introducing:\n            *   **Ensemble New-Class Detectors**: Trained using a novel \"leave-out strategy\" that partitions base classes into simulated base and new classes, optimized with entropy loss to encourage low entropy on simulated base and high entropy on simulated new classes. An ensemble of K detectors covers the entire base class space \\cite{zhou20243bx}.\n            *   **Specialized Sub-Classifiers**: Each detector has a corresponding sub-classifier, trained to specialize in a specific base class space, further enhancing discriminability \\cite{zhou20243bx}.\n            *   **Router Mechanism**: Dynamically combines predictions from the sub-classifiers and a zero-shot classifier based on the OOD scores from the new-class detectors \\cite{zhou20243bx}.\n\n*   **Key Technical Contributions**\n    *   Formalization and exploration of the practical Open-world Prompt Tuning (OPT) problem \\cite{zhou20243bx}.\n    *   Introduction of the Decomposed Prompt Tuning (DEPT) framework, theoretically proving its effectiveness in improving performance by integrating OOD detection \\cite{zhou20243bx}.\n    *   Development of Decomposed Context Optimization (DECOOP), a novel prompt tuning approach featuring:\n        *   An ensemble of new-class detectors utilizing a leave-out strategy and entropy loss for robust base-to-new discriminability \\cite{zhou20243bx}.\n        *   Specialized sub-classifiers to enhance base-class and new-class discriminability \\cite{zhou20243bx}.\n        *   A dynamic router for intelligent prediction combination \\cite{zhou20243bx}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Comprehensive experiments were performed on 11 benchmark datasets \\cite{zhou20243bx}.\n    *   **Key Performance Metrics**: Overall accuracy on the mixed base and new classes was the primary metric \\cite{zhou20243bx}.\n    *   **Comparison Results**: DECOOP significantly outperforms current state-of-the-art comparison methods, achieving a notable 2% average accuracy improvement. The effectiveness of the underlying DEPT framework was also validated \\cite{zhou20243bx}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The new-class detectors in DECOOP leverage the knowledge of *new class names* during the testing stage, which is a specific assumption for the \"open-world\" setting explored. The effectiveness of the leave-out strategy and ensemble might be sensitive to the choice of K and the partitioning strategy \\cite{zhou20243bx}.\n    *   **Scope of Applicability**: Primarily applicable to scenarios where new classes are encountered at test time, and their names (or at least the concept of \"newness\") can be leveraged, even if no training data for them is available \\cite{zhou20243bx}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: DECOOP sets a new state-of-the-art in robust prompt tuning for open-world scenarios, demonstrating significant performance gains over existing methods \\cite{zhou20243bx}.\n    *   **Potential Impact**: Introduces a crucial paradigm shift in evaluating and designing prompt tuning methods for real-world applications by explicitly addressing the challenge of mixed base and new classes. It highlights the critical role of OOD detection in enhancing the robustness and practicality of VLMs \\cite{zhou20243bx}.",
        "keywords": [
          "Open-world Prompt Tuning (OPT)",
          "Vision-Language Models (VLMs)",
          "Prompt Tuning",
          "Out-of-Distribution (OOD) Detection",
          "Decomposed Prompt Tuning (DEPT) framework",
          "DECOOP approach",
          "Base-to-New Discriminability",
          "Ensemble New-Class Detectors",
          "Leave-out Strategy",
          "Specialized Sub-Classifiers",
          "Dynamic Router Mechanism",
          "Real-world Open-world Scenarios",
          "State-of-the-art Accuracy Improvement"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **identifies a problem/gap:** \"current studies evaluate the performance of learned prompts separately on base and new classes. this evaluation lacks practicality...\"\n2.  **proposes a new problem setting:** \"we explore a problem setting called open-world prompt tuning (opt)\"\n3.  **introduces a new framework:** \"by introducing decomposed prompt tuning framework (dept), we theoretically demonstrate that opt can be solved...\"\n4.  **presents a novel approach/method:** \"based on dept, we present a novel prompt tuning approach, namely, decomposed context optimization (decoop), which introduces new-class detectors and sub-classifiers...\"\n5.  **provides empirical validation:** \"experimental results on 11 benchmark datasets validate the effectiveness of dept and demonstrate that decoop outperforms state-of-the-art methods...\"\n\nthe core contribution of this paper is the development and presentation of a **novel prompt tuning approach (decoop)** and a **framework (dept)** to address a **newly defined problem setting (opt)**. while it includes theoretical demonstrations and extensive empirical validation, these elements serve to support and prove the effectiveness of the *new method* being proposed.\n\ntherefore, the paper primarily fits the **technical** classification.\n\n**classification:** technical"
      },
      "file_name": "bcbee683ff34f87675448471d780541f7ae25ce9.pdf"
    },
    {
      "success": true,
      "doc_id": "1b90568f8606e583738c332192399de7",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical problem of **Out-of-Distribution (OOD) detection** in machine learning models, particularly the challenge of safely deploying these models in real-world, open-world settings \\cite{vishwakarma2024z1m}.\n    *   The core issue is that existing OOD detection methods, which rely on scoring functions and static thresholds, often lead to **unacceptably high False Positive Rates (FPR)** (e.g., 60-96% in Open-OOD benchmark) when thresholds are set to achieve a desired True Positive Rate (TPR, e.g., 95%).\n    *   This problem is important because high FPR can have catastrophic consequences in safety-critical applications (e.g., medical diagnosis, autonomous driving), where misclassifying an OOD sample as in-distribution (ID) is more dangerous than deferring to a human.\n    *   The challenge is exacerbated by the dynamic nature of OOD samples encountered after deployment, making static thresholds ineffective and requiring adaptive mechanisms that can guarantee FPR control while minimizing human intervention.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods primarily focus on designing scoring functions and are largely limited to **static settings** where thresholds are set a priori using ID data \\cite{vishwakarma2024z1m}.\n    *   These previous solutions often fail to guarantee FPR control in dynamic environments where OOD data distributions can vary, leading to highly fluctuating and often high FPRs.\n    *   The work positions itself as **complementary** to existing scoring function development, focusing instead on a framework for safely adapting the detection threshold on the fly, rather than proposing a new scoring function.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a **mathematically grounded human-in-the-loop OOD detection framework** that adaptively updates the detection threshold (`Ë†Î»t`) over time \\cite{vishwakarma2024z1m}.\n    *   **Adaptive Threshold Estimation**: The system uses human expert feedback on a subset of samples to estimate the FPR and adjust the threshold.\n    *   **Importance Sampling**: To obtain an unbiased estimate of FPR and detect distribution shifts, human feedback is solicited for all points declared OOD, and with a small probability `p` for points declared ID.\n    *   **Upper Confidence Bound (UCB) for FPR**: The framework constructs an anytime-valid UCB (`Ïˆ(t, Î´)`) on the estimated FPR, based on the **Law of Iterated Logarithm (LIL)** for martingales. This UCB is crucial for ensuring safety by providing a high-probability upper bound on the true FPR.\n    *   **Threshold Optimization**: At each time `t`, the threshold `Ë†Î»t` is chosen by solving `arg min Î» s.t. dFPR(Î», t) + Ïˆ(t, Î´) â‰¤ Î±`, where `dFPR(Î», t)` is the unbiased empirical FPR estimate, `Ïˆ(t, Î´)` is the LIL-based UCB, and `Î±` is the desired maximum FPR. This ensures the FPR constraint is met while maximizing TPR (by minimizing `Î»`).\n    *   **Generality**: The framework is designed to work with *any* existing OOD scoring function.\n\n*   **Key Technical Contributions**\n    *   **Novel Human-in-the-Loop Framework**: A mathematically grounded framework for adaptive OOD detection thresholding using expert feedback \\cite{vishwakarma2024z1m}.\n    *   **Guaranteed FPR Control**: Provides theoretical guarantees that the framework maintains FPR below a desired level (`Î±`) at all times, approaching the optimal threshold `Î»â‹†` from above (`Ë†Î»t â‰¥ Î»â‹†`).\n    *   **Unbiased FPR Estimator**: Develops an unbiased estimator for the true FPR, even with dependent samples due to adaptive thresholding and importance sampling.\n    *   **Anytime-Valid Confidence Bounds**: Derives a novel UCB based on the Law of Iterated Logarithm (LIL) that is simultaneously valid for all thresholds and all times, crucial for the adaptive thresholding.\n    *   **Theoretical Analysis of Convergence**: Provides bounds on the \"time to reach feasibility\" (when a safe threshold can be found) and \"time to reach Î·-optimality\" (when the system operates close to the optimal TPR while controlling FPR).\n    *   **Compatibility**: Demonstrates the framework's ability to integrate with any OOD scoring function.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive simulations were performed on both synthetic data and benchmark OOD datasets (image classification tasks) \\cite{vishwakarma2024z1m}. These included stationary settings and settings with distribution shifts.\n    *   **Baselines**: The method was compared against a non-adaptive baseline (\"TPR-95\") which sets a static threshold to achieve 95% TPR using ID data. Different confidence interval choices (No-UCB, LIL, Hoeffding) for the adaptive method were also evaluated.\n    *   **Key Performance Metrics**: FPR and TPR were the primary metrics.\n    *   **Comparison Results**:\n        *   The proposed LIL-based adaptive method consistently achieved **lower FPR** (e.g., maintaining FPR at most 5%) compared to the non-adaptive TPR-95 baseline, while maximizing TPR.\n        *   In stationary settings, the LIL method successfully satisfied the FPR constraint at all times and produced high TPR.\n        *   The framework demonstrated **compatibility with various OOD scoring functions**, validating its general applicability.\n        *   With a simple adaptation using a **windowed approach**, the method effectively handled **distribution shifts** in OOD data, quickly re-adapting to maintain FPR control.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The theoretical guarantees for FPR control and convergence are provided under assumptions of stationary settings (distributions do not change over time) and sub-Gaussian tails for score distributions \\cite{vishwakarma2024z1m}.\n    *   **Scope of Applicability**: The framework is designed to be complementary to the development of OOD scoring functions, focusing on the threshold adaptation mechanism rather than new scoring functions. It requires human feedback, which implies a human-in-the-loop setting.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in OOD detection by providing a **mathematically rigorous framework for guaranteed FPR control** in dynamic, open-world settings \\cite{vishwakarma2024z1m}.\n    *   Its ability to adapt thresholds on the fly with theoretical guarantees, while minimizing human intervention, is crucial for the **safe and reliable deployment of ML models** in safety-critical applications.\n    *   The development of an anytime-valid UCB for dependent samples (via LIL for martingales) is a notable technical innovation.\n    *   The framework's generality (compatible with any scoring function) and demonstrated effectiveness in handling distribution shifts make it a valuable contribution for future research in robust and adaptive machine learning systems.",
      "intriguing_abstract": "Deploying machine learning models safely in open-world settings is critically hampered by the unacceptably high False Positive Rates (FPRs) of existing Out-of-Distribution (OOD) detection methods, posing severe risks in safety-critical applications. Current static thresholding approaches fundamentally fail to guarantee FPR control, leading to catastrophic consequences when OOD data distributions shift.\n\nWe introduce a novel, mathematically grounded human-in-the-loop framework that revolutionizes OOD detection by adaptively updating the detection threshold on the fly. Our method provides robust theoretical guarantees for maintaining FPR below a desired level at all times, even with dynamic OOD samples. A key innovation is the development of an anytime-valid Upper Confidence Bound (UCB) on FPR, derived from the Law of Iterated Logarithm (LIL) for martingales, enabling unbiased FPR estimation despite dependent samples and adaptive thresholding. This framework is universally compatible with any OOD scoring function and demonstrates superior FPR control and adaptability to distribution shifts in extensive experiments. This work significantly advances the safe and reliable deployment of ML systems, offering a crucial step towards trustworthy AI in real-world applications.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "False Positive Rate (FPR) control",
        "human-in-the-loop framework",
        "adaptive thresholding",
        "anytime-valid Upper Confidence Bound (UCB)",
        "Law of Iterated Logarithm (LIL)",
        "guaranteed FPR control",
        "distribution shifts",
        "safety-critical applications",
        "unbiased FPR estimator",
        "real-world deployment",
        "theoretical guarantees",
        "OOD scoring function compatibility"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/b3f21af3032246b6fa87e05a6d9455433b25ce55.pdf",
      "citation_key": "vishwakarma2024z1m",
      "metadata": {
        "title": "Taming False Positives in Out-of-Distribution Detection with Human Feedback",
        "authors": [
          "Harit Vishwakarma",
          "Heguang Lin",
          "Ramya Korlakai Vinayak"
        ],
        "published_date": "2024",
        "abstract": "Robustness to out-of-distribution (OOD) samples is crucial for safely deploying machine learning models in the open world. Recent works have focused on designing scoring functions to quantify OOD uncertainty. Setting appropriate thresholds for these scoring functions for OOD detection is challenging as OOD samples are often unavailable up front. Typically, thresholds are set to achieve a desired true positive rate (TPR), e.g., $95\\%$ TPR. However, this can lead to very high false positive rates (FPR), ranging from 60 to 96\\%, as observed in the Open-OOD benchmark. In safety-critical real-life applications, e.g., medical diagnosis, controlling the FPR is essential when dealing with various OOD samples dynamically. To address these challenges, we propose a mathematically grounded OOD detection framework that leverages expert feedback to \\emph{safely} update the threshold on the fly. We provide theoretical results showing that it is guaranteed to meet the FPR constraint at all times while minimizing the use of human feedback. Another key feature of our framework is that it can work with any scoring function for OOD uncertainty quantification. Empirical evaluation of our system on synthetic and benchmark OOD datasets shows that our method can maintain FPR at most $5\\%$ while maximizing TPR.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b3f21af3032246b6fa87e05a6d9455433b25ce55.pdf",
        "venue": "International Conference on Artificial Intelligence and Statistics",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical problem of **Out-of-Distribution (OOD) detection** in machine learning models, particularly the challenge of safely deploying these models in real-world, open-world settings \\cite{vishwakarma2024z1m}.\n    *   The core issue is that existing OOD detection methods, which rely on scoring functions and static thresholds, often lead to **unacceptably high False Positive Rates (FPR)** (e.g., 60-96% in Open-OOD benchmark) when thresholds are set to achieve a desired True Positive Rate (TPR, e.g., 95%).\n    *   This problem is important because high FPR can have catastrophic consequences in safety-critical applications (e.g., medical diagnosis, autonomous driving), where misclassifying an OOD sample as in-distribution (ID) is more dangerous than deferring to a human.\n    *   The challenge is exacerbated by the dynamic nature of OOD samples encountered after deployment, making static thresholds ineffective and requiring adaptive mechanisms that can guarantee FPR control while minimizing human intervention.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection methods primarily focus on designing scoring functions and are largely limited to **static settings** where thresholds are set a priori using ID data \\cite{vishwakarma2024z1m}.\n    *   These previous solutions often fail to guarantee FPR control in dynamic environments where OOD data distributions can vary, leading to highly fluctuating and often high FPRs.\n    *   The work positions itself as **complementary** to existing scoring function development, focusing instead on a framework for safely adapting the detection threshold on the fly, rather than proposing a new scoring function.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a **mathematically grounded human-in-the-loop OOD detection framework** that adaptively updates the detection threshold (`Ë†Î»t`) over time \\cite{vishwakarma2024z1m}.\n    *   **Adaptive Threshold Estimation**: The system uses human expert feedback on a subset of samples to estimate the FPR and adjust the threshold.\n    *   **Importance Sampling**: To obtain an unbiased estimate of FPR and detect distribution shifts, human feedback is solicited for all points declared OOD, and with a small probability `p` for points declared ID.\n    *   **Upper Confidence Bound (UCB) for FPR**: The framework constructs an anytime-valid UCB (`Ïˆ(t, Î´)`) on the estimated FPR, based on the **Law of Iterated Logarithm (LIL)** for martingales. This UCB is crucial for ensuring safety by providing a high-probability upper bound on the true FPR.\n    *   **Threshold Optimization**: At each time `t`, the threshold `Ë†Î»t` is chosen by solving `arg min Î» s.t. dFPR(Î», t) + Ïˆ(t, Î´) â‰¤ Î±`, where `dFPR(Î», t)` is the unbiased empirical FPR estimate, `Ïˆ(t, Î´)` is the LIL-based UCB, and `Î±` is the desired maximum FPR. This ensures the FPR constraint is met while maximizing TPR (by minimizing `Î»`).\n    *   **Generality**: The framework is designed to work with *any* existing OOD scoring function.\n\n*   **Key Technical Contributions**\n    *   **Novel Human-in-the-Loop Framework**: A mathematically grounded framework for adaptive OOD detection thresholding using expert feedback \\cite{vishwakarma2024z1m}.\n    *   **Guaranteed FPR Control**: Provides theoretical guarantees that the framework maintains FPR below a desired level (`Î±`) at all times, approaching the optimal threshold `Î»â‹†` from above (`Ë†Î»t â‰¥ Î»â‹†`).\n    *   **Unbiased FPR Estimator**: Develops an unbiased estimator for the true FPR, even with dependent samples due to adaptive thresholding and importance sampling.\n    *   **Anytime-Valid Confidence Bounds**: Derives a novel UCB based on the Law of Iterated Logarithm (LIL) that is simultaneously valid for all thresholds and all times, crucial for the adaptive thresholding.\n    *   **Theoretical Analysis of Convergence**: Provides bounds on the \"time to reach feasibility\" (when a safe threshold can be found) and \"time to reach Î·-optimality\" (when the system operates close to the optimal TPR while controlling FPR).\n    *   **Compatibility**: Demonstrates the framework's ability to integrate with any OOD scoring function.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive simulations were performed on both synthetic data and benchmark OOD datasets (image classification tasks) \\cite{vishwakarma2024z1m}. These included stationary settings and settings with distribution shifts.\n    *   **Baselines**: The method was compared against a non-adaptive baseline (\"TPR-95\") which sets a static threshold to achieve 95% TPR using ID data. Different confidence interval choices (No-UCB, LIL, Hoeffding) for the adaptive method were also evaluated.\n    *   **Key Performance Metrics**: FPR and TPR were the primary metrics.\n    *   **Comparison Results**:\n        *   The proposed LIL-based adaptive method consistently achieved **lower FPR** (e.g., maintaining FPR at most 5%) compared to the non-adaptive TPR-95 baseline, while maximizing TPR.\n        *   In stationary settings, the LIL method successfully satisfied the FPR constraint at all times and produced high TPR.\n        *   The framework demonstrated **compatibility with various OOD scoring functions**, validating its general applicability.\n        *   With a simple adaptation using a **windowed approach**, the method effectively handled **distribution shifts** in OOD data, quickly re-adapting to maintain FPR control.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The theoretical guarantees for FPR control and convergence are provided under assumptions of stationary settings (distributions do not change over time) and sub-Gaussian tails for score distributions \\cite{vishwakarma2024z1m}.\n    *   **Scope of Applicability**: The framework is designed to be complementary to the development of OOD scoring functions, focusing on the threshold adaptation mechanism rather than new scoring functions. It requires human feedback, which implies a human-in-the-loop setting.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in OOD detection by providing a **mathematically rigorous framework for guaranteed FPR control** in dynamic, open-world settings \\cite{vishwakarma2024z1m}.\n    *   Its ability to adapt thresholds on the fly with theoretical guarantees, while minimizing human intervention, is crucial for the **safe and reliable deployment of ML models** in safety-critical applications.\n    *   The development of an anytime-valid UCB for dependent samples (via LIL for martingales) is a notable technical innovation.\n    *   The framework's generality (compatible with any scoring function) and demonstrated effectiveness in handling distribution shifts make it a valuable contribution for future research in robust and adaptive machine learning systems.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "False Positive Rate (FPR) control",
          "human-in-the-loop framework",
          "adaptive thresholding",
          "anytime-valid Upper Confidence Bound (UCB)",
          "Law of Iterated Logarithm (LIL)",
          "guaranteed FPR control",
          "distribution shifts",
          "safety-critical applications",
          "unbiased FPR estimator",
          "real-world deployment",
          "theoretical guarantees",
          "OOD scoring function compatibility"
        ],
        "paper_type": "the paper should be classified as **theoretical**.\n\nhere's the reasoning:\n\n1.  **strong indicators for theoretical:**\n    *   the abstract explicitly states: \"we propose a **mathematically grounded** ood detection framework\".\n    *   it further emphasizes: \"we provide **theoretical results showing that it is guaranteed** to meet the fpr constraint at all times while minimizing the use of human feedback.\"\n    *   the classification criteria for \"theoretical\" include: \"mathematical analysis, proofs, formal models\", and the abstract's language directly aligns with this, highlighting the mathematical foundation and provable guarantees.\n\n2.  **overlap with technical and empirical:**\n    *   the paper also \"propose[s] a... framework\" which makes it technical (presenting a new method).\n    *   it includes \"empirical evaluation of our system\" which makes it empirical (data-driven study).\n    *   however, the question asks for **one type**. in many ai/ml papers, a new method (technical) is proposed, its properties are proven (theoretical), and it's evaluated (empirical). when the mathematical grounding and provable guarantees are highlighted as a core contribution, it often leans towards theoretical. the \"guaranteed\" aspect is a significant theoretical contribution that distinguishes it from a purely heuristic or empirically-driven technical proposal.\n\n3.  **exclusion of other types:**\n    *   it is not a **survey** as it proposes a new framework, not reviews existing literature.\n    *   it is not a **case_study** as it doesn't focus on a specific application in detail.\n    *   it is not a **position** paper as it presents a solution, not an argument for a viewpoint.\n    *   it is not a **short** paper; the venue (international conference on artificial intelligence and statistics) suggests a full research paper.\n\nthe emphasis on \"mathematically grounded\" and \"theoretical results showing that it is guaranteed\" points to the core contribution being the formal analysis and proofs behind the proposed framework, making \"theoretical\" the most appropriate primary classification."
      },
      "file_name": "b3f21af3032246b6fa87e05a6d9455433b25ce55.pdf"
    },
    {
      "success": true,
      "doc_id": "b77cd28f6555cb221450860a84a69cd5",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/83d79426ea8345b73c9ce4848bc46c4f797e5fbb.pdf",
      "citation_key": "wang2024y55",
      "metadata": {
        "title": "Credal Wrapper of Model Averaging for Uncertainty Estimation on Out-Of-Distribution Detection",
        "authors": [
          "Kaizheng Wang",
          "Fabio Cuzzolin",
          "Keivan K1 Shariatmadar",
          "David Moens",
          "Hans Hallez"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/83d79426ea8345b73c9ce4848bc46c4f797e5fbb.pdf",
        "venue": "arXiv.org",
        "citationCount": 9,
        "score": 9.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "83d79426ea8345b73c9ce4848bc46c4f797e5fbb.pdf"
    },
    {
      "success": true,
      "doc_id": "6f08371b03973bb283feb9f64fff6e11",
      "summary": "Here's a focused summary of the technical paper \\cite{xu2024ufg} for a literature review:\n\n### Focused Summary for Literature Review: Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the critical need for detecting anomalies and out-of-distribution (OOD) samples in machine learning systems, which is essential for maintaining their reliability and trustworthiness.\n    *   **Importance and Challenge:**\n        *   Most machine learning models operate under a closed-set assumption, which often fails in real-world scenarios where test data can come from unknown distributions.\n        *   Anomalies and OOD samples severely degrade model performance and reliability.\n        *   The recent emergence of Large Language Models (LLMs) and Multimodal LLMs (MLLMs) with advanced comprehension and generative capabilities presents a significant, yet underexplored, paradigm shift for these detection tasks.\n        *   A comprehensive and systematic review of how LLMs are being utilized in this rapidly expanding field was lacking.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper positions itself against traditional anomaly and OOD detection methods (e.g., probabilistic approaches, deep learning techniques) by focusing specifically on the integration and impact of LLMs.\n    *   **Limitations of Previous Solutions/Surveys:**\n        *   Prior unified frameworks for OOD detection (e.g., Salehi et al., 2021; Yang et al., 2024a) did not delve into LLM utilization.\n        *   Existing reviews on language models for anomaly detection (e.g., Su et al., 2024) did not cover LLMs with emergent abilities or OOD detection.\n        *   Surveys on vision-language models for detection (e.g., Miyai et al., 2024a) neglected other data modalities.\n    *   **Positioning of this Work:** \\cite{xu2024ufg} aims to provide the first systematic survey covering both anomaly and OOD detection across various data domains, specifically concentrating on the diverse ways LLMs are employed, and proposing a novel taxonomy to structure the field.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (of the survey):** The paper's core approach is to propose a novel taxonomy that categorizes existing LLM-based anomaly and OOD detection methods into two fundamental classes based on the role LLMs play:\n        *   **LLMs for Detection:** Methods where LLMs directly act as detectors.\n            *   **Prompting-based Detection:** Involves constructing structured prompts to guide LLMs (frozen or fine-tuned) to generate detection results. This includes techniques like role-play prompting, in-context learning, and Chain-of-Thought (CoT) reasoning.\n            *   **Contrasting-based Detection:** Leverages MLLMs (e.g., CLIP) pre-trained with contrastive objectives, using similarity scores between image and text features for detection, with or without additional tuning.\n        *   **LLMs for Generation:** Methods where LLMs' emergent abilities are used to generate augmented data, pseudo-labels, textual descriptions, or explanations to aid detection.\n    *   **Novelty/Difference:** The innovation lies in this comprehensive, LLM-centric taxonomy that systematically organizes the rapidly evolving landscape of LLM applications in anomaly and OOD detection, addressing the gaps in previous surveys by covering diverse data modalities and the full spectrum of LLM roles. It also redefines anomaly and OOD detection within the LLM context.\n\n4.  **Key Technical Contributions**\n    *   **Novel Taxonomy:** Introduction of a new, two-tiered taxonomy (\"LLMs for Detection\" and \"LLMs for Generation\") to systematically classify and understand the diverse applications of LLMs in anomaly and OOD detection.\n    *   **Comprehensive Review:** Provides a structured and up-to-date review of specific technical methods within each category, detailing approaches like prompt engineering, parameter-efficient fine-tuning (PEFT), and contrastive learning strategies.\n    *   **Problem Redefinition:** Offers clear definitions for \"LLM-based Anomaly Detection\" and \"LLM-based OOD Detection,\" distinguishing between covariate and semantic shifts in the context of LLMs.\n    *   **Identification of Challenges and Future Directions:** (As stated in the abstract, though not detailed in the provided snippet) The survey identifies emerging challenges and outlines promising avenues for future research in this interdisciplinary field.\n    *   **Curated Reading List:** Provides an up-to-date reading list of relevant papers, serving as a valuable resource for researchers.\n\n5.  **Experimental Validation (as discussed in the survey about reviewed papers)**\n    *   The survey \\cite{xu2024ufg} itself does not present new experimental results but synthesizes findings from the reviewed literature.\n    *   **Key Performance Metrics and Comparison Results (from reviewed papers):**\n        *   **Prompting-based methods:** Studies like SIGLLM, LLMAD, and LogPrompt demonstrate improved anomaly detection performance on time series and log data by employing sophisticated prompt engineering (e.g., role-play, in-context learning, CoT). For visual data, methods leveraging MLLMs like GPT-4V (e.g., GPT-4V-AD, Cao et al., 2023) show promising results by transforming data or incorporating cues.\n        *   **Tuning-based methods:** Approaches using PEFT (e.g., LoRA in Tabular, AnomalyGPT, Myriad) are shown to effectively adapt LLMs for specific detection tasks and modalities, yielding enhanced performance while mitigating computational costs.\n        *   **Contrasting-based methods:** MLLMs like CLIP exhibit strong zero-shot classification capabilities for OOD and anomaly detection. The survey notes that binary zero-shot frameworks (e.g., CLIP-AC) generally outperform one-class designs. Methods incorporating anomaly/OOD prompts or pseudo-OOD labels (e.g., ZOC, NegLabel, CLIPScope) are reported to improve OOD detection by addressing the closed-world assumption of base MLLMs.\n\n6.  **Limitations & Scope**\n    *   **Scope of Applicability:** The survey focuses on LLM-based methods for anomaly and OOD detection across various data modalities (text, time series, logs, images, videos).\n    *   **Technical Limitations (of reviewed methods, as highlighted by the survey):**\n        *   **Modality Gap:** A significant challenge for directly applying frozen LLMs to non-textual data, often requiring data transformation or fine-tuning.\n        *   **Computational Cost:** Fine-tuning entire LLMs is computationally expensive, necessitating parameter-efficient fine-tuning (PEFT) techniques.\n        *   **Closed-World Assumption:** Pre-trained MLLMs often perform zero-shot classification in a closed-world setting, which can lead to misclassification of truly OOD samples into known categories.\n        *   **Prompt Engineering Dependency:** The effectiveness of prompting-based methods heavily relies on the quality and design of prompt templates.\n        *   **Limited OOD Prompting:** Direct prompting for OOD detection (as opposed to anomaly detection) is less explored in current research.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{xu2024ufg} significantly advances the technical state-of-the-art by providing the first comprehensive and systematic overview of the rapidly evolving field of LLM-based anomaly and OOD detection. It synthesizes diverse approaches into a coherent framework, which was previously lacking.\n    *   **Potential Impact on Future Research:**\n        *   The proposed taxonomy offers a foundational framework for researchers to categorize, understand, and build upon existing methods.\n        *   By clearly defining LLM-based anomaly and OOD detection, it provides a common ground for future problem formulations.\n        *   The identification of current limitations (e.g., modality gap, computational cost, closed-world issues) implicitly guides future research toward addressing these critical challenges.\n        *   The survey's emphasis on LLMs' emergent abilities for both detection and generation highlights promising avenues for novel research directions.",
      "intriguing_abstract": "Ensuring the reliability and trustworthiness of machine learning systems in real-world, open-set environments demands robust anomaly and out-of-distribution (OOD) detection. The recent advent of Large Language Models (LLMs) and Multimodal LLMs (MLLMs) presents an unprecedented paradigm shift, offering powerful new avenues for these critical tasks. Despite their transformative potential, a systematic understanding of LLM applications in this rapidly evolving domain has been lacking.\n\nThis paper presents the *first* comprehensive survey, meticulously charting the landscape of LLM-based anomaly and OOD detection across diverse data modalities. We introduce a novel, two-tiered taxonomy that categorizes methods based on the LLM's role: 'LLMs for Detection,' encompassing sophisticated prompting-based techniques (e.g., in-context learning, Chain-of-Thought) and contrastive learning approaches, and 'LLMs for Generation,' leveraging emergent abilities for data augmentation or pseudo-labeling. We redefine core concepts, synthesize cutting-edge research, and identify critical challenges such as the modality gap, computational costs, and closed-world assumptions. By providing a foundational framework and curated reading list, our survey aims to accelerate research, guiding the development of more robust and trustworthy AI systems.",
      "keywords": [
        "Anomaly detection",
        "Out-of-distribution (OOD) detection",
        "Large Language Models (LLMs)",
        "Multimodal LLMs (MLLMs)",
        "Novel taxonomy",
        "LLMs for Detection",
        "LLMs for Generation",
        "Prompting-based detection",
        "Contrasting-based detection",
        "Parameter-efficient fine-tuning (PEFT)",
        "Modality gap",
        "Closed-world assumption",
        "Emergent abilities",
        "Systematic survey"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/48020e5f1a0d5703f6169c20051eeb056194c25b.pdf",
      "citation_key": "xu2024ufg",
      "metadata": {
        "title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
        "authors": [
          "Ruiyao Xu",
          "Kaize Ding"
        ],
        "published_date": "2024",
        "abstract": "Detecting anomalies or out-of-distribution (OOD) samples is critical for maintaining the reliability and trustworthiness of machine learning systems. Recently, Large Language Models (LLMs) have demonstrated their effectiveness not only in natural language processing but also in broader applications due to their advanced comprehension and generative capabilities. The integration of LLMs into anomaly and OOD detection marks a significant shift from the traditional paradigm in the field. This survey focuses on the problem of anomaly and OOD detection under the context of LLMs. We propose a new taxonomy to categorize existing approaches into two classes based on the role played by LLMs. Following our proposed taxonomy, we further discuss the related work under each of the categories and finally discuss potential challenges and directions for future research in this field. We also provide an up-to-date reading list of relevant papers.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/48020e5f1a0d5703f6169c20051eeb056194c25b.pdf",
        "venue": "North American Chapter of the Association for Computational Linguistics",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Here's a focused summary of the technical paper \\cite{xu2024ufg} for a literature review:\n\n### Focused Summary for Literature Review: Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the critical need for detecting anomalies and out-of-distribution (OOD) samples in machine learning systems, which is essential for maintaining their reliability and trustworthiness.\n    *   **Importance and Challenge:**\n        *   Most machine learning models operate under a closed-set assumption, which often fails in real-world scenarios where test data can come from unknown distributions.\n        *   Anomalies and OOD samples severely degrade model performance and reliability.\n        *   The recent emergence of Large Language Models (LLMs) and Multimodal LLMs (MLLMs) with advanced comprehension and generative capabilities presents a significant, yet underexplored, paradigm shift for these detection tasks.\n        *   A comprehensive and systematic review of how LLMs are being utilized in this rapidly expanding field was lacking.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper positions itself against traditional anomaly and OOD detection methods (e.g., probabilistic approaches, deep learning techniques) by focusing specifically on the integration and impact of LLMs.\n    *   **Limitations of Previous Solutions/Surveys:**\n        *   Prior unified frameworks for OOD detection (e.g., Salehi et al., 2021; Yang et al., 2024a) did not delve into LLM utilization.\n        *   Existing reviews on language models for anomaly detection (e.g., Su et al., 2024) did not cover LLMs with emergent abilities or OOD detection.\n        *   Surveys on vision-language models for detection (e.g., Miyai et al., 2024a) neglected other data modalities.\n    *   **Positioning of this Work:** \\cite{xu2024ufg} aims to provide the first systematic survey covering both anomaly and OOD detection across various data domains, specifically concentrating on the diverse ways LLMs are employed, and proposing a novel taxonomy to structure the field.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (of the survey):** The paper's core approach is to propose a novel taxonomy that categorizes existing LLM-based anomaly and OOD detection methods into two fundamental classes based on the role LLMs play:\n        *   **LLMs for Detection:** Methods where LLMs directly act as detectors.\n            *   **Prompting-based Detection:** Involves constructing structured prompts to guide LLMs (frozen or fine-tuned) to generate detection results. This includes techniques like role-play prompting, in-context learning, and Chain-of-Thought (CoT) reasoning.\n            *   **Contrasting-based Detection:** Leverages MLLMs (e.g., CLIP) pre-trained with contrastive objectives, using similarity scores between image and text features for detection, with or without additional tuning.\n        *   **LLMs for Generation:** Methods where LLMs' emergent abilities are used to generate augmented data, pseudo-labels, textual descriptions, or explanations to aid detection.\n    *   **Novelty/Difference:** The innovation lies in this comprehensive, LLM-centric taxonomy that systematically organizes the rapidly evolving landscape of LLM applications in anomaly and OOD detection, addressing the gaps in previous surveys by covering diverse data modalities and the full spectrum of LLM roles. It also redefines anomaly and OOD detection within the LLM context.\n\n4.  **Key Technical Contributions**\n    *   **Novel Taxonomy:** Introduction of a new, two-tiered taxonomy (\"LLMs for Detection\" and \"LLMs for Generation\") to systematically classify and understand the diverse applications of LLMs in anomaly and OOD detection.\n    *   **Comprehensive Review:** Provides a structured and up-to-date review of specific technical methods within each category, detailing approaches like prompt engineering, parameter-efficient fine-tuning (PEFT), and contrastive learning strategies.\n    *   **Problem Redefinition:** Offers clear definitions for \"LLM-based Anomaly Detection\" and \"LLM-based OOD Detection,\" distinguishing between covariate and semantic shifts in the context of LLMs.\n    *   **Identification of Challenges and Future Directions:** (As stated in the abstract, though not detailed in the provided snippet) The survey identifies emerging challenges and outlines promising avenues for future research in this interdisciplinary field.\n    *   **Curated Reading List:** Provides an up-to-date reading list of relevant papers, serving as a valuable resource for researchers.\n\n5.  **Experimental Validation (as discussed in the survey about reviewed papers)**\n    *   The survey \\cite{xu2024ufg} itself does not present new experimental results but synthesizes findings from the reviewed literature.\n    *   **Key Performance Metrics and Comparison Results (from reviewed papers):**\n        *   **Prompting-based methods:** Studies like SIGLLM, LLMAD, and LogPrompt demonstrate improved anomaly detection performance on time series and log data by employing sophisticated prompt engineering (e.g., role-play, in-context learning, CoT). For visual data, methods leveraging MLLMs like GPT-4V (e.g., GPT-4V-AD, Cao et al., 2023) show promising results by transforming data or incorporating cues.\n        *   **Tuning-based methods:** Approaches using PEFT (e.g., LoRA in Tabular, AnomalyGPT, Myriad) are shown to effectively adapt LLMs for specific detection tasks and modalities, yielding enhanced performance while mitigating computational costs.\n        *   **Contrasting-based methods:** MLLMs like CLIP exhibit strong zero-shot classification capabilities for OOD and anomaly detection. The survey notes that binary zero-shot frameworks (e.g., CLIP-AC) generally outperform one-class designs. Methods incorporating anomaly/OOD prompts or pseudo-OOD labels (e.g., ZOC, NegLabel, CLIPScope) are reported to improve OOD detection by addressing the closed-world assumption of base MLLMs.\n\n6.  **Limitations & Scope**\n    *   **Scope of Applicability:** The survey focuses on LLM-based methods for anomaly and OOD detection across various data modalities (text, time series, logs, images, videos).\n    *   **Technical Limitations (of reviewed methods, as highlighted by the survey):**\n        *   **Modality Gap:** A significant challenge for directly applying frozen LLMs to non-textual data, often requiring data transformation or fine-tuning.\n        *   **Computational Cost:** Fine-tuning entire LLMs is computationally expensive, necessitating parameter-efficient fine-tuning (PEFT) techniques.\n        *   **Closed-World Assumption:** Pre-trained MLLMs often perform zero-shot classification in a closed-world setting, which can lead to misclassification of truly OOD samples into known categories.\n        *   **Prompt Engineering Dependency:** The effectiveness of prompting-based methods heavily relies on the quality and design of prompt templates.\n        *   **Limited OOD Prompting:** Direct prompting for OOD detection (as opposed to anomaly detection) is less explored in current research.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{xu2024ufg} significantly advances the technical state-of-the-art by providing the first comprehensive and systematic overview of the rapidly evolving field of LLM-based anomaly and OOD detection. It synthesizes diverse approaches into a coherent framework, which was previously lacking.\n    *   **Potential Impact on Future Research:**\n        *   The proposed taxonomy offers a foundational framework for researchers to categorize, understand, and build upon existing methods.\n        *   By clearly defining LLM-based anomaly and OOD detection, it provides a common ground for future problem formulations.\n        *   The identification of current limitations (e.g., modality gap, computational cost, closed-world issues) implicitly guides future research toward addressing these critical challenges.\n        *   The survey's emphasis on LLMs' emergent abilities for both detection and generation highlights promising avenues for novel research directions.",
        "keywords": [
          "Anomaly detection",
          "Out-of-distribution (OOD) detection",
          "Large Language Models (LLMs)",
          "Multimodal LLMs (MLLMs)",
          "Novel taxonomy",
          "LLMs for Detection",
          "LLMs for Generation",
          "Prompting-based detection",
          "Contrasting-based detection",
          "Parameter-efficient fine-tuning (PEFT)",
          "Modality gap",
          "Closed-world assumption",
          "Emergent abilities",
          "Systematic survey"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **survey**.\n\nhere's why:\n\n*   **title:** explicitly states \"a survey\".\n*   **abstract:**\n    *   \"this **survey** focuses on the problem...\"\n    *   \"we propose a new **taxonomy to categorize existing approaches**...\" (a key characteristic of surveys is organizing existing literature).\n    *   \"...we further discuss the **related work** under each of the categories...\" (reviews existing literature).\n    *   \"...discuss potential challenges and directions for **future research**...\" (common in surveys to identify gaps).\n    *   \"we also provide an **up-to-date reading list**...\" (a comprehensive review feature).\n*   **introduction:** discusses the general problem and mentions various existing \"methods including probabilistic approaches and recent deep learning techniques have been explored,\" indicating a review of the field.\n\nthese points align perfectly with the criteria for a **survey** paper type."
      },
      "file_name": "48020e5f1a0d5703f6169c20051eeb056194c25b.pdf"
    },
    {
      "success": true,
      "doc_id": "d88ff37f44f3d13624a622b03e2bc758",
      "summary": "Here's a focused summary of the paper \"When and How Does In-Distribution Label Help Out-of-Distribution Detection?\" \\cite{du2024aea} for a literature review:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the fundamental question of \"When and how does in-distribution (ID) label help out-of-distribution (OOD) detection?\" \\cite{du2024aea}\n    *   **Importance & Challenge**: This problem is crucial for ensuring reliable machine learning models in real-world deployments where unfamiliar data is common. It bridges the gap between classical anomaly detection (which often disregards ID labels) and contemporary OOD detection (which commonly relies on supervised learning with labeled ID data), a distinction that has not been rigorously explored theoretically.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself at the intersection of anomaly detection and OOD detection. While both aim to identify data deviating from the training distribution, anomaly detection often treats all ID data as a single class, ignoring labels, whereas OOD detection typically leverages labeled ID datasets.\n    *   **Limitations of Previous Solutions**: Previous research has not formally or theoretically delineated the impact of ID labels on OOD detection performance, leaving a significant gap in understanding this fundamental distinction.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper employs a novel graph-theoretic approach to model ID data, where vertices are data points and edges encode similarity. Data representations are characterized through spectral decomposition on this graph.\n    *   **Novelty/Difference**:\n        *   It defines edge weights for both unlabeled (`Î¶(u)`) and labeled (`Î¶(l)`) ID data, with `Î¶(l)` incorporating additional supervised connectivity for samples within the same ID class.\n        *   It establishes a theoretical equivalence (Lemma 1) between performing spectral decomposition on the normalized adjacency matrix and minimizing a specific contrastive learning objective \\cite{du2024aea}. This allows for efficient training of neural networks to learn these representations.\n        *   Crucially, it derives OOD representations by solving an optimization problem that distills OOD-ID similarity from the input space into the representation space, rather than making simplified assumptions or requiring retraining with OOD data \\cite{du2024aea}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: A formal analytical framework based on graph formulation and spectral decomposition to characterize ID and OOD representations, both with and without ID labels.\n    *   **Theoretical Insights/Analysis**:\n        *   A provable error bound (Theorem 1) that formally compares OOD detection performance with and without ID labels.\n        *   Identification of sufficient conditions (Theorem 2) under which ID labels are most beneficial: (i) when OOD data is \"near\" ID data (near OOD scenario), (ii) when ID data is sparsely connected without labels, and (iii) when semantic connections between ID data points from different classes are sufficiently large \\cite{du2024aea}.\n        *   Theoretical equivalence between spectral decomposition and a contrastive learning objective (Lemma 1).\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The authors conducted empirical evaluations on both simulated and real-world datasets.\n    *   **Key Performance Metrics & Results**:\n        *   The experiments compared OOD detection performance (e.g., using AUROC) with and without ID labels.\n        *   Results consistently validated the theoretical guarantees. For instance, on CIFAR100, OOD detection AUROC improved by 12.3% in the near OOD scenario when using ID labels, compared to a 6.06% improvement in the far OOD scenario \\cite{du2024aea}. This empirically supports the theory that ID labels are more beneficial for near OOD detection.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper's theoretical framework relies on graph-theoretic modeling and spectral decomposition, which might have computational implications for extremely large datasets if not for the contrastive learning equivalence. The analysis of OOD representations assumes they can be derived from existing ID embeddings and OOD-ID similarity, which is a realistic but specific modeling choice.\n    *   **Scope of Applicability**: The findings are primarily applicable to understanding the role of ID labels in OOD detection, particularly in scenarios where the \"closeness\" or \"separability\" of OOD data to ID data varies.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper provides the first formal and theoretical understanding of when and how ID labels contribute to OOD detection performance \\cite{du2024aea}. It moves beyond empirical observations to offer a rigorous analytical framework.\n    *   **Potential Impact**: The insights can guide the design of more effective OOD detection algorithms by informing when and how to best leverage ID labels. It also helps bridge the theoretical understanding between anomaly detection and OOD detection, potentially fostering cross-pollination of ideas and methods between these fields.",
      "intriguing_abstract": "Unraveling the mystery of reliable machine learning in uncertain environments, this paper addresses a critical, yet theoretically underexplored, question: When and how do in-distribution (ID) labels truly benefit out-of-distribution (OOD) detection? Bridging the divide between classical anomaly detection and modern OOD paradigms, we present the first formal analytical framework to rigorously quantify this impact.\n\nOur novel graph-theoretic approach models ID data through spectral decomposition, characterizing representations both with and without labels. Crucially, we establish a theoretical equivalence between spectral decomposition and a contrastive learning objective, enabling efficient neural network training. We then derive OOD representations by distilling OOD-ID similarity directly into the representation space, avoiding restrictive assumptions. This framework yields provable error bounds, formally comparing OOD detection performance with and without labels. We identify precise conditions under which ID labels are most advantageous, particularly in challenging \"near OOD\" scenarios, when ID data is sparsely connected, or when semantic connections between ID classes are significant. Validated empirically, these insights offer a paradigm shift, guiding the design of more robust OOD detection algorithms and fostering a deeper theoretical understanding for safer, more reliable AI deployments.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "In-distribution (ID) labels",
        "Graph-theoretic approach",
        "Spectral decomposition",
        "Contrastive learning objective",
        "Novel analytical framework",
        "Provable error bound",
        "Sufficient conditions (ID label benefit)",
        "Near OOD scenario",
        "OOD-ID similarity distillation",
        "Anomaly detection",
        "Reliable machine learning",
        "Unlabeled vs. labeled ID data",
        "Semantic connections"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/87268ea5825cd65c1c3151d6ecc0973f267b3c68.pdf",
      "citation_key": "du2024aea",
      "metadata": {
        "title": "When and How Does In-Distribution Label Help Out-of-Distribution Detection?",
        "authors": [
          "Xuefeng Du",
          "Yiyou Sun",
          "Yixuan Li"
        ],
        "published_date": "2024",
        "abstract": "Detecting data points deviating from the training distribution is pivotal for ensuring reliable machine learning. Extensive research has been dedicated to the challenge, spanning classical anomaly detection techniques to contemporary out-of-distribution (OOD) detection approaches. While OOD detection commonly relies on supervised learning from a labeled in-distribution (ID) dataset, anomaly detection may treat the entire ID data as a single class and disregard ID labels. This fundamental distinction raises a significant question that has yet to be rigorously explored: when and how does ID label help OOD detection? This paper bridges this gap by offering a formal understanding to theoretically delineate the impact of ID labels on OOD detection. We employ a graph-theoretic approach, rigorously analyzing the separability of ID data from OOD data in a closed-form manner. Key to our approach is the characterization of data representations through spectral decomposition on the graph. Leveraging these representations, we establish a provable error bound that compares the OOD detection performance with and without ID labels, unveiling conditions for achieving enhanced OOD detection. Lastly, we present empirical results on both simulated and real datasets, validating theoretical guarantees and reinforcing our insights. Code is publicly available at https://github.com/deeplearning-wisc/id_label.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/87268ea5825cd65c1c3151d6ecc0973f267b3c68.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Here's a focused summary of the paper \"When and How Does In-Distribution Label Help Out-of-Distribution Detection?\" \\cite{du2024aea} for a literature review:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the fundamental question of \"When and how does in-distribution (ID) label help out-of-distribution (OOD) detection?\" \\cite{du2024aea}\n    *   **Importance & Challenge**: This problem is crucial for ensuring reliable machine learning models in real-world deployments where unfamiliar data is common. It bridges the gap between classical anomaly detection (which often disregards ID labels) and contemporary OOD detection (which commonly relies on supervised learning with labeled ID data), a distinction that has not been rigorously explored theoretically.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself at the intersection of anomaly detection and OOD detection. While both aim to identify data deviating from the training distribution, anomaly detection often treats all ID data as a single class, ignoring labels, whereas OOD detection typically leverages labeled ID datasets.\n    *   **Limitations of Previous Solutions**: Previous research has not formally or theoretically delineated the impact of ID labels on OOD detection performance, leaving a significant gap in understanding this fundamental distinction.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper employs a novel graph-theoretic approach to model ID data, where vertices are data points and edges encode similarity. Data representations are characterized through spectral decomposition on this graph.\n    *   **Novelty/Difference**:\n        *   It defines edge weights for both unlabeled (`Î¶(u)`) and labeled (`Î¶(l)`) ID data, with `Î¶(l)` incorporating additional supervised connectivity for samples within the same ID class.\n        *   It establishes a theoretical equivalence (Lemma 1) between performing spectral decomposition on the normalized adjacency matrix and minimizing a specific contrastive learning objective \\cite{du2024aea}. This allows for efficient training of neural networks to learn these representations.\n        *   Crucially, it derives OOD representations by solving an optimization problem that distills OOD-ID similarity from the input space into the representation space, rather than making simplified assumptions or requiring retraining with OOD data \\cite{du2024aea}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: A formal analytical framework based on graph formulation and spectral decomposition to characterize ID and OOD representations, both with and without ID labels.\n    *   **Theoretical Insights/Analysis**:\n        *   A provable error bound (Theorem 1) that formally compares OOD detection performance with and without ID labels.\n        *   Identification of sufficient conditions (Theorem 2) under which ID labels are most beneficial: (i) when OOD data is \"near\" ID data (near OOD scenario), (ii) when ID data is sparsely connected without labels, and (iii) when semantic connections between ID data points from different classes are sufficiently large \\cite{du2024aea}.\n        *   Theoretical equivalence between spectral decomposition and a contrastive learning objective (Lemma 1).\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The authors conducted empirical evaluations on both simulated and real-world datasets.\n    *   **Key Performance Metrics & Results**:\n        *   The experiments compared OOD detection performance (e.g., using AUROC) with and without ID labels.\n        *   Results consistently validated the theoretical guarantees. For instance, on CIFAR100, OOD detection AUROC improved by 12.3% in the near OOD scenario when using ID labels, compared to a 6.06% improvement in the far OOD scenario \\cite{du2024aea}. This empirically supports the theory that ID labels are more beneficial for near OOD detection.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper's theoretical framework relies on graph-theoretic modeling and spectral decomposition, which might have computational implications for extremely large datasets if not for the contrastive learning equivalence. The analysis of OOD representations assumes they can be derived from existing ID embeddings and OOD-ID similarity, which is a realistic but specific modeling choice.\n    *   **Scope of Applicability**: The findings are primarily applicable to understanding the role of ID labels in OOD detection, particularly in scenarios where the \"closeness\" or \"separability\" of OOD data to ID data varies.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper provides the first formal and theoretical understanding of when and how ID labels contribute to OOD detection performance \\cite{du2024aea}. It moves beyond empirical observations to offer a rigorous analytical framework.\n    *   **Potential Impact**: The insights can guide the design of more effective OOD detection algorithms by informing when and how to best leverage ID labels. It also helps bridge the theoretical understanding between anomaly detection and OOD detection, potentially fostering cross-pollination of ideas and methods between these fields.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "In-distribution (ID) labels",
          "Graph-theoretic approach",
          "Spectral decomposition",
          "Contrastive learning objective",
          "Novel analytical framework",
          "Provable error bound",
          "Sufficient conditions (ID label benefit)",
          "Near OOD scenario",
          "OOD-ID similarity distillation",
          "Anomaly detection",
          "Reliable machine learning",
          "Unlabeled vs. labeled ID data",
          "Semantic connections"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"this paper bridges this gap by offering a **formal understanding to theoretically delineate** the impact of id labels on ood detection. we employ a **graph-theoretic approach, rigorously analyzing** the separability of id data from ood data in a **closed-form manner**. leveraging these representations, we establish a **provable error bound** that compares the ood detection performance with and without id labels...\"\n*   the introduction highlights a \"significant question that has yet to be **rigorously explored**\".\n*   while it mentions \"empirical results... validating theoretical guarantees\", the primary contribution described is the formal analysis and provable bounds.\n\nthese phrases strongly align with the criteria for a **theoretical** paper: \"mathematical analysis, proofs, formal models\".\n\ntherefore, the classification is: **theoretical**"
      },
      "file_name": "87268ea5825cd65c1c3151d6ecc0973f267b3c68.pdf"
    },
    {
      "success": true,
      "doc_id": "482bfde1725efe7da4e1c199482a098b",
      "summary": "Machine learning (ML) models often fail with data that deviates from their training distribution. This is a significant concern for ML-enabled devices as data drift may lead to unexpected performance. This work introduces a new framework for out of distribution (OOD) detection and data drift monitoring that combines ML and geometric methods with statistical process control (SPC). We investigated different design choices, including methods for extracting feature representations and drift quantification for OOD detection in individual images and as an approach for input data monitoring. We evaluated the framework for both identifying OOD images and demonstrating the ability to detect shifts in data streams over time. We demonstrated a proof-of-concept via the following tasks: 1) differentiating axial vs. non-axial CT images, 2) differentiating CXR vs. other radiographic imaging modalities, and 3) differentiating adult CXR vs. pediatric CXR. For the identification of individual OOD images, our framework achieved high sensitivity in detecting OOD inputs: 0.980 in CT, 0.984 in CXR, and 0.854 in pediatric CXR. Our framework is also adept at monitoring data streams and identifying the time a drift occurred. In our simulations tracking drift over time, it effectively detected a shift from CXR to non-CXR instantly, a transition from axial to non-axial CT within few days, and a drift from adult to pediatric CXRs within a dayâ€”all while maintaining a low false positive rate. Through additional experiments, we demonstrate the framework is modality-agnostic and independent from the underlying model structure, making it highly customizable for specific applications and broadly applicable across different imaging modalities and deployed ML models.",
      "intriguing_abstract": "Machine learning (ML) models often fail with data that deviates from their training distribution. This is a significant concern for ML-enabled devices as data drift may lead to unexpected performance. This work introduces a new framework for out of distribution (OOD) detection and data drift monitoring that combines ML and geometric methods with statistical process control (SPC). We investigated different design choices, including methods for extracting feature representations and drift quantification for OOD detection in individual images and as an approach for input data monitoring. We evaluated the framework for both identifying OOD images and demonstrating the ability to detect shifts in data streams over time. We demonstrated a proof-of-concept via the following tasks: 1) differentiating axial vs. non-axial CT images, 2) differentiating CXR vs. other radiographic imaging modalities, and 3) differentiating adult CXR vs. pediatric CXR. For the identification of individual OOD images, our framework achieved high sensitivity in detecting OOD inputs: 0.980 in CT, 0.984 in CXR, and 0.854 in pediatric CXR. Our framework is also adept at monitoring data streams and identifying the time a drift occurred. In our simulations tracking drift over time, it effectively detected a shift from CXR to non-CXR instantly, a transition from axial to non-axial CT within few days, and a drift from adult to pediatric CXRs within a dayâ€”all while maintaining a low false positive rate. Through additional experiments, we demonstrate the framework is modality-agnostic and independent from the underlying model structure, making it highly customizable for specific applications and broadly applicable across different imaging modalities and deployed ML models.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/9489f92cf533885359a8efc3a0f030a95abf9f1b.pdf",
      "citation_key": "zamzmi20240s6",
      "metadata": {
        "title": "Out-of-Distribution Detection and Radiological Data Monitoring Using Statistical Process Control",
        "authors": [
          "Ghada Zamzmi",
          "Kesavan Venkatesh",
          "Brandon Nelson",
          "Smriti Prathapan",
          "Paul H Yi",
          "B. Sahiner",
          "Jana G. Delfino"
        ],
        "published_date": "2024",
        "abstract": "Machine learning (ML) models often fail with data that deviates from their training distribution. This is a significant concern for ML-enabled devices as data drift may lead to unexpected performance. This work introduces a new framework for out of distribution (OOD) detection and data drift monitoring that combines ML and geometric methods with statistical process control (SPC). We investigated different design choices, including methods for extracting feature representations and drift quantification for OOD detection in individual images and as an approach for input data monitoring. We evaluated the framework for both identifying OOD images and demonstrating the ability to detect shifts in data streams over time. We demonstrated a proof-of-concept via the following tasks: 1) differentiating axial vs. non-axial CT images, 2) differentiating CXR vs. other radiographic imaging modalities, and 3) differentiating adult CXR vs. pediatric CXR. For the identification of individual OOD images, our framework achieved high sensitivity in detecting OOD inputs: 0.980 in CT, 0.984 in CXR, and 0.854 in pediatric CXR. Our framework is also adept at monitoring data streams and identifying the time a drift occurred. In our simulations tracking drift over time, it effectively detected a shift from CXR to non-CXR instantly, a transition from axial to non-axial CT within few days, and a drift from adult to pediatric CXRs within a dayâ€”all while maintaining a low false positive rate. Through additional experiments, we demonstrate the framework is modality-agnostic and independent from the underlying model structure, making it highly customizable for specific applications and broadly applicable across different imaging modalities and deployed ML models.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/9489f92cf533885359a8efc3a0f030a95abf9f1b.pdf",
        "venue": "Journal of imaging informatics in medicine",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Machine learning (ML) models often fail with data that deviates from their training distribution. This is a significant concern for ML-enabled devices as data drift may lead to unexpected performance. This work introduces a new framework for out of distribution (OOD) detection and data drift monitoring that combines ML and geometric methods with statistical process control (SPC). We investigated different design choices, including methods for extracting feature representations and drift quantification for OOD detection in individual images and as an approach for input data monitoring. We evaluated the framework for both identifying OOD images and demonstrating the ability to detect shifts in data streams over time. We demonstrated a proof-of-concept via the following tasks: 1) differentiating axial vs. non-axial CT images, 2) differentiating CXR vs. other radiographic imaging modalities, and 3) differentiating adult CXR vs. pediatric CXR. For the identification of individual OOD images, our framework achieved high sensitivity in detecting OOD inputs: 0.980 in CT, 0.984 in CXR, and 0.854 in pediatric CXR. Our framework is also adept at monitoring data streams and identifying the time a drift occurred. In our simulations tracking drift over time, it effectively detected a shift from CXR to non-CXR instantly, a transition from axial to non-axial CT within few days, and a drift from adult to pediatric CXRs within a dayâ€”all while maintaining a low false positive rate. Through additional experiments, we demonstrate the framework is modality-agnostic and independent from the underlying model structure, making it highly customizable for specific applications and broadly applicable across different imaging modalities and deployed ML models.",
        "keywords": []
      },
      "file_name": "9489f92cf533885359a8efc3a0f030a95abf9f1b.pdf"
    },
    {
      "success": true,
      "doc_id": "f7f50752aec27c5660869f81a83a71ce",
      "summary": "Here's a focused summary of the paper for a literature review, adhering to the citation requirements:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, where traditional methods often fail to capture complex data distributions from large-scale datasets \\cite{zhu2024awk}.\n    *   **Importance & Challenge**: OOD detection is crucial for deploying robust machine learning models, particularly in safety-critical domains like autonomous driving, healthcare, and security systems. Identifying instances that significantly deviate from the training distribution is essential to ensure reliability, minimize erroneous outputs, and prevent catastrophic failures. The complexity of real-world data distributions makes this a challenging task \\cite{zhu2024awk}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: `\\cite{zhu2024awk}` positions its work against various OOD detection methods, including statistical techniques, deep learning-based methods, uncertainty estimation (e.g., MSP, Mahalanobis distance), ensemble models, and density estimation techniques. It also considers recent advancements in pre-trained vision-language models like CLIP and generative models like diffusion models.\n    *   **Limitations of Previous Solutions**: Traditional methods are often inadequate for complex data distributions. Supervised OOD methods are constrained by the necessity of labeled OOD data for training. Existing zero-shot methods, such as CLIPN, may require additional large external datasets and negative text encoders, increasing model complexity and size. Prompt learning-based methods are noted for lacking informed knowledge about OOD data, leading to higher detection errors \\cite{zhu2024awk}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: `\\cite{zhu2024awk}` proposes a novel OOD detection approach that leverages the generative capabilities of diffusion models and the powerful feature extraction of CLIP. The method involves:\n        1.  Encoding an input image using the CLIP model to obtain its features.\n        2.  Using these CLIP features as *conditional inputs* to a fine-tuned denoising U-Net (based on Stable Diffusion with ControlNet).\n        3.  The U-Net reconstructs the image based on these conditional features.\n        4.  The *discrepancy (reconstruction error)* between the original and reconstructed images is then used as the primary signal for OOD identification. A low error suggests an in-distribution sample, while a high error indicates an OOD sample \\cite{zhu2024awk}.\n    *   **Novelty/Difference**: The core innovation lies in the *integration of CLIP features as conditional inputs to a diffusion model for reconstruction-based OOD detection*. Crucially, the method *does not require class-specific labeled in-distribution (ID) data or any labeled OOD data* for training the diffusion model, only in-distribution samples. This significantly enhances its practicality and scalability compared to many existing methods \\cite{zhu2024awk}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm/Method**: Introduction of a novel OOD detection method that integrates CLIP and diffusion models, using CLIP-extracted features to condition a diffusion model for image reconstruction, where the reconstruction error serves as a robust OOD indicator \\cite{zhu2024awk}.\n    *   **System Design/Architectural Innovations**: Fine-tuning a pre-trained denoising U-Net (specifically Stable Diffusion V1-5 with ControlNet) to reconstruct images guided by CLIP features, demonstrating an effective way to combine powerful pre-trained models for a new task \\cite{zhu2024awk}.\n    *   **Practicality and Scalability**: The method's ability to operate without requiring labeled OOD data or class-specific ID labels for training the diffusion model makes it highly practical and scalable for real-world applications \\cite{zhu2024awk}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were conducted on several benchmark datasets to evaluate the method's efficacy and robustness \\cite{zhu2024awk}.\n    *   **Datasets**: ImageNet-1K was used as the in-distribution (ID) dataset. Out-of-distribution (OOD) datasets included subsets from Texture, iNaturalist, Places, and SUN, carefully selected to ensure no conceptual overlap with ImageNet-1K \\cite{zhu2024awk}.\n    *   **Implementation Details**: The CLIP model used was CLIP-B/16 from OpenCLIP. The denoising U-Net was Stable Diffusion V1-5 with ControlNet, fine-tuned on ImageNet-1K for 10 epochs, minimizing Mean Squared Error (MSE) loss \\cite{zhu2024awk}.\n    *   **Key Performance Metrics**: Performance was evaluated using FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve) \\cite{zhu2024awk}.\n    *   **Comparison Results**:\n        *   The proposed method consistently achieved superior or comparable performance across all individual OOD datasets and in averaged results \\cite{zhu2024awk}.\n        *   It surpassed the best competing zero-shot method, CLIPN, by approximately 1.5% in FPR95, despite being significantly more lightweight in model size and not requiring an additional large external dataset or negative text encoder \\cite{zhu2024awk}.\n        *   It substantially outperformed prompt learning-based methods, reducing the FPR95 by about 23% \\cite{zhu2024awk}.\n        *   It also demonstrated better performance than various CLIP-based post-hoc methods (e.g., MSP, MaxLogit, ODIN, ViM, KNN) \\cite{zhu2024awk}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the assumption that a model capable of accurately reconstructing an image indicates it's part of the learned distribution, while poor reconstruction signals OOD. Its effectiveness is inherently tied to the quality of the CLIP features and the generative capacity of the underlying diffusion model.\n    *   **Scope of Applicability**: The current work primarily focuses on image OOD detection. Future work suggests exploring its application to other domains like natural language processing or audio data \\cite{zhu2024awk}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `\\cite{zhu2024awk}` significantly advances the technical state-of-the-art in OOD detection by achieving substantial improvements in detection accuracy, particularly in reducing false positive rates across diverse benchmark datasets.\n    *   **Potential Impact on Future Research**: This work demonstrates the high potential of integrating powerful pre-trained vision-language models (CLIP) with generative models (diffusion models) for robust OOD detection. It offers a practical, scalable, and effective paradigm that does not rely on labeled OOD data, paving the way for more dependable machine learning systems in safety-critical applications. It also opens avenues for future research into refining reconstruction processes and extending the approach to other data modalities \\cite{zhu2024awk}.",
      "intriguing_abstract": "Ensuring the reliability of machine learning models in safety-critical applications hinges on robust Out-of-Distribution (OOD) detection. Traditional methods often falter when confronted with complex, real-world data, demanding extensive labeled OOD samples or struggling with zero-shot generalization. We introduce a novel, highly effective OOD detection paradigm that leverages the synergistic power of pre-trained vision-language models and generative diffusion models. Our approach conditions a fine-tuned denoising U-Net (based on Stable Diffusion) with CLIP-extracted features to reconstruct input images. The resulting reconstruction error serves as a powerful, intuitive indicator for OOD samples.\n\nA key innovation is its zero-shot capability: the diffusion model is trained solely on in-distribution data, requiring no labeled OOD examples or class-specific supervision. This significantly enhances practicality and scalability. Extensive experiments on ImageNet-1K demonstrate superior performance, with our method consistently outperforming state-of-the-art zero-shot and prompt learning techniques, achieving substantial reductions in FPR95 and higher AUROC scores across diverse OOD datasets. This work represents a significant advancement, paving the way for more dependable and adaptable AI systems by enabling robust OOD detection without the prohibitive cost of OOD data labeling.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "CLIP model",
        "Diffusion models",
        "Reconstruction-based OOD detection",
        "Conditional inputs",
        "Zero-shot OOD detection",
        "No labeled OOD data requirement",
        "Safety-critical domains",
        "Pre-trained model integration",
        "Scalable machine learning",
        "Robust machine learning models",
        "FPR95",
        "AUROC"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/f418971afad1d44fb64610b91128a4eb6c3855ef.pdf",
      "citation_key": "zhu2024awk",
      "metadata": {
        "title": "Exploiting Diffusion Prior for Out-of-Distribution Detection",
        "authors": [
          "Armando Zhu",
          "Jiabei Liu",
          "Keqin Li",
          "Shuying Dai",
          "Bo Hong",
          "Peng Zhao",
          "Changsong Wei"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is crucial for deploying robust machine learning models, especially in areas where security is critical. However, traditional OOD detection methods often fail to capture complex data distributions from large scale date. In this paper, we present a novel approach for OOD detection that leverages the generative ability of diffusion models and the powerful feature extraction capabilities of CLIP. By using these features as conditional inputs to a diffusion model, we can reconstruct the images after encoding them with CLIP. The difference between the original and reconstructed images is used as a signal for OOD identification. The practicality and scalability of our method is increased by the fact that it does not require class-specific labeled ID data, as is the case with many other methods. Extensive experiments on several benchmark datasets demonstrate the robustness and effectiveness of our method, which have significantly improved the detection accuracy.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/f418971afad1d44fb64610b91128a4eb6c3855ef.pdf",
        "venue": "Irish Interdisciplinary Journal of Science &amp; Research",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Here's a focused summary of the paper for a literature review, adhering to the citation requirements:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, where traditional methods often fail to capture complex data distributions from large-scale datasets \\cite{zhu2024awk}.\n    *   **Importance & Challenge**: OOD detection is crucial for deploying robust machine learning models, particularly in safety-critical domains like autonomous driving, healthcare, and security systems. Identifying instances that significantly deviate from the training distribution is essential to ensure reliability, minimize erroneous outputs, and prevent catastrophic failures. The complexity of real-world data distributions makes this a challenging task \\cite{zhu2024awk}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: `\\cite{zhu2024awk}` positions its work against various OOD detection methods, including statistical techniques, deep learning-based methods, uncertainty estimation (e.g., MSP, Mahalanobis distance), ensemble models, and density estimation techniques. It also considers recent advancements in pre-trained vision-language models like CLIP and generative models like diffusion models.\n    *   **Limitations of Previous Solutions**: Traditional methods are often inadequate for complex data distributions. Supervised OOD methods are constrained by the necessity of labeled OOD data for training. Existing zero-shot methods, such as CLIPN, may require additional large external datasets and negative text encoders, increasing model complexity and size. Prompt learning-based methods are noted for lacking informed knowledge about OOD data, leading to higher detection errors \\cite{zhu2024awk}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: `\\cite{zhu2024awk}` proposes a novel OOD detection approach that leverages the generative capabilities of diffusion models and the powerful feature extraction of CLIP. The method involves:\n        1.  Encoding an input image using the CLIP model to obtain its features.\n        2.  Using these CLIP features as *conditional inputs* to a fine-tuned denoising U-Net (based on Stable Diffusion with ControlNet).\n        3.  The U-Net reconstructs the image based on these conditional features.\n        4.  The *discrepancy (reconstruction error)* between the original and reconstructed images is then used as the primary signal for OOD identification. A low error suggests an in-distribution sample, while a high error indicates an OOD sample \\cite{zhu2024awk}.\n    *   **Novelty/Difference**: The core innovation lies in the *integration of CLIP features as conditional inputs to a diffusion model for reconstruction-based OOD detection*. Crucially, the method *does not require class-specific labeled in-distribution (ID) data or any labeled OOD data* for training the diffusion model, only in-distribution samples. This significantly enhances its practicality and scalability compared to many existing methods \\cite{zhu2024awk}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm/Method**: Introduction of a novel OOD detection method that integrates CLIP and diffusion models, using CLIP-extracted features to condition a diffusion model for image reconstruction, where the reconstruction error serves as a robust OOD indicator \\cite{zhu2024awk}.\n    *   **System Design/Architectural Innovations**: Fine-tuning a pre-trained denoising U-Net (specifically Stable Diffusion V1-5 with ControlNet) to reconstruct images guided by CLIP features, demonstrating an effective way to combine powerful pre-trained models for a new task \\cite{zhu2024awk}.\n    *   **Practicality and Scalability**: The method's ability to operate without requiring labeled OOD data or class-specific ID labels for training the diffusion model makes it highly practical and scalable for real-world applications \\cite{zhu2024awk}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were conducted on several benchmark datasets to evaluate the method's efficacy and robustness \\cite{zhu2024awk}.\n    *   **Datasets**: ImageNet-1K was used as the in-distribution (ID) dataset. Out-of-distribution (OOD) datasets included subsets from Texture, iNaturalist, Places, and SUN, carefully selected to ensure no conceptual overlap with ImageNet-1K \\cite{zhu2024awk}.\n    *   **Implementation Details**: The CLIP model used was CLIP-B/16 from OpenCLIP. The denoising U-Net was Stable Diffusion V1-5 with ControlNet, fine-tuned on ImageNet-1K for 10 epochs, minimizing Mean Squared Error (MSE) loss \\cite{zhu2024awk}.\n    *   **Key Performance Metrics**: Performance was evaluated using FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve) \\cite{zhu2024awk}.\n    *   **Comparison Results**:\n        *   The proposed method consistently achieved superior or comparable performance across all individual OOD datasets and in averaged results \\cite{zhu2024awk}.\n        *   It surpassed the best competing zero-shot method, CLIPN, by approximately 1.5% in FPR95, despite being significantly more lightweight in model size and not requiring an additional large external dataset or negative text encoder \\cite{zhu2024awk}.\n        *   It substantially outperformed prompt learning-based methods, reducing the FPR95 by about 23% \\cite{zhu2024awk}.\n        *   It also demonstrated better performance than various CLIP-based post-hoc methods (e.g., MSP, MaxLogit, ODIN, ViM, KNN) \\cite{zhu2024awk}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the assumption that a model capable of accurately reconstructing an image indicates it's part of the learned distribution, while poor reconstruction signals OOD. Its effectiveness is inherently tied to the quality of the CLIP features and the generative capacity of the underlying diffusion model.\n    *   **Scope of Applicability**: The current work primarily focuses on image OOD detection. Future work suggests exploring its application to other domains like natural language processing or audio data \\cite{zhu2024awk}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `\\cite{zhu2024awk}` significantly advances the technical state-of-the-art in OOD detection by achieving substantial improvements in detection accuracy, particularly in reducing false positive rates across diverse benchmark datasets.\n    *   **Potential Impact on Future Research**: This work demonstrates the high potential of integrating powerful pre-trained vision-language models (CLIP) with generative models (diffusion models) for robust OOD detection. It offers a practical, scalable, and effective paradigm that does not rely on labeled OOD data, paving the way for more dependable machine learning systems in safety-critical applications. It also opens avenues for future research into refining reconstruction processes and extending the approach to other data modalities \\cite{zhu2024awk}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "CLIP model",
          "Diffusion models",
          "Reconstruction-based OOD detection",
          "Conditional inputs",
          "Zero-shot OOD detection",
          "No labeled OOD data requirement",
          "Safety-critical domains",
          "Pre-trained model integration",
          "Scalable machine learning",
          "Robust machine learning models",
          "FPR95",
          "AUROC"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   **abstract:** \"we present a novel approach for ood detection\", \"leverages the generative ability of diffusion models and the powerful feature extraction capabilities of clip\", \"reconstruct the images... used as a signal for ood identification\", \"our method\". these phrases clearly indicate the development and presentation of a new method or system. the mention of \"extensive experiments on several benchmark datasets demonstrates the robustness and effectiveness of our method\" indicates empirical validation, which is common for technical papers.\n*   **introduction:** discusses the problem of ood detection, limitations of traditional methods, and introduces key components (clip, diffusion models) that will be used in their \"novel approach\".\n\nthis paper's primary contribution is the proposal and description of a new method for out-of-distribution detection. while it includes empirical validation, the core focus is on presenting the \"novel approach.\"\n\n**classification: technical**"
      },
      "file_name": "f418971afad1d44fb64610b91128a4eb6c3855ef.pdf"
    },
    {
      "success": true,
      "doc_id": "0b7d4ee332e432574de70c96f94fbbcb",
      "summary": "While reinforcement learning (RL) algorithms have been successfully applied across numerous sequential decision-making problems, their generalization to unforeseen testing environments remains a significant concern. In this paper, we study the problem of out-of-distribution (OOD) detection in RL, which focuses on identifying situations at test time that RL agents have not encountered in their training environments. We first propose a clarification of terminology for OOD detection in RL, which aligns it with the literature from other machine learning domains. We then present new benchmark scenarios for OOD detection, which introduce anomalies with temporal autocorrelation into different components of the agent-environment loop. We argue that such scenarios have been understudied in the current literature, despite their relevance to real-world situations. Confirming our theoretical predictions, our experimental results suggest that state-of-the-art OOD detectors are not able to identify such anomalies. To address this problem, we propose a novel method for OOD detection, which we call DEXTER (Detection via Extraction of Time Series Representations). By treating environment observations as time series data, DEXTER extracts salient time series features, and then leverages an ensemble of isolation forest algorithms to detect anomalies. We find that DEXTER can reliably identify anomalies across benchmark scenarios, exhibiting superior performance compared to both state-of-the-art OOD detectors and high-dimensional changepoint detectors adopted from statistics.",
      "intriguing_abstract": "While reinforcement learning (RL) algorithms have been successfully applied across numerous sequential decision-making problems, their generalization to unforeseen testing environments remains a significant concern. In this paper, we study the problem of out-of-distribution (OOD) detection in RL, which focuses on identifying situations at test time that RL agents have not encountered in their training environments. We first propose a clarification of terminology for OOD detection in RL, which aligns it with the literature from other machine learning domains. We then present new benchmark scenarios for OOD detection, which introduce anomalies with temporal autocorrelation into different components of the agent-environment loop. We argue that such scenarios have been understudied in the current literature, despite their relevance to real-world situations. Confirming our theoretical predictions, our experimental results suggest that state-of-the-art OOD detectors are not able to identify such anomalies. To address this problem, we propose a novel method for OOD detection, which we call DEXTER (Detection via Extraction of Time Series Representations). By treating environment observations as time series data, DEXTER extracts salient time series features, and then leverages an ensemble of isolation forest algorithms to detect anomalies. We find that DEXTER can reliably identify anomalies across benchmark scenarios, exhibiting superior performance compared to both state-of-the-art OOD detectors and high-dimensional changepoint detectors adopted from statistics.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/fc1bedae1d5f338f77a053589c1dbd303b089f72.pdf",
      "citation_key": "nasvytis2024mmr",
      "metadata": {
        "title": "Rethinking Out-of-Distribution Detection for Reinforcement Learning: Advancing Methods for Evaluation and Detection",
        "authors": [
          "L. Nasvytis",
          "Kai Sandbrink",
          "Jakob Foerster",
          "Tim Franzmeyer",
          "C. S. D. Witt"
        ],
        "published_date": "2024",
        "abstract": "While reinforcement learning (RL) algorithms have been successfully applied across numerous sequential decision-making problems, their generalization to unforeseen testing environments remains a significant concern. In this paper, we study the problem of out-of-distribution (OOD) detection in RL, which focuses on identifying situations at test time that RL agents have not encountered in their training environments. We first propose a clarification of terminology for OOD detection in RL, which aligns it with the literature from other machine learning domains. We then present new benchmark scenarios for OOD detection, which introduce anomalies with temporal autocorrelation into different components of the agent-environment loop. We argue that such scenarios have been understudied in the current literature, despite their relevance to real-world situations. Confirming our theoretical predictions, our experimental results suggest that state-of-the-art OOD detectors are not able to identify such anomalies. To address this problem, we propose a novel method for OOD detection, which we call DEXTER (Detection via Extraction of Time Series Representations). By treating environment observations as time series data, DEXTER extracts salient time series features, and then leverages an ensemble of isolation forest algorithms to detect anomalies. We find that DEXTER can reliably identify anomalies across benchmark scenarios, exhibiting superior performance compared to both state-of-the-art OOD detectors and high-dimensional changepoint detectors adopted from statistics.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/fc1bedae1d5f338f77a053589c1dbd303b089f72.pdf",
        "venue": "Adaptive Agents and Multi-Agent Systems",
        "citationCount": 9,
        "score": 9.0,
        "summary": "While reinforcement learning (RL) algorithms have been successfully applied across numerous sequential decision-making problems, their generalization to unforeseen testing environments remains a significant concern. In this paper, we study the problem of out-of-distribution (OOD) detection in RL, which focuses on identifying situations at test time that RL agents have not encountered in their training environments. We first propose a clarification of terminology for OOD detection in RL, which aligns it with the literature from other machine learning domains. We then present new benchmark scenarios for OOD detection, which introduce anomalies with temporal autocorrelation into different components of the agent-environment loop. We argue that such scenarios have been understudied in the current literature, despite their relevance to real-world situations. Confirming our theoretical predictions, our experimental results suggest that state-of-the-art OOD detectors are not able to identify such anomalies. To address this problem, we propose a novel method for OOD detection, which we call DEXTER (Detection via Extraction of Time Series Representations). By treating environment observations as time series data, DEXTER extracts salient time series features, and then leverages an ensemble of isolation forest algorithms to detect anomalies. We find that DEXTER can reliably identify anomalies across benchmark scenarios, exhibiting superior performance compared to both state-of-the-art OOD detectors and high-dimensional changepoint detectors adopted from statistics.",
        "keywords": []
      },
      "file_name": "fc1bedae1d5f338f77a053589c1dbd303b089f72.pdf"
    },
    {
      "success": true,
      "doc_id": "8812dcbbf6e475190ee1ee751e4b35c0",
      "summary": "Out-of-distribution (OOD) detection is essential for deploying machine learning models in open-world environments. Activation-based methods are a key approach in OOD detection, working to mitigate overconfident predictions of OOD data. These techniques rectifying anomalous activations, enhancing the distinguishability between in-distribution (ID) data and OOD data. However, they assume by default that every channel is necessary for OOD detection, and rectify anomalous activations in each channel. Empirical evidence has shown that there is a significant difference among various channels in OOD detection, and discarding some channels can greatly enhance the performance of OOD detection. Based on this insight, we propose Discriminability-Driven Channel Selection (DDCS), which leverages an adaptive channel selection by estimating the discriminative score of each channel to boost OOD detection. The discriminative score takes inter-class similarity and inter-class variance of training data into account. However, the estimation of discriminative score itself is susceptible to anomalous activations. To better estimate score, we pre-rectify anomalous activations for each channel mildly. The experimental results show that DDCS achieves state-of-the-art performance on CIFAR and ImageNet-1K benchmarks. Moreover, DDCS can generalize to different backbones and OOD scores.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection is essential for deploying machine learning models in open-world environments. Activation-based methods are a key approach in OOD detection, working to mitigate overconfident predictions of OOD data. These techniques rectifying anomalous activations, enhancing the distinguishability between in-distribution (ID) data and OOD data. However, they assume by default that every channel is necessary for OOD detection, and rectify anomalous activations in each channel. Empirical evidence has shown that there is a significant difference among various channels in OOD detection, and discarding some channels can greatly enhance the performance of OOD detection. Based on this insight, we propose Discriminability-Driven Channel Selection (DDCS), which leverages an adaptive channel selection by estimating the discriminative score of each channel to boost OOD detection. The discriminative score takes inter-class similarity and inter-class variance of training data into account. However, the estimation of discriminative score itself is susceptible to anomalous activations. To better estimate score, we pre-rectify anomalous activations for each channel mildly. The experimental results show that DDCS achieves state-of-the-art performance on CIFAR and ImageNet-1K benchmarks. Moreover, DDCS can generalize to different backbones and OOD scores.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/36dd3bee303671d45c6ab4631c34b2dd67e19e69.pdf",
      "citation_key": "yuan2024ug7",
      "metadata": {
        "title": "Discriminability-Driven Channel Selection for Out-of-Distribution Detection",
        "authors": [
          "Yue Yuan",
          "Rundong He",
          "Yicong Dong",
          "Zhongyi Han",
          "Yilong Yin"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is essential for deploying machine learning models in open-world environments. Activation-based methods are a key approach in OOD detection, working to mitigate overconfident predictions of OOD data. These techniques rectifying anomalous activations, enhancing the distinguishability between in-distribution (ID) data and OOD data. However, they assume by default that every channel is necessary for OOD detection, and rectify anomalous activations in each channel. Empirical evidence has shown that there is a significant difference among various channels in OOD detection, and discarding some channels can greatly enhance the performance of OOD detection. Based on this insight, we propose Discriminability-Driven Channel Selection (DDCS), which leverages an adaptive channel selection by estimating the discriminative score of each channel to boost OOD detection. The discriminative score takes inter-class similarity and inter-class variance of training data into account. However, the estimation of discriminative score itself is susceptible to anomalous activations. To better estimate score, we pre-rectify anomalous activations for each channel mildly. The experimental results show that DDCS achieves state-of-the-art performance on CIFAR and ImageNet-1K benchmarks. Moreover, DDCS can generalize to different backbones and OOD scores.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/36dd3bee303671d45c6ab4631c34b2dd67e19e69.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Out-of-distribution (OOD) detection is essential for deploying machine learning models in open-world environments. Activation-based methods are a key approach in OOD detection, working to mitigate overconfident predictions of OOD data. These techniques rectifying anomalous activations, enhancing the distinguishability between in-distribution (ID) data and OOD data. However, they assume by default that every channel is necessary for OOD detection, and rectify anomalous activations in each channel. Empirical evidence has shown that there is a significant difference among various channels in OOD detection, and discarding some channels can greatly enhance the performance of OOD detection. Based on this insight, we propose Discriminability-Driven Channel Selection (DDCS), which leverages an adaptive channel selection by estimating the discriminative score of each channel to boost OOD detection. The discriminative score takes inter-class similarity and inter-class variance of training data into account. However, the estimation of discriminative score itself is susceptible to anomalous activations. To better estimate score, we pre-rectify anomalous activations for each channel mildly. The experimental results show that DDCS achieves state-of-the-art performance on CIFAR and ImageNet-1K benchmarks. Moreover, DDCS can generalize to different backbones and OOD scores.",
        "keywords": []
      },
      "file_name": "36dd3bee303671d45c6ab4631c34b2dd67e19e69.pdf"
    },
    {
      "success": true,
      "doc_id": "ce7362794f5724734e4b1eb09b8feaeb",
      "summary": "Here's a focused summary of the paper \\cite{fang20249gd} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** This paper addresses the fundamental question of the learnability and generalization ability of Out-of-Distribution (OOD) detection algorithms. Specifically, it investigates whether OOD detection is Probably Approximately Correct (PAC) learnable under commonly used evaluation metrics (risk and AUC).\n    *   **Importance & Challenge:** Supervised learning assumes training and test data come from the same distribution. OOD detection relaxes this, allowing test data from unknown classes, which is crucial for deploying reliable machine learning models in real-world scenarios. The problem is challenging because OOD data is unavailable and diverse during training, and the class-prior probability ($\\pi_{out}$) of OOD data is unknown, making generalization difficult to guarantee theoretically.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work extends classical PAC learning theory, which traditionally focuses on supervised learning under an in-distribution assumption.\n    *   **Limitations of Previous Solutions:** Existing agnostic PAC theories are often \"distribution-free\" (assuming learnability across all domains). However, \\cite{fang20249gd} demonstrates that OOD detection is *not* distribution-free learnable, highlighting a gap in theoretical understanding for this specific problem. Prior OOD detection research has been largely empirical, lacking a rigorous theoretical foundation for generalization.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper develops a theoretical framework to study the PAC learnability of OOD detection. It defines learnability under both threshold-dependent metrics (risk, specifically $\\alpha$-risk) and threshold-independent metrics (AUC).\n    *   **Novelty/Difference:** Unlike classical PAC theory, the approach focuses on identifying *necessary and sufficient conditions* for OOD detection learnability by analyzing the interplay between the \"domain space\" (the set of possible data distributions) and the \"hypothesis/ranking function space\" (the set of possible models). It moves beyond the distribution-free assumption to explore learnability in specific, practical domain spaces.\n\n*   **Key Technical Contributions**\n    *   **Necessary Conditions:** Establishes necessary conditions for OOD detection learnability under risk (Condition 1) and AUC (Condition 2).\n    *   **Impossibility Theorems:** Proves several impossibility theorems (Theorems 4, 5, 6, 7), demonstrating that OOD detection is *not* universally learnable in the \"total space\" or \"separate space\" under certain conditions, particularly when ID and OOD data overlap or when the function space is too rich.\n    *   **Necessary and Sufficient Conditions:** Identifies specific conditions that enable learnability in practical scenarios. This includes necessary and sufficient conditions for learnability under risk and AUC in:\n        *   \"Separate space\" (Theorems 8, 14 under risk; Theorems 10, 15 under AUC).\n        *   \"Finite-ID-distribution space\" (Theorem 11, Condition 4), introducing a \"compatibility condition.\"\n        *   \"Density-based space\" (Theorem 16).\n    *   **Strong Learnability:** Introduces the concept of \"strong learnability\" under risk (Definition 2) and proves its equivalence to standard learnability in \"prior-unknown spaces\" (Theorem 1), addressing the unknown $\\pi_{out}$ challenge.\n    *   **Theoretical Support for FCNNs:** Provides theoretical justification for FCNN-based OOD detection, showing learnability under risk and AUC in separate spaces if the feature space is finite (Theorems 14, 15, 16, 17).\n\n*   **Experimental Validation**\n    *   The paper is primarily theoretical and *does not involve empirical experiments* on datasets.\n    *   Instead, it provides **theoretical support** for representative OOD detection works (e.g., Hendrycks and Gimpel, 2017; Liang et al., 2018; Liu et al., 2020) by showing how their underlying assumptions or model architectures align with the derived learnability conditions.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The impossibility theorems highlight that OOD detection is not universally learnable, meaning a single algorithm cannot be expected to work across all possible scenarios. Learnability is highly dependent on the characteristics of the domain and hypothesis spaces.\n    *   **Scope of Applicability:** The theory focuses on specific definitions of domain and function spaces and two key evaluation metrics (risk and AUC). While these cover common practical scenarios, the conditions for learnability might be restrictive in highly complex or adversarial OOD settings.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art:** This work significantly advances the technical state-of-the-art by providing the first comprehensive PAC learning theory for OOD detection, bridging a critical gap between empirical success and theoretical understanding.\n    *   **Potential Impact:**\n        *   Offers crucial theoretical guidance for designing and evaluating OOD detection algorithms, indicating *when* and *under what conditions* OOD detection can be successful.\n        *   Provides a rigorous foundation for understanding the generalization capabilities of existing and future OOD methods.\n        *   Suggests that the pursuit of a \"universally working OOD detection algorithm\" may be futile, advocating for the development of scenario-specific algorithms tailored to the characteristics of the ID and OOD distributions.\n        *   Highlights the importance of considering the properties of the domain space (e.g., \"finite-ID-distribution space\" for real-world finite datasets) and function space (e.g., FCNNs) in OOD detection research.",
      "intriguing_abstract": "The deployment of reliable AI systems critically depends on their ability to detect Out-of-Distribution (OOD) data, yet the fundamental question of OOD detection's theoretical learnability and generalization has remained largely unexplored. This paper presents the first comprehensive Probably Approximately Correct (PAC) learning theory for OOD detection, bridging a significant gap between empirical success and theoretical understanding. We rigorously investigate OOD learnability under both threshold-dependent (risk) and threshold-independent (AUC) metrics, even when the OOD class-prior probability ($\\pi_{out}$) is unknown.\n\nOur work reveals surprising impossibility theorems, demonstrating that OOD detection is *not* universally distribution-free learnable, challenging the pursuit of a single, all-encompassing algorithm. Instead, we establish necessary and sufficient conditions for PAC learnability in practical domain and hypothesis spaces, such as 'separate space,' 'finite-ID-distribution space,' and 'density-based space.' We introduce 'strong learnability' and provide theoretical justification for FCNN-based OOD detection. This theory offers crucial guidance for designing robust OOD algorithms, emphasizing scenario-specific approaches and informing when and under what conditions reliable OOD generalization can be achieved.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "PAC learnability",
        "generalization ability",
        "risk and AUC metrics",
        "theoretical framework",
        "domain and hypothesis spaces",
        "necessary and sufficient conditions",
        "impossibility theorems",
        "strong learnability",
        "FCNN-based OOD detection",
        "distribution-free learnability limitations",
        "class-prior probability ($\\pi_{out}$)",
        "algorithm design guidance"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/4ff175285ef575f4dc24a518869139382665c12e.pdf",
      "citation_key": "fang20249gd",
      "metadata": {
        "title": "On the Learnability of Out-of-distribution Detection",
        "authors": [
          "Zhen Fang",
          "Yixuan Li",
          "Feng Liu",
          "Bo Han",
          "Jie Lu"
        ],
        "published_date": "2024",
        "abstract": "Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms, and corresponding learning theory is still an open problem. To study the generalization of OOD detection, this paper investigates the probably approximately correct (PAC) learning theory of OOD detection that fits the commonly used evaluation metrics in the literature. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we offer theoretical support for representative OOD detection works based on our OOD theory.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/4ff175285ef575f4dc24a518869139382665c12e.pdf",
        "venue": "Journal of machine learning research",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Here's a focused summary of the paper \\cite{fang20249gd} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** This paper addresses the fundamental question of the learnability and generalization ability of Out-of-Distribution (OOD) detection algorithms. Specifically, it investigates whether OOD detection is Probably Approximately Correct (PAC) learnable under commonly used evaluation metrics (risk and AUC).\n    *   **Importance & Challenge:** Supervised learning assumes training and test data come from the same distribution. OOD detection relaxes this, allowing test data from unknown classes, which is crucial for deploying reliable machine learning models in real-world scenarios. The problem is challenging because OOD data is unavailable and diverse during training, and the class-prior probability ($\\pi_{out}$) of OOD data is unknown, making generalization difficult to guarantee theoretically.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work extends classical PAC learning theory, which traditionally focuses on supervised learning under an in-distribution assumption.\n    *   **Limitations of Previous Solutions:** Existing agnostic PAC theories are often \"distribution-free\" (assuming learnability across all domains). However, \\cite{fang20249gd} demonstrates that OOD detection is *not* distribution-free learnable, highlighting a gap in theoretical understanding for this specific problem. Prior OOD detection research has been largely empirical, lacking a rigorous theoretical foundation for generalization.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper develops a theoretical framework to study the PAC learnability of OOD detection. It defines learnability under both threshold-dependent metrics (risk, specifically $\\alpha$-risk) and threshold-independent metrics (AUC).\n    *   **Novelty/Difference:** Unlike classical PAC theory, the approach focuses on identifying *necessary and sufficient conditions* for OOD detection learnability by analyzing the interplay between the \"domain space\" (the set of possible data distributions) and the \"hypothesis/ranking function space\" (the set of possible models). It moves beyond the distribution-free assumption to explore learnability in specific, practical domain spaces.\n\n*   **Key Technical Contributions**\n    *   **Necessary Conditions:** Establishes necessary conditions for OOD detection learnability under risk (Condition 1) and AUC (Condition 2).\n    *   **Impossibility Theorems:** Proves several impossibility theorems (Theorems 4, 5, 6, 7), demonstrating that OOD detection is *not* universally learnable in the \"total space\" or \"separate space\" under certain conditions, particularly when ID and OOD data overlap or when the function space is too rich.\n    *   **Necessary and Sufficient Conditions:** Identifies specific conditions that enable learnability in practical scenarios. This includes necessary and sufficient conditions for learnability under risk and AUC in:\n        *   \"Separate space\" (Theorems 8, 14 under risk; Theorems 10, 15 under AUC).\n        *   \"Finite-ID-distribution space\" (Theorem 11, Condition 4), introducing a \"compatibility condition.\"\n        *   \"Density-based space\" (Theorem 16).\n    *   **Strong Learnability:** Introduces the concept of \"strong learnability\" under risk (Definition 2) and proves its equivalence to standard learnability in \"prior-unknown spaces\" (Theorem 1), addressing the unknown $\\pi_{out}$ challenge.\n    *   **Theoretical Support for FCNNs:** Provides theoretical justification for FCNN-based OOD detection, showing learnability under risk and AUC in separate spaces if the feature space is finite (Theorems 14, 15, 16, 17).\n\n*   **Experimental Validation**\n    *   The paper is primarily theoretical and *does not involve empirical experiments* on datasets.\n    *   Instead, it provides **theoretical support** for representative OOD detection works (e.g., Hendrycks and Gimpel, 2017; Liang et al., 2018; Liu et al., 2020) by showing how their underlying assumptions or model architectures align with the derived learnability conditions.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The impossibility theorems highlight that OOD detection is not universally learnable, meaning a single algorithm cannot be expected to work across all possible scenarios. Learnability is highly dependent on the characteristics of the domain and hypothesis spaces.\n    *   **Scope of Applicability:** The theory focuses on specific definitions of domain and function spaces and two key evaluation metrics (risk and AUC). While these cover common practical scenarios, the conditions for learnability might be restrictive in highly complex or adversarial OOD settings.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art:** This work significantly advances the technical state-of-the-art by providing the first comprehensive PAC learning theory for OOD detection, bridging a critical gap between empirical success and theoretical understanding.\n    *   **Potential Impact:**\n        *   Offers crucial theoretical guidance for designing and evaluating OOD detection algorithms, indicating *when* and *under what conditions* OOD detection can be successful.\n        *   Provides a rigorous foundation for understanding the generalization capabilities of existing and future OOD methods.\n        *   Suggests that the pursuit of a \"universally working OOD detection algorithm\" may be futile, advocating for the development of scenario-specific algorithms tailored to the characteristics of the ID and OOD distributions.\n        *   Highlights the importance of considering the properties of the domain space (e.g., \"finite-ID-distribution space\" for real-world finite datasets) and function space (e.g., FCNNs) in OOD detection research.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "PAC learnability",
          "generalization ability",
          "risk and AUC metrics",
          "theoretical framework",
          "domain and hypothesis spaces",
          "necessary and sufficient conditions",
          "impossibility theorems",
          "strong learnability",
          "FCNN-based OOD detection",
          "distribution-free learnability limitations",
          "class-prior probability ($\\pi_{out}$)",
          "algorithm design guidance"
        ],
        "paper_type": "based on the abstract and introduction, this paper clearly falls under the **theoretical** type.\n\nhere's why:\n\n*   **abstract mentions:** \"investigates the probably approximately correct (pac) learning theory\", \"find a necessary condition for the learnability\", \"prove several impossibility theorems\", \"give several necessary and sufficient conditions to characterize the learnability\", \"offer theoretical support based on our ood theory.\" these phrases directly align with the criteria for theoretical papers (\"prove\", \"theorem\", \"analysis\", \"mathematical\", \"formal\").\n*   **introduction discusses:** the paper sets up the problem by acknowledging existing *empirical* algorithms but then pivots to address the *learning theory* aspect, specifically the \"generalization ability\" and \"learnability\" of ood detection, which are theoretical concepts.\n\nthe paper is focused on mathematical analysis, proofs, and formal models related to the learnability of ood detection within the pac learning framework."
      },
      "file_name": "4ff175285ef575f4dc24a518869139382665c12e.pdf"
    },
    {
      "success": true,
      "doc_id": "4e5a05d4a89b22922173466b321c7ee0",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/98cf00c765de7c7c985869c57bb2c41e458f773f.pdf",
      "citation_key": "cao20250gu",
      "metadata": {
        "title": "IBPL: Information Bottleneck-based Prompt Learning for graph out-of-distribution detection",
        "authors": [
          "Yanan Cao",
          "Fengzhao Shi",
          "Qing Yu",
          "Xixun Lin",
          "Chuan Zhou",
          "Lixin Zou",
          "Peng Zhang",
          "Zhao Li",
          "Dawei Yin"
        ],
        "published_date": "2025",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/98cf00c765de7c7c985869c57bb2c41e458f773f.pdf",
        "venue": "Neural Networks",
        "citationCount": 9,
        "score": 9.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "98cf00c765de7c7c985869c57bb2c41e458f773f.pdf"
    },
    {
      "success": true,
      "doc_id": "afa8c405c3505a7b13768d3929abcc03",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n### Focused Summary for Literature Review: Out-of-Distribution Detection with a Single Unconditional Diffusion Model \\cite{heng2024fjd}\n\nThis paper introduces Diffusion Paths (DiffPath), a novel approach for out-of-distribution (OOD) detection that leverages a *single* unconditional diffusion model, addressing a significant limitation of traditional generative OOD methods.\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Identifying abnormal (OOD) samples in machine learning.\n    *   **Importance & Challenge**: Deep neural networks are prone to overconfidence on OOD samples, posing risks in safety-critical applications. Traditional unsupervised OOD methods using generative models require training a *new, separate model* for each inlier dataset, leading to high computational and training costs, especially in dynamic or continual learning scenarios. The paper asks if OOD detection can be performed using a *single* generative model across diverse tasks.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: `\\cite{heng2024fjd}` departs from conventional likelihood-based or reconstruction-based generative OOD methods. While some prior work explored single discriminative models for OOD, `\\cite{heng2024fjd}` is the first to explore this for generative models, aligning with the trend of large generative foundation models. It also builds upon the idea of using score functions for OOD (e.g., MSMA), but generalizes it to higher-order terms.\n    *   **Limitations of Previous Solutions**:\n        *   Traditional generative OOD methods (e.g., using likelihoods or reconstruction loss from DMs) necessitate training a dedicated generative model for *each specific inlier distribution*.\n        *   Vanilla likelihoods from deep generative models often assign *higher* likelihoods to OOD samples, making them unreliable OOD scores.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: DiffPath utilizes a *single, pretrained unconditional diffusion model* (trained for general image generation, e.g., on ImageNet) for OOD detection across various inlier distributions. Instead of likelihoods or reconstruction errors, it measures characteristics of the *forward diffusion path* that connects a sample to a standard normal distribution.\n    *   **Novelty**: The core innovation is to use the *rate-of-change* (first derivative) and *curvature* (second derivative) of these diffusion paths as OOD statistics. These quantities are computed from the score function predicted by the diffusion model. The paper empirically observes that a single diffusion model can effectively integrate samples from *unseen distributions* approximately to standard normal, making this approach feasible.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of OOD detection based on measuring the rate-of-change and curvature along the diffusion path of samples to standard normal, using a single unconditional diffusion model.\n    *   **Specific OOD Statistics**:\n        *   **DiffPath-1D**: A one-dimensional statistic based on the sum of L2 norms of the *time derivative of the score function* (âˆ‚tÏµÎ¸), which approximates the curvature of the diffusion path.\n        *   **DiffPath-6D**: A higher-dimensional statistic that concatenates sums of first, second, and third powers of both the score function (ÏµÎ¸) and its time derivative (âˆ‚tÏµÎ¸), retaining sign information to overcome limitations of L2 norms (e.g., distinguishing symmetric samples).\n    *   **Theoretical Insights**: Provides a theoretical framework connecting the diffusion path to the *optimal transport (OT) path* between the data distribution and standard normal. The proposed OOD statistics are characterized as derivatives of this OT path, with their magnitudes being proportional to the distance between distributions in a toy Gaussian example.\n    *   **System Design Innovation**: Demonstrates the feasibility of using a *single generative foundation model* for OOD detection across diverse and unseen inlier distributions, significantly reducing the need for task-specific model training.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on various OOD tasks, including distinguishing CIFAR10 vs. SVHN, and a challenging case of CIFAR10 vs. \"negative CIFAR10\" (sign-flipped pixels). The diffusion models were trained on large datasets like ImageNet or CelebA.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic curve (AUROC) was the primary metric.\n    *   **Comparison Results**:\n        *   DiffPath (both 1D and 6D variants) achieved competitive AUROC scores compared to baselines that require *separate generative models* for each inlier distribution.\n        *   Vanilla diffusion model likelihoods (NLL) were shown to be poor OOD detectors (AUROC 0.091 for C10 vs SVHN), corroborating prior findings.\n        *   DiffPath-1D showed significant improvement over likelihoods and even the raw score norm (AUROC 0.965 vs 0.856 for C10 vs SVHN).\n        *   DiffPath-6D demonstrated superior performance in challenging cases, such as distinguishing CIFAR10 from \"negative CIFAR10\" (AUROC 0.994), where DiffPath-1D failed (AUROC 0.500) due to its reliance on L2 norms.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: DiffPath-1D, by using L2 norms, can struggle with OOD samples that produce symmetric diffusion paths (e.g., sign-flipped images), as the L2 norm discards sign information. This limitation is addressed by DiffPath-6D.\n    *   **Scope of Applicability**: The method is demonstrated for unsupervised OOD detection using unlabeled data, primarily in image domains. It relies on the ability of a single unconditional diffusion model to effectively map diverse samples to a standard normal distribution.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `\\cite{heng2024fjd}` significantly advances OOD detection by demonstrating that a *single, general-purpose generative model* can perform OOD detection across diverse tasks, eliminating the need for task-specific model retraining. This is a crucial step towards more efficient and scalable OOD detection systems.\n    *   **Potential Impact on Future Research**: This work opens new avenues for leveraging large generative foundation models for OOD detection and other downstream tasks. It also highlights the utility of analyzing the dynamics and geometry of diffusion paths (beyond just likelihoods or reconstruction) for understanding and detecting OOD samples, potentially inspiring further research into higher-order derivatives and alternative path characteristics.",
      "intriguing_abstract": "Deep neural networks often fail catastrophically on out-of-distribution (OOD) samples, yet current generative OOD methods demand costly, task-specific model training for each inlier distribution. We introduce Diffusion Paths (DiffPath), a groundbreaking approach that leverages a *single, pretrained unconditional diffusion model* for robust OOD detection across diverse datasets, fundamentally rethinking the paradigm.\n\nInstead of relying on unreliable likelihoods, DiffPath probes the intrinsic geometry of the *forward diffusion path* that maps a sample to a standard normal distribution. Our novel OOD statistics, DiffPath-1D and DiffPath-6D, quantify the *rate-of-change* (first derivative) and *curvature* (second derivative) of these paths, derived directly from the model's *score function*. This innovation eliminates the need for retraining generative models for each new inlier distribution, drastically reducing computational overhead and paving the way for scalable OOD detection with large *generative foundation models*. Extensive experiments demonstrate DiffPath's competitive performance, achieving high AUROC scores and excelling in challenging OOD scenarios where traditional methods falter. DiffPath represents a significant leap towards safer, more efficient, and universally applicable OOD detection systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Diffusion Paths (DiffPath)",
        "single unconditional diffusion model",
        "generative foundation models",
        "score function",
        "rate-of-change and curvature",
        "DiffPath-1D",
        "DiffPath-6D",
        "optimal transport path",
        "computational efficiency",
        "task-agnostic OOD detection",
        "deep neural networks overconfidence",
        "AUROC"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/39af99b93c6b95f54f78952522e6d22496dd5bf1.pdf",
      "citation_key": "heng2024fjd",
      "metadata": {
        "title": "Out-of-Distribution Detection with a Single Unconditional Diffusion Model",
        "authors": [
          "Alvin Heng",
          "A. ThiÃ©ry",
          "Harold Soh"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is a critical task in machine learning that seeks to identify abnormal samples. Traditionally, unsupervised methods utilize a deep generative model for OOD detection. However, such approaches require a new model to be trained for each inlier dataset. This paper explores whether a single model can perform OOD detection across diverse tasks. To that end, we introduce Diffusion Paths (DiffPath), which uses a single diffusion model originally trained to perform unconditional generation for OOD detection. We introduce a novel technique of measuring the rate-of-change and curvature of the diffusion paths connecting samples to the standard normal. Extensive experiments show that with a single model, DiffPath is competitive with prior work using individual models on a variety of OOD tasks involving different distributions. Our code is publicly available at https://github.com/clear-nus/diffpath.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/39af99b93c6b95f54f78952522e6d22496dd5bf1.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n### Focused Summary for Literature Review: Out-of-Distribution Detection with a Single Unconditional Diffusion Model \\cite{heng2024fjd}\n\nThis paper introduces Diffusion Paths (DiffPath), a novel approach for out-of-distribution (OOD) detection that leverages a *single* unconditional diffusion model, addressing a significant limitation of traditional generative OOD methods.\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Identifying abnormal (OOD) samples in machine learning.\n    *   **Importance & Challenge**: Deep neural networks are prone to overconfidence on OOD samples, posing risks in safety-critical applications. Traditional unsupervised OOD methods using generative models require training a *new, separate model* for each inlier dataset, leading to high computational and training costs, especially in dynamic or continual learning scenarios. The paper asks if OOD detection can be performed using a *single* generative model across diverse tasks.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: `\\cite{heng2024fjd}` departs from conventional likelihood-based or reconstruction-based generative OOD methods. While some prior work explored single discriminative models for OOD, `\\cite{heng2024fjd}` is the first to explore this for generative models, aligning with the trend of large generative foundation models. It also builds upon the idea of using score functions for OOD (e.g., MSMA), but generalizes it to higher-order terms.\n    *   **Limitations of Previous Solutions**:\n        *   Traditional generative OOD methods (e.g., using likelihoods or reconstruction loss from DMs) necessitate training a dedicated generative model for *each specific inlier distribution*.\n        *   Vanilla likelihoods from deep generative models often assign *higher* likelihoods to OOD samples, making them unreliable OOD scores.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: DiffPath utilizes a *single, pretrained unconditional diffusion model* (trained for general image generation, e.g., on ImageNet) for OOD detection across various inlier distributions. Instead of likelihoods or reconstruction errors, it measures characteristics of the *forward diffusion path* that connects a sample to a standard normal distribution.\n    *   **Novelty**: The core innovation is to use the *rate-of-change* (first derivative) and *curvature* (second derivative) of these diffusion paths as OOD statistics. These quantities are computed from the score function predicted by the diffusion model. The paper empirically observes that a single diffusion model can effectively integrate samples from *unseen distributions* approximately to standard normal, making this approach feasible.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of OOD detection based on measuring the rate-of-change and curvature along the diffusion path of samples to standard normal, using a single unconditional diffusion model.\n    *   **Specific OOD Statistics**:\n        *   **DiffPath-1D**: A one-dimensional statistic based on the sum of L2 norms of the *time derivative of the score function* (âˆ‚tÏµÎ¸), which approximates the curvature of the diffusion path.\n        *   **DiffPath-6D**: A higher-dimensional statistic that concatenates sums of first, second, and third powers of both the score function (ÏµÎ¸) and its time derivative (âˆ‚tÏµÎ¸), retaining sign information to overcome limitations of L2 norms (e.g., distinguishing symmetric samples).\n    *   **Theoretical Insights**: Provides a theoretical framework connecting the diffusion path to the *optimal transport (OT) path* between the data distribution and standard normal. The proposed OOD statistics are characterized as derivatives of this OT path, with their magnitudes being proportional to the distance between distributions in a toy Gaussian example.\n    *   **System Design Innovation**: Demonstrates the feasibility of using a *single generative foundation model* for OOD detection across diverse and unseen inlier distributions, significantly reducing the need for task-specific model training.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on various OOD tasks, including distinguishing CIFAR10 vs. SVHN, and a challenging case of CIFAR10 vs. \"negative CIFAR10\" (sign-flipped pixels). The diffusion models were trained on large datasets like ImageNet or CelebA.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic curve (AUROC) was the primary metric.\n    *   **Comparison Results**:\n        *   DiffPath (both 1D and 6D variants) achieved competitive AUROC scores compared to baselines that require *separate generative models* for each inlier distribution.\n        *   Vanilla diffusion model likelihoods (NLL) were shown to be poor OOD detectors (AUROC 0.091 for C10 vs SVHN), corroborating prior findings.\n        *   DiffPath-1D showed significant improvement over likelihoods and even the raw score norm (AUROC 0.965 vs 0.856 for C10 vs SVHN).\n        *   DiffPath-6D demonstrated superior performance in challenging cases, such as distinguishing CIFAR10 from \"negative CIFAR10\" (AUROC 0.994), where DiffPath-1D failed (AUROC 0.500) due to its reliance on L2 norms.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: DiffPath-1D, by using L2 norms, can struggle with OOD samples that produce symmetric diffusion paths (e.g., sign-flipped images), as the L2 norm discards sign information. This limitation is addressed by DiffPath-6D.\n    *   **Scope of Applicability**: The method is demonstrated for unsupervised OOD detection using unlabeled data, primarily in image domains. It relies on the ability of a single unconditional diffusion model to effectively map diverse samples to a standard normal distribution.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `\\cite{heng2024fjd}` significantly advances OOD detection by demonstrating that a *single, general-purpose generative model* can perform OOD detection across diverse tasks, eliminating the need for task-specific model retraining. This is a crucial step towards more efficient and scalable OOD detection systems.\n    *   **Potential Impact on Future Research**: This work opens new avenues for leveraging large generative foundation models for OOD detection and other downstream tasks. It also highlights the utility of analyzing the dynamics and geometry of diffusion paths (beyond just likelihoods or reconstruction) for understanding and detecting OOD samples, potentially inspiring further research into higher-order derivatives and alternative path characteristics.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Diffusion Paths (DiffPath)",
          "single unconditional diffusion model",
          "generative foundation models",
          "score function",
          "rate-of-change and curvature",
          "DiffPath-1D",
          "DiffPath-6D",
          "optimal transport path",
          "computational efficiency",
          "task-agnostic OOD detection",
          "deep neural networks overconfidence",
          "AUROC"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"we introduce diffusion paths (diffpath)\", \"we introduce a novel technique of measuring the rate-of-change and curvature of the diffusion paths\". these phrases directly indicate the proposal of a new method and a novel technical approach.\n*   **introduction discusses:** it clearly identifies a \"technical problem\" (the need for separate generative models for ood detection) and then presents a \"proposed solution\" (\"we answer in the affirmative and present diffusion paths (diffpath) in this paper\"). it also emphasizes the novelty of exploring this in the generative setting.\n*   while it also mentions \"extensive experiments show that...\" (indicating an empirical component), the primary contribution is the *development and presentation* of the new method (diffpath) and its underlying technique. the experiments serve to validate this technical contribution."
      },
      "file_name": "39af99b93c6b95f54f78952522e6d22496dd5bf1.pdf"
    },
    {
      "success": true,
      "doc_id": "af4b1b0d511a9f5c612adda27538dc33",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### TOWARDS OPTIMAL FEATURE-SHAPING METHODS FOR OUT-OF-DISTRIBUTION DETECTION \\cite{zhao2024u4m}\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing feature-shaping methods for Out-of-Distribution (OOD) detection rely on manually designed rules for specific model architectures and OOD datasets, leading to poor generalization ability.\n    *   **Importance & Challenge**: OOD detection is crucial for reliable AI systems. The challenge lies in developing a feature-shaping approach that can generalize effectively across diverse OOD scenarios and model types (e.g., transformers, MLPs, which often perform poorly with existing methods) without requiring access to OOD data for optimization.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds upon the family of feature-shaping methods like ReAct \\cite{zhao2024u4m}, ASH-P \\cite{zhao2024u4m}, BFAct \\cite{zhao2024u4m}, and VRA-P \\cite{zhao2024u4m}, which manipulate penultimate layer features to improve OOD scores.\n    *   **Limitations of Previous Solutions**: Prior methods employ ad-hoc, manually designed rules (e.g., element-wise clipping, percentile-based pruning) that are not universally optimal and suffer significant performance degradation when applied to different OOD datasets or model architectures (e.g., transformer-based models).\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper first formulates an abstract optimization framework for feature-shaping methods. It then proposes a concrete reduction using a simple piecewise constant shaping function, which approximates the continuous shaping function by partitioning feature values into intervals. The objective is to maximize the expected difference between maximum logit values for In-Distribution (ID) and OOD data, subject to a norm constraint on the shaping function parameters.\n    *   **Novelty**:\n        *   **Unifying Framework**: Provides a general optimization formulation that encapsulates and offers insights into the operational mechanisms of existing feature-shaping methods, showing they approximate the optimal solution to this concrete problem \\cite{zhao2024u4m}.\n        *   **OOD-Data-Free Optimization**: A significant innovation is the derivation of a closed-form solution for the piecewise constant shaping function that *does not require access to OOD data* during optimization. This is achieved by arguing that the OOD-related term in the objective function can be omitted due to its relatively small orthogonal component to the ID expectation, making the problem tractable using only ID data \\cite{zhao2024u4m}.\n        *   **Sign Flipping for Low-Value Features**: Unlike some prior methods (e.g., VRA-P) that set low-value features to zero, the proposed optimal shaping function can flip the sign of these features, better utilizing them for OOD detection \\cite{zhao2024u4m}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   A general optimization framework for feature-shaping methods for OOD detection.\n        *   A concrete reduction of this framework using a piecewise constant shaping function, which can be optimized to maximize the expected difference in maximum logits between ID and OOD data \\cite{zhao2024u4m}.\n        *   A novel method to derive a closed-form optimal piecewise constant shaping function using *only ID data*, making the approach highly practical \\cite{zhao2024u4m}.\n    *   **Theoretical Insights**: Demonstrates that existing feature-shaping methods empirically approximate the optimal piecewise constant shaping function derived from their framework, providing a theoretical grounding for their effectiveness \\cite{zhao2024u4m}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed across a comprehensive setup, including:\n        *   **ID Datasets**: ImageNet-1k, CIFAR10, CIFAR100.\n        *   **OOD Datasets**: Eight diverse OOD datasets for each ID dataset (e.g., iNaturalist, SUN, Places for ImageNet; TinyImageNet, SVHN, Texture for CIFAR).\n        *   **Model Architectures**: A wide variety, including convolutional networks (ResNet50, MobileNet-v2, DenseNet101), transformer-based models (ViT-B-16, ViT-L-16, SWIN-S, SWIN-B), and fully multi-layer perceptron (MLP) models (MLP-Mixer-B, MLP-Mixer-L, MLP-Mixer-Nano), with transformers and MLPs being \"largely overlooked in previous studies\" \\cite{zhao2024u4m}.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic Curve (AUC) and False Positive Rate at 95% True Positive Rate (FPR95).\n    *   **Comparison Results**:\n        *   The proposed method (referred to as \"Ours\") consistently outperforms or performs on par with state-of-the-art feature-shaping methods (e.g., ReAct, BFAct, ASH variants) and baseline OOD detection methods (MSP, ODIN, Energy, DICE) across a broad spectrum of datasets and model architectures \\cite{zhao2024u4m}.\n        *   For ImageNet-1k, the average AUC for \\cite{zhao2024u4m} is 85.91% (compared to 81.32% for ReAct and 78.48% for MSP), and average FPR95 is 36.31% (compared to 69.24% for ReAct and 69.90% for MSP) across eight OOD datasets and eight model architectures.\n        *   Crucially, the method optimized *without* OOD data performs almost on par with the method optimized *with* OOD data, empirically validating the core innovation \\cite{zhao2024u4m}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The approach relies on a piecewise constant approximation of the shaping function and an assumption that the maximum logit weight vector `wmax` does not change significantly after shaping (validated in the appendix). The argument for omitting the OOD-related term, while empirically supported, is based on an intuition about OOD data distributions.\n    *   **Scope of Applicability**: Primarily focused on OOD detection in image classification tasks using deep learning models. Applicable to various model architectures, including ConvNets, Transformers, and MLPs.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the state-of-the-art in feature-shaping for OOD detection by providing a principled, generalizable, and theoretically grounded approach. It addresses the critical limitation of prior methods' reliance on manual rules and poor generalization.\n    *   **Potential Impact**: The ability to optimize an effective feature-shaping function without requiring OOD data for training is a major practical advantage, simplifying deployment and making OOD detection more accessible in real-world scenarios where OOD data is typically unavailable. It also opens avenues for future research into more sophisticated, data-driven shaping functions and their theoretical properties.",
      "intriguing_abstract": "Reliable AI systems critically depend on robust Out-of-Distribution (OOD) detection, yet current feature-shaping methods, crucial for enhancing OOD scores, suffer from poor generalization. Their reliance on manually designed rules often fails across diverse model architectures, particularly transformer-based models and MLPs, which are largely overlooked.\n\nWe introduce a novel, unifying optimization framework that provides a principled foundation for feature-shaping. Our core innovation is the derivation of a closed-form optimal piecewise constant shaping function that can be optimized *solely using In-Distribution (ID) data*, eliminating the prohibitive need for OOD samples during training. This breakthrough not only offers theoretical insights into the operational mechanisms of prior methods but also enables more effective utilization of penultimate layer features, including sign-flipping for low-value components. Extensive experiments across convolutional networks, transformers, and MLPs, and a wide array of OOD datasets, demonstrate that our OOD-data-free approach consistently achieves state-of-the-art performance. This significant practical advancement simplifies deployment and makes robust OOD detection more accessible for real-world AI applications.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "feature-shaping methods",
        "generalization",
        "optimization framework",
        "piecewise constant shaping function",
        "OOD-data-free optimization",
        "closed-form solution",
        "penultimate layer features",
        "diverse model architectures",
        "state-of-the-art performance",
        "theoretical grounding",
        "logit difference maximization",
        "sign flipping"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/47cfe2c7ba31259ed8b005a348a48db4676279fa.pdf",
      "citation_key": "zhao2024u4m",
      "metadata": {
        "title": "Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection",
        "authors": [
          "Qinyu Zhao",
          "Ming Xu",
          "Kartik Gupta",
          "Akshay Asthana",
          "Liang Zheng",
          "Stephen Gould"
        ],
        "published_date": "2024",
        "abstract": "Feature shaping refers to a family of methods that exhibit state-of-the-art performance for out-of-distribution (OOD) detection. These approaches manipulate the feature representation, typically from the penultimate layer of a pre-trained deep learning model, so as to better differentiate between in-distribution (ID) and OOD samples. However, existing feature-shaping methods usually employ rules manually designed for specific model architectures and OOD datasets, which consequently limit their generalization ability. To address this gap, we first formulate an abstract optimization framework for studying feature-shaping methods. We then propose a concrete reduction of the framework with a simple piecewise constant shaping function and show that existing feature-shaping methods approximate the optimal solution to the concrete optimization problem. Further, assuming that OOD data is inaccessible, we propose a formulation that yields a closed-form solution for the piecewise constant shaping function, utilizing solely the ID data. Through extensive experiments, we show that the feature-shaping function optimized by our method improves the generalization ability of OOD detection across a large variety of datasets and model architectures.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/47cfe2c7ba31259ed8b005a348a48db4676279fa.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### TOWARDS OPTIMAL FEATURE-SHAPING METHODS FOR OUT-OF-DISTRIBUTION DETECTION \\cite{zhao2024u4m}\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing feature-shaping methods for Out-of-Distribution (OOD) detection rely on manually designed rules for specific model architectures and OOD datasets, leading to poor generalization ability.\n    *   **Importance & Challenge**: OOD detection is crucial for reliable AI systems. The challenge lies in developing a feature-shaping approach that can generalize effectively across diverse OOD scenarios and model types (e.g., transformers, MLPs, which often perform poorly with existing methods) without requiring access to OOD data for optimization.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds upon the family of feature-shaping methods like ReAct \\cite{zhao2024u4m}, ASH-P \\cite{zhao2024u4m}, BFAct \\cite{zhao2024u4m}, and VRA-P \\cite{zhao2024u4m}, which manipulate penultimate layer features to improve OOD scores.\n    *   **Limitations of Previous Solutions**: Prior methods employ ad-hoc, manually designed rules (e.g., element-wise clipping, percentile-based pruning) that are not universally optimal and suffer significant performance degradation when applied to different OOD datasets or model architectures (e.g., transformer-based models).\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper first formulates an abstract optimization framework for feature-shaping methods. It then proposes a concrete reduction using a simple piecewise constant shaping function, which approximates the continuous shaping function by partitioning feature values into intervals. The objective is to maximize the expected difference between maximum logit values for In-Distribution (ID) and OOD data, subject to a norm constraint on the shaping function parameters.\n    *   **Novelty**:\n        *   **Unifying Framework**: Provides a general optimization formulation that encapsulates and offers insights into the operational mechanisms of existing feature-shaping methods, showing they approximate the optimal solution to this concrete problem \\cite{zhao2024u4m}.\n        *   **OOD-Data-Free Optimization**: A significant innovation is the derivation of a closed-form solution for the piecewise constant shaping function that *does not require access to OOD data* during optimization. This is achieved by arguing that the OOD-related term in the objective function can be omitted due to its relatively small orthogonal component to the ID expectation, making the problem tractable using only ID data \\cite{zhao2024u4m}.\n        *   **Sign Flipping for Low-Value Features**: Unlike some prior methods (e.g., VRA-P) that set low-value features to zero, the proposed optimal shaping function can flip the sign of these features, better utilizing them for OOD detection \\cite{zhao2024u4m}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   A general optimization framework for feature-shaping methods for OOD detection.\n        *   A concrete reduction of this framework using a piecewise constant shaping function, which can be optimized to maximize the expected difference in maximum logits between ID and OOD data \\cite{zhao2024u4m}.\n        *   A novel method to derive a closed-form optimal piecewise constant shaping function using *only ID data*, making the approach highly practical \\cite{zhao2024u4m}.\n    *   **Theoretical Insights**: Demonstrates that existing feature-shaping methods empirically approximate the optimal piecewise constant shaping function derived from their framework, providing a theoretical grounding for their effectiveness \\cite{zhao2024u4m}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed across a comprehensive setup, including:\n        *   **ID Datasets**: ImageNet-1k, CIFAR10, CIFAR100.\n        *   **OOD Datasets**: Eight diverse OOD datasets for each ID dataset (e.g., iNaturalist, SUN, Places for ImageNet; TinyImageNet, SVHN, Texture for CIFAR).\n        *   **Model Architectures**: A wide variety, including convolutional networks (ResNet50, MobileNet-v2, DenseNet101), transformer-based models (ViT-B-16, ViT-L-16, SWIN-S, SWIN-B), and fully multi-layer perceptron (MLP) models (MLP-Mixer-B, MLP-Mixer-L, MLP-Mixer-Nano), with transformers and MLPs being \"largely overlooked in previous studies\" \\cite{zhao2024u4m}.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic Curve (AUC) and False Positive Rate at 95% True Positive Rate (FPR95).\n    *   **Comparison Results**:\n        *   The proposed method (referred to as \"Ours\") consistently outperforms or performs on par with state-of-the-art feature-shaping methods (e.g., ReAct, BFAct, ASH variants) and baseline OOD detection methods (MSP, ODIN, Energy, DICE) across a broad spectrum of datasets and model architectures \\cite{zhao2024u4m}.\n        *   For ImageNet-1k, the average AUC for \\cite{zhao2024u4m} is 85.91% (compared to 81.32% for ReAct and 78.48% for MSP), and average FPR95 is 36.31% (compared to 69.24% for ReAct and 69.90% for MSP) across eight OOD datasets and eight model architectures.\n        *   Crucially, the method optimized *without* OOD data performs almost on par with the method optimized *with* OOD data, empirically validating the core innovation \\cite{zhao2024u4m}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The approach relies on a piecewise constant approximation of the shaping function and an assumption that the maximum logit weight vector `wmax` does not change significantly after shaping (validated in the appendix). The argument for omitting the OOD-related term, while empirically supported, is based on an intuition about OOD data distributions.\n    *   **Scope of Applicability**: Primarily focused on OOD detection in image classification tasks using deep learning models. Applicable to various model architectures, including ConvNets, Transformers, and MLPs.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the state-of-the-art in feature-shaping for OOD detection by providing a principled, generalizable, and theoretically grounded approach. It addresses the critical limitation of prior methods' reliance on manual rules and poor generalization.\n    *   **Potential Impact**: The ability to optimize an effective feature-shaping function without requiring OOD data for training is a major practical advantage, simplifying deployment and making OOD detection more accessible in real-world scenarios where OOD data is typically unavailable. It also opens avenues for future research into more sophisticated, data-driven shaping functions and their theoretical properties.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "feature-shaping methods",
          "generalization",
          "optimization framework",
          "piecewise constant shaping function",
          "OOD-data-free optimization",
          "closed-form solution",
          "penultimate layer features",
          "diverse model architectures",
          "state-of-the-art performance",
          "theoretical grounding",
          "logit difference maximization",
          "sign flipping"
        ],
        "paper_type": "based on the abstract and introduction, this paper is best classified as **technical**.\n\nhere's why:\n\n*   **key phrases indicating \"technical\":**\n    *   \"to address this gap, we first **formulate an abstract optimization framework** for studying feature-shaping methods.\"\n    *   \"we then **propose a concrete reduction of the framework** with a simple piecewise constant shaping function...\"\n    *   \"...we **propose a formulation** that yields a closed-form solution for the piecewise constant shaping function...\"\n    *   \"through extensive experiments, we show that the feature-shaping function **optimized by our method** improves the generalization ability...\"\n    *   the paper identifies a problem with \"existing feature-shaping methods\" and then explicitly states its contribution as proposing new ways to address this problem (a new framework, a concrete reduction, a new formulation).\n\n*   **overlap with other types:**\n    *   **theoretical:** the paper does have strong theoretical elements, mentioning an \"optimization framework,\" \"optimal solution,\" and \"closed-form solution.\" however, these theoretical analyses are presented as part of *developing* and *characterizing* the *new methods* being proposed, rather than being the sole focus (e.g., proving a theorem about an existing system).\n    *   **empirical:** the introduction mentions \"extensive experiments\" and \"improves the generalization ability,\" indicating an empirical evaluation. however, this evaluation is done to validate the *new methods* proposed, making it a supporting component of the technical contribution.\n\nthe primary contribution is the development and presentation of new methods and a framework for feature-shaping, supported by theoretical analysis and empirical validation."
      },
      "file_name": "47cfe2c7ba31259ed8b005a348a48db4676279fa.pdf"
    },
    {
      "success": true,
      "doc_id": "05d68b11b1e7ba7396dffb881c476386",
      "summary": "Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity. However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation. To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into distinct supervision tasks. This innovative approach, termed Multi-Comprehension (MC) Ensemble, leverages diverse training tasks to generate distinct comprehensions of the data and labels, thereby extending the feature representation field. Our experimental results demonstrate the superior performance of the MC Ensemble strategy in OOD detection compared to both the naive Deep Ensemble method and a standalone model of comparable size. This underscores the effectiveness of our proposed approach in enhancing the model's capability to detect instances outside its training distribution.",
      "intriguing_abstract": "Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity. However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation. To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into distinct supervision tasks. This innovative approach, termed Multi-Comprehension (MC) Ensemble, leverages diverse training tasks to generate distinct comprehensions of the data and labels, thereby extending the feature representation field. Our experimental results demonstrate the superior performance of the MC Ensemble strategy in OOD detection compared to both the naive Deep Ensemble method and a standalone model of comparable size. This underscores the effectiveness of our proposed approach in enhancing the model's capability to detect instances outside its training distribution.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/f9893f5e60aea7b31580253a4c5658d2c0725ece.pdf",
      "citation_key": "xu20242cq",
      "metadata": {
        "title": "Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble",
        "authors": [
          "Chenhui Xu",
          "Fuxun Yu",
          "Zirui Xu",
          "Nathan Inkawhich",
          "Xiang Chen"
        ],
        "published_date": "2024",
        "abstract": "Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity. However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation. To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into distinct supervision tasks. This innovative approach, termed Multi-Comprehension (MC) Ensemble, leverages diverse training tasks to generate distinct comprehensions of the data and labels, thereby extending the feature representation field. Our experimental results demonstrate the superior performance of the MC Ensemble strategy in OOD detection compared to both the naive Deep Ensemble method and a standalone model of comparable size. This underscores the effectiveness of our proposed approach in enhancing the model's capability to detect instances outside its training distribution.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/f9893f5e60aea7b31580253a4c5658d2c0725ece.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity. However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation. To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into distinct supervision tasks. This innovative approach, termed Multi-Comprehension (MC) Ensemble, leverages diverse training tasks to generate distinct comprehensions of the data and labels, thereby extending the feature representation field. Our experimental results demonstrate the superior performance of the MC Ensemble strategy in OOD detection compared to both the naive Deep Ensemble method and a standalone model of comparable size. This underscores the effectiveness of our proposed approach in enhancing the model's capability to detect instances outside its training distribution.",
        "keywords": []
      },
      "file_name": "f9893f5e60aea7b31580253a4c5658d2c0725ece.pdf"
    },
    {
      "success": true,
      "doc_id": "2d94134885eeca7b1a679b34b6e7b988",
      "summary": "Here's a focused summary of the paper \\cite{mirzaei2024dad} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Problem**: Existing out-of-distribution (OOD) detection methods lack robustness against adversarial attacks, compromising their reliability in critical real-world applications.\n    *   **Importance & Challenge**: OOD detection is a safety-critical task (e.g., medical diagnostics, autonomous driving). Adversarial attacks can cause detectors to misclassify OOD as in-distribution (ID) or vice versa with subtle perturbations. Current approaches struggle to establish robust decision boundaries due to the high data complexity of adversarial training and the vast diversity of potential OOD samples.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Previous methods for robust OOD detection often rely on incorporating copious amounts of auxiliary OOD datasets alongside adversarial training (e.g., ATOM, ALOE, ATD, RODEO).\n    *   **Limitations of Previous Solutions**:\n        *   A significant performance gap remains between clean data performance and robustness against adversarial attacks.\n        *   Relying on auxiliary OOD datasets can bias the model towards specific OOD instances, hindering generalization to unseen OOD data.\n        *   Adversarial training is data-intensive, and collecting/curating auxiliary OOD data is costly and complex, requiring careful selection to avoid semantic overlap with ID data.\n        *   Existing methods are vulnerable even to non-adversarial perturbations (e.g., lighting, sensor noise).\n        *   Neural Ordinary Differential Equations (NODEs) and Lyapunov stability have been explored for robustness, but predominantly in classification tasks, not OOD detection.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method (AROS - Adversarially Robust OOD Detection through Stability)**: \\cite{mirzaei2024dad} proposes leveraging Neural Ordinary Differential Equations (NODEs) with the Lyapunov stability theorem to obtain robust embeddings for OOD detection.\n    *   **Novelty**:\n        *   **Lyapunov-Stabilized Embeddings**: Incorporates a tailored loss function to apply Lyapunov stability theory, ensuring both ID and OOD data converge to distinct stable equilibrium points within the dynamical system. This design encourages any perturbed input to return to its stable equilibrium, enhancing robustness.\n        *   **Fake OOD Embedding Generation**: Instead of using additional OOD image data, \\cite{mirzaei2024dad} generates \"fake OOD embeddings\" by sampling from low-likelihood regions of the ID data feature space. This approximates the boundaries where OOD data are likely to reside, addressing data scarcity and bias issues.\n        *   **Orthogonal Binary Layer**: Introduces an orthogonal binary layer following the stable feature space. This layer maximizes the separation between the equilibrium points of ID and OOD samples, further enhancing robustness against misprediction.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: A novel framework that integrates NODEs with Lyapunov stability for adversarially robust OOD detection.\n    *   **Data Generation Technique**: A method for generating synthetic OOD embeddings from ID data in the feature space, eliminating the need for auxiliary OOD datasets.\n    *   **Architectural Innovation**: The introduction of an orthogonal binary layer to enhance the separability of ID and OOD equilibrium points.\n    *   **Theoretical Insights**: Applies established Lyapunov stability theorems (Hartmanâ€“Grobman, Levyâ€“Desplanques) to provide theoretical guarantees for the robustness of the dynamical system in the context of OOD detection.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed under both adversarial and clean setups across various benchmarks.\n    *   **Datasets**: CIFAR-10, CIFAR-100, ImageNet, and real-world medical imaging data (ADNI).\n    *   **Attacks**: Strong adversarial attacks were used, including PGD1000($\\ell_\\infty$), AutoAttack, and Adaptive AutoAttack.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic curve (AUROC).\n    *   **Comparison Results**: \\cite{mirzaei2024dad} demonstrates superior performance, particularly under adversarial attacks, compared to state-of-the-art methods (e.g., RODEO, ATD, ALOE, CSI, VOS, DHM).\n        *   Notably, robust detection performance improved from 37.8% to 80.1% AUROC on CIFAR-10 vs. CIFAR-100.\n        *   Performance improved from 29.0% to 67.0% AUROC on CIFAR-100 vs. CIFAR-10.\n        *   Figure 1 illustrates that other models often perform near random (50% AUROC) or worse at higher perturbation magnitudes (e.g., $\\epsilon=8/255$), while AROS maintains high performance.\n\n*   **Limitations & Scope**\n    *   **Technical Assumptions**: The approach assumes that the neural networks utilized have continuous first derivatives with respect to the input, which is considered a reasonable assumption in practice.\n    *   **Scope of Applicability**: While addressing both adversarial and non-adversarial perturbations, the core innovation and primary focus are on enhancing robustness against adversarial attacks in OOD detection. The effectiveness relies on the ability of fake OOD embeddings to accurately represent OOD boundaries.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{mirzaei2024dad} significantly advances the technical state-of-the-art in adversarially robust OOD detection by providing a method that achieves substantially higher performance under strong attacks.\n    *   **Novel Paradigm**: Introduces a novel paradigm for robust OOD detection by integrating control theory (Lyapunov stability) with deep learning (NODEs) and a data-efficient fake OOD generation strategy.\n    *   **Reduced Data Dependency**: Mitigates the reliance on costly and potentially biased auxiliary OOD datasets for adversarial training, making robust OOD detection more practical.\n    *   **Potential Impact**: The enhanced robustness and reliability of OOD detectors developed using this approach have significant potential impact on safety-critical applications, making AI systems more trustworthy in real-world deployments.",
      "intriguing_abstract": "The reliability of out-of-distribution (OOD) detection in safety-critical applications like autonomous driving and medical diagnostics is severely compromised by its vulnerability to adversarial attacks. Existing methods struggle to establish robust decision boundaries and often rely on costly, biased auxiliary OOD datasets. We introduce AROS (Adversarially Robust OOD Detection through Stability), a novel framework that fundamentally redefines robust OOD detection. AROS leverages **Neural Ordinary Differential Equations (NODEs)** and the **Lyapunov stability theorem** to generate adversarially robust embeddings. Our key innovation lies in designing a tailored loss function that ensures in-distribution (ID) and OOD data converge to distinct, stable equilibrium points within a dynamical system, making perturbed inputs return to their original classification. Crucially, AROS eliminates the need for auxiliary OOD datasets by generating \"fake OOD embeddings\" from low-likelihood regions of the ID feature space. An **orthogonal binary layer** further maximizes the separation of these stable points. Extensive experiments demonstrate AROS's superior performance, achieving up to an 80.1% **AUROC** under strong **adversarial attacks** (e.g., PGD1000, AutoAttack) where state-of-the-art methods perform near random. This paradigm shift significantly enhances the trustworthiness and practical applicability of OOD detectors in real-world, safety-critical scenarios.",
      "keywords": [
        "Adversarially Robust OOD Detection",
        "AROS Framework",
        "Neural Ordinary Differential Equations (NODEs)",
        "Lyapunov Stability Theory",
        "Lyapunov-Stabilized Embeddings",
        "Fake OOD Embedding Generation",
        "Orthogonal Binary Layer",
        "Adversarial Attacks",
        "Safety-Critical Applications",
        "Reduced Data Dependency",
        "Theoretical Guarantees",
        "Superior Adversarial Robustness",
        "Stable Equilibrium Points"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/209c949e277081b8f2847cf3e66b90df26dcf179.pdf",
      "citation_key": "mirzaei2024dad",
      "metadata": {
        "title": "Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings",
        "authors": [
          "Hossein Mirzaei",
          "Mackenzie W. Mathis"
        ],
        "published_date": "2024",
        "abstract": "Despite significant advancements in out-of-distribution (OOD) detection, existing methods still struggle to maintain robustness against adversarial attacks, compromising their reliability in critical real-world applications. Previous studies have attempted to address this challenge by exposing detectors to auxiliary OOD datasets alongside adversarial training. However, the increased data complexity inherent in adversarial training, and the myriad of ways that OOD samples can arise during testing, often prevent these approaches from establishing robust decision boundaries. To address these limitations, we propose AROS, a novel approach leveraging neural ordinary differential equations (NODEs) with Lyapunov stability theorem in order to obtain robust embeddings for OOD detection. By incorporating a tailored loss function, we apply Lyapunov stability theory to ensure that both in-distribution (ID) and OOD data converge to stable equilibrium points within the dynamical system. This approach encourages any perturbed input to return to its stable equilibrium, thereby enhancing the model's robustness against adversarial perturbations. To not use additional data, we generate fake OOD embeddings by sampling from low-likelihood regions of the ID data feature space, approximating the boundaries where OOD data are likely to reside. To then further enhance robustness, we propose the use of an orthogonal binary layer following the stable feature space, which maximizes the separation between the equilibrium points of ID and OOD samples. We validate our method through extensive experiments across several benchmarks, demonstrating superior performance, particularly under adversarial attacks. Notably, our approach improves robust detection performance from 37.8% to 80.1% on CIFAR-10 vs. CIFAR-100 and from 29.0% to 67.0% on CIFAR-100 vs. CIFAR-10.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/209c949e277081b8f2847cf3e66b90df26dcf179.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Here's a focused summary of the paper \\cite{mirzaei2024dad} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Problem**: Existing out-of-distribution (OOD) detection methods lack robustness against adversarial attacks, compromising their reliability in critical real-world applications.\n    *   **Importance & Challenge**: OOD detection is a safety-critical task (e.g., medical diagnostics, autonomous driving). Adversarial attacks can cause detectors to misclassify OOD as in-distribution (ID) or vice versa with subtle perturbations. Current approaches struggle to establish robust decision boundaries due to the high data complexity of adversarial training and the vast diversity of potential OOD samples.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Previous methods for robust OOD detection often rely on incorporating copious amounts of auxiliary OOD datasets alongside adversarial training (e.g., ATOM, ALOE, ATD, RODEO).\n    *   **Limitations of Previous Solutions**:\n        *   A significant performance gap remains between clean data performance and robustness against adversarial attacks.\n        *   Relying on auxiliary OOD datasets can bias the model towards specific OOD instances, hindering generalization to unseen OOD data.\n        *   Adversarial training is data-intensive, and collecting/curating auxiliary OOD data is costly and complex, requiring careful selection to avoid semantic overlap with ID data.\n        *   Existing methods are vulnerable even to non-adversarial perturbations (e.g., lighting, sensor noise).\n        *   Neural Ordinary Differential Equations (NODEs) and Lyapunov stability have been explored for robustness, but predominantly in classification tasks, not OOD detection.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method (AROS - Adversarially Robust OOD Detection through Stability)**: \\cite{mirzaei2024dad} proposes leveraging Neural Ordinary Differential Equations (NODEs) with the Lyapunov stability theorem to obtain robust embeddings for OOD detection.\n    *   **Novelty**:\n        *   **Lyapunov-Stabilized Embeddings**: Incorporates a tailored loss function to apply Lyapunov stability theory, ensuring both ID and OOD data converge to distinct stable equilibrium points within the dynamical system. This design encourages any perturbed input to return to its stable equilibrium, enhancing robustness.\n        *   **Fake OOD Embedding Generation**: Instead of using additional OOD image data, \\cite{mirzaei2024dad} generates \"fake OOD embeddings\" by sampling from low-likelihood regions of the ID data feature space. This approximates the boundaries where OOD data are likely to reside, addressing data scarcity and bias issues.\n        *   **Orthogonal Binary Layer**: Introduces an orthogonal binary layer following the stable feature space. This layer maximizes the separation between the equilibrium points of ID and OOD samples, further enhancing robustness against misprediction.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: A novel framework that integrates NODEs with Lyapunov stability for adversarially robust OOD detection.\n    *   **Data Generation Technique**: A method for generating synthetic OOD embeddings from ID data in the feature space, eliminating the need for auxiliary OOD datasets.\n    *   **Architectural Innovation**: The introduction of an orthogonal binary layer to enhance the separability of ID and OOD equilibrium points.\n    *   **Theoretical Insights**: Applies established Lyapunov stability theorems (Hartmanâ€“Grobman, Levyâ€“Desplanques) to provide theoretical guarantees for the robustness of the dynamical system in the context of OOD detection.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed under both adversarial and clean setups across various benchmarks.\n    *   **Datasets**: CIFAR-10, CIFAR-100, ImageNet, and real-world medical imaging data (ADNI).\n    *   **Attacks**: Strong adversarial attacks were used, including PGD1000($\\ell_\\infty$), AutoAttack, and Adaptive AutoAttack.\n    *   **Key Performance Metrics**: Area Under the Receiver Operating Characteristic curve (AUROC).\n    *   **Comparison Results**: \\cite{mirzaei2024dad} demonstrates superior performance, particularly under adversarial attacks, compared to state-of-the-art methods (e.g., RODEO, ATD, ALOE, CSI, VOS, DHM).\n        *   Notably, robust detection performance improved from 37.8% to 80.1% AUROC on CIFAR-10 vs. CIFAR-100.\n        *   Performance improved from 29.0% to 67.0% AUROC on CIFAR-100 vs. CIFAR-10.\n        *   Figure 1 illustrates that other models often perform near random (50% AUROC) or worse at higher perturbation magnitudes (e.g., $\\epsilon=8/255$), while AROS maintains high performance.\n\n*   **Limitations & Scope**\n    *   **Technical Assumptions**: The approach assumes that the neural networks utilized have continuous first derivatives with respect to the input, which is considered a reasonable assumption in practice.\n    *   **Scope of Applicability**: While addressing both adversarial and non-adversarial perturbations, the core innovation and primary focus are on enhancing robustness against adversarial attacks in OOD detection. The effectiveness relies on the ability of fake OOD embeddings to accurately represent OOD boundaries.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{mirzaei2024dad} significantly advances the technical state-of-the-art in adversarially robust OOD detection by providing a method that achieves substantially higher performance under strong attacks.\n    *   **Novel Paradigm**: Introduces a novel paradigm for robust OOD detection by integrating control theory (Lyapunov stability) with deep learning (NODEs) and a data-efficient fake OOD generation strategy.\n    *   **Reduced Data Dependency**: Mitigates the reliance on costly and potentially biased auxiliary OOD datasets for adversarial training, making robust OOD detection more practical.\n    *   **Potential Impact**: The enhanced robustness and reliability of OOD detectors developed using this approach have significant potential impact on safety-critical applications, making AI systems more trustworthy in real-world deployments.",
        "keywords": [
          "Adversarially Robust OOD Detection",
          "AROS Framework",
          "Neural Ordinary Differential Equations (NODEs)",
          "Lyapunov Stability Theory",
          "Lyapunov-Stabilized Embeddings",
          "Fake OOD Embedding Generation",
          "Orthogonal Binary Layer",
          "Adversarial Attacks",
          "Safety-Critical Applications",
          "Reduced Data Dependency",
          "Theoretical Guarantees",
          "Superior Adversarial Robustness",
          "Stable Equilibrium Points"
        ],
        "paper_type": "this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"we **propose aros**, a novel approach leveraging neural ordinary differential equations (nodes) with lyapunov stability theorem...\", \"by incorporating a tailored loss function, we apply lyapunov stability theory...\", \"we **generate fake ood embeddings**...\", \"we **propose the use of an orthogonal binary layer**\". these phrases directly indicate the development and presentation of new methods, algorithms, and system components.\n*   **introduction discusses:** \"our contribution: to address these challenges, we **propose aros** (adversarially robust ood detection through stability), a novel approach that leverages nodes with the lyapunov stability theorem...\", \"we craft fake ood samples in the embedding space...\", \"adding an orthogonal binary layer increases the separation...\". the introduction clearly sets up a technical problem and then outlines the proposed technical solution.\n*   the paper details specific components of its proposed method (e.g., \"fake embedding crafting strategy\", \"lyapunov stability for robust ood detection\", \"orthogonal binary layer and training step\", including a new loss function lsl).\n*   while it includes \"extensive experiments\" and \"demonstrating superior performance\" (empirical elements) and leverages \"lyapunov stability theorem\" (theoretical elements), the core contribution is the *creation and description of the novel aros method*. the empirical validation serves to demonstrate the effectiveness of the proposed technical solution, and the theoretical framework underpins its design."
      },
      "file_name": "209c949e277081b8f2847cf3e66b90df26dcf179.pdf"
    },
    {
      "success": true,
      "doc_id": "e4fdfa8d42fbcb3490da9b96cd08e9fc",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION**: \\cite{sharifi2024gok}\n\n1.  **Research Problem & Motivation**\n    *   Neural networks exhibit overconfident errors when encountering Out-of-Distribution (OOD) data, which is a significant barrier to their safe and robust deployment in real-world applications \\cite{sharifi2024gok}.\n    *   Existing state-of-the-art OOD detection methods, particularly those that utilize auxiliary OOD datasets during training, often fail to fully exploit the rich local information embedded within these datasets \\cite{sharifi2024gok}.\n    *   The problem is challenging because the OOD space is vast and diverse, making it difficult for models to generalize robustly without explicit mechanisms to understand local data behavior and efficiently utilize potentially large auxiliary datasets \\cite{sharifi2024gok}.\n\n2.  **Related Work & Positioning**\n    *   OOD detection methods are broadly categorized into post-hoc approaches (e.g., MSP, ODIN, Energy) that do not use auxiliary data, and methods that leverage auxiliary OOD data during training (e.g., OE, Energy, OpenMix) \\cite{sharifi2024gok}. The latter generally achieve superior performance.\n    *   Previous auxiliary-data-based methods primarily focus on optimizing the value of a scoring function (e.g., energy score) to separate ID and OOD samples, often overlooking the local behavior or smoothness of this score function around data points \\cite{sharifi2024gok}.\n    *   While some works address outlier sampling (e.g., NTOM, POEM, DOS) for large auxiliary datasets, greedy sampling can introduce bias. This work positions itself by addressing the lack of local information exploitation and proposing a more robust sampling strategy \\cite{sharifi2024gok}. The paper explicitly contrasts its goal of decreasing the norm of the score function with `[52]` which aims to increase the Jacobian norm difference.\n\n3.  **Technical Approach & Innovation**\n    *   **Gradient Regularization (GReg):** The core innovation is to leverage the gradient of the OOD score function during training to learn local information and promote a smoother score manifold \\cite{sharifi2024gok}.\n        *   A novel regularization term, `Lâˆ‡S`, is introduced into the loss function. This term penalizes the norm of the gradient of the score function (`âˆ¥âˆ‡S(x)âˆ¥`) specifically for correctly detected ID and OOD samples \\cite{sharifi2024gok}. This encourages local stability, ensuring that small perturbations around correctly classified samples do not drastically alter their OOD score.\n        *   The formulation `Lâˆ‡SEn` (Equation 3) is tailored for the energy score, applying regularization only to samples whose energy scores are already at desired levels (low for ID, high for OOD) \\cite{sharifi2024gok}.\n    *   **Energy-Based OOD Sampling (part of GReg+):** A novel two-stage sampling method is developed to select more informative and diverse OOD samples from large auxiliary datasets \\cite{sharifi2024gok}.\n        *   It first employs **K-Means clustering** on normalized features of OOD samples to ensure that the model is exposed to diverse regions of the feature space, mitigating bias \\cite{sharifi2024gok}.\n        *   Within each cluster, **energy-based selection** is performed: samples with the smallest energy scores are chosen to be pushed towards higher OOD scores (for the main energy loss), while samples with the largest energy scores are chosen to enforce local smoothness where scores are already high (for the gradient regularization loss) \\cite{sharifi2024gok}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Gradient Regularization Method:** Introduction of `Lâˆ‡S`, a gradient regularization term that explicitly penalizes the norm of the score function's gradient for correctly classified samples, thereby promoting local smoothness and robustness around ID and OOD data points \\cite{sharifi2024gok}.\n    *   **Novel Energy-Based Sampling Algorithm:** A sophisticated two-stage sampling strategy that combines K-Means clustering on normalized features for diversity, followed by energy-score-based selection within clusters to identify the most informative samples for both the primary OOD loss and the gradient regularization loss \\cite{sharifi2024gok}.\n    *   **Theoretical Analysis:** Provides a theoretical foundation for gradient regularization through the lens of certified robustness and Lipschitz analysis, demonstrating that promoting smoothness inherently improves OOD robustness by preventing abrupt changes in score values due to minor input perturbations \\cite{sharifi2024gok}.\n    *   **Integrated System (GReg+):** Proposes GReg+, which systematically integrates the novel gradient regularization with the energy-based sampling method, enhancing existing state-of-the-art OOD detection frameworks that rely on auxiliary data \\cite{sharifi2024gok}.\n\n5.  **Experimental Validation**\n    *   **Extensive Benchmarking:** The method was rigorously evaluated through extensive experiments on several OOD benchmarks, showcasing its effectiveness across various architectures and datasets \\cite{sharifi2024gok}.\n    *   **State-of-the-Art Performance:** GReg+ achieved significant improvements over existing state-of-the-art methods, notably improving the FPR95 (False Positive Rate at 95% True Positive Rate) by 4% on ImageNet experiments \\cite{sharifi2024gok}.\n    *   **Ablation Studies:** Detailed ablation studies were conducted to demonstrate the individual contributions and effectiveness of both the gradient regularization and the energy-based sampling components \\cite{sharifi2024gok}.\n    *   **Empirical Gradient Norm Analysis:** Empirical results (Figure 3) illustrate that gradient regularization successfully reduces the rate of increase of the gradient norm during training without negatively impacting the reduction in energy loss, confirming its intended effect on promoting smoothness \\cite{sharifi2024gok}.\n\n6.  **Limitations & Scope**\n    *   The proposed method is primarily applicable to OOD detection scenarios where an auxiliary OOD dataset is available for training or fine-tuning, rather than purely post-hoc settings \\cite{sharifi2024gok}.\n    *   The effectiveness of the energy-based sampling component is dependent on the quality and diversity of the auxiliary dataset and the appropriate selection of the number of clusters \\cite{sharifi2024gok}.\n    *   The theoretical analysis focuses on the implications of gradient regularization for smoothness and certified robustness, which represents a specific, albeit crucial, aspect of OOD detection \\cite{sharifi2024gok}.\n\n7.  **Technical Significance**\n    *   **Significant SOTA Advancement:** GReg+ substantially advances the technical state-of-the-art in OOD detection, particularly for methods leveraging auxiliary data, by achieving superior performance metrics (e.g., 4% FPR95 improvement on ImageNet) \\cite{sharifi2024gok}.\n    *   **Novel Paradigm for OOD Robustness:** Introduces a novel paradigm by explicitly incorporating local information through gradient regularization, shifting beyond mere score optimization to consider the critical aspect of score manifold smoothness and stability \\cite{sharifi2024gok}.\n    *   **Enhanced Auxiliary Data Utilization:** The energy-based sampling method offers a more effective and unbiased approach to utilize large auxiliary OOD datasets, ensuring models are exposed to diverse and truly informative outlier samples, which is vital for robust generalization \\cite{sharifi2024gok}.\n    *   **Foundation for Future Research:** The strong theoretical grounding in certified robustness and Lipschitz analysis, coupled with compelling empirical success, establishes a new direction for future research into robust OOD detection by focusing on the local properties and smoothness of neural network decision boundaries \\cite{sharifi2024gok}.",
      "intriguing_abstract": "Neural networks' overconfident errors on Out-of-Distribution (OOD) data pose a critical barrier to their safe and robust deployment. Existing state-of-the-art OOD detection methods, particularly those leveraging auxiliary OOD datasets, often fail to fully exploit the rich local information embedded within these outliers. We introduce GReg+, a novel framework that fundamentally enhances OOD robustness by promoting local smoothness of the OOD score manifold. Our core innovation is a **Gradient Regularization (GReg)** term, `Lâˆ‡S`, which explicitly penalizes the norm of the score function's gradient for correctly classified samples, ensuring stability against minor input perturbations. Complementing this, we propose a sophisticated **Energy-Based OOD Sampling** strategy that leverages K-Means clustering and energy scores to select diverse and informative samples from large auxiliary datasets, optimizing their utility. Theoretically grounded in certified robustness and Lipschitz analysis, GReg+ achieves significant State-of-the-Art performance, notably improving FPR95 by 4% on ImageNet. This work offers a novel paradigm for OOD detection, moving beyond mere score optimization to establish robust, locally stable decision boundaries, paving the way for more trustworthy AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Gradient Regularization (GReg)",
        "Energy-Based OOD Sampling",
        "Auxiliary OOD datasets",
        "Score manifold smoothness",
        "Certified robustness",
        "Lipschitz analysis",
        "K-Means clustering",
        "State-of-the-art performance",
        "FPR95 improvement",
        "Neural network robustness",
        "Local information exploitation",
        "Energy score function",
        "GReg+ integrated system"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/c5b439fa6766e4d9dabf09d1b0d686311b494914.pdf",
      "citation_key": "sharifi2024gok",
      "metadata": {
        "title": "Gradient-Regularized Out-of-Distribution Detection",
        "authors": [
          "Sina Sharifi",
          "Taha Entesari",
          "Bardia Safaei",
          "Vishal M. Patel",
          "Mahyar Fazlyab"
        ],
        "published_date": "2024",
        "abstract": "One of the challenges for neural networks in real-life applications is the overconfident errors these models make when the data is not from the original training distribution. Addressing this issue is known as Out-of-Distribution (OOD) detection. Many state-of-the-art OOD methods employ an auxiliary dataset as a surrogate for OOD data during training to achieve improved performance. However, these methods fail to fully exploit the local information embedded in the auxiliary dataset. In this work, we propose the idea of leveraging the information embedded in the gradient of the loss function during training to enable the network to not only learn a desired OOD score for each sample but also to exhibit similar behavior in a local neighborhood around each sample. We also develop a novel energy-based sampling method to allow the network to be exposed to more informative OOD samples during the training phase. This is especially important when the auxiliary dataset is large. We demonstrate the effectiveness of our method through extensive experiments on several OOD benchmarks, improving the existing state-of-the-art FPR95 by 4% on our ImageNet experiment. We further provide a theoretical analysis through the lens of certified robustness and Lipschitz analysis to showcase the theoretical foundation of our work. Our code is available at https://github.com/o4lc/Greg-OOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/c5b439fa6766e4d9dabf09d1b0d686311b494914.pdf",
        "venue": "European Conference on Computer Vision",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION**: \\cite{sharifi2024gok}\n\n1.  **Research Problem & Motivation**\n    *   Neural networks exhibit overconfident errors when encountering Out-of-Distribution (OOD) data, which is a significant barrier to their safe and robust deployment in real-world applications \\cite{sharifi2024gok}.\n    *   Existing state-of-the-art OOD detection methods, particularly those that utilize auxiliary OOD datasets during training, often fail to fully exploit the rich local information embedded within these datasets \\cite{sharifi2024gok}.\n    *   The problem is challenging because the OOD space is vast and diverse, making it difficult for models to generalize robustly without explicit mechanisms to understand local data behavior and efficiently utilize potentially large auxiliary datasets \\cite{sharifi2024gok}.\n\n2.  **Related Work & Positioning**\n    *   OOD detection methods are broadly categorized into post-hoc approaches (e.g., MSP, ODIN, Energy) that do not use auxiliary data, and methods that leverage auxiliary OOD data during training (e.g., OE, Energy, OpenMix) \\cite{sharifi2024gok}. The latter generally achieve superior performance.\n    *   Previous auxiliary-data-based methods primarily focus on optimizing the value of a scoring function (e.g., energy score) to separate ID and OOD samples, often overlooking the local behavior or smoothness of this score function around data points \\cite{sharifi2024gok}.\n    *   While some works address outlier sampling (e.g., NTOM, POEM, DOS) for large auxiliary datasets, greedy sampling can introduce bias. This work positions itself by addressing the lack of local information exploitation and proposing a more robust sampling strategy \\cite{sharifi2024gok}. The paper explicitly contrasts its goal of decreasing the norm of the score function with `[52]` which aims to increase the Jacobian norm difference.\n\n3.  **Technical Approach & Innovation**\n    *   **Gradient Regularization (GReg):** The core innovation is to leverage the gradient of the OOD score function during training to learn local information and promote a smoother score manifold \\cite{sharifi2024gok}.\n        *   A novel regularization term, `Lâˆ‡S`, is introduced into the loss function. This term penalizes the norm of the gradient of the score function (`âˆ¥âˆ‡S(x)âˆ¥`) specifically for correctly detected ID and OOD samples \\cite{sharifi2024gok}. This encourages local stability, ensuring that small perturbations around correctly classified samples do not drastically alter their OOD score.\n        *   The formulation `Lâˆ‡SEn` (Equation 3) is tailored for the energy score, applying regularization only to samples whose energy scores are already at desired levels (low for ID, high for OOD) \\cite{sharifi2024gok}.\n    *   **Energy-Based OOD Sampling (part of GReg+):** A novel two-stage sampling method is developed to select more informative and diverse OOD samples from large auxiliary datasets \\cite{sharifi2024gok}.\n        *   It first employs **K-Means clustering** on normalized features of OOD samples to ensure that the model is exposed to diverse regions of the feature space, mitigating bias \\cite{sharifi2024gok}.\n        *   Within each cluster, **energy-based selection** is performed: samples with the smallest energy scores are chosen to be pushed towards higher OOD scores (for the main energy loss), while samples with the largest energy scores are chosen to enforce local smoothness where scores are already high (for the gradient regularization loss) \\cite{sharifi2024gok}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Gradient Regularization Method:** Introduction of `Lâˆ‡S`, a gradient regularization term that explicitly penalizes the norm of the score function's gradient for correctly classified samples, thereby promoting local smoothness and robustness around ID and OOD data points \\cite{sharifi2024gok}.\n    *   **Novel Energy-Based Sampling Algorithm:** A sophisticated two-stage sampling strategy that combines K-Means clustering on normalized features for diversity, followed by energy-score-based selection within clusters to identify the most informative samples for both the primary OOD loss and the gradient regularization loss \\cite{sharifi2024gok}.\n    *   **Theoretical Analysis:** Provides a theoretical foundation for gradient regularization through the lens of certified robustness and Lipschitz analysis, demonstrating that promoting smoothness inherently improves OOD robustness by preventing abrupt changes in score values due to minor input perturbations \\cite{sharifi2024gok}.\n    *   **Integrated System (GReg+):** Proposes GReg+, which systematically integrates the novel gradient regularization with the energy-based sampling method, enhancing existing state-of-the-art OOD detection frameworks that rely on auxiliary data \\cite{sharifi2024gok}.\n\n5.  **Experimental Validation**\n    *   **Extensive Benchmarking:** The method was rigorously evaluated through extensive experiments on several OOD benchmarks, showcasing its effectiveness across various architectures and datasets \\cite{sharifi2024gok}.\n    *   **State-of-the-Art Performance:** GReg+ achieved significant improvements over existing state-of-the-art methods, notably improving the FPR95 (False Positive Rate at 95% True Positive Rate) by 4% on ImageNet experiments \\cite{sharifi2024gok}.\n    *   **Ablation Studies:** Detailed ablation studies were conducted to demonstrate the individual contributions and effectiveness of both the gradient regularization and the energy-based sampling components \\cite{sharifi2024gok}.\n    *   **Empirical Gradient Norm Analysis:** Empirical results (Figure 3) illustrate that gradient regularization successfully reduces the rate of increase of the gradient norm during training without negatively impacting the reduction in energy loss, confirming its intended effect on promoting smoothness \\cite{sharifi2024gok}.\n\n6.  **Limitations & Scope**\n    *   The proposed method is primarily applicable to OOD detection scenarios where an auxiliary OOD dataset is available for training or fine-tuning, rather than purely post-hoc settings \\cite{sharifi2024gok}.\n    *   The effectiveness of the energy-based sampling component is dependent on the quality and diversity of the auxiliary dataset and the appropriate selection of the number of clusters \\cite{sharifi2024gok}.\n    *   The theoretical analysis focuses on the implications of gradient regularization for smoothness and certified robustness, which represents a specific, albeit crucial, aspect of OOD detection \\cite{sharifi2024gok}.\n\n7.  **Technical Significance**\n    *   **Significant SOTA Advancement:** GReg+ substantially advances the technical state-of-the-art in OOD detection, particularly for methods leveraging auxiliary data, by achieving superior performance metrics (e.g., 4% FPR95 improvement on ImageNet) \\cite{sharifi2024gok}.\n    *   **Novel Paradigm for OOD Robustness:** Introduces a novel paradigm by explicitly incorporating local information through gradient regularization, shifting beyond mere score optimization to consider the critical aspect of score manifold smoothness and stability \\cite{sharifi2024gok}.\n    *   **Enhanced Auxiliary Data Utilization:** The energy-based sampling method offers a more effective and unbiased approach to utilize large auxiliary OOD datasets, ensuring models are exposed to diverse and truly informative outlier samples, which is vital for robust generalization \\cite{sharifi2024gok}.\n    *   **Foundation for Future Research:** The strong theoretical grounding in certified robustness and Lipschitz analysis, coupled with compelling empirical success, establishes a new direction for future research into robust OOD detection by focusing on the local properties and smoothness of neural network decision boundaries \\cite{sharifi2024gok}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Gradient Regularization (GReg)",
          "Energy-Based OOD Sampling",
          "Auxiliary OOD datasets",
          "Score manifold smoothness",
          "Certified robustness",
          "Lipschitz analysis",
          "K-Means clustering",
          "State-of-the-art performance",
          "FPR95 improvement",
          "Neural network robustness",
          "Local information exploitation",
          "Energy score function",
          "GReg+ integrated system"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** the idea of leveraging the information embedded in the gradient...\", \"we also **develop** a novel energy-based sampling **method**...\", and \"demonstrate the effectiveness of our **method**\". these are strong indicators of presenting a new method or system.\n*   the introduction sets up a technical problem (ood detection challenges for neural networks) that the proposed method aims to solve.\n*   while the paper also includes \"extensive experiments\" (empirical) and \"theoretical analysis\" (theoretical), these aspects serve to validate and provide a foundation for the *new method* being presented. the core contribution is the development of this new approach.\n\ntherefore, the primary classification is **technical**."
      },
      "file_name": "c5b439fa6766e4d9dabf09d1b0d686311b494914.pdf"
    },
    {
      "success": true,
      "doc_id": "7bcd452a197c3b13eb7cdca847354ffc",
      "summary": "Machine Learning models often only generalize reliably to samples from the training distribution. Consequentially, detecting when input data is out-of-distribution (OOD) is crucial, especially in safety-critical applications. Current OOD detection methods, however, tend to be domain agnostic and often fail to incorporate valuable prior knowledge about the structure of the training distribution. To address this limitation, we introduce a novel, hybrid OOD detection algorithm that combines a deep learning-based perception system with a first-order logic-based knowledge representation. A logical reasoning system uses this knowledge base at run-time to infer whether inputs are consistent with prior knowledge about the training distribution. In contrast to purely neural systems, the structured knowledge representation allows humans to inspect and modify the rules that govern the OOD detectorsâ€™ behavior. This not only enhances performance but also fosters a level of explainability that is particularly beneficial in safety-critical contexts. We demonstrate the effectiveness of our method through experiments on several datasets and discuss advantages and limitations. Our code is available online.1",
      "intriguing_abstract": "Machine Learning models often only generalize reliably to samples from the training distribution. Consequentially, detecting when input data is out-of-distribution (OOD) is crucial, especially in safety-critical applications. Current OOD detection methods, however, tend to be domain agnostic and often fail to incorporate valuable prior knowledge about the structure of the training distribution. To address this limitation, we introduce a novel, hybrid OOD detection algorithm that combines a deep learning-based perception system with a first-order logic-based knowledge representation. A logical reasoning system uses this knowledge base at run-time to infer whether inputs are consistent with prior knowledge about the training distribution. In contrast to purely neural systems, the structured knowledge representation allows humans to inspect and modify the rules that govern the OOD detectorsâ€™ behavior. This not only enhances performance but also fosters a level of explainability that is particularly beneficial in safety-critical contexts. We demonstrate the effectiveness of our method through experiments on several datasets and discuss advantages and limitations. Our code is available online.1",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/1f2462ad6ffef934b7470313ffc3d42a0af35c9c.pdf",
      "citation_key": "kirchheim20243gn",
      "metadata": {
        "title": "Out-of-Distribution Detection with Logical Reasoning",
        "authors": [
          "Konstantin Kirchheim",
          "Tim Gonschorek",
          "F. Ortmeier"
        ],
        "published_date": "2024",
        "abstract": "Machine Learning models often only generalize reliably to samples from the training distribution. Consequentially, detecting when input data is out-of-distribution (OOD) is crucial, especially in safety-critical applications. Current OOD detection methods, however, tend to be domain agnostic and often fail to incorporate valuable prior knowledge about the structure of the training distribution. To address this limitation, we introduce a novel, hybrid OOD detection algorithm that combines a deep learning-based perception system with a first-order logic-based knowledge representation. A logical reasoning system uses this knowledge base at run-time to infer whether inputs are consistent with prior knowledge about the training distribution. In contrast to purely neural systems, the structured knowledge representation allows humans to inspect and modify the rules that govern the OOD detectorsâ€™ behavior. This not only enhances performance but also fosters a level of explainability that is particularly beneficial in safety-critical contexts. We demonstrate the effectiveness of our method through experiments on several datasets and discuss advantages and limitations. Our code is available online.1",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/1f2462ad6ffef934b7470313ffc3d42a0af35c9c.pdf",
        "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Machine Learning models often only generalize reliably to samples from the training distribution. Consequentially, detecting when input data is out-of-distribution (OOD) is crucial, especially in safety-critical applications. Current OOD detection methods, however, tend to be domain agnostic and often fail to incorporate valuable prior knowledge about the structure of the training distribution. To address this limitation, we introduce a novel, hybrid OOD detection algorithm that combines a deep learning-based perception system with a first-order logic-based knowledge representation. A logical reasoning system uses this knowledge base at run-time to infer whether inputs are consistent with prior knowledge about the training distribution. In contrast to purely neural systems, the structured knowledge representation allows humans to inspect and modify the rules that govern the OOD detectorsâ€™ behavior. This not only enhances performance but also fosters a level of explainability that is particularly beneficial in safety-critical contexts. We demonstrate the effectiveness of our method through experiments on several datasets and discuss advantages and limitations. Our code is available online.1",
        "keywords": []
      },
      "file_name": "1f2462ad6ffef934b7470313ffc3d42a0af35c9c.pdf"
    },
    {
      "success": true,
      "doc_id": "a2ad68dc46530a87615869c4ee17a49a",
      "summary": "When faced with an out-of-distribution (OOD) question or image, visual question answering (VQA) systems may provide unreliable answers. If relied on by real users or secondary systems, these failures may range from annoying to potentially endangering. Detecting OOD samples in single-modality settings is well-studied; however, limited attention has been paid to vision-and-language settings. In this work, we examine the question of OOD detection in the multimodal VQA task and benchmark a suite of approaches to identify OOD image-question pairs. In our experiments, we leverage popular VQA datasets to benchmark detection performance across a range of difficulties. We also produce composite datasets to examine impacts of individual modalities and of image-question agreement. Our results show that answer confidence alone is often a poor signal and that methods based on image-based question generation or examining model attention can lead to significantly better results. We find detecting ungrounded image-question pairs and small shifts in image distribution remain challenging.",
      "intriguing_abstract": "When faced with an out-of-distribution (OOD) question or image, visual question answering (VQA) systems may provide unreliable answers. If relied on by real users or secondary systems, these failures may range from annoying to potentially endangering. Detecting OOD samples in single-modality settings is well-studied; however, limited attention has been paid to vision-and-language settings. In this work, we examine the question of OOD detection in the multimodal VQA task and benchmark a suite of approaches to identify OOD image-question pairs. In our experiments, we leverage popular VQA datasets to benchmark detection performance across a range of difficulties. We also produce composite datasets to examine impacts of individual modalities and of image-question agreement. Our results show that answer confidence alone is often a poor signal and that methods based on image-based question generation or examining model attention can lead to significantly better results. We find detecting ungrounded image-question pairs and small shifts in image distribution remain challenging.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/b2f118a60c6d467bab521a29fa2a6f33f60f3915.pdf",
      "citation_key": "shi2024rfk",
      "metadata": {
        "title": "Benchmarking Out-of-Distribution Detection in Visual Question Answering",
        "authors": [
          "Xiangxi Shi",
          "Stefan Lee"
        ],
        "published_date": "2024",
        "abstract": "When faced with an out-of-distribution (OOD) question or image, visual question answering (VQA) systems may provide unreliable answers. If relied on by real users or secondary systems, these failures may range from annoying to potentially endangering. Detecting OOD samples in single-modality settings is well-studied; however, limited attention has been paid to vision-and-language settings. In this work, we examine the question of OOD detection in the multimodal VQA task and benchmark a suite of approaches to identify OOD image-question pairs. In our experiments, we leverage popular VQA datasets to benchmark detection performance across a range of difficulties. We also produce composite datasets to examine impacts of individual modalities and of image-question agreement. Our results show that answer confidence alone is often a poor signal and that methods based on image-based question generation or examining model attention can lead to significantly better results. We find detecting ungrounded image-question pairs and small shifts in image distribution remain challenging.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b2f118a60c6d467bab521a29fa2a6f33f60f3915.pdf",
        "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
        "citationCount": 8,
        "score": 8.0,
        "summary": "When faced with an out-of-distribution (OOD) question or image, visual question answering (VQA) systems may provide unreliable answers. If relied on by real users or secondary systems, these failures may range from annoying to potentially endangering. Detecting OOD samples in single-modality settings is well-studied; however, limited attention has been paid to vision-and-language settings. In this work, we examine the question of OOD detection in the multimodal VQA task and benchmark a suite of approaches to identify OOD image-question pairs. In our experiments, we leverage popular VQA datasets to benchmark detection performance across a range of difficulties. We also produce composite datasets to examine impacts of individual modalities and of image-question agreement. Our results show that answer confidence alone is often a poor signal and that methods based on image-based question generation or examining model attention can lead to significantly better results. We find detecting ungrounded image-question pairs and small shifts in image distribution remain challenging.",
        "keywords": []
      },
      "file_name": "b2f118a60c6d467bab521a29fa2a6f33f60f3915.pdf"
    },
    {
      "success": true,
      "doc_id": "c96077c7497cbbf9ce885733f48ff42d",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/1d13f355ee04e0931bd589b73f533b83bdf4e9b1.pdf",
      "citation_key": "feng2024r4v",
      "metadata": {
        "title": "When an extra rejection class meets out-of-distribution detection in long-tailed image classification",
        "authors": [
          "Shuai Feng",
          "Chongjun Wang"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/1d13f355ee04e0931bd589b73f533b83bdf4e9b1.pdf",
        "venue": "Neural Networks",
        "citationCount": 8,
        "score": 8.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "1d13f355ee04e0931bd589b73f533b83bdf4e9b1.pdf"
    },
    {
      "success": true,
      "doc_id": "51713d133dba46ff5855148954764827",
      "summary": "Here's a focused summary of the paper \\cite{li2024ypq} for a literature review:\n\n### Technical Paper Analysis: SeTAR: Out-of-Distribution Detection with Selective Low-Rank Approximation \\cite{li2024ypq}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection in neural networks, particularly within the context of Vision-and-Language Pretrained (VLP) models like CLIP.\n    *   **Importance and Challenge**: OOD detection is crucial for the safe and reliable deployment of neural networks in real-world applications (e.g., autonomous vehicles, healthcare), where models frequently encounter data not represented in their training distribution. Existing CLIP-based OOD methods face limitations:\n        *   **Zero-shot methods**: Suffer from suboptimal performance due to potential domain gaps between pre-training and downstream ID data.\n        *   **Fine-tuning methods**: Risk deconstructing the intricate, generalizable representations learned by large pre-trained models like CLIP, requiring meticulously designed training strategies.\n        *   **Sparsification-based approaches**: While effective in CNNs, their utility diminishes in large-scale pre-trained models like CLIP where activation differences for OOD become subtle.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{li2024ypq} positions its work against two main categories of CLIP-based OOD detection:\n        *   **Zero-shot methods**: Such as MCM \\cite{ming2022mcm} and GL-MCM \\cite{miyai2023bgl}, which rely on novel scoring functions without additional training. SeTAR aims to enhance these methods post-hoc.\n        *   **Fine-tuning methods**: Like LoCoOp \\cite{miyai2023a} and LoRA \\cite{hu2022lora}, which adapt CLIP to specific ID datasets. SeTAR+FT extends SeTAR to improve these fine-tuning approaches.\n    *   **Limitations of Previous Solutions**:\n        *   Zero-shot methods often yield suboptimal performance due to domain shifts.\n        *   Fine-tuning methods can be complex to design and risk catastrophic forgetting or deconstructing CLIP's robust representations.\n        *   Sparsification, effective in smaller CNNs, is less effective in large pre-trained models like CLIP due to subtle activation differences.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **SeTAR (Selective Low-Rank Approximation)**, a training-free, post-hoc method that improves OOD detection by selectively modifying the weight matrices of pre-trained models (vision-language and vision-only models).\n        *   It leverages Singular Value Decomposition (SVD) to perform low-rank approximation on selected weight matrices, specifically focusing on the `Wup` matrices within the feed-forward sublayers of the CLIP encoder (Figure 1).\n        *   The method identifies and retains \"principle singular components\" (corresponding to large singular values) while discarding \"minor singular components\" (corresponding to small singular values), which are hypothesized to contribute to noise or sensitivity to OOD inputs.\n    *   **Novelty/Difference**:\n        *   **Selective Approximation**: Unlike prior low-rank approximation methods that apply uniform rank reduction, SeTAR *selectively* chooses which weight matrices to approximate and determines a *specific rank reduction ratio* for each, based on a greedy search.\n        *   **Training-Free Post-hoc Modification**: SeTAR directly modifies the pre-trained model's weights without requiring additional training epochs or new parameters, making it efficient and scalable.\n        *   **Greedy Search Algorithm**: A simple top-to-bottom, image-to-text greedy search algorithm is introduced to determine the optimal rank reduction ratio for each `Wup` matrix, using a validation set and a loss function (e.g., LoCoOp loss) to guide the selection.\n        *   **SeTAR+FT Extension**: SeTAR is extended to **SeTAR+FT**, a novel fine-tuning approach. It first applies SeTAR to determine the principal components to retain. During fine-tuning, these principal components are frozen, and only the minor singular components (represented as low-rank matrices A and B, similar to LoRA) are updated. This allows for more effective and efficient fine-tuning by focusing updates on less critical components.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm (SeTAR)**: A simple yet effective training-free OOD detection method based on selective low-rank approximation of weight matrices, applicable to various scoring functions and model backbones.\n    *   **System Design/Architectural Innovation (SeTAR+FT)**: An extension that demonstrates the effectiveness of SeTAR in enhancing fine-tuning-based OOD detection, achieving new state-of-the-art results by intelligently combining low-rank approximation with adaptation.\n    *   **Empirical Validation**: Extensive evaluations demonstrating SeTAR and SeTAR+FT consistently outperform baseline methods and establish new state-of-the-art results on CLIP-based OOD detection benchmarks.\n    *   **Ablation Studies**: Comprehensive studies to verify the effectiveness, robustness, and generalizability of SeTAR, providing insights into its underlying mechanisms.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluations of SeTAR (training-free) against zero-shot baselines (MCM, GL-MCM).\n        *   Evaluations of SeTAR+FT against fine-tuning baselines (LoCoOp, LoRA).\n        *   Ablation studies on search algorithms, temperature hyperparameters, and different model backbones.\n    *   **Datasets**:\n        *   **In-Distribution (ID)**: ImageNet1K and Pascal-VOC.\n        *   **Out-of-Distribution (OOD)**: iNaturalist, SUN, Places, Texture, ImageNet22K, COCO.\n    *   **Model Backbone**: Primarily CLIP ViT-B/16.\n    *   **Key Performance Metrics**:\n        *   False Positive Rate at 95% True Positive Rate (FPR95) (lower is better).\n        *   Area Under the Receiver Operating Characteristic curve (AUROC) (higher is better).\n    *   **Comparison Results**:\n        *   **SeTAR (Training-Free)**: Achieved superior performance, reducing the relative FPR95 by up to 18.95% (on ImageNet1K with GL-MCM) and 36.80% (on Pascal-VOC with GL-MCM) compared to vanilla zero-shot baselines. For instance, on ImageNet1K with GL-MCM, SeTAR improved AUROC to 91.32%.\n        *   **SeTAR+FT**: Outperformed state-of-the-art fine-tuning baselines like LoCoOp and LoRA, further increasing AUROC to 92.31% on ImageNet1K when combined with fine-tuning.\n        *   Ablation studies confirmed SeTAR's effectiveness, robustness, and generalizability across different ViT backbones.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The greedy search algorithm for determining rank reduction ratios is a heuristic and may not guarantee a globally optimal solution.\n        *   The method primarily focuses on `Wup` matrices based on preliminary experiments, implying other weight matrices might also be relevant but are not explored in depth.\n        *   While \"training-free\" in terms of not updating original model weights via backpropagation, the greedy search still requires a validation set and a loss function (e.g., LoCoOp loss) to select optimal approximation parameters.\n    *   **Scope of Applicability**: Primarily demonstrated on CLIP-based vision-language models and vision-only backbones (ViT). Its direct applicability to other model architectures or modalities (e.g., pure text models) would require further investigation.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: SeTAR establishes a new state-of-the-art in CLIP-based OOD detection, offering a scalable and efficient solution that significantly improves performance over existing zero-shot and fine-tuning methods.\n    *   **Potential Impact on Future Research**:\n        *   Highlights the potential of selective low-rank approximation as a powerful, training-free technique for enhancing model robustness and OOD detection capabilities.\n        *   Opens avenues for further research into understanding how specific weight matrix components contribute to OOD sensitivity and how they can be optimally manipulated.\n        *   Provides a foundation for developing more efficient and effective fine-tuning strategies for large pre-trained models by intelligently managing parameter updates.\n        *   Encourages exploration of similar post-hoc modification techniques for other model robustness tasks.",
      "intriguing_abstract": "The safe deployment of powerful Vision-and-Language Pretrained (VLP) models like CLIP hinges on robust Out-of-Distribution (OOD) detection. Current CLIP-based OOD methods struggle, with zero-shot approaches often suboptimal and fine-tuning risking the deconstruction of valuable pre-trained representations. We introduce **SeTAR (Selective Low-Rank Approximation)**, a novel training-free, post-hoc method that dramatically enhances OOD detection by intelligently modifying pre-trained model weights. SeTAR leverages Singular Value Decomposition (SVD) to selectively approximate specific weight matrices, identifying and retaining crucial \"principal singular components\" while discarding noise-contributing \"minor components\" through a greedy search.\n\nBeyond its training-free efficacy, we present **SeTAR+FT**, an innovative fine-tuning strategy that freezes these principal components, updating only the minor ones for superior adaptation. Extensive experiments demonstrate SeTAR's remarkable performance, achieving new state-of-the-art results. It reduces False Positive Rate at 95% True Positive Rate (FPR95) by up to 36.80% and significantly improves AUROC compared to existing zero-shot and fine-tuning baselines on diverse OOD benchmarks. SeTAR offers a scalable, efficient, and generalizable solution, paving the way for more reliable and robust AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Vision-and-Language Pretrained (VLP) models",
        "CLIP",
        "Selective Low-Rank Approximation (SeTAR)",
        "Singular Value Decomposition (SVD)",
        "Training-free OOD detection",
        "Post-hoc model modification",
        "Greedy search algorithm",
        "SeTAR+FT",
        "Neural network robustness",
        "State-of-the-art performance",
        "Weight matrix approximation",
        "Principal singular components"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/728afc51ac20d79133d8c747a2d18b01c6a6de5e.pdf",
      "citation_key": "li2024ypq",
      "metadata": {
        "title": "SeTAR: Out-of-Distribution Detection with Selective Low-Rank Approximation",
        "authors": [
          "Yixia Li",
          "Boya Xiong",
          "Guanhua Chen",
          "Yun Chen"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is crucial for the safe deployment of neural networks. Existing CLIP-based approaches perform OOD detection by devising novel scoring functions or sophisticated fine-tuning methods. In this work, we propose SeTAR, a novel, training-free OOD detection method that leverages selective low-rank approximation of weight matrices in vision-language and vision-only models. SeTAR enhances OOD detection via post-hoc modification of the model's weight matrices using a simple greedy search algorithm. Based on SeTAR, we further propose SeTAR+FT, a fine-tuning extension optimizing model performance for OOD detection tasks. Extensive evaluations on ImageNet1K and Pascal-VOC benchmarks show SeTAR's superior performance, reducing the relatively false positive rate by up to 18.95% and 36.80% compared to zero-shot and fine-tuning baselines. Ablation studies further validate SeTAR's effectiveness, robustness, and generalizability across different model backbones. Our work offers a scalable, efficient solution for OOD detection, setting a new state-of-the-art in this area.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/728afc51ac20d79133d8c747a2d18b01c6a6de5e.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 7,
        "score": 7.0,
        "summary": "Here's a focused summary of the paper \\cite{li2024ypq} for a literature review:\n\n### Technical Paper Analysis: SeTAR: Out-of-Distribution Detection with Selective Low-Rank Approximation \\cite{li2024ypq}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection in neural networks, particularly within the context of Vision-and-Language Pretrained (VLP) models like CLIP.\n    *   **Importance and Challenge**: OOD detection is crucial for the safe and reliable deployment of neural networks in real-world applications (e.g., autonomous vehicles, healthcare), where models frequently encounter data not represented in their training distribution. Existing CLIP-based OOD methods face limitations:\n        *   **Zero-shot methods**: Suffer from suboptimal performance due to potential domain gaps between pre-training and downstream ID data.\n        *   **Fine-tuning methods**: Risk deconstructing the intricate, generalizable representations learned by large pre-trained models like CLIP, requiring meticulously designed training strategies.\n        *   **Sparsification-based approaches**: While effective in CNNs, their utility diminishes in large-scale pre-trained models like CLIP where activation differences for OOD become subtle.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{li2024ypq} positions its work against two main categories of CLIP-based OOD detection:\n        *   **Zero-shot methods**: Such as MCM \\cite{ming2022mcm} and GL-MCM \\cite{miyai2023bgl}, which rely on novel scoring functions without additional training. SeTAR aims to enhance these methods post-hoc.\n        *   **Fine-tuning methods**: Like LoCoOp \\cite{miyai2023a} and LoRA \\cite{hu2022lora}, which adapt CLIP to specific ID datasets. SeTAR+FT extends SeTAR to improve these fine-tuning approaches.\n    *   **Limitations of Previous Solutions**:\n        *   Zero-shot methods often yield suboptimal performance due to domain shifts.\n        *   Fine-tuning methods can be complex to design and risk catastrophic forgetting or deconstructing CLIP's robust representations.\n        *   Sparsification, effective in smaller CNNs, is less effective in large pre-trained models like CLIP due to subtle activation differences.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **SeTAR (Selective Low-Rank Approximation)**, a training-free, post-hoc method that improves OOD detection by selectively modifying the weight matrices of pre-trained models (vision-language and vision-only models).\n        *   It leverages Singular Value Decomposition (SVD) to perform low-rank approximation on selected weight matrices, specifically focusing on the `Wup` matrices within the feed-forward sublayers of the CLIP encoder (Figure 1).\n        *   The method identifies and retains \"principle singular components\" (corresponding to large singular values) while discarding \"minor singular components\" (corresponding to small singular values), which are hypothesized to contribute to noise or sensitivity to OOD inputs.\n    *   **Novelty/Difference**:\n        *   **Selective Approximation**: Unlike prior low-rank approximation methods that apply uniform rank reduction, SeTAR *selectively* chooses which weight matrices to approximate and determines a *specific rank reduction ratio* for each, based on a greedy search.\n        *   **Training-Free Post-hoc Modification**: SeTAR directly modifies the pre-trained model's weights without requiring additional training epochs or new parameters, making it efficient and scalable.\n        *   **Greedy Search Algorithm**: A simple top-to-bottom, image-to-text greedy search algorithm is introduced to determine the optimal rank reduction ratio for each `Wup` matrix, using a validation set and a loss function (e.g., LoCoOp loss) to guide the selection.\n        *   **SeTAR+FT Extension**: SeTAR is extended to **SeTAR+FT**, a novel fine-tuning approach. It first applies SeTAR to determine the principal components to retain. During fine-tuning, these principal components are frozen, and only the minor singular components (represented as low-rank matrices A and B, similar to LoRA) are updated. This allows for more effective and efficient fine-tuning by focusing updates on less critical components.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm (SeTAR)**: A simple yet effective training-free OOD detection method based on selective low-rank approximation of weight matrices, applicable to various scoring functions and model backbones.\n    *   **System Design/Architectural Innovation (SeTAR+FT)**: An extension that demonstrates the effectiveness of SeTAR in enhancing fine-tuning-based OOD detection, achieving new state-of-the-art results by intelligently combining low-rank approximation with adaptation.\n    *   **Empirical Validation**: Extensive evaluations demonstrating SeTAR and SeTAR+FT consistently outperform baseline methods and establish new state-of-the-art results on CLIP-based OOD detection benchmarks.\n    *   **Ablation Studies**: Comprehensive studies to verify the effectiveness, robustness, and generalizability of SeTAR, providing insights into its underlying mechanisms.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluations of SeTAR (training-free) against zero-shot baselines (MCM, GL-MCM).\n        *   Evaluations of SeTAR+FT against fine-tuning baselines (LoCoOp, LoRA).\n        *   Ablation studies on search algorithms, temperature hyperparameters, and different model backbones.\n    *   **Datasets**:\n        *   **In-Distribution (ID)**: ImageNet1K and Pascal-VOC.\n        *   **Out-of-Distribution (OOD)**: iNaturalist, SUN, Places, Texture, ImageNet22K, COCO.\n    *   **Model Backbone**: Primarily CLIP ViT-B/16.\n    *   **Key Performance Metrics**:\n        *   False Positive Rate at 95% True Positive Rate (FPR95) (lower is better).\n        *   Area Under the Receiver Operating Characteristic curve (AUROC) (higher is better).\n    *   **Comparison Results**:\n        *   **SeTAR (Training-Free)**: Achieved superior performance, reducing the relative FPR95 by up to 18.95% (on ImageNet1K with GL-MCM) and 36.80% (on Pascal-VOC with GL-MCM) compared to vanilla zero-shot baselines. For instance, on ImageNet1K with GL-MCM, SeTAR improved AUROC to 91.32%.\n        *   **SeTAR+FT**: Outperformed state-of-the-art fine-tuning baselines like LoCoOp and LoRA, further increasing AUROC to 92.31% on ImageNet1K when combined with fine-tuning.\n        *   Ablation studies confirmed SeTAR's effectiveness, robustness, and generalizability across different ViT backbones.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The greedy search algorithm for determining rank reduction ratios is a heuristic and may not guarantee a globally optimal solution.\n        *   The method primarily focuses on `Wup` matrices based on preliminary experiments, implying other weight matrices might also be relevant but are not explored in depth.\n        *   While \"training-free\" in terms of not updating original model weights via backpropagation, the greedy search still requires a validation set and a loss function (e.g., LoCoOp loss) to select optimal approximation parameters.\n    *   **Scope of Applicability**: Primarily demonstrated on CLIP-based vision-language models and vision-only backbones (ViT). Its direct applicability to other model architectures or modalities (e.g., pure text models) would require further investigation.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: SeTAR establishes a new state-of-the-art in CLIP-based OOD detection, offering a scalable and efficient solution that significantly improves performance over existing zero-shot and fine-tuning methods.\n    *   **Potential Impact on Future Research**:\n        *   Highlights the potential of selective low-rank approximation as a powerful, training-free technique for enhancing model robustness and OOD detection capabilities.\n        *   Opens avenues for further research into understanding how specific weight matrix components contribute to OOD sensitivity and how they can be optimally manipulated.\n        *   Provides a foundation for developing more efficient and effective fine-tuning strategies for large pre-trained models by intelligently managing parameter updates.\n        *   Encourages exploration of similar post-hoc modification techniques for other model robustness tasks.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Vision-and-Language Pretrained (VLP) models",
          "CLIP",
          "Selective Low-Rank Approximation (SeTAR)",
          "Singular Value Decomposition (SVD)",
          "Training-free OOD detection",
          "Post-hoc model modification",
          "Greedy search algorithm",
          "SeTAR+FT",
          "Neural network robustness",
          "State-of-the-art performance",
          "Weight matrix approximation",
          "Principal singular components"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** setar, a novel, training-free ood detection **method**\", \"leverages selective low-rank approximation\", \"simple greedy search **algorithm**\", and \"further **propose** setar+ft, a fine-tuning extension\". these are strong indicators of presenting new methods and algorithms.\n*   the introduction sets up a technical problem (ood detection challenges) that the proposed solution aims to address.\n*   while there are \"extensive evaluations\" and \"ablation studies\" (which are empirical), these are used to validate the *newly proposed technical method*. the primary contribution is the method itself.\n\ntherefore, this paper best fits the **technical** classification.\n\n**classification:** technical"
      },
      "file_name": "728afc51ac20d79133d8c747a2d18b01c6a6de5e.pdf"
    },
    {
      "success": true,
      "doc_id": "41cd334672ddb674ad82d51fb59f5d7e",
      "summary": "Here's a focused summary of the paper \"LOCAL-PROMPT: EXTENSIBLE LOCAL PROMPTS FOR FEW-SHOT OUT-OF-DISTRIBUTION DETECTION\" \\cite{zeng2024bti} for a literature review:\n\n---\n\n### **1. Research Problem & Motivation**\n\n*   **Specific Technical Problem**: Existing few-shot Out-of-Distribution (OOD) detection methods, especially those leveraging Vision-Language Models (VLMs), primarily focus on optimizing *global* prompts. This approach overlooks the crucial role of *local* information, leading to failures in identifying challenging OOD samples that are globally similar to in-distribution (ID) classes but differ subtly in specific regions.\n*   **Importance and Challenge**: OOD detection is critical for safety-sensitive applications (e.g., autonomous driving, face recognition). The challenge lies in distinguishing outliers when they closely resemble known categories, requiring a detector to identify subtle, regional differences. Previous VLM-based methods either use only global features, leading to coarse descriptions, or apply the same prompts to both global and local features, resulting in inaccurate local outlier identification.\n\n### **2. Related Work & Positioning**\n\n*   **Relation to Existing Approaches**:\n    *   Builds upon VLM-based OOD detection methods (e.g., MCM \\cite{ming2022}, ZOC \\cite{esmaeilpour2022}, Clipn \\cite{wang2023}) and few-shot prompt learning (e.g., CoOp \\cite{zhou2022b}).\n    *   Relates to methods that consider local information in OOD detection (e.g., GL-MCM \\cite{miyai2023b}, LoCoOp \\cite{miyai2023a}).\n*   **Limitations of Previous Solutions**:\n    *   Most VLM-based OOD methods focus on global features or use additional modules/data, often suffering from computational inefficiency or data collection demands.\n    *   Crucially, existing approaches that *do* consider local information (like GL-MCM \\cite{miyai2023b} and LoCoOp \\cite{miyai2023a}) still employ the *same prompts* for both global and local features. This limits their ability to capture fine-grained regional differences and leverage specific local outlier knowledge.\n    *   Previous prompt learning methods (e.g., CoOp \\cite{zhou2022b}) primarily optimize global textual prompts.\n\n### **3. Technical Approach & Innovation**\n\n*   **Core Technical Method**: `Local-Prompt` \\cite{zeng2024bti} introduces a novel coarse-to-fine few-shot tuning paradigm that emphasizes regional enhancement using *extensible local prompts*. It freezes global prompts and focuses on learning refined local prompts.\n    *   **Two Integral Components**:\n        1.  **Global Prompt Guided Negative Augmentation**: Utilizes frozen, coarse global prompts as guiding cues to generate hard negative augmented samples (via random cropping and similarity selection) to simulate outlier situations and leverage local outlier knowledge.\n        2.  **Local Prompt Enhanced Regional Regularization**: Employs trainable local prompts and a regional regularization strategy (including contrastive regularization and diversity regularization) to effectively capture fine local information and aid in outlier identification.\n*   **Novelty/Difference**:\n    *   **Decomposition of Prompts**: Explicitly decomposes global and local prompts, freezing global prompts for coarse guidance and training local prompts for fine-grained regional enhancement. This is a key departure from prior work that uses unified prompts.\n    *   **Local Outlier Knowledge**: Focuses on learning regional-related knowledge, including for unknown samples, which has not been explored before.\n    *   **Extensibility**: The approach is orthogonal to global prompt optimization methods, allowing `Local-Prompt` \\cite{zeng2024bti} to be seamlessly integrated with pre-trained global prompts during inference to further boost performance.\n    *   **Regional-related Metrics**: Proposes corresponding regional-related evaluation metrics to fully leverage the power of local prompts.\n\n### **4. Key Technical Contributions**\n\n*   **Novel Algorithms/Methods**:\n    *   A coarse-to-fine few-shot tuning paradigm for OOD detection, specifically designed for local prompt enhancement.\n    *   Global prompt guided negative augmentation, which synthesizes hard negative images using random cropping and global prompt similarity for local outlier knowledge acquisition.\n    *   Local prompt enhanced regional regularization, comprising contrastive regularization (local loss and local negative loss) and diversity regularization, to refine local prompts for better ID/OOD distinction.\n*   **System Design/Architectural Innovations**:\n    *   The architectural separation and distinct roles of frozen global prompts (for coarse guidance and negative augmentation selection) and trainable local prompts (for fine-grained regional feature interaction).\n*   **Theoretical Insights/Analysis**:\n    *   Highlights the importance of regional-related knowledge for OOD detection, especially for challenging samples with subtle local differences.\n    *   Demonstrates that explicitly learning local prompts for local features, distinct from global prompts, can significantly improve OOD detection performance.\n\n### **5. Experimental Validation**\n\n*   **Experiments Conducted**: Comprehensive experiments were conducted to demonstrate the effectiveness of `Local-Prompt` \\cite{zeng2024bti}. These include evaluations on OOD detection and ID classification abilities under few-shot tuning settings. Ablation studies are also mentioned to verify the effectiveness of components.\n*   **Key Performance Metrics & Comparison Results**:\n    *   **OOD Detection**: `Local-Prompt` \\cite{zeng2024bti} achieved a notable 5.17% reduction in average FPR95 (False Positive Rate at 95% True Positive Rate) against state-of-the-art methods.\n    *   **ID Accuracy**: Improved ID accuracy by 1.02%.\n    *   **Dataset**: Results were obtained on the challenging ImageNet-1k dataset under 4-shot tuning.\n    *   **Significant Finding**: The 4-shot results of `Local-Prompt` \\cite{zeng2024bti} on ImageNet-1k even outperformed the 16-shot results of previous methods, showcasing its superior data efficiency and performance.\n\n### **6. Limitations & Scope**\n\n*   **Technical Limitations/Assumptions**:\n    *   The paper states that the main purpose is to decompose global and local prompts and showcase the effectiveness of local outlier enhancement, thus they \"do not specifically select the template as it is not the focus of the paper\" for global prompts during training. This implies that the initial global prompt selection is basic (\"a photo of {class}\") and not optimized within the training phase of `Local-Prompt` \\cite{zeng2024bti}.\n*   **Scope of Applicability**:\n    *   Primarily focused on few-shot OOD detection using Vision-Language Models (specifically CLIP-like architectures).\n    *   The extensibility feature means it can be applied to enhance existing global prompt optimization methods during inference.\n\n### **7. Technical Significance**\n\n*   **Advancement of State-of-the-Art**: `Local-Prompt` \\cite{zeng2024bti} significantly advances the technical state-of-the-art in few-shot OOD detection by introducing a novel paradigm that explicitly leverages local information through dedicated local prompts. Its ability to outperform previous methods' 16-shot results with only 4 shots demonstrates a substantial improvement in data efficiency and detection capability.\n*   **Potential Impact on Future Research**:\n    *   Opens new avenues for research into fine-grained, region-specific prompt engineering for various VLM tasks beyond OOD detection.\n    *   Encourages further exploration of decomposing and specializing prompts for different levels of feature granularity (global vs. local).\n    *   The concept of \"extensible local prompts\" provides a framework for integrating new local enhancement techniques with existing or future global prompt optimization strategies, fostering modular and composable VLM tuning approaches.\n    *   Highlights the importance of synthesizing hard negative samples at a local level for robust outlier detection.",
      "intriguing_abstract": "While Vision-Language Models (VLMs) have revolutionized many tasks, their efficacy in few-shot Out-of-Distribution (OOD) detection is often hampered by an over-reliance on global features, overlooking crucial local anomalies. We introduce `Local-Prompt`, a novel coarse-to-fine tuning paradigm that fundamentally shifts focus to *extensible local prompts* for superior OOD detection. Unlike prior methods that use unified prompts, `Local-Prompt` explicitly decomposes global and local prompts, freezing global prompts for coarse guidance while training dedicated local prompts for fine-grained regional enhancement.\n\nOur approach leverages a unique Global Prompt Guided Negative Augmentation strategy to synthesize challenging local outlier samples, coupled with Local Prompt Enhanced Regional Regularization to refine local feature discrimination. This innovative framework not only captures subtle regional differences but also offers extensibility, seamlessly integrating with existing global prompt optimizations. `Local-Prompt` achieves unprecedented performance, reducing FPR95 by 5.17% and improving ID accuracy by 1.02% on ImageNet-1k, remarkably outperforming 16-shot methods with only 4 shots. This work marks a significant advancement in robust OOD detection, paving the way for safer, more reliable VLM applications by unlocking the power of localized knowledge.",
      "keywords": [
        "Few-shot OOD detection",
        "Vision-Language Models",
        "Extensible local prompts",
        "Global prompts",
        "Coarse-to-fine tuning paradigm",
        "Prompt decomposition",
        "Negative augmentation",
        "Regional regularization",
        "Local outlier knowledge",
        "FPR95 reduction",
        "Data efficiency",
        "Safety-critical applications"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/88b9e2bce0caadf7495490603f5292166e2a1860.pdf",
      "citation_key": "zeng2024bti",
      "metadata": {
        "title": "Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection",
        "authors": [
          "Fanhu Zeng",
          "Zhen Cheng",
          "Fei Zhu",
          "Xu-Yao Zhang"
        ],
        "published_date": "2024",
        "abstract": "Out-of-Distribution (OOD) detection, aiming to distinguish outliers from known categories, has gained prominence in practical scenarios. Recently, the advent of vision-language models (VLM) has heightened interest in enhancing OOD detection for VLM through few-shot tuning. However, existing methods mainly focus on optimizing global prompts, ignoring refined utilization of local information with regard to outliers. Motivated by this, we freeze global prompts and introduce Local-Prompt, a novel coarse-to-fine tuning paradigm to emphasize regional enhancement with local prompts. Our method comprises two integral components: global prompt guided negative augmentation and local prompt enhanced regional regularization. The former utilizes frozen, coarse global prompts as guiding cues to incorporate negative augmentation, thereby leveraging local outlier knowledge. The latter employs trainable local prompts and a regional regularization to capture local information effectively, aiding in outlier identification. We also propose regional-related metric to empower the enrichment of OOD detection. Moreover, since our approach explores enhancing local prompts only, it can be seamlessly integrated with trained global prompts during inference to boost the performance. Comprehensive experiments demonstrate the effectiveness and potential of our method. Notably, our method reduces average FPR95 by 5.17% against state-of-the-art method in 4-shot tuning on challenging ImageNet-1k dataset, even outperforming 16-shot results of previous methods. Code is released at https://github.com/AuroraZengfh/Local-Prompt.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/88b9e2bce0caadf7495490603f5292166e2a1860.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 7,
        "score": 7.0,
        "summary": "Here's a focused summary of the paper \"LOCAL-PROMPT: EXTENSIBLE LOCAL PROMPTS FOR FEW-SHOT OUT-OF-DISTRIBUTION DETECTION\" \\cite{zeng2024bti} for a literature review:\n\n---\n\n### **1. Research Problem & Motivation**\n\n*   **Specific Technical Problem**: Existing few-shot Out-of-Distribution (OOD) detection methods, especially those leveraging Vision-Language Models (VLMs), primarily focus on optimizing *global* prompts. This approach overlooks the crucial role of *local* information, leading to failures in identifying challenging OOD samples that are globally similar to in-distribution (ID) classes but differ subtly in specific regions.\n*   **Importance and Challenge**: OOD detection is critical for safety-sensitive applications (e.g., autonomous driving, face recognition). The challenge lies in distinguishing outliers when they closely resemble known categories, requiring a detector to identify subtle, regional differences. Previous VLM-based methods either use only global features, leading to coarse descriptions, or apply the same prompts to both global and local features, resulting in inaccurate local outlier identification.\n\n### **2. Related Work & Positioning**\n\n*   **Relation to Existing Approaches**:\n    *   Builds upon VLM-based OOD detection methods (e.g., MCM \\cite{ming2022}, ZOC \\cite{esmaeilpour2022}, Clipn \\cite{wang2023}) and few-shot prompt learning (e.g., CoOp \\cite{zhou2022b}).\n    *   Relates to methods that consider local information in OOD detection (e.g., GL-MCM \\cite{miyai2023b}, LoCoOp \\cite{miyai2023a}).\n*   **Limitations of Previous Solutions**:\n    *   Most VLM-based OOD methods focus on global features or use additional modules/data, often suffering from computational inefficiency or data collection demands.\n    *   Crucially, existing approaches that *do* consider local information (like GL-MCM \\cite{miyai2023b} and LoCoOp \\cite{miyai2023a}) still employ the *same prompts* for both global and local features. This limits their ability to capture fine-grained regional differences and leverage specific local outlier knowledge.\n    *   Previous prompt learning methods (e.g., CoOp \\cite{zhou2022b}) primarily optimize global textual prompts.\n\n### **3. Technical Approach & Innovation**\n\n*   **Core Technical Method**: `Local-Prompt` \\cite{zeng2024bti} introduces a novel coarse-to-fine few-shot tuning paradigm that emphasizes regional enhancement using *extensible local prompts*. It freezes global prompts and focuses on learning refined local prompts.\n    *   **Two Integral Components**:\n        1.  **Global Prompt Guided Negative Augmentation**: Utilizes frozen, coarse global prompts as guiding cues to generate hard negative augmented samples (via random cropping and similarity selection) to simulate outlier situations and leverage local outlier knowledge.\n        2.  **Local Prompt Enhanced Regional Regularization**: Employs trainable local prompts and a regional regularization strategy (including contrastive regularization and diversity regularization) to effectively capture fine local information and aid in outlier identification.\n*   **Novelty/Difference**:\n    *   **Decomposition of Prompts**: Explicitly decomposes global and local prompts, freezing global prompts for coarse guidance and training local prompts for fine-grained regional enhancement. This is a key departure from prior work that uses unified prompts.\n    *   **Local Outlier Knowledge**: Focuses on learning regional-related knowledge, including for unknown samples, which has not been explored before.\n    *   **Extensibility**: The approach is orthogonal to global prompt optimization methods, allowing `Local-Prompt` \\cite{zeng2024bti} to be seamlessly integrated with pre-trained global prompts during inference to further boost performance.\n    *   **Regional-related Metrics**: Proposes corresponding regional-related evaluation metrics to fully leverage the power of local prompts.\n\n### **4. Key Technical Contributions**\n\n*   **Novel Algorithms/Methods**:\n    *   A coarse-to-fine few-shot tuning paradigm for OOD detection, specifically designed for local prompt enhancement.\n    *   Global prompt guided negative augmentation, which synthesizes hard negative images using random cropping and global prompt similarity for local outlier knowledge acquisition.\n    *   Local prompt enhanced regional regularization, comprising contrastive regularization (local loss and local negative loss) and diversity regularization, to refine local prompts for better ID/OOD distinction.\n*   **System Design/Architectural Innovations**:\n    *   The architectural separation and distinct roles of frozen global prompts (for coarse guidance and negative augmentation selection) and trainable local prompts (for fine-grained regional feature interaction).\n*   **Theoretical Insights/Analysis**:\n    *   Highlights the importance of regional-related knowledge for OOD detection, especially for challenging samples with subtle local differences.\n    *   Demonstrates that explicitly learning local prompts for local features, distinct from global prompts, can significantly improve OOD detection performance.\n\n### **5. Experimental Validation**\n\n*   **Experiments Conducted**: Comprehensive experiments were conducted to demonstrate the effectiveness of `Local-Prompt` \\cite{zeng2024bti}. These include evaluations on OOD detection and ID classification abilities under few-shot tuning settings. Ablation studies are also mentioned to verify the effectiveness of components.\n*   **Key Performance Metrics & Comparison Results**:\n    *   **OOD Detection**: `Local-Prompt` \\cite{zeng2024bti} achieved a notable 5.17% reduction in average FPR95 (False Positive Rate at 95% True Positive Rate) against state-of-the-art methods.\n    *   **ID Accuracy**: Improved ID accuracy by 1.02%.\n    *   **Dataset**: Results were obtained on the challenging ImageNet-1k dataset under 4-shot tuning.\n    *   **Significant Finding**: The 4-shot results of `Local-Prompt` \\cite{zeng2024bti} on ImageNet-1k even outperformed the 16-shot results of previous methods, showcasing its superior data efficiency and performance.\n\n### **6. Limitations & Scope**\n\n*   **Technical Limitations/Assumptions**:\n    *   The paper states that the main purpose is to decompose global and local prompts and showcase the effectiveness of local outlier enhancement, thus they \"do not specifically select the template as it is not the focus of the paper\" for global prompts during training. This implies that the initial global prompt selection is basic (\"a photo of {class}\") and not optimized within the training phase of `Local-Prompt` \\cite{zeng2024bti}.\n*   **Scope of Applicability**:\n    *   Primarily focused on few-shot OOD detection using Vision-Language Models (specifically CLIP-like architectures).\n    *   The extensibility feature means it can be applied to enhance existing global prompt optimization methods during inference.\n\n### **7. Technical Significance**\n\n*   **Advancement of State-of-the-Art**: `Local-Prompt` \\cite{zeng2024bti} significantly advances the technical state-of-the-art in few-shot OOD detection by introducing a novel paradigm that explicitly leverages local information through dedicated local prompts. Its ability to outperform previous methods' 16-shot results with only 4 shots demonstrates a substantial improvement in data efficiency and detection capability.\n*   **Potential Impact on Future Research**:\n    *   Opens new avenues for research into fine-grained, region-specific prompt engineering for various VLM tasks beyond OOD detection.\n    *   Encourages further exploration of decomposing and specializing prompts for different levels of feature granularity (global vs. local).\n    *   The concept of \"extensible local prompts\" provides a framework for integrating new local enhancement techniques with existing or future global prompt optimization strategies, fostering modular and composable VLM tuning approaches.\n    *   Highlights the importance of synthesizing hard negative samples at a local level for robust outlier detection.",
        "keywords": [
          "Few-shot OOD detection",
          "Vision-Language Models",
          "Extensible local prompts",
          "Global prompts",
          "Coarse-to-fine tuning paradigm",
          "Prompt decomposition",
          "Negative augmentation",
          "Regional regularization",
          "Local outlier knowledge",
          "FPR95 reduction",
          "Data efficiency",
          "Safety-critical applications"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"introduce local-prompt, a novel coarse-to-fine tuning paradigm\", \"our method comprises two integral components\", \"global prompt guided negative augmentation and local prompt enhanced regional regularization\". these phrases directly align with the \"propose\", \"develop\", \"present\", \"algorithm\", \"method\" criteria for a technical paper.\n*   **introduction discusses:** it clearly identifies a \"technical problem\" (existing methods ignore local information for outliers) and then presents a \"proposed solution\" (local-prompt, its components, and a new regional-related metric).\n*   while it also mentions \"comprehensive experiments demonstrate the effectiveness\" and provides specific quantitative results (e.g., \"reduces average fpr95 by 5.17%\"), these empirical findings serve to validate the *new method* being proposed. the primary contribution is the development of local-prompt, making it fundamentally a technical paper with strong empirical validation."
      },
      "file_name": "88b9e2bce0caadf7495490603f5292166e2a1860.pdf"
    },
    {
      "success": true,
      "doc_id": "9f00888a057212a4afa5ff7921aa4738",
      "summary": "Out-of-distribution (OOD) detection is essential to ensure the reliability and robustness of machine learning models in real-world applications. Post-hoc OOD detection methods have gained significant attention due to the fact that they offer the advantage of not requiring additional re-training, which could degrade model performance and increase training time. However, most existing post-hoc methods rely only on the encoder output (features), logits, or the softmax probability, meaning they have no access to information that might be lost in the feature extraction process. In this work, we address this limitation by introducing Adaptive Temperature Scaling (ATS), a novel approach that dynamically calculates a temperature value based on activations of the intermediate layers. Fusing this sample-specific adjustment with class-dependent logits, our ATS captures additional statistical information before they are lost in the feature extraction process, leading to a more robust and powerful OOD detection method. We conduct extensive experiments to demonstrate the efficacy of our approach. Notably, our method can be seamlessly combined with SOTA post-hoc OOD detection methods that rely on the logits, thereby enhancing their performance and improving their robustness.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection is essential to ensure the reliability and robustness of machine learning models in real-world applications. Post-hoc OOD detection methods have gained significant attention due to the fact that they offer the advantage of not requiring additional re-training, which could degrade model performance and increase training time. However, most existing post-hoc methods rely only on the encoder output (features), logits, or the softmax probability, meaning they have no access to information that might be lost in the feature extraction process. In this work, we address this limitation by introducing Adaptive Temperature Scaling (ATS), a novel approach that dynamically calculates a temperature value based on activations of the intermediate layers. Fusing this sample-specific adjustment with class-dependent logits, our ATS captures additional statistical information before they are lost in the feature extraction process, leading to a more robust and powerful OOD detection method. We conduct extensive experiments to demonstrate the efficacy of our approach. Notably, our method can be seamlessly combined with SOTA post-hoc OOD detection methods that rely on the logits, thereby enhancing their performance and improving their robustness.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/5df7dcb96a465ed4d4d2fa2414413a41494fee8c.pdf",
      "citation_key": "krumpl2024n1w",
      "metadata": {
        "title": "ATS: Adaptive Temperature Scaling for Enhancing Out-of-Distribution Detection Methods",
        "authors": [
          "Gerhard Krumpl",
          "H. Avenhaus",
          "Horst Possegger",
          "Horst Bischof"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is essential to ensure the reliability and robustness of machine learning models in real-world applications. Post-hoc OOD detection methods have gained significant attention due to the fact that they offer the advantage of not requiring additional re-training, which could degrade model performance and increase training time. However, most existing post-hoc methods rely only on the encoder output (features), logits, or the softmax probability, meaning they have no access to information that might be lost in the feature extraction process. In this work, we address this limitation by introducing Adaptive Temperature Scaling (ATS), a novel approach that dynamically calculates a temperature value based on activations of the intermediate layers. Fusing this sample-specific adjustment with class-dependent logits, our ATS captures additional statistical information before they are lost in the feature extraction process, leading to a more robust and powerful OOD detection method. We conduct extensive experiments to demonstrate the efficacy of our approach. Notably, our method can be seamlessly combined with SOTA post-hoc OOD detection methods that rely on the logits, thereby enhancing their performance and improving their robustness.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/5df7dcb96a465ed4d4d2fa2414413a41494fee8c.pdf",
        "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
        "citationCount": 7,
        "score": 7.0,
        "summary": "Out-of-distribution (OOD) detection is essential to ensure the reliability and robustness of machine learning models in real-world applications. Post-hoc OOD detection methods have gained significant attention due to the fact that they offer the advantage of not requiring additional re-training, which could degrade model performance and increase training time. However, most existing post-hoc methods rely only on the encoder output (features), logits, or the softmax probability, meaning they have no access to information that might be lost in the feature extraction process. In this work, we address this limitation by introducing Adaptive Temperature Scaling (ATS), a novel approach that dynamically calculates a temperature value based on activations of the intermediate layers. Fusing this sample-specific adjustment with class-dependent logits, our ATS captures additional statistical information before they are lost in the feature extraction process, leading to a more robust and powerful OOD detection method. We conduct extensive experiments to demonstrate the efficacy of our approach. Notably, our method can be seamlessly combined with SOTA post-hoc OOD detection methods that rely on the logits, thereby enhancing their performance and improving their robustness.",
        "keywords": []
      },
      "file_name": "5df7dcb96a465ed4d4d2fa2414413a41494fee8c.pdf"
    },
    {
      "success": true,
      "doc_id": "a6f5b69ef516f88f64046634ef1fed19",
      "summary": "Here's a focused summary of the paper \\cite{hogeweg2024tw3} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of high-performing out-of-distribution (OOD) detection, encompassing both anomaly and novel class detection, particularly in complex, real-world classification scenarios.\n    *   **Importance & Challenge**: This problem is crucial for the practical reliability of deep learning models in open and changing environments (e.g., species recognition, medicine, autonomous driving). It's challenging due to:\n        *   The need to distinguish between \"unknown\" inputs and known classes, rather than misclassifying novel inputs with high confidence.\n        *   Limitations of existing OOD methods, which are often benchmarked on small datasets with far-OOD data and may perform inconsistently across different OOD scenarios.\n        *   The specific complexities of biodiversity datasets: large scale (500k+ images), fine-grained hierarchical classes, severe class imbalance, and varying image quality.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon and incorporates several existing state-of-the-art OOD measures (e.g., Max(linear-T-scaled), FRE, LDOF, kNN-based distances).\n    *   **Limitations of Previous Solutions**: The paper highlights that individual OOD measures often have specific strengths and weaknesses, leading to inconsistent performance across diverse OOD scenarios (near, mid, far OOD). This suggests that no single measure is universally optimal, motivating a combined approach.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{hogeweg2024tw3} proposes the **Combined OOD (COOD)** framework, which learns to combine multiple individual OOD measures into a single, more robust OOD score. A Random Forest classifier is used for this supervised combination, exploiting non-linear relationships between the measures.\n    *   **Novelty**:\n        *   **Supervised Combination Framework**: Instead of developing a single new OOD measure, COOD innovates by creating a learned ensemble that leverages the complementary strengths of diverse measures.\n        *   **Novel OOD Measures**: The paper introduces several new individual OOD measures specifically designed for novel class detection and to exploit hierarchical class structures, as well as discrepancies between linear and kNN predictions. Examples include `Max(linear+kNN)` (agreement between linear and kNN probabilities), `TD(linear, kNN)` (conceptual taxon distance between predictions), `EnWeDi(average)` (entropy-weighted average distance to NN), `Feature sum` (absence of feature responses), and `Avg. true probability of NN`.\n        *   **Explicit Handling of ID-incorrect Samples**: The framework explicitly categorizes and considers in-distribution (ID) images that are incorrectly classified by the base model (`ID-incorrect-high`, `ID-incorrect`). This is crucial for practical applicability and robust OOD model training and evaluation.\n\n*   **Key Technical Contributions**\n    *   **Novel Framework**: The COOD framework for combining multiple OOD measures using a supervised Random Forest classifier.\n    *   **Novel OOD Measures**: Introduction of several new individual OOD measures tailored for hierarchical classification and novel class detection, leveraging kNN, feature properties, and hierarchical taxon distances.\n    *   **Methodology for ID-incorrect Samples**: Demonstrating the importance of explicitly defining and handling incorrectly classified in-distribution samples for both training and evaluating OOD detection models.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive evaluation was performed on three large-scale biodiversity datasets (500k+ images each): MSM top-level model, Norwegian vertebrates MSM sub-model, and iNaturalist 2018. Experiments covered both anomaly detection (OOD-far, e.g., ImageNet-Non-Organism) and novel class detection (OOD-near, OOD-mid, e.g., non-Norwegian vertebrates, Norwegian non-vertebrates).\n    *   **Key Performance Metrics**: True Positive Rate at 1% False Positive Rate (TPR@1%FPR) was the primary metric, emphasizing practical application where minimizing ID rejections is critical. Area Under the Receiver Operating Characteristic curve (AUROC) was also reported.\n    *   **Comparison Results**:\n        *   COOD consistently and significantly outperformed individual OOD measures, including state-of-the-art methods like `Max(linear-T-scaled)`, across all datasets and OOD scenarios.\n        *   For example, COOD improved the detection of ImageNet images (OOD) from 54.3% to 85.4% TPR@1%FPR for the iNaturalist 2018 dataset.\n        *   COOD demonstrated superior detection of `ID-incorrect-high` samples compared to individual measures (e.g., 22.1% vs 0% for `Max(linear)` on MSM top-level).\n        *   SHAP analysis revealed that different individual OOD measures contribute significantly to COOD's performance depending on the task, underscoring the value of their combination.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The COOD framework is supervised and requires external datasets for training, which is a slight disadvantage compared to purely unsupervised methods.\n    *   **Scope of Applicability**: While extensively validated in the biodiversity domain, the framework is designed to be easily extendable or adaptable to other classification tasks and media modalities.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{hogeweg2024tw3} significantly advances the state-of-the-art in OOD detection by demonstrating that a learned combination of diverse OOD measures can achieve substantially higher performance than any single measure, especially in challenging, large-scale, and hierarchically structured classification problems.\n    *   **Potential Impact on Future Research**:\n        *   Encourages the development of ensemble-based OOD detection systems rather than solely focusing on individual measures.\n        *   Highlights the importance of considering hierarchical class structures and the interplay between different prediction mechanisms (e.g., linear vs. kNN) in OOD measure design.\n        *   Emphasizes the critical role of carefully defining and handling incorrectly classified in-distribution data for robust OOD model training and evaluation, which can lead to more reliable real-world applications (e.g., rejecting unusable inputs, reliably finding novel species or diseases).",
      "intriguing_abstract": "The promise of deep learning in critical real-world applications hinges on its ability to reliably identify the unknown. Current out-of-distribution (OOD) detection methods often struggle with the nuanced distinction between anomalies and novel classes, particularly in complex, large-scale environments, with no single measure proving universally effective. We introduce **Combined OOD (COOD)**, a novel supervised framework that learns to synergistically integrate multiple diverse OOD measures into a single, highly robust score using a Random Forest classifier. COOD innovates by not only combining existing state-of-the-art techniques but also by introducing novel measures specifically designed for hierarchical classification, leveraging discrepancies between linear and kNN predictions, and explicitly addressing incorrectly classified in-distribution samples. Evaluated extensively on challenging, large-scale biodiversity datasets (500k+ images), COOD consistently and significantly outperforms individual OOD measures, including state-of-the-art methods, across anomaly and novel class detection scenarios. For instance, it dramatically improved detection of far-OOD images (e.g., from 54.3% to 85.4% TPR@1%FPR). This framework marks a substantial advancement in OOD detection, paving the way for more reliable and trustworthy deep learning models in open-world settings, from species identification to medical diagnostics.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "Novel class detection",
        "Combined OOD (COOD) framework",
        "Supervised ensemble learning",
        "Random Forest classifier",
        "Hierarchical class structures",
        "kNN-based OOD measures",
        "ID-incorrect sample handling",
        "Biodiversity datasets",
        "Large-scale classification",
        "Deep learning reliability",
        "Novel OOD measures",
        "TPR@1%FPR metric",
        "State-of-the-art advancement"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/db5059dea1ee639dfc7eba751183ce3564a4b593.pdf",
      "citation_key": "hogeweg2024tw3",
      "metadata": {
        "title": "COOD: Combined out-of-distribution detection using multiple measures for anomaly & novel class detection in large-scale hierarchical classification",
        "authors": [
          "L. Hogeweg",
          "Rajesh Gangireddy",
          "Django Brunink",
          "V. Kalkman",
          "Ludo Cornelissen",
          "Jacob W. Kamminga"
        ],
        "published_date": "2024",
        "abstract": "High-performing out-of-distribution (OOD) detection, both anomaly and novel class, is an important prerequisite for the practical use of classification models. In this paper we focus on the species recognition task in images, concerned with large databases, a large number of fine-grained hierarchical classes, severe class imbalance, and varying image quality. We propose a framework for combining individual OOD measures into one combined OOD (COOD) measure using a supervised model. The individual measures are several existing state-of-the-art measures and several novel OOD measures developed with novel class detection and hierarchical class structure in mind. COOD was extensively evaluated on three large-scale (500k+ images) biodiversity datasets in the context of anomaly and novel class detection. We show that COOD outperforms individual, including state-of-the-art, OOD measures by a large margin in terms of TPR@1%FPR in the majority of experiments, e.g., improving detecting ImageNet images (OOD) from 54.3% to 83.3% for the iNaturalist 2018 dataset. SHAP (feature contribution) analysis shows that different individual OOD measures are essential for various tasks, indicating that multiple OOD measures and combinations are needed to generalize. Additionally, we show that explicitly considering ID images that are incorrectly classified for the original (species) recognition task is important for constructing high-performing OOD detection methods and for practical applicability. The framework can easily be extended or adapted to other tasks and media modalities.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/db5059dea1ee639dfc7eba751183ce3564a4b593.pdf",
        "venue": "2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
        "citationCount": 6,
        "score": 6.0,
        "summary": "Here's a focused summary of the paper \\cite{hogeweg2024tw3} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of high-performing out-of-distribution (OOD) detection, encompassing both anomaly and novel class detection, particularly in complex, real-world classification scenarios.\n    *   **Importance & Challenge**: This problem is crucial for the practical reliability of deep learning models in open and changing environments (e.g., species recognition, medicine, autonomous driving). It's challenging due to:\n        *   The need to distinguish between \"unknown\" inputs and known classes, rather than misclassifying novel inputs with high confidence.\n        *   Limitations of existing OOD methods, which are often benchmarked on small datasets with far-OOD data and may perform inconsistently across different OOD scenarios.\n        *   The specific complexities of biodiversity datasets: large scale (500k+ images), fine-grained hierarchical classes, severe class imbalance, and varying image quality.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon and incorporates several existing state-of-the-art OOD measures (e.g., Max(linear-T-scaled), FRE, LDOF, kNN-based distances).\n    *   **Limitations of Previous Solutions**: The paper highlights that individual OOD measures often have specific strengths and weaknesses, leading to inconsistent performance across diverse OOD scenarios (near, mid, far OOD). This suggests that no single measure is universally optimal, motivating a combined approach.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{hogeweg2024tw3} proposes the **Combined OOD (COOD)** framework, which learns to combine multiple individual OOD measures into a single, more robust OOD score. A Random Forest classifier is used for this supervised combination, exploiting non-linear relationships between the measures.\n    *   **Novelty**:\n        *   **Supervised Combination Framework**: Instead of developing a single new OOD measure, COOD innovates by creating a learned ensemble that leverages the complementary strengths of diverse measures.\n        *   **Novel OOD Measures**: The paper introduces several new individual OOD measures specifically designed for novel class detection and to exploit hierarchical class structures, as well as discrepancies between linear and kNN predictions. Examples include `Max(linear+kNN)` (agreement between linear and kNN probabilities), `TD(linear, kNN)` (conceptual taxon distance between predictions), `EnWeDi(average)` (entropy-weighted average distance to NN), `Feature sum` (absence of feature responses), and `Avg. true probability of NN`.\n        *   **Explicit Handling of ID-incorrect Samples**: The framework explicitly categorizes and considers in-distribution (ID) images that are incorrectly classified by the base model (`ID-incorrect-high`, `ID-incorrect`). This is crucial for practical applicability and robust OOD model training and evaluation.\n\n*   **Key Technical Contributions**\n    *   **Novel Framework**: The COOD framework for combining multiple OOD measures using a supervised Random Forest classifier.\n    *   **Novel OOD Measures**: Introduction of several new individual OOD measures tailored for hierarchical classification and novel class detection, leveraging kNN, feature properties, and hierarchical taxon distances.\n    *   **Methodology for ID-incorrect Samples**: Demonstrating the importance of explicitly defining and handling incorrectly classified in-distribution samples for both training and evaluating OOD detection models.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive evaluation was performed on three large-scale biodiversity datasets (500k+ images each): MSM top-level model, Norwegian vertebrates MSM sub-model, and iNaturalist 2018. Experiments covered both anomaly detection (OOD-far, e.g., ImageNet-Non-Organism) and novel class detection (OOD-near, OOD-mid, e.g., non-Norwegian vertebrates, Norwegian non-vertebrates).\n    *   **Key Performance Metrics**: True Positive Rate at 1% False Positive Rate (TPR@1%FPR) was the primary metric, emphasizing practical application where minimizing ID rejections is critical. Area Under the Receiver Operating Characteristic curve (AUROC) was also reported.\n    *   **Comparison Results**:\n        *   COOD consistently and significantly outperformed individual OOD measures, including state-of-the-art methods like `Max(linear-T-scaled)`, across all datasets and OOD scenarios.\n        *   For example, COOD improved the detection of ImageNet images (OOD) from 54.3% to 85.4% TPR@1%FPR for the iNaturalist 2018 dataset.\n        *   COOD demonstrated superior detection of `ID-incorrect-high` samples compared to individual measures (e.g., 22.1% vs 0% for `Max(linear)` on MSM top-level).\n        *   SHAP analysis revealed that different individual OOD measures contribute significantly to COOD's performance depending on the task, underscoring the value of their combination.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The COOD framework is supervised and requires external datasets for training, which is a slight disadvantage compared to purely unsupervised methods.\n    *   **Scope of Applicability**: While extensively validated in the biodiversity domain, the framework is designed to be easily extendable or adaptable to other classification tasks and media modalities.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{hogeweg2024tw3} significantly advances the state-of-the-art in OOD detection by demonstrating that a learned combination of diverse OOD measures can achieve substantially higher performance than any single measure, especially in challenging, large-scale, and hierarchically structured classification problems.\n    *   **Potential Impact on Future Research**:\n        *   Encourages the development of ensemble-based OOD detection systems rather than solely focusing on individual measures.\n        *   Highlights the importance of considering hierarchical class structures and the interplay between different prediction mechanisms (e.g., linear vs. kNN) in OOD measure design.\n        *   Emphasizes the critical role of carefully defining and handling incorrectly classified in-distribution data for robust OOD model training and evaluation, which can lead to more reliable real-world applications (e.g., rejecting unusable inputs, reliably finding novel species or diseases).",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "Novel class detection",
          "Combined OOD (COOD) framework",
          "Supervised ensemble learning",
          "Random Forest classifier",
          "Hierarchical class structures",
          "kNN-based OOD measures",
          "ID-incorrect sample handling",
          "Biodiversity datasets",
          "Large-scale classification",
          "Deep learning reliability",
          "Novel OOD measures",
          "TPR@1%FPR metric",
          "State-of-the-art advancement"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **proposes a new framework/method:** the abstract explicitly states, \"we **propose a framework** for combining individual ood measures into one combined ood (cood) measure using a supervised model.\" and \"several **novel ood measures developed** with novel class detection and hierarchical class structure in mind.\" this directly aligns with the \"technical\" classification criterion: \"presents new methods, algorithms, or systems.\"\n2.  **addresses a technical problem:** the introduction discusses the unreliability of classification models in open environments and the need for ood detection, setting up the technical problem that their proposed solution aims to address.\n3.  **extensive evaluation:** while the paper includes extensive empirical evaluation (\"cood was extensively evaluated on three large-scale (500k+ images) biodiversity datasets,\" \"show that cood outperforms\"), this evaluation serves to demonstrate the effectiveness and validity of the *newly proposed technical framework and measures*. many technical papers include empirical evaluations as a core part of demonstrating their contribution.\n\nthe primary contribution is the development and proposal of the cood framework and novel ood measures. the empirical evaluation is a crucial component that supports the claims of the technical contribution.\n\ntherefore, the most fitting classification is **technical**."
      },
      "file_name": "db5059dea1ee639dfc7eba751183ce3564a4b593.pdf"
    },
    {
      "success": true,
      "doc_id": "2e8ea60f2a21b9fa05363714d8ca9fcb",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   The paper addresses the critical problem of detecting test-time distribution shift in machine learning models, which is essential for safe deployment \\cite{wang2024is1}.\n    *   Specifically, it aims to provide a consolidated view and rigorous empirical analysis of two largely independent sub-fields: Out-of-Distribution (OOD) detection and Open-Set Recognition (OSR) \\cite{wang2024is1}.\n    *   This problem is important because practical ML models frequently encounter samples substantially different from their training data. It's challenging due to the independent evolution of OOD and OSR, leading to a lack of cross-evaluation and a clear understanding of their underlying similarities and differences \\cite{wang2024is1}. Existing large-scale benchmarks often fail to adequately disentangle different types of distribution shifts (semantic vs. covariate) \\cite{wang2024is1}.\n\n*   **2. Related Work & Positioning**\n    *   This work relates to existing OOD detection methods (e.g., MSP, ODIN, Energy, GradNorm, Outlier Exposure (OE)) and OSR methods (e.g., OpenMax, ARPL, MLS) \\cite{wang2024is1}.\n    *   Previous solutions recognized the similarity between OOD and OSR but lacked comprehensive cross-benchmarking and a unified conceptual framework \\cite{wang2024is1}.\n    *   Prior works on disentangling covariate and semantic shifts were often on small-scale datasets (e.g., CIFAR) which are not well-suited for defining semantic shift, or focused on robustness rather than explicit cross-evaluation of state-of-the-art methods \\cite{wang2024is1}.\n\n*   **3. Technical Approach & Innovation**\n    *   The core technical approach is a rigorous empirical analysis and cross-evaluation of state-of-the-art OOD and OSR methods across various settings \\cite{wang2024is1}.\n    *   **Novelty/Innovation**:\n        *   **Systematic Cross-Evaluation**: The paper performs the first comprehensive cross-evaluation of methods developed for OOD detection and OSR on both standard and a newly proposed large-scale benchmark \\cite{wang2024is1}.\n        *   **Conceptual Framework for Shift Disentanglement**: It proposes a new conceptual framework to disentangle semantic shift (unseen categories) and covariate shift (distributional changes within known categories) \\cite{wang2024is1}.\n        *   **New Large-Scale Benchmark**: A novel large-scale benchmark setting is introduced to assess these disentangled shifts, utilizing ImageNet-1K as in-distribution, ImageNet-21K-P for semantic shift, and ImageNet-C/ImageNet-R for covariate shift \\cite{wang2024is1}.\n        *   **New Metric**: Introduces \"Outlier-Aware Accuracy\" (OAA) to reconcile robustness to covariate shift with the ability to detect its presence \\cite{wang2024is1}.\n        *   **Empirical Analysis of Scalability**: Investigates the performance of methods, particularly Outlier Exposure, when scaled to larger datasets, providing insights into their limitations \\cite{wang2024is1}.\n\n*   **4. Key Technical Contributions**\n    *   **System Design/Architectural Innovations**: The design of a novel, large-scale benchmark that systematically disentangles semantic and covariate shifts, addressing a gap in existing evaluation protocols \\cite{wang2024is1}.\n    *   **Theoretical Insights/Analysis**:\n        *   Identifies a strong correlation between the performance of methods for OOD detection and OSR on standard benchmarks \\cite{wang2024is1}.\n        *   Provides empirical evidence that magnitude-aware scoring rules (e.g., MLS, Energy) consistently show promise across tasks and scales due to the lower feature magnitude of 'unfamiliar' examples \\cite{wang2024is1}.\n        *   Explains the surprising struggle of Outlier Exposure (OE) at scale, attributing its strong performance on smaller benchmarks to distribution overlap between auxiliary OOD training data and OOD testing data \\cite{wang2024is1}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Cross-evaluation of state-of-the-art OOD (MSP, ODIN, Energy, GradNorm, ReAct, ASH, SHE, OE) and OSR (MLS, ARPL+CS) methods on standard small-scale benchmarks (CIFAR-10/100 for OOD, CIFAR+N, TinyImageNet for OSR) \\cite{wang2024is1}.\n        *   Re-evaluation of these methods on the proposed large-scale benchmark using ImageNet-1K (ID), ImageNet-21K-P (semantic shift), and ImageNet-C/ImageNet-R (covariate shift) \\cite{wang2024is1}.\n        *   Empirical analysis of feature representations to explain performance differences, including projecting features into 2D space to visualize magnitude differences \\cite{wang2024is1}.\n    *   **Key Performance Metrics & Results**:\n        *   **Metric**: Area Under the Receiver Operating Characteristic Curve (AUROC) is the primary evaluation metric \\cite{wang2024is1}.\n        *   **Standard Benchmarks**: MLS and Energy scoring (magnitude-aware) generally perform best. Outlier Exposure (OE) achieves near-saturating performance for OOD detection and strong OSR results \\cite{wang2024is1}.\n        *   **Large-Scale Benchmark**: Surprisingly, OE struggles to scale effectively. Magnitude-aware scoring rules, particularly MLS, consistently show promise \\cite{wang2024is1}.\n        *   **Analysis Findings**: The strong performance of OE on standard benchmarks is linked to the distribution overlap between its auxiliary OOD training data and the OOD testing data. It is challenging to find suitable auxiliary OOD data for large-scale datasets \\cite{wang2024is1}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations**: The paper highlights the limitation of Outlier Exposure's scalability due to the difficulty in finding auxiliary OOD data that reflects the full range of possible distribution shifts for large-scale datasets \\cite{wang2024is1}. It also notes that small-scale datasets are not ideal for defining semantic shift \\cite{wang2024is1}.\n    *   **Scope of Applicability**: The analysis primarily focuses on image classification tasks and deep learning models (ResNet18). While providing general insights, the specific findings are tied to the evaluated methods and datasets \\cite{wang2024is1}.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art**: This work provides a crucial consolidated view of OOD detection and OSR, bridging two previously disparate fields with rigorous empirical analysis \\cite{wang2024is1}. It introduces a more robust and disentangled large-scale benchmark, addressing a significant gap in current evaluation practices \\cite{wang2024is1}. It offers actionable takeaways by identifying consistently promising methods (magnitude-aware scoring rules) and revealing the scalability challenges of others (Outlier Exposure) \\cite{wang2024is1}.\n    *   **Potential Impact**: The findings will likely guide future research towards more unified approaches to distribution shift detection, improved benchmark design, and deeper investigation into the mechanisms behind successful methods, particularly regarding the role of feature magnitudes and the strategic selection of auxiliary data for large-scale OOD detection \\cite{wang2024is1}.",
      "intriguing_abstract": "Ensuring the safe and reliable deployment of machine learning models in real-world, dynamic environments demands robust detection of test-time distribution shifts. Despite their shared goal, Out-of-Distribution (OOD) detection and Open-Set Recognition (OSR) have evolved largely independently, hindering a unified understanding and comprehensive evaluation. This paper bridges this critical gap through the first comprehensive cross-evaluation of state-of-the-art OOD and OSR methods.\n\nWe introduce a novel conceptual framework to rigorously disentangle semantic and covariate shifts, alongside a new large-scale benchmark built on ImageNet-1K, ImageNet-21K-P, and ImageNet-C/R, and a new metric, Outlier-Aware Accuracy (OAA). Our empirical analysis, utilizing AUROC, reveals a strong correlation between OOD and OSR performance and surprisingly uncovers the scalability limitations of Outlier Exposure (OE) on large datasets, attributing its prior success to auxiliary data overlap. Crucially, we demonstrate that magnitude-aware scoring rules consistently excel across tasks and scales, driven by the distinct feature magnitudes of unfamiliar examples. These findings provide actionable insights for future research, guiding the development of more unified, robust, and safer AI systems capable of operating reliably in the face of diverse distribution shifts.",
      "keywords": [
        "Test-time distribution shift",
        "Out-of-Distribution (OOD) detection",
        "Open-Set Recognition (OSR)",
        "Semantic shift",
        "Covariate shift",
        "Systematic cross-evaluation",
        "Large-scale benchmark",
        "Conceptual framework for shift disentanglement",
        "Outlier-Aware Accuracy (OAA)",
        "Magnitude-aware scoring rules",
        "Outlier Exposure (OE) scalability",
        "Safe ML deployment",
        "Feature magnitude analysis"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/201817ff23481abd4ef48ce9e2ce71314f720ea7.pdf",
      "citation_key": "wang2024is1",
      "metadata": {
        "title": "Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks",
        "authors": [
          "Hongjun Wang",
          "S. Vaze",
          "Kai Han"
        ],
        "published_date": "2024",
        "abstract": "Detecting test-time distribution shift has emerged as a key capability for safely deployed machine learning models, with the question being tackled under various guises in recent years. In this paper, we aim to provide a consolidated view of the two largest sub-fields within the community: out-of-distribution (OOD) detection and open-set recognition (OSR). In particular, we aim to provide rigorous empirical analysis of different methods across settings and provide actionable takeaways for practitioners and researchers. Concretely, we make the following contributions: (i) We perform rigorous cross-evaluation between state-of-the-art methods in the OOD detection and OSR settings and identify a strong correlation between the performances of methods for them; (ii) We propose a new, large-scale benchmark setting which we suggest better disentangles the problem tackled by OOD detection and OSR, re-evaluating state-of-the-art OOD detection and OSR methods in this setting; (iii) We surprisingly find that the best performing method on standard benchmarks (Outlier Exposure) struggles when tested at scale, while scoring rules which are sensitive to the deep feature magnitude consistently show promise; and (iv) We conduct empirical analysis to explain these phenomena and highlight directions for future research. Code: https://github.com/Visual-AI/Dissect-OOD-OSR",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/201817ff23481abd4ef48ce9e2ce71314f720ea7.pdf",
        "venue": "International Journal of Computer Vision",
        "citationCount": 6,
        "score": 6.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   The paper addresses the critical problem of detecting test-time distribution shift in machine learning models, which is essential for safe deployment \\cite{wang2024is1}.\n    *   Specifically, it aims to provide a consolidated view and rigorous empirical analysis of two largely independent sub-fields: Out-of-Distribution (OOD) detection and Open-Set Recognition (OSR) \\cite{wang2024is1}.\n    *   This problem is important because practical ML models frequently encounter samples substantially different from their training data. It's challenging due to the independent evolution of OOD and OSR, leading to a lack of cross-evaluation and a clear understanding of their underlying similarities and differences \\cite{wang2024is1}. Existing large-scale benchmarks often fail to adequately disentangle different types of distribution shifts (semantic vs. covariate) \\cite{wang2024is1}.\n\n*   **2. Related Work & Positioning**\n    *   This work relates to existing OOD detection methods (e.g., MSP, ODIN, Energy, GradNorm, Outlier Exposure (OE)) and OSR methods (e.g., OpenMax, ARPL, MLS) \\cite{wang2024is1}.\n    *   Previous solutions recognized the similarity between OOD and OSR but lacked comprehensive cross-benchmarking and a unified conceptual framework \\cite{wang2024is1}.\n    *   Prior works on disentangling covariate and semantic shifts were often on small-scale datasets (e.g., CIFAR) which are not well-suited for defining semantic shift, or focused on robustness rather than explicit cross-evaluation of state-of-the-art methods \\cite{wang2024is1}.\n\n*   **3. Technical Approach & Innovation**\n    *   The core technical approach is a rigorous empirical analysis and cross-evaluation of state-of-the-art OOD and OSR methods across various settings \\cite{wang2024is1}.\n    *   **Novelty/Innovation**:\n        *   **Systematic Cross-Evaluation**: The paper performs the first comprehensive cross-evaluation of methods developed for OOD detection and OSR on both standard and a newly proposed large-scale benchmark \\cite{wang2024is1}.\n        *   **Conceptual Framework for Shift Disentanglement**: It proposes a new conceptual framework to disentangle semantic shift (unseen categories) and covariate shift (distributional changes within known categories) \\cite{wang2024is1}.\n        *   **New Large-Scale Benchmark**: A novel large-scale benchmark setting is introduced to assess these disentangled shifts, utilizing ImageNet-1K as in-distribution, ImageNet-21K-P for semantic shift, and ImageNet-C/ImageNet-R for covariate shift \\cite{wang2024is1}.\n        *   **New Metric**: Introduces \"Outlier-Aware Accuracy\" (OAA) to reconcile robustness to covariate shift with the ability to detect its presence \\cite{wang2024is1}.\n        *   **Empirical Analysis of Scalability**: Investigates the performance of methods, particularly Outlier Exposure, when scaled to larger datasets, providing insights into their limitations \\cite{wang2024is1}.\n\n*   **4. Key Technical Contributions**\n    *   **System Design/Architectural Innovations**: The design of a novel, large-scale benchmark that systematically disentangles semantic and covariate shifts, addressing a gap in existing evaluation protocols \\cite{wang2024is1}.\n    *   **Theoretical Insights/Analysis**:\n        *   Identifies a strong correlation between the performance of methods for OOD detection and OSR on standard benchmarks \\cite{wang2024is1}.\n        *   Provides empirical evidence that magnitude-aware scoring rules (e.g., MLS, Energy) consistently show promise across tasks and scales due to the lower feature magnitude of 'unfamiliar' examples \\cite{wang2024is1}.\n        *   Explains the surprising struggle of Outlier Exposure (OE) at scale, attributing its strong performance on smaller benchmarks to distribution overlap between auxiliary OOD training data and OOD testing data \\cite{wang2024is1}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Cross-evaluation of state-of-the-art OOD (MSP, ODIN, Energy, GradNorm, ReAct, ASH, SHE, OE) and OSR (MLS, ARPL+CS) methods on standard small-scale benchmarks (CIFAR-10/100 for OOD, CIFAR+N, TinyImageNet for OSR) \\cite{wang2024is1}.\n        *   Re-evaluation of these methods on the proposed large-scale benchmark using ImageNet-1K (ID), ImageNet-21K-P (semantic shift), and ImageNet-C/ImageNet-R (covariate shift) \\cite{wang2024is1}.\n        *   Empirical analysis of feature representations to explain performance differences, including projecting features into 2D space to visualize magnitude differences \\cite{wang2024is1}.\n    *   **Key Performance Metrics & Results**:\n        *   **Metric**: Area Under the Receiver Operating Characteristic Curve (AUROC) is the primary evaluation metric \\cite{wang2024is1}.\n        *   **Standard Benchmarks**: MLS and Energy scoring (magnitude-aware) generally perform best. Outlier Exposure (OE) achieves near-saturating performance for OOD detection and strong OSR results \\cite{wang2024is1}.\n        *   **Large-Scale Benchmark**: Surprisingly, OE struggles to scale effectively. Magnitude-aware scoring rules, particularly MLS, consistently show promise \\cite{wang2024is1}.\n        *   **Analysis Findings**: The strong performance of OE on standard benchmarks is linked to the distribution overlap between its auxiliary OOD training data and the OOD testing data. It is challenging to find suitable auxiliary OOD data for large-scale datasets \\cite{wang2024is1}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations**: The paper highlights the limitation of Outlier Exposure's scalability due to the difficulty in finding auxiliary OOD data that reflects the full range of possible distribution shifts for large-scale datasets \\cite{wang2024is1}. It also notes that small-scale datasets are not ideal for defining semantic shift \\cite{wang2024is1}.\n    *   **Scope of Applicability**: The analysis primarily focuses on image classification tasks and deep learning models (ResNet18). While providing general insights, the specific findings are tied to the evaluated methods and datasets \\cite{wang2024is1}.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art**: This work provides a crucial consolidated view of OOD detection and OSR, bridging two previously disparate fields with rigorous empirical analysis \\cite{wang2024is1}. It introduces a more robust and disentangled large-scale benchmark, addressing a significant gap in current evaluation practices \\cite{wang2024is1}. It offers actionable takeaways by identifying consistently promising methods (magnitude-aware scoring rules) and revealing the scalability challenges of others (Outlier Exposure) \\cite{wang2024is1}.\n    *   **Potential Impact**: The findings will likely guide future research towards more unified approaches to distribution shift detection, improved benchmark design, and deeper investigation into the mechanisms behind successful methods, particularly regarding the role of feature magnitudes and the strategic selection of auxiliary data for large-scale OOD detection \\cite{wang2024is1}.",
        "keywords": [
          "Test-time distribution shift",
          "Out-of-Distribution (OOD) detection",
          "Open-Set Recognition (OSR)",
          "Semantic shift",
          "Covariate shift",
          "Systematic cross-evaluation",
          "Large-scale benchmark",
          "Conceptual framework for shift disentanglement",
          "Outlier-Aware Accuracy (OAA)",
          "Magnitude-aware scoring rules",
          "Outlier Exposure (OE) scalability",
          "Safe ML deployment",
          "Feature magnitude analysis"
        ],
        "paper_type": "the paper type is **empirical**.\n\nhere's why:\n\n*   **abstract mentions:**\n    *   \"we aim to provide **rigorous empirical analysis** of different methods across settings...\"\n    *   \"we **perform rigorous cross-evaluation** between state-of-the-art methods...\"\n    *   \"we **propose a new, large-scale benchmark setting**... **re-evaluating** state-of-the-art ood detection and osr methods in this setting;\"\n    *   \"we surprisingly **find** that the best performing method... struggles when **tested at scale**...\"\n    *   \"we **conduct empirical analysis** to explain these phenomena...\"\n    *   keywords like \"study\", \"experiment\", \"data\", \"findings\" are strongly implied by \"empirical analysis\", \"cross-evaluation\", \"benchmark setting\", and \"find\".\n\n*   **introduction discusses:**\n    *   \"in this **study**, we **investigate** the detection of distribution shifts, with a focus on **exploring and analyzing** ood detection and osr methods and **benchmarks**.\"\n    *   \"...there has been little **benchmarking** to understand the underlying similarities and differences between them.\"\n    *   this aligns with \"research questions, methodology\" (investigating, exploring, analyzing methods and benchmarks).\n\nthe core of the paper, as described, is to conduct experiments and analysis using data (benchmarks) to evaluate and compare existing methods, leading to new findings and explanations."
      },
      "file_name": "201817ff23481abd4ef48ce9e2ce71314f720ea7.pdf"
    },
    {
      "success": true,
      "doc_id": "8453e6303795ef1d3eb80cd44ecab89e",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses two main problems:\n        *   The fundamental challenge of Out-of-Distribution (OOD) detection, which aims to identify test samples that fall outside the training category space, crucial for building reliable and safe machine learning systems \\cite{lu2024j0n}.\n        *   The lack of a comprehensive, up-to-date, and *task-oriented* survey of recent advances in OOD detection, especially concerning new paradigms like test-time adaptation, multi-modal data sources, and methods based on large pre-trained models \\cite{lu2024j0n}.\n    *   **Importance and Challenge**: OOD detection is vital for safety-critical applications (e.g., medical diagnosis, autonomous driving) where misjudging unknown inputs can lead to severe consequences \\cite{lu2024j0n}. The field is rapidly evolving, with many recent works focusing on non-traditional scenarios. Existing surveys, primarily method-centric, fail to provide an in-depth exploration from a task-scenario viewpoint, making it challenging for researchers and practitioners to navigate the diverse landscape and identify appropriate solutions \\cite{lu2024j0n}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous surveys on OOD detection primarily focus on method taxonomy, categorizing approaches based on their underlying techniques (e.g., classification-based, density-based) \\cite{lu2024j0n}. The paper also distinguishes OOD detection from related concepts like Anomaly Detection, Novelty Detection, Open Set Recognition, and Zero-shot Learning, clarifying its specific scope \\cite{lu2024j0n}.\n    *   **Limitations of Previous Solutions**: The main limitation of prior surveys is their \"methodological perspective,\" which \"lack[s] an in-depth exploration from the viewpoint of task scenarios\" \\cite{lu2024j0n}. This oversight means they do not adequately cover emerging paradigms such as test-time learning, multi-modal data, and the significant advancements in OOD detection leveraging large pre-trained models \\cite{lu2024j0n}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The core \"method\" of this paper is the introduction of a novel, comprehensive *task-oriented taxonomy* for surveying recent advances in OOD detection \\cite{lu2024j0n}. This taxonomy organizes the field based on practical considerations and user access to the model.\n    *   **Novelty/Difference**: The approach is novel because it is the \"first time\" OOD detection advances are reviewed from a \"task-oriented perspective\" \\cite{lu2024j0n}. The proposed classification scheme includes:\n        *   **Training-driven methods**: Where the OOD detection method is allowed to modify or retrain the model \\cite{lu2024j0n}.\n        *   **Training-agnostic methods**: Where OOD detection is performed on a well-trained model without modification or retraining \\cite{lu2024j0n}.\n        *   **Large pre-trained model-based OOD detection**: A separate, important category acknowledging the rapid development and impact of foundation models \\cite{lu2024j0n}.\n        This framework provides a more practical and scenario-driven understanding compared to purely methodological classifications.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**: The primary contribution is the *novel task-oriented taxonomy* itself, which serves as a conceptual framework for organizing and understanding the diverse landscape of OOD detection methods \\cite{lu2024j0n}. This includes sub-categorizations within training-driven (e.g., reconstruction-based, OOD synthesis) and training-agnostic (e.g., post-hoc, test-time adaptive) approaches, as well as distinctions for large pre-trained models (zero-shot, few-shot, full-shot) \\cite{lu2024j0n}.\n    *   **System Design or Architectural Innovations**: While the paper does not propose a new system architecture, its taxonomy implicitly highlights architectural considerations by categorizing methods based on their interaction with the model (e.g., modifying training, post-hoc analysis, leveraging pre-trained features) \\cite{lu2024j0n}.\n    *   **Theoretical Insights or Analysis**: The paper provides a structured analysis of the OOD detection problem, clarifying its distinctions from related fields and offering a new lens through which to view and categorize existing and future research \\cite{lu2024j0n}. It also discusses evaluation scenarios, applications, and future research directions \\cite{lu2024j0n}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: As a survey paper, \\cite{lu2024j0n} does *not* present its own experimental validation of novel algorithms or systems. Instead, it synthesizes and categorizes the experimental findings of the numerous OOD detection papers it reviews.\n    *   **Key Performance Metrics and Comparison Results**: The paper dedicates Section 6 to discussing the common evaluation metrics (e.g., AUROC, AUPRO, FPR@95TPR, AUPR-In, AUPR-Out) and experimental protocols (e.g., datasets, OOD settings) used by the OOD detection community to validate the performance of various methods \\cite{lu2024j0n}. It summarizes the types of comparisons made in the literature (e.g., comparing reconstruction errors, confidence scores, or feature distances).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper's primary limitation is inherent to its nature as a survey: it provides a snapshot of a rapidly evolving field, meaning new methods and paradigms will continue to emerge beyond its publication. While comprehensive, the \"task-oriented\" perspective might group methods that are methodologically diverse but share a common task context, potentially obscuring some technical nuances.\n    *   **Scope of Applicability**: The survey's scope is specifically focused on Out-of-Distribution Detection, clearly distinguishing it from related but distinct problems like Anomaly Detection, Novelty Detection, and Open Set Recognition \\cite{lu2024j0n}. It emphasizes recent advances, particularly those involving test-time adaptation and large pre-trained models, making it highly relevant for contemporary machine learning research.\n\n7.  **Technical Significance**\n    *   **Advancement of Technical State-of-the-Art**: This survey significantly advances the technical understanding and organization of the OOD detection field by introducing a novel \"task-oriented taxonomy\" \\cite{lu2024j0n}. This framework provides a clearer, more practical lens through which to analyze and categorize existing methods, especially those addressing non-traditional scenarios and leveraging large pre-trained models. It moves beyond purely methodological classifications to consider the practical context of OOD detection.\n    *   **Potential Impact on Future Research**: The new taxonomy is expected to \"benefit the proposal of new methods and the expansion of more practical scenarios\" \\cite{lu2024j0n}. By highlighting underexplored areas and providing a structured overview, it can guide future research directions, help practitioners select appropriate methods for specific tasks, and foster innovation in building more reliable and trustworthy machine learning systems.",
      "intriguing_abstract": "The reliability of machine learning systems hinges on their ability to detect Out-of-Distribution (OOD) inputs, a critical challenge for safety-critical applications like autonomous driving and medical diagnosis. While the field of OOD detection is rapidly advancing, existing surveys primarily offer method-centric taxonomies, failing to capture the nuances of emerging paradigms such as test-time adaptation, multi-modal data, and the transformative impact of large pre-trained models.\n\nWe introduce the first comprehensive, task-oriented taxonomy for OOD detection, offering a novel lens to understand and navigate this complex landscape. Our novel framework meticulously classifies methods based on practical considerations, distinguishing between training-driven, training-agnostic, and a dedicated category for approaches leveraging large pre-trained models. This provides an unparalleled, scenario-driven overview, clarifying distinctions from related fields and synthesizing recent advancements. This practical roadmap empowers researchers to identify underexplored areas and guides practitioners in selecting optimal solutions, ultimately fostering the development of more robust, trustworthy, and safe AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "task-oriented taxonomy",
        "machine learning reliability",
        "large pre-trained models",
        "test-time adaptation",
        "training-driven methods",
        "training-agnostic methods",
        "survey paper",
        "safety-critical applications",
        "evaluation metrics",
        "conceptual framework",
        "future research directions",
        "multi-modal data"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/a58000542be3b6c6f9d275c31c64ec2b55cbf9f7.pdf",
      "citation_key": "lu2024j0n",
      "metadata": {
        "title": "Out-of-Distribution Detection: A Task-Oriented Survey of Recent Advances",
        "authors": [
          "Shuo Lu",
          "Yingsheng Wang",
          "Lijun Sheng",
          "Lingxiao He",
          "Aihua Zheng",
          "Jian Liang"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection aims to detect test samples outside the training category space, which is an essential component in building reliable machine learning systems. Existing reviews on OOD detection primarily focus on method taxonomy, surveying the field by categorizing various approaches. However, many recent works concentrate on non-traditional OOD detection scenarios, such as test-time adaptation, multi-modal data sources and other novel contexts. In this survey, we uniquely review recent advances in OOD detection from the task-oriented perspective for the first time. According to the user's access to the model, that is, whether the OOD detection method is allowed to modify or retrain the model, we classify the methods as training-driven or training-agnostic. Besides, considering the rapid development of pre-trained models, large pre-trained model-based OOD detection is also regarded as an important category and discussed separately. Furthermore, we provide a discussion of the evaluation scenarios, a variety of applications, and several future research directions. We believe this survey with new taxonomy will benefit the proposal of new methods and the expansion of more practical scenarios. A curated list of related papers is provided in the Github repository: https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/a58000542be3b6c6f9d275c31c64ec2b55cbf9f7.pdf",
        "venue": "",
        "citationCount": 6,
        "score": 6.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses two main problems:\n        *   The fundamental challenge of Out-of-Distribution (OOD) detection, which aims to identify test samples that fall outside the training category space, crucial for building reliable and safe machine learning systems \\cite{lu2024j0n}.\n        *   The lack of a comprehensive, up-to-date, and *task-oriented* survey of recent advances in OOD detection, especially concerning new paradigms like test-time adaptation, multi-modal data sources, and methods based on large pre-trained models \\cite{lu2024j0n}.\n    *   **Importance and Challenge**: OOD detection is vital for safety-critical applications (e.g., medical diagnosis, autonomous driving) where misjudging unknown inputs can lead to severe consequences \\cite{lu2024j0n}. The field is rapidly evolving, with many recent works focusing on non-traditional scenarios. Existing surveys, primarily method-centric, fail to provide an in-depth exploration from a task-scenario viewpoint, making it challenging for researchers and practitioners to navigate the diverse landscape and identify appropriate solutions \\cite{lu2024j0n}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous surveys on OOD detection primarily focus on method taxonomy, categorizing approaches based on their underlying techniques (e.g., classification-based, density-based) \\cite{lu2024j0n}. The paper also distinguishes OOD detection from related concepts like Anomaly Detection, Novelty Detection, Open Set Recognition, and Zero-shot Learning, clarifying its specific scope \\cite{lu2024j0n}.\n    *   **Limitations of Previous Solutions**: The main limitation of prior surveys is their \"methodological perspective,\" which \"lack[s] an in-depth exploration from the viewpoint of task scenarios\" \\cite{lu2024j0n}. This oversight means they do not adequately cover emerging paradigms such as test-time learning, multi-modal data, and the significant advancements in OOD detection leveraging large pre-trained models \\cite{lu2024j0n}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The core \"method\" of this paper is the introduction of a novel, comprehensive *task-oriented taxonomy* for surveying recent advances in OOD detection \\cite{lu2024j0n}. This taxonomy organizes the field based on practical considerations and user access to the model.\n    *   **Novelty/Difference**: The approach is novel because it is the \"first time\" OOD detection advances are reviewed from a \"task-oriented perspective\" \\cite{lu2024j0n}. The proposed classification scheme includes:\n        *   **Training-driven methods**: Where the OOD detection method is allowed to modify or retrain the model \\cite{lu2024j0n}.\n        *   **Training-agnostic methods**: Where OOD detection is performed on a well-trained model without modification or retraining \\cite{lu2024j0n}.\n        *   **Large pre-trained model-based OOD detection**: A separate, important category acknowledging the rapid development and impact of foundation models \\cite{lu2024j0n}.\n        This framework provides a more practical and scenario-driven understanding compared to purely methodological classifications.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**: The primary contribution is the *novel task-oriented taxonomy* itself, which serves as a conceptual framework for organizing and understanding the diverse landscape of OOD detection methods \\cite{lu2024j0n}. This includes sub-categorizations within training-driven (e.g., reconstruction-based, OOD synthesis) and training-agnostic (e.g., post-hoc, test-time adaptive) approaches, as well as distinctions for large pre-trained models (zero-shot, few-shot, full-shot) \\cite{lu2024j0n}.\n    *   **System Design or Architectural Innovations**: While the paper does not propose a new system architecture, its taxonomy implicitly highlights architectural considerations by categorizing methods based on their interaction with the model (e.g., modifying training, post-hoc analysis, leveraging pre-trained features) \\cite{lu2024j0n}.\n    *   **Theoretical Insights or Analysis**: The paper provides a structured analysis of the OOD detection problem, clarifying its distinctions from related fields and offering a new lens through which to view and categorize existing and future research \\cite{lu2024j0n}. It also discusses evaluation scenarios, applications, and future research directions \\cite{lu2024j0n}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: As a survey paper, \\cite{lu2024j0n} does *not* present its own experimental validation of novel algorithms or systems. Instead, it synthesizes and categorizes the experimental findings of the numerous OOD detection papers it reviews.\n    *   **Key Performance Metrics and Comparison Results**: The paper dedicates Section 6 to discussing the common evaluation metrics (e.g., AUROC, AUPRO, FPR@95TPR, AUPR-In, AUPR-Out) and experimental protocols (e.g., datasets, OOD settings) used by the OOD detection community to validate the performance of various methods \\cite{lu2024j0n}. It summarizes the types of comparisons made in the literature (e.g., comparing reconstruction errors, confidence scores, or feature distances).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper's primary limitation is inherent to its nature as a survey: it provides a snapshot of a rapidly evolving field, meaning new methods and paradigms will continue to emerge beyond its publication. While comprehensive, the \"task-oriented\" perspective might group methods that are methodologically diverse but share a common task context, potentially obscuring some technical nuances.\n    *   **Scope of Applicability**: The survey's scope is specifically focused on Out-of-Distribution Detection, clearly distinguishing it from related but distinct problems like Anomaly Detection, Novelty Detection, and Open Set Recognition \\cite{lu2024j0n}. It emphasizes recent advances, particularly those involving test-time adaptation and large pre-trained models, making it highly relevant for contemporary machine learning research.\n\n7.  **Technical Significance**\n    *   **Advancement of Technical State-of-the-Art**: This survey significantly advances the technical understanding and organization of the OOD detection field by introducing a novel \"task-oriented taxonomy\" \\cite{lu2024j0n}. This framework provides a clearer, more practical lens through which to analyze and categorize existing methods, especially those addressing non-traditional scenarios and leveraging large pre-trained models. It moves beyond purely methodological classifications to consider the practical context of OOD detection.\n    *   **Potential Impact on Future Research**: The new taxonomy is expected to \"benefit the proposal of new methods and the expansion of more practical scenarios\" \\cite{lu2024j0n}. By highlighting underexplored areas and providing a structured overview, it can guide future research directions, help practitioners select appropriate methods for specific tasks, and foster innovation in building more reliable and trustworthy machine learning systems.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "task-oriented taxonomy",
          "machine learning reliability",
          "large pre-trained models",
          "test-time adaptation",
          "training-driven methods",
          "training-agnostic methods",
          "survey paper",
          "safety-critical applications",
          "evaluation metrics",
          "conceptual framework",
          "future research directions",
          "multi-modal data"
        ],
        "paper_type": "the paper type is **survey**.\n\n**reasoning:**\n\n1.  **title:** the title explicitly includes \"survey\" (\"out-of-distribution detection: a task-oriented survey of recent advances\").\n2.  **abstract:**\n    *   it states, \"notably, several previous efforts have been dedicated to surveying and summarizing ood detection in recent years.\"\n    *   it then proceeds to compare itself to numerous other \"survey papers on ood detection\" in table 1 and the surrounding text (e.g., \"salehi et al. [5]offer a review...\", \"yang et al. [6]propose a unified framework to discuss ood detection...\", \"concurrent with our work, miyai et al. [10] discuss clip-based methods...\", \"cui and wang [7]conduct a survey...\").\n    *   it highlights its unique contribution within the survey landscape: \"however, previous works focus too much on the discussion from the perspective of methods and lack an in-depth exploration from the viewpoint of task scenarios. establishing a clear taxonomy of task scenarios can enhance a comprehensive understanding of the field and assist practitioners in selecting the appropriate method.\" this indicates its goal is to organize and classify existing literature in a new way.\n    *   it mentions providing \"a more comprehensive coverage of recent advances.\"\n\nthese points directly align with the criteria for a **survey** paper: \"reviews existing literature comprehensively\" and \"introduction discusses: literature organization, classification schemes.\""
      },
      "file_name": "a58000542be3b6c6f9d275c31c64ec2b55cbf9f7.pdf"
    },
    {
      "success": true,
      "doc_id": "208f645334734482759d2e68d0abb1c5",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing deep learning models for Wireless Capsule Endoscopy (WCE) diagnosis operate under a \"closed-world\" assumption, struggling to identify and classify Out-of-Distribution (OOD) data. This OOD data includes undefined disease categories or anatomical landmarks (e.g., Ampulla of Vater, Ileocecal valve, Pylorus) that are distinct from the predefined In-Distribution (ID) disease categories \\cite{tan2024oj5}.\n    *   **Importance and Challenge**: This problem is critical because misclassifying OOD data can lead to inaccurate diagnoses, reduced reliability, and increased burden on healthcare professionals. Training models solely on ID data fails to generalize effectively to real-world WCE scenarios where OOD instances are common. The challenge lies in developing robust models that can accurately distinguish between known (ID) and unknown (OOD) conditions while maintaining high diagnostic accuracy for ID data \\cite{tan2024oj5}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon and extends existing OOD detection strategies, including training-based (e.g., ConfBranch) and post-hoc methods (e.g., MSP, ODIN, MDS, ViM) \\cite{tan2024oj5}. It specifically leverages and refines mixup training and Virtual-logit Matching (ViM).\n    *   **Limitations of Previous Solutions**:\n        *   Many existing OOD detection methods struggle with effectively discerning ID and OOD samples, especially in complex medical imaging contexts like WCE.\n        *   Mixup training, while improving OOD handling, often leads to decreased calibration performance, impacting the accurate estimation of uncertainty \\cite{tan2024oj5}.\n        *   Conventional model calibration techniques (e.g., temperature scaling, label smoothing) often fail to effectively handle long-tailed data distributions prevalent in WCE, where a few categories have high frequency, leading to overconfident predictions for these classes and poor discrimination of low-frequency or OOD samples \\cite{tan2024oj5}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes the Endoscopy Out-of-Distribution (EndoOOD) framework, which integrates three key components:\n        1.  **Uncertainty-Aware Mixup Training**: Decouples mixup's data transformation and random perturbation steps to mitigate calibration degradation caused by standard mixup. It recovers raw sample output predictions and trains models by fitting decoupled outputs to original one-hot labels, avoiding confidence penalties \\cite{tan2024oj5}.\n        2.  **Long-Tailed ID Data Calibration**: Addresses overconfident probabilities for high-frequency classes in long-tailed WCE datasets. It incorporates category quantity into both Temperature Scaling (TS) and Label Smoothing (LS) by reweighting optimal temperature and penalizing high-frequency classes more heavily, respectively \\cite{tan2024oj5}.\n        3.  **Calibrated Post-hoc Inference (Virtual-logit Matching - ViM)**: Utilizes ViM to accurately distinguish between OOD and ID data during inference. ViM computes OOD-ness by integrating the norm of feature residual against a principal subspace and the original logits, minimizing information loss \\cite{tan2024oj5}.\n    *   **Novelty/Difference**: The novelty lies in the synergistic integration of these three components, specifically:\n        *   Addressing the *calibration degradation* issue of mixup training through an uncertainty-aware decoupling strategy.\n        *   Introducing *category quantity-aware* calibration techniques (modified TS and LS) to specifically tackle the challenges posed by long-tailed data distributions in medical imaging.\n        *   Combining these training-time innovations with a robust post-hoc inference method (ViM) to create a comprehensive, uncertainty-aware framework for OOD detection in WCE \\cite{tan2024oj5}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **Uncertainty-aware mixup training strategy**: A decoupled mixup approach that improves OOD detection while preserving uncertainty calibration, crucial for reliable medical diagnosis \\cite{tan2024oj5}.\n        *   **Long-tailed ID data calibration technique**: Modifies temperature scaling and label smoothing by incorporating category quantity, effectively mitigating overconfidence in high-frequency classes and improving discrimination for low-frequency and OOD samples \\cite{tan2024oj5}.\n    *   **System Design/Architectural Innovations**: The EndoOOD framework itself represents an integrated system design that combines training-time calibration and augmentation with a post-hoc inference mechanism (ViM) for robust OOD detection in WCE \\cite{tan2024oj5}.\n    *   **Theoretical Insights/Analysis**: The paper implicitly provides insights into the interplay between data augmentation (mixup), uncertainty estimation, and class imbalance (long-tailed data) in the context of OOD detection for medical images, demonstrating how targeted calibration can resolve common pitfalls \\cite{tan2024oj5}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive quantitative evaluations were performed against 12 state-of-the-art (SOTA) OOD detection methods \\cite{tan2024oj5}. An ablation study was also conducted to assess the contribution of each proposed component.\n    *   **Datasets**:\n        *   **Kvasir-Capsule**: Used for ID (11 disease classes) and Near-OOD (3 anatomical classes) data \\cite{tan2024oj5}.\n        *   **CIFAR-10**: Used as Far-OOD data to evaluate performance on significantly different image distributions \\cite{tan2024oj5}.\n    *   **Key Performance Metrics**: FPR@95 (False Positive Rate at 95% True Positive Rate), AUROC (Area Under the Receiver Operating Characteristic curve), AUPR In (Area Under the Precision-Recall curve for In-distribution), AUPR Out (Area Under the Precision-Recall curve for Out-of-distribution), and Accuracy (for ID data) \\cite{tan2024oj5}.\n    *   **Comparison Results**:\n        *   The EndoOOD framework demonstrated superior performance across all OOD metrics for both Near-OOD (Kvasir-Capsule outliers) and Far-OOD (CIFAR-10) data, surpassing all 12 baseline models \\cite{tan2024oj5}.\n        *   For Near-OOD, it achieved FPR@95 of 32.08, AUROC of 93.06, AUPR In of 90.92, and AUPR Out of 93.75 \\cite{tan2024oj5}.\n        *   For Far-OOD (CIFAR-10), it achieved error-free performance (FPR@95 of 0.00, AUROC of 100.00, AUPR In of 100.00, AUPR Out of 99.98) \\cite{tan2024oj5}.\n        *   Crucially, the accuracy for known (ID) classes also increased by over 1% (to 94.02%) compared to baselines, indicating improved overall diagnostic capability \\cite{tan2024oj5}.\n        *   **Ablation Study**: Confirmed that both uncertainty-aware mixup training and long-tailed ID data calibration positively contribute to the framework's superior performance, as removing either component led to significant degradation \\cite{tan2024oj5}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper does not explicitly detail specific technical limitations of the proposed method itself, beyond the general challenges it aims to solve. It assumes the availability of labeled ID data for training and relies on the effectiveness of ViM for post-hoc inference.\n    *   **Scope of Applicability**: The framework is specifically designed and validated for WCE diagnosis, focusing on gastrointestinal disease screening. While demonstrated on CIFAR-10 for Far-OOD, its primary application context is medical imaging. Future research is suggested to explore further advancements and applications in real-world WCE scenarios \\cite{tan2024oj5}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The EndoOOD framework significantly advances the technical state-of-the-art in OOD detection for medical imaging, particularly in WCE, by providing a robust and uncertainty-aware solution that outperforms existing SOTA methods \\cite{tan2024oj5}. It addresses critical issues of uncertainty calibration in mixup training and handling long-tailed data distributions, which are common in real-world medical datasets.\n    *   **Potential Impact**: This work has the potential to greatly enhance the reliability and accuracy of automated WCE diagnosis, leading to improved clinical decision-making and alleviating the burden on healthcare professionals. By enabling models to reliably identify and reject OOD inputs, it makes deep learning models more trustworthy and applicable in sensitive medical contexts \\cite{tan2024oj5}.",
      "intriguing_abstract": "Deep learning models for Wireless Capsule Endoscopy (WCE) diagnosis are critically hampered by their \"closed-world\" assumption, leading to dangerous misclassifications of Out-of-Distribution (OOD) dataâ€”unknown diseases or critical anatomical landmarks. This fundamental challenge undermines diagnostic reliability and burdens healthcare professionals. We introduce EndoOOD, a novel framework designed to robustly detect OOD samples while maintaining high In-Distribution (ID) accuracy.\n\nEndoOOD innovates through three synergistically integrated components: an uncertainty-aware mixup training strategy that decouples data transformation to prevent calibration degradation; a long-tailed ID data calibration technique that incorporates category quantity into Temperature Scaling and Label Smoothing to mitigate overconfidence in imbalanced datasets; and a calibrated Virtual-logit Matching (ViM) for precise post-hoc OOD inference. Extensive experiments on Kvasir-Capsule and CIFAR-10 datasets demonstrate EndoOOD's superior performance, outperforming 12 state-of-the-art methods across all OOD metrics and boosting ID diagnostic accuracy. This framework significantly enhances the trustworthiness and clinical applicability of AI in WCE, paving the way for more reliable automated medical diagnosis.",
      "keywords": [
        "Wireless Capsule Endoscopy (WCE) diagnosis",
        "Out-of-Distribution (OOD) detection",
        "EndoOOD framework",
        "Uncertainty-aware mixup training",
        "Long-tailed data calibration",
        "Virtual-logit Matching (ViM)",
        "Model calibration",
        "Medical imaging",
        "Superior OOD detection performance",
        "Improved ID classification accuracy",
        "Robust deep learning models",
        "Gastrointestinal disease screening",
        "Closed-world assumption limitation"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/63cc6260b838f2cc559715a9f68360edc743f50b.pdf",
      "citation_key": "tan2024oj5",
      "metadata": {
        "title": "Endoood: Uncertainty-Aware Out-of-Distribution Detection in Capsule Endoscopy Diagnosis",
        "authors": [
          "Qiaozhi Tan",
          "Long Bai",
          "Guan-Feng Wang",
          "Mobarak Islam Hoque",
          "Hongliang Ren"
        ],
        "published_date": "2024",
        "abstract": "Wireless capsule endoscopy (WCE) is a non-invasive diagnostic procedure that enables visualization of the gastrointestinal (GI) tract. Deep learning-based methods have shown effectiveness in disease screening using WCE data, alleviating the burden on healthcare professionals. However, existing capsule endoscopy classification methods mostly rely on predefined categories, making it challenging to identify and classify out-of-distribution (OOD) data, such as undefined categories or anatomical landmarks. To address this issue, we propose the Endoscopy Out-Of-Distribution (EndoOOD) framework, which aims to effectively handle the OOD detection challenge in WCE diagnosis. The proposed framework focuses on improving the robustness and reliability of WCE diagnostic capabilities by incorporating uncertainty-aware mixup training and long-tailed in-distribution (ID) data calibration techniques. Additionally, virtual-logit matching is employed to accurately distinguish between OOD and ID data while minimizing information loss. To assess the performance of our proposed solution, we conduct evaluations and comparisons with 12 state-of-the-art (SOTA) methods using two publicly available datasets. The results demonstrate the effectiveness of the proposed framework in enhancing diagnostic accuracy and supporting clinical decision-making.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/63cc6260b838f2cc559715a9f68360edc743f50b.pdf",
        "venue": "IEEE International Symposium on Biomedical Imaging",
        "citationCount": 6,
        "score": 6.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing deep learning models for Wireless Capsule Endoscopy (WCE) diagnosis operate under a \"closed-world\" assumption, struggling to identify and classify Out-of-Distribution (OOD) data. This OOD data includes undefined disease categories or anatomical landmarks (e.g., Ampulla of Vater, Ileocecal valve, Pylorus) that are distinct from the predefined In-Distribution (ID) disease categories \\cite{tan2024oj5}.\n    *   **Importance and Challenge**: This problem is critical because misclassifying OOD data can lead to inaccurate diagnoses, reduced reliability, and increased burden on healthcare professionals. Training models solely on ID data fails to generalize effectively to real-world WCE scenarios where OOD instances are common. The challenge lies in developing robust models that can accurately distinguish between known (ID) and unknown (OOD) conditions while maintaining high diagnostic accuracy for ID data \\cite{tan2024oj5}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon and extends existing OOD detection strategies, including training-based (e.g., ConfBranch) and post-hoc methods (e.g., MSP, ODIN, MDS, ViM) \\cite{tan2024oj5}. It specifically leverages and refines mixup training and Virtual-logit Matching (ViM).\n    *   **Limitations of Previous Solutions**:\n        *   Many existing OOD detection methods struggle with effectively discerning ID and OOD samples, especially in complex medical imaging contexts like WCE.\n        *   Mixup training, while improving OOD handling, often leads to decreased calibration performance, impacting the accurate estimation of uncertainty \\cite{tan2024oj5}.\n        *   Conventional model calibration techniques (e.g., temperature scaling, label smoothing) often fail to effectively handle long-tailed data distributions prevalent in WCE, where a few categories have high frequency, leading to overconfident predictions for these classes and poor discrimination of low-frequency or OOD samples \\cite{tan2024oj5}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes the Endoscopy Out-of-Distribution (EndoOOD) framework, which integrates three key components:\n        1.  **Uncertainty-Aware Mixup Training**: Decouples mixup's data transformation and random perturbation steps to mitigate calibration degradation caused by standard mixup. It recovers raw sample output predictions and trains models by fitting decoupled outputs to original one-hot labels, avoiding confidence penalties \\cite{tan2024oj5}.\n        2.  **Long-Tailed ID Data Calibration**: Addresses overconfident probabilities for high-frequency classes in long-tailed WCE datasets. It incorporates category quantity into both Temperature Scaling (TS) and Label Smoothing (LS) by reweighting optimal temperature and penalizing high-frequency classes more heavily, respectively \\cite{tan2024oj5}.\n        3.  **Calibrated Post-hoc Inference (Virtual-logit Matching - ViM)**: Utilizes ViM to accurately distinguish between OOD and ID data during inference. ViM computes OOD-ness by integrating the norm of feature residual against a principal subspace and the original logits, minimizing information loss \\cite{tan2024oj5}.\n    *   **Novelty/Difference**: The novelty lies in the synergistic integration of these three components, specifically:\n        *   Addressing the *calibration degradation* issue of mixup training through an uncertainty-aware decoupling strategy.\n        *   Introducing *category quantity-aware* calibration techniques (modified TS and LS) to specifically tackle the challenges posed by long-tailed data distributions in medical imaging.\n        *   Combining these training-time innovations with a robust post-hoc inference method (ViM) to create a comprehensive, uncertainty-aware framework for OOD detection in WCE \\cite{tan2024oj5}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **Uncertainty-aware mixup training strategy**: A decoupled mixup approach that improves OOD detection while preserving uncertainty calibration, crucial for reliable medical diagnosis \\cite{tan2024oj5}.\n        *   **Long-tailed ID data calibration technique**: Modifies temperature scaling and label smoothing by incorporating category quantity, effectively mitigating overconfidence in high-frequency classes and improving discrimination for low-frequency and OOD samples \\cite{tan2024oj5}.\n    *   **System Design/Architectural Innovations**: The EndoOOD framework itself represents an integrated system design that combines training-time calibration and augmentation with a post-hoc inference mechanism (ViM) for robust OOD detection in WCE \\cite{tan2024oj5}.\n    *   **Theoretical Insights/Analysis**: The paper implicitly provides insights into the interplay between data augmentation (mixup), uncertainty estimation, and class imbalance (long-tailed data) in the context of OOD detection for medical images, demonstrating how targeted calibration can resolve common pitfalls \\cite{tan2024oj5}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive quantitative evaluations were performed against 12 state-of-the-art (SOTA) OOD detection methods \\cite{tan2024oj5}. An ablation study was also conducted to assess the contribution of each proposed component.\n    *   **Datasets**:\n        *   **Kvasir-Capsule**: Used for ID (11 disease classes) and Near-OOD (3 anatomical classes) data \\cite{tan2024oj5}.\n        *   **CIFAR-10**: Used as Far-OOD data to evaluate performance on significantly different image distributions \\cite{tan2024oj5}.\n    *   **Key Performance Metrics**: FPR@95 (False Positive Rate at 95% True Positive Rate), AUROC (Area Under the Receiver Operating Characteristic curve), AUPR In (Area Under the Precision-Recall curve for In-distribution), AUPR Out (Area Under the Precision-Recall curve for Out-of-distribution), and Accuracy (for ID data) \\cite{tan2024oj5}.\n    *   **Comparison Results**:\n        *   The EndoOOD framework demonstrated superior performance across all OOD metrics for both Near-OOD (Kvasir-Capsule outliers) and Far-OOD (CIFAR-10) data, surpassing all 12 baseline models \\cite{tan2024oj5}.\n        *   For Near-OOD, it achieved FPR@95 of 32.08, AUROC of 93.06, AUPR In of 90.92, and AUPR Out of 93.75 \\cite{tan2024oj5}.\n        *   For Far-OOD (CIFAR-10), it achieved error-free performance (FPR@95 of 0.00, AUROC of 100.00, AUPR In of 100.00, AUPR Out of 99.98) \\cite{tan2024oj5}.\n        *   Crucially, the accuracy for known (ID) classes also increased by over 1% (to 94.02%) compared to baselines, indicating improved overall diagnostic capability \\cite{tan2024oj5}.\n        *   **Ablation Study**: Confirmed that both uncertainty-aware mixup training and long-tailed ID data calibration positively contribute to the framework's superior performance, as removing either component led to significant degradation \\cite{tan2024oj5}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper does not explicitly detail specific technical limitations of the proposed method itself, beyond the general challenges it aims to solve. It assumes the availability of labeled ID data for training and relies on the effectiveness of ViM for post-hoc inference.\n    *   **Scope of Applicability**: The framework is specifically designed and validated for WCE diagnosis, focusing on gastrointestinal disease screening. While demonstrated on CIFAR-10 for Far-OOD, its primary application context is medical imaging. Future research is suggested to explore further advancements and applications in real-world WCE scenarios \\cite{tan2024oj5}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The EndoOOD framework significantly advances the technical state-of-the-art in OOD detection for medical imaging, particularly in WCE, by providing a robust and uncertainty-aware solution that outperforms existing SOTA methods \\cite{tan2024oj5}. It addresses critical issues of uncertainty calibration in mixup training and handling long-tailed data distributions, which are common in real-world medical datasets.\n    *   **Potential Impact**: This work has the potential to greatly enhance the reliability and accuracy of automated WCE diagnosis, leading to improved clinical decision-making and alleviating the burden on healthcare professionals. By enabling models to reliably identify and reject OOD inputs, it makes deep learning models more trustworthy and applicable in sensitive medical contexts \\cite{tan2024oj5}.",
        "keywords": [
          "Wireless Capsule Endoscopy (WCE) diagnosis",
          "Out-of-Distribution (OOD) detection",
          "EndoOOD framework",
          "Uncertainty-aware mixup training",
          "Long-tailed data calibration",
          "Virtual-logit Matching (ViM)",
          "Model calibration",
          "Medical imaging",
          "Superior OOD detection performance",
          "Improved ID classification accuracy",
          "Robust deep learning models",
          "Gastrointestinal disease screening",
          "Closed-world assumption limitation"
        ],
        "paper_type": "based on the abstract and introduction, this paper is best classified as **technical**.\n\nhere's why:\n\n*   **abstract mentions:** \"we **propose** the endoscopy out-of-distribution (endoood) **framework**\", \"the **proposed framework** focuses on improving...\", \"incorporating uncertainty-aware mixup training and long-tailed in-distribution (id) data calibration **techniques**\", \"virtual-logit matching is **employed**\". these phrases directly align with presenting new methods, algorithms, or systems.\n*   **introduction discusses:** it identifies a \"technical problem\" (ood data challenge in wce due to closed-world assumptions) and sets the stage for a \"novel framework that effectively tackles the ood challenge\".\n*   while it also includes strong elements of **empirical** research (\"conduct evaluations and comparisons with 12 state-of-the-art (sota) methods using two publicly available datasets\"), the primary contribution described is the *development and proposal* of a new framework/method. the empirical evaluation serves to validate this technical contribution. many technical papers include an empirical section to demonstrate the effectiveness of their proposed solution."
      },
      "file_name": "63cc6260b838f2cc559715a9f68360edc743f50b.pdf"
    },
    {
      "success": true,
      "doc_id": "a63cb2b5622c80b51e9d4790c52e9960",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/5278d3db213bce1dd424ad7e0c5dc97801baceee.pdf",
      "citation_key": "ma202440a",
      "metadata": {
        "title": "Revisiting Score Propagation in Graph Out-of-Distribution Detection",
        "authors": [
          "Longfei Ma",
          "Yiyou Sun",
          "Kaize Ding",
          "Zemin Liu",
          "Fei Wu"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/5278d3db213bce1dd424ad7e0c5dc97801baceee.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 5,
        "score": 5.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "5278d3db213bce1dd424ad7e0c5dc97801baceee.pdf"
    },
    {
      "success": true,
      "doc_id": "1dc9eedb4ccb8f7fcd00e999f91f09ce",
      "summary": "Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).",
      "intriguing_abstract": "Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/a2d255583ee4cb66f343103076239af2931047be.pdf",
      "citation_key": "yang2025z62",
      "metadata": {
        "title": "Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs",
        "authors": [
          "Shenzhi Yang",
          "Bin Liang",
          "An Liu",
          "Lin Gui",
          "Xingkai Yao",
          "Xiaofang Zhang"
        ],
        "published_date": "2025",
        "abstract": "Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/a2d255583ee4cb66f343103076239af2931047be.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).",
        "keywords": []
      },
      "file_name": "a2d255583ee4cb66f343103076239af2931047be.pdf"
    },
    {
      "success": true,
      "doc_id": "012ab168cdd96c930f2cdb663b7e9a79",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/a4bd318d5b2866bd3736142109168ea961a2ab38.pdf",
      "citation_key": "zhang2024z2g",
      "metadata": {
        "title": "Unsupervised evaluation for out-of-distribution detection",
        "authors": [
          "Yuhang Zhang",
          "Jiani Hu",
          "Dongchao Wen",
          "Weihong Deng"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/a4bd318d5b2866bd3736142109168ea961a2ab38.pdf",
        "venue": "Pattern Recognition",
        "citationCount": 5,
        "score": 5.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "a4bd318d5b2866bd3736142109168ea961a2ab38.pdf"
    },
    {
      "success": true,
      "doc_id": "a675e1ae7430ddf6ed889c5c2208da82",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/3ecbd6fc9ba0a00ce49982f788918bc2b768d98b.pdf",
      "citation_key": "abdi2024mvh",
      "metadata": {
        "title": "Typicality Excels Likelihood for Unsupervised Out-of-Distribution Detection in Medical Imaging",
        "authors": [
          "Lemar Abdi",
          "M. Valiuddin",
          "Christiaan G. A. Viviers",
          "Peter H. N. de With",
          "F. V. D. Sommen"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/3ecbd6fc9ba0a00ce49982f788918bc2b768d98b.pdf",
        "venue": "UNSURE@MICCAI",
        "citationCount": 5,
        "score": 5.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "3ecbd6fc9ba0a00ce49982f788918bc2b768d98b.pdf"
    },
    {
      "success": true,
      "doc_id": "c5d54671289af286949d0dae87a6e3af",
      "summary": "Deep Reinforcement Learning (RL) has the potential to revolutionize the automation of complex sequential decision-making problems. Although it has been successfully applied to a wide range of tasks, deployment to real-world settings remains challenging and is often limited. One of the main reasons for this is the lack of safety guarantees for conventional RL algorithms, especially in situations that substantially differ from the learning environment. In such situations, state-of-the-art systems will fail silently, producing action sequences without signalizing any uncertainty regarding the current input. Recent works have suggested Out-of-Distribution (OOD) detection as an additional reliability measure when deploying RL in the real world. How these mechanisms benefit the safety of the entire system, however, is not yet fully understood. In this work, we study how OOD detection contributes to the safety of RL systems by describing the challenges involved with detecting unknown situations. We derive several definitions for unknown events and explore potential avenues for a successful safety argumentation, building on recent work for safety assurance of Machine Learning components. In a series of experiments, we compare different OOD detectors and show how difficult it is to distinguish harmless from potentially unsafe OOD events in practice, and how standard evaluation schemes can lead to deceptive conclusions, depending on which definition of unknown is applied.",
      "intriguing_abstract": "Deep Reinforcement Learning (RL) has the potential to revolutionize the automation of complex sequential decision-making problems. Although it has been successfully applied to a wide range of tasks, deployment to real-world settings remains challenging and is often limited. One of the main reasons for this is the lack of safety guarantees for conventional RL algorithms, especially in situations that substantially differ from the learning environment. In such situations, state-of-the-art systems will fail silently, producing action sequences without signalizing any uncertainty regarding the current input. Recent works have suggested Out-of-Distribution (OOD) detection as an additional reliability measure when deploying RL in the real world. How these mechanisms benefit the safety of the entire system, however, is not yet fully understood. In this work, we study how OOD detection contributes to the safety of RL systems by describing the challenges involved with detecting unknown situations. We derive several definitions for unknown events and explore potential avenues for a successful safety argumentation, building on recent work for safety assurance of Machine Learning components. In a series of experiments, we compare different OOD detectors and show how difficult it is to distinguish harmless from potentially unsafe OOD events in practice, and how standard evaluation schemes can lead to deceptive conclusions, depending on which definition of unknown is applied.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/d4bc2e2146387bfca16593152840e763cff4ef88.pdf",
      "citation_key": "haider20249q8",
      "metadata": {
        "title": "Can you trust your Agent? The Effect of Out-of-Distribution Detection on the Safety of Reinforcement Learning Systems",
        "authors": [
          "Tom Haider",
          "Karsten Roscher",
          "Benjamin Herd",
          "Felippe Schmoeller da Roza",
          "Simon Burton"
        ],
        "published_date": "2024",
        "abstract": "Deep Reinforcement Learning (RL) has the potential to revolutionize the automation of complex sequential decision-making problems. Although it has been successfully applied to a wide range of tasks, deployment to real-world settings remains challenging and is often limited. One of the main reasons for this is the lack of safety guarantees for conventional RL algorithms, especially in situations that substantially differ from the learning environment. In such situations, state-of-the-art systems will fail silently, producing action sequences without signalizing any uncertainty regarding the current input. Recent works have suggested Out-of-Distribution (OOD) detection as an additional reliability measure when deploying RL in the real world. How these mechanisms benefit the safety of the entire system, however, is not yet fully understood. In this work, we study how OOD detection contributes to the safety of RL systems by describing the challenges involved with detecting unknown situations. We derive several definitions for unknown events and explore potential avenues for a successful safety argumentation, building on recent work for safety assurance of Machine Learning components. In a series of experiments, we compare different OOD detectors and show how difficult it is to distinguish harmless from potentially unsafe OOD events in practice, and how standard evaluation schemes can lead to deceptive conclusions, depending on which definition of unknown is applied.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/d4bc2e2146387bfca16593152840e763cff4ef88.pdf",
        "venue": "ACM Symposium on Applied Computing",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Deep Reinforcement Learning (RL) has the potential to revolutionize the automation of complex sequential decision-making problems. Although it has been successfully applied to a wide range of tasks, deployment to real-world settings remains challenging and is often limited. One of the main reasons for this is the lack of safety guarantees for conventional RL algorithms, especially in situations that substantially differ from the learning environment. In such situations, state-of-the-art systems will fail silently, producing action sequences without signalizing any uncertainty regarding the current input. Recent works have suggested Out-of-Distribution (OOD) detection as an additional reliability measure when deploying RL in the real world. How these mechanisms benefit the safety of the entire system, however, is not yet fully understood. In this work, we study how OOD detection contributes to the safety of RL systems by describing the challenges involved with detecting unknown situations. We derive several definitions for unknown events and explore potential avenues for a successful safety argumentation, building on recent work for safety assurance of Machine Learning components. In a series of experiments, we compare different OOD detectors and show how difficult it is to distinguish harmless from potentially unsafe OOD events in practice, and how standard evaluation schemes can lead to deceptive conclusions, depending on which definition of unknown is applied.",
        "keywords": []
      },
      "file_name": "d4bc2e2146387bfca16593152840e763cff4ef88.pdf"
    },
    {
      "success": true,
      "doc_id": "c83b217cafc438f3dd64278e8987f2b1",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/55b668702e122d10787c5f94e4090062755753d2.pdf",
      "citation_key": "qu202422m",
      "metadata": {
        "title": "Hyper-opinion Evidential Deep Learning for Out-of-Distribution Detection",
        "authors": [
          "Jingen Qu",
          "Yufei Chen",
          "Xiaodong Yue",
          "Wei Fu",
          "Qiguang Huang"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/55b668702e122d10787c5f94e4090062755753d2.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 4,
        "score": 4.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "55b668702e122d10787c5f94e4090062755753d2.pdf"
    },
    {
      "success": true,
      "doc_id": "58ecb2862debd14661aadc9af97c6faa",
      "summary": "Here's a focused summary of the paper `\\cite{novello2024yco}` for a literature review:\n\n### Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?) `\\cite{novello2024yco}`\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Standard evaluation metrics for Out-of-Distribution (OOD) detection, such as AUROC and FPR@TPR95, can be overly optimistic and unreliable due to the finite sample size of test datasets. This leads to a lack of robust, conservative guarantees on OOD score performance.\n    *   **Importance and Challenge**: This problem is critical for safety-critical Machine Learning applications where reliable uncertainty quantification and guaranteed performance bounds for OOD detection are essential. The challenge lies in providing statistically rigorous, finite-sample guarantees for OOD score evaluation and interpretation.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon Conformal Prediction (CP) as a post-hoc uncertainty quantification framework. It relates to prior attempts to cast OOD in statistical frameworks (e.g., Selective Inference, other Conformal OOD/AD methods).\n    *   **Limitations of Previous Solutions**:\n        *   Traditional OOD evaluation metrics (AUROC, FPR) provide only empirical approximations that fluctuate with the calibration dataset, lacking probabilistic conservativeness guarantees.\n        *   Standard CP applications to OOD/Anomaly Detection typically use basic marginal guarantees and simple non-conformity scores (e.g., softmax outputs, classical distances), not fully leveraging the rich landscape of OOD scores.\n        *   Selective Inference methods often require assumptions or modifications to the underlying model, unlike CP's model-agnostic wrapper approach.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a dual application of Conformal Prediction (CP) and Out-of-Distribution (OOD) detection:\n        1.  **CP for OOD Evaluation**: It casts OOD detection into a statistical hypothesis testing framework, applying the ideas of `\\cite{bates2022}` to correct OOD scores. This involves defining `conformal AUROC` and `conformal FPR` metrics, which are corrections providing probabilistic conservativeness guarantees on the variability of these metrics, ensuring that estimations are conservative with high probability (e.g., 1-Î´). This addresses the finite-sample fluctuation problem of p-values and FPR.\n        2.  **OOD Scores for CP Improvement**: It explores using sophisticated OOD scores (e.g., Mahalanobis distance, K-Nearest Neighbors (KNN) distance) as non-conformity scores within the CP framework to build more effective prediction sets.\n    *   **Novelty/Difference**:\n        *   **Guaranteed Conservativeness**: The introduction of `conformal AUROC` and `conformal FPR` provides a novel way to evaluate OOD detectors with high-probability conservative guarantees, a significant departure from purely empirical metrics.\n        *   **Cross-Pollination**: It explicitly advocates for and demonstrates the mutual benefits of intertwining OOD and CP, showing how each field can enhance the other, rather than treating them as separate domains.\n        *   **Enhanced Non-conformity Scores**: By leveraging advanced OOD scores as non-conformity scores, it moves beyond traditional simple scores in CP, opening new avenues for CP score crafting.\n\n*   **Key Technical Contributions**\n    *   Casting the OOD detection problem into the framework of statistical hypothesis testing and applying `\\cite{bates2022}`'s ideas to correct OOD scores.\n    *   Proposing new `conformal AUROC` and `conformal FPR` metrics, which are provably conservative with high probability (1-Î´).\n    *   Building new, more involved non-conformity scores for CP based on existing OOD scores (e.g., Mahalanobis, KNN).\n    *   Highlighting and experimentally demonstrating the inherent intertwining and potential for cross-fertilization between OOD detection (designing scores) and Conformal Prediction (interpreting scores).\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Demonstrated the fluctuations of p-values and FPR due to finite calibration dataset size using the SVHN extra dataset, showing that empirical approximations can be overly optimistic.\n        *   Applied the proposed `conformal AUROC` and `conformal FPR` corrections to two reference OOD and anomaly detection benchmarks.\n        *   Conducted an experimental comparison of prediction set performance using OOD-based non-conformity scores against classical CP non-conformity scores.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   The effect of `conformal AUROC` and `conformal FPR` was shown on the **OpenOOD `\\cite{yang2022}`** and **ADBench `\\cite{han2022}`** benchmarks, demonstrating their ability to provide conservative estimates.\n        *   For CP, it was found that OOD scores like **Mahalanobis** and **KNN** are good candidates for non-conformity scores. Specifically, the **Mahalanobis score was shown to outperform classical non-conformity scores** in building prediction sets for classification tasks.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The conservativeness guarantees of the new conformal metrics come at the expense of some approximation precision. The marginal p-values are provably valid but depend on the choice of the calibration dataset, and the correction aims to provide guarantees *conditional* on the calibration set with high probability.\n    *   **Scope of Applicability**: The methods are broadly applicable to any OOD score and can enhance the reliability of OOD detection in various ML pipelines, particularly in safety-critical contexts. The CP improvement aspect is demonstrated for classification tasks but could potentially extend to other ML tasks.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art by introducing a statistically rigorous framework for evaluating OOD detection performance with probabilistic guarantees, moving beyond potentially optimistic empirical metrics. It also enriches the Conformal Prediction field by demonstrating the utility of advanced OOD scores as non-conformity measures.\n    *   **Potential Impact on Future Research**: The paper's core messageâ€”that OOD and CP are inherently intertwinedâ€”opens a large avenue for future research. It encourages cross-fertilization between the two fields, potentially leading to more robust OOD detectors, more efficient CP methods, and a deeper understanding of uncertainty quantification in ML. This could lead to more trustworthy and certifiable AI systems.",
      "intriguing_abstract": "Reliable Out-of-Distribution (OOD) detection is paramount for safety-critical AI, yet standard evaluation metrics like AUROC and FPR often provide overly optimistic and unreliable estimates due to finite test data. This paper introduces a novel, dual framework that fundamentally intertwines OOD detection with Conformal Prediction (CP) to provide statistically rigorous guarantees. We propose `conformal AUROC` and `conformal FPR`, new metrics that offer provably conservative, high-probability finite-sample guarantees on OOD score performance, correcting the inherent optimism of empirical evaluations. Simultaneously, we demonstrate how sophisticated OOD scores, such as Mahalanobis distance and K-Nearest Neighbors (KNN) distance, can serve as powerful non-conformity scores within CP, significantly enhancing prediction set quality compared to classical approaches. This cross-pollination not only provides robust uncertainty quantification for OOD detectors but also enriches CP with advanced score crafting. Our work establishes a new paradigm for evaluating and improving OOD detection, paving the way for more trustworthy and certifiable AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Conformal Prediction (CP)",
        "Conformal AUROC",
        "Conformal FPR",
        "probabilistic conservativeness guarantees",
        "finite-sample guarantees",
        "uncertainty quantification",
        "statistical hypothesis testing",
        "enhanced non-conformity scores",
        "Mahalanobis distance",
        "cross-pollination (OOD and CP)",
        "safety-critical Machine Learning"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/5f8ccbe2a87df5e1340d4bda8f6e3458ef1bf6ae.pdf",
      "citation_key": "novello2024yco",
      "metadata": {
        "title": "Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?)",
        "authors": [
          "Paul Novello",
          "Joseba Dalmau",
          "L'eo Andeol"
        ],
        "published_date": "2024",
        "abstract": "Research on Out-Of-Distribution (OOD) detection focuses mainly on building scores that efficiently distinguish OOD data from In Distribution (ID) data. On the other hand, Conformal Prediction (CP) uses non-conformity scores to construct prediction sets with probabilistic coverage guarantees. In this work, we propose to use CP to better assess the efficiency of OOD scores. Specifically, we emphasize that in standard OOD benchmark settings, evaluation metrics can be overly optimistic due to the finite sample size of the test dataset. Based on the work of (Bates et al., 2022), we define new conformal AUROC and conformal FRP@TPR95 metrics, which are corrections that provide probabilistic conservativeness guarantees on the variability of these metrics. We show the effect of these corrections on two reference OOD and anomaly detection benchmarks, OpenOOD (Yang et al., 2022) and ADBench (Han et al., 2022). We also show that the benefits of using OOD together with CP apply the other way around by using OOD scores as non-conformity scores, which results in improving upon current CP methods. One of the key messages of these contributions is that since OOD is concerned with designing scores and CP with interpreting these scores, the two fields may be inherently intertwined.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/5f8ccbe2a87df5e1340d4bda8f6e3458ef1bf6ae.pdf",
        "venue": "arXiv.org",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Here's a focused summary of the paper `\\cite{novello2024yco}` for a literature review:\n\n### Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?) `\\cite{novello2024yco}`\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Standard evaluation metrics for Out-of-Distribution (OOD) detection, such as AUROC and FPR@TPR95, can be overly optimistic and unreliable due to the finite sample size of test datasets. This leads to a lack of robust, conservative guarantees on OOD score performance.\n    *   **Importance and Challenge**: This problem is critical for safety-critical Machine Learning applications where reliable uncertainty quantification and guaranteed performance bounds for OOD detection are essential. The challenge lies in providing statistically rigorous, finite-sample guarantees for OOD score evaluation and interpretation.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon Conformal Prediction (CP) as a post-hoc uncertainty quantification framework. It relates to prior attempts to cast OOD in statistical frameworks (e.g., Selective Inference, other Conformal OOD/AD methods).\n    *   **Limitations of Previous Solutions**:\n        *   Traditional OOD evaluation metrics (AUROC, FPR) provide only empirical approximations that fluctuate with the calibration dataset, lacking probabilistic conservativeness guarantees.\n        *   Standard CP applications to OOD/Anomaly Detection typically use basic marginal guarantees and simple non-conformity scores (e.g., softmax outputs, classical distances), not fully leveraging the rich landscape of OOD scores.\n        *   Selective Inference methods often require assumptions or modifications to the underlying model, unlike CP's model-agnostic wrapper approach.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a dual application of Conformal Prediction (CP) and Out-of-Distribution (OOD) detection:\n        1.  **CP for OOD Evaluation**: It casts OOD detection into a statistical hypothesis testing framework, applying the ideas of `\\cite{bates2022}` to correct OOD scores. This involves defining `conformal AUROC` and `conformal FPR` metrics, which are corrections providing probabilistic conservativeness guarantees on the variability of these metrics, ensuring that estimations are conservative with high probability (e.g., 1-Î´). This addresses the finite-sample fluctuation problem of p-values and FPR.\n        2.  **OOD Scores for CP Improvement**: It explores using sophisticated OOD scores (e.g., Mahalanobis distance, K-Nearest Neighbors (KNN) distance) as non-conformity scores within the CP framework to build more effective prediction sets.\n    *   **Novelty/Difference**:\n        *   **Guaranteed Conservativeness**: The introduction of `conformal AUROC` and `conformal FPR` provides a novel way to evaluate OOD detectors with high-probability conservative guarantees, a significant departure from purely empirical metrics.\n        *   **Cross-Pollination**: It explicitly advocates for and demonstrates the mutual benefits of intertwining OOD and CP, showing how each field can enhance the other, rather than treating them as separate domains.\n        *   **Enhanced Non-conformity Scores**: By leveraging advanced OOD scores as non-conformity scores, it moves beyond traditional simple scores in CP, opening new avenues for CP score crafting.\n\n*   **Key Technical Contributions**\n    *   Casting the OOD detection problem into the framework of statistical hypothesis testing and applying `\\cite{bates2022}`'s ideas to correct OOD scores.\n    *   Proposing new `conformal AUROC` and `conformal FPR` metrics, which are provably conservative with high probability (1-Î´).\n    *   Building new, more involved non-conformity scores for CP based on existing OOD scores (e.g., Mahalanobis, KNN).\n    *   Highlighting and experimentally demonstrating the inherent intertwining and potential for cross-fertilization between OOD detection (designing scores) and Conformal Prediction (interpreting scores).\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Demonstrated the fluctuations of p-values and FPR due to finite calibration dataset size using the SVHN extra dataset, showing that empirical approximations can be overly optimistic.\n        *   Applied the proposed `conformal AUROC` and `conformal FPR` corrections to two reference OOD and anomaly detection benchmarks.\n        *   Conducted an experimental comparison of prediction set performance using OOD-based non-conformity scores against classical CP non-conformity scores.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   The effect of `conformal AUROC` and `conformal FPR` was shown on the **OpenOOD `\\cite{yang2022}`** and **ADBench `\\cite{han2022}`** benchmarks, demonstrating their ability to provide conservative estimates.\n        *   For CP, it was found that OOD scores like **Mahalanobis** and **KNN** are good candidates for non-conformity scores. Specifically, the **Mahalanobis score was shown to outperform classical non-conformity scores** in building prediction sets for classification tasks.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The conservativeness guarantees of the new conformal metrics come at the expense of some approximation precision. The marginal p-values are provably valid but depend on the choice of the calibration dataset, and the correction aims to provide guarantees *conditional* on the calibration set with high probability.\n    *   **Scope of Applicability**: The methods are broadly applicable to any OOD score and can enhance the reliability of OOD detection in various ML pipelines, particularly in safety-critical contexts. The CP improvement aspect is demonstrated for classification tasks but could potentially extend to other ML tasks.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art by introducing a statistically rigorous framework for evaluating OOD detection performance with probabilistic guarantees, moving beyond potentially optimistic empirical metrics. It also enriches the Conformal Prediction field by demonstrating the utility of advanced OOD scores as non-conformity measures.\n    *   **Potential Impact on Future Research**: The paper's core messageâ€”that OOD and CP are inherently intertwinedâ€”opens a large avenue for future research. It encourages cross-fertilization between the two fields, potentially leading to more robust OOD detectors, more efficient CP methods, and a deeper understanding of uncertainty quantification in ML. This could lead to more trustworthy and certifiable AI systems.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Conformal Prediction (CP)",
          "Conformal AUROC",
          "Conformal FPR",
          "probabilistic conservativeness guarantees",
          "finite-sample guarantees",
          "uncertainty quantification",
          "statistical hypothesis testing",
          "enhanced non-conformity scores",
          "Mahalanobis distance",
          "cross-pollination (OOD and CP)",
          "safety-critical Machine Learning"
        ],
        "paper_type": "this paper is best classified as **technical**.\n\nhere's why:\n\n*   **abstract mentions:** \"we propose to use cp to better assess the efficiency of ood scores,\" \"we define new conformal au-roc and conformal frp@tpr95 metrics, which are corrections that provide probabilistic conservativeness guarantees,\" and \"improving upon current cp methods.\" these phrases directly indicate the development and presentation of new methods, algorithms (in the form of new metrics and evaluation approaches), and systems (integrating cp and ood).\n*   **introduction discusses:** the problem of ood detection and existing strategies, setting the stage for the proposed technical solution.\n*   **empirical component:** while the paper does \"show the effect of these corrections on two reference ood and anomaly detection benchmarks,\" this empirical work serves to validate and demonstrate the utility of the *proposed new technical methods and metrics*, rather than being a purely data-driven study of an existing phenomenon. the core contribution is the new methodology.\n*   **position component:** the title \"should use conformal prediction\" suggests a position, but this position is argued for by presenting a concrete, new technical approach and demonstrating its benefits. it's a position *supported by* technical innovation, not a standalone argument."
      },
      "file_name": "5f8ccbe2a87df5e1340d4bda8f6e3458ef1bf6ae.pdf"
    },
    {
      "success": true,
      "doc_id": "c64cd696b4b14167dd0e93b98ff31753",
      "summary": "Here's a focused summary of the paper \"TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection\" \\cite{chen2024f28} for a literature review:\n\n---\n\n### TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection \\cite{chen2024f28}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addressing the challenge of Out-of-Distribution (OOD) detection in intelligent models, where models trained solely on in-distribution (ID) data exhibit overconfidence when encountering and misclassifying OOD data as ID classes.\n    *   **Importance and Challenge**:\n        *   Crucial for real-world applications like autonomous driving and intelligent healthcare, where misclassifying OOD samples can lead to serious consequences.\n        *   Existing methods often train classifiers only on ID data, leading to a lack of OOD knowledge and overconfidence.\n        *   Obtaining real OOD data for training is often time-consuming or costly.\n        *   Previous fake OOD generation methods (e.g., GANs) suffer from unstable training or unrealistic assumptions (e.g., strict Gaussian distributions in feature space).\n        *   Leveraging pre-trained vision-language models like CLIP for OOD detection often requires unrealistic OOD data labels or specific pre-trained visual encoders during inference.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**:\n        *   Most approaches train a classifier on ID data and then design a post-hoc score function (e.g., MSP, Mahalanobis, ODIN, Energy, ReAct) based on feature or logit outputs \\cite{chen2024f28}.\n        *   Methods using fake OOD data during training, such as GAN-based generation \\cite{chen2024f28} or synthesizing virtual OOD features in the feature space (e.g., VOS) \\cite{chen2024f28}.\n        *   Approaches leveraging large vision-language models like CLIP, which have learned extensive knowledge, including OOD knowledge \\cite{chen2024f28}.\n    *   **Limitations of Previous Solutions**:\n        *   Training only on ID data leads to overconfidence in unseen OOD data \\cite{chen2024f28}.\n        *   GAN-based fake OOD generation is often unstable and struggles to produce realistic OOD samples from only ID data \\cite{chen2024f28}.\n        *   Feature-space OOD generation methods (e.g., VOS) often assume strict, unrealistic Gaussian distributions for ID data \\cite{chen2024f28}.\n        *   CLIP-based OOD detection methods may require unrealistic OOD data labels or specific pre-trained visual encoders during OOD detection \\cite{chen2024f28}.\n        *   Existing Jigsaw-based methods (e.g., FeatureNorm) use Jigsaw for post-training layer selection, not for model training itself \\cite{chen2024f28}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (TagFog Framework)**: TagFog integrates two main components: Fake Outlier Generation (FOG) and Textual Anchor Guidance (TAG), to train a visual encoder for OOD detection.\n        *   **Fake Outlier Generation (FOG)**:\n            *   Utilizes a simple Jigsaw transformation on ID training images to create fake OOD data.\n            *   Each ID image is divided into multiple patches, which are then randomly shuffled and rearranged to form a new \"fake OOD\" image \\cite{chen2024f28}.\n            *   These fake OOD images are used to train a (K+1)-class classifier (K ID classes + 1 OOD class) \\cite{chen2024f28}.\n        *   **Textual Anchor Guidance (TAG)**:\n            *   Leverages ChatGPT to generate rich, descriptive text for each ID class (e.g., \"Please describe the {ostrich}\") \\cite{chen2024f28}.\n            *   These textual descriptions are fed into a pre-trained and fixed CLIP's Text Encoder to obtain semantic embeddings, referred to as \"anchors\" \\cite{chen2024f28}.\n            *   These anchors guide the training of the image encoder via a contrastive loss (LCI), aligning projected visual embeddings of ID images with their corresponding textual anchors \\cite{chen2024f28}.\n        *   **Combined Training**: The image encoder, classifier head, and a projection module are trained using a combined loss function:\n            *   Cross-entropy loss (LCE) for the (K+1)-class classification task (ID vs. fake OOD) \\cite{chen2024f28}.\n            *   Contrastive loss (LCI) to align projected visual embeddings with ChatGPT-generated textual anchors \\cite{chen2024f28}.\n            *   Supervised contrastive loss (LSC) (following SupCon) on all projected ID and fake OOD embedding vectors to further differentiate them \\cite{chen2024f28}.\n    *   **Novelty**:\n        *   **First usage of ChatGPT** to generate semantically rich descriptions for ID classes, providing more informative textual anchors than simple class names for OOD detection guidance \\cite{chen2024f28}.\n        *   **Simple yet effective Jigsaw-based fake OOD generation** for *model training*, which creates challenging OOD samples by disrupting semantic information while retaining some patch-level similarity, addressing limitations of GANs and feature-space methods \\cite{chen2024f28}.\n        *   **Flexible framework** that can be combined with various existing post-hoc OOD detection strategies during inference (e.g., ReAct is used by default) \\cite{chen2024f28}.\n        *   The combination of rich textual guidance and simple fake OOD generation for training a visual encoder to learn compact ID representations and leave spare regions for OOD data in the feature space \\cite{chen2024f28}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Learning Framework**: TagFog, a simple yet effective framework that leverages both fake OOD data and rich textual embeddings of ID classes to train a superior image encoder for OOD detection \\cite{chen2024f28}.\n    *   **Innovative Use of ChatGPT**: The pioneering application of ChatGPT to generate semantically richer and more informative textual descriptions for ID classes, which are then used as anchors via CLIP's text encoder to guide image encoder training \\cite{chen2024f28}.\n    *   **Effective Fake OOD Generation**: A straightforward Jigsaw-based strategy for generating fake OOD data during model training, which creates semantically shifted but partially similar samples, proving more robust than complex GANs or restrictive feature-space assumptions \\cite{chen2024f28}.\n    *   **Flexible Integration**: The framework is designed to be flexibly combined with many existing post-hoc OOD detection methods, enhancing their performance \\cite{chen2024f28}.\n    *   **Combined Loss Function**: A novel combination of cross-entropy, CLIP-based contrastive loss (LCI), and supervised contrastive loss (LSC) to simultaneously learn ID-OOD discrimination, semantic alignment, and compact feature representations \\cite{chen2024f28}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive empirical evaluations on multiple OOD detection benchmarks.\n    *   **Datasets**:\n        *   **CIFAR Benchmarks**: CIFAR10 and CIFAR100 as ID datasets, with Textures, SVHN, iSUN, Places365, LSUN-C, and LSUN-R as OOD test sets \\cite{chen2024f28}.\n        *   **ImageNet Benchmarks**: ImageNet100-I and ImageNet100-II as ID datasets, with Places, Textures, iNaturalist, and SUN as OOD test sets \\cite{chen2024f28}.\n    *   **Models/Backbones**: ResNet18 and ResNet34 for CIFAR; ResNet50 and ResNet101 for ImageNet100 \\cite{chen2024f28}. WideResNet28-10 results also provided in supplementary material.\n    *   **Metrics**: False Positive Rate at 95% True Positive Rate (FPR95â†“) and Area Under the Receiver Operating Characteristic curve (AUROCâ†‘) \\cite{chen2024f28}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   TagFog consistently achieved **new state-of-the-art performance** across all evaluated benchmarks (CIFAR10, CIFAR100, ImageNet100-I, ImageNet100-II) \\cite{chen2024f28}.\n        *   For example, on CIFAR10 (ResNet18), TagFog (with ReAct) achieved an average FPR95 of 20.01% and AUROC of 95.73%, significantly outperforming baselines like MSP (48.03% FPR95, 91.40% AUROC), Energy (30.96% FPR95, 92.05% AUROC), and ReAct alone (31.65% FPR95, 92.26% AUROC) \\cite{chen2024f28}.\n        *   Similar improvements were observed on CIFAR100 and ImageNet100 benchmarks, demonstrating the effectiveness of textual guidance and fake OOD generation in training a robust visual encoder \\cite{chen2024f28}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Relies on the availability and quality of ChatGPT for generating descriptive text for ID classes. While ChatGPT is powerful, its descriptions might not always be perfectly aligned with the visual nuances of every ID class.\n        *   The effectiveness of textual anchors is dependent on the capabilities of the pre-trained CLIP Text Encoder.\n        *   The Jigsaw transformation, while simple and effective, is a heuristic for generating fake OOD data; its optimal configuration (e.g., patch size, number of jigsaw images) might vary across datasets.\n    *   **Scope of Applicability**:\n        *   Primarily demonstrated for visual OOD detection tasks.\n        *   The framework is flexible and can be combined with various post-hoc OOD detection methods, suggesting broad applicability within this domain \\cite{chen2024f28}.\n        *   The approach is suitable for scenarios where obtaining real OOD data for training is difficult or costly.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: TagFog significantly advances the technical state-of-the-art in visual OOD detection by achieving new SOTA performance on multiple challenging benchmarks \\cite{chen2024f28}.\n    *   **Novel Paradigm for OOD Training**: Introduces a novel and effective paradigm for training visual encoders for OOD detection by synergistically combining rich semantic textual guidance (via ChatGPT and CLIP) with simple, yet challenging, fake OOD data generation \\cite{chen2024f28}.\n    *   **Reduced Reliance on Real OOD Data**: Provides a practical solution for improving OOD detection performance without requiring access to real OOD samples during training, addressing a major practical hurdle \\cite{chen2024f28}.\n    *   **Potential Impact on Future Research**:\n        *   Opens new avenues for exploring the integration of large language models (LLMs) like ChatGPT with vision-language models (VLMs) for enhancing robustness in computer vision tasks beyond OOD detection.\n        *   Encourages further research into simple, effective fake OOD generation strategies that avoid the complexities of GANs or restrictive assumptions.\n        *   Highlights the power of multi-modal knowledge (textual semantics) in guiding visual representation learning for improved generalization and uncertainty estimation.",
      "intriguing_abstract": "Intelligent systems often falter when encountering data outside their training distribution, posing significant risks in critical applications like autonomous driving and healthcare. Addressing this pervasive challenge, we introduce TagFog, a novel framework for **visual Out-of-Distribution (OOD) detection** that redefines how models learn robust representations without relying on real OOD samples. TagFog innovates through two synergistic components: **Fake Outlier Generation (FOG)** and **Textual Anchor Guidance (TAG)**. FOG employs a simple yet powerful **Jigsaw transformation** to create challenging fake OOD data during training, overcoming the instability of GANs and restrictive assumptions of feature-space methods. Simultaneously, TAG leverages the unprecedented semantic understanding of **ChatGPT** to generate rich textual descriptions for in-distribution classes, which are then transformed into potent **semantic embeddings** via a fixed **CLIP Text Encoder**. These textual anchors guide the **visual encoder** via **contrastive learning**, ensuring compact in-distribution representations while carving out distinct regions for OOD data in the **feature space**. Our comprehensive experiments demonstrate that TagFog achieves **state-of-the-art performance** across multiple OOD benchmarks (CIFAR, ImageNet), significantly enhancing detection accuracy and reliability. TagFog offers a practical, flexible, and highly effective paradigm, paving the way for safer and more trustworthy AI systems by harnessing the power of multi-modal knowledge.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "TagFog framework",
        "Textual Anchor Guidance (TAG)",
        "Fake Outlier Generation (FOG)",
        "ChatGPT",
        "CLIP Text Encoder",
        "Jigsaw transformation",
        "Contrastive learning",
        "Visual encoder training",
        "Combined loss function",
        "State-of-the-art performance",
        "Reduced reliance on real OOD data"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/835d157e2c23d3577f23778ce051ab8d706babf6.pdf",
      "citation_key": "chen2024f28",
      "metadata": {
        "title": "TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection",
        "authors": [
          "Jiankang Chen",
          "Tong Zhang",
          "Weishi Zheng",
          "Ruixuan Wang"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is crucial in many real-world applications. However, intelligent models are often trained solely on in-distribution (ID) data, leading to overconfidence when misclassifying OOD data as ID classes. In this study, we propose a new learning framework which leverage simple Jigsaw-based fake OOD data and rich semantic embeddings (`anchors') from the ChatGPT description of ID knowledge to help guide the training of the image encoder. The learning framework can be flexibly combined with existing post-hoc approaches to OOD detection, and extensive empirical evaluations on multiple OOD detection benchmarks demonstrate that rich textual representation of ID knowledge and fake OOD knowledge can well help train a visual encoder for OOD detection. With the learning framework, new state-of-the-art performance was achieved on all the benchmarks. The code is available at https://github.com/Cverchen/TagFog.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/835d157e2c23d3577f23778ce051ab8d706babf6.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Here's a focused summary of the paper \"TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection\" \\cite{chen2024f28} for a literature review:\n\n---\n\n### TagFog: Textual Anchor Guidance and Fake Outlier Generation for Visual Out-of-Distribution Detection \\cite{chen2024f28}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addressing the challenge of Out-of-Distribution (OOD) detection in intelligent models, where models trained solely on in-distribution (ID) data exhibit overconfidence when encountering and misclassifying OOD data as ID classes.\n    *   **Importance and Challenge**:\n        *   Crucial for real-world applications like autonomous driving and intelligent healthcare, where misclassifying OOD samples can lead to serious consequences.\n        *   Existing methods often train classifiers only on ID data, leading to a lack of OOD knowledge and overconfidence.\n        *   Obtaining real OOD data for training is often time-consuming or costly.\n        *   Previous fake OOD generation methods (e.g., GANs) suffer from unstable training or unrealistic assumptions (e.g., strict Gaussian distributions in feature space).\n        *   Leveraging pre-trained vision-language models like CLIP for OOD detection often requires unrealistic OOD data labels or specific pre-trained visual encoders during inference.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**:\n        *   Most approaches train a classifier on ID data and then design a post-hoc score function (e.g., MSP, Mahalanobis, ODIN, Energy, ReAct) based on feature or logit outputs \\cite{chen2024f28}.\n        *   Methods using fake OOD data during training, such as GAN-based generation \\cite{chen2024f28} or synthesizing virtual OOD features in the feature space (e.g., VOS) \\cite{chen2024f28}.\n        *   Approaches leveraging large vision-language models like CLIP, which have learned extensive knowledge, including OOD knowledge \\cite{chen2024f28}.\n    *   **Limitations of Previous Solutions**:\n        *   Training only on ID data leads to overconfidence in unseen OOD data \\cite{chen2024f28}.\n        *   GAN-based fake OOD generation is often unstable and struggles to produce realistic OOD samples from only ID data \\cite{chen2024f28}.\n        *   Feature-space OOD generation methods (e.g., VOS) often assume strict, unrealistic Gaussian distributions for ID data \\cite{chen2024f28}.\n        *   CLIP-based OOD detection methods may require unrealistic OOD data labels or specific pre-trained visual encoders during OOD detection \\cite{chen2024f28}.\n        *   Existing Jigsaw-based methods (e.g., FeatureNorm) use Jigsaw for post-training layer selection, not for model training itself \\cite{chen2024f28}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (TagFog Framework)**: TagFog integrates two main components: Fake Outlier Generation (FOG) and Textual Anchor Guidance (TAG), to train a visual encoder for OOD detection.\n        *   **Fake Outlier Generation (FOG)**:\n            *   Utilizes a simple Jigsaw transformation on ID training images to create fake OOD data.\n            *   Each ID image is divided into multiple patches, which are then randomly shuffled and rearranged to form a new \"fake OOD\" image \\cite{chen2024f28}.\n            *   These fake OOD images are used to train a (K+1)-class classifier (K ID classes + 1 OOD class) \\cite{chen2024f28}.\n        *   **Textual Anchor Guidance (TAG)**:\n            *   Leverages ChatGPT to generate rich, descriptive text for each ID class (e.g., \"Please describe the {ostrich}\") \\cite{chen2024f28}.\n            *   These textual descriptions are fed into a pre-trained and fixed CLIP's Text Encoder to obtain semantic embeddings, referred to as \"anchors\" \\cite{chen2024f28}.\n            *   These anchors guide the training of the image encoder via a contrastive loss (LCI), aligning projected visual embeddings of ID images with their corresponding textual anchors \\cite{chen2024f28}.\n        *   **Combined Training**: The image encoder, classifier head, and a projection module are trained using a combined loss function:\n            *   Cross-entropy loss (LCE) for the (K+1)-class classification task (ID vs. fake OOD) \\cite{chen2024f28}.\n            *   Contrastive loss (LCI) to align projected visual embeddings with ChatGPT-generated textual anchors \\cite{chen2024f28}.\n            *   Supervised contrastive loss (LSC) (following SupCon) on all projected ID and fake OOD embedding vectors to further differentiate them \\cite{chen2024f28}.\n    *   **Novelty**:\n        *   **First usage of ChatGPT** to generate semantically rich descriptions for ID classes, providing more informative textual anchors than simple class names for OOD detection guidance \\cite{chen2024f28}.\n        *   **Simple yet effective Jigsaw-based fake OOD generation** for *model training*, which creates challenging OOD samples by disrupting semantic information while retaining some patch-level similarity, addressing limitations of GANs and feature-space methods \\cite{chen2024f28}.\n        *   **Flexible framework** that can be combined with various existing post-hoc OOD detection strategies during inference (e.g., ReAct is used by default) \\cite{chen2024f28}.\n        *   The combination of rich textual guidance and simple fake OOD generation for training a visual encoder to learn compact ID representations and leave spare regions for OOD data in the feature space \\cite{chen2024f28}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Learning Framework**: TagFog, a simple yet effective framework that leverages both fake OOD data and rich textual embeddings of ID classes to train a superior image encoder for OOD detection \\cite{chen2024f28}.\n    *   **Innovative Use of ChatGPT**: The pioneering application of ChatGPT to generate semantically richer and more informative textual descriptions for ID classes, which are then used as anchors via CLIP's text encoder to guide image encoder training \\cite{chen2024f28}.\n    *   **Effective Fake OOD Generation**: A straightforward Jigsaw-based strategy for generating fake OOD data during model training, which creates semantically shifted but partially similar samples, proving more robust than complex GANs or restrictive feature-space assumptions \\cite{chen2024f28}.\n    *   **Flexible Integration**: The framework is designed to be flexibly combined with many existing post-hoc OOD detection methods, enhancing their performance \\cite{chen2024f28}.\n    *   **Combined Loss Function**: A novel combination of cross-entropy, CLIP-based contrastive loss (LCI), and supervised contrastive loss (LSC) to simultaneously learn ID-OOD discrimination, semantic alignment, and compact feature representations \\cite{chen2024f28}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive empirical evaluations on multiple OOD detection benchmarks.\n    *   **Datasets**:\n        *   **CIFAR Benchmarks**: CIFAR10 and CIFAR100 as ID datasets, with Textures, SVHN, iSUN, Places365, LSUN-C, and LSUN-R as OOD test sets \\cite{chen2024f28}.\n        *   **ImageNet Benchmarks**: ImageNet100-I and ImageNet100-II as ID datasets, with Places, Textures, iNaturalist, and SUN as OOD test sets \\cite{chen2024f28}.\n    *   **Models/Backbones**: ResNet18 and ResNet34 for CIFAR; ResNet50 and ResNet101 for ImageNet100 \\cite{chen2024f28}. WideResNet28-10 results also provided in supplementary material.\n    *   **Metrics**: False Positive Rate at 95% True Positive Rate (FPR95â†“) and Area Under the Receiver Operating Characteristic curve (AUROCâ†‘) \\cite{chen2024f28}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   TagFog consistently achieved **new state-of-the-art performance** across all evaluated benchmarks (CIFAR10, CIFAR100, ImageNet100-I, ImageNet100-II) \\cite{chen2024f28}.\n        *   For example, on CIFAR10 (ResNet18), TagFog (with ReAct) achieved an average FPR95 of 20.01% and AUROC of 95.73%, significantly outperforming baselines like MSP (48.03% FPR95, 91.40% AUROC), Energy (30.96% FPR95, 92.05% AUROC), and ReAct alone (31.65% FPR95, 92.26% AUROC) \\cite{chen2024f28}.\n        *   Similar improvements were observed on CIFAR100 and ImageNet100 benchmarks, demonstrating the effectiveness of textual guidance and fake OOD generation in training a robust visual encoder \\cite{chen2024f28}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Relies on the availability and quality of ChatGPT for generating descriptive text for ID classes. While ChatGPT is powerful, its descriptions might not always be perfectly aligned with the visual nuances of every ID class.\n        *   The effectiveness of textual anchors is dependent on the capabilities of the pre-trained CLIP Text Encoder.\n        *   The Jigsaw transformation, while simple and effective, is a heuristic for generating fake OOD data; its optimal configuration (e.g., patch size, number of jigsaw images) might vary across datasets.\n    *   **Scope of Applicability**:\n        *   Primarily demonstrated for visual OOD detection tasks.\n        *   The framework is flexible and can be combined with various post-hoc OOD detection methods, suggesting broad applicability within this domain \\cite{chen2024f28}.\n        *   The approach is suitable for scenarios where obtaining real OOD data for training is difficult or costly.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: TagFog significantly advances the technical state-of-the-art in visual OOD detection by achieving new SOTA performance on multiple challenging benchmarks \\cite{chen2024f28}.\n    *   **Novel Paradigm for OOD Training**: Introduces a novel and effective paradigm for training visual encoders for OOD detection by synergistically combining rich semantic textual guidance (via ChatGPT and CLIP) with simple, yet challenging, fake OOD data generation \\cite{chen2024f28}.\n    *   **Reduced Reliance on Real OOD Data**: Provides a practical solution for improving OOD detection performance without requiring access to real OOD samples during training, addressing a major practical hurdle \\cite{chen2024f28}.\n    *   **Potential Impact on Future Research**:\n        *   Opens new avenues for exploring the integration of large language models (LLMs) like ChatGPT with vision-language models (VLMs) for enhancing robustness in computer vision tasks beyond OOD detection.\n        *   Encourages further research into simple, effective fake OOD generation strategies that avoid the complexities of GANs or restrictive assumptions.\n        *   Highlights the power of multi-modal knowledge (textual semantics) in guiding visual representation learning for improved generalization and uncertainty estimation.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "TagFog framework",
          "Textual Anchor Guidance (TAG)",
          "Fake Outlier Generation (FOG)",
          "ChatGPT",
          "CLIP Text Encoder",
          "Jigsaw transformation",
          "Contrastive learning",
          "Visual encoder training",
          "Combined loss function",
          "State-of-the-art performance",
          "Reduced reliance on real OOD data"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the **abstract** explicitly states: \"we propose a new learning framework,\" \"leverage simple jigsaw-based fake ood data and rich semantic embeddings... to help guide the training of the image encoder,\" and \"the learning framework can be flexibly combined with existing post-hoc approaches.\" it also mentions achieving \"new state-of-the-art performance\" with this framework and provides a link to the code. these are all strong indicators of presenting a new method or system.\n*   the **introduction** sets up a \"technical problem\" (ood detection), discusses existing \"approaches\" and their limitations, which naturally leads to the need for a \"proposed solution\" (their new framework).\n*   while \"extensive empirical evaluations\" are mentioned, they are used to *demonstrate* the effectiveness of the *proposed learning framework*, making the empirical aspect supportive of the technical contribution, rather than the primary focus itself.\n\ntherefore, this paper clearly falls under the **technical** category.\n\n**classification:** technical"
      },
      "file_name": "835d157e2c23d3577f23778ce051ab8d706babf6.pdf"
    },
    {
      "success": true,
      "doc_id": "3f794156273df620a52416326c4c16bf",
      "summary": "Here's a focused summary of the paper `\\cite{miao2024318}` for a literature review:\n\n### Focused Summary for Literature Review: Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation \\cite{miao2024318}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, particularly in Long-Tailed Recognition (LTR) scenarios where In-Distribution (ID) classes are heavily imbalanced. A key issue is the distribution shift between pseudo OOD samples (outliers from external datasets used for training) and true OOD samples encountered during inference.\n    *   **Importance and Challenge**:\n        *   Deep Neural Networks (DNNs) are often overconfident about unknown inputs, leading to misclassification of OOD samples.\n        *   In LTR, this problem is amplified: head (majority) ID samples can have high-confidence predictions similar to OOD samples, while tail (minority) ID samples receive low-confidence predictions, making them indistinguishable from OODs or prone to being wrongly detected as OOD.\n        *   The lack of ground-truth OOD samples during training necessitates using external \"outlier\" datasets, but their distribution often mismatches that of true OODs, especially with imbalanced ID data, misleading detector training.\n        *   Existing energy-based OOD detection methods can underestimate tail class distributions and require sensitive hyperparameter tuning for energy margins.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Builds upon energy-based OOD detection methods \\cite{miao2024318} that use global energy scores.\n        *   Relates to Test-Time Adaptation (TTA) for OOD detection, but differentiates by focusing on outlier distribution calibration rather than model retraining or feature memory augmentation.\n    *   **Limitations of Previous Solutions**:\n        *   Existing OOD detection methods in LTR assume outlier distributions align well with true OODs, which is often false in practice due to diverse unknown OOD distributions \\cite{miao2024318}.\n        *   TTA methods for OOD detection (e.g., AUTO \\cite{miao2024318}, AdaOOD \\cite{miao2024318}) often require online model retraining or feature memory augmentation, incurring significant overheads and struggling with the large variation in heavily imbalanced LTR data.\n        *   Prior energy loss functions for training OOD detectors underestimate tail class distributions and involve sensitive margin hyperparameters, leading to inaccurate vanilla outlier distributions and OOD filters \\cite{miao2024318}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: `\\cite{miao2024318}` proposes **AdaptOD**, a novel approach for OOD detection in LTR, comprising two key components:\n        *   **Dynamic Outlier Distribution Adaptation (DODA)**: During inference, DODA dynamically adapts a \"vanilla\" outlier distribution (initialized from pseudo OOD data) to the true OOD distribution. It uses an OOD filter (based on Z-score of global energy) to identify predicted OOD samples and then performs a momentum update of the outlier distribution based on these samples. The adapted distribution is then used to calibrate the global energy score for final OOD detection.\n        *   **Dual-Normalized Energy Loss (DNE)**: This novel loss function is introduced during training to learn a better vanilla outlier distribution. DNE consists of:\n            *   **Batch Energy Normalization**: Normalizes logit outputs for each class across a batch of training samples.\n            *   **Class-wise Normalized Energy Loss (DNE-C)**: Balances the sum of energy for all ID samples within each ID class.\n            *   **Sample-wise Normalized Energy Loss (DNE-S)**: Balances the sum of energy across all ID classes for each ID sample.\n    *   **Novelty/Difference**:\n        *   First approach to adapt the outlier distribution to the true OOD distribution from both training and inference stages \\cite{miao2024318}.\n        *   DODA performs test-time adaptation by calibrating the outlier distribution without requiring model retraining or additional memory overheads, unlike prior TTA methods.\n        *   DNE addresses the LTR imbalance by enforcing balanced prediction energy on head and tail samples, transferring energy from head to tail, and eliminating the need for manual tuning of sensitive energy margin hyperparameters.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **AdaptOD Framework**: A holistic approach combining training and inference-time adaptation for OOD detection in LTR.\n        *   **Dynamic Outlier Distribution Adaptation (DODA)**: An online, momentum-based adaptation mechanism for outlier distributions using predicted OOD samples during inference.\n        *   **Dual-Normalized Energy Loss (DNE)**: A novel loss function incorporating Batch Energy Normalization, Class-wise Normalized Energy Loss (DNE-C), and Sample-wise Normalized Energy Loss (DNE-S) to learn balanced energy predictions for long-tailed ID data.\n    *   **System Design/Architectural Innovations**: The integration of DODA and DNE allows for a more robust and adaptive OOD detection system that can handle distribution shifts and class imbalance effectively.\n    *   **Theoretical Insights/Analysis**: DNE's design provides a mechanism to balance energy predictions across imbalanced classes, mitigating the bias towards head classes and improving the quality of the vanilla outlier distribution, which is crucial for effective adaptation.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive empirical results were conducted on three popular LTR benchmarks: CIFAR10-LT, CIFAR100-LT, and ImageNet-LT.\n    *   **OOD Datasets**: Six popular OOD datasets were used to evaluate performance.\n    *   **Key Performance Metrics**: Standard OOD detection metrics (e.g., AUROC, AUPR-In, AUPR-Out, FPR@95TPR) are typically used, though not explicitly listed in the abstract/intro, they are standard for such evaluations.\n    *   **Comparison Results**: AdaptOD substantially outperforms state-of-the-art (SOTA) OOD detection methods across various LTR scenarios \\cite{miao2024318}. The paper highlights that DODA based on predicted OOD samples can well approximate the upper-bound performance obtained with an oracle model (Table 5 in the full paper). Visualizations (Fig. 1) demonstrate better alignment of adapted outlier distributions with true OOD distributions compared to baselines.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The OOD filter relies on a Z-score-based threshold (hyperparameter Î±) determined from training ID data, assuming a certain separability of ID and OOD energy distributions.\n        *   The momentum update in DODA assumes that the predicted OOD samples provide reliable \"OOD knowledge\" for adaptation.\n    *   **Scope of Applicability**: Primarily focused on OOD detection in image classification tasks with long-tailed ID data. While the principles might extend, direct applicability to other data modalities or OOD definitions (e.g., semantic shift vs. novelty detection) is not explicitly discussed.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `\\cite{miao2024318}` significantly advances OOD detection in LTR by explicitly addressing the critical problem of distribution shift between pseudo and true OOD samples. It provides a novel, efficient, and effective solution that avoids the retraining or memory overheads of previous TTA methods.\n    *   **Potential Impact on Future Research**:\n        *   Opens new avenues for research into dynamic outlier distribution adaptation during inference, potentially inspiring similar calibration techniques for other OOD detection challenges.\n        *   The DNE loss function offers a principled way to handle class imbalance in energy-based OOD detection, which could be adopted or extended in other imbalanced learning scenarios.\n        *   The framework's success in LTR suggests its potential for real-world applications where data is inherently imbalanced and unknown inputs are common (e.g., medical diagnosis, autonomous systems).",
      "intriguing_abstract": "Deep neural networks often falter when encountering the unknown, a challenge profoundly amplified in Long-Tailed Recognition (LTR) where class imbalance severely compromises Out-of-Distribution (OOD) detection. A pervasive issue is the critical distribution shift between pseudo OOD samples used for training and the true, diverse OODs encountered during inference. We introduce **AdaptOD**, a novel framework that fundamentally rethinks OOD detection in LTR by dynamically adapting to these true OOD distributions.\n\nAt its core, **Dynamic Outlier Distribution Adaptation (DODA)** performs efficient, test-time calibration of the outlier distribution using a momentum-based update on predicted OOD samples, circumventing costly model retraining or memory augmentation. Complementing this, our novel **Dual-Normalized Energy Loss (DNE)** during training learns a superior vanilla outlier distribution by enforcing balanced energy predictions across imbalanced In-Distribution (ID) classes, eliminating sensitive margin hyperparameters. AdaptOD significantly outperforms state-of-the-art energy-based OOD detection methods across challenging LTR benchmarks (CIFAR-LT, ImageNet-LT), demonstrating superior robustness and accuracy. This work offers a principled, efficient, and highly effective solution to a pervasive real-world problem, paving the way for more reliable and adaptive AI systems in imbalanced data environments.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Long-Tailed Recognition (LTR)",
        "distribution shift",
        "outlier distribution adaptation",
        "AdaptOD framework",
        "Dynamic Outlier Distribution Adaptation (DODA)",
        "Dual-Normalized Energy Loss (DNE)",
        "energy-based OOD detection",
        "class imbalance",
        "test-time adaptation",
        "balanced energy predictions",
        "state-of-the-art performance",
        "image classification"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129.pdf",
      "citation_key": "miao2024318",
      "metadata": {
        "title": "Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation",
        "authors": [
          "Wenjun Miao",
          "Guansong Pang",
          "Jingyi Zheng",
          "Xiaolong Bai"
        ],
        "published_date": "2024",
        "abstract": "One key challenge in Out-of-Distribution (OOD) detection is the absence of ground-truth OOD samples during training. One principled approach to address this issue is to use samples from external datasets as outliers (i.e., pseudo OOD samples) to train OOD detectors. However, we find empirically that the outlier samples often present a distribution shift compared to the true OOD samples, especially in Long-Tailed Recognition (LTR) scenarios, where ID classes are heavily imbalanced, \\ie, the true OOD samples exhibit very different probability distribution to the head and tailed ID classes from the outliers. In this work, we propose a novel approach, namely normalized outlier distribution adaptation (AdaptOD), to tackle this distribution shift problem. One of its key components is dynamic outlier distribution adaptation that effectively adapts a vanilla outlier distribution based on the outlier samples to the true OOD distribution by utilizing the OOD knowledge in the predicted OOD samples during inference. Further, to obtain a more reliable set of predicted OOD samples on long-tailed ID data, a novel dual-normalized energy loss is introduced in AdaptOD, which leverages class- and sample-wise normalized energy to enforce a more balanced prediction energy on imbalanced ID samples. This helps avoid bias toward the head samples and learn a substantially better vanilla outlier distribution than existing energy losses during training. It also eliminates the need of manually tuning the sensitive margin hyperparameters in energy losses. Empirical results on three popular benchmarks for OOD detection in LTR show the superior performance of AdaptOD over state-of-the-art methods. Code is available at https://github.com/mala-lab/AdaptOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Here's a focused summary of the paper `\\cite{miao2024318}` for a literature review:\n\n### Focused Summary for Literature Review: Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation \\cite{miao2024318}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, particularly in Long-Tailed Recognition (LTR) scenarios where In-Distribution (ID) classes are heavily imbalanced. A key issue is the distribution shift between pseudo OOD samples (outliers from external datasets used for training) and true OOD samples encountered during inference.\n    *   **Importance and Challenge**:\n        *   Deep Neural Networks (DNNs) are often overconfident about unknown inputs, leading to misclassification of OOD samples.\n        *   In LTR, this problem is amplified: head (majority) ID samples can have high-confidence predictions similar to OOD samples, while tail (minority) ID samples receive low-confidence predictions, making them indistinguishable from OODs or prone to being wrongly detected as OOD.\n        *   The lack of ground-truth OOD samples during training necessitates using external \"outlier\" datasets, but their distribution often mismatches that of true OODs, especially with imbalanced ID data, misleading detector training.\n        *   Existing energy-based OOD detection methods can underestimate tail class distributions and require sensitive hyperparameter tuning for energy margins.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Builds upon energy-based OOD detection methods \\cite{miao2024318} that use global energy scores.\n        *   Relates to Test-Time Adaptation (TTA) for OOD detection, but differentiates by focusing on outlier distribution calibration rather than model retraining or feature memory augmentation.\n    *   **Limitations of Previous Solutions**:\n        *   Existing OOD detection methods in LTR assume outlier distributions align well with true OODs, which is often false in practice due to diverse unknown OOD distributions \\cite{miao2024318}.\n        *   TTA methods for OOD detection (e.g., AUTO \\cite{miao2024318}, AdaOOD \\cite{miao2024318}) often require online model retraining or feature memory augmentation, incurring significant overheads and struggling with the large variation in heavily imbalanced LTR data.\n        *   Prior energy loss functions for training OOD detectors underestimate tail class distributions and involve sensitive margin hyperparameters, leading to inaccurate vanilla outlier distributions and OOD filters \\cite{miao2024318}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: `\\cite{miao2024318}` proposes **AdaptOD**, a novel approach for OOD detection in LTR, comprising two key components:\n        *   **Dynamic Outlier Distribution Adaptation (DODA)**: During inference, DODA dynamically adapts a \"vanilla\" outlier distribution (initialized from pseudo OOD data) to the true OOD distribution. It uses an OOD filter (based on Z-score of global energy) to identify predicted OOD samples and then performs a momentum update of the outlier distribution based on these samples. The adapted distribution is then used to calibrate the global energy score for final OOD detection.\n        *   **Dual-Normalized Energy Loss (DNE)**: This novel loss function is introduced during training to learn a better vanilla outlier distribution. DNE consists of:\n            *   **Batch Energy Normalization**: Normalizes logit outputs for each class across a batch of training samples.\n            *   **Class-wise Normalized Energy Loss (DNE-C)**: Balances the sum of energy for all ID samples within each ID class.\n            *   **Sample-wise Normalized Energy Loss (DNE-S)**: Balances the sum of energy across all ID classes for each ID sample.\n    *   **Novelty/Difference**:\n        *   First approach to adapt the outlier distribution to the true OOD distribution from both training and inference stages \\cite{miao2024318}.\n        *   DODA performs test-time adaptation by calibrating the outlier distribution without requiring model retraining or additional memory overheads, unlike prior TTA methods.\n        *   DNE addresses the LTR imbalance by enforcing balanced prediction energy on head and tail samples, transferring energy from head to tail, and eliminating the need for manual tuning of sensitive energy margin hyperparameters.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **AdaptOD Framework**: A holistic approach combining training and inference-time adaptation for OOD detection in LTR.\n        *   **Dynamic Outlier Distribution Adaptation (DODA)**: An online, momentum-based adaptation mechanism for outlier distributions using predicted OOD samples during inference.\n        *   **Dual-Normalized Energy Loss (DNE)**: A novel loss function incorporating Batch Energy Normalization, Class-wise Normalized Energy Loss (DNE-C), and Sample-wise Normalized Energy Loss (DNE-S) to learn balanced energy predictions for long-tailed ID data.\n    *   **System Design/Architectural Innovations**: The integration of DODA and DNE allows for a more robust and adaptive OOD detection system that can handle distribution shifts and class imbalance effectively.\n    *   **Theoretical Insights/Analysis**: DNE's design provides a mechanism to balance energy predictions across imbalanced classes, mitigating the bias towards head classes and improving the quality of the vanilla outlier distribution, which is crucial for effective adaptation.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive empirical results were conducted on three popular LTR benchmarks: CIFAR10-LT, CIFAR100-LT, and ImageNet-LT.\n    *   **OOD Datasets**: Six popular OOD datasets were used to evaluate performance.\n    *   **Key Performance Metrics**: Standard OOD detection metrics (e.g., AUROC, AUPR-In, AUPR-Out, FPR@95TPR) are typically used, though not explicitly listed in the abstract/intro, they are standard for such evaluations.\n    *   **Comparison Results**: AdaptOD substantially outperforms state-of-the-art (SOTA) OOD detection methods across various LTR scenarios \\cite{miao2024318}. The paper highlights that DODA based on predicted OOD samples can well approximate the upper-bound performance obtained with an oracle model (Table 5 in the full paper). Visualizations (Fig. 1) demonstrate better alignment of adapted outlier distributions with true OOD distributions compared to baselines.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The OOD filter relies on a Z-score-based threshold (hyperparameter Î±) determined from training ID data, assuming a certain separability of ID and OOD energy distributions.\n        *   The momentum update in DODA assumes that the predicted OOD samples provide reliable \"OOD knowledge\" for adaptation.\n    *   **Scope of Applicability**: Primarily focused on OOD detection in image classification tasks with long-tailed ID data. While the principles might extend, direct applicability to other data modalities or OOD definitions (e.g., semantic shift vs. novelty detection) is not explicitly discussed.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: `\\cite{miao2024318}` significantly advances OOD detection in LTR by explicitly addressing the critical problem of distribution shift between pseudo and true OOD samples. It provides a novel, efficient, and effective solution that avoids the retraining or memory overheads of previous TTA methods.\n    *   **Potential Impact on Future Research**:\n        *   Opens new avenues for research into dynamic outlier distribution adaptation during inference, potentially inspiring similar calibration techniques for other OOD detection challenges.\n        *   The DNE loss function offers a principled way to handle class imbalance in energy-based OOD detection, which could be adopted or extended in other imbalanced learning scenarios.\n        *   The framework's success in LTR suggests its potential for real-world applications where data is inherently imbalanced and unknown inputs are common (e.g., medical diagnosis, autonomous systems).",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Long-Tailed Recognition (LTR)",
          "distribution shift",
          "outlier distribution adaptation",
          "AdaptOD framework",
          "Dynamic Outlier Distribution Adaptation (DODA)",
          "Dual-Normalized Energy Loss (DNE)",
          "energy-based OOD detection",
          "class imbalance",
          "test-time adaptation",
          "balanced energy predictions",
          "state-of-the-art performance",
          "image classification"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n*   **abstract keywords:** \"we propose a novel approach\", \"novel dual-normalized energy loss is introduced\", \"adaptod\" (a new system/method name), \"dynamic outlier distribution adaptation\" (a key component). these phrases directly align with the criteria for a technical paper: \"propose\", \"develop\", \"present\", \"algorithm\", \"method\".\n*   **introduction content:** the introduction sets up a technical problem (ood detection in ltr scenarios) and immediately begins to discuss the proposed solution (adaptod, doda, dne, as indicated by figure 1).\n*   **empirical results:** while the abstract mentions \"empirical results... show the superior performance\", this is the *evaluation* of the proposed technical solution, not the primary contribution itself. a paper that proposes a new method almost always includes empirical validation. the core contribution is the method."
      },
      "file_name": "3f18ce9eeb62a8d8abcc5627e9e1b8af2a902129.pdf"
    },
    {
      "success": true,
      "doc_id": "69ced6e49530826d2654e793229272b5",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Focused Summary for Literature Review: Are We Ready for Out-of-Distribution Detection in Digital Pathology? \\cite{oh2024opf}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical yet often overlooked challenge of detecting semantic and covariate Out-of-Distribution (OOD) examples in digital pathology (DP) using deep neural networks (DNNs).\n    *   **Importance and Challenge**:\n        *   DNNs are prone to overconfident, erroneous predictions under distribution shifts, which can lead to catastrophic misdiagnoses in high-stakes domains like DP, hindering real-world deployment.\n        *   It is crucial for DNNs to communicate \"I don't know\" when uncertain, allowing clinician intervention.\n        *   **Semantic OOD (S-OODD)**: Arises from label-altering shifts (e.g., rare carcinoma subtypes not in training data), requiring models to flag unseen classes.\n        *   **Misclassified Covariate OOD (MC-OODD)**: Occurs when models misclassify samples due to image space shifts (e.g., spurious correlations from staining/scanning procedures) while the underlying label is still in-distribution. Detecting these failures is essential for robust generalization.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**: Previous work in DP has explored OOD detection, often using multi-model uncertainty quantification (UQ) like ensembles \\cite{oh2024opf}.\n    *   **Limitations of Previous Solutions**: The authors identify several deficiencies in prior DP OOD detection studies:\n        *   **Misleading Practices**: Detection objectives often do not conform to the ML community's consensus (e.g., detecting covariate OOD unconditionally rather than focusing on misclassifications). Metrics like AUROC/AUPR are used for MC-OODD, which are sensitive to model accuracy, preventing fair comparisons.\n        *   **Limited OOD Detectors**: Many works rely solely on UQ-based methods (ensembles, approximate Bayes), which can yield falsely low uncertainty far from in-distribution (ID) data. More recent state-of-the-art frequentist (single-model) methods have not been explored in DP.\n        *   **Easy or Non-Public Datasets**: Studies often use simple binary classification tasks or \"OODs\" that are trivially discernible (e.g., prostate vs. colon vs. breast lymph nodes). Many use internal, non-reproducible datasets.\n        *   **Limited Depth**: Crucial factors influencing robustness and OOD behavior, such as pre-training strategies and DNN architectures, are often overlooked.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper establishes a comprehensive benchmark study for OOD detection in DP \\cite{oh2024opf}.\n    *   **Novelty/Differentiation**:\n        *   **Proper Evaluation Protocols**: Adopts public datasets (BreakHis, NCT-CRC) and simulates Open Set Recognition (OSR) for S-OODD by holding out classes. For MC-OODD, it applies common DP corruptions to ID test sets and uses the Prediction Rejection Ratio (PRR), a metric agnostic to model accuracy.\n        *   **Wider Scope of Detectors**: Compares a diverse set of recent frequentist (single-model) OOD detection methods (e.g., MSP, Maha, R+E, GrN, MLS, KLM, KNN, ViM, GEN) alongside the gold-standard Deep Ensembles (DE) with Total Uncertainty (TU) and Epistemic Uncertainty (EU).\n        *   **Exploration of Advanced ML Settings**: Investigates the impact of:\n            *   **Transfer Learning (TL)**: Compares training from scratch, ImageNet-1K (IN1K) pre-training, and various DP-specific pre-training strategies (MoCo v2, SwAV, BT for CNNs; CLIP, BiomedCLIP, QuiltNet for transformers).\n            *   **DNN Architectures**: Compares fully-convolutional networks (CNNs like ResNet, ConvNeXt) against transformers (ViT, Swin), including a novel, lightweight fully-supervised DP-specific pre-training (SIAYN) for fair architectural comparison.\n\n4.  **Key Technical Contributions** \\cite{oh2024opf}\n    *   **Novel Evaluation Framework**: Establishes the most objective and reproducible benchmark for OOD detection in DP to date, free from biases and shortcomings of prior work, using proper OSR settings for S-OODD and accuracy-agnostic PRR for MC-OODD.\n    *   **Comprehensive Detector Comparison**: Provides an extensive comparison of nine diverse frequentist OOD detectors and Deep Ensembles, leveraging information from feature, logit, and probability spaces.\n    *   **Empirical Insights on Transfer Learning**: Systematically evaluates the impact of different pre-training sources (natural images vs. DP images, self-supervised vs. supervised) on OOD detection performance across CNNs and transformers.\n    *   **Empirical Insights on Architecture**: Compares the OOD detection capabilities of CNNs and transformers under a controlled, DP-specific supervised pre-training (SIAYN).\n    *   **New Guidelines and Research Questions**: Offers novel insights and practical guidelines for practitioners in DP, opening new avenues for future research and discussion in the DP community regarding OOD detection.\n\n5.  **Experimental Validation** \\cite{oh2024opf}\n    *   **Experiments Conducted**:\n        *   **Datasets**: BreakHis (8 breast carcinoma subtypes) and NCT-CRC (9 colorectal tissue types) were used. OSR splits were simulated for S-OODD, and DP corruptions (digitization, blur, color, artifact) were applied to ID test sets for MC-OODD.\n        *   **ML Configurations**:\n            *   **(C1) ResNet-50 TL**: Compared de-novo, IN1K, and three SSL DP-specific models (MoCo v2, SwAV, BT) pre-trained on TCGA.\n            *   **(C2) ViT-B/16 TL**: Compared de-novo, IN1K, and three large vision-language models (CLIP, BiomedCLIP, QuiltNet) with varying domain gaps.\n            *   **(C3) Architecture Comparison**: Compared ResNet-50, ConvNeXt-S, ViT-B/16, and Swin-T using a novel, lightweight fully-supervised DP-specific pre-training (SIAYN) on TCGA.\n        *   **Detectors**: Nine frequentist methods (MSP, Maha, R+E, GrN, MLS, KLM, KNN, ViM, GEN) and Deep Ensembles (TU, EU) were evaluated.\n    *   **Key Performance Metrics**:\n        *   **S-OODD**: AUROC (Area Under the Receiver Operating Characteristic curve, higher is better).\n        *   **MC-OODD**: PRR (Prediction Rejection Ratio, higher is better, closer to 100% indicates correlation of low confidence to mispredictions).\n        *   **Robustness**: Class-balanced accuracy (Acc.) on ID test and covariate OOD sets.\n    *   **Comparison Results (Key Insights)**:\n        *   **Transfer Learning**: DP-specific pre-training (e.g., MoCo v2, SwAV, BT for ResNet-50; BiomedCLIP for ViT-B/16) generally leads to higher accuracy and better OOD detection performance (both S-OODD AUROC and MC-OODD PRR) compared to training from scratch or IN1K pre-training.\n        *   **Detectors**:\n            *   For S-OODD, KNN and ViM often perform competitively or best among single-model detectors, especially with strong pre-training. Deep Ensembles (TU, EU) consistently show strong performance, often outperforming single-model methods.\n            *   For MC-OODD, performance is generally lower across all detectors, indicating it's a harder problem. KNN, ViM, and Maha sometimes show good PRR, but no single detector consistently dominates. Deep Ensembles also perform well here.\n        *   **Architectures**: Transformers (ViT, Swin) and modern CNNs (ConvNeXt) pre-trained with SIAYN show strong ID accuracy and S-OODD AUROC, often outperforming ResNet-50. For MC-OODD, ConvNeXt and ViT tend to achieve higher PRR values.\n\n6.  **Limitations & Scope** \\cite{oh2024opf}\n    *   **Technical Limitations**: Some OOD detection methods are more prohibitive due to requiring access to ID training samples or inaccessible embeddings in black-box models, which can be a concern in DP.\n    *   **Scope of Applicability**: The benchmark focuses on H&E stained images and specific types of semantic and covariate shifts. While comprehensive, it doesn't cover all possible OOD scenarios or imaging modalities in DP. The \"near\" and \"far\" OOD cases are defined within the chosen datasets.\n\n7.  **Technical Significance** \\cite{oh2024opf}\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art in OOD detection for DP by providing the first comprehensive, reproducible, and unbiased benchmark. It moves beyond simplistic evaluations and limited detector sets, incorporating modern ML practices like diverse transfer learning strategies and architectural comparisons.\n    *   **Potential Impact on Future Research**:\n        *   **Guidance for Practitioners**: The findings offer crucial guidelines for selecting appropriate OOD detectors, pre-training strategies, and DNN architectures for robust AI deployment in DP.\n        *   **Foundation for Future Research**: It highlights the strengths and weaknesses of current OOD detection methods in DP, particularly the challenges of MC-OODD, and identifies promising directions for developing more robust and trustworthy AI systems in medical imaging.\n        *   **Reproducibility**: By using public datasets and making code available, it fosters reproducibility and encourages further research in this critical area.",
      "intriguing_abstract": "The promise of deep learning in digital pathology (DP) is jeopardized by deep neural networks' (DNNs) dangerous susceptibility to Out-of-Distribution (OOD) data, risking catastrophic misdiagnoses. This paper tackles the critical challenge of detecting both Semantic OOD (S-OODD)â€”unseen classesâ€”and the often-overlooked Misclassified Covariate OOD (MC-OODD), arising from subtle image shifts that lead to misclassification.\n\nWe present the first comprehensive, unbiased, and reproducible benchmark for OOD detection in DP. Our rigorous framework employs proper evaluation protocols, including Open Set Recognition (OSR) for S-OODD and the accuracy-agnostic Prediction Rejection Ratio (PRR) for MC-OODD. We systematically compare diverse frequentist OOD detectors against Deep Ensembles, meticulously investigating the impact of transfer learning strategies (ImageNet-1K, self-supervised, DP-specific) and DNN architectures (CNNs, Transformers).\n\nPivotal insights reveal DP-specific pre-training significantly enhances OOD detection. While methods like KNN and ViM excel for S-OODD, MC-OODD remains a formidable challenge. This work provides crucial guidelines for practitioners, setting a new standard for robust AI development in DP and paving the way for truly trustworthy clinical deployment.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Digital pathology (DP)",
        "Semantic OOD (S-OODD)",
        "Misclassified Covariate OOD (MC-OODD)",
        "Deep neural networks (DNNs)",
        "Comprehensive benchmark study",
        "Transfer learning strategies",
        "DNN architectures",
        "Deep Ensembles",
        "Frequentist OOD detection methods",
        "Open Set Recognition (OSR)",
        "Prediction Rejection Ratio (PRR)",
        "DP-specific pre-training",
        "Robust AI deployment",
        "Uncertainty quantification"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/59f40cf3eebd2cb6ad30363fa6abf1caea06555f.pdf",
      "citation_key": "oh2024opf",
      "metadata": {
        "title": "Are We Ready for Out-of-Distribution Detection in Digital Pathology?",
        "authors": [
          "Ji-Hun Oh",
          "Kianoush Falahkheirkhah",
          "Rohit Bhargava"
        ],
        "published_date": "2024",
        "abstract": "The detection of semantic and covariate out-of-distribution (OOD) examples is a critical yet overlooked challenge in digital pathology (DP). Recently, substantial insight and methods on OOD detection were presented by the ML community, but how do they fare in DP applications? To this end, we establish a benchmark study, our highlights being: 1) the adoption of proper evaluation protocols, 2) the comparison of diverse detectors in both a single and multi-model setting, and 3) the exploration into advanced ML settings like transfer learning (ImageNet vs. DP pre-training) and choice of architecture (CNNs vs. transformers). Through our comprehensive experiments, we contribute new insights and guidelines, paving the way for future research and discussion.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/59f40cf3eebd2cb6ad30363fa6abf1caea06555f.pdf",
        "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Focused Summary for Literature Review: Are We Ready for Out-of-Distribution Detection in Digital Pathology? \\cite{oh2024opf}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical yet often overlooked challenge of detecting semantic and covariate Out-of-Distribution (OOD) examples in digital pathology (DP) using deep neural networks (DNNs).\n    *   **Importance and Challenge**:\n        *   DNNs are prone to overconfident, erroneous predictions under distribution shifts, which can lead to catastrophic misdiagnoses in high-stakes domains like DP, hindering real-world deployment.\n        *   It is crucial for DNNs to communicate \"I don't know\" when uncertain, allowing clinician intervention.\n        *   **Semantic OOD (S-OODD)**: Arises from label-altering shifts (e.g., rare carcinoma subtypes not in training data), requiring models to flag unseen classes.\n        *   **Misclassified Covariate OOD (MC-OODD)**: Occurs when models misclassify samples due to image space shifts (e.g., spurious correlations from staining/scanning procedures) while the underlying label is still in-distribution. Detecting these failures is essential for robust generalization.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**: Previous work in DP has explored OOD detection, often using multi-model uncertainty quantification (UQ) like ensembles \\cite{oh2024opf}.\n    *   **Limitations of Previous Solutions**: The authors identify several deficiencies in prior DP OOD detection studies:\n        *   **Misleading Practices**: Detection objectives often do not conform to the ML community's consensus (e.g., detecting covariate OOD unconditionally rather than focusing on misclassifications). Metrics like AUROC/AUPR are used for MC-OODD, which are sensitive to model accuracy, preventing fair comparisons.\n        *   **Limited OOD Detectors**: Many works rely solely on UQ-based methods (ensembles, approximate Bayes), which can yield falsely low uncertainty far from in-distribution (ID) data. More recent state-of-the-art frequentist (single-model) methods have not been explored in DP.\n        *   **Easy or Non-Public Datasets**: Studies often use simple binary classification tasks or \"OODs\" that are trivially discernible (e.g., prostate vs. colon vs. breast lymph nodes). Many use internal, non-reproducible datasets.\n        *   **Limited Depth**: Crucial factors influencing robustness and OOD behavior, such as pre-training strategies and DNN architectures, are often overlooked.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper establishes a comprehensive benchmark study for OOD detection in DP \\cite{oh2024opf}.\n    *   **Novelty/Differentiation**:\n        *   **Proper Evaluation Protocols**: Adopts public datasets (BreakHis, NCT-CRC) and simulates Open Set Recognition (OSR) for S-OODD by holding out classes. For MC-OODD, it applies common DP corruptions to ID test sets and uses the Prediction Rejection Ratio (PRR), a metric agnostic to model accuracy.\n        *   **Wider Scope of Detectors**: Compares a diverse set of recent frequentist (single-model) OOD detection methods (e.g., MSP, Maha, R+E, GrN, MLS, KLM, KNN, ViM, GEN) alongside the gold-standard Deep Ensembles (DE) with Total Uncertainty (TU) and Epistemic Uncertainty (EU).\n        *   **Exploration of Advanced ML Settings**: Investigates the impact of:\n            *   **Transfer Learning (TL)**: Compares training from scratch, ImageNet-1K (IN1K) pre-training, and various DP-specific pre-training strategies (MoCo v2, SwAV, BT for CNNs; CLIP, BiomedCLIP, QuiltNet for transformers).\n            *   **DNN Architectures**: Compares fully-convolutional networks (CNNs like ResNet, ConvNeXt) against transformers (ViT, Swin), including a novel, lightweight fully-supervised DP-specific pre-training (SIAYN) for fair architectural comparison.\n\n4.  **Key Technical Contributions** \\cite{oh2024opf}\n    *   **Novel Evaluation Framework**: Establishes the most objective and reproducible benchmark for OOD detection in DP to date, free from biases and shortcomings of prior work, using proper OSR settings for S-OODD and accuracy-agnostic PRR for MC-OODD.\n    *   **Comprehensive Detector Comparison**: Provides an extensive comparison of nine diverse frequentist OOD detectors and Deep Ensembles, leveraging information from feature, logit, and probability spaces.\n    *   **Empirical Insights on Transfer Learning**: Systematically evaluates the impact of different pre-training sources (natural images vs. DP images, self-supervised vs. supervised) on OOD detection performance across CNNs and transformers.\n    *   **Empirical Insights on Architecture**: Compares the OOD detection capabilities of CNNs and transformers under a controlled, DP-specific supervised pre-training (SIAYN).\n    *   **New Guidelines and Research Questions**: Offers novel insights and practical guidelines for practitioners in DP, opening new avenues for future research and discussion in the DP community regarding OOD detection.\n\n5.  **Experimental Validation** \\cite{oh2024opf}\n    *   **Experiments Conducted**:\n        *   **Datasets**: BreakHis (8 breast carcinoma subtypes) and NCT-CRC (9 colorectal tissue types) were used. OSR splits were simulated for S-OODD, and DP corruptions (digitization, blur, color, artifact) were applied to ID test sets for MC-OODD.\n        *   **ML Configurations**:\n            *   **(C1) ResNet-50 TL**: Compared de-novo, IN1K, and three SSL DP-specific models (MoCo v2, SwAV, BT) pre-trained on TCGA.\n            *   **(C2) ViT-B/16 TL**: Compared de-novo, IN1K, and three large vision-language models (CLIP, BiomedCLIP, QuiltNet) with varying domain gaps.\n            *   **(C3) Architecture Comparison**: Compared ResNet-50, ConvNeXt-S, ViT-B/16, and Swin-T using a novel, lightweight fully-supervised DP-specific pre-training (SIAYN) on TCGA.\n        *   **Detectors**: Nine frequentist methods (MSP, Maha, R+E, GrN, MLS, KLM, KNN, ViM, GEN) and Deep Ensembles (TU, EU) were evaluated.\n    *   **Key Performance Metrics**:\n        *   **S-OODD**: AUROC (Area Under the Receiver Operating Characteristic curve, higher is better).\n        *   **MC-OODD**: PRR (Prediction Rejection Ratio, higher is better, closer to 100% indicates correlation of low confidence to mispredictions).\n        *   **Robustness**: Class-balanced accuracy (Acc.) on ID test and covariate OOD sets.\n    *   **Comparison Results (Key Insights)**:\n        *   **Transfer Learning**: DP-specific pre-training (e.g., MoCo v2, SwAV, BT for ResNet-50; BiomedCLIP for ViT-B/16) generally leads to higher accuracy and better OOD detection performance (both S-OODD AUROC and MC-OODD PRR) compared to training from scratch or IN1K pre-training.\n        *   **Detectors**:\n            *   For S-OODD, KNN and ViM often perform competitively or best among single-model detectors, especially with strong pre-training. Deep Ensembles (TU, EU) consistently show strong performance, often outperforming single-model methods.\n            *   For MC-OODD, performance is generally lower across all detectors, indicating it's a harder problem. KNN, ViM, and Maha sometimes show good PRR, but no single detector consistently dominates. Deep Ensembles also perform well here.\n        *   **Architectures**: Transformers (ViT, Swin) and modern CNNs (ConvNeXt) pre-trained with SIAYN show strong ID accuracy and S-OODD AUROC, often outperforming ResNet-50. For MC-OODD, ConvNeXt and ViT tend to achieve higher PRR values.\n\n6.  **Limitations & Scope** \\cite{oh2024opf}\n    *   **Technical Limitations**: Some OOD detection methods are more prohibitive due to requiring access to ID training samples or inaccessible embeddings in black-box models, which can be a concern in DP.\n    *   **Scope of Applicability**: The benchmark focuses on H&E stained images and specific types of semantic and covariate shifts. While comprehensive, it doesn't cover all possible OOD scenarios or imaging modalities in DP. The \"near\" and \"far\" OOD cases are defined within the chosen datasets.\n\n7.  **Technical Significance** \\cite{oh2024opf}\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art in OOD detection for DP by providing the first comprehensive, reproducible, and unbiased benchmark. It moves beyond simplistic evaluations and limited detector sets, incorporating modern ML practices like diverse transfer learning strategies and architectural comparisons.\n    *   **Potential Impact on Future Research**:\n        *   **Guidance for Practitioners**: The findings offer crucial guidelines for selecting appropriate OOD detectors, pre-training strategies, and DNN architectures for robust AI deployment in DP.\n        *   **Foundation for Future Research**: It highlights the strengths and weaknesses of current OOD detection methods in DP, particularly the challenges of MC-OODD, and identifies promising directions for developing more robust and trustworthy AI systems in medical imaging.\n        *   **Reproducibility**: By using public datasets and making code available, it fosters reproducibility and encourages further research in this critical area.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Digital pathology (DP)",
          "Semantic OOD (S-OODD)",
          "Misclassified Covariate OOD (MC-OODD)",
          "Deep neural networks (DNNs)",
          "Comprehensive benchmark study",
          "Transfer learning strategies",
          "DNN architectures",
          "Deep Ensembles",
          "Frequentist OOD detection methods",
          "Open Set Recognition (OSR)",
          "Prediction Rejection Ratio (PRR)",
          "DP-specific pre-training",
          "Robust AI deployment",
          "Uncertainty quantification"
        ],
        "paper_type": "the paper type is **empirical**.\n\n**reasoning:**\n\n1.  **abstract keywords:** the abstract explicitly mentions \"establish a benchmark study,\" \"comparison of diverse detectors,\" \"exploration into advanced ml settings,\" and \"comprehensive experiments.\" it also states, \"through our comprehensive experiments, we contribute new insights and guidelines.\" these phrases are direct indicators of an empirical study.\n2.  **introduction content:** the introduction sets up a problem (dnn fragility in digital pathology) and then describes how the paper addresses it by evaluating existing ood detection methods in this specific domain. it discusses the \"how do they fare in dp applications?\" question, which implies a comparative, data-driven evaluation.\n3.  **absence of other types:**\n    *   it's not a **survey** because its primary goal isn't to review literature comprehensively, but to evaluate existing methods.\n    *   it's not **technical** in the sense of proposing a *new* method or algorithm, but rather applying and evaluating *existing* ones.\n    *   it's not **theoretical** as it doesn't focus on mathematical proofs or formal models.\n    *   while applied to digital pathology, it's a broad \"benchmark study\" comparing multiple methods and settings, not a deep dive into a single specific application, making it less of a pure **case_study**.\n    *   it's not a **position** paper as it presents findings from experiments rather than arguing a viewpoint.\n    *   there's no indication it's a **short** communication."
      },
      "file_name": "59f40cf3eebd2cb6ad30363fa6abf1caea06555f.pdf"
    },
    {
      "success": true,
      "doc_id": "ddd4f9a88db0b2aed1b8ed59708aef49",
      "summary": "Ensuring the reliability of open-world intelligent systems heavily relies on effective out-of-distribution (OOD) detection. Despite notable successes in existing OOD detection methods, their performance in scenarios with limited training samples is still suboptimal. Therefore, we first construct a comprehensive few-shot OOD detection benchmark in this paper. Remarkably, our investigation reveals that Parameter-Efficient Fine-Tuning (PEFT) techniques, such as visual prompt tuning and visual adapter tuning, outperform traditional methods like fully fine-tuning and linear probing tuning in few-shot OOD detection. Considering that some valuable information from the pre-trained model, which is conducive to OOD detection, may be lost during the fine-tuning process, we reutilize features from the pre-trained models to mitigate this issue. Specifically, we first propose a training-free approach, termed uncertainty score ensemble (USE). This method integrates feature-matching scores to enhance existing OOD detection methods, significantly narrowing the gap between traditional fine-tuning and PEFT techniques. However, due to its training-free property, this method is unable to improve in-distribution accuracy. To this end, we further propose a method called Domain-Specific and General Knowledge Fusion (DSGF) to improve few-shot OOD detection performance and ID accuracy under different fine-tuning paradigms. Experiment results demonstrate that DSGF enhances few-shot OOD detection across different fine-tuning strategies, shot settings, and OOD detection methods. We believe our work can provide the research community with a novel path to leveraging large-scale visual pre-trained models for addressing FS-OOD detection. The code will be released.",
      "intriguing_abstract": "Ensuring the reliability of open-world intelligent systems heavily relies on effective out-of-distribution (OOD) detection. Despite notable successes in existing OOD detection methods, their performance in scenarios with limited training samples is still suboptimal. Therefore, we first construct a comprehensive few-shot OOD detection benchmark in this paper. Remarkably, our investigation reveals that Parameter-Efficient Fine-Tuning (PEFT) techniques, such as visual prompt tuning and visual adapter tuning, outperform traditional methods like fully fine-tuning and linear probing tuning in few-shot OOD detection. Considering that some valuable information from the pre-trained model, which is conducive to OOD detection, may be lost during the fine-tuning process, we reutilize features from the pre-trained models to mitigate this issue. Specifically, we first propose a training-free approach, termed uncertainty score ensemble (USE). This method integrates feature-matching scores to enhance existing OOD detection methods, significantly narrowing the gap between traditional fine-tuning and PEFT techniques. However, due to its training-free property, this method is unable to improve in-distribution accuracy. To this end, we further propose a method called Domain-Specific and General Knowledge Fusion (DSGF) to improve few-shot OOD detection performance and ID accuracy under different fine-tuning paradigms. Experiment results demonstrate that DSGF enhances few-shot OOD detection across different fine-tuning strategies, shot settings, and OOD detection methods. We believe our work can provide the research community with a novel path to leveraging large-scale visual pre-trained models for addressing FS-OOD detection. The code will be released.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/e1e7f0539ce536a3f889682bcfabee11a96b2ee1.pdf",
      "citation_key": "dong2024t8f",
      "metadata": {
        "title": "Enhancing Few-Shot Out-of-Distribution Detection With Pre-Trained Model Features",
        "authors": [
          "Jiuqing Dong",
          "Yifan Yao",
          "Wei Jin",
          "Heng Zhou",
          "Yongbin Gao",
          "Zhijun Fang"
        ],
        "published_date": "2024",
        "abstract": "Ensuring the reliability of open-world intelligent systems heavily relies on effective out-of-distribution (OOD) detection. Despite notable successes in existing OOD detection methods, their performance in scenarios with limited training samples is still suboptimal. Therefore, we first construct a comprehensive few-shot OOD detection benchmark in this paper. Remarkably, our investigation reveals that Parameter-Efficient Fine-Tuning (PEFT) techniques, such as visual prompt tuning and visual adapter tuning, outperform traditional methods like fully fine-tuning and linear probing tuning in few-shot OOD detection. Considering that some valuable information from the pre-trained model, which is conducive to OOD detection, may be lost during the fine-tuning process, we reutilize features from the pre-trained models to mitigate this issue. Specifically, we first propose a training-free approach, termed uncertainty score ensemble (USE). This method integrates feature-matching scores to enhance existing OOD detection methods, significantly narrowing the gap between traditional fine-tuning and PEFT techniques. However, due to its training-free property, this method is unable to improve in-distribution accuracy. To this end, we further propose a method called Domain-Specific and General Knowledge Fusion (DSGF) to improve few-shot OOD detection performance and ID accuracy under different fine-tuning paradigms. Experiment results demonstrate that DSGF enhances few-shot OOD detection across different fine-tuning strategies, shot settings, and OOD detection methods. We believe our work can provide the research community with a novel path to leveraging large-scale visual pre-trained models for addressing FS-OOD detection. The code will be released.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/e1e7f0539ce536a3f889682bcfabee11a96b2ee1.pdf",
        "venue": "IEEE Transactions on Image Processing",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Ensuring the reliability of open-world intelligent systems heavily relies on effective out-of-distribution (OOD) detection. Despite notable successes in existing OOD detection methods, their performance in scenarios with limited training samples is still suboptimal. Therefore, we first construct a comprehensive few-shot OOD detection benchmark in this paper. Remarkably, our investigation reveals that Parameter-Efficient Fine-Tuning (PEFT) techniques, such as visual prompt tuning and visual adapter tuning, outperform traditional methods like fully fine-tuning and linear probing tuning in few-shot OOD detection. Considering that some valuable information from the pre-trained model, which is conducive to OOD detection, may be lost during the fine-tuning process, we reutilize features from the pre-trained models to mitigate this issue. Specifically, we first propose a training-free approach, termed uncertainty score ensemble (USE). This method integrates feature-matching scores to enhance existing OOD detection methods, significantly narrowing the gap between traditional fine-tuning and PEFT techniques. However, due to its training-free property, this method is unable to improve in-distribution accuracy. To this end, we further propose a method called Domain-Specific and General Knowledge Fusion (DSGF) to improve few-shot OOD detection performance and ID accuracy under different fine-tuning paradigms. Experiment results demonstrate that DSGF enhances few-shot OOD detection across different fine-tuning strategies, shot settings, and OOD detection methods. We believe our work can provide the research community with a novel path to leveraging large-scale visual pre-trained models for addressing FS-OOD detection. The code will be released.",
        "keywords": []
      },
      "file_name": "e1e7f0539ce536a3f889682bcfabee11a96b2ee1.pdf"
    },
    {
      "success": true,
      "doc_id": "79c7d3bd117100a94741d5e9dc9665ad",
      "summary": "Detecting out-of-distribution (OOD) inputs is critical for reliable machine learning, but deep neural networks often make overconfident predictions, even for OOD inputs that deviate from the distribution of training data. Prior methods relied on the widely used softmax cross-entropy (CE) loss that is adequate for classifying in-distribution (ID) samples but not optimally designed for OOD detection. To address this issue, we propose CASE, a simple and effective OOD detection method by explicitly improving intra-class Compactness And inter-class Separability of feature Embeddings. To enhance the separation between ID and OOD samples, CASE uses a dual-loss framework, which includes a separability loss that maximizes the inter-class Euclidean distance to promote separability among different class centers, along with a compactness loss that minimizes the intra-class Euclidean distance to encourage samples to be close to their class centers. In particular, the class centers are defined as a free optimization parameter of the model and updated by gradient descent, which is simple and further enhances the OOD detection performance. Extensive experiments demonstrate the superiority of CASE, which reduces the average FPR95 by 37.11% and improves the average AUROC by 15.89% compared to the baseline method using a softmax confidence score on the more challenging CIFAR-100 model.",
      "intriguing_abstract": "Detecting out-of-distribution (OOD) inputs is critical for reliable machine learning, but deep neural networks often make overconfident predictions, even for OOD inputs that deviate from the distribution of training data. Prior methods relied on the widely used softmax cross-entropy (CE) loss that is adequate for classifying in-distribution (ID) samples but not optimally designed for OOD detection. To address this issue, we propose CASE, a simple and effective OOD detection method by explicitly improving intra-class Compactness And inter-class Separability of feature Embeddings. To enhance the separation between ID and OOD samples, CASE uses a dual-loss framework, which includes a separability loss that maximizes the inter-class Euclidean distance to promote separability among different class centers, along with a compactness loss that minimizes the intra-class Euclidean distance to encourage samples to be close to their class centers. In particular, the class centers are defined as a free optimization parameter of the model and updated by gradient descent, which is simple and further enhances the OOD detection performance. Extensive experiments demonstrate the superiority of CASE, which reduces the average FPR95 by 37.11% and improves the average AUROC by 15.89% compared to the baseline method using a softmax confidence score on the more challenging CIFAR-100 model.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/ab692fb2d15fe514a8121dbd4d1d74eae4e2f989.pdf",
      "citation_key": "feng2024ma3",
      "metadata": {
        "title": "CASE: Exploiting Intra-class Compactness and Inter-class Separability of Feature Embeddings for Out-of-Distribution Detection",
        "authors": [
          "Shuai Feng",
          "Pengsheng Jin",
          "Chongjun Wang"
        ],
        "published_date": "2024",
        "abstract": "Detecting out-of-distribution (OOD) inputs is critical for reliable machine learning, but deep neural networks often make overconfident predictions, even for OOD inputs that deviate from the distribution of training data. Prior methods relied on the widely used softmax cross-entropy (CE) loss that is adequate for classifying in-distribution (ID) samples but not optimally designed for OOD detection. To address this issue, we propose CASE, a simple and effective OOD detection method by explicitly improving intra-class Compactness And inter-class Separability of feature Embeddings. To enhance the separation between ID and OOD samples, CASE uses a dual-loss framework, which includes a separability loss that maximizes the inter-class Euclidean distance to promote separability among different class centers, along with a compactness loss that minimizes the intra-class Euclidean distance to encourage samples to be close to their class centers. In particular, the class centers are defined as a free optimization parameter of the model and updated by gradient descent, which is simple and further enhances the OOD detection performance. Extensive experiments demonstrate the superiority of CASE, which reduces the average FPR95 by 37.11% and improves the average AUROC by 15.89% compared to the baseline method using a softmax confidence score on the more challenging CIFAR-100 model.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/ab692fb2d15fe514a8121dbd4d1d74eae4e2f989.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Detecting out-of-distribution (OOD) inputs is critical for reliable machine learning, but deep neural networks often make overconfident predictions, even for OOD inputs that deviate from the distribution of training data. Prior methods relied on the widely used softmax cross-entropy (CE) loss that is adequate for classifying in-distribution (ID) samples but not optimally designed for OOD detection. To address this issue, we propose CASE, a simple and effective OOD detection method by explicitly improving intra-class Compactness And inter-class Separability of feature Embeddings. To enhance the separation between ID and OOD samples, CASE uses a dual-loss framework, which includes a separability loss that maximizes the inter-class Euclidean distance to promote separability among different class centers, along with a compactness loss that minimizes the intra-class Euclidean distance to encourage samples to be close to their class centers. In particular, the class centers are defined as a free optimization parameter of the model and updated by gradient descent, which is simple and further enhances the OOD detection performance. Extensive experiments demonstrate the superiority of CASE, which reduces the average FPR95 by 37.11% and improves the average AUROC by 15.89% compared to the baseline method using a softmax confidence score on the more challenging CIFAR-100 model.",
        "keywords": []
      },
      "file_name": "ab692fb2d15fe514a8121dbd4d1d74eae4e2f989.pdf"
    },
    {
      "success": true,
      "doc_id": "0c97385983b1b7f4aa07bb1490ed130f",
      "summary": "Detecting out-of-distribution (OOD) data is essential to ensure the reliability of machine learning models when deployed in real-world scenarios. Different from most previous test-time OOD detection methods that focus on designing OOD scores, we delve into the challenges in OOD detection from the perspective of typicality and regard the featureâ€™s high-probability region as the featureâ€™s typical set. However, the existing typical-feature-based OOD detection method implies an assumption: the proportion of typical feature sets for each channel is fixed. According to our experimental analysis, each channel contributes differently to OOD detection. Adopting a fixed proportion for all channels results in several channels losing too many typical features or incorporating too many abnormal features, resulting in low performance. Therefore, exploring the channel-aware typical features is crucial to better-separating ID and OOD data. Driven by this insight, we propose expLoring channel-Aware tyPical featureS (LAPS). Firstly, LAPS obtains the channel-aware typical set by calibrating the channel-level typical set with the global typical set from the mean and standard deviation. Then, LAPS rectifies the features into channel-aware typical sets to obtain channel-aware typical features. Finally, LAPS leverages the channel-aware typical features to calculate the energy score for OOD detection. Theoretical and visual analyses verify that LAPS achieves a better bias-variance trade-off. Experiments verify the effectiveness and generalization of LAPS under different architectures and OOD scores.",
      "intriguing_abstract": "Detecting out-of-distribution (OOD) data is essential to ensure the reliability of machine learning models when deployed in real-world scenarios. Different from most previous test-time OOD detection methods that focus on designing OOD scores, we delve into the challenges in OOD detection from the perspective of typicality and regard the featureâ€™s high-probability region as the featureâ€™s typical set. However, the existing typical-feature-based OOD detection method implies an assumption: the proportion of typical feature sets for each channel is fixed. According to our experimental analysis, each channel contributes differently to OOD detection. Adopting a fixed proportion for all channels results in several channels losing too many typical features or incorporating too many abnormal features, resulting in low performance. Therefore, exploring the channel-aware typical features is crucial to better-separating ID and OOD data. Driven by this insight, we propose expLoring channel-Aware tyPical featureS (LAPS). Firstly, LAPS obtains the channel-aware typical set by calibrating the channel-level typical set with the global typical set from the mean and standard deviation. Then, LAPS rectifies the features into channel-aware typical sets to obtain channel-aware typical features. Finally, LAPS leverages the channel-aware typical features to calculate the energy score for OOD detection. Theoretical and visual analyses verify that LAPS achieves a better bias-variance trade-off. Experiments verify the effectiveness and generalization of LAPS under different architectures and OOD scores.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/755390c365c4a39445f73ed09fe673f2b823876d.pdf",
      "citation_key": "he2024e9z",
      "metadata": {
        "title": "Exploring Channel-Aware Typical Features for Out-of-Distribution Detection",
        "authors": [
          "Rundong He",
          "Yue Yuan",
          "Zhongyi Han",
          "Fan Wang",
          "Wan Su",
          "Yilong Yin",
          "Tongliang Liu",
          "Yongshun Gong"
        ],
        "published_date": "2024",
        "abstract": "Detecting out-of-distribution (OOD) data is essential to ensure the reliability of machine learning models when deployed in real-world scenarios. Different from most previous test-time OOD detection methods that focus on designing OOD scores, we delve into the challenges in OOD detection from the perspective of typicality and regard the featureâ€™s high-probability region as the featureâ€™s typical set. However, the existing typical-feature-based OOD detection method implies an assumption: the proportion of typical feature sets for each channel is fixed. According to our experimental analysis, each channel contributes differently to OOD detection. Adopting a fixed proportion for all channels results in several channels losing too many typical features or incorporating too many abnormal features, resulting in low performance. Therefore, exploring the channel-aware typical features is crucial to better-separating ID and OOD data. Driven by this insight, we propose expLoring channel-Aware tyPical featureS (LAPS). Firstly, LAPS obtains the channel-aware typical set by calibrating the channel-level typical set with the global typical set from the mean and standard deviation. Then, LAPS rectifies the features into channel-aware typical sets to obtain channel-aware typical features. Finally, LAPS leverages the channel-aware typical features to calculate the energy score for OOD detection. Theoretical and visual analyses verify that LAPS achieves a better bias-variance trade-off. Experiments verify the effectiveness and generalization of LAPS under different architectures and OOD scores.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/755390c365c4a39445f73ed09fe673f2b823876d.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Detecting out-of-distribution (OOD) data is essential to ensure the reliability of machine learning models when deployed in real-world scenarios. Different from most previous test-time OOD detection methods that focus on designing OOD scores, we delve into the challenges in OOD detection from the perspective of typicality and regard the featureâ€™s high-probability region as the featureâ€™s typical set. However, the existing typical-feature-based OOD detection method implies an assumption: the proportion of typical feature sets for each channel is fixed. According to our experimental analysis, each channel contributes differently to OOD detection. Adopting a fixed proportion for all channels results in several channels losing too many typical features or incorporating too many abnormal features, resulting in low performance. Therefore, exploring the channel-aware typical features is crucial to better-separating ID and OOD data. Driven by this insight, we propose expLoring channel-Aware tyPical featureS (LAPS). Firstly, LAPS obtains the channel-aware typical set by calibrating the channel-level typical set with the global typical set from the mean and standard deviation. Then, LAPS rectifies the features into channel-aware typical sets to obtain channel-aware typical features. Finally, LAPS leverages the channel-aware typical features to calculate the energy score for OOD detection. Theoretical and visual analyses verify that LAPS achieves a better bias-variance trade-off. Experiments verify the effectiveness and generalization of LAPS under different architectures and OOD scores.",
        "keywords": []
      },
      "file_name": "755390c365c4a39445f73ed09fe673f2b823876d.pdf"
    },
    {
      "success": true,
      "doc_id": "f8020ae541448122574506b241fc1b2d",
      "summary": "Here's a focused summary of the paper for a literature review, adhering to the citation requirements:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of Out-of-Distribution (OOD) detection in deep learning models, particularly the issue of models exhibiting overconfidence on unseen test data \\cite{gong2024n0t}.\n    *   This problem is important because it poses significant safety challenges for deploying deep learning models in real-world, safety-critical applications like autonomous driving and medical diagnostics, where misclassifications of OOD data can lead to catastrophic outcomes \\cite{gong2024n0t}.\n    *   The problem is challenging because existing solutions often rely on introducing real or synthetic outliers during training, which can be computationally expensive, resource-intensive, and prone to bias towards specific outlier characteristics, limiting their generality to diverse, distribution-free OOD data \\cite{gong2024n0t}.\n\n*   **Related Work & Positioning**\n    *   This work relates to existing approaches that enhance OOD detection by introducing outliers during training, such as Outlier Exposure (OE) methods (using real outlier data) and feature-based outlier synthesis methods \\cite{gong2024n0t}.\n    *   The limitations of previous solutions include: (i) significant computational costs and resource demands due to incorporating extra outliers (e.g., density estimation for synthesis), and (ii) a lack of generality, as OOD data is diverse, and these methods may become biased towards specific outlier characteristics, failing to cover all potential OOD scenarios \\cite{gong2024n0t}. For instance, OE methods may perform well on near-OOD but struggle with far-OOD data like MNIST, indicating a focus on local feature discrimination over global data manifold understanding \\cite{gong2024n0t}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is the Prototypical Outlier Proxy (POP) framework, which introduces virtual OOD prototypes to reshape decision boundaries between in-distribution (ID) and OOD data without explicit outlier exposure \\cite{gong2024n0t}.\n    *   The approach is novel because it transforms the typically learnable classifier into a fixed one, augmented with a set of prototypical weight vectors that act as virtual OOD class centers \\cite{gong2024n0t}.\n    *   It further introduces a Hierarchical Similarity Boundary Loss (HSBL) that imposes adaptive penalties based on the degree of misclassification, leveraging semantic hierarchical prior knowledge of ID data to better discriminate significantly different OOD data \\cite{gong2024n0t}. This contrasts with standard cross-entropy loss which treats all misclassifications equally.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **Prototypical Outlier Proxy (POP)**: A novel framework that uses virtual OOD prototypes to create a virtual OOD domain, enabling OOD perception without real or synthesized outliers \\cite{gong2024n0t}.\n        *   **Hierarchical Similarity Boundary Loss (HSBL)**: An innovative loss function that adaptively penalizes misclassifications based on the semantic similarity between predicted and true classes, improving discrimination for semantically distant OOD data \\cite{gong2024n0t}.\n    *   **System Design/Architectural Innovations**:\n        *   **Fixed Classifier with Prototypical Outlier Proxies**: The approach pre-defines ID prototypes by fixing the classifier's weights using a Hierarchy-Aware Frame (HAFrame) and then augments this fixed classifier with additional prototypical outlier proxies. This mitigates mutual influence between ID and OOD prototypes and simplifies their positioning \\cite{gong2024n0t}.\n    *   **Theoretical Insights/Analysis**:\n        *   The method is motivated by the concept of neural collapse, where features converge around class means, and classifier weights align with these means, forming ID prototypes. POP extends this by incorporating additional prototypes for OOD data \\cite{gong2024n0t}.\n        *   The toy experiment (Fig. 3) empirically validates that introducing an outlier proxy into a fixed classifier significantly reduces overconfidence in intersection regions of the feature space \\cite{gong2024n0t}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were conducted on small-scale (CIFAR-10, CIFAR-100) and large-scale (ImageNet-200) ID datasets, using a wide range of OOD datasets (e.g., CIFAR-100, Tiny ImageNet, MNIST, SVHN, Textures, Places365, SSB-hard, NINCO, iNaturalist, OpenImage-O) from the OpenOOD benchmark \\cite{gong2024n0t}.\n    *   **Key Performance Metrics**: The method was evaluated using False Positive Rate at 95% True Positive Rate (FPR95, lower is better) and Area Under the Receiver Operating Characteristic curve (AUROC, higher is better) \\cite{gong2024n0t}.\n    *   **Comparison Results**:\n        *   POP achieved average FPR95 reductions of 7.70%, 6.30%, and 5.42% over the second-best methods on CIFAR-10, CIFAR-100, and ImageNet-200, respectively \\cite{gong2024n0t}.\n        *   For CIFAR-10, POP achieved an average FPR95 of 16.53% and AUROC of 96.09%, significantly outperforming the second-best NPOS (FPR95 24.23%, AUROC 93.44%) \\cite{gong2024n0t}.\n        *   POP demonstrated balanced and excellent performance on both near-OOD and far-OOD cases, unlike OE methods which often fail on far-OOD data \\cite{gong2024n0t}.\n        *   **Efficiency**: Compared to the recent outlier synthesis method NPOS, POP trains 7.2Ã— faster and performs inference 19.5Ã— faster \\cite{gong2024n0t}.\n\n*   **Limitations & Scope**\n    *   The method relies on the availability and quality of a semantic hierarchical prior for ID data to construct the fixed classifier (HAFrame) \\cite{gong2024n0t}.\n    *   The choice of OOD distance `d` and the number of outlier proxies `C` in the `D_pop` matrix, as well as the scaling factor `beta` in HSBL, may require careful tuning \\cite{gong2024n0t}.\n    *   While it addresses the generality issue of *specific* outliers, the concept of \"virtual\" outliers might still implicitly assume certain characteristics of the OOD space.\n    *   The scope of applicability is primarily demonstrated for image classification tasks; its effectiveness in other data modalities is not explored \\cite{gong2024n0t}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: `\\cite{gong2024n0t}` significantly advances the technical state-of-the-art in OOD detection by achieving superior performance (lower FPR95, higher AUROC) across diverse benchmarks and scales, including large-scale ImageNet \\cite{gong2024n0t}.\n    *   **Efficiency and Generality**: It addresses critical efficiency and generality problems of existing outlier exposure methods by proposing a novel, outlier-free training paradigm that is substantially faster and less biased towards specific OOD characteristics \\cite{gong2024n0t}.\n    *   **Novel Paradigm**: The introduction of Prototypical Outlier Proxies within a fixed, hierarchy-aware classifier, combined with an adaptive hierarchical similarity boundary loss, offers a new and effective way to mitigate model overconfidence and improve OOD discrimination \\cite{gong2024n0t}.\n    *   **Potential Impact**: This work has the potential to enable more reliable, robust, and deployable deep learning models in real-world applications by enhancing their ability to perceive and handle unseen data efficiently and effectively, especially in safety-critical domains \\cite{gong2024n0t}.",
      "intriguing_abstract": "Deep learning models frequently exhibit dangerous overconfidence when encountering Out-of-Distribution (OOD) data, posing severe safety risks in critical applications like autonomous driving and medical diagnostics. Existing OOD detection methods, reliant on explicit outlier exposure or synthesis, are computationally expensive, resource-intensive, and lack generality, often failing on diverse OOD scenarios. We introduce the **Prototypical Outlier Proxy (POP)** framework, a novel, outlier-free paradigm that fundamentally reshapes decision boundaries. POP leverages virtual OOD prototypes, augmenting a fixed, hierarchy-aware classifier to perceive OOD data without real or synthesized outliers. Complementing this, our **Hierarchical Similarity Boundary Loss (HSBL)** adaptively penalizes misclassifications based on semantic hierarchy, significantly enhancing discrimination for semantically distant OOD examples. Motivated by neural collapse, POP achieves state-of-the-art OOD detection, reducing FPR95 by up to 7.70% and improving AUROC across diverse CIFAR and ImageNet benchmarks. Crucially, POP trains 7.2Ã— faster and infers 19.5Ã— faster than leading outlier synthesis methods, offering superior generality for both near and far OOD data. This work paves the way for robust, efficient, and truly deployable deep learning systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "deep learning model overconfidence",
        "Prototypical Outlier Proxy (POP) framework",
        "virtual OOD prototypes",
        "Hierarchical Similarity Boundary Loss (HSBL)",
        "outlier-free training paradigm",
        "fixed classifier design",
        "computational efficiency",
        "generality of OOD detection",
        "safety-critical AI applications",
        "neural collapse theory",
        "superior OOD detection performance",
        "semantic hierarchical prior",
        "image classification tasks"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/d03cf8819aeff52708a70d506b87e50214af53b6.pdf",
      "citation_key": "gong2024n0t",
      "metadata": {
        "title": "Out-of-Distribution Detection with Prototypical Outlier Proxy",
        "authors": [
          "Mingrong Gong",
          "Chaoqi Chen",
          "Qingqiang Sun",
          "Yue Wang",
          "Hui Huang"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is a crucial task for deploying deep learning models in the wild. One of the major challenges is that well-trained deep models tend to perform over-confidence on unseen test data. Recent research attempts to leverage real or synthetic outliers to mitigate the issue, which may significantly increase computational costs and be biased toward specific outlier characteristics. In this paper, we propose a simple yet effective framework, Prototypical Outlier Proxy (POP), which introduces virtual OOD prototypes to reshape the decision boundaries between ID and OOD data. Specifically, we transform the learnable classifier into a fixed one and augment it with a set of prototypical weight vectors. Then, we introduce a hierarchical similarity boundary loss to impose adaptive penalties depending on the degree of misclassification. Extensive experiments across various benchmarks demonstrate the effectiveness of POP. Notably, POP achieves average FPR95 reductions of 7.70%, 6.30%, and 5.42% over the second-best methods on CIFAR-10, CIFAR-100, and ImageNet-200, respectively. Moreover, compared to the recent method NPOS, which relies on outlier synthesis, POP trains 7.2 times faster and performs inference 19.5 times faster.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/d03cf8819aeff52708a70d506b87e50214af53b6.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Here's a focused summary of the paper for a literature review, adhering to the citation requirements:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of Out-of-Distribution (OOD) detection in deep learning models, particularly the issue of models exhibiting overconfidence on unseen test data \\cite{gong2024n0t}.\n    *   This problem is important because it poses significant safety challenges for deploying deep learning models in real-world, safety-critical applications like autonomous driving and medical diagnostics, where misclassifications of OOD data can lead to catastrophic outcomes \\cite{gong2024n0t}.\n    *   The problem is challenging because existing solutions often rely on introducing real or synthetic outliers during training, which can be computationally expensive, resource-intensive, and prone to bias towards specific outlier characteristics, limiting their generality to diverse, distribution-free OOD data \\cite{gong2024n0t}.\n\n*   **Related Work & Positioning**\n    *   This work relates to existing approaches that enhance OOD detection by introducing outliers during training, such as Outlier Exposure (OE) methods (using real outlier data) and feature-based outlier synthesis methods \\cite{gong2024n0t}.\n    *   The limitations of previous solutions include: (i) significant computational costs and resource demands due to incorporating extra outliers (e.g., density estimation for synthesis), and (ii) a lack of generality, as OOD data is diverse, and these methods may become biased towards specific outlier characteristics, failing to cover all potential OOD scenarios \\cite{gong2024n0t}. For instance, OE methods may perform well on near-OOD but struggle with far-OOD data like MNIST, indicating a focus on local feature discrimination over global data manifold understanding \\cite{gong2024n0t}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is the Prototypical Outlier Proxy (POP) framework, which introduces virtual OOD prototypes to reshape decision boundaries between in-distribution (ID) and OOD data without explicit outlier exposure \\cite{gong2024n0t}.\n    *   The approach is novel because it transforms the typically learnable classifier into a fixed one, augmented with a set of prototypical weight vectors that act as virtual OOD class centers \\cite{gong2024n0t}.\n    *   It further introduces a Hierarchical Similarity Boundary Loss (HSBL) that imposes adaptive penalties based on the degree of misclassification, leveraging semantic hierarchical prior knowledge of ID data to better discriminate significantly different OOD data \\cite{gong2024n0t}. This contrasts with standard cross-entropy loss which treats all misclassifications equally.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **Prototypical Outlier Proxy (POP)**: A novel framework that uses virtual OOD prototypes to create a virtual OOD domain, enabling OOD perception without real or synthesized outliers \\cite{gong2024n0t}.\n        *   **Hierarchical Similarity Boundary Loss (HSBL)**: An innovative loss function that adaptively penalizes misclassifications based on the semantic similarity between predicted and true classes, improving discrimination for semantically distant OOD data \\cite{gong2024n0t}.\n    *   **System Design/Architectural Innovations**:\n        *   **Fixed Classifier with Prototypical Outlier Proxies**: The approach pre-defines ID prototypes by fixing the classifier's weights using a Hierarchy-Aware Frame (HAFrame) and then augments this fixed classifier with additional prototypical outlier proxies. This mitigates mutual influence between ID and OOD prototypes and simplifies their positioning \\cite{gong2024n0t}.\n    *   **Theoretical Insights/Analysis**:\n        *   The method is motivated by the concept of neural collapse, where features converge around class means, and classifier weights align with these means, forming ID prototypes. POP extends this by incorporating additional prototypes for OOD data \\cite{gong2024n0t}.\n        *   The toy experiment (Fig. 3) empirically validates that introducing an outlier proxy into a fixed classifier significantly reduces overconfidence in intersection regions of the feature space \\cite{gong2024n0t}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were conducted on small-scale (CIFAR-10, CIFAR-100) and large-scale (ImageNet-200) ID datasets, using a wide range of OOD datasets (e.g., CIFAR-100, Tiny ImageNet, MNIST, SVHN, Textures, Places365, SSB-hard, NINCO, iNaturalist, OpenImage-O) from the OpenOOD benchmark \\cite{gong2024n0t}.\n    *   **Key Performance Metrics**: The method was evaluated using False Positive Rate at 95% True Positive Rate (FPR95, lower is better) and Area Under the Receiver Operating Characteristic curve (AUROC, higher is better) \\cite{gong2024n0t}.\n    *   **Comparison Results**:\n        *   POP achieved average FPR95 reductions of 7.70%, 6.30%, and 5.42% over the second-best methods on CIFAR-10, CIFAR-100, and ImageNet-200, respectively \\cite{gong2024n0t}.\n        *   For CIFAR-10, POP achieved an average FPR95 of 16.53% and AUROC of 96.09%, significantly outperforming the second-best NPOS (FPR95 24.23%, AUROC 93.44%) \\cite{gong2024n0t}.\n        *   POP demonstrated balanced and excellent performance on both near-OOD and far-OOD cases, unlike OE methods which often fail on far-OOD data \\cite{gong2024n0t}.\n        *   **Efficiency**: Compared to the recent outlier synthesis method NPOS, POP trains 7.2Ã— faster and performs inference 19.5Ã— faster \\cite{gong2024n0t}.\n\n*   **Limitations & Scope**\n    *   The method relies on the availability and quality of a semantic hierarchical prior for ID data to construct the fixed classifier (HAFrame) \\cite{gong2024n0t}.\n    *   The choice of OOD distance `d` and the number of outlier proxies `C` in the `D_pop` matrix, as well as the scaling factor `beta` in HSBL, may require careful tuning \\cite{gong2024n0t}.\n    *   While it addresses the generality issue of *specific* outliers, the concept of \"virtual\" outliers might still implicitly assume certain characteristics of the OOD space.\n    *   The scope of applicability is primarily demonstrated for image classification tasks; its effectiveness in other data modalities is not explored \\cite{gong2024n0t}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: `\\cite{gong2024n0t}` significantly advances the technical state-of-the-art in OOD detection by achieving superior performance (lower FPR95, higher AUROC) across diverse benchmarks and scales, including large-scale ImageNet \\cite{gong2024n0t}.\n    *   **Efficiency and Generality**: It addresses critical efficiency and generality problems of existing outlier exposure methods by proposing a novel, outlier-free training paradigm that is substantially faster and less biased towards specific OOD characteristics \\cite{gong2024n0t}.\n    *   **Novel Paradigm**: The introduction of Prototypical Outlier Proxies within a fixed, hierarchy-aware classifier, combined with an adaptive hierarchical similarity boundary loss, offers a new and effective way to mitigate model overconfidence and improve OOD discrimination \\cite{gong2024n0t}.\n    *   **Potential Impact**: This work has the potential to enable more reliable, robust, and deployable deep learning models in real-world applications by enhancing their ability to perceive and handle unseen data efficiently and effectively, especially in safety-critical domains \\cite{gong2024n0t}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "deep learning model overconfidence",
          "Prototypical Outlier Proxy (POP) framework",
          "virtual OOD prototypes",
          "Hierarchical Similarity Boundary Loss (HSBL)",
          "outlier-free training paradigm",
          "fixed classifier design",
          "computational efficiency",
          "generality of OOD detection",
          "safety-critical AI applications",
          "neural collapse theory",
          "superior OOD detection performance",
          "semantic hierarchical prior",
          "image classification tasks"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** a simple yet effective framework, prototypical outlier proxy (pop)\". it then details the components of this framework (\"transform the learnable classifier\", \"augment it with a set of prototypical weight vectors\", \"introduce a hierarchical similarity boundary loss\"). this clearly indicates the presentation of a **new method or system**.\n*   the abstract also mentions \"extensive **experiments** across various benchmarks demonstrate the effectiveness of pop\" and provides specific quantitative results (fpr95 reductions, training/inference speed comparisons). this indicates a strong **empirical** component.\n*   the introduction sets up a technical problem (ood detection challenges in deep learning) and hints at the proposed solution (\"training with prototypical outlier proxies\" in figure 1).\n\nwhile the paper heavily relies on empirical evaluation to demonstrate its claims, its core contribution is the **proposal and development of a new framework/method**. the empirical results serve to validate this technical contribution. therefore, the primary classification is **technical**.\n\n**classification: technical**"
      },
      "file_name": "d03cf8819aeff52708a70d506b87e50214af53b6.pdf"
    },
    {
      "success": true,
      "doc_id": "e553f82db99dbc31ac39636715d284e9",
      "summary": "Out-of-distribution (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully unsupervised approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the out-of-distribution detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully unsupervised approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the out-of-distribution detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/296c108e1afadbc131d41f92d66013e9c95eb2ca.pdf",
      "citation_key": "cook2024hyb",
      "metadata": {
        "title": "Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows",
        "authors": [
          "Evan D. Cook",
          "Marc-Antoine Lavoie",
          "Steven L. Waslander"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully unsupervised approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the out-of-distribution detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/296c108e1afadbc131d41f92d66013e9c95eb2ca.pdf",
        "venue": "Proceedings of the 21st Conference on Robots and Vision",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Out-of-distribution (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully unsupervised approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the out-of-distribution detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection.",
        "keywords": []
      },
      "file_name": "296c108e1afadbc131d41f92d66013e9c95eb2ca.pdf"
    },
    {
      "success": true,
      "doc_id": "b583a881e9e99ec78dd8af6c589252d4",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection within Class-Incremental Learning (CIL) models. CIL models are designed to continuously learn new classes while retaining knowledge of old ones, but they often lack the ability to reject samples from unknown distributions.\n    *   **Importance and Challenge**: This capability is crucial for safely deploying CIL models in real-world, open environments (e.g., autonomous driving, medical diagnosis). Existing CIL methods focus on mitigating catastrophic forgetting for in-distribution (ID) classes but do not account for OOD samples. Conversely, current OOD detection methods are primarily designed for static environments, making them ineffective in dynamic CIL settings due to issues like catastrophic forgetting \\cite{miao20246mk}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: While benchmarks exist for OOD detection (e.g., OpenOOD \\cite{miao20246mk}) and CIL (e.g., FACIL \\cite{miao20246mk}) separately, there is a significant gap in systematic and large-scale benchmarking studies that assess the combined capability of CIL models in detecting OOD samples.\n    *   **Limitations of Previous Solutions**: Existing OOD methods are typically applied to non-CIL models and suffer from poor performance in CIL scenarios due to catastrophic forgetting. Similarly, CIL methods primarily focus on closed-world settings, failing to distinguish ID data from unknown OOD samples \\cite{miao20246mk}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**:\n        *   **OpenCIL Benchmark Frameworks**: \\cite{miao20246mk} proposes two principled frameworks to systematically integrate OOD detection methods into CIL models:\n            1.  **Post-hoc-based methods**: Directly apply OOD scoring functions on features/logits from a pre-trained CIL model at each incremental step, without affecting CIL performance.\n            2.  **Fine-tuning-based methods**: Freeze the feature extractor and classifier of the pre-trained CIL model, then fine-tune an *additional* classifier specifically for OOD detection using only the current task's training ID data. This prevents the fine-tuning from intensifying catastrophic forgetting in the core CIL model.\n        *   **Bi-directional Energy Regularization (BER)**: A novel fine-tuning-based OOD detection approach designed to mitigate two key biases observed in CIL models:\n            *   **New Task Energy Regularization (NTER)**: Addresses the bias where CIL models over-confidently classify OOD samples into new classes. It synthesizes pseudo-OOD samples by mixing up new class samples and uses an energy loss function to enlarge the decision boundary margin for new classes, pushing OOD samples away \\cite{miao20246mk}.\n            *   **Old Task Energy Regularization (OTER)**: Addresses the bias where CIL models exhibit low confidence for old class samples (due to catastrophic forgetting), leading to their misclassification as OOD. It synthesizes augmented old class samples by mixing new class samples with old class memory samples, boosting prediction confidence for old classes via an energy loss function \\cite{miao20246mk}.\n    *   **Novelty/Difference**:\n        *   OpenCIL is the first comprehensive benchmark for OOD detection in CIL, providing a unified evaluation protocol and enabling systematic assessment of CIL-OOD synergy.\n        *   BER is novel in its bi-directional approach to mitigate specific biases (towards new classes for OOD, and misclassifying old ID as OOD) that arise in dynamic CIL environments, by applying targeted energy regularization on both new and old class samples \\cite{miao20246mk}.\n\n*   **Key Technical Contributions**\n    *   **Novel Benchmark**: Introduction of OpenCIL, the first benchmark for comprehensively evaluating OOD detection in CIL, including two principled baseline frameworks and an evaluation protocol for 60 baselines \\cite{miao20246mk}.\n    *   **Important Observations**: Identification and analysis of critical biases in CIL models towards OOD samples and newly added classes, offering insights for future open-world CIL designs \\cite{miao20246mk}.\n    *   **New Baseline Algorithm**: Proposal of Bi-directional Energy Regularization (BER) to effectively mitigate the identified biases when incorporating fine-tuning OOD detection methods into CIL models \\cite{miao20246mk}.\n    *   **Open-source Resources**: Public release of all code and pre-processed datasets for reproducibility and further research \\cite{miao20246mk}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: A comprehensive empirical study was performed, evaluating 60 baseline models (synthesized from 4 representative CIL models and 15 diverse OOD detection methods) and the proposed BER method \\cite{miao20246mk}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   Evaluations were conducted on two popular CIL datasets (CIFAR100, ImageNet1K) and six commonly-used OOD datasets (both near and far OOD) \\cite{miao20246mk}.\n        *   A key observation was that CIL models exhibit increasing biases towards OOD samples and newly added classes with more incremental steps, leading to decreased AUC performance for OOD detection \\cite{miao20246mk}.\n        *   The proposed BER method demonstrated superior performance in mitigating these biases and improving OOD detection capabilities in CIL settings \\cite{miao20246mk}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The proposed frameworks for integrating OOD detectors assume either a post-hoc application or fine-tuning of an *additional* classifier while freezing the core CIL model's feature extractor and classifier to preserve CIL performance. BER is specifically a fine-tuning-based method.\n    *   **Scope of Applicability**: OpenCIL's benchmark covers replay-based, regularization-based, and parameter-isolation-based CIL models, and both post-hoc and fine-tuning OOD methods. BER is applicable to CIL models, particularly those where fine-tuning an OOD detector is feasible.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: OpenCIL significantly advances the technical state-of-the-art by providing the first systematic and large-scale benchmark for OOD detection in CIL, enabling rigorous evaluation and comparison of methods in this crucial area. BER offers a novel and effective approach to address specific biases inherent in CIL models when faced with OOD detection \\cite{miao20246mk}.\n    *   **Potential Impact on Future Research**: The benchmark, the identified biases, and the proposed BER method provide crucial insights and a foundational platform for future research in developing robust CIL models for open-world applications, fostering the design of CIL models that are both incrementally capable and OOD-aware \\cite{miao20246mk}.",
      "intriguing_abstract": "Deploying AI in dynamic, open-world environments demands models that not only continuously learn new classes but also reliably reject unknown, Out-of-Distribution (OOD) samples. Current Class-Incremental Learning (CIL) models, however, are ill-equipped for OOD detection, often misclassifying novel inputs or suffering from catastrophic forgetting when existing OOD methods are applied. We introduce OpenCIL, the first comprehensive benchmark framework to systematically evaluate OOD detection within CIL. OpenCIL provides two principled integration frameworks (post-hoc and fine-tuning) and a rigorous evaluation protocol for 60 baselines, revealing critical biases in CIL models towards OOD samples and newly added classes. To address these, we propose Bi-directional Energy Regularization (BER), a novel fine-tuning approach. BER mitigates biases by applying targeted energy regularization: New Task Energy Regularization (NTER) pushes OOD samples away from new classes, while Old Task Energy Regularization (OTER) boosts confidence for old, in-distribution samples. Our extensive experiments confirm that CIL models exhibit increasing biases, and BER significantly improves OOD detection performance. OpenCIL and BER pave the way for robust, OOD-aware CIL systems, crucial for safe and reliable AI deployment in truly open-ended scenarios.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Class-Incremental Learning (CIL)",
        "catastrophic forgetting",
        "OpenCIL benchmark",
        "Bi-directional Energy Regularization (BER)",
        "CIL model biases",
        "energy regularization",
        "post-hoc OOD methods",
        "fine-tuning OOD methods",
        "New Task Energy Regularization (NTER)",
        "Old Task Energy Regularization (OTER)",
        "open-world CIL",
        "systematic benchmarking"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/33fb671a3289027c84a71fc996f948195b1baeb4.pdf",
      "citation_key": "miao20246mk",
      "metadata": {
        "title": "OpenCIL: Benchmarking Out-of-Distribution Detection in Class-Incremental Learning",
        "authors": [
          "Wenjun Miao",
          "Guansong Pang",
          "Trong-Tung Nguyen",
          "Ruohang Fang",
          "Jingyi Zheng",
          "Xiaolong Bai"
        ],
        "published_date": "2024",
        "abstract": "Class incremental learning (CIL) aims to learn a model that can not only incrementally accommodate new classes, but also maintain the learned knowledge of old classes. Out-of-distribution (OOD) detection in CIL is to retain this incremental learning ability, while being able to reject unknown samples that are drawn from different distributions of the learned classes. This capability is crucial to the safety of deploying CIL models in open worlds. However, despite remarkable advancements in the respective CIL and OOD detection, there lacks a systematic and large-scale benchmark to assess the capability of advanced CIL models in detecting OOD samples. To fill this gap, in this study we design a comprehensive empirical study to establish such a benchmark, named $\\textbf{OpenCIL}$. To this end, we propose two principled frameworks for enabling four representative CIL models with 15 diverse OOD detection methods, resulting in 60 baseline models for OOD detection in CIL. The empirical evaluation is performed on two popular CIL datasets with six commonly-used OOD datasets. One key observation we find through our comprehensive evaluation is that the CIL models can be severely biased towards the OOD samples and newly added classes when they are exposed to open environments. Motivated by this, we further propose a new baseline for OOD detection in CIL, namely Bi-directional Energy Regularization ($\\textbf{BER}$), which is specially designed to mitigate these two biases in different CIL models by having energy regularization on both old and new classes. Its superior performance is justified in our experiments. All codes and datasets are open-source at https://github.com/mala-lab/OpenCIL.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/33fb671a3289027c84a71fc996f948195b1baeb4.pdf",
        "venue": "Pattern Recognition",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection within Class-Incremental Learning (CIL) models. CIL models are designed to continuously learn new classes while retaining knowledge of old ones, but they often lack the ability to reject samples from unknown distributions.\n    *   **Importance and Challenge**: This capability is crucial for safely deploying CIL models in real-world, open environments (e.g., autonomous driving, medical diagnosis). Existing CIL methods focus on mitigating catastrophic forgetting for in-distribution (ID) classes but do not account for OOD samples. Conversely, current OOD detection methods are primarily designed for static environments, making them ineffective in dynamic CIL settings due to issues like catastrophic forgetting \\cite{miao20246mk}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: While benchmarks exist for OOD detection (e.g., OpenOOD \\cite{miao20246mk}) and CIL (e.g., FACIL \\cite{miao20246mk}) separately, there is a significant gap in systematic and large-scale benchmarking studies that assess the combined capability of CIL models in detecting OOD samples.\n    *   **Limitations of Previous Solutions**: Existing OOD methods are typically applied to non-CIL models and suffer from poor performance in CIL scenarios due to catastrophic forgetting. Similarly, CIL methods primarily focus on closed-world settings, failing to distinguish ID data from unknown OOD samples \\cite{miao20246mk}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**:\n        *   **OpenCIL Benchmark Frameworks**: \\cite{miao20246mk} proposes two principled frameworks to systematically integrate OOD detection methods into CIL models:\n            1.  **Post-hoc-based methods**: Directly apply OOD scoring functions on features/logits from a pre-trained CIL model at each incremental step, without affecting CIL performance.\n            2.  **Fine-tuning-based methods**: Freeze the feature extractor and classifier of the pre-trained CIL model, then fine-tune an *additional* classifier specifically for OOD detection using only the current task's training ID data. This prevents the fine-tuning from intensifying catastrophic forgetting in the core CIL model.\n        *   **Bi-directional Energy Regularization (BER)**: A novel fine-tuning-based OOD detection approach designed to mitigate two key biases observed in CIL models:\n            *   **New Task Energy Regularization (NTER)**: Addresses the bias where CIL models over-confidently classify OOD samples into new classes. It synthesizes pseudo-OOD samples by mixing up new class samples and uses an energy loss function to enlarge the decision boundary margin for new classes, pushing OOD samples away \\cite{miao20246mk}.\n            *   **Old Task Energy Regularization (OTER)**: Addresses the bias where CIL models exhibit low confidence for old class samples (due to catastrophic forgetting), leading to their misclassification as OOD. It synthesizes augmented old class samples by mixing new class samples with old class memory samples, boosting prediction confidence for old classes via an energy loss function \\cite{miao20246mk}.\n    *   **Novelty/Difference**:\n        *   OpenCIL is the first comprehensive benchmark for OOD detection in CIL, providing a unified evaluation protocol and enabling systematic assessment of CIL-OOD synergy.\n        *   BER is novel in its bi-directional approach to mitigate specific biases (towards new classes for OOD, and misclassifying old ID as OOD) that arise in dynamic CIL environments, by applying targeted energy regularization on both new and old class samples \\cite{miao20246mk}.\n\n*   **Key Technical Contributions**\n    *   **Novel Benchmark**: Introduction of OpenCIL, the first benchmark for comprehensively evaluating OOD detection in CIL, including two principled baseline frameworks and an evaluation protocol for 60 baselines \\cite{miao20246mk}.\n    *   **Important Observations**: Identification and analysis of critical biases in CIL models towards OOD samples and newly added classes, offering insights for future open-world CIL designs \\cite{miao20246mk}.\n    *   **New Baseline Algorithm**: Proposal of Bi-directional Energy Regularization (BER) to effectively mitigate the identified biases when incorporating fine-tuning OOD detection methods into CIL models \\cite{miao20246mk}.\n    *   **Open-source Resources**: Public release of all code and pre-processed datasets for reproducibility and further research \\cite{miao20246mk}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: A comprehensive empirical study was performed, evaluating 60 baseline models (synthesized from 4 representative CIL models and 15 diverse OOD detection methods) and the proposed BER method \\cite{miao20246mk}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   Evaluations were conducted on two popular CIL datasets (CIFAR100, ImageNet1K) and six commonly-used OOD datasets (both near and far OOD) \\cite{miao20246mk}.\n        *   A key observation was that CIL models exhibit increasing biases towards OOD samples and newly added classes with more incremental steps, leading to decreased AUC performance for OOD detection \\cite{miao20246mk}.\n        *   The proposed BER method demonstrated superior performance in mitigating these biases and improving OOD detection capabilities in CIL settings \\cite{miao20246mk}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The proposed frameworks for integrating OOD detectors assume either a post-hoc application or fine-tuning of an *additional* classifier while freezing the core CIL model's feature extractor and classifier to preserve CIL performance. BER is specifically a fine-tuning-based method.\n    *   **Scope of Applicability**: OpenCIL's benchmark covers replay-based, regularization-based, and parameter-isolation-based CIL models, and both post-hoc and fine-tuning OOD methods. BER is applicable to CIL models, particularly those where fine-tuning an OOD detector is feasible.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: OpenCIL significantly advances the technical state-of-the-art by providing the first systematic and large-scale benchmark for OOD detection in CIL, enabling rigorous evaluation and comparison of methods in this crucial area. BER offers a novel and effective approach to address specific biases inherent in CIL models when faced with OOD detection \\cite{miao20246mk}.\n    *   **Potential Impact on Future Research**: The benchmark, the identified biases, and the proposed BER method provide crucial insights and a foundational platform for future research in developing robust CIL models for open-world applications, fostering the design of CIL models that are both incrementally capable and OOD-aware \\cite{miao20246mk}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Class-Incremental Learning (CIL)",
          "catastrophic forgetting",
          "OpenCIL benchmark",
          "Bi-directional Energy Regularization (BER)",
          "CIL model biases",
          "energy regularization",
          "post-hoc OOD methods",
          "fine-tuning OOD methods",
          "New Task Energy Regularization (NTER)",
          "Old Task Energy Regularization (OTER)",
          "open-world CIL",
          "systematic benchmarking"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **\"design a comprehensive empirical study to establish such a benchmark, named opencil.\"** - this directly points to an empirical study.\n2.  **\"the empirical evaluation is performed on two popular cil datasets with six commonly-used ood datasets.\"** - this describes a data-driven study with specific datasets.\n3.  **\"one key observation we find through our comprehensive evaluation is that...\"** - this highlights findings from data analysis.\n4.  **\"its superior performance is justified in our experiments.\"** - this confirms experimental validation.\n5.  the introduction also presents \"qualitative results\" and \"mean prediction confidence\" from experiments (figure 1).\n\nwhile the paper does \"propose two principled frameworks\" and \"propose a new baseline... ber\" (elements of a technical paper), these proposals are deeply embedded within and motivated by the \"comprehensive empirical study\" and its \"observations.\" the primary goal is to establish a benchmark through extensive data-driven evaluation.\n\ntherefore, the most fitting classification is **empirical**."
      },
      "file_name": "33fb671a3289027c84a71fc996f948195b1baeb4.pdf"
    },
    {
      "success": true,
      "doc_id": "59c6f70f51c92f66d4f2a723a94af9e5",
      "summary": "The remarkable achievements of Large Language Models (LLMs) have captivated the attention of both academia and industry, transcending their initial role in dialogue generation. To expand the usage scenarios of LLM, some works enhance the effectiveness and capabilities of the model by introducing more external information, which is called the agent paradigm. Based on this idea, we propose a new method that integrates the agent paradigm into out-of-distribution (OOD) detection task, aiming to improve its robustness and adaptability. Our proposed method, Concept Matching with Agent (CMA), employs neutral prompts as agents to augment the CLIP-based OOD detection process. These agents function as dynamic observers and communication hubs, interacting with both In-distribution (ID) labels and data inputs to form vector triangle relationships. This triangular framework offers a more nuanced approach than the traditional binary relationship, allowing for better separation and identification of ID and OOD inputs. Our extensive experimental results showcase the superior performance of CMA over both zero-shot and training-required methods in a diverse array of real-world scenarios.",
      "intriguing_abstract": "The remarkable achievements of Large Language Models (LLMs) have captivated the attention of both academia and industry, transcending their initial role in dialogue generation. To expand the usage scenarios of LLM, some works enhance the effectiveness and capabilities of the model by introducing more external information, which is called the agent paradigm. Based on this idea, we propose a new method that integrates the agent paradigm into out-of-distribution (OOD) detection task, aiming to improve its robustness and adaptability. Our proposed method, Concept Matching with Agent (CMA), employs neutral prompts as agents to augment the CLIP-based OOD detection process. These agents function as dynamic observers and communication hubs, interacting with both In-distribution (ID) labels and data inputs to form vector triangle relationships. This triangular framework offers a more nuanced approach than the traditional binary relationship, allowing for better separation and identification of ID and OOD inputs. Our extensive experimental results showcase the superior performance of CMA over both zero-shot and training-required methods in a diverse array of real-world scenarios.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/c8689ce4c6bb187f8f4494523c48954d99446db5.pdf",
      "citation_key": "lee2025gu9",
      "metadata": {
        "title": "Concept Matching with Agent for Out-of-Distribution Detection",
        "authors": [
          "Yuxiao Lee",
          "Xiaofeng Cao",
          "Jingcai Guo",
          "Wei Ye",
          "Qing Guo",
          "Yi Chang"
        ],
        "published_date": "2025",
        "abstract": "The remarkable achievements of Large Language Models (LLMs) have captivated the attention of both academia and industry, transcending their initial role in dialogue generation. To expand the usage scenarios of LLM, some works enhance the effectiveness and capabilities of the model by introducing more external information, which is called the agent paradigm. Based on this idea, we propose a new method that integrates the agent paradigm into out-of-distribution (OOD) detection task, aiming to improve its robustness and adaptability. Our proposed method, Concept Matching with Agent (CMA), employs neutral prompts as agents to augment the CLIP-based OOD detection process. These agents function as dynamic observers and communication hubs, interacting with both In-distribution (ID) labels and data inputs to form vector triangle relationships. This triangular framework offers a more nuanced approach than the traditional binary relationship, allowing for better separation and identification of ID and OOD inputs. Our extensive experimental results showcase the superior performance of CMA over both zero-shot and training-required methods in a diverse array of real-world scenarios.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/c8689ce4c6bb187f8f4494523c48954d99446db5.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 4,
        "score": 4.0,
        "summary": "The remarkable achievements of Large Language Models (LLMs) have captivated the attention of both academia and industry, transcending their initial role in dialogue generation. To expand the usage scenarios of LLM, some works enhance the effectiveness and capabilities of the model by introducing more external information, which is called the agent paradigm. Based on this idea, we propose a new method that integrates the agent paradigm into out-of-distribution (OOD) detection task, aiming to improve its robustness and adaptability. Our proposed method, Concept Matching with Agent (CMA), employs neutral prompts as agents to augment the CLIP-based OOD detection process. These agents function as dynamic observers and communication hubs, interacting with both In-distribution (ID) labels and data inputs to form vector triangle relationships. This triangular framework offers a more nuanced approach than the traditional binary relationship, allowing for better separation and identification of ID and OOD inputs. Our extensive experimental results showcase the superior performance of CMA over both zero-shot and training-required methods in a diverse array of real-world scenarios.",
        "keywords": []
      },
      "file_name": "c8689ce4c6bb187f8f4494523c48954d99446db5.pdf"
    },
    {
      "success": true,
      "doc_id": "7bfa2e40e7854a288d3ff4922890b822",
      "summary": "This article proposes a unified open-set fault diagnosis (OSFD) strategy based on deep learning classification models and posterior detectors. We utilize a 1-D residual network (1D-ResNet) to build a classification model and introduce an out-of-distribution (OOD) detection method that integrates the fusion of collective and extreme information (FCEI). The Feature Center Distance Matrix (FCDM) is derived from Mahalanobis distances between class feature centroids. For test samples, cosine similarity between their class-wise Mahalanobis vectors and corresponding FCDM rows is computed as the discriminative collective measure, and finally, using the maximal softmax value of the model prediction class as the extreme information. By combining and analyzing cross-class and extreme information, the method can identify OOD samples more efficiently. Experiments on the Tennessee Eastman (TE) benchmark process show that the proposed method can not only correctly classify the known faults but also accurately identify unknown faults.",
      "intriguing_abstract": "This article proposes a unified open-set fault diagnosis (OSFD) strategy based on deep learning classification models and posterior detectors. We utilize a 1-D residual network (1D-ResNet) to build a classification model and introduce an out-of-distribution (OOD) detection method that integrates the fusion of collective and extreme information (FCEI). The Feature Center Distance Matrix (FCDM) is derived from Mahalanobis distances between class feature centroids. For test samples, cosine similarity between their class-wise Mahalanobis vectors and corresponding FCDM rows is computed as the discriminative collective measure, and finally, using the maximal softmax value of the model prediction class as the extreme information. By combining and analyzing cross-class and extreme information, the method can identify OOD samples more efficiently. Experiments on the Tennessee Eastman (TE) benchmark process show that the proposed method can not only correctly classify the known faults but also accurately identify unknown faults.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/f0ea95c6b19662c33222408795c26316bd88c03f.pdf",
      "citation_key": "wang2025v65",
      "metadata": {
        "title": "Open-Set Fault Diagnosis Based on 1D-ResNet With Fusion of Cross-Class and Extreme Information for Out-of-Distribution Detection",
        "authors": [
          "Jinglong Wang",
          "Ridong Zhang"
        ],
        "published_date": "2025",
        "abstract": "This article proposes a unified open-set fault diagnosis (OSFD) strategy based on deep learning classification models and posterior detectors. We utilize a 1-D residual network (1D-ResNet) to build a classification model and introduce an out-of-distribution (OOD) detection method that integrates the fusion of collective and extreme information (FCEI). The Feature Center Distance Matrix (FCDM) is derived from Mahalanobis distances between class feature centroids. For test samples, cosine similarity between their class-wise Mahalanobis vectors and corresponding FCDM rows is computed as the discriminative collective measure, and finally, using the maximal softmax value of the model prediction class as the extreme information. By combining and analyzing cross-class and extreme information, the method can identify OOD samples more efficiently. Experiments on the Tennessee Eastman (TE) benchmark process show that the proposed method can not only correctly classify the known faults but also accurately identify unknown faults.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/f0ea95c6b19662c33222408795c26316bd88c03f.pdf",
        "venue": "IEEE Transactions on Instrumentation and Measurement",
        "citationCount": 4,
        "score": 4.0,
        "summary": "This article proposes a unified open-set fault diagnosis (OSFD) strategy based on deep learning classification models and posterior detectors. We utilize a 1-D residual network (1D-ResNet) to build a classification model and introduce an out-of-distribution (OOD) detection method that integrates the fusion of collective and extreme information (FCEI). The Feature Center Distance Matrix (FCDM) is derived from Mahalanobis distances between class feature centroids. For test samples, cosine similarity between their class-wise Mahalanobis vectors and corresponding FCDM rows is computed as the discriminative collective measure, and finally, using the maximal softmax value of the model prediction class as the extreme information. By combining and analyzing cross-class and extreme information, the method can identify OOD samples more efficiently. Experiments on the Tennessee Eastman (TE) benchmark process show that the proposed method can not only correctly classify the known faults but also accurately identify unknown faults.",
        "keywords": []
      },
      "file_name": "f0ea95c6b19662c33222408795c26316bd88c03f.pdf"
    },
    {
      "success": true,
      "doc_id": "2adb3a3e57b425457626b8e4cf53c336",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/b60ddb1b78375f709d9c4c0b416f89156e58a6b0.pdf",
      "citation_key": "he2024s9w",
      "metadata": {
        "title": "Visual Out-of-Distribution Detection in Open-Set Noisy Environments",
        "authors": [
          "Rundong He",
          "Zhongyi Han",
          "Xiushan Nie",
          "Yilong Yin",
          "Xiaojun Chang"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b60ddb1b78375f709d9c4c0b416f89156e58a6b0.pdf",
        "venue": "International Journal of Computer Vision",
        "citationCount": 4,
        "score": 4.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "b60ddb1b78375f709d9c4c0b416f89156e58a6b0.pdf"
    },
    {
      "success": true,
      "doc_id": "ebb83c49ed3012585687422871d26744",
      "summary": "Detecting out-of-distribution (OOD) samples poses a significant safety challenge when deploying models in open-world scenarios. Advanced works assume that OOD and in-distributional (ID) samples exhibit a distribution discrepancy, showing an encouraging direction in estimating the uncertainty with embedding features or predicting outputs. Besides incorporating auxiliary outlier as decision boundary, quantifying a â€œmeaningful distanceâ€ in embedding space as uncertainty measurement is a promising strategy. However, these distances-based approaches overlook the data structure and heavily rely on the high-dimension features learned by deep neural networks, causing unreliable distances due to the â€œcurse of dimensionalityâ€. In this work, we propose a data structure-aware approach to mitigate the sensitivity of distances to the â€œcurse of dimensionalityâ€, where high-dimensional features are mapped to the manifold of ID samples, leveraging the well-known manifold assumption. Specifically, we present a novel distance termed as <italic>tangent distance</italic>, which tackles the issue of generalizing the meaningfulness of distances on testing samples to detect OOD inputs. Inspired by manifold learning for adversarial examples, where adversarial region probability density is close to the orthogonal direction of the manifold, and both OOD and adversarial samples have common characteristic <inline-formula><tex-math notation=\"LaTeX\">$-$</tex-math><alternatives><mml:math><mml:mo>-</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq1-3468629.gif\"/></alternatives></inline-formula> imperceptible perturbations with shift distribution, we propose that OOD samples are relatively far away from the ID manifold, where <italic>tangent distance</italic> directly computes the Euclidean distance between samples and the nearest submanifold space <inline-formula><tex-math notation=\"LaTeX\">$-$</tex-math><alternatives><mml:math><mml:mo>-</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq2-3468629.gif\"/></alternatives></inline-formula> instantiated as the linear approximation of local region on the manifold. We provide empirical and theoretical insights to demonstrate the effectiveness of OOD uncertainty measurements on the low-dimensional subspace. Extensive experiments show that the <italic>tangent distance</italic> performs competitively with other post hoc OOD detection baselines on common and large-scale benchmarks, and the theoretical analysis supports our claim that ID samples are likely to reside in high-density regions, explaining the effectiveness of internal connections among ID data.",
      "intriguing_abstract": "Detecting out-of-distribution (OOD) samples poses a significant safety challenge when deploying models in open-world scenarios. Advanced works assume that OOD and in-distributional (ID) samples exhibit a distribution discrepancy, showing an encouraging direction in estimating the uncertainty with embedding features or predicting outputs. Besides incorporating auxiliary outlier as decision boundary, quantifying a â€œmeaningful distanceâ€ in embedding space as uncertainty measurement is a promising strategy. However, these distances-based approaches overlook the data structure and heavily rely on the high-dimension features learned by deep neural networks, causing unreliable distances due to the â€œcurse of dimensionalityâ€. In this work, we propose a data structure-aware approach to mitigate the sensitivity of distances to the â€œcurse of dimensionalityâ€, where high-dimensional features are mapped to the manifold of ID samples, leveraging the well-known manifold assumption. Specifically, we present a novel distance termed as <italic>tangent distance</italic>, which tackles the issue of generalizing the meaningfulness of distances on testing samples to detect OOD inputs. Inspired by manifold learning for adversarial examples, where adversarial region probability density is close to the orthogonal direction of the manifold, and both OOD and adversarial samples have common characteristic <inline-formula><tex-math notation=\"LaTeX\">$-$</tex-math><alternatives><mml:math><mml:mo>-</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq1-3468629.gif\"/></alternatives></inline-formula> imperceptible perturbations with shift distribution, we propose that OOD samples are relatively far away from the ID manifold, where <italic>tangent distance</italic> directly computes the Euclidean distance between samples and the nearest submanifold space <inline-formula><tex-math notation=\"LaTeX\">$-$</tex-math><alternatives><mml:math><mml:mo>-</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq2-3468629.gif\"/></alternatives></inline-formula> instantiated as the linear approximation of local region on the manifold. We provide empirical and theoretical insights to demonstrate the effectiveness of OOD uncertainty measurements on the low-dimensional subspace. Extensive experiments show that the <italic>tangent distance</italic> performs competitively with other post hoc OOD detection baselines on common and large-scale benchmarks, and the theoretical analysis supports our claim that ID samples are likely to reside in high-density regions, explaining the effectiveness of internal connections among ID data.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/ee3af6dfdc6527bc9c96c02044546c7121318a33.pdf",
      "citation_key": "li2025jdt",
      "metadata": {
        "title": "Characterizing Submanifold Region for Out-of-Distribution Detection",
        "authors": [
          "Xuhui Li",
          "Zhen Fang",
          "Yonggang Zhang",
          "Ning Ma",
          "Jiajun Bu",
          "Bo Han",
          "Haishuai Wang"
        ],
        "published_date": "2025",
        "abstract": "Detecting out-of-distribution (OOD) samples poses a significant safety challenge when deploying models in open-world scenarios. Advanced works assume that OOD and in-distributional (ID) samples exhibit a distribution discrepancy, showing an encouraging direction in estimating the uncertainty with embedding features or predicting outputs. Besides incorporating auxiliary outlier as decision boundary, quantifying a â€œmeaningful distanceâ€ in embedding space as uncertainty measurement is a promising strategy. However, these distances-based approaches overlook the data structure and heavily rely on the high-dimension features learned by deep neural networks, causing unreliable distances due to the â€œcurse of dimensionalityâ€. In this work, we propose a data structure-aware approach to mitigate the sensitivity of distances to the â€œcurse of dimensionalityâ€, where high-dimensional features are mapped to the manifold of ID samples, leveraging the well-known manifold assumption. Specifically, we present a novel distance termed as <italic>tangent distance</italic>, which tackles the issue of generalizing the meaningfulness of distances on testing samples to detect OOD inputs. Inspired by manifold learning for adversarial examples, where adversarial region probability density is close to the orthogonal direction of the manifold, and both OOD and adversarial samples have common characteristic <inline-formula><tex-math notation=\"LaTeX\">$-$</tex-math><alternatives><mml:math><mml:mo>-</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq1-3468629.gif\"/></alternatives></inline-formula> imperceptible perturbations with shift distribution, we propose that OOD samples are relatively far away from the ID manifold, where <italic>tangent distance</italic> directly computes the Euclidean distance between samples and the nearest submanifold space <inline-formula><tex-math notation=\"LaTeX\">$-$</tex-math><alternatives><mml:math><mml:mo>-</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq2-3468629.gif\"/></alternatives></inline-formula> instantiated as the linear approximation of local region on the manifold. We provide empirical and theoretical insights to demonstrate the effectiveness of OOD uncertainty measurements on the low-dimensional subspace. Extensive experiments show that the <italic>tangent distance</italic> performs competitively with other post hoc OOD detection baselines on common and large-scale benchmarks, and the theoretical analysis supports our claim that ID samples are likely to reside in high-density regions, explaining the effectiveness of internal connections among ID data.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/ee3af6dfdc6527bc9c96c02044546c7121318a33.pdf",
        "venue": "IEEE Transactions on Knowledge and Data Engineering",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Detecting out-of-distribution (OOD) samples poses a significant safety challenge when deploying models in open-world scenarios. Advanced works assume that OOD and in-distributional (ID) samples exhibit a distribution discrepancy, showing an encouraging direction in estimating the uncertainty with embedding features or predicting outputs. Besides incorporating auxiliary outlier as decision boundary, quantifying a â€œmeaningful distanceâ€ in embedding space as uncertainty measurement is a promising strategy. However, these distances-based approaches overlook the data structure and heavily rely on the high-dimension features learned by deep neural networks, causing unreliable distances due to the â€œcurse of dimensionalityâ€. In this work, we propose a data structure-aware approach to mitigate the sensitivity of distances to the â€œcurse of dimensionalityâ€, where high-dimensional features are mapped to the manifold of ID samples, leveraging the well-known manifold assumption. Specifically, we present a novel distance termed as <italic>tangent distance</italic>, which tackles the issue of generalizing the meaningfulness of distances on testing samples to detect OOD inputs. Inspired by manifold learning for adversarial examples, where adversarial region probability density is close to the orthogonal direction of the manifold, and both OOD and adversarial samples have common characteristic <inline-formula><tex-math notation=\"LaTeX\">$-$</tex-math><alternatives><mml:math><mml:mo>-</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq1-3468629.gif\"/></alternatives></inline-formula> imperceptible perturbations with shift distribution, we propose that OOD samples are relatively far away from the ID manifold, where <italic>tangent distance</italic> directly computes the Euclidean distance between samples and the nearest submanifold space <inline-formula><tex-math notation=\"LaTeX\">$-$</tex-math><alternatives><mml:math><mml:mo>-</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq2-3468629.gif\"/></alternatives></inline-formula> instantiated as the linear approximation of local region on the manifold. We provide empirical and theoretical insights to demonstrate the effectiveness of OOD uncertainty measurements on the low-dimensional subspace. Extensive experiments show that the <italic>tangent distance</italic> performs competitively with other post hoc OOD detection baselines on common and large-scale benchmarks, and the theoretical analysis supports our claim that ID samples are likely to reside in high-density regions, explaining the effectiveness of internal connections among ID data.",
        "keywords": []
      },
      "file_name": "ee3af6dfdc6527bc9c96c02044546c7121318a33.pdf"
    },
    {
      "success": true,
      "doc_id": "e1a64bbdb940fae7b3b2071747e23871",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of detecting Out-of-Distribution (OOD) instances in the context of increasingly general-purpose language models `\\cite{gulati2024dbi}`.\n    *   This problem is important because OOD shifts can severely limit the robustness and reliability of LLMs, especially in sensitive domains like medicine and finance, and are crucial for detecting long-tail phenomena.\n    *   The challenge lies in the computational complexity and storage intensiveness of existing OOD detection methods, particularly for the large training datasets associated with modern LLMs. Distance-based methods often require storing the entire in-distribution (ID) training set, while classification-based methods typically need labeled data and generally perform worse `\\cite{gulati2024dbi}`.\n\n*   **2. Related Work & Positioning**\n    *   Existing OOD detection methods broadly fall into post-hoc (applied to derived representations) and representation learning categories `\\cite{gulati2024dbi}`.\n    *   **Distance-based methods** (e.g., KNN, Mahalanobis) are effective but suffer from scalability issues due to the need to store the entire ID training set.\n    *   **Classifier-based methods** (e.g., MSP, Energy, D2U) are more storage-efficient but typically require labeled data and often yield lower performance `\\cite{gulati2024dbi}`.\n    *   `\\cite{gulati2024dbi}` positions its work as a post-hoc, clustering-based approach that aims to overcome these limitations by offering the memory and computational benefits of clustering/classifier-based techniques while achieving performance comparable to distance-based methods, without strong assumptions about data distribution or requiring labeled data. It is the first to leverage soft clustering for OOD detection with text `\\cite{gulati2024dbi}`.\n\n*   **3. Technical Approach & Innovation**\n    *   The core technical method is a novel soft clustering approach for OOD detection based on **Non-Negative Kernel Regression (NNK-Means)** `\\cite{gulati2024dbi}`.\n    *   Unlike conventional hard clustering (e.g., kMeans), NNK-Means performs soft clustering by assigning each training item to *multiple* cluster centers with non-negative weights, allowing for a more flexible and storage-efficient representation of the ID data manifold.\n    *   OOD scores are generated based on the reconstruction error: data points that cannot be well-reconstructed by the learned dictionary are considered OOD `\\cite{gulati2024dbi}`.\n    *   The approach is novel due to its introduction of **Entropy-Constrained NNK-Means (EC-NNK-Means)** `\\cite{gulati2024dbi}`. This variant addresses the hyperparameter dependency of the number of cluster centers by introducing an entropy-based regularization term. This term favors selecting atoms that represent more data points, enabling an adaptive, data-driven selection and pruning process for dictionary atoms.\n    *   `\\cite{gulati2024dbi}` also proposes **Class-wise NNK-Means (C-NNK-Means)** and **Class-wise EC-NNK-Means (C-EC-NNK-Means)**, which learn separate dictionaries for each ID class when label information is available, further enhancing OOD detection.\n\n*   **4. Key Technical Contributions**\n    *   Novel application of soft clustering via NNK-Means for OOD detection in text data, providing a better approximation of the ID data manifold `\\cite{gulati2024dbi}`.\n    *   Introduction of Entropy-Constrained NNK-Means (EC-NNK-Means), which adaptively learns an appropriate dictionary size by pruning less important atoms, thereby improving efficiency and reducing hyperparameter sensitivity `\\cite{gulati2024dbi}`.\n    *   Formulation of an OOD scoring mechanism directly from the reconstruction error of the NNK-Means model `\\cite{gulati2024dbi}`.\n    *   Development of class-wise extensions (C-NNK-Means, C-EC-NNK-Means) to effectively leverage labeled ID data for improved performance `\\cite{gulati2024dbi}`.\n\n*   **5. Experimental Validation**\n    *   Experiments were conducted on four benchmark datasets: 20 Newsgroups, Banking77, CLINC150, and AG News (in Appendix) `\\cite{gulati2024dbi}`.\n    *   The methods were evaluated using fine-tuned Sentence-BERT representations and compared against 8 popular or recently proposed baselines, including classifier-based (MSP, Energy, D2U) and distance-based (Mahalanobis, KNN) approaches, as well as kMeans `\\cite{gulati2024dbi}`.\n    *   Key performance metrics included AUROC.\n    *   Results showed that `\\cite{gulati2024dbi}`'s approaches consistently achieved superior or comparable AUROC performance, outperforming existing methods by up to 4 AUROC points.\n    *   Crucially, the proposed methods demonstrated significant improvements in efficiency: up to an 11x improvement in inference time and an 87% reduction in storage requirements. EC-NNK-Means further reduced storage by up to 97% compared to comparable approaches while maintaining competitive performance `\\cite{gulati2024dbi}`.\n\n*   **6. Limitations & Scope**\n    *   The primary technical assumption is that OOD instances will exhibit higher reconstruction errors when projected onto the dictionary learned from ID data.\n    *   The scope of applicability is focused on post-hoc OOD detection using representations derived from pre-trained or fine-tuned language models `\\cite{gulati2024dbi}`.\n    *   While the paper addresses the limitation of fixed dictionary size in original NNK-Means through EC-NNK-Means, it does not explicitly state other inherent limitations of its proposed methods.\n\n*   **7. Technical Significance**\n    *   `\\cite{gulati2024dbi}` significantly advances the technical state-of-the-art in OOD detection by introducing a novel, highly efficient, and effective soft clustering framework.\n    *   It provides a practical solution to the scalability and storage challenges faced by existing OOD detection methods, making it suitable for extreme-scale data settings and large language models.\n    *   The innovation of entropy-constrained adaptive dictionary learning offers a more robust and less hyperparameter-dependent approach to clustering for OOD detection.\n    *   This work has the potential to greatly impact future research by enabling more reliable and robust deployment of LLMs, particularly in identifying rare or anomalous \"tail-end phenomena\" in real-world applications `\\cite{gulati2024dbi}`.",
      "intriguing_abstract": "The unchecked proliferation of Out-of-Distribution (OOD) instances poses a severe threat to the reliability and safety of large language models (LLMs), especially in critical applications. Existing OOD detection methods often falter under the immense computational and storage demands of modern LLM datasets, forcing a trade-off between performance and efficiency. We introduce a groundbreaking soft clustering framework based on **Non-Negative Kernel Regression (NNK-Means)** for robust OOD detection in text. Our novel approach leverages **reconstruction error** to identify anomalies, providing a flexible and memory-efficient representation of in-distribution data. A key innovation, **Entropy-Constrained NNK-Means (EC-NNK-Means)**, adaptively learns dictionary sizes, significantly reducing hyperparameter sensitivity and further enhancing **scalability**. Experiments demonstrate our methods achieve superior **AUROC** performance, outperforming baselines by up to 4 points, while dramatically improving inference speed by 11x and reducing **storage** by up to 97%. This work offers a highly effective and practical solution, paving the way for more robust and trustworthy LLM deployments in real-world, sensitive domains.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "Language Models (LLMs)",
        "soft clustering",
        "Non-Negative Kernel Regression (NNK-Means)",
        "Entropy-Constrained NNK-Means (EC-NNK-Means)",
        "adaptive dictionary learning",
        "reconstruction error",
        "scalability and storage efficiency",
        "post-hoc OOD detection",
        "text data",
        "superior AUROC performance",
        "robustness and reliability",
        "Class-wise NNK-Means",
        "hyperparameter sensitivity reduction"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/12f04ecb1c9a76bed28656e1cb178c1b97eb7506.pdf",
      "citation_key": "gulati2024dbi",
      "metadata": {
        "title": "Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression",
        "authors": [
          "Aryan Gulati",
          "Xingjian Dong",
          "Carlos Hurtado",
          "Sarath Shekkizhar",
          "Swabha Swayamdipta",
          "Antonio Ortega"
        ],
        "published_date": "2024",
        "abstract": "As language models become more general purpose, increased attention needs to be paid to detecting out-of-distribution (OOD) instances, i.e., those not belonging to any of the distributions seen during training. Existing methods for detecting OOD data are computationally complex and storage-intensive. We propose a novel soft clustering approach for OOD detection based on non-negative kernel regression. Our approach greatly reduces computational and space complexities (up to 11x improvement in inference time and 87% reduction in storage requirements) and outperforms existing approaches by up to 4 AUROC points on four different benchmarks. We also introduce an entropy-constrained version of our algorithm, which leads to further reductions in storage requirements (up to 97% lower than comparable approaches) while retaining competitive performance. Our soft clustering approach for OOD detection highlights its potential for detecting tail-end phenomena in extreme-scale data settings.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/12f04ecb1c9a76bed28656e1cb178c1b97eb7506.pdf",
        "venue": "Conference on Empirical Methods in Natural Language Processing",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   The paper addresses the critical technical problem of detecting Out-of-Distribution (OOD) instances in the context of increasingly general-purpose language models `\\cite{gulati2024dbi}`.\n    *   This problem is important because OOD shifts can severely limit the robustness and reliability of LLMs, especially in sensitive domains like medicine and finance, and are crucial for detecting long-tail phenomena.\n    *   The challenge lies in the computational complexity and storage intensiveness of existing OOD detection methods, particularly for the large training datasets associated with modern LLMs. Distance-based methods often require storing the entire in-distribution (ID) training set, while classification-based methods typically need labeled data and generally perform worse `\\cite{gulati2024dbi}`.\n\n*   **2. Related Work & Positioning**\n    *   Existing OOD detection methods broadly fall into post-hoc (applied to derived representations) and representation learning categories `\\cite{gulati2024dbi}`.\n    *   **Distance-based methods** (e.g., KNN, Mahalanobis) are effective but suffer from scalability issues due to the need to store the entire ID training set.\n    *   **Classifier-based methods** (e.g., MSP, Energy, D2U) are more storage-efficient but typically require labeled data and often yield lower performance `\\cite{gulati2024dbi}`.\n    *   `\\cite{gulati2024dbi}` positions its work as a post-hoc, clustering-based approach that aims to overcome these limitations by offering the memory and computational benefits of clustering/classifier-based techniques while achieving performance comparable to distance-based methods, without strong assumptions about data distribution or requiring labeled data. It is the first to leverage soft clustering for OOD detection with text `\\cite{gulati2024dbi}`.\n\n*   **3. Technical Approach & Innovation**\n    *   The core technical method is a novel soft clustering approach for OOD detection based on **Non-Negative Kernel Regression (NNK-Means)** `\\cite{gulati2024dbi}`.\n    *   Unlike conventional hard clustering (e.g., kMeans), NNK-Means performs soft clustering by assigning each training item to *multiple* cluster centers with non-negative weights, allowing for a more flexible and storage-efficient representation of the ID data manifold.\n    *   OOD scores are generated based on the reconstruction error: data points that cannot be well-reconstructed by the learned dictionary are considered OOD `\\cite{gulati2024dbi}`.\n    *   The approach is novel due to its introduction of **Entropy-Constrained NNK-Means (EC-NNK-Means)** `\\cite{gulati2024dbi}`. This variant addresses the hyperparameter dependency of the number of cluster centers by introducing an entropy-based regularization term. This term favors selecting atoms that represent more data points, enabling an adaptive, data-driven selection and pruning process for dictionary atoms.\n    *   `\\cite{gulati2024dbi}` also proposes **Class-wise NNK-Means (C-NNK-Means)** and **Class-wise EC-NNK-Means (C-EC-NNK-Means)**, which learn separate dictionaries for each ID class when label information is available, further enhancing OOD detection.\n\n*   **4. Key Technical Contributions**\n    *   Novel application of soft clustering via NNK-Means for OOD detection in text data, providing a better approximation of the ID data manifold `\\cite{gulati2024dbi}`.\n    *   Introduction of Entropy-Constrained NNK-Means (EC-NNK-Means), which adaptively learns an appropriate dictionary size by pruning less important atoms, thereby improving efficiency and reducing hyperparameter sensitivity `\\cite{gulati2024dbi}`.\n    *   Formulation of an OOD scoring mechanism directly from the reconstruction error of the NNK-Means model `\\cite{gulati2024dbi}`.\n    *   Development of class-wise extensions (C-NNK-Means, C-EC-NNK-Means) to effectively leverage labeled ID data for improved performance `\\cite{gulati2024dbi}`.\n\n*   **5. Experimental Validation**\n    *   Experiments were conducted on four benchmark datasets: 20 Newsgroups, Banking77, CLINC150, and AG News (in Appendix) `\\cite{gulati2024dbi}`.\n    *   The methods were evaluated using fine-tuned Sentence-BERT representations and compared against 8 popular or recently proposed baselines, including classifier-based (MSP, Energy, D2U) and distance-based (Mahalanobis, KNN) approaches, as well as kMeans `\\cite{gulati2024dbi}`.\n    *   Key performance metrics included AUROC.\n    *   Results showed that `\\cite{gulati2024dbi}`'s approaches consistently achieved superior or comparable AUROC performance, outperforming existing methods by up to 4 AUROC points.\n    *   Crucially, the proposed methods demonstrated significant improvements in efficiency: up to an 11x improvement in inference time and an 87% reduction in storage requirements. EC-NNK-Means further reduced storage by up to 97% compared to comparable approaches while maintaining competitive performance `\\cite{gulati2024dbi}`.\n\n*   **6. Limitations & Scope**\n    *   The primary technical assumption is that OOD instances will exhibit higher reconstruction errors when projected onto the dictionary learned from ID data.\n    *   The scope of applicability is focused on post-hoc OOD detection using representations derived from pre-trained or fine-tuned language models `\\cite{gulati2024dbi}`.\n    *   While the paper addresses the limitation of fixed dictionary size in original NNK-Means through EC-NNK-Means, it does not explicitly state other inherent limitations of its proposed methods.\n\n*   **7. Technical Significance**\n    *   `\\cite{gulati2024dbi}` significantly advances the technical state-of-the-art in OOD detection by introducing a novel, highly efficient, and effective soft clustering framework.\n    *   It provides a practical solution to the scalability and storage challenges faced by existing OOD detection methods, making it suitable for extreme-scale data settings and large language models.\n    *   The innovation of entropy-constrained adaptive dictionary learning offers a more robust and less hyperparameter-dependent approach to clustering for OOD detection.\n    *   This work has the potential to greatly impact future research by enabling more reliable and robust deployment of LLMs, particularly in identifying rare or anomalous \"tail-end phenomena\" in real-world applications `\\cite{gulati2024dbi}`.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "Language Models (LLMs)",
          "soft clustering",
          "Non-Negative Kernel Regression (NNK-Means)",
          "Entropy-Constrained NNK-Means (EC-NNK-Means)",
          "adaptive dictionary learning",
          "reconstruction error",
          "scalability and storage efficiency",
          "post-hoc OOD detection",
          "text data",
          "superior AUROC performance",
          "robustness and reliability",
          "Class-wise NNK-Means",
          "hyperparameter sensitivity reduction"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **\"we propose a novel soft clustering approach for ood detection based on non-negative kernel regression.\"** - this directly indicates the development of a new method/approach.\n2.  **\"our approach greatly reduces computational and space complexities...\"** - describes the benefits of the proposed method.\n3.  **\"and outperforms existing approaches by up to 4 auroc points on four different benchmarks.\"** - this describes the empirical evaluation of the proposed method.\n4.  **\"we also introduce an entropy-constrained version of our algorithm...\"** - further emphasizes the introduction of a new algorithm.\n5.  the introduction discusses the \"challenge of generalization to out-of-distribution (ood) data\" and limitations of existing methods, setting the stage for their \"proposed nnk-means\" (figure 1).\n\nwhile the paper includes strong empirical results, its core contribution is the **proposal and development of a new method and algorithm**. the empirical evaluation serves to validate this new technical contribution. therefore, it primarily falls under the **technical** category.\n\n**classification: technical**"
      },
      "file_name": "12f04ecb1c9a76bed28656e1cb178c1b97eb7506.pdf"
    },
    {
      "success": true,
      "doc_id": "62475830f001b43327202cb67bdff1b6",
      "summary": "Out-of-distribution (OOD) detection is crucial to safety-critical machine learning applications and has been extensively studied.\nWhile recent studies have predominantly focused on classifier-based methods, research on deep generative model (DGM)-based methods have lagged relatively.\nThis disparity may be attributed to a perplexing phenomenon: DGMs often assign higher likelihoods to unknown OOD inputs than to their known training data.\nThis paper focuses on explaining the underlying mechanism of this phenomenon.\nWe propose a hypothesis that less complex images concentrate in high-density regions in the latent space, resulting in a higher likelihood assignment in the Normalizing Flow (NF).\nWe experimentally demonstrate its validity for five NF architectures, concluding that their likelihood is untrustworthy.\nAdditionally, we show that this problem can be alleviated by treating image complexity as an independent variable.\nFinally, we provide evidence of the potential applicability of our hypothesis in another DGM, PixelCNN++.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection is crucial to safety-critical machine learning applications and has been extensively studied.\nWhile recent studies have predominantly focused on classifier-based methods, research on deep generative model (DGM)-based methods have lagged relatively.\nThis disparity may be attributed to a perplexing phenomenon: DGMs often assign higher likelihoods to unknown OOD inputs than to their known training data.\nThis paper focuses on explaining the underlying mechanism of this phenomenon.\nWe propose a hypothesis that less complex images concentrate in high-density regions in the latent space, resulting in a higher likelihood assignment in the Normalizing Flow (NF).\nWe experimentally demonstrate its validity for five NF architectures, concluding that their likelihood is untrustworthy.\nAdditionally, we show that this problem can be alleviated by treating image complexity as an independent variable.\nFinally, we provide evidence of the potential applicability of our hypothesis in another DGM, PixelCNN++.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/8a0eabcb7ff3f11fdd864fe68e386fa5c5da698c.pdf",
      "citation_key": "osada20246an",
      "metadata": {
        "title": "Understanding Likelihood of Normalizing Flow and Image Complexity through the Lens of Out-of-Distribution Detection",
        "authors": [
          "Genki Osada",
          "Tsubasa Takahashi",
          "Takashi Nishide"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is crucial to safety-critical machine learning applications and has been extensively studied.\nWhile recent studies have predominantly focused on classifier-based methods, research on deep generative model (DGM)-based methods have lagged relatively.\nThis disparity may be attributed to a perplexing phenomenon: DGMs often assign higher likelihoods to unknown OOD inputs than to their known training data.\nThis paper focuses on explaining the underlying mechanism of this phenomenon.\nWe propose a hypothesis that less complex images concentrate in high-density regions in the latent space, resulting in a higher likelihood assignment in the Normalizing Flow (NF).\nWe experimentally demonstrate its validity for five NF architectures, concluding that their likelihood is untrustworthy.\nAdditionally, we show that this problem can be alleviated by treating image complexity as an independent variable.\nFinally, we provide evidence of the potential applicability of our hypothesis in another DGM, PixelCNN++.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/8a0eabcb7ff3f11fdd864fe68e386fa5c5da698c.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Out-of-distribution (OOD) detection is crucial to safety-critical machine learning applications and has been extensively studied.\nWhile recent studies have predominantly focused on classifier-based methods, research on deep generative model (DGM)-based methods have lagged relatively.\nThis disparity may be attributed to a perplexing phenomenon: DGMs often assign higher likelihoods to unknown OOD inputs than to their known training data.\nThis paper focuses on explaining the underlying mechanism of this phenomenon.\nWe propose a hypothesis that less complex images concentrate in high-density regions in the latent space, resulting in a higher likelihood assignment in the Normalizing Flow (NF).\nWe experimentally demonstrate its validity for five NF architectures, concluding that their likelihood is untrustworthy.\nAdditionally, we show that this problem can be alleviated by treating image complexity as an independent variable.\nFinally, we provide evidence of the potential applicability of our hypothesis in another DGM, PixelCNN++.",
        "keywords": []
      },
      "file_name": "8a0eabcb7ff3f11fdd864fe68e386fa5c5da698c.pdf"
    },
    {
      "success": true,
      "doc_id": "64a41c9ad4ca267484ff797a0ddf0df3",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: Multi-Label Out-of-Distribution Detection with Spectral Normalized Joint Energy \\cite{mei20248tm}\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem:** The paper addresses the challenge of Out-of-Distribution (OOD) detection in *multi-label classification* tasks \\cite{mei20248tm}. While multi-class OOD detection has seen significant progress, multi-label scenarios remain largely underexplored \\cite{mei20248tm}.\n    *   **Importance and challenge:**\n        *   Machine learning models often encounter OOD data in real-world deployments, leading to inaccurate predictions and safety concerns \\cite{mei20248tm}. OOD detection is crucial for enhancing model safety and robustness \\cite{mei20248tm}.\n        *   Multi-label classification is inherently more complex than multi-class, as it requires evaluating uncertainty across *multiple labels* simultaneously, rather than a single dominant one \\cite{mei20248tm}.\n        *   Achieving stable model training is essential for accurate multi-label OOD sample identification \\cite{mei20248tm}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches:**\n        *   The work builds upon the concept of energy-based models (EBMs) for OOD detection, which have been shown effective for quantifying OOD uncertainty in multi-class settings (e.g., Liu et al. [28]) \\cite{mei20248tm}.\n        *   It extends the application of energy scores to multi-label contexts, drawing inspiration from approaches that leverage the collective power of all label data (e.g., Wang et al. [39]) \\cite{mei20248tm}.\n        *   It integrates spectral normalization, a regularization technique known for enhancing model robustness and generalization, into the OOD detection framework \\cite{mei20248tm}.\n    *   **Limitations of previous solutions:**\n        *   Prior OOD detection research has predominantly focused on *multi-class* tasks, leaving multi-label classification largely unaddressed \\cite{mei20248tm}.\n        *   Generative models face significant difficulties in accurately estimating joint likelihood for multi-label data \\cite{mei20248tm}.\n        *   Some earlier multi-label OOD approaches, despite using joint energy, implicitly assumed label independence, which was later found to be suboptimal \\cite{mei20248tm}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method:** The paper introduces Spectral Normalized Joint Energy (SNoJoE) \\cite{mei20248tm}.\n        *   **Label-wise Joint Energy:** For each input `x`, the method first derives a label-wise energy function `E_yi(x) = -ln(1 + e^(f_yi(x)))` from the predictive probability of a binary logistic classifier for each class `i` \\cite{mei20248tm}. These individual label energies are then aggregated into a joint energy `E_joint(x) = Î£_i=1^K -E_yi(x)`, which serves as the OOD uncertainty score \\cite{mei20248tm}.\n        *   **Spectral Normalization (SN):** Applied to the weight matrices of the initial layers (e.g., first 9 layers of ResNet-101) of the neural network during feature extraction \\cite{mei20248tm}. SN ensures that the spectral norm of these weight matrices is less than or equal to 1, enforcing a bi-Lipschitz constraint on the hidden layers. This makes the hidden layer representations \"distance preserving,\" enhancing generalization and robustness \\cite{mei20248tm}.\n    *   **Novelty/Difference:**\n        *   SNoJoE is novel in its combination of cross-label energy scores with spectral normalization specifically for multi-label OOD detection \\cite{mei20248tm}.\n        *   The application of spectral normalization to regularize the feature space for OOD detection is innovative, as it promotes a well-regulated feature space, reduces gradient variation, and improves generalization to OOD instances \\cite{mei20248tm}.\n        *   The method directly addresses multi-label OOD by consolidating label-specific information through a theoretically justified energy function, bypassing the complexities of joint likelihood estimation in generative models \\cite{mei20248tm}.\n\n4.  **Key Technical Contributions**\n    *   **Novel algorithms/methods:**\n        *   Introduction of SNoJoE, a new method for OOD uncertainty assessment in multi-label classification, which integrates label-wise joint energy with spectral normalization \\cite{mei20248tm}.\n        *   A theoretically grounded approach for deriving label-wise joint energy from binary logistic classifiers, used as an effective OOD scoring function \\cite{mei20248tm}.\n    *   **System design/architectural innovations:**\n        *   Integration of spectral normalization into the initial layers of a standard CNN backbone (e.g., ResNet-101) to regularize the feature space, ensuring bi-Lipschitz continuity and \"distance preserving\" properties of hidden layer representations, thereby enhancing robustness and generalization for OOD detection \\cite{mei20248tm}.\n    *   **Theoretical insights/analysis:**\n        *   Demonstrates that applying spectral normalization to joint energy scores significantly amplifies the model's capability for OOD detection \\cite{mei20248tm}.\n        *   Provides a theoretical interpretation of the label-wise energy function derived from the logistic form \\cite{mei20248tm}.\n        *   Highlights the effectiveness of aggregating label energies over summing label scores for OOD detection in multi-label contexts \\cite{mei20248tm}.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted:**\n        *   OOD detection experiments were performed using PASCAL-VOC as the in-distribution (ID) dataset \\cite{mei20248tm}.\n        *   ImageNet-22K (20 selected classes) and Texture datasets were employed as out-of-distribution (OOD) datasets \\cite{mei20248tm}.\n        *   Ablation studies were conducted to quantify the performance enhancement attributed to spectral normalization \\cite{mei20248tm}.\n        *   The multi-label classifier was based on a ResNet-101 backbone, pre-trained on ImageNet-1K, with spectral normalization applied to the first 9 layers \\cite{mei20248tm}.\n    *   **Key performance metrics and comparison results:**\n        *   **Metric:** False Positive Rate at 95% True Positive Rate (FPR95) \\cite{mei20248tm}.\n        *   **Results:** SNoJoE achieved new state-of-the-art performance, demonstrating:\n            *   An 11% relative reduction in FPR95 on the ImageNet-22K OOD dataset \\cite{mei20248tm}.\n            *   A 54% relative reduction in FPR95 on the Texture OOD dataset (with a t-test p-value < 0.01), compared to prior top performances \\cite{mei20248tm}.\n        *   The trained multi-label classifier achieved a mean Average Precision (mAP) of 89.19% on PASCAL-VOC \\cite{mei20248tm}.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations/assumptions:**\n        *   The method relies on a pre-trained multi-label classifier (ResNet-101 pre-trained on ImageNet-1K) \\cite{mei20248tm}.\n        *   The energy threshold `Ï„` for OOD detection is set at 95% to correctly classify the majority of in-distribution data, which is a fixed heuristic \\cite{mei20248tm}.\n        *   While the joint energy formulation is presented as addressing \"joint uncertainty,\" its derivation as a sum of individual label energies might still implicitly assume certain independence properties or a specific way of combining information \\cite{mei20248tm}.\n    *   **Scope of applicability:**\n        *   Primarily validated for image-based multi-label classification OOD detection tasks \\cite{mei20248tm}.\n        *   Applicable to scenarios requiring robust OOD detection for multi-label models, such as in safety-critical systems or open-world recognition \\cite{mei20248tm}.\n\n7.  **Technical Significance**\n    *   **Advancement of technical state-of-the-art:**\n        *   SNoJoE establishes a new state-of-the-art in multi-label OOD detection, significantly outperforming previous methods with substantial reductions in FPR95 on challenging OOD datasets \\cite{mei20248tm}.\n        *   It provides a robust and generalizable solution for a previously underexplored and challenging area of OOD detection \\cite{mei20248tm}.\n    *   **Potential impact on future research:**\n        *   Opens new avenues for research into the synergistic effects of regularization techniques (like spectral normalization) and energy-based OOD detection methods in complex multi-label settings \\cite{mei20248tm}.\n        *   Encourages further exploration of more sophisticated ways to model and combine label dependencies within energy functions for OOD detection \\cite{mei20248tm}.\n        *   The approach could inspire the application of similar spectral normalization strategies to other uncertainty quantification tasks or model robustness challenges in deep learning \\cite{mei20248tm}.\n        *   The public availability of code and datasets promotes reproducible research and further development in the field \\cite{mei20248tm}.",
      "intriguing_abstract": "The real world demands deep learning models that not only classify accurately but also confidently identify the unfamiliar. Yet, robust Out-of-Distribution (OOD) detection in complex *multi-label* scenarios remains a critical, underexplored challenge, vital for safe and reliable AI deployment. We introduce **Spectral Normalized Joint Energy (SNoJoE)**, a pioneering approach that redefines multi-label OOD detection.\n\nSNoJoE innovatively combines a theoretically grounded label-wise joint energy function, which aggregates uncertainty across all labels, with **spectral normalization** applied to early network layers. This regularization enforces a bi-Lipschitz constraint, creating a highly robust and distance-preserving feature space that significantly enhances generalization to OOD instances. Our method bypasses the limitations of generative models and implicit label independence assumptions prevalent in prior work. Evaluated on PASCAL-VOC and challenging OOD datasets like ImageNet-22K and Texture, SNoJoE achieves new state-of-the-art performance, demonstrating an 11% relative reduction in FPR95 on ImageNet-22K and an unprecedented 54% reduction on Texture. SNoJoE offers a crucial advancement for safer, more reliable multi-label AI systems, opening new avenues for research in uncertainty quantification and model robustness.",
      "keywords": [
        "Multi-label OOD detection",
        "Spectral Normalized Joint Energy (SNoJoE)",
        "Energy-based models",
        "Spectral normalization",
        "Joint energy function",
        "Feature space regularization",
        "Bi-Lipschitz continuity",
        "State-of-the-art performance",
        "FPR95 metric",
        "Model robustness",
        "Image-based classification",
        "Uncertainty quantification"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/8cb280caa94c758e659adfb413b25a3d2e37a837.pdf",
      "citation_key": "mei20248tm",
      "metadata": {
        "title": "Multi-Label Out-of-Distribution Detection with Spectral Normalized Joint Energy",
        "authors": [
          "Yihan Mei",
          "Xinyu Wang",
          "De-Fu Zhang",
          "Xiaoling Wang"
        ],
        "published_date": "2024",
        "abstract": "In today's interconnected world, achieving reliable out-of-distribution (OOD) detection poses a significant challenge for machine learning models. While numerous studies have introduced improved approaches for multi-class OOD detection tasks, the investigation into multi-label OOD detection tasks has been notably limited. We introduce Spectral Normalized Joint Energy (SNoJoE), a method that consolidates label-specific information across multiple labels through the theoretically justified concept of an energy-based function. Throughout the training process, we employ spectral normalization to manage the model's feature space, thereby enhancing model efficacy and generalization, in addition to bolstering robustness. Our findings indicate that the application of spectral normalization to joint energy scores notably amplifies the model's capability for OOD detection. We perform OOD detection experiments utilizing PASCAL-VOC as the in-distribution dataset and ImageNet-22K or Texture as the out-of-distribution datasets. Our experimental results reveal that, in comparison to prior top performances, SNoJoE achieves 11% and 54% relative reductions in FPR95 on the respective OOD datasets, thereby defining the new state of the art in this field of study.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/8cb280caa94c758e659adfb413b25a3d2e37a837.pdf",
        "venue": "APWeb/WAIM",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: Multi-Label Out-of-Distribution Detection with Spectral Normalized Joint Energy \\cite{mei20248tm}\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem:** The paper addresses the challenge of Out-of-Distribution (OOD) detection in *multi-label classification* tasks \\cite{mei20248tm}. While multi-class OOD detection has seen significant progress, multi-label scenarios remain largely underexplored \\cite{mei20248tm}.\n    *   **Importance and challenge:**\n        *   Machine learning models often encounter OOD data in real-world deployments, leading to inaccurate predictions and safety concerns \\cite{mei20248tm}. OOD detection is crucial for enhancing model safety and robustness \\cite{mei20248tm}.\n        *   Multi-label classification is inherently more complex than multi-class, as it requires evaluating uncertainty across *multiple labels* simultaneously, rather than a single dominant one \\cite{mei20248tm}.\n        *   Achieving stable model training is essential for accurate multi-label OOD sample identification \\cite{mei20248tm}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches:**\n        *   The work builds upon the concept of energy-based models (EBMs) for OOD detection, which have been shown effective for quantifying OOD uncertainty in multi-class settings (e.g., Liu et al. [28]) \\cite{mei20248tm}.\n        *   It extends the application of energy scores to multi-label contexts, drawing inspiration from approaches that leverage the collective power of all label data (e.g., Wang et al. [39]) \\cite{mei20248tm}.\n        *   It integrates spectral normalization, a regularization technique known for enhancing model robustness and generalization, into the OOD detection framework \\cite{mei20248tm}.\n    *   **Limitations of previous solutions:**\n        *   Prior OOD detection research has predominantly focused on *multi-class* tasks, leaving multi-label classification largely unaddressed \\cite{mei20248tm}.\n        *   Generative models face significant difficulties in accurately estimating joint likelihood for multi-label data \\cite{mei20248tm}.\n        *   Some earlier multi-label OOD approaches, despite using joint energy, implicitly assumed label independence, which was later found to be suboptimal \\cite{mei20248tm}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method:** The paper introduces Spectral Normalized Joint Energy (SNoJoE) \\cite{mei20248tm}.\n        *   **Label-wise Joint Energy:** For each input `x`, the method first derives a label-wise energy function `E_yi(x) = -ln(1 + e^(f_yi(x)))` from the predictive probability of a binary logistic classifier for each class `i` \\cite{mei20248tm}. These individual label energies are then aggregated into a joint energy `E_joint(x) = Î£_i=1^K -E_yi(x)`, which serves as the OOD uncertainty score \\cite{mei20248tm}.\n        *   **Spectral Normalization (SN):** Applied to the weight matrices of the initial layers (e.g., first 9 layers of ResNet-101) of the neural network during feature extraction \\cite{mei20248tm}. SN ensures that the spectral norm of these weight matrices is less than or equal to 1, enforcing a bi-Lipschitz constraint on the hidden layers. This makes the hidden layer representations \"distance preserving,\" enhancing generalization and robustness \\cite{mei20248tm}.\n    *   **Novelty/Difference:**\n        *   SNoJoE is novel in its combination of cross-label energy scores with spectral normalization specifically for multi-label OOD detection \\cite{mei20248tm}.\n        *   The application of spectral normalization to regularize the feature space for OOD detection is innovative, as it promotes a well-regulated feature space, reduces gradient variation, and improves generalization to OOD instances \\cite{mei20248tm}.\n        *   The method directly addresses multi-label OOD by consolidating label-specific information through a theoretically justified energy function, bypassing the complexities of joint likelihood estimation in generative models \\cite{mei20248tm}.\n\n4.  **Key Technical Contributions**\n    *   **Novel algorithms/methods:**\n        *   Introduction of SNoJoE, a new method for OOD uncertainty assessment in multi-label classification, which integrates label-wise joint energy with spectral normalization \\cite{mei20248tm}.\n        *   A theoretically grounded approach for deriving label-wise joint energy from binary logistic classifiers, used as an effective OOD scoring function \\cite{mei20248tm}.\n    *   **System design/architectural innovations:**\n        *   Integration of spectral normalization into the initial layers of a standard CNN backbone (e.g., ResNet-101) to regularize the feature space, ensuring bi-Lipschitz continuity and \"distance preserving\" properties of hidden layer representations, thereby enhancing robustness and generalization for OOD detection \\cite{mei20248tm}.\n    *   **Theoretical insights/analysis:**\n        *   Demonstrates that applying spectral normalization to joint energy scores significantly amplifies the model's capability for OOD detection \\cite{mei20248tm}.\n        *   Provides a theoretical interpretation of the label-wise energy function derived from the logistic form \\cite{mei20248tm}.\n        *   Highlights the effectiveness of aggregating label energies over summing label scores for OOD detection in multi-label contexts \\cite{mei20248tm}.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted:**\n        *   OOD detection experiments were performed using PASCAL-VOC as the in-distribution (ID) dataset \\cite{mei20248tm}.\n        *   ImageNet-22K (20 selected classes) and Texture datasets were employed as out-of-distribution (OOD) datasets \\cite{mei20248tm}.\n        *   Ablation studies were conducted to quantify the performance enhancement attributed to spectral normalization \\cite{mei20248tm}.\n        *   The multi-label classifier was based on a ResNet-101 backbone, pre-trained on ImageNet-1K, with spectral normalization applied to the first 9 layers \\cite{mei20248tm}.\n    *   **Key performance metrics and comparison results:**\n        *   **Metric:** False Positive Rate at 95% True Positive Rate (FPR95) \\cite{mei20248tm}.\n        *   **Results:** SNoJoE achieved new state-of-the-art performance, demonstrating:\n            *   An 11% relative reduction in FPR95 on the ImageNet-22K OOD dataset \\cite{mei20248tm}.\n            *   A 54% relative reduction in FPR95 on the Texture OOD dataset (with a t-test p-value < 0.01), compared to prior top performances \\cite{mei20248tm}.\n        *   The trained multi-label classifier achieved a mean Average Precision (mAP) of 89.19% on PASCAL-VOC \\cite{mei20248tm}.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations/assumptions:**\n        *   The method relies on a pre-trained multi-label classifier (ResNet-101 pre-trained on ImageNet-1K) \\cite{mei20248tm}.\n        *   The energy threshold `Ï„` for OOD detection is set at 95% to correctly classify the majority of in-distribution data, which is a fixed heuristic \\cite{mei20248tm}.\n        *   While the joint energy formulation is presented as addressing \"joint uncertainty,\" its derivation as a sum of individual label energies might still implicitly assume certain independence properties or a specific way of combining information \\cite{mei20248tm}.\n    *   **Scope of applicability:**\n        *   Primarily validated for image-based multi-label classification OOD detection tasks \\cite{mei20248tm}.\n        *   Applicable to scenarios requiring robust OOD detection for multi-label models, such as in safety-critical systems or open-world recognition \\cite{mei20248tm}.\n\n7.  **Technical Significance**\n    *   **Advancement of technical state-of-the-art:**\n        *   SNoJoE establishes a new state-of-the-art in multi-label OOD detection, significantly outperforming previous methods with substantial reductions in FPR95 on challenging OOD datasets \\cite{mei20248tm}.\n        *   It provides a robust and generalizable solution for a previously underexplored and challenging area of OOD detection \\cite{mei20248tm}.\n    *   **Potential impact on future research:**\n        *   Opens new avenues for research into the synergistic effects of regularization techniques (like spectral normalization) and energy-based OOD detection methods in complex multi-label settings \\cite{mei20248tm}.\n        *   Encourages further exploration of more sophisticated ways to model and combine label dependencies within energy functions for OOD detection \\cite{mei20248tm}.\n        *   The approach could inspire the application of similar spectral normalization strategies to other uncertainty quantification tasks or model robustness challenges in deep learning \\cite{mei20248tm}.\n        *   The public availability of code and datasets promotes reproducible research and further development in the field \\cite{mei20248tm}.",
        "keywords": [
          "Multi-label OOD detection",
          "Spectral Normalized Joint Energy (SNoJoE)",
          "Energy-based models",
          "Spectral normalization",
          "Joint energy function",
          "Feature space regularization",
          "Bi-Lipschitz continuity",
          "State-of-the-art performance",
          "FPR95 metric",
          "Model robustness",
          "Image-based classification",
          "Uncertainty quantification"
        ],
        "paper_type": "this paper is best classified as **technical**.\n\nhere's why:\n\n*   **abstract:** explicitly states \"we introduce spectral normalized joint energy (snojoe), a method that consolidates label-specific information...\" and describes how this method works (\"employ spectral normalization\"). this directly aligns with the \"technical\" criterion: \"presents new methods, algorithms, or systems.\"\n*   **introduction:** discusses a technical problem (\"ood detection in multi-label classification contexts remains underexplored\") which sets the stage for their proposed technical solution.\n*   **empirical evidence:** while the paper clearly performs experiments and presents \"experimental results\" and \"findings,\" which are characteristics of an \"empirical\" paper, these experiments are conducted to validate the *new method* (snojoe) they are introducing. the core contribution is the development and presentation of snojoe. many technical papers include empirical validation as a necessary component. if the paper were *only* analyzing existing data or methods without proposing a new one, it would be purely empirical. here, the novelty lies in the proposed method."
      },
      "file_name": "8cb280caa94c758e659adfb413b25a3d2e37a837.pdf"
    },
    {
      "success": true,
      "doc_id": "0a78affb62365ea3ae01f86ce875093d",
      "summary": "In recent years, large-scale vision-language models such as CLIP have shown remarkable performance on various zero-shot classification tasks. Inspired by these pretrained models, many studies have proposed effective fine-tuning methods to exploit the modelsâ€™ pre-trained knowledge. One common approach is to fine-tune the entire model to transfer the pre-trained knowledge to target tasks. On the other hand, given the high cost of fine-tuning large-scale models, parameter-efficient fine-tuning methods are also being explored. While there have been performance comparisons of existing fine-tuning methods, they often focus solely on classification performance. Such a singular focus is not sufficient to assess the quality of the transferred pre-trained knowledge comprehensively. For a more rigorous evaluation, other metrics, such as the detection of out-of-distribution samples, should be considered, given their importance for model reliability. However, the comparison of fine-tuning methods concerning model reliability has been less explored. Therefore, we aim to fill this gap by offering a comprehensive comparative analysis on the out-of-distribution detection performance of CLIP-based fine-tuning methods along with their in-distribution classification performance. Our experimental results on the OpenOOD v1.5 benchmark dataset suggest that fine-tuning the entire model provides superior performance in both classification and out-of-distribution detection in a few-shot setting.",
      "intriguing_abstract": "In recent years, large-scale vision-language models such as CLIP have shown remarkable performance on various zero-shot classification tasks. Inspired by these pretrained models, many studies have proposed effective fine-tuning methods to exploit the modelsâ€™ pre-trained knowledge. One common approach is to fine-tune the entire model to transfer the pre-trained knowledge to target tasks. On the other hand, given the high cost of fine-tuning large-scale models, parameter-efficient fine-tuning methods are also being explored. While there have been performance comparisons of existing fine-tuning methods, they often focus solely on classification performance. Such a singular focus is not sufficient to assess the quality of the transferred pre-trained knowledge comprehensively. For a more rigorous evaluation, other metrics, such as the detection of out-of-distribution samples, should be considered, given their importance for model reliability. However, the comparison of fine-tuning methods concerning model reliability has been less explored. Therefore, we aim to fill this gap by offering a comprehensive comparative analysis on the out-of-distribution detection performance of CLIP-based fine-tuning methods along with their in-distribution classification performance. Our experimental results on the OpenOOD v1.5 benchmark dataset suggest that fine-tuning the entire model provides superior performance in both classification and out-of-distribution detection in a few-shot setting.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/05a8b19f4b4ddd316eb959d6f68378842f1c65a2.pdf",
      "citation_key": "kim2024vqc",
      "metadata": {
        "title": "Comparison of Out-of-Distribution Detection Performance of CLIP-based Fine-Tuning Methods",
        "authors": [
          "Jeonghyeon Kim",
          "Jihyo Kim",
          "Sangheum Hwang"
        ],
        "published_date": "2024",
        "abstract": "In recent years, large-scale vision-language models such as CLIP have shown remarkable performance on various zero-shot classification tasks. Inspired by these pretrained models, many studies have proposed effective fine-tuning methods to exploit the modelsâ€™ pre-trained knowledge. One common approach is to fine-tune the entire model to transfer the pre-trained knowledge to target tasks. On the other hand, given the high cost of fine-tuning large-scale models, parameter-efficient fine-tuning methods are also being explored. While there have been performance comparisons of existing fine-tuning methods, they often focus solely on classification performance. Such a singular focus is not sufficient to assess the quality of the transferred pre-trained knowledge comprehensively. For a more rigorous evaluation, other metrics, such as the detection of out-of-distribution samples, should be considered, given their importance for model reliability. However, the comparison of fine-tuning methods concerning model reliability has been less explored. Therefore, we aim to fill this gap by offering a comprehensive comparative analysis on the out-of-distribution detection performance of CLIP-based fine-tuning methods along with their in-distribution classification performance. Our experimental results on the OpenOOD v1.5 benchmark dataset suggest that fine-tuning the entire model provides superior performance in both classification and out-of-distribution detection in a few-shot setting.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/05a8b19f4b4ddd316eb959d6f68378842f1c65a2.pdf",
        "venue": "International Conference on Electronics, Information and Communications",
        "citationCount": 3,
        "score": 3.0,
        "summary": "In recent years, large-scale vision-language models such as CLIP have shown remarkable performance on various zero-shot classification tasks. Inspired by these pretrained models, many studies have proposed effective fine-tuning methods to exploit the modelsâ€™ pre-trained knowledge. One common approach is to fine-tune the entire model to transfer the pre-trained knowledge to target tasks. On the other hand, given the high cost of fine-tuning large-scale models, parameter-efficient fine-tuning methods are also being explored. While there have been performance comparisons of existing fine-tuning methods, they often focus solely on classification performance. Such a singular focus is not sufficient to assess the quality of the transferred pre-trained knowledge comprehensively. For a more rigorous evaluation, other metrics, such as the detection of out-of-distribution samples, should be considered, given their importance for model reliability. However, the comparison of fine-tuning methods concerning model reliability has been less explored. Therefore, we aim to fill this gap by offering a comprehensive comparative analysis on the out-of-distribution detection performance of CLIP-based fine-tuning methods along with their in-distribution classification performance. Our experimental results on the OpenOOD v1.5 benchmark dataset suggest that fine-tuning the entire model provides superior performance in both classification and out-of-distribution detection in a few-shot setting.",
        "keywords": []
      },
      "file_name": "05a8b19f4b4ddd316eb959d6f68378842f1c65a2.pdf"
    },
    {
      "success": true,
      "doc_id": "4892a45265113cf1f786b2e09cd63135",
      "summary": "Here's a focused summary of the paper \\cite{kahya2024ywf} for a literature review:\n\n### Focused Summary for Literature Review: FOOD: FACIAL AUTHENTICATION AND OUT-OF-DISTRIBUTION DETECTION WITH SHORT-RANGE FMCW RADAR \\cite{kahya2024ywf}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the dual challenge of accurate facial authentication using short-range FMCW radar while simultaneously detecting out-of-distribution (OOD) samples to prevent erroneous classifications.\n    *   **Importance and Challenge**: This problem is crucial for secure and reliable deployment of deep learning models in real-world scenarios, especially in sensitive applications like authentication. Radar systems offer advantages over camera-based methods (resilience to environmental conditions, privacy preservation), but existing radar-based facial authentication systems predominantly focus on classification accuracy, neglecting the critical aspect of OOD detection, which can lead to overconfident and incorrect predictions for unknown inputs.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Radar-based Face Authentication**: Previous works (e.g., \\cite{kahya2024ywf} citing [10-15]) have explored various radar frequencies (61 GHz, 77 GHz) and deep learning architectures (DNNs, CNNs, autoencoders, Siamese Networks, PointNet) for face classification, achieving high accuracies (e.g., 92% to 98.69%).\n        *   **General OOD Detection**: A wide range of methods exist, including maximum softmax probabilities (MSP \\cite{kahya2024ywf} citing [16]), input perturbation and temperature scaling (ODIN \\cite{kahya2024ywf} citing [17]), Mahalanobis distance (MAHA \\cite{kahya2024ywf} citing [20]), energy-based methods \\cite{kahya2024ywf} citing [23], and gradient-based approaches (GradNorm \\cite{kahya2024ywf} citing [25]).\n        *   **Radar-based OOD Detection**: Some studies have explored OOD detection in radar for general objects or human activities (e.g., \\cite{kahya2024ywf} citing [29-32]), but not specifically for facial authentication.\n    *   **Limitations of Previous Solutions**: Existing radar-based facial authentication systems predominantly concentrate on achieving high classification accuracy, *overlooking the performance of their pipeline when exposed to OOD samples*. This leaves a significant gap in security and reliability for real-world deployment. General OOD detectors are not inherently designed for radar-specific data or integrated into a facial authentication pipeline.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes FOOD, a novel reconstruction-based deep neural network architecture. It consists of:\n        *   A **Main Convolutional Part (MP)**: Features a one-encoder and multi-decoder configuration. The encoder processes raw ADC radar data, and the three decoders are dedicated to reconstructing the three in-distribution (ID) human face classes (Person 1, Person 2, Person 3).\n        *   **Intermediate Linear Encoder-Decoder Parts**:\n            *   **Common Leaf (CL)**: Situated at the end of the MP's encoder, it's a simple linear encoder-decoder designed for OOD detection by reconstructing intermediate features of all ID classes.\n            *   **Private Leaves (PLs)**: Three separate linear encoder-decoder networks, each positioned within one of the MP's decoders (just before the final reconstruction layer). They are ID class-specific and reconstruct intermediate features of their corresponding ID classes.\n        *   **Novel Loss Function**: A composite loss function combining seven distinct Mean Squared Error (MSE) reconstruction losses: three from the MP, one from the CL, and three from the PLs. All seven losses are minimized simultaneously during training.\n        *   **OOD Detection Mechanism**: During test time, a sample is classified as OOD if its reconstruction scores from the CL and PLs (CL+PL1, CL+PL2, CL+PL3) all exceed pre-defined thresholds (guaranteeing 95% of ID data is correctly detected).\n        *   **Human Face Classification Mechanism**: If a sample is not OOD, it's an ID. Its class is determined by finding the smallest total reconstruction MSE from the combined MP and PL parts (MP1+PL1, MP2+PL2, MP3+PL3).\n    *   **Novelty/Difference**: The core innovation lies in the *joint design* of a reconstruction-based architecture that inherently supports both accurate multi-class facial authentication and robust OOD detection within a single pipeline. The specific multi-decoder, multi-leaf (CL and PLs) architecture, coupled with its unique seven-component loss function, allows for specialized reconstruction errors to be leveraged for both tasks, which is distinct from prior works that either focused solely on classification or applied generic OOD methods post-hoc.\n\n4.  **Key Technical Contributions**\n    *   **Novel Architecture**: Introduction of a reconstruction-based architecture (FOOD) with a main convolutional one-encoder multi-decoder (MP) and intermediate linear common (CL) and private (PLs) leaves, designed for joint classification and OOD detection.\n    *   **Novel Loss Function**: Proposal of a composite loss function comprising seven distinct reconstruction losses, strategically derived from different parts of the network (MP, CL, PLs) to optimize both classification and OOD detection.\n    *   **Integrated OOD Detection**: A method for OOD detection using multi-thresholding on reconstruction errors from CL and PLs, seamlessly integrated into the facial authentication pipeline.\n    *   **Empirical Superiority**: Demonstration of superior performance in OOD detection compared to state-of-the-art OOD methods when applied to radar-based facial data.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Training and evaluation of the FOOD framework for both facial authentication and OOD detection.\n        *   Comparison of FOOD's OOD detection performance against eight state-of-the-art OOD detection methods (MSP, ODIN, ENERGY, OE, REACT, GRADNORM, MAXLOGIT, KL) applied to a pre-trained ResNet34 model.\n        *   Ablation studies to demonstrate the impact of PLs on classification accuracy (MP vs. MP+PLs) and the combined effect of CL and PLs on OOD detection (CL vs. CL+PLs).\n    *   **Dataset**: A custom dataset collected using an Infineon BGT60TR13C 60 GHz FMCW radar sensor.\n        *   **ID Samples**: Three male participants (the first three authors), 190,126 frames.\n        *   **OOD Samples**: 13 people (10 male, 3 female), 15,818 frames.\n        *   Data collected at 25 cm distance, 2 minutes per recording, different days/times, varying room backgrounds, no facial accessories.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Facial Authentication (ID samples)**: Achieved an average classification accuracy of **98.07%**. (A ResNet34 baseline achieved 99.10% but lacked OOD detection).\n        *   **OOD Detection**:\n            *   Average Area Under the Receiver Operating Characteristic (AUROC): **98.50%**.\n            *   Average False Positive Rate at 95% True Positive Rate (FPR95): **6.20%**.\n            *   Average Area Under the Precision-Recall Curve (AUPR IN/OUT): 97.61% / 98.88%.\n        *   **Comparison with SOTA OOD Methods**: FOOD significantly *outperformed all eight SOTA OOD detection methods* across AUROC, AUPR IN/OUT, and FPR95 metrics. For example, for PER 1, FOOD achieved 98.40% AUROC and 8.93% FPR95, while the best SOTA (GradNorm) achieved 77.77% AUROC and 70.45% FPR95.\n        *   **Inference Time**: FOOD demonstrated very fast inference, with a Test Time of 5 seconds for all test samples, significantly faster than most SOTA OOD methods (e.g., ODIN at 255s, GradNorm at 191s).\n        *   **Ablation Study Results**:\n            *   **Classification**: MP+PLs (98.07% accuracy) significantly outperformed MP alone (67.01% accuracy), highlighting the crucial role of PLs.\n            *   **OOD Detection**: CL+PLs (average AUROC 98.50%, FPR95 6.20%) substantially improved over CL alone (average AUROC 94.15%, FPR95 32.96%), confirming the synergistic effect of PLs.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The ID dataset is relatively small, consisting of only three individuals. While OOD samples are from 13 people, the system's generalization to a much larger ID population is not explicitly tested.\n        *   Data collection was performed under controlled conditions (fixed distance of 25 cm, no facial accessories), which might limit direct applicability to highly variable real-world scenarios without further robustness testing.\n        *   The radar system uses a single Tx and three Rx antennas, which is a specific configuration.\n    *   **Scope of Applicability**: Primarily focused on short-range 60 GHz FMCW radar for human facial authentication. The framework is demonstrated for a specific number of ID classes (three) but could potentially be extended.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art by being the first to propose a unified, reconstruction-based deep learning framework that *jointly and effectively* addresses both facial authentication and OOD detection using short-range FMCW radar. It overcomes the critical limitation of previous radar-based authentication systems that lacked OOD detection capabilities.\n    *   **Potential Impact on Future Research**:\n        *   Establishes a new benchmark for secure and reliable radar-based authentication systems by integrating OOD detection.\n        *   The novel architecture and loss function provide a strong foundation for future research in robust radar-based perception, particularly in scenarios requiring high security and resilience to unknown inputs.\n        *   Opens avenues for exploring similar integrated approaches in other radar applications (e.g., gesture recognition, activity classification) where OOD detection is vital.\n        *   The superior performance and fast inference time make it a practical solution for real-time applications.",
      "intriguing_abstract": "Deep learning models in critical authentication systems face a significant vulnerability: unknown, out-of-distribution (OOD) inputs. This paper introduces FOOD (Facial Authentication and Out-of-Distribution Detection), a pioneering reconstruction-based deep neural network designed for secure facial authentication using short-range 60 GHz FMCW radar. Unlike existing radar-based systems that neglect OOD detection, FOOD simultaneously achieves high authentication accuracy and robust OOD identification, addressing a critical gap for real-world deployment.\n\nOur novel architecture features a one-encoder multi-decoder main part, complemented by common and private linear encoder-decoder 'leaves', all optimized by a unique composite loss function comprising seven distinct Mean Squared Error (MSE) reconstruction losses. This integrated design allows FOOD to effectively classify in-distribution faces while flagging OOD samples based on specialized reconstruction errors.\n\nExperiments on a custom 60 GHz radar dataset demonstrate FOOD's unprecedented performance: 98.07% facial authentication accuracy and an outstanding 98.50% AUROC for OOD detection, with a low 6.20% FPR95. Crucially, FOOD significantly outperforms eight state-of-the-art OOD methods and offers remarkably fast inference. This work establishes a new benchmark for secure, privacy-preserving, and reliable radar-based authentication.",
      "keywords": [
        "FMCW radar",
        "facial authentication",
        "out-of-distribution (OOD) detection",
        "reconstruction-based deep learning",
        "FOOD architecture",
        "joint classification and OOD detection",
        "one-encoder multi-decoder",
        "Common and Private Leaves (CL/PLs)",
        "composite loss function",
        "60 GHz short-range radar",
        "high classification accuracy",
        "superior OOD detection performance",
        "fast inference"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/400333890cf74f523068ab767a87fede2042131e.pdf",
      "citation_key": "kahya2024ywf",
      "metadata": {
        "title": "FOOD: Facial Authentication and Out-of-Distribution Detection with Short-Range FMCW Radar",
        "authors": [
          "Sabri Mustafa Kahya",
          "Boran Hamdi Sivrikaya",
          "Muhammet Sami Yavuz",
          "Eckehard G. Steinbach"
        ],
        "published_date": "2024",
        "abstract": "This paper proposes a short-range FMCW radar-based facial authentication and out-of-distribution (OOD) detection framework. Our pipeline jointly estimates the correct classes for the in-distribution (ID) samples and detects the OOD samples to prevent their inaccurate prediction. Our reconstruction-based architecture consists of a main convolutional block with one encoder and multi-decoder configuration, and intermediate linear encoder-decoder parts. Together, these elements form an accurate human face classifier and a robust OOD detector. For our dataset, gathered using a 60 GHz short-range FMCW radar, our network achieves an average classification accuracy of 98.07% in identifying in-distribution human faces. As an OOD detector, it achieves an average Area Under the Receiver Operating Characteristic (AUROC) curve of 98.50% and an average False Positive Rate at 95% True Positive Rate (FPR95) of 6.20%. Also, our extensive experiments show that the proposed approach outperforms previous OOD detectors in terms of common OOD detection metrics.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/400333890cf74f523068ab767a87fede2042131e.pdf",
        "venue": "International Conference on Information Photonics",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the paper \\cite{kahya2024ywf} for a literature review:\n\n### Focused Summary for Literature Review: FOOD: FACIAL AUTHENTICATION AND OUT-OF-DISTRIBUTION DETECTION WITH SHORT-RANGE FMCW RADAR \\cite{kahya2024ywf}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the dual challenge of accurate facial authentication using short-range FMCW radar while simultaneously detecting out-of-distribution (OOD) samples to prevent erroneous classifications.\n    *   **Importance and Challenge**: This problem is crucial for secure and reliable deployment of deep learning models in real-world scenarios, especially in sensitive applications like authentication. Radar systems offer advantages over camera-based methods (resilience to environmental conditions, privacy preservation), but existing radar-based facial authentication systems predominantly focus on classification accuracy, neglecting the critical aspect of OOD detection, which can lead to overconfident and incorrect predictions for unknown inputs.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Radar-based Face Authentication**: Previous works (e.g., \\cite{kahya2024ywf} citing [10-15]) have explored various radar frequencies (61 GHz, 77 GHz) and deep learning architectures (DNNs, CNNs, autoencoders, Siamese Networks, PointNet) for face classification, achieving high accuracies (e.g., 92% to 98.69%).\n        *   **General OOD Detection**: A wide range of methods exist, including maximum softmax probabilities (MSP \\cite{kahya2024ywf} citing [16]), input perturbation and temperature scaling (ODIN \\cite{kahya2024ywf} citing [17]), Mahalanobis distance (MAHA \\cite{kahya2024ywf} citing [20]), energy-based methods \\cite{kahya2024ywf} citing [23], and gradient-based approaches (GradNorm \\cite{kahya2024ywf} citing [25]).\n        *   **Radar-based OOD Detection**: Some studies have explored OOD detection in radar for general objects or human activities (e.g., \\cite{kahya2024ywf} citing [29-32]), but not specifically for facial authentication.\n    *   **Limitations of Previous Solutions**: Existing radar-based facial authentication systems predominantly concentrate on achieving high classification accuracy, *overlooking the performance of their pipeline when exposed to OOD samples*. This leaves a significant gap in security and reliability for real-world deployment. General OOD detectors are not inherently designed for radar-specific data or integrated into a facial authentication pipeline.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes FOOD, a novel reconstruction-based deep neural network architecture. It consists of:\n        *   A **Main Convolutional Part (MP)**: Features a one-encoder and multi-decoder configuration. The encoder processes raw ADC radar data, and the three decoders are dedicated to reconstructing the three in-distribution (ID) human face classes (Person 1, Person 2, Person 3).\n        *   **Intermediate Linear Encoder-Decoder Parts**:\n            *   **Common Leaf (CL)**: Situated at the end of the MP's encoder, it's a simple linear encoder-decoder designed for OOD detection by reconstructing intermediate features of all ID classes.\n            *   **Private Leaves (PLs)**: Three separate linear encoder-decoder networks, each positioned within one of the MP's decoders (just before the final reconstruction layer). They are ID class-specific and reconstruct intermediate features of their corresponding ID classes.\n        *   **Novel Loss Function**: A composite loss function combining seven distinct Mean Squared Error (MSE) reconstruction losses: three from the MP, one from the CL, and three from the PLs. All seven losses are minimized simultaneously during training.\n        *   **OOD Detection Mechanism**: During test time, a sample is classified as OOD if its reconstruction scores from the CL and PLs (CL+PL1, CL+PL2, CL+PL3) all exceed pre-defined thresholds (guaranteeing 95% of ID data is correctly detected).\n        *   **Human Face Classification Mechanism**: If a sample is not OOD, it's an ID. Its class is determined by finding the smallest total reconstruction MSE from the combined MP and PL parts (MP1+PL1, MP2+PL2, MP3+PL3).\n    *   **Novelty/Difference**: The core innovation lies in the *joint design* of a reconstruction-based architecture that inherently supports both accurate multi-class facial authentication and robust OOD detection within a single pipeline. The specific multi-decoder, multi-leaf (CL and PLs) architecture, coupled with its unique seven-component loss function, allows for specialized reconstruction errors to be leveraged for both tasks, which is distinct from prior works that either focused solely on classification or applied generic OOD methods post-hoc.\n\n4.  **Key Technical Contributions**\n    *   **Novel Architecture**: Introduction of a reconstruction-based architecture (FOOD) with a main convolutional one-encoder multi-decoder (MP) and intermediate linear common (CL) and private (PLs) leaves, designed for joint classification and OOD detection.\n    *   **Novel Loss Function**: Proposal of a composite loss function comprising seven distinct reconstruction losses, strategically derived from different parts of the network (MP, CL, PLs) to optimize both classification and OOD detection.\n    *   **Integrated OOD Detection**: A method for OOD detection using multi-thresholding on reconstruction errors from CL and PLs, seamlessly integrated into the facial authentication pipeline.\n    *   **Empirical Superiority**: Demonstration of superior performance in OOD detection compared to state-of-the-art OOD methods when applied to radar-based facial data.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Training and evaluation of the FOOD framework for both facial authentication and OOD detection.\n        *   Comparison of FOOD's OOD detection performance against eight state-of-the-art OOD detection methods (MSP, ODIN, ENERGY, OE, REACT, GRADNORM, MAXLOGIT, KL) applied to a pre-trained ResNet34 model.\n        *   Ablation studies to demonstrate the impact of PLs on classification accuracy (MP vs. MP+PLs) and the combined effect of CL and PLs on OOD detection (CL vs. CL+PLs).\n    *   **Dataset**: A custom dataset collected using an Infineon BGT60TR13C 60 GHz FMCW radar sensor.\n        *   **ID Samples**: Three male participants (the first three authors), 190,126 frames.\n        *   **OOD Samples**: 13 people (10 male, 3 female), 15,818 frames.\n        *   Data collected at 25 cm distance, 2 minutes per recording, different days/times, varying room backgrounds, no facial accessories.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Facial Authentication (ID samples)**: Achieved an average classification accuracy of **98.07%**. (A ResNet34 baseline achieved 99.10% but lacked OOD detection).\n        *   **OOD Detection**:\n            *   Average Area Under the Receiver Operating Characteristic (AUROC): **98.50%**.\n            *   Average False Positive Rate at 95% True Positive Rate (FPR95): **6.20%**.\n            *   Average Area Under the Precision-Recall Curve (AUPR IN/OUT): 97.61% / 98.88%.\n        *   **Comparison with SOTA OOD Methods**: FOOD significantly *outperformed all eight SOTA OOD detection methods* across AUROC, AUPR IN/OUT, and FPR95 metrics. For example, for PER 1, FOOD achieved 98.40% AUROC and 8.93% FPR95, while the best SOTA (GradNorm) achieved 77.77% AUROC and 70.45% FPR95.\n        *   **Inference Time**: FOOD demonstrated very fast inference, with a Test Time of 5 seconds for all test samples, significantly faster than most SOTA OOD methods (e.g., ODIN at 255s, GradNorm at 191s).\n        *   **Ablation Study Results**:\n            *   **Classification**: MP+PLs (98.07% accuracy) significantly outperformed MP alone (67.01% accuracy), highlighting the crucial role of PLs.\n            *   **OOD Detection**: CL+PLs (average AUROC 98.50%, FPR95 6.20%) substantially improved over CL alone (average AUROC 94.15%, FPR95 32.96%), confirming the synergistic effect of PLs.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The ID dataset is relatively small, consisting of only three individuals. While OOD samples are from 13 people, the system's generalization to a much larger ID population is not explicitly tested.\n        *   Data collection was performed under controlled conditions (fixed distance of 25 cm, no facial accessories), which might limit direct applicability to highly variable real-world scenarios without further robustness testing.\n        *   The radar system uses a single Tx and three Rx antennas, which is a specific configuration.\n    *   **Scope of Applicability**: Primarily focused on short-range 60 GHz FMCW radar for human facial authentication. The framework is demonstrated for a specific number of ID classes (three) but could potentially be extended.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art by being the first to propose a unified, reconstruction-based deep learning framework that *jointly and effectively* addresses both facial authentication and OOD detection using short-range FMCW radar. It overcomes the critical limitation of previous radar-based authentication systems that lacked OOD detection capabilities.\n    *   **Potential Impact on Future Research**:\n        *   Establishes a new benchmark for secure and reliable radar-based authentication systems by integrating OOD detection.\n        *   The novel architecture and loss function provide a strong foundation for future research in robust radar-based perception, particularly in scenarios requiring high security and resilience to unknown inputs.\n        *   Opens avenues for exploring similar integrated approaches in other radar applications (e.g., gesture recognition, activity classification) where OOD detection is vital.\n        *   The superior performance and fast inference time make it a practical solution for real-time applications.",
        "keywords": [
          "FMCW radar",
          "facial authentication",
          "out-of-distribution (OOD) detection",
          "reconstruction-based deep learning",
          "FOOD architecture",
          "joint classification and OOD detection",
          "one-encoder multi-decoder",
          "Common and Private Leaves (CL/PLs)",
          "composite loss function",
          "60 GHz short-range radar",
          "high classification accuracy",
          "superior OOD detection performance",
          "fast inference"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"this paper **proposes** a short-range fmcw radar-based facial authentication and out-of-distribution (ood) detection framework.\" it then describes the \"pipeline,\" \"reconstruction-based architecture,\" and \"elements\" that form the classifier and detector. it also presents specific performance metrics (accuracy, auroc, fpr95) and claims the \"proposed approach outperforms previous ood detectors.\"\n*   the introduction reinforces this by stating: \"in this study, we **propose** a facial authentication system, food...\" and \"food is a **novel** facial authentication system that not only classifies... but also detects...\" it further describes the \"unique framework\" and \"reconstruction-based framework\" with its components.\n\nthese phrases strongly indicate the paper is presenting a new method, algorithm, or system. while it includes empirical results to validate the proposed system, the primary contribution is the invention and description of the system itself.\n\ntherefore, the paper best fits the **technical** classification."
      },
      "file_name": "400333890cf74f523068ab767a87fede2042131e.pdf"
    },
    {
      "success": true,
      "doc_id": "8ed25dc99b1bb526bd2a253533e95670",
      "summary": "Training robust deep learning models is crucial in Earth Observation, where globally deployed models often face distribution shifts that degrade performance, especially in low-data regions. Out-of-distribution (OOD) detection addresses this by identifying inputs that deviate from indistribution (ID) data. However, existing methods either assume access to OOD data or compromise primary task performance, limiting real-world use. We introduce TARDIS, a post-hoc OOD detection method designed for scalable geospatial deployment. Our core innovation lies in generating surrogate distribution labels by leveraging ID data within the feature space. TARDIS takes a pre-trained model, ID data, and data from an unknown distribution (WILD), separates WILD into surrogate ID and OOD labels based on internal activations, and trains a binary classifier to detect distribution shifts. We validate on EuroSAT and xBD across 17 setups covering covariate and semantic shifts, showing near-upper-bound surrogate labeling performance in 13 cases and matching the performance of top post-hoc activation-and scoring-based methods. Finally, deploying TARDIS on Fields of the World reveals actionable insights into pre-trained model behavior at scale. The code is available at https://github.com/microsoft/geospatial-ood-detection",
      "intriguing_abstract": "Training robust deep learning models is crucial in Earth Observation, where globally deployed models often face distribution shifts that degrade performance, especially in low-data regions. Out-of-distribution (OOD) detection addresses this by identifying inputs that deviate from indistribution (ID) data. However, existing methods either assume access to OOD data or compromise primary task performance, limiting real-world use. We introduce TARDIS, a post-hoc OOD detection method designed for scalable geospatial deployment. Our core innovation lies in generating surrogate distribution labels by leveraging ID data within the feature space. TARDIS takes a pre-trained model, ID data, and data from an unknown distribution (WILD), separates WILD into surrogate ID and OOD labels based on internal activations, and trains a binary classifier to detect distribution shifts. We validate on EuroSAT and xBD across 17 setups covering covariate and semantic shifts, showing near-upper-bound surrogate labeling performance in 13 cases and matching the performance of top post-hoc activation-and scoring-based methods. Finally, deploying TARDIS on Fields of the World reveals actionable insights into pre-trained model behavior at scale. The code is available at https://github.com/microsoft/geospatial-ood-detection",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/90af5e08aa6e57e55124dd3f1f40bdb0c051b7c9.pdf",
      "citation_key": "ekim2024zwd",
      "metadata": {
        "title": "Distribution Shifts at Scale: Out-of-distribution Detection in Earth Observation",
        "authors": [
          "Burak Ekim",
          "G. Tadesse",
          "Caleb Robinson",
          "G. Hacheme",
          "Michael Schmitt",
          "R. Dodhia",
          "J. M. L. Ferres"
        ],
        "published_date": "2024",
        "abstract": "Training robust deep learning models is crucial in Earth Observation, where globally deployed models often face distribution shifts that degrade performance, especially in low-data regions. Out-of-distribution (OOD) detection addresses this by identifying inputs that deviate from indistribution (ID) data. However, existing methods either assume access to OOD data or compromise primary task performance, limiting real-world use. We introduce TARDIS, a post-hoc OOD detection method designed for scalable geospatial deployment. Our core innovation lies in generating surrogate distribution labels by leveraging ID data within the feature space. TARDIS takes a pre-trained model, ID data, and data from an unknown distribution (WILD), separates WILD into surrogate ID and OOD labels based on internal activations, and trains a binary classifier to detect distribution shifts. We validate on EuroSAT and xBD across 17 setups covering covariate and semantic shifts, showing near-upper-bound surrogate labeling performance in 13 cases and matching the performance of top post-hoc activation-and scoring-based methods. Finally, deploying TARDIS on Fields of the World reveals actionable insights into pre-trained model behavior at scale. The code is available at https://github.com/microsoft/geospatial-ood-detection",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/90af5e08aa6e57e55124dd3f1f40bdb0c051b7c9.pdf",
        "venue": "2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Training robust deep learning models is crucial in Earth Observation, where globally deployed models often face distribution shifts that degrade performance, especially in low-data regions. Out-of-distribution (OOD) detection addresses this by identifying inputs that deviate from indistribution (ID) data. However, existing methods either assume access to OOD data or compromise primary task performance, limiting real-world use. We introduce TARDIS, a post-hoc OOD detection method designed for scalable geospatial deployment. Our core innovation lies in generating surrogate distribution labels by leveraging ID data within the feature space. TARDIS takes a pre-trained model, ID data, and data from an unknown distribution (WILD), separates WILD into surrogate ID and OOD labels based on internal activations, and trains a binary classifier to detect distribution shifts. We validate on EuroSAT and xBD across 17 setups covering covariate and semantic shifts, showing near-upper-bound surrogate labeling performance in 13 cases and matching the performance of top post-hoc activation-and scoring-based methods. Finally, deploying TARDIS on Fields of the World reveals actionable insights into pre-trained model behavior at scale. The code is available at https://github.com/microsoft/geospatial-ood-detection",
        "keywords": []
      },
      "file_name": "90af5e08aa6e57e55124dd3f1f40bdb0c051b7c9.pdf"
    },
    {
      "success": true,
      "doc_id": "145bb22211156eca725f2fc4f532a6ae",
      "summary": "Here's a focused summary of the paper \"Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning\" \\cite{shin2024lnf} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of Out-of-Distribution (OOD) detection in models trained on long-tailed datasets. Specifically, existing methods struggle to reliably distinguish between tail-class in-distribution (ID) samples and OOD samples.\n    *   **Importance & Challenge:** This problem is critical for reliable machine learning, as overconfidence in OOD samples can lead to harmful decisions. The challenge arises because methods designed for long-tailed recognition (LTR) and OOD detection often have conflicting goals in the logit space, leading to trade-offs between ID classification accuracy (especially for tail classes) and OOD detection performance \\cite{shin2024lnf}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Previous work in OOD detection for long-tail learning (LT-OOD) includes training methodologies like PASCL \\cite{shin2024lnf} and BEL \\cite{shin2024lnf} (often using two-branch architectures), post-hoc scoring techniques \\cite{shin2024lnf}, and abstention class learning methods like EAT \\cite{shin2024lnf} and COCL \\cite{shin2024lnf}.\n    *   **Limitations of Previous Solutions:**\n        *   Simply combining existing LTR methods (e.g., Logit Adjustment - LA) with OOD methods (e.g., Outlier Exposure - OE) results in performance trade-offs, where improving one metric (e.g., OOD detection) degrades the other (e.g., tail-class classification accuracy) \\cite{shin2024lnf}.\n        *   Methods like PASCL and BEL often rely on two-branch architectures, increasing model complexity.\n        *   While some methods utilize representation norms for OOD scoring (e.g., Objectosphere \\cite{shin2024lnf}, CSI \\cite{shin2024lnf}, NAN \\cite{shin2024lnf}), they generally lack a dedicated training method to *actively widen the gap* between ID and OOD representation norms.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper introduces Representation Norm Amplification (RNA) \\cite{shin2024lnf}, a novel training method that decouples ID classification and OOD detection. It uses the norm of the representation vector as a new dimension for OOD detection, while classification is handled in the logit space.\n    *   **Novelty/Difference:**\n        *   RNA \\cite{shin2024lnf} intentionally induces a noticeable discrepancy in the representation norm between ID and OOD data.\n        *   It achieves this by training the classifier to minimize classification loss *only for ID samples*, regularized by a loss that *enlarges the norm of ID representations*.\n        *   Crucially, auxiliary OOD samples are passed through the network to regularize Batch Normalization (BN) layers using both ID and OOD data. This process indirectly reduces OOD representation norms and creates a discernible difference in activation ratios and representation norms.\n        *   The key innovation is that *only ID data is involved in the gradient for updating model parameters* for the classification objective, ensuring that feature learning for ID classification is not perturbed by OOD regularization.\n\n*   **Key Technical Contributions**\n    *   **Novel Training Method:** RNA \\cite{shin2024lnf} provides a unique training methodology that disentangles ID classification and OOD detection in long-tail learning by leveraging representation norms.\n    *   **Decoupling Strategy:** It proposes a novel strategy to decouple these two problems, performing classification in the logit space and OOD detection in the embedding space using representation norms.\n    *   **Mechanism for Norm Discrepancy:** The method introduces a specific mechanism involving ID norm amplification and BN layer regularization with OOD data to create a clear separation in representation norms.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** RNA \\cite{shin2024lnf} was evaluated on standard OOD detection benchmarks in long-tail settings.\n    *   **Key Performance Metrics & Comparison:**\n        *   **Metrics:** FPR95 (False Positive Rate at 95% True Positive Rate for OOD detection) and classification accuracy.\n        *   **Datasets:** CIFAR10-LT and ImageNet-LT.\n        *   **Results:** RNA \\cite{shin2024lnf} achieved superior performance compared to state-of-the-art methods:\n            *   Improved FPR95 by 1.70% (CIFAR10-LT) and 9.46% (ImageNet-LT).\n            *   Improved classification accuracy by 2.43% (CIFAR10-LT) and 6.87% (ImageNet-LT).\n            *   Demonstrated simultaneous high performance in both OOD detection and classification, effectively overcoming the trade-offs observed in previous methods (e.g., CE+OE, LA+OE, PASCL).\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The method relies on the availability of an auxiliary OOD dataset for training, similar to Outlier Exposure. The effectiveness of the BN regularization mechanism is central to its performance.\n    *   **Scope of Applicability:** RNA \\cite{shin2024lnf} is specifically designed for OOD detection in the context of *long-tail learning*, where class imbalance is a significant factor.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** RNA \\cite{shin2024lnf} significantly advances the technical state-of-the-art by providing a method that simultaneously achieves high performance in both OOD detection and long-tail classification, resolving a long-standing trade-off.\n    *   **Potential Impact:** It introduces a new paradigm for tackling combined OOD and long-tail problems by decoupling them and leveraging representation norms. This could inspire future research into alternative dimensions or spaces for OOD detection that do not interfere with the primary classification task, particularly in challenging imbalanced data scenarios.",
      "intriguing_abstract": "The reliable detection of Out-of-Distribution (OOD) samples in long-tail learning remains a critical challenge, often plagued by a persistent dilemma: improving OOD performance degrades tail-class classification, and vice-versa. This fundamental trade-off leads to models that are either unreliable for novel inputs or inaccurate for rare, yet crucial, in-distribution classes.\n\nWe introduce **Representation Norm Amplification (RNA)**, a novel training methodology that fundamentally decouples ID classification from OOD detection. Unlike prior methods, RNA leverages the **representation norm** as a dedicated dimension for OOD detection, while classification occurs robustly in the **logit space**. Our key innovation lies in actively amplifying the norms of in-distribution (ID) representations while simultaneously regularizing **Batch Normalization (BN)** layers with auxiliary OOD data to reduce OOD norms. Crucially, only ID data contributes to the classification gradient, ensuring robust feature learning unperturbed by OOD regularization.\n\nRNA achieves unprecedented gains, outperforming state-of-the-art methods by significantly improving both OOD detection (**FPR95**) and long-tail **classification accuracy** on CIFAR10-LT and ImageNet-LT datasets. This novel paradigm resolves the long-standing trade-off, offering a robust solution for real-world **imbalanced data** scenarios and paving the way for future research into decoupled OOD detection strategies.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "long-tail learning",
        "Representation Norm Amplification (RNA)",
        "decoupling strategy",
        "representation norms",
        "ID norm amplification",
        "Batch Normalization regularization",
        "auxiliary OOD samples",
        "trade-off resolution",
        "simultaneous high performance",
        "FPR95"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/71fdc063701dc3f431942398d53b0290a9975d32.pdf",
      "citation_key": "shin2024lnf",
      "metadata": {
        "title": "Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning",
        "authors": [
          "Dong Geun Shin",
          "Hye Won Chung"
        ],
        "published_date": "2024",
        "abstract": "Detecting out-of-distribution (OOD) samples is a critical task for reliable machine learning. However, it becomes particularly challenging when the models are trained on long-tailed datasets, as the models often struggle to distinguish tail-class in-distribution samples from OOD samples. We examine the main challenges in this problem by identifying the trade-offs between OOD detection and in-distribution (ID) classification, faced by existing methods. We then introduce our method, called \\textit{Representation Norm Amplification} (RNA), which solves this challenge by decoupling the two problems. The main idea is to use the norm of the representation as a new dimension for OOD detection, and to develop a training method that generates a noticeable discrepancy in the representation norm between ID and OOD data, while not perturbing the feature learning for ID classification. Our experiments show that RNA achieves superior performance in both OOD detection and classification compared to the state-of-the-art methods, by 1.70\\% and 9.46\\% in FPR95 and 2.43\\% and 6.87\\% in classification accuracy on CIFAR10-LT and ImageNet-LT, respectively. The code for this work is available at https://github.com/dgshin21/RNA.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/71fdc063701dc3f431942398d53b0290a9975d32.pdf",
        "venue": "Trans. Mach. Learn. Res.",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the paper \"Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning\" \\cite{shin2024lnf} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of Out-of-Distribution (OOD) detection in models trained on long-tailed datasets. Specifically, existing methods struggle to reliably distinguish between tail-class in-distribution (ID) samples and OOD samples.\n    *   **Importance & Challenge:** This problem is critical for reliable machine learning, as overconfidence in OOD samples can lead to harmful decisions. The challenge arises because methods designed for long-tailed recognition (LTR) and OOD detection often have conflicting goals in the logit space, leading to trade-offs between ID classification accuracy (especially for tail classes) and OOD detection performance \\cite{shin2024lnf}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Previous work in OOD detection for long-tail learning (LT-OOD) includes training methodologies like PASCL \\cite{shin2024lnf} and BEL \\cite{shin2024lnf} (often using two-branch architectures), post-hoc scoring techniques \\cite{shin2024lnf}, and abstention class learning methods like EAT \\cite{shin2024lnf} and COCL \\cite{shin2024lnf}.\n    *   **Limitations of Previous Solutions:**\n        *   Simply combining existing LTR methods (e.g., Logit Adjustment - LA) with OOD methods (e.g., Outlier Exposure - OE) results in performance trade-offs, where improving one metric (e.g., OOD detection) degrades the other (e.g., tail-class classification accuracy) \\cite{shin2024lnf}.\n        *   Methods like PASCL and BEL often rely on two-branch architectures, increasing model complexity.\n        *   While some methods utilize representation norms for OOD scoring (e.g., Objectosphere \\cite{shin2024lnf}, CSI \\cite{shin2024lnf}, NAN \\cite{shin2024lnf}), they generally lack a dedicated training method to *actively widen the gap* between ID and OOD representation norms.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper introduces Representation Norm Amplification (RNA) \\cite{shin2024lnf}, a novel training method that decouples ID classification and OOD detection. It uses the norm of the representation vector as a new dimension for OOD detection, while classification is handled in the logit space.\n    *   **Novelty/Difference:**\n        *   RNA \\cite{shin2024lnf} intentionally induces a noticeable discrepancy in the representation norm between ID and OOD data.\n        *   It achieves this by training the classifier to minimize classification loss *only for ID samples*, regularized by a loss that *enlarges the norm of ID representations*.\n        *   Crucially, auxiliary OOD samples are passed through the network to regularize Batch Normalization (BN) layers using both ID and OOD data. This process indirectly reduces OOD representation norms and creates a discernible difference in activation ratios and representation norms.\n        *   The key innovation is that *only ID data is involved in the gradient for updating model parameters* for the classification objective, ensuring that feature learning for ID classification is not perturbed by OOD regularization.\n\n*   **Key Technical Contributions**\n    *   **Novel Training Method:** RNA \\cite{shin2024lnf} provides a unique training methodology that disentangles ID classification and OOD detection in long-tail learning by leveraging representation norms.\n    *   **Decoupling Strategy:** It proposes a novel strategy to decouple these two problems, performing classification in the logit space and OOD detection in the embedding space using representation norms.\n    *   **Mechanism for Norm Discrepancy:** The method introduces a specific mechanism involving ID norm amplification and BN layer regularization with OOD data to create a clear separation in representation norms.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** RNA \\cite{shin2024lnf} was evaluated on standard OOD detection benchmarks in long-tail settings.\n    *   **Key Performance Metrics & Comparison:**\n        *   **Metrics:** FPR95 (False Positive Rate at 95% True Positive Rate for OOD detection) and classification accuracy.\n        *   **Datasets:** CIFAR10-LT and ImageNet-LT.\n        *   **Results:** RNA \\cite{shin2024lnf} achieved superior performance compared to state-of-the-art methods:\n            *   Improved FPR95 by 1.70% (CIFAR10-LT) and 9.46% (ImageNet-LT).\n            *   Improved classification accuracy by 2.43% (CIFAR10-LT) and 6.87% (ImageNet-LT).\n            *   Demonstrated simultaneous high performance in both OOD detection and classification, effectively overcoming the trade-offs observed in previous methods (e.g., CE+OE, LA+OE, PASCL).\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The method relies on the availability of an auxiliary OOD dataset for training, similar to Outlier Exposure. The effectiveness of the BN regularization mechanism is central to its performance.\n    *   **Scope of Applicability:** RNA \\cite{shin2024lnf} is specifically designed for OOD detection in the context of *long-tail learning*, where class imbalance is a significant factor.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** RNA \\cite{shin2024lnf} significantly advances the technical state-of-the-art by providing a method that simultaneously achieves high performance in both OOD detection and long-tail classification, resolving a long-standing trade-off.\n    *   **Potential Impact:** It introduces a new paradigm for tackling combined OOD and long-tail problems by decoupling them and leveraging representation norms. This could inspire future research into alternative dimensions or spaces for OOD detection that do not interfere with the primary classification task, particularly in challenging imbalanced data scenarios.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "long-tail learning",
          "Representation Norm Amplification (RNA)",
          "decoupling strategy",
          "representation norms",
          "ID norm amplification",
          "Batch Normalization regularization",
          "auxiliary OOD samples",
          "trade-off resolution",
          "simultaneous high performance",
          "FPR95"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we then introduce our method, called representation norm amplification (rna), which solves this challenge...\" and describes its mechanism (\"use the norm of the representation as a new dimension for ood detection, and to develop a training method\"). this directly aligns with the \"technical\" criteria of presenting new methods, algorithms, or systems.\n*   the introduction discusses a technical problem (\"new challenges in ood detection posed by long-tailed datasets\") and the need for \"improved methods,\" leading into the proposed solution.\n*   while the paper also presents \"experiments\" and \"superior performance\" with quantitative results (fpr95, classification accuracy), which are characteristics of an \"empirical\" paper, these experiments serve to validate the *new method* being proposed. the core contribution is the method itself.\n\ntherefore, the primary classification is **technical**."
      },
      "file_name": "71fdc063701dc3f431942398d53b0290a9975d32.pdf"
    },
    {
      "success": true,
      "doc_id": "dd3eb6233915d483b3ffb70986d2957f",
      "summary": "Here is a focused summary of the paper \"Towards Out-of-Distribution Detection in Vocoder Recognition via Latent Feature Reconstruction\" \\cite{du2024kj8} for a literature review:\n\n### Technical Paper Analysis: Towards Out-of-Distribution Detection in Vocoder Recognition via Latent Feature Reconstruction \\cite{du2024kj8}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection in deepfake algorithm recognition, specifically focusing on identifying unknown vocoder algorithms used in synthesized speech.\n    *   **Importance and Challenge**: The growing threat of impersonation due to advancements in synthesized speech necessitates robust deepfake detection. Existing vocoder recognition systems cannot cover all possible vocoder algorithms, making OOD detection crucial. Current OOD detection methods, primarily probability-score-based or classify-distance-based, suffer from limitations such as reduced accuracy for samples near decision thresholds and a lack of explicit consideration for the speech synthesis process's characteristic tendencies.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds upon the field of deepfake algorithm recognition, particularly OOD detection, which has been a focus in challenges like ASVspoof and ADD.\n    *   **Limitations of Previous Solutions**:\n        *   **Probability-score-based methods**: Rely on the premise that in-distribution (ID) samples have higher maximum softmax probabilities. They struggle to evaluate the proximity of outliers to inlier classes as they are trained only on ID data.\n        *   **Classify-distance-based methods**: Aim to classify samples far from ID class centers as OOD. However, relying solely on distance can impact accuracy for samples at the threshold's edge.\n        *   **General limitations**: Both methods require careful selection of thresholds, which can significantly affect results. They also do not explicitly consider the synthetic audio generation process and its characteristic tendencies.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a reconstruction-based OOD detection approach utilizing an autoencoder architecture. This architecture consists of a single encoder and multiple decoders, where each decoder is specialized to reconstruct acoustic features corresponding to a specific vocoder class.\n    *   **Novelty/Differentiation**:\n        *   **Reconstruction-based OOD detection**: Unlike probability or distance-based methods, this approach classifies a sample as OOD if none of the class-specific decoders can satisfactorily reconstruct its features, directly leveraging reconstruction error.\n        *   **Class-specific decoders**: Each decoder is trained to reconstruct features for only one specific vocoder class, ensuring that features from other classes (including OOD) result in high reconstruction error.\n        *   **Contrastive Learning**: Incorporated to enhance the distinctiveness of reconstructed features by minimizing the distance between an input feature and its corresponding decoder's reconstruction, while maximizing the distance to reconstructions from other decoders.\n        *   **Auxiliary Classifier**: Added to constrain the encoder's output, ensuring that the compressed representation is closely aligned with its relevant class before decoding, preventing the encoder from generating overly similar outputs across classes.\n        *   **WavLM Features**: Utilizes acoustic features extracted from a pre-trained WavLM model, leveraging its universal speech representations.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: A reconstruction-based OOD detection algorithm for vocoder recognition, employing a multi-decoder autoencoder.\n    *   **Methodological Innovation**: Integration of contrastive learning and an auxiliary classifier within the autoencoder framework to improve the distinctiveness of class-specific reconstructions and constrain encoder outputs.\n    *   **Feature Engineering**: Investigation into the optimal WavLM intermediate layers for acoustic feature extraction in this specific OOD detection task.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Comparison against three baseline deepfake detection systems.\n        *   Ablation studies to validate the effectiveness of contrastive loss and the auxiliary classifier.\n        *   Investigation of different WavLM intermediate layers for feature extraction.\n        *   Visualization of Mean Square Error (MSE) distribution for ID vs. OOD samples.\n    *   **Datasets**: WaveFake dataset (MelGAN, FullBand-MelGAN, MelGAN-Large, MultiBand-MelGAN, HiFi-GAN, Parallel WaveGAN, WaveGlow) for ID samples. BigvGAN and UnivNet for OOD samples.\n    *   **Baseline Systems**: ECAPA-TDNN \\cite{du2024kj8}, AASIST \\cite{du2024kj8}, and RawNet2 \\cite{du2024kj8}.\n    *   **Key Performance Metrics**: Accuracy (Acc), Macro-average precision (MAP), Recall rate (Recall), and F1 score (F1).\n    *   **Comparison Results**:\n        *   The proposed approach (Proposed (weighted-18)) achieved an F1 score of 68.04%, surpassing the best baseline (AASIST at 64.08%) by a relative margin of approximately 10%.\n        *   Ablation studies showed significant performance drops without contrastive loss (F1: 59.21%) and without the auxiliary classifier (F1: 55.48%), confirming their effectiveness.\n        *   The 6th layer of WavLM provided the highest classification accuracy for vocoder classes, but combining weighted features from layers up to the 18th (Proposed (weighted-18)) yielded the best OOD detection performance.\n        *   MSE visualization demonstrated a clear distinction between ID and OOD samples, supporting the reconstruction-error-based detection mechanism.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The OOD detection relies on a predefined MSE threshold, similar to how previous methods relied on probability or distance thresholds, which still requires careful selection. The paper uses the averaged MSE loss from the last training epoch as the threshold.\n    *   **Scope of Applicability**: The method is specifically designed and validated for out-of-distribution detection in *vocoder recognition* within the context of deepfake audio detection. Its direct applicability to other OOD detection tasks without adaptation is not explicitly discussed.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work advances the technical state-of-the-art by introducing a novel reconstruction-based paradigm for OOD detection in vocoder recognition, which explicitly considers the characteristics of the speech synthesis process. It addresses the limitations of existing probability-score and classify-distance-based methods, particularly concerning samples at decision boundaries.\n    *   **Potential Impact**: The proposed method offers a more robust and accurate approach to identifying unknown deepfake vocoders, enhancing the security of speech communities. The integration of contrastive learning and auxiliary classification provides a blueprint for improving feature distinctiveness in similar reconstruction-based anomaly detection tasks. The investigation into WavLM layers also provides valuable insights for future research utilizing pre-trained speech models.",
      "intriguing_abstract": "The escalating threat of deepfake audio demands robust detection systems capable of identifying even *unknown* synthesis algorithms, a critical challenge for current vocoder recognition approaches. This paper introduces a novel *reconstruction-based Out-of-Distribution (OOD) detection* paradigm, specifically designed to identify unknown vocoders in synthesized speech. Our innovative multi-decoder autoencoder architecture features class-specific decoders, each trained to reconstruct acoustic features for a single vocoder type. OOD samples are effectively identified by their significantly high *reconstruction error* across all decoders. To enhance feature distinctiveness and constrain latent representations, we integrate *contrastive learning* and an *auxiliary classifier*, leveraging universal *WavLM features*. Experimental results demonstrate that our method significantly outperforms state-of-the-art baselines, achieving a 10% relative improvement in F1 score. This work advances the technical state-of-the-art, offering a more resilient solution for deepfake detection and providing a powerful blueprint for reconstruction-based anomaly detection in critical security applications.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "vocoder recognition",
        "deepfake algorithm recognition",
        "reconstruction-based OOD detection",
        "multi-decoder autoencoder",
        "class-specific decoders",
        "contrastive learning",
        "auxiliary classifier",
        "WavLM features",
        "reconstruction error",
        "synthesized speech",
        "speech synthesis process characteristics"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/59fdf00e73e64dd9104ec4df010fc3bc4eac6c66.pdf",
      "citation_key": "du2024kj8",
      "metadata": {
        "title": "Towards Out-of-Distribution Detection in Vocoder Recognition via Latent Feature Reconstruction",
        "authors": [
          "Renmingyue Du",
          "Jixun Yao",
          "Qiuqiang Kong",
          "Yin Cao"
        ],
        "published_date": "2024",
        "abstract": "Advancements in synthesized speech have created a growing threat of impersonation, making it crucial to develop deepfake algorithm recognition. One significant aspect is out-of-distribution (OOD) detection, which has gained notable attention due to its important role in deepfake algorithm recognition. However, most of the current approaches for detecting OOD in deepfake algorithm recognition rely on probability-score or classified-distance, which may lead to limitations in the accuracy of the sample at the edge of the threshold. In this study, we propose a reconstruction-based detection approach that employs an autoencoder architecture to compress and reconstruct the acoustic feature extracted from a pre-trained WavLM model. Each acoustic feature belonging to a specific vocoder class is only aptly reconstructed by its corresponding decoder. When none of the decoders can satisfactorily reconstruct a feature, it is classified as an OOD sample. To enhance the distinctiveness of the reconstructed features by each decoder, we incorporate contrastive learning and an auxiliary classifier to further constrain the reconstructed feature. Experiments demonstrate that our proposed approach surpasses baseline systems by a relative margin of 10\\% in the evaluation dataset. Ablation studies further validate the effectiveness of both the contrastive constraint and the auxiliary classifier within our proposed approach.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/59fdf00e73e64dd9104ec4df010fc3bc4eac6c66.pdf",
        "venue": "",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here is a focused summary of the paper \"Towards Out-of-Distribution Detection in Vocoder Recognition via Latent Feature Reconstruction\" \\cite{du2024kj8} for a literature review:\n\n### Technical Paper Analysis: Towards Out-of-Distribution Detection in Vocoder Recognition via Latent Feature Reconstruction \\cite{du2024kj8}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection in deepfake algorithm recognition, specifically focusing on identifying unknown vocoder algorithms used in synthesized speech.\n    *   **Importance and Challenge**: The growing threat of impersonation due to advancements in synthesized speech necessitates robust deepfake detection. Existing vocoder recognition systems cannot cover all possible vocoder algorithms, making OOD detection crucial. Current OOD detection methods, primarily probability-score-based or classify-distance-based, suffer from limitations such as reduced accuracy for samples near decision thresholds and a lack of explicit consideration for the speech synthesis process's characteristic tendencies.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds upon the field of deepfake algorithm recognition, particularly OOD detection, which has been a focus in challenges like ASVspoof and ADD.\n    *   **Limitations of Previous Solutions**:\n        *   **Probability-score-based methods**: Rely on the premise that in-distribution (ID) samples have higher maximum softmax probabilities. They struggle to evaluate the proximity of outliers to inlier classes as they are trained only on ID data.\n        *   **Classify-distance-based methods**: Aim to classify samples far from ID class centers as OOD. However, relying solely on distance can impact accuracy for samples at the threshold's edge.\n        *   **General limitations**: Both methods require careful selection of thresholds, which can significantly affect results. They also do not explicitly consider the synthetic audio generation process and its characteristic tendencies.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a reconstruction-based OOD detection approach utilizing an autoencoder architecture. This architecture consists of a single encoder and multiple decoders, where each decoder is specialized to reconstruct acoustic features corresponding to a specific vocoder class.\n    *   **Novelty/Differentiation**:\n        *   **Reconstruction-based OOD detection**: Unlike probability or distance-based methods, this approach classifies a sample as OOD if none of the class-specific decoders can satisfactorily reconstruct its features, directly leveraging reconstruction error.\n        *   **Class-specific decoders**: Each decoder is trained to reconstruct features for only one specific vocoder class, ensuring that features from other classes (including OOD) result in high reconstruction error.\n        *   **Contrastive Learning**: Incorporated to enhance the distinctiveness of reconstructed features by minimizing the distance between an input feature and its corresponding decoder's reconstruction, while maximizing the distance to reconstructions from other decoders.\n        *   **Auxiliary Classifier**: Added to constrain the encoder's output, ensuring that the compressed representation is closely aligned with its relevant class before decoding, preventing the encoder from generating overly similar outputs across classes.\n        *   **WavLM Features**: Utilizes acoustic features extracted from a pre-trained WavLM model, leveraging its universal speech representations.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: A reconstruction-based OOD detection algorithm for vocoder recognition, employing a multi-decoder autoencoder.\n    *   **Methodological Innovation**: Integration of contrastive learning and an auxiliary classifier within the autoencoder framework to improve the distinctiveness of class-specific reconstructions and constrain encoder outputs.\n    *   **Feature Engineering**: Investigation into the optimal WavLM intermediate layers for acoustic feature extraction in this specific OOD detection task.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Comparison against three baseline deepfake detection systems.\n        *   Ablation studies to validate the effectiveness of contrastive loss and the auxiliary classifier.\n        *   Investigation of different WavLM intermediate layers for feature extraction.\n        *   Visualization of Mean Square Error (MSE) distribution for ID vs. OOD samples.\n    *   **Datasets**: WaveFake dataset (MelGAN, FullBand-MelGAN, MelGAN-Large, MultiBand-MelGAN, HiFi-GAN, Parallel WaveGAN, WaveGlow) for ID samples. BigvGAN and UnivNet for OOD samples.\n    *   **Baseline Systems**: ECAPA-TDNN \\cite{du2024kj8}, AASIST \\cite{du2024kj8}, and RawNet2 \\cite{du2024kj8}.\n    *   **Key Performance Metrics**: Accuracy (Acc), Macro-average precision (MAP), Recall rate (Recall), and F1 score (F1).\n    *   **Comparison Results**:\n        *   The proposed approach (Proposed (weighted-18)) achieved an F1 score of 68.04%, surpassing the best baseline (AASIST at 64.08%) by a relative margin of approximately 10%.\n        *   Ablation studies showed significant performance drops without contrastive loss (F1: 59.21%) and without the auxiliary classifier (F1: 55.48%), confirming their effectiveness.\n        *   The 6th layer of WavLM provided the highest classification accuracy for vocoder classes, but combining weighted features from layers up to the 18th (Proposed (weighted-18)) yielded the best OOD detection performance.\n        *   MSE visualization demonstrated a clear distinction between ID and OOD samples, supporting the reconstruction-error-based detection mechanism.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The OOD detection relies on a predefined MSE threshold, similar to how previous methods relied on probability or distance thresholds, which still requires careful selection. The paper uses the averaged MSE loss from the last training epoch as the threshold.\n    *   **Scope of Applicability**: The method is specifically designed and validated for out-of-distribution detection in *vocoder recognition* within the context of deepfake audio detection. Its direct applicability to other OOD detection tasks without adaptation is not explicitly discussed.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work advances the technical state-of-the-art by introducing a novel reconstruction-based paradigm for OOD detection in vocoder recognition, which explicitly considers the characteristics of the speech synthesis process. It addresses the limitations of existing probability-score and classify-distance-based methods, particularly concerning samples at decision boundaries.\n    *   **Potential Impact**: The proposed method offers a more robust and accurate approach to identifying unknown deepfake vocoders, enhancing the security of speech communities. The integration of contrastive learning and auxiliary classification provides a blueprint for improving feature distinctiveness in similar reconstruction-based anomaly detection tasks. The investigation into WavLM layers also provides valuable insights for future research utilizing pre-trained speech models.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "vocoder recognition",
          "deepfake algorithm recognition",
          "reconstruction-based OOD detection",
          "multi-decoder autoencoder",
          "class-specific decoders",
          "contrastive learning",
          "auxiliary classifier",
          "WavLM features",
          "reconstruction error",
          "synthesized speech",
          "speech synthesis process characteristics"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose a reconstruction-based detection approach** that employs an **autoencoder architecture** to compress and reconstruct the acoustic feature...\" and \"we **incorporate contrastive learning and an auxiliary classifier**\". these phrases directly align with the \"technical\" classification criteria of presenting new methods, algorithms, or systems.\n*   the abstract also mentions: \"**experiments demonstrate that our proposed approach surpasses baseline systems**\" and \"**ablation studies further validate the effectiveness**\". these indicate an empirical evaluation of the proposed method.\n\nwhile the paper clearly includes an empirical component, its primary contribution, as highlighted by the \"propose\" and detailed description of the \"approach\" and \"architecture,\" is the development of a new method. the experiments serve to validate this new technical contribution. therefore, the paper's core type is best described as **technical**.\n\n**classification:** technical"
      },
      "file_name": "59fdf00e73e64dd9104ec4df010fc3bc4eac6c66.pdf"
    },
    {
      "success": true,
      "doc_id": "a4dc8627fc345429a1108e368dabbe5f",
      "summary": "Out-of-distribution (OOD) detection is essential in autonomous driving, to determine when learning-based components encounter unexpected inputs. Traditional detectors typically use encoder models with fixed settings, thus lacking effective human interaction capabilities. With the rise of large foundation models, multimodal inputs offer the possibility of taking human language as a latent representation, thus enabling language-defined OOD detection. In this paper, we use the cosine similarity of image and text representations encoded by the multimodal model CLIP as a new representation to improve the transparency and controllability of latent encodings used for visual anomaly detection. We compare our approach with existing pre-trained encoders that can only produce latent representations that are meaningless from the user's standpoint. Our experiments on realistic driving data show that the language-based latent representation performs better than the traditional representation of the vision encoder and helps improve the detection performance when combined with standard representations.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection is essential in autonomous driving, to determine when learning-based components encounter unexpected inputs. Traditional detectors typically use encoder models with fixed settings, thus lacking effective human interaction capabilities. With the rise of large foundation models, multimodal inputs offer the possibility of taking human language as a latent representation, thus enabling language-defined OOD detection. In this paper, we use the cosine similarity of image and text representations encoded by the multimodal model CLIP as a new representation to improve the transparency and controllability of latent encodings used for visual anomaly detection. We compare our approach with existing pre-trained encoders that can only produce latent representations that are meaningless from the user's standpoint. Our experiments on realistic driving data show that the language-based latent representation performs better than the traditional representation of the vision encoder and helps improve the detection performance when combined with standard representations.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/f561b83d58498973ec9252054ae38a29aa3f8b42.pdf",
      "citation_key": "mao20244lp",
      "metadata": {
        "title": "Language-Enhanced Latent Representations for Out-of-Distribution Detection in Autonomous Driving",
        "authors": [
          "Zhenjiang Mao",
          "Dong-You Jhong",
          "Ao Wang",
          "Ivan Ruchkin"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is essential in autonomous driving, to determine when learning-based components encounter unexpected inputs. Traditional detectors typically use encoder models with fixed settings, thus lacking effective human interaction capabilities. With the rise of large foundation models, multimodal inputs offer the possibility of taking human language as a latent representation, thus enabling language-defined OOD detection. In this paper, we use the cosine similarity of image and text representations encoded by the multimodal model CLIP as a new representation to improve the transparency and controllability of latent encodings used for visual anomaly detection. We compare our approach with existing pre-trained encoders that can only produce latent representations that are meaningless from the user's standpoint. Our experiments on realistic driving data show that the language-based latent representation performs better than the traditional representation of the vision encoder and helps improve the detection performance when combined with standard representations.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/f561b83d58498973ec9252054ae38a29aa3f8b42.pdf",
        "venue": "arXiv.org",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Out-of-distribution (OOD) detection is essential in autonomous driving, to determine when learning-based components encounter unexpected inputs. Traditional detectors typically use encoder models with fixed settings, thus lacking effective human interaction capabilities. With the rise of large foundation models, multimodal inputs offer the possibility of taking human language as a latent representation, thus enabling language-defined OOD detection. In this paper, we use the cosine similarity of image and text representations encoded by the multimodal model CLIP as a new representation to improve the transparency and controllability of latent encodings used for visual anomaly detection. We compare our approach with existing pre-trained encoders that can only produce latent representations that are meaningless from the user's standpoint. Our experiments on realistic driving data show that the language-based latent representation performs better than the traditional representation of the vision encoder and helps improve the detection performance when combined with standard representations.",
        "keywords": []
      },
      "file_name": "f561b83d58498973ec9252054ae38a29aa3f8b42.pdf"
    },
    {
      "success": true,
      "doc_id": "114a128eba61af65b504c5eb181af31a",
      "summary": "The rise of foundation models is pushing Computer Vision research towards a paradigm shift, in the wake of what already happened in the Natural Language Processing field. These models, trained at scale on huge data collections, provide high-quality representations that generalize well enough to be applied directly to downstream tasks, often outperforming task-specific models. The Out Of Distribution (OOD) detection problem, which involves the ability to recognize when test samples come from a previously unseen semantic category, represents one of the research fields in which this paradigm shift could have the greatest impact. However, existing testbeds are limited in scale and scope and get easily saturated when adopting foundation-based pretrainings. With this work, we introduce a new benchmark covering realistic yet harder OOD detection tasks to properly assess the performance of large pretrained models. We design an experimental framework to analyze specific choices in the model learning and use (which dataset, pretraining objective, OOD scoring function) and extensively evaluate the comparison to standard approaches that leverage a training phase on the available In Distribution (ID) data. The results highlight the actual performance benefits of leveraging foundation models in this context without any further learning effort, and identify situations where task-specific fine-tuning remains the best choice.",
      "intriguing_abstract": "The rise of foundation models is pushing Computer Vision research towards a paradigm shift, in the wake of what already happened in the Natural Language Processing field. These models, trained at scale on huge data collections, provide high-quality representations that generalize well enough to be applied directly to downstream tasks, often outperforming task-specific models. The Out Of Distribution (OOD) detection problem, which involves the ability to recognize when test samples come from a previously unseen semantic category, represents one of the research fields in which this paradigm shift could have the greatest impact. However, existing testbeds are limited in scale and scope and get easily saturated when adopting foundation-based pretrainings. With this work, we introduce a new benchmark covering realistic yet harder OOD detection tasks to properly assess the performance of large pretrained models. We design an experimental framework to analyze specific choices in the model learning and use (which dataset, pretraining objective, OOD scoring function) and extensively evaluate the comparison to standard approaches that leverage a training phase on the available In Distribution (ID) data. The results highlight the actual performance benefits of leveraging foundation models in this context without any further learning effort, and identify situations where task-specific fine-tuning remains the best choice.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/38866b5afbf33b7207ce4e23b0a58d0745835570.pdf",
      "citation_key": "borlino20245ku",
      "metadata": {
        "title": "Foundation Models and Fine-Tuning: A Benchmark for Out of Distribution Detection",
        "authors": [
          "Francesco Cappio Borlino",
          "L. Lu",
          "Tatiana Tommasi"
        ],
        "published_date": "2024",
        "abstract": "The rise of foundation models is pushing Computer Vision research towards a paradigm shift, in the wake of what already happened in the Natural Language Processing field. These models, trained at scale on huge data collections, provide high-quality representations that generalize well enough to be applied directly to downstream tasks, often outperforming task-specific models. The Out Of Distribution (OOD) detection problem, which involves the ability to recognize when test samples come from a previously unseen semantic category, represents one of the research fields in which this paradigm shift could have the greatest impact. However, existing testbeds are limited in scale and scope and get easily saturated when adopting foundation-based pretrainings. With this work, we introduce a new benchmark covering realistic yet harder OOD detection tasks to properly assess the performance of large pretrained models. We design an experimental framework to analyze specific choices in the model learning and use (which dataset, pretraining objective, OOD scoring function) and extensively evaluate the comparison to standard approaches that leverage a training phase on the available In Distribution (ID) data. The results highlight the actual performance benefits of leveraging foundation models in this context without any further learning effort, and identify situations where task-specific fine-tuning remains the best choice.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/38866b5afbf33b7207ce4e23b0a58d0745835570.pdf",
        "venue": "IEEE Access",
        "citationCount": 3,
        "score": 3.0,
        "summary": "The rise of foundation models is pushing Computer Vision research towards a paradigm shift, in the wake of what already happened in the Natural Language Processing field. These models, trained at scale on huge data collections, provide high-quality representations that generalize well enough to be applied directly to downstream tasks, often outperforming task-specific models. The Out Of Distribution (OOD) detection problem, which involves the ability to recognize when test samples come from a previously unseen semantic category, represents one of the research fields in which this paradigm shift could have the greatest impact. However, existing testbeds are limited in scale and scope and get easily saturated when adopting foundation-based pretrainings. With this work, we introduce a new benchmark covering realistic yet harder OOD detection tasks to properly assess the performance of large pretrained models. We design an experimental framework to analyze specific choices in the model learning and use (which dataset, pretraining objective, OOD scoring function) and extensively evaluate the comparison to standard approaches that leverage a training phase on the available In Distribution (ID) data. The results highlight the actual performance benefits of leveraging foundation models in this context without any further learning effort, and identify situations where task-specific fine-tuning remains the best choice.",
        "keywords": []
      },
      "file_name": "38866b5afbf33b7207ce4e23b0a58d0745835570.pdf"
    },
    {
      "success": true,
      "doc_id": "07899f9a9323ec351b6ca94b156ff0cc",
      "summary": "Although deep neural networks have made significant progress in tasks related to remote sensing image scene classification, most of these tasks assume that the training and test data are independently and identically distributed. However, when remote sensing scene classification models are deployed in the real world, the model will inevitably encounter situations where the distribution of the test set differs from that of the training set, leading to unpredictable errors during the inference and testing phase. For instance, in the context of large-scale remote sensing scene classification applications, it is difficult to obtain all the feature classes in the training phase. Consequently, during the inference and testing phases, the model will categorize images of unidentified unknown classes into known classes. Therefore, the deployment of out-of-distribution (OOD) detection within the realm of remote sensing scene classification is crucial for ensuring the reliability and safety of model application in real-world scenarios. Despite significant advancements in OOD detection methods in recent years, there remains a lack of a unified benchmark for evaluating various OOD methods specifically in remote sensing scene classification tasks. We designed different benchmarks on three classical remote sensing datasets to simulate scenes with different distributional shift. Ten different types of OOD detection methods were employed, and their performance was evaluated and compared using quantitative metrics. Numerous experiments were conducted to evaluate the overall performance of these state-of-the-art OOD detection methods under different test benchmarks. The comparative results show that the virtual-logit matching methods without additional training outperform the other types of methods on our benchmarks, suggesting that additional training methods are unnecessary for remote sensing image scene classification applications. Furthermore, we provide insights into OOD detection models and performance enhancement in real world. To the best of our knowledge, this study is the first evaluation and analysis of methods for detecting out-of-distribution data in remote sensing. We hope that this research will serve as a fundamental resource for future studies on out-of-distribution detection in remote sensing.",
      "intriguing_abstract": "Although deep neural networks have made significant progress in tasks related to remote sensing image scene classification, most of these tasks assume that the training and test data are independently and identically distributed. However, when remote sensing scene classification models are deployed in the real world, the model will inevitably encounter situations where the distribution of the test set differs from that of the training set, leading to unpredictable errors during the inference and testing phase. For instance, in the context of large-scale remote sensing scene classification applications, it is difficult to obtain all the feature classes in the training phase. Consequently, during the inference and testing phases, the model will categorize images of unidentified unknown classes into known classes. Therefore, the deployment of out-of-distribution (OOD) detection within the realm of remote sensing scene classification is crucial for ensuring the reliability and safety of model application in real-world scenarios. Despite significant advancements in OOD detection methods in recent years, there remains a lack of a unified benchmark for evaluating various OOD methods specifically in remote sensing scene classification tasks. We designed different benchmarks on three classical remote sensing datasets to simulate scenes with different distributional shift. Ten different types of OOD detection methods were employed, and their performance was evaluated and compared using quantitative metrics. Numerous experiments were conducted to evaluate the overall performance of these state-of-the-art OOD detection methods under different test benchmarks. The comparative results show that the virtual-logit matching methods without additional training outperform the other types of methods on our benchmarks, suggesting that additional training methods are unnecessary for remote sensing image scene classification applications. Furthermore, we provide insights into OOD detection models and performance enhancement in real world. To the best of our knowledge, this study is the first evaluation and analysis of methods for detecting out-of-distribution data in remote sensing. We hope that this research will serve as a fundamental resource for future studies on out-of-distribution detection in remote sensing.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/2fd2e37ffd4e45eab72eab0a22512d5fe1adfdf3.pdf",
      "citation_key": "li2024tk8",
      "metadata": {
        "title": "Evaluation of Ten Deep-Learning-Based Out-of-Distribution Detection Methods for Remote Sensing Image Scene Classification",
        "authors": [
          "SiCong Li",
          "Ning Li",
          "Min Jing",
          "Chen Ji",
          "Liang Cheng"
        ],
        "published_date": "2024",
        "abstract": "Although deep neural networks have made significant progress in tasks related to remote sensing image scene classification, most of these tasks assume that the training and test data are independently and identically distributed. However, when remote sensing scene classification models are deployed in the real world, the model will inevitably encounter situations where the distribution of the test set differs from that of the training set, leading to unpredictable errors during the inference and testing phase. For instance, in the context of large-scale remote sensing scene classification applications, it is difficult to obtain all the feature classes in the training phase. Consequently, during the inference and testing phases, the model will categorize images of unidentified unknown classes into known classes. Therefore, the deployment of out-of-distribution (OOD) detection within the realm of remote sensing scene classification is crucial for ensuring the reliability and safety of model application in real-world scenarios. Despite significant advancements in OOD detection methods in recent years, there remains a lack of a unified benchmark for evaluating various OOD methods specifically in remote sensing scene classification tasks. We designed different benchmarks on three classical remote sensing datasets to simulate scenes with different distributional shift. Ten different types of OOD detection methods were employed, and their performance was evaluated and compared using quantitative metrics. Numerous experiments were conducted to evaluate the overall performance of these state-of-the-art OOD detection methods under different test benchmarks. The comparative results show that the virtual-logit matching methods without additional training outperform the other types of methods on our benchmarks, suggesting that additional training methods are unnecessary for remote sensing image scene classification applications. Furthermore, we provide insights into OOD detection models and performance enhancement in real world. To the best of our knowledge, this study is the first evaluation and analysis of methods for detecting out-of-distribution data in remote sensing. We hope that this research will serve as a fundamental resource for future studies on out-of-distribution detection in remote sensing.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/2fd2e37ffd4e45eab72eab0a22512d5fe1adfdf3.pdf",
        "venue": "Remote Sensing",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Although deep neural networks have made significant progress in tasks related to remote sensing image scene classification, most of these tasks assume that the training and test data are independently and identically distributed. However, when remote sensing scene classification models are deployed in the real world, the model will inevitably encounter situations where the distribution of the test set differs from that of the training set, leading to unpredictable errors during the inference and testing phase. For instance, in the context of large-scale remote sensing scene classification applications, it is difficult to obtain all the feature classes in the training phase. Consequently, during the inference and testing phases, the model will categorize images of unidentified unknown classes into known classes. Therefore, the deployment of out-of-distribution (OOD) detection within the realm of remote sensing scene classification is crucial for ensuring the reliability and safety of model application in real-world scenarios. Despite significant advancements in OOD detection methods in recent years, there remains a lack of a unified benchmark for evaluating various OOD methods specifically in remote sensing scene classification tasks. We designed different benchmarks on three classical remote sensing datasets to simulate scenes with different distributional shift. Ten different types of OOD detection methods were employed, and their performance was evaluated and compared using quantitative metrics. Numerous experiments were conducted to evaluate the overall performance of these state-of-the-art OOD detection methods under different test benchmarks. The comparative results show that the virtual-logit matching methods without additional training outperform the other types of methods on our benchmarks, suggesting that additional training methods are unnecessary for remote sensing image scene classification applications. Furthermore, we provide insights into OOD detection models and performance enhancement in real world. To the best of our knowledge, this study is the first evaluation and analysis of methods for detecting out-of-distribution data in remote sensing. We hope that this research will serve as a fundamental resource for future studies on out-of-distribution detection in remote sensing.",
        "keywords": []
      },
      "file_name": "2fd2e37ffd4e45eab72eab0a22512d5fe1adfdf3.pdf"
    },
    {
      "success": true,
      "doc_id": "3693a85cb00884634d3a268f8a640278",
      "summary": "Out-of-distribution (OOD) detection is a crucial problem in practice, especially, for the safe deployment of machine learning models in industrial settings. Previous work has used free energy as a score function and proposed a fine-tuning method that utilized OOD data in the training phase of the classification model, which achieves a higher performance on the OOD detection task compared with traditional methods. One key drawback, however, is that the loss function parameters are highly dependent on involved datasets, which means it cannot be dynamically adapted and implemented in others settings; in other words, the general ability of the energy score is considerably limited. In this work, our point of departure is to enlarge distinguishability between in-distribution features and OOD data. Consequently, we present a simple yet effective sparsity-regularized (SR) tuning framework for this purpose. Our framework has two types of workflows depending on if external OOD data is available, the complexity of the original training loss is sharply reduced by adopting this modification, meanwhile, the adapted ability and detection performance are enhanced. Also, we contribute a mini dataset as a light and efficient alternative of the previous large-scale one. In the experiments, we verify the effectiveness of our framework in a wide range of typical datasets along with common network architectures.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection is a crucial problem in practice, especially, for the safe deployment of machine learning models in industrial settings. Previous work has used free energy as a score function and proposed a fine-tuning method that utilized OOD data in the training phase of the classification model, which achieves a higher performance on the OOD detection task compared with traditional methods. One key drawback, however, is that the loss function parameters are highly dependent on involved datasets, which means it cannot be dynamically adapted and implemented in others settings; in other words, the general ability of the energy score is considerably limited. In this work, our point of departure is to enlarge distinguishability between in-distribution features and OOD data. Consequently, we present a simple yet effective sparsity-regularized (SR) tuning framework for this purpose. Our framework has two types of workflows depending on if external OOD data is available, the complexity of the original training loss is sharply reduced by adopting this modification, meanwhile, the adapted ability and detection performance are enhanced. Also, we contribute a mini dataset as a light and efficient alternative of the previous large-scale one. In the experiments, we verify the effectiveness of our framework in a wide range of typical datasets along with common network architectures.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/b84938e00a7c422dd68cecc1b11117c455fdc7f1.pdf",
      "citation_key": "chen20247p7",
      "metadata": {
        "title": "Exploring feature sparsity for out-of-distribution detection",
        "authors": [
          "Qichao Chen",
          "Kuan Li",
          "Zhiyuan Chen",
          "Tomas Maul",
          "Jianping Yin"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is a crucial problem in practice, especially, for the safe deployment of machine learning models in industrial settings. Previous work has used free energy as a score function and proposed a fine-tuning method that utilized OOD data in the training phase of the classification model, which achieves a higher performance on the OOD detection task compared with traditional methods. One key drawback, however, is that the loss function parameters are highly dependent on involved datasets, which means it cannot be dynamically adapted and implemented in others settings; in other words, the general ability of the energy score is considerably limited. In this work, our point of departure is to enlarge distinguishability between in-distribution features and OOD data. Consequently, we present a simple yet effective sparsity-regularized (SR) tuning framework for this purpose. Our framework has two types of workflows depending on if external OOD data is available, the complexity of the original training loss is sharply reduced by adopting this modification, meanwhile, the adapted ability and detection performance are enhanced. Also, we contribute a mini dataset as a light and efficient alternative of the previous large-scale one. In the experiments, we verify the effectiveness of our framework in a wide range of typical datasets along with common network architectures.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b84938e00a7c422dd68cecc1b11117c455fdc7f1.pdf",
        "venue": "Scientific Reports",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Out-of-distribution (OOD) detection is a crucial problem in practice, especially, for the safe deployment of machine learning models in industrial settings. Previous work has used free energy as a score function and proposed a fine-tuning method that utilized OOD data in the training phase of the classification model, which achieves a higher performance on the OOD detection task compared with traditional methods. One key drawback, however, is that the loss function parameters are highly dependent on involved datasets, which means it cannot be dynamically adapted and implemented in others settings; in other words, the general ability of the energy score is considerably limited. In this work, our point of departure is to enlarge distinguishability between in-distribution features and OOD data. Consequently, we present a simple yet effective sparsity-regularized (SR) tuning framework for this purpose. Our framework has two types of workflows depending on if external OOD data is available, the complexity of the original training loss is sharply reduced by adopting this modification, meanwhile, the adapted ability and detection performance are enhanced. Also, we contribute a mini dataset as a light and efficient alternative of the previous large-scale one. In the experiments, we verify the effectiveness of our framework in a wide range of typical datasets along with common network architectures.",
        "keywords": []
      },
      "file_name": "b84938e00a7c422dd68cecc1b11117c455fdc7f1.pdf"
    },
    {
      "success": true,
      "doc_id": "c72651f51ced2826414f68c59a8b9d2e",
      "summary": "Out-of-distribution (OOD) detection is a crucial part of deploying machine learning models safely. It has been extensively studied with a plethora of methods developed in the literature. This problem is tackled with an OOD score computation, however, previous methods compute the OOD scores with limited usage of the in-distribution dataset. For instance, the OOD scores are computed with information from a small portion of the in-distribution data. Furthermore, these methods encode images with a neural image encoder. The robustness of these methods is rarely checked with respect to image encoders of different training methods and architectures. In this work, we introduce the diffusion process into the OOD task. The diffusion model integrates information on the whole training set into the predicted noise vectors. What's more, we deduce a closed-form solution for the noise vector (stable point). Then the noise vector is converted into our OOD score, we test both the deep model predicted noise vector and the closed-form noise vector on the OOD benchmarks \\cite{openood}. Our method outperforms previous OOD methods across all types of image encoders (Table. \\ref{main}). A $3.5\\%$ performance gain is achieved with the MAE-based image encoder. Moreover, we studied the robustness of OOD methods by applying different types of image encoders. Some OOD methods failed to generalize well when switching image encoders from ResNet to Vision Transformers, our method performs exhibits good robustness with all the image encoders.",
      "intriguing_abstract": "Out-of-distribution (OOD) detection is a crucial part of deploying machine learning models safely. It has been extensively studied with a plethora of methods developed in the literature. This problem is tackled with an OOD score computation, however, previous methods compute the OOD scores with limited usage of the in-distribution dataset. For instance, the OOD scores are computed with information from a small portion of the in-distribution data. Furthermore, these methods encode images with a neural image encoder. The robustness of these methods is rarely checked with respect to image encoders of different training methods and architectures. In this work, we introduce the diffusion process into the OOD task. The diffusion model integrates information on the whole training set into the predicted noise vectors. What's more, we deduce a closed-form solution for the noise vector (stable point). Then the noise vector is converted into our OOD score, we test both the deep model predicted noise vector and the closed-form noise vector on the OOD benchmarks \\cite{openood}. Our method outperforms previous OOD methods across all types of image encoders (Table. \\ref{main}). A $3.5\\%$ performance gain is achieved with the MAE-based image encoder. Moreover, we studied the robustness of OOD methods by applying different types of image encoders. Some OOD methods failed to generalize well when switching image encoders from ResNet to Vision Transformers, our method performs exhibits good robustness with all the image encoders.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/df088cb9d0e12f9c4879d82191366e7476167480.pdf",
      "citation_key": "zhou2024ae1",
      "metadata": {
        "title": "NODI: Out-Of-Distribution Detection with Noise from Diffusion",
        "authors": [
          "Jingqiu Zhou",
          "Aojun Zhou",
          "Hongsheng Li"
        ],
        "published_date": "2024",
        "abstract": "Out-of-distribution (OOD) detection is a crucial part of deploying machine learning models safely. It has been extensively studied with a plethora of methods developed in the literature. This problem is tackled with an OOD score computation, however, previous methods compute the OOD scores with limited usage of the in-distribution dataset. For instance, the OOD scores are computed with information from a small portion of the in-distribution data. Furthermore, these methods encode images with a neural image encoder. The robustness of these methods is rarely checked with respect to image encoders of different training methods and architectures. In this work, we introduce the diffusion process into the OOD task. The diffusion model integrates information on the whole training set into the predicted noise vectors. What's more, we deduce a closed-form solution for the noise vector (stable point). Then the noise vector is converted into our OOD score, we test both the deep model predicted noise vector and the closed-form noise vector on the OOD benchmarks \\cite{openood}. Our method outperforms previous OOD methods across all types of image encoders (Table. \\ref{main}). A $3.5\\%$ performance gain is achieved with the MAE-based image encoder. Moreover, we studied the robustness of OOD methods by applying different types of image encoders. Some OOD methods failed to generalize well when switching image encoders from ResNet to Vision Transformers, our method performs exhibits good robustness with all the image encoders.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/df088cb9d0e12f9c4879d82191366e7476167480.pdf",
        "venue": "arXiv.org",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Out-of-distribution (OOD) detection is a crucial part of deploying machine learning models safely. It has been extensively studied with a plethora of methods developed in the literature. This problem is tackled with an OOD score computation, however, previous methods compute the OOD scores with limited usage of the in-distribution dataset. For instance, the OOD scores are computed with information from a small portion of the in-distribution data. Furthermore, these methods encode images with a neural image encoder. The robustness of these methods is rarely checked with respect to image encoders of different training methods and architectures. In this work, we introduce the diffusion process into the OOD task. The diffusion model integrates information on the whole training set into the predicted noise vectors. What's more, we deduce a closed-form solution for the noise vector (stable point). Then the noise vector is converted into our OOD score, we test both the deep model predicted noise vector and the closed-form noise vector on the OOD benchmarks \\cite{openood}. Our method outperforms previous OOD methods across all types of image encoders (Table. \\ref{main}). A $3.5\\%$ performance gain is achieved with the MAE-based image encoder. Moreover, we studied the robustness of OOD methods by applying different types of image encoders. Some OOD methods failed to generalize well when switching image encoders from ResNet to Vision Transformers, our method performs exhibits good robustness with all the image encoders.",
        "keywords": []
      },
      "file_name": "df088cb9d0e12f9c4879d82191366e7476167480.pdf"
    },
    {
      "success": true,
      "doc_id": "e4fd3e394eca3ed6de8a4b0ff6cf5c64",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Deep neural networks often exhibit inadequate robustness and reliability when encountering out-of-distribution (OoD) data, particularly in safety-critical applications like autonomous driving.\n    *   A key challenge is that these networks typically lack the ability to reliably detect when an input is OoD, making it difficult to trust their predictions.\n    *   Existing OoD detection benchmarks for semantic segmentation primarily focus on constrained domains like road scenes, limiting the semantic diversity (e.g., 19 classes from Cityscapes), which does not reflect the complexity of real-world scenarios.\n\n*   **Related Work & Positioning**\n    *   **Limitations of previous solutions**:\n        *   Many generative models (e.g., GANs) for OoD detection require training with proxy outliers or comparison networks, which `\\cite{galesso2024g7t}` avoids.\n        *   Non-parametric methods (e.g., kNNs like cDNP \\cite{13}) are effective but `\\cite{galesso2024g7t}` proposes a parametric density estimator (diffusion model) for improved robustness.\n        *   Confidence-based methods from segmentation models often rely on the model's inherent prediction confidence, which can be overconfident for OoD data.\n        *   Domain-specific methods (e.g., JSRNet \\cite{47} for road surfaces) are not generalizable to diverse scenes.\n        *   Previous diffusion-based OoD methods often rely on expensive input reconstruction, leading to long runtimes, or use less effective OoD score computations (e.g., L2 distance of estimated scores to perturbations \\cite{40}).\n    *   **Positioning**: `\\cite{galesso2024g7t}` extends OoD detection for semantic segmentation to general natural images, addressing the limitation of constrained road scene benchmarks. It builds on the idea of using deep segmentation embedding spaces for OoD detection \\cite{13} but improves upon it with a parametric diffusion model. It leverages score matching interpretations of diffusion models, but introduces a novel score computation and architecture tailored for this task.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method (DOoD - Diffusion for OoD Detection)**: `\\cite{galesso2024g7t}` proposes a two-step approach:\n        1.  **Feature Extraction**: Utilizes a pre-trained semantic segmentation model (e.g., ViT/MiT encoders) to extract dense feature maps (specifically, key features from transformer encoders) from input images. These features are known to induce meaningful distances between in-distribution and OoD entities.\n        2.  **OoD Score Estimation**: A diffusion model is trained on individual feature vectors extracted from in-distribution data. At inference, OoD scores are computed pixel-wise based on the directional similarity between the estimated score from the diffusion model and the perturbation noise. Lower scores indicate higher likelihood of being OoD.\n    *   **Novel Architecture**: Replaces the common 2D U-Net denoiser in diffusion models with a **small MLP-based denoiser**. This MLP operates on *individual feature vectors* (not spatial feature maps) to explicitly discard harmful spatial correlations. This prevents the model from easily reconstructing or \"explaining away\" anomalous features by extrapolating from neighboring in-distribution features.\n    *   **Novel OoD Score Computation**: Instead of reconstruction errors or L2 distances, `\\cite{galesso2024g7t}` computes OoD scores based on the **directional similarity (dot product)** between the estimated score (derived from the diffusion model's noise prediction) and the perturbation noise. This is averaged over multiple diffusion timesteps and noise samples for robustness.\n\n*   **Key Technical Contributions**\n    *   **Novel Benchmark**: Introduction of **ADE-OoD**, a new benchmark for OoD detection in semantic segmentation, based on the ADE20k dataset. It features 150 in-distribution categories and diverse indoor/outdoor scenes with high semantic complexity, significantly expanding beyond traditional road scene benchmarks.\n    *   **Novel Algorithm (DOoD)**: A diffusion score matching approach for pixel-wise OoD detection that is robust to high semantic diversity.\n    *   **System Design/Architectural Innovation**: The use of an **MLP-based denoiser** operating on individual feature vectors, rather than a 2D U-Net, to prevent the exploitation of spatial correlations for anomaly reconstruction.\n    *   **Novel OoD Score Metric**: Computation of OoD scores based on the **directional similarity** between the estimated score and the perturbation, which is shown to be effective.\n\n*   **Experimental Validation**\n    *   **Benchmarks**: Evaluated DOoD on standard road scene OoD benchmarks (RoadAnomaly \\cite{28}, Fishyscapes Lost&Found \\cite{4,36}, SMIYC-Anomaly \\cite{6}) and the newly introduced ADE-OoD benchmark.\n    *   **Performance**:\n        *   On common road scene benchmarks, DOoD performs **on par or better than the state of the art**, notably without requiring outlier data for training or making assumptions about the data domain.\n        *   On the challenging ADE-OoD benchmark, DOoD **outperforms previous approaches**, demonstrating its robustness to increased semantic diversity, though the paper notes there is still significant room for future improvements.\n        *   The approach is particularly effective for detecting semantically anomalous objects and in scenarios with large domain shifts.\n\n*   **Limitations & Scope**\n    *   While outperforming previous methods on ADE-OoD, the paper acknowledges that the benchmark \"leaves much room for future improvements,\" indicating that current methods, including DOoD, are not yet fully robust to the extreme diversity of general natural images.\n    *   The method relies on features extracted from a pre-trained semantic segmentation model, meaning its performance is inherently tied to the quality and generalizability of the chosen feature extractor.\n    *   The MLP denoiser explicitly discards spatial correlations, which, while beneficial for preventing anomaly reconstruction, might implicitly limit the model's ability to leverage potentially useful global context in certain complex OoD scenarios.\n\n*   **Technical Significance**\n    *   `\\cite{galesso2024g7t}` significantly advances the technical state-of-the-art by extending OoD detection for semantic segmentation from constrained road scenes to the more challenging domain of general natural images.\n    *   The introduction of the ADE-OoD benchmark provides a crucial new tool for evaluating and driving research in this expanded domain, pushing the boundaries of what current OoD methods can achieve.\n    *   The DOoD method, with its innovative MLP-based diffusion architecture and directional score computation, offers a robust and generalizable approach that does not require outlier training, making it highly practical.\n    *   This work opens new avenues for research into more robust and generalizable OoD detection techniques, particularly in complex, high-diversity environments, and encourages the development of diffusion models tailored for specific data characteristics (e.g., feature spaces).",
      "intriguing_abstract": "Deep neural networks often falter when confronted with out-of-distribution (OoD) data, posing significant reliability risks in safety-critical semantic segmentation. Current OoD detection benchmarks are limited to constrained domains, failing to capture the immense semantic diversity of real-world scenarios. We introduce DOoD (Diffusion for OoD Detection), a novel approach that extends pixel-wise OoD detection to general natural images, addressing this critical gap.\n\nDOoD leverages pre-trained segmentation feature spaces and a **diffusion score matching** model to estimate OoD scores. Our key innovations include an **MLP-based denoiser** operating on individual feature vectors, explicitly discarding spatial correlations to prevent anomalous feature reconstruction. Furthermore, we propose a novel OoD score computation based on the **directional similarity** between the estimated score and perturbation noise. To drive research in this expanded domain, we present **ADE-OoD**, a new benchmark featuring 150 diverse semantic categories. DOoD achieves state-of-the-art performance on existing benchmarks and significantly outperforms prior methods on the challenging ADE-OoD, demonstrating superior robustness to semantic diversity. This work marks a crucial step towards building more trustworthy and reliable AI systems for complex real-world environments.",
      "keywords": [
        "Out-of-distribution (OoD) detection",
        "semantic segmentation",
        "deep neural network robustness",
        "diffusion models",
        "DOoD algorithm",
        "MLP-based denoiser",
        "directional similarity score",
        "ADE-OoD benchmark",
        "general natural images",
        "feature extraction",
        "pixel-wise OoD detection",
        "high semantic diversity",
        "safety-critical applications",
        "score matching"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/26d34f9c230a93506b60465daaaae8c23011f412.pdf",
      "citation_key": "galesso2024g7t",
      "metadata": {
        "title": "Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond",
        "authors": [
          "Silvio Galesso",
          "Philipp SchrÃ¶ppel",
          "Hssan Driss",
          "Thomas Brox"
        ],
        "published_date": "2024",
        "abstract": "In recent years, research on out-of-distribution (OoD) detection for semantic segmentation has mainly focused on road scenes -- a domain with a constrained amount of semantic diversity. In this work, we challenge this constraint and extend the domain of this task to general natural images. To this end, we introduce: 1. the ADE-OoD benchmark, which is based on the ADE20k dataset and includes images from diverse domains with a high semantic diversity, and 2. a novel approach that uses Diffusion score matching for OoD detection (DOoD) and is robust to the increased semantic diversity. ADE-OoD features indoor and outdoor images, defines 150 semantic categories as in-distribution, and contains a variety of OoD objects. For DOoD, we train a diffusion model with an MLP architecture on semantic in-distribution embeddings and build on the score matching interpretation to compute pixel-wise OoD scores at inference time. On common road scene OoD benchmarks, DOoD performs on par or better than the state of the art, without using outliers for training or making assumptions about the data domain. On ADE-OoD, DOoD outperforms previous approaches, but leaves much room for future improvements.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/26d34f9c230a93506b60465daaaae8c23011f412.pdf",
        "venue": "European Conference on Computer Vision",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Deep neural networks often exhibit inadequate robustness and reliability when encountering out-of-distribution (OoD) data, particularly in safety-critical applications like autonomous driving.\n    *   A key challenge is that these networks typically lack the ability to reliably detect when an input is OoD, making it difficult to trust their predictions.\n    *   Existing OoD detection benchmarks for semantic segmentation primarily focus on constrained domains like road scenes, limiting the semantic diversity (e.g., 19 classes from Cityscapes), which does not reflect the complexity of real-world scenarios.\n\n*   **Related Work & Positioning**\n    *   **Limitations of previous solutions**:\n        *   Many generative models (e.g., GANs) for OoD detection require training with proxy outliers or comparison networks, which `\\cite{galesso2024g7t}` avoids.\n        *   Non-parametric methods (e.g., kNNs like cDNP \\cite{13}) are effective but `\\cite{galesso2024g7t}` proposes a parametric density estimator (diffusion model) for improved robustness.\n        *   Confidence-based methods from segmentation models often rely on the model's inherent prediction confidence, which can be overconfident for OoD data.\n        *   Domain-specific methods (e.g., JSRNet \\cite{47} for road surfaces) are not generalizable to diverse scenes.\n        *   Previous diffusion-based OoD methods often rely on expensive input reconstruction, leading to long runtimes, or use less effective OoD score computations (e.g., L2 distance of estimated scores to perturbations \\cite{40}).\n    *   **Positioning**: `\\cite{galesso2024g7t}` extends OoD detection for semantic segmentation to general natural images, addressing the limitation of constrained road scene benchmarks. It builds on the idea of using deep segmentation embedding spaces for OoD detection \\cite{13} but improves upon it with a parametric diffusion model. It leverages score matching interpretations of diffusion models, but introduces a novel score computation and architecture tailored for this task.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method (DOoD - Diffusion for OoD Detection)**: `\\cite{galesso2024g7t}` proposes a two-step approach:\n        1.  **Feature Extraction**: Utilizes a pre-trained semantic segmentation model (e.g., ViT/MiT encoders) to extract dense feature maps (specifically, key features from transformer encoders) from input images. These features are known to induce meaningful distances between in-distribution and OoD entities.\n        2.  **OoD Score Estimation**: A diffusion model is trained on individual feature vectors extracted from in-distribution data. At inference, OoD scores are computed pixel-wise based on the directional similarity between the estimated score from the diffusion model and the perturbation noise. Lower scores indicate higher likelihood of being OoD.\n    *   **Novel Architecture**: Replaces the common 2D U-Net denoiser in diffusion models with a **small MLP-based denoiser**. This MLP operates on *individual feature vectors* (not spatial feature maps) to explicitly discard harmful spatial correlations. This prevents the model from easily reconstructing or \"explaining away\" anomalous features by extrapolating from neighboring in-distribution features.\n    *   **Novel OoD Score Computation**: Instead of reconstruction errors or L2 distances, `\\cite{galesso2024g7t}` computes OoD scores based on the **directional similarity (dot product)** between the estimated score (derived from the diffusion model's noise prediction) and the perturbation noise. This is averaged over multiple diffusion timesteps and noise samples for robustness.\n\n*   **Key Technical Contributions**\n    *   **Novel Benchmark**: Introduction of **ADE-OoD**, a new benchmark for OoD detection in semantic segmentation, based on the ADE20k dataset. It features 150 in-distribution categories and diverse indoor/outdoor scenes with high semantic complexity, significantly expanding beyond traditional road scene benchmarks.\n    *   **Novel Algorithm (DOoD)**: A diffusion score matching approach for pixel-wise OoD detection that is robust to high semantic diversity.\n    *   **System Design/Architectural Innovation**: The use of an **MLP-based denoiser** operating on individual feature vectors, rather than a 2D U-Net, to prevent the exploitation of spatial correlations for anomaly reconstruction.\n    *   **Novel OoD Score Metric**: Computation of OoD scores based on the **directional similarity** between the estimated score and the perturbation, which is shown to be effective.\n\n*   **Experimental Validation**\n    *   **Benchmarks**: Evaluated DOoD on standard road scene OoD benchmarks (RoadAnomaly \\cite{28}, Fishyscapes Lost&Found \\cite{4,36}, SMIYC-Anomaly \\cite{6}) and the newly introduced ADE-OoD benchmark.\n    *   **Performance**:\n        *   On common road scene benchmarks, DOoD performs **on par or better than the state of the art**, notably without requiring outlier data for training or making assumptions about the data domain.\n        *   On the challenging ADE-OoD benchmark, DOoD **outperforms previous approaches**, demonstrating its robustness to increased semantic diversity, though the paper notes there is still significant room for future improvements.\n        *   The approach is particularly effective for detecting semantically anomalous objects and in scenarios with large domain shifts.\n\n*   **Limitations & Scope**\n    *   While outperforming previous methods on ADE-OoD, the paper acknowledges that the benchmark \"leaves much room for future improvements,\" indicating that current methods, including DOoD, are not yet fully robust to the extreme diversity of general natural images.\n    *   The method relies on features extracted from a pre-trained semantic segmentation model, meaning its performance is inherently tied to the quality and generalizability of the chosen feature extractor.\n    *   The MLP denoiser explicitly discards spatial correlations, which, while beneficial for preventing anomaly reconstruction, might implicitly limit the model's ability to leverage potentially useful global context in certain complex OoD scenarios.\n\n*   **Technical Significance**\n    *   `\\cite{galesso2024g7t}` significantly advances the technical state-of-the-art by extending OoD detection for semantic segmentation from constrained road scenes to the more challenging domain of general natural images.\n    *   The introduction of the ADE-OoD benchmark provides a crucial new tool for evaluating and driving research in this expanded domain, pushing the boundaries of what current OoD methods can achieve.\n    *   The DOoD method, with its innovative MLP-based diffusion architecture and directional score computation, offers a robust and generalizable approach that does not require outlier training, making it highly practical.\n    *   This work opens new avenues for research into more robust and generalizable OoD detection techniques, particularly in complex, high-diversity environments, and encourages the development of diffusion models tailored for specific data characteristics (e.g., feature spaces).",
        "keywords": [
          "Out-of-distribution (OoD) detection",
          "semantic segmentation",
          "deep neural network robustness",
          "diffusion models",
          "DOoD algorithm",
          "MLP-based denoiser",
          "directional similarity score",
          "ADE-OoD benchmark",
          "general natural images",
          "feature extraction",
          "pixel-wise OoD detection",
          "high semantic diversity",
          "safety-critical applications",
          "score matching"
        ],
        "paper_type": "based on the abstract and introduction, this paper is best classified as **technical**.\n\nhere's why:\n\n*   **abstract mentions:** \"we introduce ... a novel approach that uses diffusion score matching for ood detection (dood)\", \"train a diffusion model with an mlp architecture\", \"compute pixel-wise ood scores\". these phrases clearly indicate the development and presentation of a new method or system. it also introduces a new benchmark (ade-ood), which is a technical contribution in itself (a new resource/system).\n*   **introduction discusses:** it sets up a technical problem (ood detection for semantic segmentation) and then immediately points to the proposed solution by linking to the \"dood code\". the empirical results presented in the abstract serve to validate the effectiveness of this novel technical approach.\n\nwhile it also contains strong empirical elements (introducing a benchmark, performing experiments, comparing to state-of-the-art), the core contribution is the \"novel approach\" (dood) and the new \"benchmark\" (ade-ood), making it primarily a technical paper that includes empirical validation."
      },
      "file_name": "26d34f9c230a93506b60465daaaae8c23011f412.pdf"
    },
    {
      "success": true,
      "doc_id": "8d4b0621c0e49963c18129cea3202d09",
      "summary": "Deep neural networks (DNNs) are often constructed under the closed-world assumption, which may fail to generalize to the out-of-distribution (OOD) data. This leads to DNNs producing overconfident wrong predictions and can result in disastrous consequences in safety-critical applications. Existing OOD detection methods mainly rely on curating a set of OOD data for model training or hyper-parameter tuning to distinguish OOD data from training data (also known as in-distribution data or InD data). However, OOD samples are not always available during the training phase in real-world applications, hindering the OOD detection accuracy. To overcome this limitation, we propose a Gaussian-process-based OOD detection method to establish a decision boundary based on InD data only. The basic idea is to perform uncertainty quantification of the unconstrained softmax scores of a DNN via a multi-class Gaussian process (GP), and then define a score function to separate InD and potential OOD data based on their fundamental differences in the posterior predictive distribution from the GP. Two case studies on conventional image classification datasets and real-world image datasets are conducted to demonstrate that the proposed method outperforms the state-of-the-art OOD detection methods when OOD samples are not observed in the training phase.",
      "intriguing_abstract": "Deep neural networks (DNNs) are often constructed under the closed-world assumption, which may fail to generalize to the out-of-distribution (OOD) data. This leads to DNNs producing overconfident wrong predictions and can result in disastrous consequences in safety-critical applications. Existing OOD detection methods mainly rely on curating a set of OOD data for model training or hyper-parameter tuning to distinguish OOD data from training data (also known as in-distribution data or InD data). However, OOD samples are not always available during the training phase in real-world applications, hindering the OOD detection accuracy. To overcome this limitation, we propose a Gaussian-process-based OOD detection method to establish a decision boundary based on InD data only. The basic idea is to perform uncertainty quantification of the unconstrained softmax scores of a DNN via a multi-class Gaussian process (GP), and then define a score function to separate InD and potential OOD data based on their fundamental differences in the posterior predictive distribution from the GP. Two case studies on conventional image classification datasets and real-world image datasets are conducted to demonstrate that the proposed method outperforms the state-of-the-art OOD detection methods when OOD samples are not observed in the training phase.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/375583f16d9ee1947397d993859fcd75811cade9.pdf",
      "citation_key": "chen202491k",
      "metadata": {
        "title": "Uncertainty-Aware Out-of-Distribution Detection with Gaussian Processes",
        "authors": [
          "Yang Chen",
          "Chih-Li Sung",
          "A. Kusari",
          "Xiaoyang Song",
          "Wenbo Sun"
        ],
        "published_date": "2024",
        "abstract": "Deep neural networks (DNNs) are often constructed under the closed-world assumption, which may fail to generalize to the out-of-distribution (OOD) data. This leads to DNNs producing overconfident wrong predictions and can result in disastrous consequences in safety-critical applications. Existing OOD detection methods mainly rely on curating a set of OOD data for model training or hyper-parameter tuning to distinguish OOD data from training data (also known as in-distribution data or InD data). However, OOD samples are not always available during the training phase in real-world applications, hindering the OOD detection accuracy. To overcome this limitation, we propose a Gaussian-process-based OOD detection method to establish a decision boundary based on InD data only. The basic idea is to perform uncertainty quantification of the unconstrained softmax scores of a DNN via a multi-class Gaussian process (GP), and then define a score function to separate InD and potential OOD data based on their fundamental differences in the posterior predictive distribution from the GP. Two case studies on conventional image classification datasets and real-world image datasets are conducted to demonstrate that the proposed method outperforms the state-of-the-art OOD detection methods when OOD samples are not observed in the training phase.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/375583f16d9ee1947397d993859fcd75811cade9.pdf",
        "venue": "arXiv.org",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Deep neural networks (DNNs) are often constructed under the closed-world assumption, which may fail to generalize to the out-of-distribution (OOD) data. This leads to DNNs producing overconfident wrong predictions and can result in disastrous consequences in safety-critical applications. Existing OOD detection methods mainly rely on curating a set of OOD data for model training or hyper-parameter tuning to distinguish OOD data from training data (also known as in-distribution data or InD data). However, OOD samples are not always available during the training phase in real-world applications, hindering the OOD detection accuracy. To overcome this limitation, we propose a Gaussian-process-based OOD detection method to establish a decision boundary based on InD data only. The basic idea is to perform uncertainty quantification of the unconstrained softmax scores of a DNN via a multi-class Gaussian process (GP), and then define a score function to separate InD and potential OOD data based on their fundamental differences in the posterior predictive distribution from the GP. Two case studies on conventional image classification datasets and real-world image datasets are conducted to demonstrate that the proposed method outperforms the state-of-the-art OOD detection methods when OOD samples are not observed in the training phase.",
        "keywords": []
      },
      "file_name": "375583f16d9ee1947397d993859fcd75811cade9.pdf"
    },
    {
      "success": true,
      "doc_id": "179e4c031593a5ad7f02ec064cca3be8",
      "summary": "Here's a focused summary of the paper \\cite{long2024os1} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper \\cite{long2024os1} addresses a fundamental flaw in the evaluation of Out-of-Distribution (OOD) detection methods: existing benchmarks primarily classify samples with novel labels as OOD, even if their semantic content is very close to in-distribution (ID) data.\n    *   This creates a \"Sorites Paradox\" â€“ an ambiguity in defining what constitutes an OOD sample, as there's no clear boundary for \"how different\" a sample must be. This problem is important because it leads to inaccurate assessment of OOD detection models and hinders progress in developing robust systems.\n    *   Current benchmarks often suffer from issues like similar, overlapping, or insufficient semantic labels, making manual filtering labor-intensive and subjective \\cite{long2024os1}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection benchmarks typically use two datasets with non-overlapping semantic labels for ID and OOD data \\cite{long2024os1}.\n    *   The limitation of previous solutions is their reliance on semantic labels alone to define OOD, which fails to account for the *degree* of semantic and covariate shifts, leading to the Sorites Paradox \\cite{long2024os1}.\n    *   This work positions itself by moving beyond a binary OOD/ID classification to a continuous measurement of \"shift degrees\" relative to ID data, providing a more nuanced and robust evaluation framework \\cite{long2024os1}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is the construction of the **Incremental Shift OOD (IS-OOD) benchmark** \\cite{long2024os1}. This benchmark divides test samples into subsets based on their measured semantic and covariate shift degrees relative to the ID dataset (ImageNet-1K).\n    *   A key innovation is the **Language Aligned Image feature Decomposition (LAID)** method \\cite{long2024os1}. LAID leverages the aligned text and image features of the CLIP model to decompose image features into distinct semantic and covariate components.\n    *   LAID trains an orthogonal transformation matrix in the text feature space (using constructed texts with semantic and covariate prompts and triplet loss) and then applies this matrix to the image feature space, enabling separate measurement of semantic and covariate shifts \\cite{long2024os1}.\n    *   The paper \\cite{long2024os1} also introduces **Synthetic Incremental Shift (Syn-IS)**, a dataset of high-quality generated images with diverse covariate contents (using SDXL-Turbo and official style templates) to complement IS-OOD, addressing the limited covariate variation in real-world datasets like ImageNet-21K.\n\n*   **Key Technical Contributions**\n    *   **Novel Benchmark**: Construction of the IS-OOD benchmark, which categorizes OOD samples by incremental semantic and covariate shift levels, moving beyond binary OOD definitions \\cite{long2024os1}.\n    *   **Novel Method for Feature Decomposition**: Introduction of LAID, a CLIP-based method for decomposing image features into semantic and covariate components by aligning with text feature decomposition \\cite{long2024os1}.\n    *   **Novel Dataset**: Generation of the Syn-IS dataset to provide more diverse and controlled covariate shifts, complementing real-world datasets \\cite{long2024os1}.\n    *   **Novel Evaluation Metrics**: Introduction of Pearson correlation coefficient and \"sensitivity\" metrics to quantify how model performance changes with increasing shift levels \\cite{long2024os1}.\n\n*   **Experimental Validation**\n    *   Experiments were conducted by evaluating various OOD detection methods (e.g., MSP, ODIN, GradNorm, KNN, ASH) on the IS-OOD benchmark \\cite{long2024os1}.\n    *   The ID dataset was ImageNet-1K, and OOD samples were drawn from ImageNet-21K (divided into 8x8 shift levels) and the Syn-IS dataset \\cite{long2024os1}.\n    *   Key performance metrics included FPR@95, AUROC, and AUPR, along with the newly proposed correlation and sensitivity metrics \\cite{long2024os1}.\n    *   **Key Results/Insights**:\n        *   The performance of most OOD detection methods significantly improves as the semantic shift increases \\cite{long2024os1}.\n        *   Some methods, like GradNorm, exhibit different OOD detection mechanisms, relying less on semantic shifts \\cite{long2024os1}.\n        *   Excessive covariate shifts in an image are also likely to be considered OOD by some methods, indicating their sensitivity to non-semantic variations \\cite{long2024os1}.\n        *   OOD detection methods perform best with large semantic shifts and small covariate shifts, confirming sensitivity to both but primary influence from semantic shifts \\cite{long2024os1}.\n\n*   **Limitations & Scope**\n    *   The paper \\cite{long2024os1} implicitly acknowledges the limitation of limited covariate variation in large-scale datasets like ImageNet-21K, which Syn-IS aims to address.\n    *   The scope of applicability is primarily OOD detection in computer vision, particularly for image classification models. The LAID method is dependent on the properties of CLIP features.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in OOD detection evaluation by providing a more granular and semantically informed benchmark \\cite{long2024os1}.\n    *   By decomposing shifts into semantic and covariate components, it enables a deeper understanding of *why* OOD detection methods succeed or fail, moving beyond a simple pass/fail assessment \\cite{long2024os1}.\n    *   The proposed LAID method offers a novel way to quantify different types of data shifts, which could be valuable for other areas like domain adaptation or robustness research \\cite{long2024os1}.\n    *   The insights gained from the IS-OOD benchmark have the potential to guide future research towards developing OOD detection methods that are more robust to covariate shifts while being highly sensitive to semantic novelty \\cite{long2024os1}.",
      "intriguing_abstract": "The evaluation of Out-of-Distribution (OOD) detection methods is plagued by a fundamental flaw: existing benchmarks often misclassify samples with novel labels as OOD, even when their semantic content closely aligns with in-distribution data, creating a \"Sorites Paradox\" of ambiguity. This hinders the development of truly robust AI. We introduce a paradigm shift in OOD evaluation with the **Incremental Shift OOD (IS-OOD) benchmark**, moving beyond binary definitions to continuously measure semantic and covariate shifts.\n\nOur novel **Language Aligned Image feature Decomposition (LAID)** method, leveraging CLIP's multimodal capabilities, precisely disentangles image features into distinct semantic and covariate components, enabling granular quantification of these shifts. Complementing this, the **Synthetic Incremental Shift (Syn-IS)** dataset provides diverse, controlled covariate variations. Experiments on IS-OOD reveal that OOD detection performance significantly correlates with semantic shift, while also highlighting method sensitivities to excessive covariate shifts. This framework offers unprecedented insights into *why* OOD methods succeed or fail, paving the way for developing next-generation detectors that are robust to nuisance variations and acutely sensitive to genuine semantic novelty, crucial for reliable AI systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "OOD evaluation",
        "semantic shift",
        "covariate shift",
        "Sorites Paradox",
        "Incremental Shift OOD (IS-OOD) benchmark",
        "Language Aligned Image feature Decomposition (LAID)",
        "CLIP model",
        "feature decomposition",
        "Synthetic Incremental Shift (Syn-IS) dataset",
        "novel evaluation metrics",
        "granular OOD evaluation",
        "sensitivity to non-semantic variations",
        "computer vision"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/74491e50e381210badd7c8a0eee69d10410f6a68.pdf",
      "citation_key": "long2024os1",
      "metadata": {
        "title": "Rethinking the Evaluation of Out-of-Distribution Detection: A Sorites Paradox",
        "authors": [
          "Xingming Long",
          "Jie Zhang",
          "Shiguang Shan",
          "Xilin Chen"
        ],
        "published_date": "2024",
        "abstract": "Most existing out-of-distribution (OOD) detection benchmarks classify samples with novel labels as the OOD data. However, some marginal OOD samples actually have close semantic contents to the in-distribution (ID) sample, which makes determining the OOD sample a Sorites Paradox. In this paper, we construct a benchmark named Incremental Shift OOD (IS-OOD) to address the issue, in which we divide the test samples into subsets with different semantic and covariate shift degrees relative to the ID dataset. The data division is achieved through a shift measuring method based on our proposed Language Aligned Image feature Decomposition (LAID). Moreover, we construct a Synthetic Incremental Shift (Syn-IS) dataset that contains high-quality generated images with more diverse covariate contents to complement the IS-OOD benchmark. We evaluate current OOD detection methods on our benchmark and find several important insights: (1) The performance of most OOD detection methods significantly improves as the semantic shift increases; (2) Some methods like GradNorm may have different OOD detection mechanisms as they rely less on semantic shifts to make decisions; (3) Excessive covariate shifts in the image are also likely to be considered as OOD for some methods. Our code and data are released in https://github.com/qqwsad5/IS-OOD.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/74491e50e381210badd7c8a0eee69d10410f6a68.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the paper \\cite{long2024os1} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper \\cite{long2024os1} addresses a fundamental flaw in the evaluation of Out-of-Distribution (OOD) detection methods: existing benchmarks primarily classify samples with novel labels as OOD, even if their semantic content is very close to in-distribution (ID) data.\n    *   This creates a \"Sorites Paradox\" â€“ an ambiguity in defining what constitutes an OOD sample, as there's no clear boundary for \"how different\" a sample must be. This problem is important because it leads to inaccurate assessment of OOD detection models and hinders progress in developing robust systems.\n    *   Current benchmarks often suffer from issues like similar, overlapping, or insufficient semantic labels, making manual filtering labor-intensive and subjective \\cite{long2024os1}.\n\n*   **Related Work & Positioning**\n    *   Existing OOD detection benchmarks typically use two datasets with non-overlapping semantic labels for ID and OOD data \\cite{long2024os1}.\n    *   The limitation of previous solutions is their reliance on semantic labels alone to define OOD, which fails to account for the *degree* of semantic and covariate shifts, leading to the Sorites Paradox \\cite{long2024os1}.\n    *   This work positions itself by moving beyond a binary OOD/ID classification to a continuous measurement of \"shift degrees\" relative to ID data, providing a more nuanced and robust evaluation framework \\cite{long2024os1}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is the construction of the **Incremental Shift OOD (IS-OOD) benchmark** \\cite{long2024os1}. This benchmark divides test samples into subsets based on their measured semantic and covariate shift degrees relative to the ID dataset (ImageNet-1K).\n    *   A key innovation is the **Language Aligned Image feature Decomposition (LAID)** method \\cite{long2024os1}. LAID leverages the aligned text and image features of the CLIP model to decompose image features into distinct semantic and covariate components.\n    *   LAID trains an orthogonal transformation matrix in the text feature space (using constructed texts with semantic and covariate prompts and triplet loss) and then applies this matrix to the image feature space, enabling separate measurement of semantic and covariate shifts \\cite{long2024os1}.\n    *   The paper \\cite{long2024os1} also introduces **Synthetic Incremental Shift (Syn-IS)**, a dataset of high-quality generated images with diverse covariate contents (using SDXL-Turbo and official style templates) to complement IS-OOD, addressing the limited covariate variation in real-world datasets like ImageNet-21K.\n\n*   **Key Technical Contributions**\n    *   **Novel Benchmark**: Construction of the IS-OOD benchmark, which categorizes OOD samples by incremental semantic and covariate shift levels, moving beyond binary OOD definitions \\cite{long2024os1}.\n    *   **Novel Method for Feature Decomposition**: Introduction of LAID, a CLIP-based method for decomposing image features into semantic and covariate components by aligning with text feature decomposition \\cite{long2024os1}.\n    *   **Novel Dataset**: Generation of the Syn-IS dataset to provide more diverse and controlled covariate shifts, complementing real-world datasets \\cite{long2024os1}.\n    *   **Novel Evaluation Metrics**: Introduction of Pearson correlation coefficient and \"sensitivity\" metrics to quantify how model performance changes with increasing shift levels \\cite{long2024os1}.\n\n*   **Experimental Validation**\n    *   Experiments were conducted by evaluating various OOD detection methods (e.g., MSP, ODIN, GradNorm, KNN, ASH) on the IS-OOD benchmark \\cite{long2024os1}.\n    *   The ID dataset was ImageNet-1K, and OOD samples were drawn from ImageNet-21K (divided into 8x8 shift levels) and the Syn-IS dataset \\cite{long2024os1}.\n    *   Key performance metrics included FPR@95, AUROC, and AUPR, along with the newly proposed correlation and sensitivity metrics \\cite{long2024os1}.\n    *   **Key Results/Insights**:\n        *   The performance of most OOD detection methods significantly improves as the semantic shift increases \\cite{long2024os1}.\n        *   Some methods, like GradNorm, exhibit different OOD detection mechanisms, relying less on semantic shifts \\cite{long2024os1}.\n        *   Excessive covariate shifts in an image are also likely to be considered OOD by some methods, indicating their sensitivity to non-semantic variations \\cite{long2024os1}.\n        *   OOD detection methods perform best with large semantic shifts and small covariate shifts, confirming sensitivity to both but primary influence from semantic shifts \\cite{long2024os1}.\n\n*   **Limitations & Scope**\n    *   The paper \\cite{long2024os1} implicitly acknowledges the limitation of limited covariate variation in large-scale datasets like ImageNet-21K, which Syn-IS aims to address.\n    *   The scope of applicability is primarily OOD detection in computer vision, particularly for image classification models. The LAID method is dependent on the properties of CLIP features.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art in OOD detection evaluation by providing a more granular and semantically informed benchmark \\cite{long2024os1}.\n    *   By decomposing shifts into semantic and covariate components, it enables a deeper understanding of *why* OOD detection methods succeed or fail, moving beyond a simple pass/fail assessment \\cite{long2024os1}.\n    *   The proposed LAID method offers a novel way to quantify different types of data shifts, which could be valuable for other areas like domain adaptation or robustness research \\cite{long2024os1}.\n    *   The insights gained from the IS-OOD benchmark have the potential to guide future research towards developing OOD detection methods that are more robust to covariate shifts while being highly sensitive to semantic novelty \\cite{long2024os1}.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "OOD evaluation",
          "semantic shift",
          "covariate shift",
          "Sorites Paradox",
          "Incremental Shift OOD (IS-OOD) benchmark",
          "Language Aligned Image feature Decomposition (LAID)",
          "CLIP model",
          "feature decomposition",
          "Synthetic Incremental Shift (Syn-IS) dataset",
          "novel evaluation metrics",
          "granular OOD evaluation",
          "sensitivity to non-semantic variations",
          "computer vision"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **problem identification:** the paper identifies a problem with existing ood detection benchmarks, specifically the \"sorites paradox\" in determining ood samples.\n2.  **proposed solution (technical contribution):**\n    *   \"we construct a benchmark named incremental shift ood (is-ood) to address the issue\"\n    *   \"the data division is achieved through a shift measuring method based on our proposed language aligned image feature decomposition (laid).\"\n    *   \"we construct a synthetic incremental shift (syn-is) dataset\"\n    these clearly indicate the development of new systems, methods, and datasets.\n3.  **evaluation (empirical component):**\n    *   \"we evaluate current ood detection methods on our benchmark and find several important insights\"\n    this shows an empirical study conducted using their newly developed benchmark.\n\nwhile there is a strong empirical component (evaluating methods and presenting findings), the primary contribution highlighted in the abstract is the **construction of a new benchmark, a new method (laid), and a new dataset (syn-is)**. these are all technical developments. the empirical evaluation serves to demonstrate the utility and insights gained from their technical contributions.\n\ntherefore, the paper best fits the **technical** classification.\n\n**classification:** technical"
      },
      "file_name": "74491e50e381210badd7c8a0eee69d10410f6a68.pdf"
    },
    {
      "success": true,
      "doc_id": "b2a3892aa12acfebfae6ae7e70673ab6",
      "summary": "Graph machine learning has witnessed rapid growth, driving advancements across diverse domains. However, the in-distribution assumption, where training and testing data share the same distribution, often breaks in real-world scenarios, leading to degraded model performance under distribution shifts. This challenge has catalyzed interest in graph out-of-distribution (GOOD) detection, which focuses on identifying graph data that deviates from the distribution seen during training, thereby enhancing model robustness. In this paper, we provide a rigorous definition of GOOD detection and systematically categorize existing methods into four types: enhancement-based, reconstruction-based, information propagation-based, and classification-based approaches. We analyze the principles and mechanisms of each approach and clarify the distinctions between GOOD detection and related fields, such as graph anomaly detection, outlier detection, and GOOD generalization. Beyond methodology, we discuss practical applications and theoretical foundations, highlighting the unique challenges posed by graph data. Finally, we discuss the primary challenges and propose future directions to advance this emerging field. The repository of this survey is available at https://github.com/ca1man-2022/Awesome-GOOD-Detection.",
      "intriguing_abstract": "Graph machine learning has witnessed rapid growth, driving advancements across diverse domains. However, the in-distribution assumption, where training and testing data share the same distribution, often breaks in real-world scenarios, leading to degraded model performance under distribution shifts. This challenge has catalyzed interest in graph out-of-distribution (GOOD) detection, which focuses on identifying graph data that deviates from the distribution seen during training, thereby enhancing model robustness. In this paper, we provide a rigorous definition of GOOD detection and systematically categorize existing methods into four types: enhancement-based, reconstruction-based, information propagation-based, and classification-based approaches. We analyze the principles and mechanisms of each approach and clarify the distinctions between GOOD detection and related fields, such as graph anomaly detection, outlier detection, and GOOD generalization. Beyond methodology, we discuss practical applications and theoretical foundations, highlighting the unique challenges posed by graph data. Finally, we discuss the primary challenges and propose future directions to advance this emerging field. The repository of this survey is available at https://github.com/ca1man-2022/Awesome-GOOD-Detection.",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/5c18f91dfa622c3c6ba455de9df5535a48bff463.pdf",
      "citation_key": "cai2025ez2",
      "metadata": {
        "title": "Out-of-Distribution Detection on Graphs: A Survey",
        "authors": [
          "Tingyi Cai",
          "Yunliang Jiang",
          "Yixin Liu",
          "Ming Li",
          "Changqin Huang",
          "Shirui Pan"
        ],
        "published_date": "2025",
        "abstract": "Graph machine learning has witnessed rapid growth, driving advancements across diverse domains. However, the in-distribution assumption, where training and testing data share the same distribution, often breaks in real-world scenarios, leading to degraded model performance under distribution shifts. This challenge has catalyzed interest in graph out-of-distribution (GOOD) detection, which focuses on identifying graph data that deviates from the distribution seen during training, thereby enhancing model robustness. In this paper, we provide a rigorous definition of GOOD detection and systematically categorize existing methods into four types: enhancement-based, reconstruction-based, information propagation-based, and classification-based approaches. We analyze the principles and mechanisms of each approach and clarify the distinctions between GOOD detection and related fields, such as graph anomaly detection, outlier detection, and GOOD generalization. Beyond methodology, we discuss practical applications and theoretical foundations, highlighting the unique challenges posed by graph data. Finally, we discuss the primary challenges and propose future directions to advance this emerging field. The repository of this survey is available at https://github.com/ca1man-2022/Awesome-GOOD-Detection.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/5c18f91dfa622c3c6ba455de9df5535a48bff463.pdf",
        "venue": "arXiv.org",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Graph machine learning has witnessed rapid growth, driving advancements across diverse domains. However, the in-distribution assumption, where training and testing data share the same distribution, often breaks in real-world scenarios, leading to degraded model performance under distribution shifts. This challenge has catalyzed interest in graph out-of-distribution (GOOD) detection, which focuses on identifying graph data that deviates from the distribution seen during training, thereby enhancing model robustness. In this paper, we provide a rigorous definition of GOOD detection and systematically categorize existing methods into four types: enhancement-based, reconstruction-based, information propagation-based, and classification-based approaches. We analyze the principles and mechanisms of each approach and clarify the distinctions between GOOD detection and related fields, such as graph anomaly detection, outlier detection, and GOOD generalization. Beyond methodology, we discuss practical applications and theoretical foundations, highlighting the unique challenges posed by graph data. Finally, we discuss the primary challenges and propose future directions to advance this emerging field. The repository of this survey is available at https://github.com/ca1man-2022/Awesome-GOOD-Detection.",
        "keywords": []
      },
      "file_name": "5c18f91dfa622c3c6ba455de9df5535a48bff463.pdf"
    },
    {
      "success": true,
      "doc_id": "ff84dd269e800aefefe15e00f76fac0a",
      "summary": "Here's a focused summary of the technical paper \\cite{liu2025m5u} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection and segmentation in multimodal settings. Existing machine learning models often operate under a closed-set assumption, leading to overconfident predictions on unknown (OOD) samples.\n    *   **Importance & Challenge**: This problem is crucial for safety-critical applications like autonomous driving and robot-assisted surgery, where identifying unknown objects is paramount. The challenge lies in the inherent lack of supervision signals for unknown data during training, and the fact that most prior OOD methods are designed for unimodal data (e.g., images or point clouds), failing to leverage complementary information from multiple modalities. Multimodal outlier synthesis methods, when they exist, are often computationally expensive.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Prior OOD detection and segmentation methods primarily focus on unimodal inputs (e.g., images, point clouds) using techniques like post-hoc scoring, distance metrics in feature space, or synthesizing outliers. Multimodal OOD is an emerging area, with notable work by Dong et al. \\cite{dong2023multiood} introducing benchmarks and a multimodal outlier synthesis technique (NP-Mix).\n    *   **Limitations of Previous Solutions**:\n        *   Most methods are unimodal, neglecting the complementary nature of real-world multimodal data.\n        *   Uncertainty-based methods suffer from overconfidence issues.\n        *   Outlier exposure methods require costly and often unavailable real OOD datasets.\n        *   Synthetic outlier methods are typically unimodal or, in multimodal cases like NP-Mix \\cite{dong2023multiood}, computationally prohibitive for tasks like segmentation and can introduce unwanted noise.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{liu2025m5u} proposes **Feature Mixing**, an \"extremely simple and fast\" method for multimodal outlier synthesis. Given in-distribution (ID) features from two modalities, Feature Mixing randomly selects and swaps a subset of `N` feature dimensions between them to generate new multimodal outlier features. These synthesized outliers are then optimized during training by maximizing their prediction entropy.\n    *   **Novelty/Difference**:\n        *   **Simplicity and Speed**: Unlike computationally expensive methods like NP-Mix \\cite{dong2023multiood}, Feature Mixing operates directly in the feature space with negligible overhead, achieving significant speedups.\n        *   **Modality-Agnostic**: The method is applicable to diverse modality combinations (e.g., image/point cloud, video/optical flow).\n        *   **Theoretical Support**: The paper provides theoretical insights (Theorem 1 and 2) demonstrating that synthesized outliers lie in low-likelihood regions of the ID feature distribution while being bounded in their deviation, ensuring they align with real OOD characteristics without introducing excessive noise.\n        *   **Effective Outlier Generation**: It generates outliers that span wider embedding spaces without injecting noise, effectively reducing overconfidence and enhancing ID/OOD distinction.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of **Feature Mixing**, a simple, fast, and modality-agnostic method for multimodal outlier synthesis with theoretical backing.\n    *   **Theoretical Insights**: Provision of Theorem 1 and Theorem 2, which formally support the efficacy of Feature Mixing in generating meaningful outliers.\n    *   **System Design/Architectural Innovations**: Integration of Feature Mixing into a dual-stream network framework for multimodal OOD detection and segmentation, combined with entropy maximization for outlier optimization.\n    *   **Novel Dataset**: Introduction of **CARLA-OOD**, a challenging synthetic multimodal dataset for OOD segmentation, featuring diverse OOD objects in various scenes and weather conditions, addressing a scarcity in this domain.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive evaluations were performed across eight datasets and four modalities for both multimodal OOD detection and segmentation.\n        *   **Multimodal OOD Segmentation**: Tested on large-scale real-world datasets (SemanticKITTI, nuScenes) and the newly introduced synthetic CARLA-OOD dataset, using image and point cloud data.\n        *   **Multimodal OOD Detection**: Evaluated on five action recognition datasets from the MultiOOD benchmark \\cite{dong2023multiood} (HMDB51, UCF101, Kinetics-600, HAC, EPIC-Kitchens), using video and optical flow modalities.\n    *   **Key Performance Metrics & Results**:\n        *   **State-of-the-Art Performance**: Feature Mixing achieves state-of-the-art performance in most cases compared to existing outlier synthesis methods.\n        *   **Significant Speedup**: The method demonstrates a substantial speedup, achieving 10Ã— for multimodal OOD detection and an impressive 370Ã— for segmentation compared to prior work like NP-Mix \\cite{dong2023multiood}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper does not explicitly state specific technical limitations beyond the general challenges of OOD detection. The \"extremely simple\" nature of Feature Mixing might imply that it focuses on a specific type of OOD generation (feature-level mixing) and might not cover all possible complex OOD scenarios that more sophisticated, albeit slower, methods might address. However, its SOTA performance suggests this simplicity is highly effective for the evaluated tasks.\n    *   **Scope of Applicability**: Feature Mixing is broadly applicable to various multimodal setups (e.g., image/point cloud, video/optical flow) and tasks (OOD detection and segmentation). The method is designed for scenarios where ID features can be extracted and mixed.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{liu2025m5u} significantly advances the technical state-of-the-art in multimodal OOD detection and segmentation by providing an extremely efficient and effective outlier synthesis method. It addresses the critical gap of computationally expensive or unimodal-only solutions.\n    *   **Potential Impact**: The simplicity, speed, and strong performance of Feature Mixing make it highly practical for real-world safety-critical applications. The introduction of the CARLA-OOD dataset also provides a valuable resource for future research in multimodal OOD segmentation, fostering further development in this crucial area.",
      "intriguing_abstract": "The reliability of AI in safety-critical domains like autonomous driving and robot-assisted surgery hinges on its ability to detect and segment Out-of-Distribution (OOD) anomalies. Current deep learning models, often operating under closed-set assumptions, exhibit dangerous overconfidence when encountering unknown multimodal inputs. Existing OOD methods are largely unimodal or rely on computationally prohibitive multimodal outlier synthesis, hindering real-world deployment.\n\nWe introduce **Feature Mixing**, an elegantly simple yet profoundly effective method for multimodal outlier synthesis. Unlike prior complex approaches, Feature Mixing operates directly in the feature space, randomly swapping dimensions between modalities to generate robust OOD samples with negligible computational overhead. This novel technique is theoretically grounded, demonstrating that synthesized outliers occupy low-likelihood regions without introducing noise. Integrated into a dual-stream network, Feature Mixing, coupled with entropy maximization, achieves state-of-the-art performance across diverse multimodal OOD detection and segmentation tasks, delivering unprecedented speedups of up to 370x. We also present CARLA-OOD, a challenging synthetic dataset for OOD segmentation. Feature Mixing represents a significant leap towards deployable, trustworthy AI, making robust multimodal OOD awareness practical for the first time.",
      "keywords": [
        "Out-of-Distribution (OOD) detection and segmentation",
        "Multimodal settings",
        "Feature Mixing",
        "Multimodal outlier synthesis",
        "Safety-critical applications",
        "Theoretical insights",
        "CARLA-OOD dataset",
        "Prediction entropy maximization",
        "Computational efficiency",
        "State-of-the-art performance",
        "Modality-agnostic",
        "Feature space manipulation",
        "Dual-stream network"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/b826af7705a11f6fefc9452eed5db6309520f170.pdf",
      "citation_key": "liu2025m5u",
      "metadata": {
        "title": "Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation",
        "authors": [
          "Moru Liu",
          "Hao Dong",
          "Jessica Kelly",
          "Olga Fink",
          "Mario Trapp"
        ],
        "published_date": "2025",
        "abstract": "Out-of-distribution (OOD) detection and segmentation are crucial for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. While prior research has primarily focused on unimodal image data, real-world applications are inherently multimodal, requiring the integration of multiple modalities for improved OOD detection. A key challenge is the lack of supervision signals from unknown data, leading to overconfident predictions on OOD samples. To address this challenge, we propose Feature Mixing, an extremely simple and fast method for multimodal outlier synthesis with theoretical support, which can be further optimized to help the model better distinguish between in-distribution (ID) and OOD data. Feature Mixing is modality-agnostic and applicable to various modality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal dataset for OOD segmentation, featuring synthetic OOD objects across diverse scenes and weather conditions. Extensive experiments on SemanticKITTI, nuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that Feature Mixing achieves state-of-the-art performance with a $10 \\times$ to $370 \\times$ speedup. Our source code and dataset will be available at https://github.com/mona4399/FeatureMixing.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/b826af7705a11f6fefc9452eed5db6309520f170.pdf",
        "venue": "arXiv.org",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the technical paper \\cite{liu2025m5u} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: The paper addresses the critical challenge of Out-of-Distribution (OOD) detection and segmentation in multimodal settings. Existing machine learning models often operate under a closed-set assumption, leading to overconfident predictions on unknown (OOD) samples.\n    *   **Importance & Challenge**: This problem is crucial for safety-critical applications like autonomous driving and robot-assisted surgery, where identifying unknown objects is paramount. The challenge lies in the inherent lack of supervision signals for unknown data during training, and the fact that most prior OOD methods are designed for unimodal data (e.g., images or point clouds), failing to leverage complementary information from multiple modalities. Multimodal outlier synthesis methods, when they exist, are often computationally expensive.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Prior OOD detection and segmentation methods primarily focus on unimodal inputs (e.g., images, point clouds) using techniques like post-hoc scoring, distance metrics in feature space, or synthesizing outliers. Multimodal OOD is an emerging area, with notable work by Dong et al. \\cite{dong2023multiood} introducing benchmarks and a multimodal outlier synthesis technique (NP-Mix).\n    *   **Limitations of Previous Solutions**:\n        *   Most methods are unimodal, neglecting the complementary nature of real-world multimodal data.\n        *   Uncertainty-based methods suffer from overconfidence issues.\n        *   Outlier exposure methods require costly and often unavailable real OOD datasets.\n        *   Synthetic outlier methods are typically unimodal or, in multimodal cases like NP-Mix \\cite{dong2023multiood}, computationally prohibitive for tasks like segmentation and can introduce unwanted noise.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{liu2025m5u} proposes **Feature Mixing**, an \"extremely simple and fast\" method for multimodal outlier synthesis. Given in-distribution (ID) features from two modalities, Feature Mixing randomly selects and swaps a subset of `N` feature dimensions between them to generate new multimodal outlier features. These synthesized outliers are then optimized during training by maximizing their prediction entropy.\n    *   **Novelty/Difference**:\n        *   **Simplicity and Speed**: Unlike computationally expensive methods like NP-Mix \\cite{dong2023multiood}, Feature Mixing operates directly in the feature space with negligible overhead, achieving significant speedups.\n        *   **Modality-Agnostic**: The method is applicable to diverse modality combinations (e.g., image/point cloud, video/optical flow).\n        *   **Theoretical Support**: The paper provides theoretical insights (Theorem 1 and 2) demonstrating that synthesized outliers lie in low-likelihood regions of the ID feature distribution while being bounded in their deviation, ensuring they align with real OOD characteristics without introducing excessive noise.\n        *   **Effective Outlier Generation**: It generates outliers that span wider embedding spaces without injecting noise, effectively reducing overconfidence and enhancing ID/OOD distinction.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of **Feature Mixing**, a simple, fast, and modality-agnostic method for multimodal outlier synthesis with theoretical backing.\n    *   **Theoretical Insights**: Provision of Theorem 1 and Theorem 2, which formally support the efficacy of Feature Mixing in generating meaningful outliers.\n    *   **System Design/Architectural Innovations**: Integration of Feature Mixing into a dual-stream network framework for multimodal OOD detection and segmentation, combined with entropy maximization for outlier optimization.\n    *   **Novel Dataset**: Introduction of **CARLA-OOD**, a challenging synthetic multimodal dataset for OOD segmentation, featuring diverse OOD objects in various scenes and weather conditions, addressing a scarcity in this domain.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive evaluations were performed across eight datasets and four modalities for both multimodal OOD detection and segmentation.\n        *   **Multimodal OOD Segmentation**: Tested on large-scale real-world datasets (SemanticKITTI, nuScenes) and the newly introduced synthetic CARLA-OOD dataset, using image and point cloud data.\n        *   **Multimodal OOD Detection**: Evaluated on five action recognition datasets from the MultiOOD benchmark \\cite{dong2023multiood} (HMDB51, UCF101, Kinetics-600, HAC, EPIC-Kitchens), using video and optical flow modalities.\n    *   **Key Performance Metrics & Results**:\n        *   **State-of-the-Art Performance**: Feature Mixing achieves state-of-the-art performance in most cases compared to existing outlier synthesis methods.\n        *   **Significant Speedup**: The method demonstrates a substantial speedup, achieving 10Ã— for multimodal OOD detection and an impressive 370Ã— for segmentation compared to prior work like NP-Mix \\cite{dong2023multiood}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper does not explicitly state specific technical limitations beyond the general challenges of OOD detection. The \"extremely simple\" nature of Feature Mixing might imply that it focuses on a specific type of OOD generation (feature-level mixing) and might not cover all possible complex OOD scenarios that more sophisticated, albeit slower, methods might address. However, its SOTA performance suggests this simplicity is highly effective for the evaluated tasks.\n    *   **Scope of Applicability**: Feature Mixing is broadly applicable to various multimodal setups (e.g., image/point cloud, video/optical flow) and tasks (OOD detection and segmentation). The method is designed for scenarios where ID features can be extracted and mixed.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{liu2025m5u} significantly advances the technical state-of-the-art in multimodal OOD detection and segmentation by providing an extremely efficient and effective outlier synthesis method. It addresses the critical gap of computationally expensive or unimodal-only solutions.\n    *   **Potential Impact**: The simplicity, speed, and strong performance of Feature Mixing make it highly practical for real-world safety-critical applications. The introduction of the CARLA-OOD dataset also provides a valuable resource for future research in multimodal OOD segmentation, fostering further development in this crucial area.",
        "keywords": [
          "Out-of-Distribution (OOD) detection and segmentation",
          "Multimodal settings",
          "Feature Mixing",
          "Multimodal outlier synthesis",
          "Safety-critical applications",
          "Theoretical insights",
          "CARLA-OOD dataset",
          "Prediction entropy maximization",
          "Computational efficiency",
          "State-of-the-art performance",
          "Modality-agnostic",
          "Feature space manipulation",
          "Dual-stream network"
        ],
        "paper_type": "the paper type is **technical**.\n\n**reasoning:**\n\n*   **abstract:** explicitly states \"we **propose feature mixing**, an extremely simple and fast **method** for multimodal outlier synthesis with theoretical support.\" it also mentions introducing \"carla-ood, a novel multimodal dataset.\" the abstract then details \"extensive **experiments**... demonstrate that feature mixing achieves state-of-the-art performance.\" this clearly indicates the development and evaluation of a new method and a new system/resource (dataset).\n*   **introduction:** discusses a \"technical problem\" (ood detection/segmentation in multimodal settings, the challenge of neural networks assigning high confidence to ood inputs) and sets the stage for a \"proposed solution\" (their method for synthetic outliers).\n*   **keywords from criteria:** \"propose,\" \"develop,\" \"present,\" \"method,\" \"algorithm\" (implied by \"method\"). while it also has strong empirical components (\"extensive experiments,\" \"demonstrate performance\"), the core contribution is the *new method* and *new dataset*, which are then evaluated. the empirical work serves to validate the technical contribution."
      },
      "file_name": "b826af7705a11f6fefc9452eed5db6309520f170.pdf"
    },
    {
      "success": true,
      "doc_id": "528546656ced6742548a13d27cd71b38",
      "summary": "Here's a focused summary of the paper \\cite{li2025xv2} for a literature review:\n\n### Technical Paper Analysis: Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection \\cite{li2025xv2}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, particularly the reliance of effective regularization-based methods (like Outlier Exposure, OE) on acquiring a large pool of high-quality natural OOD data. Existing virtual outlier synthesis methods often suffer from either poor quality, lack of diversity and representativeness, or high computational cost due to monotonous sampling strategies or heavy-parameterized generative models.\n    *   **Importance and Challenge**: OOD detection is crucial for developing trustworthy and reliable machine learning systems, especially in safety-critical applications (e.g., autonomous driving, medical imaging) where erroneous predictions on unknown data can lead to perilous situations. The challenge lies in efficiently synthesizing diverse and representative virtual outliers using *only* in-distribution (ID) data to effectively train models to distinguish between ID and OOD samples, without requiring real OOD examples.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{li2025xv2} positions itself within regularization-based OOD detection methods, specifically those that enhance models' discriminative ability during training. It builds upon the idea of synthesizing virtual outliers to overcome the limitations of Outlier Exposure (OE) methods, which require meticulously gathered natural OOD data.\n    *   **Limitations of Previous Solutions**:\n        *   **Outlier Exposure (OE)**: Heavily relies on acquiring a large pool of high-quality natural outliers, which is often infeasible or expensive for many domain-specific applications.\n        *   **Prior Virtual Outlier Synthesis**:\n            *   Methods generating outliers in pixel space (e.g., using GANs) are computationally expensive due to generative models.\n            *   Methods generating outliers in feature space (e.g., Gaussian sampling) often impose stringent assumptions on ID data or exclusively sample from sub-regions near decision boundaries. This leads to synthesized outliers that lack diversity and representativeness, which are crucial for effective OOD learning.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{li2025xv2} proposes the Hamiltonian Monte Carlo Outlier Synthesis (HamOS) framework. HamOS formulates the outlier synthesis process as sampling from Markov chains in a latent hyperspherical feature space, based solely on ID data.\n        *   It employs a novel **OOD-ness estimation** function, defined as the average Euclidean distance to the k-th nearest neighbors of two adjacent ID clusters. The potential energy for HMC is set as the negative logarithm of this OOD-ness.\n        *   **Hamiltonian Monte Carlo (HMC)**, specifically Spherical HMC, is used to generate a sequence of diverse and representative virtual outliers by traversing the feature space efficiently.\n        *   **Hard Margin Barrier**: To prevent erroneous outlier synthesis (i.e., generating outliers within ID clusters), \\cite{li2025xv2} introduces a hard margin in the HMC acceptance step, based on kernel density estimation (KDE) with a von Mises-Fisher kernel to approximate ID probability.\n        *   **Training**: The model is trained with a dual-head framework, utilizing an ID contrastive loss and an OOD discernment loss to learn a proper hyperspherical space that enhances ID-OOD separation.\n    *   **Novelty/Difference**:\n        *   **First to use Markov chains for outlier synthesis**: Unlike previous methods that rely on Gaussian sampling or complex generative models, \\cite{li2025xv2} introduces a paradigm shift by explicitly sampling through Markov chains.\n        *   **Efficient and Diverse Sampling**: HMC's ability to traverse long distances in state space with high acceptance rates allows for the generation of diverse and representative outliers across a broad range of OOD characteristics and regions in the hyperspherical space.\n        *   **Solely ID-data based**: Achieves high-quality outlier synthesis without any auxiliary OOD data.\n        *   **Integrated OOD-ness and ID-likelihood**: Combines OOD-ness estimation with an ID probability-based hard margin to ensure synthesized outliers are both OOD-like and distinct from ID clusters.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduction of a new framework for outlier synthesis via Markov chains, specifically using Hamiltonian Monte Carlo, as an alternative to Gaussian sampling or generative models.\n        *   A novel OOD-ness estimation method based on k-nearest neighbor distances in hyperspherical space to guide outlier generation.\n        *   Integration of a hard margin barrier, calculated via kernel density estimation with the von Mises-Fisher kernel, into the HMC acceptance step to reject erroneous outliers within ID clusters.\n    *   **System Design/Architectural Innovations**: A dual-head training framework that projects feature embeddings into a reduced-dimensional hyperspherical space for outlier synthesis, while maintaining an FC head for original ID classification.\n    *   **Theoretical Insights/Analysis**: Demonstrates that by formulating outlier synthesis as sampling from Markov chains with an OOD-ness potential energy, diverse and representative outliers can be efficiently generated, exposing the model to miscellaneous potential OOD scenarios.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive empirical analysis was performed on both standard and large-scale OOD detection benchmarks.\n        *   Standard benchmarks: CIFAR-10 and CIFAR-100 (with five standard OOD test datasets).\n        *   Large-scale benchmark: ImageNet-1K.\n        *   Ablation studies were conducted to elucidate the intrinsic mechanism of \\cite{li2025xv2}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **SOTA Performance**: \\cite{li2025xv2} significantly surpasses competitive baselines (both virtual outlier synthesis methods like VOS, NPOS, and regularization methods like ODINE, Energy, CSI) on all tested benchmarks.\n        *   **FPR95**: Achieved substantial improvements in FPR95 (False Positive Rate at 95% True Positive Rate for ID data). Specifically, it enhanced FPR95 on CIFAR-10 by 27.17% and on CIFAR-100 by 5.96%.\n        *   **AUROC**: Figure 1 indicates superior AUROC performance on ImageNet-1K compared to baselines.\n        *   **Diversity**: Figure 2 and Figure 4(b) demonstrate that \\cite{li2025xv2} generates outliers with a broader range of OOD scores and higher variance, indicating greater diversity. Figure 4(c) shows synthesized outliers have diverse OOD scores and low ID-likelihood.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The effectiveness relies on the quality of the learned hyperspherical feature space and the accuracy of the OOD-ness estimation based on ID data distances.\n        *   The choice of hyperparameters for HMC (e.g., Leapfrog steps, step size) and the hard margin threshold `Î´` can influence synthesis quality.\n        *   While efficient, HMC still involves iterative numerical approximations, which might have computational implications compared to simpler Gaussian noise injection, though \\cite{li2025xv2} claims great efficiency due to high acceptance rates.\n    *   **Scope of Applicability**: \\cite{li2025xv2} is a general framework compatible with various HMC variants, ID contrastive losses, and scoring functions. It is primarily applicable to scenarios where acquiring natural OOD data is difficult or impossible, and where OOD detection is critical for system reliability.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{li2025xv2} establishes a new state-of-the-art in OOD detection by introducing a novel and effective paradigm for virtual outlier synthesis. It addresses a critical bottleneck in OOD-aware training by providing a method to generate diverse and representative outliers without relying on external OOD data.\n    *   **Potential Impact on Future Research**:\n        *   Opens new avenues for exploring advanced sampling algorithms (beyond Gaussian distributions) for outlier synthesis in feature space.\n        *   Could inspire further research into more sophisticated OOD-ness estimation functions and adaptive hard margin strategies.\n        *   The framework's compatibility with various components suggests potential for integration with other OOD detection techniques and adaptation to different domain-specific challenges.\n        *   Contributes significantly to the development of more trustworthy and reliable machine learning systems by improving their ability to handle unknown inputs.",
      "intriguing_abstract": "Developing trustworthy AI systems hinges on robust Out-of-Distribution (OOD) detection, yet current regularization methods like Outlier Exposure critically depend on scarce, high-quality OOD data. Existing virtual outlier synthesis techniques often fall short, yielding poor quality or limited diversity. We introduce **Hamiltonian Monte Carlo Outlier Synthesis (HamOS)**, a novel framework that revolutionizes OOD detection by generating diverse and representative virtual outliers using *only* in-distribution (ID) data.\n\nHamOS is the first to leverage **Markov chains** via **Spherical Hamiltonian Monte Carlo (HMC)** to efficiently sample a latent hyperspherical feature space. Our approach employs a novel **OOD-ness estimation** function, guided by k-nearest neighbor distances, and integrates a **hard margin barrier** based on **kernel density estimation (KDE)** to ensure synthesized outliers are genuinely OOD and distinct from ID clusters. This paradigm shift overcomes the limitations of prior methods, enabling the generation of outliers that span a broad range of OOD characteristics. Extensive experiments demonstrate HamOS achieves state-of-the-art performance, significantly improving metrics like **FPR95** (e.g., 27.17% on CIFAR-10) and **AUROC** across standard and large-scale benchmarks. HamOS represents a critical advancement towards building truly reliable and safety-critical machine learning systems.",
      "keywords": [
        "Out-of-Distribution (OOD) detection",
        "virtual outlier synthesis",
        "Hamiltonian Monte Carlo (HMC)",
        "sampling from Markov chains",
        "hyperspherical feature space",
        "novel OOD-ness estimation",
        "hard margin barrier",
        "solely ID-data based",
        "efficient and diverse outlier sampling",
        "dual-head training framework",
        "State-of-the-Art (SOTA) performance",
        "FPR95",
        "trustworthy machine learning systems"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/50864505777b344d2ee4b4d18880f3ba3ca58836.pdf",
      "citation_key": "li2025xv2",
      "metadata": {
        "title": "Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection",
        "authors": [
          "Hengzhuang Li",
          "Teng Zhang"
        ],
        "published_date": "2025",
        "abstract": "Out-of-distribution (OOD) detection is crucial for developing trustworthy and reliable machine learning systems. Recent advances in training with auxiliary OOD data demonstrate efficacy in enhancing detection capabilities. Nonetheless, these methods heavily rely on acquiring a large pool of high-quality natural outliers. Some prior methods try to alleviate this problem by synthesizing virtual outliers but suffer from either poor quality or high cost due to the monotonous sampling strategy and the heavy-parameterized generative models. In this paper, we overcome all these problems by proposing the Hamiltonian Monte Carlo Outlier Synthesis (HamOS) framework, which views the synthesis process as sampling from Markov chains. Based solely on the in-distribution data, the Markov chains can extensively traverse the feature space and generate diverse and representative outliers, hence exposing the model to miscellaneous potential OOD scenarios. The Hamiltonian Monte Carlo with sampling acceptance rate almost close to 1 also makes our framework enjoy great efficiency. By empirically competing with SOTA baselines on both standard and large-scale benchmarks, we verify the efficacy and efficiency of our proposed HamOS.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/50864505777b344d2ee4b4d18880f3ba3ca58836.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the paper \\cite{li2025xv2} for a literature review:\n\n### Technical Paper Analysis: Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection \\cite{li2025xv2}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of Out-of-Distribution (OOD) detection, particularly the reliance of effective regularization-based methods (like Outlier Exposure, OE) on acquiring a large pool of high-quality natural OOD data. Existing virtual outlier synthesis methods often suffer from either poor quality, lack of diversity and representativeness, or high computational cost due to monotonous sampling strategies or heavy-parameterized generative models.\n    *   **Importance and Challenge**: OOD detection is crucial for developing trustworthy and reliable machine learning systems, especially in safety-critical applications (e.g., autonomous driving, medical imaging) where erroneous predictions on unknown data can lead to perilous situations. The challenge lies in efficiently synthesizing diverse and representative virtual outliers using *only* in-distribution (ID) data to effectively train models to distinguish between ID and OOD samples, without requiring real OOD examples.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{li2025xv2} positions itself within regularization-based OOD detection methods, specifically those that enhance models' discriminative ability during training. It builds upon the idea of synthesizing virtual outliers to overcome the limitations of Outlier Exposure (OE) methods, which require meticulously gathered natural OOD data.\n    *   **Limitations of Previous Solutions**:\n        *   **Outlier Exposure (OE)**: Heavily relies on acquiring a large pool of high-quality natural outliers, which is often infeasible or expensive for many domain-specific applications.\n        *   **Prior Virtual Outlier Synthesis**:\n            *   Methods generating outliers in pixel space (e.g., using GANs) are computationally expensive due to generative models.\n            *   Methods generating outliers in feature space (e.g., Gaussian sampling) often impose stringent assumptions on ID data or exclusively sample from sub-regions near decision boundaries. This leads to synthesized outliers that lack diversity and representativeness, which are crucial for effective OOD learning.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{li2025xv2} proposes the Hamiltonian Monte Carlo Outlier Synthesis (HamOS) framework. HamOS formulates the outlier synthesis process as sampling from Markov chains in a latent hyperspherical feature space, based solely on ID data.\n        *   It employs a novel **OOD-ness estimation** function, defined as the average Euclidean distance to the k-th nearest neighbors of two adjacent ID clusters. The potential energy for HMC is set as the negative logarithm of this OOD-ness.\n        *   **Hamiltonian Monte Carlo (HMC)**, specifically Spherical HMC, is used to generate a sequence of diverse and representative virtual outliers by traversing the feature space efficiently.\n        *   **Hard Margin Barrier**: To prevent erroneous outlier synthesis (i.e., generating outliers within ID clusters), \\cite{li2025xv2} introduces a hard margin in the HMC acceptance step, based on kernel density estimation (KDE) with a von Mises-Fisher kernel to approximate ID probability.\n        *   **Training**: The model is trained with a dual-head framework, utilizing an ID contrastive loss and an OOD discernment loss to learn a proper hyperspherical space that enhances ID-OOD separation.\n    *   **Novelty/Difference**:\n        *   **First to use Markov chains for outlier synthesis**: Unlike previous methods that rely on Gaussian sampling or complex generative models, \\cite{li2025xv2} introduces a paradigm shift by explicitly sampling through Markov chains.\n        *   **Efficient and Diverse Sampling**: HMC's ability to traverse long distances in state space with high acceptance rates allows for the generation of diverse and representative outliers across a broad range of OOD characteristics and regions in the hyperspherical space.\n        *   **Solely ID-data based**: Achieves high-quality outlier synthesis without any auxiliary OOD data.\n        *   **Integrated OOD-ness and ID-likelihood**: Combines OOD-ness estimation with an ID probability-based hard margin to ensure synthesized outliers are both OOD-like and distinct from ID clusters.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduction of a new framework for outlier synthesis via Markov chains, specifically using Hamiltonian Monte Carlo, as an alternative to Gaussian sampling or generative models.\n        *   A novel OOD-ness estimation method based on k-nearest neighbor distances in hyperspherical space to guide outlier generation.\n        *   Integration of a hard margin barrier, calculated via kernel density estimation with the von Mises-Fisher kernel, into the HMC acceptance step to reject erroneous outliers within ID clusters.\n    *   **System Design/Architectural Innovations**: A dual-head training framework that projects feature embeddings into a reduced-dimensional hyperspherical space for outlier synthesis, while maintaining an FC head for original ID classification.\n    *   **Theoretical Insights/Analysis**: Demonstrates that by formulating outlier synthesis as sampling from Markov chains with an OOD-ness potential energy, diverse and representative outliers can be efficiently generated, exposing the model to miscellaneous potential OOD scenarios.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive empirical analysis was performed on both standard and large-scale OOD detection benchmarks.\n        *   Standard benchmarks: CIFAR-10 and CIFAR-100 (with five standard OOD test datasets).\n        *   Large-scale benchmark: ImageNet-1K.\n        *   Ablation studies were conducted to elucidate the intrinsic mechanism of \\cite{li2025xv2}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **SOTA Performance**: \\cite{li2025xv2} significantly surpasses competitive baselines (both virtual outlier synthesis methods like VOS, NPOS, and regularization methods like ODINE, Energy, CSI) on all tested benchmarks.\n        *   **FPR95**: Achieved substantial improvements in FPR95 (False Positive Rate at 95% True Positive Rate for ID data). Specifically, it enhanced FPR95 on CIFAR-10 by 27.17% and on CIFAR-100 by 5.96%.\n        *   **AUROC**: Figure 1 indicates superior AUROC performance on ImageNet-1K compared to baselines.\n        *   **Diversity**: Figure 2 and Figure 4(b) demonstrate that \\cite{li2025xv2} generates outliers with a broader range of OOD scores and higher variance, indicating greater diversity. Figure 4(c) shows synthesized outliers have diverse OOD scores and low ID-likelihood.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The effectiveness relies on the quality of the learned hyperspherical feature space and the accuracy of the OOD-ness estimation based on ID data distances.\n        *   The choice of hyperparameters for HMC (e.g., Leapfrog steps, step size) and the hard margin threshold `Î´` can influence synthesis quality.\n        *   While efficient, HMC still involves iterative numerical approximations, which might have computational implications compared to simpler Gaussian noise injection, though \\cite{li2025xv2} claims great efficiency due to high acceptance rates.\n    *   **Scope of Applicability**: \\cite{li2025xv2} is a general framework compatible with various HMC variants, ID contrastive losses, and scoring functions. It is primarily applicable to scenarios where acquiring natural OOD data is difficult or impossible, and where OOD detection is critical for system reliability.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{li2025xv2} establishes a new state-of-the-art in OOD detection by introducing a novel and effective paradigm for virtual outlier synthesis. It addresses a critical bottleneck in OOD-aware training by providing a method to generate diverse and representative outliers without relying on external OOD data.\n    *   **Potential Impact on Future Research**:\n        *   Opens new avenues for exploring advanced sampling algorithms (beyond Gaussian distributions) for outlier synthesis in feature space.\n        *   Could inspire further research into more sophisticated OOD-ness estimation functions and adaptive hard margin strategies.\n        *   The framework's compatibility with various components suggests potential for integration with other OOD detection techniques and adaptation to different domain-specific challenges.\n        *   Contributes significantly to the development of more trustworthy and reliable machine learning systems by improving their ability to handle unknown inputs.",
        "keywords": [
          "Out-of-Distribution (OOD) detection",
          "virtual outlier synthesis",
          "Hamiltonian Monte Carlo (HMC)",
          "sampling from Markov chains",
          "hyperspherical feature space",
          "novel OOD-ness estimation",
          "hard margin barrier",
          "solely ID-data based",
          "efficient and diverse outlier sampling",
          "dual-head training framework",
          "State-of-the-Art (SOTA) performance",
          "FPR95",
          "trustworthy machine learning systems"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"in this paper, we overcome all these problems by **proposing** the hamiltonian monte carlo outlier synthesis (hamos) framework...\" and \"by **empirically competing with sota baselines**, we **verify the efficacy and efficiency of our proposed hamos**.\"\n*   the introduction reiterates: \"**we propose an innovative hamiltonian monte carlo outlier synthesis (hamos) framework** for ood detection, **presenting a paradigm shift in outlier synthesis by explicit sampling through markov chains**...\" it then details the components of this new framework, such as \"novel ood-ness estimation\" and the use of \"hamiltonian monte carlo (hmc)\".\n*   the contributions section clearly lists: \"we **propose** the general hamiltonian monte carlo outlier synthesis (hamos) framework...\" and \"we conduct extensive **experiments**... to demonstrate that hamos establishs sota performance...\"\n\nthis paper clearly presents a **new method/framework** (hamos) and then provides **empirical evidence** to support its effectiveness. while it contains strong empirical components, the core contribution is the **development and proposal of a novel system/algorithm**.\n\ntherefore, it best fits the **technical** classification."
      },
      "file_name": "50864505777b344d2ee4b4d18880f3ba3ca58836.pdf"
    },
    {
      "success": true,
      "doc_id": "83f83fc7635e6f5c7c9c3fbb6d5c9093",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/46bffadb953e47f58ecca858e6e1ea0acb181501.pdf",
      "citation_key": "liu2024m2l",
      "metadata": {
        "title": "TAG: Text Prompt Augmentation for Zero-Shot Out-of-Distribution Detection",
        "authors": [
          "Xixi Liu",
          "Christopher Zach"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/46bffadb953e47f58ecca858e6e1ea0acb181501.pdf",
        "venue": "European Conference on Computer Vision",
        "citationCount": 3,
        "score": 3.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "46bffadb953e47f58ecca858e6e1ea0acb181501.pdf"
    },
    {
      "success": true,
      "doc_id": "6b3a24f9dc601867cbb3f8cd8cab61b7",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/973b3a4cc286286a24003998fc8596f664ec1d19.pdf",
      "citation_key": "yu2024ez3",
      "metadata": {
        "title": "Exploring using jigsaw puzzles for out-of-distribution detection",
        "authors": [
          "Yeonguk Yu",
          "Sungho Shin",
          "Minhwan Ko",
          "Kyoobin Lee"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/973b3a4cc286286a24003998fc8596f664ec1d19.pdf",
        "venue": "Computer Vision and Image Understanding",
        "citationCount": 3,
        "score": 3.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "973b3a4cc286286a24003998fc8596f664ec1d19.pdf"
    },
    {
      "success": true,
      "doc_id": "5aec2eb18b0729e3482d7694a75dc460",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/be26ccca1684334ca6a0bf7a8c47e85071283185.pdf",
      "citation_key": "ahsan20241ht",
      "metadata": {
        "title": "OODNet: A deep blind JPEG image compression deblocking network using out-of-distribution detection",
        "authors": [
          "Syed Safwan Ahsan",
          "Alireza Esmaeilzehi",
          "M. O. Ahmad"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/be26ccca1684334ca6a0bf7a8c47e85071283185.pdf",
        "venue": "Journal of Visual Communication and Image Representation",
        "citationCount": 3,
        "score": 3.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "be26ccca1684334ca6a0bf7a8c47e85071283185.pdf"
    },
    {
      "success": true,
      "doc_id": "e92879e830fcc0f898b0df8c04f8d786",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Out-of-Distribution_Detection/9b4a20fd47293a48c9be88aa6c7be471123f9487.pdf",
      "citation_key": "ma202473w",
      "metadata": {
        "title": "A Provable Decision Rule for Out-of-Distribution Detection",
        "authors": [
          "Xinsong Ma",
          "Xin Zou",
          "Weiwei Liu"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/9b4a20fd47293a48c9be88aa6c7be471123f9487.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 3,
        "score": 3.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "9b4a20fd47293a48c9be88aa6c7be471123f9487.pdf"
    },
    {
      "success": true,
      "doc_id": "4ad78f50ae19b4f95a38c1645c72159e",
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: Detecting future out-of-distribution (OOD) states in Autonomous Vessels (AVs) *before* they are reached, to enable proactive intervention.\n    *   **Importance & Challenge**: AVs are complex cyber-physical systems operating in uncertain environments (e.g., ocean currents, sensor/actuator noise). OOD states can indicate anomalies, compromise safety, affect passenger comfort, or require manual correction. Existing OOD detection often focuses on simulations or lacks real-time, predictive capabilities for AVs using data-driven digital twins.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **OOD Detection**: Acknowledges traditional OOD methods (softmax-based, GANs, distance-based, autoencoder-based like SelfOracle, VAEs). Notes that most OOD research focuses on image data, with time-series remaining relatively unexplored.\n        *   **Time-series OOD**: Mentions Banerjee et al. \\cite{isaku2025kiz} using statistical change-point detection for land-based vehicles.\n        *   **Digital Twins for AVs**: References works on predictive digital twins for fault diagnosis and path planning in AVs, often built with domain-expert models \\cite{isaku2025kiz}.\n    *   **Limitations of Previous Solutions**:\n        *   Existing OOD for AVs primarily runs during simulations to improve algorithms *before* deployment, lacking real-time operational detection.\n        *   Prior digital twin applications for AVs have not focused on OOD detection as a capability.\n        *   Many existing digital twins for AVs are built with domain-expert models, not leveraging data-driven machine learning for real-time, predictive OOD.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method (ODDIT)**: A novel digital twin-based approach (ODDIT) for proactive OOD detection in AVs. It operates in three phases: (i) building the Digital Twin Model (DTM), (ii) creating the Digital Twin Capability (DTC), and (iii) operating the DT with real-time data.\n    *   **Dual-Component Architecture**:\n        *   **Digital Twin Model (DTM)**: Built using a Recurrent Neural Network (RNN) trained on historical in-distribution data. Its function is to predict future vessel states (e.g., surge, sway, yaw) given current state and control inputs.\n        *   **Digital Twin Capability (DTC)**: Implemented using a Deep Autoencoder model, also trained on historical in-distribution data. It evaluates the *predicted* future states from the DTM to determine if they are OOD, based on reconstruction error.\n    *   **Novelty**:\n        *   First data-driven digital twin for AVs specifically designed for *predictive* OOD detection in real-time.\n        *   Integration of an RNN for future state prediction with an Autoencoder for OOD assessment, enabling proactive intervention.\n        *   Addresses the gap in real-time, data-driven OOD detection for complex time-series data from AVs.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduction of ODDIT, a novel digital twin framework for predictive OOD detection in time series data from AVs.\n        *   A dual-component architecture combining an RNN for continuous future vessel state prediction and a deep autoencoder for evaluating these predicted states against normal operational behavior.\n    *   **System Design/Architectural Innovations**: A unified digital twin (DTM + DTC) that operates alongside its physical counterpart, continuously streaming real-time data, predicting future states, and identifying OOD scenarios ahead of time.\n    *   **Theoretical Insights**: While primarily an applied paper, the framework provides a robust, data-driven mechanism for quantifying deviations from learned in-distribution behavior in complex cyber-physical systems.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluated ODDIT with five distinct vessel models (Mariner, Container, Remus 100, NPS AUV, Otter) under simulated conditions.\n        *   Tested across two types of maneuvers: waypoint navigation and zigzag maneuvers.\n        *   Included simulated disturbances: sensor noise, actuator noise (rudder angle shifts), and environmental disturbances (sudden spikes in ocean currents).\n    *   **Key Performance Metrics**: Achieved high accuracy in detecting OOD states, measured by AUROC (Area Under the Receiver Operating Characteristic curve) and TNR@TPR95 (True Negative Rate at 95% True Positive Rate).\n    *   **Comparison Results**: ODDIT consistently achieved AUROC and TNR@TPR95 scores up to 99% across multiple vessels and scenarios. It consistently outperformed two alternative methods: an output-based approach and a distance-based approach, across sensor noise, actuator noise, and environmental disturbances for most vessels.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Relies on historical in-distribution data for training both the RNN and Autoencoder; the quality and representativeness of this data are crucial.\n        *   Evaluated under simulated conditions (SIL/HIL simulators), which, while robust, may not fully capture all real-world complexities.\n    *   **Scope of Applicability**: Applicable to AVs at any autonomy level, provided sufficient operational data is available for training the data-driven digital twin.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: ODDIT significantly advances the technical state-of-the-art by introducing a novel, data-driven digital twin framework for *proactive* and *real-time* OOD detection in autonomous vessels. This moves beyond reactive anomaly detection to predictive capabilities.\n    *   **Potential Impact**:\n        *   **Operational Safety**: Enables AVs to take necessary actions (autonomous or human-assisted) to prevent unsafe situations before they occur.\n        *   **Testing**: Assists software testers in scenario-centered testing by identifying critical, high-risk situations that fall outside normal operational distributions.\n        *   **Future Research**: Opens avenues for further research into robust data-driven digital twins for complex CPSs, particularly in integrating more sophisticated ML models for prediction and OOD detection, and validating under real-world conditions.",
      "intriguing_abstract": "Ensuring the safety and reliability of Autonomous Vessels (AVs) in dynamic, uncertain environments hinges on anticipating unforeseen operational anomalies *before* they manifest. Current Out-of-Distribution (OOD) detection methods are predominantly reactive or confined to simulations, leaving a critical gap in real-time, proactive intervention capabilities. We introduce **ODDIT**, a novel data-driven digital twin framework engineered for **predictive OOD detection** in AVs.\n\nODDIT uniquely integrates a **Recurrent Neural Network (RNN)** to forecast future vessel states with a **Deep Autoencoder** that assesses these predicted states for deviations from normal operational behavior. This dual-component architecture enables the system to identify potential OOD scenarios *ahead of time*, facilitating proactive safety measures. Rigorously validated across five distinct vessel models and various simulated disturbances (sensor noise, actuator noise, environmental changes), ODDIT consistently achieved exceptional performance, with AUROC and TNR@TPR95 scores up to 99%, significantly outperforming existing approaches. ODDIT marks a significant advancement in ensuring the operational safety and reliability of complex **cyber-physical systems**, empowering AVs to navigate uncertain environments with unprecedented foresight and paving the way for more robust autonomous navigation.",
      "keywords": [
        "Out-of-distribution (OOD) detection",
        "Autonomous Vessels (AVs)",
        "Digital twins",
        "Proactive OOD detection",
        "Real-time OOD detection",
        "ODDIT framework",
        "Data-driven digital twin",
        "Recurrent Neural Network (RNN)",
        "Deep Autoencoder",
        "Future state prediction",
        "Time-series data",
        "Operational safety",
        "High accuracy (AUROC",
        "TNR@TPR95)"
      ],
      "file_path": "paper_data/Out-of-Distribution_Detection/0e6010e6b53e1d281107844fbcf54608194599cf.pdf",
      "citation_key": "isaku2025kiz",
      "metadata": {
        "title": "Digital Twin-based Out-of-Distribution Detection in Autonomous Vessels",
        "authors": [
          "Erblin Isaku",
          "Hassan Sartaj",
          "Shaukat Ali"
        ],
        "published_date": "2025",
        "abstract": "An autonomous vessel (AV) is a complex cyber-physical system (CPS) with software enabling many key functionalities, e.g., navigation software enables an AV to autonomously or semi-autonomously follow a path to its destination. Digital twins of such AVs enable advanced functionalities such as running what-if scenarios, performing predictive maintenance, and enabling fault diagnosis. Due to technological improvements, real-time analyses using continuous data from vessels' real-time operations have become increasingly possible. However, the literature has little explored developing advanced analyses in real-time data in AVs with digital twins built with machine learning techniques. To this end, we present a novel digital twin-based approach (ODDIT) to detect future out-of-distribution (OOD) states of an AV before reaching them, enabling proactive intervention. Such states may indicate anomalies requiring attention (e.g., manual correction by the ship master) and assist testers in scenario-centered testing. The digital twin consists of two machine-learning models predicting future vessel states and whether the predicted state will be OOD. We evaluated ODDIT with five vessels across waypoint and zigzag maneuvering under simulated conditions, including sensor and actuator noise and environmental disturbances i.e., ocean current. ODDIT achieved high accuracy in detecting OOD states, with AUROC and TNR@TPR95 scores reaching 99\\% across multiple vessels.",
        "file_path": "paper_data/Out-of-Distribution_Detection/info/0e6010e6b53e1d281107844fbcf54608194599cf.pdf",
        "venue": "arXiv.org",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: Detecting future out-of-distribution (OOD) states in Autonomous Vessels (AVs) *before* they are reached, to enable proactive intervention.\n    *   **Importance & Challenge**: AVs are complex cyber-physical systems operating in uncertain environments (e.g., ocean currents, sensor/actuator noise). OOD states can indicate anomalies, compromise safety, affect passenger comfort, or require manual correction. Existing OOD detection often focuses on simulations or lacks real-time, predictive capabilities for AVs using data-driven digital twins.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **OOD Detection**: Acknowledges traditional OOD methods (softmax-based, GANs, distance-based, autoencoder-based like SelfOracle, VAEs). Notes that most OOD research focuses on image data, with time-series remaining relatively unexplored.\n        *   **Time-series OOD**: Mentions Banerjee et al. \\cite{isaku2025kiz} using statistical change-point detection for land-based vehicles.\n        *   **Digital Twins for AVs**: References works on predictive digital twins for fault diagnosis and path planning in AVs, often built with domain-expert models \\cite{isaku2025kiz}.\n    *   **Limitations of Previous Solutions**:\n        *   Existing OOD for AVs primarily runs during simulations to improve algorithms *before* deployment, lacking real-time operational detection.\n        *   Prior digital twin applications for AVs have not focused on OOD detection as a capability.\n        *   Many existing digital twins for AVs are built with domain-expert models, not leveraging data-driven machine learning for real-time, predictive OOD.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method (ODDIT)**: A novel digital twin-based approach (ODDIT) for proactive OOD detection in AVs. It operates in three phases: (i) building the Digital Twin Model (DTM), (ii) creating the Digital Twin Capability (DTC), and (iii) operating the DT with real-time data.\n    *   **Dual-Component Architecture**:\n        *   **Digital Twin Model (DTM)**: Built using a Recurrent Neural Network (RNN) trained on historical in-distribution data. Its function is to predict future vessel states (e.g., surge, sway, yaw) given current state and control inputs.\n        *   **Digital Twin Capability (DTC)**: Implemented using a Deep Autoencoder model, also trained on historical in-distribution data. It evaluates the *predicted* future states from the DTM to determine if they are OOD, based on reconstruction error.\n    *   **Novelty**:\n        *   First data-driven digital twin for AVs specifically designed for *predictive* OOD detection in real-time.\n        *   Integration of an RNN for future state prediction with an Autoencoder for OOD assessment, enabling proactive intervention.\n        *   Addresses the gap in real-time, data-driven OOD detection for complex time-series data from AVs.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   Introduction of ODDIT, a novel digital twin framework for predictive OOD detection in time series data from AVs.\n        *   A dual-component architecture combining an RNN for continuous future vessel state prediction and a deep autoencoder for evaluating these predicted states against normal operational behavior.\n    *   **System Design/Architectural Innovations**: A unified digital twin (DTM + DTC) that operates alongside its physical counterpart, continuously streaming real-time data, predicting future states, and identifying OOD scenarios ahead of time.\n    *   **Theoretical Insights**: While primarily an applied paper, the framework provides a robust, data-driven mechanism for quantifying deviations from learned in-distribution behavior in complex cyber-physical systems.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluated ODDIT with five distinct vessel models (Mariner, Container, Remus 100, NPS AUV, Otter) under simulated conditions.\n        *   Tested across two types of maneuvers: waypoint navigation and zigzag maneuvers.\n        *   Included simulated disturbances: sensor noise, actuator noise (rudder angle shifts), and environmental disturbances (sudden spikes in ocean currents).\n    *   **Key Performance Metrics**: Achieved high accuracy in detecting OOD states, measured by AUROC (Area Under the Receiver Operating Characteristic curve) and TNR@TPR95 (True Negative Rate at 95% True Positive Rate).\n    *   **Comparison Results**: ODDIT consistently achieved AUROC and TNR@TPR95 scores up to 99% across multiple vessels and scenarios. It consistently outperformed two alternative methods: an output-based approach and a distance-based approach, across sensor noise, actuator noise, and environmental disturbances for most vessels.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Relies on historical in-distribution data for training both the RNN and Autoencoder; the quality and representativeness of this data are crucial.\n        *   Evaluated under simulated conditions (SIL/HIL simulators), which, while robust, may not fully capture all real-world complexities.\n    *   **Scope of Applicability**: Applicable to AVs at any autonomy level, provided sufficient operational data is available for training the data-driven digital twin.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: ODDIT significantly advances the technical state-of-the-art by introducing a novel, data-driven digital twin framework for *proactive* and *real-time* OOD detection in autonomous vessels. This moves beyond reactive anomaly detection to predictive capabilities.\n    *   **Potential Impact**:\n        *   **Operational Safety**: Enables AVs to take necessary actions (autonomous or human-assisted) to prevent unsafe situations before they occur.\n        *   **Testing**: Assists software testers in scenario-centered testing by identifying critical, high-risk situations that fall outside normal operational distributions.\n        *   **Future Research**: Opens avenues for further research into robust data-driven digital twins for complex CPSs, particularly in integrating more sophisticated ML models for prediction and OOD detection, and validating under real-world conditions.",
        "keywords": [
          "Out-of-distribution (OOD) detection",
          "Autonomous Vessels (AVs)",
          "Digital twins",
          "Proactive OOD detection",
          "Real-time OOD detection",
          "ODDIT framework",
          "Data-driven digital twin",
          "Recurrent Neural Network (RNN)",
          "Deep Autoencoder",
          "Future state prediction",
          "Time-series data",
          "Operational safety",
          "High accuracy (AUROC",
          "TNR@TPR95)"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we present a novel digital twin-based approach (oddit) to detect future out-of-distribution (ood) states...\"\n*   it describes the components of this approach: \"the digital twin consists of two machine-learning models...\"\n*   it discusses the problem it aims to solve: \"detect future out-of-distribution (ood) states of an a v before reaching them, enabling proactive intervention.\"\n*   the introduction further elaborates on the problem of identifying out-of-distribution states in autonomous vessels.\n*   while it includes an evaluation (\"we evaluated oddit...\", \"oddit achieved high accuracy...\"), this evaluation serves to validate the *new method* being presented.\n\nthese points strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems.\n\n**classification: technical**"
      },
      "file_name": "0e6010e6b53e1d281107844fbcf54608194599cf.pdf"
    }
  ]
}