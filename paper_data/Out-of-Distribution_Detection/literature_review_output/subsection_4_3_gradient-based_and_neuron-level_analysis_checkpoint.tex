\subsection{Gradient-Based and Neuron-Level Analysis}

A significant shift in Out-of-Distribution (OOD) detection research involves delving into the fine-grained internal dynamics of neural networks, leveraging gradient information and individual neuron activations to extract more precise and interpretable OOD signals. This introspection moves beyond aggregate model outputs to understand *how* and *why* a model processes OOD inputs differently.

One prominent direction focuses on abnormalities in gradient-based attribution maps, which reveal how input features influence predictions. \cite{chen2023za1} introduced GAIA (Gradient Abnormality Inspection and Aggregation), a framework that quantifies the "abnormality" in gradient-based attribution results, observing that OOD samples lead to "meaningless attribution results" with abnormal non-zero density in deeper layers. Building on gradient insights, \cite{behpour2023x13} proposed GradOrth, which identifies OOD data by computing the norm of the gradient projection onto a low-rank subspace deemed important for in-distribution (ID) data, indicating a weak correlation with ID patterns. While these methods are post-hoc, analyzing gradients after training, \cite{chen2020mbk} introduced ALOE (Adversarial Learning with inlier and Outlier Exposure), a training-time strategy that uses adversarial examples generated via gradients to robustify OOD detectors against small input perturbations. ALOE's objective is to promote smoother OOD score functions for ID data and clearer separation for OOD data, directly addressing the robustness aspect through gradient-informed regularization during training.

Another crucial area explores the 'coverage' of neuron activation states by in-distribution data, revealing deviations from learned patterns. \cite{liu2023zb3} proposed Neuron Activation Coverage (NAC), a novel statistical measure that quantifies how well neuron states are "covered" by ID training data, serving as an uncertainty measure for OOD detection and a metric for OOD generalization. This approach provides a deeper, neuron-centric understanding of OOD phenomena. Complementing this, \cite{zhu2022oir} introduced Batch Normalization Assisted Typical Set Estimation (BATS) with a Truncated BN (TrBN) unit, which rectifies extreme feature activations into their "typical set" to boost OOD detection scores, effectively managing neuron states. \cite{xu2023767} further generalized this concept with Variational Rectified Activation (VRA), providing a theoretical derivation for an optimal activation function that not only suppresses abnormally high activations (like TrBN) but also low ones, and amplifies intermediate activations, leading to superior OOD separation. These rectification methods demonstrate a progression from heuristic to theoretically grounded manipulation of neuron activations.

Beyond individual neuron states, statistical analyses of activation patterns also prove effective. \cite{dong2021swz} developed Neural Mean Discrepancy (NMD), a metric that quantifies the difference between the average activations (neural means) of input examples and the training data across multiple layers. NMD leverages Batch Normalization's running averages for efficiency, providing a lightweight yet powerful OOD signal. More recently, \cite{schmidt2024syr} presented SISOM (Simultaneous Informative Sampling and Outlier Mining), a unified approach for active learning and OOD detection that enriches feature representations by weighting neurons based on their gradient contribution to the KL divergence between a uniform distribution and the model's softmax output. This method effectively combines gradient-based saliency with neuron activation analysis to identify unexplored regions and decision boundaries, showcasing a sophisticated integration of these fine-grained internal dynamics.

The collective efforts in this subsection highlight a growing trend towards deeper introspection into model internals. By analyzing gradient-based attribution maps, the coverage of neuron activation states, and employing gradient regularization during training, researchers are developing more precise, interpretable, and robust OOD detection methods. However, challenges remain in establishing universal patterns for gradient abnormalities or neuron coverage across diverse architectures and OOD types, and in balancing the computational cost of such fine-grained analysis with real-time deployment needs.