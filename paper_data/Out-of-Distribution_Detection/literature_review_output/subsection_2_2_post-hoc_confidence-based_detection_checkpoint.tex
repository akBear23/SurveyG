\subsection{Post-Hoc Confidence-Based Detection}

The development of robust out-of-distribution (OOD) detection methods is paramount for ensuring the reliability and safety of machine learning systems in real-world applications. Early and highly influential research in this domain focused on leveraging and refining confidence scores derived from pre-trained discriminative classifiers. These "post-hoc" methods are particularly attractive due to their efficiency, as they do not require any model retraining or modification of the original classification objective, thereby minimizing computational overhead and preserving the model's primary task performance. This section details the evolution of such confidence-based approaches, from foundational baselines to sophisticated enhancements.

A seminal contribution to this field was the introduction of Maximum Softmax Probability (MSP) as a baseline for OOD detection by \cite{hendrycks17baseline}. This straightforward yet surprisingly effective method operates on the premise that a well-trained classifier should assign a high maximum softmax probability to in-distribution (ID) samples, reflecting strong confidence in its classification. Conversely, OOD samples, which do not align with any learned class, are expected to yield lower maximum probabilities. Despite its simplicity, MSP established a crucial benchmark, demonstrating that standard neural network outputs inherently contain valuable uncertainty signals. The work also played a pivotal role in standardizing evaluation protocols and datasets, fostering more rigorous comparisons across diverse OOD detection techniques. However, a significant limitation of MSP is the pervasive problem of neural network overconfidence on OOD inputs \cite{community_0, community_5}. Models can often assign spuriously high confidence to novel, unseen data, especially for "near OOD" examples that share superficial similarities with ID data, leading to suboptimal discrimination and false negatives. This fundamental challenge highlights that raw softmax probabilities, while indicative, are not always reliable estimators of true data density or typicality \cite{peng20243ji}.

Building upon the insights from MSP, \cite{Liang_etal_2018} introduced Out-of-Distribution Detector for Neural Networks (ODIN), a method designed to significantly amplify the distinction between ID and OOD samples without requiring any model retraining. ODIN introduced two key innovations. First, it incorporated temperature scaling, a technique originally used for model calibration, which smooths the softmax distribution by dividing the logits by a temperature parameter $T$. This adjustment makes the confidence scores less extreme and often more discriminative for OOD detection by re-calibrating the output probabilities. Second, and more crucially, ODIN proposed a small, carefully crafted input perturbation. This perturbation is calculated to push the input towards the direction that maximizes the softmax probability for the predicted class. For ID samples, this makes them "more ID-like" in the model's perception, increasing their confidence. For OOD samples, which lack a strong alignment with any ID class, this perturbation often fails to significantly boost confidence or may even push them towards lower confidence, thereby increasing the separation in confidence scores between ID and OOD data. By combining these two simple yet powerful post-hoc techniques, ODIN substantially boosted OOD detection performance over MSP, establishing a strong, efficient baseline.

Further refining the ODIN paradigm, \cite{Hsu_Y_2020} proposed Generalized ODIN (G-ODIN), which aimed to improve robustness by addressing a potential weakness in ODIN's perturbation strategy. While ODIN perturbs inputs to maximize confidence for the *predicted* class, G-ODIN considers a broader context. Instead of relying on a single predicted class, G-ODIN perturbs the input towards the direction that minimizes the maximum softmax probability across *all* ID classes. This approach makes the OOD score more robust by ensuring that an OOD sample is not mistakenly pushed to high confidence for an incorrect ID class. By considering the full set of ID classes during perturbation, G-ODIN can achieve better discrimination, especially when OOD samples might be ambiguous or share features with multiple ID categories.

The concept of temperature scaling, a cornerstone of ODIN, has continued to evolve. Recognizing that a fixed global temperature might not be optimal for all samples, \cite{krumpl2024n1w} introduced Adaptive Temperature Scaling (ATS). ATS proposes dynamically calculating a *sample-specific* temperature value based on activations from intermediate layers of the neural network. By fusing this sample-specific adjustment with class-dependent logits, ATS captures additional statistical information that might otherwise be lost in the feature extraction process. This dynamic approach leads to a more robust and powerful OOD detection method, demonstrating that even subtle refinements to temperature scaling can significantly enhance the performance and robustness of existing logit-based OOD detection techniques.

While highly effective and efficient, these confidence-based methods fundamentally rely on the assumption that the classifier's output space (logits or softmax probabilities) can reliably distinguish between ID and OOD data. However, as highlighted by \cite{peng20243ji}, raw logit-based scores, including energy scores (which are closely related to logits), often make implicit assumptions about the underlying data distribution, such as constant partition functions across classes, or that softmax probabilities directly represent true data densities. These assumptions are not always accurate, limiting the theoretical grounding and empirical robustness of simpler confidence scores. To address this, \cite{peng20243ji} proposed ConjNorm, a novel theoretical framework grounded in Bregman divergence, which unifies density function design for OOD detection within the exponential family of distributions. By devising an unbiased and analytically tractable estimator for the partition function using importance sampling, ConjNorm offers a more principled and flexible approach to density estimation for OOD scoring, moving beyond restrictive distributional assumptions and leading to superior empirical performance. This work signifies a critical advancement towards more theoretically robust confidence-based OOD measures.

In summary, post-hoc confidence-based detection methods, starting from the simplicity of MSP and progressing through the innovative enhancements of ODIN, G-ODIN, and ATS, have laid a robust foundation for the field. They collectively demonstrated that significant improvements in uncertainty quantification could be achieved by cleverly leveraging and refining the outputs of existing pre-trained classifiers without the need for costly retraining. However, their inherent reliance on the classifier's output space and the potential for overconfidence or inaccurate density estimation remain persistent challenges. These limitations motivate the exploration of richer, intermediate representations and more theoretically grounded approaches to OOD detection, which are discussed in subsequent sections.