\subsection{Learning Robust and Separable Feature Representations}
The intrinsic quality and structured organization of a model's internal feature representations are paramount for effective Out-of-Distribution (OOD) detection. This subsection delves into advanced methodologies that actively engineer the deep neural network's embedding space, aiming to enhance the discriminability between in-distribution (ID) and OOD samples. These approaches collectively improve the inherent OOD robustness of the learned representations by designing a more structured and discriminative embedding space, often by enforcing explicit geometric separation, creating more compact and well-defined ID clusters, or refining feature transformations.

A significant line of research leverages the intrinsic properties of deep neural networks, particularly the phenomenon of Neural Collapse (NC), to enforce explicit geometric separation between ID classes and push OOD samples away. Neural Collapse describes the convergence of features within each class to their respective class means, and these class means to a simplex equiangular tight frame (ETF) structure in the terminal phase of training. Building on this, \cite{ammar2023pr1} introduced NECO, a post-hoc method that capitalizes on a newly observed property dubbed ID/OOD Orthogonality (NC5). This property posits that OOD data tends to become increasingly orthogonal to the principal component space spanned by ID class means. NECO exploits this by projecting features onto this ID-derived principal component space, using the projection magnitude as an OOD score. A smaller projection magnitude indicates higher OOD likelihood. Extending this concept, \cite{wu20242p3} proposes a novel separation loss (`LSep`) that actively constrains OOD features to reside in a subspace orthogonal to the principal subspace of ID features, which is implicitly defined by the final layer's weights. This approach moves beyond merely observing orthogonality to explicitly enforcing it during training, typically by leveraging auxiliary OOD data to push their features into distinct, non-overlapping dimensions. An earlier, more general effort towards compact ID representations, \cite{zaeemzadeh2021lmh} proposed embedding ID samples into a low-dimensional space forming a union of 1-dimensional subspaces, arguing that such a highly constrained representation inherently makes it less likely for OOD samples to occupy ID regions. While Neural Collapse-based methods offer strong theoretical underpinnings for explicit separation, their robustness to subtle, near-OOD shifts that might not perfectly align with orthogonal subspaces remains a critical area for further investigation, as these shifts might still project significantly onto the ID subspace.

Beyond direct geometric enforcement, feature transformation and subspace learning techniques are employed to enhance separability, often addressing the "curse of dimensionality" that can plague distance-based methods in high-dimensional feature spaces. Traditional linear dimensionality reduction methods often struggle to capture the complex non-linear relationships inherent in deep features. \cite{song2022f5d} introduced RankFeat, a post-hoc method that uses Singular Value Decomposition (SVD) to identify and remove a dominant rank-1 component from high-level features. This spectral manipulation implicitly refines the feature space by mitigating the over-confidence induced by this component in OOD samples, effectively "flattening" the feature manifold. Addressing the limitations of purely linear transformations, \cite{fang2024lv2} proposes Kernel PCA (KPCA) for OOD detection, devising novel non-linear mappings like Cosine Mapping (CoP) and Cosine-Gaussian Mapping (CoRP). These mappings explicitly transform features into a space where ID and OOD data become linearly separable, overcoming the ineffectiveness of conventional PCA on raw features, a challenge also noted by \cite{guan2023dwv} which explored regularized PCA reconstruction errors. To directly combat the curse of dimensionality, \cite{ghosal2023q20} proposes Subspace Nearest Neighbor (SNN), which regularizes the model and its feature representation by leveraging the most relevant subset of dimensions (i.e., subspace) during training. This subspace learning yields more distinguishable distance measures between ID and OOD data. Similarly, \cite{li2025jdt} introduces a data structure-aware approach using a novel "tangent distance" that maps high-dimensional features to the manifold of ID samples. By directly computing the Euclidean distance between samples and the nearest submanifold space (linear approximation of local regions on the manifold), it mitigates the sensitivity of distances to high dimensionality, proposing that OOD samples are relatively far from the ID manifold. The computational overhead and the challenge of selecting optimal non-linear kernels or relevant subspaces for diverse OOD scenarios represent practical considerations for these transformation-based methods.

Another significant direction involves refining ID clusters through prototype-based learning and mixture models, which aim to capture the nuanced structure of ID data more faithfully. Traditional distance-based OOD methods often oversimplify ID classes by modeling them with a single centroid, failing to capture intra-class diversity and leading to suboptimal OOD boundaries. \cite{lu20249d4} addresses this with Prototypic Learning with a Mixture of prototypes (PALM), which models each ID class with multiple prototypes using a mixture of von Mises-Fisher (vMF) distributions in a hyperspherical embedding space. This approach creates more faithful and compact ID clusters, allowing for a more precise definition of ID boundaries by optimizing both a Maximum Likelihood Estimation (MLE) loss and a novel prototype contrastive loss. Extending this concept to multimodal settings, \cite{li2024rs5} introduces Dynamic Prototype Updating (DPU), which dynamically adjusts multimodal prediction discrepancy intensification based on a sample's similarity to its class prototype. DPU employs Cohesive-Separate Contrastive Training (CSCT) to build a robust representation space and Pro-ratio Discrepancy Intensification (PDI) to balance intra-class cohesion with inter-class separation, thereby enhancing OOD detection in complex multimodal data. Complementing these empirical approaches, \cite{du2024aea} provides theoretical insights into how in-distribution labels help OOD detection, particularly for "near OOD" scenarios. Through a graph-theoretic framework and spectral decomposition, they demonstrate that ID labels, by defining supervised connectivity, enable the learning of more discriminative ID representations that facilitate OOD-ID separation, especially when ID data is sparsely connected without labels. While prototype-based methods offer improved fidelity, the challenge of determining the optimal number of prototypes and their sensitivity to noisy ID data remains, and OOD samples falling between distinct ID prototypes can still pose detection difficulties.

Despite these significant advancements in actively structuring and refining feature spaces, a persistent challenge remains in ensuring that these learned representations generalize effectively to truly novel and diverse OOD types. While methods leveraging Neural Collapse offer promising theoretical underpinnings for explicit separation, their robustness to subtle, near-OOD shifts that might not perfectly align with orthogonal subspaces requires further investigation. Similarly, prototype-based methods, while improving intra-class modeling, still face the inherent difficulty of defining boundaries for the unknown, especially when OOD data falls within the convex hull of ID prototypes. Future research could focus on adaptive feature space shaping techniques that dynamically adjust to the evolving nature of OOD data, perhaps through meta-learning or continuous adaptation mechanisms, to achieve more universally robust and discriminative representations that are less sensitive to the specific characteristics of unseen OOD data.