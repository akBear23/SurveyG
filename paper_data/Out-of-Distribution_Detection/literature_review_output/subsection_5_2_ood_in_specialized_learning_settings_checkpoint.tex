\subsection{OOD in Specialized Learning Settings}

Out-of-distribution (OOD) detection becomes particularly challenging in specialized learning paradigms where inherent data characteristics complicate the distinction between in-distribution (ID) and novel samples. This subsection delves into OOD detection within long-tailed recognition and class-incremental learning, highlighting the unique complexities and tailored solutions developed to ensure OOD robustness in these realistic scenarios.

In \textbf{long-tailed recognition (LTR)}, the severe class imbalance creates a pervasive confusion between tail-class ID samples and true OODs. Models often exhibit overconfidence on dominant head classes, leading to OOD samples being misclassified into these categories, while simultaneously treating sparse tail-class instances as anomalies \cite{miao2023brn, wei2023f15, shin2024lnf}. Addressing this requires strategies that either modify the learning objective, augment data, or engineer the representation space to explicitly disentangle tail-class ID from OOD.

One prominent approach involves modifying the learning objective or expanding the label space. \cite{miao2023brn} introduced Calibrated Outlier Class Learning (COCL), which extends the label space with an explicit outlier class. COCL employs a debiased large margin learning strategy, incorporating OOD-aware tail class prototype learning to prevent tail samples from being mistaken for OOD, and debiased head class learning to mitigate the dominant influence of head classes on OOD samples. This direct manipulation of the decision boundary in the logit space offers a targeted solution to the class imbalance problem. Complementing this, \cite{choi202367m} recognized that even auxiliary OOD data used in outlier exposure can exhibit class imbalance. They developed a balanced energy regularization loss that adaptively applies stronger regularization to auxiliary samples from majority classes, ensuring a more effective learning of OOD boundaries in long-tailed and semantic segmentation tasks.

Another crucial strategy focuses on data augmentation and dynamic outlier adaptation. \cite{wei2023f15} proposed EAT, a framework that utilizes dynamic virtual labels for OOD data and context-rich tail class augmentation. By overlaying tail-class images onto OOD backgrounds, EAT encourages the model to focus on discriminative foreground features, improving both tail-class generalization and OOD distinction. This data-centric approach contrasts with COCL's loss modifications by enriching the training data itself. Further advancements in dynamic outlier adaptation include \cite{nie2024ghv}'s Virtual Outlier Smoothing (VOSo), which constructs virtual outliers by perturbing semantic regions of ID samples in the image space and assigns them dynamic soft labels. This creates a smoother decision boundary, preventing tail classes from being abruptly classified as OOD. To enhance the diversity of auxiliary OOD data, \cite{yao2024epq} theoretically demonstrated that increased diversity improves OOD generalization and proposed `diverseMix`, a semantic-level interpolation strategy with dynamic adjustment. Similarly, \cite{jiang2023vzb} introduced Diverse Outlier Sampling (DOS), which selects diverse and informative outliers from auxiliary datasets by clustering normalized latent representations. These dynamic sampling and generation techniques, along with adaptive weighting strategies like Hopfield Boosting \cite{hofmann2024gnx} that prioritize "hard" outliers, collectively contribute to refining the decision boundary in long-tailed settings, ensuring that tail classes are not erroneously flagged as OOD while true anomalies are detected.

Beyond explicit outlier exposure and loss modifications, engineering the representation space is critical. \cite{shin2024lnf} introduced \textbf{Representation Norm Amplification (RNA)}, a novel training method that directly addresses the trade-off between LTR classification accuracy and OOD detection performance. RNA decouples ID classification and OOD detection by leveraging the norm of the representation vector as a dedicated dimension for OOD scoring. It achieves this by training the classifier to minimize classification loss only for ID samples, while simultaneously regularizing to enlarge the norm of ID representations. Crucially, auxiliary OOD samples are used to regularize Batch Normalization (BN) layers, indirectly reducing OOD representation norms and creating a discernible difference in activation ratios and representation norms. This allows for simultaneous high performance in both tasks, overcoming limitations of previous methods. Similarly, \cite{lu20249d4} proposed Prototypic ALearning with a Mixture of prototypes (PALM), which models each ID class with multiple prototypes using a mixture of von Mises-Fisher distributions. While not exclusively for long-tailed settings, this approach is highly beneficial for capturing the inherent intra-class diversity within sparse tail classes, leading to more faithful embeddings and improved ID-OOD separability. \cite{zhang202312h} introduced Multi-scale OOD DEtection (MODE), leveraging both global and local representations with an attention-based local propagation mechanism. This multi-scale approach can help distinguish fine-grained tail-class features from OOD noise, especially when global features are ambiguous due to background clutter.

In \textbf{class-incremental learning (CIL)}, where models continuously learn new classes over time, maintaining robust OOD performance is a significant hurdle due to catastrophic forgetting of previously learned classes. The challenge lies in adapting to new ID classes without degrading the OOD detection capability for both old and new data distributions. This area has historically been underexplored, but recent work has begun to provide dedicated solutions and benchmarks.

\cite{miao20246mk} introduced OpenCIL, the first comprehensive benchmark for OOD detection in CIL, highlighting that CIL models exhibit increasing biases towards OOD samples and newly added classes with more incremental steps, leading to decreased OOD detection performance. OpenCIL proposes two frameworks for integrating OOD detection into CIL: post-hoc methods (applying OOD scores on CIL model features) and fine-tuning-based methods (training an additional OOD classifier while freezing the CIL backbone). To mitigate the identified biases, \cite{miao20246mk} further proposed Bi-directional Energy Regularization (BER). BER addresses two key issues: New Task Energy Regularization (NTER) prevents OOD samples from being over-confidently classified into new classes by synthesizing pseudo-OOD samples and enlarging decision margins. Old Task Energy Regularization (OTER) prevents old ID samples from being misclassified as OOD (due to catastrophic forgetting) by boosting prediction confidence for old classes using augmented memory samples. BER provides a targeted solution to the unique challenges of OOD in CIL by explicitly addressing the dynamic nature of the ID distribution.

Another promising direction is the integration of uncertainty quantification methods. \cite{aguilar2023ms5} proposed Continual Evidential Deep Learning (CEDL), which integrates Evidential Deep Learning (EDL) into a continual learning framework to simultaneously perform incremental object classification and OOD detection. CEDL combines exemplar rehearsal and knowledge distillation with a novel loss function that includes evidential cross-entropy, KL-divergence regularization for new classes, and knowledge distillation. Their findings indicate that evidential vacuity is a good indicator for OOD detection in CIL, while dissonance struggles to distinguish old ID from OOD. This work offers a principled way to estimate and leverage uncertainty for OOD detection in evolving CIL environments.

Beyond these dedicated CIL-OOD methods, several general OOD concepts offer indirect but promising contributions. Techniques that enhance training stability and prevent overconfidence are crucial in CIL. \cite{cheng20233yi}'s Average of Pruning (AoP), which combines model averaging and network pruning, could help mitigate OOD detection instability and overfitting during continuous learning. Similarly, \cite{chen2024kl7}'s Optimal Parameter and Neuron Pruning (OPNP), a training-free method, could reduce overconfidence in CIL models without requiring additional training data, thus improving OOD discrimination. Leveraging generic pre-trained representations, as explored by GROOD \cite{vojr2023ee1}, might offer a more stable foundation for OOD detection in CIL, as these representations are less susceptible to task-specific catastrophic forgetting compared to features learned from scratch. The dynamic prototype updating mechanism in \cite{li2024rs5}'s DPU, though developed for multimodal OOD, conceptually aligns with the need to dynamically refine class representations in CIL to maintain stable boundaries for OOD detection.

In conclusion, specialized learning settings like long-tailed recognition have seen significant progress through tailored solutions that address the nuanced interactions between ID and OOD data, often leveraging dynamic outlier adaptation, sophisticated representation learning, and explicit norm amplification. Crucially, the field of OOD detection in class-incremental learning is rapidly maturing, moving from an underexplored area to one with dedicated benchmarks and methods like OpenCIL and BER, and principled uncertainty-aware approaches like CEDL. Future research needs to further integrate these insights, developing dynamic and adaptive OOD detection frameworks that can explicitly handle evolving ID distributions and catastrophic forgetting, ensuring robust OOD performance in truly open-ended, lifelong learning scenarios.