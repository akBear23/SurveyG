\subsection{OOD for Autonomous Systems and Cyber-Physical Systems}

The safe and reliable deployment of autonomous systems, encompassing self-driving vehicles, robotics, and industrial cyber-physical systems (CPS), critically depends on their ability to detect and appropriately react to Out-of-Distribution (OOD) events. In these dynamic, open-world environments, encountering unforeseen objects, sensor malfunctions, or adversarial attacks can lead to catastrophic failures if not promptly identified. This subsection delves into the specialized advancements in OOD detection that address the stringent requirements of real-time performance, robust multimodal sensor fusion, and the nuanced handling of diverse OOD events in such safety-critical applications.

Ensuring the trustworthiness of learning-enabled components in CPS necessitates OOD detection with strong statistical guarantees and real-time capabilities. Early work by \cite{cai2020lsi} addressed this by integrating Variational Autoencoders (VAEs) and Deep Support Vector Data Description (SVDD) within an Inductive Conformal Anomaly Detection (ICAD) framework, providing well-calibrated false alarm rates for high-dimensional sensor inputs. Building on such foundational guarantees, \cite{kaur2022cty} introduced iDECODe, which leverages in-distribution equivariance for conformal OOD detection, offering bounded false detection rates. Extending this to dynamic environments, \cite{kaur20248t3} proposed CODiT for OOD detection in time-series (dependent) data within CPS, utilizing temporal equivariance and Fisher's method for robust, guaranteed false alarm rates. A crucial practical concern in safety-critical systems is managing false positives; \cite{vishwakarma2024z1m} tackled this with a human-in-the-loop framework that adaptively updates OOD detection thresholds using expert feedback and provides theoretical guarantees on false positive rates, even under distribution shifts. Beyond mere statistical detection, \cite{guerin202201y} argued that traditional OOD detection is insufficient for safety-critical contexts, advocating for Out-of-Model-Scope (OMS) detection, which focuses on identifying inputs that lead to actual model errors, thereby providing a more direct measure of safety. Robustness against malicious inputs is also paramount; \cite{chen2020mbk} introduced ALOE (Adversarial Learning with inlier and Outlier Exposure), a training-time strategy that robustifies OOD detectors against both adversarial in-distribution and OOD examples, a critical defense against cyber-attacks in CPS. For continually evolving autonomous systems, \cite{aguilar2023ms5} proposed Continual Evidential Deep Learning (CEDL), enabling simultaneous incremental learning of new classes and OOD detection, crucial for systems operating in open-ended environments.

A significant challenge in autonomous systems is the effective integration of heterogeneous sensor data, such as LiDAR, camera, and radar, for robust OOD detection. Traditional unimodal OOD methods often fail to leverage the complementary information across modalities, which is vital for distinguishing subtle OOD events from sensor noise or adverse environmental conditions. Addressing this, \cite{dong2024a8k} introduced MultiOOD, the first dedicated benchmark for multimodal OOD detection, alongside the "Agree-to-Disagree" (A2D) algorithm and "Nearest Neighbor Prototype-based Mixup" (NP-Mix) for outlier synthesis. Their work demonstrated that leveraging modality prediction discrepancies significantly enhances OOD performance, providing a foundational step for multimodal OOD, although primarily evaluated on video-based action recognition. Directly targeting autonomous driving, \cite{liu2025m5u} proposed "Feature Mixing," an extremely simple and fast multimodal outlier synthesis method for OOD detection and segmentation, specifically for image and point cloud data. This method, which randomly swaps feature dimensions between modalities, achieves state-of-the-art performance with significant speedups over prior methods like NP-Mix, making it highly practical for real-time applications. They also introduced CARLA-OOD, a challenging synthetic multimodal dataset for OOD segmentation in driving scenarios. Further specializing in 3D perception, \cite{ksel20246fe} revisited OOD detection in LiDAR-based 3D object detection, proposing a lightweight post-hoc method that integrates features from the backbone, bounding box parameters, and output logits of a fixed 3D object detector. Crucially, they introduced a novel synthetic OOD generation strategy by perturbing known ID objects and established a new nuScenes OOD benchmark, providing a more realistic evaluation protocol for unknown foreground objects in autonomous driving. For multimodal intent understanding, \cite{zhang2024cx0} proposed MIntOOD, integrating weighted feature fusion with multi-granularity representation learning for both classification and OOD detection, highlighting the need for context-aware OOD in complex autonomous tasks.

The advent of large pre-trained foundation models, particularly Vision-Language Models (VLMs), offers new avenues for open-world OOD detection in autonomous systems by leveraging their vast semantic understanding. \cite{mao20244lp} explored language-enhanced latent representations for OOD detection in autonomous driving, using the cosine similarity of image and text representations encoded by CLIP. This approach improves the transparency and controllability of latent encodings, demonstrating superior performance on realistic driving data compared to traditional vision encoder representations. Similarly, \cite{chen2024f28}'s TagFog, while a general visual OOD method, is motivated by applications like autonomous driving and uses textual anchor guidance from large language models (e.g., ChatGPT) and jigsaw-based fake outlier generation to train robust visual encoders. This allows for learning more compact ID representations and leaving spare regions for OOD data in the feature space, enhancing open-vocabulary OOD capabilities. The broader landscape of OOD detection in the VLM era, as surveyed by \cite{miyai20247ro}, underscores the transformative potential of these models for detecting novel, semantically rich OOD events that traditional methods might miss.

In conclusion, OOD detection is an indispensable enabler for safe and robust autonomous operation. Significant progress has been made in developing methods that offer statistical guarantees, enhance robustness against adversarial attacks, and, critically, leverage multimodal sensor fusion for a more comprehensive understanding of the operational environment. The emergence of VLM-based approaches further promises to extend OOD capabilities to truly open-world, semantically rich unknown scenarios. However, challenges persist in developing unified theoretical frameworks that seamlessly integrate OOD detection with the broader concept of Out-of-Model-Scope, especially in highly dynamic, multimodal, and continually learning systems. Future directions should focus on scaling these guarantees to highly complex, distributed CPS, further integrating human feedback for adaptive learning, and establishing comprehensive benchmarks that reflect the full spectrum of OOD events and temporal dependencies in real-world autonomous environments, including adverse weather conditions and sensor degradation.