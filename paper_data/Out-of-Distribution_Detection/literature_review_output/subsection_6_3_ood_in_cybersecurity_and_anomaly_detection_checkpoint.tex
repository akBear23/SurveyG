\subsection{OOD in Cybersecurity and Anomaly Detection}
Out-of-distribution (OOD) detection is a cornerstone of modern cybersecurity and anomaly detection, providing a critical defense against the dynamic and adversarial nature of digital threats. In these high-stakes environments, OOD samples frequently represent malicious activities, ranging from sophisticated network intrusions and advanced persistent threats to novel malware and fraudulent financial transactions. The ability to promptly and accurately identify these deviations from established normal patterns is paramount for safeguarding critical infrastructure, sensitive data, and financial systems. This subsection synthesizes how OOD detection methods are specifically adapted and applied to diverse data streams, including network traffic, system logs, user behavior, and graph-structured data, highlighting their utility in protecting against unpredictable and evolving threats.

A primary challenge in cybersecurity is the real-time detection of novel network intrusions and traffic anomalies amidst high-volume data streams. Early OOD methods focused on efficiency and feature-space analysis to meet these demands. For instance, Neural Mean Discrepancy (NMD) \cite{dong2021swz} offers an efficient post-hoc technique for detecting OOD samples by measuring deviations in deep neural network activation means, making it suitable for rapid monitoring of network traffic. Similarly, FeatureNorm and NormRatio \cite{yu2022egq} identify optimal intermediate layers where in-distribution (ID) and OOD data exhibit maximal feature norm separation, providing a robust signal for unusual traffic patterns without requiring explicit OOD training samples. Addressing the need for rapid identification of new types of malicious traffic with limited labeled data, SPN \cite{miao2023zf5} proposes a few-shot learning approach based on a Siamese Prototypical Network, incorporating margin loss to ensure OOD detection capabilities for unknown traffic types. In specialized network contexts, such as Controller Area Network (CAN) bus intrusion detection, a cascaded two-stage classification architecture leveraging an Auxiliary Classifier Generative Adversarial Network (ACGAN) effectively distinguishes known attacks from normal traffic while detecting unknown attack classes as OOD \cite{zhao20221ag}, demonstrating architectural adaptations for resource-constrained environments.

For malware analysis and system log anomaly detection, the focus shifts to distinguishing subtle, potentially polymorphic threats from benign system variations, often under conditions of data scarcity. Methods that refine internal representations are crucial here. RankFeat \cite{song2022f5d} enhances OOD detection by removing dominant rank-1 feature components that might obscure subtle OOD signals, proving effective for identifying novel threats in complex datasets like malware binaries. To mitigate ambiguity caused by atypical ID samples, Batch Normalization Assisted Typical Set Estimation (BATS) \cite{zhu2022oir} rectifies extreme features to form a "typical set," which is vital for distinguishing subtle malicious anomalies in system logs from benign, yet unusual, system variations. Furthermore, MOODv2 \cite{li2024n34} enhances ID representation learning through Masked Image Modeling (MIM), yielding more robust and distinct ID features critical for distinguishing subtle malware variants or sophisticated intrusion attempts. In unsupervised settings, where labeled anomalies are rare, Density of States Estimation (DoSE) \cite{morningstar2020re9} leverages multiple summary statistics from generative models to identify atypical samples, overcoming the common challenge of generative models assigning high likelihoods to OOD data, a critical consideration for unsupervised anomaly detection in logs or network flows. Beyond feature-level analysis, neuron-centric approaches like Neuron Activation Coverage (NAC) \cite{liu2023zb3} quantify the "coverage degree" of neuron states to detect OOD, proving useful for identifying deviations in learned patterns of user behavior or system states that could indicate a compromise or insider threat.

The inherently adversarial nature of cybersecurity necessitates OOD detection methods that are robust to manipulation. Attackers actively seek to bypass detectors by crafting adversarial examples that appear in-distribution. To counter this, Adversarial Learning with inlier and Outlier Exposure (ALOE) \cite{chen2020mbk} trains models against both adversarial ID and OOD examples, significantly improving robustness against malicious perturbations designed to evade detection. Building on this, Adversarially Robust OOD Detection Using Lyapunov-Stabilized Embeddings (AROS) \cite{mirzaei2024dad} leverages Neural Ordinary Differential Equations (NODEs) and Lyapunov stability to achieve robust embeddings. AROS notably generates "fake OOD embeddings" from low-likelihood regions of the ID feature space, eliminating the need for auxiliary OOD datasets and enhancing robustness against strong adversarial attacks. Gradient-based methods also contribute to robustness; GradOrth \cite{behpour2023x13} identifies OOD samples by projecting gradients onto low-rank subspaces of ID data, offering a nuanced way to detect deviations in model processing. Similarly, GAIA \cite{chen2023za1} detects "abnormality" in gradient-based attribution results, providing interpretability for security analysts investigating suspicious activities. Furthermore, the concept of tangent distance \cite{li2025jdt} addresses the "curse of dimensionality" in high-dimensional feature spaces, offering a data structure-aware approach to quantify OOD uncertainty by measuring distance to the nearest submanifold space, which is crucial for robust OOD detection against subtle perturbations.

For graph-structured data, prevalent in network topology, social networks, and financial transaction graphs, OOD detection faces unique challenges due to non-Euclidean data structures and complex relationships. GOOD-D \cite{liu202227x} pioneers unsupervised graph-level OOD detection using perturbation-free hierarchical contrastive learning. Addressing the scarcity of OOD data for graphs, GOLD \cite{wang2025xwm} implicitly generates adversarial latent samples to enhance detection without auxiliary OOD datasets. GOODAT \cite{wang2024es5} offers a test-time, plug-and-play graph OOD detection method that leverages a graph masker guided by the Information Bottleneck principle, providing an efficient solution for monitoring network intrusions. The growing importance of this domain is underscored by comprehensive surveys like \cite{cai2025ez2} and unified benchmarks such as UB-GOLD \cite{wang2024q01}, which allows for rigorous comparison of unsupervised graph-level anomaly and OOD detection methods across various threat scenarios. For node-level OOD detection in graph neural networks, NODESAFE \cite{yang2025z62} optimizes energy scores to reduce extreme values and mitigate logit shifts, significantly improving detection accuracy against structural manipulations.

The rise of Large Language Models (LLMs) and multimodal data streams has opened new avenues for detecting sophisticated threats like phishing and social engineering. A survey by \cite{xu2024ufg} systematically reviews how LLMs are utilized for anomaly and OOD detection across various data modalities, including text. For multi-modal OOD detection, \cite{dai2023mhn} leverages LLMs' world knowledge to generate descriptive features while calibrating for hallucination, enhancing the detection of complex, multi-modal threats. Envisioning Outlier Exposure (EOE) \cite{cao20246gj} utilizes LLMs to generate synthetic outlier class labels, providing "envisioned outlier exposure" to improve zero-shot OOD detection without real OOD data, which is crucial for identifying novel attack patterns or zero-day exploits. Furthermore, MIntOOD \cite{zhang2024cx0} proposes a multimodal intent understanding system that simultaneously achieves classification and OOD detection by fusing text, video, and audio, vital for detecting anomalous user behavior or sophisticated social engineering attacks.

In safety-critical Cyber-Physical Systems (CPS), OOD detection demands strong theoretical guarantees and real-time applicability. Inductive Conformal Anomaly Detection (ICAD) \cite{cai2020lsi}, using learned nonconformity measures, provides statistically sound false alarm rate guarantees for real-time OOD detection in CPS, crucial for applications like autonomous vehicles and industrial control systems. Building on this, iDECODe \cite{kaur2022cty} introduces a novel non-conformity measure based on in-distribution equivariance, further strengthening conformal OOD detection with bounded false detection rates. Extending these guarantees to temporal data, CODiT \cite{kaur20248t3} provides OOD detection with conformal guarantees for time-series data in CPS, directly applicable to monitoring network traffic and system logs for evolving threats. To address the practical issue of high false positive rates in dynamic environments, a human-in-the-loop framework \cite{vishwakarma2024z1m} adaptively updates OOD detection thresholds with theoretical guarantees on false positive rate control, ensuring trustworthy deployment. Furthermore, understanding the fundamental objectives of OOD methods, as explored by \cite{bitterwolf2022rw0}, helps in designing more principled and effective security detectors. The Model-Specific OOD framework \cite{averly20239rv} offers a unified perspective on OOD detection based on a deployed model's actual misclassification behavior, which is highly relevant for understanding what a security system *actually* fails on in a real-world context. Finally, Continual Evidential Deep Learning (CEDL) \cite{aguilar2023ms5} integrates evidential deep learning into a continual learning framework to simultaneously perform incremental classification and OOD detection, a critical capability for systems facing evolving threats without catastrophic forgetting.

In conclusion, OOD detection is an indispensable and rapidly evolving field within cybersecurity and anomaly detection. It has progressed from basic statistical deviation measures to sophisticated, robust, and context-aware methodologies capable of addressing diverse data types and adversarial environments. While significant advancements have been made in developing methods for various data modalities, enhancing robustness against adversarial threats, and providing theoretical guarantees, several challenges persist. These include balancing the need for universal OOD solutions with the demonstrated benefits of domain-specific adaptations, developing scalable and theoretically sound methods that can handle the full spectrum of real-world distribution shifts without relying on scarce OOD training data, and rigorously aligning OOD detection with the ultimate goal of ensuring model safety and reliability in constantly changing, unpredictable digital environments. Future research must continue to bridge theoretical rigor with practical deployment, particularly in the face of increasingly sophisticated and adaptive cyber threats.