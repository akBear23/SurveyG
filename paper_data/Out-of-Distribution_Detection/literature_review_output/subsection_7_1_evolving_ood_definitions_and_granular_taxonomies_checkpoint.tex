\subsection{Evolving OOD Definitions and Granular Taxonomies}

The conceptualization of Out-of-Distribution (OOD) detection has undergone a significant evolution, moving beyond a simplistic binary distinction between in-distribution (ID) and OOD data towards a more nuanced, granular, and context-aware understanding. This shift is critical for developing robust and trustworthy AI systems capable of operating reliably in complex real-world environments.

Initially, OOD detection primarily focused on identifying samples from entirely novel semantic categories. However, this narrow view proved insufficient, leading to the introduction of more granular definitions. A pivotal development was the formal distinction between different types of distribution shifts. \cite{yang2022it3} introduced the concept of \textit{Full-Spectrum Out-of-Distribution (FS-OOD) Detection}, explicitly differentiating between \textit{semantic shift} (novel classes) and \textit{covariate shift} (label-preserving appearance changes like lighting or style). Their proposed Semantics score function (SEM) aimed to disentangle these shifts, demonstrating that existing methods often failed to robustly handle covariate-shifted ID data, treating it erroneously as OOD. Further complicating the landscape, \cite{ming2021wu7} highlighted the critical impact of spurious correlations, formalizing "spurious OOD" where models rely on non-causal features, making detection challenging even for inputs that visually resemble ID data. This emphasized that OOD can arise not just from novel semantics or appearance, but also from the model's learned biases.

The need for more rigorous evaluation of these granular shifts quickly became apparent. \cite{yang2023ckx} critically analyzed existing ImageNet-based OOD benchmarks, revealing issues such as ID contamination, semantic ambiguities, and unintended covariate shifts that hindered the accurate assessment of semantic OOD detection. To address this, they introduced `ImageNet-OOD`, a meticulously human-curated dataset designed to isolate pure semantic shift by minimizing covariate variations. Building on this, \cite{wang2024is1} provided a comprehensive cross-evaluation of OOD detection and Open-Set Recognition (OSR) methods, further disentangling semantic and covariate shifts on large-scale benchmarks and proposing a new "Outlier-Aware Accuracy" (OAA) metric to reconcile robustness to covariate shift with the ability to detect its presence. These works collectively underscored the importance of clean, disentangled evaluation for understanding what OOD algorithms truly detect.

A significant conceptual re-framing of the OOD problem was introduced by \cite{averly20239rv} with the \textit{Model-Specific Out-of-Distribution (MS-OOD) Detection} framework. This paradigm shifted the definition of OOD from being purely based on data properties to being dependent on a \textit{specific deployed model's performance and misclassification behavior}. Under MS-OOD, an example is considered OOD if the model cannot classify it correctly, unifying semantic shift, covariate shift, and even misclassified in-distribution examples under a single, performance-driven ground truth. This perspective acknowledges that what constitutes "OOD" can be subjective and model-dependent, moving towards a more practical, context-aware definition.

The binary nature of traditional OOD evaluation also faced scrutiny. \cite{long2024os1} addressed the "Sorites Paradox" in OOD evaluation, arguing that a simple binary ID/OOD distinction fails to capture the continuous \textit{degree} of semantic and covariate shifts. They introduced the \textit{Incremental Shift OOD (IS-OOD)} benchmark and \textit{Language Aligned Image feature Decomposition (LAID)}, a CLIP-based method to quantitatively decompose image features into distinct semantic and covariate components. This allowed for continuous measurement of shift degrees, providing a far more granular and informative evaluation of OOD detection performance as a function of shift intensity.

As the field matured and its problem definitions became increasingly complex, the need for structured organization emerged. \cite{lang20237w3} provided the first comprehensive survey on OOD detection in Natural Language Processing (NLP), introducing a novel taxonomy based on the availability of OOD data during training and highlighting NLP-specific challenges. This reflects the emergence of task-oriented and domain-specific taxonomies to organize the field's growing complexity, moving beyond generic definitions to practical, application-driven categorizations. Complementing this, theoretical works like \cite{du2024aea} and \cite{fang20249gd} contribute to this maturing conceptual understanding by exploring the fundamental learnability of OOD detection and the role of in-distribution labels, implicitly influencing how OOD boundaries are conceptualized and defined under various conditions.

In conclusion, the evolution of OOD definitions has progressed from a rudimentary binary classification to a sophisticated, multi-faceted understanding. This trajectory, marked by the differentiation of semantic and covariate shifts, the adoption of model-specific perspectives, the development of continuous shift measurements, and the emergence of task-oriented taxonomies, collectively reflects a maturing conceptual understanding of OOD detection. However, challenges remain in developing scalable, universally applicable methods that can robustly handle the full spectrum of these granular shifts without relying on scarce OOD training data, particularly in diverse real-world applications.