\subsection{Outlier Exposure and Virtual Outlier Synthesis}

The challenge of deploying deep learning models in open-world environments necessitates robust mechanisms for identifying Out-of-Distribution (OOD) inputs. A significant advancement in this area is the Outlier Exposure (OE) paradigm, where auxiliary OOD data is incorporated during model training to explicitly teach the model to distinguish novel inputs. This approach often frames OOD detection as a binary classification task, differentiating between in-distribution (ID) and OOD data.

The theoretical underpinnings of OE suggest that many methods leveraging OOD training data are asymptotically equivalent to a binary discriminator, with practical differences often stemming from estimation procedures and the specific choice of auxiliary OOD data \cite{bitterwolf2022rw0}. Early implementations of OE demonstrated its effectiveness, but subsequent research has focused on refining its application and addressing inherent limitations. For instance, \cite{choi202367m} identified that auxiliary OOD data often exhibits class imbalance, proposing a balanced energy regularization loss to apply stronger regularization to majority OOD classes, thereby enhancing detection performance in diverse tasks like semantic segmentation and long-tailed classification. Addressing the vulnerability of OE to adversarial attacks, \cite{chen2020mbk} introduced Adversarial Learning with inlier and Outlier Exposure (ALOE), which robustifies detectors by training against both adversarial in-distribution and OOD examples, significantly improving robustness against perturbations.

As OE matured, its application extended to more complex scenarios. In long-tailed recognition, where distinguishing OOD from tail classes is particularly challenging, \cite{miao2023brn} proposed Calibrated Outlier Class Learning (COCL). This method uses debiased large margin learning and outlier-class-aware logit calibration to explicitly separate OOD samples from both head and tail ID classes, outperforming traditional OE by mitigating class-specific biases. Similarly, \cite{wei2023f15} introduced EAT, which employs dynamic virtual labels for OOD data and context-rich tail class augmentation to improve OOD detection in long-tailed settings, demonstrating that strong inlier classification does not automatically imply good OOD detection.

Despite its successes, a critical limitation of OE is the reliance on the availability and diversity of *real* auxiliary OOD data. Collecting sufficiently diverse and representative OOD datasets is often impractical or impossible, leading to a shift towards Virtual Outlier Synthesis (VOS). VOS addresses this data scarcity by generating synthetic outliers, thereby overcoming the dependence on real OOD datasets and enhancing model robustness.

Early forays into VOS, such as Mixture Outlier Exposure (MixOE) by \cite{zhang20212tb}, generated virtual outliers by mixing ID and auxiliary data. This approach was particularly effective for fine-grained OOD detection, where novel inputs are semantically similar to ID data and require a broader coverage of the feature space. Building on the need for diversity, \cite{jiang2023vzb} introduced Diverse Outlier Sampling (DOS), a strategy that selects diverse and informative outliers from auxiliary datasets by combining clustering on normalized features with uncertainty-based selection. This aimed to shape a globally compact decision boundary, improving upon biased greedy sampling. Further advancing this, \cite{yao2024epq} proposed `diverseMix`, a diversity-induced mixup strategy with theoretical guarantees, which generates semantically distinct synthetic outliers through dynamic interpolation, provably enhancing the diversity of the auxiliary set.

More sophisticated VOS methods have emerged, generating synthetic outliers directly from in-distribution data or leveraging advanced generative models. \cite{nie2024ghv} introduced Virtual Outlier Smoothing (VOSo), which constructs auxiliary OOD samples by perturbing semantic regions of ID samples in the *image space*, using Class Activation Maps (CAMs). Crucially, VOSo assigns dynamic soft labels based on the perturbation extent, creating a smoother decision boundary and more nuanced uncertainty estimation than traditional uniform OOD labels. Similarly, \cite{yang2023pre} (MixOOD) also utilized Mixup-based strategies to generate augmented images as auxiliary OOD data, demonstrating improved distinction between ID and OOD samples. \cite{chen20243na} explored a "negative branch" method with directional regularization and OOD training data, which implicitly functions as a form of virtual outlier generation to enhance anomaly detection.

The advent of large pre-trained models, particularly Vision-Language Models (VLMs), has opened new avenues for VOS. \cite{ding20242m0} proposed Outlier Label Exposure (OLE) for zero-shot OOD detection, which generates textual outlier prototypes by clustering and refining auxiliary outlier class labels. This effectively synthesizes OOD knowledge in the language domain, enhancing VLM safety without extensive training. Complementing this, \cite{li20245b6} introduced `NegPrompt`, a method that learns transferable negative prompts for each ID class using only ID data. These negative prompts implicitly define OOD boundaries, enabling open-vocabulary OOD detection by leveraging the VLM's semantic understanding. \cite{miyai2023591} (GL-MCM) further explored VLM capabilities by combining global and local concept matching for zero-shot OOD, implicitly handling multi-object OOD scenarios by leveraging local features to overcome contamination of global features. \cite{yu20249dd} developed Self-Calibrated Tuning (SCT) for VLMs, which adaptively balances ID classification and OOD regularization by leveraging ID-irrelevant local context as surrogate OOD data, addressing the issue of spurious OOD features.

Generative models, especially diffusion models, have also been harnessed for VOS. \cite{gao2023kmk} introduced DiffGuard, a semantic mismatch-guided OOD detection method that uses pre-trained diffusion models. It synthesizes new images conditioned on an input and its predicted label, identifying OOD samples by measuring the dissimilarity between the original and synthesized images. This approach leverages the conditional generation capabilities of diffusion models to highlight semantic contradictions, overcoming scalability issues of prior generative methods.

The VOS paradigm has also extended to specialized domains and multimodal inputs. For pixel-wise OOD detection in semantic segmentation, \cite{besnier2021jgn} (ObsNet+LAA) generates OOD-like training data via local adversarial attacks, simulating unknown objects to train an auxiliary observer network. Similarly, \cite{liu2022fdj} (RPL) utilizes Outlier Exposure with synthetic OOD data to learn residual anomaly patterns without retraining the base segmentation model. In 3D LiDAR-based object detection, \cite{ksel20246fe} generates synthetic OOD objects by perturbing known ID object categories, addressing data scarcity in this domain. For multimodal OOD detection, \cite{dong2024a8k} introduced Nearest Neighbor Prototype-based Mixup (NP-Mix) as part of their Agree-to-Disagree (A2D) algorithm, generating outliers by leveraging nearest neighbor class prototypes to explore broader feature spaces. Building on this, \cite{li2024rs5} proposed Dynamic Prototype Updating (DPU), which dynamically adjusts multimodal prediction discrepancy intensification based on a sample's similarity to its class prototype, accounting for intra-class variability in multimodal data. Finally, \cite{hofmann2024gnx} introduced Hopfield Boosting, an OE approach that adaptively samples "hard" outliers using a novel energy function derived from Modern Hopfield Networks, further refining the selection of informative synthetic or real outliers.

In conclusion, Outlier Exposure has evolved from a foundational paradigm to a sophisticated framework that explicitly trains models to recognize novel inputs. The critical challenge of OOD data scarcity has driven the field towards Virtual Outlier Synthesis, which leverages advanced techniques like semantic-level interpolation, adversarial generation, and prompt-based synthesis to create diverse and effective training examples. While VOS has significantly reduced the reliance on real OOD datasets and enhanced model robustness across various modalities and tasks, ongoing challenges include ensuring the representativeness of synthetic outliers for truly unknown OOD distributions, scaling complex generation methods, and developing stronger theoretical guarantees for their generalization capabilities.