\subsection*{Open Challenges and Future Research Avenues}

The quest for truly robust and autonomous AI systems hinges critically on their ability to reliably detect and appropriately handle Out-of-Distribution (OOD) inputs. Despite significant advancements, the field of OOD detection continues to grapple with several profound challenges that define current research frontiers and pave the way for future innovation.

One persistent challenge is the "near OOD" problem, where subtle shifts in data distribution are difficult to distinguish from in-distribution (ID) variations. Models often exhibit overconfidence on these semantically similar, yet novel, inputs, leading to unreliable predictions \cite{ming2021wu7}. Addressing this requires a multi-faceted approach. Some research focuses on **data-centric strategies** to refine the ID/OOD boundary during training. For instance, Mixture Outlier Exposure (MixOE) \cite{zhang20212tb} generates virtual outliers by mixing ID and auxiliary data, specifically targeting fine-grained OOD detection where samples share visual similarities with ID data. Similarly, Virtual Outlier Smoothing (VOSo) \cite{nie2024ghv} constructs virtual outliers by perturbing semantic regions of ID samples, aiming to create smoother, more robust decision boundaries. However, a key challenge remains in generating truly representative and diverse near-OOD samples without inadvertently corrupting the ID manifold. Other efforts concentrate on **representation-centric enhancements**, aiming to improve the inherent separability of ID and OOD features. Batch Normalization Assisted Typical Set Estimation (BATS) \cite{zhu2022oir} rectifies extreme features, while Variational Rectified Activation (VRA) \cite{xu2023767} proposes optimal activation functions to improve ID/OOD separability. Leveraging Neural Collapse properties, such as ID/OOD Orthogonality (NC5) \cite{ammar2023pr1}, projects features onto principal component spaces for better OOD detection, inherently aiding in distinguishing subtle shifts (as discussed in Section 4.2). Neuron Activation Coverage (NAC) \cite{liu2023zb3} provides a novel uncertainty measure sensitive to abnormal activation patterns caused by subtle OOD inputs by quantifying neuron behavior. From a theoretical perspective, \cite{du2024aea} highlights the crucial role of ID labels in these near-OOD scenarios. Despite these advancements, a fundamental understanding of *what constitutes a "near OOD" boundary* and how to robustly generalize detection across diverse, subtly shifted domains remains an open problem, necessitating more robust benchmarks like ImageNet-OOD \cite{yang2023ckx} and IS-OOD \cite{long2024os1} that disentangle semantic and covariate shifts for accurate evaluation.

Another significant open challenge is the scalability of OOD detection methods, particularly for increasingly large foundation models like Vision-Language Models (VLMs) and Large Language Models (LLMs). While these models offer unprecedented representational power and open-vocabulary capabilities (as explored in Section 5.3), traditional OOD methods often struggle with their computational and data demands, or fail to leverage their rich representations effectively without prohibitive inference costs or extensive fine-tuning. Current research is making strides in adapting OOD detection to this new paradigm. Approaches include leveraging pre-trained features, such as GL-MCM \cite{miyai2023591} which combines global and local CLIP features for zero-shot OOD detection, offering flexibility for multi-object scenes. **Prompt engineering and virtual outlier generation** are also emerging as scalable solutions: Outlier Label Exposure (OLE) \cite{ding20242m0} uses auxiliary outlier class labels as pseudo OOD text prompts for VLMs, and NegPrompt \cite{li20245b6} learns transferable negative prompts from ID data alone to enhance OOD sensitivity without external outlier data. Self-Calibrated Tuning (SCT) \cite{yu20249dd} adaptively adjusts ID classification and OOD regularization in VLMs to mitigate spurious OOD features. The potential of LLMs for generating synthetic outlier exposure is explored by \cite{cao20246gj}, envisioning how LLM knowledge can create diverse outlier labels for zero-shot OOD detection. For multimodal foundation models, the MultiOOD benchmark and the Agree-to-Disagree (A2D) algorithm \cite{dong2024a8k} leverage inter-modal prediction discrepancies, while Dynamic Prototype Updating (DPU) \cite{li2024rs5} accounts for intra-class variability. However, the core challenge lies in developing OOD detection frameworks that are *inherently* scalable, efficient, and robust for models with billions of parameters, without requiring extensive retraining or sacrificing the model's generalizability. This includes tackling prohibitive inference costs, catastrophic forgetting during OOD-specific fine-tuning, and the theoretical understanding of OOD behavior in these complex architectures, as highlighted by \cite{miyai20247ro}.

Looking ahead, future research avenues are poised to develop more adaptive and dynamic OOD systems that can learn and adjust in real-time. This involves moving beyond static OOD detectors to systems capable of continuous monitoring and adaptation in dynamic environments, such as Cyber-Physical Systems (CPS). Building on the practical deployment considerations discussed in Section 6.4, methods like those pioneered by \cite{cai2020lsi} use learned nonconformity measures within a conformal prediction framework to provide real-time OOD detection with statistical guarantees. Further advancements like iDECODe \cite{kaur2022cty} leverage in-distribution equivariance for conformal OOD detection with bounded false detection rates, a concept extended to dependent time-series data in \cite{kaur20248t3}. The challenge of adapting to domain shifts at test time for dense OOD detection in segmentation is addressed by ATTA \cite{gao2023epm}, which uses a dual-level adaptation framework. Future work needs to focus on **online OOD detection** that can continuously update its model of ID and OOD without full retraining, **proactive adaptation** that anticipates shifts, and **self-correcting AI systems** that can not only detect OOD but also intelligently propose mitigation strategies or request human intervention \cite{vishwakarma2024z1m}. The concept of adaptive sampling of "hard" outliers during training, as demonstrated by Energy-based Hopfield Boosting \cite{hofmann2024gnx}, also contributes to dynamic system adjustment.

Another promising direction involves exploring **causal inference for OOD detection** to understand underlying mechanisms rather than merely identifying statistical anomalies. Traditional OOD methods often rely on statistical correlations, making them vulnerable to spurious associations that do not generalize across different environments. The work by \cite{ming2021wu7} on the impact of spurious correlation for OOD detection underscores this limitation. Future research should focus on developing OOD detectors that are robust to such correlations by explicitly learning causal relationships. This could involve leveraging frameworks like Invariant Risk Minimization (IRM) \cite{arjovsky2019invariant} or Structural Causal Models (SCMs) to disentangle causal (invariant) features from non-causal (environmental) ones. Specific research questions include: How can we design training objectives that promote the learning of causally invariant representations that are inherently more robust to OOD shifts? Can interventional or counterfactual reasoning be used to identify features that truly *cause* an input to be OOD, leading to more interpretable and generalizable OOD signals? Furthermore, exploring causal discovery techniques to model the underlying causal graph of ID data could enable the detection of OOD samples as deviations from this fundamental structure, offering a deeper, more principled understanding of novelty.

Finally, fostering deeper integration with other machine learning tasks like active learning and continual learning is crucial for holistic, efficient, and robust AI solutions that can operate autonomously in complex environments. OOD detection naturally complements **active learning (AL)**, as OOD samples represent regions of uncertainty where the model's competence is low, making them ideal candidates for human labeling. SISOM \cite{schmidt2024syr} proposes a unified approach, demonstrating that OOD detection and AL can be addressed simultaneously by leveraging enriched feature space distance metrics. Future work could explore how OOD uncertainty can more effectively guide AL to discover truly novel classes or subtle shifts, rather than just ambiguous ID samples. Similarly, in **continual learning (CL)**, OOD detection is vital for maintaining robustness to previously learned ID data while reliably identifying novel inputs without catastrophic forgetting. Continual Evidential Deep Learning (CEDL) \cite{aguilar2023ms5} offers a solution for simultaneous incremental object classification and OOD detection. MIntOOD \cite{zhang2024cx0} extends this to multimodal intent understanding. The challenge lies in developing OOD detectors that can dynamically evolve with the model in CL settings, updating their ID boundaries without re-exposing to all past data or confusing new ID classes with true OOD. These integrated approaches represent a significant step towards building AI systems that are not only aware of their limitations but can also actively learn, adapt, and operate safely in dynamic, open-world settings.

Ultimately, the future of OOD detection lies in a paradigm shift from reactive, isolated detectors to proactive, integrated, and self-monitoring AI systems. This grand vision entails models that continuously learn their own competence boundaries, adapt dynamically to evolving environments, leverage causal understanding for robust generalization, and seamlessly integrate with learning processes like active and continual learning. Such holistic, efficient, and robust AI solutions will be indispensable for building trustworthy systems that can operate autonomously and ethically in an increasingly complex and unpredictable world.