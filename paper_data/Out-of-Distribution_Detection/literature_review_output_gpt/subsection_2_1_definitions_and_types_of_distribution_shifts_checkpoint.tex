\subsection{Definitions and Types of Distribution Shifts}

The problem of Out-of-Distribution (OOD) detection is crucial in ensuring the reliability of machine learning models when they encounter data that diverges from the training distribution. This subsection aims to clarify key concepts related to OOD detection, including definitions of in-distribution (ID) and out-of-distribution (OOD) samples, as well as categorizing the various types of distribution shifts that can occur.

In the context of OOD detection, ID samples refer to data points that the model has been trained on, whereas OOD samples are those that originate from a different distribution, which the model has not encountered during training. The distinction between these two categories is essential for developing effective detection strategies. Papers such as \cite{yang2022it3} introduce the concept of Full-Spectrum OOD detection, which emphasizes the need to differentiate between semantic shifts (new classes) and covariate shifts (changes in input distribution). For instance, a semantic shift occurs when a model is presented with entirely new categories that were not included in the training set, while a covariate shift involves variations in the input data distribution that do not change the underlying classes, such as changes in lighting or background.

One notable contribution to the understanding of distribution shifts is the work by \cite{ming2021wu7}, which highlights the impact of spurious correlations in training data on OOD detection performance. The authors categorize OOD samples into non-spurious and spurious OOD, where spurious OOD samples contain misleading features that can lead to incorrect model predictions. This categorization addresses a significant limitation in existing OOD detection frameworks, which often fail to account for the complexities introduced by spurious correlations.

Further advancements in the field include the introduction of a unified framework by \cite{averly20239rv}, which seeks to integrate the detection of both semantic and covariate shifts under a single model-specific perspective. This approach recognizes that OOD detection is not merely about identifying unseen classes but also about managing the inherent uncertainties associated with covariate shifts. By establishing a model-specific acceptance and rejection framework, the authors provide a more nuanced understanding of how ID labels can assist in OOD detection, particularly in scenarios where the model's performance on ID data directly influences its ability to recognize OOD samples.

Another significant contribution is the work by \cite{long2024os1}, which critiques existing benchmarks for their simplistic binary classification of OOD samples. The authors propose a new benchmark, Incremental Shift OOD (IS-OOD), that categorizes samples based on the degree of semantic and covariate shifts. This innovative approach allows for a more detailed evaluation of OOD detection methods, moving beyond the binary classification that has dominated previous research.

Despite these advancements, challenges remain in the field of OOD detection. For instance, the reliance on labeled ID data, as highlighted by \cite{du20248xe}, poses limitations when attempting to leverage unlabeled data for OOD detection. The authors propose a framework that utilizes unlabeled wild data to improve detection performance, addressing a critical gap in the literature regarding the effective use of unlabeled data for this purpose.

In conclusion, while significant strides have been made in understanding and categorizing distribution shifts in OOD detection, challenges persist. Future research should focus on developing methods that can effectively leverage both labeled and unlabeled data, while also addressing the complexities introduced by spurious correlations and the need for nuanced evaluation frameworks. The integration of these elements will be crucial for advancing the reliability of machine learning models in real-world applications.
```