\subsection{Post-hoc Scoring Mechanisms}

Out-of-Distribution (OOD) detection is a critical challenge in deploying machine learning models in real-world scenarios, particularly when models confront data that deviates from their training distributions. Post-hoc scoring mechanisms have emerged as a popular approach, leveraging the outputs of pre-trained models to derive OOD scores. This subsection reviews foundational techniques such as Maximum Softmax Probability (MSP), Mahalanobis distance, and energy-based scores, highlighting their advantages and limitations.

A seminal contribution to this area is the work by Hendrycks and Gimpel (2017), which introduced simple baselines for OOD detection, including MSP and Mahalanobis distance on features \cite{hendrycks2017baseline}. MSP calculates the maximum softmax probability of the model's output, with lower probabilities indicating potential OOD samples. While this method is straightforward and easy to implement, it often struggles with high-confidence misclassifications, particularly in scenarios where OOD samples share visual similarities with in-distribution (ID) data.

Building on this foundation, Liang et al. (2018) proposed ODIN, which enhances the softmax confidence score through temperature scaling and input perturbation \cite{liang2018enhancing}. This approach addresses some limitations of MSP by introducing a more nuanced handling of input variations, yet it still relies heavily on the quality of the underlying model and can be sensitive to perturbation choices.

Lee et al. (2018) further advanced the field by applying Mahalanobis distance to feature representations, regularizing the feature space with generative adversarial networks (GANs) \cite{lee2018simple}. This technique effectively captures the distribution of in-distribution data, but it introduces additional complexity and computational overhead associated with GAN training. Moreover, it still suffers from the fundamental challenge of relying on the model's ability to learn robust feature representations, which can be compromised in practice.

In contrast, Liu et al. (2020) introduced energy-based models that optimize an energy score during training to push OOD samples to higher energy levels \cite{liu2020energy}. This method provides a more principled approach to OOD detection by directly modeling the energy landscape of the data distribution. However, it requires careful tuning of energy parameters and may not generalize well across different datasets.

Recent works have sought to address the limitations of earlier approaches by exploring more sophisticated sampling strategies and model adaptations. For instance, Huang et al. (2021) utilized a "Meta-OOD Score" based on likelihoods from pre-trained language models, demonstrating the potential of leveraging generative models for OOD detection \cite{huang2021meta}. This approach highlights the importance of integrating diverse data sources to enhance detection capabilities, yet it still faces challenges related to model complexity and the need for extensive training data.

The work by Wang et al. (2022) on "Virtual Outlier Synthesis" (VOS) introduces a training-time optimization method that generates synthetic OOD samples to improve model robustness \cite{wang2022virtual}. This method illustrates the trend towards enhancing OOD detection through data augmentation techniques, yet it remains dependent on the quality and representativeness of the synthetic data generated.

More recently, Ming et al. (2023) built upon energy-based models by leveraging and fine-tuning pre-trained large models for OOD detection, further illustrating the trend towards utilizing large-scale pre-trained networks \cite{ming2023fine}. While this approach shows promise, it underscores the ongoing challenge of ensuring that models remain effective in the face of diverse and unpredictable OOD inputs.

In summary, while post-hoc scoring mechanisms have made significant strides in OOD detection, unresolved issues remain, particularly regarding the reliance on model quality and the challenges posed by the diversity of OOD samples. Future research directions could focus on developing more robust methods that integrate diverse data modalities and enhance model adaptability to improve OOD detection performance in real-world applications.
```