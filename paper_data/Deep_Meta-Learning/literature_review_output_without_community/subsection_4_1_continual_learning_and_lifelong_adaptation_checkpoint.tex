\subsection{Continual Learning and Lifelong Adaptation}

Continual Learning (CL) and Lifelong Adaptation (LLA) represent a paramount challenge and a critical frontier in artificial intelligence, aiming to equip models with the capacity to learn sequentially from an endless stream of tasks or data over extended periods \cite{son2023lda, hospedales2020m37}. Unlike traditional deep learning, which often assumes a static dataset and a single training phase, CL demands that models continuously acquire new knowledge and skills without degrading performance on previously learned tasks. The central impediment to achieving this is "catastrophic forgetting," a phenomenon where deep neural networks abruptly lose knowledge of prior tasks upon learning new ones \cite{son2023lda}. This inherent instability stems from the fundamental plasticity-stability dilemma: the model must be plastic enough to adapt to novel information but stable enough to retain existing knowledge.

Meta-learning, often described as "learning to learn," offers a powerful paradigm to address this dilemma by focusing on acquiring generalizable learning strategies rather than task-specific knowledge \cite{peng20209of}. Within the meta-learning framework, the goal is to develop "meta-continual learning" (MCL) systems that can meta-learn the ability to learn continually, thereby facilitating persistent knowledge accumulation, effective knowledge transfer, and robust adaptation to constantly evolving environments \cite{son2023lda}. This moves beyond static task adaptation, characteristic of many initial meta-learning applications, towards dynamic, ongoing learning processes.

Early meta-learning efforts, while not explicitly designed for sequential learning, laid crucial groundwork by emphasizing rapid adaptation and knowledge transfer across tasks \cite{hospedales2020m37}. For instance, optimization-based meta-learners like Model-Agnostic Meta-Learning (MAML) \cite{finn2017vrt} learn an optimal initialization that allows for swift adaptation to a new task with only a few gradient steps. Similarly, metric-based approaches learn transferable similarity functions to generalize to novel classes from limited examples \cite{peng20209of}. These foundational methods excel at enabling rapid adaptation to *individual* new tasks by leveraging shared structures across a distribution of tasks. However, they do not inherently provide explicit mechanisms to prevent catastrophic forgetting when tasks arrive *sequentially* over time. The challenge for MCL lies in extending these rapid adaptation capabilities to a persistent, non-stationary stream of tasks, where the meta-learner itself must learn how to balance plasticity and stability.

To overcome catastrophic forgetting and enable true lifelong adaptation, meta-learning research has evolved to incorporate explicit mechanisms for knowledge retention and robust adaptation within sequential learning contexts. These approaches generally fall into several broad categories, which will be explored in detail in subsequent subsections:

\begin{enumerate}
    \item \textbf{Regularization-based MCL:} These methods focus on meta-learning strategies to protect important knowledge or modulate plasticity during sequential updates. This can involve learning how to selectively update parameters, constrain parameter changes, or regularize the learning process to prevent drastic shifts that would erase prior knowledge.
    \item \textbf{Replay-based MCL:} This category leverages meta-learning to optimize the use of past experiences. Instead of simply storing and replaying old data, meta-learning can be used to learn *what* to replay, *when* to replay, or *how* to integrate replayed experiences most effectively into the learning process to mitigate forgetting.
    \item \textbf{Architecture-based and Decoupled MCL:} These approaches introduce novel structural designs or algorithmic decoupling to achieve inherent forgetting immunity. This might involve meta-learning specialized network architectures, dynamic network expansion, or separating representation learning from sequential knowledge integration to ensure that core representations remain stable while new information is assimilated.
    \item \textbf{Biologically Inspired Mechanisms:} Drawing inspiration from natural intelligence, some meta-learning methods explore biologically plausible mechanisms, such as local plasticity rules or neuromodulation, to achieve robust and energy-efficient lifelong adaptation, addressing the biological implausibility of traditional backpropagation in continuous learning settings.
\end{enumerate}

The integration of meta-learning with continual learning is crucial for developing AI systems capable of operating autonomously in dynamic, real-world environments. This includes scenarios where models must continually adapt to evolving data distributions, learn new skills in embodied AI, or maintain performance with large foundation models without constant re-training. The ability to persistently accumulate knowledge and adapt to novel circumstances without forgetting is a prerequisite for truly intelligent and versatile AI, setting the stage for more resilient and perpetually learning systems. While significant progress has been made, challenges remain in scaling these approaches to an unbounded stream of diverse tasks, formalizing the optimal balance between plasticity and stability, and developing theoretically sound and computationally efficient mechanisms to prevent catastrophic forgetting. The subsequent subsections will delve into the specific methodologies and advancements within these categories, highlighting how meta-learning is pushing the boundaries towards robust lifelong adaptation.