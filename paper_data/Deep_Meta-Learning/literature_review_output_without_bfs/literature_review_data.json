{
  "title": "A Comprehensive Literature Review with Self-Reflection",
  "papers_processed": 285,
  "paper_list": [
    "bfe284e4338e62f0a61bb33398353efd687f206f.pdf",
    "020bb2ba5f3923858cd6882ba5c5a44ea8041ab6.pdf",
    "3904315e2eca50d0086e4b7273f7fd707c652230.pdf",
    "d8d680aea59295c020b9d53d78dd8d954a876845.pdf",
    "208cd4b25768f0096fb2e80e7690473da0e2a563.pdf",
    "4625628163a2ee0e6cd320cd7a14b4ccded2a631.pdf",
    "282a380fb5ac26d99667224cef8c630f6882704f.pdf",
    "15561ab20c298e113b0008b7a029486a422e7ca3.pdf",
    "06b8e82542d1873928d007548a23d3b77daa11f8.pdf",
    "b0d8165eecf2aa04a85e701d0c6bb4edd4b3811b.pdf",
    "482c0cbfffa77154e3c879c497f50b605297d5bc.pdf",
    "332c44793b70776b9b966128c52e694222b1ab73.pdf",
    "91e6d31e3bb634007dbc3abc3d84da01412fea17.pdf",
    "557e9371711c7409c78c96a6a2bea290a28cb365.pdf",
    "22733aac53e89446aed76dd1983bf2d74567ba88.pdf",
    "c40a927a558ad5a5ffe254605ed3bfebd18be39c.pdf",
    "f4eff7c0127a2ef92c441f028c3bb15b64cabcc8.pdf",
    "361e953f792a585496834ee14216b94d0ce9ae74.pdf",
    "2e4316e7c38373d068f8ff55f26ff83dfc4238b8.pdf",
    "eb8dba325534da472170293b054596a17558c7f2.pdf",
    "505422c6e07b356969e641cdb0985ab2c85ccae4.pdf",
    "6f1a0ac23a26f58da3f5dd5d3426e6f0f2e52298.pdf",
    "30834ae1497c35d362eea14857d93c28d2d12b57.pdf",
    "615e443f15778e9fdde27fecebd5c6d028816e27.pdf",
    "17b6829678802a20e51558ec28c5369414defe42.pdf",
    "e95e3a314cab21171e206cd0824fe93c1c47677c.pdf",
    "4bf9f88d438c7d978fb854eba686cf3933879df1.pdf",
    "38b547a2cf81bacd30cbb322e7279091753604dc.pdf",
    "f68020d22d9895d0d7f173b14961459395f96861.pdf",
    "1ae1c18632d6d4d61b70c918354d633ce24c0bcd.pdf",
    "42de54e614110c0c0a0bbbfee045e11e53eb4a7d.pdf",
    "2bdebf2fb0f5c21907fcaae6d87c7ba5811e778a.pdf",
    "16a3dd5ab3e8570f6083ddf6f88aa5e916450fef.pdf",
    "d700cd5e6fec5d138abf754fe463443ef5f47a95.pdf",
    "e4d018da22a15a39ed47fa6ee000d77ab916aaae.pdf",
    "290357314d0c339bcce31cfbe6b29aa50f89b026.pdf",
    "b6bf19db98572ceec901c96392f2f65f98cd3be6.pdf",
    "79aa092bb37f5ab75d93195f2a5288a51bb8f21d.pdf",
    "51cb7ff41dc6e97a83151e2b7daff87a77d14490.pdf",
    "72d6ea4a92e3b30e3520e6fe10de06e27ece0775.pdf",
    "bf8d58faf972ad0a1026c0a7c5577c07996ef3a7.pdf",
    "5276a6bc74aacf30cc7dc0bfe4d08a2cdec8571b.pdf",
    "03778809fb16471490c57e1259ddf56a23f06ab5.pdf",
    "2e072998dd7b40e9e514b2bb43c8074bd5aa43d2.pdf",
    "e35e0ad5959c3160d66309c3c1e10df9b4352c6d.pdf",
    "2cc418271f790c2a25c0102d16db2fa7442991b6.pdf",
    "a2f64a00ce88326fcd047e0a88af6f47a495742e.pdf",
    "aea3f03299ff0cfea9b394f5559aa1c173f9876f.pdf",
    "1bb15e82795dccd5c5cc71abb0fe2d86c4e2fd61.pdf",
    "9feb0f686252c119ccb1a4b4ccd0d6605e96e8fe.pdf",
    "35ad6ba10006975c2bc67ecefaa9ee6af2453bdc.pdf",
    "31eba23839649c21c3e462a7568b6b72041d4b5c.pdf",
    "2a9f2423d512fa9c90c86521a16f03d961a043f0.pdf",
    "558583c0a90c8a1c37b76c9eeb5fd2b4e80985a1.pdf",
    "cc587f036497bd78a9e1a0d1fdf8bcbcfb1a6dc5.pdf",
    "23bac2542b145bf2fcd17d7fa0a02ae03d0a45f7.pdf",
    "8291dcc23a6daf3afc976acba07b8b47aa0caebe.pdf",
    "6f43439d8c666f05937a41d8041fbb3f08fd97eb.pdf",
    "759ae1234d46e2d1399ce9d642724738a766ed22.pdf",
    "8f502a85ed14fecab7c04d3523ef01458e5e8d1d.pdf",
    "9e1ea0a5a29a19baf531aa5d9f32ca51d240d575.pdf",
    "190ae56a68a94620d7ddfdc7c4b1424673f78b97.pdf",
    "acf3b693d1c04070f2f4cc7bbe839d9e50329e34.pdf",
    "fd66dfb9ca3eb16b365b621bcdf1145b3a29f51e.pdf",
    "4c5f9062192728d20c8d15fe4abf2d68d462db80.pdf",
    "c7629a4d7e1c87fd1ea73850bcb800538fd0aa4b.pdf",
    "8db32b965c10c7dc9f1e3ab357c5298f37d1b86f.pdf",
    "3f787ac280c3d0dbb16eb2456e62ffbf1a56ff62.pdf",
    "13b00c6c8e6fd35a540b08904824aff0d6b66897.pdf",
    "b49f0998b4f8e356a8e3f4313917585cb6a33f57.pdf",
    "754878242a3b480b2ca9031bff623f2c557f2caa.pdf",
    "64a85b9e330315364739766bf170c11b4889dc68.pdf",
    "f10a78ca84de4c255095ff44c5281c2e70f6385c.pdf",
    "bbe13b72314fffcc2f35b0660195f2f6607c00a0.pdf",
    "6bf147de5839aae8abb201afbd1c84c64eb9ce99.pdf",
    "f068074f6ad44fcd512cb15ec2510bbba373f405.pdf",
    "a9f1e05bb2f6f2eeaf92fe1fc5ca3f0eb498f673.pdf",
    "fa1aa587c53c293a88a31bd1ed3e9161c96f4e04.pdf",
    "4e0a735ee8f7606dd13633a88de15f6dfe3348ac.pdf",
    "6867458654058f9a401b5871d666227cd5135360.pdf",
    "82b7f2ab4faec66f16a62b9b5c610c7a5aa1e410.pdf",
    "8a59e5fd6250ccb286c52c27e2ea1ad00565e56b.pdf",
    "15d7105b4e334468a4eddb14f681583cbc8a5dd0.pdf",
    "91f09ff4b588dcd9e5f27cb5c8ce18481b8fcced.pdf",
    "0341673e7ed78a096b9b9b51fbdbeff08beed660.pdf",
    "7bd95a62fd6320730cbb24a0e4fafac97d840652.pdf",
    "0833bed96c0a571782b4b31e90c730726b702595.pdf",
    "1aed7b21007519b7482ac4a005d5f2e0c7a1d047.pdf",
    "77c6cfe76bfc9ebb23cd895747f721a9790445e7.pdf",
    "f8438509b55749850fa6078aea3fa940a4dbcaab.pdf",
    "7f567f1e8972ff31a7ced59c329e7d75da645baf.pdf",
    "84600a7e8737b525d3bb86545b2859379ed084aa.pdf",
    "0d13ff7e27e0a1fb06c57efaeacfc90ccaef3452.pdf",
    "447d48d47d8854a5224138ea5def956c69932738.pdf",
    "7b201e42e32430d951458916810a7dbf1e946a6d.pdf",
    "d0eb13325d77e50a60102139e84484a9beaf62ff.pdf",
    "78d2f29d9b5af247250e04ae1e686b0c6886b2b1.pdf",
    "6ac73bcb953640dcc9c5b7f730f57ad135593d8e.pdf",
    "d1ad1bfa0bb76002b10e7f211b937842baeb28d9.pdf",
    "5ed35dc0dee7970d0408100ef152fca4b17bc637.pdf",
    "859e953bba919a6f989d440b6c23ab19a8cb855b.pdf",
    "40df15ce1de6eb0366179f4726aa55a3e50141fc.pdf",
    "5b470924b4c62bb7bb579e37653cc7c660ac49e3.pdf",
    "769c5e812f0c3c7393b5fae215bd731694667ba2.pdf",
    "a4de6509a26d4f31deea44194581c46b4ebab04c.pdf",
    "3e0298554f27de660bbd10a0bc1d680c507812ae.pdf",
    "f6271880cc1d7ff6514672366fe124fdb1212fb2.pdf",
    "0e8827f439152cf1f5670a3ab391db6148abc7e0.pdf",
    "fd005bd79cb75e247c8e52255a3aa0228c93ae3b.pdf",
    "bc06b836e8011c7c9e2f95dd86783e2157baccfa.pdf",
    "66c2031ebf6407e50e309f4a989497353927859b.pdf",
    "4da500f57577b4ee207ab80b4cde0e1ee338f948.pdf",
    "c317d2faa26b38250960cf3d2e6cf095b9d5b92d.pdf",
    "26b07c6309ef12034571f20973097691a22d7116.pdf",
    "475468f90bd44d34e30991873a37c38e75ff3ffe.pdf",
    "dfd4135cc81c6dfe5ccc4d6d54b4652fa3dd831f.pdf",
    "0c7081bbc26a62aaf7d4ec161a8c59a2b8d162eb.pdf",
    "2d8d30eb2f6d554d13be811d8cee541387573bd9.pdf",
    "5ffee7480bdb997a0f8452829016eee71cb8bbce.pdf",
    "af0d2f8b21334ea9d6dd05254923707f605635d6.pdf",
    "56fcd0f932d4ea5c06fcc42c717fc7ea88b4b6eb.pdf",
    "5ad8802447f81bd8574a3bee0c2d1a6456d1533b.pdf",
    "6c026fcb8d676d64c3e42a74068b918145616a6a.pdf",
    "da8828a4b93f96daa0c863406ba595c6ee27255a.pdf",
    "3bd02411eaa798a158aa780a4d75d0cbfa0af790.pdf",
    "e874da1570e0ca85da39ec74d7d4a012d6413828.pdf",
    "8f12add50397f697631b3fff04608d5efa957867.pdf",
    "756b3e51e8ac2951bfd7d5b5322f1502442eab8e.pdf",
    "80444838b08f8f96b7d18bcc2fd348dad248f2a7.pdf",
    "e07f94238e5362922cf8e8c4d004ad26df52cc9d.pdf",
    "737ee2562b31437146de4df7e2948d1027ef2ecd.pdf",
    "3b479d5df78cd259989d8bbac5d68926d846d3ba.pdf",
    "4454a763c891afb3fb8fa6567a367d05b1938e97.pdf",
    "39226d30f6f76843ef4fe0c2a5c7c334b3beba2e.pdf",
    "641ea570259679b9913d1cacadd8356ed1398149.pdf",
    "1845ece5be61f96292d0b3ea3ecec251b2510909.pdf",
    "9342fce9c5a69f545a778ca7e885ba9d63af928f.pdf",
    "b1493cac304d3fea710b375fa09e4b943a8a7de9.pdf",
    "cc8f827346abea33f1eef838653a2507fc82de6b.pdf",
    "12f851dd2148fff930064b99e88664aec732b8d0.pdf",
    "72cb23c88bd98b1aff0c13302a565be071a4728d.pdf",
    "a1d8d2784d3e468c92410124072bc2eb4c3ace5b.pdf",
    "3c4831e493dc7a362359cdb1883e8c16d084c55b.pdf",
    "e457c9edc3ff2dec29d4f46597c03c56c59708af.pdf",
    "a38500c3448189abd05e72e35332224b96e24a32.pdf",
    "3a4840ecfddc5e938e715379462af6fdbaa5e9b6.pdf",
    "ecf89ea7a615c8442c3dca737482235a57223d37.pdf",
    "a8286ccd3dd83d1bd97582daa09d8db94724d799.pdf",
    "741c64927fb615689ca08235c67ff0c3a5cb25ec.pdf",
    "83565158dc845dc75024db60e5be6bcc25eb0257.pdf",
    "d91ce56b1905e22bde9fccfed8abdeb751537b38.pdf",
    "b1b9bd8d6bc72132f092cb465cc31c19c3a9b589.pdf",
    "98b41528c58e6f5b7b28be5b54029e52ca90c4ab.pdf",
    "3805c99f092f961f81538bea1d3727f552b72727.pdf",
    "3ffafa982182e5b3d41b89ad6627e3fd9865c7e8.pdf",
    "47da3a722b007cef7238299a075c0595fed8632e.pdf",
    "c67de8be8b033362e94d98dcefae88e4b75dd6c7.pdf",
    "e34c14773be68f14bde61badad2e697e1b1330f2.pdf",
    "20b19232cfbb86d9130101ab0ad5fab02188ab0f.pdf",
    "634807a85a6805d6b20863738bc3b287747aeb18.pdf",
    "434d8baa964856bcf4bbe9d1bf49dc70ac2128ab.pdf",
    "5af8c7c650e9ec50d91a16be287ce54b16075fe7.pdf",
    "da1e2e79ec61158876c69bdfa0f3918806c7073f.pdf",
    "f8ee167e718cb152d816f06d42c66efec729a536.pdf",
    "b2058b849f29e99ed4052e2d82b248acc4d6685f.pdf",
    "1d421d179a2520ba23dc1375fe2989e4ba79b437.pdf",
    "63275bb3009b3ec76a51491f5732ab130621b813.pdf",
    "5a8a079d30d40fc24565db7f1687d22dc323d24e.pdf",
    "c51a16812ae6aaf4fc6692eadb96878c1a1d26d3.pdf",
    "eeb0407b2f47857fe7b44c948c08ef23469a8ad2.pdf",
    "b8a16fd8d823cfe683c19d58bec77a023b5bf1ef.pdf",
    "2270ebe7d3ee925abbc062b937aa43805c702cf9.pdf",
    "04396f17e2bdc848300b8670104895b0b3fee84f.pdf",
    "8d6d320dbe9bdd6a1ea844faaf3dc0f5fff2543b.pdf",
    "9d951d22e54e49d60cbc001be6446a03ce4898b1.pdf",
    "cfd039fd9a929ddd08a9e65385690604070ca795.pdf",
    "07f72693aff855ca920dd303ae2e49b057087d5f.pdf",
    "0be1e53ccf4320e6e140523a75d55bac57d4d3e2.pdf",
    "9bc63d773bc04cca984ad6b9f80949b64e56e536.pdf",
    "dea00783b876b41e852adc0ad1954e1005324edd.pdf",
    "d726e991e68ed892bd4c42c8c8150ebc71ae1b9e.pdf",
    "37a349a7a46a9339cb59ac02f81d3848a62d3885.pdf",
    "c6c048fda390e834651090c6f0d4a057528c2028.pdf",
    "1a1879f7e1abaa056db71ebf2123d01bf6d6a7cf.pdf",
    "2dc6799265db441bfa53eb9346cf67fec9a27e39.pdf",
    "3732faadd5df5e6fa097f7f24be871249e6875dd.pdf",
    "069cce0ffad769451fe6008e67a6cd27f9eaa281.pdf",
    "42ac39327eb25d2e757b55eb5eb180f6a55dd020.pdf",
    "1c741e0d5a1d730830392bf4061f9eba3e9af568.pdf",
    "2b39fc628eb7dca420809d931b0086f1d3161990.pdf",
    "4317f6713cbb5fd05fb818fbf535097948b176a3.pdf",
    "7ecab7276a1a0360ad594ae08a0fa91a26ecb025.pdf",
    "2e3e8a56981df1e33d93284be43f81704abc5795.pdf",
    "6da2203f2cbd3c9530764fab58ef74acb8a2c585.pdf",
    "2c8e887bc26c2021c683fe701dd794dd7467e695.pdf",
    "61b03c891489247bcb5ad432b4d485784a274fb4.pdf",
    "1eee17fd5f7a36a64c771d89dbbb00319935c6a8.pdf",
    "28194a351abc44fb9553ccc89d9be3f03b544889.pdf",
    "a968524df2c59fb0ed8892603546f55b731d6439.pdf",
    "1c421007b21a145c53600ca0241783945580bf84.pdf",
    "4e6dbd91bf635f2e9698782daf084b8c779c880d.pdf",
    "cf70392a3b1ae92fdb1b70448aaddcbd03726d3d.pdf",
    "2be63f81ae867082dcb7f94fd8c0aa2ac3ee6e25.pdf",
    "d31b38a6f29f9e3705eea312b69561ec8cfb2a68.pdf",
    "d38e8979ed6cda06aee13efecc6f9a217ece0132.pdf",
    "e0f1ae0ea72e74587dc74883853331d13adad05d.pdf",
    "24411be9cbb7ca4bc27fb6e3285601405e39061f.pdf",
    "fdbe673ffb7408cd626f09a64d0427171354cd5c.pdf",
    "2cc2b10a8482e854e16e50df3a5fb087788556ad.pdf",
    "cb596495788a5fa432a2342fc28f1c623e75d12e.pdf",
    "c09d2846ff81c5dbdf4f8662bd2d9bb4dd61b396.pdf",
    "c8905a4c9c5cbeff6e905687c5077e8af47b8ce4.pdf",
    "b48894f4f4cdebfaa290720960440b024675698c.pdf",
    "78da960c61d41c9c0fc2711fecacc5f5f29660ff.pdf",
    "c91e61d0d8c2c218bc5ad68e217b7d93b80a655c.pdf",
    "ba3281b764913926ef1b7bd0995a58fcc83079fe.pdf",
    "a4a7e66408e7fd7e4b7b01db23d76c054ee2ee79.pdf",
    "59c6f21af0db0411928abf56cd8607c3dcaa61bf.pdf",
    "fe10bf13aeb8728a955f1f8fd312ce77773b59ec.pdf",
    "ac002147f56f0053d5c82968648dace155b6c1dc.pdf",
    "58b1daf9437248f253a6f6a2c5bf260272e7646a.pdf",
    "2dd01e77768b82dcb9c0a760e75efe528dacf6c9.pdf",
    "af531719c3ed74a3a858cdb12c6f488fcfafb8c6.pdf",
    "1ba77e063014a8616a621bed8dd43e18f83712de.pdf",
    "a1c68c32b11d83c9d48c48163f2a445ce359069e.pdf",
    "e4f618eb2e62d986f9746c9fbda2e234fe4c0a40.pdf",
    "b1c2df70f8c287c98e8735d82185bdadf2d4d24b.pdf",
    "59654fcc571a9040ae2f6d02f78543f1903e5a04.pdf",
    "e5638e677d40c9ea67401b9b5241f381a73be6fd.pdf",
    "ac353dc230e18a9f778caedd44c6e2ae70b8c08e.pdf",
    "d87b248c029c7a6a3eab838b73460c834542913e.pdf",
    "c267e53f823a2ef9e9e6bbc26196d68b789fb4c2.pdf",
    "b0e2151301e613daabd42c310d76d3a489bd4cdc.pdf",
    "8f338e2bfc051b35ddbfd743d31681187f3618ab.pdf",
    "610c416cc6a9007547a4a0b8771bb210d73bc3fa.pdf",
    "34fb233e68187fe8e9d3ca017137ad0914993270.pdf",
    "9adc67e027edfea39a7904d96f7d436cd3ec3dff.pdf",
    "27e13096c66a52de889573cdb4e6f2649782d995.pdf",
    "ccdc15a014009d0b4d7f411b3708fb44c562bcff.pdf",
    "d404afdbe65110393771e6eff571491444a910ab.pdf",
    "4b02a48d5204d2e81794776a68d255d69f6e421e.pdf",
    "7d0216a7331ee4031fe488c8ff1da2adfcc59a0c.pdf",
    "205770123d5779da5470ae58cf446bc3e9cfc195.pdf",
    "88c8e710567d9e4d365944cf239bd304638a5a46.pdf",
    "b237deb6c0234378238a6ee49b229b1299b7efe6.pdf",
    "bfb22a7d0f64625b897ebfe3a3f7498d5c71cbb1.pdf",
    "e582dccc95d150d4fca3f2e40e3b67850451ad35.pdf",
    "dfc50bea60deca4a10216f1b2482ac517c4dcc96.pdf",
    "b18efa8feb5e8024546e0abe6bafd58b928a413b.pdf",
    "684b36d780bda6e7c4a4c99aa03390466d476476.pdf",
    "3b32351004d1628329b875576323a7b1767e9e5a.pdf",
    "bef33d15c3e8d433261f97f7001cc41a5ae0ec32.pdf",
    "7515c1ae5d78d4ddecbe380da3a9072ed0bdca01.pdf",
    "287b8037b0f75caec9fab471dd48fe0b81090f74.pdf",
    "b6efb87e4b609fb67304f73b8ee9c1984fce5e88.pdf",
    "d8475d3f7ec9c656547985dffd4384fcb5670275.pdf",
    "e5ff671a38bc7b115afc23a845a8e742c9529f3f.pdf",
    "c253896381b6763981e83dc67a726b6e5e1b6d8f.pdf",
    "7efbdc4a651244d139708f7a5d4552562bdb351c.pdf",
    "644f33e831824777acb91c53a2be642d530f3848.pdf",
    "d9956c775c776c1e4fd7980cd091fab70a55f37d.pdf",
    "71c00beb70d83eab08f1cf6c32f48c112bd9bfdf.pdf",
    "17d70bb09b3be0601e5cdc3debbe81b2338b86ab.pdf",
    "dae9960c44810cf0b9dc64ac8919eb34c19f3913.pdf",
    "272b071e05e960ef3adab2bc8a078fd165b268d5.pdf",
    "b079b1a459758b86c82ac7415dbe3eecee8b02e8.pdf",
    "51fa4c6047b661e596d1943fb8c54d03a8c85099.pdf",
    "52f37e9bd84547db2ecefed420715f312827c398.pdf",
    "5b32284df29baf5201cb8b2313dc077465b15838.pdf",
    "27c71dc136246f9e8a9c985af441cd7426e810ab.pdf",
    "5f72ae90072c4d0df0d4460e7818b6d5ee2cef00.pdf",
    "4481108a93744c5ad282a4ac2fea7883913184bb.pdf",
    "5042c452912818d012274e9754a2c45cf203691d.pdf",
    "588c69df5e7920db0037db76c41f933ee16c290d.pdf",
    "fb0749b9bc04914e294f57c89199572e3cb5183c.pdf",
    "97718bcc9174ee43faf6ee4c105654a5ce7b35b1.pdf",
    "21f5dba5b14c4d78bd869e2a05b4bb9f74db2157.pdf",
    "7527e22accc5796290b4fe1b259c406b44a0b220.pdf",
    "c9b0ddbe27193d10f800943d91450b44324e6d57.pdf",
    "8a44b6276a4c7375e21072e6a300d83fac3ffcf0.pdf",
    "ca48013d99a608e800ae34388fe9fba9ea6ca280.pdf",
    "e1a8bf47ef1c51298f5bcf957062c6ee63a96bfb.pdf",
    "e3de80376d111cf6d282294d7c16023ec1eb2386.pdf",
    "a962dc06a19c08bb76184bde864e7f1e2e502150.pdf",
    "b82a9500246176a6b32598ded8d2b96d1e29f61c.pdf"
  ],
  "citations_map": {
    "bfe284e4338e62f0a61bb33398353efd687f206f.pdf": "sung2017nc5",
    "020bb2ba5f3923858cd6882ba5c5a44ea8041ab6.pdf": "hospedales2020m37",
    "3904315e2eca50d0086e4b7273f7fd707c652230.pdf": "santoro2016323",
    "d8d680aea59295c020b9d53d78dd8d954a876845.pdf": "sun2018iy7",
    "208cd4b25768f0096fb2e80e7690473da0e2a563.pdf": "bertinetto2018ur2",
    "4625628163a2ee0e6cd320cd7a14b4ccded2a631.pdf": "rakelly2019m09",
    "282a380fb5ac26d99667224cef8c630f6882704f.pdf": "wang20167px",
    "15561ab20c298e113b0008b7a029486a422e7ca3.pdf": "franceschi2018u1q",
    "06b8e82542d1873928d007548a23d3b77daa11f8.pdf": "pan2019pue",
    "b0d8165eecf2aa04a85e701d0c6bb4edd4b3811b.pdf": "lanctot2017m2v",
    "482c0cbfffa77154e3c879c497f50b605297d5bc.pdf": "finn20174c4",
    "332c44793b70776b9b966128c52e694222b1ab73.pdf": "huisman2020b7w",
    "91e6d31e3bb634007dbc3abc3d84da01412fea17.pdf": "oconnell2022twd",
    "557e9371711c7409c78c96a6a2bea290a28cb365.pdf": "zhu2020rb5",
    "22733aac53e89446aed76dd1983bf2d74567ba88.pdf": "herzen2021300",
    "c40a927a558ad5a5ffe254605ed3bfebd18be39c.pdf": "wang2020tae",
    "f4eff7c0127a2ef92c441f028c3bb15b64cabcc8.pdf": "yu2018nm7",
    "361e953f792a585496834ee14216b94d0ce9ae74.pdf": "zintgraf2019zat",
    "2e4316e7c38373d068f8ff55f26ff83dfc4238b8.pdf": "li2018soc",
    "eb8dba325534da472170293b054596a17558c7f2.pdf": "guo2021zpk",
    "505422c6e07b356969e641cdb0985ab2c85ccae4.pdf": "li20219tk",
    "6f1a0ac23a26f58da3f5dd5d3426e6f0f2e52298.pdf": "tian2022znj",
    "30834ae1497c35d362eea14857d93c28d2d12b57.pdf": "oh2017x02",
    "615e443f15778e9fdde27fecebd5c6d028816e27.pdf": "papoudakis2019gyl",
    "17b6829678802a20e51558ec28c5369414defe42.pdf": "yoon2019k84",
    "e95e3a314cab21171e206cd0824fe93c1c47677c.pdf": "rajasegaran2020llk",
    "4bf9f88d438c7d978fb854eba686cf3933879df1.pdf": "yin2019cct",
    "38b547a2cf81bacd30cbb322e7279091753604dc.pdf": "qiao2019p6r",
    "f68020d22d9895d0d7f173b14961459395f96861.pdf": "gao2020h75",
    "1ae1c18632d6d4d61b70c918354d633ce24c0bcd.pdf": "patacchiola2020kpq",
    "42de54e614110c0c0a0bbbfee045e11e53eb4a7d.pdf": "nagabandi2018esl",
    "2bdebf2fb0f5c21907fcaae6d87c7ba5811e778a.pdf": "finn2017vrt",
    "16a3dd5ab3e8570f6083ddf6f88aa5e916450fef.pdf": "such2019xok",
    "d700cd5e6fec5d138abf754fe463443ef5f47a95.pdf": "fei20211x6",
    "e4d018da22a15a39ed47fa6ee000d77ab916aaae.pdf": "wang2021ya6",
    "290357314d0c339bcce31cfbe6b29aa50f89b026.pdf": "jang2019a48",
    "b6bf19db98572ceec901c96392f2f65f98cd3be6.pdf": "zhu2022zp1",
    "79aa092bb37f5ab75d93195f2a5288a51bb8f21d.pdf": "gao20223fn",
    "51cb7ff41dc6e97a83151e2b7daff87a77d14490.pdf": "bartler2021i8o",
    "72d6ea4a92e3b30e3520e6fe10de06e27ece0775.pdf": "memon2022j2y",
    "bf8d58faf972ad0a1026c0a7c5577c07996ef3a7.pdf": "yang2018p36",
    "5276a6bc74aacf30cc7dc0bfe4d08a2cdec8571b.pdf": "guo2020acf",
    "03778809fb16471490c57e1259ddf56a23f06ab5.pdf": "dixit20218dd",
    "2e072998dd7b40e9e514b2bb43c8074bd5aa43d2.pdf": "zhou20200ls",
    "e35e0ad5959c3160d66309c3c1e10df9b4352c6d.pdf": "rajasegaran2020glw",
    "2cc418271f790c2a25c0102d16db2fa7442991b6.pdf": "wang2022va1",
    "a2f64a00ce88326fcd047e0a88af6f47a495742e.pdf": "dufumier2021ec1",
    "aea3f03299ff0cfea9b394f5559aa1c173f9876f.pdf": "wistuba2021wha",
    "1bb15e82795dccd5c5cc71abb0fe2d86c4e2fd61.pdf": "ren2019nu0",
    "9feb0f686252c119ccb1a4b4ccd0d6605e96e8fe.pdf": "zhang2020p3y",
    "35ad6ba10006975c2bc67ecefaa9ee6af2453bdc.pdf": "zhou20188lr",
    "31eba23839649c21c3e462a7568b6b72041d4b5c.pdf": "bing2022om0",
    "2a9f2423d512fa9c90c86521a16f03d961a043f0.pdf": "tian20200qx",
    "558583c0a90c8a1c37b76c9eeb5fd2b4e80985a1.pdf": "cai20215z1",
    "cc587f036497bd78a9e1a0d1fdf8bcbcfb1a6dc5.pdf": "wang2021i3l",
    "23bac2542b145bf2fcd17d7fa0a02ae03d0a45f7.pdf": "nam2022z75",
    "8291dcc23a6daf3afc976acba07b8b47aa0caebe.pdf": "zhu2022d9a",
    "6f43439d8c666f05937a41d8041fbb3f08fd97eb.pdf": "wang20204p9",
    "759ae1234d46e2d1399ce9d642724738a766ed22.pdf": "xu2020txy",
    "8f502a85ed14fecab7c04d3523ef01458e5e8d1d.pdf": "xue2022ram",
    "9e1ea0a5a29a19baf531aa5d9f32ca51d240d575.pdf": "li20208tg",
    "190ae56a68a94620d7ddfdc7c4b1424673f78b97.pdf": "chai2022kv5",
    "acf3b693d1c04070f2f4cc7bbe839d9e50329e34.pdf": "yi2021547",
    "fd66dfb9ca3eb16b365b621bcdf1145b3a29f51e.pdf": "pang2018qqo",
    "4c5f9062192728d20c8d15fe4abf2d68d462db80.pdf": "zhang2020s15",
    "c7629a4d7e1c87fd1ea73850bcb800538fd0aa4b.pdf": "zintgraf2021lv1",
    "8db32b965c10c7dc9f1e3ab357c5298f37d1b86f.pdf": "ouyang2021c4t",
    "3f787ac280c3d0dbb16eb2456e62ffbf1a56ff62.pdf": "li2019gpj",
    "13b00c6c8e6fd35a540b08904824aff0d6b66897.pdf": "yu2019o41",
    "b49f0998b4f8e356a8e3f4313917585cb6a33f57.pdf": "chen2021j5t",
    "754878242a3b480b2ca9031bff623f2c557f2caa.pdf": "zintgraf2021hoc",
    "64a85b9e330315364739766bf170c11b4889dc68.pdf": "xu20199h0",
    "f10a78ca84de4c255095ff44c5281c2e70f6385c.pdf": "ding2021284",
    "bbe13b72314fffcc2f35b0660195f2f6607c00a0.pdf": "reed2017sxd",
    "6bf147de5839aae8abb201afbd1c84c64eb9ce99.pdf": "shao2021loj",
    "f068074f6ad44fcd512cb15ec2510bbba373f405.pdf": "jomaa20190ul",
    "a9f1e05bb2f6f2eeaf92fe1fc5ca3f0eb498f673.pdf": "woo2022f3e",
    "fa1aa587c53c293a88a31bd1ed3e9161c96f4e04.pdf": "park2020m5z",
    "4e0a735ee8f7606dd13633a88de15f6dfe3348ac.pdf": "chen2019oep",
    "6867458654058f9a401b5871d666227cd5135360.pdf": "marra20192vv",
    "82b7f2ab4faec66f16a62b9b5c610c7a5aa1e410.pdf": "casebeer20225fs",
    "8a59e5fd6250ccb286c52c27e2ea1ad00565e56b.pdf": "nobakht2022p86",
    "15d7105b4e334468a4eddb14f681583cbc8a5dd0.pdf": "vasconcelos2021fn3",
    "91f09ff4b588dcd9e5f27cb5c8ce18481b8fcced.pdf": "libin2020x8v",
    "0341673e7ed78a096b9b9b51fbdbeff08beed660.pdf": "algan2020u0v",
    "7bd95a62fd6320730cbb24a0e4fafac97d840652.pdf": "lan20196o7",
    "0833bed96c0a571782b4b31e90c730726b702595.pdf": "huang20214b2",
    "1aed7b21007519b7482ac4a005d5f2e0c7a1d047.pdf": "chen2022z45",
    "77c6cfe76bfc9ebb23cd895747f721a9790445e7.pdf": "abdollahzadeh2021zfy",
    "f8438509b55749850fa6078aea3fa940a4dbcaab.pdf": "chen2019xg0",
    "7f567f1e8972ff31a7ced59c329e7d75da645baf.pdf": "xu2018rdh",
    "84600a7e8737b525d3bb86545b2859379ed084aa.pdf": "shen2022kdk",
    "0d13ff7e27e0a1fb06c57efaeacfc90ccaef3452.pdf": "zhang2021hh1",
    "447d48d47d8854a5224138ea5def956c69932738.pdf": "lin2022i6k",
    "7b201e42e32430d951458916810a7dbf1e946a6d.pdf": "tseng2020m83",
    "d0eb13325d77e50a60102139e84484a9beaf62ff.pdf": "peng20209of",
    "78d2f29d9b5af247250e04ae1e686b0c6886b2b1.pdf": "fong20183q5",
    "6ac73bcb953640dcc9c5b7f730f57ad135593d8e.pdf": "liu2022tgc",
    "d1ad1bfa0bb76002b10e7f211b937842baeb28d9.pdf": "bing2022xo7",
    "5ed35dc0dee7970d0408100ef152fca4b17bc637.pdf": "nakasi2020w5x",
    "859e953bba919a6f989d440b6c23ab19a8cb855b.pdf": "przewiezlikowski2022d4y",
    "40df15ce1de6eb0366179f4726aa55a3e50141fc.pdf": "xu2018rjq",
    "5b470924b4c62bb7bb579e37653cc7c660ac49e3.pdf": "ding2019a79",
    "769c5e812f0c3c7393b5fae215bd731694667ba2.pdf": "dorfman2020gku",
    "a4de6509a26d4f31deea44194581c46b4ebab04c.pdf": "wang20210y3",
    "3e0298554f27de660bbd10a0bc1d680c507812ae.pdf": "millea2021bfu",
    "f6271880cc1d7ff6514672366fe124fdb1212fb2.pdf": "lindsey202075a",
    "0e8827f439152cf1f5670a3ab391db6148abc7e0.pdf": "gao2022y3s",
    "fd005bd79cb75e247c8e52255a3aa0228c93ae3b.pdf": "ren2022fc5",
    "bc06b836e8011c7c9e2f95dd86783e2157baccfa.pdf": "wen2022sql",
    "66c2031ebf6407e50e309f4a989497353927859b.pdf": "vecoven2018hc1",
    "4da500f57577b4ee207ab80b4cde0e1ee338f948.pdf": "liang2021juf",
    "c317d2faa26b38250960cf3d2e6cf095b9d5b92d.pdf": "holla2020r6z",
    "26b07c6309ef12034571f20973097691a22d7116.pdf": "fernando2018lt5",
    "475468f90bd44d34e30991873a37c38e75ff3ffe.pdf": "jankowski20138zb",
    "dfd4135cc81c6dfe5ccc4d6d54b4652fa3dd831f.pdf": "banayeeanzade2021zke",
    "0c7081bbc26a62aaf7d4ec161a8c59a2b8d162eb.pdf": "campedelli2021jja",
    "2d8d30eb2f6d554d13be811d8cee541387573bd9.pdf": "jiang20220tg",
    "5ffee7480bdb997a0f8452829016eee71cb8bbce.pdf": "zheng2021olf",
    "af0d2f8b21334ea9d6dd05254923707f605635d6.pdf": "alandoli2021pqm",
    "56fcd0f932d4ea5c06fcc42c717fc7ea88b4b6eb.pdf": "li2021tkg",
    "5ad8802447f81bd8574a3bee0c2d1a6456d1533b.pdf": "daglarli2020nzw",
    "6c026fcb8d676d64c3e42a74068b918145616a6a.pdf": "phaphuangwittayakul2022api",
    "da8828a4b93f96daa0c863406ba595c6ee27255a.pdf": "nie2021pcz",
    "3bd02411eaa798a158aa780a4d75d0cbfa0af790.pdf": "zheng20200ig",
    "e874da1570e0ca85da39ec74d7d4a012d6413828.pdf": "chen2022ccz",
    "8f12add50397f697631b3fff04608d5efa957867.pdf": "qu2022mu6",
    "756b3e51e8ac2951bfd7d5b5322f1502442eab8e.pdf": "alajaji2020b6c",
    "80444838b08f8f96b7d18bcc2fd348dad248f2a7.pdf": "jiang2021uo6",
    "e07f94238e5362922cf8e8c4d004ad26df52cc9d.pdf": "rkhami2021c1c",
    "737ee2562b31437146de4df7e2948d1027ef2ecd.pdf": "holla20202od",
    "3b479d5df78cd259989d8bbac5d68926d846d3ba.pdf": "bhathiya2020avm",
    "4454a763c891afb3fb8fa6567a367d05b1938e97.pdf": "bernacchia20211r0",
    "39226d30f6f76843ef4fe0c2a5c7c334b3beba2e.pdf": "kumar2017p0v",
    "641ea570259679b9913d1cacadd8356ed1398149.pdf": "daglarli20216fl",
    "1845ece5be61f96292d0b3ea3ecec251b2510909.pdf": "baz2022n78",
    "9342fce9c5a69f545a778ca7e885ba9d63af928f.pdf": "dorfman2020mgv",
    "b1493cac304d3fea710b375fa09e4b943a8a7de9.pdf": "vuorio2018gwb",
    "cc8f827346abea33f1eef838653a2507fc82de6b.pdf": "ma2021kfz",
    "12f851dd2148fff930064b99e88664aec732b8d0.pdf": "tian2016j46",
    "72cb23c88bd98b1aff0c13302a565be071a4728d.pdf": "pinedaarango2021254",
    "a1d8d2784d3e468c92410124072bc2eb4c3ace5b.pdf": "foliadis20223y2",
    "3c4831e493dc7a362359cdb1883e8c16d084c55b.pdf": "sutton2022jss",
    "e457c9edc3ff2dec29d4f46597c03c56c59708af.pdf": "huo2022rp4",
    "a38500c3448189abd05e72e35332224b96e24a32.pdf": "hurtado2021h2q",
    "3a4840ecfddc5e938e715379462af6fdbaa5e9b6.pdf": "lee2021jou",
    "ecf89ea7a615c8442c3dca737482235a57223d37.pdf": "peixoto20180pd",
    "a8286ccd3dd83d1bd97582daa09d8db94724d799.pdf": "yuan20205j8",
    "741c64927fb615689ca08235c67ff0c3a5cb25ec.pdf": "zhang2021yox",
    "83565158dc845dc75024db60e5be6bcc25eb0257.pdf": "luo202123f",
    "d91ce56b1905e22bde9fccfed8abdeb751537b38.pdf": "chen2021yqh",
    "b1b9bd8d6bc72132f092cb465cc31c19c3a9b589.pdf": "behl2018rjm",
    "98b41528c58e6f5b7b28be5b54029e52ca90c4ab.pdf": "xu2019brv",
    "3805c99f092f961f81538bea1d3727f552b72727.pdf": "sultana202094g",
    "3ffafa982182e5b3d41b89ad6627e3fd9865c7e8.pdf": "furfaro20197q6",
    "47da3a722b007cef7238299a075c0595fed8632e.pdf": "gu2019tvc",
    "c67de8be8b033362e94d98dcefae88e4b75dd6c7.pdf": "zhang2021p9j",
    "e34c14773be68f14bde61badad2e697e1b1330f2.pdf": "saadallah2021ihn",
    "20b19232cfbb86d9130101ab0ad5fab02188ab0f.pdf": "luedtke2020uub",
    "634807a85a6805d6b20863738bc3b287747aeb18.pdf": "nasrabadi201801h",
    "434d8baa964856bcf4bbe9d1bf49dc70ac2128ab.pdf": "puri20202sx",
    "5af8c7c650e9ec50d91a16be287ce54b16075fe7.pdf": "beck2023x24",
    "da1e2e79ec61158876c69bdfa0f3918806c7073f.pdf": "zhang2023t7k",
    "f8ee167e718cb152d816f06d42c66efec729a536.pdf": "khoee2024ksk",
    "b2058b849f29e99ed4052e2d82b248acc4d6685f.pdf": "hao2023zfk",
    "1d421d179a2520ba23dc1375fe2989e4ba79b437.pdf": "nathaniel2023ycu",
    "63275bb3009b3ec76a51491f5732ab130621b813.pdf": "singh2023zo5",
    "5a8a079d30d40fc24565db7f1687d22dc323d24e.pdf": "wang2023srr",
    "c51a16812ae6aaf4fc6692eadb96878c1a1d26d3.pdf": "liang2023zzh",
    "eeb0407b2f47857fe7b44c948c08ef23469a8ad2.pdf": "tian2023iyh",
    "b8a16fd8d823cfe683c19d58bec77a023b5bf1ef.pdf": "bian2024041",
    "2270ebe7d3ee925abbc062b937aa43805c702cf9.pdf": "schwarz2022jfu",
    "04396f17e2bdc848300b8670104895b0b3fee84f.pdf": "son2023lda",
    "8d6d320dbe9bdd6a1ea844faaf3dc0f5fff2543b.pdf": "wang2024d09",
    "9d951d22e54e49d60cbc001be6446a03ce4898b1.pdf": "rao20232e3",
    "cfd039fd9a929ddd08a9e65385690604070ca795.pdf": "zhang2023jz8",
    "07f72693aff855ca920dd303ae2e49b057087d5f.pdf": "xiu2023ga8",
    "0be1e53ccf4320e6e140523a75d55bac57d4d3e2.pdf": "cai2023ro7",
    "9bc63d773bc04cca984ad6b9f80949b64e56e536.pdf": "lee20230j8",
    "dea00783b876b41e852adc0ad1954e1005324edd.pdf": "guarino2023zsq",
    "d726e991e68ed892bd4c42c8c8150ebc71ae1b9e.pdf": "aqeel2025zql",
    "37a349a7a46a9339cb59ac02f81d3848a62d3885.pdf": "lee2024snq",
    "c6c048fda390e834651090c6f0d4a057528c2028.pdf": "li2023asx",
    "1a1879f7e1abaa056db71ebf2123d01bf6d6a7cf.pdf": "schmidgall20238t4",
    "2dc6799265db441bfa53eb9346cf67fec9a27e39.pdf": "wang2023x5w",
    "3732faadd5df5e6fa097f7f24be871249e6875dd.pdf": "wang2023ryf",
    "069cce0ffad769451fe6008e67a6cd27f9eaa281.pdf": "li2023fhe",
    "42ac39327eb25d2e757b55eb5eb180f6a55dd020.pdf": "yang20238th",
    "1c741e0d5a1d730830392bf4061f9eba3e9af568.pdf": "raja2023hco",
    "2b39fc628eb7dca420809d931b0086f1d3161990.pdf": "fahim2023jsu",
    "4317f6713cbb5fd05fb818fbf535097948b176a3.pdf": "hu2022y0i",
    "7ecab7276a1a0360ad594ae08a0fa91a26ecb025.pdf": "wang2023kho",
    "2e3e8a56981df1e33d93284be43f81704abc5795.pdf": "li2023zn0",
    "6da2203f2cbd3c9530764fab58ef74acb8a2c585.pdf": "chi20235vq",
    "2c8e887bc26c2021c683fe701dd794dd7467e695.pdf": "manoharan2021r46",
    "61b03c891489247bcb5ad432b4d485784a274fb4.pdf": "visca20217nt",
    "1eee17fd5f7a36a64c771d89dbbb00319935c6a8.pdf": "so2021y48",
    "28194a351abc44fb9553ccc89d9be3f03b544889.pdf": "yang2022oxf",
    "a968524df2c59fb0ed8892603546f55b731d6439.pdf": "gupta2021fbg",
    "1c421007b21a145c53600ca0241783945580bf84.pdf": "zheng2021dx4",
    "4e6dbd91bf635f2e9698782daf084b8c779c880d.pdf": "zhang2021sbz",
    "cf70392a3b1ae92fdb1b70448aaddcbd03726d3d.pdf": "wang2024jzu",
    "2be63f81ae867082dcb7f94fd8c0aa2ac3ee6e25.pdf": "zhu20249wq",
    "d31b38a6f29f9e3705eea312b69561ec8cfb2a68.pdf": "yaghoubi2024j56",
    "d38e8979ed6cda06aee13efecc6f9a217ece0132.pdf": "ren20242qj",
    "e0f1ae0ea72e74587dc74883853331d13adad05d.pdf": "ik20248rp",
    "24411be9cbb7ca4bc27fb6e3285601405e39061f.pdf": "weilenmann2024ve2",
    "fdbe673ffb7408cd626f09a64d0427171354cd5c.pdf": "xia2024qx2",
    "2cc2b10a8482e854e16e50df3a5fb087788556ad.pdf": "zhao2024f4b",
    "cb596495788a5fa432a2342fc28f1c623e75d12e.pdf": "li20242rv",
    "c09d2846ff81c5dbdf4f8662bd2d9bb4dd61b396.pdf": "dong2024110",
    "c8905a4c9c5cbeff6e905687c5077e8af47b8ce4.pdf": "liao2024o1z",
    "b48894f4f4cdebfaa290720960440b024675698c.pdf": "naskar202446a",
    "78da960c61d41c9c0fc2711fecacc5f5f29660ff.pdf": "zhang2024a5a",
    "c91e61d0d8c2c218bc5ad68e217b7d93b80a655c.pdf": "sharma2024zlw",
    "ba3281b764913926ef1b7bd0995a58fcc83079fe.pdf": "ouyang2024xj0",
    "a4a7e66408e7fd7e4b7b01db23d76c054ee2ee79.pdf": "wang2025zze",
    "59c6f21af0db0411928abf56cd8607c3dcaa61bf.pdf": "chia2024ltk",
    "fe10bf13aeb8728a955f1f8fd312ce77773b59ec.pdf": "li20246fg",
    "ac002147f56f0053d5c82968648dace155b6c1dc.pdf": "yang2024rh9",
    "58b1daf9437248f253a6f6a2c5bf260272e7646a.pdf": "gao20242uv",
    "2dd01e77768b82dcb9c0a760e75efe528dacf6c9.pdf": "huang2024hlo",
    "af531719c3ed74a3a858cdb12c6f488fcfafb8c6.pdf": "liu2024hko",
    "1ba77e063014a8616a621bed8dd43e18f83712de.pdf": "li2024x2t",
    "a1c68c32b11d83c9d48c48163f2a445ce359069e.pdf": "khattar2024sr6",
    "e4f618eb2e62d986f9746c9fbda2e234fe4c0a40.pdf": "yen2024cxp",
    "b1c2df70f8c287c98e8735d82185bdadf2d4d24b.pdf": "you2024xuq",
    "59654fcc571a9040ae2f6d02f78543f1903e5a04.pdf": "hao2024dyp",
    "e5638e677d40c9ea67401b9b5241f381a73be6fd.pdf": "lang20246m8",
    "ac353dc230e18a9f778caedd44c6e2ae70b8c08e.pdf": "xu2024ywn",
    "d87b248c029c7a6a3eab838b73460c834542913e.pdf": "ding2024jjo",
    "c267e53f823a2ef9e9e6bbc26196d68b789fb4c2.pdf": "wang2024dai",
    "b0e2151301e613daabd42c310d76d3a489bd4cdc.pdf": "nussenbaum2024z82",
    "8f338e2bfc051b35ddbfd743d31681187f3618ab.pdf": "alsaleh2024vdv",
    "610c416cc6a9007547a4a0b8771bb210d73bc3fa.pdf": "ghassemi20241ek",
    "34fb233e68187fe8e9d3ca017137ad0914993270.pdf": "li20254kd",
    "9adc67e027edfea39a7904d96f7d436cd3ec3dff.pdf": "zhao202420b",
    "27e13096c66a52de889573cdb4e6f2649782d995.pdf": "zhang2024xg0",
    "ccdc15a014009d0b4d7f411b3708fb44c562bcff.pdf": "ruwurm2024806",
    "d404afdbe65110393771e6eff571491444a910ab.pdf": "jang2024pyi",
    "4b02a48d5204d2e81794776a68d255d69f6e421e.pdf": "su2024h1g",
    "7d0216a7331ee4031fe488c8ff1da2adfcc59a0c.pdf": "li20246zp",
    "205770123d5779da5470ae58cf446bc3e9cfc195.pdf": "lupu20249p4",
    "88c8e710567d9e4d365944cf239bd304638a5a46.pdf": "briscik2024cpd",
    "b237deb6c0234378238a6ee49b229b1299b7efe6.pdf": "sun2024kbv",
    "bfb22a7d0f64625b897ebfe3a3f7498d5c71cbb1.pdf": "eghbali2024huh",
    "e582dccc95d150d4fca3f2e40e3b67850451ad35.pdf": "zhu2024ok7",
    "dfc50bea60deca4a10216f1b2482ac517c4dcc96.pdf": "long202400t",
    "b18efa8feb5e8024546e0abe6bafd58b928a413b.pdf": "gu20252u3",
    "684b36d780bda6e7c4a4c99aa03390466d476476.pdf": "zhang2024mf0",
    "3b32351004d1628329b875576323a7b1767e9e5a.pdf": "liu2024jz5",
    "bef33d15c3e8d433261f97f7001cc41a5ae0ec32.pdf": "ozkara2024nst",
    "7515c1ae5d78d4ddecbe380da3a9072ed0bdca01.pdf": "cui2024bov",
    "287b8037b0f75caec9fab471dd48fe0b81090f74.pdf": "wang2024so2",
    "b6efb87e4b609fb67304f73b8ee9c1984fce5e88.pdf": "ma2024vk4",
    "d8475d3f7ec9c656547985dffd4384fcb5670275.pdf": "amorim20240xf",
    "e5ff671a38bc7b115afc23a845a8e742c9529f3f.pdf": "shen2024hea",
    "c253896381b6763981e83dc67a726b6e5e1b6d8f.pdf": "ferrini20249g0",
    "7efbdc4a651244d139708f7a5d4552562bdb351c.pdf": "wang2024tpb",
    "644f33e831824777acb91c53a2be642d530f3848.pdf": "song2024epb",
    "d9956c775c776c1e4fd7980cd091fab70a55f37d.pdf": "wang20245h1",
    "71c00beb70d83eab08f1cf6c32f48c112bd9bfdf.pdf": "tam2024a1h",
    "17d70bb09b3be0601e5cdc3debbe81b2338b86ab.pdf": "qiao2024l71",
    "dae9960c44810cf0b9dc64ac8919eb34c19f3913.pdf": "xing2024n9q",
    "272b071e05e960ef3adab2bc8a078fd165b268d5.pdf": "cheng2024mky",
    "b079b1a459758b86c82ac7415dbe3eecee8b02e8.pdf": "xia20246dc",
    "51fa4c6047b661e596d1943fb8c54d03a8c85099.pdf": "yang20243gt",
    "52f37e9bd84547db2ecefed420715f312827c398.pdf": "zhang2024ycr",
    "5b32284df29baf5201cb8b2313dc077465b15838.pdf": "raymond202441h",
    "27c71dc136246f9e8a9c985af441cd7426e810ab.pdf": "khalid2024pss",
    "5f72ae90072c4d0df0d4460e7818b6d5ee2cef00.pdf": "kumar2024he9",
    "4481108a93744c5ad282a4ac2fea7883913184bb.pdf": "kukanov20249bs",
    "5042c452912818d012274e9754a2c45cf203691d.pdf": "chen20245h8",
    "588c69df5e7920db0037db76c41f933ee16c290d.pdf": "liu2024az5",
    "fb0749b9bc04914e294f57c89199572e3cb5183c.pdf": "xu2024mf9",
    "97718bcc9174ee43faf6ee4c105654a5ce7b35b1.pdf": "chen2024b4d",
    "21f5dba5b14c4d78bd869e2a05b4bb9f74db2157.pdf": "wen2024xmk",
    "7527e22accc5796290b4fe1b259c406b44a0b220.pdf": "liao2024jm9",
    "c9b0ddbe27193d10f800943d91450b44324e6d57.pdf": "meng2024nqq",
    "8a44b6276a4c7375e21072e6a300d83fac3ffcf0.pdf": "wu2024v0z",
    "ca48013d99a608e800ae34388fe9fba9ea6ca280.pdf": "farrell2024mpy",
    "e1a8bf47ef1c51298f5bcf957062c6ee63a96bfb.pdf": "ma20243e9",
    "e3de80376d111cf6d282294d7c16023ec1eb2386.pdf": "gven2024a3n",
    "a962dc06a19c08bb76184bde864e7f1e2e502150.pdf": "wang2024bhk",
    "b82a9500246176a6b32598ded8d2b96d1e29f61c.pdf": "pu2024m1b"
  },
  "sections": {
    "Introduction to Deep Meta-Learning": "\\section{Introduction to Deep Meta-Learning}\n\\label{sec:introduction_to_deep_meta-learning}\n\n\n\n\\subsection{Defining Deep Meta-Learning: Learning to Learn}\n\\label{sec:1_1_defining_deep_meta-learning:_learning_to_learn}\n\n\nDeep meta-learning represents a transformative paradigm designed to overcome fundamental limitations inherent in conventional deep learning, particularly its pronounced reliance on vast quantities of task-specific data and its struggles with robust generalization to novel, unseen tasks. At its core, meta-learning, frequently encapsulated by the phrase \"learning to learn,\" is the sophisticated process of acquiring an inductive bias or an explicit algorithm that empowers a base model to rapidly assimilate new skills or adapt to novel tasks with minimal data \\cite{hospedales2020m37, son2023lda}. This approach directly confronts scenarios where traditional deep learning models, after being trained on a fixed dataset, often exhibit poor performance when confronted with new data distributions or task specifications, highlighting a critical gap in their adaptive intelligence \\cite{hospedales2020m37}.\n\nThe operational framework of deep meta-learning is systematically structured into two distinct and sequential phases: meta-training and meta-testing. During the **meta-training phase**, the meta-learner is exposed to a diverse distribution of related tasks. The primary objective here is not to achieve optimal performance on any single task, but rather to learn a transferable skill or a generalizable strategy for efficient learning across these tasks. This learned strategy might manifest as an effective initialization for model parameters, an adaptive update rule, or a robust mechanism for feature extraction. Subsequently, in the **meta-testing phase**, these acquired adaptive capabilities are deployed for rapid adaptation to truly novel tasks, often with only a handful of labeled examples—a scenario commonly referred to as few-shot learning. The efficacy of meta-learning is critically assessed by how swiftly and effectively the meta-learner can adapt to these new, unseen tasks, thereby demonstrating its acquired \"learning to learn\" proficiency \\cite{hospedales2020m37, son2023lda}.\n\nThe \"inductive bias\" or \"explicit algorithm\" learned by the meta-learner is crucial for this rapid adaptation. In this context, an inductive bias refers to the set of assumptions or preferences that a learning algorithm uses to generalize from limited training data. For meta-learning, this bias is itself learned from experience across multiple tasks. It can take various forms: a set of initial parameters that are optimally poised for fine-tuning on new tasks, a learned optimization procedure that dictates how a base model's parameters should be updated, a sophisticated metric function for comparing data points in an embedding space, or even an architectural design that incorporates external memory mechanisms for efficient information storage and retrieval \\cite{hospedales2020m37}. This concept builds upon earlier ideas in machine learning, where the goal was to automatically find good choices for \"meta-parameters\" (e.g., learning rates, initial weights) that govern a base learning system, as highlighted by the historical development of \"meta-gradient\" methods \\cite{sutton2022jss}. The essence is to generalize the *learning process itself*, rather than just the solution to a specific task.\n\nThe \"deep\" aspect of deep meta-learning signifies the integration of these meta-learning principles with powerful deep neural network architectures. Deep learning provides the robust representation learning capabilities necessary to extract meaningful, high-level features from complex, high-dimensional data. This synergy allows meta-learners to operate effectively on raw inputs, such as images, text, or sensor data, enabling the \"learning to learn\" process to be applied to real-world, intricate problems. By leveraging deep neural networks, meta-learning can discover more sophisticated and flexible inductive biases, making the adaptive process more powerful and scalable than traditional meta-learning approaches \\cite{hospedales2020m37}.\n\nTo illustrate this framework, consider a canonical example: N-way, K-shot classification. In this setting, the meta-learner is trained to classify N novel classes, given only K examples per class. During meta-training, the system is presented with numerous distinct N-way, K-shot tasks, each drawn from a distribution of related classification problems (e.g., classifying different sets of N animal species with K images each). The meta-learner learns a strategy that allows it to quickly adapt to these varying tasks. Subsequently, during meta-testing, the system is confronted with a *completely new* N-way, K-shot task involving N *unseen* classes (e.g., classifying N entirely new animal species with K examples). Its success is measured by how effectively and rapidly it can classify instances from these novel classes, demonstrating its ability to generalize the *learning process* rather than merely memorizing class-specific features.\n\nIn conclusion, deep meta-learning fundamentally redefines how AI systems acquire knowledge, shifting from a narrow, task-specific learning paradigm to a more generalizable process of \"learning to learn.\" This core principle, instantiated through the distinct meta-training and meta-testing phases, has proven instrumental in addressing the critical data efficiency and generalization challenges that often plague conventional deep learning. This paradigm is realized through diverse methodological families—optimization-based, metric-based, and model-based approaches—which will be systematically explored in the subsequent sections, alongside their applications and challenges.\n\\subsection{Historical Context and Evolution of the Field}\n\\label{sec:1_2_historical_context__and__evolution_of_the_field}\n\n\nThe intellectual lineage of meta-learning, often encapsulated as \"learning to learn,\" reflects a persistent ambition in artificial intelligence: to create systems capable of rapid adaptation and robust generalization, akin to human cognitive flexibility. This pursuit has unfolded through distinct intellectual phases, from early theoretical explorations to its contemporary prominence, profoundly shaped by the advent and integration of powerful deep neural network architectures \\cite{hospedales2020m37, peng20209of}.\n\nThe foundational concepts of meta-learning emerged well before the deep learning era, driven by the desire to automate and optimize the learning process itself. In the 1980s and 1990s, researchers explored ideas such as hyperparameter optimization and the notion of \"learning optimizers.\" A significant conceptual precursor involved meta-gradient methods, pioneered by Schmidhuber and colleagues, which aimed to learn internal learning rates or even entire optimization algorithms through gradient descent on the learning process \\cite{sutton2022jss}. These early efforts, though often constrained by computational limitations and the expressiveness of available models, established the crucial principle: that a system could acquire an inductive bias or an explicit algorithm to enhance its future learning efficiency. Concurrently, influences from cognitive science, such as the Baldwin effect, provided a biological analogy, suggesting how individual learning could shape the evolution of innate learning biases across generations \\cite{fernando2018lt5}. This period laid the theoretical groundwork, emphasizing the potential for higher-order learning to improve base-level task acquisition, even if practical implementations were nascent.\n\nThe mid-2010s marked a dramatic resurgence and acceleration of meta-learning research, primarily catalyzed by the transformative power of deep learning. Deep neural networks provided the scalable and expressive function approximators necessary to realize complex meta-learning concepts that were previously computationally intractable \\cite{hospedales2020m37}. This period witnessed a \"Cambrian explosion\" of diverse meta-learning paradigms, each offering a distinct philosophical approach to the \"learning to learn\" challenge.\n\nOne early intellectual shift focused on endowing neural networks with explicit memory, addressing the need for models to quickly store and retrieve task-specific information for one-shot learning. This led to the development of model-based approaches, exemplified by Memory-Augmented Neural Networks (MANN) \\cite{Santoro2016}. The motivation here was to move beyond implicit parameter adaptation to architectures that could intrinsically adapt by processing and recalling relevant contextual data, a concept further explored in Section 4.2.\n\nParallel to this, the metric-based meta-learning paradigm gained traction, driven by the challenge of few-shot classification where models must generalize from minimal examples. The core intellectual contribution was the realization that learning a robust, transferable similarity function within an embedding space could enable effective comparison and classification of novel instances. This philosophy was embodied by seminal works such as Matching Networks \\cite{Vinyals2016}, Prototypical Networks \\cite{Snell2017}, and Relation Networks \\cite{sung2017nc5}. These approaches collectively demonstrated the power of learning discriminative feature spaces that facilitate rapid generalization by measuring relationships between examples, as further detailed in Section 4.1. The strength of these methods lay in their intuitive geometric interpretation and relative simplicity for specific tasks, but they often lacked the dynamic adaptability required for more complex, sequential learning scenarios.\n\nPerhaps the most impactful intellectual shift for the field's contemporary trajectory was the widespread adoption of gradient-based meta-learning. This paradigm directly built upon the early meta-gradient ideas, now leveraging the full differentiability of deep neural networks to optimize the *process* of learning itself \\cite{sutton2022jss}. The central insight was to reframe meta-learning as finding an optimal initialization or an efficient update rule that would enable a base model to rapidly adapt to new tasks with minimal gradient steps. Model-Agnostic Meta-Learning (MAML) \\cite{Finn2017} was a pivotal contribution, demonstrating how to learn an initial set of parameters that are highly amenable to rapid fine-tuning across a distribution of tasks. MAML's model-agnostic nature and its broad applicability across various deep learning architectures made it a cornerstone, fundamentally changing how researchers approached meta-learning by framing it within a bilevel optimization framework \\cite{franceschi2018u1q}. This success spurred further research into explicitly \"learning the optimizer,\" with approaches like Meta-Learner LSTMs \\cite{Ravi2017} and Meta-SGD \\cite{Li2017} aiming to meta-learn more flexible and adaptive update rules (discussed in Section 3.2). Concurrently, theoretical understanding of these methods deepened, with work exploring generalization bounds for MAML, offering insights into *why* these algorithms perform effectively in few-shot settings \\cite{chen2021j5t}.\n\nBeyond these core paradigms, the field continued to diversify. The integration of meta-learning with deep reinforcement learning (Meta-RL) addressed the notorious sample inefficiency and generalization challenges in dynamic environments, enabling agents to rapidly acquire new skills \\cite{wang20167px}. This extension, explored in Section 5.1, highlighted meta-learning's capacity to learn transferable behaviors. More recently, probabilistic meta-learning, exemplified by Conditional Neural Processes (CNP) \\cite{Garnelo2018}, emerged to model distributions over functions and quantify uncertainty, offering robust decision-making capabilities crucial for real-world applications (further discussed in Sections 4.3 and 5.2). The expanding scope of \"learning to learn\" also saw meta-learning applied to fundamental components like loss functions \\cite{raymond202441h}.\n\nIn summary, the evolution of meta-learning has been a dynamic interplay of ambitious theoretical concepts and the enabling power of deep learning. From early, computationally limited attempts to optimize learning processes to the sophisticated, deep neural network-driven paradigms of today, the field has consistently pushed the boundaries of generalization and adaptation. This progression, marked by distinct intellectual shifts towards memory-augmented, metric-based, and especially gradient-based approaches, has transformed meta-learning into a powerful framework for tackling data scarcity, non-stationarity, and complex decision-making, thereby setting a robust stage for understanding its current trajectory and future potential.\n",
    "Foundational Concepts and Problem Settings": "\\section{Foundational Concepts and Problem Settings}\n\\label{sec:foundational_concepts__and__problem_settings}\n\n\n\n\\subsection{Few-Shot Learning: The Prototypical Challenge}\n\\label{sec:2_1_few-shot_learning:_the_prototypical_challenge}\n\n\nFew-shot learning (FSL) represents a quintessential and pervasive challenge for deep learning, demanding that models generalize effectively to novel classes or tasks when presented with only a handful of labeled examples \\cite{huisman2020b7w, hospedales2020m37}. This scenario directly confronts the data-hungry nature of conventional deep learning models, which typically require vast amounts of annotated data to achieve robust performance. The prevalence of FSL is not merely an academic concern but a critical reality in numerous real-world applications where data annotation is prohibitively expensive, new categories emerge frequently, or data privacy concerns limit large-scale collection. Illustrative examples span diverse domains, including the medical diagnosis of rare diseases where labeled instances are inherently scarce, identifying emerging cyber threats like zero-day malware with minimal prior examples \\cite{li20246zp}, or enabling robotic systems to acquire complex new skills from a single visual demonstration \\cite{finn20174c4}. The inherent scarcity of data in such contexts establishes FSL as a primary driver for the development of meta-learning research.\n\nFormally, a few-shot learning task is typically defined within an N-way K-shot classification paradigm \\cite{son2023lda}. In this setup, a model is presented with a \"support set\" ($S$) containing $N$ novel classes, with $K$ labeled examples for each class. The goal is then to accurately classify instances in a \"query set\" ($Q$), which consists of unlabeled examples from these same $N$ novel classes. The meta-learning framework addresses this by employing an \"episodic training\" strategy. During the meta-training phase, the meta-learner is exposed to a large number of distinct FSL tasks, sampled from a distribution of related \"base\" tasks. Each meta-training episode simulates a few-shot scenario, allowing the model to learn how to rapidly adapt. In the subsequent meta-testing phase, the meta-learner is evaluated on truly novel tasks, drawn from a different set of classes unseen during meta-training, assessing its ability to quickly generalize with only the few examples provided in the support set of each new task \\cite{son2023lda}.\n\nMeta-learning offers a powerful framework to overcome the fundamental data scarcity inherent in FSL by leveraging prior experience from a distribution of related tasks \\cite{huisman2020b7w}. Instead of learning a single task from scratch, a meta-learner acquires an inductive bias or an explicit adaptation strategy that enables it to quickly form robust representations or adaptation rules for novel tasks. This \"learning to learn\" paradigm is crucial because traditional deep learning models, when faced with only a few examples, are highly susceptible to overfitting or simply failing to learn any meaningful features. Meta-learning mitigates this by training a model to become an efficient learner itself, rather than just a task-specific performer. These meta-learning strategies broadly fall into distinct categories, such as optimization-based, metric-based, and model-based approaches, which will be explored in detail in Sections 3 and 4.\n\nDespite the promise of meta-learning, FSL presents several persistent challenges that continue to drive research. One significant hurdle is the problem of generalization across diverse tasks, particularly when there are shifts in the underlying data distribution. For instance, cross-domain few-shot learning, where new tasks originate from domains unseen during meta-training, poses a formidable challenge to existing meta-learning methods, often leading to vulnerable generalization \\cite{tian2023iyh}. Furthermore, the fundamental generalization capabilities of meta-learning algorithms themselves are under scrutiny, with studies highlighting issues of underfitting or overfitting depending on task complexity, revealing a gap between theoretical expectations and practical performance \\cite{wang2024bhk}. Within metric-based FSL, which relies on learned embedding spaces, the \"hubness problem\" can arise, where certain class prototypes become the nearest neighbor for many test instances regardless of their true class, hindering classification accuracy \\cite{fei20211x6}. Addressing these challenges necessitates stronger theoretical guarantees for generalization, moving beyond empirical observations to provide a deeper understanding of why and when meta-learning succeeds in data-scarce scenarios \\cite{chen2021j5t}.\n\nThe principles of few-shot learning extend beyond supervised classification, serving as a critical driver for meta-learning research in other domains where rapid adaptation from limited experience is vital. In reinforcement learning, for example, the challenge of learning new policies with minimal interactions—often termed few-shot reinforcement learning—has led to seminal works exploring how agents can implicitly learn an RL algorithm \\cite{wang20167px} or acquire new skills from a single demonstration in one-shot visual imitation learning \\cite{finn20174c4}. The practical impact of FSL is also evident in diverse real-world applications, such as robust and interpretable EMG-based hand gesture recognition \\cite{tam2024a1h} and few-shot Android malware classification \\cite{li20246zp}, where the combination of data scarcity and the imperative for rapid adaptation makes FSL a central problem.\n\nIn conclusion, few-shot learning remains a cornerstone challenge that fundamentally shapes and propels innovation in meta-learning. It highlights the limitations of traditional deep learning in data-scarce environments and underscores the necessity for models that can \"learn to learn.\" While meta-learning provides a powerful conceptual and algorithmic framework, ongoing research continues to address critical issues such as improving robustness to domain shifts, mitigating underfitting and overfitting across heterogeneous tasks, and developing more unified theoretical understandings to ensure reliable and efficient generalization in the face of limited data.\n\\subsection{Meta-Reinforcement Learning: Adapting in Dynamic Environments}\n\\label{sec:2_2_meta-reinforcement_learning:_adapting_in_dynamic_environments}\n\n\nMeta-Reinforcement Learning (Meta-RL) represents a critical extension of meta-learning principles to the domain of reinforcement learning (RL), addressing fundamental limitations of traditional RL in dynamic and diverse environments. At its core, Meta-RL aims to enable an agent to \"learn to learn\" new behaviors, allowing it to rapidly adapt its policy to novel, unseen tasks within a family of related tasks \\cite{beck2023x24}. This paradigm is crucial for developing intelligent agents that can operate effectively in complex, real-world scenarios characterized by evolving objectives, changing dynamics, and sparse rewards, where learning from scratch for each new task is prohibitively inefficient.\n\nThe foundational problem setting for Meta-RL involves a distribution over Markov Decision Processes (MDPs), denoted as $p(\\mathcal{M})$. Each task $\\mathcal{T}_i$ is an instance of an MDP $\\mathcal{M}_i = (\\mathcal{S}, \\mathcal{A}, \\mathcal{P}_i, \\mathcal{R}_i, \\gamma)$, where $\\mathcal{S}$ is the state space, $\\mathcal{A}$ is the action space, $\\mathcal{P}_i$ is the task-specific transition function, $\\mathcal{R}_i$ is the task-specific reward function, and $\\gamma$ is the discount factor. The objective of a meta-RL agent is to learn an adaptation procedure or a meta-policy that, after observing a small amount of interaction data (e.g., a few trajectories) from a *new*, unseen task $\\mathcal{M}_{\\text{new}} \\sim p(\\mathcal{M})$, can quickly infer the task's specifics and derive an effective policy for it \\cite{beck2023x24}. This process typically involves a meta-training phase, where the agent learns its adaptive capabilities across a diverse set of tasks from $p(\\mathcal{M})$, and a meta-testing phase, where these learned abilities are deployed for fast adaptation to truly novel tasks.\n\nMeta-RL directly confronts several notorious challenges in traditional RL. Firstly, **sample efficiency** is a primary concern. Standard deep RL algorithms often require millions of environmental interactions to learn a single task, making them impractical for real-world deployment where data collection is costly or time-consuming. By leveraging prior experience from a distribution of related tasks, Meta-RL aims to drastically reduce the amount of new data needed for effective learning on a novel task. Secondly, **generalization** is enhanced. Policies learned for one specific task often fail to generalize to even slightly different tasks. Meta-RL fosters the acquisition of transferable skills or meta-knowledge that allows agents to generalize their learning process, rather than just their policy, across a spectrum of tasks. This means the agent learns *how* to learn, rather than just *what* to do.\n\nThe mechanisms through which meta-learning facilitates this rapid adaptation in RL are diverse, but they generally fall into categories that aim to either learn an efficient adaptation process or infer task-specific context. For instance, some approaches focus on learning an effective *initialization* for a policy that can be quickly fine-tuned with a few gradient steps on a new task. Others aim to learn *contextual representations* of tasks, where an encoder processes initial experience to infer latent variables that characterize the current task, which then guide the policy. A third category involves learning *implicit learning algorithms* through recurrent architectures, where the network's internal state acts as a memory of past interactions, allowing it to adapt its behavior over time within a single episode \\cite{finn2017vrt, wang20167px}. These high-level strategies enable agents to quickly infer task dynamics, reward functions, or optimal behaviors from minimal interaction, thereby accelerating learning and improving robustness.\n\nA critical aspect of Meta-RL is the challenge of **efficient exploration** in new, unknown tasks. When an agent encounters a novel MDP, it must explore to gather information about its dynamics and rewards before it can exploit optimal actions. Meta-RL approaches often incorporate mechanisms for Bayes-adaptive exploration, where the agent actively seeks to reduce its uncertainty about the current task's identity, leading to more structured and efficient data collection \\cite{zintgraf2019zat, rakelly2019m09}. This is particularly vital in environments with sparse rewards, where random exploration is unlikely to yield meaningful learning signals. Furthermore, the problem of learning from static, **offline datasets** introduces additional complexities, such as \"MDP ambiguity,\" where the available data may not be sufficient to distinguish between different underlying tasks, posing significant challenges for learning effective meta-exploration strategies \\cite{dorfman2020mgv}.\n\nIn summary, Meta-RL is a powerful paradigm for developing agents that are not only proficient at specific tasks but also possess the meta-skill to rapidly acquire new capabilities. By addressing the core challenges of sample efficiency, generalization, and efficient exploration within dynamic and uncertain environments, Meta-RL paves the way for more robust, autonomous, and adaptable AI systems capable of operating in complex real-world scenarios. The subsequent sections will delve into the specific methodologies that realize these adaptive capabilities, categorizing them by their underlying principles.\n\\subsection{Core Paradigms: Optimization, Metric, and Model-Based Approaches}\n\\label{sec:2_3_core_paradigms:_optimization,_metric,__and__model-based_approaches}\n\n\nDeep meta-learning methodologies are broadly categorized into three fundamental paradigms: optimization-based, metric-based, and model-based approaches \\cite{hospedales2020m37}. Each paradigm offers a distinct conceptual framework and set of mechanisms to enable models to \"learn to learn,\" addressing the challenge of rapid adaptation and generalization to novel tasks with limited data. This section provides a high-level overview of these core paradigms, highlighting their fundamental differences and inherent strengths, thereby setting the stage for their detailed exploration in subsequent sections.\n\n**Optimization-based meta-learning** focuses on learning effective initializations or update rules that enable a base model to quickly adapt to new tasks through a few gradient steps. The core idea is to train a meta-learner to produce parameters or an optimization strategy that is highly amenable to rapid fine-tuning on unseen tasks \\cite{sutton2022jss}. This often involves a bi-level optimization process, where an inner loop performs task-specific adaptation, and an outer loop optimizes the meta-parameters (e.g., initial weights) across a distribution of tasks. The seminal Model-Agnostic Meta-Learning (MAML) \\cite{Finn2017} exemplifies this by seeking an initial parameter set that can be quickly adapted to any new task using standard gradient descent. While MAML offers broad applicability due to its model-agnostic nature, it often entails computational challenges related to second-order gradients and can be sensitive to hyperparameter choices. Subsequent research has explored learning the optimizer itself, such as with Meta-Learner LSTMs \\cite{Ravi2017} and Meta-SGD \\cite{Li2017}, which learn explicit update rules or adaptive learning rates. More advanced techniques, like HyperMAML \\cite{przewiezlikowski2022d4y}, replace gradient-based inner loops with learned hypernetworks to generate weight updates, offering more flexible and efficient adaptation. Theoretical analyses, such as those exploring generalization bounds \\cite{chen2021j5t} or the surprising role of negative learning rates in meta-training \\cite{bernacchia20211r0}, continue to refine our understanding of this paradigm's mechanics and limitations. Optimization-based methods are powerful for their generality and ability to adapt complex deep learning models, but their effectiveness can be constrained by computational cost and the stability of the meta-optimization process.\n\n**Metric-based meta-learning** operates on the principle of learning robust similarity functions within embedding spaces. The goal is to transform raw input data into a feature space where examples from the same class are close together, and examples from different classes are far apart, regardless of whether these classes were seen during meta-training. This allows for efficient comparison and classification of novel examples with limited support data, typically through nearest-neighbor-like mechanisms. These methods learn an embedding network that maps inputs into a feature space where distances directly correspond to semantic similarity. Early approaches like Matching Networks \\cite{Vinyals2016} introduced attention mechanisms to dynamically weigh support examples, while Prototypical Networks \\cite{Snell2017} simplified this by representing each class with a single centroid (prototype) in the embedding space. A significant conceptual leap was made by Relation Networks \\cite{sung2017nc5}, which meta-learned a deep, non-linear 'relation function' to explicitly compute similarity scores between embedded query and support examples, moving beyond fixed distance metrics. The strength of metric-based approaches lies in their intuitive nature, interpretability (due to explicit comparisons), and efficiency for few-shot classification tasks. However, their applicability is often limited to tasks that can be effectively framed as similarity comparisons in a learned feature space, and their generalization capabilities can be sensitive to the quality and diversity of the learned embedding.\n\n**Model-based meta-learning** is distinguished by designing network architectures with intrinsic adaptation capabilities. Instead of learning an optimization process or a similarity function, these models are engineered to quickly integrate new task information directly into their internal state or memory, often without explicit gradient updates during adaptation. This paradigm seeks to build \"fast weights\" or memory mechanisms that can rapidly store and retrieve task-specific knowledge. Pioneering work in this area includes Memory-Augmented Neural Networks (MANN) \\cite{Santoro2016}, which leverage external memory modules (inspired by Neural Turing Machines) to store and retrieve task-relevant information for one-shot learning. Architectures like A Simple Neural Attentive Meta-Learner (SNAIL) \\cite{Mishra2018} further combine temporal convolutions and attention to process sequences of experience, enabling fast in-context learning. A distinct and powerful sub-area within model-based approaches is Neural Processes, beginning with Conditional Neural Processes (CNP) \\cite{Garnelo2018}. These models learn to map context sets to distributions over functions, providing not only predictions but also crucial uncertainty estimates, which is vital for robust decision-making. Model-based methods excel at complex sequential decision-making tasks and scenarios requiring explicit memory or uncertainty quantification. Their primary challenge often lies in the increased architectural complexity and the difficulty of designing general-purpose adaptive mechanisms that perform well across highly diverse task distributions.\n\nIn summary, these three paradigms offer distinct yet complementary strategies for tackling the 'learning to learn' challenge. Optimization-based methods provide broad applicability by learning how to adapt parameters, but can be computationally intensive and sensitive to meta-optimization dynamics. Metric-based approaches offer efficient few-shot classification by learning robust similarity measures, though their applicability is often constrained to comparison-based tasks. Model-based methods push towards more sophisticated in-context learning and probabilistic function approximation through architectural innovations, offering powerful adaptation but often at the cost of increased architectural complexity and dependence on specific designs. The ongoing research across these paradigms continues to explore the trade-offs between generalizability, computational efficiency, and the ability to provide meaningful uncertainty estimates across diverse and complex real-world tasks.\n",
    "Optimization-Based Meta-Learning": "\\section{Optimization-Based Meta-Learning}\n\\label{sec:optimization-based_meta-learning}\n\n\n\n\\subsection{Learning a Good Initialization: MAML and its Variants}\n\\label{sec:3_1_learning_a_good_initialization:_maml__and__its_variants}\n\n\nA fundamental challenge in few-shot learning is to enable models to rapidly adapt to new tasks with minimal labeled data. Optimization-based meta-learning addresses this by learning an effective initial set of model parameters that can be quickly fine-tuned for novel tasks.\n\nThe seminal work in this area is Model-Agnostic Meta-Learning (MAML) \\cite{Finn et al., 2017}, which proposes training a model's initial parameters such that a few gradient steps on a new task lead to significant performance improvement. MAML operates on a bi-level optimization structure: an inner loop performs task-specific adaptation by taking a few gradient steps on a support set, yielding adapted parameters. The outer loop then optimizes the initial parameters by evaluating the performance of these adapted parameters on a query set, using second-order gradients. This approach is inherently model-agnostic, meaning it can be applied to any model trained with gradient descent, making it broadly applicable across various deep learning architectures and tasks. While powerful for learning transferable knowledge, MAML's reliance on second-order derivatives can lead to substantial computational overhead and memory consumption, especially for large models, and it can be sensitive to hyperparameter choices.\n\nTo mitigate the computational burden associated with MAML's higher-order gradients, Reptile \\cite{Nichol2018} was introduced as a computationally more efficient first-order approximation. Reptile simplifies the meta-learning process by repeatedly training on a task for several gradient steps and then moving the meta-parameters (the initial parameters) towards the task-specific parameters obtained after adaptation. This update rule, $\\theta \\leftarrow \\theta + \\epsilon (\\phi - \\theta)$ where $\\phi$ are the task-adapted parameters, effectively approximates the MAML objective without explicitly computing second-order derivatives. This simplification significantly reduces the computational cost and memory footprint, allowing for greater scalability while maintaining competitive performance in many few-shot learning scenarios.\n\nFurther improving generalization and efficiency, particularly for complex models, is the Latent Embedding Optimization (LEO) framework \\cite{Rusu et al., 2018}. LEO builds upon the optimization-based paradigm by learning a low-dimensional latent embedding for the model parameters. Instead of optimizing directly in the high-dimensional parameter space, LEO performs the inner-loop adaptation (task-specific fine-tuning) within this more compact and efficient latent space. The adapted latent parameters are then decoded back to the original parameter space for inference. This strategy enhances robustness and scalability by operating in a learned, more meaningful representation, which can lead to better generalization and faster adaptation compared to direct optimization in the full parameter space.\n\nThe model-agnostic nature of MAML has enabled its application across diverse domains, demonstrating its practical utility. For instance, in few-shot Hyperspectral Image (HSI) classification, MAML, combined with regularized fine-tuning, has been successfully employed to overcome the challenge of limited labeled samples and facilitate effective cross-domain transfer learning \\cite{li2023fhe}. This application showcases MAML's ability to learn robust initializations that enable accurate classification even when only a handful of labeled examples are available for new HSI datasets, achieving high overall accuracy.\n\nIn conclusion, MAML and its variants represent a powerful paradigm within meta-learning, focusing on learning transferable initializations that enable rapid adaptation. While MAML laid the foundational groundwork with its bi-level optimization and model-agnosticism, its computational demands spurred the development of more efficient approximations like Reptile and advanced techniques like LEO, which optimize in learned latent spaces for improved generalization and efficiency. Despite these advancements, challenges persist in balancing computational cost, hyperparameter sensitivity, and ensuring robust generalization across highly diverse task distributions, pointing towards continued research in developing more robust and theoretically grounded optimization-based meta-learning algorithms.\n\\subsection{Learning the Optimizer: Meta-Learner LSTMs and Meta-SGD}\n\\label{sec:3_2_learning_the_optimizer:_meta-learner_lstms__and__meta-sgd}\n\n\nTranscending the paradigm of merely learning an effective initialization, a significant branch of meta-learning research focuses on explicitly learning the optimization process itself. This advanced approach frames meta-learning as the challenge of discovering an adaptive, data-driven optimization algorithm, offering greater flexibility and control over the learning process compared to relying on fixed, hand-designed optimizers. This subsection delves into two prominent methodologies within this domain: Meta-Learner LSTMs and Meta-SGD, which exemplify the quest to meta-learn the dynamics of parameter updates.\n\nOne pioneering approach in this direction is the Meta-Learner LSTM, introduced by \\cite{Ravi2017}. This method employs a recurrent neural network, specifically an LSTM, as the meta-learner to generate parameter updates for a base learner. The LSTM takes the base learner's gradients and previous internal states as input, and subsequently outputs the updates for each parameter, effectively learning a complex, stateful optimization algorithm. This allows the meta-learner to capture intricate dependencies and historical information during the inner-loop adaptation, moving beyond simple gradient descent to learn highly non-linear and context-dependent update rules. However, the inherent complexity of training such a meta-learner, which involves backpropagating through the unrolled optimization steps of the base learner, presents significant computational challenges and can lead to issues with training stability.\n\nBuilding upon the principles of gradient-based meta-learning, \\cite{Li2017} proposed Meta-SGD, an approach that extends the meta-learning objective to encompass more components of the optimization process. Unlike methods that primarily focus on learning a good initialization, Meta-SGD meta-learns not only initial parameters but also per-parameter learning rates and update directions for the inner-loop adaptation. This means that for each parameter of the base learner, the meta-learner learns how to scale and direct its gradient update, effectively transforming the standard gradient descent rule into a more adaptive, learned optimizer. By learning these fine-grained components, Meta-SGD provides a powerful mechanism for the base learner to adapt rapidly and efficiently to new tasks with only a few gradient steps, offering a more flexible and data-driven adaptation strategy than fixed learning rates.\n\nBoth Meta-Learner LSTMs and Meta-SGD represent a crucial shift in meta-learning, moving from static initializations to dynamic, learned optimization procedures. While \\cite{Ravi2017}'s Meta-Learner LSTM offers a highly flexible, black-box approach to learning an optimizer through its recurrent structure, it comes with the overhead of training a complex sequential model to generate updates. In contrast, \\cite{Li2017}'s Meta-SGD provides a more structured, yet equally adaptive, approach by directly learning the components of the gradient update rule, such as per-parameter learning rates and update directions. Both methods aim to imbue the base learner with the ability to \"learn how to learn\" by discovering an adaptive optimization algorithm from data, rather than relying on predefined heuristics.\n\nDespite their significant contributions to enabling more flexible and powerful adaptation, these sophisticated techniques introduce their own set of challenges. The increased complexity of the meta-learner and the meta-optimization objective can lead to higher computational demands and difficulties in ensuring stable and efficient training. Furthermore, the generalization capabilities of these learned optimizers to tasks significantly different from those seen during meta-training remain an active area of research. Future work will likely explore more efficient architectures for meta-optimizers, hybrid approaches that combine the strengths of explicit optimization learning with other meta-learning paradigms, and methods to improve the robustness and scalability of these adaptive learning algorithms to even broader and more diverse task distributions.\n\\subsection{Differentiable Solvers and Hypernetworks for Parameter Adaptation}\n\\label{sec:3_3_differentiable_solvers__and__hypernetworks_for_parameter_adaptation}\n\n\nThe pursuit of highly flexible and rapid adaptation mechanisms in meta-learning has led to the exploration of advanced techniques that move beyond conventional gradient-based inner-loop optimization. This subsection delves into two prominent paradigms: leveraging differentiable closed-form solvers as base learners and employing hypernetworks to generate model parameters dynamically. These approaches enable meta-learners to optimize for rapid, interpretable adaptation tailored to specific problem structures, or to modulate entire network architectures based on task-specific information.\n\nOne significant direction involves integrating classical machine learning algorithms as differentiable components within a meta-learning framework. \\textcite{bertinetto2018ur2} pioneered this by proposing a meta-learning approach where the base learner is a differentiable closed-form solver, such as Ridge Regression. Their method meta-learns both a deep feature extractor and the hyperparameters of the base solver end-to-end, efficiently backpropagating through the solver's closed-form solution (e.g., using the Woodbury identity for speed) to enable rapid adaptation in few-shot classification tasks. This allows for data-dependent adaptation at test time, offering more flexibility than similarity-based methods while being computationally more efficient than gradient-based meta-learning for a few adaptation steps.\n\nBuilding upon the idea of meta-learning parameters for classical models, subsequent work has extended this to more complex scenarios. \\textcite{wistuba2021wha} introduced Few-Shot Bayesian Optimization (FSBO) by meta-learning deep kernel Gaussian Processes (GPs) as surrogate models for hyperparameter optimization. Here, the deep kernel parameters are learned across a distribution of tasks, allowing the classical GP model to rapidly adapt its predictions to new tasks with very few evaluations. Further refining this, \\textcite{chen2022z45} presented Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT) for molecular property prediction. This framework uses bilevel optimization to meta-learn feature extractor parameters while adapting base kernel parameters per task, leveraging the Implicit Function Theorem for exact hypergradient computation, thereby achieving a robust balance between generalization and task-specific adaptation for deep kernel GPs. In a related vein, \\textcite{lee2024snq} proposed Sequential Bayesian Meta-Continual Learning (SB-MCL), a biologically inspired framework that decouples deep representation learning from sequential knowledge integration. Here, neural networks are meta-learned to map complex data to a latent space suitable for simple statistical models, which then perform exact sequential Bayesian updates, effectively offloading continual learning to robust, forgetting-immune classical models.\n\nComplementing differentiable solvers, hypernetworks offer another powerful mechanism for flexible parameter adaptation. Instead of optimizing the parameters of a base learner, hypernetworks are neural networks that generate the weights or parameters of another 'main' network, conditioned on task-specific information. This provides a mechanism for dynamic architecture generation or flexible parameter modulation without explicit gradient-based inner loops. \\textcite{przewiezlikowski2022d4y} exemplify this with HyperMAML, which replaces MAML's gradient-based inner-loop adaptation with a trainable hypernetwork. The hypernetwork directly outputs weight updates for the base model based on support set embeddings and labels, enabling more substantial and flexible weight modifications in a single step, thereby offering a computationally efficient alternative to classical MAML.\n\nBeyond these direct applications, the broader theme of learning flexible adaptation mechanisms also encompasses biologically inspired approaches. \\textcite{lindsey202075a} explored Feedback and Local Plasticity (FLP), a meta-learning framework that learns biologically plausible local synaptic update rules and decoupled feedback weights for deep credit assignment. While not strictly a differentiable solver or hypernetwork, FLP meta-learns parameters (feedback weights, plasticity coefficients) that modulate the learning process itself, demonstrating how meta-learning can discover effective, local learning rules that excel in challenging scenarios like continual learning, often outperforming gradient-based meta-learners.\n\nIn summary, differentiable solvers and hypernetworks represent significant advancements in meta-learning, offering powerful alternatives to traditional gradient-based adaptation. Differentiable solvers provide interpretable and efficient adaptation by optimizing classical models, while hypernetworks enable dynamic parameter generation for flexible architectural and functional modulation. Biologically inspired approaches further expand this landscape by learning the very rules of adaptation. Despite these strides, challenges remain in scaling complex differentiable solvers to arbitrary models, ensuring the interpretability of hypernetwork-generated parameters, and fully understanding the theoretical underpinnings of learned, non-gradient-based adaptation rules. Future research may explore hybrid models that combine these strengths, or delve deeper into the biological plausibility and robustness of such learned adaptation mechanisms.\n",
    "Metric and Model-Based Meta-Learning": "\\section{Metric and Model-Based Meta-Learning}\n\\label{sec:metric__and__model-based_meta-learning}\n\n\n\n\\subsection{Learning Similarity Measures: Matching, Prototypical, and Relation Networks}\n\\label{sec:4_1_learning_similarity_measures:_matching,_prototypical,__and__relation_networks}\n\n\nA distinct family of meta-learning approaches addresses few-shot classification by focusing on learning robust similarity measures within a discriminative embedding space. These methods aim to classify novel instances by comparing them directly to a small set of labeled support examples, thereby enabling accurate generalization from minimal data.\n\nPioneering this direction, Matching Networks \\cite{Vinyals2016} introduced an end-to-end differentiable framework that learns to map a small labeled support set and an unlabeled query to a classification. This is achieved through an attention-based comparison function, where the network dynamically weighs the contribution of each support example to classify the new instance, effectively performing a non-parametric classification in a learned feature space. While innovative, the direct comparison to every support example can be computationally intensive as the support set size grows.\n\nBuilding upon this foundation, Prototypical Networks \\cite{Snell2017} simplified the similarity learning paradigm by proposing that each class in a learned embedding space can be represented by a single \"prototype.\" This prototype is typically computed as the mean of the embedded support examples for that class. Classification of a new query instance then involves assigning it to the class whose prototype is closest in the embedding space, often using Euclidean distance. This approach offers improved computational efficiency and enhanced interpretability compared to Matching Networks, as class representations are explicitly defined, and it demonstrated competitive performance in few-shot classification tasks.\n\nFurther generalizing the concept of similarity, Relation Networks \\cite{Sung2018} moved beyond fixed distance metrics or attention mechanisms by learning a non-linear \"relation function\" to explicitly compute similarity scores. This network takes the concatenated embeddings of a query example and a support example (or a class prototype) as input and outputs a scalar score indicating their similarity. By learning this relation function, the model gains greater flexibility in defining what constitutes \"similarity,\" allowing for more complex and adaptive comparisons between embedded instances. This approach often leads to more robust similarity measures, especially when simple distance metrics might be insufficient.\n\nThe core ideas of these metric-based approaches continue to be extended and applied to more complex few-shot scenarios. For instance, the principles of Prototypical Networks have been adapted to tackle challenging tasks like few-shot cross-domain object detection. The Instance-level Prototype learning Network (IPNet) \\cite{zhang2024mf0} addresses data deficiency in target domains by fusing cropped instances from both source and target domains to learn representative prototypes for each class. These learned prototypes are then utilized to discriminate feature salience and facilitate domain alignment, demonstrating the adaptability of prototype-based methods beyond simple image classification to more intricate problems involving object localization and domain generalization.\n\nIn summary, Matching, Prototypical, and Relation Networks collectively represent a powerful family of meta-learning techniques that excel in few-shot classification by learning discriminative feature spaces and robust similarity measures. Their effectiveness stems from their intuitive comparison mechanisms, allowing accurate generalization from minimal examples. However, their primary limitation often lies in their task-specificity, as they are predominantly designed for classification tasks and might struggle to generalize to problems requiring complex structural changes or where a simple distance metric or learned relation function is insufficient for capturing task-specific nuances beyond feature comparison. Future research may explore hybrid approaches that combine the strengths of metric learning with other meta-learning paradigms to enhance their applicability to a broader range of tasks.\n\\subsection{Memory-Augmented Neural Networks for In-Context Learning}\n\\label{sec:4_2_memory-augmented_neural_networks_for_in-context_learning}\n\n\nModel-based meta-learning approaches offer a distinct paradigm for achieving rapid, in-context adaptation by designing network architectures that intrinsically facilitate fast information integration and knowledge transfer. Unlike gradient-based methods that learn to optimize parameters or metric-based approaches that learn similarity functions, this category focuses on equipping neural networks with explicit mechanisms for storing and retrieving task-specific information, enabling one-shot learning without explicit gradient updates.\n\nA pioneering work in this domain is the Memory-Augmented Neural Network (MANN) proposed by \\cite{santoro2016323}. Inspired by Neural Turing Machines (NTMs), MANN augments a standard neural network with an external memory module, allowing the network to learn to store and retrieve task-relevant information through differentiable read and write operations. This architectural innovation enables the model to quickly adapt to new tasks by leveraging previously encountered experiences stored in its memory, effectively performing one-shot learning by recalling specific data points or features rather than re-optimizing its weights. The core contribution of MANN lies in demonstrating how an explicit memory component can mitigate catastrophic forgetting and facilitate rapid knowledge acquisition, allowing the network to learn an internal \"algorithm\" for fast information integration. However, the complexity of training such memory-augmented networks and the scalability of their memory access mechanisms can pose significant challenges, particularly for very large datasets or highly diverse tasks.\n\nBuilding upon the principles of in-context learning, the Simple Neural Attentive Meta-Learner (SNAIL) \\cite{mishra2018simple} offers an alternative architectural approach that integrates temporal convolutions and attention mechanisms. SNAIL processes sequences of experience (support set and query examples) through a combination of causal convolutions, which efficiently aggregate information from past steps in the sequence, and a task-specific attention mechanism, which allows the network to selectively focus on the most relevant information for the current prediction. This design enables SNAIL to learn an internal meta-learning algorithm that can rapidly adapt to new tasks by attending to and integrating information from the context set, all within a single forward pass without requiring explicit gradient updates during adaptation. By leveraging standard deep learning components like convolutions and attention, SNAIL provides a more streamlined and potentially more scalable architecture for in-context learning compared to the explicit memory controllers of MANN, while still achieving powerful meta-learning capabilities across various tasks.\n\nIn summary, memory-augmented and attention-based neural networks represent a powerful class of meta-learning models that achieve rapid, in-context adaptation through architectural design rather than explicit parameter optimization. While MANN \\cite{santoro2016323} introduced the foundational concept of external memory for one-shot learning, SNAIL \\cite{mishra2018simple} refined this idea by integrating temporal convolutions and attention for efficient sequential processing. These models excel at learning an intrinsic 'algorithm' for fast information integration, demonstrating how architectural innovation can intrinsically equip neural networks with powerful meta-learning capabilities. However, challenges remain in scaling these architectures to extremely complex tasks and ensuring efficient memory management or attention mechanisms without incurring prohibitive computational costs or architectural complexity. Future research may explore hybrid approaches that combine the strengths of these model-based methods with more efficient memory structures or integrate them with other meta-learning paradigms.\n\\subsection{Neural Processes: Probabilistic Function Approximation}\n\\label{sec:4_3_neural_processes:_probabilistic_function_approximation}\n\n\nWithin the landscape of model-based meta-learning, Neural Processes (NPs) represent a distinct and powerful paradigm focused on probabilistic function approximation, drawing inspiration from the robustness of Gaussian Processes (GPs) while aiming for the scalability and flexibility of deep neural networks. Unlike traditional deep learning methods that yield point estimates, NPs learn to map context sets to distributions over functions, thereby providing not only predictions but also crucial quantification of predictive uncertainty. This capability is paramount for robust decision-making, active learning, and scenarios where confidence in predictions is as important as the predictions themselves, moving beyond deterministic outputs to a deeper understanding of the underlying data-generating process. NPs achieve this by amortizing inference over a distribution of tasks, learning a general mechanism to infer function properties from limited data.\n\nThe foundational work in this area is the Conditional Neural Process (CNP) \\cite{Garnelo2018}. CNPs introduced the concept of learning a distribution over functions by modeling conditional independence between target points given a context set. Specifically, a CNP employs a permutation-invariant encoder to aggregate information from observed context points (input-output pairs) into a global representation. This representation then parameterizes a simple, often factorized, Gaussian distribution over the target points. This allows the model to meta-learn in both regression and classification tasks while providing explicit uncertainty estimates, a significant advancement over prior deterministic meta-learning approaches. However, the strong conditional independence assumption in CNPs can lead to over-smoothed predictions, as it struggles to capture complex dependencies and multi-modalities inherent in intricate function structures.\n\nTo address the limitations of CNPs regarding expressiveness and the inability to capture dependencies between target points, the original Neural Process (NP) was subsequently introduced \\cite{Garnelo2018b}. This variant, sometimes referred to as Latent Neural Process, relaxes the strict conditional independence assumption by incorporating a global latent variable. The NP architecture includes two paths: a deterministic path similar to CNP, and a latent path where the encoder outputs parameters for a global latent distribution (e.g., a Gaussian). A latent variable is sampled from this distribution, which, along with the deterministic context representation, then informs the parameters of the predictive distribution. This latent variable acts as a global summary of the function's properties, enabling the model to capture richer function spaces and model dependencies between target points, thus mitigating the over-smoothing observed in standard CNPs.\n\nA further significant advancement in this lineage is the Attentive Neural Process (ANP) \\cite{Kim2019}. ANPs integrate self-attention mechanisms into the Neural Process framework, allowing the model to selectively weigh the importance of different context points when forming its representation. By employing an attention mechanism, ANPs can focus on the most relevant information within the context set, leading to more accurate predictions and better-calibrated uncertainty estimates. This selective attention mechanism significantly enhances the model's performance and flexibility, effectively tackling the over-smoothing issue more comprehensively than its predecessors by capturing fine-grained dependencies and local variations in the function, particularly beneficial for tasks with heterogeneous data distributions.\n\nWhile CNP, NP, and ANP primarily focus on standard regression and classification, Generalized Conditional Neural Processes (GCNP) \\cite{Requeima2019} extend the NP paradigm to handle structured data, such as graphs or meshes. GCNPs achieve this by integrating graph neural networks (GNNs) into the encoder architecture, allowing the model to leverage the underlying relational structure of the data when forming its context representation. This specialized extension demonstrates the versatility of the NP framework, adapting it to domains where explicit spatial or relational inductive biases are crucial. Another notable extension, Convolutional Conditional Neural Processes (ConvCNPs) \\cite{Gordon2019}, further enhances NPs by incorporating convolutional layers, which introduce spatial inductive biases and enable desirable equivariance properties, proving effective for image-based tasks.\n\nThe unique contribution of Neural Processes to probabilistic meta-learning lies in their ability to provide well-calibrated uncertainty estimates alongside predictions. This allows for more informed generalization, enabling applications such as active learning, where the model can query points where its uncertainty is high, or risk-aware decision-making, where the confidence in a prediction directly influences subsequent actions. Despite their strengths, NPs still face challenges. The permutation-invariant aggregation mechanism, while flexible, can act as an information bottleneck, potentially losing crucial structural information present in the context set. Furthermore, scaling NPs to very high-dimensional inputs or extremely large context sets can be computationally intensive. A persistent challenge across all probabilistic deep learning models, including NPs, is ensuring perfect calibration of uncertainty across diverse and potentially out-of-distribution tasks. As highlighted in recent critiques of other probabilistic deep learning approaches like Evidential Deep Learning \\cite{shen2024hea}, the reliability and faithful quantification of epistemic uncertainty remain non-trivial, often requiring careful architectural design and training objectives to avoid overconfidence or underestimation. Future work will likely focus on improving their computational efficiency, enhancing their expressiveness for highly complex functions by addressing the aggregation bottleneck, developing more principled methods for choosing the latent variable dimensionality, and refining uncertainty calibration techniques to ensure robustness and trustworthiness in real-world applications.\n",
    "Advanced Meta-Learning for Complex Scenarios": "\\section{Advanced Meta-Learning for Complex Scenarios}\n\\label{sec:advanced_meta-learning_for_complex_scenarios}\n\n\n\n\\subsection{Meta-Reinforcement Learning and Imitation Learning}\n\\label{sec:5_1_meta-reinforcement_learning__and__imitation_learning}\n\nMeta-Reinforcement Learning (Meta-RL) and Meta-Imitation Learning (Meta-IL) represent a critical evolution in equipping agents with the ability to rapidly adapt to novel tasks and environments. These paradigms directly confront the notorious challenges of sample inefficiency and limited generalization inherent in traditional reinforcement learning (RL) and imitation learning (IL) by enabling agents to \"learn to learn\" across a distribution of related tasks \\cite{beck2023x24}. By acquiring a transferable skill or an efficient adaptation mechanism, meta-learning allows agents to quickly infer optimal behaviors, adapt to new reward functions, or acquire policies from minimal demonstrations, thereby accelerating learning and improving robustness in complex sequential decision-making scenarios.\n\nThe early trajectory of Meta-RL research explored implicit adaptation mechanisms, primarily leveraging Recurrent Neural Networks (RNNs). A seminal contribution by \\cite{wang20167px} demonstrated that an LSTM, when trained across a diverse set of tasks with past actions, rewards, and observations as inputs, could implicitly learn an internal RL algorithm. This recurrent architecture effectively encoded task-specific information within its hidden state, allowing it to adapt its policy to new tasks without requiring explicit weight updates, a process termed \"learning to reinforcement learn.\" While groundbreaking, this approach was initially demonstrated in simpler domains, raising questions about its scalability to complex, high-dimensional environments. Building on the concept of adaptive behaviors through architectural innovation, \\cite{vecoven2018hc1} introduced Neuro-Modulated Networks (NMNs). These networks employed a neuromodulatory sub-network to dynamically tune the activation function parameters of a main policy network, offering a more scalable solution than simply increasing network depth or width. NMNs achieved faster and more stable adaptive behaviors compared to standard RNNs, though their performance could be sensitive to the choice of activation functions. Further pushing the boundaries of implicit algorithmic learning, \\cite{xu2020txy} proposed FRODO, an algorithm that utilized meta-gradient descent to discover its own RL objective function online, parameterizing the update target with a neural network. This ambitious approach aimed to learn the very learning rule, but scaling such online objective learning to complex, real-world environments remains a significant practical challenge. These RNN-based methods, while powerful, often struggled with long-term credit assignment and the explicit representation of task uncertainty, paving the way for more explicit adaptation strategies \\cite{finn2017vrt, sutton2022jss}.\n\nA parallel and highly influential direction in meta-learning, particularly for rapid and explicit adaptation, emerged with gradient-based methods. Model-Agnostic Meta-Learning (MAML) \\cite{finn20174c4} proved instrumental in this regard, extending its bi-level optimization framework to both Meta-RL and Meta-IL. For Meta-RL, MAML learns an initialization that can be quickly fine-tuned with a few gradient steps on a new task, significantly improving sample efficiency compared to learning from scratch. In the realm of Meta-Imitation Learning (Meta-IL), \\cite{finn20174c4} pioneered one-shot visual imitation learning, enabling robots to acquire new skills from a single visual demonstration. This was a significant advancement, as it allowed end-to-end learning of visuomotor policies directly from raw pixel inputs, adapting via a few gradient updates. This approach addressed the critical data efficiency bottleneck in robotics, where collecting numerous demonstrations per task is often infeasible. However, a key challenge in imitation learning is the domain shift between human demonstrations and robot embodiments. \\cite{yu2018nm7} addressed this by leveraging meta-learning to build prior knowledge for cross-domain transfer, facilitating more robust one-shot imitation. While gradient-based methods like MAML offer strong generalization capabilities, they can be computationally intensive and susceptible to meta-overfitting, where the meta-learner performs well on meta-training tasks but struggles with truly novel task distributions \\cite{chen2021j5t}. To mitigate this, \\cite{tseng2020m83} proposed regularizing meta-learning via gradient dropout, a simple yet effective method to alleviate overfitting during the inner-loop adaptation, thereby enhancing generalization to new tasks. More recent work by \\cite{wang2024bhk} further investigates the underfitting/overfitting challenges in meta-learning, proposing a \"Task Relation Learner\" (TRLearner) to calibrate optimization by leveraging task similarities, which could be highly relevant for improving the robustness of gradient-based Meta-RL and Meta-IL.\n\nTo tackle increasingly complex and long-horizon tasks, meta-learning has also been integrated with hierarchical and skill-based approaches. These methods aim to decompose complex behaviors into reusable sub-skills, which can then be meta-learned and composed. \\cite{yang2018p36} proposed a hierarchical deep reinforcement learning algorithm that simultaneously learned basic and compound skills, utilizing two levels of hierarchy with a meta critic overseeing basic skills. Building on this, \\cite{xu2019brv} introduced Hierarchical Meta-Critic Networks for sample-efficient learning, providing transferable knowledge across tasks by sharing a global basic critic and a meta critic. This framework allowed for the distillation of meta-knowledge above the task level, enhancing adaptation. \\cite{lan20196o7} further improved generalization by proposing Meta-RL with Task Embedding and Shared Policy, explicitly capturing shared information across tasks and meta-learning how to quickly abstract task-specific information. More recently, \\cite{nam2022z75} devised a skill-based Meta-RL method that leverages prior experience extracted from offline datasets to learn reusable skills and meta-train a high-level policy. This enables efficient composition of learned skills into long-horizon behaviors, allowing for rapid adaptation to unseen target tasks with significantly fewer environment interactions.\n\nThe versatility of Meta-RL extends to various real-world applications, demonstrating its capacity for rapid adaptation in dynamic and resource-constrained settings. For instance, \\cite{wang2020tae} developed a fast adaptive task offloading method in edge computing based on Meta-RL, which can adapt quickly to new environments with minimal gradient updates and samples. In robotics, \\cite{visca20217nt} presented a deep meta-learning framework for energy-aware path planning for unmanned ground vehicles, allowing adaptation to unknown terrains. Furthermore, \\cite{ma20243e9} proposed a Graph Convolutional Network based Multi-Objective Meta-Deep Q-Learning (GM2DQL) method for eco-routing, demonstrating rapid adaptation to dynamic traffic conditions. Beyond efficiency, Meta-RL is also being extended to safety-critical domains. \\cite{khattar2024sr6} introduced a novel \"CMDP-within-online\" framework for Meta-Safe Reinforcement Learning, providing the first provable guarantees for task-averaged regret and constraint violations. This work is crucial for deploying RL agents in applications where both rapid adaptation and strict adherence to safety constraints are paramount. The integration of language instructions also shows promise, with \\cite{bing2022xo7} presenting a meta-RL algorithm that utilizes language to shape task interpretation in robotic manipulation, offering a more intuitive way to specify new tasks.\n\nIn conclusion, the field of Meta-Reinforcement Learning and Imitation Learning has undergone a significant evolution, moving from early demonstrations of implicit algorithmic learning within recurrent networks to sophisticated frameworks that explicitly optimize for adaptability and leverage hierarchical structures. While substantial progress has been made in addressing sample inefficiency and generalization, future research will likely focus on improving robustness to out-of-distribution tasks in dynamic environments, bridging the sim-to-real gap more effectively, and scaling to even more diverse and open-ended task distributions. The integration of meta-learning with other advanced learning paradigms, particularly for safety and human-robot interaction, will be crucial for achieving truly autonomous and adaptable AI agents capable of operating effectively in complex, real-world scenarios.\n\\subsection{Probabilistic Meta-Learning for Task Inference and Exploration}\n\\label{sec:5_2_probabilistic_meta-learning_for_task_inference__and__exploration}\n\n\nA critical challenge in meta-reinforcement learning (meta-RL) is the efficient adaptation to novel tasks, particularly in environments characterized by inherent uncertainty. Advanced probabilistic meta-learning frameworks explicitly address this by modeling task uncertainty, enabling more efficient exploration and the development of Bayes-adaptive policies. These policies condition actions not just on the current state, but also on the agent's evolving belief about the underlying task, leading to more robust and uncertainty-aware adaptation.\n\nA foundational contribution in this area is VariBAD (Variational Bayes-Adaptive Deep RL) by \\cite{zintgraf2019zat}. VariBAD meta-learns an approximate Bayes-adaptive policy by jointly training a Variational Auto-Encoder (VAE) for posterior inference over latent MDP embeddings and a policy conditioned on this belief. This approach allows the agent to perform principled online exploration by continuously updating its belief about the task as it interacts with the environment, demonstrating superior exploratory behavior compared to methods like posterior sampling in tasks such as Gridworld navigation \\cite{zintgraf2019zat}. However, VariBAD's reliance on on-policy experience during meta-training limited its sample efficiency, a common bottleneck in deep RL.\n\nTo address the sample inefficiency of on-policy meta-RL, \\cite{rakelly2019m09} introduced PEARL (Probabilistic Embeddings for Actor-Critic RL). PEARL is an off-policy meta-RL algorithm that leverages probabilistic context variables to encode task-specific information, conditioning the policy on this latent variable. A key innovation is its permutation-invariant encoder for task inference, which processes past experience to estimate the posterior over context variables, enabling significantly improved meta-training sample efficiency (20-100X) and structured exploration through posterior sampling. By decoupling the data used for policy training from that for encoder training, PEARL effectively integrates probabilistic task inference with off-policy actor-critic methods, achieving higher asymptotic performance on continuous control benchmarks \\cite{rakelly2019m09}.\n\nThe utility of probabilistic context variables extends beyond standard meta-RL to related problems like Inverse Reinforcement Learning (IRL). \\cite{yu2019o41} proposed PEMIRL (Probabilistic Embeddings for Meta-Inverse Reinforcement Learning), which adapts the probabilistic context variable paradigm to infer reward functions from few, unstructured, and heterogeneous demonstrations. PEMIRL integrates a deep latent variable model with maximum entropy IRL, utilizing mutual information regularization between the probabilistic context variable and trajectories to ensure the learned reward function effectively uses the inferred context. This enables few-shot reward inference for new tasks without requiring explicit task groupings or labels, a significant step towards more practical IRL applications \\cite{yu2019o41}.\n\nFurther pushing the boundaries of meta-learning under realistic constraints, \\cite{dorfman2020mgv} tackled the critical problem of Offline Meta-Reinforcement Learning with BOReL (Bayesian Offline Reinforcement Learning). BOReL is an off-policy VariBAD variant designed to learn exploration strategies from static, pre-collected datasets, rather than requiring active online data collection. This work formalizes the concept of \"MDP ambiguity,\" highlighting the inherent limitations of data identifiability when inferring task beliefs solely from offline data, and proposes strategies to mitigate it. BOReL demonstrates that effective meta-exploration can be learned from offline data, outperforming online baselines in some sparse reward tasks, which is crucial for applications where online interaction is costly or unsafe \\cite{dorfman2020mgv}.\n\nThe principles of Bayes-adaptive meta-learning continue to inspire advancements in specific applications and challenging environments. For instance, \\cite{zintgraf2021hoc} extended deep interactive Bayesian RL via meta-learning, enabling agents to learn about and adapt to other agents' unknown strategies in multi-agent settings by meta-learning approximate belief inference and Bayes-optimal behavior. Similarly, \\cite{bing2022om0} addressed meta-RL in non-stationary and dynamic environments by introducing a training strategy and task representation based on Gaussian mixture models, achieving zero-shot adaptation and competitive performance in changing conditions. More recently, \\cite{wang2024d09} proposed CBAMRL (Contrastive Learning-Based Bayes-Adaptive Meta-Reinforcement Learning) for active pantograph control in high-speed railways, employing a Bayes-adaptive strategy for zero-shot adaptation and a contrastive learning-based contextual encoder to represent complex task distributions, demonstrating rapid adaptation to unknown perturbations.\n\nIn conclusion, probabilistic meta-learning frameworks have significantly advanced the field by providing principled ways to model and leverage task uncertainty. From foundational methods like VariBAD to off-policy improvements in PEARL, extensions to Meta-IRL with PEMIRL, and the crucial offline learning capabilities of BOReL, these approaches enable more efficient exploration and robust adaptation in complex, partially observable environments. Despite these advancements, challenges remain in fully addressing MDP ambiguity in diverse offline datasets, scaling to extremely broad task distributions, and integrating these sophisticated probabilistic models with real-time, safety-critical applications while maintaining theoretical guarantees.\n\\subsection{Meta-Learning for Continual and Lifelong Adaptation}\n\\label{sec:5_3_meta-learning_for_continual__and__lifelong_adaptation}\n\nIntelligent agents operating in real-world environments face the fundamental challenge of continual and lifelong learning: they must adapt to non-stationary dynamics, sequentially encountered new tasks, and streaming data without succumbing to catastrophic forgetting \\cite{son2023lda}. This necessitates developing systems that can continuously learn and evolve over time, retaining previously acquired knowledge while rapidly integrating new information. Meta-learning offers a powerful paradigm to address these issues by enabling models to \"learn to learn\" robust, efficient, and lifelong adaptation mechanisms, thereby moving towards truly autonomous AI agents. This section critically examines how meta-learning approaches, often synergistically combined with other techniques, facilitate continuous learning, knowledge retention, and rapid integration of new information, focusing on the mechanisms that enable models to overcome the plasticity-stability dilemma inherent in lifelong adaptation.\n\nA primary challenge in continual learning is mitigating catastrophic forgetting, where acquiring new knowledge erodes previously learned skills. Meta-learning addresses this by learning how to adapt parameters or update rules in a way that preserves past knowledge while integrating new information. Architectural and biologically-inspired meta-learning approaches intrinsically manage the plasticity-stability dilemma through their design. For instance, Neuro-Modulated Networks (NMNs) \\cite{vecoven2018hc1} demonstrated that a neuromodulatory network could dynamically tune activation functions, leading to faster and more stable adaptive behaviors than standard recurrent neural networks. Similarly, Feedback and Local Plasticity (FLP) \\cite{lindsey202075a} introduced a meta-learning framework with decoupled feedback pathways and local synaptic plasticity rules, demonstrating superior performance in continual learning tasks and offering a universality proof for approximating any learning algorithm \\cite{finn2017vrt}. These models highlight the potential of architectural innovations to build in mechanisms for knowledge retention. More recently, Sequential Bayesian Meta-Continual Learning (SB-MCL) \\cite{lee2024snq} proposed a distinct framework that inherently prevents catastrophic forgetting by fixing neural network parameters during continual learning and offloading sequential updates to robust statistical models via meta-learned mappings. This approach decouples the expressive power of deep networks from the sequential update process, ensuring stability by leveraging the theoretical guarantees of Bayesian updates in exponential family distributions.\n\nOptimization-based meta-learning, particularly Model-Agnostic Meta-Learning (MAML) \\cite{finn20174c4}, has been instrumental in enabling rapid adaptation to new tasks by optimizing for a good initialization (as discussed in Section 3.1). However, its direct application to continual learning faces challenges such as meta-overfitting and insufficient weight modification in few gradient steps. To address these, various extensions have been proposed. \\cite{tseng2020m83} introduced gradient dropout regularization during the inner-loop optimization of gradient-based meta-learning to improve generalization to new tasks in a sequence. HyperMAML \\cite{przewiezlikowski2022d4y} replaced the gradient-based inner loop with a hypernetwork, allowing for more flexible and significant weight updates in a single step, which is crucial for adapting to diverse new tasks in a continual setting without repeated gradient computations. Furthermore, \\cite{wang2024bhk} introduced TRLearner, which uses task relation matrices and consistency regularization to mitigate underfitting and overfitting in MAML for continual adaptation. For class-incremental settings, iTAML \\cite{rajasegaran2020llk} developed an incremental task-agnostic meta-learning approach with a novel meta-update rule designed to maintain equilibrium across encountered tasks and effectively combat catastrophic forgetting. A distinct approach to learning the optimization process for continual learning was proposed by \\cite{vuorio2018gwb}, which meta-trains a neural network to predict parameter update steps that respect the importance of parameters to previous tasks, thereby directly learning to mitigate forgetting. These optimization-based methods collectively aim to learn *how to update* parameters to balance new learning with old knowledge retention, offering algorithmic solutions that complement architectural designs for stability.\n\nBeyond explicit parameter adaptation, meta-learning facilitates adaptation to non-stationary environments and dynamic task changes by learning more abstract adaptive strategies. As introduced in Section 5.1, early work by \\cite{wang20167px} demonstrated that recurrent neural networks could implicitly learn a reinforcement learning algorithm within their recurrent dynamics for rapid task adaptation. Building on the probabilistic meta-learning frameworks for task inference and exploration discussed in Section 5.2, these methods have been extended to address online adaptation and robust exploration in lifelong settings. VariBAD \\cite{zintgraf2019zat} and PEARL \\cite{rakelly2019m09} leverage probabilistic context variables and latent MDP embeddings to enable structured online exploration and improved sample efficiency, which are crucial for dynamic environments where task identity might be unknown or changing. BOReL \\cite{dorfman2020mgv} tackled Offline Meta-Reinforcement Learning, learning exploration from static datasets and mitigating \"MDP ambiguity,\" a critical challenge for lifelong learning from diverse, pre-recorded data sources. For non-stationary and dynamic environments, \\cite{bing2022om0} proposed a training strategy using Gaussian mixture models for task representation, achieving competitive asymptotic performance and superior zero-shot adaptation. While Meta-Safe Reinforcement Learning \\cite{khattar2024sr6} is discussed in detail in Section 6.4, its CMDP-within-online framework is particularly relevant here for providing provable guarantees for task-averaged regret and constraint violations in dynamic environments, which is essential for reliable lifelong operation in safety-critical contexts.\n\nMeta-learning has also been synergistically combined with other techniques to enhance continual adaptation, particularly in scenarios with realistic constraints. For instance, in lifelong language learning, \\cite{holla20202od} effectively combated catastrophic forgetting by combining meta-learning with sparse experience replay. By using replayed examples as the query set in a first-order MAML framework, their approach directly optimizes the model to prevent forgetting, demonstrating state-of-the-art performance under realistic constraints like single passes over data and no task identifiers. This highlights the power of combining meta-learning's adaptive capabilities with memory management strategies. Furthermore, hierarchical meta-learning approaches \\cite{yang2018p36, xu2019brv} have explored learning basic and compound skills or using meta-critic networks for sample-efficient learning and transferable knowledge, which are vital for accumulating complex behaviors over a lifetime. Skill-based meta-RL \\cite{nam2022z75} further leveraged offline datasets to extract reusable skills, enabling efficient meta-learning on long-horizon, sparse-reward tasks.\n\nThe practical utility of meta-learning for continual adaptation is evident across diverse real-world applications. \\cite{li20208tg} proposed an online meta-learning algorithm for self-supervised visual odometry, enabling continuous adaptation to new environments as a vehicle navigates. MAGICVFM \\cite{lupu20249p4} introduced a stable adaptive controller for ground vehicles that integrates visual foundation models and meta-learning for real-time terrain adaptation, backed by mathematical stability guarantees, showcasing robust performance in dynamic physical systems. Similarly, \\cite{ma20243e9} applied GCN-based multi-objective meta-Deep Q-Learning for eco-routing, demonstrating one-shot adaptation to new driving conditions. For high-speed railways, \\cite{wang2024d09} developed a contrastive learning-based Bayes-adaptive meta-RL (CBAMRL) for active pantograph control, achieving zero-shot adaptation in non-stationary environments. In the domain of class-incremental learning, a transformer-based approach by \\cite{kumar2024he9} demonstrated that meta-learners can exhibit significant generalization to newly introduced classes even without explicit training for this task, highlighting their inherent adaptability for integrating new categories over time. These applications underscore meta-learning's capacity to provide robust, efficient, and often theoretically grounded adaptation in complex, dynamic real-world systems.\n\nDespite significant progress, challenges remain in scaling these approaches to truly open-ended, highly complex real-world scenarios. Key tensions exist between architectural solutions (e.g., NMNs, SB-MCL) that intrinsically manage plasticity and stability, and algorithmic solutions (e.g., iTAML, meta-optimizers for CL) that modify learning rules. While memory-based methods like sparse experience replay are effective, they are constrained by finite memory buffers, raising questions about their efficacy in truly open-ended lifelong scenarios where knowledge accumulation is unbounded. Future research must focus on developing more robust and generalizable meta-learning frameworks that can operate with minimal supervision, handle extreme non-stationarity, provide stronger theoretical guarantees for all aspects of lifelong adaptation, and efficiently integrate diverse knowledge sources. The development of robust evaluation benchmarks specifically for continual meta-learning will also be crucial to drive progress towards truly autonomous and adaptable AI agents.\n",
    "Real-World Applications and Robustness": "\\section{Real-World Applications and Robustness}\n\\label{sec:real-world_applications__and__robustness}\n\n\n\n\\subsection{Domain-Specific Adaptation and Generalization}\n\\label{sec:6_1_domain-specific_adaptation__and__generalization}\n\n\nMeta-learning offers a compelling paradigm for addressing the inherent challenges of data scarcity, spatiotemporal heterogeneity, and the critical need for rapid, cost-effective deployment in diverse, unseen operational environments. By learning to learn, meta-learning enables models to quickly adapt and generalize to new tasks or domains with minimal new data, showcasing its practical efficacy across various scientific and engineering fields.\n\nA prominent application demonstrating meta-learning's utility in rapid adaptation is wireless localization. Traditional fingerprinting-based methods struggle with environment-specificity, demanding extensive data collection and retraining for each new physical setting. To overcome this, \\cite{gao20223fn} and \\cite{gao2022y3s} introduce MetaLoc, a pioneering framework that leverages Model-Agnostic Meta-Learning (MAML) to learn optimal \"meta-parameters\" – essentially a robust model initialization – from historical tasks. This allows a deep neural network to quickly adapt to new environments with minimal new data and computationally inexpensive updates, significantly enhancing scalability and cost-effectiveness. Building upon this, \\cite{pu2024m1b} further refines neural network positioning by proposing a Bayesian meta-learning approach. This method enhances robustness by inferring the Bayesian posterior, effectively mitigating model uncertainty and preventing overfitting when adapting to new environments with very limited samples, thus improving the reliability of rapid adaptation in dynamic wireless settings.\n\nBeyond static environments, meta-learning proves invaluable in tackling complex spatiotemporal heterogeneity. In climate science, accurately estimating global carbon fluxes (e.g., Gross Primary Production) is hampered by sparse and unbalanced in-situ observations, particularly in crucial regions like the tropics. \\cite{nathaniel2023ycu} introduces MetaFlux, which employs an MAML-adapted meta-learning ensemble to upscale these sparse spatiotemporal observations. This approach provides robust estimates even in data-poor regions and demonstrates enhanced robustness in predicting extreme flux events, significantly outperforming non-meta-learning baselines. Generalizing this concept, \\cite{dong2024110} proposes HimNet, a Heterogeneity-Informed Meta-Parameter Learning scheme for spatiotemporal time series forecasting. HimNet implicitly characterizes spatiotemporal heterogeneity through learnable embeddings and dynamically generates context-specific parameters from compact meta-parameter pools, addressing the limitations of prior methods that rely on auxiliary features or suffer from high computational costs. This represents a significant advancement in leveraging heterogeneity to inform model adaptation. Similarly, \\cite{pan2019pue} addresses urban traffic prediction, another domain characterized by complex spatio-temporal correlations, using a deep meta-learning model (ST-MetaNet) that collectively predicts traffic by capturing diverse spatial and temporal patterns.\n\nMeta-learning also provides critical solutions for few-shot learning scenarios where data is inherently scarce. For instance, few-shot short utterance speaker verification, crucial for applications like online payments, faces challenges due to the limited availability of voice samples. \\cite{wang2023x5w} addresses this by employing a meta-learning approach, specifically Prototypical Networks enhanced with an ECAPA-TDNN feature extractor and an episodic training strategy that incorporates global classification. This enables the model to learn more discriminative speaker features and achieve identification with minimal voice samples, outperforming traditional methods. The utility extends to other specialized domains: \\cite{wang2023srr} introduces Meta-Transfer Learning with Freezing Operation (MTLFO) for few-shot bearing fault diagnosis, which learns new knowledge rapidly from small samples while avoiding overfitting. In remote sensing, \\cite{alajaji2020b6c} applies MAML for few-shot scene classification, demonstrating its ability to classify new, unseen classes from limited labeled samples. Furthermore, \\cite{cheng2024mky} proposes a meta-transfer learning framework for general hyperspectral image super-resolution, tackling data scarcity and significant domain differences by accumulating diverse task experiences and gradually expanding the number of bands. Even in video processing, \\cite{gupta2021fbg} presents Ada-VSR, an adaptive video super-resolution method that uses meta-transfer learning to quickly adapt to novel degradation conditions with only a few gradient updates, significantly reducing inference time.\n\nIn conclusion, the literature clearly demonstrates meta-learning's profound impact on domain-specific adaptation and generalization. By enabling rapid learning from limited data and effectively handling complex heterogeneity, meta-learning addresses critical real-world challenges across wireless communication, climate science, security, manufacturing, and remote sensing. However, ongoing research continues to explore ways to balance the computational overhead of meta-learning with scalability, develop more universally robust meta-objectives, and reduce the reliance on diverse meta-training data to fully unlock its potential for truly adaptable and cost-effective AI systems.\n\\subsection{Meta-Learning for Data Quality and Robustness}\n\\label{sec:6_2_meta-learning_for_data_quality__and__robustness}\n\n\nReal-world machine learning applications are frequently hampered by imperfect data, including noisy labels, imbalanced distributions, and varying data utility, all of which can severely degrade model performance and robustness. Meta-learning offers a powerful paradigm to address these challenges by enabling deep neural networks to \"learn how to learn\" from such imperfections, thereby enhancing data quality and improving model resilience.\n\nA significant area of focus is making deep neural networks inherently noise-tolerant. \\cite{li2018soc} pioneered a meta-learning based noise-tolerant (MLNT) training algorithm that optimizes a meta-objective to prevent overfitting to label noise. This approach innovatively generates synthetic noisy labels through a \"random neighbor label transfer\" method and enforces consistency with a stable self-ensembling teacher model, effectively learning parameters that are robust against a wide spectrum of label corruption. Building on this, \\cite{algan2020u0v} introduced Meta Soft Label Generation (MSLG), a meta-learning algorithm that jointly generates optimal soft labels and learns deep neural network parameters. MSLG adapts the meta-learning paradigm to estimate label distributions by evaluating gradient directions on both noisy training data and a small, noise-free meta-dataset, iteratively refining soft labels to minimize loss on clean samples. This provides a more nuanced approach to handling label uncertainty compared to direct label correction. Further specializing in specific domains, \\cite{zhang2021p9j} proposed an adaptive label noise cleaning algorithm based on meta-supervision for deep face recognition. This method learns reliable cleaning knowledge from well-labeled noisy data and gradually transfers it to target data, incorporating a threshold adapter to manage transfer learning drift and achieve state-of-the-art performance on noisy face datasets. Extending beyond simple label noise, \\cite{liu2022tgc} tackled diverse data biases in deep face recognition, such as ethnicity, head pose, and occlusion. They proposed a sample-level weighting approach, Multi-variation Cosine Margin (MvCoM), guided by a meta-learning set to predict these weights, thereby simultaneously handling multiple variation factors and enhancing robustness against complex data imbalances.\n\nAnother critical aspect of data quality is data valuation, where meta-learning helps identify and leverage the most valuable data samples. \\cite{yoon2019k84} addressed the computationally intensive nature of traditional data valuation methods (like Data Shapley) by proposing Data Valuation using Reinforcement Learning (DVRL). This meta-learning framework jointly optimizes a data value estimator (a neural network predicting sample selection probabilities) and a target task predictor model. Crucially, DVRL employs reinforcement learning to handle the non-differentiable process of data sampling, using the predictor's performance on a small validation set as a reward signal. This scalable and model-agnostic approach significantly outperforms prior methods in tasks like corrupted sample discovery, domain adaptation, and robust learning, demonstrating meta-learning's power in discerning data utility.\n\nBeyond explicit label correction and data valuation, meta-learning also contributes to broader aspects of model robustness against data imperfections. For instance, in few-shot learning scenarios, the \"hubness problem\"—where certain class prototypes become the nearest neighbor for many test instances regardless of their true class—can arise from data distribution characteristics. \\cite{fei20211x6} demonstrated that many few-shot learning methods suffer from this and proposed using z-score feature normalization during meta-training to mitigate its negative effects, thereby boosting the robustness and performance of existing methods. Furthermore, addressing biases in training data for fair ranking systems, \\cite{wang2024so2} introduced a Meta Curriculum-based Fair Ranking (MCFR) framework. This framework utilizes a meta-learner to generate weighted losses, focusing more on minority groups to alleviate data bias. By formulating this as a bilevel optimization problem and integrating a curriculum learning scheduler for sampling the meta-dataset, MCFR learns to adaptively re-weight samples, ensuring fairer ranking outcomes.\n\nIn conclusion, meta-learning provides a versatile toolkit for enhancing data quality and model robustness in the face of real-world data imperfections. Techniques range from learning to correct or down-weight noisy labels, as seen in \\cite{li2018soc} and \\cite{algan2020u0v}, to sophisticated data valuation methods like DVRL \\cite{yoon2019k84} that identify and prioritize valuable samples. Moreover, meta-learning contributes to mitigating broader data-induced issues such as hubness \\cite{fei20211x6} and fairness biases \\cite{wang2024so2}. A common limitation across many of these approaches, however, remains the reliance on a small, often clean, validation or meta-dataset to guide the meta-learning process, which may not always be available in extreme real-world scenarios. Future research could focus on developing meta-objectives that are less dependent on such clean auxiliary data, further improving the scalability and generalizability of meta-learning for data quality and robustness across an even wider range of tasks and data imperfections.\n\\subsection{Meta-Learning with Large Pre-trained Models}\n\\label{sec:6_3_meta-learning_with_large_pre-trained_models}\n\nThe advent of large pre-trained models, including Vision-Language Models (VLMs) and Large Language Models (LLMs), has fundamentally reshaped the landscape of few-shot learning, instigating a crucial paradigm shift in meta-learning. This subsection explores how meta-learning strategies are now predominantly employed to efficiently adapt, steer, or minimally tune these massive foundational models for novel tasks with limited data, moving beyond the traditional goal of learning optimal initial model weights.\n\nHistorically, meta-learning focused on learning generalizable initialization parameters or architectures that could quickly adapt to new tasks with a few gradient steps \\cite{Finn_MAML_2017, Nichol_Reptile_2018}. Early surveys, such as \\cite{huisman2020b7w}, noted an empirical correlation between larger network backbones and improved few-shot performance, implicitly hinting at the power of rich, pre-learned representations. This observation paved the way for integrating powerful pre-trained models into meta-learning frameworks. For instance, early work by \\cite{holla20202od} demonstrated the efficacy of meta-learning with sparse experience replay for lifelong language learning, leveraging pre-trained BERT as a representation network to mitigate catastrophic forgetting. Similarly, \\cite{li2023zn0} advanced few-shot text classification by proposing SEML, which enhances meta-learning with self-supervised information derived from unlabeled data, further enriching the feature representations learned by models like BERT. These initial integrations showcased meta-learning's ability to leverage pre-trained knowledge for specific adaptive challenges.\n\nThe true transformation, however, lies in the shift from fine-tuning entire models to efficiently interacting with or minimally tuning *frozen* foundational models. A seminal contribution in this area is \"Learning to Prompt\" (L2P) by \\cite{Chen_L2P_2021}, which introduced a meta-learning approach where a meta-learner generates task-specific learnable prompts to guide a *frozen* Vision-Language Model for few-shot adaptation. This technique significantly reduces the number of parameters requiring fine-tuning, thereby minimizing computational cost and data requirements. Building upon this, \\cite{wang2024dai} addressed a critical limitation of prompt tuning: overfitting to base classes and poor generalization to novel classes. They proposed \"Learning to Learn Better Visual Prompts,\" which integrates a meta-learning-informed episodic training strategy (akin to MAML's inner-outer loop optimization) into prompt tuning. This enables the model to learn more generalizable prompt vectors that effectively transfer knowledge to unseen categories, demonstrating meta-learning's power in optimizing the *prompting strategy itself* for improved few-shot generalization. The practical impact of this paradigm is further exemplified by \\cite{lupu20249p4}'s MAGICVFM, a stable adaptive controller for ground vehicles. This system integrates Visual Foundation Models (VFMs) and meta-learning to adapt only the last layer of a deep neural network based on VFM-derived visual features, showcasing efficient and robust adaptation of foundational models in safety-critical scenarios.\n\nFor Large Language Models (LLMs), meta-learning plays a crucial role in addressing their inherent data and computational demands, particularly for domain-specific adaptation \\cite{lee2021jou}. While in-context learning (ICL) is an emergent capability of large transformers, exhibiting properties analogous to meta-learning by adapting to tasks from demonstrations without explicit weight updates, explicit meta-learning strategies are actively employed to enhance or steer this emergent behavior. \\cite{Wang_Meta-Learning_2022} provides a comprehensive survey, highlighting how meta-learning underpins strategies like prompt-based learning, parameter-efficient fine-tuning (PEFT), and in-context learning to adapt these massive models with minimal data and computational overhead. This underscores a paradigm shift towards learning *how to interact with* or *efficiently tune* these powerful, pre-trained models rather than learning their initial weights from scratch. Furthermore, meta-learning with transformer-based models is being applied to real-world challenges like class incremental learning, where `\\cite{kumar2024he9}` proposes a transformer-based aggregation function within a meta-learner to classify newly introduced classes without retraining, showcasing how meta-learning enables continuous adaptation for these large NLP models.\n\nBeyond prompt tuning, meta-learning principles are being explored for other parameter-efficient fine-tuning (PEFT) techniques. For instance, meta-learning could be applied to optimize configurations for adapters (e.g., determining optimal LoRA ranks or placement) or to learn dynamic learning rate schedules for specific modules, further enhancing adaptation efficiency. The immense scale and complexity of foundational models also necessitate advancements in meta-optimization. \\cite{ozkara2024nst} introduced Meta-Adaptive Optimizers (MADA), which meta-learn the most suitable optimizer dynamically during training. This approach is particularly beneficial for the complex optimization landscapes and high computational costs associated with fine-tuning large models, potentially leading to faster convergence or better generalization with fewer steps. Moreover, theoretical advancements, such as the analysis of optimal (even counter-intuitive negative) inner-loop learning rates in MAML for overparameterized models by \\cite{bernacchia20211r0}, offer fundamental insights into the meta-optimization process. These insights are highly relevant for designing more robust and efficient meta-learning algorithms to adapt large pre-trained models, where overparameterization is the norm and optimal tuning strategies are critical for performance and computational efficiency.\n\nThe practical deployment of large foundation models, especially in sensitive domains, also highlights the critical role of meta-learning in distributed and privacy-preserving adaptation. The immense scale of these models, coupled with privacy concerns in real-world user data, makes centralized fine-tuning impractical. Federated meta-learning emerges as a critical enabling technology for privacy-preserving personalization, allowing large models to adapt to diverse client data without centralizing raw information. Examples include federated meta-learning frameworks for EV charging demand forecasting \\cite{you2024xuq} and driver distraction detection \\cite{liu2024jz5}, which enable collaborative learning across multiple clients while preserving data privacy, highly pertinent for deploying large models in sensitive, real-world environments.\n\nIn conclusion, meta-learning has undergone a significant evolution, transitioning from learning initial model parameters to developing sophisticated strategies for efficiently interacting with, steering, or minimally tuning large pre-trained models. This shift, driven by techniques like learning to generate optimal prompts and parameter-efficient fine-tuning, unlocks the immense potential of foundational models for rapid adaptation across a vast array of few-shot downstream applications. However, challenges remain in fully understanding the emergent properties of in-context learning, developing universally robust and parameter-efficient meta-learning strategies, scaling meta-training to encompass the full diversity of tasks that these increasingly capable foundational models can address, and advancing the theoretical understanding of meta-optimization in these overparameterized regimes.\n\\subsection{Safety and Interpretability in Meta-Learning Systems}\n\\label{sec:6_4_safety__and__interpretability_in_meta-learning_systems}\n\n\nThe deployment of highly adaptive meta-learning systems in real-world, often safety-critical, applications necessitates a rigorous focus on their safety and interpretability. While meta-learning excels at rapid adaptation to new tasks with limited data, ensuring that this adaptability does not compromise reliability, transparency, and trustworthiness is paramount. Recent advancements are beginning to address these crucial aspects, moving towards more responsible AI development.\n\nA significant step towards reliable autonomous systems is the development of meta-safe reinforcement learning (Meta-SRL), which provides provable guarantees for safety. \\cite{khattar2024sr6} introduces a novel \"CMDP-within-online\" framework for Meta-SRL, offering the first provable guarantees for task-averaged regret and constraint violations in Constrained Markov Decision Processes (CMDPs). This framework is critical for enabling RL agents to adapt quickly to unseen tasks while strictly adhering to safety constraints, even in the presence of inexact policies and state visitation distributions. Complementing this, \\cite{lupu20249p4} presents MAGICVFM, a stable adaptive controller for ground vehicles that integrates visual foundation models with meta-learning for real-time terrain adaptation. This system is backed by mathematical guarantees of exponential stability and robustness, directly contributing to the safe operation of autonomous systems in complex, dynamic environments. Similarly, \\cite{oconnell2022twd} demonstrates Neural-Fly, a meta-learning approach that enables rapid online adaptation for agile UAV flight in strong winds, providing robustness and exponential stability guarantees crucial for safe aerial navigation.\n\nBeyond explicit safety guarantees, interpretability and reliable confidence estimates are vital for trust and accountability, particularly in human-machine interaction. \\cite{tam2024a1h} addresses this by proposing a deep metric meta-learning framework for robust and interpretable EMG-based hand gesture recognition. Their method learns a semantically meaningful embedding space and derives a class proximity-based confidence estimator, offering more reliable and transparent confidence measures than traditional softmax outputs, which is crucial for safety-critical applications like prosthetic control. This approach tackles the poor generalization and overconfidence issues prevalent in conventional deep learning models. In a similar vein, \\cite{chen2022z45} and \\cite{wistuba2021wha} leverage meta-learning with deep kernel Gaussian Processes (GPs) to provide robust predictions with well-calibrated uncertainty estimates in few-shot settings, such as molecular property prediction and hyperparameter optimization. These calibrated uncertainties are essential for informed decision-making and building trust in high-stakes scientific and engineering domains. Further enhancing reliability, \\cite{aqeel2025zql} introduces Confident Meta-learning (CoMet) for unsupervised anomaly detection, which integrates soft confident learning to assign lower weights to low-confidence samples and meta-learning to stabilize training. This approach improves robustness to noisy data and provides critical confidence signals for anomaly detection, a key safety function.\n\nThe robustness of meta-learning systems to continuous data streams and evolving tasks also contributes to their overall safety and reliability. \\cite{holla20202od} tackles catastrophic forgetting in lifelong language learning by combining meta-learning with sparse experience replay. By preventing models from losing previously acquired knowledge, this method ensures sustained performance and reliability in dynamic environments. Building on this, \\cite{lee2024snq} proposes Sequential Bayesian Meta-Continual Learning (SB-MCL), a framework that inherently prevents catastrophic forgetting in neural networks by offloading sequential updates to robust statistical models, thereby ensuring long-term reliability and stability of learned knowledge.\n\nDespite these advancements, the efficacy of meta-learning in all safety-critical domains is not universally established. For instance, \\cite{guarino2023zsq} conducted a comprehensive comparison of meta-learning, transfer learning, and contrastive learning for encrypted traffic classification, a security-critical task. Their findings indicated that meta-learning methods, at least with the evaluated techniques and protocols, performed worse than other representation learning paradigms. This highlights the imperative for careful evaluation and validation of meta-learning approaches in specific safety-critical contexts, as their benefits are not guaranteed across all application types.\n\nIn conclusion, while meta-learning offers powerful tools for rapid adaptation, the integration of provable safety guarantees, interpretable confidence estimates, and robust continual learning mechanisms is crucial for its responsible deployment. Future research must continue to bridge the gap between adaptive effectiveness and the stringent requirements of safety, transparency, and trustworthiness, ensuring that these advanced AI systems can be reliably used in the most demanding real-world scenarios.\n",
    "Challenges and Future Directions": "\\section{Challenges and Future Directions}\n\\label{sec:challenges__and__future_directions}\n\n\n\n\\subsection{Theoretical Gaps and Generalization Challenges}\n\\label{sec:7_1_theoretical_gaps__and__generalization_challenges}\n\nDespite significant advancements, deep meta-learning continues to grapple with fundamental theoretical limitations and persistent generalization challenges, particularly when confronted with truly novel task distributions. A critical issue is meta-overfitting, where meta-learners excel on meta-training tasks but struggle to adapt effectively to unseen tasks that deviate significantly from the meta-training distribution, often exhibiting sensitivity to subtle shifts in task characteristics \\cite{wang2024bhk, khoee2024ksk}.\n\nThe challenge of meta-overfitting is a central concern. Traditional meta-learning, often relying on bi-level optimization, can lead to underfitting or overfitting depending on task complexity, hindering generalization \\cite{wang2024bhk}. To address this, \\textcite{wang2024bhk} proposed TRLearner, a plug-and-play method that introduces relation-aware consistency regularization based on extracted task relation matrices. This approach offers theoretical guarantees for improved generalization by ensuring consistent performance on similar tasks, moving beyond simple empirical observations. Similarly, in the context of Vision-Language Models, \\textcite{wang2024dai} tackled the generalization challenge in prompt tuning, where models often overfit to base classes and perform poorly on novel ones. Their meta-learning-informed episodic training strategy effectively mitigates this overfitting, demonstrating improved generalization to new classes.\n\nA related problem is the meta-learner's tendency to \"memorize\" meta-training tasks rather than learning a truly adaptive mechanism. \\textcite{yin2019cct} highlighted this by showing that meta-learners can sometimes solve all meta-training tasks zero-shot without actual adaptation, leading to poor performance on novel tasks. They proposed an information-theoretic meta-regularization objective to prioritize data-driven adaptation. The sensitivity to shifts in task distribution is particularly evident in cross-domain few-shot learning. \\textcite{tian2023iyh} addressed this by proposing an adversarial meta-training framework that dynamically generates pseudo tasks to improve generalization to unseen domains, emphasizing the need for robust meta-knowledge. Surveys like \\textcite{khoee2024ksk} further formalize the problem of Domain Generalization through meta-learning, underscoring that effective generalization to unseen domains necessitates sufficient diversity in meta-training tasks. Practical applications also highlight these limitations; for instance, \\textcite{zhu2022d9a} and \\textcite{zhu2020rb5} developed meta-learning solutions for No-Reference Image Quality Assessment to improve generalization to unseen distortion types, a common real-world challenge. However, meta-learning's efficacy is not universally guaranteed; \\textcite{guarino2023zsq}'s empirical study on encrypted traffic classification found that meta-learning methods performed worse than transfer or contrastive learning, suggesting that in some domains, the learned meta-knowledge may not transfer as effectively. This is further supported by observations from the NeurIPS 2021 MetaDL challenge, where backbone fine-tuning often outperformed episodic meta-learning, indicating that simpler transfer learning might sometimes be more effective for generalization \\cite{baz2022n78}.\n\nBeyond empirical observations, there is a pressing need for stronger theoretical guarantees for generalization across diverse tasks. While some works provide theoretical foundations, such as \\textcite{finn2017vrt} demonstrating the universality of gradient-based meta-learning in approximating any learning algorithm, these do not always translate into robust generalization guarantees for complex real-world scenarios. More specific theoretical insights are emerging, such as \\textcite{bernacchia20211r0}'s surprising finding that the optimal inner loop learning rate for MAML during meta-training can be negative. This theoretical analysis, derived from random matrix theory and the Neural Tangent Kernel framework, offers a deeper understanding of MAML's generalization behavior and challenges conventional assumptions about gradient-based optimization in meta-learning. In safety-critical applications, theoretical guarantees are paramount; \\textcite{khattar2024sr6} introduced a CMDP-within-online framework for Meta-Safe Reinforcement Learning, providing the first provable guarantees for task-averaged regret and constraint violations. Similarly, \\textcite{lupu20249p4} developed MAGICVFM for ground vehicle control, integrating visual foundation models and meta-learning with mathematical stability guarantees, showcasing a move towards theoretically robust adaptive systems.\n\nThe computational complexity of meta-training and the challenges associated with scaling meta-learning algorithms to very large and highly heterogeneous task distributions remain crucial areas for foundational research. Early surveys, such as \\textcite{huisman2020b7w}, already identified high computational costs as a significant open challenge. Optimization-based meta-learning, particularly methods like MAML, often involve backpropagating through multiple inner-loop gradient steps, leading to substantial memory and computational overhead. To mitigate this, \\textcite{bertinetto2018ur2} proposed meta-learning with differentiable closed-form solvers (e.g., Ridge Regression), which allows for efficient adaptation and backpropagation by leveraging matrix identities. Building on this, \\textcite{przewiezlikowski2022d4y} introduced HyperMAML, replacing MAML's gradient-based inner loop with a trainable hypernetwork to generate more substantial and efficient weight updates in a single step, thereby reducing computational complexity. The meta-learning of optimizers, as seen in \\textcite{ozkara2024nst}'s MADA framework, also implicitly aims to improve the overall efficiency of the learning process itself. Furthermore, scaling meta-learning to very large and distributed task distributions, especially in privacy-sensitive domains, has led to the integration of federated learning. Approaches like \\textcite{you2024xuq}'s FMGCN for EV charging demand forecasting, \\textcite{liu2024jz5}'s AFM3D for driver distraction detection, and \\textcite{qu2022mu6}'s ALL for parking occupancy prediction, combine federated learning with meta-learning to address data silos, heterogeneity, and computational efficiency in distributed, multi-client environments. These efforts highlight the ongoing struggle to make meta-learning practical and scalable for real-world, dynamic, and diverse task landscapes.\n\nIn conclusion, while deep meta-learning has demonstrated impressive capabilities in few-shot learning and adaptation, significant theoretical and practical hurdles persist. The field continues to grapple with fundamental issues of meta-overfitting and sensitivity to task distribution shifts, necessitating more robust regularization and task-aware learning mechanisms. The demand for stronger theoretical guarantees for generalization, moving beyond empirical success to provable performance, remains a critical research direction. Simultaneously, addressing the inherent computational complexity and developing scalable meta-learning algorithms for increasingly large and heterogeneous task distributions are crucial for unlocking the full potential of learning-to-learn paradigms in real-world applications.\n\\subsection{Ethical Considerations and Societal Impact}\n\\label{sec:7_2_ethical_considerations__and__societal_impact}\n\n\nThe rapid advancement of autonomous and adaptive meta-learning systems, while promising significant technological breakthroughs, simultaneously introduces profound ethical implications and necessitates careful consideration of their broader societal impact. As these systems learn \"how to learn\" and adapt to novel tasks with minimal human intervention, critical discussions surrounding potential issues such as bias amplification, the challenge of accountability, and the risk of misuse become increasingly urgent.\n\nA primary concern revolves around **bias amplification**. Meta-learning algorithms are designed to extract generalizable knowledge from a distribution of tasks \\cite{hospedales2020m37, huisman2020b7w}. If the data used for meta-training, or the tasks themselves, contain existing societal biases, the meta-learner can inadvertently perpetuate or even exacerbate these biases when applied to new, unseen scenarios. For instance, in deep face recognition, where training data is often imbalanced across various demographic and environmental factors, meta-learning approaches must explicitly account for \"diverse data biases\" to prevent significant accuracy degradation for underrepresented groups \\cite{liu2022tgc}. Similarly, in information retrieval, meta-learning frameworks are being developed to address \"data bias\" and promote \"fair ranking\" by guiding the meta-learner to mitigate skewness towards biased attributes \\cite{wang2024so2}. Furthermore, methods that leverage self-supervised learning from unlabeled data \\cite{li2023zn0} or learn from uncurated datasets \\cite{aqeel2025zql} risk embedding and amplifying latent biases present in these larger, less scrutinized data pools if not carefully designed with fairness in mind. Even efforts to improve data quality through meta-learning, such as data valuation \\cite{yoon2019k84} or learning from noisy labels \\cite{li2018soc}, could inadvertently prioritize data points that reinforce existing biases if the underlying valuation or noise models are themselves biased.\n\nThe inherent adaptability of meta-learning systems also poses significant challenges for **accountability**. When AI systems learn not just parameters, but the very rules or initializations that govern their adaptation \\cite{Finn_MAML_2017, Nichol_Reptile_2018}, their decision-making processes can become opaque and emergent. This complexity makes it difficult to trace *why* a system behaved in a particular way or adapted to a new situation in a specific manner. The intricate interplay of initialization layers and learned \"meta-layers\" for task-specific fine-tuning, as explored in efforts to rethink meta-learning's core mechanisms \\cite{wang2024bhk}, adds layers of abstraction that complicate interpretability. Similarly, meta-adaptive optimizers that dynamically learn the most suitable optimization strategy during training \\cite{ozkara2024nst} further obscure the causal chain of decisions. Recognizing these challenges, some research directly addresses accountability in safety-critical domains. For example, meta-safe reinforcement learning aims to provide \"provable guarantees\" for task-averaged regret and constraint violations in complex environments, a crucial step towards ensuring reliable behavior in autonomous systems \\cite{khattar2024sr6}. In ground interaction control for vehicles, the integration of visual foundation models with meta-learning for real-time adaptation, while offering \"mathematical stability guarantees,\" still presents interpretability challenges for understanding specific adaptations \\cite{lupu20249p4}. Efforts to enhance \"interpretability\" and provide \"robust confidence estimates\" in human-machine interfaces, such as EMG-based hand gesture recognition, directly acknowledge the need for transparent decision-making in adaptive systems \\cite{tam2024a1h}.\n\nBeyond these, the **potential for misuse** of highly adaptable meta-learning technologies is a critical concern. The ability of meta-learning to enable rapid learning from few examples \\cite{sung2017nc5, li2023zn0, wang2024dai} is a double-edged sword. While beneficial for legitimate applications like few-shot malware classification \\cite{li20246zp, wang2023kho} or medical diagnosis, this same capability could be exploited for malicious purposes, such as rapidly deploying surveillance systems for new targets, generating targeted disinformation, or developing more evasive adversarial agents. The power of domain generalization \\cite{khoee2024ksk} and cross-domain transfer learning \\cite{jang2019a48, chai2022kv5, liang2021juf, cheng2024mky} means models can be trained on one dataset and quickly adapted to another, potentially enabling malicious actors to bypass security measures or adapt to new adversarial environments more rapidly. Even privacy-preserving paradigms like federated meta-learning \\cite{you2024xuq, liu2024jz5, qu2022mu6}, designed to keep data localized, could introduce new privacy risks if the meta-learning process itself is compromised or if the aggregated meta-knowledge inadvertently reveals sensitive information.\n\nIn conclusion, while meta-learning promises to unlock unprecedented levels of AI adaptability and efficiency, its ethical implications demand proactive attention. The inherent risks of bias amplification, the complexities of ensuring accountability in highly adaptive systems, and the potential for misuse underscore the urgent need for responsible development, transparent deployment, and robust regulatory frameworks. Future research must not only focus on advancing algorithmic performance but also prioritize the integration of fairness-aware designs, enhanced interpretability, and provable safety guarantees into meta-learning architectures to ensure that these powerful advancements contribute positively to society while mitigating their inherent risks.\n\\subsection{Emerging Trends and Hybrid Approaches}\n\\label{sec:7_3_emerging_trends__and__hybrid_approaches}\n\n\nThe trajectory of deep meta-learning is increasingly defined by a concerted effort to transcend isolated paradigms, fostering integrated, hybrid approaches that draw strength from diverse methodologies to develop more robust, efficient, and truly generalizable adaptive AI systems \\cite{hospedales2020m37}. This subsection delineates promising future research directions, emphasizing the growing interest in combining different meta-learning methodologies, the continued exploration of biologically inspired mechanisms, and the expansion into novel, high-impact applications.\n\nA significant emerging trend involves the explicit hybridization of meta-learning paradigms, moving beyond single-paradigm solutions to leverage complementary strengths. For instance, the integration of probabilistic modeling with optimization-based or metric-based insights is enhancing task inference and efficient exploration. While foundational probabilistic meta-RL methods like VariBAD \\cite{zintgraf2019zat} and PEARL \\cite{rakelly2019m09} have been instrumental in learning Bayes-adaptive policies and improving sample efficiency (as discussed in Section 5.2), their future lies in deeper integration with other meta-learning types. This includes approaches that use optimization to refine probabilistic models or metric learning. For example, \\cite{tseng2020m83} proposed Gradient Dropout, an optimization-based regularization technique for gradient-based meta-learning that mitigates overfitting by randomly dropping gradients during inner-loop adaptation, thereby improving generalization, particularly when combined with other meta-learning strategies. Furthermore, meta-learning is increasingly applied to refine metric learning itself, as demonstrated by \\cite{chen2019oep}'s Deep Meta Metric Learning (DMML) for learning set-based distances, \\cite{zheng20200ig}'s DML-ALA for adaptive learnable assessment, and \\cite{jiang20220tg}'s MMSI for meta-mining strategies with semiglobal information. These works exemplify hybrid approaches where a meta-learner (often optimization-based) is employed to discover more robust and generalizable similarity measures, thereby enhancing the performance of metric-based systems. This synergistic combination aims to create systems that not only adapt quickly but also quantify uncertainty and make more informed decisions.\n\nAnother prominent direction focuses on learning adaptive algorithms and architectures, often drawing inspiration from biological systems or employing meta-gradients to discover optimal learning processes. The concept of \"learning to learn\" extends to learning the very algorithms that govern adaptation, a powerful idea with roots in early work showing recurrent neural networks (RNNs) could implicitly learn reinforcement learning algorithms \\cite{wang20167px}. This has evolved into the field of meta-gradients, where gradients are computed through the learning process itself to optimize meta-parameters \\cite{sutton2022jss}. For instance, \\cite{xu2020txy} proposed FRODO, an algorithm that uses meta-gradient descent to discover its own RL objective function online by parameterizing the update target with a neural network, moving beyond handcrafted objectives. Theoretically, gradient-based meta-learning, such as MAML, has been shown to possess universal approximation capabilities for learning algorithms, suggesting its potential to discover highly effective learning strategies \\cite{finn2017vrt}. Biologically inspired mechanisms offer another avenue for adaptive architectures. Directly inspired by cellular neuromodulation, \\cite{vecoven2018hc1} introduced Neuro-Modulated Networks (NMNs), where a neuromodulatory network dynamically tunes the activation function parameters of a main network, leading to faster and more stable adaptive behaviors. Similarly, \\cite{fernando2018lt5} explored meta-learning by the Baldwin effect, demonstrating its capability to evolve few-shot supervised and reinforcement learning mechanisms by shaping hyperparameters and initial parameters without requiring backpropagation through meta-parameters. These approaches collectively aim to imbue AI systems with intrinsic, flexible adaptation capabilities, moving towards more autonomous and robust learning.\n\nThese emerging trends are paving the way for novel applications in complex real-world domains, pushing the boundaries of what adaptive AI can achieve. In scientific discovery, meta-learning holds immense promise for accelerating research by enabling models to generalize from limited, heterogeneous data. For example, \\cite{ruwurm2024806} introduced METEOR, a meta-learning methodology for Earth observation problems that adapts to diverse tasks and resolutions, using knowledge from global land cover information to perform well on new, unseen geospatial problems with few labels. This demonstrates meta-learning's capacity to extract generalizable insights from vast, varied datasets and apply them to specific, data-scarce scientific challenges. Another critical area is personalized medicine, where meta-learning's ability to adapt to individual patient data, handle data scarcity, and account for heterogeneity is invaluable for tasks like drug discovery, personalized diagnostics, and treatment optimization. While direct citations of meta-learning in personalized medicine are still emerging, the principles demonstrated in personalized robotics \\cite{yu2018nm7} and adaptive control systems \\cite{wang2020tae, ma20243e9, visca20217nt} strongly suggest its imminent impact. Furthermore, meta-learning is crucial for enhancing the adaptability of large pre-trained models in complex scenarios, such as class incremental learning in NLP \\cite{kumar2024he9, lee2021jou}, where it enables models to efficiently learn new classes without catastrophic forgetting or extensive retraining. The ability to rapidly adapt to new environments and tasks, as seen in meta-RL for robotics and control, and for resource management, underscores its potential to tackle dynamic and non-stationary real-world challenges.\n\nIn conclusion, the future of deep meta-learning is marked by a concerted effort to move beyond isolated paradigms towards integrated, hybrid approaches that draw strength from diverse methodologies. The increasing sophistication of probabilistic modeling, the ambition to learn the very algorithms and architectures of adaptation, and the expansion into complex real-world applications like scientific discovery and personalized medicine collectively underscore a vision for truly adaptive and generalizable AI. While significant progress has been made in enhancing robustness, efficiency, and generalization, challenges remain in scaling these hybrid systems to even greater complexity, ensuring stronger theoretical guarantees for learned objectives \\cite{chen2021j5t}, and developing robust generalization mechanisms across vastly different task distributions. Addressing these frontiers will be crucial for the field's continued evolution towards more versatile and impactful adaptive AI systems.\n",
    "Conclusion": "\\section{Conclusion}\n\\label{sec:conclusion}\n\n\n\n"
  },
  "subsections": {
    "Defining Deep Meta-Learning: Learning to Learn": "\\subsection{Defining Deep Meta-Learning: Learning to Learn}\n\nDeep meta-learning represents a transformative paradigm designed to overcome fundamental limitations inherent in conventional deep learning, particularly its pronounced reliance on vast quantities of task-specific data and its struggles with robust generalization to novel, unseen tasks. At its core, meta-learning, frequently encapsulated by the phrase \"learning to learn,\" is the sophisticated process of acquiring an inductive bias or an explicit algorithm that empowers a base model to rapidly assimilate new skills or adapt to novel tasks with minimal data \\cite{hospedales2020m37, son2023lda}. This approach directly confronts scenarios where traditional deep learning models, after being trained on a fixed dataset, often exhibit poor performance when confronted with new data distributions or task specifications, highlighting a critical gap in their adaptive intelligence \\cite{hospedales2020m37}.\n\nThe operational framework of deep meta-learning is systematically structured into two distinct and sequential phases: meta-training and meta-testing. During the **meta-training phase**, the meta-learner is exposed to a diverse distribution of related tasks. The primary objective here is not to achieve optimal performance on any single task, but rather to learn a transferable skill or a generalizable strategy for efficient learning across these tasks. This learned strategy might manifest as an effective initialization for model parameters, an adaptive update rule, or a robust mechanism for feature extraction. Subsequently, in the **meta-testing phase**, these acquired adaptive capabilities are deployed for rapid adaptation to truly novel tasks, often with only a handful of labeled examples—a scenario commonly referred to as few-shot learning. The efficacy of meta-learning is critically assessed by how swiftly and effectively the meta-learner can adapt to these new, unseen tasks, thereby demonstrating its acquired \"learning to learn\" proficiency \\cite{hospedales2020m37, son2023lda}.\n\nThe \"inductive bias\" or \"explicit algorithm\" learned by the meta-learner is crucial for this rapid adaptation. In this context, an inductive bias refers to the set of assumptions or preferences that a learning algorithm uses to generalize from limited training data. For meta-learning, this bias is itself learned from experience across multiple tasks. It can take various forms: a set of initial parameters that are optimally poised for fine-tuning on new tasks, a learned optimization procedure that dictates how a base model's parameters should be updated, a sophisticated metric function for comparing data points in an embedding space, or even an architectural design that incorporates external memory mechanisms for efficient information storage and retrieval \\cite{hospedales2020m37}. This concept builds upon earlier ideas in machine learning, where the goal was to automatically find good choices for \"meta-parameters\" (e.g., learning rates, initial weights) that govern a base learning system, as highlighted by the historical development of \"meta-gradient\" methods \\cite{sutton2022jss}. The essence is to generalize the *learning process itself*, rather than just the solution to a specific task.\n\nThe \"deep\" aspect of deep meta-learning signifies the integration of these meta-learning principles with powerful deep neural network architectures. Deep learning provides the robust representation learning capabilities necessary to extract meaningful, high-level features from complex, high-dimensional data. This synergy allows meta-learners to operate effectively on raw inputs, such as images, text, or sensor data, enabling the \"learning to learn\" process to be applied to real-world, intricate problems. By leveraging deep neural networks, meta-learning can discover more sophisticated and flexible inductive biases, making the adaptive process more powerful and scalable than traditional meta-learning approaches \\cite{hospedales2020m37}.\n\nTo illustrate this framework, consider a canonical example: N-way, K-shot classification. In this setting, the meta-learner is trained to classify N novel classes, given only K examples per class. During meta-training, the system is presented with numerous distinct N-way, K-shot tasks, each drawn from a distribution of related classification problems (e.g., classifying different sets of N animal species with K images each). The meta-learner learns a strategy that allows it to quickly adapt to these varying tasks. Subsequently, during meta-testing, the system is confronted with a *completely new* N-way, K-shot task involving N *unseen* classes (e.g., classifying N entirely new animal species with K examples). Its success is measured by how effectively and rapidly it can classify instances from these novel classes, demonstrating its ability to generalize the *learning process* rather than merely memorizing class-specific features.\n\nIn conclusion, deep meta-learning fundamentally redefines how AI systems acquire knowledge, shifting from a narrow, task-specific learning paradigm to a more generalizable process of \"learning to learn.\" This core principle, instantiated through the distinct meta-training and meta-testing phases, has proven instrumental in addressing the critical data efficiency and generalization challenges that often plague conventional deep learning. This paradigm is realized through diverse methodological families—optimization-based, metric-based, and model-based approaches—which will be systematically explored in the subsequent sections, alongside their applications and challenges.",
    "Historical Context and Evolution of the Field": "\\subsection{Historical Context and Evolution of the Field}\n\nThe intellectual lineage of meta-learning, often encapsulated as \"learning to learn,\" reflects a persistent ambition in artificial intelligence: to create systems capable of rapid adaptation and robust generalization, akin to human cognitive flexibility. This pursuit has unfolded through distinct intellectual phases, from early theoretical explorations to its contemporary prominence, profoundly shaped by the advent and integration of powerful deep neural network architectures \\cite{hospedales2020m37, peng20209of}.\n\nThe foundational concepts of meta-learning emerged well before the deep learning era, driven by the desire to automate and optimize the learning process itself. In the 1980s and 1990s, researchers explored ideas such as hyperparameter optimization and the notion of \"learning optimizers.\" A significant conceptual precursor involved meta-gradient methods, pioneered by Schmidhuber and colleagues, which aimed to learn internal learning rates or even entire optimization algorithms through gradient descent on the learning process \\cite{sutton2022jss}. These early efforts, though often constrained by computational limitations and the expressiveness of available models, established the crucial principle: that a system could acquire an inductive bias or an explicit algorithm to enhance its future learning efficiency. Concurrently, influences from cognitive science, such as the Baldwin effect, provided a biological analogy, suggesting how individual learning could shape the evolution of innate learning biases across generations \\cite{fernando2018lt5}. This period laid the theoretical groundwork, emphasizing the potential for higher-order learning to improve base-level task acquisition, even if practical implementations were nascent.\n\nThe mid-2010s marked a dramatic resurgence and acceleration of meta-learning research, primarily catalyzed by the transformative power of deep learning. Deep neural networks provided the scalable and expressive function approximators necessary to realize complex meta-learning concepts that were previously computationally intractable \\cite{hospedales2020m37}. This period witnessed a \"Cambrian explosion\" of diverse meta-learning paradigms, each offering a distinct philosophical approach to the \"learning to learn\" challenge.\n\nOne early intellectual shift focused on endowing neural networks with explicit memory, addressing the need for models to quickly store and retrieve task-specific information for one-shot learning. This led to the development of model-based approaches, exemplified by Memory-Augmented Neural Networks (MANN) \\cite{Santoro2016}. The motivation here was to move beyond implicit parameter adaptation to architectures that could intrinsically adapt by processing and recalling relevant contextual data, a concept further explored in Section 4.2.\n\nParallel to this, the metric-based meta-learning paradigm gained traction, driven by the challenge of few-shot classification where models must generalize from minimal examples. The core intellectual contribution was the realization that learning a robust, transferable similarity function within an embedding space could enable effective comparison and classification of novel instances. This philosophy was embodied by seminal works such as Matching Networks \\cite{Vinyals2016}, Prototypical Networks \\cite{Snell2017}, and Relation Networks \\cite{sung2017nc5}. These approaches collectively demonstrated the power of learning discriminative feature spaces that facilitate rapid generalization by measuring relationships between examples, as further detailed in Section 4.1. The strength of these methods lay in their intuitive geometric interpretation and relative simplicity for specific tasks, but they often lacked the dynamic adaptability required for more complex, sequential learning scenarios.\n\nPerhaps the most impactful intellectual shift for the field's contemporary trajectory was the widespread adoption of gradient-based meta-learning. This paradigm directly built upon the early meta-gradient ideas, now leveraging the full differentiability of deep neural networks to optimize the *process* of learning itself \\cite{sutton2022jss}. The central insight was to reframe meta-learning as finding an optimal initialization or an efficient update rule that would enable a base model to rapidly adapt to new tasks with minimal gradient steps. Model-Agnostic Meta-Learning (MAML) \\cite{Finn2017} was a pivotal contribution, demonstrating how to learn an initial set of parameters that are highly amenable to rapid fine-tuning across a distribution of tasks. MAML's model-agnostic nature and its broad applicability across various deep learning architectures made it a cornerstone, fundamentally changing how researchers approached meta-learning by framing it within a bilevel optimization framework \\cite{franceschi2018u1q}. This success spurred further research into explicitly \"learning the optimizer,\" with approaches like Meta-Learner LSTMs \\cite{Ravi2017} and Meta-SGD \\cite{Li2017} aiming to meta-learn more flexible and adaptive update rules (discussed in Section 3.2). Concurrently, theoretical understanding of these methods deepened, with work exploring generalization bounds for MAML, offering insights into *why* these algorithms perform effectively in few-shot settings \\cite{chen2021j5t}.\n\nBeyond these core paradigms, the field continued to diversify. The integration of meta-learning with deep reinforcement learning (Meta-RL) addressed the notorious sample inefficiency and generalization challenges in dynamic environments, enabling agents to rapidly acquire new skills \\cite{wang20167px}. This extension, explored in Section 5.1, highlighted meta-learning's capacity to learn transferable behaviors. More recently, probabilistic meta-learning, exemplified by Conditional Neural Processes (CNP) \\cite{Garnelo2018}, emerged to model distributions over functions and quantify uncertainty, offering robust decision-making capabilities crucial for real-world applications (further discussed in Sections 4.3 and 5.2). The expanding scope of \"learning to learn\" also saw meta-learning applied to fundamental components like loss functions \\cite{raymond202441h}.\n\nIn summary, the evolution of meta-learning has been a dynamic interplay of ambitious theoretical concepts and the enabling power of deep learning. From early, computationally limited attempts to optimize learning processes to the sophisticated, deep neural network-driven paradigms of today, the field has consistently pushed the boundaries of generalization and adaptation. This progression, marked by distinct intellectual shifts towards memory-augmented, metric-based, and especially gradient-based approaches, has transformed meta-learning into a powerful framework for tackling data scarcity, non-stationarity, and complex decision-making, thereby setting a robust stage for understanding its current trajectory and future potential.",
    "Few-Shot Learning: The Prototypical Challenge": "\\subsection{Few-Shot Learning: The Prototypical Challenge}\n\nFew-shot learning (FSL) represents a quintessential and pervasive challenge for deep learning, demanding that models generalize effectively to novel classes or tasks when presented with only a handful of labeled examples \\cite{huisman2020b7w, hospedales2020m37}. This scenario directly confronts the data-hungry nature of conventional deep learning models, which typically require vast amounts of annotated data to achieve robust performance. The prevalence of FSL is not merely an academic concern but a critical reality in numerous real-world applications where data annotation is prohibitively expensive, new categories emerge frequently, or data privacy concerns limit large-scale collection. Illustrative examples span diverse domains, including the medical diagnosis of rare diseases where labeled instances are inherently scarce, identifying emerging cyber threats like zero-day malware with minimal prior examples \\cite{li20246zp}, or enabling robotic systems to acquire complex new skills from a single visual demonstration \\cite{finn20174c4}. The inherent scarcity of data in such contexts establishes FSL as a primary driver for the development of meta-learning research.\n\nFormally, a few-shot learning task is typically defined within an N-way K-shot classification paradigm \\cite{son2023lda}. In this setup, a model is presented with a \"support set\" ($S$) containing $N$ novel classes, with $K$ labeled examples for each class. The goal is then to accurately classify instances in a \"query set\" ($Q$), which consists of unlabeled examples from these same $N$ novel classes. The meta-learning framework addresses this by employing an \"episodic training\" strategy. During the meta-training phase, the meta-learner is exposed to a large number of distinct FSL tasks, sampled from a distribution of related \"base\" tasks. Each meta-training episode simulates a few-shot scenario, allowing the model to learn how to rapidly adapt. In the subsequent meta-testing phase, the meta-learner is evaluated on truly novel tasks, drawn from a different set of classes unseen during meta-training, assessing its ability to quickly generalize with only the few examples provided in the support set of each new task \\cite{son2023lda}.\n\nMeta-learning offers a powerful framework to overcome the fundamental data scarcity inherent in FSL by leveraging prior experience from a distribution of related tasks \\cite{huisman2020b7w}. Instead of learning a single task from scratch, a meta-learner acquires an inductive bias or an explicit adaptation strategy that enables it to quickly form robust representations or adaptation rules for novel tasks. This \"learning to learn\" paradigm is crucial because traditional deep learning models, when faced with only a few examples, are highly susceptible to overfitting or simply failing to learn any meaningful features. Meta-learning mitigates this by training a model to become an efficient learner itself, rather than just a task-specific performer. These meta-learning strategies broadly fall into distinct categories, such as optimization-based, metric-based, and model-based approaches, which will be explored in detail in Sections 3 and 4.\n\nDespite the promise of meta-learning, FSL presents several persistent challenges that continue to drive research. One significant hurdle is the problem of generalization across diverse tasks, particularly when there are shifts in the underlying data distribution. For instance, cross-domain few-shot learning, where new tasks originate from domains unseen during meta-training, poses a formidable challenge to existing meta-learning methods, often leading to vulnerable generalization \\cite{tian2023iyh}. Furthermore, the fundamental generalization capabilities of meta-learning algorithms themselves are under scrutiny, with studies highlighting issues of underfitting or overfitting depending on task complexity, revealing a gap between theoretical expectations and practical performance \\cite{wang2024bhk}. Within metric-based FSL, which relies on learned embedding spaces, the \"hubness problem\" can arise, where certain class prototypes become the nearest neighbor for many test instances regardless of their true class, hindering classification accuracy \\cite{fei20211x6}. Addressing these challenges necessitates stronger theoretical guarantees for generalization, moving beyond empirical observations to provide a deeper understanding of why and when meta-learning succeeds in data-scarce scenarios \\cite{chen2021j5t}.\n\nThe principles of few-shot learning extend beyond supervised classification, serving as a critical driver for meta-learning research in other domains where rapid adaptation from limited experience is vital. In reinforcement learning, for example, the challenge of learning new policies with minimal interactions—often termed few-shot reinforcement learning—has led to seminal works exploring how agents can implicitly learn an RL algorithm \\cite{wang20167px} or acquire new skills from a single demonstration in one-shot visual imitation learning \\cite{finn20174c4}. The practical impact of FSL is also evident in diverse real-world applications, such as robust and interpretable EMG-based hand gesture recognition \\cite{tam2024a1h} and few-shot Android malware classification \\cite{li20246zp}, where the combination of data scarcity and the imperative for rapid adaptation makes FSL a central problem.\n\nIn conclusion, few-shot learning remains a cornerstone challenge that fundamentally shapes and propels innovation in meta-learning. It highlights the limitations of traditional deep learning in data-scarce environments and underscores the necessity for models that can \"learn to learn.\" While meta-learning provides a powerful conceptual and algorithmic framework, ongoing research continues to address critical issues such as improving robustness to domain shifts, mitigating underfitting and overfitting across heterogeneous tasks, and developing more unified theoretical understandings to ensure reliable and efficient generalization in the face of limited data.",
    "Meta-Reinforcement Learning: Adapting in Dynamic Environments": "\\subsection*{Meta-Reinforcement Learning: Adapting in Dynamic Environments}\n\nMeta-Reinforcement Learning (Meta-RL) represents a critical extension of meta-learning principles to the domain of reinforcement learning (RL), addressing fundamental limitations of traditional RL in dynamic and diverse environments. At its core, Meta-RL aims to enable an agent to \"learn to learn\" new behaviors, allowing it to rapidly adapt its policy to novel, unseen tasks within a family of related tasks \\cite{beck2023x24}. This paradigm is crucial for developing intelligent agents that can operate effectively in complex, real-world scenarios characterized by evolving objectives, changing dynamics, and sparse rewards, where learning from scratch for each new task is prohibitively inefficient.\n\nThe foundational problem setting for Meta-RL involves a distribution over Markov Decision Processes (MDPs), denoted as $p(\\mathcal{M})$. Each task $\\mathcal{T}_i$ is an instance of an MDP $\\mathcal{M}_i = (\\mathcal{S}, \\mathcal{A}, \\mathcal{P}_i, \\mathcal{R}_i, \\gamma)$, where $\\mathcal{S}$ is the state space, $\\mathcal{A}$ is the action space, $\\mathcal{P}_i$ is the task-specific transition function, $\\mathcal{R}_i$ is the task-specific reward function, and $\\gamma$ is the discount factor. The objective of a meta-RL agent is to learn an adaptation procedure or a meta-policy that, after observing a small amount of interaction data (e.g., a few trajectories) from a *new*, unseen task $\\mathcal{M}_{\\text{new}} \\sim p(\\mathcal{M})$, can quickly infer the task's specifics and derive an effective policy for it \\cite{beck2023x24}. This process typically involves a meta-training phase, where the agent learns its adaptive capabilities across a diverse set of tasks from $p(\\mathcal{M})$, and a meta-testing phase, where these learned abilities are deployed for fast adaptation to truly novel tasks.\n\nMeta-RL directly confronts several notorious challenges in traditional RL. Firstly, **sample efficiency** is a primary concern. Standard deep RL algorithms often require millions of environmental interactions to learn a single task, making them impractical for real-world deployment where data collection is costly or time-consuming. By leveraging prior experience from a distribution of related tasks, Meta-RL aims to drastically reduce the amount of new data needed for effective learning on a novel task. Secondly, **generalization** is enhanced. Policies learned for one specific task often fail to generalize to even slightly different tasks. Meta-RL fosters the acquisition of transferable skills or meta-knowledge that allows agents to generalize their learning process, rather than just their policy, across a spectrum of tasks. This means the agent learns *how* to learn, rather than just *what* to do.\n\nThe mechanisms through which meta-learning facilitates this rapid adaptation in RL are diverse, but they generally fall into categories that aim to either learn an efficient adaptation process or infer task-specific context. For instance, some approaches focus on learning an effective *initialization* for a policy that can be quickly fine-tuned with a few gradient steps on a new task. Others aim to learn *contextual representations* of tasks, where an encoder processes initial experience to infer latent variables that characterize the current task, which then guide the policy. A third category involves learning *implicit learning algorithms* through recurrent architectures, where the network's internal state acts as a memory of past interactions, allowing it to adapt its behavior over time within a single episode \\cite{finn2017vrt, wang20167px}. These high-level strategies enable agents to quickly infer task dynamics, reward functions, or optimal behaviors from minimal interaction, thereby accelerating learning and improving robustness.\n\nA critical aspect of Meta-RL is the challenge of **efficient exploration** in new, unknown tasks. When an agent encounters a novel MDP, it must explore to gather information about its dynamics and rewards before it can exploit optimal actions. Meta-RL approaches often incorporate mechanisms for Bayes-adaptive exploration, where the agent actively seeks to reduce its uncertainty about the current task's identity, leading to more structured and efficient data collection \\cite{zintgraf2019zat, rakelly2019m09}. This is particularly vital in environments with sparse rewards, where random exploration is unlikely to yield meaningful learning signals. Furthermore, the problem of learning from static, **offline datasets** introduces additional complexities, such as \"MDP ambiguity,\" where the available data may not be sufficient to distinguish between different underlying tasks, posing significant challenges for learning effective meta-exploration strategies \\cite{dorfman2020mgv}.\n\nIn summary, Meta-RL is a powerful paradigm for developing agents that are not only proficient at specific tasks but also possess the meta-skill to rapidly acquire new capabilities. By addressing the core challenges of sample efficiency, generalization, and efficient exploration within dynamic and uncertain environments, Meta-RL paves the way for more robust, autonomous, and adaptable AI systems capable of operating in complex real-world scenarios. The subsequent sections will delve into the specific methodologies that realize these adaptive capabilities, categorizing them by their underlying principles.",
    "Core Paradigms: Optimization, Metric, and Model-Based Approaches": "\\subsection{Core Paradigms: Optimization, Metric, and Model-Based Approaches}\n\nDeep meta-learning methodologies are broadly categorized into three fundamental paradigms: optimization-based, metric-based, and model-based approaches \\cite{hospedales2020m37}. Each paradigm offers a distinct conceptual framework and set of mechanisms to enable models to \"learn to learn,\" addressing the challenge of rapid adaptation and generalization to novel tasks with limited data. This section provides a high-level overview of these core paradigms, highlighting their fundamental differences and inherent strengths, thereby setting the stage for their detailed exploration in subsequent sections.\n\n**Optimization-based meta-learning** focuses on learning effective initializations or update rules that enable a base model to quickly adapt to new tasks through a few gradient steps. The core idea is to train a meta-learner to produce parameters or an optimization strategy that is highly amenable to rapid fine-tuning on unseen tasks \\cite{sutton2022jss}. This often involves a bi-level optimization process, where an inner loop performs task-specific adaptation, and an outer loop optimizes the meta-parameters (e.g., initial weights) across a distribution of tasks. The seminal Model-Agnostic Meta-Learning (MAML) \\cite{Finn2017} exemplifies this by seeking an initial parameter set that can be quickly adapted to any new task using standard gradient descent. While MAML offers broad applicability due to its model-agnostic nature, it often entails computational challenges related to second-order gradients and can be sensitive to hyperparameter choices. Subsequent research has explored learning the optimizer itself, such as with Meta-Learner LSTMs \\cite{Ravi2017} and Meta-SGD \\cite{Li2017}, which learn explicit update rules or adaptive learning rates. More advanced techniques, like HyperMAML \\cite{przewiezlikowski2022d4y}, replace gradient-based inner loops with learned hypernetworks to generate weight updates, offering more flexible and efficient adaptation. Theoretical analyses, such as those exploring generalization bounds \\cite{chen2021j5t} or the surprising role of negative learning rates in meta-training \\cite{bernacchia20211r0}, continue to refine our understanding of this paradigm's mechanics and limitations. Optimization-based methods are powerful for their generality and ability to adapt complex deep learning models, but their effectiveness can be constrained by computational cost and the stability of the meta-optimization process.\n\n**Metric-based meta-learning** operates on the principle of learning robust similarity functions within embedding spaces. The goal is to transform raw input data into a feature space where examples from the same class are close together, and examples from different classes are far apart, regardless of whether these classes were seen during meta-training. This allows for efficient comparison and classification of novel examples with limited support data, typically through nearest-neighbor-like mechanisms. These methods learn an embedding network that maps inputs into a feature space where distances directly correspond to semantic similarity. Early approaches like Matching Networks \\cite{Vinyals2016} introduced attention mechanisms to dynamically weigh support examples, while Prototypical Networks \\cite{Snell2017} simplified this by representing each class with a single centroid (prototype) in the embedding space. A significant conceptual leap was made by Relation Networks \\cite{sung2017nc5}, which meta-learned a deep, non-linear 'relation function' to explicitly compute similarity scores between embedded query and support examples, moving beyond fixed distance metrics. The strength of metric-based approaches lies in their intuitive nature, interpretability (due to explicit comparisons), and efficiency for few-shot classification tasks. However, their applicability is often limited to tasks that can be effectively framed as similarity comparisons in a learned feature space, and their generalization capabilities can be sensitive to the quality and diversity of the learned embedding.\n\n**Model-based meta-learning** is distinguished by designing network architectures with intrinsic adaptation capabilities. Instead of learning an optimization process or a similarity function, these models are engineered to quickly integrate new task information directly into their internal state or memory, often without explicit gradient updates during adaptation. This paradigm seeks to build \"fast weights\" or memory mechanisms that can rapidly store and retrieve task-specific knowledge. Pioneering work in this area includes Memory-Augmented Neural Networks (MANN) \\cite{Santoro2016}, which leverage external memory modules (inspired by Neural Turing Machines) to store and retrieve task-relevant information for one-shot learning. Architectures like A Simple Neural Attentive Meta-Learner (SNAIL) \\cite{Mishra2018} further combine temporal convolutions and attention to process sequences of experience, enabling fast in-context learning. A distinct and powerful sub-area within model-based approaches is Neural Processes, beginning with Conditional Neural Processes (CNP) \\cite{Garnelo2018}. These models learn to map context sets to distributions over functions, providing not only predictions but also crucial uncertainty estimates, which is vital for robust decision-making. Model-based methods excel at complex sequential decision-making tasks and scenarios requiring explicit memory or uncertainty quantification. Their primary challenge often lies in the increased architectural complexity and the difficulty of designing general-purpose adaptive mechanisms that perform well across highly diverse task distributions.\n\nIn summary, these three paradigms offer distinct yet complementary strategies for tackling the 'learning to learn' challenge. Optimization-based methods provide broad applicability by learning how to adapt parameters, but can be computationally intensive and sensitive to meta-optimization dynamics. Metric-based approaches offer efficient few-shot classification by learning robust similarity measures, though their applicability is often constrained to comparison-based tasks. Model-based methods push towards more sophisticated in-context learning and probabilistic function approximation through architectural innovations, offering powerful adaptation but often at the cost of increased architectural complexity and dependence on specific designs. The ongoing research across these paradigms continues to explore the trade-offs between generalizability, computational efficiency, and the ability to provide meaningful uncertainty estimates across diverse and complex real-world tasks.",
    "Learning a Good Initialization: MAML and its Variants": "\\subsection{Learning a Good Initialization: MAML and its Variants}\n\nA fundamental challenge in few-shot learning is to enable models to rapidly adapt to new tasks with minimal labeled data. Optimization-based meta-learning addresses this by learning an effective initial set of model parameters that can be quickly fine-tuned for novel tasks.\n\nThe seminal work in this area is Model-Agnostic Meta-Learning (MAML) \\cite{Finn et al., 2017}, which proposes training a model's initial parameters such that a few gradient steps on a new task lead to significant performance improvement. MAML operates on a bi-level optimization structure: an inner loop performs task-specific adaptation by taking a few gradient steps on a support set, yielding adapted parameters. The outer loop then optimizes the initial parameters by evaluating the performance of these adapted parameters on a query set, using second-order gradients. This approach is inherently model-agnostic, meaning it can be applied to any model trained with gradient descent, making it broadly applicable across various deep learning architectures and tasks. While powerful for learning transferable knowledge, MAML's reliance on second-order derivatives can lead to substantial computational overhead and memory consumption, especially for large models, and it can be sensitive to hyperparameter choices.\n\nTo mitigate the computational burden associated with MAML's higher-order gradients, Reptile \\cite{Nichol2018} was introduced as a computationally more efficient first-order approximation. Reptile simplifies the meta-learning process by repeatedly training on a task for several gradient steps and then moving the meta-parameters (the initial parameters) towards the task-specific parameters obtained after adaptation. This update rule, $\\theta \\leftarrow \\theta + \\epsilon (\\phi - \\theta)$ where $\\phi$ are the task-adapted parameters, effectively approximates the MAML objective without explicitly computing second-order derivatives. This simplification significantly reduces the computational cost and memory footprint, allowing for greater scalability while maintaining competitive performance in many few-shot learning scenarios.\n\nFurther improving generalization and efficiency, particularly for complex models, is the Latent Embedding Optimization (LEO) framework \\cite{Rusu et al., 2018}. LEO builds upon the optimization-based paradigm by learning a low-dimensional latent embedding for the model parameters. Instead of optimizing directly in the high-dimensional parameter space, LEO performs the inner-loop adaptation (task-specific fine-tuning) within this more compact and efficient latent space. The adapted latent parameters are then decoded back to the original parameter space for inference. This strategy enhances robustness and scalability by operating in a learned, more meaningful representation, which can lead to better generalization and faster adaptation compared to direct optimization in the full parameter space.\n\nThe model-agnostic nature of MAML has enabled its application across diverse domains, demonstrating its practical utility. For instance, in few-shot Hyperspectral Image (HSI) classification, MAML, combined with regularized fine-tuning, has been successfully employed to overcome the challenge of limited labeled samples and facilitate effective cross-domain transfer learning \\cite{li2023fhe}. This application showcases MAML's ability to learn robust initializations that enable accurate classification even when only a handful of labeled examples are available for new HSI datasets, achieving high overall accuracy.\n\nIn conclusion, MAML and its variants represent a powerful paradigm within meta-learning, focusing on learning transferable initializations that enable rapid adaptation. While MAML laid the foundational groundwork with its bi-level optimization and model-agnosticism, its computational demands spurred the development of more efficient approximations like Reptile and advanced techniques like LEO, which optimize in learned latent spaces for improved generalization and efficiency. Despite these advancements, challenges persist in balancing computational cost, hyperparameter sensitivity, and ensuring robust generalization across highly diverse task distributions, pointing towards continued research in developing more robust and theoretically grounded optimization-based meta-learning algorithms.",
    "Learning the Optimizer: Meta-Learner LSTMs and Meta-SGD": "\\subsection*{Learning the Optimizer: Meta-Learner LSTMs and Meta-SGD}\n\nTranscending the paradigm of merely learning an effective initialization, a significant branch of meta-learning research focuses on explicitly learning the optimization process itself. This advanced approach frames meta-learning as the challenge of discovering an adaptive, data-driven optimization algorithm, offering greater flexibility and control over the learning process compared to relying on fixed, hand-designed optimizers. This subsection delves into two prominent methodologies within this domain: Meta-Learner LSTMs and Meta-SGD, which exemplify the quest to meta-learn the dynamics of parameter updates.\n\nOne pioneering approach in this direction is the Meta-Learner LSTM, introduced by \\cite{Ravi2017}. This method employs a recurrent neural network, specifically an LSTM, as the meta-learner to generate parameter updates for a base learner. The LSTM takes the base learner's gradients and previous internal states as input, and subsequently outputs the updates for each parameter, effectively learning a complex, stateful optimization algorithm. This allows the meta-learner to capture intricate dependencies and historical information during the inner-loop adaptation, moving beyond simple gradient descent to learn highly non-linear and context-dependent update rules. However, the inherent complexity of training such a meta-learner, which involves backpropagating through the unrolled optimization steps of the base learner, presents significant computational challenges and can lead to issues with training stability.\n\nBuilding upon the principles of gradient-based meta-learning, \\cite{Li2017} proposed Meta-SGD, an approach that extends the meta-learning objective to encompass more components of the optimization process. Unlike methods that primarily focus on learning a good initialization, Meta-SGD meta-learns not only initial parameters but also per-parameter learning rates and update directions for the inner-loop adaptation. This means that for each parameter of the base learner, the meta-learner learns how to scale and direct its gradient update, effectively transforming the standard gradient descent rule into a more adaptive, learned optimizer. By learning these fine-grained components, Meta-SGD provides a powerful mechanism for the base learner to adapt rapidly and efficiently to new tasks with only a few gradient steps, offering a more flexible and data-driven adaptation strategy than fixed learning rates.\n\nBoth Meta-Learner LSTMs and Meta-SGD represent a crucial shift in meta-learning, moving from static initializations to dynamic, learned optimization procedures. While \\cite{Ravi2017}'s Meta-Learner LSTM offers a highly flexible, black-box approach to learning an optimizer through its recurrent structure, it comes with the overhead of training a complex sequential model to generate updates. In contrast, \\cite{Li2017}'s Meta-SGD provides a more structured, yet equally adaptive, approach by directly learning the components of the gradient update rule, such as per-parameter learning rates and update directions. Both methods aim to imbue the base learner with the ability to \"learn how to learn\" by discovering an adaptive optimization algorithm from data, rather than relying on predefined heuristics.\n\nDespite their significant contributions to enabling more flexible and powerful adaptation, these sophisticated techniques introduce their own set of challenges. The increased complexity of the meta-learner and the meta-optimization objective can lead to higher computational demands and difficulties in ensuring stable and efficient training. Furthermore, the generalization capabilities of these learned optimizers to tasks significantly different from those seen during meta-training remain an active area of research. Future work will likely explore more efficient architectures for meta-optimizers, hybrid approaches that combine the strengths of explicit optimization learning with other meta-learning paradigms, and methods to improve the robustness and scalability of these adaptive learning algorithms to even broader and more diverse task distributions.",
    "Differentiable Solvers and Hypernetworks for Parameter Adaptation": "\\subsection{Differentiable Solvers and Hypernetworks for Parameter Adaptation}\n\nThe pursuit of highly flexible and rapid adaptation mechanisms in meta-learning has led to the exploration of advanced techniques that move beyond conventional gradient-based inner-loop optimization. This subsection delves into two prominent paradigms: leveraging differentiable closed-form solvers as base learners and employing hypernetworks to generate model parameters dynamically. These approaches enable meta-learners to optimize for rapid, interpretable adaptation tailored to specific problem structures, or to modulate entire network architectures based on task-specific information.\n\nOne significant direction involves integrating classical machine learning algorithms as differentiable components within a meta-learning framework. \\textcite{bertinetto2018ur2} pioneered this by proposing a meta-learning approach where the base learner is a differentiable closed-form solver, such as Ridge Regression. Their method meta-learns both a deep feature extractor and the hyperparameters of the base solver end-to-end, efficiently backpropagating through the solver's closed-form solution (e.g., using the Woodbury identity for speed) to enable rapid adaptation in few-shot classification tasks. This allows for data-dependent adaptation at test time, offering more flexibility than similarity-based methods while being computationally more efficient than gradient-based meta-learning for a few adaptation steps.\n\nBuilding upon the idea of meta-learning parameters for classical models, subsequent work has extended this to more complex scenarios. \\textcite{wistuba2021wha} introduced Few-Shot Bayesian Optimization (FSBO) by meta-learning deep kernel Gaussian Processes (GPs) as surrogate models for hyperparameter optimization. Here, the deep kernel parameters are learned across a distribution of tasks, allowing the classical GP model to rapidly adapt its predictions to new tasks with very few evaluations. Further refining this, \\textcite{chen2022z45} presented Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT) for molecular property prediction. This framework uses bilevel optimization to meta-learn feature extractor parameters while adapting base kernel parameters per task, leveraging the Implicit Function Theorem for exact hypergradient computation, thereby achieving a robust balance between generalization and task-specific adaptation for deep kernel GPs. In a related vein, \\textcite{lee2024snq} proposed Sequential Bayesian Meta-Continual Learning (SB-MCL), a biologically inspired framework that decouples deep representation learning from sequential knowledge integration. Here, neural networks are meta-learned to map complex data to a latent space suitable for simple statistical models, which then perform exact sequential Bayesian updates, effectively offloading continual learning to robust, forgetting-immune classical models.\n\nComplementing differentiable solvers, hypernetworks offer another powerful mechanism for flexible parameter adaptation. Instead of optimizing the parameters of a base learner, hypernetworks are neural networks that generate the weights or parameters of another 'main' network, conditioned on task-specific information. This provides a mechanism for dynamic architecture generation or flexible parameter modulation without explicit gradient-based inner loops. \\textcite{przewiezlikowski2022d4y} exemplify this with HyperMAML, which replaces MAML's gradient-based inner-loop adaptation with a trainable hypernetwork. The hypernetwork directly outputs weight updates for the base model based on support set embeddings and labels, enabling more substantial and flexible weight modifications in a single step, thereby offering a computationally efficient alternative to classical MAML.\n\nBeyond these direct applications, the broader theme of learning flexible adaptation mechanisms also encompasses biologically inspired approaches. \\textcite{lindsey202075a} explored Feedback and Local Plasticity (FLP), a meta-learning framework that learns biologically plausible local synaptic update rules and decoupled feedback weights for deep credit assignment. While not strictly a differentiable solver or hypernetwork, FLP meta-learns parameters (feedback weights, plasticity coefficients) that modulate the learning process itself, demonstrating how meta-learning can discover effective, local learning rules that excel in challenging scenarios like continual learning, often outperforming gradient-based meta-learners.\n\nIn summary, differentiable solvers and hypernetworks represent significant advancements in meta-learning, offering powerful alternatives to traditional gradient-based adaptation. Differentiable solvers provide interpretable and efficient adaptation by optimizing classical models, while hypernetworks enable dynamic parameter generation for flexible architectural and functional modulation. Biologically inspired approaches further expand this landscape by learning the very rules of adaptation. Despite these strides, challenges remain in scaling complex differentiable solvers to arbitrary models, ensuring the interpretability of hypernetwork-generated parameters, and fully understanding the theoretical underpinnings of learned, non-gradient-based adaptation rules. Future research may explore hybrid models that combine these strengths, or delve deeper into the biological plausibility and robustness of such learned adaptation mechanisms.",
    "Learning Similarity Measures: Matching, Prototypical, and Relation Networks": "\\subsection{Learning Similarity Measures: Matching, Prototypical, and Relation Networks}\n\nA distinct family of meta-learning approaches addresses few-shot classification by focusing on learning robust similarity measures within a discriminative embedding space. These methods aim to classify novel instances by comparing them directly to a small set of labeled support examples, thereby enabling accurate generalization from minimal data.\n\nPioneering this direction, Matching Networks \\cite{Vinyals2016} introduced an end-to-end differentiable framework that learns to map a small labeled support set and an unlabeled query to a classification. This is achieved through an attention-based comparison function, where the network dynamically weighs the contribution of each support example to classify the new instance, effectively performing a non-parametric classification in a learned feature space. While innovative, the direct comparison to every support example can be computationally intensive as the support set size grows.\n\nBuilding upon this foundation, Prototypical Networks \\cite{Snell2017} simplified the similarity learning paradigm by proposing that each class in a learned embedding space can be represented by a single \"prototype.\" This prototype is typically computed as the mean of the embedded support examples for that class. Classification of a new query instance then involves assigning it to the class whose prototype is closest in the embedding space, often using Euclidean distance. This approach offers improved computational efficiency and enhanced interpretability compared to Matching Networks, as class representations are explicitly defined, and it demonstrated competitive performance in few-shot classification tasks.\n\nFurther generalizing the concept of similarity, Relation Networks \\cite{Sung2018} moved beyond fixed distance metrics or attention mechanisms by learning a non-linear \"relation function\" to explicitly compute similarity scores. This network takes the concatenated embeddings of a query example and a support example (or a class prototype) as input and outputs a scalar score indicating their similarity. By learning this relation function, the model gains greater flexibility in defining what constitutes \"similarity,\" allowing for more complex and adaptive comparisons between embedded instances. This approach often leads to more robust similarity measures, especially when simple distance metrics might be insufficient.\n\nThe core ideas of these metric-based approaches continue to be extended and applied to more complex few-shot scenarios. For instance, the principles of Prototypical Networks have been adapted to tackle challenging tasks like few-shot cross-domain object detection. The Instance-level Prototype learning Network (IPNet) \\cite{zhang2024mf0} addresses data deficiency in target domains by fusing cropped instances from both source and target domains to learn representative prototypes for each class. These learned prototypes are then utilized to discriminate feature salience and facilitate domain alignment, demonstrating the adaptability of prototype-based methods beyond simple image classification to more intricate problems involving object localization and domain generalization.\n\nIn summary, Matching, Prototypical, and Relation Networks collectively represent a powerful family of meta-learning techniques that excel in few-shot classification by learning discriminative feature spaces and robust similarity measures. Their effectiveness stems from their intuitive comparison mechanisms, allowing accurate generalization from minimal examples. However, their primary limitation often lies in their task-specificity, as they are predominantly designed for classification tasks and might struggle to generalize to problems requiring complex structural changes or where a simple distance metric or learned relation function is insufficient for capturing task-specific nuances beyond feature comparison. Future research may explore hybrid approaches that combine the strengths of metric learning with other meta-learning paradigms to enhance their applicability to a broader range of tasks.",
    "Memory-Augmented Neural Networks for In-Context Learning": "\\subsection{Memory-Augmented Neural Networks for In-Context Learning}\n\nModel-based meta-learning approaches offer a distinct paradigm for achieving rapid, in-context adaptation by designing network architectures that intrinsically facilitate fast information integration and knowledge transfer. Unlike gradient-based methods that learn to optimize parameters or metric-based approaches that learn similarity functions, this category focuses on equipping neural networks with explicit mechanisms for storing and retrieving task-specific information, enabling one-shot learning without explicit gradient updates.\n\nA pioneering work in this domain is the Memory-Augmented Neural Network (MANN) proposed by \\cite{santoro2016323}. Inspired by Neural Turing Machines (NTMs), MANN augments a standard neural network with an external memory module, allowing the network to learn to store and retrieve task-relevant information through differentiable read and write operations. This architectural innovation enables the model to quickly adapt to new tasks by leveraging previously encountered experiences stored in its memory, effectively performing one-shot learning by recalling specific data points or features rather than re-optimizing its weights. The core contribution of MANN lies in demonstrating how an explicit memory component can mitigate catastrophic forgetting and facilitate rapid knowledge acquisition, allowing the network to learn an internal \"algorithm\" for fast information integration. However, the complexity of training such memory-augmented networks and the scalability of their memory access mechanisms can pose significant challenges, particularly for very large datasets or highly diverse tasks.\n\nBuilding upon the principles of in-context learning, the Simple Neural Attentive Meta-Learner (SNAIL) \\cite{mishra2018simple} offers an alternative architectural approach that integrates temporal convolutions and attention mechanisms. SNAIL processes sequences of experience (support set and query examples) through a combination of causal convolutions, which efficiently aggregate information from past steps in the sequence, and a task-specific attention mechanism, which allows the network to selectively focus on the most relevant information for the current prediction. This design enables SNAIL to learn an internal meta-learning algorithm that can rapidly adapt to new tasks by attending to and integrating information from the context set, all within a single forward pass without requiring explicit gradient updates during adaptation. By leveraging standard deep learning components like convolutions and attention, SNAIL provides a more streamlined and potentially more scalable architecture for in-context learning compared to the explicit memory controllers of MANN, while still achieving powerful meta-learning capabilities across various tasks.\n\nIn summary, memory-augmented and attention-based neural networks represent a powerful class of meta-learning models that achieve rapid, in-context adaptation through architectural design rather than explicit parameter optimization. While MANN \\cite{santoro2016323} introduced the foundational concept of external memory for one-shot learning, SNAIL \\cite{mishra2018simple} refined this idea by integrating temporal convolutions and attention for efficient sequential processing. These models excel at learning an intrinsic 'algorithm' for fast information integration, demonstrating how architectural innovation can intrinsically equip neural networks with powerful meta-learning capabilities. However, challenges remain in scaling these architectures to extremely complex tasks and ensuring efficient memory management or attention mechanisms without incurring prohibitive computational costs or architectural complexity. Future research may explore hybrid approaches that combine the strengths of these model-based methods with more efficient memory structures or integrate them with other meta-learning paradigms.",
    "Neural Processes: Probabilistic Function Approximation": "\\subsection{Neural Processes: Probabilistic Function Approximation}\n\nWithin the landscape of model-based meta-learning, Neural Processes (NPs) represent a distinct and powerful paradigm focused on probabilistic function approximation, drawing inspiration from the robustness of Gaussian Processes (GPs) while aiming for the scalability and flexibility of deep neural networks. Unlike traditional deep learning methods that yield point estimates, NPs learn to map context sets to distributions over functions, thereby providing not only predictions but also crucial quantification of predictive uncertainty. This capability is paramount for robust decision-making, active learning, and scenarios where confidence in predictions is as important as the predictions themselves, moving beyond deterministic outputs to a deeper understanding of the underlying data-generating process. NPs achieve this by amortizing inference over a distribution of tasks, learning a general mechanism to infer function properties from limited data.\n\nThe foundational work in this area is the Conditional Neural Process (CNP) \\cite{Garnelo2018}. CNPs introduced the concept of learning a distribution over functions by modeling conditional independence between target points given a context set. Specifically, a CNP employs a permutation-invariant encoder to aggregate information from observed context points (input-output pairs) into a global representation. This representation then parameterizes a simple, often factorized, Gaussian distribution over the target points. This allows the model to meta-learn in both regression and classification tasks while providing explicit uncertainty estimates, a significant advancement over prior deterministic meta-learning approaches. However, the strong conditional independence assumption in CNPs can lead to over-smoothed predictions, as it struggles to capture complex dependencies and multi-modalities inherent in intricate function structures.\n\nTo address the limitations of CNPs regarding expressiveness and the inability to capture dependencies between target points, the original Neural Process (NP) was subsequently introduced \\cite{Garnelo2018b}. This variant, sometimes referred to as Latent Neural Process, relaxes the strict conditional independence assumption by incorporating a global latent variable. The NP architecture includes two paths: a deterministic path similar to CNP, and a latent path where the encoder outputs parameters for a global latent distribution (e.g., a Gaussian). A latent variable is sampled from this distribution, which, along with the deterministic context representation, then informs the parameters of the predictive distribution. This latent variable acts as a global summary of the function's properties, enabling the model to capture richer function spaces and model dependencies between target points, thus mitigating the over-smoothing observed in standard CNPs.\n\nA further significant advancement in this lineage is the Attentive Neural Process (ANP) \\cite{Kim2019}. ANPs integrate self-attention mechanisms into the Neural Process framework, allowing the model to selectively weigh the importance of different context points when forming its representation. By employing an attention mechanism, ANPs can focus on the most relevant information within the context set, leading to more accurate predictions and better-calibrated uncertainty estimates. This selective attention mechanism significantly enhances the model's performance and flexibility, effectively tackling the over-smoothing issue more comprehensively than its predecessors by capturing fine-grained dependencies and local variations in the function, particularly beneficial for tasks with heterogeneous data distributions.\n\nWhile CNP, NP, and ANP primarily focus on standard regression and classification, Generalized Conditional Neural Processes (GCNP) \\cite{Requeima2019} extend the NP paradigm to handle structured data, such as graphs or meshes. GCNPs achieve this by integrating graph neural networks (GNNs) into the encoder architecture, allowing the model to leverage the underlying relational structure of the data when forming its context representation. This specialized extension demonstrates the versatility of the NP framework, adapting it to domains where explicit spatial or relational inductive biases are crucial. Another notable extension, Convolutional Conditional Neural Processes (ConvCNPs) \\cite{Gordon2019}, further enhances NPs by incorporating convolutional layers, which introduce spatial inductive biases and enable desirable equivariance properties, proving effective for image-based tasks.\n\nThe unique contribution of Neural Processes to probabilistic meta-learning lies in their ability to provide well-calibrated uncertainty estimates alongside predictions. This allows for more informed generalization, enabling applications such as active learning, where the model can query points where its uncertainty is high, or risk-aware decision-making, where the confidence in a prediction directly influences subsequent actions. Despite their strengths, NPs still face challenges. The permutation-invariant aggregation mechanism, while flexible, can act as an information bottleneck, potentially losing crucial structural information present in the context set. Furthermore, scaling NPs to very high-dimensional inputs or extremely large context sets can be computationally intensive. A persistent challenge across all probabilistic deep learning models, including NPs, is ensuring perfect calibration of uncertainty across diverse and potentially out-of-distribution tasks. As highlighted in recent critiques of other probabilistic deep learning approaches like Evidential Deep Learning \\cite{shen2024hea}, the reliability and faithful quantification of epistemic uncertainty remain non-trivial, often requiring careful architectural design and training objectives to avoid overconfidence or underestimation. Future work will likely focus on improving their computational efficiency, enhancing their expressiveness for highly complex functions by addressing the aggregation bottleneck, developing more principled methods for choosing the latent variable dimensionality, and refining uncertainty calibration techniques to ensure robustness and trustworthiness in real-world applications.",
    "Meta-Reinforcement Learning and Imitation Learning": "\\subsection{Meta-Reinforcement Learning and Imitation Learning}\nMeta-Reinforcement Learning (Meta-RL) and Meta-Imitation Learning (Meta-IL) represent a critical evolution in equipping agents with the ability to rapidly adapt to novel tasks and environments. These paradigms directly confront the notorious challenges of sample inefficiency and limited generalization inherent in traditional reinforcement learning (RL) and imitation learning (IL) by enabling agents to \"learn to learn\" across a distribution of related tasks \\cite{beck2023x24}. By acquiring a transferable skill or an efficient adaptation mechanism, meta-learning allows agents to quickly infer optimal behaviors, adapt to new reward functions, or acquire policies from minimal demonstrations, thereby accelerating learning and improving robustness in complex sequential decision-making scenarios.\n\nThe early trajectory of Meta-RL research explored implicit adaptation mechanisms, primarily leveraging Recurrent Neural Networks (RNNs). A seminal contribution by \\cite{wang20167px} demonstrated that an LSTM, when trained across a diverse set of tasks with past actions, rewards, and observations as inputs, could implicitly learn an internal RL algorithm. This recurrent architecture effectively encoded task-specific information within its hidden state, allowing it to adapt its policy to new tasks without requiring explicit weight updates, a process termed \"learning to reinforcement learn.\" While groundbreaking, this approach was initially demonstrated in simpler domains, raising questions about its scalability to complex, high-dimensional environments. Building on the concept of adaptive behaviors through architectural innovation, \\cite{vecoven2018hc1} introduced Neuro-Modulated Networks (NMNs). These networks employed a neuromodulatory sub-network to dynamically tune the activation function parameters of a main policy network, offering a more scalable solution than simply increasing network depth or width. NMNs achieved faster and more stable adaptive behaviors compared to standard RNNs, though their performance could be sensitive to the choice of activation functions. Further pushing the boundaries of implicit algorithmic learning, \\cite{xu2020txy} proposed FRODO, an algorithm that utilized meta-gradient descent to discover its own RL objective function online, parameterizing the update target with a neural network. This ambitious approach aimed to learn the very learning rule, but scaling such online objective learning to complex, real-world environments remains a significant practical challenge. These RNN-based methods, while powerful, often struggled with long-term credit assignment and the explicit representation of task uncertainty, paving the way for more explicit adaptation strategies \\cite{finn2017vrt, sutton2022jss}.\n\nA parallel and highly influential direction in meta-learning, particularly for rapid and explicit adaptation, emerged with gradient-based methods. Model-Agnostic Meta-Learning (MAML) \\cite{finn20174c4} proved instrumental in this regard, extending its bi-level optimization framework to both Meta-RL and Meta-IL. For Meta-RL, MAML learns an initialization that can be quickly fine-tuned with a few gradient steps on a new task, significantly improving sample efficiency compared to learning from scratch. In the realm of Meta-Imitation Learning (Meta-IL), \\cite{finn20174c4} pioneered one-shot visual imitation learning, enabling robots to acquire new skills from a single visual demonstration. This was a significant advancement, as it allowed end-to-end learning of visuomotor policies directly from raw pixel inputs, adapting via a few gradient updates. This approach addressed the critical data efficiency bottleneck in robotics, where collecting numerous demonstrations per task is often infeasible. However, a key challenge in imitation learning is the domain shift between human demonstrations and robot embodiments. \\cite{yu2018nm7} addressed this by leveraging meta-learning to build prior knowledge for cross-domain transfer, facilitating more robust one-shot imitation. While gradient-based methods like MAML offer strong generalization capabilities, they can be computationally intensive and susceptible to meta-overfitting, where the meta-learner performs well on meta-training tasks but struggles with truly novel task distributions \\cite{chen2021j5t}. To mitigate this, \\cite{tseng2020m83} proposed regularizing meta-learning via gradient dropout, a simple yet effective method to alleviate overfitting during the inner-loop adaptation, thereby enhancing generalization to new tasks. More recent work by \\cite{wang2024bhk} further investigates the underfitting/overfitting challenges in meta-learning, proposing a \"Task Relation Learner\" (TRLearner) to calibrate optimization by leveraging task similarities, which could be highly relevant for improving the robustness of gradient-based Meta-RL and Meta-IL.\n\nTo tackle increasingly complex and long-horizon tasks, meta-learning has also been integrated with hierarchical and skill-based approaches. These methods aim to decompose complex behaviors into reusable sub-skills, which can then be meta-learned and composed. \\cite{yang2018p36} proposed a hierarchical deep reinforcement learning algorithm that simultaneously learned basic and compound skills, utilizing two levels of hierarchy with a meta critic overseeing basic skills. Building on this, \\cite{xu2019brv} introduced Hierarchical Meta-Critic Networks for sample-efficient learning, providing transferable knowledge across tasks by sharing a global basic critic and a meta critic. This framework allowed for the distillation of meta-knowledge above the task level, enhancing adaptation. \\cite{lan20196o7} further improved generalization by proposing Meta-RL with Task Embedding and Shared Policy, explicitly capturing shared information across tasks and meta-learning how to quickly abstract task-specific information. More recently, \\cite{nam2022z75} devised a skill-based Meta-RL method that leverages prior experience extracted from offline datasets to learn reusable skills and meta-train a high-level policy. This enables efficient composition of learned skills into long-horizon behaviors, allowing for rapid adaptation to unseen target tasks with significantly fewer environment interactions.\n\nThe versatility of Meta-RL extends to various real-world applications, demonstrating its capacity for rapid adaptation in dynamic and resource-constrained settings. For instance, \\cite{wang2020tae} developed a fast adaptive task offloading method in edge computing based on Meta-RL, which can adapt quickly to new environments with minimal gradient updates and samples. In robotics, \\cite{visca20217nt} presented a deep meta-learning framework for energy-aware path planning for unmanned ground vehicles, allowing adaptation to unknown terrains. Furthermore, \\cite{ma20243e9} proposed a Graph Convolutional Network based Multi-Objective Meta-Deep Q-Learning (GM2DQL) method for eco-routing, demonstrating rapid adaptation to dynamic traffic conditions. Beyond efficiency, Meta-RL is also being extended to safety-critical domains. \\cite{khattar2024sr6} introduced a novel \"CMDP-within-online\" framework for Meta-Safe Reinforcement Learning, providing the first provable guarantees for task-averaged regret and constraint violations. This work is crucial for deploying RL agents in applications where both rapid adaptation and strict adherence to safety constraints are paramount. The integration of language instructions also shows promise, with \\cite{bing2022xo7} presenting a meta-RL algorithm that utilizes language to shape task interpretation in robotic manipulation, offering a more intuitive way to specify new tasks.\n\nIn conclusion, the field of Meta-Reinforcement Learning and Imitation Learning has undergone a significant evolution, moving from early demonstrations of implicit algorithmic learning within recurrent networks to sophisticated frameworks that explicitly optimize for adaptability and leverage hierarchical structures. While substantial progress has been made in addressing sample inefficiency and generalization, future research will likely focus on improving robustness to out-of-distribution tasks in dynamic environments, bridging the sim-to-real gap more effectively, and scaling to even more diverse and open-ended task distributions. The integration of meta-learning with other advanced learning paradigms, particularly for safety and human-robot interaction, will be crucial for achieving truly autonomous and adaptable AI agents capable of operating effectively in complex, real-world scenarios.",
    "Probabilistic Meta-Learning for Task Inference and Exploration": "\\subsection{Probabilistic Meta-Learning for Task Inference and Exploration}\n\nA critical challenge in meta-reinforcement learning (meta-RL) is the efficient adaptation to novel tasks, particularly in environments characterized by inherent uncertainty. Advanced probabilistic meta-learning frameworks explicitly address this by modeling task uncertainty, enabling more efficient exploration and the development of Bayes-adaptive policies. These policies condition actions not just on the current state, but also on the agent's evolving belief about the underlying task, leading to more robust and uncertainty-aware adaptation.\n\nA foundational contribution in this area is VariBAD (Variational Bayes-Adaptive Deep RL) by \\cite{zintgraf2019zat}. VariBAD meta-learns an approximate Bayes-adaptive policy by jointly training a Variational Auto-Encoder (VAE) for posterior inference over latent MDP embeddings and a policy conditioned on this belief. This approach allows the agent to perform principled online exploration by continuously updating its belief about the task as it interacts with the environment, demonstrating superior exploratory behavior compared to methods like posterior sampling in tasks such as Gridworld navigation \\cite{zintgraf2019zat}. However, VariBAD's reliance on on-policy experience during meta-training limited its sample efficiency, a common bottleneck in deep RL.\n\nTo address the sample inefficiency of on-policy meta-RL, \\cite{rakelly2019m09} introduced PEARL (Probabilistic Embeddings for Actor-Critic RL). PEARL is an off-policy meta-RL algorithm that leverages probabilistic context variables to encode task-specific information, conditioning the policy on this latent variable. A key innovation is its permutation-invariant encoder for task inference, which processes past experience to estimate the posterior over context variables, enabling significantly improved meta-training sample efficiency (20-100X) and structured exploration through posterior sampling. By decoupling the data used for policy training from that for encoder training, PEARL effectively integrates probabilistic task inference with off-policy actor-critic methods, achieving higher asymptotic performance on continuous control benchmarks \\cite{rakelly2019m09}.\n\nThe utility of probabilistic context variables extends beyond standard meta-RL to related problems like Inverse Reinforcement Learning (IRL). \\cite{yu2019o41} proposed PEMIRL (Probabilistic Embeddings for Meta-Inverse Reinforcement Learning), which adapts the probabilistic context variable paradigm to infer reward functions from few, unstructured, and heterogeneous demonstrations. PEMIRL integrates a deep latent variable model with maximum entropy IRL, utilizing mutual information regularization between the probabilistic context variable and trajectories to ensure the learned reward function effectively uses the inferred context. This enables few-shot reward inference for new tasks without requiring explicit task groupings or labels, a significant step towards more practical IRL applications \\cite{yu2019o41}.\n\nFurther pushing the boundaries of meta-learning under realistic constraints, \\cite{dorfman2020mgv} tackled the critical problem of Offline Meta-Reinforcement Learning with BOReL (Bayesian Offline Reinforcement Learning). BOReL is an off-policy VariBAD variant designed to learn exploration strategies from static, pre-collected datasets, rather than requiring active online data collection. This work formalizes the concept of \"MDP ambiguity,\" highlighting the inherent limitations of data identifiability when inferring task beliefs solely from offline data, and proposes strategies to mitigate it. BOReL demonstrates that effective meta-exploration can be learned from offline data, outperforming online baselines in some sparse reward tasks, which is crucial for applications where online interaction is costly or unsafe \\cite{dorfman2020mgv}.\n\nThe principles of Bayes-adaptive meta-learning continue to inspire advancements in specific applications and challenging environments. For instance, \\cite{zintgraf2021hoc} extended deep interactive Bayesian RL via meta-learning, enabling agents to learn about and adapt to other agents' unknown strategies in multi-agent settings by meta-learning approximate belief inference and Bayes-optimal behavior. Similarly, \\cite{bing2022om0} addressed meta-RL in non-stationary and dynamic environments by introducing a training strategy and task representation based on Gaussian mixture models, achieving zero-shot adaptation and competitive performance in changing conditions. More recently, \\cite{wang2024d09} proposed CBAMRL (Contrastive Learning-Based Bayes-Adaptive Meta-Reinforcement Learning) for active pantograph control in high-speed railways, employing a Bayes-adaptive strategy for zero-shot adaptation and a contrastive learning-based contextual encoder to represent complex task distributions, demonstrating rapid adaptation to unknown perturbations.\n\nIn conclusion, probabilistic meta-learning frameworks have significantly advanced the field by providing principled ways to model and leverage task uncertainty. From foundational methods like VariBAD to off-policy improvements in PEARL, extensions to Meta-IRL with PEMIRL, and the crucial offline learning capabilities of BOReL, these approaches enable more efficient exploration and robust adaptation in complex, partially observable environments. Despite these advancements, challenges remain in fully addressing MDP ambiguity in diverse offline datasets, scaling to extremely broad task distributions, and integrating these sophisticated probabilistic models with real-time, safety-critical applications while maintaining theoretical guarantees.",
    "Meta-Learning for Continual and Lifelong Adaptation": "\\subsection{Meta-Learning for Continual and Lifelong Adaptation}\nIntelligent agents operating in real-world environments face the fundamental challenge of continual and lifelong learning: they must adapt to non-stationary dynamics, sequentially encountered new tasks, and streaming data without succumbing to catastrophic forgetting \\cite{son2023lda}. This necessitates developing systems that can continuously learn and evolve over time, retaining previously acquired knowledge while rapidly integrating new information. Meta-learning offers a powerful paradigm to address these issues by enabling models to \"learn to learn\" robust, efficient, and lifelong adaptation mechanisms, thereby moving towards truly autonomous AI agents. This section critically examines how meta-learning approaches, often synergistically combined with other techniques, facilitate continuous learning, knowledge retention, and rapid integration of new information, focusing on the mechanisms that enable models to overcome the plasticity-stability dilemma inherent in lifelong adaptation.\n\nA primary challenge in continual learning is mitigating catastrophic forgetting, where acquiring new knowledge erodes previously learned skills. Meta-learning addresses this by learning how to adapt parameters or update rules in a way that preserves past knowledge while integrating new information. Architectural and biologically-inspired meta-learning approaches intrinsically manage the plasticity-stability dilemma through their design. For instance, Neuro-Modulated Networks (NMNs) \\cite{vecoven2018hc1} demonstrated that a neuromodulatory network could dynamically tune activation functions, leading to faster and more stable adaptive behaviors than standard recurrent neural networks. Similarly, Feedback and Local Plasticity (FLP) \\cite{lindsey202075a} introduced a meta-learning framework with decoupled feedback pathways and local synaptic plasticity rules, demonstrating superior performance in continual learning tasks and offering a universality proof for approximating any learning algorithm \\cite{finn2017vrt}. These models highlight the potential of architectural innovations to build in mechanisms for knowledge retention. More recently, Sequential Bayesian Meta-Continual Learning (SB-MCL) \\cite{lee2024snq} proposed a distinct framework that inherently prevents catastrophic forgetting by fixing neural network parameters during continual learning and offloading sequential updates to robust statistical models via meta-learned mappings. This approach decouples the expressive power of deep networks from the sequential update process, ensuring stability by leveraging the theoretical guarantees of Bayesian updates in exponential family distributions.\n\nOptimization-based meta-learning, particularly Model-Agnostic Meta-Learning (MAML) \\cite{finn20174c4}, has been instrumental in enabling rapid adaptation to new tasks by optimizing for a good initialization (as discussed in Section 3.1). However, its direct application to continual learning faces challenges such as meta-overfitting and insufficient weight modification in few gradient steps. To address these, various extensions have been proposed. \\cite{tseng2020m83} introduced gradient dropout regularization during the inner-loop optimization of gradient-based meta-learning to improve generalization to new tasks in a sequence. HyperMAML \\cite{przewiezlikowski2022d4y} replaced the gradient-based inner loop with a hypernetwork, allowing for more flexible and significant weight updates in a single step, which is crucial for adapting to diverse new tasks in a continual setting without repeated gradient computations. Furthermore, \\cite{wang2024bhk} introduced TRLearner, which uses task relation matrices and consistency regularization to mitigate underfitting and overfitting in MAML for continual adaptation. For class-incremental settings, iTAML \\cite{rajasegaran2020llk} developed an incremental task-agnostic meta-learning approach with a novel meta-update rule designed to maintain equilibrium across encountered tasks and effectively combat catastrophic forgetting. A distinct approach to learning the optimization process for continual learning was proposed by \\cite{vuorio2018gwb}, which meta-trains a neural network to predict parameter update steps that respect the importance of parameters to previous tasks, thereby directly learning to mitigate forgetting. These optimization-based methods collectively aim to learn *how to update* parameters to balance new learning with old knowledge retention, offering algorithmic solutions that complement architectural designs for stability.\n\nBeyond explicit parameter adaptation, meta-learning facilitates adaptation to non-stationary environments and dynamic task changes by learning more abstract adaptive strategies. As introduced in Section 5.1, early work by \\cite{wang20167px} demonstrated that recurrent neural networks could implicitly learn a reinforcement learning algorithm within their recurrent dynamics for rapid task adaptation. Building on the probabilistic meta-learning frameworks for task inference and exploration discussed in Section 5.2, these methods have been extended to address online adaptation and robust exploration in lifelong settings. VariBAD \\cite{zintgraf2019zat} and PEARL \\cite{rakelly2019m09} leverage probabilistic context variables and latent MDP embeddings to enable structured online exploration and improved sample efficiency, which are crucial for dynamic environments where task identity might be unknown or changing. BOReL \\cite{dorfman2020mgv} tackled Offline Meta-Reinforcement Learning, learning exploration from static datasets and mitigating \"MDP ambiguity,\" a critical challenge for lifelong learning from diverse, pre-recorded data sources. For non-stationary and dynamic environments, \\cite{bing2022om0} proposed a training strategy using Gaussian mixture models for task representation, achieving competitive asymptotic performance and superior zero-shot adaptation. While Meta-Safe Reinforcement Learning \\cite{khattar2024sr6} is discussed in detail in Section 6.4, its CMDP-within-online framework is particularly relevant here for providing provable guarantees for task-averaged regret and constraint violations in dynamic environments, which is essential for reliable lifelong operation in safety-critical contexts.\n\nMeta-learning has also been synergistically combined with other techniques to enhance continual adaptation, particularly in scenarios with realistic constraints. For instance, in lifelong language learning, \\cite{holla20202od} effectively combated catastrophic forgetting by combining meta-learning with sparse experience replay. By using replayed examples as the query set in a first-order MAML framework, their approach directly optimizes the model to prevent forgetting, demonstrating state-of-the-art performance under realistic constraints like single passes over data and no task identifiers. This highlights the power of combining meta-learning's adaptive capabilities with memory management strategies. Furthermore, hierarchical meta-learning approaches \\cite{yang2018p36, xu2019brv} have explored learning basic and compound skills or using meta-critic networks for sample-efficient learning and transferable knowledge, which are vital for accumulating complex behaviors over a lifetime. Skill-based meta-RL \\cite{nam2022z75} further leveraged offline datasets to extract reusable skills, enabling efficient meta-learning on long-horizon, sparse-reward tasks.\n\nThe practical utility of meta-learning for continual adaptation is evident across diverse real-world applications. \\cite{li20208tg} proposed an online meta-learning algorithm for self-supervised visual odometry, enabling continuous adaptation to new environments as a vehicle navigates. MAGICVFM \\cite{lupu20249p4} introduced a stable adaptive controller for ground vehicles that integrates visual foundation models and meta-learning for real-time terrain adaptation, backed by mathematical stability guarantees, showcasing robust performance in dynamic physical systems. Similarly, \\cite{ma20243e9} applied GCN-based multi-objective meta-Deep Q-Learning for eco-routing, demonstrating one-shot adaptation to new driving conditions. For high-speed railways, \\cite{wang2024d09} developed a contrastive learning-based Bayes-adaptive meta-RL (CBAMRL) for active pantograph control, achieving zero-shot adaptation in non-stationary environments. In the domain of class-incremental learning, a transformer-based approach by \\cite{kumar2024he9} demonstrated that meta-learners can exhibit significant generalization to newly introduced classes even without explicit training for this task, highlighting their inherent adaptability for integrating new categories over time. These applications underscore meta-learning's capacity to provide robust, efficient, and often theoretically grounded adaptation in complex, dynamic real-world systems.\n\nDespite significant progress, challenges remain in scaling these approaches to truly open-ended, highly complex real-world scenarios. Key tensions exist between architectural solutions (e.g., NMNs, SB-MCL) that intrinsically manage plasticity and stability, and algorithmic solutions (e.g., iTAML, meta-optimizers for CL) that modify learning rules. While memory-based methods like sparse experience replay are effective, they are constrained by finite memory buffers, raising questions about their efficacy in truly open-ended lifelong scenarios where knowledge accumulation is unbounded. Future research must focus on developing more robust and generalizable meta-learning frameworks that can operate with minimal supervision, handle extreme non-stationarity, provide stronger theoretical guarantees for all aspects of lifelong adaptation, and efficiently integrate diverse knowledge sources. The development of robust evaluation benchmarks specifically for continual meta-learning will also be crucial to drive progress towards truly autonomous and adaptable AI agents.",
    "Domain-Specific Adaptation and Generalization": "\\subsection{Domain-Specific Adaptation and Generalization}\n\nMeta-learning offers a compelling paradigm for addressing the inherent challenges of data scarcity, spatiotemporal heterogeneity, and the critical need for rapid, cost-effective deployment in diverse, unseen operational environments. By learning to learn, meta-learning enables models to quickly adapt and generalize to new tasks or domains with minimal new data, showcasing its practical efficacy across various scientific and engineering fields.\n\nA prominent application demonstrating meta-learning's utility in rapid adaptation is wireless localization. Traditional fingerprinting-based methods struggle with environment-specificity, demanding extensive data collection and retraining for each new physical setting. To overcome this, \\cite{gao20223fn} and \\cite{gao2022y3s} introduce MetaLoc, a pioneering framework that leverages Model-Agnostic Meta-Learning (MAML) to learn optimal \"meta-parameters\" – essentially a robust model initialization – from historical tasks. This allows a deep neural network to quickly adapt to new environments with minimal new data and computationally inexpensive updates, significantly enhancing scalability and cost-effectiveness. Building upon this, \\cite{pu2024m1b} further refines neural network positioning by proposing a Bayesian meta-learning approach. This method enhances robustness by inferring the Bayesian posterior, effectively mitigating model uncertainty and preventing overfitting when adapting to new environments with very limited samples, thus improving the reliability of rapid adaptation in dynamic wireless settings.\n\nBeyond static environments, meta-learning proves invaluable in tackling complex spatiotemporal heterogeneity. In climate science, accurately estimating global carbon fluxes (e.g., Gross Primary Production) is hampered by sparse and unbalanced in-situ observations, particularly in crucial regions like the tropics. \\cite{nathaniel2023ycu} introduces MetaFlux, which employs an MAML-adapted meta-learning ensemble to upscale these sparse spatiotemporal observations. This approach provides robust estimates even in data-poor regions and demonstrates enhanced robustness in predicting extreme flux events, significantly outperforming non-meta-learning baselines. Generalizing this concept, \\cite{dong2024110} proposes HimNet, a Heterogeneity-Informed Meta-Parameter Learning scheme for spatiotemporal time series forecasting. HimNet implicitly characterizes spatiotemporal heterogeneity through learnable embeddings and dynamically generates context-specific parameters from compact meta-parameter pools, addressing the limitations of prior methods that rely on auxiliary features or suffer from high computational costs. This represents a significant advancement in leveraging heterogeneity to inform model adaptation. Similarly, \\cite{pan2019pue} addresses urban traffic prediction, another domain characterized by complex spatio-temporal correlations, using a deep meta-learning model (ST-MetaNet) that collectively predicts traffic by capturing diverse spatial and temporal patterns.\n\nMeta-learning also provides critical solutions for few-shot learning scenarios where data is inherently scarce. For instance, few-shot short utterance speaker verification, crucial for applications like online payments, faces challenges due to the limited availability of voice samples. \\cite{wang2023x5w} addresses this by employing a meta-learning approach, specifically Prototypical Networks enhanced with an ECAPA-TDNN feature extractor and an episodic training strategy that incorporates global classification. This enables the model to learn more discriminative speaker features and achieve identification with minimal voice samples, outperforming traditional methods. The utility extends to other specialized domains: \\cite{wang2023srr} introduces Meta-Transfer Learning with Freezing Operation (MTLFO) for few-shot bearing fault diagnosis, which learns new knowledge rapidly from small samples while avoiding overfitting. In remote sensing, \\cite{alajaji2020b6c} applies MAML for few-shot scene classification, demonstrating its ability to classify new, unseen classes from limited labeled samples. Furthermore, \\cite{cheng2024mky} proposes a meta-transfer learning framework for general hyperspectral image super-resolution, tackling data scarcity and significant domain differences by accumulating diverse task experiences and gradually expanding the number of bands. Even in video processing, \\cite{gupta2021fbg} presents Ada-VSR, an adaptive video super-resolution method that uses meta-transfer learning to quickly adapt to novel degradation conditions with only a few gradient updates, significantly reducing inference time.\n\nIn conclusion, the literature clearly demonstrates meta-learning's profound impact on domain-specific adaptation and generalization. By enabling rapid learning from limited data and effectively handling complex heterogeneity, meta-learning addresses critical real-world challenges across wireless communication, climate science, security, manufacturing, and remote sensing. However, ongoing research continues to explore ways to balance the computational overhead of meta-learning with scalability, develop more universally robust meta-objectives, and reduce the reliance on diverse meta-training data to fully unlock its potential for truly adaptable and cost-effective AI systems.",
    "Meta-Learning for Data Quality and Robustness": "\\subsection{Meta-Learning for Data Quality and Robustness}\n\nReal-world machine learning applications are frequently hampered by imperfect data, including noisy labels, imbalanced distributions, and varying data utility, all of which can severely degrade model performance and robustness. Meta-learning offers a powerful paradigm to address these challenges by enabling deep neural networks to \"learn how to learn\" from such imperfections, thereby enhancing data quality and improving model resilience.\n\nA significant area of focus is making deep neural networks inherently noise-tolerant. \\cite{li2018soc} pioneered a meta-learning based noise-tolerant (MLNT) training algorithm that optimizes a meta-objective to prevent overfitting to label noise. This approach innovatively generates synthetic noisy labels through a \"random neighbor label transfer\" method and enforces consistency with a stable self-ensembling teacher model, effectively learning parameters that are robust against a wide spectrum of label corruption. Building on this, \\cite{algan2020u0v} introduced Meta Soft Label Generation (MSLG), a meta-learning algorithm that jointly generates optimal soft labels and learns deep neural network parameters. MSLG adapts the meta-learning paradigm to estimate label distributions by evaluating gradient directions on both noisy training data and a small, noise-free meta-dataset, iteratively refining soft labels to minimize loss on clean samples. This provides a more nuanced approach to handling label uncertainty compared to direct label correction. Further specializing in specific domains, \\cite{zhang2021p9j} proposed an adaptive label noise cleaning algorithm based on meta-supervision for deep face recognition. This method learns reliable cleaning knowledge from well-labeled noisy data and gradually transfers it to target data, incorporating a threshold adapter to manage transfer learning drift and achieve state-of-the-art performance on noisy face datasets. Extending beyond simple label noise, \\cite{liu2022tgc} tackled diverse data biases in deep face recognition, such as ethnicity, head pose, and occlusion. They proposed a sample-level weighting approach, Multi-variation Cosine Margin (MvCoM), guided by a meta-learning set to predict these weights, thereby simultaneously handling multiple variation factors and enhancing robustness against complex data imbalances.\n\nAnother critical aspect of data quality is data valuation, where meta-learning helps identify and leverage the most valuable data samples. \\cite{yoon2019k84} addressed the computationally intensive nature of traditional data valuation methods (like Data Shapley) by proposing Data Valuation using Reinforcement Learning (DVRL). This meta-learning framework jointly optimizes a data value estimator (a neural network predicting sample selection probabilities) and a target task predictor model. Crucially, DVRL employs reinforcement learning to handle the non-differentiable process of data sampling, using the predictor's performance on a small validation set as a reward signal. This scalable and model-agnostic approach significantly outperforms prior methods in tasks like corrupted sample discovery, domain adaptation, and robust learning, demonstrating meta-learning's power in discerning data utility.\n\nBeyond explicit label correction and data valuation, meta-learning also contributes to broader aspects of model robustness against data imperfections. For instance, in few-shot learning scenarios, the \"hubness problem\"—where certain class prototypes become the nearest neighbor for many test instances regardless of their true class—can arise from data distribution characteristics. \\cite{fei20211x6} demonstrated that many few-shot learning methods suffer from this and proposed using z-score feature normalization during meta-training to mitigate its negative effects, thereby boosting the robustness and performance of existing methods. Furthermore, addressing biases in training data for fair ranking systems, \\cite{wang2024so2} introduced a Meta Curriculum-based Fair Ranking (MCFR) framework. This framework utilizes a meta-learner to generate weighted losses, focusing more on minority groups to alleviate data bias. By formulating this as a bilevel optimization problem and integrating a curriculum learning scheduler for sampling the meta-dataset, MCFR learns to adaptively re-weight samples, ensuring fairer ranking outcomes.\n\nIn conclusion, meta-learning provides a versatile toolkit for enhancing data quality and model robustness in the face of real-world data imperfections. Techniques range from learning to correct or down-weight noisy labels, as seen in \\cite{li2018soc} and \\cite{algan2020u0v}, to sophisticated data valuation methods like DVRL \\cite{yoon2019k84} that identify and prioritize valuable samples. Moreover, meta-learning contributes to mitigating broader data-induced issues such as hubness \\cite{fei20211x6} and fairness biases \\cite{wang2024so2}. A common limitation across many of these approaches, however, remains the reliance on a small, often clean, validation or meta-dataset to guide the meta-learning process, which may not always be available in extreme real-world scenarios. Future research could focus on developing meta-objectives that are less dependent on such clean auxiliary data, further improving the scalability and generalizability of meta-learning for data quality and robustness across an even wider range of tasks and data imperfections.",
    "Meta-Learning with Large Pre-trained Models": "\\subsection{Meta-Learning with Large Pre-trained Models}\nThe advent of large pre-trained models, including Vision-Language Models (VLMs) and Large Language Models (LLMs), has fundamentally reshaped the landscape of few-shot learning, instigating a crucial paradigm shift in meta-learning. This subsection explores how meta-learning strategies are now predominantly employed to efficiently adapt, steer, or minimally tune these massive foundational models for novel tasks with limited data, moving beyond the traditional goal of learning optimal initial model weights.\n\nHistorically, meta-learning focused on learning generalizable initialization parameters or architectures that could quickly adapt to new tasks with a few gradient steps \\cite{Finn_MAML_2017, Nichol_Reptile_2018}. Early surveys, such as \\cite{huisman2020b7w}, noted an empirical correlation between larger network backbones and improved few-shot performance, implicitly hinting at the power of rich, pre-learned representations. This observation paved the way for integrating powerful pre-trained models into meta-learning frameworks. For instance, early work by \\cite{holla20202od} demonstrated the efficacy of meta-learning with sparse experience replay for lifelong language learning, leveraging pre-trained BERT as a representation network to mitigate catastrophic forgetting. Similarly, \\cite{li2023zn0} advanced few-shot text classification by proposing SEML, which enhances meta-learning with self-supervised information derived from unlabeled data, further enriching the feature representations learned by models like BERT. These initial integrations showcased meta-learning's ability to leverage pre-trained knowledge for specific adaptive challenges.\n\nThe true transformation, however, lies in the shift from fine-tuning entire models to efficiently interacting with or minimally tuning *frozen* foundational models. A seminal contribution in this area is \"Learning to Prompt\" (L2P) by \\cite{Chen_L2P_2021}, which introduced a meta-learning approach where a meta-learner generates task-specific learnable prompts to guide a *frozen* Vision-Language Model for few-shot adaptation. This technique significantly reduces the number of parameters requiring fine-tuning, thereby minimizing computational cost and data requirements. Building upon this, \\cite{wang2024dai} addressed a critical limitation of prompt tuning: overfitting to base classes and poor generalization to novel classes. They proposed \"Learning to Learn Better Visual Prompts,\" which integrates a meta-learning-informed episodic training strategy (akin to MAML's inner-outer loop optimization) into prompt tuning. This enables the model to learn more generalizable prompt vectors that effectively transfer knowledge to unseen categories, demonstrating meta-learning's power in optimizing the *prompting strategy itself* for improved few-shot generalization. The practical impact of this paradigm is further exemplified by \\cite{lupu20249p4}'s MAGICVFM, a stable adaptive controller for ground vehicles. This system integrates Visual Foundation Models (VFMs) and meta-learning to adapt only the last layer of a deep neural network based on VFM-derived visual features, showcasing efficient and robust adaptation of foundational models in safety-critical scenarios.\n\nFor Large Language Models (LLMs), meta-learning plays a crucial role in addressing their inherent data and computational demands, particularly for domain-specific adaptation \\cite{lee2021jou}. While in-context learning (ICL) is an emergent capability of large transformers, exhibiting properties analogous to meta-learning by adapting to tasks from demonstrations without explicit weight updates, explicit meta-learning strategies are actively employed to enhance or steer this emergent behavior. \\cite{Wang_Meta-Learning_2022} provides a comprehensive survey, highlighting how meta-learning underpins strategies like prompt-based learning, parameter-efficient fine-tuning (PEFT), and in-context learning to adapt these massive models with minimal data and computational overhead. This underscores a paradigm shift towards learning *how to interact with* or *efficiently tune* these powerful, pre-trained models rather than learning their initial weights from scratch. Furthermore, meta-learning with transformer-based models is being applied to real-world challenges like class incremental learning, where `\\cite{kumar2024he9}` proposes a transformer-based aggregation function within a meta-learner to classify newly introduced classes without retraining, showcasing how meta-learning enables continuous adaptation for these large NLP models.\n\nBeyond prompt tuning, meta-learning principles are being explored for other parameter-efficient fine-tuning (PEFT) techniques. For instance, meta-learning could be applied to optimize configurations for adapters (e.g., determining optimal LoRA ranks or placement) or to learn dynamic learning rate schedules for specific modules, further enhancing adaptation efficiency. The immense scale and complexity of foundational models also necessitate advancements in meta-optimization. \\cite{ozkara2024nst} introduced Meta-Adaptive Optimizers (MADA), which meta-learn the most suitable optimizer dynamically during training. This approach is particularly beneficial for the complex optimization landscapes and high computational costs associated with fine-tuning large models, potentially leading to faster convergence or better generalization with fewer steps. Moreover, theoretical advancements, such as the analysis of optimal (even counter-intuitive negative) inner-loop learning rates in MAML for overparameterized models by \\cite{bernacchia20211r0}, offer fundamental insights into the meta-optimization process. These insights are highly relevant for designing more robust and efficient meta-learning algorithms to adapt large pre-trained models, where overparameterization is the norm and optimal tuning strategies are critical for performance and computational efficiency.\n\nThe practical deployment of large foundation models, especially in sensitive domains, also highlights the critical role of meta-learning in distributed and privacy-preserving adaptation. The immense scale of these models, coupled with privacy concerns in real-world user data, makes centralized fine-tuning impractical. Federated meta-learning emerges as a critical enabling technology for privacy-preserving personalization, allowing large models to adapt to diverse client data without centralizing raw information. Examples include federated meta-learning frameworks for EV charging demand forecasting \\cite{you2024xuq} and driver distraction detection \\cite{liu2024jz5}, which enable collaborative learning across multiple clients while preserving data privacy, highly pertinent for deploying large models in sensitive, real-world environments.\n\nIn conclusion, meta-learning has undergone a significant evolution, transitioning from learning initial model parameters to developing sophisticated strategies for efficiently interacting with, steering, or minimally tuning large pre-trained models. This shift, driven by techniques like learning to generate optimal prompts and parameter-efficient fine-tuning, unlocks the immense potential of foundational models for rapid adaptation across a vast array of few-shot downstream applications. However, challenges remain in fully understanding the emergent properties of in-context learning, developing universally robust and parameter-efficient meta-learning strategies, scaling meta-training to encompass the full diversity of tasks that these increasingly capable foundational models can address, and advancing the theoretical understanding of meta-optimization in these overparameterized regimes.",
    "Safety and Interpretability in Meta-Learning Systems": "\\subsection{Safety and Interpretability in Meta-Learning Systems}\n\nThe deployment of highly adaptive meta-learning systems in real-world, often safety-critical, applications necessitates a rigorous focus on their safety and interpretability. While meta-learning excels at rapid adaptation to new tasks with limited data, ensuring that this adaptability does not compromise reliability, transparency, and trustworthiness is paramount. Recent advancements are beginning to address these crucial aspects, moving towards more responsible AI development.\n\nA significant step towards reliable autonomous systems is the development of meta-safe reinforcement learning (Meta-SRL), which provides provable guarantees for safety. \\cite{khattar2024sr6} introduces a novel \"CMDP-within-online\" framework for Meta-SRL, offering the first provable guarantees for task-averaged regret and constraint violations in Constrained Markov Decision Processes (CMDPs). This framework is critical for enabling RL agents to adapt quickly to unseen tasks while strictly adhering to safety constraints, even in the presence of inexact policies and state visitation distributions. Complementing this, \\cite{lupu20249p4} presents MAGICVFM, a stable adaptive controller for ground vehicles that integrates visual foundation models with meta-learning for real-time terrain adaptation. This system is backed by mathematical guarantees of exponential stability and robustness, directly contributing to the safe operation of autonomous systems in complex, dynamic environments. Similarly, \\cite{oconnell2022twd} demonstrates Neural-Fly, a meta-learning approach that enables rapid online adaptation for agile UAV flight in strong winds, providing robustness and exponential stability guarantees crucial for safe aerial navigation.\n\nBeyond explicit safety guarantees, interpretability and reliable confidence estimates are vital for trust and accountability, particularly in human-machine interaction. \\cite{tam2024a1h} addresses this by proposing a deep metric meta-learning framework for robust and interpretable EMG-based hand gesture recognition. Their method learns a semantically meaningful embedding space and derives a class proximity-based confidence estimator, offering more reliable and transparent confidence measures than traditional softmax outputs, which is crucial for safety-critical applications like prosthetic control. This approach tackles the poor generalization and overconfidence issues prevalent in conventional deep learning models. In a similar vein, \\cite{chen2022z45} and \\cite{wistuba2021wha} leverage meta-learning with deep kernel Gaussian Processes (GPs) to provide robust predictions with well-calibrated uncertainty estimates in few-shot settings, such as molecular property prediction and hyperparameter optimization. These calibrated uncertainties are essential for informed decision-making and building trust in high-stakes scientific and engineering domains. Further enhancing reliability, \\cite{aqeel2025zql} introduces Confident Meta-learning (CoMet) for unsupervised anomaly detection, which integrates soft confident learning to assign lower weights to low-confidence samples and meta-learning to stabilize training. This approach improves robustness to noisy data and provides critical confidence signals for anomaly detection, a key safety function.\n\nThe robustness of meta-learning systems to continuous data streams and evolving tasks also contributes to their overall safety and reliability. \\cite{holla20202od} tackles catastrophic forgetting in lifelong language learning by combining meta-learning with sparse experience replay. By preventing models from losing previously acquired knowledge, this method ensures sustained performance and reliability in dynamic environments. Building on this, \\cite{lee2024snq} proposes Sequential Bayesian Meta-Continual Learning (SB-MCL), a framework that inherently prevents catastrophic forgetting in neural networks by offloading sequential updates to robust statistical models, thereby ensuring long-term reliability and stability of learned knowledge.\n\nDespite these advancements, the efficacy of meta-learning in all safety-critical domains is not universally established. For instance, \\cite{guarino2023zsq} conducted a comprehensive comparison of meta-learning, transfer learning, and contrastive learning for encrypted traffic classification, a security-critical task. Their findings indicated that meta-learning methods, at least with the evaluated techniques and protocols, performed worse than other representation learning paradigms. This highlights the imperative for careful evaluation and validation of meta-learning approaches in specific safety-critical contexts, as their benefits are not guaranteed across all application types.\n\nIn conclusion, while meta-learning offers powerful tools for rapid adaptation, the integration of provable safety guarantees, interpretable confidence estimates, and robust continual learning mechanisms is crucial for its responsible deployment. Future research must continue to bridge the gap between adaptive effectiveness and the stringent requirements of safety, transparency, and trustworthiness, ensuring that these advanced AI systems can be reliably used in the most demanding real-world scenarios.",
    "Theoretical Gaps and Generalization Challenges": "\\subsection{Theoretical Gaps and Generalization Challenges}\nDespite significant advancements, deep meta-learning continues to grapple with fundamental theoretical limitations and persistent generalization challenges, particularly when confronted with truly novel task distributions. A critical issue is meta-overfitting, where meta-learners excel on meta-training tasks but struggle to adapt effectively to unseen tasks that deviate significantly from the meta-training distribution, often exhibiting sensitivity to subtle shifts in task characteristics \\cite{wang2024bhk, khoee2024ksk}.\n\nThe challenge of meta-overfitting is a central concern. Traditional meta-learning, often relying on bi-level optimization, can lead to underfitting or overfitting depending on task complexity, hindering generalization \\cite{wang2024bhk}. To address this, \\textcite{wang2024bhk} proposed TRLearner, a plug-and-play method that introduces relation-aware consistency regularization based on extracted task relation matrices. This approach offers theoretical guarantees for improved generalization by ensuring consistent performance on similar tasks, moving beyond simple empirical observations. Similarly, in the context of Vision-Language Models, \\textcite{wang2024dai} tackled the generalization challenge in prompt tuning, where models often overfit to base classes and perform poorly on novel ones. Their meta-learning-informed episodic training strategy effectively mitigates this overfitting, demonstrating improved generalization to new classes.\n\nA related problem is the meta-learner's tendency to \"memorize\" meta-training tasks rather than learning a truly adaptive mechanism. \\textcite{yin2019cct} highlighted this by showing that meta-learners can sometimes solve all meta-training tasks zero-shot without actual adaptation, leading to poor performance on novel tasks. They proposed an information-theoretic meta-regularization objective to prioritize data-driven adaptation. The sensitivity to shifts in task distribution is particularly evident in cross-domain few-shot learning. \\textcite{tian2023iyh} addressed this by proposing an adversarial meta-training framework that dynamically generates pseudo tasks to improve generalization to unseen domains, emphasizing the need for robust meta-knowledge. Surveys like \\textcite{khoee2024ksk} further formalize the problem of Domain Generalization through meta-learning, underscoring that effective generalization to unseen domains necessitates sufficient diversity in meta-training tasks. Practical applications also highlight these limitations; for instance, \\textcite{zhu2022d9a} and \\textcite{zhu2020rb5} developed meta-learning solutions for No-Reference Image Quality Assessment to improve generalization to unseen distortion types, a common real-world challenge. However, meta-learning's efficacy is not universally guaranteed; \\textcite{guarino2023zsq}'s empirical study on encrypted traffic classification found that meta-learning methods performed worse than transfer or contrastive learning, suggesting that in some domains, the learned meta-knowledge may not transfer as effectively. This is further supported by observations from the NeurIPS 2021 MetaDL challenge, where backbone fine-tuning often outperformed episodic meta-learning, indicating that simpler transfer learning might sometimes be more effective for generalization \\cite{baz2022n78}.\n\nBeyond empirical observations, there is a pressing need for stronger theoretical guarantees for generalization across diverse tasks. While some works provide theoretical foundations, such as \\textcite{finn2017vrt} demonstrating the universality of gradient-based meta-learning in approximating any learning algorithm, these do not always translate into robust generalization guarantees for complex real-world scenarios. More specific theoretical insights are emerging, such as \\textcite{bernacchia20211r0}'s surprising finding that the optimal inner loop learning rate for MAML during meta-training can be negative. This theoretical analysis, derived from random matrix theory and the Neural Tangent Kernel framework, offers a deeper understanding of MAML's generalization behavior and challenges conventional assumptions about gradient-based optimization in meta-learning. In safety-critical applications, theoretical guarantees are paramount; \\textcite{khattar2024sr6} introduced a CMDP-within-online framework for Meta-Safe Reinforcement Learning, providing the first provable guarantees for task-averaged regret and constraint violations. Similarly, \\textcite{lupu20249p4} developed MAGICVFM for ground vehicle control, integrating visual foundation models and meta-learning with mathematical stability guarantees, showcasing a move towards theoretically robust adaptive systems.\n\nThe computational complexity of meta-training and the challenges associated with scaling meta-learning algorithms to very large and highly heterogeneous task distributions remain crucial areas for foundational research. Early surveys, such as \\textcite{huisman2020b7w}, already identified high computational costs as a significant open challenge. Optimization-based meta-learning, particularly methods like MAML, often involve backpropagating through multiple inner-loop gradient steps, leading to substantial memory and computational overhead. To mitigate this, \\textcite{bertinetto2018ur2} proposed meta-learning with differentiable closed-form solvers (e.g., Ridge Regression), which allows for efficient adaptation and backpropagation by leveraging matrix identities. Building on this, \\textcite{przewiezlikowski2022d4y} introduced HyperMAML, replacing MAML's gradient-based inner loop with a trainable hypernetwork to generate more substantial and efficient weight updates in a single step, thereby reducing computational complexity. The meta-learning of optimizers, as seen in \\textcite{ozkara2024nst}'s MADA framework, also implicitly aims to improve the overall efficiency of the learning process itself. Furthermore, scaling meta-learning to very large and distributed task distributions, especially in privacy-sensitive domains, has led to the integration of federated learning. Approaches like \\textcite{you2024xuq}'s FMGCN for EV charging demand forecasting, \\textcite{liu2024jz5}'s AFM3D for driver distraction detection, and \\textcite{qu2022mu6}'s ALL for parking occupancy prediction, combine federated learning with meta-learning to address data silos, heterogeneity, and computational efficiency in distributed, multi-client environments. These efforts highlight the ongoing struggle to make meta-learning practical and scalable for real-world, dynamic, and diverse task landscapes.\n\nIn conclusion, while deep meta-learning has demonstrated impressive capabilities in few-shot learning and adaptation, significant theoretical and practical hurdles persist. The field continues to grapple with fundamental issues of meta-overfitting and sensitivity to task distribution shifts, necessitating more robust regularization and task-aware learning mechanisms. The demand for stronger theoretical guarantees for generalization, moving beyond empirical success to provable performance, remains a critical research direction. Simultaneously, addressing the inherent computational complexity and developing scalable meta-learning algorithms for increasingly large and heterogeneous task distributions are crucial for unlocking the full potential of learning-to-learn paradigms in real-world applications.",
    "Ethical Considerations and Societal Impact": "\\subsection*{Ethical Considerations and Societal Impact}\n\nThe rapid advancement of autonomous and adaptive meta-learning systems, while promising significant technological breakthroughs, simultaneously introduces profound ethical implications and necessitates careful consideration of their broader societal impact. As these systems learn \"how to learn\" and adapt to novel tasks with minimal human intervention, critical discussions surrounding potential issues such as bias amplification, the challenge of accountability, and the risk of misuse become increasingly urgent.\n\nA primary concern revolves around **bias amplification**. Meta-learning algorithms are designed to extract generalizable knowledge from a distribution of tasks \\cite{hospedales2020m37, huisman2020b7w}. If the data used for meta-training, or the tasks themselves, contain existing societal biases, the meta-learner can inadvertently perpetuate or even exacerbate these biases when applied to new, unseen scenarios. For instance, in deep face recognition, where training data is often imbalanced across various demographic and environmental factors, meta-learning approaches must explicitly account for \"diverse data biases\" to prevent significant accuracy degradation for underrepresented groups \\cite{liu2022tgc}. Similarly, in information retrieval, meta-learning frameworks are being developed to address \"data bias\" and promote \"fair ranking\" by guiding the meta-learner to mitigate skewness towards biased attributes \\cite{wang2024so2}. Furthermore, methods that leverage self-supervised learning from unlabeled data \\cite{li2023zn0} or learn from uncurated datasets \\cite{aqeel2025zql} risk embedding and amplifying latent biases present in these larger, less scrutinized data pools if not carefully designed with fairness in mind. Even efforts to improve data quality through meta-learning, such as data valuation \\cite{yoon2019k84} or learning from noisy labels \\cite{li2018soc}, could inadvertently prioritize data points that reinforce existing biases if the underlying valuation or noise models are themselves biased.\n\nThe inherent adaptability of meta-learning systems also poses significant challenges for **accountability**. When AI systems learn not just parameters, but the very rules or initializations that govern their adaptation \\cite{Finn_MAML_2017, Nichol_Reptile_2018}, their decision-making processes can become opaque and emergent. This complexity makes it difficult to trace *why* a system behaved in a particular way or adapted to a new situation in a specific manner. The intricate interplay of initialization layers and learned \"meta-layers\" for task-specific fine-tuning, as explored in efforts to rethink meta-learning's core mechanisms \\cite{wang2024bhk}, adds layers of abstraction that complicate interpretability. Similarly, meta-adaptive optimizers that dynamically learn the most suitable optimization strategy during training \\cite{ozkara2024nst} further obscure the causal chain of decisions. Recognizing these challenges, some research directly addresses accountability in safety-critical domains. For example, meta-safe reinforcement learning aims to provide \"provable guarantees\" for task-averaged regret and constraint violations in complex environments, a crucial step towards ensuring reliable behavior in autonomous systems \\cite{khattar2024sr6}. In ground interaction control for vehicles, the integration of visual foundation models with meta-learning for real-time adaptation, while offering \"mathematical stability guarantees,\" still presents interpretability challenges for understanding specific adaptations \\cite{lupu20249p4}. Efforts to enhance \"interpretability\" and provide \"robust confidence estimates\" in human-machine interfaces, such as EMG-based hand gesture recognition, directly acknowledge the need for transparent decision-making in adaptive systems \\cite{tam2024a1h}.\n\nBeyond these, the **potential for misuse** of highly adaptable meta-learning technologies is a critical concern. The ability of meta-learning to enable rapid learning from few examples \\cite{sung2017nc5, li2023zn0, wang2024dai} is a double-edged sword. While beneficial for legitimate applications like few-shot malware classification \\cite{li20246zp, wang2023kho} or medical diagnosis, this same capability could be exploited for malicious purposes, such as rapidly deploying surveillance systems for new targets, generating targeted disinformation, or developing more evasive adversarial agents. The power of domain generalization \\cite{khoee2024ksk} and cross-domain transfer learning \\cite{jang2019a48, chai2022kv5, liang2021juf, cheng2024mky} means models can be trained on one dataset and quickly adapted to another, potentially enabling malicious actors to bypass security measures or adapt to new adversarial environments more rapidly. Even privacy-preserving paradigms like federated meta-learning \\cite{you2024xuq, liu2024jz5, qu2022mu6}, designed to keep data localized, could introduce new privacy risks if the meta-learning process itself is compromised or if the aggregated meta-knowledge inadvertently reveals sensitive information.\n\nIn conclusion, while meta-learning promises to unlock unprecedented levels of AI adaptability and efficiency, its ethical implications demand proactive attention. The inherent risks of bias amplification, the complexities of ensuring accountability in highly adaptive systems, and the potential for misuse underscore the urgent need for responsible development, transparent deployment, and robust regulatory frameworks. Future research must not only focus on advancing algorithmic performance but also prioritize the integration of fairness-aware designs, enhanced interpretability, and provable safety guarantees into meta-learning architectures to ensure that these powerful advancements contribute positively to society while mitigating their inherent risks.",
    "Emerging Trends and Hybrid Approaches": "\\subsection*{Emerging Trends and Hybrid Approaches}\n\nThe trajectory of deep meta-learning is increasingly defined by a concerted effort to transcend isolated paradigms, fostering integrated, hybrid approaches that draw strength from diverse methodologies to develop more robust, efficient, and truly generalizable adaptive AI systems \\cite{hospedales2020m37}. This subsection delineates promising future research directions, emphasizing the growing interest in combining different meta-learning methodologies, the continued exploration of biologically inspired mechanisms, and the expansion into novel, high-impact applications.\n\nA significant emerging trend involves the explicit hybridization of meta-learning paradigms, moving beyond single-paradigm solutions to leverage complementary strengths. For instance, the integration of probabilistic modeling with optimization-based or metric-based insights is enhancing task inference and efficient exploration. While foundational probabilistic meta-RL methods like VariBAD \\cite{zintgraf2019zat} and PEARL \\cite{rakelly2019m09} have been instrumental in learning Bayes-adaptive policies and improving sample efficiency (as discussed in Section 5.2), their future lies in deeper integration with other meta-learning types. This includes approaches that use optimization to refine probabilistic models or metric learning. For example, \\cite{tseng2020m83} proposed Gradient Dropout, an optimization-based regularization technique for gradient-based meta-learning that mitigates overfitting by randomly dropping gradients during inner-loop adaptation, thereby improving generalization, particularly when combined with other meta-learning strategies. Furthermore, meta-learning is increasingly applied to refine metric learning itself, as demonstrated by \\cite{chen2019oep}'s Deep Meta Metric Learning (DMML) for learning set-based distances, \\cite{zheng20200ig}'s DML-ALA for adaptive learnable assessment, and \\cite{jiang20220tg}'s MMSI for meta-mining strategies with semiglobal information. These works exemplify hybrid approaches where a meta-learner (often optimization-based) is employed to discover more robust and generalizable similarity measures, thereby enhancing the performance of metric-based systems. This synergistic combination aims to create systems that not only adapt quickly but also quantify uncertainty and make more informed decisions.\n\nAnother prominent direction focuses on learning adaptive algorithms and architectures, often drawing inspiration from biological systems or employing meta-gradients to discover optimal learning processes. The concept of \"learning to learn\" extends to learning the very algorithms that govern adaptation, a powerful idea with roots in early work showing recurrent neural networks (RNNs) could implicitly learn reinforcement learning algorithms \\cite{wang20167px}. This has evolved into the field of meta-gradients, where gradients are computed through the learning process itself to optimize meta-parameters \\cite{sutton2022jss}. For instance, \\cite{xu2020txy} proposed FRODO, an algorithm that uses meta-gradient descent to discover its own RL objective function online by parameterizing the update target with a neural network, moving beyond handcrafted objectives. Theoretically, gradient-based meta-learning, such as MAML, has been shown to possess universal approximation capabilities for learning algorithms, suggesting its potential to discover highly effective learning strategies \\cite{finn2017vrt}. Biologically inspired mechanisms offer another avenue for adaptive architectures. Directly inspired by cellular neuromodulation, \\cite{vecoven2018hc1} introduced Neuro-Modulated Networks (NMNs), where a neuromodulatory network dynamically tunes the activation function parameters of a main network, leading to faster and more stable adaptive behaviors. Similarly, \\cite{fernando2018lt5} explored meta-learning by the Baldwin effect, demonstrating its capability to evolve few-shot supervised and reinforcement learning mechanisms by shaping hyperparameters and initial parameters without requiring backpropagation through meta-parameters. These approaches collectively aim to imbue AI systems with intrinsic, flexible adaptation capabilities, moving towards more autonomous and robust learning.\n\nThese emerging trends are paving the way for novel applications in complex real-world domains, pushing the boundaries of what adaptive AI can achieve. In scientific discovery, meta-learning holds immense promise for accelerating research by enabling models to generalize from limited, heterogeneous data. For example, \\cite{ruwurm2024806} introduced METEOR, a meta-learning methodology for Earth observation problems that adapts to diverse tasks and resolutions, using knowledge from global land cover information to perform well on new, unseen geospatial problems with few labels. This demonstrates meta-learning's capacity to extract generalizable insights from vast, varied datasets and apply them to specific, data-scarce scientific challenges. Another critical area is personalized medicine, where meta-learning's ability to adapt to individual patient data, handle data scarcity, and account for heterogeneity is invaluable for tasks like drug discovery, personalized diagnostics, and treatment optimization. While direct citations of meta-learning in personalized medicine are still emerging, the principles demonstrated in personalized robotics \\cite{yu2018nm7} and adaptive control systems \\cite{wang2020tae, ma20243e9, visca20217nt} strongly suggest its imminent impact. Furthermore, meta-learning is crucial for enhancing the adaptability of large pre-trained models in complex scenarios, such as class incremental learning in NLP \\cite{kumar2024he9, lee2021jou}, where it enables models to efficiently learn new classes without catastrophic forgetting or extensive retraining. The ability to rapidly adapt to new environments and tasks, as seen in meta-RL for robotics and control, and for resource management, underscores its potential to tackle dynamic and non-stationary real-world challenges.\n\nIn conclusion, the future of deep meta-learning is marked by a concerted effort to move beyond isolated paradigms towards integrated, hybrid approaches that draw strength from diverse methodologies. The increasing sophistication of probabilistic modeling, the ambition to learn the very algorithms and architectures of adaptation, and the expansion into complex real-world applications like scientific discovery and personalized medicine collectively underscore a vision for truly adaptive and generalizable AI. While significant progress has been made in enhancing robustness, efficiency, and generalization, challenges remain in scaling these hybrid systems to even greater complexity, ensuring stronger theoretical guarantees for learned objectives \\cite{chen2021j5t}, and developing robust generalization mechanisms across vastly different task distributions. Addressing these frontiers will be crucial for the field's continued evolution towards more versatile and impactful adaptive AI systems."
  },
  "latex_document": "\\documentclass[12pt,a4paper]{article}\n    \\usepackage[utf8]{inputenc}\n    \\usepackage[T1]{fontenc}\n    \\usepackage{amsmath,amsfonts,amssymb}\n    \\usepackage{graphicx}\n    \\usepackage[margin=2.5cm]{geometry}\n    \\usepackage{setspace}\n    \\usepackage{natbib}\n    \\usepackage{url}\n    \\usepackage{hyperref}\n    \\usepackage{booktabs}\n    \\usepackage{longtable}\n    \\usepackage{array}\n    \\usepackage{multirow}\n    \\usepackage{wrapfig}\n    \\usepackage{float}\n    \\usepackage{colortbl}\n    \\usepackage{pdflscape}\n    \\usepackage{tabu}\n    \\usepackage{threeparttable}\n    \\usepackage{threeparttablex}\n    \\usepackage[normalem]{ulem}\n    \\usepackage{makecell}\n    \\usepackage{xcolor}\n\n    % Set line spacing\n    \\doublespacing\n\n    % Configure hyperref\n    \\hypersetup{\n        colorlinks=true,\n        linkcolor=blue,\n        filecolor=magenta,      \n        urlcolor=cyan,\n        citecolor=red,\n    }\n\n    % Title and author information\n    \\title{A Comprehensive Literature Review with Self-Reflection}\n    \\author{Literature Review}\n    \\date{\\today}\n\n    \\begin{document}\n\n    \\maketitle\n\n    % Abstract (optional)\n    \\begin{abstract}\n    This literature review provides a comprehensive analysis of recent research in the field. The review synthesizes findings from 285 research papers, identifying key themes, methodological approaches, and future research directions.\n    \\end{abstract}\n\n    \\newpage\n    \\tableofcontents\n    \\newpage\n\n    \\label{sec:introduction_to_deep_meta-learning}\n\n\\section{Introduction to Deep Meta-Learning}\n\\label{sec:introduction\\_to\\_deep\\_meta-learning}\n\n\\subsection{Defining Deep Meta-Learning: Learning to Learn}\n\\label{sec:1\\_1\\_defining\\_deep\\_meta-learning:\\_learning\\_to\\_learn}\n\nDeep meta-learning represents a transformative paradigm designed to overcome fundamental limitations inherent in conventional deep learning, particularly its pronounced reliance on vast quantities of task-specific data and its struggles with robust generalization to novel, unseen tasks. At its core, meta-learning, frequently encapsulated by the phrase \"learning to learn,\" is the sophisticated process of acquiring an inductive bias or an explicit algorithm that empowers a base model to rapidly assimilate new skills or adapt to novel tasks with minimal data \\cite{hospedales2020m37, son2023lda}. This approach directly confronts scenarios where traditional deep learning models, after being trained on a fixed dataset, often exhibit poor performance when confronted with new data distributions or task specifications, highlighting a critical gap in their adaptive intelligence \\cite{hospedales2020m37}.\n\nThe operational framework of deep meta-learning is systematically structured into two distinct and sequential phases: meta-training and meta-testing. During the \\textbf{meta-training phase}, the meta-learner is exposed to a diverse distribution of related tasks. The primary objective here is not to achieve optimal performance on any single task, but rather to learn a transferable skill or a generalizable strategy for efficient learning across these tasks. This learned strategy might manifest as an effective initialization for model parameters, an adaptive update rule, or a robust mechanism for feature extraction. Subsequently, in the \\textbf{meta-testing phase}, these acquired adaptive capabilities are deployed for rapid adaptation to truly novel tasks, often with only a handful of labeled examples—a scenario commonly referred to as few-shot learning. The efficacy of meta-learning is critically assessed by how swiftly and effectively the meta-learner can adapt to these new, unseen tasks, thereby demonstrating its acquired \"learning to learn\" proficiency \\cite{hospedales2020m37, son2023lda}.\n\nThe \"inductive bias\" or \"explicit algorithm\" learned by the meta-learner is crucial for this rapid adaptation. In this context, an inductive bias refers to the set of assumptions or preferences that a learning algorithm uses to generalize from limited training data. For meta-learning, this bias is itself learned from experience across multiple tasks. It can take various forms: a set of initial parameters that are optimally poised for fine-tuning on new tasks, a learned optimization procedure that dictates how a base model's parameters should be updated, a sophisticated metric function for comparing data points in an embedding space, or even an architectural design that incorporates external memory mechanisms for efficient information storage and retrieval \\cite{hospedales2020m37}. This concept builds upon earlier ideas in machine learning, where the goal was to automatically find good choices for \"meta-parameters\" (e.g., learning rates, initial weights) that govern a base learning system, as highlighted by the historical development of \"meta-gradient\" methods \\cite{sutton2022jss}. The essence is to generalize the \\textit{learning process itself}, rather than just the solution to a specific task.\n\nThe \"deep\" aspect of deep meta-learning signifies the integration of these meta-learning principles with powerful deep neural network architectures. Deep learning provides the robust representation learning capabilities necessary to extract meaningful, high-level features from complex, high-dimensional data. This synergy allows meta-learners to operate effectively on raw inputs, such as images, text, or sensor data, enabling the \"learning to learn\" process to be applied to real-world, intricate problems. By leveraging deep neural networks, meta-learning can discover more sophisticated and flexible inductive biases, making the adaptive process more powerful and scalable than traditional meta-learning approaches \\cite{hospedales2020m37}.\n\nTo illustrate this framework, consider a canonical example: N-way, K-shot classification. In this setting, the meta-learner is trained to classify N novel classes, given only K examples per class. During meta-training, the system is presented with numerous distinct N-way, K-shot tasks, each drawn from a distribution of related classification problems (e.g., classifying different sets of N animal species with K images each). The meta-learner learns a strategy that allows it to quickly adapt to these varying tasks. Subsequently, during meta-testing, the system is confronted with a \\textit{completely new} N-way, K-shot task involving N \\textit{unseen} classes (e.g., classifying N entirely new animal species with K examples). Its success is measured by how effectively and rapidly it can classify instances from these novel classes, demonstrating its ability to generalize the \\textit{learning process} rather than merely memorizing class-specific features.\n\nIn conclusion, deep meta-learning fundamentally redefines how AI systems acquire knowledge, shifting from a narrow, task-specific learning paradigm to a more generalizable process of \"learning to learn.\" This core principle, instantiated through the distinct meta-training and meta-testing phases, has proven instrumental in addressing the critical data efficiency and generalization challenges that often plague conventional deep learning. This paradigm is realized through diverse methodological families—optimization-based, metric-based, and model-based approaches—which will be systematically explored in the subsequent sections, alongside their applications and challenges.\n\\subsection{Historical Context and Evolution of the Field}\n\\label{sec:1\\_2\\_historical\\_context\\_\\_and\\_\\_evolution\\_of\\_the\\_field}\n\nThe intellectual lineage of meta-learning, often encapsulated as \"learning to learn,\" reflects a persistent ambition in artificial intelligence: to create systems capable of rapid adaptation and robust generalization, akin to human cognitive flexibility. This pursuit has unfolded through distinct intellectual phases, from early theoretical explorations to its contemporary prominence, profoundly shaped by the advent and integration of powerful deep neural network architectures \\cite{hospedales2020m37, peng20209of}.\n\nThe foundational concepts of meta-learning emerged well before the deep learning era, driven by the desire to automate and optimize the learning process itself. In the 1980s and 1990s, researchers explored ideas such as hyperparameter optimization and the notion of \"learning optimizers.\" A significant conceptual precursor involved meta-gradient methods, pioneered by Schmidhuber and colleagues, which aimed to learn internal learning rates or even entire optimization algorithms through gradient descent on the learning process \\cite{sutton2022jss}. These early efforts, though often constrained by computational limitations and the expressiveness of available models, established the crucial principle: that a system could acquire an inductive bias or an explicit algorithm to enhance its future learning efficiency. Concurrently, influences from cognitive science, such as the Baldwin effect, provided a biological analogy, suggesting how individual learning could shape the evolution of innate learning biases across generations \\cite{fernando2018lt5}. This period laid the theoretical groundwork, emphasizing the potential for higher-order learning to improve base-level task acquisition, even if practical implementations were nascent.\n\nThe mid-2010s marked a dramatic resurgence and acceleration of meta-learning research, primarily catalyzed by the transformative power of deep learning. Deep neural networks provided the scalable and expressive function approximators necessary to realize complex meta-learning concepts that were previously computationally intractable \\cite{hospedales2020m37}. This period witnessed a \"Cambrian explosion\" of diverse meta-learning paradigms, each offering a distinct philosophical approach to the \"learning to learn\" challenge.\n\nOne early intellectual shift focused on endowing neural networks with explicit memory, addressing the need for models to quickly store and retrieve task-specific information for one-shot learning. This led to the development of model-based approaches, exemplified by Memory-Augmented Neural Networks (MANN) \\cite{Santoro2016}. The motivation here was to move beyond implicit parameter adaptation to architectures that could intrinsically adapt by processing and recalling relevant contextual data, a concept further explored in Section 4.2.\n\nParallel to this, the metric-based meta-learning paradigm gained traction, driven by the challenge of few-shot classification where models must generalize from minimal examples. The core intellectual contribution was the realization that learning a robust, transferable similarity function within an embedding space could enable effective comparison and classification of novel instances. This philosophy was embodied by seminal works such as Matching Networks \\cite{Vinyals2016}, Prototypical Networks \\cite{Snell2017}, and Relation Networks \\cite{sung2017nc5}. These approaches collectively demonstrated the power of learning discriminative feature spaces that facilitate rapid generalization by measuring relationships between examples, as further detailed in Section 4.1. The strength of these methods lay in their intuitive geometric interpretation and relative simplicity for specific tasks, but they often lacked the dynamic adaptability required for more complex, sequential learning scenarios.\n\nPerhaps the most impactful intellectual shift for the field's contemporary trajectory was the widespread adoption of gradient-based meta-learning. This paradigm directly built upon the early meta-gradient ideas, now leveraging the full differentiability of deep neural networks to optimize the \\textit{process} of learning itself \\cite{sutton2022jss}. The central insight was to reframe meta-learning as finding an optimal initialization or an efficient update rule that would enable a base model to rapidly adapt to new tasks with minimal gradient steps. Model-Agnostic Meta-Learning (MAML) \\cite{Finn2017} was a pivotal contribution, demonstrating how to learn an initial set of parameters that are highly amenable to rapid fine-tuning across a distribution of tasks. MAML's model-agnostic nature and its broad applicability across various deep learning architectures made it a cornerstone, fundamentally changing how researchers approached meta-learning by framing it within a bilevel optimization framework \\cite{franceschi2018u1q}. This success spurred further research into explicitly \"learning the optimizer,\" with approaches like Meta-Learner LSTMs \\cite{Ravi2017} and Meta-SGD \\cite{Li2017} aiming to meta-learn more flexible and adaptive update rules (discussed in Section 3.2). Concurrently, theoretical understanding of these methods deepened, with work exploring generalization bounds for MAML, offering insights into \\textit{why} these algorithms perform effectively in few-shot settings \\cite{chen2021j5t}.\n\nBeyond these core paradigms, the field continued to diversify. The integration of meta-learning with deep reinforcement learning (Meta-RL) addressed the notorious sample inefficiency and generalization challenges in dynamic environments, enabling agents to rapidly acquire new skills \\cite{wang20167px}. This extension, explored in Section 5.1, highlighted meta-learning's capacity to learn transferable behaviors. More recently, probabilistic meta-learning, exemplified by Conditional Neural Processes (CNP) \\cite{Garnelo2018}, emerged to model distributions over functions and quantify uncertainty, offering robust decision-making capabilities crucial for real-world applications (further discussed in Sections 4.3 and 5.2). The expanding scope of \"learning to learn\" also saw meta-learning applied to fundamental components like loss functions \\cite{raymond202441h}.\n\nIn summary, the evolution of meta-learning has been a dynamic interplay of ambitious theoretical concepts and the enabling power of deep learning. From early, computationally limited attempts to optimize learning processes to the sophisticated, deep neural network-driven paradigms of today, the field has consistently pushed the boundaries of generalization and adaptation. This progression, marked by distinct intellectual shifts towards memory-augmented, metric-based, and especially gradient-based approaches, has transformed meta-learning into a powerful framework for tackling data scarcity, non-stationarity, and complex decision-making, thereby setting a robust stage for understanding its current trajectory and future potential.\n\n\n\\label{sec:foundational_concepts_and_problem_settings}\n\n\\section{Foundational Concepts and Problem Settings}\n\\label{sec:foundational\\_concepts\\_\\_and\\_\\_problem\\_settings}\n\n\\subsection{Few-Shot Learning: The Prototypical Challenge}\n\\label{sec:2\\_1\\_few-shot\\_learning:\\_the\\_prototypical\\_challenge}\n\nFew-shot learning (FSL) represents a quintessential and pervasive challenge for deep learning, demanding that models generalize effectively to novel classes or tasks when presented with only a handful of labeled examples \\cite{huisman2020b7w, hospedales2020m37}. This scenario directly confronts the data-hungry nature of conventional deep learning models, which typically require vast amounts of annotated data to achieve robust performance. The prevalence of FSL is not merely an academic concern but a critical reality in numerous real-world applications where data annotation is prohibitively expensive, new categories emerge frequently, or data privacy concerns limit large-scale collection. Illustrative examples span diverse domains, including the medical diagnosis of rare diseases where labeled instances are inherently scarce, identifying emerging cyber threats like zero-day malware with minimal prior examples \\cite{li20246zp}, or enabling robotic systems to acquire complex new skills from a single visual demonstration \\cite{finn20174c4}. The inherent scarcity of data in such contexts establishes FSL as a primary driver for the development of meta-learning research.\n\nFormally, a few-shot learning task is typically defined within an N-way K-shot classification paradigm \\cite{son2023lda}. In this setup, a model is presented with a \"support set\" ($S$) containing $N$ novel classes, with $K$ labeled examples for each class. The goal is then to accurately classify instances in a \"query set\" ($Q$), which consists of unlabeled examples from these same $N$ novel classes. The meta-learning framework addresses this by employing an \"episodic training\" strategy. During the meta-training phase, the meta-learner is exposed to a large number of distinct FSL tasks, sampled from a distribution of related \"base\" tasks. Each meta-training episode simulates a few-shot scenario, allowing the model to learn how to rapidly adapt. In the subsequent meta-testing phase, the meta-learner is evaluated on truly novel tasks, drawn from a different set of classes unseen during meta-training, assessing its ability to quickly generalize with only the few examples provided in the support set of each new task \\cite{son2023lda}.\n\nMeta-learning offers a powerful framework to overcome the fundamental data scarcity inherent in FSL by leveraging prior experience from a distribution of related tasks \\cite{huisman2020b7w}. Instead of learning a single task from scratch, a meta-learner acquires an inductive bias or an explicit adaptation strategy that enables it to quickly form robust representations or adaptation rules for novel tasks. This \"learning to learn\" paradigm is crucial because traditional deep learning models, when faced with only a few examples, are highly susceptible to overfitting or simply failing to learn any meaningful features. Meta-learning mitigates this by training a model to become an efficient learner itself, rather than just a task-specific performer. These meta-learning strategies broadly fall into distinct categories, such as optimization-based, metric-based, and model-based approaches, which will be explored in detail in Sections 3 and 4.\n\nDespite the promise of meta-learning, FSL presents several persistent challenges that continue to drive research. One significant hurdle is the problem of generalization across diverse tasks, particularly when there are shifts in the underlying data distribution. For instance, cross-domain few-shot learning, where new tasks originate from domains unseen during meta-training, poses a formidable challenge to existing meta-learning methods, often leading to vulnerable generalization \\cite{tian2023iyh}. Furthermore, the fundamental generalization capabilities of meta-learning algorithms themselves are under scrutiny, with studies highlighting issues of underfitting or overfitting depending on task complexity, revealing a gap between theoretical expectations and practical performance \\cite{wang2024bhk}. Within metric-based FSL, which relies on learned embedding spaces, the \"hubness problem\" can arise, where certain class prototypes become the nearest neighbor for many test instances regardless of their true class, hindering classification accuracy \\cite{fei20211x6}. Addressing these challenges necessitates stronger theoretical guarantees for generalization, moving beyond empirical observations to provide a deeper understanding of why and when meta-learning succeeds in data-scarce scenarios \\cite{chen2021j5t}.\n\nThe principles of few-shot learning extend beyond supervised classification, serving as a critical driver for meta-learning research in other domains where rapid adaptation from limited experience is vital. In reinforcement learning, for example, the challenge of learning new policies with minimal interactions—often termed few-shot reinforcement learning—has led to seminal works exploring how agents can implicitly learn an RL algorithm \\cite{wang20167px} or acquire new skills from a single demonstration in one-shot visual imitation learning \\cite{finn20174c4}. The practical impact of FSL is also evident in diverse real-world applications, such as robust and interpretable EMG-based hand gesture recognition \\cite{tam2024a1h} and few-shot Android malware classification \\cite{li20246zp}, where the combination of data scarcity and the imperative for rapid adaptation makes FSL a central problem.\n\nIn conclusion, few-shot learning remains a cornerstone challenge that fundamentally shapes and propels innovation in meta-learning. It highlights the limitations of traditional deep learning in data-scarce environments and underscores the necessity for models that can \"learn to learn.\" While meta-learning provides a powerful conceptual and algorithmic framework, ongoing research continues to address critical issues such as improving robustness to domain shifts, mitigating underfitting and overfitting across heterogeneous tasks, and developing more unified theoretical understandings to ensure reliable and efficient generalization in the face of limited data.\n\\subsection{Meta-Reinforcement Learning: Adapting in Dynamic Environments}\n\\label{sec:2\\_2\\_meta-reinforcement\\_learning:\\_adapting\\_in\\_dynamic\\_environments}\n\nMeta-Reinforcement Learning (Meta-RL) represents a critical extension of meta-learning principles to the domain of reinforcement learning (RL), addressing fundamental limitations of traditional RL in dynamic and diverse environments. At its core, Meta-RL aims to enable an agent to \"learn to learn\" new behaviors, allowing it to rapidly adapt its policy to novel, unseen tasks within a family of related tasks \\cite{beck2023x24}. This paradigm is crucial for developing intelligent agents that can operate effectively in complex, real-world scenarios characterized by evolving objectives, changing dynamics, and sparse rewards, where learning from scratch for each new task is prohibitively inefficient.\n\nThe foundational problem setting for Meta-RL involves a distribution over Markov Decision Processes (MDPs), denoted as $p(\\mathcal{M})$. Each task $\\mathcal{T}\\_i$ is an instance of an MDP $\\mathcal{M}\\_i = (\\mathcal{S}, \\mathcal{A}, \\mathcal{P}\\_i, \\mathcal{R}\\_i, \\gamma)$, where $\\mathcal{S}$ is the state space, $\\mathcal{A}$ is the action space, $\\mathcal{P}\\_i$ is the task-specific transition function, $\\mathcal{R}\\_i$ is the task-specific reward function, and $\\gamma$ is the discount factor. The objective of a meta-RL agent is to learn an adaptation procedure or a meta-policy that, after observing a small amount of interaction data (e.g., a few trajectories) from a \\textit{new}, unseen task $\\mathcal{M}\\_{\\text{new}} \\sim p(\\mathcal{M})$, can quickly infer the task's specifics and derive an effective policy for it \\cite{beck2023x24}. This process typically involves a meta-training phase, where the agent learns its adaptive capabilities across a diverse set of tasks from $p(\\mathcal{M})$, and a meta-testing phase, where these learned abilities are deployed for fast adaptation to truly novel tasks.\n\nMeta-RL directly confronts several notorious challenges in traditional RL. Firstly, \\textbf{sample efficiency} is a primary concern. Standard deep RL algorithms often require millions of environmental interactions to learn a single task, making them impractical for real-world deployment where data collection is costly or time-consuming. By leveraging prior experience from a distribution of related tasks, Meta-RL aims to drastically reduce the amount of new data needed for effective learning on a novel task. Secondly, \\textbf{generalization} is enhanced. Policies learned for one specific task often fail to generalize to even slightly different tasks. Meta-RL fosters the acquisition of transferable skills or meta-knowledge that allows agents to generalize their learning process, rather than just their policy, across a spectrum of tasks. This means the agent learns \\textit{how} to learn, rather than just \\textit{what} to do.\n\nThe mechanisms through which meta-learning facilitates this rapid adaptation in RL are diverse, but they generally fall into categories that aim to either learn an efficient adaptation process or infer task-specific context. For instance, some approaches focus on learning an effective \\textit{initialization} for a policy that can be quickly fine-tuned with a few gradient steps on a new task. Others aim to learn \\textit{contextual representations} of tasks, where an encoder processes initial experience to infer latent variables that characterize the current task, which then guide the policy. A third category involves learning \\textit{implicit learning algorithms} through recurrent architectures, where the network's internal state acts as a memory of past interactions, allowing it to adapt its behavior over time within a single episode \\cite{finn2017vrt, wang20167px}. These high-level strategies enable agents to quickly infer task dynamics, reward functions, or optimal behaviors from minimal interaction, thereby accelerating learning and improving robustness.\n\nA critical aspect of Meta-RL is the challenge of \\textbf{efficient exploration} in new, unknown tasks. When an agent encounters a novel MDP, it must explore to gather information about its dynamics and rewards before it can exploit optimal actions. Meta-RL approaches often incorporate mechanisms for Bayes-adaptive exploration, where the agent actively seeks to reduce its uncertainty about the current task's identity, leading to more structured and efficient data collection \\cite{zintgraf2019zat, rakelly2019m09}. This is particularly vital in environments with sparse rewards, where random exploration is unlikely to yield meaningful learning signals. Furthermore, the problem of learning from static, \\textbf{offline datasets} introduces additional complexities, such as \"MDP ambiguity,\" where the available data may not be sufficient to distinguish between different underlying tasks, posing significant challenges for learning effective meta-exploration strategies \\cite{dorfman2020mgv}.\n\nIn summary, Meta-RL is a powerful paradigm for developing agents that are not only proficient at specific tasks but also possess the meta-skill to rapidly acquire new capabilities. By addressing the core challenges of sample efficiency, generalization, and efficient exploration within dynamic and uncertain environments, Meta-RL paves the way for more robust, autonomous, and adaptable AI systems capable of operating in complex real-world scenarios. The subsequent sections will delve into the specific methodologies that realize these adaptive capabilities, categorizing them by their underlying principles.\n\\subsection{Core Paradigms: Optimization, Metric, and Model-Based Approaches}\n\\label{sec:2\\_3\\_core\\_paradigms:\\_optimization,\\_metric,\\_\\_and\\_\\_model-based\\_approaches}\n\nDeep meta-learning methodologies are broadly categorized into three fundamental paradigms: optimization-based, metric-based, and model-based approaches \\cite{hospedales2020m37}. Each paradigm offers a distinct conceptual framework and set of mechanisms to enable models to \"learn to learn,\" addressing the challenge of rapid adaptation and generalization to novel tasks with limited data. This section provides a high-level overview of these core paradigms, highlighting their fundamental differences and inherent strengths, thereby setting the stage for their detailed exploration in subsequent sections.\n\n\\textbf{Optimization-based meta-learning} focuses on learning effective initializations or update rules that enable a base model to quickly adapt to new tasks through a few gradient steps. The core idea is to train a meta-learner to produce parameters or an optimization strategy that is highly amenable to rapid fine-tuning on unseen tasks \\cite{sutton2022jss}. This often involves a bi-level optimization process, where an inner loop performs task-specific adaptation, and an outer loop optimizes the meta-parameters (e.g., initial weights) across a distribution of tasks. The seminal Model-Agnostic Meta-Learning (MAML) \\cite{Finn2017} exemplifies this by seeking an initial parameter set that can be quickly adapted to any new task using standard gradient descent. While MAML offers broad applicability due to its model-agnostic nature, it often entails computational challenges related to second-order gradients and can be sensitive to hyperparameter choices. Subsequent research has explored learning the optimizer itself, such as with Meta-Learner LSTMs \\cite{Ravi2017} and Meta-SGD \\cite{Li2017}, which learn explicit update rules or adaptive learning rates. More advanced techniques, like HyperMAML \\cite{przewiezlikowski2022d4y}, replace gradient-based inner loops with learned hypernetworks to generate weight updates, offering more flexible and efficient adaptation. Theoretical analyses, such as those exploring generalization bounds \\cite{chen2021j5t} or the surprising role of negative learning rates in meta-training \\cite{bernacchia20211r0}, continue to refine our understanding of this paradigm's mechanics and limitations. Optimization-based methods are powerful for their generality and ability to adapt complex deep learning models, but their effectiveness can be constrained by computational cost and the stability of the meta-optimization process.\n\n\\textbf{Metric-based meta-learning} operates on the principle of learning robust similarity functions within embedding spaces. The goal is to transform raw input data into a feature space where examples from the same class are close together, and examples from different classes are far apart, regardless of whether these classes were seen during meta-training. This allows for efficient comparison and classification of novel examples with limited support data, typically through nearest-neighbor-like mechanisms. These methods learn an embedding network that maps inputs into a feature space where distances directly correspond to semantic similarity. Early approaches like Matching Networks \\cite{Vinyals2016} introduced attention mechanisms to dynamically weigh support examples, while Prototypical Networks \\cite{Snell2017} simplified this by representing each class with a single centroid (prototype) in the embedding space. A significant conceptual leap was made by Relation Networks \\cite{sung2017nc5}, which meta-learned a deep, non-linear 'relation function' to explicitly compute similarity scores between embedded query and support examples, moving beyond fixed distance metrics. The strength of metric-based approaches lies in their intuitive nature, interpretability (due to explicit comparisons), and efficiency for few-shot classification tasks. However, their applicability is often limited to tasks that can be effectively framed as similarity comparisons in a learned feature space, and their generalization capabilities can be sensitive to the quality and diversity of the learned embedding.\n\n\\textbf{Model-based meta-learning} is distinguished by designing network architectures with intrinsic adaptation capabilities. Instead of learning an optimization process or a similarity function, these models are engineered to quickly integrate new task information directly into their internal state or memory, often without explicit gradient updates during adaptation. This paradigm seeks to build \"fast weights\" or memory mechanisms that can rapidly store and retrieve task-specific knowledge. Pioneering work in this area includes Memory-Augmented Neural Networks (MANN) \\cite{Santoro2016}, which leverage external memory modules (inspired by Neural Turing Machines) to store and retrieve task-relevant information for one-shot learning. Architectures like A Simple Neural Attentive Meta-Learner (SNAIL) \\cite{Mishra2018} further combine temporal convolutions and attention to process sequences of experience, enabling fast in-context learning. A distinct and powerful sub-area within model-based approaches is Neural Processes, beginning with Conditional Neural Processes (CNP) \\cite{Garnelo2018}. These models learn to map context sets to distributions over functions, providing not only predictions but also crucial uncertainty estimates, which is vital for robust decision-making. Model-based methods excel at complex sequential decision-making tasks and scenarios requiring explicit memory or uncertainty quantification. Their primary challenge often lies in the increased architectural complexity and the difficulty of designing general-purpose adaptive mechanisms that perform well across highly diverse task distributions.\n\nIn summary, these three paradigms offer distinct yet complementary strategies for tackling the 'learning to learn' challenge. Optimization-based methods provide broad applicability by learning how to adapt parameters, but can be computationally intensive and sensitive to meta-optimization dynamics. Metric-based approaches offer efficient few-shot classification by learning robust similarity measures, though their applicability is often constrained to comparison-based tasks. Model-based methods push towards more sophisticated in-context learning and probabilistic function approximation through architectural innovations, offering powerful adaptation but often at the cost of increased architectural complexity and dependence on specific designs. The ongoing research across these paradigms continues to explore the trade-offs between generalizability, computational efficiency, and the ability to provide meaningful uncertainty estimates across diverse and complex real-world tasks.\n\n\n\\label{sec:optimization-based_meta-learning}\n\n\\section{Optimization-Based Meta-Learning}\n\\label{sec:optimization-based\\_meta-learning}\n\n\\subsection{Learning a Good Initialization: MAML and its Variants}\n\\label{sec:3\\_1\\_learning\\_a\\_good\\_initialization:\\_maml\\_\\_and\\_\\_its\\_variants}\n\nA fundamental challenge in few-shot learning is to enable models to rapidly adapt to new tasks with minimal labeled data. Optimization-based meta-learning addresses this by learning an effective initial set of model parameters that can be quickly fine-tuned for novel tasks.\n\nThe seminal work in this area is Model-Agnostic Meta-Learning (MAML) \\cite{Finn et al., 2017}, which proposes training a model's initial parameters such that a few gradient steps on a new task lead to significant performance improvement. MAML operates on a bi-level optimization structure: an inner loop performs task-specific adaptation by taking a few gradient steps on a support set, yielding adapted parameters. The outer loop then optimizes the initial parameters by evaluating the performance of these adapted parameters on a query set, using second-order gradients. This approach is inherently model-agnostic, meaning it can be applied to any model trained with gradient descent, making it broadly applicable across various deep learning architectures and tasks. While powerful for learning transferable knowledge, MAML's reliance on second-order derivatives can lead to substantial computational overhead and memory consumption, especially for large models, and it can be sensitive to hyperparameter choices.\n\nTo mitigate the computational burden associated with MAML's higher-order gradients, Reptile \\cite{Nichol2018} was introduced as a computationally more efficient first-order approximation. Reptile simplifies the meta-learning process by repeatedly training on a task for several gradient steps and then moving the meta-parameters (the initial parameters) towards the task-specific parameters obtained after adaptation. This update rule, $\\theta \\leftarrow \\theta + \\epsilon (\\phi - \\theta)$ where $\\phi$ are the task-adapted parameters, effectively approximates the MAML objective without explicitly computing second-order derivatives. This simplification significantly reduces the computational cost and memory footprint, allowing for greater scalability while maintaining competitive performance in many few-shot learning scenarios.\n\nFurther improving generalization and efficiency, particularly for complex models, is the Latent Embedding Optimization (LEO) framework \\cite{Rusu et al., 2018}. LEO builds upon the optimization-based paradigm by learning a low-dimensional latent embedding for the model parameters. Instead of optimizing directly in the high-dimensional parameter space, LEO performs the inner-loop adaptation (task-specific fine-tuning) within this more compact and efficient latent space. The adapted latent parameters are then decoded back to the original parameter space for inference. This strategy enhances robustness and scalability by operating in a learned, more meaningful representation, which can lead to better generalization and faster adaptation compared to direct optimization in the full parameter space.\n\nThe model-agnostic nature of MAML has enabled its application across diverse domains, demonstrating its practical utility. For instance, in few-shot Hyperspectral Image (HSI) classification, MAML, combined with regularized fine-tuning, has been successfully employed to overcome the challenge of limited labeled samples and facilitate effective cross-domain transfer learning \\cite{li2023fhe}. This application showcases MAML's ability to learn robust initializations that enable accurate classification even when only a handful of labeled examples are available for new HSI datasets, achieving high overall accuracy.\n\nIn conclusion, MAML and its variants represent a powerful paradigm within meta-learning, focusing on learning transferable initializations that enable rapid adaptation. While MAML laid the foundational groundwork with its bi-level optimization and model-agnosticism, its computational demands spurred the development of more efficient approximations like Reptile and advanced techniques like LEO, which optimize in learned latent spaces for improved generalization and efficiency. Despite these advancements, challenges persist in balancing computational cost, hyperparameter sensitivity, and ensuring robust generalization across highly diverse task distributions, pointing towards continued research in developing more robust and theoretically grounded optimization-based meta-learning algorithms.\n\\subsection{Learning the Optimizer: Meta-Learner LSTMs and Meta-SGD}\n\\label{sec:3\\_2\\_learning\\_the\\_optimizer:\\_meta-learner\\_lstms\\_\\_and\\_\\_meta-sgd}\n\nTranscending the paradigm of merely learning an effective initialization, a significant branch of meta-learning research focuses on explicitly learning the optimization process itself. This advanced approach frames meta-learning as the challenge of discovering an adaptive, data-driven optimization algorithm, offering greater flexibility and control over the learning process compared to relying on fixed, hand-designed optimizers. This subsection delves into two prominent methodologies within this domain: Meta-Learner LSTMs and Meta-SGD, which exemplify the quest to meta-learn the dynamics of parameter updates.\n\nOne pioneering approach in this direction is the Meta-Learner LSTM, introduced by \\cite{Ravi2017}. This method employs a recurrent neural network, specifically an LSTM, as the meta-learner to generate parameter updates for a base learner. The LSTM takes the base learner's gradients and previous internal states as input, and subsequently outputs the updates for each parameter, effectively learning a complex, stateful optimization algorithm. This allows the meta-learner to capture intricate dependencies and historical information during the inner-loop adaptation, moving beyond simple gradient descent to learn highly non-linear and context-dependent update rules. However, the inherent complexity of training such a meta-learner, which involves backpropagating through the unrolled optimization steps of the base learner, presents significant computational challenges and can lead to issues with training stability.\n\nBuilding upon the principles of gradient-based meta-learning, \\cite{Li2017} proposed Meta-SGD, an approach that extends the meta-learning objective to encompass more components of the optimization process. Unlike methods that primarily focus on learning a good initialization, Meta-SGD meta-learns not only initial parameters but also per-parameter learning rates and update directions for the inner-loop adaptation. This means that for each parameter of the base learner, the meta-learner learns how to scale and direct its gradient update, effectively transforming the standard gradient descent rule into a more adaptive, learned optimizer. By learning these fine-grained components, Meta-SGD provides a powerful mechanism for the base learner to adapt rapidly and efficiently to new tasks with only a few gradient steps, offering a more flexible and data-driven adaptation strategy than fixed learning rates.\n\nBoth Meta-Learner LSTMs and Meta-SGD represent a crucial shift in meta-learning, moving from static initializations to dynamic, learned optimization procedures. While \\cite{Ravi2017}'s Meta-Learner LSTM offers a highly flexible, black-box approach to learning an optimizer through its recurrent structure, it comes with the overhead of training a complex sequential model to generate updates. In contrast, \\cite{Li2017}'s Meta-SGD provides a more structured, yet equally adaptive, approach by directly learning the components of the gradient update rule, such as per-parameter learning rates and update directions. Both methods aim to imbue the base learner with the ability to \"learn how to learn\" by discovering an adaptive optimization algorithm from data, rather than relying on predefined heuristics.\n\nDespite their significant contributions to enabling more flexible and powerful adaptation, these sophisticated techniques introduce their own set of challenges. The increased complexity of the meta-learner and the meta-optimization objective can lead to higher computational demands and difficulties in ensuring stable and efficient training. Furthermore, the generalization capabilities of these learned optimizers to tasks significantly different from those seen during meta-training remain an active area of research. Future work will likely explore more efficient architectures for meta-optimizers, hybrid approaches that combine the strengths of explicit optimization learning with other meta-learning paradigms, and methods to improve the robustness and scalability of these adaptive learning algorithms to even broader and more diverse task distributions.\n\\subsection{Differentiable Solvers and Hypernetworks for Parameter Adaptation}\n\\label{sec:3\\_3\\_differentiable\\_solvers\\_\\_and\\_\\_hypernetworks\\_for\\_parameter\\_adaptation}\n\nThe pursuit of highly flexible and rapid adaptation mechanisms in meta-learning has led to the exploration of advanced techniques that move beyond conventional gradient-based inner-loop optimization. This subsection delves into two prominent paradigms: leveraging differentiable closed-form solvers as base learners and employing hypernetworks to generate model parameters dynamically. These approaches enable meta-learners to optimize for rapid, interpretable adaptation tailored to specific problem structures, or to modulate entire network architectures based on task-specific information.\n\nOne significant direction involves integrating classical machine learning algorithms as differentiable components within a meta-learning framework. \\textcite{bertinetto2018ur2} pioneered this by proposing a meta-learning approach where the base learner is a differentiable closed-form solver, such as Ridge Regression. Their method meta-learns both a deep feature extractor and the hyperparameters of the base solver end-to-end, efficiently backpropagating through the solver's closed-form solution (e.g., using the Woodbury identity for speed) to enable rapid adaptation in few-shot classification tasks. This allows for data-dependent adaptation at test time, offering more flexibility than similarity-based methods while being computationally more efficient than gradient-based meta-learning for a few adaptation steps.\n\nBuilding upon the idea of meta-learning parameters for classical models, subsequent work has extended this to more complex scenarios. \\textcite{wistuba2021wha} introduced Few-Shot Bayesian Optimization (FSBO) by meta-learning deep kernel Gaussian Processes (GPs) as surrogate models for hyperparameter optimization. Here, the deep kernel parameters are learned across a distribution of tasks, allowing the classical GP model to rapidly adapt its predictions to new tasks with very few evaluations. Further refining this, \\textcite{chen2022z45} presented Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT) for molecular property prediction. This framework uses bilevel optimization to meta-learn feature extractor parameters while adapting base kernel parameters per task, leveraging the Implicit Function Theorem for exact hypergradient computation, thereby achieving a robust balance between generalization and task-specific adaptation for deep kernel GPs. In a related vein, \\textcite{lee2024snq} proposed Sequential Bayesian Meta-Continual Learning (SB-MCL), a biologically inspired framework that decouples deep representation learning from sequential knowledge integration. Here, neural networks are meta-learned to map complex data to a latent space suitable for simple statistical models, which then perform exact sequential Bayesian updates, effectively offloading continual learning to robust, forgetting-immune classical models.\n\nComplementing differentiable solvers, hypernetworks offer another powerful mechanism for flexible parameter adaptation. Instead of optimizing the parameters of a base learner, hypernetworks are neural networks that generate the weights or parameters of another 'main' network, conditioned on task-specific information. This provides a mechanism for dynamic architecture generation or flexible parameter modulation without explicit gradient-based inner loops. \\textcite{przewiezlikowski2022d4y} exemplify this with HyperMAML, which replaces MAML's gradient-based inner-loop adaptation with a trainable hypernetwork. The hypernetwork directly outputs weight updates for the base model based on support set embeddings and labels, enabling more substantial and flexible weight modifications in a single step, thereby offering a computationally efficient alternative to classical MAML.\n\nBeyond these direct applications, the broader theme of learning flexible adaptation mechanisms also encompasses biologically inspired approaches. \\textcite{lindsey202075a} explored Feedback and Local Plasticity (FLP), a meta-learning framework that learns biologically plausible local synaptic update rules and decoupled feedback weights for deep credit assignment. While not strictly a differentiable solver or hypernetwork, FLP meta-learns parameters (feedback weights, plasticity coefficients) that modulate the learning process itself, demonstrating how meta-learning can discover effective, local learning rules that excel in challenging scenarios like continual learning, often outperforming gradient-based meta-learners.\n\nIn summary, differentiable solvers and hypernetworks represent significant advancements in meta-learning, offering powerful alternatives to traditional gradient-based adaptation. Differentiable solvers provide interpretable and efficient adaptation by optimizing classical models, while hypernetworks enable dynamic parameter generation for flexible architectural and functional modulation. Biologically inspired approaches further expand this landscape by learning the very rules of adaptation. Despite these strides, challenges remain in scaling complex differentiable solvers to arbitrary models, ensuring the interpretability of hypernetwork-generated parameters, and fully understanding the theoretical underpinnings of learned, non-gradient-based adaptation rules. Future research may explore hybrid models that combine these strengths, or delve deeper into the biological plausibility and robustness of such learned adaptation mechanisms.\n\n\n\\label{sec:metric_and_model-based_meta-learning}\n\n\\section{Metric and Model-Based Meta-Learning}\n\\label{sec:metric\\_\\_and\\_\\_model-based\\_meta-learning}\n\n\\subsection{Learning Similarity Measures: Matching, Prototypical, and Relation Networks}\n\\label{sec:4\\_1\\_learning\\_similarity\\_measures:\\_matching,\\_prototypical,\\_\\_and\\_\\_relation\\_networks}\n\nA distinct family of meta-learning approaches addresses few-shot classification by focusing on learning robust similarity measures within a discriminative embedding space. These methods aim to classify novel instances by comparing them directly to a small set of labeled support examples, thereby enabling accurate generalization from minimal data.\n\nPioneering this direction, Matching Networks \\cite{Vinyals2016} introduced an end-to-end differentiable framework that learns to map a small labeled support set and an unlabeled query to a classification. This is achieved through an attention-based comparison function, where the network dynamically weighs the contribution of each support example to classify the new instance, effectively performing a non-parametric classification in a learned feature space. While innovative, the direct comparison to every support example can be computationally intensive as the support set size grows.\n\nBuilding upon this foundation, Prototypical Networks \\cite{Snell2017} simplified the similarity learning paradigm by proposing that each class in a learned embedding space can be represented by a single \"prototype.\" This prototype is typically computed as the mean of the embedded support examples for that class. Classification of a new query instance then involves assigning it to the class whose prototype is closest in the embedding space, often using Euclidean distance. This approach offers improved computational efficiency and enhanced interpretability compared to Matching Networks, as class representations are explicitly defined, and it demonstrated competitive performance in few-shot classification tasks.\n\nFurther generalizing the concept of similarity, Relation Networks \\cite{Sung2018} moved beyond fixed distance metrics or attention mechanisms by learning a non-linear \"relation function\" to explicitly compute similarity scores. This network takes the concatenated embeddings of a query example and a support example (or a class prototype) as input and outputs a scalar score indicating their similarity. By learning this relation function, the model gains greater flexibility in defining what constitutes \"similarity,\" allowing for more complex and adaptive comparisons between embedded instances. This approach often leads to more robust similarity measures, especially when simple distance metrics might be insufficient.\n\nThe core ideas of these metric-based approaches continue to be extended and applied to more complex few-shot scenarios. For instance, the principles of Prototypical Networks have been adapted to tackle challenging tasks like few-shot cross-domain object detection. The Instance-level Prototype learning Network (IPNet) \\cite{zhang2024mf0} addresses data deficiency in target domains by fusing cropped instances from both source and target domains to learn representative prototypes for each class. These learned prototypes are then utilized to discriminate feature salience and facilitate domain alignment, demonstrating the adaptability of prototype-based methods beyond simple image classification to more intricate problems involving object localization and domain generalization.\n\nIn summary, Matching, Prototypical, and Relation Networks collectively represent a powerful family of meta-learning techniques that excel in few-shot classification by learning discriminative feature spaces and robust similarity measures. Their effectiveness stems from their intuitive comparison mechanisms, allowing accurate generalization from minimal examples. However, their primary limitation often lies in their task-specificity, as they are predominantly designed for classification tasks and might struggle to generalize to problems requiring complex structural changes or where a simple distance metric or learned relation function is insufficient for capturing task-specific nuances beyond feature comparison. Future research may explore hybrid approaches that combine the strengths of metric learning with other meta-learning paradigms to enhance their applicability to a broader range of tasks.\n\\subsection{Memory-Augmented Neural Networks for In-Context Learning}\n\\label{sec:4\\_2\\_memory-augmented\\_neural\\_networks\\_for\\_in-context\\_learning}\n\nModel-based meta-learning approaches offer a distinct paradigm for achieving rapid, in-context adaptation by designing network architectures that intrinsically facilitate fast information integration and knowledge transfer. Unlike gradient-based methods that learn to optimize parameters or metric-based approaches that learn similarity functions, this category focuses on equipping neural networks with explicit mechanisms for storing and retrieving task-specific information, enabling one-shot learning without explicit gradient updates.\n\nA pioneering work in this domain is the Memory-Augmented Neural Network (MANN) proposed by \\cite{santoro2016323}. Inspired by Neural Turing Machines (NTMs), MANN augments a standard neural network with an external memory module, allowing the network to learn to store and retrieve task-relevant information through differentiable read and write operations. This architectural innovation enables the model to quickly adapt to new tasks by leveraging previously encountered experiences stored in its memory, effectively performing one-shot learning by recalling specific data points or features rather than re-optimizing its weights. The core contribution of MANN lies in demonstrating how an explicit memory component can mitigate catastrophic forgetting and facilitate rapid knowledge acquisition, allowing the network to learn an internal \"algorithm\" for fast information integration. However, the complexity of training such memory-augmented networks and the scalability of their memory access mechanisms can pose significant challenges, particularly for very large datasets or highly diverse tasks.\n\nBuilding upon the principles of in-context learning, the Simple Neural Attentive Meta-Learner (SNAIL) \\cite{mishra2018simple} offers an alternative architectural approach that integrates temporal convolutions and attention mechanisms. SNAIL processes sequences of experience (support set and query examples) through a combination of causal convolutions, which efficiently aggregate information from past steps in the sequence, and a task-specific attention mechanism, which allows the network to selectively focus on the most relevant information for the current prediction. This design enables SNAIL to learn an internal meta-learning algorithm that can rapidly adapt to new tasks by attending to and integrating information from the context set, all within a single forward pass without requiring explicit gradient updates during adaptation. By leveraging standard deep learning components like convolutions and attention, SNAIL provides a more streamlined and potentially more scalable architecture for in-context learning compared to the explicit memory controllers of MANN, while still achieving powerful meta-learning capabilities across various tasks.\n\nIn summary, memory-augmented and attention-based neural networks represent a powerful class of meta-learning models that achieve rapid, in-context adaptation through architectural design rather than explicit parameter optimization. While MANN \\cite{santoro2016323} introduced the foundational concept of external memory for one-shot learning, SNAIL \\cite{mishra2018simple} refined this idea by integrating temporal convolutions and attention for efficient sequential processing. These models excel at learning an intrinsic 'algorithm' for fast information integration, demonstrating how architectural innovation can intrinsically equip neural networks with powerful meta-learning capabilities. However, challenges remain in scaling these architectures to extremely complex tasks and ensuring efficient memory management or attention mechanisms without incurring prohibitive computational costs or architectural complexity. Future research may explore hybrid approaches that combine the strengths of these model-based methods with more efficient memory structures or integrate them with other meta-learning paradigms.\n\\subsection{Neural Processes: Probabilistic Function Approximation}\n\\label{sec:4\\_3\\_neural\\_processes:\\_probabilistic\\_function\\_approximation}\n\nWithin the landscape of model-based meta-learning, Neural Processes (NPs) represent a distinct and powerful paradigm focused on probabilistic function approximation, drawing inspiration from the robustness of Gaussian Processes (GPs) while aiming for the scalability and flexibility of deep neural networks. Unlike traditional deep learning methods that yield point estimates, NPs learn to map context sets to distributions over functions, thereby providing not only predictions but also crucial quantification of predictive uncertainty. This capability is paramount for robust decision-making, active learning, and scenarios where confidence in predictions is as important as the predictions themselves, moving beyond deterministic outputs to a deeper understanding of the underlying data-generating process. NPs achieve this by amortizing inference over a distribution of tasks, learning a general mechanism to infer function properties from limited data.\n\nThe foundational work in this area is the Conditional Neural Process (CNP) \\cite{Garnelo2018}. CNPs introduced the concept of learning a distribution over functions by modeling conditional independence between target points given a context set. Specifically, a CNP employs a permutation-invariant encoder to aggregate information from observed context points (input-output pairs) into a global representation. This representation then parameterizes a simple, often factorized, Gaussian distribution over the target points. This allows the model to meta-learn in both regression and classification tasks while providing explicit uncertainty estimates, a significant advancement over prior deterministic meta-learning approaches. However, the strong conditional independence assumption in CNPs can lead to over-smoothed predictions, as it struggles to capture complex dependencies and multi-modalities inherent in intricate function structures.\n\nTo address the limitations of CNPs regarding expressiveness and the inability to capture dependencies between target points, the original Neural Process (NP) was subsequently introduced \\cite{Garnelo2018b}. This variant, sometimes referred to as Latent Neural Process, relaxes the strict conditional independence assumption by incorporating a global latent variable. The NP architecture includes two paths: a deterministic path similar to CNP, and a latent path where the encoder outputs parameters for a global latent distribution (e.g., a Gaussian). A latent variable is sampled from this distribution, which, along with the deterministic context representation, then informs the parameters of the predictive distribution. This latent variable acts as a global summary of the function's properties, enabling the model to capture richer function spaces and model dependencies between target points, thus mitigating the over-smoothing observed in standard CNPs.\n\nA further significant advancement in this lineage is the Attentive Neural Process (ANP) \\cite{Kim2019}. ANPs integrate self-attention mechanisms into the Neural Process framework, allowing the model to selectively weigh the importance of different context points when forming its representation. By employing an attention mechanism, ANPs can focus on the most relevant information within the context set, leading to more accurate predictions and better-calibrated uncertainty estimates. This selective attention mechanism significantly enhances the model's performance and flexibility, effectively tackling the over-smoothing issue more comprehensively than its predecessors by capturing fine-grained dependencies and local variations in the function, particularly beneficial for tasks with heterogeneous data distributions.\n\nWhile CNP, NP, and ANP primarily focus on standard regression and classification, Generalized Conditional Neural Processes (GCNP) \\cite{Requeima2019} extend the NP paradigm to handle structured data, such as graphs or meshes. GCNPs achieve this by integrating graph neural networks (GNNs) into the encoder architecture, allowing the model to leverage the underlying relational structure of the data when forming its context representation. This specialized extension demonstrates the versatility of the NP framework, adapting it to domains where explicit spatial or relational inductive biases are crucial. Another notable extension, Convolutional Conditional Neural Processes (ConvCNPs) \\cite{Gordon2019}, further enhances NPs by incorporating convolutional layers, which introduce spatial inductive biases and enable desirable equivariance properties, proving effective for image-based tasks.\n\nThe unique contribution of Neural Processes to probabilistic meta-learning lies in their ability to provide well-calibrated uncertainty estimates alongside predictions. This allows for more informed generalization, enabling applications such as active learning, where the model can query points where its uncertainty is high, or risk-aware decision-making, where the confidence in a prediction directly influences subsequent actions. Despite their strengths, NPs still face challenges. The permutation-invariant aggregation mechanism, while flexible, can act as an information bottleneck, potentially losing crucial structural information present in the context set. Furthermore, scaling NPs to very high-dimensional inputs or extremely large context sets can be computationally intensive. A persistent challenge across all probabilistic deep learning models, including NPs, is ensuring perfect calibration of uncertainty across diverse and potentially out-of-distribution tasks. As highlighted in recent critiques of other probabilistic deep learning approaches like Evidential Deep Learning \\cite{shen2024hea}, the reliability and faithful quantification of epistemic uncertainty remain non-trivial, often requiring careful architectural design and training objectives to avoid overconfidence or underestimation. Future work will likely focus on improving their computational efficiency, enhancing their expressiveness for highly complex functions by addressing the aggregation bottleneck, developing more principled methods for choosing the latent variable dimensionality, and refining uncertainty calibration techniques to ensure robustness and trustworthiness in real-world applications.\n\n\n\\label{sec:advanced_meta-learning_for_complex_scenarios}\n\n\\section{Advanced Meta-Learning for Complex Scenarios}\n\\label{sec:advanced\\_meta-learning\\_for\\_complex\\_scenarios}\n\n\\subsection{Meta-Reinforcement Learning and Imitation Learning}\n\\label{sec:5\\_1\\_meta-reinforcement\\_learning\\_\\_and\\_\\_imitation\\_learning}\n\nMeta-Reinforcement Learning (Meta-RL) and Meta-Imitation Learning (Meta-IL) represent a critical evolution in equipping agents with the ability to rapidly adapt to novel tasks and environments. These paradigms directly confront the notorious challenges of sample inefficiency and limited generalization inherent in traditional reinforcement learning (RL) and imitation learning (IL) by enabling agents to \"learn to learn\" across a distribution of related tasks \\cite{beck2023x24}. By acquiring a transferable skill or an efficient adaptation mechanism, meta-learning allows agents to quickly infer optimal behaviors, adapt to new reward functions, or acquire policies from minimal demonstrations, thereby accelerating learning and improving robustness in complex sequential decision-making scenarios.\n\nThe early trajectory of Meta-RL research explored implicit adaptation mechanisms, primarily leveraging Recurrent Neural Networks (RNNs). A seminal contribution by \\cite{wang20167px} demonstrated that an LSTM, when trained across a diverse set of tasks with past actions, rewards, and observations as inputs, could implicitly learn an internal RL algorithm. This recurrent architecture effectively encoded task-specific information within its hidden state, allowing it to adapt its policy to new tasks without requiring explicit weight updates, a process termed \"learning to reinforcement learn.\" While groundbreaking, this approach was initially demonstrated in simpler domains, raising questions about its scalability to complex, high-dimensional environments. Building on the concept of adaptive behaviors through architectural innovation, \\cite{vecoven2018hc1} introduced Neuro-Modulated Networks (NMNs). These networks employed a neuromodulatory sub-network to dynamically tune the activation function parameters of a main policy network, offering a more scalable solution than simply increasing network depth or width. NMNs achieved faster and more stable adaptive behaviors compared to standard RNNs, though their performance could be sensitive to the choice of activation functions. Further pushing the boundaries of implicit algorithmic learning, \\cite{xu2020txy} proposed FRODO, an algorithm that utilized meta-gradient descent to discover its own RL objective function online, parameterizing the update target with a neural network. This ambitious approach aimed to learn the very learning rule, but scaling such online objective learning to complex, real-world environments remains a significant practical challenge. These RNN-based methods, while powerful, often struggled with long-term credit assignment and the explicit representation of task uncertainty, paving the way for more explicit adaptation strategies \\cite{finn2017vrt, sutton2022jss}.\n\nA parallel and highly influential direction in meta-learning, particularly for rapid and explicit adaptation, emerged with gradient-based methods. Model-Agnostic Meta-Learning (MAML) \\cite{finn20174c4} proved instrumental in this regard, extending its bi-level optimization framework to both Meta-RL and Meta-IL. For Meta-RL, MAML learns an initialization that can be quickly fine-tuned with a few gradient steps on a new task, significantly improving sample efficiency compared to learning from scratch. In the realm of Meta-Imitation Learning (Meta-IL), \\cite{finn20174c4} pioneered one-shot visual imitation learning, enabling robots to acquire new skills from a single visual demonstration. This was a significant advancement, as it allowed end-to-end learning of visuomotor policies directly from raw pixel inputs, adapting via a few gradient updates. This approach addressed the critical data efficiency bottleneck in robotics, where collecting numerous demonstrations per task is often infeasible. However, a key challenge in imitation learning is the domain shift between human demonstrations and robot embodiments. \\cite{yu2018nm7} addressed this by leveraging meta-learning to build prior knowledge for cross-domain transfer, facilitating more robust one-shot imitation. While gradient-based methods like MAML offer strong generalization capabilities, they can be computationally intensive and susceptible to meta-overfitting, where the meta-learner performs well on meta-training tasks but struggles with truly novel task distributions \\cite{chen2021j5t}. To mitigate this, \\cite{tseng2020m83} proposed regularizing meta-learning via gradient dropout, a simple yet effective method to alleviate overfitting during the inner-loop adaptation, thereby enhancing generalization to new tasks. More recent work by \\cite{wang2024bhk} further investigates the underfitting/overfitting challenges in meta-learning, proposing a \"Task Relation Learner\" (TRLearner) to calibrate optimization by leveraging task similarities, which could be highly relevant for improving the robustness of gradient-based Meta-RL and Meta-IL.\n\nTo tackle increasingly complex and long-horizon tasks, meta-learning has also been integrated with hierarchical and skill-based approaches. These methods aim to decompose complex behaviors into reusable sub-skills, which can then be meta-learned and composed. \\cite{yang2018p36} proposed a hierarchical deep reinforcement learning algorithm that simultaneously learned basic and compound skills, utilizing two levels of hierarchy with a meta critic overseeing basic skills. Building on this, \\cite{xu2019brv} introduced Hierarchical Meta-Critic Networks for sample-efficient learning, providing transferable knowledge across tasks by sharing a global basic critic and a meta critic. This framework allowed for the distillation of meta-knowledge above the task level, enhancing adaptation. \\cite{lan20196o7} further improved generalization by proposing Meta-RL with Task Embedding and Shared Policy, explicitly capturing shared information across tasks and meta-learning how to quickly abstract task-specific information. More recently, \\cite{nam2022z75} devised a skill-based Meta-RL method that leverages prior experience extracted from offline datasets to learn reusable skills and meta-train a high-level policy. This enables efficient composition of learned skills into long-horizon behaviors, allowing for rapid adaptation to unseen target tasks with significantly fewer environment interactions.\n\nThe versatility of Meta-RL extends to various real-world applications, demonstrating its capacity for rapid adaptation in dynamic and resource-constrained settings. For instance, \\cite{wang2020tae} developed a fast adaptive task offloading method in edge computing based on Meta-RL, which can adapt quickly to new environments with minimal gradient updates and samples. In robotics, \\cite{visca20217nt} presented a deep meta-learning framework for energy-aware path planning for unmanned ground vehicles, allowing adaptation to unknown terrains. Furthermore, \\cite{ma20243e9} proposed a Graph Convolutional Network based Multi-Objective Meta-Deep Q-Learning (GM2DQL) method for eco-routing, demonstrating rapid adaptation to dynamic traffic conditions. Beyond efficiency, Meta-RL is also being extended to safety-critical domains. \\cite{khattar2024sr6} introduced a novel \"CMDP-within-online\" framework for Meta-Safe Reinforcement Learning, providing the first provable guarantees for task-averaged regret and constraint violations. This work is crucial for deploying RL agents in applications where both rapid adaptation and strict adherence to safety constraints are paramount. The integration of language instructions also shows promise, with \\cite{bing2022xo7} presenting a meta-RL algorithm that utilizes language to shape task interpretation in robotic manipulation, offering a more intuitive way to specify new tasks.\n\nIn conclusion, the field of Meta-Reinforcement Learning and Imitation Learning has undergone a significant evolution, moving from early demonstrations of implicit algorithmic learning within recurrent networks to sophisticated frameworks that explicitly optimize for adaptability and leverage hierarchical structures. While substantial progress has been made in addressing sample inefficiency and generalization, future research will likely focus on improving robustness to out-of-distribution tasks in dynamic environments, bridging the sim-to-real gap more effectively, and scaling to even more diverse and open-ended task distributions. The integration of meta-learning with other advanced learning paradigms, particularly for safety and human-robot interaction, will be crucial for achieving truly autonomous and adaptable AI agents capable of operating effectively in complex, real-world scenarios.\n\\subsection{Probabilistic Meta-Learning for Task Inference and Exploration}\n\\label{sec:5\\_2\\_probabilistic\\_meta-learning\\_for\\_task\\_inference\\_\\_and\\_\\_exploration}\n\nA critical challenge in meta-reinforcement learning (meta-RL) is the efficient adaptation to novel tasks, particularly in environments characterized by inherent uncertainty. Advanced probabilistic meta-learning frameworks explicitly address this by modeling task uncertainty, enabling more efficient exploration and the development of Bayes-adaptive policies. These policies condition actions not just on the current state, but also on the agent's evolving belief about the underlying task, leading to more robust and uncertainty-aware adaptation.\n\nA foundational contribution in this area is VariBAD (Variational Bayes-Adaptive Deep RL) by \\cite{zintgraf2019zat}. VariBAD meta-learns an approximate Bayes-adaptive policy by jointly training a Variational Auto-Encoder (VAE) for posterior inference over latent MDP embeddings and a policy conditioned on this belief. This approach allows the agent to perform principled online exploration by continuously updating its belief about the task as it interacts with the environment, demonstrating superior exploratory behavior compared to methods like posterior sampling in tasks such as Gridworld navigation \\cite{zintgraf2019zat}. However, VariBAD's reliance on on-policy experience during meta-training limited its sample efficiency, a common bottleneck in deep RL.\n\nTo address the sample inefficiency of on-policy meta-RL, \\cite{rakelly2019m09} introduced PEARL (Probabilistic Embeddings for Actor-Critic RL). PEARL is an off-policy meta-RL algorithm that leverages probabilistic context variables to encode task-specific information, conditioning the policy on this latent variable. A key innovation is its permutation-invariant encoder for task inference, which processes past experience to estimate the posterior over context variables, enabling significantly improved meta-training sample efficiency (20-100X) and structured exploration through posterior sampling. By decoupling the data used for policy training from that for encoder training, PEARL effectively integrates probabilistic task inference with off-policy actor-critic methods, achieving higher asymptotic performance on continuous control benchmarks \\cite{rakelly2019m09}.\n\nThe utility of probabilistic context variables extends beyond standard meta-RL to related problems like Inverse Reinforcement Learning (IRL). \\cite{yu2019o41} proposed PEMIRL (Probabilistic Embeddings for Meta-Inverse Reinforcement Learning), which adapts the probabilistic context variable paradigm to infer reward functions from few, unstructured, and heterogeneous demonstrations. PEMIRL integrates a deep latent variable model with maximum entropy IRL, utilizing mutual information regularization between the probabilistic context variable and trajectories to ensure the learned reward function effectively uses the inferred context. This enables few-shot reward inference for new tasks without requiring explicit task groupings or labels, a significant step towards more practical IRL applications \\cite{yu2019o41}.\n\nFurther pushing the boundaries of meta-learning under realistic constraints, \\cite{dorfman2020mgv} tackled the critical problem of Offline Meta-Reinforcement Learning with BOReL (Bayesian Offline Reinforcement Learning). BOReL is an off-policy VariBAD variant designed to learn exploration strategies from static, pre-collected datasets, rather than requiring active online data collection. This work formalizes the concept of \"MDP ambiguity,\" highlighting the inherent limitations of data identifiability when inferring task beliefs solely from offline data, and proposes strategies to mitigate it. BOReL demonstrates that effective meta-exploration can be learned from offline data, outperforming online baselines in some sparse reward tasks, which is crucial for applications where online interaction is costly or unsafe \\cite{dorfman2020mgv}.\n\nThe principles of Bayes-adaptive meta-learning continue to inspire advancements in specific applications and challenging environments. For instance, \\cite{zintgraf2021hoc} extended deep interactive Bayesian RL via meta-learning, enabling agents to learn about and adapt to other agents' unknown strategies in multi-agent settings by meta-learning approximate belief inference and Bayes-optimal behavior. Similarly, \\cite{bing2022om0} addressed meta-RL in non-stationary and dynamic environments by introducing a training strategy and task representation based on Gaussian mixture models, achieving zero-shot adaptation and competitive performance in changing conditions. More recently, \\cite{wang2024d09} proposed CBAMRL (Contrastive Learning-Based Bayes-Adaptive Meta-Reinforcement Learning) for active pantograph control in high-speed railways, employing a Bayes-adaptive strategy for zero-shot adaptation and a contrastive learning-based contextual encoder to represent complex task distributions, demonstrating rapid adaptation to unknown perturbations.\n\nIn conclusion, probabilistic meta-learning frameworks have significantly advanced the field by providing principled ways to model and leverage task uncertainty. From foundational methods like VariBAD to off-policy improvements in PEARL, extensions to Meta-IRL with PEMIRL, and the crucial offline learning capabilities of BOReL, these approaches enable more efficient exploration and robust adaptation in complex, partially observable environments. Despite these advancements, challenges remain in fully addressing MDP ambiguity in diverse offline datasets, scaling to extremely broad task distributions, and integrating these sophisticated probabilistic models with real-time, safety-critical applications while maintaining theoretical guarantees.\n\\subsection{Meta-Learning for Continual and Lifelong Adaptation}\n\\label{sec:5\\_3\\_meta-learning\\_for\\_continual\\_\\_and\\_\\_lifelong\\_adaptation}\n\nIntelligent agents operating in real-world environments face the fundamental challenge of continual and lifelong learning: they must adapt to non-stationary dynamics, sequentially encountered new tasks, and streaming data without succumbing to catastrophic forgetting \\cite{son2023lda}. This necessitates developing systems that can continuously learn and evolve over time, retaining previously acquired knowledge while rapidly integrating new information. Meta-learning offers a powerful paradigm to address these issues by enabling models to \"learn to learn\" robust, efficient, and lifelong adaptation mechanisms, thereby moving towards truly autonomous AI agents. This section critically examines how meta-learning approaches, often synergistically combined with other techniques, facilitate continuous learning, knowledge retention, and rapid integration of new information, focusing on the mechanisms that enable models to overcome the plasticity-stability dilemma inherent in lifelong adaptation.\n\nA primary challenge in continual learning is mitigating catastrophic forgetting, where acquiring new knowledge erodes previously learned skills. Meta-learning addresses this by learning how to adapt parameters or update rules in a way that preserves past knowledge while integrating new information. Architectural and biologically-inspired meta-learning approaches intrinsically manage the plasticity-stability dilemma through their design. For instance, Neuro-Modulated Networks (NMNs) \\cite{vecoven2018hc1} demonstrated that a neuromodulatory network could dynamically tune activation functions, leading to faster and more stable adaptive behaviors than standard recurrent neural networks. Similarly, Feedback and Local Plasticity (FLP) \\cite{lindsey202075a} introduced a meta-learning framework with decoupled feedback pathways and local synaptic plasticity rules, demonstrating superior performance in continual learning tasks and offering a universality proof for approximating any learning algorithm \\cite{finn2017vrt}. These models highlight the potential of architectural innovations to build in mechanisms for knowledge retention. More recently, Sequential Bayesian Meta-Continual Learning (SB-MCL) \\cite{lee2024snq} proposed a distinct framework that inherently prevents catastrophic forgetting by fixing neural network parameters during continual learning and offloading sequential updates to robust statistical models via meta-learned mappings. This approach decouples the expressive power of deep networks from the sequential update process, ensuring stability by leveraging the theoretical guarantees of Bayesian updates in exponential family distributions.\n\nOptimization-based meta-learning, particularly Model-Agnostic Meta-Learning (MAML) \\cite{finn20174c4}, has been instrumental in enabling rapid adaptation to new tasks by optimizing for a good initialization (as discussed in Section 3.1). However, its direct application to continual learning faces challenges such as meta-overfitting and insufficient weight modification in few gradient steps. To address these, various extensions have been proposed. \\cite{tseng2020m83} introduced gradient dropout regularization during the inner-loop optimization of gradient-based meta-learning to improve generalization to new tasks in a sequence. HyperMAML \\cite{przewiezlikowski2022d4y} replaced the gradient-based inner loop with a hypernetwork, allowing for more flexible and significant weight updates in a single step, which is crucial for adapting to diverse new tasks in a continual setting without repeated gradient computations. Furthermore, \\cite{wang2024bhk} introduced TRLearner, which uses task relation matrices and consistency regularization to mitigate underfitting and overfitting in MAML for continual adaptation. For class-incremental settings, iTAML \\cite{rajasegaran2020llk} developed an incremental task-agnostic meta-learning approach with a novel meta-update rule designed to maintain equilibrium across encountered tasks and effectively combat catastrophic forgetting. A distinct approach to learning the optimization process for continual learning was proposed by \\cite{vuorio2018gwb}, which meta-trains a neural network to predict parameter update steps that respect the importance of parameters to previous tasks, thereby directly learning to mitigate forgetting. These optimization-based methods collectively aim to learn \\textit{how to update} parameters to balance new learning with old knowledge retention, offering algorithmic solutions that complement architectural designs for stability.\n\nBeyond explicit parameter adaptation, meta-learning facilitates adaptation to non-stationary environments and dynamic task changes by learning more abstract adaptive strategies. As introduced in Section 5.1, early work by \\cite{wang20167px} demonstrated that recurrent neural networks could implicitly learn a reinforcement learning algorithm within their recurrent dynamics for rapid task adaptation. Building on the probabilistic meta-learning frameworks for task inference and exploration discussed in Section 5.2, these methods have been extended to address online adaptation and robust exploration in lifelong settings. VariBAD \\cite{zintgraf2019zat} and PEARL \\cite{rakelly2019m09} leverage probabilistic context variables and latent MDP embeddings to enable structured online exploration and improved sample efficiency, which are crucial for dynamic environments where task identity might be unknown or changing. BOReL \\cite{dorfman2020mgv} tackled Offline Meta-Reinforcement Learning, learning exploration from static datasets and mitigating \"MDP ambiguity,\" a critical challenge for lifelong learning from diverse, pre-recorded data sources. For non-stationary and dynamic environments, \\cite{bing2022om0} proposed a training strategy using Gaussian mixture models for task representation, achieving competitive asymptotic performance and superior zero-shot adaptation. While Meta-Safe Reinforcement Learning \\cite{khattar2024sr6} is discussed in detail in Section 6.4, its CMDP-within-online framework is particularly relevant here for providing provable guarantees for task-averaged regret and constraint violations in dynamic environments, which is essential for reliable lifelong operation in safety-critical contexts.\n\nMeta-learning has also been synergistically combined with other techniques to enhance continual adaptation, particularly in scenarios with realistic constraints. For instance, in lifelong language learning, \\cite{holla20202od} effectively combated catastrophic forgetting by combining meta-learning with sparse experience replay. By using replayed examples as the query set in a first-order MAML framework, their approach directly optimizes the model to prevent forgetting, demonstrating state-of-the-art performance under realistic constraints like single passes over data and no task identifiers. This highlights the power of combining meta-learning's adaptive capabilities with memory management strategies. Furthermore, hierarchical meta-learning approaches \\cite{yang2018p36, xu2019brv} have explored learning basic and compound skills or using meta-critic networks for sample-efficient learning and transferable knowledge, which are vital for accumulating complex behaviors over a lifetime. Skill-based meta-RL \\cite{nam2022z75} further leveraged offline datasets to extract reusable skills, enabling efficient meta-learning on long-horizon, sparse-reward tasks.\n\nThe practical utility of meta-learning for continual adaptation is evident across diverse real-world applications. \\cite{li20208tg} proposed an online meta-learning algorithm for self-supervised visual odometry, enabling continuous adaptation to new environments as a vehicle navigates. MAGICVFM \\cite{lupu20249p4} introduced a stable adaptive controller for ground vehicles that integrates visual foundation models and meta-learning for real-time terrain adaptation, backed by mathematical stability guarantees, showcasing robust performance in dynamic physical systems. Similarly, \\cite{ma20243e9} applied GCN-based multi-objective meta-Deep Q-Learning for eco-routing, demonstrating one-shot adaptation to new driving conditions. For high-speed railways, \\cite{wang2024d09} developed a contrastive learning-based Bayes-adaptive meta-RL (CBAMRL) for active pantograph control, achieving zero-shot adaptation in non-stationary environments. In the domain of class-incremental learning, a transformer-based approach by \\cite{kumar2024he9} demonstrated that meta-learners can exhibit significant generalization to newly introduced classes even without explicit training for this task, highlighting their inherent adaptability for integrating new categories over time. These applications underscore meta-learning's capacity to provide robust, efficient, and often theoretically grounded adaptation in complex, dynamic real-world systems.\n\nDespite significant progress, challenges remain in scaling these approaches to truly open-ended, highly complex real-world scenarios. Key tensions exist between architectural solutions (e.g., NMNs, SB-MCL) that intrinsically manage plasticity and stability, and algorithmic solutions (e.g., iTAML, meta-optimizers for CL) that modify learning rules. While memory-based methods like sparse experience replay are effective, they are constrained by finite memory buffers, raising questions about their efficacy in truly open-ended lifelong scenarios where knowledge accumulation is unbounded. Future research must focus on developing more robust and generalizable meta-learning frameworks that can operate with minimal supervision, handle extreme non-stationarity, provide stronger theoretical guarantees for all aspects of lifelong adaptation, and efficiently integrate diverse knowledge sources. The development of robust evaluation benchmarks specifically for continual meta-learning will also be crucial to drive progress towards truly autonomous and adaptable AI agents.\n\n\n\\label{sec:real-world_applications_and_robustness}\n\n\\section{Real-World Applications and Robustness}\n\\label{sec:real-world\\_applications\\_\\_and\\_\\_robustness}\n\n\\subsection{Domain-Specific Adaptation and Generalization}\n\\label{sec:6\\_1\\_domain-specific\\_adaptation\\_\\_and\\_\\_generalization}\n\nMeta-learning offers a compelling paradigm for addressing the inherent challenges of data scarcity, spatiotemporal heterogeneity, and the critical need for rapid, cost-effective deployment in diverse, unseen operational environments. By learning to learn, meta-learning enables models to quickly adapt and generalize to new tasks or domains with minimal new data, showcasing its practical efficacy across various scientific and engineering fields.\n\nA prominent application demonstrating meta-learning's utility in rapid adaptation is wireless localization. Traditional fingerprinting-based methods struggle with environment-specificity, demanding extensive data collection and retraining for each new physical setting. To overcome this, \\cite{gao20223fn} and \\cite{gao2022y3s} introduce MetaLoc, a pioneering framework that leverages Model-Agnostic Meta-Learning (MAML) to learn optimal \"meta-parameters\" – essentially a robust model initialization – from historical tasks. This allows a deep neural network to quickly adapt to new environments with minimal new data and computationally inexpensive updates, significantly enhancing scalability and cost-effectiveness. Building upon this, \\cite{pu2024m1b} further refines neural network positioning by proposing a Bayesian meta-learning approach. This method enhances robustness by inferring the Bayesian posterior, effectively mitigating model uncertainty and preventing overfitting when adapting to new environments with very limited samples, thus improving the reliability of rapid adaptation in dynamic wireless settings.\n\nBeyond static environments, meta-learning proves invaluable in tackling complex spatiotemporal heterogeneity. In climate science, accurately estimating global carbon fluxes (e.g., Gross Primary Production) is hampered by sparse and unbalanced in-situ observations, particularly in crucial regions like the tropics. \\cite{nathaniel2023ycu} introduces MetaFlux, which employs an MAML-adapted meta-learning ensemble to upscale these sparse spatiotemporal observations. This approach provides robust estimates even in data-poor regions and demonstrates enhanced robustness in predicting extreme flux events, significantly outperforming non-meta-learning baselines. Generalizing this concept, \\cite{dong2024110} proposes HimNet, a Heterogeneity-Informed Meta-Parameter Learning scheme for spatiotemporal time series forecasting. HimNet implicitly characterizes spatiotemporal heterogeneity through learnable embeddings and dynamically generates context-specific parameters from compact meta-parameter pools, addressing the limitations of prior methods that rely on auxiliary features or suffer from high computational costs. This represents a significant advancement in leveraging heterogeneity to inform model adaptation. Similarly, \\cite{pan2019pue} addresses urban traffic prediction, another domain characterized by complex spatio-temporal correlations, using a deep meta-learning model (ST-MetaNet) that collectively predicts traffic by capturing diverse spatial and temporal patterns.\n\nMeta-learning also provides critical solutions for few-shot learning scenarios where data is inherently scarce. For instance, few-shot short utterance speaker verification, crucial for applications like online payments, faces challenges due to the limited availability of voice samples. \\cite{wang2023x5w} addresses this by employing a meta-learning approach, specifically Prototypical Networks enhanced with an ECAPA-TDNN feature extractor and an episodic training strategy that incorporates global classification. This enables the model to learn more discriminative speaker features and achieve identification with minimal voice samples, outperforming traditional methods. The utility extends to other specialized domains: \\cite{wang2023srr} introduces Meta-Transfer Learning with Freezing Operation (MTLFO) for few-shot bearing fault diagnosis, which learns new knowledge rapidly from small samples while avoiding overfitting. In remote sensing, \\cite{alajaji2020b6c} applies MAML for few-shot scene classification, demonstrating its ability to classify new, unseen classes from limited labeled samples. Furthermore, \\cite{cheng2024mky} proposes a meta-transfer learning framework for general hyperspectral image super-resolution, tackling data scarcity and significant domain differences by accumulating diverse task experiences and gradually expanding the number of bands. Even in video processing, \\cite{gupta2021fbg} presents Ada-VSR, an adaptive video super-resolution method that uses meta-transfer learning to quickly adapt to novel degradation conditions with only a few gradient updates, significantly reducing inference time.\n\nIn conclusion, the literature clearly demonstrates meta-learning's profound impact on domain-specific adaptation and generalization. By enabling rapid learning from limited data and effectively handling complex heterogeneity, meta-learning addresses critical real-world challenges across wireless communication, climate science, security, manufacturing, and remote sensing. However, ongoing research continues to explore ways to balance the computational overhead of meta-learning with scalability, develop more universally robust meta-objectives, and reduce the reliance on diverse meta-training data to fully unlock its potential for truly adaptable and cost-effective AI systems.\n\\subsection{Meta-Learning for Data Quality and Robustness}\n\\label{sec:6\\_2\\_meta-learning\\_for\\_data\\_quality\\_\\_and\\_\\_robustness}\n\nReal-world machine learning applications are frequently hampered by imperfect data, including noisy labels, imbalanced distributions, and varying data utility, all of which can severely degrade model performance and robustness. Meta-learning offers a powerful paradigm to address these challenges by enabling deep neural networks to \"learn how to learn\" from such imperfections, thereby enhancing data quality and improving model resilience.\n\nA significant area of focus is making deep neural networks inherently noise-tolerant. \\cite{li2018soc} pioneered a meta-learning based noise-tolerant (MLNT) training algorithm that optimizes a meta-objective to prevent overfitting to label noise. This approach innovatively generates synthetic noisy labels through a \"random neighbor label transfer\" method and enforces consistency with a stable self-ensembling teacher model, effectively learning parameters that are robust against a wide spectrum of label corruption. Building on this, \\cite{algan2020u0v} introduced Meta Soft Label Generation (MSLG), a meta-learning algorithm that jointly generates optimal soft labels and learns deep neural network parameters. MSLG adapts the meta-learning paradigm to estimate label distributions by evaluating gradient directions on both noisy training data and a small, noise-free meta-dataset, iteratively refining soft labels to minimize loss on clean samples. This provides a more nuanced approach to handling label uncertainty compared to direct label correction. Further specializing in specific domains, \\cite{zhang2021p9j} proposed an adaptive label noise cleaning algorithm based on meta-supervision for deep face recognition. This method learns reliable cleaning knowledge from well-labeled noisy data and gradually transfers it to target data, incorporating a threshold adapter to manage transfer learning drift and achieve state-of-the-art performance on noisy face datasets. Extending beyond simple label noise, \\cite{liu2022tgc} tackled diverse data biases in deep face recognition, such as ethnicity, head pose, and occlusion. They proposed a sample-level weighting approach, Multi-variation Cosine Margin (MvCoM), guided by a meta-learning set to predict these weights, thereby simultaneously handling multiple variation factors and enhancing robustness against complex data imbalances.\n\nAnother critical aspect of data quality is data valuation, where meta-learning helps identify and leverage the most valuable data samples. \\cite{yoon2019k84} addressed the computationally intensive nature of traditional data valuation methods (like Data Shapley) by proposing Data Valuation using Reinforcement Learning (DVRL). This meta-learning framework jointly optimizes a data value estimator (a neural network predicting sample selection probabilities) and a target task predictor model. Crucially, DVRL employs reinforcement learning to handle the non-differentiable process of data sampling, using the predictor's performance on a small validation set as a reward signal. This scalable and model-agnostic approach significantly outperforms prior methods in tasks like corrupted sample discovery, domain adaptation, and robust learning, demonstrating meta-learning's power in discerning data utility.\n\nBeyond explicit label correction and data valuation, meta-learning also contributes to broader aspects of model robustness against data imperfections. For instance, in few-shot learning scenarios, the \"hubness problem\"—where certain class prototypes become the nearest neighbor for many test instances regardless of their true class—can arise from data distribution characteristics. \\cite{fei20211x6} demonstrated that many few-shot learning methods suffer from this and proposed using z-score feature normalization during meta-training to mitigate its negative effects, thereby boosting the robustness and performance of existing methods. Furthermore, addressing biases in training data for fair ranking systems, \\cite{wang2024so2} introduced a Meta Curriculum-based Fair Ranking (MCFR) framework. This framework utilizes a meta-learner to generate weighted losses, focusing more on minority groups to alleviate data bias. By formulating this as a bilevel optimization problem and integrating a curriculum learning scheduler for sampling the meta-dataset, MCFR learns to adaptively re-weight samples, ensuring fairer ranking outcomes.\n\nIn conclusion, meta-learning provides a versatile toolkit for enhancing data quality and model robustness in the face of real-world data imperfections. Techniques range from learning to correct or down-weight noisy labels, as seen in \\cite{li2018soc} and \\cite{algan2020u0v}, to sophisticated data valuation methods like DVRL \\cite{yoon2019k84} that identify and prioritize valuable samples. Moreover, meta-learning contributes to mitigating broader data-induced issues such as hubness \\cite{fei20211x6} and fairness biases \\cite{wang2024so2}. A common limitation across many of these approaches, however, remains the reliance on a small, often clean, validation or meta-dataset to guide the meta-learning process, which may not always be available in extreme real-world scenarios. Future research could focus on developing meta-objectives that are less dependent on such clean auxiliary data, further improving the scalability and generalizability of meta-learning for data quality and robustness across an even wider range of tasks and data imperfections.\n\\subsection{Meta-Learning with Large Pre-trained Models}\n\\label{sec:6\\_3\\_meta-learning\\_with\\_large\\_pre-trained\\_models}\n\nThe advent of large pre-trained models, including Vision-Language Models (VLMs) and Large Language Models (LLMs), has fundamentally reshaped the landscape of few-shot learning, instigating a crucial paradigm shift in meta-learning. This subsection explores how meta-learning strategies are now predominantly employed to efficiently adapt, steer, or minimally tune these massive foundational models for novel tasks with limited data, moving beyond the traditional goal of learning optimal initial model weights.\n\nHistorically, meta-learning focused on learning generalizable initialization parameters or architectures that could quickly adapt to new tasks with a few gradient steps \\cite{Finn\\_MAML\\_2017, Nichol\\_Reptile\\_2018}. Early surveys, such as \\cite{huisman2020b7w}, noted an empirical correlation between larger network backbones and improved few-shot performance, implicitly hinting at the power of rich, pre-learned representations. This observation paved the way for integrating powerful pre-trained models into meta-learning frameworks. For instance, early work by \\cite{holla20202od} demonstrated the efficacy of meta-learning with sparse experience replay for lifelong language learning, leveraging pre-trained BERT as a representation network to mitigate catastrophic forgetting. Similarly, \\cite{li2023zn0} advanced few-shot text classification by proposing SEML, which enhances meta-learning with self-supervised information derived from unlabeled data, further enriching the feature representations learned by models like BERT. These initial integrations showcased meta-learning's ability to leverage pre-trained knowledge for specific adaptive challenges.\n\nThe true transformation, however, lies in the shift from fine-tuning entire models to efficiently interacting with or minimally tuning \\textit{frozen} foundational models. A seminal contribution in this area is \"Learning to Prompt\" (L2P) by \\cite{Chen\\_L2P\\_2021}, which introduced a meta-learning approach where a meta-learner generates task-specific learnable prompts to guide a \\textit{frozen} Vision-Language Model for few-shot adaptation. This technique significantly reduces the number of parameters requiring fine-tuning, thereby minimizing computational cost and data requirements. Building upon this, \\cite{wang2024dai} addressed a critical limitation of prompt tuning: overfitting to base classes and poor generalization to novel classes. They proposed \"Learning to Learn Better Visual Prompts,\" which integrates a meta-learning-informed episodic training strategy (akin to MAML's inner-outer loop optimization) into prompt tuning. This enables the model to learn more generalizable prompt vectors that effectively transfer knowledge to unseen categories, demonstrating meta-learning's power in optimizing the \\textit{prompting strategy itself} for improved few-shot generalization. The practical impact of this paradigm is further exemplified by \\cite{lupu20249p4}'s MAGICVFM, a stable adaptive controller for ground vehicles. This system integrates Visual Foundation Models (VFMs) and meta-learning to adapt only the last layer of a deep neural network based on VFM-derived visual features, showcasing efficient and robust adaptation of foundational models in safety-critical scenarios.\n\nFor Large Language Models (LLMs), meta-learning plays a crucial role in addressing their inherent data and computational demands, particularly for domain-specific adaptation \\cite{lee2021jou}. While in-context learning (ICL) is an emergent capability of large transformers, exhibiting properties analogous to meta-learning by adapting to tasks from demonstrations without explicit weight updates, explicit meta-learning strategies are actively employed to enhance or steer this emergent behavior. \\cite{Wang\\_Meta-Learning\\_2022} provides a comprehensive survey, highlighting how meta-learning underpins strategies like prompt-based learning, parameter-efficient fine-tuning (PEFT), and in-context learning to adapt these massive models with minimal data and computational overhead. This underscores a paradigm shift towards learning \\textit{how to interact with} or \\textit{efficiently tune} these powerful, pre-trained models rather than learning their initial weights from scratch. Furthermore, meta-learning with transformer-based models is being applied to real-world challenges like class incremental learning, where \\texttt{\\cite{kumar2024he9}} proposes a transformer-based aggregation function within a meta-learner to classify newly introduced classes without retraining, showcasing how meta-learning enables continuous adaptation for these large NLP models.\n\nBeyond prompt tuning, meta-learning principles are being explored for other parameter-efficient fine-tuning (PEFT) techniques. For instance, meta-learning could be applied to optimize configurations for adapters (e.g., determining optimal LoRA ranks or placement) or to learn dynamic learning rate schedules for specific modules, further enhancing adaptation efficiency. The immense scale and complexity of foundational models also necessitate advancements in meta-optimization. \\cite{ozkara2024nst} introduced Meta-Adaptive Optimizers (MADA), which meta-learn the most suitable optimizer dynamically during training. This approach is particularly beneficial for the complex optimization landscapes and high computational costs associated with fine-tuning large models, potentially leading to faster convergence or better generalization with fewer steps. Moreover, theoretical advancements, such as the analysis of optimal (even counter-intuitive negative) inner-loop learning rates in MAML for overparameterized models by \\cite{bernacchia20211r0}, offer fundamental insights into the meta-optimization process. These insights are highly relevant for designing more robust and efficient meta-learning algorithms to adapt large pre-trained models, where overparameterization is the norm and optimal tuning strategies are critical for performance and computational efficiency.\n\nThe practical deployment of large foundation models, especially in sensitive domains, also highlights the critical role of meta-learning in distributed and privacy-preserving adaptation. The immense scale of these models, coupled with privacy concerns in real-world user data, makes centralized fine-tuning impractical. Federated meta-learning emerges as a critical enabling technology for privacy-preserving personalization, allowing large models to adapt to diverse client data without centralizing raw information. Examples include federated meta-learning frameworks for EV charging demand forecasting \\cite{you2024xuq} and driver distraction detection \\cite{liu2024jz5}, which enable collaborative learning across multiple clients while preserving data privacy, highly pertinent for deploying large models in sensitive, real-world environments.\n\nIn conclusion, meta-learning has undergone a significant evolution, transitioning from learning initial model parameters to developing sophisticated strategies for efficiently interacting with, steering, or minimally tuning large pre-trained models. This shift, driven by techniques like learning to generate optimal prompts and parameter-efficient fine-tuning, unlocks the immense potential of foundational models for rapid adaptation across a vast array of few-shot downstream applications. However, challenges remain in fully understanding the emergent properties of in-context learning, developing universally robust and parameter-efficient meta-learning strategies, scaling meta-training to encompass the full diversity of tasks that these increasingly capable foundational models can address, and advancing the theoretical understanding of meta-optimization in these overparameterized regimes.\n\\subsection{Safety and Interpretability in Meta-Learning Systems}\n\\label{sec:6\\_4\\_safety\\_\\_and\\_\\_interpretability\\_in\\_meta-learning\\_systems}\n\nThe deployment of highly adaptive meta-learning systems in real-world, often safety-critical, applications necessitates a rigorous focus on their safety and interpretability. While meta-learning excels at rapid adaptation to new tasks with limited data, ensuring that this adaptability does not compromise reliability, transparency, and trustworthiness is paramount. Recent advancements are beginning to address these crucial aspects, moving towards more responsible AI development.\n\nA significant step towards reliable autonomous systems is the development of meta-safe reinforcement learning (Meta-SRL), which provides provable guarantees for safety. \\cite{khattar2024sr6} introduces a novel \"CMDP-within-online\" framework for Meta-SRL, offering the first provable guarantees for task-averaged regret and constraint violations in Constrained Markov Decision Processes (CMDPs). This framework is critical for enabling RL agents to adapt quickly to unseen tasks while strictly adhering to safety constraints, even in the presence of inexact policies and state visitation distributions. Complementing this, \\cite{lupu20249p4} presents MAGICVFM, a stable adaptive controller for ground vehicles that integrates visual foundation models with meta-learning for real-time terrain adaptation. This system is backed by mathematical guarantees of exponential stability and robustness, directly contributing to the safe operation of autonomous systems in complex, dynamic environments. Similarly, \\cite{oconnell2022twd} demonstrates Neural-Fly, a meta-learning approach that enables rapid online adaptation for agile UAV flight in strong winds, providing robustness and exponential stability guarantees crucial for safe aerial navigation.\n\nBeyond explicit safety guarantees, interpretability and reliable confidence estimates are vital for trust and accountability, particularly in human-machine interaction. \\cite{tam2024a1h} addresses this by proposing a deep metric meta-learning framework for robust and interpretable EMG-based hand gesture recognition. Their method learns a semantically meaningful embedding space and derives a class proximity-based confidence estimator, offering more reliable and transparent confidence measures than traditional softmax outputs, which is crucial for safety-critical applications like prosthetic control. This approach tackles the poor generalization and overconfidence issues prevalent in conventional deep learning models. In a similar vein, \\cite{chen2022z45} and \\cite{wistuba2021wha} leverage meta-learning with deep kernel Gaussian Processes (GPs) to provide robust predictions with well-calibrated uncertainty estimates in few-shot settings, such as molecular property prediction and hyperparameter optimization. These calibrated uncertainties are essential for informed decision-making and building trust in high-stakes scientific and engineering domains. Further enhancing reliability, \\cite{aqeel2025zql} introduces Confident Meta-learning (CoMet) for unsupervised anomaly detection, which integrates soft confident learning to assign lower weights to low-confidence samples and meta-learning to stabilize training. This approach improves robustness to noisy data and provides critical confidence signals for anomaly detection, a key safety function.\n\nThe robustness of meta-learning systems to continuous data streams and evolving tasks also contributes to their overall safety and reliability. \\cite{holla20202od} tackles catastrophic forgetting in lifelong language learning by combining meta-learning with sparse experience replay. By preventing models from losing previously acquired knowledge, this method ensures sustained performance and reliability in dynamic environments. Building on this, \\cite{lee2024snq} proposes Sequential Bayesian Meta-Continual Learning (SB-MCL), a framework that inherently prevents catastrophic forgetting in neural networks by offloading sequential updates to robust statistical models, thereby ensuring long-term reliability and stability of learned knowledge.\n\nDespite these advancements, the efficacy of meta-learning in all safety-critical domains is not universally established. For instance, \\cite{guarino2023zsq} conducted a comprehensive comparison of meta-learning, transfer learning, and contrastive learning for encrypted traffic classification, a security-critical task. Their findings indicated that meta-learning methods, at least with the evaluated techniques and protocols, performed worse than other representation learning paradigms. This highlights the imperative for careful evaluation and validation of meta-learning approaches in specific safety-critical contexts, as their benefits are not guaranteed across all application types.\n\nIn conclusion, while meta-learning offers powerful tools for rapid adaptation, the integration of provable safety guarantees, interpretable confidence estimates, and robust continual learning mechanisms is crucial for its responsible deployment. Future research must continue to bridge the gap between adaptive effectiveness and the stringent requirements of safety, transparency, and trustworthiness, ensuring that these advanced AI systems can be reliably used in the most demanding real-world scenarios.\n\n\n\\label{sec:challenges_and_future_directions}\n\n\\section{Challenges and Future Directions}\n\\label{sec:challenges\\_\\_and\\_\\_future\\_directions}\n\n\\subsection{Theoretical Gaps and Generalization Challenges}\n\\label{sec:7\\_1\\_theoretical\\_gaps\\_\\_and\\_\\_generalization\\_challenges}\n\nDespite significant advancements, deep meta-learning continues to grapple with fundamental theoretical limitations and persistent generalization challenges, particularly when confronted with truly novel task distributions. A critical issue is meta-overfitting, where meta-learners excel on meta-training tasks but struggle to adapt effectively to unseen tasks that deviate significantly from the meta-training distribution, often exhibiting sensitivity to subtle shifts in task characteristics \\cite{wang2024bhk, khoee2024ksk}.\n\nThe challenge of meta-overfitting is a central concern. Traditional meta-learning, often relying on bi-level optimization, can lead to underfitting or overfitting depending on task complexity, hindering generalization \\cite{wang2024bhk}. To address this, \\textcite{wang2024bhk} proposed TRLearner, a plug-and-play method that introduces relation-aware consistency regularization based on extracted task relation matrices. This approach offers theoretical guarantees for improved generalization by ensuring consistent performance on similar tasks, moving beyond simple empirical observations. Similarly, in the context of Vision-Language Models, \\textcite{wang2024dai} tackled the generalization challenge in prompt tuning, where models often overfit to base classes and perform poorly on novel ones. Their meta-learning-informed episodic training strategy effectively mitigates this overfitting, demonstrating improved generalization to new classes.\n\nA related problem is the meta-learner's tendency to \"memorize\" meta-training tasks rather than learning a truly adaptive mechanism. \\textcite{yin2019cct} highlighted this by showing that meta-learners can sometimes solve all meta-training tasks zero-shot without actual adaptation, leading to poor performance on novel tasks. They proposed an information-theoretic meta-regularization objective to prioritize data-driven adaptation. The sensitivity to shifts in task distribution is particularly evident in cross-domain few-shot learning. \\textcite{tian2023iyh} addressed this by proposing an adversarial meta-training framework that dynamically generates pseudo tasks to improve generalization to unseen domains, emphasizing the need for robust meta-knowledge. Surveys like \\textcite{khoee2024ksk} further formalize the problem of Domain Generalization through meta-learning, underscoring that effective generalization to unseen domains necessitates sufficient diversity in meta-training tasks. Practical applications also highlight these limitations; for instance, \\textcite{zhu2022d9a} and \\textcite{zhu2020rb5} developed meta-learning solutions for No-Reference Image Quality Assessment to improve generalization to unseen distortion types, a common real-world challenge. However, meta-learning's efficacy is not universally guaranteed; \\textcite{guarino2023zsq}'s empirical study on encrypted traffic classification found that meta-learning methods performed worse than transfer or contrastive learning, suggesting that in some domains, the learned meta-knowledge may not transfer as effectively. This is further supported by observations from the NeurIPS 2021 MetaDL challenge, where backbone fine-tuning often outperformed episodic meta-learning, indicating that simpler transfer learning might sometimes be more effective for generalization \\cite{baz2022n78}.\n\nBeyond empirical observations, there is a pressing need for stronger theoretical guarantees for generalization across diverse tasks. While some works provide theoretical foundations, such as \\textcite{finn2017vrt} demonstrating the universality of gradient-based meta-learning in approximating any learning algorithm, these do not always translate into robust generalization guarantees for complex real-world scenarios. More specific theoretical insights are emerging, such as \\textcite{bernacchia20211r0}'s surprising finding that the optimal inner loop learning rate for MAML during meta-training can be negative. This theoretical analysis, derived from random matrix theory and the Neural Tangent Kernel framework, offers a deeper understanding of MAML's generalization behavior and challenges conventional assumptions about gradient-based optimization in meta-learning. In safety-critical applications, theoretical guarantees are paramount; \\textcite{khattar2024sr6} introduced a CMDP-within-online framework for Meta-Safe Reinforcement Learning, providing the first provable guarantees for task-averaged regret and constraint violations. Similarly, \\textcite{lupu20249p4} developed MAGICVFM for ground vehicle control, integrating visual foundation models and meta-learning with mathematical stability guarantees, showcasing a move towards theoretically robust adaptive systems.\n\nThe computational complexity of meta-training and the challenges associated with scaling meta-learning algorithms to very large and highly heterogeneous task distributions remain crucial areas for foundational research. Early surveys, such as \\textcite{huisman2020b7w}, already identified high computational costs as a significant open challenge. Optimization-based meta-learning, particularly methods like MAML, often involve backpropagating through multiple inner-loop gradient steps, leading to substantial memory and computational overhead. To mitigate this, \\textcite{bertinetto2018ur2} proposed meta-learning with differentiable closed-form solvers (e.g., Ridge Regression), which allows for efficient adaptation and backpropagation by leveraging matrix identities. Building on this, \\textcite{przewiezlikowski2022d4y} introduced HyperMAML, replacing MAML's gradient-based inner loop with a trainable hypernetwork to generate more substantial and efficient weight updates in a single step, thereby reducing computational complexity. The meta-learning of optimizers, as seen in \\textcite{ozkara2024nst}'s MADA framework, also implicitly aims to improve the overall efficiency of the learning process itself. Furthermore, scaling meta-learning to very large and distributed task distributions, especially in privacy-sensitive domains, has led to the integration of federated learning. Approaches like \\textcite{you2024xuq}'s FMGCN for EV charging demand forecasting, \\textcite{liu2024jz5}'s AFM3D for driver distraction detection, and \\textcite{qu2022mu6}'s ALL for parking occupancy prediction, combine federated learning with meta-learning to address data silos, heterogeneity, and computational efficiency in distributed, multi-client environments. These efforts highlight the ongoing struggle to make meta-learning practical and scalable for real-world, dynamic, and diverse task landscapes.\n\nIn conclusion, while deep meta-learning has demonstrated impressive capabilities in few-shot learning and adaptation, significant theoretical and practical hurdles persist. The field continues to grapple with fundamental issues of meta-overfitting and sensitivity to task distribution shifts, necessitating more robust regularization and task-aware learning mechanisms. The demand for stronger theoretical guarantees for generalization, moving beyond empirical success to provable performance, remains a critical research direction. Simultaneously, addressing the inherent computational complexity and developing scalable meta-learning algorithms for increasingly large and heterogeneous task distributions are crucial for unlocking the full potential of learning-to-learn paradigms in real-world applications.\n\\subsection{Ethical Considerations and Societal Impact}\n\\label{sec:7\\_2\\_ethical\\_considerations\\_\\_and\\_\\_societal\\_impact}\n\nThe rapid advancement of autonomous and adaptive meta-learning systems, while promising significant technological breakthroughs, simultaneously introduces profound ethical implications and necessitates careful consideration of their broader societal impact. As these systems learn \"how to learn\" and adapt to novel tasks with minimal human intervention, critical discussions surrounding potential issues such as bias amplification, the challenge of accountability, and the risk of misuse become increasingly urgent.\n\nA primary concern revolves around \\textbf{bias amplification}. Meta-learning algorithms are designed to extract generalizable knowledge from a distribution of tasks \\cite{hospedales2020m37, huisman2020b7w}. If the data used for meta-training, or the tasks themselves, contain existing societal biases, the meta-learner can inadvertently perpetuate or even exacerbate these biases when applied to new, unseen scenarios. For instance, in deep face recognition, where training data is often imbalanced across various demographic and environmental factors, meta-learning approaches must explicitly account for \"diverse data biases\" to prevent significant accuracy degradation for underrepresented groups \\cite{liu2022tgc}. Similarly, in information retrieval, meta-learning frameworks are being developed to address \"data bias\" and promote \"fair ranking\" by guiding the meta-learner to mitigate skewness towards biased attributes \\cite{wang2024so2}. Furthermore, methods that leverage self-supervised learning from unlabeled data \\cite{li2023zn0} or learn from uncurated datasets \\cite{aqeel2025zql} risk embedding and amplifying latent biases present in these larger, less scrutinized data pools if not carefully designed with fairness in mind. Even efforts to improve data quality through meta-learning, such as data valuation \\cite{yoon2019k84} or learning from noisy labels \\cite{li2018soc}, could inadvertently prioritize data points that reinforce existing biases if the underlying valuation or noise models are themselves biased.\n\nThe inherent adaptability of meta-learning systems also poses significant challenges for \\textbf{accountability}. When AI systems learn not just parameters, but the very rules or initializations that govern their adaptation \\cite{Finn\\_MAML\\_2017, Nichol\\_Reptile\\_2018}, their decision-making processes can become opaque and emergent. This complexity makes it difficult to trace \\textit{why} a system behaved in a particular way or adapted to a new situation in a specific manner. The intricate interplay of initialization layers and learned \"meta-layers\" for task-specific fine-tuning, as explored in efforts to rethink meta-learning's core mechanisms \\cite{wang2024bhk}, adds layers of abstraction that complicate interpretability. Similarly, meta-adaptive optimizers that dynamically learn the most suitable optimization strategy during training \\cite{ozkara2024nst} further obscure the causal chain of decisions. Recognizing these challenges, some research directly addresses accountability in safety-critical domains. For example, meta-safe reinforcement learning aims to provide \"provable guarantees\" for task-averaged regret and constraint violations in complex environments, a crucial step towards ensuring reliable behavior in autonomous systems \\cite{khattar2024sr6}. In ground interaction control for vehicles, the integration of visual foundation models with meta-learning for real-time adaptation, while offering \"mathematical stability guarantees,\" still presents interpretability challenges for understanding specific adaptations \\cite{lupu20249p4}. Efforts to enhance \"interpretability\" and provide \"robust confidence estimates\" in human-machine interfaces, such as EMG-based hand gesture recognition, directly acknowledge the need for transparent decision-making in adaptive systems \\cite{tam2024a1h}.\n\nBeyond these, the \\textbf{potential for misuse} of highly adaptable meta-learning technologies is a critical concern. The ability of meta-learning to enable rapid learning from few examples \\cite{sung2017nc5, li2023zn0, wang2024dai} is a double-edged sword. While beneficial for legitimate applications like few-shot malware classification \\cite{li20246zp, wang2023kho} or medical diagnosis, this same capability could be exploited for malicious purposes, such as rapidly deploying surveillance systems for new targets, generating targeted disinformation, or developing more evasive adversarial agents. The power of domain generalization \\cite{khoee2024ksk} and cross-domain transfer learning \\cite{jang2019a48, chai2022kv5, liang2021juf, cheng2024mky} means models can be trained on one dataset and quickly adapted to another, potentially enabling malicious actors to bypass security measures or adapt to new adversarial environments more rapidly. Even privacy-preserving paradigms like federated meta-learning \\cite{you2024xuq, liu2024jz5, qu2022mu6}, designed to keep data localized, could introduce new privacy risks if the meta-learning process itself is compromised or if the aggregated meta-knowledge inadvertently reveals sensitive information.\n\nIn conclusion, while meta-learning promises to unlock unprecedented levels of AI adaptability and efficiency, its ethical implications demand proactive attention. The inherent risks of bias amplification, the complexities of ensuring accountability in highly adaptive systems, and the potential for misuse underscore the urgent need for responsible development, transparent deployment, and robust regulatory frameworks. Future research must not only focus on advancing algorithmic performance but also prioritize the integration of fairness-aware designs, enhanced interpretability, and provable safety guarantees into meta-learning architectures to ensure that these powerful advancements contribute positively to society while mitigating their inherent risks.\n\\subsection{Emerging Trends and Hybrid Approaches}\n\\label{sec:7\\_3\\_emerging\\_trends\\_\\_and\\_\\_hybrid\\_approaches}\n\nThe trajectory of deep meta-learning is increasingly defined by a concerted effort to transcend isolated paradigms, fostering integrated, hybrid approaches that draw strength from diverse methodologies to develop more robust, efficient, and truly generalizable adaptive AI systems \\cite{hospedales2020m37}. This subsection delineates promising future research directions, emphasizing the growing interest in combining different meta-learning methodologies, the continued exploration of biologically inspired mechanisms, and the expansion into novel, high-impact applications.\n\nA significant emerging trend involves the explicit hybridization of meta-learning paradigms, moving beyond single-paradigm solutions to leverage complementary strengths. For instance, the integration of probabilistic modeling with optimization-based or metric-based insights is enhancing task inference and efficient exploration. While foundational probabilistic meta-RL methods like VariBAD \\cite{zintgraf2019zat} and PEARL \\cite{rakelly2019m09} have been instrumental in learning Bayes-adaptive policies and improving sample efficiency (as discussed in Section 5.2), their future lies in deeper integration with other meta-learning types. This includes approaches that use optimization to refine probabilistic models or metric learning. For example, \\cite{tseng2020m83} proposed Gradient Dropout, an optimization-based regularization technique for gradient-based meta-learning that mitigates overfitting by randomly dropping gradients during inner-loop adaptation, thereby improving generalization, particularly when combined with other meta-learning strategies. Furthermore, meta-learning is increasingly applied to refine metric learning itself, as demonstrated by \\cite{chen2019oep}'s Deep Meta Metric Learning (DMML) for learning set-based distances, \\cite{zheng20200ig}'s DML-ALA for adaptive learnable assessment, and \\cite{jiang20220tg}'s MMSI for meta-mining strategies with semiglobal information. These works exemplify hybrid approaches where a meta-learner (often optimization-based) is employed to discover more robust and generalizable similarity measures, thereby enhancing the performance of metric-based systems. This synergistic combination aims to create systems that not only adapt quickly but also quantify uncertainty and make more informed decisions.\n\nAnother prominent direction focuses on learning adaptive algorithms and architectures, often drawing inspiration from biological systems or employing meta-gradients to discover optimal learning processes. The concept of \"learning to learn\" extends to learning the very algorithms that govern adaptation, a powerful idea with roots in early work showing recurrent neural networks (RNNs) could implicitly learn reinforcement learning algorithms \\cite{wang20167px}. This has evolved into the field of meta-gradients, where gradients are computed through the learning process itself to optimize meta-parameters \\cite{sutton2022jss}. For instance, \\cite{xu2020txy} proposed FRODO, an algorithm that uses meta-gradient descent to discover its own RL objective function online by parameterizing the update target with a neural network, moving beyond handcrafted objectives. Theoretically, gradient-based meta-learning, such as MAML, has been shown to possess universal approximation capabilities for learning algorithms, suggesting its potential to discover highly effective learning strategies \\cite{finn2017vrt}. Biologically inspired mechanisms offer another avenue for adaptive architectures. Directly inspired by cellular neuromodulation, \\cite{vecoven2018hc1} introduced Neuro-Modulated Networks (NMNs), where a neuromodulatory network dynamically tunes the activation function parameters of a main network, leading to faster and more stable adaptive behaviors. Similarly, \\cite{fernando2018lt5} explored meta-learning by the Baldwin effect, demonstrating its capability to evolve few-shot supervised and reinforcement learning mechanisms by shaping hyperparameters and initial parameters without requiring backpropagation through meta-parameters. These approaches collectively aim to imbue AI systems with intrinsic, flexible adaptation capabilities, moving towards more autonomous and robust learning.\n\nThese emerging trends are paving the way for novel applications in complex real-world domains, pushing the boundaries of what adaptive AI can achieve. In scientific discovery, meta-learning holds immense promise for accelerating research by enabling models to generalize from limited, heterogeneous data. For example, \\cite{ruwurm2024806} introduced METEOR, a meta-learning methodology for Earth observation problems that adapts to diverse tasks and resolutions, using knowledge from global land cover information to perform well on new, unseen geospatial problems with few labels. This demonstrates meta-learning's capacity to extract generalizable insights from vast, varied datasets and apply them to specific, data-scarce scientific challenges. Another critical area is personalized medicine, where meta-learning's ability to adapt to individual patient data, handle data scarcity, and account for heterogeneity is invaluable for tasks like drug discovery, personalized diagnostics, and treatment optimization. While direct citations of meta-learning in personalized medicine are still emerging, the principles demonstrated in personalized robotics \\cite{yu2018nm7} and adaptive control systems \\cite{wang2020tae, ma20243e9, visca20217nt} strongly suggest its imminent impact. Furthermore, meta-learning is crucial for enhancing the adaptability of large pre-trained models in complex scenarios, such as class incremental learning in NLP \\cite{kumar2024he9, lee2021jou}, where it enables models to efficiently learn new classes without catastrophic forgetting or extensive retraining. The ability to rapidly adapt to new environments and tasks, as seen in meta-RL for robotics and control, and for resource management, underscores its potential to tackle dynamic and non-stationary real-world challenges.\n\nIn conclusion, the future of deep meta-learning is marked by a concerted effort to move beyond isolated paradigms towards integrated, hybrid approaches that draw strength from diverse methodologies. The increasing sophistication of probabilistic modeling, the ambition to learn the very algorithms and architectures of adaptation, and the expansion into complex real-world applications like scientific discovery and personalized medicine collectively underscore a vision for truly adaptive and generalizable AI. While significant progress has been made in enhancing robustness, efficiency, and generalization, challenges remain in scaling these hybrid systems to even greater complexity, ensuring stronger theoretical guarantees for learned objectives \\cite{chen2021j5t}, and developing robust generalization mechanisms across vastly different task distributions. Addressing these frontiers will be crucial for the field's continued evolution towards more versatile and impactful adaptive AI systems.\n\n\n\\label{sec:conclusion}\n\n\\section{Conclusion}\n\\label{sec:conclusion}\n\n\n\n\\newpage\n\\section*{References}\n\\addcontentsline{toc}{section}{References}\n\n\\begin{thebibliography}{285}\n\n\\bibitem{sung2017nc5}\nFlood Sung, Yongxin Yang, Li Zhang, et al. (2017). \\textit{Learning to Compare: Relation Network for Few-Shot Learning}. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition.\n\n\\bibitem{hospedales2020m37}\nTimothy M. Hospedales, Antreas Antoniou, P. Micaelli, et al. (2020). \\textit{Meta-Learning in Neural Networks: A Survey}. IEEE Transactions on Pattern Analysis and Machine Intelligence.\n\n\\bibitem{santoro2016323}\nAdam Santoro, Sergey Bartunov, M. Botvinick, et al. (2016). \\textit{Meta-Learning with Memory-Augmented Neural Networks}. International Conference on Machine Learning.\n\n\\bibitem{sun2018iy7}\nQianru Sun, Yaoyao Liu, Tat-Seng Chua, et al. (2018). \\textit{Meta-Transfer Learning for Few-Shot Learning}. Computer Vision and Pattern Recognition.\n\n\\bibitem{bertinetto2018ur2}\nLuca Bertinetto, João F. Henriques, Philip H. S. Torr, et al. (2018). \\textit{Meta-learning with differentiable closed-form solvers}. International Conference on Learning Representations.\n\n\\bibitem{rakelly2019m09}\nKate Rakelly, Aurick Zhou, Deirdre Quillen, et al. (2019). \\textit{Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables}. International Conference on Machine Learning.\n\n\\bibitem{wang20167px}\nJane X. Wang, Z. Kurth-Nelson, Hubert Soyer, et al. (2016). \\textit{Learning to reinforcement learn}. Annual Meeting of the Cognitive Science Society.\n\n\\bibitem{franceschi2018u1q}\nLuca Franceschi, P. Frasconi, Saverio Salzo, et al. (2018). \\textit{Bilevel Programming for Hyperparameter Optimization and Meta-Learning}. International Conference on Machine Learning.\n\n\\bibitem{pan2019pue}\nZheyi Pan, Yuxuan Liang, Weifeng Wang, et al. (2019). \\textit{Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning}. Knowledge Discovery and Data Mining.\n\n\\bibitem{lanctot2017m2v}\nMarc Lanctot, V. Zambaldi, A. Gruslys, et al. (2017). \\textit{A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning}. Neural Information Processing Systems.\n\n\\bibitem{finn20174c4}\nChelsea Finn, Tianhe Yu, Tianhao Zhang, et al. (2017). \\textit{One-Shot Visual Imitation Learning via Meta-Learning}. Conference on Robot Learning.\n\n\\bibitem{huisman2020b7w}\nM. Huisman, Jan N. van Rijn, and A. Plaat (2020). \\textit{A survey of deep meta-learning}. Artificial Intelligence Review.\n\n\\bibitem{oconnell2022twd}\nM. O'Connell, Guanya Shi, Xichen Shi, et al. (2022). \\textit{Neural-Fly enables rapid learning for agile flight in strong winds}. Science Robotics.\n\n\\bibitem{zhu2020rb5}\nHancheng Zhu, Leida Li, Jinjian Wu, et al. (2020). \\textit{MetaIQA: Deep Meta-Learning for No-Reference Image Quality Assessment}. Computer Vision and Pattern Recognition.\n\n\\bibitem{herzen2021300}\nJ. Herzen, Francesco Lässig, Samuele Giuliano Piazzetta, et al. (2021). \\textit{Darts: User-Friendly Modern Machine Learning for Time Series}. Journal of machine learning research.\n\n\\bibitem{wang2020tae}\nJin Wang, Jia Hu, G. Min, et al. (2020). \\textit{Fast Adaptive Task Offloading in Edge Computing Based on Meta Reinforcement Learning}. IEEE Transactions on Parallel and Distributed Systems.\n\n\\bibitem{yu2018nm7}\nTianhe Yu, Chelsea Finn, Annie Xie, et al. (2018). \\textit{One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning}. Robotics: Science and Systems.\n\n\\bibitem{zintgraf2019zat}\nLuisa M. Zintgraf, Kyriacos Shiarlis, Maximilian Igl, et al. (2019). \\textit{VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning}. International Conference on Learning Representations.\n\n\\bibitem{li2018soc}\nJunnan Li, Yongkang Wong, Qi Zhao, et al. (2018). \\textit{Learning to Learn From Noisy Labeled Data}. Computer Vision and Pattern Recognition.\n\n\\bibitem{guo2021zpk}\nZhichun Guo, Chuxu Zhang, W. Yu, et al. (2021). \\textit{Few-Shot Graph Learning for Molecular Property Prediction}. The Web Conference.\n\n\\bibitem{li20219tk}\nShuang Li, Kaixiong Gong, Chi Harold Liu, et al. (2021). \\textit{MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition}. Computer Vision and Pattern Recognition.\n\n\\bibitem{tian2022znj}\nYingjie Tian, Xiaoxi Zhao, and Wei-Hsin Huang (2022). \\textit{Meta-learning approaches for learning-to-learn in deep learning: A survey}. Neurocomputing.\n\n\\bibitem{oh2017x02}\nJunhyuk Oh, Satinder Singh, Honglak Lee, et al. (2017). \\textit{Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning}. International Conference on Machine Learning.\n\n\\bibitem{papoudakis2019gyl}\nGeorgios Papoudakis, Filippos Christianos, Arrasy Rahman, et al. (2019). \\textit{Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning}. arXiv.org.\n\n\\bibitem{yoon2019k84}\nJinsung Yoon, Sercan Ö. Arik, and Tomas Pfister (2019). \\textit{Data Valuation using Reinforcement Learning}. International Conference on Machine Learning.\n\n\\bibitem{rajasegaran2020llk}\nJathushan Rajasegaran, Salman Hameed Khan, Munawar Hayat, et al. (2020). \\textit{iTAML: An Incremental Task-Agnostic Meta-learning Approach}. Computer Vision and Pattern Recognition.\n\n\\bibitem{yin2019cct}\nMingzhang Yin, G. Tucker, Mingyuan Zhou, et al. (2019). \\textit{Meta-Learning without Memorization}. International Conference on Learning Representations.\n\n\\bibitem{qiao2019p6r}\nLimeng Qiao, Yemin Shi, Jia Li, et al. (2019). \\textit{Transductive Episodic-Wise Adaptive Metric for Few-Shot Learning}. IEEE International Conference on Computer Vision.\n\n\\bibitem{gao2020h75}\nKuiliang Gao, Bing Liu, Xuchu Yu, et al. (2020). \\textit{Deep Relation Network for Hyperspectral Image Few-Shot Classification}. Remote Sensing.\n\n\\bibitem{patacchiola2020kpq}\nMassimiliano Patacchiola, Jack Turner, Elliot J. Crowley, et al. (2020). \\textit{Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels}. Neural Information Processing Systems.\n\n\\bibitem{nagabandi2018esl}\nAnusha Nagabandi, Chelsea Finn, and S. Levine (2018). \\textit{Deep Online Learning via Meta-Learning: Continual Adaptation for Model-Based RL}. International Conference on Learning Representations.\n\n\\bibitem{finn2017vrt}\nChelsea Finn, and S. Levine (2017). \\textit{Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm}. International Conference on Learning Representations.\n\n\\bibitem{such2019xok}\nF. Such, Aditya Rawal, J. Lehman, et al. (2019). \\textit{Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data}. International Conference on Machine Learning.\n\n\\bibitem{fei20211x6}\nNanyi Fei, Yizhao Gao, Zhiwu Lu, et al. (2021). \\textit{Z-Score Normalization, Hubness, and Few-Shot Learning}. IEEE International Conference on Computer Vision.\n\n\\bibitem{wang2021ya6}\nShaofei Wang, Marko Mihajlovic, Qianli Ma, et al. (2021). \\textit{MetaAvatar: Learning Animatable Clothed Human Models from Few Depth Images}. Neural Information Processing Systems.\n\n\\bibitem{jang2019a48}\nYunhun Jang, Hankook Lee, Sung Ju Hwang, et al. (2019). \\textit{Learning What and Where to Transfer}. International Conference on Machine Learning.\n\n\\bibitem{zhu2022zp1}\nTaiyu Zhu, Kezhi Li, P. Herrero, et al. (2022). \\textit{Personalized Blood Glucose Prediction for Type 1 Diabetes Using Evidential Deep Learning and Meta-Learning}. IEEE Transactions on Biomedical Engineering.\n\n\\bibitem{gao20223fn}\nJun Gao, Dongze Wu, Feng Yin, et al. (2022). \\textit{MetaLoc: Learning to Learn Wireless Localization}. IEEE Journal on Selected Areas in Communications.\n\n\\bibitem{bartler2021i8o}\nAlexander Bartler, Andreas Bühler, Felix Wiewel, et al. (2021). \\textit{MT3: Meta Test-Time Training for Self-Supervised Test-Time Adaption}. International Conference on Artificial Intelligence and Statistics.\n\n\\bibitem{memon2022j2y}\nM. Memon, Pardeep Kumar, and R. Iqbal (2022). \\textit{Meta Deep Learn Leaf Disease Identification Model for Cotton Crop}. De Computis.\n\n\\bibitem{yang2018p36}\nZhaoyang Yang, K. Merrick, Lianwen Jin, et al. (2018). \\textit{Hierarchical Deep Reinforcement Learning for Continuous Action Control}. IEEE Transactions on Neural Networks and Learning Systems.\n\n\\bibitem{guo2020acf}\nHuifeng Guo, Bo Chen, Ruiming Tang, et al. (2020). \\textit{An Embedding Learning Framework for Numerical Features in CTR Prediction}. Knowledge Discovery and Data Mining.\n\n\\bibitem{dixit20218dd}\nSonal Dixit, N. Verma, and A. K. Ghosh (2021). \\textit{Intelligent Fault Diagnosis of Rotary Machines: Conditional Auxiliary Classifier GAN Coupled With Meta Learning Using Limited Data}. IEEE Transactions on Instrumentation and Measurement.\n\n\\bibitem{zhou20200ls}\nAllan Zhou, Tom Knowles, and Chelsea Finn (2020). \\textit{Meta-Learning Symmetries by Reparameterization}. International Conference on Learning Representations.\n\n\\bibitem{rajasegaran2020glw}\nJathushan Rajasegaran, Salman Hameed Khan, Munawar Hayat, et al. (2020). \\textit{Self-supervised Knowledge Distillation for Few-shot Learning}. British Machine Vision Conference.\n\n\\bibitem{wang2022va1}\nYulei Wang, Xi Chen, Fengchao Wang, et al. (2022). \\textit{Meta-Learning based Hyperspectral Target Detection using Siamese Network}. IEEE Transactions on Geoscience and Remote Sensing.\n\n\\bibitem{dufumier2021ec1}\nBenoit Dufumier, P. Gori, J. Victor, et al. (2021). \\textit{Contrastive Learning with Continuous Proxy Meta-Data for 3D MRI Classification}. International Conference on Medical Image Computing and Computer-Assisted Intervention.\n\n\\bibitem{wistuba2021wha}\nMartin Wistuba, and Josif Grabocka (2021). \\textit{Few-Shot Bayesian Optimization with Deep Kernel Surrogates}. International Conference on Learning Representations.\n\n\\bibitem{ren2019nu0}\nYuxiang Ren, Bo Liu, Chao Huang, et al. (2019). \\textit{Heterogeneous Deep Graph Infomax}. arXiv.org.\n\n\\bibitem{zhang2020p3y}\nShen Zhang, Fei Ye, Bingnan Wang, et al. (2020). \\textit{Few-Shot Bearing Fault Diagnosis Based on Model-Agnostic Meta-Learning}. IEEE transactions on industry applications.\n\n\\bibitem{zhou20188lr}\nFengwei Zhou, Bin Wu, and Zhenguo Li (2018). \\textit{Deep Meta-Learning: Learning to Learn in the Concept Space}. arXiv.org.\n\n\\bibitem{bing2022om0}\nZhenshan Bing, David Lerch, Kai Huang, et al. (2022). \\textit{Meta-Reinforcement Learning in Non-Stationary and Dynamic Environments}. IEEE Transactions on Pattern Analysis and Machine Intelligence.\n\n\\bibitem{tian20200qx}\nShan Tian, Songsong Mo, Liwei Wang, et al. (2020). \\textit{Deep Reinforcement Learning-Based Approach to Tackle Topic-Aware Influence Maximization}. Data Science and Engineering.\n\n\\bibitem{cai20215z1}\nRizhao Cai, Zhi Li, Renjie Wan, et al. (2021). \\textit{Learning Meta Pattern for Face Anti-Spoofing}. IEEE Transactions on Information Forensics and Security.\n\n\\bibitem{wang2021i3l}\nYaqing Wang, Fenglong Ma, Haoyu Wang, et al. (2021). \\textit{Multimodal Emergent Fake News Detection via Meta Neural Process Networks}. Knowledge Discovery and Data Mining.\n\n\\bibitem{nam2022z75}\nTaewook Nam, Shao-Hua Sun, Karl Pertsch, et al. (2022). \\textit{Skill-based Meta-Reinforcement Learning}. International Conference on Learning Representations.\n\n\\bibitem{zhu2022d9a}\nHancheng Zhu, Leida Li, Jinjian Wu, et al. (2022). \\textit{Generalizable No-Reference Image Quality Assessment via Deep Meta-Learning}. IEEE transactions on circuits and systems for video technology (Print).\n\n\\bibitem{wang20204p9}\nZhen Wang, Guosheng Hu, and Q. Hu (2020). \\textit{Training Noise-Robust Deep Neural Networks via Meta-Learning}. Computer Vision and Pattern Recognition.\n\n\\bibitem{xu2020txy}\nZhongwen Xu, H. V. Hasselt, Matteo Hessel, et al. (2020). \\textit{Meta-Gradient Reinforcement Learning with an Objective Discovered Online}. Neural Information Processing Systems.\n\n\\bibitem{xue2022ram}\nSiqiao Xue, C. Qu, X. Shi, et al. (2022). \\textit{A Meta Reinforcement Learning Approach for Predictive Autoscaling in the Cloud}. Knowledge Discovery and Data Mining.\n\n\\bibitem{li20208tg}\nShunkai Li, Xin Wang, Yingdian Cao, et al. (2020). \\textit{Self-Supervised Deep Visual Odometry With Online Adaptation}. Computer Vision and Pattern Recognition.\n\n\\bibitem{chai2022kv5}\nYitian Chai, Hongyu Zhang, Beijun Shen, et al. (2022). \\textit{Cross-Domain Deep Code Search with Meta Learning}. International Conference on Software Engineering.\n\n\\bibitem{yi2021547}\nHongsuk Yi, and Khac-Hoai Nam Bui (2021). \\textit{An Automated Hyperparameter Search-Based Deep Learning Model for Highway Traffic Prediction}. IEEE transactions on intelligent transportation systems (Print).\n\n\\bibitem{pang2018qqo}\nKunkun Pang, Mingzhi Dong, Yang Wu, et al. (2018). \\textit{Meta-Learning Transferable Active Learning Policies by Deep Reinforcement Learning}. arXiv.org.\n\n\\bibitem{zhang2020s15}\nHaimiao Zhang, Baodong Liu, Hengyong Yu, et al. (2020). \\textit{MetaInv-Net: Meta Inversion Network for Sparse View CT Image Reconstruction}. IEEE Transactions on Medical Imaging.\n\n\\bibitem{zintgraf2021lv1}\nLuisa M. Zintgraf, Sebastian Schulze, Cong Lu, et al. (2021). \\textit{VariBAD: Variational Bayes-Adaptive Deep RL via Meta-Learning}. Journal of machine learning research.\n\n\\bibitem{ouyang2021c4t}\nW. Ouyang, Xiuwu Zhang, Shukui Ren, et al. (2021). \\textit{Learning Graph Meta Embeddings for Cold-Start Ads in Click-Through Rate Prediction}. Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.\n\n\\bibitem{li2019gpj}\nJuncheng Li, X. Wang, Siliang Tang, et al. (2019). \\textit{Unsupervised Reinforcement Learning of Transferable Meta-Skills for Embodied Navigation}. Computer Vision and Pattern Recognition.\n\n\\bibitem{yu2019o41}\nLantao Yu, Tianhe Yu, Chelsea Finn, et al. (2019). \\textit{Meta-Inverse Reinforcement Learning with Probabilistic Context Variables}. Neural Information Processing Systems.\n\n\\bibitem{chen2021j5t}\nQi Chen, Changjian Shui, and M. Marchand (2021). \\textit{Generalization Bounds For Meta-Learning: An Information-Theoretic Analysis}. Neural Information Processing Systems.\n\n\\bibitem{zintgraf2021hoc}\nLuisa M. Zintgraf, Sam Devlin, K. Ciosek, et al. (2021). \\textit{Deep Interactive Bayesian Reinforcement Learning via Meta-Learning}. Adaptive Agents and Multi-Agent Systems.\n\n\\bibitem{xu20199h0}\nHao Xu, Haibin Chang, and Dongxiao Zhang (2019). \\textit{DL-PDE: Deep-learning based data-driven discovery of partial differential equations from discrete and noisy data}. Communications in Computational Physics.\n\n\\bibitem{ding2021284}\nKaize Ding, Jianling Wang, James Caverlee, et al. (2021). \\textit{Meta Propagation Networks for Graph Few-shot Semi-supervised Learning}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{reed2017sxd}\nScott E. Reed, Yutian Chen, T. Paine, et al. (2017). \\textit{Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions}. International Conference on Learning Representations.\n\n\\bibitem{shao2021loj}\nHuikai Shao, Dexing Zhong, Xuefeng Du, et al. (2021). \\textit{Few-Shot Learning for Palmprint Recognition via Meta-Siamese Network}. IEEE Transactions on Instrumentation and Measurement.\n\n\\bibitem{jomaa20190ul}\nH. Jomaa, Josif Grabocka, and L. Schmidt-Thieme (2019). \\textit{Dataset2Vec: learning dataset meta-features}. Data mining and knowledge discovery.\n\n\\bibitem{woo2022f3e}\nGerald Woo, Chenghao Liu, Doyen Sahoo, et al. (2022). \\textit{Learning Deep Time-index Models for Time Series Forecasting}. International Conference on Machine Learning.\n\n\\bibitem{park2020m5z}\nSeongho Park, S. Han, Ji-Won Baek, et al. (2020). \\textit{Meta Variance Transfer: Learning to Augment from the Others}. International Conference on Machine Learning.\n\n\\bibitem{chen2019oep}\nGuangyi Chen, Tianren Zhang, Jiwen Lu, et al. (2019). \\textit{Deep Meta Metric Learning}. IEEE International Conference on Computer Vision.\n\n\\bibitem{marra20192vv}\nG. Marra, Francesco Giannini, Michelangelo Diligenti, et al. (2019). \\textit{Integrating Learning and Reasoning with Deep Logic Models}. ECML/PKDD.\n\n\\bibitem{casebeer20225fs}\nJonah Casebeer, Nicholas J. Bryan, and Paris Smaragdis (2022). \\textit{Meta-AF: Meta-Learning for Adaptive Filters}. IEEE/ACM Transactions on Audio Speech and Language Processing.\n\n\\bibitem{nobakht2022p86}\nMehrnoosh Nobakht, R. Javidan, and A. Pourebrahimi (2022). \\textit{DEMD-IoT: a deep ensemble model for IoT malware detection using CNNs and network traffic}. Evolutionary Systematics.\n\n\\bibitem{vasconcelos2021fn3}\nC. Vasconcelos, H. Larochelle, Vincent Dumoulin, et al. (2021). \\textit{Impact of Aliasing on Generalization in Deep Convolutional Networks}. IEEE International Conference on Computer Vision.\n\n\\bibitem{libin2020x8v}\nPieter J. K. Libin, Arno Moonens, T. Verstraeten, et al. (2020). \\textit{Deep reinforcement learning for large-scale epidemic control}. ECML/PKDD.\n\n\\bibitem{algan2020u0v}\nG. Algan, and I. Ulusoy (2020). \\textit{Meta Soft Label Generation for Noisy Labels}. International Conference on Pattern Recognition.\n\n\\bibitem{lan20196o7}\nLin Lan, Zhenguo Li, X. Guan, et al. (2019). \\textit{Meta Reinforcement Learning with Task Embedding and Shared Policy}. International Joint Conference on Artificial Intelligence.\n\n\\bibitem{huang20214b2}\nChao Huang, Zhangjie Cao, Yunbo Wang, et al. (2021). \\textit{MetaSets: Meta-Learning on Point Sets for Generalizable Representations}. Computer Vision and Pattern Recognition.\n\n\\bibitem{chen2022z45}\nWenlin Chen, Austin Tripp, and José Miguel Hernández-Lobato (2022). \\textit{Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction}. International Conference on Learning Representations.\n\n\\bibitem{abdollahzadeh2021zfy}\nMilad Abdollahzadeh, Touba Malekzadeh, and Ngai-Man Cheung (2021). \\textit{Revisit Multimodal Meta-Learning through the Lens of Multi-Task Learning}. Neural Information Processing Systems.\n\n\\bibitem{chen2019xg0}\nShangyu Chen, Wenya Wang, and Sinno Jialin Pan (2019). \\textit{MetaQuant: Learning to Quantize by Learning to Penetrate Non-differentiable Quantization}. Neural Information Processing Systems.\n\n\\bibitem{xu2018rdh}\nTianbing Xu, Qiang Liu, Liang Zhao, et al. (2018). \\textit{Learning to Explore with Meta-Policy Gradient}. International Conference on Machine Learning.\n\n\\bibitem{shen2022kdk}\nXiangyu Shen, Haifeng Zheng, Xinxin Feng, et al. (2022). \\textit{ML-HGR-Net: A Meta-Learning Network for FMCW Radar Based Hand Gesture Recognition}. IEEE Sensors Journal.\n\n\\bibitem{zhang2021hh1}\nHuayi Zhang, Lei Cao, Peter M. VanNostrand, et al. (2021). \\textit{ELITE: Robust Deep Anomaly Detection with Meta Gradient}. Knowledge Discovery and Data Mining.\n\n\\bibitem{lin2022i6k}\nHong Lin, Rita Tse, Su-Kit Tang, et al. (2022). \\textit{Few-shot learning approach with multi-scale feature fusion and attention for plant disease recognition}. Frontiers in Plant Science.\n\n\\bibitem{tseng2020m83}\nHung-Yu Tseng, Yi-Wen Chen, Yi-Hsuan Tsai, et al. (2020). \\textit{Regularizing Meta-Learning via Gradient Dropout}. Asian Conference on Computer Vision.\n\n\\bibitem{peng20209of}\nHuimin Peng (2020). \\textit{A Comprehensive Overview and Survey of Recent Advances in Meta-Learning}. arXiv.org.\n\n\\bibitem{fong20183q5}\nS. Fong, S. Deb, and Xin-She Yang (2018). \\textit{How meta-heuristic algorithms contribute to deep learning in the hype of big data analytics}. Unpublished manuscript.\n\n\\bibitem{liu2022tgc}\nChang Liu, Xiang Yu, Yao-Hung Hubert Tsai, et al. (2022). \\textit{Learning to Learn across Diverse Data Biases in Deep Face Recognition}. Computer Vision and Pattern Recognition.\n\n\\bibitem{bing2022xo7}\nZhenshan Bing, A. Koch, Xiangtong Yao, et al. (2022). \\textit{Meta-Reinforcement Learning via Language Instructions}. IEEE International Conference on Robotics and Automation.\n\n\\bibitem{nakasi2020w5x}\nRose Nakasi, Ernest Mwebaze, A. Zawedde, et al. (2020). \\textit{A new approach for microscopic diagnosis of malaria parasites in thick blood smears using pre-trained deep learning models}. SN Applied Sciences.\n\n\\bibitem{przewiezlikowski2022d4y}\nMarcin Przewiezlikowski, P. Przybysz, J. Tabor, et al. (2022). \\textit{HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks}. Neurocomputing.\n\n\\bibitem{xu2018rjq}\nTianbing Xu, Qiang Liu, Liang Zhao, et al. (2018). \\textit{Learning to Explore via Meta-Policy Gradient}. International Conference on Machine Learning.\n\n\\bibitem{ding2019a79}\nYue Ding, Xia Tian, Lirong Yin, et al. (2019). \\textit{Multi-scale Relation Network for Few-Shot Learning Based on Meta-learning}. International Conference on Virtual Storytelling.\n\n\\bibitem{dorfman2020gku}\nRon Dorfman, and Aviv Tamar (2020). \\textit{Offline Meta Learning of Exploration}. Unpublished manuscript.\n\n\\bibitem{wang20210y3}\nZe Wang, Zichen Miao, Xiantong Zhen, et al. (2021). \\textit{Learning to Learn Dense Gaussian Processes for Few-Shot Learning}. Neural Information Processing Systems.\n\n\\bibitem{millea2021bfu}\nAdrian Millea (2021). \\textit{Deep Reinforcement Learning for Trading - A Critical Survey}. International Conference on Data Technologies and Applications.\n\n\\bibitem{lindsey202075a}\nJack W Lindsey, and Ashok Litwin-Kumar (2020). \\textit{Learning to Learn with Feedback and Local Plasticity}. Neural Information Processing Systems.\n\n\\bibitem{gao2022y3s}\nJun Gao, Ceyao Zhang, Qinglei Kong, et al. (2022). \\textit{MetaLoc: Learning to Learn Indoor RSS Fingerprinting Localization over Multiple Scenarios}. ICC 2022 - IEEE International Conference on Communications.\n\n\\bibitem{ren2022fc5}\nXinyue Ren, Weiwei Zhang, Ming-hui Wu, et al. (2022). \\textit{Meta-YOLO: Meta-Learning for Few-Shot Traffic Sign Detection via Decoupling Dependencies}. Applied Sciences.\n\n\\bibitem{wen2022sql}\nXin-Cheng Wen, Cuiyun Gao, Jiaxin Ye, et al. (2022). \\textit{Meta-Path Based Attentional Graph Learning Model for Vulnerability Detection}. IEEE Transactions on Software Engineering.\n\n\\bibitem{vecoven2018hc1}\nNicolas Vecoven, D. Ernst, Antoine Wehenkel, et al. (2018). \\textit{Introducing neuromodulation in deep neural networks to learn adaptive behaviours}. PLoS ONE.\n\n\\bibitem{liang2021juf}\nXuejian Liang, Yehui Zhang, and Junping Zhang (2021). \\textit{Attention Multisource Fusion-Based Deep Few-Shot Learning for Hyperspectral Image Classification}. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing.\n\n\\bibitem{holla2020r6z}\nNithin Holla, Pushkar Mishra, H. Yannakoudakis, et al. (2020). \\textit{Learning to Learn to Disambiguate: Meta-Learning for Few-Shot Word Sense Disambiguation}. Findings.\n\n\\bibitem{fernando2018lt5}\nChrisantha Fernando, Jakub Sygnowski, Simon Osindero, et al. (2018). \\textit{Meta-learning by the Baldwin effect}. Annual Conference on Genetic and Evolutionary Computation.\n\n\\bibitem{jankowski20138zb}\nNorbert Jankowski, Wlodzislaw Duch, and Krzysztof Grabczewski (2013). \\textit{Meta-Learning in Computational Intelligence}. Meta-Learning in Computational Intelligence.\n\n\\bibitem{banayeeanzade2021zke}\nMohammadamin Banayeeanzade, Rasoul Mirzaiezadeh, Hosein Hasani, et al. (2021). \\textit{Generative vs. Discriminative: Rethinking The Meta-Continual Learning}. Neural Information Processing Systems.\n\n\\bibitem{campedelli2021jja}\nG. Campedelli, Mihovil Bartulovic, and K. Carley (2021). \\textit{Learning future terrorist targets through temporal meta-graphs}. Scientific Reports.\n\n\\bibitem{jiang20220tg}\nXiruo Jiang, Sheng Liu, Xili Dai, et al. (2022). \\textit{Deep Metric Learning Based on Meta-Mining Strategy With Semiglobal Information}. IEEE Transactions on Neural Networks and Learning Systems.\n\n\\bibitem{zheng2021olf}\nWenbo Zheng, Lan Yan, Chao Gou, et al. (2021). \\textit{Learning to learn by yourself: Unsupervised meta‐learning with self‐knowledge distillation for COVID‐19 diagnosis from pneumonia cases}. International Journal of Intelligent Systems.\n\n\\bibitem{alandoli2021pqm}\nM. Al-Andoli, Shing Chiang Tan, W. Cheah, et al. (2021). \\textit{A Review on Community Detection in Large Complex Networks from Conventional to Deep Learning Methods: A Call for the Use of Parallel Meta-Heuristic Algorithms}. IEEE Access.\n\n\\bibitem{li2021tkg}\nDenghao Li, Pablo Ortega, Xia Wei, et al. (2021). \\textit{Model-Agnostic Meta-Learning for EEG Motor Imagery Decoding in Brain-Computer-Interfacing}. International IEEE/EMBS Conference on Neural Engineering.\n\n\\bibitem{daglarli2020nzw}\nEvren Daglarli (2020). \\textit{Explainable Artificial Intelligence (xAI) Approaches and Deep Meta-Learning Models}. Advances and Applications in Deep Learning.\n\n\\bibitem{phaphuangwittayakul2022api}\nAniwat Phaphuangwittayakul, Fangli Ying, Yi Guo, et al. (2022). \\textit{Few-shot image generation based on contrastive meta-learning generative adversarial network}. The Visual Computer.\n\n\\bibitem{nie2021pcz}\nJing Nie, Nianyi Wang, Jingbin Li, et al. (2021). \\textit{Meta-learning prediction of physical and chemical properties of magnetized water and fertilizer based on LSTM}. Plant Methods.\n\n\\bibitem{zheng20200ig}\nWenzhao Zheng, Jiwen Lu, and Jie Zhou (2020). \\textit{Deep Metric Learning via Adaptive Learnable Assessment}. Computer Vision and Pattern Recognition.\n\n\\bibitem{chen2022ccz}\nYixiong Chen, Chunhui Zhang, C. Ding, et al. (2022). \\textit{Generating and Weighting Semantically Consistent Sample Pairs for Ultrasound Contrastive Learning}. IEEE Transactions on Medical Imaging.\n\n\\bibitem{qu2022mu6}\nH. Qu, Sheng Liu, Jun Li, et al. (2022). \\textit{Adaptation and Learning to Learn (ALL): An Integrated Approach for Small-Sample Parking Occupancy Prediction}. Mathematics.\n\n\\bibitem{alajaji2020b6c}\nD. Alajaji, and H. Alhichri (2020). \\textit{Few Shot Scene Classification in Remote Sensing using Meta-Agnostic Machine}. 2020 6th Conference on Data Science and Machine Learning Applications (CDMA).\n\n\\bibitem{jiang2021uo6}\nMengjuan Jiang, Fanzhang Li, and Li Liu (2021). \\textit{Continual meta-learning algorithm}. Applied intelligence (Boston).\n\n\\bibitem{rkhami2021c1c}\nAnouar Rkhami, Yassine Hadjadj-Aoul, and A. Outtagarts (2021). \\textit{Learn to improve: A novel deep reinforcement learning approach for beyond 5G network slicing}. Consumer Communications and Networking Conference.\n\n\\bibitem{holla20202od}\nNithin Holla, Pushkar Mishra, H. Yannakoudakis, et al. (2020). \\textit{Meta-Learning with Sparse Experience Replay for Lifelong Language Learning}. arXiv.org.\n\n\\bibitem{bhathiya2020avm}\nH. S. Bhathiya, and Uthayasanker Thayasivam (2020). \\textit{Meta Learning for Few-Shot Joint Intent Detection and Slot-Filling}. International Conference on Machine Learning Technologies.\n\n\\bibitem{bernacchia20211r0}\nA. Bernacchia (2021). \\textit{Meta-learning with negative learning rates}. International Conference on Learning Representations.\n\n\\bibitem{kumar2017p0v}\nSaurabh Kumar, Pararth Shah, Dilek Z. Hakkani-Tür, et al. (2017). \\textit{Federated Control with Hierarchical Multi-Agent Deep Reinforcement Learning}. arXiv.org.\n\n\\bibitem{daglarli20216fl}\nEvren Daglarli (2021). \\textit{Explainable Artificial Intelligence (xAI) Approaches and Deep Meta-Learning Models for Cyber-Physical Systems}. Advances in Systems Analysis, Software Engineering, and High Performance Computing.\n\n\\bibitem{baz2022n78}\nAdrian El Baz, André Carvalho, Hong Chen, et al. (2022). \\textit{Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification}. Neural Information Processing Systems.\n\n\\bibitem{dorfman2020mgv}\nRon Dorfman, and Aviv Tamar (2020). \\textit{Offline Meta Reinforcement Learning}. arXiv.org.\n\n\\bibitem{vuorio2018gwb}\nRisto Vuorio, D.-Y. Cho, Daejoong Kim, et al. (2018). \\textit{Meta Continual Learning}. arXiv.org.\n\n\\bibitem{ma2021kfz}\nYing Ma, G. Zhong, Wen Liu, et al. (2021). \\textit{ML-CGAN: Conditional Generative Adversarial Network with a Meta-learner Structure for High-Quality Image Generation with Few Training Data}. Cognitive Computation.\n\n\\bibitem{tian2016j46}\nZhonghuan Tian, and S. Fong (2016). \\textit{Survey of Meta-Heuristic Algorithms for Deep Learning Training}. Unpublished manuscript.\n\n\\bibitem{pinedaarango2021254}\nSebastian Pineda-Arango, Felix Heinrich, Kiran Madhusudhanan, et al. (2021). \\textit{Multimodal Meta-Learning for Time Series Regression}. AALTD@ECML/PKDD.\n\n\\bibitem{foliadis20223y2}\nAnastasios Foliadis, M. H. C. García, R. Stirling-Gallacher, et al. (2022). \\textit{Multi-Environment based Meta-Learning with CSI Fingerprints for Radio Based Positioning}. IEEE Wireless Communications and Networking Conference.\n\n\\bibitem{sutton2022jss}\nR. Sutton (2022). \\textit{A History of Meta-gradient: Gradient Methods for Meta-learning}. arXiv.org.\n\n\\bibitem{huo2022rp4}\nHaomiao Huo, Jindan Xu, Gege Su, et al. (2022). \\textit{Intelligent MIMO Detection Using Meta Learning}. IEEE Wireless Communications Letters.\n\n\\bibitem{hurtado2021h2q}\nJ. Hurtado, Hans Lobel, and Álvaro Soto (2021). \\textit{Overcoming Catastrophic Forgetting Using Sparse Coding and Meta Learning}. IEEE Access.\n\n\\bibitem{lee2021jou}\nHung-yi Lee, Ngoc Thang Vu, and Shang-Wen Li (2021). \\textit{Meta Learning and Its Applications to Natural Language Processing}. Annual Meeting of the Association for Computational Linguistics.\n\n\\bibitem{peixoto20180pd}\nB. Peixoto, S. Avila, Zanoni Dias, et al. (2018). \\textit{Breaking down violence: A deep-learning strategy to model and classify violence in videos}. ARES.\n\n\\bibitem{yuan20205j8}\nPengyu Yuan, Aryan Mobiny, J. Jahanipour, et al. (2020). \\textit{Few Is Enough: Task-Augmented Active Meta-Learning for Brain Cell Classification}. International Conference on Medical Image Computing and Computer-Assisted Intervention.\n\n\\bibitem{zhang2021yox}\nZitian Zhang, Fuyou Li, Xiaoli Chu, et al. (2021). \\textit{dmTP: A Deep Meta-Learning Based Framework for Mobile Traffic Prediction}. IEEE wireless communications.\n\n\\bibitem{luo202123f}\nYaoru Luo, Guole Liu, Yuanhao Guo, et al. (2021). \\textit{Deep Neural Networks Learn Meta-Structures from Noisy Labels in Semantic Segmentation}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{chen2021yqh}\nMengting Chen, Xinggang Wang, Heng Luo, et al. (2021). \\textit{Learning to focus: cascaded feature matching network for few-shot image recognition}. Science China Information Sciences.\n\n\\bibitem{behl2018rjm}\nHarkirat Singh Behl, M. Najafi, and Philip H. S. Torr (2018). \\textit{Meta-Learning Deep Visual Words for Fast Video Object Segmentation}. IEEE/RJS International Conference on Intelligent RObots and Systems.\n\n\\bibitem{xu2019brv}\nZhixiong Xu, Lei Cao, and Xi-liang Chen (2019). \\textit{Learning to Learn: Hierarchical Meta-Critic Networks}. IEEE Access.\n\n\\bibitem{sultana202094g}\nN. Sultana, Jeffrey Chan, and A. K. Qin (2020). \\textit{Learning to Optimise General TSP Instances}. arXiv.org.\n\n\\bibitem{furfaro20197q6}\nR. Furfaro, T. Campbell, R. Linares, et al. (2019). \\textit{Space Debris Identification and Characterization via Deep Meta-Learning}. Unpublished manuscript.\n\n\\bibitem{gu2019tvc}\nKeren Gu, S. Greydanus, Luke Metz, et al. (2019). \\textit{Meta-Learning Biologically Plausible Semi-Supervised Update Rules}. bioRxiv.\n\n\\bibitem{zhang2021p9j}\nYaobin Zhang, Weihong Deng, Yaoyao Zhong, et al. (2021). \\textit{Adaptive Label Noise Cleaning with Meta-Supervision for Deep Face Recognition}. IEEE International Conference on Computer Vision.\n\n\\bibitem{saadallah2021ihn}\nA. Saadallah, and K. Morik (2021). \\textit{Online Ensemble Aggregation using Deep Reinforcement Learning for Time Series Forecasting}. International Conference on Data Science and Advanced Analytics.\n\n\\bibitem{luedtke2020uub}\nAlexander Luedtke, M. Carone, N. Simon, et al. (2020). \\textit{Learning to learn from data: Using deep adversarial learning to construct optimal statistical procedures}. Science Advances.\n\n\\bibitem{nasrabadi201801h}\nMorteza Zakeri Nasrabadi, S. Parsa, and A. Kalaee (2018). \\textit{Format-aware learn&fuzz: deep test data generation for efficient fuzzing}. Neural computing & applications (Print).\n\n\\bibitem{puri20202sx}\nR. Puri, A. Zakhor, and Raul Puri (2020). \\textit{Few Shot Learning For Point Cloud Data Using Model Agnostic Meta Learning}. International Conference on Information Photonics.\n\n\\bibitem{beck2023x24}\nJacob Beck, Risto Vuorio, E. Liu, et al. (2023). \\textit{A Tutorial on Meta-Reinforcement Learning}. Found. Trends Mach. Learn..\n\n\\bibitem{zhang2023t7k}\nBaoquan Zhang, and Demin Yu (2023). \\textit{MetaDiff: Meta-Learning with Conditional Diffusion for Few-Shot Learning}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{khoee2024ksk}\nArsham Gholamzadeh Khoee, Yinan Yu, and R. Feldt (2024). \\textit{Domain Generalization through Meta-Learning: A Survey}. Artificial Intelligence Review.\n\n\\bibitem{hao2023zfk}\nXiaoyang Hao, Zhixi Feng, Shuyuan Yang, et al. (2023). \\textit{Automatic Modulation Classification via Meta-Learning}. IEEE Internet of Things Journal.\n\n\\bibitem{nathaniel2023ycu}\nJuan Nathaniel, Jiangong Liu, and P. Gentine (2023). \\textit{MetaFlux: Meta-learning global carbon fluxes from sparse spatiotemporal observations}. Scientific Data.\n\n\\bibitem{singh2023zo5}\nKuljeet Singh, and Deepti Malhotra (2023). \\textit{Meta-Health: Learning-to-Learn (Meta-learning) as a Next Generation of Deep Learning Exploring Healthcare Challenges and Solutions for Rare Disorders: A Systematic Analysis}. Archives of Computational Methods in Engineering.\n\n\\bibitem{wang2023srr}\nPeiqi Wang, Jingde Li, Shubei Wang, et al. (2023). \\textit{A new meta-transfer learning method with freezing operation for few-shot bearing fault diagnosis}. Measurement science and technology.\n\n\\bibitem{liang2023zzh}\nXiaoxia Liang, M. Zhang, Guojin Feng, et al. (2023). \\textit{A Novel Deep Model with Meta-learning for Rolling Bearing Few-shot Fault Diagnosis}. Journal of Dynamics Monitoring and Diagnostics.\n\n\\bibitem{tian2023iyh}\nPinzhuo Tian, and Shaorong Xie (2023). \\textit{An Adversarial Meta-Training Framework for Cross-Domain Few-Shot Learning}. IEEE transactions on multimedia.\n\n\\bibitem{bian2024041}\nWanyu Bian, Albert Jang, and Fang Liu (2024). \\textit{Multi-task Magnetic Resonance Imaging Reconstruction using Meta-learning}. Magnetic Resonance Imaging.\n\n\\bibitem{schwarz2022jfu}\nJonathan Schwarz, and Y. Teh (2022). \\textit{Meta-Learning Sparse Compression Networks}. Trans. Mach. Learn. Res..\n\n\\bibitem{son2023lda}\nJaehyeon Son, Soochan Lee, and Gunhee Kim (2023). \\textit{When Meta-Learning Meets Online and Continual Learning: A Survey}. IEEE Transactions on Pattern Analysis and Machine Intelligence.\n\n\\bibitem{wang2024d09}\nHui Wang, Zhiwei Han, Xufan Wang, et al. (2024). \\textit{Contrastive Learning-Based Bayes-Adaptive Meta-Reinforcement Learning for Active Pantograph Control in High-Speed Railways}. IEEE Transactions on Transportation Electrification.\n\n\\bibitem{rao20232e3}\nHaocong Rao, Cyril Leung, and Chun Miao (2023). \\textit{Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard Skeleton Mining for Unsupervised Person Re-Identification}. International Journal of Computer Vision.\n\n\\bibitem{zhang2023jz8}\nYiqiang Zhang, Jiaxing Che, Yijun Hu, et al. (2023). \\textit{Real-Time Ocean Current Compensation for AUV Trajectory Tracking Control Using a Meta-Learning and Self-Adaptation Hybrid Approach}. Italian National Conference on Sensors.\n\n\\bibitem{xiu2023ga8}\nXi Xiu, Jialun Li, Yujie Long, et al. (2023). \\textit{MRLCC: an adaptive cloud task scheduling method based on meta reinforcement learning}. Journal of Cloud Computing.\n\n\\bibitem{cai2023ro7}\nShaokang Cai, Dezhi Han, and Dun Li (2023). \\textit{A Feedback Semi-Supervised Learning With Meta-Gradient for Intrusion Detection}. IEEE Systems Journal.\n\n\\bibitem{lee20230j8}\nSuyoung Lee, Myungsik Cho, and Young-Jin Sung (2023). \\textit{Parameterizing Non-Parametric Meta-Reinforcement Learning Tasks via Subtask Decomposition}. Neural Information Processing Systems.\n\n\\bibitem{guarino2023zsq}\nIdio Guarino, Chao Wang, A. Finamore, et al. (2023). \\textit{Many or Few Samples?: Comparing Transfer, Contrastive and Meta-Learning in Encrypted Traffic Classification}. Traffic Monitoring and Analysis.\n\n\\bibitem{aqeel2025zql}\nMuhammad Aqeel, Shakiba Sharifi, Marco Cristani, et al. (2025). \\textit{Towards Real Unsupervised Anomaly Detection Via Confident Meta-Learning}. arXiv.org.\n\n\\bibitem{lee2024snq}\nSoochan Lee, Hyeonseong Jeon, Jaehyeon Son, et al. (2024). \\textit{Learning to Continually Learn with the Bayesian Principle}. International Conference on Machine Learning.\n\n\\bibitem{li2023asx}\nZhongshen Li, Junru Jin, Wenjia He, et al. (2023). \\textit{CoraL: interpretable contrastive meta-learning for the prediction of cancer-associated ncRNA-encoded small peptides}. Briefings Bioinform..\n\n\\bibitem{schmidgall20238t4}\nSamuel Schmidgall, and Joe Hays (2023). \\textit{Meta-SpikePropamine: learning to learn with synaptic plasticity in spiking neural networks}. Frontiers in Neuroscience.\n\n\\bibitem{wang2023x5w}\nWeijie Wang, Hong Zhao, Yikun Yang, et al. (2023). \\textit{Few-shot short utterance speaker verification using meta-learning}. PeerJ Computer Science.\n\n\\bibitem{wang2023ryf}\nCaiyong Wang, Haiqing Li, Wen-bin Ma, et al. (2023). \\textit{MetaScleraSeg: an effective meta-learning framework for generalized sclera segmentation}. Neural computing & applications (Print).\n\n\\bibitem{li2023fhe}\nWenmei Li, Qing Liu, Yu Zhang, et al. (2023). \\textit{Few-Shot Hyperspectral Image Classification Using Meta Learning and Regularized Finetuning}. IEEE Transactions on Geoscience and Remote Sensing.\n\n\\bibitem{yang20238th}\nJin Yang, Liang Bao, Wenjing Liu, et al. (2023). \\textit{On a Meta Learning-Based Scheduler for Deep Learning Clusters}. IEEE Transactions on Cloud Computing.\n\n\\bibitem{raja2023hco}\nK. Raja, and S. Kannimuthu (2023). \\textit{Deep learning-based feature selection and prediction system for autism spectrum disorder using a hybrid meta-heuristics approach}. Journal of Intelligent & Fuzzy Systems.\n\n\\bibitem{fahim2023jsu}\nM. Fahim, Vishal Sharma, R. Hunter, et al. (2023). \\textit{Healthy Aging: A Deep Meta-Class Sequence Model to Integrate Intelligence in Digital Twin}. IEEE Journal of Translational Engineering in Health and Medicine.\n\n\\bibitem{hu2022y0i}\nCong Hu, Haoji Xu, and Xiaojun Wu (2022). \\textit{Substitute Meta-Learning for Black-Box Adversarial Attack}. IEEE Signal Processing Letters.\n\n\\bibitem{wang2023kho}\nZhiqiang Wang, Man Li, H. Ou, et al. (2023). \\textit{A Few-Shot Malicious Encrypted Traffic Detection Approach Based on Model-Agnostic Meta-Learning}. Security and Communication Networks.\n\n\\bibitem{li2023zn0}\nHui Li, Guimin Huang, Yiqun Li, et al. (2023). \\textit{SEML: Self-Supervised Information-Enhanced Meta-learning for Few-Shot Text Classification}. International Journal of Computational Intelligence Systems.\n\n\\bibitem{chi20235vq}\nSunyi Chi, B. Dong, Yiming Xu, et al. (2023). \\textit{APAM: Adaptive Pre-Training and Adaptive Meta Learning in Language Model for Noisy Labels and Long-Tailed Learning}. International Conference on Machine Learning and Applications.\n\n\\bibitem{manoharan2021r46}\nPraveen Manoharan, Malini Pooni Venkat, S. Nagarathinam, et al. (2021). \\textit{Learn to chill: intelligent chiller scheduling using meta-learning and deep reinforcement learning}. International Conference on Systems for Energy-Efficient Built Environments.\n\n\\bibitem{visca20217nt}\nMarco Visca, R. Powell, Yang Gao, et al. (2021). \\textit{Deep Meta-Learning Energy-Aware Path Planner for Unmanned Ground Vehicles in Unknown Terrains}. IEEE Access.\n\n\\bibitem{so2021y48}\nChaehan So (2021). \\textit{Exploring Meta Learning: Parameterizing the Learning-to-learn Process for Image Classification}. Digital Signal Processing and Signal Processing Education Workshop.\n\n\\bibitem{yang2022oxf}\nZhixiong Yang, Jingyuan Xia, T. Qiu, et al. (2022). \\textit{A Meta-Learning based Gradient Descent Algorithm for MU-MIMO Beamforming}. International Conference on Wireless Communications and Signal Processing.\n\n\\bibitem{gupta2021fbg}\nAkash Gupta, P. Jonnalagedda, B. Bhanu, et al. (2021). \\textit{Ada-VSR: Adaptive Video Super-Resolution with Meta-Learning}. ACM Multimedia.\n\n\\bibitem{zheng2021dx4}\nWenbo Zheng, Lan Yan, Fei-Yue Wang, et al. (2021). \\textit{Learning from the Web: Webly Supervised Meta-Learning for Masked Face Recognition}. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW).\n\n\\bibitem{zhang2021sbz}\nPeng Zhang, Chenbing Liu, Xingshuo Chang, et al. (2021). \\textit{Metric-based Meta-Learning Model for Few-Shot PolSAR Image Terrain Classification}. Radar.\n\n\\bibitem{wang2024jzu}\nChien-Yao Wang, I-Hau Yeh, and Hongpeng Liao (2024). \\textit{YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information}. European Conference on Computer Vision.\n\n\\bibitem{zhu20249wq}\nFenghao Zhu, Xinquan Wang, Chongwen Huang, et al. (2024). \\textit{Robust Beamforming for RIS-Aided Communications: Gradient-Based Manifold Meta Learning}. IEEE Transactions on Wireless Communications.\n\n\\bibitem{yaghoubi2024j56}\nElaheh Yaghoubi, Elnaz Yaghoubi, Ahmed Khamees, et al. (2024). \\textit{A systematic review and meta-analysis of artificial neural network, machine learning, deep learning, and ensemble learning approaches in field of geotechnical engineering}. Neural computing & applications (Print).\n\n\\bibitem{ren20242qj}\nLei Ren, Tingyu Mo, and Xuejun Cheng (2024). \\textit{Meta-learning Based Domain Generalization Framework for Fault Diagnosis With Gradient Aligning and Semantic Matching}. IEEE Transactions on Industrial Informatics.\n\n\\bibitem{ik20248rp}\nGültekin Işık, and Ishak Paçal (2024). \\textit{Few-shot classification of ultrasound breast cancer images using meta-learning algorithms}. Neural computing & applications (Print).\n\n\\bibitem{weilenmann2024ve2}\nC. Weilenmann, A. Ziogas, T. Zellweger, et al. (2024). \\textit{Single neuromorphic memristor closely emulates multiple synaptic mechanisms for energy efficient neural networks}. Nature Communications.\n\n\\bibitem{xia2024qx2}\nJingyuan Xia, Zhixiong Yang, Shengxi Li, et al. (2024). \\textit{Blind Super-Resolution via Meta-Learning and Markov Chain Monte Carlo Simulation}. IEEE Transactions on Pattern Analysis and Machine Intelligence.\n\n\\bibitem{zhao2024f4b}\nHaoming Zhao, Liang Ou, Ziming Zhang, et al. (2024). \\textit{The value of deep learning-based X-ray techniques in detecting and classifying K-L grades of knee osteoarthritis: a systematic review and meta-analysis}. European Radiology.\n\n\\bibitem{li20242rv}\nJiawen Li, Tao Zhou, and Haoyan Cui (2024). \\textit{Brain-Inspired Deep Meta-Reinforcement Learning for Active Coordinated Fault-Tolerant Load Frequency Control of Multi-Area Grids}. IEEE Transactions on Automation Science and Engineering.\n\n\\bibitem{dong2024110}\nZheng Dong, Renhe Jiang, Haotian Gao, et al. (2024). \\textit{Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series Forecasting}. Knowledge Discovery and Data Mining.\n\n\\bibitem{liao2024o1z}\nHuaizhang Liao, Jingyuan Xia, Zhixiong Yang, et al. (2024). \\textit{Meta-Learning Based Domain Prior With Application to Optical-ISAR Image Translation}. IEEE transactions on circuits and systems for video technology (Print).\n\n\\bibitem{naskar202446a}\nGourab Naskar, Sk Mohiuddin, Samir Malakar, et al. (2024). \\textit{Deepfake detection using deep feature stacking and meta-learning}. Heliyon.\n\n\\bibitem{zhang2024a5a}\nRuiyi Zhang, Rushi Qiang, Sai Ashish Somayajula, et al. (2024). \\textit{AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning}. North American Chapter of the Association for Computational Linguistics.\n\n\\bibitem{sharma2024zlw}\nNelson Sharma, Aswini Ghosh, R. Misra, et al. (2024). \\textit{Deep Meta Q-Learning Based Multi-Task Offloading in Edge-Cloud Systems}. IEEE Transactions on Mobile Computing.\n\n\\bibitem{ouyang2024xj0}\nTiancheng Ouyang, Yingying Su, Chengchao Wang, et al. (2024). \\textit{Combined Meta-Learning With CNN-LSTM Algorithms for State-of-Health Estimation of Lithium-Ion Battery}. IEEE transactions on power electronics.\n\n\\bibitem{wang2025zze}\nChangdong Wang, Zhou Shu, Jingli Yang, et al. (2025). \\textit{Learning to Imbalanced Open Set Generalize: A Meta-Learning Framework for Enhanced Mechanical Diagnosis}. IEEE Transactions on Cybernetics.\n\n\\bibitem{chia2024ltk}\nYu-Hsin Chia, Wei-Hao Liao, S. Vyas, et al. (2024). \\textit{In Vivo Intelligent Fluorescence Endo‐Microscopy by Varifocal Meta‐Device and Deep Learning}. Advancement of science.\n\n\\bibitem{li20246fg}\nWenzhong Li, Xiang Li, Yeting Xu, et al. (2024). \\textit{MetaABR: A Meta-Learning Approach on Adaptative Bitrate Selection for Video Streaming}. IEEE Transactions on Mobile Computing.\n\n\\bibitem{yang2024rh9}\nJing Yang, and Xiaomin Wang (2024). \\textit{Meta-learning with deep flow kernel network for few shot cross-domain remaining useful life prediction}. Reliability Engineering & System Safety.\n\n\\bibitem{gao20242uv}\nYuan Gao, Wei Chen, Fajun Li, et al. (2024). \\textit{Meta‐Attention Deep Learning for Smart Development of Metasurface Sensors}. Advancement of science.\n\n\\bibitem{huang2024hlo}\nHai-Hui Huang, Jun Shu, and Yong Liang (2024). \\textit{MUMA: A Multi-Omics Meta-Learning Algorithm for Data Interpretation and Classification}. IEEE journal of biomedical and health informatics.\n\n\\bibitem{liu2024hko}\nShicheng Liu, and Minghui Zhu (2024). \\textit{Meta Inverse Constrained Reinforcement Learning: Convergence Guarantee and Generalization Analysis}. International Conference on Learning Representations.\n\n\\bibitem{li2024x2t}\nJiawen Li, and Yuanyuan Cheng (2024). \\textit{Deep Meta-Reinforcement Learning-Based Data-Driven Active Fault Tolerance Load Frequency Control for Islanded Microgrids Considering Internet of Things}. IEEE Internet of Things Journal.\n\n\\bibitem{khattar2024sr6}\nVanshaj Khattar, Yuhao Ding, Bilgehan Sel, et al. (2024). \\textit{A CMDP-within-online framework for Meta-Safe Reinforcement Learning}. International Conference on Learning Representations.\n\n\\bibitem{yen2024cxp}\nTzu-Yun Yen, Chan-Shien Ho, Yueh-peng Chen, et al. (2024). \\textit{Diagnostic Accuracy of Deep Learning for the Prediction of Osteoporosis Using Plain X-rays: A Systematic Review and Meta-Analysis}. Diagnostics.\n\n\\bibitem{you2024xuq}\nLinlin You, Qiyang Chen, Haohao Qu, et al. (2024). \\textit{FMGCN: Federated Meta Learning-Augmented Graph Convolutional Network for EV Charging Demand Forecasting}. IEEE Internet of Things Journal.\n\n\\bibitem{hao2024dyp}\nXiaoyang Hao, Zhixi Feng, Tongqing Peng, et al. (2024). \\textit{Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification}. IEEE Internet of Things Journal.\n\n\\bibitem{lang20246m8}\nShujun Lang, Xu Liu, Mingliang Zhou, et al. (2024). \\textit{A Full-Reference Image Quality Assessment Method via Deep Meta-Learning and Conformer}. IEEE transactions on broadcasting.\n\n\\bibitem{xu2024ywn}\nMeng Xu, Yi Mei, Fangfang Zhang, et al. (2024). \\textit{Niching Genetic Programming to Learn Actions for Deep Reinforcement Learning in Dynamic Flexible Scheduling}. IEEE Transactions on Evolutionary Computation.\n\n\\bibitem{ding2024jjo}\nYang Ding, Heng Zhang, and Ting Qiu (2024). \\textit{Deep learning approach to predict autism spectrum disorder: a systematic review and meta-analysis}. BMC Psychiatry.\n\n\\bibitem{wang2024dai}\nFengxiang Wang, Wanrong Huang, Shaowu Yang, et al. (2024). \\textit{Learning to Learn Better Visual Prompts}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{nussenbaum2024z82}\nKate Nussenbaum, and Catherine A. Hartley (2024). \\textit{Understanding the development of reward learning through the lens of meta-learning}. Nature Reviews Psychology.\n\n\\bibitem{alsaleh2024vdv}\nAqilah M. Alsaleh, Eid Albalawi, A. Algosaibi, et al. (2024). \\textit{Few-Shot Learning for Medical Image Segmentation Using 3D U-Net and Model-Agnostic Meta-Learning (MAML)}. Diagnostics.\n\n\\bibitem{ghassemi20241ek}\nSina Ghassemi, Tianyi Zhang, Ward van Breda, et al. (2024). \\textit{Unsupervised Multimodal Learning for Dependency-Free Personality Recognition}. IEEE Transactions on Affective Computing.\n\n\\bibitem{li20254kd}\nJiawen Li, and Tao Zhou (2025). \\textit{Efficient Replay Deep Meta-Reinforcement Learning for Active Fault-Tolerant Control of Solid Oxide Fuel Cell Systems Considering Multivariable Coordination}. IEEE Transactions on Transportation Electrification.\n\n\\bibitem{zhao202420b}\nJianjin Zhao, Qi Li, Yueping Hong, et al. (2024). \\textit{MetaRockETC: Adaptive Encrypted Traffic Classification in Complex Network Environments via Time Series Analysis and Meta-Learning}. IEEE Transactions on Network and Service Management.\n\n\\bibitem{zhang2024xg0}\nLei Zhang, Yuhang Zhou, Yi Yang, et al. (2024). \\textit{Meta Invariance Defense Towards Generalizable Robustness to Unknown Adversarial Attacks}. IEEE Transactions on Pattern Analysis and Machine Intelligence.\n\n\\bibitem{ruwurm2024806}\nMarc Rußwurm, Sherrie Wang, B. Kellenberger, et al. (2024). \\textit{Meta-learning to address diverse Earth observation problems across resolutions}. Communications Earth &amp; Environment.\n\n\\bibitem{jang2024pyi}\nJungik Jang, Jisung Pyo, Young-il Yoon, et al. (2024). \\textit{Meta-Transformer: A Meta-Learning Framework for Scalable Automatic Modulation Classification}. IEEE Access.\n\n\\bibitem{su2024h1g}\nHao Su, Qingtao Yao, Ling Xiang, et al. (2024). \\textit{Semi-Supervised Temporal Meta-Learning Framework for Wind Turbine Bearing Fault Diagnosis Under Limited Annotation Data}. IEEE Transactions on Instrumentation and Measurement.\n\n\\bibitem{li20246zp}\nYao Li, Dawei Yuan, Tao Zhang, et al. (2024). \\textit{Meta-Learning for Multi-Family Android Malware Classification}. ACM Transactions on Software Engineering and Methodology.\n\n\\bibitem{lupu20249p4}\nE. Lupu, Fengze Xie, James A. Preiss, et al. (2024). \\textit{MAGICVFM-Meta-Learning Adaptation for Ground Interaction Control With Visual Foundation Models}. IEEE Transactions on robotics.\n\n\\bibitem{briscik2024cpd}\nMitja Briscik, Gabriele Tazza, M. Dillies, et al. (2024). \\textit{Supervised multiple kernel learning approaches for multi-omics data integration}. BioData Mining.\n\n\\bibitem{sun2024kbv}\nJingmin Sun, Zecheng Zhang, and Hayden Schaeffer (2024). \\textit{LeMON: Learning to Learn Multi-Operator Networks}. arXiv.org.\n\n\\bibitem{eghbali2024huh}\nY. Eghbali, Shiva Kazemi Taskou, Mohammad Robat Mili, et al. (2024). \\textit{Providing URLLC Service in Multi-STAR-RIS Assisted and Full-Duplex Cellular Wireless Systems: A Meta-Learning Approach}. IEEE Communications Letters.\n\n\\bibitem{zhu2024ok7}\nYihuan Zhu, Yunan Liu, Chunpeng Wang, et al. (2024). \\textit{Intermediate Domain-Based Meta Learning Framework for Adaptive Object Detection}. IEEE transactions on circuits and systems for video technology (Print).\n\n\\bibitem{long202400t}\nJianyu Long, Rongxin Zhang, Yibin Chen, et al. (2024). \\textit{A Customized Meta-Learning Framework for Diagnosing New Faults From Unseen Working Conditions With Few Labeled Data}. IEEE/ASME transactions on mechatronics.\n\n\\bibitem{gu20252u3}\nYan Gu, Zhaoze Liu, Shuhong Dai, et al. (2025). \\textit{Deep Reinforcement Learning for Job Scheduling and Resource Management in Cloud Computing: An Algorithm-Level Review}. arXiv.org.\n\n\\bibitem{zhang2024mf0}\nLin Zhang, Bo Zhang, Botian Shi, et al. (2024). \\textit{Few-Shot Cross-Domain Object Detection With Instance-Level Prototype-Based Meta-Learning}. IEEE transactions on circuits and systems for video technology (Print).\n\n\\bibitem{liu2024jz5}\nSheng Liu, Linlin You, Rui Zhu, et al. (2024). \\textit{AFM3D: An Asynchronous Federated Meta-Learning Framework for Driver Distraction Detection}. IEEE transactions on intelligent transportation systems (Print).\n\n\\bibitem{ozkara2024nst}\nKaan Ozkara, Can Karakus, Parameswaran Raman, et al. (2024). \\textit{MADA: Meta-Adaptive Optimizers through hyper-gradient Descent}. International Conference on Machine Learning.\n\n\\bibitem{cui2024bov}\nQi Cui, Weixuan Tang, Zhili Zhou, et al. (2024). \\textit{Meta Security Metric Learning for Secure Deep Image Hiding}. IEEE Transactions on Dependable and Secure Computing.\n\n\\bibitem{wang2024so2}\nYuan Wang, Zhiqiang Tao, and Yi Fang (2024). \\textit{A Unified Meta-Learning Framework for Fair Ranking With Curriculum Learning}. IEEE Transactions on Knowledge and Data Engineering.\n\n\\bibitem{ma2024vk4}\nHan Ma, Baoyu Fan, B. Ng, et al. (2024). \\textit{VL-Meta: Vision-Language Models for Multimodal Meta-Learning}. Mathematics.\n\n\\bibitem{amorim20240xf}\nLucas B V de Amorim, George D. C. Cavalcanti, and Rafael M. O. Cruz (2024). \\textit{Meta-Scaler: A Meta-Learning Framework for the Selection of Scaling Techniques}. IEEE Transactions on Neural Networks and Learning Systems.\n\n\\bibitem{shen2024hea}\nMaohao Shen, J. J. Ryu, Soumya Ghosh, et al. (2024). \\textit{Are Uncertainty Quantification Capabilities of Evidential Deep Learning a Mirage?}. Neural Information Processing Systems.\n\n\\bibitem{ferrini20249g0}\nFrancesco Ferrini, Antonio Longa, Andrea Passerini, et al. (2024). \\textit{A Self-Explainable Heterogeneous GNN for Relational Deep Learning}. Trans. Mach. Learn. Res..\n\n\\bibitem{wang2024tpb}\nChenxing Wang (2024). \\textit{Towards Effective Fusion and Forecasting of Multimodal Spatio-temporal Data for Smart Mobility}. International Conference on Information and Knowledge Management.\n\n\\bibitem{song2024epb}\nWen-qi Song, Di Wu, Weiming Shen, et al. (2024). \\textit{Early fault detection for rolling bearings: A meta‐learning approach}. IET Collaborative Intelligent Manufacturing.\n\n\\bibitem{wang20245h1}\nZih-Wei Wang, and Vincent W. S. Wong (2024). \\textit{Bayesian Meta-Learning for Adaptive Traffic Prediction in Wireless Networks}. IEEE Transactions on Mobile Computing.\n\n\\bibitem{tam2024a1h}\nS. Tam, S. T. P. Raghu, Étienne Buteau, et al. (2024). \\textit{Towards Robust and Interpretable EMG-based Hand Gesture Recognition using Deep Metric Meta Learning}. arXiv.org.\n\n\\bibitem{qiao2024l71}\nRuihua Qiao, Tao Jiang, and Weiyong Yu (2024). \\textit{Meta-Learning-Based Fronthaul Compression for Cloud Radio Access Networks}. IEEE Transactions on Wireless Communications.\n\n\\bibitem{xing2024n9q}\nYun Xing, Qing Guo, Xiaofeng Cao, et al. (2024). \\textit{MetaRepair: Learning to Repair Deep Neural Networks from Repairing Experiences}. ACM Multimedia.\n\n\\bibitem{cheng2024mky}\nYingsong Cheng, Xinya Wang, Yong Ma, et al. (2024). \\textit{General Hyperspectral Image Super-Resolution via Meta-Transfer Learning}. IEEE Transactions on Neural Networks and Learning Systems.\n\n\\bibitem{xia20246dc}\nPengcheng Xia, Yixiang Huang, Chengliang Liu, et al. (2024). \\textit{Learn to Supervise: Deep Reinforcement Learning-Based Prototype Refinement for Few-Shot Motor Fault Diagnosis}. IEEE Transactions on Neural Networks and Learning Systems.\n\n\\bibitem{yang20243gt}\nFan Yang, Nor Azman Ismail, Y. Y. Pang, et al. (2024). \\textit{A Systematic Literature Review of Deep Learning Approaches for Sketch-Based Image Retrieval: Datasets, Metrics, and Future Directions}. IEEE Access.\n\n\\bibitem{zhang2024ycr}\nLianwei Zhang, Dongjiang Niu, Beiyi Zhang, et al. (2024). \\textit{Property-Guided Few-Shot Learning for Molecular Property Prediction With Dual-View Encoder and Relation Graph Learning Network}. IEEE journal of biomedical and health informatics.\n\n\\bibitem{raymond202441h}\nChristian Raymond (2024). \\textit{Meta-Learning Loss Functions for Deep Neural Networks}. arXiv.org.\n\n\\bibitem{khalid2024pss}\nMudassar Khalid, C. Pluempitiwiriyawej, S. Wangsiripitak, et al. (2024). \\textit{The Applications of Deep Learning in ECG Classification for Disease Diagnosis: A Systematic Review and Meta-Data Analysis}. Engineering Journal.\n\n\\bibitem{kumar2024he9}\nSandeep Kumar, Amit Sharma, Vikrant Shokeen, et al. (2024). \\textit{Meta-learning for real-world class incremental learning: a transformer-based approach}. Scientific Reports.\n\n\\bibitem{kukanov20249bs}\nIvan Kukanov, Janne Laakkonen, Tomi Kinnunen, et al. (2024). \\textit{Meta-Learning Approaches For Improving Detection of Unseen Speech Deepfakes}. Spoken Language Technology Workshop.\n\n\\bibitem{chen20245h8}\nCheng Chen, Hao Fang, Yuxiao Yang, et al. (2024). \\textit{Model-agnostic meta-learning for EEG-based inter-subject emotion recognition}. Journal of Neural Engineering.\n\n\\bibitem{liu2024az5}\nYonghao Liu, Mengyu Li, Ximing Li, et al. (2024). \\textit{Meta-GPS++: Enhancing Graph Meta-Learning with Contrastive Learning and Self-Training}. ACM Transactions on Knowledge Discovery from Data.\n\n\\bibitem{xu2024mf9}\nZexing Xu, Linjun Zhang, Sitan Yang, et al. (2024). \\textit{F-FOMAML: GNN-Enhanced Meta-Learning for Peak Period Demand Forecasting with Proxy Data}. arXiv.org.\n\n\\bibitem{chen2024b4d}\nWeiye Chen, Yiqun Xie, Xiaowei Jia, et al. (2024). \\textit{Referee-Meta-Learning for Fast Adaptation of Locational Fairness}. AAAI Conference on Artificial Intelligence.\n\n\\bibitem{wen2024xmk}\nGang Wen, and Limin Li (2024). \\textit{MMOSurv: meta-learning for few-shot survival analysis with multi-omics data}. Bioinformatics.\n\n\\bibitem{liao2024jm9}\nYang Liao, Jing Zhao, Jiyong Bian, et al. (2024). \\textit{From mechanism to application: Decrypting light‐regulated denitrifying microbiome through geometric deep learning}. iMeta.\n\n\\bibitem{meng2024nqq}\nWei Meng, Hao Ju, Tongxu Ai, et al. (2024). \\textit{Transferring Meta-Policy From Simulation to Reality via Progressive Neural Network}. IEEE Robotics and Automation Letters.\n\n\\bibitem{wu2024v0z}\nHaotian Wu, Maojun Zhang, Yulin Shao, et al. (2024). \\textit{MIMO Channel as a Neural Function: Implicit Neural Representations for Extreme CSI Compression in Massive MIMO Systems}. arXiv.org.\n\n\\bibitem{farrell2024mpy}\nM. Farrell, Nicolas Le Guillarme, Liam Brierley, et al. (2024). \\textit{The changing landscape of text mining: a review of approaches for ecology and evolution}. Proceedings B.\n\n\\bibitem{ma20243e9}\nXin Ma, Yuanchang Xie, and Chunxiao Chigan (2024). \\textit{Graph Convolutional Network Based Multi-Objective Meta-Deep Q-Learning for Eco-Routing}. IEEE transactions on intelligent transportation systems (Print).\n\n\\bibitem{gven2024a3n}\nEray Güven, and G. Kurt (2024). \\textit{Learning-to-Learn the Wave Angle Estimation}. IEEE Transactions on Communications.\n\n\\bibitem{wang2024bhk}\nJingyao Wang, Wenwen Qiang, Jiangmeng Li, et al. (2024). \\textit{Rethinking Meta-Learning from a Learning Lens}. arXiv.org.\n\n\\bibitem{pu2024m1b}\nQ. Pu, Youkun Chen, Mu Zhou, et al. (2024). \\textit{Bayesian Meta-Learning: Toward Fast Adaptation in Neural Network Positioning Techniques}. IEEE Internet of Things Journal.\n\n\\end{thebibliography}\n\n\\end{document}",
  "generation_date": "2025-10-07T21:41:13.057375",
  "processed_papers_data": [
    {
      "success": true,
      "doc_id": "70e25c24da12051fac99a6d56191f6b1",
      "summary": "Here's a focused summary of the paper \"Learning to Compare: Relation Network for Few-Shot Learning\" \\cite{sung2017nc5} for a literature review:\n\n---\n\n### Analysis of \"Learning to Compare: Relation Network for Few-Shot Learning\" \\cite{sung2017nc5}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addressing the challenge of few-shot learning, where deep learning models must learn to recognize new classes from only a very small number of labeled examples (e.g., one or five per class). It also extends to zero-shot learning, where only a class description is available.\n    *   **Importance & Challenge**: Conventional deep learning models require vast amounts of labeled data, limiting their scalability to new, rare, or emerging categories due to high annotation costs and data scarcity. Humans, in contrast, excel at learning from few or no examples. Existing few-shot methods often suffer from complex inference mechanisms, reliance on recurrent neural networks (RNNs), or the need for fine-tuning on the target problem, which can be slow or computationally expensive.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{sung2017nc5} is most closely related to embedding and metric learning approaches (e.g., Matching Networks \\cite{sung2017nc5}, Prototypical Networks \\cite{sung2017nc5}, Siamese Networks \\cite{sung2017nc5}) that learn projection functions to make data easily recognizable.\n    *   **Limitations of Previous Solutions**:\n        *   **Fine-tuning based methods (e.g., MAML \\cite{sung2017nc5}, Meta-Learner LSTM \\cite{sung2017nc5})**: Require fine-tuning on the target few-shot problem, making them slower and less suitable for low-latency applications.\n        *   **RNN-memory based methods (e.g., MANN \\cite{sung2017nc5}, Meta Nets \\cite{sung2017nc5})**: Involve complex recurrent architectures and face challenges in reliably storing long-term historical information.\n        *   **Metric learning methods (e.g., Prototypical Networks \\cite{sung2017nc5}, Siamese Networks \\cite{sung2017nc5})**: Typically rely on a *fixed* (e.g., Euclidean) or *linear* similarity metric after learning embeddings.\n    *   **Positioning of \\cite{sung2017nc5}**: Unlike prior metric learning methods, \\cite{sung2017nc5} *learns a transferrable deep, non-linear metric* (a \"relation classifier CNN\") for comparing images or embeddings, rather than using a pre-defined fixed or linear one. It avoids the complexity of RNNs and the need for fine-tuning, offering a simpler and faster feed-forward solution.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The **Relation Network (RN)** \\cite{sung2017nc5} is a two-branch, end-to-end meta-learning framework.\n        *   It consists of an **embedding module** (`f_phi`) and a **relation module** (`g_psi`).\n        *   The `f_phi` module generates feature maps for both query images and support (sample) images.\n        *   These feature maps are then combined (concatenated in depth).\n        *   The combined feature map is fed into the `g_psi` module, which outputs a scalar \"relation score\" (between 0 and 1) indicating the similarity between the query and sample.\n        *   For K-shot learning (K > 1), the embeddings of all K samples from a class are element-wise summed to form a single class-level feature map.\n        *   The model is trained using a Mean Squared Error (MSE) loss, regressing relation scores to 1 for matched pairs and 0 for mismatched pairs.\n    *   **Novelty/Differentiation**:\n        *   **Learnable Non-linear Metric**: The key innovation is learning a deep, non-linear \"relation function\" (`g_psi`) to compare embeddings, rather than relying on a fixed distance metric (e.g., Euclidean) or a simple linear classifier. This allows for more flexible and powerful comparison.\n        *   **End-to-End Meta-Learning**: The entire network (embedding and relation modules) is trained end-to-end from scratch using an episode-based meta-learning strategy, simulating the few-shot setting during training.\n        *   **Unified Framework**: The RN architecture is elegantly extended to zero-shot learning by replacing the sample image branch with a heterogeneous embedding module for semantic class descriptions (e.g., attribute vectors), while keeping the core relation module.\n        *   **Simplicity and Speed**: It achieves strong performance without complex RNN architectures or the need for fine-tuning during inference, making it simpler and faster than many alternatives.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm/Method**: Introduction of the Relation Network \\cite{sung2017nc5} that meta-learns a deep, non-linear distance metric (relation function) for comparing inputs.\n    *   **System Design/Architectural Innovation**: A two-branch architecture with distinct embedding and relation modules, designed for direct comparison of feature representations. The use of feature map concatenation and subsequent convolutional layers in the relation module allows for learning complex relationships.\n    *   **Theoretical Insights/Analysis**: While not explicitly theoretical, the paper demonstrates that a deeper, learned non-linear comparator provides a more generalizable solution than fixed or linear metrics for few-shot and zero-shot learning. The choice of MSE loss for relation score regression is a conceptual contribution.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on:\n        *   **Few-shot classification**: Omniglot and miniImageNet datasets, evaluating 5-way 1-shot, 5-way 5-shot, 20-way 1-shot, and 20-way 5-shot settings.\n        *   **Zero-shot classification**: Animals with Attributes (AwA) and Caltech-UCSD Birds-200-2011 (CUB) datasets.\n    *   **Key Performance Metrics**: Classification accuracy (averaged over many episodes) and standard deviation.\n    *   **Comparison Results**:\n        *   **Omniglot**: Achieved state-of-the-art performance across most few-shot settings (5-way 1-shot, 20-way 1-shot, 20-way 5-shot), with higher average accuracies and lower standard deviations compared to baselines like Matching Nets \\cite{sung2017nc5}, MAML \\cite{sung2017nc5}, and Prototypical Networks \\cite{sung2017nc5}.\n        *   **miniImageNet**: Achieved state-of-the-art performance on 5-way 1-shot and competitive results on 5-way 5-shot, outperforming Prototypical Networks \\cite{sung2017nc5} when trained under identical episode settings.\n        *   **Zero-shot learning**: Demonstrated compelling performance on AwA and CUB, showcasing the framework's generality.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper implicitly assumes that a learned non-linear comparison function is superior to fixed metrics, which is validated empirically. The choice of MSE loss is noted as \"somewhat non-standard\" but justified conceptually. The architecture relies on standard CNN blocks, which might be further optimized.\n    *   **Scope of Applicability**: Primarily focused on few-shot and zero-shot image classification tasks. While the concept of a learnable relation function is general, its direct application is shown for visual data and semantic embeddings.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{sung2017nc5} significantly advances the state-of-the-art in few-shot learning by introducing a simpler, faster, and more effective approach that consistently outperforms or is competitive with more complex methods.\n    *   **Potential Impact on Future Research**:\n        *   **Shift from Fixed to Learned Metrics**: Encourages future research to explore learned, non-linear comparison functions rather than relying on pre-defined distance metrics.\n        *   **Unified Frameworks**: Provides a strong example of a unified framework that can elegantly handle both few-shot and zero-shot learning, potentially inspiring more generalizable meta-learning architectures.\n        *   **Practical Applications**: Its simplicity and feed-forward nature make it highly suitable for real-world applications where computational resources or latency are critical, fostering the deployment of few-shot learning in new domains.",
      "intriguing_abstract": "Deep learning models excel with vast data, yet struggle with the human-like ability to learn from just a few examples. This paper introduces the **Relation Network (RN)**, a novel **meta-learning** framework designed to address the critical challenge of **few-shot learning** and **zero-shot learning**. Unlike traditional **deep metric learning** approaches that rely on fixed or linear similarity measures, our core innovation lies in learning a **deep, non-linear relation function** that directly compares feature **embeddings** to determine their similarity.\n\nThe RN comprises an embedding module and a relation module, trained **end-to-end** using an episode-based strategy. This architecture elegantly learns a transferrable comparison mechanism, avoiding the complexities of recurrent neural networks or the need for slow fine-tuning during inference. We demonstrate that this learned, non-linear metric significantly boosts performance, achieving **state-of-the-art** results on challenging **few-shot classification** benchmarks like Omniglot and miniImageNet, and compelling performance in **zero-shot classification** tasks. The simplicity, speed, and generalizability of the Relation Network offer a powerful, practical solution for rapidly adapting deep models to data-scarce environments, paving the way for more scalable and human-centric AI systems.",
      "keywords": [
        "Few-shot learning",
        "Relation Network (RN)",
        "Meta-learning",
        "Learnable non-linear metric",
        "Zero-shot learning",
        "Embedding module",
        "Relation module",
        "End-to-end meta-learning",
        "Image classification",
        "Feature map concatenation",
        "Mean Squared Error (MSE) loss",
        "State-of-the-art performance",
        "Unified framework",
        "Computational efficiency"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/bfe284e4338e62f0a61bb33398353efd687f206f.pdf",
      "citation_key": "sung2017nc5",
      "metadata": {
        "title": "Learning to Compare: Relation Network for Few-Shot Learning",
        "authors": [
          "Flood Sung",
          "Yongxin Yang",
          "Li Zhang",
          "T. Xiang",
          "Philip H. S. Torr",
          "Timothy M. Hospedales"
        ],
        "published_date": "2017",
        "abstract": "We present a conceptually simple, flexible, and general framework for few-shot learning, where a classifier must learn to recognise new classes given only few examples from each. Our method, called the Relation Network (RN), is trained end-to-end from scratch. During meta-learning, it learns to learn a deep distance metric to compare a small number of images within episodes, each of which is designed to simulate the few-shot setting. Once trained, a RN is able to classify images of new classes by computing relation scores between query images and the few examples of each new class without further updating the network. Besides providing improved performance on few-shot learning, our framework is easily extended to zero-shot learning. Extensive experiments on five benchmarks demonstrate that our simple approach provides a unified and effective approach for both of these two tasks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/bfe284e4338e62f0a61bb33398353efd687f206f.pdf",
        "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
        "citationCount": 4190,
        "score": 523.75,
        "summary": "Here's a focused summary of the paper \"Learning to Compare: Relation Network for Few-Shot Learning\" \\cite{sung2017nc5} for a literature review:\n\n---\n\n### Analysis of \"Learning to Compare: Relation Network for Few-Shot Learning\" \\cite{sung2017nc5}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Addressing the challenge of few-shot learning, where deep learning models must learn to recognize new classes from only a very small number of labeled examples (e.g., one or five per class). It also extends to zero-shot learning, where only a class description is available.\n    *   **Importance & Challenge**: Conventional deep learning models require vast amounts of labeled data, limiting their scalability to new, rare, or emerging categories due to high annotation costs and data scarcity. Humans, in contrast, excel at learning from few or no examples. Existing few-shot methods often suffer from complex inference mechanisms, reliance on recurrent neural networks (RNNs), or the need for fine-tuning on the target problem, which can be slow or computationally expensive.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{sung2017nc5} is most closely related to embedding and metric learning approaches (e.g., Matching Networks \\cite{sung2017nc5}, Prototypical Networks \\cite{sung2017nc5}, Siamese Networks \\cite{sung2017nc5}) that learn projection functions to make data easily recognizable.\n    *   **Limitations of Previous Solutions**:\n        *   **Fine-tuning based methods (e.g., MAML \\cite{sung2017nc5}, Meta-Learner LSTM \\cite{sung2017nc5})**: Require fine-tuning on the target few-shot problem, making them slower and less suitable for low-latency applications.\n        *   **RNN-memory based methods (e.g., MANN \\cite{sung2017nc5}, Meta Nets \\cite{sung2017nc5})**: Involve complex recurrent architectures and face challenges in reliably storing long-term historical information.\n        *   **Metric learning methods (e.g., Prototypical Networks \\cite{sung2017nc5}, Siamese Networks \\cite{sung2017nc5})**: Typically rely on a *fixed* (e.g., Euclidean) or *linear* similarity metric after learning embeddings.\n    *   **Positioning of \\cite{sung2017nc5}**: Unlike prior metric learning methods, \\cite{sung2017nc5} *learns a transferrable deep, non-linear metric* (a \"relation classifier CNN\") for comparing images or embeddings, rather than using a pre-defined fixed or linear one. It avoids the complexity of RNNs and the need for fine-tuning, offering a simpler and faster feed-forward solution.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The **Relation Network (RN)** \\cite{sung2017nc5} is a two-branch, end-to-end meta-learning framework.\n        *   It consists of an **embedding module** (`f_phi`) and a **relation module** (`g_psi`).\n        *   The `f_phi` module generates feature maps for both query images and support (sample) images.\n        *   These feature maps are then combined (concatenated in depth).\n        *   The combined feature map is fed into the `g_psi` module, which outputs a scalar \"relation score\" (between 0 and 1) indicating the similarity between the query and sample.\n        *   For K-shot learning (K > 1), the embeddings of all K samples from a class are element-wise summed to form a single class-level feature map.\n        *   The model is trained using a Mean Squared Error (MSE) loss, regressing relation scores to 1 for matched pairs and 0 for mismatched pairs.\n    *   **Novelty/Differentiation**:\n        *   **Learnable Non-linear Metric**: The key innovation is learning a deep, non-linear \"relation function\" (`g_psi`) to compare embeddings, rather than relying on a fixed distance metric (e.g., Euclidean) or a simple linear classifier. This allows for more flexible and powerful comparison.\n        *   **End-to-End Meta-Learning**: The entire network (embedding and relation modules) is trained end-to-end from scratch using an episode-based meta-learning strategy, simulating the few-shot setting during training.\n        *   **Unified Framework**: The RN architecture is elegantly extended to zero-shot learning by replacing the sample image branch with a heterogeneous embedding module for semantic class descriptions (e.g., attribute vectors), while keeping the core relation module.\n        *   **Simplicity and Speed**: It achieves strong performance without complex RNN architectures or the need for fine-tuning during inference, making it simpler and faster than many alternatives.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm/Method**: Introduction of the Relation Network \\cite{sung2017nc5} that meta-learns a deep, non-linear distance metric (relation function) for comparing inputs.\n    *   **System Design/Architectural Innovation**: A two-branch architecture with distinct embedding and relation modules, designed for direct comparison of feature representations. The use of feature map concatenation and subsequent convolutional layers in the relation module allows for learning complex relationships.\n    *   **Theoretical Insights/Analysis**: While not explicitly theoretical, the paper demonstrates that a deeper, learned non-linear comparator provides a more generalizable solution than fixed or linear metrics for few-shot and zero-shot learning. The choice of MSE loss for relation score regression is a conceptual contribution.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on:\n        *   **Few-shot classification**: Omniglot and miniImageNet datasets, evaluating 5-way 1-shot, 5-way 5-shot, 20-way 1-shot, and 20-way 5-shot settings.\n        *   **Zero-shot classification**: Animals with Attributes (AwA) and Caltech-UCSD Birds-200-2011 (CUB) datasets.\n    *   **Key Performance Metrics**: Classification accuracy (averaged over many episodes) and standard deviation.\n    *   **Comparison Results**:\n        *   **Omniglot**: Achieved state-of-the-art performance across most few-shot settings (5-way 1-shot, 20-way 1-shot, 20-way 5-shot), with higher average accuracies and lower standard deviations compared to baselines like Matching Nets \\cite{sung2017nc5}, MAML \\cite{sung2017nc5}, and Prototypical Networks \\cite{sung2017nc5}.\n        *   **miniImageNet**: Achieved state-of-the-art performance on 5-way 1-shot and competitive results on 5-way 5-shot, outperforming Prototypical Networks \\cite{sung2017nc5} when trained under identical episode settings.\n        *   **Zero-shot learning**: Demonstrated compelling performance on AwA and CUB, showcasing the framework's generality.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper implicitly assumes that a learned non-linear comparison function is superior to fixed metrics, which is validated empirically. The choice of MSE loss is noted as \"somewhat non-standard\" but justified conceptually. The architecture relies on standard CNN blocks, which might be further optimized.\n    *   **Scope of Applicability**: Primarily focused on few-shot and zero-shot image classification tasks. While the concept of a learnable relation function is general, its direct application is shown for visual data and semantic embeddings.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{sung2017nc5} significantly advances the state-of-the-art in few-shot learning by introducing a simpler, faster, and more effective approach that consistently outperforms or is competitive with more complex methods.\n    *   **Potential Impact on Future Research**:\n        *   **Shift from Fixed to Learned Metrics**: Encourages future research to explore learned, non-linear comparison functions rather than relying on pre-defined distance metrics.\n        *   **Unified Frameworks**: Provides a strong example of a unified framework that can elegantly handle both few-shot and zero-shot learning, potentially inspiring more generalizable meta-learning architectures.\n        *   **Practical Applications**: Its simplicity and feed-forward nature make it highly suitable for real-world applications where computational resources or latency are critical, fostering the deployment of few-shot learning in new domains.",
        "keywords": [
          "Few-shot learning",
          "Relation Network (RN)",
          "Meta-learning",
          "Learnable non-linear metric",
          "Zero-shot learning",
          "Embedding module",
          "Relation module",
          "End-to-end meta-learning",
          "Image classification",
          "Feature map concatenation",
          "Mean Squared Error (MSE) loss",
          "State-of-the-art performance",
          "Unified framework",
          "Computational efficiency"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   **abstract mentions:** \"we present a conceptually simple, ﬂexible, and general framework\", \"our method, called the relation network (rn)\", \"learns to learn a deep distance metric\", \"classify images of new classes by computing relation scores\". these phrases clearly indicate the development and presentation of a new method or system.\n*   **introduction discusses:** the problem with existing deep learning models (\"need large amounts of labelled data\"), the motivation for few-shot/zero-shot learning, and defines the technical problem (\"few-shot learning aims to recognise novel visual cate-gories from very few labelled examples\"). this sets the stage for a proposed technical solution.\n*   while \"extensive experiments on ﬁve benchmarks demonstrate...\" indicates an empirical component, the primary contribution is the **new method** (relation network) that is being proposed and evaluated. the experiments serve to validate this new technical contribution.\n\ntherefore, this paper best fits the **technical** classification."
      },
      "file_name": "bfe284e4338e62f0a61bb33398353efd687f206f.pdf"
    },
    {
      "success": true,
      "doc_id": "361fdc8eea617c1ed6d0f9987189ceea",
      "summary": "The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.",
      "intriguing_abstract": "The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/020bb2ba5f3923858cd6882ba5c5a44ea8041ab6.pdf",
      "citation_key": "hospedales2020m37",
      "metadata": {
        "title": "Meta-Learning in Neural Networks: A Survey",
        "authors": [
          "Timothy M. Hospedales",
          "Antreas Antoniou",
          "P. Micaelli",
          "A. Storkey"
        ],
        "published_date": "2020",
        "abstract": "The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.",
        "file_path": "paper_data/Deep_Meta-Learning/info/020bb2ba5f3923858cd6882ba5c5a44ea8041ab6.pdf",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "citationCount": 2147,
        "score": 429.40000000000003,
        "summary": "The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.",
        "keywords": []
      },
      "file_name": "020bb2ba5f3923858cd6882ba5c5a44ea8041ab6.pdf"
    },
    {
      "success": true,
      "doc_id": "463637331e20f0e542694660047fc485",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3904315e2eca50d0086e4b7273f7fd707c652230.pdf",
      "citation_key": "santoro2016323",
      "metadata": {
        "title": "Meta-Learning with Memory-Augmented Neural Networks",
        "authors": [
          "Adam Santoro",
          "Sergey Bartunov",
          "M. Botvinick",
          "D. Wierstra",
          "T. Lillicrap"
        ],
        "published_date": "2016",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/3904315e2eca50d0086e4b7273f7fd707c652230.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 1861,
        "score": 206.77777777777777,
        "summary": "",
        "keywords": []
      },
      "file_name": "3904315e2eca50d0086e4b7273f7fd707c652230.pdf"
    },
    {
      "success": true,
      "doc_id": "cbb96753a926648cad5487b90dbf546b",
      "summary": "Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, meta-learning typically uses shallow neural networks (SNNs), thus limiting its effectiveness. In this paper we propose a novel few-shot learning method called meta-transfer learning (MTL) which learns to adapt a deep NN for few shot learning tasks. Specifically, \"meta\" refers to training multiple tasks, and \"transfer\" is achieved by learning scaling and shifting functions of DNN weights for each task. In addition, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum for MTL. We conduct experiments using (5-class, 1-shot) and (5-class, 5-shot) recognition tasks on two challenging few-shot learning benchmarks: miniImageNet and Fewshot-CIFAR100. Extensive comparisons to related works validate that our meta-transfer learning approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.",
      "intriguing_abstract": "Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, meta-learning typically uses shallow neural networks (SNNs), thus limiting its effectiveness. In this paper we propose a novel few-shot learning method called meta-transfer learning (MTL) which learns to adapt a deep NN for few shot learning tasks. Specifically, \"meta\" refers to training multiple tasks, and \"transfer\" is achieved by learning scaling and shifting functions of DNN weights for each task. In addition, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum for MTL. We conduct experiments using (5-class, 1-shot) and (5-class, 5-shot) recognition tasks on two challenging few-shot learning benchmarks: miniImageNet and Fewshot-CIFAR100. Extensive comparisons to related works validate that our meta-transfer learning approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d8d680aea59295c020b9d53d78dd8d954a876845.pdf",
      "citation_key": "sun2018iy7",
      "metadata": {
        "title": "Meta-Transfer Learning for Few-Shot Learning",
        "authors": [
          "Qianru Sun",
          "Yaoyao Liu",
          "Tat-Seng Chua",
          "B. Schiele"
        ],
        "published_date": "2018",
        "abstract": "Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, meta-learning typically uses shallow neural networks (SNNs), thus limiting its effectiveness. In this paper we propose a novel few-shot learning method called meta-transfer learning (MTL) which learns to adapt a deep NN for few shot learning tasks. Specifically, \"meta\" refers to training multiple tasks, and \"transfer\" is achieved by learning scaling and shifting functions of DNN weights for each task. In addition, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum for MTL. We conduct experiments using (5-class, 1-shot) and (5-class, 5-shot) recognition tasks on two challenging few-shot learning benchmarks: miniImageNet and Fewshot-CIFAR100. Extensive comparisons to related works validate that our meta-transfer learning approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d8d680aea59295c020b9d53d78dd8d954a876845.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 1112,
        "score": 158.85714285714286,
        "summary": "Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, meta-learning typically uses shallow neural networks (SNNs), thus limiting its effectiveness. In this paper we propose a novel few-shot learning method called meta-transfer learning (MTL) which learns to adapt a deep NN for few shot learning tasks. Specifically, \"meta\" refers to training multiple tasks, and \"transfer\" is achieved by learning scaling and shifting functions of DNN weights for each task. In addition, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum for MTL. We conduct experiments using (5-class, 1-shot) and (5-class, 5-shot) recognition tasks on two challenging few-shot learning benchmarks: miniImageNet and Fewshot-CIFAR100. Extensive comparisons to related works validate that our meta-transfer learning approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.",
        "keywords": []
      },
      "file_name": "d8d680aea59295c020b9d53d78dd8d954a876845.pdf"
    },
    {
      "success": true,
      "doc_id": "99acca71cbb61dd19cde2847654ac73a",
      "summary": "Here's a focused summary of the technical paper \\cite{bertinetto2018ur2} for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** Adapting deep neural networks to new concepts from only a few examples (few-shot learning) is computationally expensive and challenging using standard fine-tuning procedures. Traditional deep learning requires vast amounts of labeled data, which is often scarce or costly to acquire.\n    *   **Importance & Challenge:** The ability to learn from limited data is crucial for real-world applications (e.g., drug discovery, rare species classification). Existing meta-learning approaches for few-shot learning often fall into two categories: fast but inflexible (e.g., nearest neighbors based on similarity metrics) or adaptable but computationally slow and memory-intensive (e.g., backpropagating through many gradient descent steps).\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   Contrasts with similarity-based methods (e.g., Siamese networks, Matching Networks, Prototypical Networks) which are fast but lack data-dependent adaptation at test-time.\n        *   Differs from gradient-based meta-learning (e.g., MAML, LSTMs as optimizers) which are adaptable but suffer from high memory costs when backpropagating through multiple gradient steps.\n    *   **Limitations of Previous Solutions:**\n        *   Similarity-based methods: Parameter updates only occur in the outer meta-training loop, preventing adaptation at test time.\n        *   Gradient-based methods: Backpropagation through gradient descent steps is memory-intensive, limiting the number of adaptation steps.\n    *   **Positioning:** \\cite{bertinetto2018ur2} proposes a novel approach by using simple, fast-converging, and differentiable classical machine learning algorithms (like ridge regression) as the base learner within a meta-learning framework. This offers more flexibility than similarity-based methods (by producing episode-specific parameters) and faster convergence than gradient-based methods (due to closed-form solutions).\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a meta-learning framework where the base learner is a differentiable closed-form solver, specifically Ridge Regression. The deep feature extractor (CNN) and the hyper-parameters of the base learner are jointly optimized via backpropagation through the entire learning process of the base learner.\n    *   **Novelty/Differentiation:**\n        *   **Differentiable Closed-Form Solvers:** Integrates standard, efficient machine learning tools (like ridge regression) directly as the adaptation mechanism within a deep meta-learning pipeline, enabling end-to-end training.\n        *   **Efficient Backpropagation via Woodbury Identity:** To overcome the computational cost of matrix inversion for high-dimensional features, the Woodbury identity is leveraged. This transforms the `(e x e)` matrix inversion (where `e` is embedding size) into an `(n x n)` matrix inversion (where `n` is the number of samples in an episode). Since `n` is very small in few-shot learning, this makes the overall cost linear in `e` and highly efficient.\n        *   **Meta-Learning Hyper-parameters:** The meta-learner learns not only the deep feature extractor's parameters but also the hyper-parameters of the base learner (e.g., regularization strength `λ`, and output calibration parameters `α`, `β` for ridge regression).\n        *   **Extension to Iterative Solvers:** The approach is extended to iterative solvers like Logistic Regression by using Newton's method, which can be formulated as Iteratively Reweighted Least Squares, maintaining differentiability.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   A novel meta-learning algorithm that uses differentiable closed-form solvers (Ridge Regression) as the base learner for few-shot classification.\n        *   An efficient method for backpropagating through ridge regression by applying the Woodbury identity, making it computationally feasible for high-dimensional deep features in few-shot settings.\n        *   A differentiable iterative solver for logistic regression (via Iteratively Reweighted Least Squares) integrated into the meta-learning framework.\n    *   **System Design/Architectural Innovations:** A meta-learning architecture where a deep feature extractor `Φ` is meta-trained alongside the hyper-parameters `Ψ` of a simple, differentiable base learner `Λ` (e.g., Ridge Regression), allowing the base learner to improve its learning capabilities across episodes.\n    *   **Theoretical Insights/Analysis:** Demonstrates that efficient, classical ML solvers can be effectively integrated into deep meta-learning by making them differentiable, overcoming computational hurdles with matrix identities, and allowing for end-to-end optimization of both feature extractors and base learner hyper-parameters.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were performed to evaluate the proposed methods.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Benchmarks:** Omniglot, CIFAR-100 (adapted for few-shot learning), and miniImageNet.\n        *   **Metrics:** Classification accuracy.\n        *   **Results:** The proposed methods achieve performance competitive with or superior to the state-of-the-art on all three benchmarks. The base learners are highlighted as fast, simple to implement, and effective.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   While generally robust, matrix inversion could theoretically be numerically unstable if the matrix `(X^T X + λI)` or `(X X^T + λI)` were close to singular, though this was not observed in their experiments with `λ > 0`.\n        *   The base learners demonstrated are primarily linear models (ridge regression, logistic regression).\n    *   **Scope of Applicability:** Most beneficial for few-shot learning scenarios where the number of training examples `n` per episode is small, as this is when the Woodbury identity provides significant computational advantages.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{bertinetto2018ur2} introduces a simple, efficient, and highly competitive alternative to existing meta-learning paradigms (similarity-based and gradient-based) for few-shot learning, achieving strong empirical results.\n    *   **Potential Impact on Future Research:**\n        *   Opens a new avenue for integrating a broader range of classical, efficient machine learning algorithms into deep learning pipelines by making them differentiable.\n        *   Provides a framework for designing meta-learners that effectively balance adaptability and computational efficiency.\n        *   Could inspire further research into differentiable versions of other non-deep models and their application in various meta-learning and optimization tasks.",
      "intriguing_abstract": "Adapting deep neural networks to new concepts from only a few examples—few-shot learning—remains a critical bottleneck, often forcing a trade-off between rapid adaptation and computational efficiency. We introduce a novel meta-learning paradigm that elegantly resolves this dilemma by integrating differentiable closed-form solvers, such as Ridge Regression, directly as the base learner within an end-to-end trainable framework. Our key innovation lies in efficiently backpropagating through these classical algorithms, leveraging the Woodbury identity to dramatically reduce computational costs associated with matrix inversion, particularly for high-dimensional features. This enables the joint optimization of a deep feature extractor and the base learner's hyperparameters, facilitating rapid, episode-specific adaptation. We further extend this approach to iterative solvers like Logistic Regression via Iteratively Reweighted Least Squares. Achieving state-of-the-art or competitive performance on Omniglot, CIFAR-100, and miniImageNet, our method offers a simple, fast, and highly effective alternative. This work opens exciting avenues for embedding a wider array of classical machine learning algorithms into deep learning pipelines, fostering a new generation of adaptable and efficient meta-learners.",
      "keywords": [
        "few-shot learning",
        "meta-learning",
        "differentiable closed-form solvers",
        "ridge regression",
        "Woodbury identity",
        "efficient backpropagation",
        "hyper-parameter meta-learning",
        "computational efficiency",
        "adaptability",
        "end-to-end training",
        "logistic regression",
        "deep feature extractor",
        "state-of-the-art performance",
        "classical machine learning integration"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/208cd4b25768f0096fb2e80e7690473da0e2a563.pdf",
      "citation_key": "bertinetto2018ur2",
      "metadata": {
        "title": "Meta-learning with differentiable closed-form solvers",
        "authors": [
          "Luca Bertinetto",
          "João F. Henriques",
          "Philip H. S. Torr",
          "A. Vedaldi"
        ],
        "published_date": "2018",
        "abstract": "Adapting deep networks to new concepts from a few examples is challenging, due to the high computational requirements of standard fine-tuning procedures. Most work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent. Nonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently. In this paper, we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning. The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression, as part of its own internal model, enabling it to quickly adapt to novel data. This requires back-propagating errors through the solver steps. While normally the cost of the matrix operations involved in such a process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage. We propose both closed-form and iterative solvers, based on ridge regression and logistic regression components. Our methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/208cd4b25768f0096fb2e80e7690473da0e2a563.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 962,
        "score": 137.42857142857142,
        "summary": "Here's a focused summary of the technical paper \\cite{bertinetto2018ur2} for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** Adapting deep neural networks to new concepts from only a few examples (few-shot learning) is computationally expensive and challenging using standard fine-tuning procedures. Traditional deep learning requires vast amounts of labeled data, which is often scarce or costly to acquire.\n    *   **Importance & Challenge:** The ability to learn from limited data is crucial for real-world applications (e.g., drug discovery, rare species classification). Existing meta-learning approaches for few-shot learning often fall into two categories: fast but inflexible (e.g., nearest neighbors based on similarity metrics) or adaptable but computationally slow and memory-intensive (e.g., backpropagating through many gradient descent steps).\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   Contrasts with similarity-based methods (e.g., Siamese networks, Matching Networks, Prototypical Networks) which are fast but lack data-dependent adaptation at test-time.\n        *   Differs from gradient-based meta-learning (e.g., MAML, LSTMs as optimizers) which are adaptable but suffer from high memory costs when backpropagating through multiple gradient steps.\n    *   **Limitations of Previous Solutions:**\n        *   Similarity-based methods: Parameter updates only occur in the outer meta-training loop, preventing adaptation at test time.\n        *   Gradient-based methods: Backpropagation through gradient descent steps is memory-intensive, limiting the number of adaptation steps.\n    *   **Positioning:** \\cite{bertinetto2018ur2} proposes a novel approach by using simple, fast-converging, and differentiable classical machine learning algorithms (like ridge regression) as the base learner within a meta-learning framework. This offers more flexibility than similarity-based methods (by producing episode-specific parameters) and faster convergence than gradient-based methods (due to closed-form solutions).\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a meta-learning framework where the base learner is a differentiable closed-form solver, specifically Ridge Regression. The deep feature extractor (CNN) and the hyper-parameters of the base learner are jointly optimized via backpropagation through the entire learning process of the base learner.\n    *   **Novelty/Differentiation:**\n        *   **Differentiable Closed-Form Solvers:** Integrates standard, efficient machine learning tools (like ridge regression) directly as the adaptation mechanism within a deep meta-learning pipeline, enabling end-to-end training.\n        *   **Efficient Backpropagation via Woodbury Identity:** To overcome the computational cost of matrix inversion for high-dimensional features, the Woodbury identity is leveraged. This transforms the `(e x e)` matrix inversion (where `e` is embedding size) into an `(n x n)` matrix inversion (where `n` is the number of samples in an episode). Since `n` is very small in few-shot learning, this makes the overall cost linear in `e` and highly efficient.\n        *   **Meta-Learning Hyper-parameters:** The meta-learner learns not only the deep feature extractor's parameters but also the hyper-parameters of the base learner (e.g., regularization strength `λ`, and output calibration parameters `α`, `β` for ridge regression).\n        *   **Extension to Iterative Solvers:** The approach is extended to iterative solvers like Logistic Regression by using Newton's method, which can be formulated as Iteratively Reweighted Least Squares, maintaining differentiability.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   A novel meta-learning algorithm that uses differentiable closed-form solvers (Ridge Regression) as the base learner for few-shot classification.\n        *   An efficient method for backpropagating through ridge regression by applying the Woodbury identity, making it computationally feasible for high-dimensional deep features in few-shot settings.\n        *   A differentiable iterative solver for logistic regression (via Iteratively Reweighted Least Squares) integrated into the meta-learning framework.\n    *   **System Design/Architectural Innovations:** A meta-learning architecture where a deep feature extractor `Φ` is meta-trained alongside the hyper-parameters `Ψ` of a simple, differentiable base learner `Λ` (e.g., Ridge Regression), allowing the base learner to improve its learning capabilities across episodes.\n    *   **Theoretical Insights/Analysis:** Demonstrates that efficient, classical ML solvers can be effectively integrated into deep meta-learning by making them differentiable, overcoming computational hurdles with matrix identities, and allowing for end-to-end optimization of both feature extractors and base learner hyper-parameters.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were performed to evaluate the proposed methods.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Benchmarks:** Omniglot, CIFAR-100 (adapted for few-shot learning), and miniImageNet.\n        *   **Metrics:** Classification accuracy.\n        *   **Results:** The proposed methods achieve performance competitive with or superior to the state-of-the-art on all three benchmarks. The base learners are highlighted as fast, simple to implement, and effective.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   While generally robust, matrix inversion could theoretically be numerically unstable if the matrix `(X^T X + λI)` or `(X X^T + λI)` were close to singular, though this was not observed in their experiments with `λ > 0`.\n        *   The base learners demonstrated are primarily linear models (ridge regression, logistic regression).\n    *   **Scope of Applicability:** Most beneficial for few-shot learning scenarios where the number of training examples `n` per episode is small, as this is when the Woodbury identity provides significant computational advantages.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{bertinetto2018ur2} introduces a simple, efficient, and highly competitive alternative to existing meta-learning paradigms (similarity-based and gradient-based) for few-shot learning, achieving strong empirical results.\n    *   **Potential Impact on Future Research:**\n        *   Opens a new avenue for integrating a broader range of classical, efficient machine learning algorithms into deep learning pipelines by making them differentiable.\n        *   Provides a framework for designing meta-learners that effectively balance adaptability and computational efficiency.\n        *   Could inspire further research into differentiable versions of other non-deep models and their application in various meta-learning and optimization tasks.",
        "keywords": [
          "few-shot learning",
          "meta-learning",
          "differentiable closed-form solvers",
          "ridge regression",
          "Woodbury identity",
          "efficient backpropagation",
          "hyper-parameter meta-learning",
          "computational efficiency",
          "adaptability",
          "end-to-end training",
          "logistic regression",
          "deep feature extractor",
          "state-of-the-art performance",
          "classical machine learning integration"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** to use these fast convergent methods as the main adaptation mechanism for few-shot learning.\" and \"we **propose** both c\" (cut off, but implies proposing something). it also describes a new approach: \"teach a deep network to use standard machine learning tools... as part of its own internal model.\" and mentions technical details like \"back-propagating errors through the solver steps\" and \"using the woodbury identity.\"\n*   the introduction further clarifies: \"we **propose** both closed-form and iterative solvers, based on ridge regression and logistic regression components. our **methods** constitute a simple and novel approach to the problem of few-shot learning...\"\n*   the paper aims to solve a technical problem (adapting deep networks to new concepts from few examples) by presenting new methods and solvers. the mention of achieving competitive performance on benchmarks indicates the evaluation of these proposed methods.\n\nthis aligns perfectly with the criteria for a **technical** paper:\n*   **abstract mentions:** \"propose\", \"develop\" (implied by teaching a deep network to use tools), \"present\" (implied by proposing methods), \"algorithm\" (implied by solvers), \"method\" (explicitly mentioned).\n*   **introduction discusses:** technical problem (few-shot learning adaptation), proposed solution (new methods, solvers, technical details like woodbury identity).\n\ntherefore, the paper is a **technical** paper."
      },
      "file_name": "208cd4b25768f0096fb2e80e7690473da0e2a563.pdf"
    },
    {
      "success": true,
      "doc_id": "fd4bdc4498f0b195afe10df50a8ee0ed",
      "summary": "Here's a focused summary of the paper \"Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables\" \\cite{rakelly2019m09} for a literature review:\n\n### Technical Paper Analysis: \"Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables\" \\cite{rakelly2019m09}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Current meta-reinforcement learning (meta-RL) algorithms suffer from severe sample inefficiency, primarily due to their heavy reliance on on-policy experience during both meta-training and adaptation. They also lack robust mechanisms to reason about task uncertainty, which limits their effectiveness, especially in sparse reward environments.\n    *   **Importance and Challenge**: Conventional deep RL requires millions of interactions per task, making learning repertoires of behaviors prohibitive. Meta-RL aims to accelerate learning new tasks by leveraging shared structure across a distribution of tasks. However, the \"meta-training\" phase itself demands massive amounts of data, negating much of the sample efficiency benefit. Developing off-policy meta-RL is challenging because meta-learning typically assumes a match between meta-training and meta-test data distributions, and off-policy data is systematically different from the on-policy data used for adaptation. Additionally, meta-RL requires stochastic exploration strategies, which are not directly optimized by typical off-policy (value-based) RL methods.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Context-based Meta-RL (e.g., recurrent/recursive methods)**: Similar to these methods, \\cite{rakelly2019m09} uses a latent representation (context) to condition the policy. However, PEARL represents task contexts with *probabilistic* latent variables, enabling explicit reasoning over task uncertainty. It also uses a permutation-invariant encoder instead of recurrence, which is faster and mitigates overfitting for long-horizon tasks.\n        *   **Gradient-based Meta-RL (e.g., MAML)**: These methods primarily focus on *on-policy* meta-learning. PEARL distinguishes itself by focusing on *off-policy* meta-learning, which is non-trivial for gradient-based approaches.\n        *   **Probabilistic Meta-learning**: Extends the idea of adapting model predictions using probabilistic latent task variables (inferred via amortized approximate inference) from supervised learning to *off-policy meta-RL*.\n        *   **Posterior Sampling**: PEARL can be interpreted as a meta-learned variant of classical posterior sampling, where the probabilistic context captures task uncertainty for structured exploration.\n        *   **Partially Observed MDPs (POMDPs)**: Views adaptation as a POMDP problem and uses a variational approach, but leverages meta-learning structure to simplify inference.\n    *   **Limitations of Previous Solutions**:\n        *   **On-policy reliance**: Most prior meta-RL methods are on-policy, leading to extremely poor meta-training sample efficiency.\n        *   **Difficulty with off-policy**: Straightforward incorporation of recurrent policies with off-policy learning is difficult and often ineffective, especially for complex continuous control tasks.\n        *   **Lack of uncertainty reasoning**: Prior methods often lack explicit mechanisms to model and leverage task uncertainty for effective exploration, particularly in sparse reward settings.\n        *   **Asymptotic performance**: Gradient-based methods, while effective, are empirically found to reach lower asymptotic performance compared to PEARL's context-based approach.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **PEARL (Probabilistic Embeddings for Actor-Critic RL)**, an off-policy meta-RL algorithm that disentangles task inference from control. It integrates online inference of probabilistic context variables with existing off-policy RL algorithms.\n    *   **Novelty/Difference**:\n        *   **Probabilistic Context Variables (Z)**: A latent probabilistic variable `Z` is introduced to encode task-specific information, conditioning the policy `π(a|s,z)`. This allows for explicit reasoning about task uncertainty.\n        *   **Online Probabilistic Filtering**: An amortized variational inference network `q_φ(z|c)` is trained to estimate the posterior `p(z|c)` from a history of experience `c`. This network accumulates statistics online to infer how to solve a new task.\n        *   **Permutation-Invariant Encoder**: The inference network `q_φ(z|c)` is designed as a permutation-invariant function of prior experience, modeling it as a product of independent Gaussian factors. This ensures that the order of observed transitions does not affect task inference, making it robust and efficient.\n        *   **Posterior Sampling for Structured Exploration**: By modeling `Z` probabilistically, PEARL leverages posterior sampling. At meta-test time, `z` is sampled from the current posterior (initially a prior), and the agent acts optimally according to this sampled `z` for an entire episode. This enables temporally-extended and structured exploration, where the agent tests \"task hypotheses\" and updates its belief (posterior) based on collected experience.\n        *   **Decoupled Off-Policy Training**: The key innovation for off-policy efficiency is decoupling the data used to train the policy (actor-critic) from the data used to train the probabilistic encoder. The policy and critic are trained with off-policy data from a standard replay buffer, treating `z` as part of the state. The encoder `q(z|c)` is trained with context batches, which can be sampled differently to minimize distribution mismatch and enable efficient learning of task inference.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: PEARL, an off-policy meta-RL algorithm that achieves high sample efficiency during meta-training and rapid adaptation.\n    *   **Probabilistic Latent Task Variables**: Introduction and effective utilization of probabilistic context variables `Z` to capture task uncertainty and enable structured exploration.\n    *   **Permutation-Invariant Inference Network**: A novel architecture for the inference network `q_φ(z|c)` that processes experience in a permutation-invariant manner, leading to robust and efficient task inference.\n    *   **Integration of Posterior Sampling with Meta-RL**: A meta-learned variant of posterior sampling for exploration, allowing agents to explore coherently and adaptively in new tasks.\n    *   **Off-Policy Meta-Training Strategy**: A principled approach to integrate probabilistic task inference with off-policy actor-critic RL, by decoupling the data sampling strategies for the policy and the context encoder, overcoming a major challenge in meta-RL.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluated on six continuous control meta-learning environments (e.g., varying goal locations, dynamics, or reward functions).\n        *   Speciﬁcally examined structured exploration in a 2-D navigation environment with sparse rewards.\n        *   Compared against prior state-of-the-art meta-RL algorithms.\n    *   **Key Performance Metrics**:\n        *   Meta-training sample efficiency (number of environment interactions required during meta-training).\n        *   Asymptotic performance (final reward achieved after convergence).\n        *   Qualitative analysis of exploration strategies.\n    *   **Comparison Results**:\n        *   Achieved **20-100X improvement in meta-training sample efficiency** compared to prior algorithms.\n        *   Demonstrated **substantial increases in asymptotic performance** on several meta-RL benchmarks.\n        *   Showed that the model effectively conducts **structured exploration** to adapt rapidly to new tasks, particularly in sparse reward settings.\n        *   Empirically validated that straightforward incorporation of recurrent policies with off-policy learning is difficult, highlighting the necessity of PEARL's approach.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper implicitly acknowledges the difficulty of combining meta-learning with value-based RL, stating that a \"naive combination... could be ineffective\" and that they \"were unable to optimize such a method\" in practice. This highlights the complexity of the problem PEARL addresses. The method relies on the assumption that the policy can treat the inferred context `z` as part of the state.\n    *   **Scope of Applicability**: Primarily demonstrated on continuous control meta-learning tasks with varying dynamics or reward functions. While the principles are general, its direct applicability to other domains (e.g., discrete actions, very high-dimensional observations without pre-processing) would require further investigation. The permutation-invariant encoder assumes that the order of context transitions doesn't matter for task inference, which holds for many MDP definitions but might not for tasks where temporal order within the context is crucial for task identification.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: PEARL significantly advances the state-of-the-art in meta-RL by providing a highly sample-efficient off-policy algorithm. It addresses critical limitations of prior work, particularly the prohibitive meta-training costs and the lack of principled exploration strategies under uncertainty.\n    *   **Potential Impact on Future Research**:\n        *   Opens avenues for applying meta-RL to real-world problems where data collection is expensive.\n        *   Provides a strong baseline and framework for future research in off-policy meta-RL, probabilistic task inference, and structured exploration.\n        *   The decoupled training strategy and the use of probabilistic context variables offer a robust foundation for developing more complex and efficient meta-learning agents.\n        *   The open-source implementation facilitates further research and comparisons in the field.",
      "intriguing_abstract": "Meta-Reinforcement Learning (meta-RL) promises rapid adaptation, yet its widespread application is hampered by severe sample inefficiency due to reliance on on-policy data during meta-training. We introduce **PEARL (Probabilistic Embeddings for Actor-Critic RL)**, a novel off-policy meta-RL algorithm that dramatically overcomes this limitation.\n\nPEARL disentangles task inference from control by leveraging **probabilistic context variables** to explicitly model task uncertainty. An amortized **variational inference** network, featuring a permutation-invariant encoder, learns to infer task-specific latent representations from past experience. This probabilistic formulation enables a meta-learned variant of **posterior sampling** for temporally-extended, **structured exploration**—crucial for efficient adaptation, especially in sparse reward environments.\n\nBy decoupling the training of the actor-critic policy from the context encoder, PEARL achieves unprecedented **off-policy sample efficiency**. Our experiments demonstrate a **20-100X improvement in meta-training sample efficiency** and superior asymptotic performance across diverse continuous control benchmarks. PEARL represents a significant leap forward, making meta-RL practical for real-world applications where data acquisition is costly, and paving the way for more robust and adaptive intelligent agents.",
      "keywords": [
        "PEARL",
        "Off-policy meta-reinforcement learning",
        "Probabilistic context variables",
        "Sample inefficiency",
        "Permutation-invariant encoder",
        "Posterior sampling for structured exploration",
        "Decoupled off-policy training",
        "Meta-training sample efficiency improvement",
        "Rapid adaptation",
        "Asymptotic performance increase",
        "Task uncertainty reasoning",
        "Continuous control meta-learning"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/4625628163a2ee0e6cd320cd7a14b4ccded2a631.pdf",
      "citation_key": "rakelly2019m09",
      "metadata": {
        "title": "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables",
        "authors": [
          "Kate Rakelly",
          "Aurick Zhou",
          "Deirdre Quillen",
          "Chelsea Finn",
          "S. Levine"
        ],
        "published_date": "2019",
        "abstract": "Deep reinforcement learning algorithms require large amounts of experience to learn an individual task. While in principle meta-reinforcement learning (meta-RL) algorithms enable agents to learn new skills from small amounts of experience, several major challenges preclude their practicality. Current methods rely heavily on on-policy experience, limiting their sample efficiency. The also lack mechanisms to reason about task uncertainty when adapting to new tasks, limiting their effectiveness in sparse reward problems. In this paper, we address these challenges by developing an off-policy meta-RL algorithm that disentangles task inference and control. In our approach, we perform online probabilistic filtering of latent task variables to infer how to solve a new task from small amounts of experience. This probabilistic interpretation enables posterior sampling for structured and efficient exploration. We demonstrate how to integrate these task variables with off-policy RL algorithms to achieve both meta-training and adaptation efficiency. Our method outperforms prior algorithms in sample efficiency by 20-100X as well as in asymptotic performance on several meta-RL benchmarks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4625628163a2ee0e6cd320cd7a14b4ccded2a631.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 694,
        "score": 115.66666666666666,
        "summary": "Here's a focused summary of the paper \"Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables\" \\cite{rakelly2019m09} for a literature review:\n\n### Technical Paper Analysis: \"Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables\" \\cite{rakelly2019m09}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Current meta-reinforcement learning (meta-RL) algorithms suffer from severe sample inefficiency, primarily due to their heavy reliance on on-policy experience during both meta-training and adaptation. They also lack robust mechanisms to reason about task uncertainty, which limits their effectiveness, especially in sparse reward environments.\n    *   **Importance and Challenge**: Conventional deep RL requires millions of interactions per task, making learning repertoires of behaviors prohibitive. Meta-RL aims to accelerate learning new tasks by leveraging shared structure across a distribution of tasks. However, the \"meta-training\" phase itself demands massive amounts of data, negating much of the sample efficiency benefit. Developing off-policy meta-RL is challenging because meta-learning typically assumes a match between meta-training and meta-test data distributions, and off-policy data is systematically different from the on-policy data used for adaptation. Additionally, meta-RL requires stochastic exploration strategies, which are not directly optimized by typical off-policy (value-based) RL methods.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Context-based Meta-RL (e.g., recurrent/recursive methods)**: Similar to these methods, \\cite{rakelly2019m09} uses a latent representation (context) to condition the policy. However, PEARL represents task contexts with *probabilistic* latent variables, enabling explicit reasoning over task uncertainty. It also uses a permutation-invariant encoder instead of recurrence, which is faster and mitigates overfitting for long-horizon tasks.\n        *   **Gradient-based Meta-RL (e.g., MAML)**: These methods primarily focus on *on-policy* meta-learning. PEARL distinguishes itself by focusing on *off-policy* meta-learning, which is non-trivial for gradient-based approaches.\n        *   **Probabilistic Meta-learning**: Extends the idea of adapting model predictions using probabilistic latent task variables (inferred via amortized approximate inference) from supervised learning to *off-policy meta-RL*.\n        *   **Posterior Sampling**: PEARL can be interpreted as a meta-learned variant of classical posterior sampling, where the probabilistic context captures task uncertainty for structured exploration.\n        *   **Partially Observed MDPs (POMDPs)**: Views adaptation as a POMDP problem and uses a variational approach, but leverages meta-learning structure to simplify inference.\n    *   **Limitations of Previous Solutions**:\n        *   **On-policy reliance**: Most prior meta-RL methods are on-policy, leading to extremely poor meta-training sample efficiency.\n        *   **Difficulty with off-policy**: Straightforward incorporation of recurrent policies with off-policy learning is difficult and often ineffective, especially for complex continuous control tasks.\n        *   **Lack of uncertainty reasoning**: Prior methods often lack explicit mechanisms to model and leverage task uncertainty for effective exploration, particularly in sparse reward settings.\n        *   **Asymptotic performance**: Gradient-based methods, while effective, are empirically found to reach lower asymptotic performance compared to PEARL's context-based approach.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **PEARL (Probabilistic Embeddings for Actor-Critic RL)**, an off-policy meta-RL algorithm that disentangles task inference from control. It integrates online inference of probabilistic context variables with existing off-policy RL algorithms.\n    *   **Novelty/Difference**:\n        *   **Probabilistic Context Variables (Z)**: A latent probabilistic variable `Z` is introduced to encode task-specific information, conditioning the policy `π(a|s,z)`. This allows for explicit reasoning about task uncertainty.\n        *   **Online Probabilistic Filtering**: An amortized variational inference network `q_φ(z|c)` is trained to estimate the posterior `p(z|c)` from a history of experience `c`. This network accumulates statistics online to infer how to solve a new task.\n        *   **Permutation-Invariant Encoder**: The inference network `q_φ(z|c)` is designed as a permutation-invariant function of prior experience, modeling it as a product of independent Gaussian factors. This ensures that the order of observed transitions does not affect task inference, making it robust and efficient.\n        *   **Posterior Sampling for Structured Exploration**: By modeling `Z` probabilistically, PEARL leverages posterior sampling. At meta-test time, `z` is sampled from the current posterior (initially a prior), and the agent acts optimally according to this sampled `z` for an entire episode. This enables temporally-extended and structured exploration, where the agent tests \"task hypotheses\" and updates its belief (posterior) based on collected experience.\n        *   **Decoupled Off-Policy Training**: The key innovation for off-policy efficiency is decoupling the data used to train the policy (actor-critic) from the data used to train the probabilistic encoder. The policy and critic are trained with off-policy data from a standard replay buffer, treating `z` as part of the state. The encoder `q(z|c)` is trained with context batches, which can be sampled differently to minimize distribution mismatch and enable efficient learning of task inference.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: PEARL, an off-policy meta-RL algorithm that achieves high sample efficiency during meta-training and rapid adaptation.\n    *   **Probabilistic Latent Task Variables**: Introduction and effective utilization of probabilistic context variables `Z` to capture task uncertainty and enable structured exploration.\n    *   **Permutation-Invariant Inference Network**: A novel architecture for the inference network `q_φ(z|c)` that processes experience in a permutation-invariant manner, leading to robust and efficient task inference.\n    *   **Integration of Posterior Sampling with Meta-RL**: A meta-learned variant of posterior sampling for exploration, allowing agents to explore coherently and adaptively in new tasks.\n    *   **Off-Policy Meta-Training Strategy**: A principled approach to integrate probabilistic task inference with off-policy actor-critic RL, by decoupling the data sampling strategies for the policy and the context encoder, overcoming a major challenge in meta-RL.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluated on six continuous control meta-learning environments (e.g., varying goal locations, dynamics, or reward functions).\n        *   Speciﬁcally examined structured exploration in a 2-D navigation environment with sparse rewards.\n        *   Compared against prior state-of-the-art meta-RL algorithms.\n    *   **Key Performance Metrics**:\n        *   Meta-training sample efficiency (number of environment interactions required during meta-training).\n        *   Asymptotic performance (final reward achieved after convergence).\n        *   Qualitative analysis of exploration strategies.\n    *   **Comparison Results**:\n        *   Achieved **20-100X improvement in meta-training sample efficiency** compared to prior algorithms.\n        *   Demonstrated **substantial increases in asymptotic performance** on several meta-RL benchmarks.\n        *   Showed that the model effectively conducts **structured exploration** to adapt rapidly to new tasks, particularly in sparse reward settings.\n        *   Empirically validated that straightforward incorporation of recurrent policies with off-policy learning is difficult, highlighting the necessity of PEARL's approach.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper implicitly acknowledges the difficulty of combining meta-learning with value-based RL, stating that a \"naive combination... could be ineffective\" and that they \"were unable to optimize such a method\" in practice. This highlights the complexity of the problem PEARL addresses. The method relies on the assumption that the policy can treat the inferred context `z` as part of the state.\n    *   **Scope of Applicability**: Primarily demonstrated on continuous control meta-learning tasks with varying dynamics or reward functions. While the principles are general, its direct applicability to other domains (e.g., discrete actions, very high-dimensional observations without pre-processing) would require further investigation. The permutation-invariant encoder assumes that the order of context transitions doesn't matter for task inference, which holds for many MDP definitions but might not for tasks where temporal order within the context is crucial for task identification.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: PEARL significantly advances the state-of-the-art in meta-RL by providing a highly sample-efficient off-policy algorithm. It addresses critical limitations of prior work, particularly the prohibitive meta-training costs and the lack of principled exploration strategies under uncertainty.\n    *   **Potential Impact on Future Research**:\n        *   Opens avenues for applying meta-RL to real-world problems where data collection is expensive.\n        *   Provides a strong baseline and framework for future research in off-policy meta-RL, probabilistic task inference, and structured exploration.\n        *   The decoupled training strategy and the use of probabilistic context variables offer a robust foundation for developing more complex and efficient meta-learning agents.\n        *   The open-source implementation facilitates further research and comparisons in the field.",
        "keywords": [
          "PEARL",
          "Off-policy meta-reinforcement learning",
          "Probabilistic context variables",
          "Sample inefficiency",
          "Permutation-invariant encoder",
          "Posterior sampling for structured exploration",
          "Decoupled off-policy training",
          "Meta-training sample efficiency improvement",
          "Rapid adaptation",
          "Asymptotic performance increase",
          "Task uncertainty reasoning",
          "Continuous control meta-learning"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"we address these challenges by **developing an off-policy meta-rl algorithm**\", \"in our approach, we perform online probabilistic filtering...\", \"we demonstrate how to integrate these task variables with off-policy rl algorithms\", \"our method outperforms prior algorithms...\". the core focus is on proposing and developing a new algorithm/method.\n*   **introduction discusses:** it clearly outlines a \"technical problem\" (sample inefficiency, reliance on on-policy data in meta-rl) and sets the stage for a \"proposed solution\" (which the abstract then details as the new algorithm).\n\nwhile the abstract also mentions \"our method outperforms prior algorithms... on several meta-rl benchmarks,\" which indicates strong empirical validation, the primary contribution described is the *development* of the new algorithm and its underlying mechanisms. empirical results are used to demonstrate the effectiveness of this new technical contribution."
      },
      "file_name": "4625628163a2ee0e6cd320cd7a14b4ccded2a631.pdf"
    },
    {
      "success": true,
      "doc_id": "6981b82241af1e9fb7cce63634f4c59b",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Deep reinforcement learning (RL) systems, despite superhuman performance in some domains, suffer from two major limitations:\n        *   They demand massive amounts of training data \\cite{wang20167px}.\n        *   They typically specialize on one restricted task domain, lacking flexible adaptation to new tasks \\cite{wang20167px}.\n    *   The problem is to develop deep RL methods that can adapt rapidly and sample-efficiently to new tasks, overcoming these limitations.\n\n*   **Related Work & Positioning**\n    *   This work builds upon the concept of \"meta-learning,\" where a system learns to learn, often involving two learning systems (a fast, lower-level system for task adaptation and a slower, higher-level system for tuning) \\cite{wang20167px}.\n    *   Specifically, it extends previous work by Hochreiter et al. (2001) and Santoro et al. (2016) that demonstrated recurrent neural networks (RNNs) could support meta-learning in a *fully supervised context* \\cite{wang20167px}.\n    *   **Limitations of previous solutions:** Prior RNN-based meta-learning approaches were restricted to supervised learning, where explicit target outputs were provided as auxiliary inputs. They did not address the unique challenges of reinforcement learning, such as navigating exploration-exploitation tradeoffs or learning from sparse reward signals \\cite{wang20167px}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method:** The paper introduces \"deep meta-reinforcement learning\" (deep meta-RL), which applies the RNN-based meta-learning approach to the RL setting \\cite{wang20167px}.\n    *   A recurrent neural network (specifically, an LSTM) is trained using a standard deep RL algorithm (Advantage Actor-Critic, A2C/A3C) across a distribution of related tasks \\cite{wang20167px}.\n    *   **Key Innovation:** Instead of target outputs, the RNN receives auxiliary inputs indicating the *action taken on the previous step* and, critically, the *reward received from that action* \\cite{wang20167px}.\n    *   Through this training, the *recurrent dynamics* of the network itself learn to implement a *second, distinct reinforcement learning procedure* \\cite{wang20167px}. This \"learned RL algorithm\" operates within the RNN's activations, adapting its policy based on the history of actions and rewards within an episode, even when the network weights are frozen \\cite{wang20167px}.\n    *   This learned RL algorithm can develop its own exploration strategies and policy update rules, which can differ significantly from the algorithm used to train the network's weights, and is configured to exploit the underlying structure of the training domain for rapid adaptation \\cite{wang20167px}.\n\n*   **Key Technical Contributions**\n    *   **Novel Framework:** Introduction of the deep meta-reinforcement learning framework, extending RNN-based meta-learning from supervised learning to the more complex domain of reinforcement learning \\cite{wang20167px}.\n    *   **Implicit Learning of RL Algorithms:** Demonstrating that an RNN, when provided with previous actions and rewards as inputs, can implicitly learn a full-fledged RL algorithm within its recurrent dynamics, capable of handling exploration-exploitation and policy updates \\cite{wang20167px}.\n    *   **Prior-Dependent Adaptation:** The learned RL procedure is shown to be \"fit to the statistics spanning the multi-task environment,\" allowing it to adapt rapidly and efficiently to new task instances drawn from that distribution \\cite{wang20167px}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Seven proof-of-concept experiments were performed, including four focusing on various bandit tasks (e.g., independent arms, dependent arms) and two on Markov Decision Problems (MDPs) \\cite{wang20167px}.\n    *   **Common Setup:** All experiments utilized an LSTM-based architecture, trained with the Advantage Actor-Critic (A2C/A3C) algorithm. Training and testing involved fixed-length episodes, with tasks randomly sampled from a predetermined distribution, and the LSTM hidden state initialized at the beginning of each episode \\cite{wang20167px}. Inputs typically included the last reward, last action, and sometimes the current time step or observation \\cite{wang20167px}.\n    *   **Key Performance Metrics:** For bandit tasks, performance was evaluated using cumulative regret (loss from playing sub-optimal arms) and the number of sub-optimal pulls \\cite{wang20167px}.\n    *   **Comparison Results (Bandits with Independent Arms - Experiment 1):**\n        *   Meta-RL (LSTM A2C) was compared against established bandit algorithms: Gittins indices (Bayesian optimal), UCB, and Thompson sampling \\cite{wang20167px}.\n        *   **Result:** Meta-RL outperformed both Thompson sampling and UCB, demonstrating its ability to learn an effective exploration-exploitation strategy. While it performed less well than the theoretically optimal Gittins indices, its strong performance validated the approach \\cite{wang20167px}.\n        *   **Critical Finding:** Removing the reward information from the LSTM's input resulted in chance-level performance, empirically confirming that the reward signal is essential for the network to learn an internal RL procedure \\cite{wang20167px}.\n\n*   **Limitations & Scope**\n    *   The experiments are proof-of-concept, conducted in relatively constrained environments (various bandit problems and simple MDPs), rather than large-scale, complex domains \\cite{wang20167px}.\n    *   The paper explicitly states that comparisons between specific architectures or extensive hyperparameter tuning are outside its scope, focusing instead on validating the general meta-RL framework \\cite{wang20167px}.\n    *   Generalization was primarily tested on tasks drawn from the *same distribution* or *slight modifications* thereof, suggesting the learned RL algorithm is specialized to a family of tasks \\cite{wang20167px}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a novel framework to address the critical challenges of data inefficiency and task specialization in deep RL \\cite{wang20167px}.\n    *   It proposes a paradigm shift where the learning algorithm itself is learned and embedded within the recurrent dynamics of a neural network, moving beyond hand-engineered learning rules \\cite{wang20167px}.\n    *   **Potential Impact:** This approach could lead to more rapidly adaptive and sample-efficient RL agents, bringing deep RL closer to human-like learning capabilities. It opens new avenues for designing agents that can implicitly discover and exploit the underlying structure of task environments, and has potential implications for understanding biological learning mechanisms \\cite{wang20167px}.",
      "intriguing_abstract": "Deep reinforcement learning (RL) systems, despite their impressive capabilities, remain notoriously sample-inefficient and struggle with rapid adaptation to novel tasks. We introduce a groundbreaking deep meta-reinforcement learning framework that enables agents to *learn to learn* an RL algorithm itself, addressing these critical limitations. Our approach leverages a recurrent neural network (RNN), specifically an LSTM, trained with a standard deep RL algorithm (A2C/A3C) across a distribution of related tasks.\n\nThe core innovation lies in providing the RNN with its previous action and the reward received as auxiliary inputs. Through this mechanism, the network's recurrent dynamics implicitly learn a distinct, internal reinforcement learning procedure. This \"learned RL algorithm\" dynamically adapts its policy within an episode, handling complex exploration-exploitation tradeoffs and policy updates, even with frozen network weights. Unlike prior supervised meta-learning, our system navigates the unique challenges of RL, demonstrating superior sample efficiency and rapid adaptation in diverse bandit and simple MDP environments. This paradigm shift, where the learning algorithm is discovered rather than engineered, promises more flexible and human-like AI, paving the way for agents that can rapidly exploit the underlying structure of new environments.",
      "keywords": [
        "Deep meta-reinforcement learning",
        "meta-learning",
        "recurrent neural networks (RNNs)",
        "implicit learning of RL algorithms",
        "learned RL algorithm",
        "rapid adaptation",
        "sample-efficient learning",
        "exploration-exploitation",
        "auxiliary inputs (action",
        "reward)",
        "recurrent dynamics",
        "Advantage Actor-Critic (A2C/A3C)",
        "bandit tasks",
        "Markov Decision Problems",
        "prior-dependent adaptation"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/282a380fb5ac26d99667224cef8c630f6882704f.pdf",
      "citation_key": "wang20167px",
      "metadata": {
        "title": "Learning to reinforcement learn",
        "authors": [
          "Jane X. Wang",
          "Z. Kurth-Nelson",
          "Hubert Soyer",
          "Joel Z. Leibo",
          "Dhruva Tirumala",
          "R. Munos",
          "C. Blundell",
          "D. Kumaran",
          "M. Botvinick"
        ],
        "published_date": "2016",
        "abstract": "In recent years deep reinforcement learning (RL) systems have attained superhuman performance in a number of challenging task domains. However, a major limitation of such applications is their demand for massive amounts of training data. A critical present objective is thus to develop deep RL methods that can adapt rapidly to new tasks. In the present work we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning. Previous work has shown that recurrent networks can support meta-learning in a fully supervised context. We extend this approach to the RL setting. What emerges is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure. This second, learned RL algorithm can differ from the original one in arbitrary ways. Importantly, because it is learned, it is configured to exploit structure in the training domain. We unpack these points in a series of seven proof-of-concept experiments, each of which examines a key aspect of deep meta-RL. We consider prospects for extending and scaling up the approach, and also point out some potentially important implications for neuroscience.",
        "file_path": "paper_data/Deep_Meta-Learning/info/282a380fb5ac26d99667224cef8c630f6882704f.pdf",
        "venue": "Annual Meeting of the Cognitive Science Society",
        "citationCount": 1007,
        "score": 111.88888888888889,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   Deep reinforcement learning (RL) systems, despite superhuman performance in some domains, suffer from two major limitations:\n        *   They demand massive amounts of training data \\cite{wang20167px}.\n        *   They typically specialize on one restricted task domain, lacking flexible adaptation to new tasks \\cite{wang20167px}.\n    *   The problem is to develop deep RL methods that can adapt rapidly and sample-efficiently to new tasks, overcoming these limitations.\n\n*   **Related Work & Positioning**\n    *   This work builds upon the concept of \"meta-learning,\" where a system learns to learn, often involving two learning systems (a fast, lower-level system for task adaptation and a slower, higher-level system for tuning) \\cite{wang20167px}.\n    *   Specifically, it extends previous work by Hochreiter et al. (2001) and Santoro et al. (2016) that demonstrated recurrent neural networks (RNNs) could support meta-learning in a *fully supervised context* \\cite{wang20167px}.\n    *   **Limitations of previous solutions:** Prior RNN-based meta-learning approaches were restricted to supervised learning, where explicit target outputs were provided as auxiliary inputs. They did not address the unique challenges of reinforcement learning, such as navigating exploration-exploitation tradeoffs or learning from sparse reward signals \\cite{wang20167px}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method:** The paper introduces \"deep meta-reinforcement learning\" (deep meta-RL), which applies the RNN-based meta-learning approach to the RL setting \\cite{wang20167px}.\n    *   A recurrent neural network (specifically, an LSTM) is trained using a standard deep RL algorithm (Advantage Actor-Critic, A2C/A3C) across a distribution of related tasks \\cite{wang20167px}.\n    *   **Key Innovation:** Instead of target outputs, the RNN receives auxiliary inputs indicating the *action taken on the previous step* and, critically, the *reward received from that action* \\cite{wang20167px}.\n    *   Through this training, the *recurrent dynamics* of the network itself learn to implement a *second, distinct reinforcement learning procedure* \\cite{wang20167px}. This \"learned RL algorithm\" operates within the RNN's activations, adapting its policy based on the history of actions and rewards within an episode, even when the network weights are frozen \\cite{wang20167px}.\n    *   This learned RL algorithm can develop its own exploration strategies and policy update rules, which can differ significantly from the algorithm used to train the network's weights, and is configured to exploit the underlying structure of the training domain for rapid adaptation \\cite{wang20167px}.\n\n*   **Key Technical Contributions**\n    *   **Novel Framework:** Introduction of the deep meta-reinforcement learning framework, extending RNN-based meta-learning from supervised learning to the more complex domain of reinforcement learning \\cite{wang20167px}.\n    *   **Implicit Learning of RL Algorithms:** Demonstrating that an RNN, when provided with previous actions and rewards as inputs, can implicitly learn a full-fledged RL algorithm within its recurrent dynamics, capable of handling exploration-exploitation and policy updates \\cite{wang20167px}.\n    *   **Prior-Dependent Adaptation:** The learned RL procedure is shown to be \"fit to the statistics spanning the multi-task environment,\" allowing it to adapt rapidly and efficiently to new task instances drawn from that distribution \\cite{wang20167px}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Seven proof-of-concept experiments were performed, including four focusing on various bandit tasks (e.g., independent arms, dependent arms) and two on Markov Decision Problems (MDPs) \\cite{wang20167px}.\n    *   **Common Setup:** All experiments utilized an LSTM-based architecture, trained with the Advantage Actor-Critic (A2C/A3C) algorithm. Training and testing involved fixed-length episodes, with tasks randomly sampled from a predetermined distribution, and the LSTM hidden state initialized at the beginning of each episode \\cite{wang20167px}. Inputs typically included the last reward, last action, and sometimes the current time step or observation \\cite{wang20167px}.\n    *   **Key Performance Metrics:** For bandit tasks, performance was evaluated using cumulative regret (loss from playing sub-optimal arms) and the number of sub-optimal pulls \\cite{wang20167px}.\n    *   **Comparison Results (Bandits with Independent Arms - Experiment 1):**\n        *   Meta-RL (LSTM A2C) was compared against established bandit algorithms: Gittins indices (Bayesian optimal), UCB, and Thompson sampling \\cite{wang20167px}.\n        *   **Result:** Meta-RL outperformed both Thompson sampling and UCB, demonstrating its ability to learn an effective exploration-exploitation strategy. While it performed less well than the theoretically optimal Gittins indices, its strong performance validated the approach \\cite{wang20167px}.\n        *   **Critical Finding:** Removing the reward information from the LSTM's input resulted in chance-level performance, empirically confirming that the reward signal is essential for the network to learn an internal RL procedure \\cite{wang20167px}.\n\n*   **Limitations & Scope**\n    *   The experiments are proof-of-concept, conducted in relatively constrained environments (various bandit problems and simple MDPs), rather than large-scale, complex domains \\cite{wang20167px}.\n    *   The paper explicitly states that comparisons between specific architectures or extensive hyperparameter tuning are outside its scope, focusing instead on validating the general meta-RL framework \\cite{wang20167px}.\n    *   Generalization was primarily tested on tasks drawn from the *same distribution* or *slight modifications* thereof, suggesting the learned RL algorithm is specialized to a family of tasks \\cite{wang20167px}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a novel framework to address the critical challenges of data inefficiency and task specialization in deep RL \\cite{wang20167px}.\n    *   It proposes a paradigm shift where the learning algorithm itself is learned and embedded within the recurrent dynamics of a neural network, moving beyond hand-engineered learning rules \\cite{wang20167px}.\n    *   **Potential Impact:** This approach could lead to more rapidly adaptive and sample-efficient RL agents, bringing deep RL closer to human-like learning capabilities. It opens new avenues for designing agents that can implicitly discover and exploit the underlying structure of task environments, and has potential implications for understanding biological learning mechanisms \\cite{wang20167px}.",
        "keywords": [
          "Deep meta-reinforcement learning",
          "meta-learning",
          "recurrent neural networks (RNNs)",
          "implicit learning of RL algorithms",
          "learned RL algorithm",
          "rapid adaptation",
          "sample-efficient learning",
          "exploration-exploitation",
          "auxiliary inputs (action",
          "reward)",
          "recurrent dynamics",
          "Advantage Actor-Critic (A2C/A3C)",
          "bandit tasks",
          "Markov Decision Problems",
          "prior-dependent adaptation"
        ],
        "paper_type": "based on the abstract and introduction, this paper should be classified as **technical**.\n\nhere's why:\n\n*   **abstract mentions:** \"we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning.\" it describes developing \"deep rl methods that can adapt rapidly to new tasks\" and a \"system that is trained using one rl algorithm, but whose recurrent dynamics implement a second, quite separate rl procedure.\" these phrases directly align with presenting new methods, algorithms, or systems.\n*   **introduction discusses:** \"in the present work, we outline a framework for meeting these challenges, which we refer to as deep meta-reinforcement learning\". it details the \"key concept is to use standard deep rl techniques to train a recurrent neural network in such a way that the recurrent network comes to implement its own, free-standing rl procedure.\" this clearly describes a technical problem and a proposed solution.\n*   while the paper includes \"seven proof-of-concept experiments\" (making it also empirical in nature), the primary contribution and emphasis are on the *development and introduction of the novel deep meta-reinforcement learning framework and method*. the experiments serve to validate this new technical contribution."
      },
      "file_name": "282a380fb5ac26d99667224cef8c630f6882704f.pdf"
    },
    {
      "success": true,
      "doc_id": "2b1950635f0153eed10aa0939d4b9217",
      "summary": "We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning. We show that an approximate version of the bilevel problem can be solved by taking into explicit account the optimization dynamics for the inner objective. Depending on the specific setting, the outer variables take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner. We provide sufficient conditions under which solutions of the approximate problem converge to those of the exact problem. We instantiate our approach for meta-learning in the case of deep learning where representation layers are treated as hyperparameters shared across a set of training episodes. In experiments, we confirm our theoretical findings, present encouraging results for few-shot learning and contrast the bilevel approach against classical approaches for learning-to-learn.",
      "intriguing_abstract": "We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning. We show that an approximate version of the bilevel problem can be solved by taking into explicit account the optimization dynamics for the inner objective. Depending on the specific setting, the outer variables take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner. We provide sufficient conditions under which solutions of the approximate problem converge to those of the exact problem. We instantiate our approach for meta-learning in the case of deep learning where representation layers are treated as hyperparameters shared across a set of training episodes. In experiments, we confirm our theoretical findings, present encouraging results for few-shot learning and contrast the bilevel approach against classical approaches for learning-to-learn.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/15561ab20c298e113b0008b7a029486a422e7ca3.pdf",
      "citation_key": "franceschi2018u1q",
      "metadata": {
        "title": "Bilevel Programming for Hyperparameter Optimization and Meta-Learning",
        "authors": [
          "Luca Franceschi",
          "P. Frasconi",
          "Saverio Salzo",
          "Riccardo Grazzi",
          "M. Pontil"
        ],
        "published_date": "2018",
        "abstract": "We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning. We show that an approximate version of the bilevel problem can be solved by taking into explicit account the optimization dynamics for the inner objective. Depending on the specific setting, the outer variables take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner. We provide sufficient conditions under which solutions of the approximate problem converge to those of the exact problem. We instantiate our approach for meta-learning in the case of deep learning where representation layers are treated as hyperparameters shared across a set of training episodes. In experiments, we confirm our theoretical findings, present encouraging results for few-shot learning and contrast the bilevel approach against classical approaches for learning-to-learn.",
        "file_path": "paper_data/Deep_Meta-Learning/info/15561ab20c298e113b0008b7a029486a422e7ca3.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 762,
        "score": 108.85714285714285,
        "summary": "We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning. We show that an approximate version of the bilevel problem can be solved by taking into explicit account the optimization dynamics for the inner objective. Depending on the specific setting, the outer variables take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner. We provide sufficient conditions under which solutions of the approximate problem converge to those of the exact problem. We instantiate our approach for meta-learning in the case of deep learning where representation layers are treated as hyperparameters shared across a set of training episodes. In experiments, we confirm our theoretical findings, present encouraging results for few-shot learning and contrast the bilevel approach against classical approaches for learning-to-learn.",
        "keywords": []
      },
      "file_name": "15561ab20c298e113b0008b7a029486a422e7ca3.pdf"
    },
    {
      "success": true,
      "doc_id": "70ebb0d8e4859c83e6216f15e55f3ca8",
      "summary": "Predicting urban traffic is of great importance to intelligent transportation systems and public safety, yet is very challenging because of two aspects: 1) complex spatio-temporal correlations of urban traffic, including spatial correlations between locations along with temporal correlations among timestamps; 2) diversity of such spatio-temporal correlations, which vary from location to location and depend on the surrounding geographical information, e.g., points of interests and road networks. To tackle these challenges, we proposed a deep-meta-learning based model, entitled ST-MetaNet, to collectively predict traffic in all location at once. ST-MetaNet employs a sequence-to-sequence architecture, consisting of an encoder to learn historical information and a decoder to make predictions step by step. In specific, the encoder and decoder have the same network structure, consisting of a recurrent neural network to encode the traffic, a meta graph attention network to capture diverse spatial correlations, and a meta recurrent neural network to consider diverse temporal correlations. Extensive experiments were conducted based on two real-world datasets to illustrate the effectiveness of ST-MetaNet beyond several state-of-the-art methods.",
      "intriguing_abstract": "Predicting urban traffic is of great importance to intelligent transportation systems and public safety, yet is very challenging because of two aspects: 1) complex spatio-temporal correlations of urban traffic, including spatial correlations between locations along with temporal correlations among timestamps; 2) diversity of such spatio-temporal correlations, which vary from location to location and depend on the surrounding geographical information, e.g., points of interests and road networks. To tackle these challenges, we proposed a deep-meta-learning based model, entitled ST-MetaNet, to collectively predict traffic in all location at once. ST-MetaNet employs a sequence-to-sequence architecture, consisting of an encoder to learn historical information and a decoder to make predictions step by step. In specific, the encoder and decoder have the same network structure, consisting of a recurrent neural network to encode the traffic, a meta graph attention network to capture diverse spatial correlations, and a meta recurrent neural network to consider diverse temporal correlations. Extensive experiments were conducted based on two real-world datasets to illustrate the effectiveness of ST-MetaNet beyond several state-of-the-art methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/06b8e82542d1873928d007548a23d3b77daa11f8.pdf",
      "citation_key": "pan2019pue",
      "metadata": {
        "title": "Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning",
        "authors": [
          "Zheyi Pan",
          "Yuxuan Liang",
          "Weifeng Wang",
          "Yong Yu",
          "Yu Zheng",
          "Junbo Zhang"
        ],
        "published_date": "2019",
        "abstract": "Predicting urban traffic is of great importance to intelligent transportation systems and public safety, yet is very challenging because of two aspects: 1) complex spatio-temporal correlations of urban traffic, including spatial correlations between locations along with temporal correlations among timestamps; 2) diversity of such spatio-temporal correlations, which vary from location to location and depend on the surrounding geographical information, e.g., points of interests and road networks. To tackle these challenges, we proposed a deep-meta-learning based model, entitled ST-MetaNet, to collectively predict traffic in all location at once. ST-MetaNet employs a sequence-to-sequence architecture, consisting of an encoder to learn historical information and a decoder to make predictions step by step. In specific, the encoder and decoder have the same network structure, consisting of a recurrent neural network to encode the traffic, a meta graph attention network to capture diverse spatial correlations, and a meta recurrent neural network to consider diverse temporal correlations. Extensive experiments were conducted based on two real-world datasets to illustrate the effectiveness of ST-MetaNet beyond several state-of-the-art methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/06b8e82542d1873928d007548a23d3b77daa11f8.pdf",
        "venue": "Knowledge Discovery and Data Mining",
        "citationCount": 557,
        "score": 92.83333333333333,
        "summary": "Predicting urban traffic is of great importance to intelligent transportation systems and public safety, yet is very challenging because of two aspects: 1) complex spatio-temporal correlations of urban traffic, including spatial correlations between locations along with temporal correlations among timestamps; 2) diversity of such spatio-temporal correlations, which vary from location to location and depend on the surrounding geographical information, e.g., points of interests and road networks. To tackle these challenges, we proposed a deep-meta-learning based model, entitled ST-MetaNet, to collectively predict traffic in all location at once. ST-MetaNet employs a sequence-to-sequence architecture, consisting of an encoder to learn historical information and a decoder to make predictions step by step. In specific, the encoder and decoder have the same network structure, consisting of a recurrent neural network to encode the traffic, a meta graph attention network to capture diverse spatial correlations, and a meta recurrent neural network to consider diverse temporal correlations. Extensive experiments were conducted based on two real-world datasets to illustrate the effectiveness of ST-MetaNet beyond several state-of-the-art methods.",
        "keywords": []
      },
      "file_name": "06b8e82542d1873928d007548a23d3b77daa11f8.pdf"
    },
    {
      "success": true,
      "doc_id": "4c4dc09245eae01c45d19b3f44ca073c",
      "summary": "To achieve general intelligence, agents must learn how to interact with others in a shared environment: this is the challenge of multiagent reinforcement learning (MARL). The simplest form is independent reinforcement learning (InRL), where each agent treats its experience as part of its (non-stationary) environment. In this paper, we first observe that policies learned using InRL can overfit to the other agents' policies during training, failing to sufficiently generalize during execution. We introduce a new metric, joint-policy correlation, to quantify this effect. We describe an algorithm for general MARL, based on approximate best responses to mixtures of policies generated using deep reinforcement learning, and empirical game-theoretic analysis to compute meta-strategies for policy selection. The algorithm generalizes previous ones such as InRL, iterated best response, double oracle, and fictitious play. Then, we present a scalable implementation which reduces the memory requirement using decoupled meta-solvers. Finally, we demonstrate the generality of the resulting policies in two partially observable settings: gridworld coordination games and poker.",
      "intriguing_abstract": "To achieve general intelligence, agents must learn how to interact with others in a shared environment: this is the challenge of multiagent reinforcement learning (MARL). The simplest form is independent reinforcement learning (InRL), where each agent treats its experience as part of its (non-stationary) environment. In this paper, we first observe that policies learned using InRL can overfit to the other agents' policies during training, failing to sufficiently generalize during execution. We introduce a new metric, joint-policy correlation, to quantify this effect. We describe an algorithm for general MARL, based on approximate best responses to mixtures of policies generated using deep reinforcement learning, and empirical game-theoretic analysis to compute meta-strategies for policy selection. The algorithm generalizes previous ones such as InRL, iterated best response, double oracle, and fictitious play. Then, we present a scalable implementation which reduces the memory requirement using decoupled meta-solvers. Finally, we demonstrate the generality of the resulting policies in two partially observable settings: gridworld coordination games and poker.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b0d8165eecf2aa04a85e701d0c6bb4edd4b3811b.pdf",
      "citation_key": "lanctot2017m2v",
      "metadata": {
        "title": "A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning",
        "authors": [
          "Marc Lanctot",
          "V. Zambaldi",
          "A. Gruslys",
          "Angeliki Lazaridou",
          "K. Tuyls",
          "J. Pérolat",
          "David Silver",
          "T. Graepel"
        ],
        "published_date": "2017",
        "abstract": "To achieve general intelligence, agents must learn how to interact with others in a shared environment: this is the challenge of multiagent reinforcement learning (MARL). The simplest form is independent reinforcement learning (InRL), where each agent treats its experience as part of its (non-stationary) environment. In this paper, we first observe that policies learned using InRL can overfit to the other agents' policies during training, failing to sufficiently generalize during execution. We introduce a new metric, joint-policy correlation, to quantify this effect. We describe an algorithm for general MARL, based on approximate best responses to mixtures of policies generated using deep reinforcement learning, and empirical game-theoretic analysis to compute meta-strategies for policy selection. The algorithm generalizes previous ones such as InRL, iterated best response, double oracle, and fictitious play. Then, we present a scalable implementation which reduces the memory requirement using decoupled meta-solvers. Finally, we demonstrate the generality of the resulting policies in two partially observable settings: gridworld coordination games and poker.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b0d8165eecf2aa04a85e701d0c6bb4edd4b3811b.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 660,
        "score": 82.5,
        "summary": "To achieve general intelligence, agents must learn how to interact with others in a shared environment: this is the challenge of multiagent reinforcement learning (MARL). The simplest form is independent reinforcement learning (InRL), where each agent treats its experience as part of its (non-stationary) environment. In this paper, we first observe that policies learned using InRL can overfit to the other agents' policies during training, failing to sufficiently generalize during execution. We introduce a new metric, joint-policy correlation, to quantify this effect. We describe an algorithm for general MARL, based on approximate best responses to mixtures of policies generated using deep reinforcement learning, and empirical game-theoretic analysis to compute meta-strategies for policy selection. The algorithm generalizes previous ones such as InRL, iterated best response, double oracle, and fictitious play. Then, we present a scalable implementation which reduces the memory requirement using decoupled meta-solvers. Finally, we demonstrate the generality of the resulting policies in two partially observable settings: gridworld coordination games and poker.",
        "keywords": []
      },
      "file_name": "b0d8165eecf2aa04a85e701d0c6bb4edd4b3811b.pdf"
    },
    {
      "success": true,
      "doc_id": "b048bebc91db29b4880e93547b94905e",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{finn20174c4}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Enabling robots to quickly and efficiently acquire a wide variety of complex skills from raw sensory inputs (e.g., pixels) in unstructured environments, especially when using high-capacity models like deep neural networks.\n    *   **Importance & Challenge**:\n        *   **Robot Generalism**: Current methods struggle to make robots generalists capable of many tasks with diverse objects.\n        *   **Data Efficiency**: Deep learning models typically require a large amount of supervision or experience *per task*, making it infeasible to learn many skills from scratch.\n        *   **Lack of Experience Reuse**: Most methods do not leverage experience from previous tasks to accelerate learning for new tasks, leading to independent data collection for every new skill.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Combines imitation learning with meta-learning for one-shot learning from visual demonstrations.\n        *   Differs from prior efficient imitation methods that rely on known environment states (e.g., object poses) by focusing on raw sensory inputs.\n        *   Contrasts with multi-task robotic learning methods (e.g., contextual policies that take task identity or a demonstration as input) by learning a policy that can be *adapted* through gradient updates.\n    *   **Limitations of Previous Solutions**:\n        *   **Imitation Learning from Raw Pixels**: Often requires a large number of demonstrations per task, a major roadblock for generalist robots. Also, compounding errors are a known issue (though not addressed by this paper).\n        *   **Inverse Reinforcement Learning**: Can reduce demonstration needs but requires additional robot experience (trial-and-error or model learning).\n        *   **Contextual Policies**: While sharing information across tasks, they typically provide the task as an input to the policy, which can be less flexible or parameter-efficient than gradient-based adaptation.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a meta-imitation learning method that extends Model-Agnostic Meta-Learning (MAML) \\cite{finn20174c4} to the visual imitation learning setting.\n    *   **Novelty/Difference**:\n        *   **Gradient-Based Adaptation**: Instead of providing task identity or a demonstration as a direct input, the method learns a parameterized policy that can be adapted to new tasks via gradient updates on a single demonstration.\n        *   **Scalability to Raw Pixels**: For the first time, it demonstrates that vision-based policies can be fine-tuned end-to-end from one demonstration using meta-learning, scaling to raw pixel inputs.\n        *   **Data Efficiency**: Requires significantly fewer prior tasks for effective meta-learning and a modest number of demonstrations for meta-training compared to prior one-shot imitation methods.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **Meta-Imitation Learning with MAML**: An extension of MAML to train a policy that can quickly adapt to new imitation tasks from a single visual demonstration.\n        *   **Learning to Imitate without Expert Actions**: A modification that allows one-shot adaptation using only raw observations (video) at test time by meta-learning a loss function, assuming expert actions are available during meta-training.\n    *   **System Design/Architectural Innovations**:\n        *   **Two-Head Architecture**: A modification where the final layers of the network are not shared between the pre- and post-gradient update stages, providing more flexibility in adaptation and enabling the meta-learning of a loss function.\n        *   **Bias Transformation**: A novel architectural component that concatenates a learnable parameter vector to a hidden layer's post-synaptic activations, increasing the representational power and stability of gradient-based meta-learning.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Simulated planar reaching tasks (e.g., reaching a target of a specific color).\n        *   Simulated pushing tasks (e.g., pushing an object to a goal in a new scene).\n        *   Real robot visual placing tasks (e.g., placing an object on a target in a new setting).\n    *   **Key Performance Metrics & Comparison Results**:\n        *   Demonstrated the ability to learn new tasks, end-to-end, from a single visual demonstration.\n        *   Successfully adapted visuomotor policies to new task variants using only one visual demonstration, including scenarios where only a raw video of the demonstration (without expert controls) was available.\n        *   Qualitatively shown to be effective on real robotic systems, indicating practical applicability.\n        *   The paper claims the method requires \"significantly fewer prior tasks\" and a \"relatively modest number of demonstrations for meta-learning\" compared to prior methods, enabling scaling to raw pixel inputs.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Does not address the widely-studied issue of compounding errors in imitation learning.\n        *   For \"learning to imitate without expert actions,\" it assumes access to expert actions during meta-training, even if not at test time.\n        *   The problem of domain shift (e.g., between a human demonstration video and the robot's view) is left for future work.\n    *   **Scope of Applicability**: Primarily focused on vision-based robotic manipulation tasks requiring one-shot skill acquisition from visual demonstrations.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: Significantly advances the state-of-the-art in imitation learning by enabling robots to acquire new, complex skills from just a single visual demonstration, directly from raw pixel inputs.\n    *   **Potential Impact on Future Research**:\n        *   Paves the way for more data-efficient and generalist robots by amortizing experience across tasks.\n        *   Opens avenues for research into meta-learning for robotics, especially for tasks where expert demonstrations are scarce or difficult to obtain.\n        *   The architectural innovations (two-head, bias transformation) provide valuable insights for designing more effective meta-learning models.",
      "intriguing_abstract": "Imagine a robot acquiring a complex new skill from just a single visual demonstration, directly from raw pixel inputs, without extensive prior training. This paper introduces a groundbreaking **meta-imitation learning** approach that extends **Model-Agnostic Meta-Learning (MAML)** to enable unprecedented **one-shot skill acquisition** in robotics. We address the critical challenge of data inefficiency in deep learning for robot generalism by proposing a novel method for **gradient-based policy adaptation**.\n\nUnlike prior methods that require many demonstrations per task or rely on known environment states, our system learns a parameterized **visuomotor policy** capable of fine-tuning end-to-end from a single visual example. This is the first demonstration of vision-based policies adapting from one **raw pixel demonstration**, significantly reducing the data burden and enabling learning even when only raw video is available at test time. Our innovations include a **two-head architecture** and **bias transformation**, enhancing adaptation stability. Validated across simulated and real-world robotic manipulation tasks, this work paves the way for truly **generalist robots** that can rapidly learn diverse skills, transforming human-robot interaction and deployment in unstructured environments.",
      "keywords": [
        "Meta-imitation learning",
        "One-shot learning",
        "Raw sensory inputs (pixels)",
        "Gradient-based adaptation",
        "Model-Agnostic Meta-Learning (MAML)",
        "Robotic skill acquisition",
        "Data efficiency",
        "Visuomotor policies",
        "Two-head architecture",
        "Bias transformation",
        "Generalist robots",
        "Expert-action-free imitation",
        "Unstructured environments"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/482c0cbfffa77154e3c879c497f50b605297d5bc.pdf",
      "citation_key": "finn20174c4",
      "metadata": {
        "title": "One-Shot Visual Imitation Learning via Meta-Learning",
        "authors": [
          "Chelsea Finn",
          "Tianhe Yu",
          "Tianhao Zhang",
          "P. Abbeel",
          "S. Levine"
        ],
        "published_date": "2017",
        "abstract": "In order for a robot to be a generalist that can perform a wide range of jobs, it must be able to acquire a wide variety of skills quickly and efficiently in complex unstructured environments. High-capacity models such as deep neural networks can enable a robot to represent complex skills, but learning each skill from scratch then becomes infeasible. In this work, we present a meta-imitation learning method that enables a robot to learn how to learn more efficiently, allowing it to acquire new skills from just a single demonstration. Unlike prior methods for one-shot imitation, our method can scale to raw pixel inputs and requires data from significantly fewer prior tasks for effective learning of new skills. Our experiments on both simulated and real robot platforms demonstrate the ability to learn new tasks, end-to-end, from a single visual demonstration.",
        "file_path": "paper_data/Deep_Meta-Learning/info/482c0cbfffa77154e3c879c497f50b605297d5bc.pdf",
        "venue": "Conference on Robot Learning",
        "citationCount": 577,
        "score": 72.125,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{finn20174c4}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Enabling robots to quickly and efficiently acquire a wide variety of complex skills from raw sensory inputs (e.g., pixels) in unstructured environments, especially when using high-capacity models like deep neural networks.\n    *   **Importance & Challenge**:\n        *   **Robot Generalism**: Current methods struggle to make robots generalists capable of many tasks with diverse objects.\n        *   **Data Efficiency**: Deep learning models typically require a large amount of supervision or experience *per task*, making it infeasible to learn many skills from scratch.\n        *   **Lack of Experience Reuse**: Most methods do not leverage experience from previous tasks to accelerate learning for new tasks, leading to independent data collection for every new skill.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Combines imitation learning with meta-learning for one-shot learning from visual demonstrations.\n        *   Differs from prior efficient imitation methods that rely on known environment states (e.g., object poses) by focusing on raw sensory inputs.\n        *   Contrasts with multi-task robotic learning methods (e.g., contextual policies that take task identity or a demonstration as input) by learning a policy that can be *adapted* through gradient updates.\n    *   **Limitations of Previous Solutions**:\n        *   **Imitation Learning from Raw Pixels**: Often requires a large number of demonstrations per task, a major roadblock for generalist robots. Also, compounding errors are a known issue (though not addressed by this paper).\n        *   **Inverse Reinforcement Learning**: Can reduce demonstration needs but requires additional robot experience (trial-and-error or model learning).\n        *   **Contextual Policies**: While sharing information across tasks, they typically provide the task as an input to the policy, which can be less flexible or parameter-efficient than gradient-based adaptation.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a meta-imitation learning method that extends Model-Agnostic Meta-Learning (MAML) \\cite{finn20174c4} to the visual imitation learning setting.\n    *   **Novelty/Difference**:\n        *   **Gradient-Based Adaptation**: Instead of providing task identity or a demonstration as a direct input, the method learns a parameterized policy that can be adapted to new tasks via gradient updates on a single demonstration.\n        *   **Scalability to Raw Pixels**: For the first time, it demonstrates that vision-based policies can be fine-tuned end-to-end from one demonstration using meta-learning, scaling to raw pixel inputs.\n        *   **Data Efficiency**: Requires significantly fewer prior tasks for effective meta-learning and a modest number of demonstrations for meta-training compared to prior one-shot imitation methods.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **Meta-Imitation Learning with MAML**: An extension of MAML to train a policy that can quickly adapt to new imitation tasks from a single visual demonstration.\n        *   **Learning to Imitate without Expert Actions**: A modification that allows one-shot adaptation using only raw observations (video) at test time by meta-learning a loss function, assuming expert actions are available during meta-training.\n    *   **System Design/Architectural Innovations**:\n        *   **Two-Head Architecture**: A modification where the final layers of the network are not shared between the pre- and post-gradient update stages, providing more flexibility in adaptation and enabling the meta-learning of a loss function.\n        *   **Bias Transformation**: A novel architectural component that concatenates a learnable parameter vector to a hidden layer's post-synaptic activations, increasing the representational power and stability of gradient-based meta-learning.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Simulated planar reaching tasks (e.g., reaching a target of a specific color).\n        *   Simulated pushing tasks (e.g., pushing an object to a goal in a new scene).\n        *   Real robot visual placing tasks (e.g., placing an object on a target in a new setting).\n    *   **Key Performance Metrics & Comparison Results**:\n        *   Demonstrated the ability to learn new tasks, end-to-end, from a single visual demonstration.\n        *   Successfully adapted visuomotor policies to new task variants using only one visual demonstration, including scenarios where only a raw video of the demonstration (without expert controls) was available.\n        *   Qualitatively shown to be effective on real robotic systems, indicating practical applicability.\n        *   The paper claims the method requires \"significantly fewer prior tasks\" and a \"relatively modest number of demonstrations for meta-learning\" compared to prior methods, enabling scaling to raw pixel inputs.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Does not address the widely-studied issue of compounding errors in imitation learning.\n        *   For \"learning to imitate without expert actions,\" it assumes access to expert actions during meta-training, even if not at test time.\n        *   The problem of domain shift (e.g., between a human demonstration video and the robot's view) is left for future work.\n    *   **Scope of Applicability**: Primarily focused on vision-based robotic manipulation tasks requiring one-shot skill acquisition from visual demonstrations.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: Significantly advances the state-of-the-art in imitation learning by enabling robots to acquire new, complex skills from just a single visual demonstration, directly from raw pixel inputs.\n    *   **Potential Impact on Future Research**:\n        *   Paves the way for more data-efficient and generalist robots by amortizing experience across tasks.\n        *   Opens avenues for research into meta-learning for robotics, especially for tasks where expert demonstrations are scarce or difficult to obtain.\n        *   The architectural innovations (two-head, bias transformation) provide valuable insights for designing more effective meta-learning models.",
        "keywords": [
          "Meta-imitation learning",
          "One-shot learning",
          "Raw sensory inputs (pixels)",
          "Gradient-based adaptation",
          "Model-Agnostic Meta-Learning (MAML)",
          "Robotic skill acquisition",
          "Data efficiency",
          "Visuomotor policies",
          "Two-head architecture",
          "Bias transformation",
          "Generalist robots",
          "Expert-action-free imitation",
          "Unstructured environments"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract states: \"we present a meta-imitation learning method\" and describes its capabilities and improvements over prior methods. it also mentions \"our experiments... demonstrate the ability to learn new tasks\".\n*   the introduction states: \"we propose to combine meta-learning with imitation, enabling a robot to reuse past experience and, as a result, learn new skills from a single demonstration.\" it also differentiates its \"approach learns a parameterized policy\".\n\nthe core contribution described is the **development and presentation of a new method/approach** (meta-imitation learning). while it includes empirical validation (\"our experiments... demonstrate\"), the primary focus in the abstract and introduction is on the proposed solution itself.\n\ntherefore, this paper best fits the **technical** classification."
      },
      "file_name": "482c0cbfffa77154e3c879c497f50b605297d5bc.pdf"
    },
    {
      "success": true,
      "doc_id": "25d4fba8e12f43b5e00a62be7352a669",
      "summary": "This paper, \"A Survey of Deep Meta-Learning\" by Huisman, van Rijn, and Plaat \\cite{huisman2020b7w}, provides a comprehensive overview of the rapidly evolving field of Deep Meta-Learning.\n\n1.  **Research Problem & Motivation**\n    *   **Problem:** Deep neural networks typically require vast amounts of data and computational resources to achieve high performance, limiting their ability to quickly learn new concepts. This contrasts with human intelligence, which can learn rapidly from few examples.\n    *   **Motivation for Meta-Learning:** Meta-learning addresses this by enabling networks to \"learn how to learn,\" improving their learning ability over time by accumulating knowledge across diverse tasks.\n    *   **Motivation for *this survey*:** The Deep Meta-Learning field is advancing quickly but lacks a unified, in-depth overview of current techniques. Existing surveys are either too broad or omit crucial technical details, creating a gap in accessible, comprehensive resources for researchers.\n\n2.  **Related Work & Positioning**\n    *   **Existing Surveys:**\n        *   Vanschoren (2018) provided a broad overview of meta-learning, but with limited focus on Deep Meta-Learning techniques.\n        *   Hospedales et al. (2020) adopted a similar scope to this paper but aimed for a broad overview, consequently omitting technical details of various techniques.\n    *   **Positioning:** This work aims to bridge the identified gap by offering \"detailed explications of contemporary Deep Meta-Learning techniques, using a unified notation\" \\cite{huisman2020b7w}. It focuses on modern, state-of-the-art techniques in supervised and reinforcement learning, detailing their strengths, weaknesses, and interrelationships, while also identifying key challenges and future directions.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Method (of the survey):** The paper's core technical approach is a structured, in-depth literature review and synthesis of Deep Meta-Learning methods. It establishes a theoretical foundation and a unified notation to consistently describe various techniques.\n    *   **Categorization:** It adopts a widely recognized taxonomy, categorizing Deep Meta-Learning approaches into three main types:\n        *   i) Metric-based meta-learning\n        *   ii) Model-based meta-learning\n        *   iii) Optimization-based meta-learning\n    *   **Innovation (of the survey):** The primary innovation of this paper lies in its commitment to providing \"detailed insights into the key techniques\" with \"unified notation\" \\cite{huisman2020b7w}, which distinguishes it from prior, less detailed or broader surveys. It also explicitly identifies and discusses open challenges.\n\n4.  **Key Technical Contributions**\n    *   **Unified and Detailed Overview:** Provides a coherent, in-depth, and technically detailed overview of the rapidly evolving Deep Meta-Learning field, serving as a foundational resource.\n    *   **Taxonomy and Relationships:** Organizes a vast array of techniques into a clear, established taxonomy (metric-, model-, optimization-based) and elucidates their interrelationships, strengths, and weaknesses.\n    *   **Formal Foundation:** Establishes a common theoretical foundation and consistent notation for understanding diverse meta-learning algorithms.\n    *   **Identification of Open Challenges:** Pinpoints critical open challenges in the field, such as the need for performance evaluations on heterogeneous benchmarks and the reduction of computational costs associated with meta-learning.\n    *   **Empirical Observation Analysis:** Highlights a significant empirical observation from existing literature: a strong correlation between network complexity (backbone size) and few-shot classification performance, suggesting that larger networks often perform better even in few-shot settings, which challenges conventional wisdom about overfitting.\n\n5.  **Experimental Validation**\n    *   **Analysis of Existing Results:** The paper analyzes and presents findings from existing experimental literature, particularly illustrated in Figure 1. This figure showcases the accuracy scores of various meta-learning techniques on 1-shot miniImageNet classification.\n    *   **Key Performance Insight:** It empirically observes a \"strong relationship between the network complexity and the classification performance\" \\cite{huisman2020b7w}. Specifically, techniques employing larger feature extraction backbones (e.g., ResNet-12, WRN-28-10) tend to achieve superior few-shot classification performance.\n    *   **Implication for Metrics/Comparisons:** This observation suggests that the size of the network backbone is a crucial factor that should be accounted for when comparing meta-learning algorithms, as it can significantly influence reported performance and challenges the intuitive assumption that smaller models are inherently better for few-shot learning to prevent overfitting.\n\n6.  **Limitations & Scope**\n    *   **Scope of Applicability:** The survey specifically focuses on \"Deep Meta-Learning,\" which is defined as meta-learning procedures designed to learn a good inductive bias for (deep) neural networks.\n    *   **Exclusions:** It explicitly excludes broader meta-learning concepts like traditional algorithm selection and hyperparameter optimization techniques.\n    *   **Identified Open Challenges (Limitations of the field):** The paper highlights that the field still faces challenges such as the lack of standardized performance evaluations on heterogeneous benchmarks and the high computational costs associated with meta-learning. The observation regarding network complexity (Figure 1) also implies a limitation in current comparative studies if network architecture is not rigorously controlled or analyzed.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art (in understanding):** This survey significantly advances the technical state-of-the-art by providing a much-needed, coherent, and technically detailed overview of Deep Meta-Learning, making complex concepts more accessible and facilitating deeper understanding.\n    *   **Educational and Reference Value:** It is designed to serve as both an \"educational introduction\" for newcomers and \"reference material for experienced researchers\" \\cite{huisman2020b7w}.\n    *   **Impact on Future Research:**\n        *   By unifying notation and providing detailed explications, it lays a stronger foundation for future research, enabling more consistent comparisons and building upon existing work.\n        *   The explicit identification of open challenges (e.g., heterogeneous benchmarks, computational costs) directly guides future research efforts towards critical areas.\n        *   The empirical insight regarding network complexity and few-shot performance (Figure 1) provides a crucial consideration for the design and evaluation of future meta-learning algorithms, potentially leading to more robust and fair comparisons.",
      "intriguing_abstract": "Deep neural networks achieve remarkable feats but are notoriously data-hungry, a stark contrast to human intelligence's ability to learn rapidly from few examples. Deep Meta-Learning offers a transformative paradigm, enabling models to \"learn how to learn\" by accumulating knowledge across diverse tasks. Yet, the field's rapid expansion has outpaced the availability of a unified, technically rigorous overview.\n\nThis survey, \"A Survey of Deep Meta-Learning,\" bridges this critical gap. We provide an in-depth, coherent explication of contemporary Deep Meta-Learning techniques, categorized into metric-, model-, and optimization-based approaches, all presented with a consistent, unified notation. Beyond clarifying complex methodologies, we unveil a pivotal empirical observation: few-shot classification performance strongly correlates with network backbone complexity, challenging conventional wisdom and demanding re-evaluation of comparative benchmarks. By identifying key open challenges and offering a foundational resource, this paper serves as an indispensable guide for both newcomers and seasoned researchers, propelling future advancements in efficient, human-like machine learning.",
      "keywords": [
        "Deep Meta-Learning",
        "Few-shot learning",
        "Unified notation",
        "Meta-learning taxonomies",
        "Network complexity correlation",
        "Few-shot classification performance",
        "Open challenges",
        "Computational costs",
        "Heterogeneous benchmarks",
        "Supervised learning",
        "Reinforcement learning",
        "Structured literature review",
        "Inductive bias"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/332c44793b70776b9b966128c52e694222b1ab73.pdf",
      "citation_key": "huisman2020b7w",
      "metadata": {
        "title": "A survey of deep meta-learning",
        "authors": [
          "M. Huisman",
          "Jan N. van Rijn",
          "A. Plaat"
        ],
        "published_date": "2020",
        "abstract": "Deep neural networks can achieve great successes when presented with large data sets and sufficient computational resources. However, their ability to learn new concepts quickly is limited. Meta-learning is one approach to address this issue, by enabling the network to learn how to learn. The field of Deep Meta-Learning advances at great speed, but lacks a unified, in-depth overview of current techniques. With this work, we aim to bridge this gap. After providing the reader with a theoretical foundation, we investigate and summarize key methods, which are categorized into (i) metric-, (ii) model-, and (iii) optimization-based techniques. In addition, we identify the main open challenges, such as performance evaluations on heterogeneous benchmarks, and reduction of the computational costs of meta-learning.",
        "file_path": "paper_data/Deep_Meta-Learning/info/332c44793b70776b9b966128c52e694222b1ab73.pdf",
        "venue": "Artificial Intelligence Review",
        "citationCount": 356,
        "score": 71.2,
        "summary": "This paper, \"A Survey of Deep Meta-Learning\" by Huisman, van Rijn, and Plaat \\cite{huisman2020b7w}, provides a comprehensive overview of the rapidly evolving field of Deep Meta-Learning.\n\n1.  **Research Problem & Motivation**\n    *   **Problem:** Deep neural networks typically require vast amounts of data and computational resources to achieve high performance, limiting their ability to quickly learn new concepts. This contrasts with human intelligence, which can learn rapidly from few examples.\n    *   **Motivation for Meta-Learning:** Meta-learning addresses this by enabling networks to \"learn how to learn,\" improving their learning ability over time by accumulating knowledge across diverse tasks.\n    *   **Motivation for *this survey*:** The Deep Meta-Learning field is advancing quickly but lacks a unified, in-depth overview of current techniques. Existing surveys are either too broad or omit crucial technical details, creating a gap in accessible, comprehensive resources for researchers.\n\n2.  **Related Work & Positioning**\n    *   **Existing Surveys:**\n        *   Vanschoren (2018) provided a broad overview of meta-learning, but with limited focus on Deep Meta-Learning techniques.\n        *   Hospedales et al. (2020) adopted a similar scope to this paper but aimed for a broad overview, consequently omitting technical details of various techniques.\n    *   **Positioning:** This work aims to bridge the identified gap by offering \"detailed explications of contemporary Deep Meta-Learning techniques, using a unified notation\" \\cite{huisman2020b7w}. It focuses on modern, state-of-the-art techniques in supervised and reinforcement learning, detailing their strengths, weaknesses, and interrelationships, while also identifying key challenges and future directions.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Method (of the survey):** The paper's core technical approach is a structured, in-depth literature review and synthesis of Deep Meta-Learning methods. It establishes a theoretical foundation and a unified notation to consistently describe various techniques.\n    *   **Categorization:** It adopts a widely recognized taxonomy, categorizing Deep Meta-Learning approaches into three main types:\n        *   i) Metric-based meta-learning\n        *   ii) Model-based meta-learning\n        *   iii) Optimization-based meta-learning\n    *   **Innovation (of the survey):** The primary innovation of this paper lies in its commitment to providing \"detailed insights into the key techniques\" with \"unified notation\" \\cite{huisman2020b7w}, which distinguishes it from prior, less detailed or broader surveys. It also explicitly identifies and discusses open challenges.\n\n4.  **Key Technical Contributions**\n    *   **Unified and Detailed Overview:** Provides a coherent, in-depth, and technically detailed overview of the rapidly evolving Deep Meta-Learning field, serving as a foundational resource.\n    *   **Taxonomy and Relationships:** Organizes a vast array of techniques into a clear, established taxonomy (metric-, model-, optimization-based) and elucidates their interrelationships, strengths, and weaknesses.\n    *   **Formal Foundation:** Establishes a common theoretical foundation and consistent notation for understanding diverse meta-learning algorithms.\n    *   **Identification of Open Challenges:** Pinpoints critical open challenges in the field, such as the need for performance evaluations on heterogeneous benchmarks and the reduction of computational costs associated with meta-learning.\n    *   **Empirical Observation Analysis:** Highlights a significant empirical observation from existing literature: a strong correlation between network complexity (backbone size) and few-shot classification performance, suggesting that larger networks often perform better even in few-shot settings, which challenges conventional wisdom about overfitting.\n\n5.  **Experimental Validation**\n    *   **Analysis of Existing Results:** The paper analyzes and presents findings from existing experimental literature, particularly illustrated in Figure 1. This figure showcases the accuracy scores of various meta-learning techniques on 1-shot miniImageNet classification.\n    *   **Key Performance Insight:** It empirically observes a \"strong relationship between the network complexity and the classification performance\" \\cite{huisman2020b7w}. Specifically, techniques employing larger feature extraction backbones (e.g., ResNet-12, WRN-28-10) tend to achieve superior few-shot classification performance.\n    *   **Implication for Metrics/Comparisons:** This observation suggests that the size of the network backbone is a crucial factor that should be accounted for when comparing meta-learning algorithms, as it can significantly influence reported performance and challenges the intuitive assumption that smaller models are inherently better for few-shot learning to prevent overfitting.\n\n6.  **Limitations & Scope**\n    *   **Scope of Applicability:** The survey specifically focuses on \"Deep Meta-Learning,\" which is defined as meta-learning procedures designed to learn a good inductive bias for (deep) neural networks.\n    *   **Exclusions:** It explicitly excludes broader meta-learning concepts like traditional algorithm selection and hyperparameter optimization techniques.\n    *   **Identified Open Challenges (Limitations of the field):** The paper highlights that the field still faces challenges such as the lack of standardized performance evaluations on heterogeneous benchmarks and the high computational costs associated with meta-learning. The observation regarding network complexity (Figure 1) also implies a limitation in current comparative studies if network architecture is not rigorously controlled or analyzed.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art (in understanding):** This survey significantly advances the technical state-of-the-art by providing a much-needed, coherent, and technically detailed overview of Deep Meta-Learning, making complex concepts more accessible and facilitating deeper understanding.\n    *   **Educational and Reference Value:** It is designed to serve as both an \"educational introduction\" for newcomers and \"reference material for experienced researchers\" \\cite{huisman2020b7w}.\n    *   **Impact on Future Research:**\n        *   By unifying notation and providing detailed explications, it lays a stronger foundation for future research, enabling more consistent comparisons and building upon existing work.\n        *   The explicit identification of open challenges (e.g., heterogeneous benchmarks, computational costs) directly guides future research efforts towards critical areas.\n        *   The empirical insight regarding network complexity and few-shot performance (Figure 1) provides a crucial consideration for the design and evaluation of future meta-learning algorithms, potentially leading to more robust and fair comparisons.",
        "keywords": [
          "Deep Meta-Learning",
          "Few-shot learning",
          "Unified notation",
          "Meta-learning taxonomies",
          "Network complexity correlation",
          "Few-shot classification performance",
          "Open challenges",
          "Computational costs",
          "Heterogeneous benchmarks",
          "Supervised learning",
          "Reinforcement learning",
          "Structured literature review",
          "Inductive bias"
        ],
        "paper_type": "based on the provided abstract, introduction, title, and venue, this paper clearly fits the **survey** type.\n\nhere's why:\n\n*   **title:** \"a survey of deep meta-learning\" explicitly uses the word \"survey.\"\n*   **venue:** \"artificial intelligence review\" suggests a journal that publishes review articles.\n*   **abstract:**\n    *   states the field \"lacks a uniﬁed, in-depth overview of current techniques.\"\n    *   aims to \"bridge this gap.\"\n    *   describes the methodology: \"investigate and summarize key methods, which are categorized into i) metric-, ii) model-, and iii) optimization-based techniques.\"\n    *   mentions identifying \"main open challenges,\" which is common in survey papers.\n*   **introduction:**\n    *   reinforces the idea of reviewing existing work by presenting \"fig. 1 the accuracy scores of the covered techniques on 1-shot miniimagenet classiﬁcation,\" indicating a comparison and summary of *other* methods, not new ones proposed by the authors.\n\nthese points directly align with the criteria for a **survey** paper: \"reviews existing literature comprehensively,\" \"abstract mentions: 'survey', 'review', 'comprehensive analysis', 'state-of-the-art',\" and \"introduction discusses: literature organization, classification schemes.\""
      },
      "file_name": "332c44793b70776b9b966128c52e694222b1ab73.pdf"
    },
    {
      "success": true,
      "doc_id": "ec3a53dfb6961490a7e08424ccb81bf9",
      "summary": "Executing safe and precise flight maneuvers in dynamic high-speed winds is important for the ongoing commoditization of uninhabited aerial vehicles (UAVs). However, because the relationship between various wind conditions and its effect on aircraft maneuverability is not well understood, it is challenging to design effective robot controllers using traditional control design methods. We present Neural-Fly, a learning-based approach that allows rapid online adaptation by incorporating pretrained representations through deep learning. Neural-Fly builds on two key observations that aerodynamics in different wind conditions share a common representation and that the wind-specific part lies in a low-dimensional space. To that end, Neural-Fly uses a proposed learning algorithm, domain adversarially invariant meta-learning (DAIML), to learn the shared representation, only using 12 minutes of flight data. With the learned representation as a basis, Neural-Fly then uses a composite adaptation law to update a set of linear coefficients for mixing the basis elements. When evaluated under challenging wind conditions generated with the Caltech Real Weather Wind Tunnel, with wind speeds up to 43.6 kilometers/hour (12.1 meters/second), Neural-Fly achieves precise flight control with substantially smaller tracking error than stateof-the-art nonlinear and adaptive controllers. In addition to strong empirical performance, the exponential stability of Neural-Fly results in robustness guarantees. Last, our control design extrapolates to unseen wind conditions, is shown to be effective for outdoor flights with only onboard sensors, and can transfer across drones with minimal performance degradation. Description A drone adapts to dynamic wind conditions using deep neural networks in real time with stability guarantees.",
      "intriguing_abstract": "Executing safe and precise flight maneuvers in dynamic high-speed winds is important for the ongoing commoditization of uninhabited aerial vehicles (UAVs). However, because the relationship between various wind conditions and its effect on aircraft maneuverability is not well understood, it is challenging to design effective robot controllers using traditional control design methods. We present Neural-Fly, a learning-based approach that allows rapid online adaptation by incorporating pretrained representations through deep learning. Neural-Fly builds on two key observations that aerodynamics in different wind conditions share a common representation and that the wind-specific part lies in a low-dimensional space. To that end, Neural-Fly uses a proposed learning algorithm, domain adversarially invariant meta-learning (DAIML), to learn the shared representation, only using 12 minutes of flight data. With the learned representation as a basis, Neural-Fly then uses a composite adaptation law to update a set of linear coefficients for mixing the basis elements. When evaluated under challenging wind conditions generated with the Caltech Real Weather Wind Tunnel, with wind speeds up to 43.6 kilometers/hour (12.1 meters/second), Neural-Fly achieves precise flight control with substantially smaller tracking error than stateof-the-art nonlinear and adaptive controllers. In addition to strong empirical performance, the exponential stability of Neural-Fly results in robustness guarantees. Last, our control design extrapolates to unseen wind conditions, is shown to be effective for outdoor flights with only onboard sensors, and can transfer across drones with minimal performance degradation. Description A drone adapts to dynamic wind conditions using deep neural networks in real time with stability guarantees.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/91e6d31e3bb634007dbc3abc3d84da01412fea17.pdf",
      "citation_key": "oconnell2022twd",
      "metadata": {
        "title": "Neural-Fly enables rapid learning for agile flight in strong winds",
        "authors": [
          "M. O'Connell",
          "Guanya Shi",
          "Xichen Shi",
          "K. Azizzadenesheli",
          "Anima Anandkumar",
          "Yisong Yue",
          "Soon-Jo Chung"
        ],
        "published_date": "2022",
        "abstract": "Executing safe and precise flight maneuvers in dynamic high-speed winds is important for the ongoing commoditization of uninhabited aerial vehicles (UAVs). However, because the relationship between various wind conditions and its effect on aircraft maneuverability is not well understood, it is challenging to design effective robot controllers using traditional control design methods. We present Neural-Fly, a learning-based approach that allows rapid online adaptation by incorporating pretrained representations through deep learning. Neural-Fly builds on two key observations that aerodynamics in different wind conditions share a common representation and that the wind-specific part lies in a low-dimensional space. To that end, Neural-Fly uses a proposed learning algorithm, domain adversarially invariant meta-learning (DAIML), to learn the shared representation, only using 12 minutes of flight data. With the learned representation as a basis, Neural-Fly then uses a composite adaptation law to update a set of linear coefficients for mixing the basis elements. When evaluated under challenging wind conditions generated with the Caltech Real Weather Wind Tunnel, with wind speeds up to 43.6 kilometers/hour (12.1 meters/second), Neural-Fly achieves precise flight control with substantially smaller tracking error than stateof-the-art nonlinear and adaptive controllers. In addition to strong empirical performance, the exponential stability of Neural-Fly results in robustness guarantees. Last, our control design extrapolates to unseen wind conditions, is shown to be effective for outdoor flights with only onboard sensors, and can transfer across drones with minimal performance degradation. Description A drone adapts to dynamic wind conditions using deep neural networks in real time with stability guarantees.",
        "file_path": "paper_data/Deep_Meta-Learning/info/91e6d31e3bb634007dbc3abc3d84da01412fea17.pdf",
        "venue": "Science Robotics",
        "citationCount": 212,
        "score": 70.66666666666666,
        "summary": "Executing safe and precise flight maneuvers in dynamic high-speed winds is important for the ongoing commoditization of uninhabited aerial vehicles (UAVs). However, because the relationship between various wind conditions and its effect on aircraft maneuverability is not well understood, it is challenging to design effective robot controllers using traditional control design methods. We present Neural-Fly, a learning-based approach that allows rapid online adaptation by incorporating pretrained representations through deep learning. Neural-Fly builds on two key observations that aerodynamics in different wind conditions share a common representation and that the wind-specific part lies in a low-dimensional space. To that end, Neural-Fly uses a proposed learning algorithm, domain adversarially invariant meta-learning (DAIML), to learn the shared representation, only using 12 minutes of flight data. With the learned representation as a basis, Neural-Fly then uses a composite adaptation law to update a set of linear coefficients for mixing the basis elements. When evaluated under challenging wind conditions generated with the Caltech Real Weather Wind Tunnel, with wind speeds up to 43.6 kilometers/hour (12.1 meters/second), Neural-Fly achieves precise flight control with substantially smaller tracking error than stateof-the-art nonlinear and adaptive controllers. In addition to strong empirical performance, the exponential stability of Neural-Fly results in robustness guarantees. Last, our control design extrapolates to unseen wind conditions, is shown to be effective for outdoor flights with only onboard sensors, and can transfer across drones with minimal performance degradation. Description A drone adapts to dynamic wind conditions using deep neural networks in real time with stability guarantees.",
        "keywords": []
      },
      "file_name": "91e6d31e3bb634007dbc3abc3d84da01412fea17.pdf"
    },
    {
      "success": true,
      "doc_id": "03398d1fc8934260a466b4e2ddd9386e",
      "summary": "Recently, increasing interest has been drawn in exploiting deep convolutional neural networks (DCNNs) for no-reference image quality assessment (NR-IQA). Despite of the notable success achieved, there is a broad consensus that training DCNNs heavily relies on massive annotated data. Unfortunately, IQA is a typical small sample problem. Therefore, most of the existing DCNN-based IQA metrics operate based on pre-trained networks. However, these pre-trained networks are not designed for IQA task, leading to generalization problem when evaluating different types of distortions. With this motivation, this paper presents a no-reference IQA metric based on deep meta-learning. The underlying idea is to learn the meta-knowledge shared by human when evaluating the quality of images with various distortions, which can then be adapted to unknown distortions easily. Specifically, we first collect a number of NR-IQA tasks for different distortions. Then meta-learning is adopted to learn the prior knowledge shared by diversified distortions. Finally, the quality prior model is fine-tuned on a target NR-IQA task for quickly obtaining the quality model. Extensive experiments demonstrate that the proposed metric outperforms the state-of-the-arts by a large margin. Furthermore, the meta-model learned from synthetic distortions can also be easily generalized to authentic distortions, which is highly desired in real-world applications of IQA metrics.",
      "intriguing_abstract": "Recently, increasing interest has been drawn in exploiting deep convolutional neural networks (DCNNs) for no-reference image quality assessment (NR-IQA). Despite of the notable success achieved, there is a broad consensus that training DCNNs heavily relies on massive annotated data. Unfortunately, IQA is a typical small sample problem. Therefore, most of the existing DCNN-based IQA metrics operate based on pre-trained networks. However, these pre-trained networks are not designed for IQA task, leading to generalization problem when evaluating different types of distortions. With this motivation, this paper presents a no-reference IQA metric based on deep meta-learning. The underlying idea is to learn the meta-knowledge shared by human when evaluating the quality of images with various distortions, which can then be adapted to unknown distortions easily. Specifically, we first collect a number of NR-IQA tasks for different distortions. Then meta-learning is adopted to learn the prior knowledge shared by diversified distortions. Finally, the quality prior model is fine-tuned on a target NR-IQA task for quickly obtaining the quality model. Extensive experiments demonstrate that the proposed metric outperforms the state-of-the-arts by a large margin. Furthermore, the meta-model learned from synthetic distortions can also be easily generalized to authentic distortions, which is highly desired in real-world applications of IQA metrics.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/557e9371711c7409c78c96a6a2bea290a28cb365.pdf",
      "citation_key": "zhu2020rb5",
      "metadata": {
        "title": "MetaIQA: Deep Meta-Learning for No-Reference Image Quality Assessment",
        "authors": [
          "Hancheng Zhu",
          "Leida Li",
          "Jinjian Wu",
          "W. Dong",
          "Guangming Shi"
        ],
        "published_date": "2020",
        "abstract": "Recently, increasing interest has been drawn in exploiting deep convolutional neural networks (DCNNs) for no-reference image quality assessment (NR-IQA). Despite of the notable success achieved, there is a broad consensus that training DCNNs heavily relies on massive annotated data. Unfortunately, IQA is a typical small sample problem. Therefore, most of the existing DCNN-based IQA metrics operate based on pre-trained networks. However, these pre-trained networks are not designed for IQA task, leading to generalization problem when evaluating different types of distortions. With this motivation, this paper presents a no-reference IQA metric based on deep meta-learning. The underlying idea is to learn the meta-knowledge shared by human when evaluating the quality of images with various distortions, which can then be adapted to unknown distortions easily. Specifically, we first collect a number of NR-IQA tasks for different distortions. Then meta-learning is adopted to learn the prior knowledge shared by diversified distortions. Finally, the quality prior model is fine-tuned on a target NR-IQA task for quickly obtaining the quality model. Extensive experiments demonstrate that the proposed metric outperforms the state-of-the-arts by a large margin. Furthermore, the meta-model learned from synthetic distortions can also be easily generalized to authentic distortions, which is highly desired in real-world applications of IQA metrics.",
        "file_path": "paper_data/Deep_Meta-Learning/info/557e9371711c7409c78c96a6a2bea290a28cb365.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 304,
        "score": 60.800000000000004,
        "summary": "Recently, increasing interest has been drawn in exploiting deep convolutional neural networks (DCNNs) for no-reference image quality assessment (NR-IQA). Despite of the notable success achieved, there is a broad consensus that training DCNNs heavily relies on massive annotated data. Unfortunately, IQA is a typical small sample problem. Therefore, most of the existing DCNN-based IQA metrics operate based on pre-trained networks. However, these pre-trained networks are not designed for IQA task, leading to generalization problem when evaluating different types of distortions. With this motivation, this paper presents a no-reference IQA metric based on deep meta-learning. The underlying idea is to learn the meta-knowledge shared by human when evaluating the quality of images with various distortions, which can then be adapted to unknown distortions easily. Specifically, we first collect a number of NR-IQA tasks for different distortions. Then meta-learning is adopted to learn the prior knowledge shared by diversified distortions. Finally, the quality prior model is fine-tuned on a target NR-IQA task for quickly obtaining the quality model. Extensive experiments demonstrate that the proposed metric outperforms the state-of-the-arts by a large margin. Furthermore, the meta-model learned from synthetic distortions can also be easily generalized to authentic distortions, which is highly desired in real-world applications of IQA metrics.",
        "keywords": []
      },
      "file_name": "557e9371711c7409c78c96a6a2bea290a28cb365.pdf"
    },
    {
      "success": true,
      "doc_id": "33a7c3469e06c239168b20d0c528abc6",
      "summary": "We present Darts, a Python machine learning library for time series, with a focus on forecasting. Darts offers a variety of models, from classics such as ARIMA to state-of-the-art deep neural networks. The emphasis of the library is on offering modern machine learning functionalities, such as supporting multidimensional series, meta-learning on multiple series, training on large datasets, incorporating external data, ensembling models, and providing a rich support for probabilistic forecasting. At the same time, great care goes into the API design to make it user-friendly and easy to use. For instance, all models can be used using fit()/predict(), similar to scikit-learn.",
      "intriguing_abstract": "We present Darts, a Python machine learning library for time series, with a focus on forecasting. Darts offers a variety of models, from classics such as ARIMA to state-of-the-art deep neural networks. The emphasis of the library is on offering modern machine learning functionalities, such as supporting multidimensional series, meta-learning on multiple series, training on large datasets, incorporating external data, ensembling models, and providing a rich support for probabilistic forecasting. At the same time, great care goes into the API design to make it user-friendly and easy to use. For instance, all models can be used using fit()/predict(), similar to scikit-learn.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/22733aac53e89446aed76dd1983bf2d74567ba88.pdf",
      "citation_key": "herzen2021300",
      "metadata": {
        "title": "Darts: User-Friendly Modern Machine Learning for Time Series",
        "authors": [
          "J. Herzen",
          "Francesco Lässig",
          "Samuele Giuliano Piazzetta",
          "T. Neuer",
          "L'eo Tafti",
          "Guillaume Raille",
          "Tomas Van Pottelbergh",
          "Marek Pasieka",
          "Andrzej Skrodzki",
          "Nicolas Huguenin",
          "Maxime Dumonal",
          "Jan Ko'scisz",
          "Dennis Bader",
          "Frédérick Gusset",
          "Mounir Benheddi",
          "Camila Williamson",
          "Michal Kosinski",
          "M. Petrik",
          "Gaël Grosch"
        ],
        "published_date": "2021",
        "abstract": "We present Darts, a Python machine learning library for time series, with a focus on forecasting. Darts offers a variety of models, from classics such as ARIMA to state-of-the-art deep neural networks. The emphasis of the library is on offering modern machine learning functionalities, such as supporting multidimensional series, meta-learning on multiple series, training on large datasets, incorporating external data, ensembling models, and providing a rich support for probabilistic forecasting. At the same time, great care goes into the API design to make it user-friendly and easy to use. For instance, all models can be used using fit()/predict(), similar to scikit-learn.",
        "file_path": "paper_data/Deep_Meta-Learning/info/22733aac53e89446aed76dd1983bf2d74567ba88.pdf",
        "venue": "Journal of machine learning research",
        "citationCount": 243,
        "score": 60.75,
        "summary": "We present Darts, a Python machine learning library for time series, with a focus on forecasting. Darts offers a variety of models, from classics such as ARIMA to state-of-the-art deep neural networks. The emphasis of the library is on offering modern machine learning functionalities, such as supporting multidimensional series, meta-learning on multiple series, training on large datasets, incorporating external data, ensembling models, and providing a rich support for probabilistic forecasting. At the same time, great care goes into the API design to make it user-friendly and easy to use. For instance, all models can be used using fit()/predict(), similar to scikit-learn.",
        "keywords": []
      },
      "file_name": "22733aac53e89446aed76dd1983bf2d74567ba88.pdf"
    },
    {
      "success": true,
      "doc_id": "4a18d53b201eb00200b6dce79199bbc3",
      "summary": "Multi-access edge computing (MEC) aims to extend cloud service to the network edge to reduce network traffic and service latency. A fundamental problem in MEC is how to efficiently offload heterogeneous tasks of mobile applications from user equipment (UE) to MEC hosts. Recently, many deep reinforcement learning (DRL)-based methods have been proposed to learn offloading policies through interacting with the MEC environment that consists of UE, wireless channels, and MEC hosts. However, these methods have weak adaptability to new environments because they have low sample efficiency and need full retraining to learn updated policies for new environments. To overcome this weakness, we propose a task offloading method based on meta reinforcement learning, which can adapt fast to new environments with a small number of gradient updates and samples. We model mobile applications as Directed Acyclic Graphs (DAGs) and the offloading policy by a custom sequence-to-sequence (seq2seq) neural network. To efficiently train the seq2seq network, we propose a method that synergizes the first order approximation and clipped surrogate objective. The experimental results demonstrate that this new offloading method can reduce the latency by up to 25 percent compared to three baselines while being able to adapt fast to new environments.",
      "intriguing_abstract": "Multi-access edge computing (MEC) aims to extend cloud service to the network edge to reduce network traffic and service latency. A fundamental problem in MEC is how to efficiently offload heterogeneous tasks of mobile applications from user equipment (UE) to MEC hosts. Recently, many deep reinforcement learning (DRL)-based methods have been proposed to learn offloading policies through interacting with the MEC environment that consists of UE, wireless channels, and MEC hosts. However, these methods have weak adaptability to new environments because they have low sample efficiency and need full retraining to learn updated policies for new environments. To overcome this weakness, we propose a task offloading method based on meta reinforcement learning, which can adapt fast to new environments with a small number of gradient updates and samples. We model mobile applications as Directed Acyclic Graphs (DAGs) and the offloading policy by a custom sequence-to-sequence (seq2seq) neural network. To efficiently train the seq2seq network, we propose a method that synergizes the first order approximation and clipped surrogate objective. The experimental results demonstrate that this new offloading method can reduce the latency by up to 25 percent compared to three baselines while being able to adapt fast to new environments.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c40a927a558ad5a5ffe254605ed3bfebd18be39c.pdf",
      "citation_key": "wang2020tae",
      "metadata": {
        "title": "Fast Adaptive Task Offloading in Edge Computing Based on Meta Reinforcement Learning",
        "authors": [
          "Jin Wang",
          "Jia Hu",
          "G. Min",
          "Albert Y. Zomaya",
          "N. Georgalas"
        ],
        "published_date": "2020",
        "abstract": "Multi-access edge computing (MEC) aims to extend cloud service to the network edge to reduce network traffic and service latency. A fundamental problem in MEC is how to efficiently offload heterogeneous tasks of mobile applications from user equipment (UE) to MEC hosts. Recently, many deep reinforcement learning (DRL)-based methods have been proposed to learn offloading policies through interacting with the MEC environment that consists of UE, wireless channels, and MEC hosts. However, these methods have weak adaptability to new environments because they have low sample efficiency and need full retraining to learn updated policies for new environments. To overcome this weakness, we propose a task offloading method based on meta reinforcement learning, which can adapt fast to new environments with a small number of gradient updates and samples. We model mobile applications as Directed Acyclic Graphs (DAGs) and the offloading policy by a custom sequence-to-sequence (seq2seq) neural network. To efficiently train the seq2seq network, we propose a method that synergizes the first order approximation and clipped surrogate objective. The experimental results demonstrate that this new offloading method can reduce the latency by up to 25 percent compared to three baselines while being able to adapt fast to new environments.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c40a927a558ad5a5ffe254605ed3bfebd18be39c.pdf",
        "venue": "IEEE Transactions on Parallel and Distributed Systems",
        "citationCount": 288,
        "score": 57.6,
        "summary": "Multi-access edge computing (MEC) aims to extend cloud service to the network edge to reduce network traffic and service latency. A fundamental problem in MEC is how to efficiently offload heterogeneous tasks of mobile applications from user equipment (UE) to MEC hosts. Recently, many deep reinforcement learning (DRL)-based methods have been proposed to learn offloading policies through interacting with the MEC environment that consists of UE, wireless channels, and MEC hosts. However, these methods have weak adaptability to new environments because they have low sample efficiency and need full retraining to learn updated policies for new environments. To overcome this weakness, we propose a task offloading method based on meta reinforcement learning, which can adapt fast to new environments with a small number of gradient updates and samples. We model mobile applications as Directed Acyclic Graphs (DAGs) and the offloading policy by a custom sequence-to-sequence (seq2seq) neural network. To efficiently train the seq2seq network, we propose a method that synergizes the first order approximation and clipped surrogate objective. The experimental results demonstrate that this new offloading method can reduce the latency by up to 25 percent compared to three baselines while being able to adapt fast to new environments.",
        "keywords": []
      },
      "file_name": "c40a927a558ad5a5ffe254605ed3bfebd18be39c.pdf"
    },
    {
      "success": true,
      "doc_id": "520ff87f6403748a40aab29afd3cd0df",
      "summary": "Humans and animals are capable of learning a new behavior by observing others perform the skill just once. We consider the problem of allowing a robot to do the same -- learning from a raw video pixels of a human, even when there is substantial domain shift in the perspective, environment, and embodiment between the robot and the observed human. Prior approaches to this problem have hand-specified how human and robot actions correspond and often relied on explicit human pose detection systems. In this work, we present an approach for one-shot learning from a video of a human by using human and robot demonstration data from a variety of previous tasks to build up prior knowledge through meta-learning. Then, combining this prior knowledge and only a single video demonstration from a human, the robot can perform the task that the human demonstrated. We show experiments on both a PR2 arm and a Sawyer arm, demonstrating that after meta-learning, the robot can learn to place, push, and pick-and-place new objects using just one video of a human performing the manipulation.",
      "intriguing_abstract": "Humans and animals are capable of learning a new behavior by observing others perform the skill just once. We consider the problem of allowing a robot to do the same -- learning from a raw video pixels of a human, even when there is substantial domain shift in the perspective, environment, and embodiment between the robot and the observed human. Prior approaches to this problem have hand-specified how human and robot actions correspond and often relied on explicit human pose detection systems. In this work, we present an approach for one-shot learning from a video of a human by using human and robot demonstration data from a variety of previous tasks to build up prior knowledge through meta-learning. Then, combining this prior knowledge and only a single video demonstration from a human, the robot can perform the task that the human demonstrated. We show experiments on both a PR2 arm and a Sawyer arm, demonstrating that after meta-learning, the robot can learn to place, push, and pick-and-place new objects using just one video of a human performing the manipulation.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/f4eff7c0127a2ef92c441f028c3bb15b64cabcc8.pdf",
      "citation_key": "yu2018nm7",
      "metadata": {
        "title": "One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning",
        "authors": [
          "Tianhe Yu",
          "Chelsea Finn",
          "Annie Xie",
          "Sudeep Dasari",
          "Tianhao Zhang",
          "P. Abbeel",
          "S. Levine"
        ],
        "published_date": "2018",
        "abstract": "Humans and animals are capable of learning a new behavior by observing others perform the skill just once. We consider the problem of allowing a robot to do the same -- learning from a raw video pixels of a human, even when there is substantial domain shift in the perspective, environment, and embodiment between the robot and the observed human. Prior approaches to this problem have hand-specified how human and robot actions correspond and often relied on explicit human pose detection systems. In this work, we present an approach for one-shot learning from a video of a human by using human and robot demonstration data from a variety of previous tasks to build up prior knowledge through meta-learning. Then, combining this prior knowledge and only a single video demonstration from a human, the robot can perform the task that the human demonstrated. We show experiments on both a PR2 arm and a Sawyer arm, demonstrating that after meta-learning, the robot can learn to place, push, and pick-and-place new objects using just one video of a human performing the manipulation.",
        "file_path": "paper_data/Deep_Meta-Learning/info/f4eff7c0127a2ef92c441f028c3bb15b64cabcc8.pdf",
        "venue": "Robotics: Science and Systems",
        "citationCount": 367,
        "score": 52.42857142857142,
        "summary": "Humans and animals are capable of learning a new behavior by observing others perform the skill just once. We consider the problem of allowing a robot to do the same -- learning from a raw video pixels of a human, even when there is substantial domain shift in the perspective, environment, and embodiment between the robot and the observed human. Prior approaches to this problem have hand-specified how human and robot actions correspond and often relied on explicit human pose detection systems. In this work, we present an approach for one-shot learning from a video of a human by using human and robot demonstration data from a variety of previous tasks to build up prior knowledge through meta-learning. Then, combining this prior knowledge and only a single video demonstration from a human, the robot can perform the task that the human demonstrated. We show experiments on both a PR2 arm and a Sawyer arm, demonstrating that after meta-learning, the robot can learn to place, push, and pick-and-place new objects using just one video of a human performing the manipulation.",
        "keywords": []
      },
      "file_name": "f4eff7c0127a2ef92c441f028c3bb15b64cabcc8.pdf"
    },
    {
      "success": true,
      "doc_id": "1abfd20dc9532d796e1c472820230fb7",
      "summary": "Here's a focused summary of the paper \"VARIBAD: A VERY GOOD METHOD FOR BAYES-ADAPTIVE DEEP RL VIA META-LEARNING\" \\cite{zintgraf2019zat} for a literature review:\n\n### 1. Research Problem & Motivation\n\n*   **Specific Technical Problem**: The paper addresses the challenge of optimally trading off exploration and exploitation in unknown environments within Reinforcement Learning (RL) \\cite{zintgraf2019zat}. Specifically, it aims to compute or approximate Bayes-optimal policies, which condition actions on the agent's uncertainty about the environment, to maximize expected online return.\n*   **Importance and Challenge**:\n    *   **Intractability of Bayes-Optimal Policies**: Computing a truly Bayes-optimal policy, which involves planning in a Bayes-Adaptive Markov Decision Process (BAMDP) where the state space is augmented with a belief distribution over environments, is intractable for all but the smallest tasks \\cite{zintgraf2019zat}.\n    *   **Inefficiency of Shortcuts**: Common shortcuts like posterior sampling are more tractable but can lead to highly inefficient exploration, as they do not optimally reduce uncertainty \\cite{zintgraf2019zat}.\n    *   **Intractable Inference**: Even maintaining the posterior belief required for methods like posterior sampling can be intractable \\cite{zintgraf2019zat}.\n    *   **Online Performance**: Maximizing expected return *during learning* (online return) is crucial in many real-world applications \\cite{zintgraf2019zat}.\n\n### 2. Related Work & Positioning\n\n*   **Bayes-Adaptive MDPs (BAMDPs)**: The work builds on the theoretical framework of BAMDPs, which formally define Bayes-optimal policies by augmenting the state space with a belief distribution over MDPs \\cite{zintgraf2019zat}.\n    *   **Limitations**: BAMDPs are generally intractable for complex problems due to the high-dimensional belief space and the difficulty of updating beliefs \\cite{zintgraf2019zat}.\n*   **Posterior Sampling**: This is a common heuristic that samples a single MDP from the posterior and acts optimally within it for an episode \\cite{zintgraf2019zat}.\n    *   **Limitations**: While more tractable than full BAMDPs, posterior sampling's exploration can be highly inefficient and far from Bayes-optimal, as it doesn't strategically seek information (illustrated in Figure 1) \\cite{zintgraf2019zat}.\n*   **Meta-Reinforcement Learning (Meta-RL)**: The paper positions itself within meta-RL, where an agent learns to adapt to new, related tasks from a distribution \\cite{zintgraf2019zat}.\n    *   **Limitations of Previous Meta-RL**: Existing meta-RL methods often do not explicitly reason about task uncertainty in a Bayes-optimal way, or they rely on privileged task information during training, limiting their applicability and exploration efficiency \\cite{zintgraf2019zat}.\n*   **VariBAD's Positioning**: VariBAD aims to overcome the intractability of Bayes-optimal policies and the inefficiency of posterior sampling by meta-learning an *approximate* Bayes-adaptive policy that performs efficient, structured online exploration, without requiring privileged task information \\cite{zintgraf2019zat}.\n\n### 3. Technical Approach & Innovation\n\n*   **Core Method**: Variational Bayes-Adaptive Deep RL (variBAD) meta-learns to perform approximate inference in an unknown environment and incorporates task uncertainty directly into action selection \\cite{zintgraf2019zat}.\n*   **Latent Variable Representation**: Each MDP `M` is represented by a learned, low-dimensional stochastic latent variable `m`. The reward and transition functions are then conditioned on this `m` and shared across tasks \\cite{zintgraf2019zat}.\n*   **Joint Meta-Training**: VariBAD jointly meta-trains two main components:\n    1.  **Variational Auto-Encoder (VAE)**: An amortized inference network `q_phi(m | tau_t)` (encoder) infers the posterior distribution over `m` given the agent's experience `tau_t` (trajectory of states, actions, rewards) up to time `t`. A decoder `p_theta(tau_H+ | m)` predicts past and future states and rewards conditioned on `m` \\cite{zintgraf2019zat}.\n    2.  **Policy Network**: A policy `pi_psi(a_t | s_t, q_phi(m | tau_t))` conditions its actions on both the environment state `s_t` and the *posterior belief* `q_phi(m | tau_t)` over the task embedding `m`. This allows the policy to learn how to trade off exploration and exploitation under task uncertainty \\cite{zintgraf2019zat}.\n*   **Online Inference**: The encoder processes trajectories online using a recurrent network, allowing the agent to continuously update its belief about the task as it interacts with the environment \\cite{zintgraf2019zat}.\n*   **Decoding Future Trajectories**: Unlike conventional VAEs, the decoder models the *entire* trajectory (`tau_H+`, including future states and rewards), which helps variBAD learn to infer properties of unseen states given past experience \\cite{zintgraf2019zat}.\n*   **Training Objective**: The overall objective maximizes a combination of the RL objective (for the policy) and an ELBO (Evidence Lower Bound) for the VAE, which includes a reconstruction loss and a KL divergence term between the approximate posterior and a prior (the previous posterior) \\cite{zintgraf2019zat}.\n\n### 4. Key Technical Contributions\n\n*   **Novel Algorithms/Methods**:\n    *   A novel framework for meta-learning approximate variational inference for unknown tasks, enabling online belief updates \\cite{zintgraf2019zat}.\n    *   Joint meta-training of a VAE (for posterior inference over latent MDP embeddings) and a policy conditioned on this posterior, allowing for end-to-end learning of Bayes-adaptive behavior \\cite{zintgraf2019zat}.\n*   **System Design/Architectural Innovations**:\n    *   Representation of MDPs via low-dimensional stochastic latent variables `m`, significantly reducing the complexity of inference compared to direct modeling of reward/transition functions \\cite{zintgraf2019zat}.\n    *   A recurrent neural network encoder for processing online trajectories and generating task posteriors, coupled with a decoder that predicts future trajectories \\cite{zintgraf2019zat}.\n*   **Theoretical Insights/Analysis**:\n    *   Provides a tractable and flexible approach to learning Bayes-adaptive policies, making minimal assumptions (only requiring a distribution over tasks for meta-training) \\cite{zintgraf2019zat}.\n    *   Demonstrates how conditioning a policy on a learned posterior over task embeddings can effectively approximate Bayes-optimal exploration \\cite{zintgraf2019zat}.\n\n### 5. Experimental Validation\n\n*   **Experiments Conducted**:\n    *   **Gridworld Domain**: An environment where the agent must navigate to an unknown goal, illustrating structured online exploration \\cite{zintgraf2019zat}.\n    *   **MuJoCo Domains**: Standard continuous control tasks widely used in meta-RL benchmarks \\cite{zintgraf2019zat}.\n*   **Key Performance Metrics**: Average online return achieved during learning \\cite{zintgraf2019zat}.\n*   **Comparison Results**:\n    *   **Gridworld**: VariBAD's performance closely matches that of a hard-coded Bayes-optimal agent, achieving optimal performance from the third rollout. It significantly outperforms posterior sampling, which requires six rollouts to reach optimal performance \\cite{zintgraf2019zat}.\n    *   **MuJoCo**: VariBAD achieves higher online return compared to existing meta-learning methods, demonstrating superior exploratory behavior at test time \\cite{zintgraf2019zat}.\n\n### 6. Limitations & Scope\n\n*   **Technical Limitations/Assumptions**:\n    *   Assumes the availability of a distribution `p(M)` over MDPs for meta-training \\cite{zintgraf2019zat}.\n    *   For computational efficiency with long horizons, the ELBO terms are subsampled for random time steps `t` \\cite{zintgraf2019zat}.\n    *   The RL loss is not backpropagated through the encoder in experiments, which simplifies training and avoids gradient interference, but might not be theoretically optimal \\cite{zintgraf2019zat}.\n*   **Scope of Applicability**: VariBAD is applicable to multi-task meta-learning settings where tasks share some underlying structure and a distribution over these tasks can be sampled for training \\cite{zintgraf2019zat}. It is particularly suited for scenarios where efficient online exploration is critical.\n\n### 7. Technical Significance\n\n*   **Advancement of State-of-the-Art**: VariBAD provides a significant step towards tractable approximate Bayes-optimal exploration in deep reinforcement learning \\cite{zintgraf2019zat}. It offers a principled, yet scalable, way to incorporate task uncertainty into decision-making, which has been a long-standing challenge in RL \\cite{zintgraf2019zat}.\n*   **Potential Impact on Future Research**:\n    *   Opens new avenues for developing more efficient and robust exploration strategies in complex, unknown environments \\cite{zintgraf2019zat}.\n    *   Could inspire further research into learning more sophisticated amortized inference mechanisms for Bayesian RL \\cite{zintgraf2019zat}.\n    *   Its end-to-end learning of Bayes-adaptive policies without explicit planning at test time could be a blueprint for future meta-RL algorithms focused on online adaptation and exploration \\cite{zintgraf2019zat}.",
      "intriguing_abstract": "The quest for Bayes-optimal exploration, where agents intelligently balance gathering information and maximizing rewards in unknown environments, remains a cornerstone challenge in reinforcement learning. Traditional approaches struggle with the intractability of Bayes-Adaptive MDPs or the inefficiency of heuristic methods like posterior sampling. We introduce **VariBAD (Variational Bayes-Adaptive Deep RL)**, a novel meta-learning framework that tackles this by learning to perform approximate variational inference over latent task embeddings.\n\nVariBAD jointly meta-trains a recurrent variational auto-encoder to infer an online posterior belief about the unknown task, and a deep policy network that conditions its actions directly on this evolving belief. This allows the agent to intrinsically learn sophisticated, information-seeking exploration strategies without explicit planning. Our experiments demonstrate that VariBAD achieves near Bayes-optimal performance in challenging Gridworld tasks, significantly outperforming posterior sampling. Furthermore, it yields superior online return on complex MuJoCo benchmarks compared to state-of-the-art meta-RL methods. VariBAD offers a principled, scalable solution for incorporating task uncertainty into deep RL, paving the way for more robust and efficient online adaptation in real-world applications.",
      "keywords": [
        "Variational Bayes-Adaptive Deep RL (variBAD)",
        "Bayes-optimal policies",
        "Meta-Reinforcement Learning",
        "approximate Bayes-adaptive policy",
        "variational inference",
        "amortized inference",
        "latent MDP embeddings",
        "policy conditioned on posterior belief",
        "online belief updates",
        "efficient online exploration",
        "task uncertainty",
        "joint meta-training",
        "deep reinforcement learning"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/361e953f792a585496834ee14216b94d0ce9ae74.pdf",
      "citation_key": "zintgraf2019zat",
      "metadata": {
        "title": "VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning",
        "authors": [
          "Luisa M. Zintgraf",
          "Kyriacos Shiarlis",
          "Maximilian Igl",
          "Sebastian Schulze",
          "Y. Gal",
          "Katja Hofmann",
          "S. Whiteson"
        ],
        "published_date": "2019",
        "abstract": "Trading off exploration and exploitation in an unknown environment is key to maximising expected return during learning. A Bayes-optimal policy, which does so optimally, conditions its actions not only on the environment state but on the agent's uncertainty about the environment. Computing a Bayes-optimal policy is however intractable for all but the smallest tasks. In this paper, we introduce variational Bayes-Adaptive Deep RL (variBAD), a way to meta-learn to perform approximate inference in an unknown environment, and incorporate task uncertainty directly during action selection. In a grid-world domain, we illustrate how variBAD performs structured online exploration as a function of task uncertainty. We further evaluate variBAD on MuJoCo domains widely used in meta-RL and show that it achieves higher online return than existing methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/361e953f792a585496834ee14216b94d0ce9ae74.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 290,
        "score": 48.33333333333333,
        "summary": "Here's a focused summary of the paper \"VARIBAD: A VERY GOOD METHOD FOR BAYES-ADAPTIVE DEEP RL VIA META-LEARNING\" \\cite{zintgraf2019zat} for a literature review:\n\n### 1. Research Problem & Motivation\n\n*   **Specific Technical Problem**: The paper addresses the challenge of optimally trading off exploration and exploitation in unknown environments within Reinforcement Learning (RL) \\cite{zintgraf2019zat}. Specifically, it aims to compute or approximate Bayes-optimal policies, which condition actions on the agent's uncertainty about the environment, to maximize expected online return.\n*   **Importance and Challenge**:\n    *   **Intractability of Bayes-Optimal Policies**: Computing a truly Bayes-optimal policy, which involves planning in a Bayes-Adaptive Markov Decision Process (BAMDP) where the state space is augmented with a belief distribution over environments, is intractable for all but the smallest tasks \\cite{zintgraf2019zat}.\n    *   **Inefficiency of Shortcuts**: Common shortcuts like posterior sampling are more tractable but can lead to highly inefficient exploration, as they do not optimally reduce uncertainty \\cite{zintgraf2019zat}.\n    *   **Intractable Inference**: Even maintaining the posterior belief required for methods like posterior sampling can be intractable \\cite{zintgraf2019zat}.\n    *   **Online Performance**: Maximizing expected return *during learning* (online return) is crucial in many real-world applications \\cite{zintgraf2019zat}.\n\n### 2. Related Work & Positioning\n\n*   **Bayes-Adaptive MDPs (BAMDPs)**: The work builds on the theoretical framework of BAMDPs, which formally define Bayes-optimal policies by augmenting the state space with a belief distribution over MDPs \\cite{zintgraf2019zat}.\n    *   **Limitations**: BAMDPs are generally intractable for complex problems due to the high-dimensional belief space and the difficulty of updating beliefs \\cite{zintgraf2019zat}.\n*   **Posterior Sampling**: This is a common heuristic that samples a single MDP from the posterior and acts optimally within it for an episode \\cite{zintgraf2019zat}.\n    *   **Limitations**: While more tractable than full BAMDPs, posterior sampling's exploration can be highly inefficient and far from Bayes-optimal, as it doesn't strategically seek information (illustrated in Figure 1) \\cite{zintgraf2019zat}.\n*   **Meta-Reinforcement Learning (Meta-RL)**: The paper positions itself within meta-RL, where an agent learns to adapt to new, related tasks from a distribution \\cite{zintgraf2019zat}.\n    *   **Limitations of Previous Meta-RL**: Existing meta-RL methods often do not explicitly reason about task uncertainty in a Bayes-optimal way, or they rely on privileged task information during training, limiting their applicability and exploration efficiency \\cite{zintgraf2019zat}.\n*   **VariBAD's Positioning**: VariBAD aims to overcome the intractability of Bayes-optimal policies and the inefficiency of posterior sampling by meta-learning an *approximate* Bayes-adaptive policy that performs efficient, structured online exploration, without requiring privileged task information \\cite{zintgraf2019zat}.\n\n### 3. Technical Approach & Innovation\n\n*   **Core Method**: Variational Bayes-Adaptive Deep RL (variBAD) meta-learns to perform approximate inference in an unknown environment and incorporates task uncertainty directly into action selection \\cite{zintgraf2019zat}.\n*   **Latent Variable Representation**: Each MDP `M` is represented by a learned, low-dimensional stochastic latent variable `m`. The reward and transition functions are then conditioned on this `m` and shared across tasks \\cite{zintgraf2019zat}.\n*   **Joint Meta-Training**: VariBAD jointly meta-trains two main components:\n    1.  **Variational Auto-Encoder (VAE)**: An amortized inference network `q_phi(m | tau_t)` (encoder) infers the posterior distribution over `m` given the agent's experience `tau_t` (trajectory of states, actions, rewards) up to time `t`. A decoder `p_theta(tau_H+ | m)` predicts past and future states and rewards conditioned on `m` \\cite{zintgraf2019zat}.\n    2.  **Policy Network**: A policy `pi_psi(a_t | s_t, q_phi(m | tau_t))` conditions its actions on both the environment state `s_t` and the *posterior belief* `q_phi(m | tau_t)` over the task embedding `m`. This allows the policy to learn how to trade off exploration and exploitation under task uncertainty \\cite{zintgraf2019zat}.\n*   **Online Inference**: The encoder processes trajectories online using a recurrent network, allowing the agent to continuously update its belief about the task as it interacts with the environment \\cite{zintgraf2019zat}.\n*   **Decoding Future Trajectories**: Unlike conventional VAEs, the decoder models the *entire* trajectory (`tau_H+`, including future states and rewards), which helps variBAD learn to infer properties of unseen states given past experience \\cite{zintgraf2019zat}.\n*   **Training Objective**: The overall objective maximizes a combination of the RL objective (for the policy) and an ELBO (Evidence Lower Bound) for the VAE, which includes a reconstruction loss and a KL divergence term between the approximate posterior and a prior (the previous posterior) \\cite{zintgraf2019zat}.\n\n### 4. Key Technical Contributions\n\n*   **Novel Algorithms/Methods**:\n    *   A novel framework for meta-learning approximate variational inference for unknown tasks, enabling online belief updates \\cite{zintgraf2019zat}.\n    *   Joint meta-training of a VAE (for posterior inference over latent MDP embeddings) and a policy conditioned on this posterior, allowing for end-to-end learning of Bayes-adaptive behavior \\cite{zintgraf2019zat}.\n*   **System Design/Architectural Innovations**:\n    *   Representation of MDPs via low-dimensional stochastic latent variables `m`, significantly reducing the complexity of inference compared to direct modeling of reward/transition functions \\cite{zintgraf2019zat}.\n    *   A recurrent neural network encoder for processing online trajectories and generating task posteriors, coupled with a decoder that predicts future trajectories \\cite{zintgraf2019zat}.\n*   **Theoretical Insights/Analysis**:\n    *   Provides a tractable and flexible approach to learning Bayes-adaptive policies, making minimal assumptions (only requiring a distribution over tasks for meta-training) \\cite{zintgraf2019zat}.\n    *   Demonstrates how conditioning a policy on a learned posterior over task embeddings can effectively approximate Bayes-optimal exploration \\cite{zintgraf2019zat}.\n\n### 5. Experimental Validation\n\n*   **Experiments Conducted**:\n    *   **Gridworld Domain**: An environment where the agent must navigate to an unknown goal, illustrating structured online exploration \\cite{zintgraf2019zat}.\n    *   **MuJoCo Domains**: Standard continuous control tasks widely used in meta-RL benchmarks \\cite{zintgraf2019zat}.\n*   **Key Performance Metrics**: Average online return achieved during learning \\cite{zintgraf2019zat}.\n*   **Comparison Results**:\n    *   **Gridworld**: VariBAD's performance closely matches that of a hard-coded Bayes-optimal agent, achieving optimal performance from the third rollout. It significantly outperforms posterior sampling, which requires six rollouts to reach optimal performance \\cite{zintgraf2019zat}.\n    *   **MuJoCo**: VariBAD achieves higher online return compared to existing meta-learning methods, demonstrating superior exploratory behavior at test time \\cite{zintgraf2019zat}.\n\n### 6. Limitations & Scope\n\n*   **Technical Limitations/Assumptions**:\n    *   Assumes the availability of a distribution `p(M)` over MDPs for meta-training \\cite{zintgraf2019zat}.\n    *   For computational efficiency with long horizons, the ELBO terms are subsampled for random time steps `t` \\cite{zintgraf2019zat}.\n    *   The RL loss is not backpropagated through the encoder in experiments, which simplifies training and avoids gradient interference, but might not be theoretically optimal \\cite{zintgraf2019zat}.\n*   **Scope of Applicability**: VariBAD is applicable to multi-task meta-learning settings where tasks share some underlying structure and a distribution over these tasks can be sampled for training \\cite{zintgraf2019zat}. It is particularly suited for scenarios where efficient online exploration is critical.\n\n### 7. Technical Significance\n\n*   **Advancement of State-of-the-Art**: VariBAD provides a significant step towards tractable approximate Bayes-optimal exploration in deep reinforcement learning \\cite{zintgraf2019zat}. It offers a principled, yet scalable, way to incorporate task uncertainty into decision-making, which has been a long-standing challenge in RL \\cite{zintgraf2019zat}.\n*   **Potential Impact on Future Research**:\n    *   Opens new avenues for developing more efficient and robust exploration strategies in complex, unknown environments \\cite{zintgraf2019zat}.\n    *   Could inspire further research into learning more sophisticated amortized inference mechanisms for Bayesian RL \\cite{zintgraf2019zat}.\n    *   Its end-to-end learning of Bayes-adaptive policies without explicit planning at test time could be a blueprint for future meta-RL algorithms focused on online adaptation and exploration \\cite{zintgraf2019zat}.",
        "keywords": [
          "Variational Bayes-Adaptive Deep RL (variBAD)",
          "Bayes-optimal policies",
          "Meta-Reinforcement Learning",
          "approximate Bayes-adaptive policy",
          "variational inference",
          "amortized inference",
          "latent MDP embeddings",
          "policy conditioned on posterior belief",
          "online belief updates",
          "efficient online exploration",
          "task uncertainty",
          "joint meta-training",
          "deep reinforcement learning"
        ],
        "paper_type": "the paper type is **technical**.\n\n**reasoning:**\n\n1.  **abstract:** explicitly states, \"in this paper, we introduce variational bayes-adaptive deep rl (varibad), a way to meta-learn to perform approximate inference...\" this is a clear indication of presenting a new method or system. it then describes the functionality of this new method and its evaluation.\n2.  **introduction:** sets up a technical problem (\"computing a bayes-optimal policy is however intractable for all but the smallest tasks\") and immediately follows with the proposed solution (\"in this paper, we introduce variational bayes-adaptive deep rl (varibad)...\"). it also discusses the technical domain of reinforcement learning and bayes-adaptive markov decision processes.\n3.  **keywords from criteria:** the abstract uses \"introduce\" and describes an \"algorithm\" or \"method\" (varibad). the introduction discusses a \"technical problem\" and a \"proposed solution.\"\n4.  **empirical aspect:** while the paper clearly includes empirical evaluation (\"we further evaluate varibad on mujoco domains... and show that it achieves higher online return\"), this evaluation serves to demonstrate the effectiveness of the *new method* being proposed. the core contribution is the method itself, making it primarily technical, with empirical validation."
      },
      "file_name": "361e953f792a585496834ee14216b94d0ce9ae74.pdf"
    },
    {
      "success": true,
      "doc_id": "9376df58503bfec4e37e68b1086e1c8f",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Focused Summary for Literature Review: Learning to Learn from Noisy Labeled Data \\cite{li2018soc}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Deep Neural Networks (DNNs) suffer significant performance degradation when trained on datasets with noisy labels, as they tend to overfit to this label noise.\n    *   **Importance & Challenge:** High-quality, manually annotated datasets are expensive and time-consuming to collect. Inexpensive data sources (e.g., web data) are abundant but inherently contain inaccurate labels. Developing noise-tolerant training algorithms is crucial for leveraging these vast, low-cost data sources without compromising model performance. The challenge lies in enabling DNNs to learn underlying true patterns despite pervasive label corruption, without relying on clean labels or extensive human supervision.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   **Noise Modeling:** Some methods formulate explicit or implicit noise models (e.g., using neural networks, graphical models) to infer true labels or re-weight samples \\cite{li2018soc}.\n        *   **Correction Methods:** Approaches like bootstrapping \\cite{li2018soc} or joint optimization of network parameters and labels \\cite{li2018soc} aim to reduce noise influence.\n        *   **Noise-Tolerant Loss Functions:** Other methods design robust loss functions \\cite{li2018soc}.\n        *   **Meta-Learning (MAML):** The proposed method is related to MAML \\cite{li2018soc} in its model-agnostic nature and use of gradient updates on simulated meta-tasks, but MAML focuses on few-shot learning, whereas this work targets noise tolerance.\n        *   **Self-Ensembling:** The method adapts self-ensembling techniques \\cite{li2018soc} (specifically, the student-teacher model) from semi-supervised learning to construct a reliable teacher model for consistency regularization.\n    *   **Limitations of Previous Solutions:**\n        *   Many noise modeling methods require a small set of clean labels or expensive estimation, limiting scalability \\cite{li2018soc}.\n        *   They often rely on specific assumptions about the noise model, which may not hold for complex real-world noise \\cite{li2018soc}.\n        *   Correction methods can be less effective and more heuristic \\cite{li2018soc}.\n        *   Existing meta-learning approaches like MAML are not designed for label noise robustness \\cite{li2018soc}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a Meta-Learning based Noise-Tolerant (MLNT) training algorithm. For each mini-batch, a meta-learning update is performed *before* the conventional gradient update. This meta-update optimizes the model's parameters to be less prone to overfitting and more robust against label noise.\n    *   **Novelty/Difference:**\n        *   **Meta-Objective for Noise Tolerance:** Instead of directly correcting labels or designing specific noise models, MLNT optimizes for model parameters that are inherently noise-tolerant. It trains the model such that after one gradient update using *synthetic* noisy labels, the model does not overfit to that specific noise \\cite{li2018soc}.\n        *   **Synthetic Noise Generation:** A novel \"random neighbor label transfer\" method is used to generate synthetic noisy labels. This process selects samples, finds their nearest neighbors (based on feature representations from a pre-trained DNN), and replaces the original label with a neighbor's label. This aims to preserve the underlying noise transition distribution \\cite{li2018soc}.\n        *   **Consistency Loss with Self-Ensembling Teacher:** The meta-objective enforces consistency between the predictions of the student model (after a synthetic noise update) and a teacher model. The teacher model's parameters are an Exponential Moving Average (EMA) of the student's, making it more stable and less affected by synthetic noise. Kullback-Leibler (KL)-divergence is used as the consistency loss \\cite{li2018soc}.\n        *   **Iterative Training Scheme:** An iterative approach is introduced to: (1) filter out potentially wrong labels from the classification loss using a \"mentor\" model (best model from previous iteration), and (2) improve the teacher model's predictions by merging them with the mentor model's predictions \\cite{li2018soc}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm:** A meta-learning based noise-tolerant training algorithm that optimizes a meta-objective before conventional training, making the model robust to a wide spectrum of artificially generated label noise \\cite{li2018soc}.\n    *   **Methodology for Meta-Objective:** Formulation of a meta-objective that trains the model to produce consistent predictions with a self-ensembling teacher model after learning from various synthetic noisy labels via gradient updates \\cite{li2018soc}.\n    *   **Synthetic Noise Generation:** Introduction of \"random neighbor label transfer\" for generating synthetic noisy labels that mimic the underlying noise distribution \\cite{li2018soc}.\n    *   **Iterative Refinement:** An iterative training scheme that incorporates data filtering based on a mentor model and merges mentor/teacher predictions for enhanced consistency loss effectiveness \\cite{li2018soc}.\n    *   **Model-Agnosticism:** The proposed method is theoretically applicable to any model trained with gradient-based rules \\cite{li2018soc}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were performed on two datasets:\n        *   **CIFAR-10:** With artificially injected symmetric (r=0.1 to 0.9) and asymmetric (r=0.1 to 0.5) label noise \\cite{li2018soc}.\n        *   **Clothing1M:** A large-scale dataset with real-world label noise \\cite{li2018soc}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Metric:** Classification accuracy.\n        *   **Baselines:** Compared against state-of-the-art methods including Cross Entropy, Bootstrap, Co-teaching, MentorNet, Decoupling, PENCIL, and D-MAML \\cite{li2018soc}.\n        *   **Results:** MLNT consistently demonstrated advantageous performance, achieving higher classification accuracy across various noise ratios on CIFAR-10 (e.g., 87.1% at 70% symmetric noise, 86.2% at 50% asymmetric noise) and on the real-world Clothing1M dataset (74.6% accuracy) compared to all baselines \\cite{li2018soc}.\n        *   **Ablation Studies:** Examined the impact of hyper-parameters (number of synthetic mini-batches M, label replacement ratio α, data filtering threshold γ) and validated the effectiveness of the first-order approximation for meta-gradients \\cite{li2018soc}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The meta-gradient calculation uses a first-order approximation to increase computation speed, though experiments show it performs almost as well as second-order derivatives \\cite{li2018soc}.\n        *   The \"random neighbor label transfer\" relies on feature representations from a DNN pre-trained on the entire noisy training set, which might introduce some dependency on initial model quality \\cite{li2018soc}.\n        *   The method involves several hyper-parameters (M, α, γ, smoothing coefficient, meta-learning rate) that need to be tuned, typically via a validation set \\cite{li2018soc}.\n    *   **Scope of Applicability:** The method is model-agnostic and applicable to any model trained with gradient-based rules, primarily demonstrated for image classification tasks \\cite{li2018soc}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This work significantly advances the technical state-of-the-art in learning from noisy labeled data by introducing a novel, model-agnostic meta-learning framework. It effectively addresses the overfitting issue without requiring clean labels or explicit noise modeling assumptions \\cite{li2018soc}.\n    *   **Potential Impact:** The proposed MLNT algorithm offers a robust and scalable solution for training DNNs on large, noisy datasets, which are increasingly common in real-world applications. It opens avenues for future research in meta-learning for various data imperfection challenges beyond label noise, potentially impacting fields where data annotation is costly or unreliable \\cite{li2018soc}.",
      "intriguing_abstract": "The pervasive challenge of noisy labels severely degrades Deep Neural Network (DNN) performance, limiting the utility of abundant, low-cost data. We introduce a novel Meta-Learning based Noise-Tolerant (MLNT) algorithm that enables DNNs to inherently resist overfitting to label noise without requiring clean data or explicit noise modeling. Our core innovation lies in a meta-objective that trains the model to produce consistent predictions with a robust self-ensembling teacher, even after learning from various *synthetic* noisy labels generated via a novel \"random neighbor label transfer\" method. This meta-learning approach optimizes for parameters that are intrinsically noise-tolerant, ensuring robustness across diverse noise patterns. Further enhanced by an iterative scheme incorporating a \"mentor\" model for data filtering and prediction merging, MLNT significantly outperforms state-of-the-art methods on both artificially corrupted CIFAR-10 and the real-world Clothing1M dataset. This model-agnostic framework offers a powerful, scalable solution for robust learning from imperfect data, critically advancing the state-of-the-art in noise-tolerant deep learning.",
      "keywords": [
        "Deep Neural Networks (DNNs)",
        "noisy labels",
        "overfitting to label noise",
        "Meta-Learning based Noise-Tolerant (MLNT) algorithm",
        "meta-learning for noise tolerance",
        "synthetic noise generation",
        "random neighbor label transfer",
        "self-ensembling teacher model",
        "consistency loss",
        "iterative training scheme",
        "model-agnosticism",
        "image classification",
        "high classification accuracy",
        "state-of-the-art advancement"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/2e4316e7c38373d068f8ff55f26ff83dfc4238b8.pdf",
      "citation_key": "li2018soc",
      "metadata": {
        "title": "Learning to Learn From Noisy Labeled Data",
        "authors": [
          "Junnan Li",
          "Yongkang Wong",
          "Qi Zhao",
          "Mohan Kankanhalli"
        ],
        "published_date": "2018",
        "abstract": "Despite the success of deep neural networks (DNNs) in image classification tasks, the human-level performance relies on massive training data with high-quality manual annotations, which are expensive and time-consuming to collect. There exist many inexpensive data sources on the web, but they tend to contain inaccurate labels. Training on noisy labeled datasets causes performance degradation because DNNs can easily overfit to the label noise. To overcome this problem, we propose a noise-tolerant training algorithm, where a meta-learning update is performed prior to conventional gradient update. The proposed meta-learning method simulates actual training by generating synthetic noisy labels, and train the model such that after one gradient update using each set of synthetic noisy labels, the model does not overfit to the specific noise. We conduct extensive experiments on the noisy CIFAR-10 dataset and the Clothing1M dataset. The results demonstrate the advantageous performance of the proposed method compared to several state-of-the-art baselines.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2e4316e7c38373d068f8ff55f26ff83dfc4238b8.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 338,
        "score": 48.285714285714285,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Focused Summary for Literature Review: Learning to Learn from Noisy Labeled Data \\cite{li2018soc}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Deep Neural Networks (DNNs) suffer significant performance degradation when trained on datasets with noisy labels, as they tend to overfit to this label noise.\n    *   **Importance & Challenge:** High-quality, manually annotated datasets are expensive and time-consuming to collect. Inexpensive data sources (e.g., web data) are abundant but inherently contain inaccurate labels. Developing noise-tolerant training algorithms is crucial for leveraging these vast, low-cost data sources without compromising model performance. The challenge lies in enabling DNNs to learn underlying true patterns despite pervasive label corruption, without relying on clean labels or extensive human supervision.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   **Noise Modeling:** Some methods formulate explicit or implicit noise models (e.g., using neural networks, graphical models) to infer true labels or re-weight samples \\cite{li2018soc}.\n        *   **Correction Methods:** Approaches like bootstrapping \\cite{li2018soc} or joint optimization of network parameters and labels \\cite{li2018soc} aim to reduce noise influence.\n        *   **Noise-Tolerant Loss Functions:** Other methods design robust loss functions \\cite{li2018soc}.\n        *   **Meta-Learning (MAML):** The proposed method is related to MAML \\cite{li2018soc} in its model-agnostic nature and use of gradient updates on simulated meta-tasks, but MAML focuses on few-shot learning, whereas this work targets noise tolerance.\n        *   **Self-Ensembling:** The method adapts self-ensembling techniques \\cite{li2018soc} (specifically, the student-teacher model) from semi-supervised learning to construct a reliable teacher model for consistency regularization.\n    *   **Limitations of Previous Solutions:**\n        *   Many noise modeling methods require a small set of clean labels or expensive estimation, limiting scalability \\cite{li2018soc}.\n        *   They often rely on specific assumptions about the noise model, which may not hold for complex real-world noise \\cite{li2018soc}.\n        *   Correction methods can be less effective and more heuristic \\cite{li2018soc}.\n        *   Existing meta-learning approaches like MAML are not designed for label noise robustness \\cite{li2018soc}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a Meta-Learning based Noise-Tolerant (MLNT) training algorithm. For each mini-batch, a meta-learning update is performed *before* the conventional gradient update. This meta-update optimizes the model's parameters to be less prone to overfitting and more robust against label noise.\n    *   **Novelty/Difference:**\n        *   **Meta-Objective for Noise Tolerance:** Instead of directly correcting labels or designing specific noise models, MLNT optimizes for model parameters that are inherently noise-tolerant. It trains the model such that after one gradient update using *synthetic* noisy labels, the model does not overfit to that specific noise \\cite{li2018soc}.\n        *   **Synthetic Noise Generation:** A novel \"random neighbor label transfer\" method is used to generate synthetic noisy labels. This process selects samples, finds their nearest neighbors (based on feature representations from a pre-trained DNN), and replaces the original label with a neighbor's label. This aims to preserve the underlying noise transition distribution \\cite{li2018soc}.\n        *   **Consistency Loss with Self-Ensembling Teacher:** The meta-objective enforces consistency between the predictions of the student model (after a synthetic noise update) and a teacher model. The teacher model's parameters are an Exponential Moving Average (EMA) of the student's, making it more stable and less affected by synthetic noise. Kullback-Leibler (KL)-divergence is used as the consistency loss \\cite{li2018soc}.\n        *   **Iterative Training Scheme:** An iterative approach is introduced to: (1) filter out potentially wrong labels from the classification loss using a \"mentor\" model (best model from previous iteration), and (2) improve the teacher model's predictions by merging them with the mentor model's predictions \\cite{li2018soc}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm:** A meta-learning based noise-tolerant training algorithm that optimizes a meta-objective before conventional training, making the model robust to a wide spectrum of artificially generated label noise \\cite{li2018soc}.\n    *   **Methodology for Meta-Objective:** Formulation of a meta-objective that trains the model to produce consistent predictions with a self-ensembling teacher model after learning from various synthetic noisy labels via gradient updates \\cite{li2018soc}.\n    *   **Synthetic Noise Generation:** Introduction of \"random neighbor label transfer\" for generating synthetic noisy labels that mimic the underlying noise distribution \\cite{li2018soc}.\n    *   **Iterative Refinement:** An iterative training scheme that incorporates data filtering based on a mentor model and merges mentor/teacher predictions for enhanced consistency loss effectiveness \\cite{li2018soc}.\n    *   **Model-Agnosticism:** The proposed method is theoretically applicable to any model trained with gradient-based rules \\cite{li2018soc}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** Extensive experiments were performed on two datasets:\n        *   **CIFAR-10:** With artificially injected symmetric (r=0.1 to 0.9) and asymmetric (r=0.1 to 0.5) label noise \\cite{li2018soc}.\n        *   **Clothing1M:** A large-scale dataset with real-world label noise \\cite{li2018soc}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Metric:** Classification accuracy.\n        *   **Baselines:** Compared against state-of-the-art methods including Cross Entropy, Bootstrap, Co-teaching, MentorNet, Decoupling, PENCIL, and D-MAML \\cite{li2018soc}.\n        *   **Results:** MLNT consistently demonstrated advantageous performance, achieving higher classification accuracy across various noise ratios on CIFAR-10 (e.g., 87.1% at 70% symmetric noise, 86.2% at 50% asymmetric noise) and on the real-world Clothing1M dataset (74.6% accuracy) compared to all baselines \\cite{li2018soc}.\n        *   **Ablation Studies:** Examined the impact of hyper-parameters (number of synthetic mini-batches M, label replacement ratio α, data filtering threshold γ) and validated the effectiveness of the first-order approximation for meta-gradients \\cite{li2018soc}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The meta-gradient calculation uses a first-order approximation to increase computation speed, though experiments show it performs almost as well as second-order derivatives \\cite{li2018soc}.\n        *   The \"random neighbor label transfer\" relies on feature representations from a DNN pre-trained on the entire noisy training set, which might introduce some dependency on initial model quality \\cite{li2018soc}.\n        *   The method involves several hyper-parameters (M, α, γ, smoothing coefficient, meta-learning rate) that need to be tuned, typically via a validation set \\cite{li2018soc}.\n    *   **Scope of Applicability:** The method is model-agnostic and applicable to any model trained with gradient-based rules, primarily demonstrated for image classification tasks \\cite{li2018soc}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This work significantly advances the technical state-of-the-art in learning from noisy labeled data by introducing a novel, model-agnostic meta-learning framework. It effectively addresses the overfitting issue without requiring clean labels or explicit noise modeling assumptions \\cite{li2018soc}.\n    *   **Potential Impact:** The proposed MLNT algorithm offers a robust and scalable solution for training DNNs on large, noisy datasets, which are increasingly common in real-world applications. It opens avenues for future research in meta-learning for various data imperfection challenges beyond label noise, potentially impacting fields where data annotation is costly or unreliable \\cite{li2018soc}.",
        "keywords": [
          "Deep Neural Networks (DNNs)",
          "noisy labels",
          "overfitting to label noise",
          "Meta-Learning based Noise-Tolerant (MLNT) algorithm",
          "meta-learning for noise tolerance",
          "synthetic noise generation",
          "random neighbor label transfer",
          "self-ensembling teacher model",
          "consistency loss",
          "iterative training scheme",
          "model-agnosticism",
          "image classification",
          "high classification accuracy",
          "state-of-the-art advancement"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose a noise-tolerant training algorithm**, where a **meta-learning update is performed**...\" and \"the **proposed meta-learning method** simulates actual training...\"\n*   the introduction reiterates: \"in this work **we propose a meta-learning based noise-tolerant (mlnt) training** to learn from noisy labeled data...\"\n*   the paper then describes conducting \"extensive experiments\" and demonstrating \"advantageous performance of the proposed method.\"\n\nthese phrases strongly align with the criteria for a **technical** paper, which \"presents new methods, algorithms, or systems.\" while it also includes empirical evaluation, the primary contribution is the development and presentation of a novel algorithm.\n\n**classification: technical**"
      },
      "file_name": "2e4316e7c38373d068f8ff55f26ff83dfc4238b8.pdf"
    },
    {
      "success": true,
      "doc_id": "318aca99035432dd36c8d888c8145d69",
      "summary": "The recent success of graph neural networks has significantly boosted molecular property prediction, advancing activities such as drug discovery. The existing deep neural network methods usually require large training dataset for each property, impairing their performance in cases (especially for new molecular properties) with a limited amount of experimental data, which are common in real situations. To this end, we propose Meta-MGNN, a novel model for few-shot molecular property prediction. Meta-MGNN applies molecular graph neural network to learn molecular representations and builds a meta-learning framework for model optimization. To exploit unlabeled molecular information and address task heterogeneity of different molecular properties, Meta-MGNN further incorporates molecular structures, attribute based self-supervised modules and self-attentive task weights into the former framework, strengthening the whole learning model. Extensive experiments on two public multi-property datasets demonstrate that Meta-MGNN outperforms a variety of state-of-the-art methods.",
      "intriguing_abstract": "The recent success of graph neural networks has significantly boosted molecular property prediction, advancing activities such as drug discovery. The existing deep neural network methods usually require large training dataset for each property, impairing their performance in cases (especially for new molecular properties) with a limited amount of experimental data, which are common in real situations. To this end, we propose Meta-MGNN, a novel model for few-shot molecular property prediction. Meta-MGNN applies molecular graph neural network to learn molecular representations and builds a meta-learning framework for model optimization. To exploit unlabeled molecular information and address task heterogeneity of different molecular properties, Meta-MGNN further incorporates molecular structures, attribute based self-supervised modules and self-attentive task weights into the former framework, strengthening the whole learning model. Extensive experiments on two public multi-property datasets demonstrate that Meta-MGNN outperforms a variety of state-of-the-art methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/eb8dba325534da472170293b054596a17558c7f2.pdf",
      "citation_key": "guo2021zpk",
      "metadata": {
        "title": "Few-Shot Graph Learning for Molecular Property Prediction",
        "authors": [
          "Zhichun Guo",
          "Chuxu Zhang",
          "W. Yu",
          "John E. Herr",
          "O. Wiest",
          "Meng Jiang",
          "N. Chawla"
        ],
        "published_date": "2021",
        "abstract": "The recent success of graph neural networks has significantly boosted molecular property prediction, advancing activities such as drug discovery. The existing deep neural network methods usually require large training dataset for each property, impairing their performance in cases (especially for new molecular properties) with a limited amount of experimental data, which are common in real situations. To this end, we propose Meta-MGNN, a novel model for few-shot molecular property prediction. Meta-MGNN applies molecular graph neural network to learn molecular representations and builds a meta-learning framework for model optimization. To exploit unlabeled molecular information and address task heterogeneity of different molecular properties, Meta-MGNN further incorporates molecular structures, attribute based self-supervised modules and self-attentive task weights into the former framework, strengthening the whole learning model. Extensive experiments on two public multi-property datasets demonstrate that Meta-MGNN outperforms a variety of state-of-the-art methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/eb8dba325534da472170293b054596a17558c7f2.pdf",
        "venue": "The Web Conference",
        "citationCount": 188,
        "score": 47.0,
        "summary": "The recent success of graph neural networks has significantly boosted molecular property prediction, advancing activities such as drug discovery. The existing deep neural network methods usually require large training dataset for each property, impairing their performance in cases (especially for new molecular properties) with a limited amount of experimental data, which are common in real situations. To this end, we propose Meta-MGNN, a novel model for few-shot molecular property prediction. Meta-MGNN applies molecular graph neural network to learn molecular representations and builds a meta-learning framework for model optimization. To exploit unlabeled molecular information and address task heterogeneity of different molecular properties, Meta-MGNN further incorporates molecular structures, attribute based self-supervised modules and self-attentive task weights into the former framework, strengthening the whole learning model. Extensive experiments on two public multi-property datasets demonstrate that Meta-MGNN outperforms a variety of state-of-the-art methods.",
        "keywords": []
      },
      "file_name": "eb8dba325534da472170293b054596a17558c7f2.pdf"
    },
    {
      "success": true,
      "doc_id": "214125cac7ac60bf6622e3f87032b82e",
      "summary": "Real-world training data usually exhibits long-tailed distribution, where several majority classes have a significantly larger number of samples than the remaining minority classes. This imbalance degrades the performance of typical supervised learning algorithms designed for balanced training sets. In this paper, we address this issue by augmenting minority classes with a recently proposed implicit semantic data augmentation (ISDA) algorithm [37], which produces diversified augmented samples by translating deep features along many semantically meaningful directions. Importantly, given that ISDA estimates the class-conditional statistics to obtain semantic directions, we find it ineffective to do this on minority classes due to the insufficient training data. To this end, we propose a novel approach to learn transformed semantic directions with meta-learning automatically. In specific, the augmentation strategy during training is dynamically optimized, aiming to minimize the loss on a small balanced validation set, which is approximated via a meta update step. Extensive empirical results on CIFAR-LT-10/100, ImageNet-LT, and iNaturalist 2017/2018 validate the effectiveness of our method.",
      "intriguing_abstract": "Real-world training data usually exhibits long-tailed distribution, where several majority classes have a significantly larger number of samples than the remaining minority classes. This imbalance degrades the performance of typical supervised learning algorithms designed for balanced training sets. In this paper, we address this issue by augmenting minority classes with a recently proposed implicit semantic data augmentation (ISDA) algorithm [37], which produces diversified augmented samples by translating deep features along many semantically meaningful directions. Importantly, given that ISDA estimates the class-conditional statistics to obtain semantic directions, we find it ineffective to do this on minority classes due to the insufficient training data. To this end, we propose a novel approach to learn transformed semantic directions with meta-learning automatically. In specific, the augmentation strategy during training is dynamically optimized, aiming to minimize the loss on a small balanced validation set, which is approximated via a meta update step. Extensive empirical results on CIFAR-LT-10/100, ImageNet-LT, and iNaturalist 2017/2018 validate the effectiveness of our method.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/505422c6e07b356969e641cdb0985ab2c85ccae4.pdf",
      "citation_key": "li20219tk",
      "metadata": {
        "title": "MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition",
        "authors": [
          "Shuang Li",
          "Kaixiong Gong",
          "Chi Harold Liu",
          "Yulin Wang",
          "Feng Qiao",
          "Xinjing Cheng"
        ],
        "published_date": "2021",
        "abstract": "Real-world training data usually exhibits long-tailed distribution, where several majority classes have a significantly larger number of samples than the remaining minority classes. This imbalance degrades the performance of typical supervised learning algorithms designed for balanced training sets. In this paper, we address this issue by augmenting minority classes with a recently proposed implicit semantic data augmentation (ISDA) algorithm [37], which produces diversified augmented samples by translating deep features along many semantically meaningful directions. Importantly, given that ISDA estimates the class-conditional statistics to obtain semantic directions, we find it ineffective to do this on minority classes due to the insufficient training data. To this end, we propose a novel approach to learn transformed semantic directions with meta-learning automatically. In specific, the augmentation strategy during training is dynamically optimized, aiming to minimize the loss on a small balanced validation set, which is approximated via a meta update step. Extensive empirical results on CIFAR-LT-10/100, ImageNet-LT, and iNaturalist 2017/2018 validate the effectiveness of our method.",
        "file_path": "paper_data/Deep_Meta-Learning/info/505422c6e07b356969e641cdb0985ab2c85ccae4.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 171,
        "score": 42.75,
        "summary": "Real-world training data usually exhibits long-tailed distribution, where several majority classes have a significantly larger number of samples than the remaining minority classes. This imbalance degrades the performance of typical supervised learning algorithms designed for balanced training sets. In this paper, we address this issue by augmenting minority classes with a recently proposed implicit semantic data augmentation (ISDA) algorithm [37], which produces diversified augmented samples by translating deep features along many semantically meaningful directions. Importantly, given that ISDA estimates the class-conditional statistics to obtain semantic directions, we find it ineffective to do this on minority classes due to the insufficient training data. To this end, we propose a novel approach to learn transformed semantic directions with meta-learning automatically. In specific, the augmentation strategy during training is dynamically optimized, aiming to minimize the loss on a small balanced validation set, which is approximated via a meta update step. Extensive empirical results on CIFAR-LT-10/100, ImageNet-LT, and iNaturalist 2017/2018 validate the effectiveness of our method.",
        "keywords": []
      },
      "file_name": "505422c6e07b356969e641cdb0985ab2c85ccae4.pdf"
    },
    {
      "success": true,
      "doc_id": "37e960d983dd55bc03d839404ec1e62d",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/6f1a0ac23a26f58da3f5dd5d3426e6f0f2e52298.pdf",
      "citation_key": "tian2022znj",
      "metadata": {
        "title": "Meta-learning approaches for learning-to-learn in deep learning: A survey",
        "authors": [
          "Yingjie Tian",
          "Xiaoxi Zhao",
          "Wei-Hsin Huang"
        ],
        "published_date": "2022",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/6f1a0ac23a26f58da3f5dd5d3426e6f0f2e52298.pdf",
        "venue": "Neurocomputing",
        "citationCount": 106,
        "score": 35.33333333333333,
        "summary": "",
        "keywords": []
      },
      "file_name": "6f1a0ac23a26f58da3f5dd5d3426e6f0f2e52298.pdf"
    },
    {
      "success": true,
      "doc_id": "19162e805e5e7b6fa08459fe4c4a90f2",
      "summary": "As a step towards developing zero-shot task generalization capabilities in reinforcement learning (RL), we introduce a new RL problem where the agent should learn to execute sequences of instructions after learning useful skills that solve subtasks. In this problem, we consider two types of generalizations: to previously unseen instructions and to longer sequences of instructions. For generalization over unseen instructions, we propose a new objective which encourages learning correspondences between similar subtasks by making analogies. For generalization over sequential instructions, we present a hierarchical architecture where a meta controller learns to use the acquired skills for executing the instructions. To deal with delayed reward, we propose a new neural architecture in the meta controller that learns when to update the subtask, which makes learning more efficient. Experimental results on a stochastic 3D domain show that the proposed ideas are crucial for generalization to longer instructions as well as unseen instructions.",
      "intriguing_abstract": "As a step towards developing zero-shot task generalization capabilities in reinforcement learning (RL), we introduce a new RL problem where the agent should learn to execute sequences of instructions after learning useful skills that solve subtasks. In this problem, we consider two types of generalizations: to previously unseen instructions and to longer sequences of instructions. For generalization over unseen instructions, we propose a new objective which encourages learning correspondences between similar subtasks by making analogies. For generalization over sequential instructions, we present a hierarchical architecture where a meta controller learns to use the acquired skills for executing the instructions. To deal with delayed reward, we propose a new neural architecture in the meta controller that learns when to update the subtask, which makes learning more efficient. Experimental results on a stochastic 3D domain show that the proposed ideas are crucial for generalization to longer instructions as well as unseen instructions.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/30834ae1497c35d362eea14857d93c28d2d12b57.pdf",
      "citation_key": "oh2017x02",
      "metadata": {
        "title": "Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning",
        "authors": [
          "Junhyuk Oh",
          "Satinder Singh",
          "Honglak Lee",
          "Pushmeet Kohli"
        ],
        "published_date": "2017",
        "abstract": "As a step towards developing zero-shot task generalization capabilities in reinforcement learning (RL), we introduce a new RL problem where the agent should learn to execute sequences of instructions after learning useful skills that solve subtasks. In this problem, we consider two types of generalizations: to previously unseen instructions and to longer sequences of instructions. For generalization over unseen instructions, we propose a new objective which encourages learning correspondences between similar subtasks by making analogies. For generalization over sequential instructions, we present a hierarchical architecture where a meta controller learns to use the acquired skills for executing the instructions. To deal with delayed reward, we propose a new neural architecture in the meta controller that learns when to update the subtask, which makes learning more efficient. Experimental results on a stochastic 3D domain show that the proposed ideas are crucial for generalization to longer instructions as well as unseen instructions.",
        "file_path": "paper_data/Deep_Meta-Learning/info/30834ae1497c35d362eea14857d93c28d2d12b57.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 273,
        "score": 34.125,
        "summary": "As a step towards developing zero-shot task generalization capabilities in reinforcement learning (RL), we introduce a new RL problem where the agent should learn to execute sequences of instructions after learning useful skills that solve subtasks. In this problem, we consider two types of generalizations: to previously unseen instructions and to longer sequences of instructions. For generalization over unseen instructions, we propose a new objective which encourages learning correspondences between similar subtasks by making analogies. For generalization over sequential instructions, we present a hierarchical architecture where a meta controller learns to use the acquired skills for executing the instructions. To deal with delayed reward, we propose a new neural architecture in the meta controller that learns when to update the subtask, which makes learning more efficient. Experimental results on a stochastic 3D domain show that the proposed ideas are crucial for generalization to longer instructions as well as unseen instructions.",
        "keywords": []
      },
      "file_name": "30834ae1497c35d362eea14857d93c28d2d12b57.pdf"
    },
    {
      "success": true,
      "doc_id": "cead153a4aece3a4b87f9ee43517a966",
      "summary": "Recent developments in deep reinforcement learning are concerned with creating decision-making agents which can perform well in various complex domains. A particular approach which has received increasing attention is multi-agent reinforcement learning, in which multiple agents learn concurrently to coordinate their actions. In such multi-agent environments, additional learning problems arise due to the continually changing decision-making policies of agents. This paper surveys recent works that address the non-stationarity problem in multi-agent deep reinforcement learning. The surveyed methods range from modifications in the training procedure, such as centralized training, to learning representations of the opponent's policy, meta-learning, communication, and decentralized learning. The survey concludes with a list of open problems and possible lines of future research.",
      "intriguing_abstract": "Recent developments in deep reinforcement learning are concerned with creating decision-making agents which can perform well in various complex domains. A particular approach which has received increasing attention is multi-agent reinforcement learning, in which multiple agents learn concurrently to coordinate their actions. In such multi-agent environments, additional learning problems arise due to the continually changing decision-making policies of agents. This paper surveys recent works that address the non-stationarity problem in multi-agent deep reinforcement learning. The surveyed methods range from modifications in the training procedure, such as centralized training, to learning representations of the opponent's policy, meta-learning, communication, and decentralized learning. The survey concludes with a list of open problems and possible lines of future research.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/615e443f15778e9fdde27fecebd5c6d028816e27.pdf",
      "citation_key": "papoudakis2019gyl",
      "metadata": {
        "title": "Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning",
        "authors": [
          "Georgios Papoudakis",
          "Filippos Christianos",
          "Arrasy Rahman",
          "Stefano V. Albrecht"
        ],
        "published_date": "2019",
        "abstract": "Recent developments in deep reinforcement learning are concerned with creating decision-making agents which can perform well in various complex domains. A particular approach which has received increasing attention is multi-agent reinforcement learning, in which multiple agents learn concurrently to coordinate their actions. In such multi-agent environments, additional learning problems arise due to the continually changing decision-making policies of agents. This paper surveys recent works that address the non-stationarity problem in multi-agent deep reinforcement learning. The surveyed methods range from modifications in the training procedure, such as centralized training, to learning representations of the opponent's policy, meta-learning, communication, and decentralized learning. The survey concludes with a list of open problems and possible lines of future research.",
        "file_path": "paper_data/Deep_Meta-Learning/info/615e443f15778e9fdde27fecebd5c6d028816e27.pdf",
        "venue": "arXiv.org",
        "citationCount": 200,
        "score": 33.33333333333333,
        "summary": "Recent developments in deep reinforcement learning are concerned with creating decision-making agents which can perform well in various complex domains. A particular approach which has received increasing attention is multi-agent reinforcement learning, in which multiple agents learn concurrently to coordinate their actions. In such multi-agent environments, additional learning problems arise due to the continually changing decision-making policies of agents. This paper surveys recent works that address the non-stationarity problem in multi-agent deep reinforcement learning. The surveyed methods range from modifications in the training procedure, such as centralized training, to learning representations of the opponent's policy, meta-learning, communication, and decentralized learning. The survey concludes with a list of open problems and possible lines of future research.",
        "keywords": []
      },
      "file_name": "615e443f15778e9fdde27fecebd5c6d028816e27.pdf"
    },
    {
      "success": true,
      "doc_id": "4c0daeeda1e591e44833f851466f17c9",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION**: \\cite{yoon2019k84}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Quantifying the value of individual data samples in machine learning datasets.\n    *   **Importance and Challenge**:\n        *   Machine learning models benefit from large-scale, high-quality data, but collecting such data is costly and challenging.\n        *   Not all data samples are equally useful; low-quality, noisy, or irrelevant data can be detrimental to model performance.\n        *   Real-world datasets often contain incorrect labels, samples from different distributions (domain mismatch), or noisy inputs.\n        *   Evaluating the value of each datum is difficult, especially for complex models (e.g., deep neural networks) trained on large datasets, due to the intricate interactions between samples.\n        *   Accurate data valuation can enable use cases like building insights, domain adaptation, corrupted sample discovery, robust learning, optimizing data collection, and value-based data pricing.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**:\n        *   **Leave-one-out (LOO)**: Quantifies value by removing a sample and measuring performance difference.\n        *   **Influence Function \\cite{koh2017understanding}**: Approximates LOO using gradients of the loss function with small perturbations.\n        *   **Data Shapley \\cite{ghorbani2019data}**: Game theory-based approach that considers marginal performance improvement across all possible data subsets.\n        *   **Meta-learning based adaptive learning**: Other works use meta-learning for adaptive weight assignment in robust learning, domain adaptation, and corrupted sample discovery (e.g., Learning to Reweight, MentorNet).\n    *   **Limitations of Previous Solutions**:\n        *   **Computational Cost**: LOO scales linearly with dataset size, becoming prohibitive for large datasets. Data Shapley is exponentially complex, even with Monte Carlo approximations, requiring re-training for many combinations. Influence Function requires expensive Hessian computations.\n        *   **Approximation Limitations**: LOO can underestimate the value of redundant samples. Approximations for Shapley values can lead to fundamental limitations in valuation performance.\n        *   **Decoupled Optimization**: Most prior data valuation methods (LOO, Influence Function, Data Shapley) decouple data valuation from the predictor model's training, limiting performance due to a lack of joint optimization.\n        *   **Model Specificity**: Some meta-learning approaches are not fully model-agnostic or directly model data value.\n    *   **DVRL's Positioning**: \\cite{yoon2019k84} proposes a novel meta-learning framework that *directly models the value of data using learnable neural networks* (a data value estimator) and *jointly optimizes* this estimator with the target task predictor model. It uses reinforcement learning to handle the non-differentiable sampling process, making it model-agnostic and applicable to non-differentiable objectives.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: Data Valuation using Reinforcement Learning (DVRL) is a meta-learning framework comprising two jointly optimized learnable functions:\n        1.  **Target Task Predictor Model (`f_theta`)**: A standard machine learning model (e.g., neural network) trained to minimize a weighted loss function, where weights are provided by the data value estimator.\n        2.  **Data Value Estimator Model (`h_phi`)**: A deep neural network that learns to output a selection probability (weight) `w = h_phi(x,y)` for each training sample `(x,y)`. These probabilities represent the likelihood of a datum being used in training and serve as its estimated value.\n    *   **Novelty/Difference**:\n        *   **Joint Optimization**: The data value estimator and the predictor model are optimized together. The predictor is trained using samples weighted by the estimator's output, and the estimator is trained to improve the predictor's performance on a small validation set.\n        *   **Reinforcement Learning for Valuation**: The sampling process (selecting data based on `h_phi`) is non-differentiable. \\cite{yoon2019k84} innovatively uses the REINFORCE algorithm to train the data value estimator. The \"reward\" signal for the reinforcement learning agent is derived from the predictor model's performance (loss) on a small, clean validation set, with a moving average baseline for stability.\n        *   **Model-Agnosticism**: The framework is designed to be applicable to various predictor models and even non-differentiable target objectives.\n        *   **Scalability**: Unlike previous methods, DVRL's computational complexity is not directly dependent on the training dataset size, making it scalable to large datasets and complex models.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: A novel meta-learning framework for data valuation that integrates a data value estimator with a target task predictor model.\n    *   **System Design/Architectural Innovations**: The use of a deep neural network as a data value estimator, trained via reinforcement learning, to generate sample-specific weights for the predictor model.\n    *   **Theoretical Insights/Analysis**: Formulation of data valuation as a bi-level optimization problem, solved through joint training with reinforcement learning for the non-differentiable component.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluation of data value estimation quality across various use cases: removing high/low value samples, corrupted sample discovery, domain adaptation, and robust learning.\n        *   Comparison against multiple benchmark methods.\n    *   **Datasets**: 12 public datasets, including tabular (Adult, Blog, Rossmann), image (MNIST, CIFAR-10/100, Flower, HAM 10000), and language (Email Spam, SMS Spam).\n    *   **Baseline Predictor Models**: Diverse models used to demonstrate model-agnosticism, including LightGBM, XGBoost, MLPs, Inception-v3, multinomial logistic regression, Naive Bayes, ResNet-32, and WideResNet-28-10.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **General Data Valuation**: DVRL marginally improved prediction performance by removing the least important samples (e.g., using 60-70% of data) even in conventional supervised settings, indicating accurate value estimation.\n        *   **Corrupted Sample Discovery**: DVRL's performance was \"close to optimal in many regimes\" (i.e., nearly as good as knowing noisy samples a priori).\n        *   **Domain Adaptation**: DVRL significantly outperformed state-of-the-art methods by **14.6%**.\n        *   **Robust Learning**: DVRL significantly outperformed state-of-the-art methods by **10.8%**.\n        *   **Scalability**: Demonstrated on large-scale datasets like CIFAR-100 with complex models (ResNet-32, WideResNet-28-10), showing its practical applicability.\n        *   **Benchmarks**: DVRL consistently yielded superior data value estimates compared to Random, Leave-one-out, Data Shapley, Learning to Reweight, MentorNet, and Influence Function across various scenarios.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the availability of a small validation dataset from the target distribution to provide the reinforcement signal.\n    *   **Computational Overhead**: While significantly more scalable than alternatives, DVRL's training time overhead is stated to be \"only twice of conventional training,\" implying it still adds computational cost compared to training a predictor alone.\n    *   **Scope of Applicability**: Applicable to various machine learning tasks (classification, regression) and data types (tabular, image, language), and is model-agnostic.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{yoon2019k84} significantly advances the technical state-of-the-art in data valuation by introducing a scalable, jointly optimized, and model-agnostic framework. It overcomes the computational and fundamental limitations of prior methods like LOO and Data Shapley.\n    *   **Potential Impact on Future Research**:\n        *   Enables more efficient and robust machine learning by identifying and prioritizing valuable data, leading to better model performance with less data or in the presence of noise/domain shift.\n        *   Opens avenues for research into adaptive data collection strategies, automated data cleaning, and fair data pricing mechanisms.\n        *   The reinforcement learning approach for non-differentiable data selection could inspire similar meta-learning strategies in other areas of ML.",
      "intriguing_abstract": "The escalating cost and variable quality of data pose significant challenges to modern machine learning. Quantifying the individual value of data samples, crucial for robust and efficient models, remains notoriously difficult due to intricate interdependencies and computational hurdles. We introduce Data Valuation using Reinforcement Learning (DVRL), a novel *meta-learning framework* that fundamentally redefines how data value is assessed. DVRL employs a *deep neural network* as a *data value estimator*, which is *jointly optimized* with the target task predictor. Crucially, it leverages *reinforcement learning* to navigate the non-differentiable data selection process, enabling a truly *model-agnostic* and *scalable* solution that overcomes the limitations of computationally prohibitive methods like Leave-one-out or *Data Shapley*.\n\nOur extensive experiments across 12 diverse datasets demonstrate DVRL's superior performance in critical applications: achieving near-optimal *corrupted sample discovery*, outperforming state-of-the-art by **14.6% in domain adaptation**, and **10.8% in robust learning**. This paradigm shift in *data valuation* offers unprecedented capabilities for optimizing data collection, enhancing model robustness, and enabling fair data pricing, paving the way for more efficient and trustworthy AI systems.",
      "keywords": [
        "Data valuation",
        "Reinforcement Learning",
        "Meta-learning framework",
        "Joint optimization",
        "Data value estimator",
        "Model-agnosticism",
        "Scalability",
        "Corrupted sample discovery",
        "Domain adaptation",
        "Robust learning",
        "REINFORCE algorithm",
        "Bi-level optimization",
        "Prior data valuation methods"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/17b6829678802a20e51558ec28c5369414defe42.pdf",
      "citation_key": "yoon2019k84",
      "metadata": {
        "title": "Data Valuation using Reinforcement Learning",
        "authors": [
          "Jinsung Yoon",
          "Sercan Ö. Arik",
          "Tomas Pfister"
        ],
        "published_date": "2019",
        "abstract": "Quantifying the value of data is a fundamental problem in machine learning. Data valuation has multiple important use cases: (1) building insights about the learning task, (2) domain adaptation, (3) corrupted sample discovery, and (4) robust learning. To adaptively learn data values jointly with the target task predictor model, we propose a meta learning framework which we name Data Valuation using Reinforcement Learning (DVRL). We employ a data value estimator (modeled by a deep neural network) to learn how likely each datum is used in training of the predictor model. We train the data value estimator using a reinforcement signal of the reward obtained on a small validation set that reflects performance on the target task. We demonstrate that DVRL yields superior data value estimates compared to alternative methods across different types of datasets and in a diverse set of application scenarios. The corrupted sample discovery performance of DVRL is close to optimal in many regimes (i.e. as if the noisy samples were known apriori), and for domain adaptation and robust learning DVRL significantly outperforms state-of-the-art by 14.6% and 10.8%, respectively.",
        "file_path": "paper_data/Deep_Meta-Learning/info/17b6829678802a20e51558ec28c5369414defe42.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 194,
        "score": 32.33333333333333,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION**: \\cite{yoon2019k84}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Quantifying the value of individual data samples in machine learning datasets.\n    *   **Importance and Challenge**:\n        *   Machine learning models benefit from large-scale, high-quality data, but collecting such data is costly and challenging.\n        *   Not all data samples are equally useful; low-quality, noisy, or irrelevant data can be detrimental to model performance.\n        *   Real-world datasets often contain incorrect labels, samples from different distributions (domain mismatch), or noisy inputs.\n        *   Evaluating the value of each datum is difficult, especially for complex models (e.g., deep neural networks) trained on large datasets, due to the intricate interactions between samples.\n        *   Accurate data valuation can enable use cases like building insights, domain adaptation, corrupted sample discovery, robust learning, optimizing data collection, and value-based data pricing.\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**:\n        *   **Leave-one-out (LOO)**: Quantifies value by removing a sample and measuring performance difference.\n        *   **Influence Function \\cite{koh2017understanding}**: Approximates LOO using gradients of the loss function with small perturbations.\n        *   **Data Shapley \\cite{ghorbani2019data}**: Game theory-based approach that considers marginal performance improvement across all possible data subsets.\n        *   **Meta-learning based adaptive learning**: Other works use meta-learning for adaptive weight assignment in robust learning, domain adaptation, and corrupted sample discovery (e.g., Learning to Reweight, MentorNet).\n    *   **Limitations of Previous Solutions**:\n        *   **Computational Cost**: LOO scales linearly with dataset size, becoming prohibitive for large datasets. Data Shapley is exponentially complex, even with Monte Carlo approximations, requiring re-training for many combinations. Influence Function requires expensive Hessian computations.\n        *   **Approximation Limitations**: LOO can underestimate the value of redundant samples. Approximations for Shapley values can lead to fundamental limitations in valuation performance.\n        *   **Decoupled Optimization**: Most prior data valuation methods (LOO, Influence Function, Data Shapley) decouple data valuation from the predictor model's training, limiting performance due to a lack of joint optimization.\n        *   **Model Specificity**: Some meta-learning approaches are not fully model-agnostic or directly model data value.\n    *   **DVRL's Positioning**: \\cite{yoon2019k84} proposes a novel meta-learning framework that *directly models the value of data using learnable neural networks* (a data value estimator) and *jointly optimizes* this estimator with the target task predictor model. It uses reinforcement learning to handle the non-differentiable sampling process, making it model-agnostic and applicable to non-differentiable objectives.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: Data Valuation using Reinforcement Learning (DVRL) is a meta-learning framework comprising two jointly optimized learnable functions:\n        1.  **Target Task Predictor Model (`f_theta`)**: A standard machine learning model (e.g., neural network) trained to minimize a weighted loss function, where weights are provided by the data value estimator.\n        2.  **Data Value Estimator Model (`h_phi`)**: A deep neural network that learns to output a selection probability (weight) `w = h_phi(x,y)` for each training sample `(x,y)`. These probabilities represent the likelihood of a datum being used in training and serve as its estimated value.\n    *   **Novelty/Difference**:\n        *   **Joint Optimization**: The data value estimator and the predictor model are optimized together. The predictor is trained using samples weighted by the estimator's output, and the estimator is trained to improve the predictor's performance on a small validation set.\n        *   **Reinforcement Learning for Valuation**: The sampling process (selecting data based on `h_phi`) is non-differentiable. \\cite{yoon2019k84} innovatively uses the REINFORCE algorithm to train the data value estimator. The \"reward\" signal for the reinforcement learning agent is derived from the predictor model's performance (loss) on a small, clean validation set, with a moving average baseline for stability.\n        *   **Model-Agnosticism**: The framework is designed to be applicable to various predictor models and even non-differentiable target objectives.\n        *   **Scalability**: Unlike previous methods, DVRL's computational complexity is not directly dependent on the training dataset size, making it scalable to large datasets and complex models.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: A novel meta-learning framework for data valuation that integrates a data value estimator with a target task predictor model.\n    *   **System Design/Architectural Innovations**: The use of a deep neural network as a data value estimator, trained via reinforcement learning, to generate sample-specific weights for the predictor model.\n    *   **Theoretical Insights/Analysis**: Formulation of data valuation as a bi-level optimization problem, solved through joint training with reinforcement learning for the non-differentiable component.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluation of data value estimation quality across various use cases: removing high/low value samples, corrupted sample discovery, domain adaptation, and robust learning.\n        *   Comparison against multiple benchmark methods.\n    *   **Datasets**: 12 public datasets, including tabular (Adult, Blog, Rossmann), image (MNIST, CIFAR-10/100, Flower, HAM 10000), and language (Email Spam, SMS Spam).\n    *   **Baseline Predictor Models**: Diverse models used to demonstrate model-agnosticism, including LightGBM, XGBoost, MLPs, Inception-v3, multinomial logistic regression, Naive Bayes, ResNet-32, and WideResNet-28-10.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **General Data Valuation**: DVRL marginally improved prediction performance by removing the least important samples (e.g., using 60-70% of data) even in conventional supervised settings, indicating accurate value estimation.\n        *   **Corrupted Sample Discovery**: DVRL's performance was \"close to optimal in many regimes\" (i.e., nearly as good as knowing noisy samples a priori).\n        *   **Domain Adaptation**: DVRL significantly outperformed state-of-the-art methods by **14.6%**.\n        *   **Robust Learning**: DVRL significantly outperformed state-of-the-art methods by **10.8%**.\n        *   **Scalability**: Demonstrated on large-scale datasets like CIFAR-100 with complex models (ResNet-32, WideResNet-28-10), showing its practical applicability.\n        *   **Benchmarks**: DVRL consistently yielded superior data value estimates compared to Random, Leave-one-out, Data Shapley, Learning to Reweight, MentorNet, and Influence Function across various scenarios.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The method relies on the availability of a small validation dataset from the target distribution to provide the reinforcement signal.\n    *   **Computational Overhead**: While significantly more scalable than alternatives, DVRL's training time overhead is stated to be \"only twice of conventional training,\" implying it still adds computational cost compared to training a predictor alone.\n    *   **Scope of Applicability**: Applicable to various machine learning tasks (classification, regression) and data types (tabular, image, language), and is model-agnostic.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{yoon2019k84} significantly advances the technical state-of-the-art in data valuation by introducing a scalable, jointly optimized, and model-agnostic framework. It overcomes the computational and fundamental limitations of prior methods like LOO and Data Shapley.\n    *   **Potential Impact on Future Research**:\n        *   Enables more efficient and robust machine learning by identifying and prioritizing valuable data, leading to better model performance with less data or in the presence of noise/domain shift.\n        *   Opens avenues for research into adaptive data collection strategies, automated data cleaning, and fair data pricing mechanisms.\n        *   The reinforcement learning approach for non-differentiable data selection could inspire similar meta-learning strategies in other areas of ML.",
        "keywords": [
          "Data valuation",
          "Reinforcement Learning",
          "Meta-learning framework",
          "Joint optimization",
          "Data value estimator",
          "Model-agnosticism",
          "Scalability",
          "Corrupted sample discovery",
          "Domain adaptation",
          "Robust learning",
          "REINFORCE algorithm",
          "Bi-level optimization",
          "Prior data valuation methods"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **\"we propose a meta learning framework which we name data valuation using reinforcement learning (dvrl)\"**: this is a direct indicator of presenting a new method or system.\n2.  **\"we employ a data value estimator (modeled by a deep neural network) to learn...\"**: describes the components and workings of the proposed method.\n3.  **\"we train the data value estimator using a reinforcement signal...\"**: explains the algorithm/training process of the new method.\n4.  **\"we demonstrate that dvrl yields superior data value estimates compared to alternative methods...\"** and **\"dvrl signiﬁcantly outperforms state-of-the-art by 14.6% and 10.8%, respectively.\"**: these are empirical results used to validate the effectiveness of the *proposed* method.\n\nthe core contribution described is the development and presentation of a new framework/method (dvrl). the empirical results serve to validate this technical contribution.\n\ntherefore, this paper best fits the **technical** classification."
      },
      "file_name": "17b6829678802a20e51558ec28c5369414defe42.pdf"
    },
    {
      "success": true,
      "doc_id": "1897300bfb1531d6298cd1e4451dcfdb",
      "summary": "Humans can continuously learn new knowledge as their experience grows. In contrast, previous learning in deep neural networks can quickly fade out when they are trained on a new task. In this paper, we hypothesize this problem can be avoided by learning a set of generalized parameters, that are neither specific to old nor new tasks. In this pursuit, we introduce a novel meta-learning approach that seeks to maintain an equilibrium between all the encountered tasks. This is ensured by a new meta-update rule which avoids catastrophic forgetting. In comparison to previous meta-learning techniques, our approach is task-agnostic. When presented with a continuum of data, our model automatically identifies the task and quickly adapts to it with just a single update. We perform extensive experiments on five datasets in a class-incremental setting, leading to significant improvements over the state of the art methods (e.g., a 21.3% boost on CIFAR100 with 10 incremental tasks). Specifically, on large-scale datasets that generally prove difficult cases for incremental learning, our approach delivers absolute gains as high as 19.1% and 7.4% on ImageNet and MS-Celeb datasets, respectively.",
      "intriguing_abstract": "Humans can continuously learn new knowledge as their experience grows. In contrast, previous learning in deep neural networks can quickly fade out when they are trained on a new task. In this paper, we hypothesize this problem can be avoided by learning a set of generalized parameters, that are neither specific to old nor new tasks. In this pursuit, we introduce a novel meta-learning approach that seeks to maintain an equilibrium between all the encountered tasks. This is ensured by a new meta-update rule which avoids catastrophic forgetting. In comparison to previous meta-learning techniques, our approach is task-agnostic. When presented with a continuum of data, our model automatically identifies the task and quickly adapts to it with just a single update. We perform extensive experiments on five datasets in a class-incremental setting, leading to significant improvements over the state of the art methods (e.g., a 21.3% boost on CIFAR100 with 10 incremental tasks). Specifically, on large-scale datasets that generally prove difficult cases for incremental learning, our approach delivers absolute gains as high as 19.1% and 7.4% on ImageNet and MS-Celeb datasets, respectively.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e95e3a314cab21171e206cd0824fe93c1c47677c.pdf",
      "citation_key": "rajasegaran2020llk",
      "metadata": {
        "title": "iTAML: An Incremental Task-Agnostic Meta-learning Approach",
        "authors": [
          "Jathushan Rajasegaran",
          "Salman Hameed Khan",
          "Munawar Hayat",
          "F. Khan",
          "M. Shah"
        ],
        "published_date": "2020",
        "abstract": "Humans can continuously learn new knowledge as their experience grows. In contrast, previous learning in deep neural networks can quickly fade out when they are trained on a new task. In this paper, we hypothesize this problem can be avoided by learning a set of generalized parameters, that are neither specific to old nor new tasks. In this pursuit, we introduce a novel meta-learning approach that seeks to maintain an equilibrium between all the encountered tasks. This is ensured by a new meta-update rule which avoids catastrophic forgetting. In comparison to previous meta-learning techniques, our approach is task-agnostic. When presented with a continuum of data, our model automatically identifies the task and quickly adapts to it with just a single update. We perform extensive experiments on five datasets in a class-incremental setting, leading to significant improvements over the state of the art methods (e.g., a 21.3% boost on CIFAR100 with 10 incremental tasks). Specifically, on large-scale datasets that generally prove difficult cases for incremental learning, our approach delivers absolute gains as high as 19.1% and 7.4% on ImageNet and MS-Celeb datasets, respectively.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e95e3a314cab21171e206cd0824fe93c1c47677c.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 159,
        "score": 31.8,
        "summary": "Humans can continuously learn new knowledge as their experience grows. In contrast, previous learning in deep neural networks can quickly fade out when they are trained on a new task. In this paper, we hypothesize this problem can be avoided by learning a set of generalized parameters, that are neither specific to old nor new tasks. In this pursuit, we introduce a novel meta-learning approach that seeks to maintain an equilibrium between all the encountered tasks. This is ensured by a new meta-update rule which avoids catastrophic forgetting. In comparison to previous meta-learning techniques, our approach is task-agnostic. When presented with a continuum of data, our model automatically identifies the task and quickly adapts to it with just a single update. We perform extensive experiments on five datasets in a class-incremental setting, leading to significant improvements over the state of the art methods (e.g., a 21.3% boost on CIFAR100 with 10 incremental tasks). Specifically, on large-scale datasets that generally prove difficult cases for incremental learning, our approach delivers absolute gains as high as 19.1% and 7.4% on ImageNet and MS-Celeb datasets, respectively.",
        "keywords": []
      },
      "file_name": "e95e3a314cab21171e206cd0824fe93c1c47677c.pdf"
    },
    {
      "success": true,
      "doc_id": "ac83acd44d8f2ca26d480d54556a44b1",
      "summary": "The ability to learn new concepts with small amounts of data is a critical aspect of intelligence that has proven challenging for deep learning methods. Meta-learning has emerged as a promising technique for leveraging data from previous tasks to enable efficient learning of new tasks. However, most meta-learning algorithms implicitly require that the meta-training tasks be mutually-exclusive, such that no single model can solve all of the tasks at once. For example, when creating tasks for few-shot image classification, prior work uses a per-task random assignment of image classes to N-way classification labels. If this is not done, the meta-learner can ignore the task training data and learn a single model that performs all of the meta-training tasks zero-shot, but does not adapt effectively to new image classes. This requirement means that the user must take great care in designing the tasks, for example by shuffling labels or removing task identifying information from the inputs. In some domains, this makes meta-learning entirely inapplicable. In this paper, we address this challenge by designing a meta-regularization objective using information theory that places precedence on data-driven adaptation. This causes the meta-learner to decide what must be learned from the task training data and what should be inferred from the task testing input. By doing so, our algorithm can successfully use data from non-mutually-exclusive tasks to efficiently adapt to novel tasks. We demonstrate its applicability to both contextual and gradient-based meta-learning algorithms, and apply it in practical settings where applying standard meta-learning has been difficult. Our approach substantially outperforms standard meta-learning algorithms in these settings.",
      "intriguing_abstract": "The ability to learn new concepts with small amounts of data is a critical aspect of intelligence that has proven challenging for deep learning methods. Meta-learning has emerged as a promising technique for leveraging data from previous tasks to enable efficient learning of new tasks. However, most meta-learning algorithms implicitly require that the meta-training tasks be mutually-exclusive, such that no single model can solve all of the tasks at once. For example, when creating tasks for few-shot image classification, prior work uses a per-task random assignment of image classes to N-way classification labels. If this is not done, the meta-learner can ignore the task training data and learn a single model that performs all of the meta-training tasks zero-shot, but does not adapt effectively to new image classes. This requirement means that the user must take great care in designing the tasks, for example by shuffling labels or removing task identifying information from the inputs. In some domains, this makes meta-learning entirely inapplicable. In this paper, we address this challenge by designing a meta-regularization objective using information theory that places precedence on data-driven adaptation. This causes the meta-learner to decide what must be learned from the task training data and what should be inferred from the task testing input. By doing so, our algorithm can successfully use data from non-mutually-exclusive tasks to efficiently adapt to novel tasks. We demonstrate its applicability to both contextual and gradient-based meta-learning algorithms, and apply it in practical settings where applying standard meta-learning has been difficult. Our approach substantially outperforms standard meta-learning algorithms in these settings.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/4bf9f88d438c7d978fb854eba686cf3933879df1.pdf",
      "citation_key": "yin2019cct",
      "metadata": {
        "title": "Meta-Learning without Memorization",
        "authors": [
          "Mingzhang Yin",
          "G. Tucker",
          "Mingyuan Zhou",
          "S. Levine",
          "Chelsea Finn"
        ],
        "published_date": "2019",
        "abstract": "The ability to learn new concepts with small amounts of data is a critical aspect of intelligence that has proven challenging for deep learning methods. Meta-learning has emerged as a promising technique for leveraging data from previous tasks to enable efficient learning of new tasks. However, most meta-learning algorithms implicitly require that the meta-training tasks be mutually-exclusive, such that no single model can solve all of the tasks at once. For example, when creating tasks for few-shot image classification, prior work uses a per-task random assignment of image classes to N-way classification labels. If this is not done, the meta-learner can ignore the task training data and learn a single model that performs all of the meta-training tasks zero-shot, but does not adapt effectively to new image classes. This requirement means that the user must take great care in designing the tasks, for example by shuffling labels or removing task identifying information from the inputs. In some domains, this makes meta-learning entirely inapplicable. In this paper, we address this challenge by designing a meta-regularization objective using information theory that places precedence on data-driven adaptation. This causes the meta-learner to decide what must be learned from the task training data and what should be inferred from the task testing input. By doing so, our algorithm can successfully use data from non-mutually-exclusive tasks to efficiently adapt to novel tasks. We demonstrate its applicability to both contextual and gradient-based meta-learning algorithms, and apply it in practical settings where applying standard meta-learning has been difficult. Our approach substantially outperforms standard meta-learning algorithms in these settings.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4bf9f88d438c7d978fb854eba686cf3933879df1.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 189,
        "score": 31.5,
        "summary": "The ability to learn new concepts with small amounts of data is a critical aspect of intelligence that has proven challenging for deep learning methods. Meta-learning has emerged as a promising technique for leveraging data from previous tasks to enable efficient learning of new tasks. However, most meta-learning algorithms implicitly require that the meta-training tasks be mutually-exclusive, such that no single model can solve all of the tasks at once. For example, when creating tasks for few-shot image classification, prior work uses a per-task random assignment of image classes to N-way classification labels. If this is not done, the meta-learner can ignore the task training data and learn a single model that performs all of the meta-training tasks zero-shot, but does not adapt effectively to new image classes. This requirement means that the user must take great care in designing the tasks, for example by shuffling labels or removing task identifying information from the inputs. In some domains, this makes meta-learning entirely inapplicable. In this paper, we address this challenge by designing a meta-regularization objective using information theory that places precedence on data-driven adaptation. This causes the meta-learner to decide what must be learned from the task training data and what should be inferred from the task testing input. By doing so, our algorithm can successfully use data from non-mutually-exclusive tasks to efficiently adapt to novel tasks. We demonstrate its applicability to both contextual and gradient-based meta-learning algorithms, and apply it in practical settings where applying standard meta-learning has been difficult. Our approach substantially outperforms standard meta-learning algorithms in these settings.",
        "keywords": []
      },
      "file_name": "4bf9f88d438c7d978fb854eba686cf3933879df1.pdf"
    },
    {
      "success": true,
      "doc_id": "bee25688e5f04917a10648cd71508a0a",
      "summary": "Few-shot learning, which aims at extracting new concepts rapidly from extremely few examples of novel classes, has been featured into the meta-learning paradigm recently. Yet, the key challenge of how to learn a generalizable classifier with the capability of adapting to specific tasks with severely limited data still remains in this domain. To this end, we propose a Transductive Episodic-wise Adaptive Metric (TEAM) framework for few-shot learning, by integrating the meta-learning paradigm with both deep metric learning and transductive inference. With exploring the pairwise constraints and regularization prior within each task, we explicitly formulate the adaptation procedure into a standard semi-definite programming problem. By solving the problem with its closed-form solution on the fly with the setup of transduction, our approach efficiently tailors an episodic-wise metric for each task to adapt all features from a shared task-agnostic embedding space into a more discriminative task-specific metric space. Moreover, we further leverage an attention-based bi-directional similarity strategy for extracting the more robust relationship between queries and prototypes. Extensive experiments on three benchmark datasets show that our framework is superior to other existing approaches and achieves the state-of-the-art performance in the few-shot literature.",
      "intriguing_abstract": "Few-shot learning, which aims at extracting new concepts rapidly from extremely few examples of novel classes, has been featured into the meta-learning paradigm recently. Yet, the key challenge of how to learn a generalizable classifier with the capability of adapting to specific tasks with severely limited data still remains in this domain. To this end, we propose a Transductive Episodic-wise Adaptive Metric (TEAM) framework for few-shot learning, by integrating the meta-learning paradigm with both deep metric learning and transductive inference. With exploring the pairwise constraints and regularization prior within each task, we explicitly formulate the adaptation procedure into a standard semi-definite programming problem. By solving the problem with its closed-form solution on the fly with the setup of transduction, our approach efficiently tailors an episodic-wise metric for each task to adapt all features from a shared task-agnostic embedding space into a more discriminative task-specific metric space. Moreover, we further leverage an attention-based bi-directional similarity strategy for extracting the more robust relationship between queries and prototypes. Extensive experiments on three benchmark datasets show that our framework is superior to other existing approaches and achieves the state-of-the-art performance in the few-shot literature.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/38b547a2cf81bacd30cbb322e7279091753604dc.pdf",
      "citation_key": "qiao2019p6r",
      "metadata": {
        "title": "Transductive Episodic-Wise Adaptive Metric for Few-Shot Learning",
        "authors": [
          "Limeng Qiao",
          "Yemin Shi",
          "Jia Li",
          "Yaowei Wang",
          "Tiejun Huang",
          "Yonghong Tian"
        ],
        "published_date": "2019",
        "abstract": "Few-shot learning, which aims at extracting new concepts rapidly from extremely few examples of novel classes, has been featured into the meta-learning paradigm recently. Yet, the key challenge of how to learn a generalizable classifier with the capability of adapting to specific tasks with severely limited data still remains in this domain. To this end, we propose a Transductive Episodic-wise Adaptive Metric (TEAM) framework for few-shot learning, by integrating the meta-learning paradigm with both deep metric learning and transductive inference. With exploring the pairwise constraints and regularization prior within each task, we explicitly formulate the adaptation procedure into a standard semi-definite programming problem. By solving the problem with its closed-form solution on the fly with the setup of transduction, our approach efficiently tailors an episodic-wise metric for each task to adapt all features from a shared task-agnostic embedding space into a more discriminative task-specific metric space. Moreover, we further leverage an attention-based bi-directional similarity strategy for extracting the more robust relationship between queries and prototypes. Extensive experiments on three benchmark datasets show that our framework is superior to other existing approaches and achieves the state-of-the-art performance in the few-shot literature.",
        "file_path": "paper_data/Deep_Meta-Learning/info/38b547a2cf81bacd30cbb322e7279091753604dc.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 186,
        "score": 31.0,
        "summary": "Few-shot learning, which aims at extracting new concepts rapidly from extremely few examples of novel classes, has been featured into the meta-learning paradigm recently. Yet, the key challenge of how to learn a generalizable classifier with the capability of adapting to specific tasks with severely limited data still remains in this domain. To this end, we propose a Transductive Episodic-wise Adaptive Metric (TEAM) framework for few-shot learning, by integrating the meta-learning paradigm with both deep metric learning and transductive inference. With exploring the pairwise constraints and regularization prior within each task, we explicitly formulate the adaptation procedure into a standard semi-definite programming problem. By solving the problem with its closed-form solution on the fly with the setup of transduction, our approach efficiently tailors an episodic-wise metric for each task to adapt all features from a shared task-agnostic embedding space into a more discriminative task-specific metric space. Moreover, we further leverage an attention-based bi-directional similarity strategy for extracting the more robust relationship between queries and prototypes. Extensive experiments on three benchmark datasets show that our framework is superior to other existing approaches and achieves the state-of-the-art performance in the few-shot literature.",
        "keywords": []
      },
      "file_name": "38b547a2cf81bacd30cbb322e7279091753604dc.pdf"
    },
    {
      "success": true,
      "doc_id": "c229e80fac4949dfbc5a4af65d796c92",
      "summary": "Deep learning has achieved great success in hyperspectral image classification. However, when processing new hyperspectral images, the existing deep learning models must be retrained from scratch with sufficient samples, which is inefficient and undesirable in practical tasks. This paper aims to explore how to accurately classify new hyperspectral images with only a few labeled samples, i.e., the hyperspectral images few-shot classification. Specifically, we design a new deep classification model based on relational network and train it with the idea of meta-learning. Firstly, the feature learning module and the relation learning module of the model can make full use of the spatial–spectral information in hyperspectral images and carry out relation learning by comparing the similarity between samples. Secondly, the task-based learning strategy can enable the model to continuously enhance its ability to learn how to learn with a large number of tasks randomly generated from different data sets. Benefitting from the above two points, the proposed method has excellent generalization ability and can obtain satisfactory classification results with only a few labeled samples. In order to verify the performance of the proposed method, experiments were carried out on three public data sets. The results indicate that the proposed method can achieve better classification results than the traditional semisupervised support vector machine and semisupervised deep learning models.",
      "intriguing_abstract": "Deep learning has achieved great success in hyperspectral image classification. However, when processing new hyperspectral images, the existing deep learning models must be retrained from scratch with sufficient samples, which is inefficient and undesirable in practical tasks. This paper aims to explore how to accurately classify new hyperspectral images with only a few labeled samples, i.e., the hyperspectral images few-shot classification. Specifically, we design a new deep classification model based on relational network and train it with the idea of meta-learning. Firstly, the feature learning module and the relation learning module of the model can make full use of the spatial–spectral information in hyperspectral images and carry out relation learning by comparing the similarity between samples. Secondly, the task-based learning strategy can enable the model to continuously enhance its ability to learn how to learn with a large number of tasks randomly generated from different data sets. Benefitting from the above two points, the proposed method has excellent generalization ability and can obtain satisfactory classification results with only a few labeled samples. In order to verify the performance of the proposed method, experiments were carried out on three public data sets. The results indicate that the proposed method can achieve better classification results than the traditional semisupervised support vector machine and semisupervised deep learning models.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/f68020d22d9895d0d7f173b14961459395f96861.pdf",
      "citation_key": "gao2020h75",
      "metadata": {
        "title": "Deep Relation Network for Hyperspectral Image Few-Shot Classification",
        "authors": [
          "Kuiliang Gao",
          "Bing Liu",
          "Xuchu Yu",
          "Jinchun Qin",
          "Pengqiang Zhang",
          "Xiong Tan"
        ],
        "published_date": "2020",
        "abstract": "Deep learning has achieved great success in hyperspectral image classification. However, when processing new hyperspectral images, the existing deep learning models must be retrained from scratch with sufficient samples, which is inefficient and undesirable in practical tasks. This paper aims to explore how to accurately classify new hyperspectral images with only a few labeled samples, i.e., the hyperspectral images few-shot classification. Specifically, we design a new deep classification model based on relational network and train it with the idea of meta-learning. Firstly, the feature learning module and the relation learning module of the model can make full use of the spatial–spectral information in hyperspectral images and carry out relation learning by comparing the similarity between samples. Secondly, the task-based learning strategy can enable the model to continuously enhance its ability to learn how to learn with a large number of tasks randomly generated from different data sets. Benefitting from the above two points, the proposed method has excellent generalization ability and can obtain satisfactory classification results with only a few labeled samples. In order to verify the performance of the proposed method, experiments were carried out on three public data sets. The results indicate that the proposed method can achieve better classification results than the traditional semisupervised support vector machine and semisupervised deep learning models.",
        "file_path": "paper_data/Deep_Meta-Learning/info/f68020d22d9895d0d7f173b14961459395f96861.pdf",
        "venue": "Remote Sensing",
        "citationCount": 143,
        "score": 28.6,
        "summary": "Deep learning has achieved great success in hyperspectral image classification. However, when processing new hyperspectral images, the existing deep learning models must be retrained from scratch with sufficient samples, which is inefficient and undesirable in practical tasks. This paper aims to explore how to accurately classify new hyperspectral images with only a few labeled samples, i.e., the hyperspectral images few-shot classification. Specifically, we design a new deep classification model based on relational network and train it with the idea of meta-learning. Firstly, the feature learning module and the relation learning module of the model can make full use of the spatial–spectral information in hyperspectral images and carry out relation learning by comparing the similarity between samples. Secondly, the task-based learning strategy can enable the model to continuously enhance its ability to learn how to learn with a large number of tasks randomly generated from different data sets. Benefitting from the above two points, the proposed method has excellent generalization ability and can obtain satisfactory classification results with only a few labeled samples. In order to verify the performance of the proposed method, experiments were carried out on three public data sets. The results indicate that the proposed method can achieve better classification results than the traditional semisupervised support vector machine and semisupervised deep learning models.",
        "keywords": []
      },
      "file_name": "f68020d22d9895d0d7f173b14961459395f96861.pdf"
    },
    {
      "success": true,
      "doc_id": "99df3a4f7395396df6e3d581c9ab8cde",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/1ae1c18632d6d4d61b70c918354d633ce24c0bcd.pdf",
      "citation_key": "patacchiola2020kpq",
      "metadata": {
        "title": "Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels",
        "authors": [
          "Massimiliano Patacchiola",
          "Jack Turner",
          "Elliot J. Crowley",
          "M. O’Boyle",
          "A. Storkey"
        ],
        "published_date": "2020",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/1ae1c18632d6d4d61b70c918354d633ce24c0bcd.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 141,
        "score": 28.200000000000003,
        "summary": "",
        "keywords": []
      },
      "file_name": "1ae1c18632d6d4d61b70c918354d633ce24c0bcd.pdf"
    },
    {
      "success": true,
      "doc_id": "827d3dfefdccdead3acd57960c55bf50",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Focused Summary for Literature Review: Deep Online Learning via Meta-Learning\n\nThis paper, \"Deep Online Learning via Meta-Learning: Continual Adaptation for Model-Based RL\" by Nagabandi, Finn, and Levine \\cite{nagabandi2018esl}, addresses the critical challenge of enabling deep neural network models to perform rapid and continual online adaptation in dynamic, non-stationary environments.\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep neural network models, despite their representational power, struggle with rapid online adaptation to streaming data, especially in non-stationary task distributions where tasks change over time and their boundaries are unknown.\n    *   **Importance & Challenge**: Real-world intelligent systems (e.g., robots) operate in constantly changing environments (varying terrains, motor failures, unexpected disturbances). Humans and animals adapt quickly, but deep models typically require large minibatches and multiple epochs for effective training, making them unsuitable for fast, continuous online learning from single data points. The challenge lies in achieving both rapid adaptation and the ability to recall prior knowledge while specializing in new tasks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Online Learning**: Builds on traditional online SGD \\cite{nagabandi2018esl}, but addresses its limitations with deep neural networks.\n        *   **Continual/Lifelong Learning**: Related to handling non-stationary task distributions but differs by focusing on rapid online adaptation rather than primarily avoiding catastrophic forgetting or forward transfer over small, distinct task sets \\cite{nagabandi2018esl}.\n        *   **Meta-Learning (MAML)**: Extends MAML \\cite{nagabandi2018esl} which learns a good prior for few-shot adaptation.\n        *   **Model-Based Meta-RL**: Improves upon prior k-shot model-based meta-RL methods (e.g., Nagabandi et al., 2018, referenced in the paper) that perform batch-mode updates from a fixed prior, discarding previous adaptations \\cite{nagabandi2018esl}.\n    *   **Limitations of Previous Solutions**:\n        *   Traditional online SGD is ineffective for deep neural networks due to their high dimensionality and need for batch training \\cite{nagabandi2018esl}.\n        *   Most meta-learning approaches focus on learning one task at a time from a single batch of data, not continuous streams or unknown task boundaries \\cite{nagabandi2018esl}.\n        *   Prior model-based meta-RL methods are limited to k-shot adaptation, resetting the model at each step and thus not enabling continual online adaptation or knowledge evolution \\cite{nagabandi2018esl}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **Meta-learning for Online Learning (MOLe)** \\cite{nagabandi2018esl}.\n        *   It uses **online Stochastic Gradient Descent (SGD)** for parameter updates.\n        *   An **Expectation-Maximization (EM) algorithm** is employed to maintain and adapt a mixture of deep neural network models, each specialized for a different task.\n        *   A **Chinese Restaurant Process (CRP) prior** is integrated into the EM framework to dynamically instantiate new models (tasks) as needed and recall old ones when previously seen tasks reappear \\cite{nagabandi2018esl}.\n        *   Crucially, **Model-Agnostic Meta-Learning (MAML)** is used to meta-train a prior initialization for the model parameters. This meta-learned prior makes direct online adaptation with SGD effective for deep networks, which would otherwise be challenging \\cite{nagabandi2018esl}.\n    *   **Novelty/Difference**: The key innovation is the synergistic combination of meta-learning (MAML) to enable effective online SGD for deep models, with an EM-CRP framework for managing a dynamic mixture of models in a continually adapting, non-stationary environment. This allows for both rapid adaptation and the accumulation/recall of task-specific knowledge without requiring explicit task delineations \\cite{nagabandi2018esl}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of the MOLe algorithm, which integrates MAML, EM, and CRP for continual online adaptation of deep neural networks \\cite{nagabandi2018esl}.\n    *   **Adaptive Mixture Model**: A method for maintaining a probabilistic mixture of neural network models, allowing for natural task specialization and recall, with dynamic instantiation of new tasks via a CRP prior \\cite{nagabandi2018esl}.\n    *   **Enabling Online SGD for Deep Nets**: Demonstrating that a MAML-trained prior can make online SGD effective for deep neural networks in a streaming data setting, overcoming a significant practical limitation \\cite{nagabandi2018esl}.\n    *   **Application to Model-Based RL**: A robust framework for continuous model adaptation in model-based reinforcement learning, critical for control in dynamic environments \\cite{nagabandi2018esl}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Evaluated MOLe in the context of model-based RL on a suite of challenging simulated robotic tasks.\n    *   **Robotic Agents**: Experiments involved a half-cheetah agent and a hexapedal crawler robot \\cite{nagabandi2018esl}.\n    *   **Non-Stationary Scenarios**: Tasks included continuous model adaptation in environments with varying terrains (e.g., uphill/downhill slopes), unexpected disturbances, and simulated motor failures \\cite{nagabandi2018esl}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   MOLe demonstrated online instantiation of new tasks, effective adaptation to out-of-distribution tasks, and the ability to recognize and revert to prior tasks \\cite{nagabandi2018esl}.\n        *   It significantly outperformed a state-of-the-art k-shot model-based meta-RL method (Nagabandi et al., 2018, referenced in the paper) \\cite{nagabandi2018esl}.\n        *   MOLe also outperformed natural baselines, including continuous gradient updates for adaptation and online learning without meta-training \\cite{nagabandi2018esl}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The EM algorithm is approximated by performing E and M steps only once per time step, without rolling back previous gradient updates, which is a simplification but deemed reasonable due to temporal correlation in online data \\cite{nagabandi2018esl}.\n    *   **Scope of Applicability**: While demonstrated in model-based RL, the approach is formulated generally for arbitrary online prediction problems with streaming data and non-stationary task distributions \\cite{nagabandi2018esl}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: MOLe significantly advances the state-of-the-art in online learning for deep neural networks by enabling them to adapt rapidly and continually in complex, non-stationary environments \\cite{nagabandi2018esl}.\n    *   **Potential Impact**: This work has substantial potential impact on future research in adaptive control, robotics, and other real-world intelligent systems where continuous learning and adaptation to unforeseen changes are paramount. It bridges the gap between powerful deep learning models and the demands of dynamic online learning scenarios \\cite{nagabandi2018esl}.",
      "intriguing_abstract": "Deep neural networks, despite their power, fundamentally struggle with the relentless dynamism of real-world environments, demanding rapid and continual online adaptation to streaming data. We introduce **Meta-learning for Online Learning (MOLe)**, a novel framework that enables deep models to continually adapt to non-stationary task distributions, mimicking human-like flexibility.\n\nMOLe synergistically combines **Model-Agnostic Meta-Learning (MAML)** to meta-train a robust prior, making **online Stochastic Gradient Descent (SGD)** effective for deep networks—a critical breakthrough. This is coupled with an **Expectation-Maximization (EM) algorithm** and a **Chinese Restaurant Process (CRP) prior** to dynamically manage a probabilistic mixture of specialized deep models. This unique architecture allows for the seamless instantiation of new tasks and the intelligent recall of previously encountered ones, all without requiring explicit task boundaries.\n\nDemonstrated in **model-based reinforcement learning** for **robotics**, MOLe empowers agents to rapidly adapt to varying terrains, unexpected disturbances, and simulated motor failures. Our experiments show MOLe significantly outperforms state-of-the-art k-shot meta-RL methods, bridging a critical gap between powerful deep learning and the demands of **continual adaptation** in complex, real-world intelligent systems.",
      "keywords": [
        "Deep Online Learning via Meta-Learning (MOLe)",
        "Rapid continual online adaptation",
        "Non-stationary environments",
        "Model-Agnostic Meta-Learning (MAML)",
        "Online Stochastic Gradient Descent (SGD)",
        "Expectation-Maximization (EM) algorithm",
        "Chinese Restaurant Process (CRP) prior",
        "Mixture of deep neural network models",
        "Model-Based Reinforcement Learning",
        "Dynamic task instantiation and recall",
        "Enabling online SGD for deep networks",
        "Robotics",
        "Streaming data",
        "Out-of-distribution task adaptation"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/42de54e614110c0c0a0bbbfee045e11e53eb4a7d.pdf",
      "citation_key": "nagabandi2018esl",
      "metadata": {
        "title": "Deep Online Learning via Meta-Learning: Continual Adaptation for Model-Based RL",
        "authors": [
          "Anusha Nagabandi",
          "Chelsea Finn",
          "S. Levine"
        ],
        "published_date": "2018",
        "abstract": "Humans and animals can learn complex predictive models that allow them to accurately and reliably reason about real-world phenomena, and they can adapt such models extremely quickly in the face of unexpected changes. Deep neural network models allow us to represent very complex functions, but lack this capacity for rapid online adaptation. The goal in this paper is to develop a method for continual online learning from an incoming stream of data, using deep neural network models. We formulate an online learning procedure that uses stochastic gradient descent to update model parameters, and an expectation maximization algorithm with a Chinese restaurant process prior to develop and maintain a mixture of models to handle non-stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. Furthermore, we observe that meta-learning can be used to meta-train a model such that this direct online adaptation with SGD is effective, which is otherwise not the case for large function approximators. In this work, we apply our meta-learning for online learning (MOLe) approach to model-based reinforcement learning, where adapting the predictive model is critical for control; we demonstrate that MOLe outperforms alternative prior methods, and enables effective continuous adaptation in non-stationary task distributions such as varying terrains, motor failures, and unexpected disturbances.",
        "file_path": "paper_data/Deep_Meta-Learning/info/42de54e614110c0c0a0bbbfee045e11e53eb4a7d.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 196,
        "score": 28.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Focused Summary for Literature Review: Deep Online Learning via Meta-Learning\n\nThis paper, \"Deep Online Learning via Meta-Learning: Continual Adaptation for Model-Based RL\" by Nagabandi, Finn, and Levine \\cite{nagabandi2018esl}, addresses the critical challenge of enabling deep neural network models to perform rapid and continual online adaptation in dynamic, non-stationary environments.\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep neural network models, despite their representational power, struggle with rapid online adaptation to streaming data, especially in non-stationary task distributions where tasks change over time and their boundaries are unknown.\n    *   **Importance & Challenge**: Real-world intelligent systems (e.g., robots) operate in constantly changing environments (varying terrains, motor failures, unexpected disturbances). Humans and animals adapt quickly, but deep models typically require large minibatches and multiple epochs for effective training, making them unsuitable for fast, continuous online learning from single data points. The challenge lies in achieving both rapid adaptation and the ability to recall prior knowledge while specializing in new tasks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **Online Learning**: Builds on traditional online SGD \\cite{nagabandi2018esl}, but addresses its limitations with deep neural networks.\n        *   **Continual/Lifelong Learning**: Related to handling non-stationary task distributions but differs by focusing on rapid online adaptation rather than primarily avoiding catastrophic forgetting or forward transfer over small, distinct task sets \\cite{nagabandi2018esl}.\n        *   **Meta-Learning (MAML)**: Extends MAML \\cite{nagabandi2018esl} which learns a good prior for few-shot adaptation.\n        *   **Model-Based Meta-RL**: Improves upon prior k-shot model-based meta-RL methods (e.g., Nagabandi et al., 2018, referenced in the paper) that perform batch-mode updates from a fixed prior, discarding previous adaptations \\cite{nagabandi2018esl}.\n    *   **Limitations of Previous Solutions**:\n        *   Traditional online SGD is ineffective for deep neural networks due to their high dimensionality and need for batch training \\cite{nagabandi2018esl}.\n        *   Most meta-learning approaches focus on learning one task at a time from a single batch of data, not continuous streams or unknown task boundaries \\cite{nagabandi2018esl}.\n        *   Prior model-based meta-RL methods are limited to k-shot adaptation, resetting the model at each step and thus not enabling continual online adaptation or knowledge evolution \\cite{nagabandi2018esl}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **Meta-learning for Online Learning (MOLe)** \\cite{nagabandi2018esl}.\n        *   It uses **online Stochastic Gradient Descent (SGD)** for parameter updates.\n        *   An **Expectation-Maximization (EM) algorithm** is employed to maintain and adapt a mixture of deep neural network models, each specialized for a different task.\n        *   A **Chinese Restaurant Process (CRP) prior** is integrated into the EM framework to dynamically instantiate new models (tasks) as needed and recall old ones when previously seen tasks reappear \\cite{nagabandi2018esl}.\n        *   Crucially, **Model-Agnostic Meta-Learning (MAML)** is used to meta-train a prior initialization for the model parameters. This meta-learned prior makes direct online adaptation with SGD effective for deep networks, which would otherwise be challenging \\cite{nagabandi2018esl}.\n    *   **Novelty/Difference**: The key innovation is the synergistic combination of meta-learning (MAML) to enable effective online SGD for deep models, with an EM-CRP framework for managing a dynamic mixture of models in a continually adapting, non-stationary environment. This allows for both rapid adaptation and the accumulation/recall of task-specific knowledge without requiring explicit task delineations \\cite{nagabandi2018esl}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of the MOLe algorithm, which integrates MAML, EM, and CRP for continual online adaptation of deep neural networks \\cite{nagabandi2018esl}.\n    *   **Adaptive Mixture Model**: A method for maintaining a probabilistic mixture of neural network models, allowing for natural task specialization and recall, with dynamic instantiation of new tasks via a CRP prior \\cite{nagabandi2018esl}.\n    *   **Enabling Online SGD for Deep Nets**: Demonstrating that a MAML-trained prior can make online SGD effective for deep neural networks in a streaming data setting, overcoming a significant practical limitation \\cite{nagabandi2018esl}.\n    *   **Application to Model-Based RL**: A robust framework for continuous model adaptation in model-based reinforcement learning, critical for control in dynamic environments \\cite{nagabandi2018esl}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: Evaluated MOLe in the context of model-based RL on a suite of challenging simulated robotic tasks.\n    *   **Robotic Agents**: Experiments involved a half-cheetah agent and a hexapedal crawler robot \\cite{nagabandi2018esl}.\n    *   **Non-Stationary Scenarios**: Tasks included continuous model adaptation in environments with varying terrains (e.g., uphill/downhill slopes), unexpected disturbances, and simulated motor failures \\cite{nagabandi2018esl}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   MOLe demonstrated online instantiation of new tasks, effective adaptation to out-of-distribution tasks, and the ability to recognize and revert to prior tasks \\cite{nagabandi2018esl}.\n        *   It significantly outperformed a state-of-the-art k-shot model-based meta-RL method (Nagabandi et al., 2018, referenced in the paper) \\cite{nagabandi2018esl}.\n        *   MOLe also outperformed natural baselines, including continuous gradient updates for adaptation and online learning without meta-training \\cite{nagabandi2018esl}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The EM algorithm is approximated by performing E and M steps only once per time step, without rolling back previous gradient updates, which is a simplification but deemed reasonable due to temporal correlation in online data \\cite{nagabandi2018esl}.\n    *   **Scope of Applicability**: While demonstrated in model-based RL, the approach is formulated generally for arbitrary online prediction problems with streaming data and non-stationary task distributions \\cite{nagabandi2018esl}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: MOLe significantly advances the state-of-the-art in online learning for deep neural networks by enabling them to adapt rapidly and continually in complex, non-stationary environments \\cite{nagabandi2018esl}.\n    *   **Potential Impact**: This work has substantial potential impact on future research in adaptive control, robotics, and other real-world intelligent systems where continuous learning and adaptation to unforeseen changes are paramount. It bridges the gap between powerful deep learning models and the demands of dynamic online learning scenarios \\cite{nagabandi2018esl}.",
        "keywords": [
          "Deep Online Learning via Meta-Learning (MOLe)",
          "Rapid continual online adaptation",
          "Non-stationary environments",
          "Model-Agnostic Meta-Learning (MAML)",
          "Online Stochastic Gradient Descent (SGD)",
          "Expectation-Maximization (EM) algorithm",
          "Chinese Restaurant Process (CRP) prior",
          "Mixture of deep neural network models",
          "Model-Based Reinforcement Learning",
          "Dynamic task instantiation and recall",
          "Enabling online SGD for deep networks",
          "Robotics",
          "Streaming data",
          "Out-of-distribution task adaptation"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"the goal in this paper is to **develop a method** for continual online learning...\", \"we **formulate an online learning procedure**...\", \"we **apply our meta-learning for online learning (mole) approach**...\".\n*   the introduction further elaborates on this proposed approach and its application.\n*   the paper describes specific algorithms and components: \"stochastic gradient descent\", \"expectation maximization algorithm with a chinese restaurant process prior\", \"meta-learning\".\n*   it also mentions demonstrating that \"mole outperforms alternative prior methods\", which indicates an empirical evaluation of the proposed method.\n\nthese phrases strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems. while it includes empirical validation, the primary contribution described is the development and presentation of a novel approach.\n\n**classification: technical**"
      },
      "file_name": "42de54e614110c0c0a0bbbfee045e11e53eb4a7d.pdf"
    },
    {
      "success": true,
      "doc_id": "c0a7a7117fc699ed1e49fcf54a50989f",
      "summary": "Learning to learn is a powerful paradigm for enabling models to learn from data more effectively and efficiently. A popular approach to meta-learning is to train a recurrent model to read in a training dataset as input and output the parameters of a learned model, or output predictions for new test inputs. Alternatively, a more recent approach to meta-learning aims to acquire deep representations that can be effectively fine-tuned, via standard gradient descent, to new tasks. In this paper, we consider the meta-learning problem from the perspective of universality, formalizing the notion of learning algorithm approximation and comparing the expressive power of the aforementioned recurrent models to the more recent approaches that embed gradient descent into the meta-learner. In particular, we seek to answer the following question: does deep representation combined with standard gradient descent have sufficient capacity to approximate any learning algorithm? We find that this is indeed true, and further find, in our experiments, that gradient-based meta-learning consistently leads to learning strategies that generalize more widely compared to those represented by recurrent models.",
      "intriguing_abstract": "Learning to learn is a powerful paradigm for enabling models to learn from data more effectively and efficiently. A popular approach to meta-learning is to train a recurrent model to read in a training dataset as input and output the parameters of a learned model, or output predictions for new test inputs. Alternatively, a more recent approach to meta-learning aims to acquire deep representations that can be effectively fine-tuned, via standard gradient descent, to new tasks. In this paper, we consider the meta-learning problem from the perspective of universality, formalizing the notion of learning algorithm approximation and comparing the expressive power of the aforementioned recurrent models to the more recent approaches that embed gradient descent into the meta-learner. In particular, we seek to answer the following question: does deep representation combined with standard gradient descent have sufficient capacity to approximate any learning algorithm? We find that this is indeed true, and further find, in our experiments, that gradient-based meta-learning consistently leads to learning strategies that generalize more widely compared to those represented by recurrent models.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2bdebf2fb0f5c21907fcaae6d87c7ba5811e778a.pdf",
      "citation_key": "finn2017vrt",
      "metadata": {
        "title": "Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm",
        "authors": [
          "Chelsea Finn",
          "S. Levine"
        ],
        "published_date": "2017",
        "abstract": "Learning to learn is a powerful paradigm for enabling models to learn from data more effectively and efficiently. A popular approach to meta-learning is to train a recurrent model to read in a training dataset as input and output the parameters of a learned model, or output predictions for new test inputs. Alternatively, a more recent approach to meta-learning aims to acquire deep representations that can be effectively fine-tuned, via standard gradient descent, to new tasks. In this paper, we consider the meta-learning problem from the perspective of universality, formalizing the notion of learning algorithm approximation and comparing the expressive power of the aforementioned recurrent models to the more recent approaches that embed gradient descent into the meta-learner. In particular, we seek to answer the following question: does deep representation combined with standard gradient descent have sufficient capacity to approximate any learning algorithm? We find that this is indeed true, and further find, in our experiments, that gradient-based meta-learning consistently leads to learning strategies that generalize more widely compared to those represented by recurrent models.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2bdebf2fb0f5c21907fcaae6d87c7ba5811e778a.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 223,
        "score": 27.875,
        "summary": "Learning to learn is a powerful paradigm for enabling models to learn from data more effectively and efficiently. A popular approach to meta-learning is to train a recurrent model to read in a training dataset as input and output the parameters of a learned model, or output predictions for new test inputs. Alternatively, a more recent approach to meta-learning aims to acquire deep representations that can be effectively fine-tuned, via standard gradient descent, to new tasks. In this paper, we consider the meta-learning problem from the perspective of universality, formalizing the notion of learning algorithm approximation and comparing the expressive power of the aforementioned recurrent models to the more recent approaches that embed gradient descent into the meta-learner. In particular, we seek to answer the following question: does deep representation combined with standard gradient descent have sufficient capacity to approximate any learning algorithm? We find that this is indeed true, and further find, in our experiments, that gradient-based meta-learning consistently leads to learning strategies that generalize more widely compared to those represented by recurrent models.",
        "keywords": []
      },
      "file_name": "2bdebf2fb0f5c21907fcaae6d87c7ba5811e778a.pdf"
    },
    {
      "success": true,
      "doc_id": "efddc285b40d3d615566fa1247d3640f",
      "summary": "This paper investigates the intriguing question of whether we can create learning algorithms that automatically generate training data, learning environments, and curricula in order to help AI agents rapidly learn. We show that such algorithms are possible via Generative Teaching Networks (GTNs), a general approach that is, in theory, applicable to supervised, unsupervised, and reinforcement learning, although our experiments only focus on the supervised case. GTNs are deep neural networks that generate data and/or training environments that a learner (e.g. a freshly initialized neural network) trains on for a few SGD steps before being tested on a target task. We then differentiate through the entire learning process via meta-gradients to update the GTN parameters to improve performance on the target task. GTNs have the beneficial property that they can theoretically generate any type of data or training environment, making their potential impact large. This paper introduces GTNs, discusses their potential, and showcases that they can substantially accelerate learning. We also demonstrate a practical and exciting application of GTNs: accelerating the evaluation of candidate architectures for neural architecture search (NAS), which is rate-limited by such evaluations, enabling massive speed-ups in NAS. GTN-NAS improves the NAS state of the art, finding higher performing architectures when controlling for the search proposal mechanism. GTN-NAS also is competitive with the overall state of the art approaches, which achieve top performance while using orders of magnitude less computation than typical NAS methods. Speculating forward, GTNs may represent a first step toward the ambitious goal of algorithms that generate their own training data and, in doing so, open a variety of interesting new research questions and directions.",
      "intriguing_abstract": "This paper investigates the intriguing question of whether we can create learning algorithms that automatically generate training data, learning environments, and curricula in order to help AI agents rapidly learn. We show that such algorithms are possible via Generative Teaching Networks (GTNs), a general approach that is, in theory, applicable to supervised, unsupervised, and reinforcement learning, although our experiments only focus on the supervised case. GTNs are deep neural networks that generate data and/or training environments that a learner (e.g. a freshly initialized neural network) trains on for a few SGD steps before being tested on a target task. We then differentiate through the entire learning process via meta-gradients to update the GTN parameters to improve performance on the target task. GTNs have the beneficial property that they can theoretically generate any type of data or training environment, making their potential impact large. This paper introduces GTNs, discusses their potential, and showcases that they can substantially accelerate learning. We also demonstrate a practical and exciting application of GTNs: accelerating the evaluation of candidate architectures for neural architecture search (NAS), which is rate-limited by such evaluations, enabling massive speed-ups in NAS. GTN-NAS improves the NAS state of the art, finding higher performing architectures when controlling for the search proposal mechanism. GTN-NAS also is competitive with the overall state of the art approaches, which achieve top performance while using orders of magnitude less computation than typical NAS methods. Speculating forward, GTNs may represent a first step toward the ambitious goal of algorithms that generate their own training data and, in doing so, open a variety of interesting new research questions and directions.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/16a3dd5ab3e8570f6083ddf6f88aa5e916450fef.pdf",
      "citation_key": "such2019xok",
      "metadata": {
        "title": "Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data",
        "authors": [
          "F. Such",
          "Aditya Rawal",
          "J. Lehman",
          "Kenneth O. Stanley",
          "J. Clune"
        ],
        "published_date": "2019",
        "abstract": "This paper investigates the intriguing question of whether we can create learning algorithms that automatically generate training data, learning environments, and curricula in order to help AI agents rapidly learn. We show that such algorithms are possible via Generative Teaching Networks (GTNs), a general approach that is, in theory, applicable to supervised, unsupervised, and reinforcement learning, although our experiments only focus on the supervised case. GTNs are deep neural networks that generate data and/or training environments that a learner (e.g. a freshly initialized neural network) trains on for a few SGD steps before being tested on a target task. We then differentiate through the entire learning process via meta-gradients to update the GTN parameters to improve performance on the target task. GTNs have the beneficial property that they can theoretically generate any type of data or training environment, making their potential impact large. This paper introduces GTNs, discusses their potential, and showcases that they can substantially accelerate learning. We also demonstrate a practical and exciting application of GTNs: accelerating the evaluation of candidate architectures for neural architecture search (NAS), which is rate-limited by such evaluations, enabling massive speed-ups in NAS. GTN-NAS improves the NAS state of the art, finding higher performing architectures when controlling for the search proposal mechanism. GTN-NAS also is competitive with the overall state of the art approaches, which achieve top performance while using orders of magnitude less computation than typical NAS methods. Speculating forward, GTNs may represent a first step toward the ambitious goal of algorithms that generate their own training data and, in doing so, open a variety of interesting new research questions and directions.",
        "file_path": "paper_data/Deep_Meta-Learning/info/16a3dd5ab3e8570f6083ddf6f88aa5e916450fef.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 164,
        "score": 27.333333333333332,
        "summary": "This paper investigates the intriguing question of whether we can create learning algorithms that automatically generate training data, learning environments, and curricula in order to help AI agents rapidly learn. We show that such algorithms are possible via Generative Teaching Networks (GTNs), a general approach that is, in theory, applicable to supervised, unsupervised, and reinforcement learning, although our experiments only focus on the supervised case. GTNs are deep neural networks that generate data and/or training environments that a learner (e.g. a freshly initialized neural network) trains on for a few SGD steps before being tested on a target task. We then differentiate through the entire learning process via meta-gradients to update the GTN parameters to improve performance on the target task. GTNs have the beneficial property that they can theoretically generate any type of data or training environment, making their potential impact large. This paper introduces GTNs, discusses their potential, and showcases that they can substantially accelerate learning. We also demonstrate a practical and exciting application of GTNs: accelerating the evaluation of candidate architectures for neural architecture search (NAS), which is rate-limited by such evaluations, enabling massive speed-ups in NAS. GTN-NAS improves the NAS state of the art, finding higher performing architectures when controlling for the search proposal mechanism. GTN-NAS also is competitive with the overall state of the art approaches, which achieve top performance while using orders of magnitude less computation than typical NAS methods. Speculating forward, GTNs may represent a first step toward the ambitious goal of algorithms that generate their own training data and, in doing so, open a variety of interesting new research questions and directions.",
        "keywords": []
      },
      "file_name": "16a3dd5ab3e8570f6083ddf6f88aa5e916450fef.pdf"
    },
    {
      "success": true,
      "doc_id": "f21c6a66c0e98726aaf312e003f675f9",
      "summary": "The goal of few-shot learning (FSL) is to recognize a set of novel classes with only few labeled samples by exploiting a large set of abundant base class samples. Adopting a meta-learning framework, most recent FSL methods meta-learn a deep feature embedding network, and during inference classify novel class samples using nearest neighbor in the learned high-dimensional embedding space. This means that these methods are prone to the hubness problem, that is, a certain class prototype becomes the nearest neighbor of many test instances regardless which classes they belong to. However, this problem is largely ignored in existing FSL studies. In this work, for the first time we show that many FSL methods indeed suffer from the hubness problem. To mitigate its negative effects, we further propose to employ z-score feature normalization, a simple yet effective trans-formation, during meta-training. A theoretical analysis is provided on why it helps. Extensive experiments are then conducted to show that with z-score normalization, the performance of many recent FSL methods can be boosted, resulting in new state-of-the-art on three benchmarks.",
      "intriguing_abstract": "The goal of few-shot learning (FSL) is to recognize a set of novel classes with only few labeled samples by exploiting a large set of abundant base class samples. Adopting a meta-learning framework, most recent FSL methods meta-learn a deep feature embedding network, and during inference classify novel class samples using nearest neighbor in the learned high-dimensional embedding space. This means that these methods are prone to the hubness problem, that is, a certain class prototype becomes the nearest neighbor of many test instances regardless which classes they belong to. However, this problem is largely ignored in existing FSL studies. In this work, for the first time we show that many FSL methods indeed suffer from the hubness problem. To mitigate its negative effects, we further propose to employ z-score feature normalization, a simple yet effective trans-formation, during meta-training. A theoretical analysis is provided on why it helps. Extensive experiments are then conducted to show that with z-score normalization, the performance of many recent FSL methods can be boosted, resulting in new state-of-the-art on three benchmarks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d700cd5e6fec5d138abf754fe463443ef5f47a95.pdf",
      "citation_key": "fei20211x6",
      "metadata": {
        "title": "Z-Score Normalization, Hubness, and Few-Shot Learning",
        "authors": [
          "Nanyi Fei",
          "Yizhao Gao",
          "Zhiwu Lu",
          "Tao Xiang"
        ],
        "published_date": "2021",
        "abstract": "The goal of few-shot learning (FSL) is to recognize a set of novel classes with only few labeled samples by exploiting a large set of abundant base class samples. Adopting a meta-learning framework, most recent FSL methods meta-learn a deep feature embedding network, and during inference classify novel class samples using nearest neighbor in the learned high-dimensional embedding space. This means that these methods are prone to the hubness problem, that is, a certain class prototype becomes the nearest neighbor of many test instances regardless which classes they belong to. However, this problem is largely ignored in existing FSL studies. In this work, for the first time we show that many FSL methods indeed suffer from the hubness problem. To mitigate its negative effects, we further propose to employ z-score feature normalization, a simple yet effective trans-formation, during meta-training. A theoretical analysis is provided on why it helps. Extensive experiments are then conducted to show that with z-score normalization, the performance of many recent FSL methods can be boosted, resulting in new state-of-the-art on three benchmarks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d700cd5e6fec5d138abf754fe463443ef5f47a95.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 105,
        "score": 26.25,
        "summary": "The goal of few-shot learning (FSL) is to recognize a set of novel classes with only few labeled samples by exploiting a large set of abundant base class samples. Adopting a meta-learning framework, most recent FSL methods meta-learn a deep feature embedding network, and during inference classify novel class samples using nearest neighbor in the learned high-dimensional embedding space. This means that these methods are prone to the hubness problem, that is, a certain class prototype becomes the nearest neighbor of many test instances regardless which classes they belong to. However, this problem is largely ignored in existing FSL studies. In this work, for the first time we show that many FSL methods indeed suffer from the hubness problem. To mitigate its negative effects, we further propose to employ z-score feature normalization, a simple yet effective trans-formation, during meta-training. A theoretical analysis is provided on why it helps. Extensive experiments are then conducted to show that with z-score normalization, the performance of many recent FSL methods can be boosted, resulting in new state-of-the-art on three benchmarks.",
        "keywords": []
      },
      "file_name": "d700cd5e6fec5d138abf754fe463443ef5f47a95.pdf"
    },
    {
      "success": true,
      "doc_id": "394d6a0d0c16da99ac5a22bd308abdb0",
      "summary": "In this paper, we aim to create generalizable and controllable neural signed distance fields (SDFs) that represent clothed humans from monocular depth observations. Recent advances in deep learning, especially neural implicit representations, have enabled human shape reconstruction and controllable avatar generation from different sensor inputs. However, to generate realistic cloth deformations from novel input poses, watertight meshes or dense full-body scans are usually needed as inputs. Furthermore, due to the difficulty of effectively modeling pose-dependent cloth deformations for diverse body shapes and cloth types, existing approaches resort to per-subject/cloth-type optimization from scratch, which is computationally expensive. In contrast, we propose an approach that can quickly generate realistic clothed human avatars, represented as controllable neural SDFs, given only monocular depth images. We achieve this by using meta-learning to learn an initialization of a hypernetwork that predicts the parameters of neural SDFs. The hypernetwork is conditioned on human poses and represents a clothed neural avatar that deforms non-rigidly according to the input poses. Meanwhile, it is meta-learned to effectively incorporate priors of diverse body shapes and cloth types and thus can be much faster to fine-tune, compared to models trained from scratch. We qualitatively and quantitatively show that our approach outperforms state-of-the-art approaches that require complete meshes as inputs while our approach requires only depth frames as inputs and runs orders of magnitudes faster. Furthermore, we demonstrate that our meta-learned hypernetwork is very robust, being the first to generate avatars with realistic dynamic cloth deformations given as few as 8 monocular depth frames.",
      "intriguing_abstract": "In this paper, we aim to create generalizable and controllable neural signed distance fields (SDFs) that represent clothed humans from monocular depth observations. Recent advances in deep learning, especially neural implicit representations, have enabled human shape reconstruction and controllable avatar generation from different sensor inputs. However, to generate realistic cloth deformations from novel input poses, watertight meshes or dense full-body scans are usually needed as inputs. Furthermore, due to the difficulty of effectively modeling pose-dependent cloth deformations for diverse body shapes and cloth types, existing approaches resort to per-subject/cloth-type optimization from scratch, which is computationally expensive. In contrast, we propose an approach that can quickly generate realistic clothed human avatars, represented as controllable neural SDFs, given only monocular depth images. We achieve this by using meta-learning to learn an initialization of a hypernetwork that predicts the parameters of neural SDFs. The hypernetwork is conditioned on human poses and represents a clothed neural avatar that deforms non-rigidly according to the input poses. Meanwhile, it is meta-learned to effectively incorporate priors of diverse body shapes and cloth types and thus can be much faster to fine-tune, compared to models trained from scratch. We qualitatively and quantitatively show that our approach outperforms state-of-the-art approaches that require complete meshes as inputs while our approach requires only depth frames as inputs and runs orders of magnitudes faster. Furthermore, we demonstrate that our meta-learned hypernetwork is very robust, being the first to generate avatars with realistic dynamic cloth deformations given as few as 8 monocular depth frames.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e4d018da22a15a39ed47fa6ee000d77ab916aaae.pdf",
      "citation_key": "wang2021ya6",
      "metadata": {
        "title": "MetaAvatar: Learning Animatable Clothed Human Models from Few Depth Images",
        "authors": [
          "Shaofei Wang",
          "Marko Mihajlovic",
          "Qianli Ma",
          "Andreas Geiger",
          "Siyu Tang"
        ],
        "published_date": "2021",
        "abstract": "In this paper, we aim to create generalizable and controllable neural signed distance fields (SDFs) that represent clothed humans from monocular depth observations. Recent advances in deep learning, especially neural implicit representations, have enabled human shape reconstruction and controllable avatar generation from different sensor inputs. However, to generate realistic cloth deformations from novel input poses, watertight meshes or dense full-body scans are usually needed as inputs. Furthermore, due to the difficulty of effectively modeling pose-dependent cloth deformations for diverse body shapes and cloth types, existing approaches resort to per-subject/cloth-type optimization from scratch, which is computationally expensive. In contrast, we propose an approach that can quickly generate realistic clothed human avatars, represented as controllable neural SDFs, given only monocular depth images. We achieve this by using meta-learning to learn an initialization of a hypernetwork that predicts the parameters of neural SDFs. The hypernetwork is conditioned on human poses and represents a clothed neural avatar that deforms non-rigidly according to the input poses. Meanwhile, it is meta-learned to effectively incorporate priors of diverse body shapes and cloth types and thus can be much faster to fine-tune, compared to models trained from scratch. We qualitatively and quantitatively show that our approach outperforms state-of-the-art approaches that require complete meshes as inputs while our approach requires only depth frames as inputs and runs orders of magnitudes faster. Furthermore, we demonstrate that our meta-learned hypernetwork is very robust, being the first to generate avatars with realistic dynamic cloth deformations given as few as 8 monocular depth frames.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e4d018da22a15a39ed47fa6ee000d77ab916aaae.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 103,
        "score": 25.75,
        "summary": "In this paper, we aim to create generalizable and controllable neural signed distance fields (SDFs) that represent clothed humans from monocular depth observations. Recent advances in deep learning, especially neural implicit representations, have enabled human shape reconstruction and controllable avatar generation from different sensor inputs. However, to generate realistic cloth deformations from novel input poses, watertight meshes or dense full-body scans are usually needed as inputs. Furthermore, due to the difficulty of effectively modeling pose-dependent cloth deformations for diverse body shapes and cloth types, existing approaches resort to per-subject/cloth-type optimization from scratch, which is computationally expensive. In contrast, we propose an approach that can quickly generate realistic clothed human avatars, represented as controllable neural SDFs, given only monocular depth images. We achieve this by using meta-learning to learn an initialization of a hypernetwork that predicts the parameters of neural SDFs. The hypernetwork is conditioned on human poses and represents a clothed neural avatar that deforms non-rigidly according to the input poses. Meanwhile, it is meta-learned to effectively incorporate priors of diverse body shapes and cloth types and thus can be much faster to fine-tune, compared to models trained from scratch. We qualitatively and quantitatively show that our approach outperforms state-of-the-art approaches that require complete meshes as inputs while our approach requires only depth frames as inputs and runs orders of magnitudes faster. Furthermore, we demonstrate that our meta-learned hypernetwork is very robust, being the first to generate avatars with realistic dynamic cloth deformations given as few as 8 monocular depth frames.",
        "keywords": []
      },
      "file_name": "e4d018da22a15a39ed47fa6ee000d77ab916aaae.pdf"
    },
    {
      "success": true,
      "doc_id": "96df58170c868239cec8e5a25c66de37",
      "summary": "Here's a focused summary of the paper \\cite{jang2019a48} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem:** Existing transfer learning methods struggle when applied between heterogeneous network architectures and tasks, often requiring exhaustive and manual tuning to determine \"what knowledge to transfer\" and \"where in the target network to transfer it.\"\n    *   **Importance & Challenge:** Deep Neural Networks (DNNs) require large datasets, which are expensive to collect for every target task. Transfer learning is crucial for small-data regimes. However, manually configuring transfer rules (e.g., which layers to match, which features are relevant) is sub-optimal, time-consuming, and lacks a principled mechanism, especially when source and target tasks/architectures differ significantly.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches:**\n        *   **Pre-training with fine-tuning:** Widely used but fails if source and target tasks are semantically distant or architectures largely differ.\n        *   **Knowledge Distillation-based:** Learning without Forgetting (LwF) \\cite{li2018learning} uses knowledge distillation for different tasks.\n        *   **Feature Matching-based:** FitNet \\cite{romero2015fitnets}, Attention Transfer (AT) \\cite{zagoruyko2017paying}, and Jacobian Matching \\cite{srinivas2018jacobian} transfer knowledge by matching feature maps, attention maps, or Jacobians between teacher (source) and student (target) networks.\n    *   **Limitations of Previous Solutions:** These methods lack a mechanism to automatically identify *which* source information is useful and *between which layers* of the networks it should be transferred. They rely on hand-crafted layer associations and do not consider the varying importance of different features (channels) or layers, leading to sub-optimal performance and extensive manual configuration.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method:** Proposes a novel meta-learning approach called \"Learning What and Where to Transfer\" (L2T-ww) that automatically learns transfer rules.\n    *   **Meta-Networks:** Introduces two types of meta-networks, parameterized by $\\phi$:\n        *   `f_m,n`: Decides \"what to transfer\" by generating non-negative channel-wise weights ($w_{m,n,c}$) for feature maps, emphasizing useful channels.\n        *   `g_m,n`: Decides \"where to transfer\" by generating non-negative weights ($\\alpha_{m,n}$) for each pair of source layer `m` and target layer `n`, indicating the amount of knowledge to transfer between them.\n    *   **Combined Transfer Loss:** Integrates these weights into a weighted feature matching loss ($L_{wfm}$), which is added as a regularization term to the original task loss ($L_{org}$).\n    *   **Novel Training Scheme (3-stage meta-learning):** Addresses the challenge of weak influence of the regularization term on the meta-objective in standard bilevel optimization.\n        1.  Update target model parameters ($\\theta$) by minimizing *only* $L_{wfm}$ for $T$ steps (e.g., $T=2$). This directly trains target features using source knowledge.\n        2.  Perform a one-step adaptation of $\\theta$ by minimizing $L_{org}$.\n        3.  Update meta-network parameters ($\\phi$) by minimizing $L_{org}$ on the adapted $\\theta$. This measures how quickly the target model adapts to the task after being guided by the meta-networks, allowing for more direct and efficient updates to $\\phi$.\n    *   **Joint Training:** Alternately updates target model parameters ($\\theta$) and meta-network parameters ($\\phi$) using this scheme.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:** Introduction of meta-networks (`f_m,n` and `g_m,n`) that learn channel-wise importance and layer-to-layer transfer weights, enabling data-driven selection of \"what\" and \"where\" to transfer.\n    *   **System Design/Architectural Innovations:** A principled meta-learning framework for automatically configuring transfer learning, moving beyond manual heuristics.\n    *   **Theoretical Insights/Analysis:** Development of an efficient 3-stage meta-learning scheme that significantly accelerates the training of meta-networks by increasing the direct influence of the transfer objective on the meta-objective, allowing for meaningful updates with fewer inner-loop iterations.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Validated on two scales of image classification tasks (32x32 and 224x224) using various datasets (TinyImageNet, CIFAR-10/100, STL-10, ImageNet, CUB200, MIT Indoor, Stanford 40 Actions, Stanford Dogs) and heterogeneous network architectures (ResNet-32/34, VGG9, ResNet-18).\n    *   **Key Performance Metrics & Comparison Results:**\n        *   Compared against baselines: Learning without Forgetting (LwF), Attention Transfer (AT), and Unweighted Feature Matching (FM) with hand-crafted layer configurations (single, one-to-one).\n        *   **Significant Outperformance:** L2T-ww consistently and significantly outperformed prior baselines. For example, on the ImageNet to CUB200 transfer, L2T-ww achieved 65.05% accuracy, while the second-best baseline obtained 58.90%.\n        *   **Robustness:** Demonstrated superior performance, especially when the target task had an insufficient number of training samples and when transferring from multiple source models.\n        *   **Learned Matching:** Visualizations showed that the meta-networks learned non-trivial and effective layer associations, often connecting layers with different spatial sizes, which is not typically done in hand-crafted methods.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The paper primarily focuses on image classification tasks and convolutional neural networks. The meta-networks themselves are relatively simple (1-layer fully-connected), which might limit their expressiveness in highly complex transfer scenarios. The hyperparameter $\\lambda$ for balancing $L_{org}$ and $L_{wfm}$ still requires tuning.\n    *   **Scope of Applicability:** While generic for deep neural networks, the empirical validation is confined to image classification. The computational overhead of bilevel optimization, though made more efficient, is still present compared to simpler transfer methods.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art:** Represents a significant step towards automated, data-driven transfer learning by providing a principled method to learn optimal transfer configurations (what features from which layers to transfer to which target layers).\n    *   **Potential Impact:**\n        *   Reduces the need for extensive manual tuning and expert knowledge in heterogeneous transfer learning scenarios.\n        *   Enables more effective knowledge transfer, leading to improved performance in low-data regimes and when source/target domains or architectures are disparate.\n        *   Opens avenues for future research in meta-learning for optimizing various aspects of neural network training and adaptation.",
      "intriguing_abstract": "The promise of transfer learning in deep neural networks often falters when bridging heterogeneous architectures and semantically distant tasks, demanding exhaustive and often sub-optimal manual configuration of *what* knowledge to transfer and *where* within the target network. We introduce **Learning What and Where to Transfer (L2T-ww)**, a novel meta-learning framework that automates this critical process.\n\nL2T-ww employs two specialized meta-networks: one dynamically learns **channel-wise weights** to identify salient features for transfer, while the other determines optimal **layer-to-layer transfer weights**, effectively mapping knowledge between disparate source and target network layers. This principled, data-driven approach replaces heuristic layer associations with an adaptive mechanism. Furthermore, we propose an efficient 3-stage meta-learning scheme that significantly accelerates the optimization of these meta-networks, overcoming challenges inherent in bilevel optimization.\n\nExtensive experiments across diverse image classification tasks and heterogeneous architectures demonstrate L2T-ww's superior performance, consistently outperforming state-of-the-art baselines, particularly in **low-data regimes**. Our method not only streamlines knowledge transfer but also unlocks new capabilities for adapting deep models, making it a pivotal step towards truly automated and robust transfer learning.",
      "keywords": [
        "Learning What and Where to Transfer (L2T-ww)",
        "meta-learning",
        "heterogeneous transfer learning",
        "automated transfer rule learning",
        "meta-networks for channel and layer weighting",
        "3-stage meta-learning scheme",
        "weighted feature matching loss",
        "bilevel optimization",
        "image classification",
        "low-data regimes",
        "significant performance improvement",
        "learned non-trivial layer associations",
        "reduced manual tuning"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/290357314d0c339bcce31cfbe6b29aa50f89b026.pdf",
      "citation_key": "jang2019a48",
      "metadata": {
        "title": "Learning What and Where to Transfer",
        "authors": [
          "Yunhun Jang",
          "Hankook Lee",
          "Sung Ju Hwang",
          "Jinwoo Shin"
        ],
        "published_date": "2019",
        "abstract": "As the application of deep learning has expanded to real-world problems with insufficient volume of training data, transfer learning recently has gained much attention as means of improving the performance in such small-data regime. However, when existing methods are applied between heterogeneous architectures and tasks, it becomes more important to manage their detailed configurations and often requires exhaustive tuning on them for the desired performance. To address the issue, we propose a novel transfer learning approach based on meta-learning that can automatically learn what knowledge to transfer from the source network to where in the target network. Given source and target networks, we propose an efficient training scheme to learn meta-networks that decide (a) which pairs of layers between the source and target networks should be matched for knowledge transfer and (b) which features and how much knowledge from each feature should be transferred. We validate our meta-transfer approach against recent transfer learning methods on various datasets and network architectures, on which our automated scheme significantly outperforms the prior baselines that find \"what and where to transfer\" in a hand-crafted manner.",
        "file_path": "paper_data/Deep_Meta-Learning/info/290357314d0c339bcce31cfbe6b29aa50f89b026.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 154,
        "score": 25.666666666666664,
        "summary": "Here's a focused summary of the paper \\cite{jang2019a48} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem:** Existing transfer learning methods struggle when applied between heterogeneous network architectures and tasks, often requiring exhaustive and manual tuning to determine \"what knowledge to transfer\" and \"where in the target network to transfer it.\"\n    *   **Importance & Challenge:** Deep Neural Networks (DNNs) require large datasets, which are expensive to collect for every target task. Transfer learning is crucial for small-data regimes. However, manually configuring transfer rules (e.g., which layers to match, which features are relevant) is sub-optimal, time-consuming, and lacks a principled mechanism, especially when source and target tasks/architectures differ significantly.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches:**\n        *   **Pre-training with fine-tuning:** Widely used but fails if source and target tasks are semantically distant or architectures largely differ.\n        *   **Knowledge Distillation-based:** Learning without Forgetting (LwF) \\cite{li2018learning} uses knowledge distillation for different tasks.\n        *   **Feature Matching-based:** FitNet \\cite{romero2015fitnets}, Attention Transfer (AT) \\cite{zagoruyko2017paying}, and Jacobian Matching \\cite{srinivas2018jacobian} transfer knowledge by matching feature maps, attention maps, or Jacobians between teacher (source) and student (target) networks.\n    *   **Limitations of Previous Solutions:** These methods lack a mechanism to automatically identify *which* source information is useful and *between which layers* of the networks it should be transferred. They rely on hand-crafted layer associations and do not consider the varying importance of different features (channels) or layers, leading to sub-optimal performance and extensive manual configuration.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method:** Proposes a novel meta-learning approach called \"Learning What and Where to Transfer\" (L2T-ww) that automatically learns transfer rules.\n    *   **Meta-Networks:** Introduces two types of meta-networks, parameterized by $\\phi$:\n        *   `f_m,n`: Decides \"what to transfer\" by generating non-negative channel-wise weights ($w_{m,n,c}$) for feature maps, emphasizing useful channels.\n        *   `g_m,n`: Decides \"where to transfer\" by generating non-negative weights ($\\alpha_{m,n}$) for each pair of source layer `m` and target layer `n`, indicating the amount of knowledge to transfer between them.\n    *   **Combined Transfer Loss:** Integrates these weights into a weighted feature matching loss ($L_{wfm}$), which is added as a regularization term to the original task loss ($L_{org}$).\n    *   **Novel Training Scheme (3-stage meta-learning):** Addresses the challenge of weak influence of the regularization term on the meta-objective in standard bilevel optimization.\n        1.  Update target model parameters ($\\theta$) by minimizing *only* $L_{wfm}$ for $T$ steps (e.g., $T=2$). This directly trains target features using source knowledge.\n        2.  Perform a one-step adaptation of $\\theta$ by minimizing $L_{org}$.\n        3.  Update meta-network parameters ($\\phi$) by minimizing $L_{org}$ on the adapted $\\theta$. This measures how quickly the target model adapts to the task after being guided by the meta-networks, allowing for more direct and efficient updates to $\\phi$.\n    *   **Joint Training:** Alternately updates target model parameters ($\\theta$) and meta-network parameters ($\\phi$) using this scheme.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:** Introduction of meta-networks (`f_m,n` and `g_m,n`) that learn channel-wise importance and layer-to-layer transfer weights, enabling data-driven selection of \"what\" and \"where\" to transfer.\n    *   **System Design/Architectural Innovations:** A principled meta-learning framework for automatically configuring transfer learning, moving beyond manual heuristics.\n    *   **Theoretical Insights/Analysis:** Development of an efficient 3-stage meta-learning scheme that significantly accelerates the training of meta-networks by increasing the direct influence of the transfer objective on the meta-objective, allowing for meaningful updates with fewer inner-loop iterations.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Validated on two scales of image classification tasks (32x32 and 224x224) using various datasets (TinyImageNet, CIFAR-10/100, STL-10, ImageNet, CUB200, MIT Indoor, Stanford 40 Actions, Stanford Dogs) and heterogeneous network architectures (ResNet-32/34, VGG9, ResNet-18).\n    *   **Key Performance Metrics & Comparison Results:**\n        *   Compared against baselines: Learning without Forgetting (LwF), Attention Transfer (AT), and Unweighted Feature Matching (FM) with hand-crafted layer configurations (single, one-to-one).\n        *   **Significant Outperformance:** L2T-ww consistently and significantly outperformed prior baselines. For example, on the ImageNet to CUB200 transfer, L2T-ww achieved 65.05% accuracy, while the second-best baseline obtained 58.90%.\n        *   **Robustness:** Demonstrated superior performance, especially when the target task had an insufficient number of training samples and when transferring from multiple source models.\n        *   **Learned Matching:** Visualizations showed that the meta-networks learned non-trivial and effective layer associations, often connecting layers with different spatial sizes, which is not typically done in hand-crafted methods.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The paper primarily focuses on image classification tasks and convolutional neural networks. The meta-networks themselves are relatively simple (1-layer fully-connected), which might limit their expressiveness in highly complex transfer scenarios. The hyperparameter $\\lambda$ for balancing $L_{org}$ and $L_{wfm}$ still requires tuning.\n    *   **Scope of Applicability:** While generic for deep neural networks, the empirical validation is confined to image classification. The computational overhead of bilevel optimization, though made more efficient, is still present compared to simpler transfer methods.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art:** Represents a significant step towards automated, data-driven transfer learning by providing a principled method to learn optimal transfer configurations (what features from which layers to transfer to which target layers).\n    *   **Potential Impact:**\n        *   Reduces the need for extensive manual tuning and expert knowledge in heterogeneous transfer learning scenarios.\n        *   Enables more effective knowledge transfer, leading to improved performance in low-data regimes and when source/target domains or architectures are disparate.\n        *   Opens avenues for future research in meta-learning for optimizing various aspects of neural network training and adaptation.",
        "keywords": [
          "Learning What and Where to Transfer (L2T-ww)",
          "meta-learning",
          "heterogeneous transfer learning",
          "automated transfer rule learning",
          "meta-networks for channel and layer weighting",
          "3-stage meta-learning scheme",
          "weighted feature matching loss",
          "bilevel optimization",
          "image classification",
          "low-data regimes",
          "significant performance improvement",
          "learned non-trivial layer associations",
          "reduced manual tuning"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** a novel transfer learning approach based on meta-learning that can automatically learn what knowledge to transfer from the source network to where in the target network.\" and \"we **propose** an efﬁcient training scheme to learn meta-networks\".\n*   it describes the components of this new approach (meta-networks, training scheme) and what they achieve.\n*   the introduction further contrasts \"prior approaches\" with \"our meta-transfer method,\" emphasizing the novelty of their solution.\n*   the paper then mentions validating this proposed approach against baselines on various datasets, which is an empirical evaluation *of the proposed method*.\n\nthis aligns perfectly with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\".\n\nthe final classification is: **technical**"
      },
      "file_name": "290357314d0c339bcce31cfbe6b29aa50f89b026.pdf"
    },
    {
      "success": true,
      "doc_id": "05ca8345eab7510b29c455f2d229835c",
      "summary": "The availability of large amounts of data from continuous glucose monitoring (CGM), together with the latest advances in deep learning techniques, have opened the door to a new paradigm of algorithm design for personalized blood glucose (BG) prediction in type 1 diabetes (T1D) with superior performance. However, there are several challenges that prevent the widespread implementation of deep learning algorithms in actual clinical settings, including unclear prediction confidence and limited training data for new T1D subjects. To this end, we propose a novel deep learning framework, Fast-adaptive and Confident Neural Network (FCNN), to meet these clinical challenges. In particular, an attention-based recurrent neural network is used to learn representations from CGM input and forward a weighted sum of hidden states to an evidential output layer, aiming to compute personalized BG predictions with theoretically supported model confidence. The model-agnostic meta-learning is employed to enable fast adaptation for a new T1D subject with limited training data. The proposed framework has been validated on three clinical datasets. In particular, for a dataset including 12 subjects with T1D, FCNN achieved a root mean square error of 18.64±2.60 mg/dL and 31.07±3.62 mg/dL for 30 and 60-minute prediction horizons, respectively, which outperformed all the considered baseline methods with significant improvements. These results indicate that FCNN is a viable and effective approach for predicting BG levels in T1D. The well-trained models can be implemented in smartphone apps to improve glycemic control by enabling proactive actions through real-time glucose alerts.",
      "intriguing_abstract": "The availability of large amounts of data from continuous glucose monitoring (CGM), together with the latest advances in deep learning techniques, have opened the door to a new paradigm of algorithm design for personalized blood glucose (BG) prediction in type 1 diabetes (T1D) with superior performance. However, there are several challenges that prevent the widespread implementation of deep learning algorithms in actual clinical settings, including unclear prediction confidence and limited training data for new T1D subjects. To this end, we propose a novel deep learning framework, Fast-adaptive and Confident Neural Network (FCNN), to meet these clinical challenges. In particular, an attention-based recurrent neural network is used to learn representations from CGM input and forward a weighted sum of hidden states to an evidential output layer, aiming to compute personalized BG predictions with theoretically supported model confidence. The model-agnostic meta-learning is employed to enable fast adaptation for a new T1D subject with limited training data. The proposed framework has been validated on three clinical datasets. In particular, for a dataset including 12 subjects with T1D, FCNN achieved a root mean square error of 18.64±2.60 mg/dL and 31.07±3.62 mg/dL for 30 and 60-minute prediction horizons, respectively, which outperformed all the considered baseline methods with significant improvements. These results indicate that FCNN is a viable and effective approach for predicting BG levels in T1D. The well-trained models can be implemented in smartphone apps to improve glycemic control by enabling proactive actions through real-time glucose alerts.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b6bf19db98572ceec901c96392f2f65f98cd3be6.pdf",
      "citation_key": "zhu2022zp1",
      "metadata": {
        "title": "Personalized Blood Glucose Prediction for Type 1 Diabetes Using Evidential Deep Learning and Meta-Learning",
        "authors": [
          "Taiyu Zhu",
          "Kezhi Li",
          "P. Herrero",
          "P. Georgiou"
        ],
        "published_date": "2022",
        "abstract": "The availability of large amounts of data from continuous glucose monitoring (CGM), together with the latest advances in deep learning techniques, have opened the door to a new paradigm of algorithm design for personalized blood glucose (BG) prediction in type 1 diabetes (T1D) with superior performance. However, there are several challenges that prevent the widespread implementation of deep learning algorithms in actual clinical settings, including unclear prediction confidence and limited training data for new T1D subjects. To this end, we propose a novel deep learning framework, Fast-adaptive and Confident Neural Network (FCNN), to meet these clinical challenges. In particular, an attention-based recurrent neural network is used to learn representations from CGM input and forward a weighted sum of hidden states to an evidential output layer, aiming to compute personalized BG predictions with theoretically supported model confidence. The model-agnostic meta-learning is employed to enable fast adaptation for a new T1D subject with limited training data. The proposed framework has been validated on three clinical datasets. In particular, for a dataset including 12 subjects with T1D, FCNN achieved a root mean square error of 18.64±2.60 mg/dL and 31.07±3.62 mg/dL for 30 and 60-minute prediction horizons, respectively, which outperformed all the considered baseline methods with significant improvements. These results indicate that FCNN is a viable and effective approach for predicting BG levels in T1D. The well-trained models can be implemented in smartphone apps to improve glycemic control by enabling proactive actions through real-time glucose alerts.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b6bf19db98572ceec901c96392f2f65f98cd3be6.pdf",
        "venue": "IEEE Transactions on Biomedical Engineering",
        "citationCount": 76,
        "score": 25.333333333333332,
        "summary": "The availability of large amounts of data from continuous glucose monitoring (CGM), together with the latest advances in deep learning techniques, have opened the door to a new paradigm of algorithm design for personalized blood glucose (BG) prediction in type 1 diabetes (T1D) with superior performance. However, there are several challenges that prevent the widespread implementation of deep learning algorithms in actual clinical settings, including unclear prediction confidence and limited training data for new T1D subjects. To this end, we propose a novel deep learning framework, Fast-adaptive and Confident Neural Network (FCNN), to meet these clinical challenges. In particular, an attention-based recurrent neural network is used to learn representations from CGM input and forward a weighted sum of hidden states to an evidential output layer, aiming to compute personalized BG predictions with theoretically supported model confidence. The model-agnostic meta-learning is employed to enable fast adaptation for a new T1D subject with limited training data. The proposed framework has been validated on three clinical datasets. In particular, for a dataset including 12 subjects with T1D, FCNN achieved a root mean square error of 18.64±2.60 mg/dL and 31.07±3.62 mg/dL for 30 and 60-minute prediction horizons, respectively, which outperformed all the considered baseline methods with significant improvements. These results indicate that FCNN is a viable and effective approach for predicting BG levels in T1D. The well-trained models can be implemented in smartphone apps to improve glycemic control by enabling proactive actions through real-time glucose alerts.",
        "keywords": []
      },
      "file_name": "b6bf19db98572ceec901c96392f2f65f98cd3be6.pdf"
    },
    {
      "success": true,
      "doc_id": "7cccbf8d4264dfb66ada682e241df7bd",
      "summary": "Here's a focused summary of the paper \\cite{gao20223fn} for a literature review:\n\n### Technical Paper Analysis: MetaLoc: Learning to Learn Wireless Localization \\cite{gao20223fn}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Existing wireless localization methods, whether statistical or data-driven, struggle to generalize to new environments. They are environment-specific, requiring extensive data collection (site surveys) and retraining for each new deployment.\n    *   **Importance & Challenge:** This lack of generalization leads to considerable time, effort, and cost waste, hindering the scalability and practical deployment of accurate localization systems for emerging applications (e.g., autonomous driving, 3D scene reconstruction, 5G/6G precise location services) in diverse and dynamic indoor environments.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper positions itself within fingerprinting-based localization, which involves offline database creation and online matching using features like RSS or CSI. It acknowledges classic signal processing methods (probabilistic, deterministic) and machine learning-based approaches.\n    *   **Limitations of Previous Solutions:**\n        *   **Environment Specificity:** Most prior work focuses on single environments, lacking universal applicability.\n        *   **Data Hunger:** Machine learning models require large amounts of data, making database building time-consuming and labor-intensive for each new environment.\n        *   **Robustness Issues:** Wireless signal propagation variability and dynamic indoor environments challenge the robustness of existing methods.\n        *   **Cost-effectiveness:** Techniques like data augmentation, semi-supervised learning, informed ML, and federated learning still face challenges in mitigating noise, representing knowledge, or dealing with fingerprint inconsistencies over space and time, thus not fully addressing the cost of site surveys.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes MetaLoc, the first fingerprinting-based localization framework leveraging Model-Agnostic Meta-Learning (MAML). It uses a deep neural network trained on historical data from well-calibrated environments.\n    *   **Novelty/Difference:**\n        *   **Meta-Learning for Localization:** MetaLoc learns \"meta-parameters\" through a two-loop optimization mechanism. These meta-parameters serve as an optimal initialization for the neural network, enabling rapid and efficient adaptation to new, unseen environments with minimal new data.\n        *   **Two Paradigms:** Introduces a centralized paradigm (vanilla MAML, sharing data from all historical environments) and a distributed paradigm (MAML-TS, MAML-DG, maintaining data privacy by training environment-specific meta-parameters).\n        *   **Advanced Distributed Paradigm (MAML-DG):** Modifies the vanilla MAML loss function to ensure consistent loss reduction across various training domains, facilitating faster convergence.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Introduction of MAML to wireless localization, specifically for fingerprinting-based methods.\n        *   Development of two meta-parameter training paradigms: centralized and distributed.\n        *   Proposal of MAML-DG, an advanced distributed algorithm with a dual-component loss function for improved learning efficiency and faster convergence.\n    *   **System Design/Architectural Innovations:** A framework that learns an initialization (meta-parameters) for a deep neural network, allowing it to quickly adapt to new environments, breaking the traditional environment-specific localization bottleneck.\n    *   **Empirical Contribution:** Creation of a comprehensive, publicly available real-world dataset for fair evaluation, collected using smartphones and multiple WiFi routers across diverse indoor scenarios (spacious hall, cluttered lab), with extensive measurements (260 CSI images/RSS vectors per grid point).\n    *   **Flexible Model Compatibility:** MetaLoc is compatible with any model trained via gradient descent and can utilize various wireless signal features (RSS, CSI) for both regression and classification problems.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** Experiments were performed on both synthetic and the newly created real-world datasets.\n    *   **Key Performance Metrics:** Localization accuracy, robustness, and cost-effectiveness.\n    *   **Comparison Results:** MetaLoc consistently outperforms baseline methods across these metrics. A key finding is its ability to adapt effectively with just three CSI images per point in a new environment, demonstrating significant cost-effectiveness.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The framework relies on the availability of historical data from \"well-calibrated environments\" for meta-training. While it addresses generalization, the initial meta-training phase still requires data.\n    *   **Scope of Applicability:** Primarily focused on indoor fingerprinting-based localization using RSS and CSI wireless signal features. While flexible in model and feature compatibility, its direct validation is within this domain.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** MetaLoc significantly advances the technical state-of-the-art by introducing meta-learning to wireless localization, enabling rapid adaptation to new environments with minimal new data collection and computationally inexpensive updates. This addresses a critical bottleneck in deploying scalable localization systems.\n    *   **Potential Impact:**\n        *   **Cost Reduction:** Dramatically reduces the time and resources needed for site surveys and model retraining in new environments.\n        *   **Enhanced Scalability:** Facilitates the deployment of localization systems across diverse and dynamic indoor settings.\n        *   **Future Research:** Provides a foundational framework for \"learning-to-learn\" in wireless localization, with implications for next-generation intelligent networks (e.g., 6G) and other data-driven wireless challenges.",
      "intriguing_abstract": "Traditional wireless localization systems are notoriously environment-specific, demanding costly and time-consuming site surveys and retraining for every new deployment, severely limiting their scalability. We introduce **MetaLoc**, the first fingerprinting-based localization framework to leverage **Model-Agnostic Meta-Learning (MAML)**, fundamentally transforming how localization models adapt. MetaLoc learns optimal 'meta-parameters' from historical data, enabling rapid and efficient adaptation to entirely new, unseen environments with unprecedented data efficiency – requiring as few as three **CSI** images per point. We propose both centralized and novel **distributed meta-learning paradigms**, including **MAML-DG** with an advanced dual-component loss for faster convergence and enhanced privacy. Validated on a comprehensive, publicly available real-world dataset, MetaLoc consistently outperforms state-of-the-art baselines in accuracy and robustness. This breakthrough dramatically reduces operational costs, unlocks scalable deployment for diverse indoor settings, and lays a crucial foundation for \"learning-to-learn\" in future **6G** precise location services.",
      "keywords": [
        "MetaLoc",
        "wireless localization",
        "Model-Agnostic Meta-Learning (MAML)",
        "fingerprinting-based localization",
        "generalization to new environments",
        "rapid adaptation",
        "minimal data collection",
        "meta-parameters",
        "MAML-DG",
        "cost-effectiveness",
        "scalability",
        "public real-world dataset",
        "RSS/CSI features",
        "environment-specific bottleneck"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/79aa092bb37f5ab75d93195f2a5288a51bb8f21d.pdf",
      "citation_key": "gao20223fn",
      "metadata": {
        "title": "MetaLoc: Learning to Learn Wireless Localization",
        "authors": [
          "Jun Gao",
          "Dongze Wu",
          "Feng Yin",
          "Qinglei Kong",
          "Lexi Xu",
          "Shuguang Cui"
        ],
        "published_date": "2022",
        "abstract": "Existing localization methods that intensively leverage the environment-specific received signal strength (RSS) or channel state information (CSI) of wireless signals are rather accurate in certain environments. However, these methods, whether based on pure statistical signal processing or data-driven approaches, often struggle to generalize to new environments, which results in considerable time and effort being wasted. To address this challenge, we propose MetaLoc, which is the first fingerprinting-based localization framework that leverages the Model-Agnostic Meta-Learning (MAML). Specifically, built on a deep neural network with strong representation capabilities, MetaLoc is trained on historical data sourced from well-calibrated environments, employing a two-loop optimization mechanism to obtain the meta-parameters. These meta-parameters act as the initialization for quick adaptation in new environments, reducing the need for much human effort. The framework introduces two paradigms for the optimization of meta-parameters: a centralized paradigm that simplifies the process by sharing data from all historical environments, and a distributed paradigm that maintains data privacy by training meta-parameters for each specific environment separately. Furthermore, the advanced distributed paradigm modifies the vanilla MAML loss function to ensure that the reduction of loss occurs in a consistent direction across various training domains, thus facilitating faster convergence during training. Our experiments on both synthetic and real datasets demonstrate that MetaLoc outperforms baseline methods in terms of localization accuracy, robustness, and cost-effectiveness. The code and datasets used in this study are publicly available at: https://github.com/WU-Dongze/MetaLoc.",
        "file_path": "paper_data/Deep_Meta-Learning/info/79aa092bb37f5ab75d93195f2a5288a51bb8f21d.pdf",
        "venue": "IEEE Journal on Selected Areas in Communications",
        "citationCount": 73,
        "score": 24.333333333333332,
        "summary": "Here's a focused summary of the paper \\cite{gao20223fn} for a literature review:\n\n### Technical Paper Analysis: MetaLoc: Learning to Learn Wireless Localization \\cite{gao20223fn}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** Existing wireless localization methods, whether statistical or data-driven, struggle to generalize to new environments. They are environment-specific, requiring extensive data collection (site surveys) and retraining for each new deployment.\n    *   **Importance & Challenge:** This lack of generalization leads to considerable time, effort, and cost waste, hindering the scalability and practical deployment of accurate localization systems for emerging applications (e.g., autonomous driving, 3D scene reconstruction, 5G/6G precise location services) in diverse and dynamic indoor environments.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper positions itself within fingerprinting-based localization, which involves offline database creation and online matching using features like RSS or CSI. It acknowledges classic signal processing methods (probabilistic, deterministic) and machine learning-based approaches.\n    *   **Limitations of Previous Solutions:**\n        *   **Environment Specificity:** Most prior work focuses on single environments, lacking universal applicability.\n        *   **Data Hunger:** Machine learning models require large amounts of data, making database building time-consuming and labor-intensive for each new environment.\n        *   **Robustness Issues:** Wireless signal propagation variability and dynamic indoor environments challenge the robustness of existing methods.\n        *   **Cost-effectiveness:** Techniques like data augmentation, semi-supervised learning, informed ML, and federated learning still face challenges in mitigating noise, representing knowledge, or dealing with fingerprint inconsistencies over space and time, thus not fully addressing the cost of site surveys.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes MetaLoc, the first fingerprinting-based localization framework leveraging Model-Agnostic Meta-Learning (MAML). It uses a deep neural network trained on historical data from well-calibrated environments.\n    *   **Novelty/Difference:**\n        *   **Meta-Learning for Localization:** MetaLoc learns \"meta-parameters\" through a two-loop optimization mechanism. These meta-parameters serve as an optimal initialization for the neural network, enabling rapid and efficient adaptation to new, unseen environments with minimal new data.\n        *   **Two Paradigms:** Introduces a centralized paradigm (vanilla MAML, sharing data from all historical environments) and a distributed paradigm (MAML-TS, MAML-DG, maintaining data privacy by training environment-specific meta-parameters).\n        *   **Advanced Distributed Paradigm (MAML-DG):** Modifies the vanilla MAML loss function to ensure consistent loss reduction across various training domains, facilitating faster convergence.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Introduction of MAML to wireless localization, specifically for fingerprinting-based methods.\n        *   Development of two meta-parameter training paradigms: centralized and distributed.\n        *   Proposal of MAML-DG, an advanced distributed algorithm with a dual-component loss function for improved learning efficiency and faster convergence.\n    *   **System Design/Architectural Innovations:** A framework that learns an initialization (meta-parameters) for a deep neural network, allowing it to quickly adapt to new environments, breaking the traditional environment-specific localization bottleneck.\n    *   **Empirical Contribution:** Creation of a comprehensive, publicly available real-world dataset for fair evaluation, collected using smartphones and multiple WiFi routers across diverse indoor scenarios (spacious hall, cluttered lab), with extensive measurements (260 CSI images/RSS vectors per grid point).\n    *   **Flexible Model Compatibility:** MetaLoc is compatible with any model trained via gradient descent and can utilize various wireless signal features (RSS, CSI) for both regression and classification problems.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** Experiments were performed on both synthetic and the newly created real-world datasets.\n    *   **Key Performance Metrics:** Localization accuracy, robustness, and cost-effectiveness.\n    *   **Comparison Results:** MetaLoc consistently outperforms baseline methods across these metrics. A key finding is its ability to adapt effectively with just three CSI images per point in a new environment, demonstrating significant cost-effectiveness.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The framework relies on the availability of historical data from \"well-calibrated environments\" for meta-training. While it addresses generalization, the initial meta-training phase still requires data.\n    *   **Scope of Applicability:** Primarily focused on indoor fingerprinting-based localization using RSS and CSI wireless signal features. While flexible in model and feature compatibility, its direct validation is within this domain.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** MetaLoc significantly advances the technical state-of-the-art by introducing meta-learning to wireless localization, enabling rapid adaptation to new environments with minimal new data collection and computationally inexpensive updates. This addresses a critical bottleneck in deploying scalable localization systems.\n    *   **Potential Impact:**\n        *   **Cost Reduction:** Dramatically reduces the time and resources needed for site surveys and model retraining in new environments.\n        *   **Enhanced Scalability:** Facilitates the deployment of localization systems across diverse and dynamic indoor settings.\n        *   **Future Research:** Provides a foundational framework for \"learning-to-learn\" in wireless localization, with implications for next-generation intelligent networks (e.g., 6G) and other data-driven wireless challenges.",
        "keywords": [
          "MetaLoc",
          "wireless localization",
          "Model-Agnostic Meta-Learning (MAML)",
          "fingerprinting-based localization",
          "generalization to new environments",
          "rapid adaptation",
          "minimal data collection",
          "meta-parameters",
          "MAML-DG",
          "cost-effectiveness",
          "scalability",
          "public real-world dataset",
          "RSS/CSI features",
          "environment-specific bottleneck"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract:**\n    *   \"we **propose metaloc**, which is the **first** fingerprinting-based localization framework...\" - clearly indicates a new system/method.\n    *   describes the technical details: \"built on a deep neural network,\" \"two-loop optimization mechanism,\" \"introduces **two paradigms**,\" \"modifies the vanilla maml loss function.\"\n    *   mentions \"experiments\" and \"outperforms baseline methods,\" which points to empirical validation of the proposed technical solution.\n*   **introduction:**\n    *   highlights the need to \"develop a state-of-the-art localization system.\"\n    *   **b. contributions** section explicitly states:\n        *   \"the paper introduces a pioneering localization framework called **metaloc**...\"\n        *   \"it comprises **two paradigms**...\"\n        *   \"we introduce a **new algorithm called maml-dg**...\"\n        *   \"overall, the main contributions of this work are fourfold: 1)outstanding localization performance... 3)innovative proposed paradigms...\"\n    *   section iii is titled \"the proposed system\" and details the \"metaloc framework\" and \"meta-learning\" concepts, including \"algorithm 1 vanilla maml.\"\n\nwhile the paper includes empirical validation (\"experiments on both synthetic and real datasets\") and some theoretical analysis (\"performance analysis of the vanilla maml,\" \"theorem 1\"), these elements serve to support and evaluate the **new methods, algorithms, and system** being presented. the core contribution is the development and description of metaloc itself."
      },
      "file_name": "79aa092bb37f5ab75d93195f2a5288a51bb8f21d.pdf"
    },
    {
      "success": true,
      "doc_id": "ec05b5f894b04647fa62be67b32f7724",
      "summary": "An unresolved problem in Deep Learning is the ability of neural networks to cope with domain shifts during test-time, imposed by commonly fixing network parameters after training. Our proposed method Meta Test-Time Training (MT3), however, breaks this paradigm and enables adaption at test-time. We combine meta-learning, self-supervision and test-time training to learn to adapt to unseen test distributions. By minimizing the self-supervised loss, we learn task-specific model parameters for different tasks. A meta-model is optimized such that its adaption to the different task-specific models leads to higher performance on those tasks. During test-time a single unlabeled image is sufficient to adapt the meta-model parameters. This is achieved by minimizing only the self-supervised loss component resulting in a better prediction for that image. Our approach significantly improves the state-of-the-art results on the CIFAR-10-Corrupted image classification benchmark. Our implementation is available on GitHub.",
      "intriguing_abstract": "An unresolved problem in Deep Learning is the ability of neural networks to cope with domain shifts during test-time, imposed by commonly fixing network parameters after training. Our proposed method Meta Test-Time Training (MT3), however, breaks this paradigm and enables adaption at test-time. We combine meta-learning, self-supervision and test-time training to learn to adapt to unseen test distributions. By minimizing the self-supervised loss, we learn task-specific model parameters for different tasks. A meta-model is optimized such that its adaption to the different task-specific models leads to higher performance on those tasks. During test-time a single unlabeled image is sufficient to adapt the meta-model parameters. This is achieved by minimizing only the self-supervised loss component resulting in a better prediction for that image. Our approach significantly improves the state-of-the-art results on the CIFAR-10-Corrupted image classification benchmark. Our implementation is available on GitHub.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/51cb7ff41dc6e97a83151e2b7daff87a77d14490.pdf",
      "citation_key": "bartler2021i8o",
      "metadata": {
        "title": "MT3: Meta Test-Time Training for Self-Supervised Test-Time Adaption",
        "authors": [
          "Alexander Bartler",
          "Andreas Bühler",
          "Felix Wiewel",
          "Mario Döbler",
          "Binh Yang"
        ],
        "published_date": "2021",
        "abstract": "An unresolved problem in Deep Learning is the ability of neural networks to cope with domain shifts during test-time, imposed by commonly fixing network parameters after training. Our proposed method Meta Test-Time Training (MT3), however, breaks this paradigm and enables adaption at test-time. We combine meta-learning, self-supervision and test-time training to learn to adapt to unseen test distributions. By minimizing the self-supervised loss, we learn task-specific model parameters for different tasks. A meta-model is optimized such that its adaption to the different task-specific models leads to higher performance on those tasks. During test-time a single unlabeled image is sufficient to adapt the meta-model parameters. This is achieved by minimizing only the self-supervised loss component resulting in a better prediction for that image. Our approach significantly improves the state-of-the-art results on the CIFAR-10-Corrupted image classification benchmark. Our implementation is available on GitHub.",
        "file_path": "paper_data/Deep_Meta-Learning/info/51cb7ff41dc6e97a83151e2b7daff87a77d14490.pdf",
        "venue": "International Conference on Artificial Intelligence and Statistics",
        "citationCount": 92,
        "score": 23.0,
        "summary": "An unresolved problem in Deep Learning is the ability of neural networks to cope with domain shifts during test-time, imposed by commonly fixing network parameters after training. Our proposed method Meta Test-Time Training (MT3), however, breaks this paradigm and enables adaption at test-time. We combine meta-learning, self-supervision and test-time training to learn to adapt to unseen test distributions. By minimizing the self-supervised loss, we learn task-specific model parameters for different tasks. A meta-model is optimized such that its adaption to the different task-specific models leads to higher performance on those tasks. During test-time a single unlabeled image is sufficient to adapt the meta-model parameters. This is achieved by minimizing only the self-supervised loss component resulting in a better prediction for that image. Our approach significantly improves the state-of-the-art results on the CIFAR-10-Corrupted image classification benchmark. Our implementation is available on GitHub.",
        "keywords": []
      },
      "file_name": "51cb7ff41dc6e97a83151e2b7daff87a77d14490.pdf"
    },
    {
      "success": true,
      "doc_id": "dba53d45b8c51d765d3587bce0bb9410",
      "summary": "Agriculture is essential to the growth of every country. Cotton and other major crops fall into the cash crops. Cotton is affected by most of the diseases that cause significant crop damage. Many diseases affect yield through the leaf. Detecting disease early saves crop from further damage. Cotton is susceptible to several diseases, including leaf spot, target spot, bacterial blight, nutrient deficiency, powdery mildew, leaf curl, etc. Accurate disease identification is important for taking effective measures. Deep learning in the identification of plant disease plays an important role. The proposed model based on meta Deep Learning is used to identify several cotton leaf diseases accurately. We gathered cotton leaf images from the field for this study. The dataset contains 2385 images of healthy and diseased leaves. The size of the dataset was increased with the help of the data augmentation approach. The dataset was trained on Custom CNN, VGG16 Transfer Learning, ResNet50, and our proposed model: the meta deep learn leaf disease identification model. A meta learning technique has been proposed and implemented to provide a good accuracy and generalization. The proposed model has outperformed the Cotton Dataset with an accuracy of 98.53%.",
      "intriguing_abstract": "Agriculture is essential to the growth of every country. Cotton and other major crops fall into the cash crops. Cotton is affected by most of the diseases that cause significant crop damage. Many diseases affect yield through the leaf. Detecting disease early saves crop from further damage. Cotton is susceptible to several diseases, including leaf spot, target spot, bacterial blight, nutrient deficiency, powdery mildew, leaf curl, etc. Accurate disease identification is important for taking effective measures. Deep learning in the identification of plant disease plays an important role. The proposed model based on meta Deep Learning is used to identify several cotton leaf diseases accurately. We gathered cotton leaf images from the field for this study. The dataset contains 2385 images of healthy and diseased leaves. The size of the dataset was increased with the help of the data augmentation approach. The dataset was trained on Custom CNN, VGG16 Transfer Learning, ResNet50, and our proposed model: the meta deep learn leaf disease identification model. A meta learning technique has been proposed and implemented to provide a good accuracy and generalization. The proposed model has outperformed the Cotton Dataset with an accuracy of 98.53%.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/72d6ea4a92e3b30e3520e6fe10de06e27ece0775.pdf",
      "citation_key": "memon2022j2y",
      "metadata": {
        "title": "Meta Deep Learn Leaf Disease Identification Model for Cotton Crop",
        "authors": [
          "M. Memon",
          "Pardeep Kumar",
          "R. Iqbal"
        ],
        "published_date": "2022",
        "abstract": "Agriculture is essential to the growth of every country. Cotton and other major crops fall into the cash crops. Cotton is affected by most of the diseases that cause significant crop damage. Many diseases affect yield through the leaf. Detecting disease early saves crop from further damage. Cotton is susceptible to several diseases, including leaf spot, target spot, bacterial blight, nutrient deficiency, powdery mildew, leaf curl, etc. Accurate disease identification is important for taking effective measures. Deep learning in the identification of plant disease plays an important role. The proposed model based on meta Deep Learning is used to identify several cotton leaf diseases accurately. We gathered cotton leaf images from the field for this study. The dataset contains 2385 images of healthy and diseased leaves. The size of the dataset was increased with the help of the data augmentation approach. The dataset was trained on Custom CNN, VGG16 Transfer Learning, ResNet50, and our proposed model: the meta deep learn leaf disease identification model. A meta learning technique has been proposed and implemented to provide a good accuracy and generalization. The proposed model has outperformed the Cotton Dataset with an accuracy of 98.53%.",
        "file_path": "paper_data/Deep_Meta-Learning/info/72d6ea4a92e3b30e3520e6fe10de06e27ece0775.pdf",
        "venue": "De Computis",
        "citationCount": 68,
        "score": 22.666666666666664,
        "summary": "Agriculture is essential to the growth of every country. Cotton and other major crops fall into the cash crops. Cotton is affected by most of the diseases that cause significant crop damage. Many diseases affect yield through the leaf. Detecting disease early saves crop from further damage. Cotton is susceptible to several diseases, including leaf spot, target spot, bacterial blight, nutrient deficiency, powdery mildew, leaf curl, etc. Accurate disease identification is important for taking effective measures. Deep learning in the identification of plant disease plays an important role. The proposed model based on meta Deep Learning is used to identify several cotton leaf diseases accurately. We gathered cotton leaf images from the field for this study. The dataset contains 2385 images of healthy and diseased leaves. The size of the dataset was increased with the help of the data augmentation approach. The dataset was trained on Custom CNN, VGG16 Transfer Learning, ResNet50, and our proposed model: the meta deep learn leaf disease identification model. A meta learning technique has been proposed and implemented to provide a good accuracy and generalization. The proposed model has outperformed the Cotton Dataset with an accuracy of 98.53%.",
        "keywords": []
      },
      "file_name": "72d6ea4a92e3b30e3520e6fe10de06e27ece0775.pdf"
    },
    {
      "success": true,
      "doc_id": "05b05e7b1c79c53e05f2568592279c35",
      "summary": "Robotic control in a continuous action space has long been a challenging topic. This is especially true when controlling robots to solve compound tasks, as both basic skills and compound skills need to be learned. In this paper, we propose a hierarchical deep reinforcement learning algorithm to learn basic skills and compound skills simultaneously. In the proposed algorithm, compound skills and basic skills are learned by two levels of hierarchy. In the first level of hierarchy, each basic skill is handled by its own actor, overseen by a shared basic critic. Then, in the second level of hierarchy, compound skills are learned by a meta critic by reusing basic skills. The proposed algorithm was evaluated on a Pioneer 3AT robot in three different navigation scenarios with fully observable tasks. The simulations were built in Gazebo 2 in a robot operating system Indigo environment. The results show that the proposed algorithm can learn both high performance basic skills and compound skills through the same learning process. The compound skills learned outperform those learned by a discrete action space deep reinforcement learning algorithm.",
      "intriguing_abstract": "Robotic control in a continuous action space has long been a challenging topic. This is especially true when controlling robots to solve compound tasks, as both basic skills and compound skills need to be learned. In this paper, we propose a hierarchical deep reinforcement learning algorithm to learn basic skills and compound skills simultaneously. In the proposed algorithm, compound skills and basic skills are learned by two levels of hierarchy. In the first level of hierarchy, each basic skill is handled by its own actor, overseen by a shared basic critic. Then, in the second level of hierarchy, compound skills are learned by a meta critic by reusing basic skills. The proposed algorithm was evaluated on a Pioneer 3AT robot in three different navigation scenarios with fully observable tasks. The simulations were built in Gazebo 2 in a robot operating system Indigo environment. The results show that the proposed algorithm can learn both high performance basic skills and compound skills through the same learning process. The compound skills learned outperform those learned by a discrete action space deep reinforcement learning algorithm.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/bf8d58faf972ad0a1026c0a7c5577c07996ef3a7.pdf",
      "citation_key": "yang2018p36",
      "metadata": {
        "title": "Hierarchical Deep Reinforcement Learning for Continuous Action Control",
        "authors": [
          "Zhaoyang Yang",
          "K. Merrick",
          "Lianwen Jin",
          "H. Abbass"
        ],
        "published_date": "2018",
        "abstract": "Robotic control in a continuous action space has long been a challenging topic. This is especially true when controlling robots to solve compound tasks, as both basic skills and compound skills need to be learned. In this paper, we propose a hierarchical deep reinforcement learning algorithm to learn basic skills and compound skills simultaneously. In the proposed algorithm, compound skills and basic skills are learned by two levels of hierarchy. In the first level of hierarchy, each basic skill is handled by its own actor, overseen by a shared basic critic. Then, in the second level of hierarchy, compound skills are learned by a meta critic by reusing basic skills. The proposed algorithm was evaluated on a Pioneer 3AT robot in three different navigation scenarios with fully observable tasks. The simulations were built in Gazebo 2 in a robot operating system Indigo environment. The results show that the proposed algorithm can learn both high performance basic skills and compound skills through the same learning process. The compound skills learned outperform those learned by a discrete action space deep reinforcement learning algorithm.",
        "file_path": "paper_data/Deep_Meta-Learning/info/bf8d58faf972ad0a1026c0a7c5577c07996ef3a7.pdf",
        "venue": "IEEE Transactions on Neural Networks and Learning Systems",
        "citationCount": 158,
        "score": 22.57142857142857,
        "summary": "Robotic control in a continuous action space has long been a challenging topic. This is especially true when controlling robots to solve compound tasks, as both basic skills and compound skills need to be learned. In this paper, we propose a hierarchical deep reinforcement learning algorithm to learn basic skills and compound skills simultaneously. In the proposed algorithm, compound skills and basic skills are learned by two levels of hierarchy. In the first level of hierarchy, each basic skill is handled by its own actor, overseen by a shared basic critic. Then, in the second level of hierarchy, compound skills are learned by a meta critic by reusing basic skills. The proposed algorithm was evaluated on a Pioneer 3AT robot in three different navigation scenarios with fully observable tasks. The simulations were built in Gazebo 2 in a robot operating system Indigo environment. The results show that the proposed algorithm can learn both high performance basic skills and compound skills through the same learning process. The compound skills learned outperform those learned by a discrete action space deep reinforcement learning algorithm.",
        "keywords": []
      },
      "file_name": "bf8d58faf972ad0a1026c0a7c5577c07996ef3a7.pdf"
    },
    {
      "success": true,
      "doc_id": "f19f37ed0dfc8e38ebf4bde315c5e029",
      "summary": "Click-Through Rate (CTR) prediction is critical for industrial recommender systems, where most deep CTR models follow an Embedding & Feature Interaction paradigm. However, the majority of methods focus on designing network architectures to better capture feature interactions while the feature embedding, especially for numerical features, has been overlooked. Existing approaches for numerical features are difficult to capture informative knowledge because of the low capacity or hard discretization based on the offline expertise feature engineering. In this paper, we propose a novel embedding learning framework for numerical features in CTR prediction (AutoDis) with high model capacity, end-to-end training and unique representation properties preserved. AutoDis consists of three core components: meta-embeddings, automatic discretization and aggregation. Specifically, we propose meta-embeddings for each numerical field to learn global knowledge from the perspective of field with a manageable number of parameters. Then the differentiable automatic discretization performs soft discretization and captures the correlations between the numerical features and meta-embeddings. Finally, distinctive and informative embeddings are learned via an aggregation function. Comprehensive experiments on two public and one industrial datasets are conducted to validate the effectiveness of AutoDis. Moreover, AutoDis has been deployed onto a mainstream advertising platform, where online A/B test demonstrates the improvement over the base model by 2.1% and 2.7% in terms of CTR and eCPM, respectively. In addition, the code of our framework is publicly available in MindSpore.",
      "intriguing_abstract": "Click-Through Rate (CTR) prediction is critical for industrial recommender systems, where most deep CTR models follow an Embedding & Feature Interaction paradigm. However, the majority of methods focus on designing network architectures to better capture feature interactions while the feature embedding, especially for numerical features, has been overlooked. Existing approaches for numerical features are difficult to capture informative knowledge because of the low capacity or hard discretization based on the offline expertise feature engineering. In this paper, we propose a novel embedding learning framework for numerical features in CTR prediction (AutoDis) with high model capacity, end-to-end training and unique representation properties preserved. AutoDis consists of three core components: meta-embeddings, automatic discretization and aggregation. Specifically, we propose meta-embeddings for each numerical field to learn global knowledge from the perspective of field with a manageable number of parameters. Then the differentiable automatic discretization performs soft discretization and captures the correlations between the numerical features and meta-embeddings. Finally, distinctive and informative embeddings are learned via an aggregation function. Comprehensive experiments on two public and one industrial datasets are conducted to validate the effectiveness of AutoDis. Moreover, AutoDis has been deployed onto a mainstream advertising platform, where online A/B test demonstrates the improvement over the base model by 2.1% and 2.7% in terms of CTR and eCPM, respectively. In addition, the code of our framework is publicly available in MindSpore.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5276a6bc74aacf30cc7dc0bfe4d08a2cdec8571b.pdf",
      "citation_key": "guo2020acf",
      "metadata": {
        "title": "An Embedding Learning Framework for Numerical Features in CTR Prediction",
        "authors": [
          "Huifeng Guo",
          "Bo Chen",
          "Ruiming Tang",
          "Weinan Zhang",
          "Zhenguo Li",
          "Xiuqiang He"
        ],
        "published_date": "2020",
        "abstract": "Click-Through Rate (CTR) prediction is critical for industrial recommender systems, where most deep CTR models follow an Embedding & Feature Interaction paradigm. However, the majority of methods focus on designing network architectures to better capture feature interactions while the feature embedding, especially for numerical features, has been overlooked. Existing approaches for numerical features are difficult to capture informative knowledge because of the low capacity or hard discretization based on the offline expertise feature engineering. In this paper, we propose a novel embedding learning framework for numerical features in CTR prediction (AutoDis) with high model capacity, end-to-end training and unique representation properties preserved. AutoDis consists of three core components: meta-embeddings, automatic discretization and aggregation. Specifically, we propose meta-embeddings for each numerical field to learn global knowledge from the perspective of field with a manageable number of parameters. Then the differentiable automatic discretization performs soft discretization and captures the correlations between the numerical features and meta-embeddings. Finally, distinctive and informative embeddings are learned via an aggregation function. Comprehensive experiments on two public and one industrial datasets are conducted to validate the effectiveness of AutoDis. Moreover, AutoDis has been deployed onto a mainstream advertising platform, where online A/B test demonstrates the improvement over the base model by 2.1% and 2.7% in terms of CTR and eCPM, respectively. In addition, the code of our framework is publicly available in MindSpore.",
        "file_path": "paper_data/Deep_Meta-Learning/info/5276a6bc74aacf30cc7dc0bfe4d08a2cdec8571b.pdf",
        "venue": "Knowledge Discovery and Data Mining",
        "citationCount": 110,
        "score": 22.0,
        "summary": "Click-Through Rate (CTR) prediction is critical for industrial recommender systems, where most deep CTR models follow an Embedding & Feature Interaction paradigm. However, the majority of methods focus on designing network architectures to better capture feature interactions while the feature embedding, especially for numerical features, has been overlooked. Existing approaches for numerical features are difficult to capture informative knowledge because of the low capacity or hard discretization based on the offline expertise feature engineering. In this paper, we propose a novel embedding learning framework for numerical features in CTR prediction (AutoDis) with high model capacity, end-to-end training and unique representation properties preserved. AutoDis consists of three core components: meta-embeddings, automatic discretization and aggregation. Specifically, we propose meta-embeddings for each numerical field to learn global knowledge from the perspective of field with a manageable number of parameters. Then the differentiable automatic discretization performs soft discretization and captures the correlations between the numerical features and meta-embeddings. Finally, distinctive and informative embeddings are learned via an aggregation function. Comprehensive experiments on two public and one industrial datasets are conducted to validate the effectiveness of AutoDis. Moreover, AutoDis has been deployed onto a mainstream advertising platform, where online A/B test demonstrates the improvement over the base model by 2.1% and 2.7% in terms of CTR and eCPM, respectively. In addition, the code of our framework is publicly available in MindSpore.",
        "keywords": []
      },
      "file_name": "5276a6bc74aacf30cc7dc0bfe4d08a2cdec8571b.pdf"
    },
    {
      "success": true,
      "doc_id": "ae8b3325979841140b1cbe27c5a84f56",
      "summary": "The industrial advancement has promoted the development of deep learning (DL)-based intelligent fault diagnosis methods for condition-based maintenance (CBM). Though these methods rely on large dataset for training, the collection of large number of fault samples is not practically feasible. For this purpose, generative adversarial networks (GANs) are capable to generate high-quality synthetic samples. However, the problem still persists with the training of GAN using limited fault samples that are present in practical conditions. This article proposes a novel conditional auxiliary classifier GAN framework coupled with model agnostic meta learning (MAML) to resolve this problem. The objective is to initialize and update the network parameters using MAML instead of regular stochastic gradient learning. This modification enables GAN to learn the task of synthetic sample generation using the limited training dataset. The effectiveness of the proposed framework has been compared with several famous state-of-the-art intelligent fault diagnosis methods existing in the literature. The comparative performance has been validated on benchmarked datasets, i.e., air compressor and bearing datasets collected from a single-stage reciprocating air compressor. The proposed framework is able to achieve the classification accuracy of 99.26% and 98.55% for bearing and air compressor datasets, respectively, with only ten samples per class. Moreover, a real-time case study is performed to validate the proposed method in real time.",
      "intriguing_abstract": "The industrial advancement has promoted the development of deep learning (DL)-based intelligent fault diagnosis methods for condition-based maintenance (CBM). Though these methods rely on large dataset for training, the collection of large number of fault samples is not practically feasible. For this purpose, generative adversarial networks (GANs) are capable to generate high-quality synthetic samples. However, the problem still persists with the training of GAN using limited fault samples that are present in practical conditions. This article proposes a novel conditional auxiliary classifier GAN framework coupled with model agnostic meta learning (MAML) to resolve this problem. The objective is to initialize and update the network parameters using MAML instead of regular stochastic gradient learning. This modification enables GAN to learn the task of synthetic sample generation using the limited training dataset. The effectiveness of the proposed framework has been compared with several famous state-of-the-art intelligent fault diagnosis methods existing in the literature. The comparative performance has been validated on benchmarked datasets, i.e., air compressor and bearing datasets collected from a single-stage reciprocating air compressor. The proposed framework is able to achieve the classification accuracy of 99.26% and 98.55% for bearing and air compressor datasets, respectively, with only ten samples per class. Moreover, a real-time case study is performed to validate the proposed method in real time.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/03778809fb16471490c57e1259ddf56a23f06ab5.pdf",
      "citation_key": "dixit20218dd",
      "metadata": {
        "title": "Intelligent Fault Diagnosis of Rotary Machines: Conditional Auxiliary Classifier GAN Coupled With Meta Learning Using Limited Data",
        "authors": [
          "Sonal Dixit",
          "N. Verma",
          "A. K. Ghosh"
        ],
        "published_date": "2021",
        "abstract": "The industrial advancement has promoted the development of deep learning (DL)-based intelligent fault diagnosis methods for condition-based maintenance (CBM). Though these methods rely on large dataset for training, the collection of large number of fault samples is not practically feasible. For this purpose, generative adversarial networks (GANs) are capable to generate high-quality synthetic samples. However, the problem still persists with the training of GAN using limited fault samples that are present in practical conditions. This article proposes a novel conditional auxiliary classifier GAN framework coupled with model agnostic meta learning (MAML) to resolve this problem. The objective is to initialize and update the network parameters using MAML instead of regular stochastic gradient learning. This modification enables GAN to learn the task of synthetic sample generation using the limited training dataset. The effectiveness of the proposed framework has been compared with several famous state-of-the-art intelligent fault diagnosis methods existing in the literature. The comparative performance has been validated on benchmarked datasets, i.e., air compressor and bearing datasets collected from a single-stage reciprocating air compressor. The proposed framework is able to achieve the classification accuracy of 99.26% and 98.55% for bearing and air compressor datasets, respectively, with only ten samples per class. Moreover, a real-time case study is performed to validate the proposed method in real time.",
        "file_path": "paper_data/Deep_Meta-Learning/info/03778809fb16471490c57e1259ddf56a23f06ab5.pdf",
        "venue": "IEEE Transactions on Instrumentation and Measurement",
        "citationCount": 87,
        "score": 21.75,
        "summary": "The industrial advancement has promoted the development of deep learning (DL)-based intelligent fault diagnosis methods for condition-based maintenance (CBM). Though these methods rely on large dataset for training, the collection of large number of fault samples is not practically feasible. For this purpose, generative adversarial networks (GANs) are capable to generate high-quality synthetic samples. However, the problem still persists with the training of GAN using limited fault samples that are present in practical conditions. This article proposes a novel conditional auxiliary classifier GAN framework coupled with model agnostic meta learning (MAML) to resolve this problem. The objective is to initialize and update the network parameters using MAML instead of regular stochastic gradient learning. This modification enables GAN to learn the task of synthetic sample generation using the limited training dataset. The effectiveness of the proposed framework has been compared with several famous state-of-the-art intelligent fault diagnosis methods existing in the literature. The comparative performance has been validated on benchmarked datasets, i.e., air compressor and bearing datasets collected from a single-stage reciprocating air compressor. The proposed framework is able to achieve the classification accuracy of 99.26% and 98.55% for bearing and air compressor datasets, respectively, with only ten samples per class. Moreover, a real-time case study is performed to validate the proposed method in real time.",
        "keywords": []
      },
      "file_name": "03778809fb16471490c57e1259ddf56a23f06ab5.pdf"
    },
    {
      "success": true,
      "doc_id": "9acdecb3c31616deacf4ac68bf5699c8",
      "summary": "Many successful deep learning architectures are equivariant to certain transformations in order to conserve parameters and improve generalization: most famously, convolution layers are equivariant to shifts of the input. This approach only works when practitioners know a-priori symmetries of the task and can manually construct an architecture with the corresponding equivariances. Our goal is a general approach for learning equivariances from data, without needing prior knowledge of a task's symmetries or custom task-specific architectures. We present a method for learning and encoding equivariances into networks by learning corresponding parameter sharing patterns from data. Our method can provably encode equivariance-inducing parameter sharing for any finite group of symmetry transformations, and we find experimentally that it can automatically learn a variety of equivariances from symmetries in data. We provide our experiment code and pre-trained models at this https URL.",
      "intriguing_abstract": "Many successful deep learning architectures are equivariant to certain transformations in order to conserve parameters and improve generalization: most famously, convolution layers are equivariant to shifts of the input. This approach only works when practitioners know a-priori symmetries of the task and can manually construct an architecture with the corresponding equivariances. Our goal is a general approach for learning equivariances from data, without needing prior knowledge of a task's symmetries or custom task-specific architectures. We present a method for learning and encoding equivariances into networks by learning corresponding parameter sharing patterns from data. Our method can provably encode equivariance-inducing parameter sharing for any finite group of symmetry transformations, and we find experimentally that it can automatically learn a variety of equivariances from symmetries in data. We provide our experiment code and pre-trained models at this https URL.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2e072998dd7b40e9e514b2bb43c8074bd5aa43d2.pdf",
      "citation_key": "zhou20200ls",
      "metadata": {
        "title": "Meta-Learning Symmetries by Reparameterization",
        "authors": [
          "Allan Zhou",
          "Tom Knowles",
          "Chelsea Finn"
        ],
        "published_date": "2020",
        "abstract": "Many successful deep learning architectures are equivariant to certain transformations in order to conserve parameters and improve generalization: most famously, convolution layers are equivariant to shifts of the input. This approach only works when practitioners know a-priori symmetries of the task and can manually construct an architecture with the corresponding equivariances. Our goal is a general approach for learning equivariances from data, without needing prior knowledge of a task's symmetries or custom task-specific architectures. We present a method for learning and encoding equivariances into networks by learning corresponding parameter sharing patterns from data. Our method can provably encode equivariance-inducing parameter sharing for any finite group of symmetry transformations, and we find experimentally that it can automatically learn a variety of equivariances from symmetries in data. We provide our experiment code and pre-trained models at this https URL.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2e072998dd7b40e9e514b2bb43c8074bd5aa43d2.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 102,
        "score": 20.400000000000002,
        "summary": "Many successful deep learning architectures are equivariant to certain transformations in order to conserve parameters and improve generalization: most famously, convolution layers are equivariant to shifts of the input. This approach only works when practitioners know a-priori symmetries of the task and can manually construct an architecture with the corresponding equivariances. Our goal is a general approach for learning equivariances from data, without needing prior knowledge of a task's symmetries or custom task-specific architectures. We present a method for learning and encoding equivariances into networks by learning corresponding parameter sharing patterns from data. Our method can provably encode equivariance-inducing parameter sharing for any finite group of symmetry transformations, and we find experimentally that it can automatically learn a variety of equivariances from symmetries in data. We provide our experiment code and pre-trained models at this https URL.",
        "keywords": []
      },
      "file_name": "2e072998dd7b40e9e514b2bb43c8074bd5aa43d2.pdf"
    },
    {
      "success": true,
      "doc_id": "33f62fba04c45c18a2bb496e57102bfc",
      "summary": "Real-world contains an overwhelmingly large number of object classes, learning all of which at once is infeasible. Few shot learning is a promising learning paradigm due to its ability to learn out of order distributions quickly with only a few samples. Recent works [7, 41] show that simply learning a good feature embedding can outperform more sophisticated meta-learning and metric learning algorithms for few-shot learning. In this paper, we propose a simple approach to improve the representation capacity of deep neural networks for few-shot learning tasks. We follow a two-stage learning process: First, we train a neural network to maximize the entropy of the feature embedding, thus creating an optimal output manifold using a self-supervised auxiliary loss. In the second stage, we minimize the entropy on feature embedding by bringing self-supervised twins together, while constraining the manifold with student-teacher distillation. Our experiments show that, even in the first stage, self-supervision can outperform current state-of-the-art methods, with further gains achieved by our second stage distillation process. Our codes are available at: this https URL.",
      "intriguing_abstract": "Real-world contains an overwhelmingly large number of object classes, learning all of which at once is infeasible. Few shot learning is a promising learning paradigm due to its ability to learn out of order distributions quickly with only a few samples. Recent works [7, 41] show that simply learning a good feature embedding can outperform more sophisticated meta-learning and metric learning algorithms for few-shot learning. In this paper, we propose a simple approach to improve the representation capacity of deep neural networks for few-shot learning tasks. We follow a two-stage learning process: First, we train a neural network to maximize the entropy of the feature embedding, thus creating an optimal output manifold using a self-supervised auxiliary loss. In the second stage, we minimize the entropy on feature embedding by bringing self-supervised twins together, while constraining the manifold with student-teacher distillation. Our experiments show that, even in the first stage, self-supervision can outperform current state-of-the-art methods, with further gains achieved by our second stage distillation process. Our codes are available at: this https URL.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e35e0ad5959c3160d66309c3c1e10df9b4352c6d.pdf",
      "citation_key": "rajasegaran2020glw",
      "metadata": {
        "title": "Self-supervised Knowledge Distillation for Few-shot Learning",
        "authors": [
          "Jathushan Rajasegaran",
          "Salman Hameed Khan",
          "Munawar Hayat",
          "F. Khan",
          "M. Shah"
        ],
        "published_date": "2020",
        "abstract": "Real-world contains an overwhelmingly large number of object classes, learning all of which at once is infeasible. Few shot learning is a promising learning paradigm due to its ability to learn out of order distributions quickly with only a few samples. Recent works [7, 41] show that simply learning a good feature embedding can outperform more sophisticated meta-learning and metric learning algorithms for few-shot learning. In this paper, we propose a simple approach to improve the representation capacity of deep neural networks for few-shot learning tasks. We follow a two-stage learning process: First, we train a neural network to maximize the entropy of the feature embedding, thus creating an optimal output manifold using a self-supervised auxiliary loss. In the second stage, we minimize the entropy on feature embedding by bringing self-supervised twins together, while constraining the manifold with student-teacher distillation. Our experiments show that, even in the first stage, self-supervision can outperform current state-of-the-art methods, with further gains achieved by our second stage distillation process. Our codes are available at: this https URL.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e35e0ad5959c3160d66309c3c1e10df9b4352c6d.pdf",
        "venue": "British Machine Vision Conference",
        "citationCount": 100,
        "score": 20.0,
        "summary": "Real-world contains an overwhelmingly large number of object classes, learning all of which at once is infeasible. Few shot learning is a promising learning paradigm due to its ability to learn out of order distributions quickly with only a few samples. Recent works [7, 41] show that simply learning a good feature embedding can outperform more sophisticated meta-learning and metric learning algorithms for few-shot learning. In this paper, we propose a simple approach to improve the representation capacity of deep neural networks for few-shot learning tasks. We follow a two-stage learning process: First, we train a neural network to maximize the entropy of the feature embedding, thus creating an optimal output manifold using a self-supervised auxiliary loss. In the second stage, we minimize the entropy on feature embedding by bringing self-supervised twins together, while constraining the manifold with student-teacher distillation. Our experiments show that, even in the first stage, self-supervision can outperform current state-of-the-art methods, with further gains achieved by our second stage distillation process. Our codes are available at: this https URL.",
        "keywords": []
      },
      "file_name": "e35e0ad5959c3160d66309c3c1e10df9b4352c6d.pdf"
    },
    {
      "success": true,
      "doc_id": "112a4d6eb7a54bd362bc61583b8e5f2c",
      "summary": "When predicting data for which limited supervised information is available, hyperspectral target detection methods based on deep transfer learning expect that the network will not require considerable retraining to generalize to unfamiliar application contexts. Meta-learning is an effective and practical framework for solving this problem in deep learning. This paper proposes a new meta-learning based hyperspectral target detection using Siamese network (MLSN). Firstly, a deep residual convolution feature embedding module is designed to embed spectral vectors into Euclidean feature space. Then, the triplet loss is used to learn the intraclass similarity and interclass dissimilarity between spectra in embedding feature space by using the known labeled source data on the designed three-channel Siamese network for meta-training. The learned meta-knowledge is updated with prior target spectrum through a designed two-channel Siamese network to quickly adapt to the new detection task. It should be noted that the parameters and structure of the deep residual convolution embedding modules of each channel in the Siamese network are identical. Lastly, the spatial information is combined, and the detection map of the two-channel Siamese network is processed by the guiding image filtering and morphological closing operation, and a final detection result is obtained. Based on the experimental analysis of six real hyperspectral image data sets, the proposed MLSN has shown its excellent comprehensive performance.",
      "intriguing_abstract": "When predicting data for which limited supervised information is available, hyperspectral target detection methods based on deep transfer learning expect that the network will not require considerable retraining to generalize to unfamiliar application contexts. Meta-learning is an effective and practical framework for solving this problem in deep learning. This paper proposes a new meta-learning based hyperspectral target detection using Siamese network (MLSN). Firstly, a deep residual convolution feature embedding module is designed to embed spectral vectors into Euclidean feature space. Then, the triplet loss is used to learn the intraclass similarity and interclass dissimilarity between spectra in embedding feature space by using the known labeled source data on the designed three-channel Siamese network for meta-training. The learned meta-knowledge is updated with prior target spectrum through a designed two-channel Siamese network to quickly adapt to the new detection task. It should be noted that the parameters and structure of the deep residual convolution embedding modules of each channel in the Siamese network are identical. Lastly, the spatial information is combined, and the detection map of the two-channel Siamese network is processed by the guiding image filtering and morphological closing operation, and a final detection result is obtained. Based on the experimental analysis of six real hyperspectral image data sets, the proposed MLSN has shown its excellent comprehensive performance.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2cc418271f790c2a25c0102d16db2fa7442991b6.pdf",
      "citation_key": "wang2022va1",
      "metadata": {
        "title": "Meta-Learning based Hyperspectral Target Detection using Siamese Network",
        "authors": [
          "Yulei Wang",
          "Xi Chen",
          "Fengchao Wang",
          "Meiping Song",
          "Chunyan Yu"
        ],
        "published_date": "2022",
        "abstract": "When predicting data for which limited supervised information is available, hyperspectral target detection methods based on deep transfer learning expect that the network will not require considerable retraining to generalize to unfamiliar application contexts. Meta-learning is an effective and practical framework for solving this problem in deep learning. This paper proposes a new meta-learning based hyperspectral target detection using Siamese network (MLSN). Firstly, a deep residual convolution feature embedding module is designed to embed spectral vectors into Euclidean feature space. Then, the triplet loss is used to learn the intraclass similarity and interclass dissimilarity between spectra in embedding feature space by using the known labeled source data on the designed three-channel Siamese network for meta-training. The learned meta-knowledge is updated with prior target spectrum through a designed two-channel Siamese network to quickly adapt to the new detection task. It should be noted that the parameters and structure of the deep residual convolution embedding modules of each channel in the Siamese network are identical. Lastly, the spatial information is combined, and the detection map of the two-channel Siamese network is processed by the guiding image filtering and morphological closing operation, and a final detection result is obtained. Based on the experimental analysis of six real hyperspectral image data sets, the proposed MLSN has shown its excellent comprehensive performance.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2cc418271f790c2a25c0102d16db2fa7442991b6.pdf",
        "venue": "IEEE Transactions on Geoscience and Remote Sensing",
        "citationCount": 57,
        "score": 19.0,
        "summary": "When predicting data for which limited supervised information is available, hyperspectral target detection methods based on deep transfer learning expect that the network will not require considerable retraining to generalize to unfamiliar application contexts. Meta-learning is an effective and practical framework for solving this problem in deep learning. This paper proposes a new meta-learning based hyperspectral target detection using Siamese network (MLSN). Firstly, a deep residual convolution feature embedding module is designed to embed spectral vectors into Euclidean feature space. Then, the triplet loss is used to learn the intraclass similarity and interclass dissimilarity between spectra in embedding feature space by using the known labeled source data on the designed three-channel Siamese network for meta-training. The learned meta-knowledge is updated with prior target spectrum through a designed two-channel Siamese network to quickly adapt to the new detection task. It should be noted that the parameters and structure of the deep residual convolution embedding modules of each channel in the Siamese network are identical. Lastly, the spatial information is combined, and the detection map of the two-channel Siamese network is processed by the guiding image filtering and morphological closing operation, and a final detection result is obtained. Based on the experimental analysis of six real hyperspectral image data sets, the proposed MLSN has shown its excellent comprehensive performance.",
        "keywords": []
      },
      "file_name": "2cc418271f790c2a25c0102d16db2fa7442991b6.pdf"
    },
    {
      "success": true,
      "doc_id": "ba9d06679407892acef9e769dc3101c7",
      "summary": "Traditional supervised learning with deep neural networks requires a tremendous amount of labelled data to converge to a good solution. For 3D medical images, it is often impractical to build a large homogeneous annotated dataset for a specific pathology. Self-supervised methods offer a new way to learn a representation of the images in an unsupervised manner with a neural network. In particular, contrastive learning has shown great promises by (almost) matching the performance of fully-supervised CNN on vision tasks. Nonetheless, this method does not take advantage of available meta-data, such as participant's age, viewed as prior knowledge. Here, we propose to leverage continuous proxy metadata, in the contrastive learning framework, by introducing a new loss called y-Aware InfoNCE loss. Specifically, we improve the positive sampling during pre-training by adding more positive examples with similar proxy meta-data with the anchor, assuming they share similar discriminative semantic features.With our method, a 3D CNN model pre-trained on $10^4$ multi-site healthy brain MRI scans can extract relevant features for three classification tasks: schizophrenia, bipolar diagnosis and Alzheimer's detection. When fine-tuned, it also outperforms 3D CNN trained from scratch on these tasks, as well as state-of-the-art self-supervised methods. Our code is made publicly available here.",
      "intriguing_abstract": "Traditional supervised learning with deep neural networks requires a tremendous amount of labelled data to converge to a good solution. For 3D medical images, it is often impractical to build a large homogeneous annotated dataset for a specific pathology. Self-supervised methods offer a new way to learn a representation of the images in an unsupervised manner with a neural network. In particular, contrastive learning has shown great promises by (almost) matching the performance of fully-supervised CNN on vision tasks. Nonetheless, this method does not take advantage of available meta-data, such as participant's age, viewed as prior knowledge. Here, we propose to leverage continuous proxy metadata, in the contrastive learning framework, by introducing a new loss called y-Aware InfoNCE loss. Specifically, we improve the positive sampling during pre-training by adding more positive examples with similar proxy meta-data with the anchor, assuming they share similar discriminative semantic features.With our method, a 3D CNN model pre-trained on $10^4$ multi-site healthy brain MRI scans can extract relevant features for three classification tasks: schizophrenia, bipolar diagnosis and Alzheimer's detection. When fine-tuned, it also outperforms 3D CNN trained from scratch on these tasks, as well as state-of-the-art self-supervised methods. Our code is made publicly available here.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/a2f64a00ce88326fcd047e0a88af6f47a495742e.pdf",
      "citation_key": "dufumier2021ec1",
      "metadata": {
        "title": "Contrastive Learning with Continuous Proxy Meta-Data for 3D MRI Classification",
        "authors": [
          "Benoit Dufumier",
          "P. Gori",
          "J. Victor",
          "A. Grigis",
          "M. Wessa",
          "P. Brambilla",
          "P. Favre",
          "M. Polosan",
          "C. Mcdonald",
          "C. Piguet",
          "E. Duchesnay"
        ],
        "published_date": "2021",
        "abstract": "Traditional supervised learning with deep neural networks requires a tremendous amount of labelled data to converge to a good solution. For 3D medical images, it is often impractical to build a large homogeneous annotated dataset for a specific pathology. Self-supervised methods offer a new way to learn a representation of the images in an unsupervised manner with a neural network. In particular, contrastive learning has shown great promises by (almost) matching the performance of fully-supervised CNN on vision tasks. Nonetheless, this method does not take advantage of available meta-data, such as participant's age, viewed as prior knowledge. Here, we propose to leverage continuous proxy metadata, in the contrastive learning framework, by introducing a new loss called y-Aware InfoNCE loss. Specifically, we improve the positive sampling during pre-training by adding more positive examples with similar proxy meta-data with the anchor, assuming they share similar discriminative semantic features.With our method, a 3D CNN model pre-trained on $10^4$ multi-site healthy brain MRI scans can extract relevant features for three classification tasks: schizophrenia, bipolar diagnosis and Alzheimer's detection. When fine-tuned, it also outperforms 3D CNN trained from scratch on these tasks, as well as state-of-the-art self-supervised methods. Our code is made publicly available here.",
        "file_path": "paper_data/Deep_Meta-Learning/info/a2f64a00ce88326fcd047e0a88af6f47a495742e.pdf",
        "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
        "citationCount": 75,
        "score": 18.75,
        "summary": "Traditional supervised learning with deep neural networks requires a tremendous amount of labelled data to converge to a good solution. For 3D medical images, it is often impractical to build a large homogeneous annotated dataset for a specific pathology. Self-supervised methods offer a new way to learn a representation of the images in an unsupervised manner with a neural network. In particular, contrastive learning has shown great promises by (almost) matching the performance of fully-supervised CNN on vision tasks. Nonetheless, this method does not take advantage of available meta-data, such as participant's age, viewed as prior knowledge. Here, we propose to leverage continuous proxy metadata, in the contrastive learning framework, by introducing a new loss called y-Aware InfoNCE loss. Specifically, we improve the positive sampling during pre-training by adding more positive examples with similar proxy meta-data with the anchor, assuming they share similar discriminative semantic features.With our method, a 3D CNN model pre-trained on $10^4$ multi-site healthy brain MRI scans can extract relevant features for three classification tasks: schizophrenia, bipolar diagnosis and Alzheimer's detection. When fine-tuned, it also outperforms 3D CNN trained from scratch on these tasks, as well as state-of-the-art self-supervised methods. Our code is made publicly available here.",
        "keywords": []
      },
      "file_name": "a2f64a00ce88326fcd047e0a88af6f47a495742e.pdf"
    },
    {
      "success": true,
      "doc_id": "223c7bfc25d0b0814f36d7b414a8bdc5",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION**: \\cite{wistuba2021wha}\n\n---\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Hyperparameter Optimization (HPO) is computationally intensive due to the high cost of evaluating the black-box response function (e.g., validation error). Existing transfer learning approaches for HPO often struggle with scalability and rapid adaptation to new tasks with limited evaluations.\n    *   **Importance & Challenge**: Efficient HPO is a cornerstone of automated machine learning (AutoML). The challenge lies in leveraging historical HPO data from other tasks to significantly reduce the number of evaluations needed for a *new* task, especially when only a *few* evaluations are permissible for that new task. Existing methods face issues with scalability (e.g., cubic complexity of Gaussian Processes) or effectively handling the diverse scales of response functions across different tasks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous transfer learning in HPO includes learning a single Gaussian Process (GP) for all data \\cite{bardenet2013bayesian, swersky2013multi}, ensembles of GPs (one per task) \\cite{wistuba2018scalable, feurer2018scalable}, and Bayesian Neural Networks (BNNs) with task embeddings or multi-task architectures \\cite{schilling2015bayesian, springenberg2016bayesian, perrone2018scalable}. Some work also focuses on warm-starting Bayesian Optimization (BO) with good initial settings \\cite{feurer2015initializing, wistuba2015bayesian}.\n    *   **Limitations of Previous Solutions**:\n        *   Single GP: Does not scale well (cubic complexity with data points).\n        *   Ensembles of GPs: Scales linearly with tasks but still cubically per task, limiting applicability with large datasets per task.\n        *   BNNs: Can be computationally intensive to train, or may not fully capture uncertainty. Many approaches involve task-specific parameters that grow with the number of tasks.\n        *   General: Most prior work does not explicitly frame HPO as a \"few-shot learning\" problem, nor do they robustly address the challenge of varying response function scales across tasks without requiring target-task specific normalization.\n    *   **Positioning**: This work proposes a novel paradigm by reconceptualizing transfer learning in HPO as a *few-shot learning problem*, aiming for a single, shared model that quickly adapts to new tasks with minimal evaluations, addressing scalability and adaptation challenges more directly.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**:\n        *   **Few-Shot Bayesian Optimization (FSBO)**: The core idea is to train a shared deep surrogate model that can quickly adapt to the response function of a new task with few evaluations.\n        *   **Deep Kernel Network for GP Surrogate**: A neural network (`phi`) transforms input hyperparameters into a latent representation, which then serves as input to a standard kernel function (`k`) for a Gaussian Process.\n        *   **End-to-End Meta-Learning**: The deep kernel parameters are meta-learned (trained) in an end-to-end fashion by maximizing the log marginal likelihood across a collection of source tasks. This allows the model to learn task-independent parameters that generalize well.\n        *   **Fine-tuning at Test Time**: For a new target task, the meta-learned deep kernel parameters are fine-tuned on the few available examples of that specific task.\n        *   **Task Augmentation Strategy**: During meta-training, labels for each batch are randomly scaled to a new range. This makes the learned representation invariant to different offsets and ranges of response functions, eliminating the need for target-task specific label normalization.\n        *   **Data-Driven Warm-Start Initialization**: An evolutionary algorithm is used to find an optimal set of initial hyperparameter settings by minimizing a loss (e.g., normalized regret) on the source tasks, leveraging the meta-learned surrogate model to approximate unknown function values.\n    *   **Novelty/Difference**:\n        *   First to frame transfer learning in HPO as a few-shot learning problem, directly addressing the need for rapid adaptation with limited new data.\n        *   The meta-learning approach for the deep kernel GP allows for a single, scalable model that adapts quickly, unlike task-specific models or less flexible transfer methods.\n        *   The task augmentation strategy is a novel and effective way to handle the label normalization problem across diverse HPO tasks, making the model robust without requiring target-task specific normalization.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **Few-Shot Bayesian Optimization (FSBO)**: A new framework for HPO that leverages meta-learning to enable rapid adaptation to new tasks with few evaluations.\n        *   **Meta-learned Deep Kernel Surrogate**: A deep kernel network for Gaussian Processes, whose parameters are meta-learned end-to-end across tasks, allowing for efficient knowledge transfer and quick adaptation.\n        *   **Task Augmentation Strategy**: A novel technique that randomly scales labels during meta-training to make the surrogate model invariant to varying response function scales, simplifying deployment on new tasks.\n        *   **Evolutionary Algorithm for Data-Driven Warm Start**: A method to intelligently initialize BO by selecting promising hyperparameter settings based on the meta-learned surrogate's predictions on source tasks.\n    *   **Theoretical Insights/Analysis**: The work leverages recent theoretical results (Chen et al., 2020) confirming the convergence of stochastic gradient ascent for marginal likelihood optimization even with correlated data (batches from a single task).\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Extensive empirical comparison against several state-of-the-art baselines (including methods published at ICLR and NeurIPS).\n        *   Evaluated on three diverse hyperparameter optimization problems: AdaBoost, GLMNet, and SVM.\n        *   Utilized metadata sets from OpenML (GLMNet, SVM) and a publicly available dataset (AdaBoost).\n        *   Ablation studies were performed to assess the impact of individual components, such as fine-tuning and the task augmentation strategy.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   Achieved **new state-of-the-art results** in transfer learning for HPO.\n        *   Demonstrated **statistically significant performance improvements** over strong baselines across diverse metadata sets.\n        *   A motivating example showed the method's ability to accurately reconstruct underlying functions with very few observations.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The stochastic gradient used for optimizing the marginal likelihood is a biased estimator, though theoretical guarantees for convergence exist.\n        *   The effectiveness of transfer learning inherently relies on the assumption that source tasks are sufficiently \"related\" to the target task.\n        *   The task augmentation strategy is applied only during meta-training on source tasks, not during fine-tuning on the target task.\n    *   **Scope of Applicability**:\n        *   Primarily applicable to HPO problems where a collection of historical HPO data (meta-data) from related tasks is available.\n        *   Well-suited for scenarios requiring rapid HPO with a limited budget of evaluations on new tasks.\n        *   Scales effectively to a large number of source tasks.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: Establishes a new state-of-the-art in transfer learning for HPO by introducing a robust, scalable, and rapidly adapting few-shot learning paradigm.\n    *   **Potential Impact on Future Research**:\n        *   **More Efficient AutoML**: Significantly reduces the computational burden and time for hyperparameter tuning, making AutoML more practical and accessible.\n        *   **Robustness and Generalization**: The meta-learned deep kernel and task augmentation strategy lead to more robust surrogate models that generalize better across diverse HPO tasks and are invariant to response function scaling.\n        *   **New Research Directions**: Opens avenues for applying meta-learning and few-shot learning to other expensive black-box optimization problems beyond HPO, especially where meta-data is available.\n        *   **Scalability**: Provides a solution that scales well with the number of source tasks, enabling the utilization of increasingly large meta-datasets.",
      "intriguing_abstract": "Hyperparameter Optimization (HPO) is a critical yet computationally prohibitive bottleneck in automated machine learning (AutoML), especially when rapid adaptation to new tasks with limited evaluations is required. Existing transfer learning approaches often falter due to scalability issues or an inability to robustly handle diverse response function scales. We introduce **Few-Shot Bayesian Optimization (FSBO)**, a novel framework that reconceptualizes HPO transfer as a few-shot learning problem, enabling unprecedented efficiency and adaptability.\n\nOur core innovation is an end-to-end meta-learned deep kernel for Gaussian Processes, which rapidly fine-tunes to new tasks with minimal data. A unique task augmentation strategy ensures robustness to varying response function scales, eliminating the need for target-task specific normalization. Furthermore, we propose a data-driven evolutionary warm-start initialization, leveraging the meta-learned surrogate. Extensive experiments demonstrate FSBO achieves **state-of-the-art performance**, significantly outperforming strong baselines across diverse HPO problems. This work paves the way for truly scalable and efficient AutoML, making advanced machine learning more accessible and robust.",
      "keywords": [
        "Hyperparameter Optimization (HPO)",
        "Few-Shot Bayesian Optimization (FSBO)",
        "Meta-learning",
        "Deep Kernel Network",
        "Gaussian Process (GP) Surrogate",
        "Task Augmentation Strategy",
        "Rapid adaptation",
        "Automated Machine Learning (AutoML)",
        "Transfer learning",
        "Scalability",
        "State-of-the-art results",
        "Data-Driven Warm-Start",
        "Black-box optimization",
        "Response function scaling invariance"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/aea3f03299ff0cfea9b394f5559aa1c173f9876f.pdf",
      "citation_key": "wistuba2021wha",
      "metadata": {
        "title": "Few-Shot Bayesian Optimization with Deep Kernel Surrogates",
        "authors": [
          "Martin Wistuba",
          "Josif Grabocka"
        ],
        "published_date": "2021",
        "abstract": "Hyperparameter optimization (HPO) is a central pillar in the automation of machine learning solutions and is mainly performed via Bayesian optimization, where a parametric surrogate is learned to approximate the black box response function (e.g. validation error). Unfortunately, evaluating the response function is computationally intensive. As a remedy, earlier work emphasizes the need for transfer learning surrogates which learn to optimize hyperparameters for an algorithm from other tasks. In contrast to previous work, we propose to rethink HPO as a few-shot learning problem in which we train a shared deep surrogate model to quickly adapt (with few response evaluations) to the response function of a new task. We propose the use of a deep kernel network for a Gaussian process surrogate that is meta-learned in an end-to-end fashion in order to jointly approximate the response functions of a collection of training data sets. As a result, the novel few-shot optimization of our deep kernel surrogate leads to new state-of-the-art results at HPO compared to several recent methods on diverse metadata sets.",
        "file_path": "paper_data/Deep_Meta-Learning/info/aea3f03299ff0cfea9b394f5559aa1c173f9876f.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 73,
        "score": 18.25,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **CITATION**: \\cite{wistuba2021wha}\n\n---\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Hyperparameter Optimization (HPO) is computationally intensive due to the high cost of evaluating the black-box response function (e.g., validation error). Existing transfer learning approaches for HPO often struggle with scalability and rapid adaptation to new tasks with limited evaluations.\n    *   **Importance & Challenge**: Efficient HPO is a cornerstone of automated machine learning (AutoML). The challenge lies in leveraging historical HPO data from other tasks to significantly reduce the number of evaluations needed for a *new* task, especially when only a *few* evaluations are permissible for that new task. Existing methods face issues with scalability (e.g., cubic complexity of Gaussian Processes) or effectively handling the diverse scales of response functions across different tasks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous transfer learning in HPO includes learning a single Gaussian Process (GP) for all data \\cite{bardenet2013bayesian, swersky2013multi}, ensembles of GPs (one per task) \\cite{wistuba2018scalable, feurer2018scalable}, and Bayesian Neural Networks (BNNs) with task embeddings or multi-task architectures \\cite{schilling2015bayesian, springenberg2016bayesian, perrone2018scalable}. Some work also focuses on warm-starting Bayesian Optimization (BO) with good initial settings \\cite{feurer2015initializing, wistuba2015bayesian}.\n    *   **Limitations of Previous Solutions**:\n        *   Single GP: Does not scale well (cubic complexity with data points).\n        *   Ensembles of GPs: Scales linearly with tasks but still cubically per task, limiting applicability with large datasets per task.\n        *   BNNs: Can be computationally intensive to train, or may not fully capture uncertainty. Many approaches involve task-specific parameters that grow with the number of tasks.\n        *   General: Most prior work does not explicitly frame HPO as a \"few-shot learning\" problem, nor do they robustly address the challenge of varying response function scales across tasks without requiring target-task specific normalization.\n    *   **Positioning**: This work proposes a novel paradigm by reconceptualizing transfer learning in HPO as a *few-shot learning problem*, aiming for a single, shared model that quickly adapts to new tasks with minimal evaluations, addressing scalability and adaptation challenges more directly.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**:\n        *   **Few-Shot Bayesian Optimization (FSBO)**: The core idea is to train a shared deep surrogate model that can quickly adapt to the response function of a new task with few evaluations.\n        *   **Deep Kernel Network for GP Surrogate**: A neural network (`phi`) transforms input hyperparameters into a latent representation, which then serves as input to a standard kernel function (`k`) for a Gaussian Process.\n        *   **End-to-End Meta-Learning**: The deep kernel parameters are meta-learned (trained) in an end-to-end fashion by maximizing the log marginal likelihood across a collection of source tasks. This allows the model to learn task-independent parameters that generalize well.\n        *   **Fine-tuning at Test Time**: For a new target task, the meta-learned deep kernel parameters are fine-tuned on the few available examples of that specific task.\n        *   **Task Augmentation Strategy**: During meta-training, labels for each batch are randomly scaled to a new range. This makes the learned representation invariant to different offsets and ranges of response functions, eliminating the need for target-task specific label normalization.\n        *   **Data-Driven Warm-Start Initialization**: An evolutionary algorithm is used to find an optimal set of initial hyperparameter settings by minimizing a loss (e.g., normalized regret) on the source tasks, leveraging the meta-learned surrogate model to approximate unknown function values.\n    *   **Novelty/Difference**:\n        *   First to frame transfer learning in HPO as a few-shot learning problem, directly addressing the need for rapid adaptation with limited new data.\n        *   The meta-learning approach for the deep kernel GP allows for a single, scalable model that adapts quickly, unlike task-specific models or less flexible transfer methods.\n        *   The task augmentation strategy is a novel and effective way to handle the label normalization problem across diverse HPO tasks, making the model robust without requiring target-task specific normalization.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   **Few-Shot Bayesian Optimization (FSBO)**: A new framework for HPO that leverages meta-learning to enable rapid adaptation to new tasks with few evaluations.\n        *   **Meta-learned Deep Kernel Surrogate**: A deep kernel network for Gaussian Processes, whose parameters are meta-learned end-to-end across tasks, allowing for efficient knowledge transfer and quick adaptation.\n        *   **Task Augmentation Strategy**: A novel technique that randomly scales labels during meta-training to make the surrogate model invariant to varying response function scales, simplifying deployment on new tasks.\n        *   **Evolutionary Algorithm for Data-Driven Warm Start**: A method to intelligently initialize BO by selecting promising hyperparameter settings based on the meta-learned surrogate's predictions on source tasks.\n    *   **Theoretical Insights/Analysis**: The work leverages recent theoretical results (Chen et al., 2020) confirming the convergence of stochastic gradient ascent for marginal likelihood optimization even with correlated data (batches from a single task).\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Extensive empirical comparison against several state-of-the-art baselines (including methods published at ICLR and NeurIPS).\n        *   Evaluated on three diverse hyperparameter optimization problems: AdaBoost, GLMNet, and SVM.\n        *   Utilized metadata sets from OpenML (GLMNet, SVM) and a publicly available dataset (AdaBoost).\n        *   Ablation studies were performed to assess the impact of individual components, such as fine-tuning and the task augmentation strategy.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   Achieved **new state-of-the-art results** in transfer learning for HPO.\n        *   Demonstrated **statistically significant performance improvements** over strong baselines across diverse metadata sets.\n        *   A motivating example showed the method's ability to accurately reconstruct underlying functions with very few observations.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The stochastic gradient used for optimizing the marginal likelihood is a biased estimator, though theoretical guarantees for convergence exist.\n        *   The effectiveness of transfer learning inherently relies on the assumption that source tasks are sufficiently \"related\" to the target task.\n        *   The task augmentation strategy is applied only during meta-training on source tasks, not during fine-tuning on the target task.\n    *   **Scope of Applicability**:\n        *   Primarily applicable to HPO problems where a collection of historical HPO data (meta-data) from related tasks is available.\n        *   Well-suited for scenarios requiring rapid HPO with a limited budget of evaluations on new tasks.\n        *   Scales effectively to a large number of source tasks.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art**: Establishes a new state-of-the-art in transfer learning for HPO by introducing a robust, scalable, and rapidly adapting few-shot learning paradigm.\n    *   **Potential Impact on Future Research**:\n        *   **More Efficient AutoML**: Significantly reduces the computational burden and time for hyperparameter tuning, making AutoML more practical and accessible.\n        *   **Robustness and Generalization**: The meta-learned deep kernel and task augmentation strategy lead to more robust surrogate models that generalize better across diverse HPO tasks and are invariant to response function scaling.\n        *   **New Research Directions**: Opens avenues for applying meta-learning and few-shot learning to other expensive black-box optimization problems beyond HPO, especially where meta-data is available.\n        *   **Scalability**: Provides a solution that scales well with the number of source tasks, enabling the utilization of increasingly large meta-datasets.",
        "keywords": [
          "Hyperparameter Optimization (HPO)",
          "Few-Shot Bayesian Optimization (FSBO)",
          "Meta-learning",
          "Deep Kernel Network",
          "Gaussian Process (GP) Surrogate",
          "Task Augmentation Strategy",
          "Rapid adaptation",
          "Automated Machine Learning (AutoML)",
          "Transfer learning",
          "Scalability",
          "State-of-the-art results",
          "Data-Driven Warm-Start",
          "Black-box optimization",
          "Response function scaling invariance"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **technical** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"we propose to rethink hpo as a few-shot learning problem,\" \"we propose the use of a deep kernel network for a gaussian process surrogate that is meta-learned.\" these phrases clearly indicate the development and presentation of a new method or system.\n*   **introduction discusses:** the problem of hyperparameter optimization, the limitations of existing bayesian optimization, and then immediately introduces the \"novel few-shot optimization of our deep kernel surrogate\" as the proposed solution. it details the technical components like \"deep kernel network\" and \"gaussian process surrogate.\"\n*   the paper aims to introduce a new approach and demonstrate its effectiveness, which is characteristic of a technical paper."
      },
      "file_name": "aea3f03299ff0cfea9b394f5559aa1c173f9876f.pdf"
    },
    {
      "success": true,
      "doc_id": "d08d14c6bee1b0d007278a98bf0bec7d",
      "summary": "Graph representation learning is to learn universal node representations that preserve both node attributes and structural information. The derived node representations can be used to serve various downstream tasks, such as node classification and node clustering. When a graph is heterogeneous, the problem becomes more challenging than the homogeneous graph node learning problem. Inspired by the emerging information theoretic-based learning algorithm, in this paper we propose an unsupervised graph neural network Heterogeneous Deep Graph Infomax (HDGI) for heterogeneous graph representation learning. We use the meta-path structure to analyze the connections involving semantics in heterogeneous graphs and utilize graph convolution module and semantic-level attention mechanism to capture local representations. By maximizing local-global mutual information, HDGI effectively learns high-level node representations that can be utilized in downstream graph-related tasks. Experiment results show that HDGI remarkably outperforms state-of-the-art unsupervised graph representation learning methods on both classification and clustering tasks. By feeding the learned representations into a parametric model, such as logistic regression, we even achieve comparable performance in node classification tasks when comparing with state-of-the-art supervised end-to-end GNN models.",
      "intriguing_abstract": "Graph representation learning is to learn universal node representations that preserve both node attributes and structural information. The derived node representations can be used to serve various downstream tasks, such as node classification and node clustering. When a graph is heterogeneous, the problem becomes more challenging than the homogeneous graph node learning problem. Inspired by the emerging information theoretic-based learning algorithm, in this paper we propose an unsupervised graph neural network Heterogeneous Deep Graph Infomax (HDGI) for heterogeneous graph representation learning. We use the meta-path structure to analyze the connections involving semantics in heterogeneous graphs and utilize graph convolution module and semantic-level attention mechanism to capture local representations. By maximizing local-global mutual information, HDGI effectively learns high-level node representations that can be utilized in downstream graph-related tasks. Experiment results show that HDGI remarkably outperforms state-of-the-art unsupervised graph representation learning methods on both classification and clustering tasks. By feeding the learned representations into a parametric model, such as logistic regression, we even achieve comparable performance in node classification tasks when comparing with state-of-the-art supervised end-to-end GNN models.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/1bb15e82795dccd5c5cc71abb0fe2d86c4e2fd61.pdf",
      "citation_key": "ren2019nu0",
      "metadata": {
        "title": "Heterogeneous Deep Graph Infomax",
        "authors": [
          "Yuxiang Ren",
          "Bo Liu",
          "Chao Huang",
          "Peng Dai",
          "Liefeng Bo",
          "Jiawei Zhang"
        ],
        "published_date": "2019",
        "abstract": "Graph representation learning is to learn universal node representations that preserve both node attributes and structural information. The derived node representations can be used to serve various downstream tasks, such as node classification and node clustering. When a graph is heterogeneous, the problem becomes more challenging than the homogeneous graph node learning problem. Inspired by the emerging information theoretic-based learning algorithm, in this paper we propose an unsupervised graph neural network Heterogeneous Deep Graph Infomax (HDGI) for heterogeneous graph representation learning. We use the meta-path structure to analyze the connections involving semantics in heterogeneous graphs and utilize graph convolution module and semantic-level attention mechanism to capture local representations. By maximizing local-global mutual information, HDGI effectively learns high-level node representations that can be utilized in downstream graph-related tasks. Experiment results show that HDGI remarkably outperforms state-of-the-art unsupervised graph representation learning methods on both classification and clustering tasks. By feeding the learned representations into a parametric model, such as logistic regression, we even achieve comparable performance in node classification tasks when comparing with state-of-the-art supervised end-to-end GNN models.",
        "file_path": "paper_data/Deep_Meta-Learning/info/1bb15e82795dccd5c5cc71abb0fe2d86c4e2fd61.pdf",
        "venue": "arXiv.org",
        "citationCount": 108,
        "score": 18.0,
        "summary": "Graph representation learning is to learn universal node representations that preserve both node attributes and structural information. The derived node representations can be used to serve various downstream tasks, such as node classification and node clustering. When a graph is heterogeneous, the problem becomes more challenging than the homogeneous graph node learning problem. Inspired by the emerging information theoretic-based learning algorithm, in this paper we propose an unsupervised graph neural network Heterogeneous Deep Graph Infomax (HDGI) for heterogeneous graph representation learning. We use the meta-path structure to analyze the connections involving semantics in heterogeneous graphs and utilize graph convolution module and semantic-level attention mechanism to capture local representations. By maximizing local-global mutual information, HDGI effectively learns high-level node representations that can be utilized in downstream graph-related tasks. Experiment results show that HDGI remarkably outperforms state-of-the-art unsupervised graph representation learning methods on both classification and clustering tasks. By feeding the learned representations into a parametric model, such as logistic regression, we even achieve comparable performance in node classification tasks when comparing with state-of-the-art supervised end-to-end GNN models.",
        "keywords": []
      },
      "file_name": "1bb15e82795dccd5c5cc71abb0fe2d86c4e2fd61.pdf"
    },
    {
      "success": true,
      "doc_id": "3c123094b1f3a580c431554d28a8c10e",
      "summary": "The rapid development of artificial intelligence and deep learning has provided many opportunities to further enhance the safety, stability, and accuracy of industrial cyber-physical systems (CPS). As indispensable components to many mission-critical CPS assets and equipment, mechanical bearings need to be monitored to identify any trace of abnormal conditions. Most of the data-driven approaches applied to bearing fault diagnosis up-to-date are trained using a large amount of fault data collected a priori. In many practical applications, however, it can be unsafe and time-consuming to collect sufficient data samples for each fault category, making it challenging to train a robust classifier. In this article, we propose a few-shot learning framework for bearing fault diagnosis based on model-agnostic meta-learning, which targets for training an effective fault classifier using limited data. In addition, it can leverage the training data and learn to identify new fault scenarios more efficiently. Case studies on the generalization to new artificial faults show that the proposed framework achieves an overall accuracy up to 25% higher than a Siamese-network-based benchmark study. Finally, the robustness and the generalization capability of the proposed framework is further validated by applying it to identify real bearing damages using data from artificial damages, which compares favorably against six state-of-the-art few-shot learning algorithms using consistent test environments.",
      "intriguing_abstract": "The rapid development of artificial intelligence and deep learning has provided many opportunities to further enhance the safety, stability, and accuracy of industrial cyber-physical systems (CPS). As indispensable components to many mission-critical CPS assets and equipment, mechanical bearings need to be monitored to identify any trace of abnormal conditions. Most of the data-driven approaches applied to bearing fault diagnosis up-to-date are trained using a large amount of fault data collected a priori. In many practical applications, however, it can be unsafe and time-consuming to collect sufficient data samples for each fault category, making it challenging to train a robust classifier. In this article, we propose a few-shot learning framework for bearing fault diagnosis based on model-agnostic meta-learning, which targets for training an effective fault classifier using limited data. In addition, it can leverage the training data and learn to identify new fault scenarios more efficiently. Case studies on the generalization to new artificial faults show that the proposed framework achieves an overall accuracy up to 25% higher than a Siamese-network-based benchmark study. Finally, the robustness and the generalization capability of the proposed framework is further validated by applying it to identify real bearing damages using data from artificial damages, which compares favorably against six state-of-the-art few-shot learning algorithms using consistent test environments.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/9feb0f686252c119ccb1a4b4ccd0d6605e96e8fe.pdf",
      "citation_key": "zhang2020p3y",
      "metadata": {
        "title": "Few-Shot Bearing Fault Diagnosis Based on Model-Agnostic Meta-Learning",
        "authors": [
          "Shen Zhang",
          "Fei Ye",
          "Bingnan Wang",
          "T. Habetler"
        ],
        "published_date": "2020",
        "abstract": "The rapid development of artificial intelligence and deep learning has provided many opportunities to further enhance the safety, stability, and accuracy of industrial cyber-physical systems (CPS). As indispensable components to many mission-critical CPS assets and equipment, mechanical bearings need to be monitored to identify any trace of abnormal conditions. Most of the data-driven approaches applied to bearing fault diagnosis up-to-date are trained using a large amount of fault data collected a priori. In many practical applications, however, it can be unsafe and time-consuming to collect sufficient data samples for each fault category, making it challenging to train a robust classifier. In this article, we propose a few-shot learning framework for bearing fault diagnosis based on model-agnostic meta-learning, which targets for training an effective fault classifier using limited data. In addition, it can leverage the training data and learn to identify new fault scenarios more efficiently. Case studies on the generalization to new artificial faults show that the proposed framework achieves an overall accuracy up to 25% higher than a Siamese-network-based benchmark study. Finally, the robustness and the generalization capability of the proposed framework is further validated by applying it to identify real bearing damages using data from artificial damages, which compares favorably against six state-of-the-art few-shot learning algorithms using consistent test environments.",
        "file_path": "paper_data/Deep_Meta-Learning/info/9feb0f686252c119ccb1a4b4ccd0d6605e96e8fe.pdf",
        "venue": "IEEE transactions on industry applications",
        "citationCount": 89,
        "score": 17.8,
        "summary": "The rapid development of artificial intelligence and deep learning has provided many opportunities to further enhance the safety, stability, and accuracy of industrial cyber-physical systems (CPS). As indispensable components to many mission-critical CPS assets and equipment, mechanical bearings need to be monitored to identify any trace of abnormal conditions. Most of the data-driven approaches applied to bearing fault diagnosis up-to-date are trained using a large amount of fault data collected a priori. In many practical applications, however, it can be unsafe and time-consuming to collect sufficient data samples for each fault category, making it challenging to train a robust classifier. In this article, we propose a few-shot learning framework for bearing fault diagnosis based on model-agnostic meta-learning, which targets for training an effective fault classifier using limited data. In addition, it can leverage the training data and learn to identify new fault scenarios more efficiently. Case studies on the generalization to new artificial faults show that the proposed framework achieves an overall accuracy up to 25% higher than a Siamese-network-based benchmark study. Finally, the robustness and the generalization capability of the proposed framework is further validated by applying it to identify real bearing damages using data from artificial damages, which compares favorably against six state-of-the-art few-shot learning algorithms using consistent test environments.",
        "keywords": []
      },
      "file_name": "9feb0f686252c119ccb1a4b4ccd0d6605e96e8fe.pdf"
    },
    {
      "success": true,
      "doc_id": "7d5db5ad4fd6ceb2b2429ce8efbacbb0",
      "summary": "Few-shot learning remains challenging for meta-learning that learns a learning algorithm (meta-learner) from many related tasks. In this work, we argue that this is due to the lack of a good representation for meta-learning, and propose deep meta-learning to integrate the representation power of deep learning into meta-learning. The framework is composed of three modules, a concept generator, a meta-learner, and a concept discriminator, which are learned jointly. The concept generator, e.g. a deep residual net, extracts a representation for each instance that captures its high-level concept, on which the meta-learner performs few-shot learning, and the concept discriminator recognizes the concepts. By learning to learn in the concept space rather than in the complicated instance space, deep meta-learning can substantially improve vanilla meta-learning, which is demonstrated on various few-shot image recognition problems. For example, on 5-way-1-shot image recognition on CIFAR-100 and CUB-200, it improves Matching Nets from 50.53% and 56.53% to 58.18% and 63.47%, improves MAML from 49.28% and 50.45% to 56.65% and 64.63%, and improves Meta-SGD from 53.83% and 53.34% to 61.62% and 66.95%, respectively.",
      "intriguing_abstract": "Few-shot learning remains challenging for meta-learning that learns a learning algorithm (meta-learner) from many related tasks. In this work, we argue that this is due to the lack of a good representation for meta-learning, and propose deep meta-learning to integrate the representation power of deep learning into meta-learning. The framework is composed of three modules, a concept generator, a meta-learner, and a concept discriminator, which are learned jointly. The concept generator, e.g. a deep residual net, extracts a representation for each instance that captures its high-level concept, on which the meta-learner performs few-shot learning, and the concept discriminator recognizes the concepts. By learning to learn in the concept space rather than in the complicated instance space, deep meta-learning can substantially improve vanilla meta-learning, which is demonstrated on various few-shot image recognition problems. For example, on 5-way-1-shot image recognition on CIFAR-100 and CUB-200, it improves Matching Nets from 50.53% and 56.53% to 58.18% and 63.47%, improves MAML from 49.28% and 50.45% to 56.65% and 64.63%, and improves Meta-SGD from 53.83% and 53.34% to 61.62% and 66.95%, respectively.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/35ad6ba10006975c2bc67ecefaa9ee6af2453bdc.pdf",
      "citation_key": "zhou20188lr",
      "metadata": {
        "title": "Deep Meta-Learning: Learning to Learn in the Concept Space",
        "authors": [
          "Fengwei Zhou",
          "Bin Wu",
          "Zhenguo Li"
        ],
        "published_date": "2018",
        "abstract": "Few-shot learning remains challenging for meta-learning that learns a learning algorithm (meta-learner) from many related tasks. In this work, we argue that this is due to the lack of a good representation for meta-learning, and propose deep meta-learning to integrate the representation power of deep learning into meta-learning. The framework is composed of three modules, a concept generator, a meta-learner, and a concept discriminator, which are learned jointly. The concept generator, e.g. a deep residual net, extracts a representation for each instance that captures its high-level concept, on which the meta-learner performs few-shot learning, and the concept discriminator recognizes the concepts. By learning to learn in the concept space rather than in the complicated instance space, deep meta-learning can substantially improve vanilla meta-learning, which is demonstrated on various few-shot image recognition problems. For example, on 5-way-1-shot image recognition on CIFAR-100 and CUB-200, it improves Matching Nets from 50.53% and 56.53% to 58.18% and 63.47%, improves MAML from 49.28% and 50.45% to 56.65% and 64.63%, and improves Meta-SGD from 53.83% and 53.34% to 61.62% and 66.95%, respectively.",
        "file_path": "paper_data/Deep_Meta-Learning/info/35ad6ba10006975c2bc67ecefaa9ee6af2453bdc.pdf",
        "venue": "arXiv.org",
        "citationCount": 124,
        "score": 17.71428571428571,
        "summary": "Few-shot learning remains challenging for meta-learning that learns a learning algorithm (meta-learner) from many related tasks. In this work, we argue that this is due to the lack of a good representation for meta-learning, and propose deep meta-learning to integrate the representation power of deep learning into meta-learning. The framework is composed of three modules, a concept generator, a meta-learner, and a concept discriminator, which are learned jointly. The concept generator, e.g. a deep residual net, extracts a representation for each instance that captures its high-level concept, on which the meta-learner performs few-shot learning, and the concept discriminator recognizes the concepts. By learning to learn in the concept space rather than in the complicated instance space, deep meta-learning can substantially improve vanilla meta-learning, which is demonstrated on various few-shot image recognition problems. For example, on 5-way-1-shot image recognition on CIFAR-100 and CUB-200, it improves Matching Nets from 50.53% and 56.53% to 58.18% and 63.47%, improves MAML from 49.28% and 50.45% to 56.65% and 64.63%, and improves Meta-SGD from 53.83% and 53.34% to 61.62% and 66.95%, respectively.",
        "keywords": []
      },
      "file_name": "35ad6ba10006975c2bc67ecefaa9ee6af2453bdc.pdf"
    },
    {
      "success": true,
      "doc_id": "c0decee9aca0a2ed60a05c4502c56d87",
      "summary": "In recent years, the subject of deep reinforcement learning (DRL) has developed very rapidly, and is now applied in various fields, such as decision making and control tasks. However, artificial agents trained with RL algorithms require great amounts of training data, unlike humans that are able to learn new skills from very few examples. The concept of meta-reinforcement learning (meta-RL) has been recently proposed to enable agents to learn similar but new skills from a small amount of experience by leveraging a set of tasks with a shared structure. Due to the task representation learning strategy with few-shot adaptation, most recent work is limited to narrow task distributions and stationary environments, where tasks do not change within episodes. In this work, we address those limitations and introduce a training strategy that is applicable to non-stationary environments, as well as a task representation based on Gaussian mixture models to model clustered task distributions. We evaluate our method on several continuous robotic control benchmarks. Compared with state-of-the-art literature that is only applicable to stationary environments with few-shot adaption, our algorithm first achieves competitive asymptotic performance and superior sample efficiency in stationary environments with zero-shot adaption. Second, our algorithm learns to perform successfully in non-stationary settings as well as a continual learning setting, while learning well-structured task representations. Last, our algorithm learns basic distinct behaviors and well-structured task representations in task distributions with multiple qualitatively distinct tasks.",
      "intriguing_abstract": "In recent years, the subject of deep reinforcement learning (DRL) has developed very rapidly, and is now applied in various fields, such as decision making and control tasks. However, artificial agents trained with RL algorithms require great amounts of training data, unlike humans that are able to learn new skills from very few examples. The concept of meta-reinforcement learning (meta-RL) has been recently proposed to enable agents to learn similar but new skills from a small amount of experience by leveraging a set of tasks with a shared structure. Due to the task representation learning strategy with few-shot adaptation, most recent work is limited to narrow task distributions and stationary environments, where tasks do not change within episodes. In this work, we address those limitations and introduce a training strategy that is applicable to non-stationary environments, as well as a task representation based on Gaussian mixture models to model clustered task distributions. We evaluate our method on several continuous robotic control benchmarks. Compared with state-of-the-art literature that is only applicable to stationary environments with few-shot adaption, our algorithm first achieves competitive asymptotic performance and superior sample efficiency in stationary environments with zero-shot adaption. Second, our algorithm learns to perform successfully in non-stationary settings as well as a continual learning setting, while learning well-structured task representations. Last, our algorithm learns basic distinct behaviors and well-structured task representations in task distributions with multiple qualitatively distinct tasks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/31eba23839649c21c3e462a7568b6b72041d4b5c.pdf",
      "citation_key": "bing2022om0",
      "metadata": {
        "title": "Meta-Reinforcement Learning in Non-Stationary and Dynamic Environments",
        "authors": [
          "Zhenshan Bing",
          "David Lerch",
          "Kai Huang",
          "Alois Knoll"
        ],
        "published_date": "2022",
        "abstract": "In recent years, the subject of deep reinforcement learning (DRL) has developed very rapidly, and is now applied in various fields, such as decision making and control tasks. However, artificial agents trained with RL algorithms require great amounts of training data, unlike humans that are able to learn new skills from very few examples. The concept of meta-reinforcement learning (meta-RL) has been recently proposed to enable agents to learn similar but new skills from a small amount of experience by leveraging a set of tasks with a shared structure. Due to the task representation learning strategy with few-shot adaptation, most recent work is limited to narrow task distributions and stationary environments, where tasks do not change within episodes. In this work, we address those limitations and introduce a training strategy that is applicable to non-stationary environments, as well as a task representation based on Gaussian mixture models to model clustered task distributions. We evaluate our method on several continuous robotic control benchmarks. Compared with state-of-the-art literature that is only applicable to stationary environments with few-shot adaption, our algorithm first achieves competitive asymptotic performance and superior sample efficiency in stationary environments with zero-shot adaption. Second, our algorithm learns to perform successfully in non-stationary settings as well as a continual learning setting, while learning well-structured task representations. Last, our algorithm learns basic distinct behaviors and well-structured task representations in task distributions with multiple qualitatively distinct tasks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/31eba23839649c21c3e462a7568b6b72041d4b5c.pdf",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "citationCount": 53,
        "score": 17.666666666666664,
        "summary": "In recent years, the subject of deep reinforcement learning (DRL) has developed very rapidly, and is now applied in various fields, such as decision making and control tasks. However, artificial agents trained with RL algorithms require great amounts of training data, unlike humans that are able to learn new skills from very few examples. The concept of meta-reinforcement learning (meta-RL) has been recently proposed to enable agents to learn similar but new skills from a small amount of experience by leveraging a set of tasks with a shared structure. Due to the task representation learning strategy with few-shot adaptation, most recent work is limited to narrow task distributions and stationary environments, where tasks do not change within episodes. In this work, we address those limitations and introduce a training strategy that is applicable to non-stationary environments, as well as a task representation based on Gaussian mixture models to model clustered task distributions. We evaluate our method on several continuous robotic control benchmarks. Compared with state-of-the-art literature that is only applicable to stationary environments with few-shot adaption, our algorithm first achieves competitive asymptotic performance and superior sample efficiency in stationary environments with zero-shot adaption. Second, our algorithm learns to perform successfully in non-stationary settings as well as a continual learning setting, while learning well-structured task representations. Last, our algorithm learns basic distinct behaviors and well-structured task representations in task distributions with multiple qualitatively distinct tasks.",
        "keywords": []
      },
      "file_name": "31eba23839649c21c3e462a7568b6b72041d4b5c.pdf"
    },
    {
      "success": true,
      "doc_id": "a61037abdd260f11790045c61321fd47",
      "summary": "Motivated by the application of viral marketing, the topic-aware influence maximization (TIM) problem has been proposed to identify the most influential users under given topics. In particular, it aims to find k seeds (users) in social network G, such that the seeds can maximize the influence on users under the specific query topics and diffusion model such as independent cascade (IC) or linear threshold (LT). This problem has been proved to be NP-hard, and most of the proposed techniques suffer from the efficiency issue due to the lack of generalization. Even worse, the design of these algorithms requires significant specialized knowledge which is hard to be understood and implemented. To overcome these issues, this paper aims to learn a generalized heuristic framework to solve TIM problems by meta-learning. To this end, we first propose two topic-aware social influence propagation models based on IC and LT model, respectively, which is conducive to better advertising injections. We then encode the feature of each node by a vector and introduce a model, called deep influence evaluation model , to evaluate the user influence under different circumstances. Based on this model, we can construct the solution according to the influence evaluations efficiently, rather than spending a high cost to compute the exact influence by considering the complex graph structure. We conducted experiments on generated graph instances and real-world social networks. The results show the superiority in performance and comparable quality of our framework.",
      "intriguing_abstract": "Motivated by the application of viral marketing, the topic-aware influence maximization (TIM) problem has been proposed to identify the most influential users under given topics. In particular, it aims to find k seeds (users) in social network G, such that the seeds can maximize the influence on users under the specific query topics and diffusion model such as independent cascade (IC) or linear threshold (LT). This problem has been proved to be NP-hard, and most of the proposed techniques suffer from the efficiency issue due to the lack of generalization. Even worse, the design of these algorithms requires significant specialized knowledge which is hard to be understood and implemented. To overcome these issues, this paper aims to learn a generalized heuristic framework to solve TIM problems by meta-learning. To this end, we first propose two topic-aware social influence propagation models based on IC and LT model, respectively, which is conducive to better advertising injections. We then encode the feature of each node by a vector and introduce a model, called deep influence evaluation model , to evaluate the user influence under different circumstances. Based on this model, we can construct the solution according to the influence evaluations efficiently, rather than spending a high cost to compute the exact influence by considering the complex graph structure. We conducted experiments on generated graph instances and real-world social networks. The results show the superiority in performance and comparable quality of our framework.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2a9f2423d512fa9c90c86521a16f03d961a043f0.pdf",
      "citation_key": "tian20200qx",
      "metadata": {
        "title": "Deep Reinforcement Learning-Based Approach to Tackle Topic-Aware Influence Maximization",
        "authors": [
          "Shan Tian",
          "Songsong Mo",
          "Liwei Wang",
          "Zhiyong Peng"
        ],
        "published_date": "2020",
        "abstract": "Motivated by the application of viral marketing, the topic-aware influence maximization (TIM) problem has been proposed to identify the most influential users under given topics. In particular, it aims to find k seeds (users) in social network G, such that the seeds can maximize the influence on users under the specific query topics and diffusion model such as independent cascade (IC) or linear threshold (LT). This problem has been proved to be NP-hard, and most of the proposed techniques suffer from the efficiency issue due to the lack of generalization. Even worse, the design of these algorithms requires significant specialized knowledge which is hard to be understood and implemented. To overcome these issues, this paper aims to learn a generalized heuristic framework to solve TIM problems by meta-learning. To this end, we first propose two topic-aware social influence propagation models based on IC and LT model, respectively, which is conducive to better advertising injections. We then encode the feature of each node by a vector and introduce a model, called deep influence evaluation model , to evaluate the user influence under different circumstances. Based on this model, we can construct the solution according to the influence evaluations efficiently, rather than spending a high cost to compute the exact influence by considering the complex graph structure. We conducted experiments on generated graph instances and real-world social networks. The results show the superiority in performance and comparable quality of our framework.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2a9f2423d512fa9c90c86521a16f03d961a043f0.pdf",
        "venue": "Data Science and Engineering",
        "citationCount": 88,
        "score": 17.6,
        "summary": "Motivated by the application of viral marketing, the topic-aware influence maximization (TIM) problem has been proposed to identify the most influential users under given topics. In particular, it aims to find k seeds (users) in social network G, such that the seeds can maximize the influence on users under the specific query topics and diffusion model such as independent cascade (IC) or linear threshold (LT). This problem has been proved to be NP-hard, and most of the proposed techniques suffer from the efficiency issue due to the lack of generalization. Even worse, the design of these algorithms requires significant specialized knowledge which is hard to be understood and implemented. To overcome these issues, this paper aims to learn a generalized heuristic framework to solve TIM problems by meta-learning. To this end, we first propose two topic-aware social influence propagation models based on IC and LT model, respectively, which is conducive to better advertising injections. We then encode the feature of each node by a vector and introduce a model, called deep influence evaluation model , to evaluate the user influence under different circumstances. Based on this model, we can construct the solution according to the influence evaluations efficiently, rather than spending a high cost to compute the exact influence by considering the complex graph structure. We conducted experiments on generated graph instances and real-world social networks. The results show the superiority in performance and comparable quality of our framework.",
        "keywords": []
      },
      "file_name": "2a9f2423d512fa9c90c86521a16f03d961a043f0.pdf"
    },
    {
      "success": true,
      "doc_id": "b2bcb7cf926d89f1a72bc12a46ab3a23",
      "summary": "Face Anti-Spoofing (FAS) is essential to secure face recognition systems and has been extensively studied in recent years. Although deep neural networks (DNNs) for the FAS task have achieved promising results in intra-dataset experiments with similar distributions of training and testing data, the DNNs’ generalization ability is limited under the cross-domain scenarios with different distributions of training and testing data. To improve the generalization ability, recent hybrid methods have been explored to extract task-aware handcrafted features (e.g., Local Binary Pattern) as discriminative information for the input of DNNs. However, the handcrafted feature extraction relies on experts’ domain knowledge, and how to choose appropriate handcrafted features is underexplored. To this end, we propose a learnable network to extract Meta Pattern (MP) in our learning-to-learn framework. By replacing handcrafted features with the MP, the discriminative information from MP is capable of learning a more generalized model. Moreover, we devise a two-stream network to hierarchically fuse the input RGB image and the extracted MP by using our proposed Hierarchical Fusion Module (HFM). We conduct comprehensive experiments and show that our MP outperforms the compared handcrafted features. Also, our proposed method with HFM and the MP can achieve state-of-the-art performance on two different domain generalization evaluation benchmarks.",
      "intriguing_abstract": "Face Anti-Spoofing (FAS) is essential to secure face recognition systems and has been extensively studied in recent years. Although deep neural networks (DNNs) for the FAS task have achieved promising results in intra-dataset experiments with similar distributions of training and testing data, the DNNs’ generalization ability is limited under the cross-domain scenarios with different distributions of training and testing data. To improve the generalization ability, recent hybrid methods have been explored to extract task-aware handcrafted features (e.g., Local Binary Pattern) as discriminative information for the input of DNNs. However, the handcrafted feature extraction relies on experts’ domain knowledge, and how to choose appropriate handcrafted features is underexplored. To this end, we propose a learnable network to extract Meta Pattern (MP) in our learning-to-learn framework. By replacing handcrafted features with the MP, the discriminative information from MP is capable of learning a more generalized model. Moreover, we devise a two-stream network to hierarchically fuse the input RGB image and the extracted MP by using our proposed Hierarchical Fusion Module (HFM). We conduct comprehensive experiments and show that our MP outperforms the compared handcrafted features. Also, our proposed method with HFM and the MP can achieve state-of-the-art performance on two different domain generalization evaluation benchmarks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/558583c0a90c8a1c37b76c9eeb5fd2b4e80985a1.pdf",
      "citation_key": "cai20215z1",
      "metadata": {
        "title": "Learning Meta Pattern for Face Anti-Spoofing",
        "authors": [
          "Rizhao Cai",
          "Zhi Li",
          "Renjie Wan",
          "Haoliang Li",
          "Yongjian Hu",
          "A. Kot"
        ],
        "published_date": "2021",
        "abstract": "Face Anti-Spoofing (FAS) is essential to secure face recognition systems and has been extensively studied in recent years. Although deep neural networks (DNNs) for the FAS task have achieved promising results in intra-dataset experiments with similar distributions of training and testing data, the DNNs’ generalization ability is limited under the cross-domain scenarios with different distributions of training and testing data. To improve the generalization ability, recent hybrid methods have been explored to extract task-aware handcrafted features (e.g., Local Binary Pattern) as discriminative information for the input of DNNs. However, the handcrafted feature extraction relies on experts’ domain knowledge, and how to choose appropriate handcrafted features is underexplored. To this end, we propose a learnable network to extract Meta Pattern (MP) in our learning-to-learn framework. By replacing handcrafted features with the MP, the discriminative information from MP is capable of learning a more generalized model. Moreover, we devise a two-stream network to hierarchically fuse the input RGB image and the extracted MP by using our proposed Hierarchical Fusion Module (HFM). We conduct comprehensive experiments and show that our MP outperforms the compared handcrafted features. Also, our proposed method with HFM and the MP can achieve state-of-the-art performance on two different domain generalization evaluation benchmarks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/558583c0a90c8a1c37b76c9eeb5fd2b4e80985a1.pdf",
        "venue": "IEEE Transactions on Information Forensics and Security",
        "citationCount": 70,
        "score": 17.5,
        "summary": "Face Anti-Spoofing (FAS) is essential to secure face recognition systems and has been extensively studied in recent years. Although deep neural networks (DNNs) for the FAS task have achieved promising results in intra-dataset experiments with similar distributions of training and testing data, the DNNs’ generalization ability is limited under the cross-domain scenarios with different distributions of training and testing data. To improve the generalization ability, recent hybrid methods have been explored to extract task-aware handcrafted features (e.g., Local Binary Pattern) as discriminative information for the input of DNNs. However, the handcrafted feature extraction relies on experts’ domain knowledge, and how to choose appropriate handcrafted features is underexplored. To this end, we propose a learnable network to extract Meta Pattern (MP) in our learning-to-learn framework. By replacing handcrafted features with the MP, the discriminative information from MP is capable of learning a more generalized model. Moreover, we devise a two-stream network to hierarchically fuse the input RGB image and the extracted MP by using our proposed Hierarchical Fusion Module (HFM). We conduct comprehensive experiments and show that our MP outperforms the compared handcrafted features. Also, our proposed method with HFM and the MP can achieve state-of-the-art performance on two different domain generalization evaluation benchmarks.",
        "keywords": []
      },
      "file_name": "558583c0a90c8a1c37b76c9eeb5fd2b4e80985a1.pdf"
    },
    {
      "success": true,
      "doc_id": "66922f83ba2caa8f3f6a7ac41020bd9d",
      "summary": "Fake news travels at unprecedented speeds, reaches global audiences and puts users and communities at great risk via social media platforms. Deep learning based models show good performance when trained on large amounts of labeled data on events of interest, whereas the performance of models tends to degrade on other events due to domain shift. Therefore, significant challenges are posed for existing detection approaches to detect fake news on emergent events, where large-scale labeled datasets are difficult to obtain. Moreover, adding the knowledge from newly emergent events requires to build a new model from scratch or continue to fine-tune the model, which can be challenging, expensive, and unrealistic for real-world settings. In order to address those challenges, we propose an end-to-end fake news detection framework named MetaFEND, which is able to learn quickly to detect fake news on emergent events with a few verified posts. Specifically, the proposed model integrates meta-learning and neural process methods together to enjoy the benefits of these approaches. In particular, a label embedding module and a hard attention mechanism are proposed to enhance the effectiveness by handling categorical information and trimming irrelevant posts. Extensive experiments are conducted on multimedia datasets collected from Twitter and Weibo. The experimental results show our proposed MetaFEND model can detect fake news on never-seen events effectively and outperform the state-of-the-art methods.",
      "intriguing_abstract": "Fake news travels at unprecedented speeds, reaches global audiences and puts users and communities at great risk via social media platforms. Deep learning based models show good performance when trained on large amounts of labeled data on events of interest, whereas the performance of models tends to degrade on other events due to domain shift. Therefore, significant challenges are posed for existing detection approaches to detect fake news on emergent events, where large-scale labeled datasets are difficult to obtain. Moreover, adding the knowledge from newly emergent events requires to build a new model from scratch or continue to fine-tune the model, which can be challenging, expensive, and unrealistic for real-world settings. In order to address those challenges, we propose an end-to-end fake news detection framework named MetaFEND, which is able to learn quickly to detect fake news on emergent events with a few verified posts. Specifically, the proposed model integrates meta-learning and neural process methods together to enjoy the benefits of these approaches. In particular, a label embedding module and a hard attention mechanism are proposed to enhance the effectiveness by handling categorical information and trimming irrelevant posts. Extensive experiments are conducted on multimedia datasets collected from Twitter and Weibo. The experimental results show our proposed MetaFEND model can detect fake news on never-seen events effectively and outperform the state-of-the-art methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/cc587f036497bd78a9e1a0d1fdf8bcbcfb1a6dc5.pdf",
      "citation_key": "wang2021i3l",
      "metadata": {
        "title": "Multimodal Emergent Fake News Detection via Meta Neural Process Networks",
        "authors": [
          "Yaqing Wang",
          "Fenglong Ma",
          "Haoyu Wang",
          "Kishlay Jha",
          "Jing Gao"
        ],
        "published_date": "2021",
        "abstract": "Fake news travels at unprecedented speeds, reaches global audiences and puts users and communities at great risk via social media platforms. Deep learning based models show good performance when trained on large amounts of labeled data on events of interest, whereas the performance of models tends to degrade on other events due to domain shift. Therefore, significant challenges are posed for existing detection approaches to detect fake news on emergent events, where large-scale labeled datasets are difficult to obtain. Moreover, adding the knowledge from newly emergent events requires to build a new model from scratch or continue to fine-tune the model, which can be challenging, expensive, and unrealistic for real-world settings. In order to address those challenges, we propose an end-to-end fake news detection framework named MetaFEND, which is able to learn quickly to detect fake news on emergent events with a few verified posts. Specifically, the proposed model integrates meta-learning and neural process methods together to enjoy the benefits of these approaches. In particular, a label embedding module and a hard attention mechanism are proposed to enhance the effectiveness by handling categorical information and trimming irrelevant posts. Extensive experiments are conducted on multimedia datasets collected from Twitter and Weibo. The experimental results show our proposed MetaFEND model can detect fake news on never-seen events effectively and outperform the state-of-the-art methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/cc587f036497bd78a9e1a0d1fdf8bcbcfb1a6dc5.pdf",
        "venue": "Knowledge Discovery and Data Mining",
        "citationCount": 66,
        "score": 16.5,
        "summary": "Fake news travels at unprecedented speeds, reaches global audiences and puts users and communities at great risk via social media platforms. Deep learning based models show good performance when trained on large amounts of labeled data on events of interest, whereas the performance of models tends to degrade on other events due to domain shift. Therefore, significant challenges are posed for existing detection approaches to detect fake news on emergent events, where large-scale labeled datasets are difficult to obtain. Moreover, adding the knowledge from newly emergent events requires to build a new model from scratch or continue to fine-tune the model, which can be challenging, expensive, and unrealistic for real-world settings. In order to address those challenges, we propose an end-to-end fake news detection framework named MetaFEND, which is able to learn quickly to detect fake news on emergent events with a few verified posts. Specifically, the proposed model integrates meta-learning and neural process methods together to enjoy the benefits of these approaches. In particular, a label embedding module and a hard attention mechanism are proposed to enhance the effectiveness by handling categorical information and trimming irrelevant posts. Extensive experiments are conducted on multimedia datasets collected from Twitter and Weibo. The experimental results show our proposed MetaFEND model can detect fake news on never-seen events effectively and outperform the state-of-the-art methods.",
        "keywords": []
      },
      "file_name": "cc587f036497bd78a9e1a0d1fdf8bcbcfb1a6dc5.pdf"
    },
    {
      "success": true,
      "doc_id": "6e94ee74d19ac239bf49d0a6131ee271",
      "summary": "While deep reinforcement learning methods have shown impressive results in robot learning, their sample inefficiency makes the learning of complex, long-horizon behaviors with real robot systems infeasible. To mitigate this issue, meta-reinforcement learning methods aim to enable fast learning on novel tasks by learning how to learn. Yet, the application has been limited to short-horizon tasks with dense rewards. To enable learning long-horizon behaviors, recent works have explored leveraging prior experience in the form of offline datasets without reward or task annotations. While these approaches yield improved sample efficiency, millions of interactions with environments are still required to solve complex tasks. In this work, we devise a method that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to solve unseen target tasks with orders of magnitude fewer environment interactions. Our core idea is to leverage prior experience extracted from offline datasets during meta-learning. Specifically, we propose to (1) extract reusable skills and a skill prior from offline datasets, (2) meta-train a high-level policy that learns to efficiently compose learned skills into long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve an unseen target task. Experimental results on continuous control tasks in navigation and manipulation demonstrate that the proposed method can efficiently solve long-horizon novel target tasks by combining the strengths of meta-learning and the usage of offline datasets, while prior approaches in RL, meta-RL, and multi-task RL require substantially more environment interactions to solve the tasks.",
      "intriguing_abstract": "While deep reinforcement learning methods have shown impressive results in robot learning, their sample inefficiency makes the learning of complex, long-horizon behaviors with real robot systems infeasible. To mitigate this issue, meta-reinforcement learning methods aim to enable fast learning on novel tasks by learning how to learn. Yet, the application has been limited to short-horizon tasks with dense rewards. To enable learning long-horizon behaviors, recent works have explored leveraging prior experience in the form of offline datasets without reward or task annotations. While these approaches yield improved sample efficiency, millions of interactions with environments are still required to solve complex tasks. In this work, we devise a method that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to solve unseen target tasks with orders of magnitude fewer environment interactions. Our core idea is to leverage prior experience extracted from offline datasets during meta-learning. Specifically, we propose to (1) extract reusable skills and a skill prior from offline datasets, (2) meta-train a high-level policy that learns to efficiently compose learned skills into long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve an unseen target task. Experimental results on continuous control tasks in navigation and manipulation demonstrate that the proposed method can efficiently solve long-horizon novel target tasks by combining the strengths of meta-learning and the usage of offline datasets, while prior approaches in RL, meta-RL, and multi-task RL require substantially more environment interactions to solve the tasks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/23bac2542b145bf2fcd17d7fa0a02ae03d0a45f7.pdf",
      "citation_key": "nam2022z75",
      "metadata": {
        "title": "Skill-based Meta-Reinforcement Learning",
        "authors": [
          "Taewook Nam",
          "Shao-Hua Sun",
          "Karl Pertsch",
          "S. Hwang",
          "Joseph J. Lim"
        ],
        "published_date": "2022",
        "abstract": "While deep reinforcement learning methods have shown impressive results in robot learning, their sample inefficiency makes the learning of complex, long-horizon behaviors with real robot systems infeasible. To mitigate this issue, meta-reinforcement learning methods aim to enable fast learning on novel tasks by learning how to learn. Yet, the application has been limited to short-horizon tasks with dense rewards. To enable learning long-horizon behaviors, recent works have explored leveraging prior experience in the form of offline datasets without reward or task annotations. While these approaches yield improved sample efficiency, millions of interactions with environments are still required to solve complex tasks. In this work, we devise a method that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to solve unseen target tasks with orders of magnitude fewer environment interactions. Our core idea is to leverage prior experience extracted from offline datasets during meta-learning. Specifically, we propose to (1) extract reusable skills and a skill prior from offline datasets, (2) meta-train a high-level policy that learns to efficiently compose learned skills into long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve an unseen target task. Experimental results on continuous control tasks in navigation and manipulation demonstrate that the proposed method can efficiently solve long-horizon novel target tasks by combining the strengths of meta-learning and the usage of offline datasets, while prior approaches in RL, meta-RL, and multi-task RL require substantially more environment interactions to solve the tasks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/23bac2542b145bf2fcd17d7fa0a02ae03d0a45f7.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 49,
        "score": 16.333333333333332,
        "summary": "While deep reinforcement learning methods have shown impressive results in robot learning, their sample inefficiency makes the learning of complex, long-horizon behaviors with real robot systems infeasible. To mitigate this issue, meta-reinforcement learning methods aim to enable fast learning on novel tasks by learning how to learn. Yet, the application has been limited to short-horizon tasks with dense rewards. To enable learning long-horizon behaviors, recent works have explored leveraging prior experience in the form of offline datasets without reward or task annotations. While these approaches yield improved sample efficiency, millions of interactions with environments are still required to solve complex tasks. In this work, we devise a method that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to solve unseen target tasks with orders of magnitude fewer environment interactions. Our core idea is to leverage prior experience extracted from offline datasets during meta-learning. Specifically, we propose to (1) extract reusable skills and a skill prior from offline datasets, (2) meta-train a high-level policy that learns to efficiently compose learned skills into long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve an unseen target task. Experimental results on continuous control tasks in navigation and manipulation demonstrate that the proposed method can efficiently solve long-horizon novel target tasks by combining the strengths of meta-learning and the usage of offline datasets, while prior approaches in RL, meta-RL, and multi-task RL require substantially more environment interactions to solve the tasks.",
        "keywords": []
      },
      "file_name": "23bac2542b145bf2fcd17d7fa0a02ae03d0a45f7.pdf"
    },
    {
      "success": true,
      "doc_id": "e12302ca2abe2add783679d9c38538cd",
      "summary": "Recently, researchers have shown great interest in using convolutional neural networks (CNNs) for no-reference image quality assessment (NR-IQA). Due to the lack of big training data, the efforts of existing metrics in optimizing CNN-based NR-IQA models remain limited. Furthermore, the diversity of distortions in images result in the generalization problem of NR-IQA models when trained with known distortions and tested on unseen distortions, which is an easy task for human. Hence, we propose a NR-IQA metric via deep meta-learning, which is highly generalizable in the face of unseen distortions. The fundamental idea is to learn the meta-knowledge shared by human when evaluating the quality of images with diversified distortions. Specifically, we define NR-IQA of different distortions as a series of tasks and propose a task selection strategy to build two task sets, which are characterized by synthetic to synthetic and synthetic to authentic distortions, respectively. Based on these two task sets, an optimization-based meta-learning is proposed to learn the generalized NR-IQA model, which can be directly used to evaluate the quality of images with unseen distortions. Extensive experiments demonstrate that our NR-IQA metric outperforms the state-of-the-arts in terms of both evaluation performance and generalization ability.",
      "intriguing_abstract": "Recently, researchers have shown great interest in using convolutional neural networks (CNNs) for no-reference image quality assessment (NR-IQA). Due to the lack of big training data, the efforts of existing metrics in optimizing CNN-based NR-IQA models remain limited. Furthermore, the diversity of distortions in images result in the generalization problem of NR-IQA models when trained with known distortions and tested on unseen distortions, which is an easy task for human. Hence, we propose a NR-IQA metric via deep meta-learning, which is highly generalizable in the face of unseen distortions. The fundamental idea is to learn the meta-knowledge shared by human when evaluating the quality of images with diversified distortions. Specifically, we define NR-IQA of different distortions as a series of tasks and propose a task selection strategy to build two task sets, which are characterized by synthetic to synthetic and synthetic to authentic distortions, respectively. Based on these two task sets, an optimization-based meta-learning is proposed to learn the generalized NR-IQA model, which can be directly used to evaluate the quality of images with unseen distortions. Extensive experiments demonstrate that our NR-IQA metric outperforms the state-of-the-arts in terms of both evaluation performance and generalization ability.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/8291dcc23a6daf3afc976acba07b8b47aa0caebe.pdf",
      "citation_key": "zhu2022d9a",
      "metadata": {
        "title": "Generalizable No-Reference Image Quality Assessment via Deep Meta-Learning",
        "authors": [
          "Hancheng Zhu",
          "Leida Li",
          "Jinjian Wu",
          "W. Dong",
          "Guangming Shi"
        ],
        "published_date": "2022",
        "abstract": "Recently, researchers have shown great interest in using convolutional neural networks (CNNs) for no-reference image quality assessment (NR-IQA). Due to the lack of big training data, the efforts of existing metrics in optimizing CNN-based NR-IQA models remain limited. Furthermore, the diversity of distortions in images result in the generalization problem of NR-IQA models when trained with known distortions and tested on unseen distortions, which is an easy task for human. Hence, we propose a NR-IQA metric via deep meta-learning, which is highly generalizable in the face of unseen distortions. The fundamental idea is to learn the meta-knowledge shared by human when evaluating the quality of images with diversified distortions. Specifically, we define NR-IQA of different distortions as a series of tasks and propose a task selection strategy to build two task sets, which are characterized by synthetic to synthetic and synthetic to authentic distortions, respectively. Based on these two task sets, an optimization-based meta-learning is proposed to learn the generalized NR-IQA model, which can be directly used to evaluate the quality of images with unseen distortions. Extensive experiments demonstrate that our NR-IQA metric outperforms the state-of-the-arts in terms of both evaluation performance and generalization ability.",
        "file_path": "paper_data/Deep_Meta-Learning/info/8291dcc23a6daf3afc976acba07b8b47aa0caebe.pdf",
        "venue": "IEEE transactions on circuits and systems for video technology (Print)",
        "citationCount": 48,
        "score": 16.0,
        "summary": "Recently, researchers have shown great interest in using convolutional neural networks (CNNs) for no-reference image quality assessment (NR-IQA). Due to the lack of big training data, the efforts of existing metrics in optimizing CNN-based NR-IQA models remain limited. Furthermore, the diversity of distortions in images result in the generalization problem of NR-IQA models when trained with known distortions and tested on unseen distortions, which is an easy task for human. Hence, we propose a NR-IQA metric via deep meta-learning, which is highly generalizable in the face of unseen distortions. The fundamental idea is to learn the meta-knowledge shared by human when evaluating the quality of images with diversified distortions. Specifically, we define NR-IQA of different distortions as a series of tasks and propose a task selection strategy to build two task sets, which are characterized by synthetic to synthetic and synthetic to authentic distortions, respectively. Based on these two task sets, an optimization-based meta-learning is proposed to learn the generalized NR-IQA model, which can be directly used to evaluate the quality of images with unseen distortions. Extensive experiments demonstrate that our NR-IQA metric outperforms the state-of-the-arts in terms of both evaluation performance and generalization ability.",
        "keywords": []
      },
      "file_name": "8291dcc23a6daf3afc976acba07b8b47aa0caebe.pdf"
    },
    {
      "success": true,
      "doc_id": "1b36f8c2be2d001e405f44dc999b09b4",
      "summary": "Label noise may significantly degrade the performance of Deep Neural Networks (DNNs). To train noise-robust DNNs, Loss correction (LC) approaches have been introduced. LC approaches assume the noisy labels are corrupted from clean (ground-truth) labels by an unknown noise transition matrix T. The backbone DNNs and T can be trained separately, where T is approximated with prior knowledge. For example, T is constructed by stacking the maximum or mean predic- tions of the samples from each class. In this work, we pro- pose a new loss correction approach, named as Meta Loss Correction (MLC), to directly learn T from data via the meta-learning framework. The MLC is model-agnostic and learns T from data rather than heuristically approximates it using prior knowledge. Extensive evaluations are conducted on computer vision (MNIST, CIFAR-10, CIFAR-100, Cloth- ing1M) and natural language processing (Twitter) datasets. The experimental results show that MLC achieves very com- petitive performance against state-of-the-art approaches.",
      "intriguing_abstract": "Label noise may significantly degrade the performance of Deep Neural Networks (DNNs). To train noise-robust DNNs, Loss correction (LC) approaches have been introduced. LC approaches assume the noisy labels are corrupted from clean (ground-truth) labels by an unknown noise transition matrix T. The backbone DNNs and T can be trained separately, where T is approximated with prior knowledge. For example, T is constructed by stacking the maximum or mean predic- tions of the samples from each class. In this work, we pro- pose a new loss correction approach, named as Meta Loss Correction (MLC), to directly learn T from data via the meta-learning framework. The MLC is model-agnostic and learns T from data rather than heuristically approximates it using prior knowledge. Extensive evaluations are conducted on computer vision (MNIST, CIFAR-10, CIFAR-100, Cloth- ing1M) and natural language processing (Twitter) datasets. The experimental results show that MLC achieves very com- petitive performance against state-of-the-art approaches.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/6f43439d8c666f05937a41d8041fbb3f08fd97eb.pdf",
      "citation_key": "wang20204p9",
      "metadata": {
        "title": "Training Noise-Robust Deep Neural Networks via Meta-Learning",
        "authors": [
          "Zhen Wang",
          "Guosheng Hu",
          "Q. Hu"
        ],
        "published_date": "2020",
        "abstract": "Label noise may significantly degrade the performance of Deep Neural Networks (DNNs). To train noise-robust DNNs, Loss correction (LC) approaches have been introduced. LC approaches assume the noisy labels are corrupted from clean (ground-truth) labels by an unknown noise transition matrix T. The backbone DNNs and T can be trained separately, where T is approximated with prior knowledge. For example, T is constructed by stacking the maximum or mean predic- tions of the samples from each class. In this work, we pro- pose a new loss correction approach, named as Meta Loss Correction (MLC), to directly learn T from data via the meta-learning framework. The MLC is model-agnostic and learns T from data rather than heuristically approximates it using prior knowledge. Extensive evaluations are conducted on computer vision (MNIST, CIFAR-10, CIFAR-100, Cloth- ing1M) and natural language processing (Twitter) datasets. The experimental results show that MLC achieves very com- petitive performance against state-of-the-art approaches.",
        "file_path": "paper_data/Deep_Meta-Learning/info/6f43439d8c666f05937a41d8041fbb3f08fd97eb.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 79,
        "score": 15.8,
        "summary": "Label noise may significantly degrade the performance of Deep Neural Networks (DNNs). To train noise-robust DNNs, Loss correction (LC) approaches have been introduced. LC approaches assume the noisy labels are corrupted from clean (ground-truth) labels by an unknown noise transition matrix T. The backbone DNNs and T can be trained separately, where T is approximated with prior knowledge. For example, T is constructed by stacking the maximum or mean predic- tions of the samples from each class. In this work, we pro- pose a new loss correction approach, named as Meta Loss Correction (MLC), to directly learn T from data via the meta-learning framework. The MLC is model-agnostic and learns T from data rather than heuristically approximates it using prior knowledge. Extensive evaluations are conducted on computer vision (MNIST, CIFAR-10, CIFAR-100, Cloth- ing1M) and natural language processing (Twitter) datasets. The experimental results show that MLC achieves very com- petitive performance against state-of-the-art approaches.",
        "keywords": []
      },
      "file_name": "6f43439d8c666f05937a41d8041fbb3f08fd97eb.pdf"
    },
    {
      "success": true,
      "doc_id": "7a04dff5dbce8deb3c2e7aa6aaaf0e33",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{xu2020txy}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep reinforcement learning (RL) algorithms rely on handcrafted objective functions (e.g., Q-learning, policy gradient) designed by human experts. This limits their flexibility and adaptability, as each objective defines the algorithm's semantics.\n    *   **Importance & Challenge**:\n        *   Choosing the \"right\" proxy objective is critical in RL, as agents lack access to a differentiable performance metric.\n        *   Handcrafting objectives requires significant expert knowledge and may not generalize well or adapt to changing environments.\n        *   The challenge is to enable an RL agent to discover its own objective function online, solely from interactive experience, making it more adaptive and efficient.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds on meta-gradient learning, which has been applied to adapt learning rates, optimizers, initial parameters, and various RL meta-parameters (e.g., discount factor, intrinsic rewards, auxiliary tasks) \\cite{xu2020txy}.\n    *   **Limitations of Previous Solutions**:\n        *   Most prior meta-learning work, especially black-box approaches that parameterize the entire RL algorithm, operates *offline* and requires *multiple lifetimes* (i.e., a distribution of related environments and the ability to reset).\n        *   \"White-box\" meta-gradient methods typically tune hyperparameters of *existing* RL update rules, rather than discovering the rule itself.\n        *   No prior work has addressed the combination of a *black-box* approach that parameterizes the RL algorithm, *meta-learned online*, during a *single agent lifetime* \\cite{xu2020txy}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **FRODO (Flexible Reinforcement Objective Discovered Online)**, an algorithm based on meta-gradient descent that learns its own objective function. It achieves this by parameterizing the **update target** `G` (a pivotal quantity in most deep RL algorithms) with a deep neural network, `G = g(τ)`, where `τ` is the trajectory and `g` is the meta-network with parameters `φ` \\cite{xu2020txy}.\n    *   **Novelty/Difference**:\n        *   **Online, Single-Lifetime Meta-Learning**: Unlike most meta-learning, FRODO learns and adapts its objective *online* within a *single training lifetime* on a single task, without requiring a distribution of environments or resets \\cite{xu2020txy}.\n        *   **Black-Box Objective Discovery**: It uses a neural network to *flexibly parameterize* the update target, effectively discovering a new RL objective rather than just tuning hyperparameters of a predefined one.\n        *   **Target vs. Loss Parameterization**: The authors hypothesize that learning the *update target* `G` (which induces a squared loss) leads to more stable online meta-gradients compared to directly parameterizing the loss function, crucial for avoiding divergence in an online setting \\cite{xu2020txy}.\n        *   **Two-Level Optimization**: A meta-learned inner loss (based on `g(τ)`) updates agent parameters `θ`, and an outer loss (e.g., canonical multi-step bootstrapped return or VTrace) computes meta-gradients to update the meta-network parameters `φ` \\cite{xu2020txy}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of FRODO, the first algorithm to perform online, single-lifetime, black-box meta-learning of an RL objective (specifically, the update target) using meta-gradients \\cite{xu2020txy}.\n    *   **Parameterization Strategy**: Proposing to parameterize the *update target* `G` with a neural network `g(τ)` for enhanced stability in online meta-gradient learning, contrasting with direct loss parameterization \\cite{xu2020txy}.\n    *   **Demonstrated Capabilities**: Shows that FRODO can discover solutions to fundamental RL challenges such as bootstrapping, adaptation to non-stationarity, and off-policy learning \\cite{xu2020txy}.\n    *   **General Applicability**: The framework is instantiated for value prediction, value-based control, and actor-critic algorithms, demonstrating its versatility \\cite{xu2020txy}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   **Toy Problems**:\n            *   \"Catch\" environment: To demonstrate learning bootstrapping, where the agent needs to predict beyond a limited look-ahead horizon \\cite{xu2020txy}.\n            *   \"5-state Random Walk\": To demonstrate adaptation to non-stationary rewards \\cite{xu2020txy}.\n        *   **Large-Scale Experiments**: Applied to 57 classic Atari games using an actor-critic variant within a distributed actor-learner framework, addressing off-policy learning issues \\cite{xu2020txy}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **\"Catch\"**: FRODO's mean episode return surpassed the best possible performance of a 3-step look-ahead agent, achieving optimal control (average return of 1) \\cite{xu2020txy}.\n        *   **\"5-state Random Walk\"**: FRODO achieved lower mean squared error (MSE) in value predictions and adapted more robustly to reward changes compared to various fixed TD(λ) agents, especially during non-stationary periods \\cite{xu2020txy}.\n        *   **Atari Learning Environment**: Augmented with a simple heuristic for consistent predictions, the meta-gradient algorithm (using VTrace as the outer update for off-policy correction) *outperformed the median score of a strong actor-critic baseline* \\cite{xu2020txy}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The paper notes the need for a \"simple heuristic to encourage consistent predictions\" on Atari, suggesting practical challenges in scaling online meta-learning.\n        *   While the target parameterization is hypothesized to be more stable, online meta-gradient learning can still be complex and sensitive to hyperparameter choices.\n    *   **Scope of Applicability**: FRODO is designed to be applicable to *any* RL environment, as it learns online on a single task. It does not require a distribution of related environments or the ability to reset and rerun on different environments, making it broadly applicable \\cite{xu2020txy}.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art**: \\cite{xu2020txy} significantly advances the technical state-of-the-art by demonstrating the feasibility of online, single-lifetime, black-box meta-learning of RL objectives. It moves beyond the paradigm of handcrafted objectives, allowing agents to discover their own learning rules.\n    *   **Potential Impact**: This work opens new avenues for developing more adaptive, efficient, and general RL agents. By enabling agents to learn *how to learn* their core objective functions from experience, it could lead to more robust AI systems capable of adapting to novel and changing environments without human intervention in objective design. It highlights the potential of meta-gradients for fundamental algorithmic discovery in RL.",
      "intriguing_abstract": "Deep reinforcement learning (RL) agents are fundamentally constrained by handcrafted objective functions, limiting their flexibility and adaptability. We introduce **FRODO (Flexible Reinforcement Objective Discovered Online)**, a pioneering meta-gradient algorithm that empowers RL agents to discover their *own* objective functions online, solely from interactive experience. Unlike prior meta-learning approaches that operate offline or require multiple lifetimes, FRODO performs *black-box objective discovery* within a *single agent lifetime* on a single task.\n\nOur core innovation lies in parameterizing the crucial `update target`—a pivotal quantity in most deep RL algorithms—with a deep neural network, optimized via meta-gradient descent. This strategy enhances stability for online learning compared to direct loss parameterization. FRODO demonstrates remarkable capabilities, autonomously learning optimal bootstrapping, adapting to non-stationary environments, and improving off-policy learning in complex settings like Atari. By enabling agents to learn *how to learn* their core objective functions, FRODO represents a significant leap towards truly adaptive, efficient, and general RL systems, moving beyond human-designed learning rules and opening new frontiers for algorithmic discovery.",
      "keywords": [
        "Deep reinforcement learning",
        "handcrafted objective functions",
        "meta-gradient learning",
        "online single-lifetime meta-learning",
        "black-box objective discovery",
        "FRODO algorithm",
        "parameterizing RL update target",
        "two-level optimization",
        "bootstrapping discovery",
        "non-stationarity adaptation",
        "off-policy learning",
        "Atari games",
        "algorithmic discovery",
        "adaptive RL agents"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/759ae1234d46e2d1399ce9d642724738a766ed22.pdf",
      "citation_key": "xu2020txy",
      "metadata": {
        "title": "Meta-Gradient Reinforcement Learning with an Objective Discovered Online",
        "authors": [
          "Zhongwen Xu",
          "H. V. Hasselt",
          "Matteo Hessel",
          "Junhyuk Oh",
          "Satinder Singh",
          "David Silver"
        ],
        "published_date": "2020",
        "abstract": "Deep reinforcement learning includes a broad family of algorithms that parameterise an internal representation, such as a value function or policy, by a deep neural network. Each algorithm optimises its parameters with respect to an objective, such as Q-learning or policy gradient, that defines its semantics. In this work, we propose an algorithm based on meta-gradient descent that discovers its own objective, flexibly parameterised by a deep neural network, solely from interactive experience with its environment. Over time, this allows the agent to learn how to learn increasingly effectively. Furthermore, because the objective is discovered online, it can adapt to changes over time. We demonstrate that the algorithm discovers how to address several important issues in RL, such as bootstrapping, non-stationarity, and off-policy learning. On the Atari Learning Environment, the meta-gradient algorithm adapts over time to learn with greater efficiency, eventually outperforming the median score of a strong actor-critic baseline.",
        "file_path": "paper_data/Deep_Meta-Learning/info/759ae1234d46e2d1399ce9d642724738a766ed22.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 79,
        "score": 15.8,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{xu2020txy}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep reinforcement learning (RL) algorithms rely on handcrafted objective functions (e.g., Q-learning, policy gradient) designed by human experts. This limits their flexibility and adaptability, as each objective defines the algorithm's semantics.\n    *   **Importance & Challenge**:\n        *   Choosing the \"right\" proxy objective is critical in RL, as agents lack access to a differentiable performance metric.\n        *   Handcrafting objectives requires significant expert knowledge and may not generalize well or adapt to changing environments.\n        *   The challenge is to enable an RL agent to discover its own objective function online, solely from interactive experience, making it more adaptive and efficient.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds on meta-gradient learning, which has been applied to adapt learning rates, optimizers, initial parameters, and various RL meta-parameters (e.g., discount factor, intrinsic rewards, auxiliary tasks) \\cite{xu2020txy}.\n    *   **Limitations of Previous Solutions**:\n        *   Most prior meta-learning work, especially black-box approaches that parameterize the entire RL algorithm, operates *offline* and requires *multiple lifetimes* (i.e., a distribution of related environments and the ability to reset).\n        *   \"White-box\" meta-gradient methods typically tune hyperparameters of *existing* RL update rules, rather than discovering the rule itself.\n        *   No prior work has addressed the combination of a *black-box* approach that parameterizes the RL algorithm, *meta-learned online*, during a *single agent lifetime* \\cite{xu2020txy}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes **FRODO (Flexible Reinforcement Objective Discovered Online)**, an algorithm based on meta-gradient descent that learns its own objective function. It achieves this by parameterizing the **update target** `G` (a pivotal quantity in most deep RL algorithms) with a deep neural network, `G = g(τ)`, where `τ` is the trajectory and `g` is the meta-network with parameters `φ` \\cite{xu2020txy}.\n    *   **Novelty/Difference**:\n        *   **Online, Single-Lifetime Meta-Learning**: Unlike most meta-learning, FRODO learns and adapts its objective *online* within a *single training lifetime* on a single task, without requiring a distribution of environments or resets \\cite{xu2020txy}.\n        *   **Black-Box Objective Discovery**: It uses a neural network to *flexibly parameterize* the update target, effectively discovering a new RL objective rather than just tuning hyperparameters of a predefined one.\n        *   **Target vs. Loss Parameterization**: The authors hypothesize that learning the *update target* `G` (which induces a squared loss) leads to more stable online meta-gradients compared to directly parameterizing the loss function, crucial for avoiding divergence in an online setting \\cite{xu2020txy}.\n        *   **Two-Level Optimization**: A meta-learned inner loss (based on `g(τ)`) updates agent parameters `θ`, and an outer loss (e.g., canonical multi-step bootstrapped return or VTrace) computes meta-gradients to update the meta-network parameters `φ` \\cite{xu2020txy}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of FRODO, the first algorithm to perform online, single-lifetime, black-box meta-learning of an RL objective (specifically, the update target) using meta-gradients \\cite{xu2020txy}.\n    *   **Parameterization Strategy**: Proposing to parameterize the *update target* `G` with a neural network `g(τ)` for enhanced stability in online meta-gradient learning, contrasting with direct loss parameterization \\cite{xu2020txy}.\n    *   **Demonstrated Capabilities**: Shows that FRODO can discover solutions to fundamental RL challenges such as bootstrapping, adaptation to non-stationarity, and off-policy learning \\cite{xu2020txy}.\n    *   **General Applicability**: The framework is instantiated for value prediction, value-based control, and actor-critic algorithms, demonstrating its versatility \\cite{xu2020txy}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   **Toy Problems**:\n            *   \"Catch\" environment: To demonstrate learning bootstrapping, where the agent needs to predict beyond a limited look-ahead horizon \\cite{xu2020txy}.\n            *   \"5-state Random Walk\": To demonstrate adaptation to non-stationary rewards \\cite{xu2020txy}.\n        *   **Large-Scale Experiments**: Applied to 57 classic Atari games using an actor-critic variant within a distributed actor-learner framework, addressing off-policy learning issues \\cite{xu2020txy}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **\"Catch\"**: FRODO's mean episode return surpassed the best possible performance of a 3-step look-ahead agent, achieving optimal control (average return of 1) \\cite{xu2020txy}.\n        *   **\"5-state Random Walk\"**: FRODO achieved lower mean squared error (MSE) in value predictions and adapted more robustly to reward changes compared to various fixed TD(λ) agents, especially during non-stationary periods \\cite{xu2020txy}.\n        *   **Atari Learning Environment**: Augmented with a simple heuristic for consistent predictions, the meta-gradient algorithm (using VTrace as the outer update for off-policy correction) *outperformed the median score of a strong actor-critic baseline* \\cite{xu2020txy}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The paper notes the need for a \"simple heuristic to encourage consistent predictions\" on Atari, suggesting practical challenges in scaling online meta-learning.\n        *   While the target parameterization is hypothesized to be more stable, online meta-gradient learning can still be complex and sensitive to hyperparameter choices.\n    *   **Scope of Applicability**: FRODO is designed to be applicable to *any* RL environment, as it learns online on a single task. It does not require a distribution of related environments or the ability to reset and rerun on different environments, making it broadly applicable \\cite{xu2020txy}.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art**: \\cite{xu2020txy} significantly advances the technical state-of-the-art by demonstrating the feasibility of online, single-lifetime, black-box meta-learning of RL objectives. It moves beyond the paradigm of handcrafted objectives, allowing agents to discover their own learning rules.\n    *   **Potential Impact**: This work opens new avenues for developing more adaptive, efficient, and general RL agents. By enabling agents to learn *how to learn* their core objective functions from experience, it could lead to more robust AI systems capable of adapting to novel and changing environments without human intervention in objective design. It highlights the potential of meta-gradients for fundamental algorithmic discovery in RL.",
        "keywords": [
          "Deep reinforcement learning",
          "handcrafted objective functions",
          "meta-gradient learning",
          "online single-lifetime meta-learning",
          "black-box objective discovery",
          "FRODO algorithm",
          "parameterizing RL update target",
          "two-level optimization",
          "bootstrapping discovery",
          "non-stationarity adaptation",
          "off-policy learning",
          "Atari games",
          "algorithmic discovery",
          "adaptive RL agents"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   **technical:** the abstract explicitly states, \"we **propose an algorithm** based on meta-gradient descent that discovers its own objective...\" and discusses the \"meta-gradient **algorithm**.\" the introduction reinforces this by stating, \"our goal is an **algorithm** that instead learns its own objective...\" this clearly indicates the paper presents a new method or system.\n*   **empirical:** the abstract mentions, \"on the atari learning environment, the meta-gradient algorithm adapts over time to learn with greater efﬁciency, eventually **outperforming the median score of a strong actor-critic baseline**.\" this describes experimental results and findings, which are characteristic of an empirical paper.\n\nwhile the paper includes strong empirical validation, its primary contribution, as highlighted in the abstract and introduction, is the **proposal of a new algorithm**. the empirical results serve to demonstrate the effectiveness of this new technical contribution. therefore, the most fitting single classification is **technical**.\n\n**classification: technical**"
      },
      "file_name": "759ae1234d46e2d1399ce9d642724738a766ed22.pdf"
    },
    {
      "success": true,
      "doc_id": "cee05bea6081a900033f93899602be7c",
      "summary": "Predictive autoscaling (autoscaling with workload forecasting) is an important mechanism that supports autonomous adjustment of computing resources in accordance with fluctuating workload demands in the Cloud. In recent works, Reinforcement Learning (RL) has been introduced as a promising approach to learn the resource management policies to guide the scaling actions under the dynamic and uncertain cloud environment. However, RL methods face the following challenges in steering predictive autoscaling, such as lack of accuracy in decision-making, inefficient sampling and significant variability in workload patterns that may cause policies to fail at test time. To this end, we propose an end-to-end predictive meta model-based RL algorithm, aiming to optimally allocate resource to maintain a stable CPU utilization level, which incorporates a specially-designed deep periodic workload prediction model as the input and embeds the Neural Process [11, 16] to guide the learning of the optimal scaling actions over numerous application services in the Cloud. Our algorithm not only ensures the predictability and accuracy of the scaling strategy, but also enables the scaling decisions to adapt to the changing workloads with high sample efficiency. Our method has achieved significant performance improvement compared to the existing algorithms and has been deployed online at Alipay, supporting the autoscaling of applications for the world-leading payment platform.",
      "intriguing_abstract": "Predictive autoscaling (autoscaling with workload forecasting) is an important mechanism that supports autonomous adjustment of computing resources in accordance with fluctuating workload demands in the Cloud. In recent works, Reinforcement Learning (RL) has been introduced as a promising approach to learn the resource management policies to guide the scaling actions under the dynamic and uncertain cloud environment. However, RL methods face the following challenges in steering predictive autoscaling, such as lack of accuracy in decision-making, inefficient sampling and significant variability in workload patterns that may cause policies to fail at test time. To this end, we propose an end-to-end predictive meta model-based RL algorithm, aiming to optimally allocate resource to maintain a stable CPU utilization level, which incorporates a specially-designed deep periodic workload prediction model as the input and embeds the Neural Process [11, 16] to guide the learning of the optimal scaling actions over numerous application services in the Cloud. Our algorithm not only ensures the predictability and accuracy of the scaling strategy, but also enables the scaling decisions to adapt to the changing workloads with high sample efficiency. Our method has achieved significant performance improvement compared to the existing algorithms and has been deployed online at Alipay, supporting the autoscaling of applications for the world-leading payment platform.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/8f502a85ed14fecab7c04d3523ef01458e5e8d1d.pdf",
      "citation_key": "xue2022ram",
      "metadata": {
        "title": "A Meta Reinforcement Learning Approach for Predictive Autoscaling in the Cloud",
        "authors": [
          "Siqiao Xue",
          "C. Qu",
          "X. Shi",
          "Cong Liao",
          "Shiyi Zhu",
          "Xiaoyu Tan",
          "Lintao Ma",
          "Shiyu Wang",
          "Shijun Wang",
          "Yun Hu",
          "Lei Lei",
          "Yang Zheng",
          "Jianguo Li",
          "James Zhang"
        ],
        "published_date": "2022",
        "abstract": "Predictive autoscaling (autoscaling with workload forecasting) is an important mechanism that supports autonomous adjustment of computing resources in accordance with fluctuating workload demands in the Cloud. In recent works, Reinforcement Learning (RL) has been introduced as a promising approach to learn the resource management policies to guide the scaling actions under the dynamic and uncertain cloud environment. However, RL methods face the following challenges in steering predictive autoscaling, such as lack of accuracy in decision-making, inefficient sampling and significant variability in workload patterns that may cause policies to fail at test time. To this end, we propose an end-to-end predictive meta model-based RL algorithm, aiming to optimally allocate resource to maintain a stable CPU utilization level, which incorporates a specially-designed deep periodic workload prediction model as the input and embeds the Neural Process [11, 16] to guide the learning of the optimal scaling actions over numerous application services in the Cloud. Our algorithm not only ensures the predictability and accuracy of the scaling strategy, but also enables the scaling decisions to adapt to the changing workloads with high sample efficiency. Our method has achieved significant performance improvement compared to the existing algorithms and has been deployed online at Alipay, supporting the autoscaling of applications for the world-leading payment platform.",
        "file_path": "paper_data/Deep_Meta-Learning/info/8f502a85ed14fecab7c04d3523ef01458e5e8d1d.pdf",
        "venue": "Knowledge Discovery and Data Mining",
        "citationCount": 45,
        "score": 15.0,
        "summary": "Predictive autoscaling (autoscaling with workload forecasting) is an important mechanism that supports autonomous adjustment of computing resources in accordance with fluctuating workload demands in the Cloud. In recent works, Reinforcement Learning (RL) has been introduced as a promising approach to learn the resource management policies to guide the scaling actions under the dynamic and uncertain cloud environment. However, RL methods face the following challenges in steering predictive autoscaling, such as lack of accuracy in decision-making, inefficient sampling and significant variability in workload patterns that may cause policies to fail at test time. To this end, we propose an end-to-end predictive meta model-based RL algorithm, aiming to optimally allocate resource to maintain a stable CPU utilization level, which incorporates a specially-designed deep periodic workload prediction model as the input and embeds the Neural Process [11, 16] to guide the learning of the optimal scaling actions over numerous application services in the Cloud. Our algorithm not only ensures the predictability and accuracy of the scaling strategy, but also enables the scaling decisions to adapt to the changing workloads with high sample efficiency. Our method has achieved significant performance improvement compared to the existing algorithms and has been deployed online at Alipay, supporting the autoscaling of applications for the world-leading payment platform.",
        "keywords": []
      },
      "file_name": "8f502a85ed14fecab7c04d3523ef01458e5e8d1d.pdf"
    },
    {
      "success": true,
      "doc_id": "74040dd8f83114ad98aca5158735d747",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing self-supervised Visual Odometry (VO) networks suffer a significant performance drop when deployed in environments different from their training data (i.e., domain shift). This \"closed-world assumption\" makes them impractical for real-world applications like autonomous driving or robotics, where scenes continuously change \\cite{li20208tg}.\n    *   **Importance & Challenge**: VO is crucial for many real-world applications. The challenge lies in enabling VO networks to continuously and rapidly adapt to new, unseen, and non-stationary environments in a self-supervised, real-time manner, without requiring pre-collected ground truth data for fine-tuning \\cite{li20208tg}. Naive online learning approaches are limited by a small temporal perceptive field, leading to oscillating parameters, inconsistent gradients, and slow convergence.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon self-supervised VO methods like SfM-Learner \\cite{li20208tg} and SA VO \\cite{li20208tg}, which use photometric loss and 3D geometric constraints. It also draws inspiration from meta-learning, particularly Model Agnostic Meta-Learning (MAML) \\cite{li20208tg}, and domain adaptation techniques for feature alignment.\n    *   **Limitations of Previous Solutions**:\n        *   Classic SLAM/VO methods fail in challenging conditions (e.g., dynamic objects, textureless regions).\n        *   Learning-based VO methods (e.g., DeepVO) often require expensive ground truth data.\n        *   Self-supervised VO methods (e.g., SfM-Learner \\cite{li20208tg}) typically focus on local structure from motion and fail to exploit spatial-temporal correlations over long sequences, leading to poor generalization across domains.\n        *   Conventional online learning struggles with non-stationary data distributions and slow convergence due to limited temporal context.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes an online meta-learning algorithm for self-supervised VO that enables continuous adaptation to new environments.\n        *   **Online Meta-Learning Objective**: Instead of minimizing the loss on the current data `D_i`, the objective is extended to minimize the loss on the *next* data `D_{i+1}` after adapting to `D_i` (Eq. 3). This effectively incorporates the online adaptation process into the learning objective, motivating the network to learn parameters that perform well consistently over time. This is analogous to MAML \\cite{li20208tg}.\n        *   **Two-Stage Gradient Descent**: An inner loop updates parameters on `D_i`, and an outer loop evaluates the updated model on `D_{i+1}`. Taylor expansion shows this maximizes the similarity between gradients at `D_i` and `D_{i+1}`, ensuring consistent gradient directions and faster adaptation.\n        *   **Spatial-Temporal Aggregation with ConvLSTM**: Convolutional Long Short-Term Memory (convLSTM) units are embedded into the encoder of the DepthNet and PoseNet. This allows the network to aggregate rich spatial-temporal information from a sliding window of `N` consecutive frames, leveraging past experience for better estimation and faster adaptation, and mitigating error accumulation.\n        *   **Online Feature Alignment**: A method is introduced to align non-stationary feature distributions at different times. It uses Layer Normalization statistics (mean and variance) and an exponential moving average to update feature statistics, ensuring consistency across changing scenes.\n    *   **Novelty/Difference**: The key innovation is the integration of online meta-learning with spatial-temporal aggregation (convLSTM) and online feature alignment within a self-supervised VO framework. This allows for real-time, continuous adaptation to unseen and changing environments without external supervision, directly addressing the domain shift problem that plagues existing learning-based VO methods \\cite{li20208tg}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: An online meta-learning algorithm specifically tailored for self-supervised VO, which optimizes for future performance after adaptation to the current data.\n    *   **Architectural Innovation**: Integration of convLSTM into the DepthNet and PoseNet encoders to effectively aggregate spatial-temporal information and leverage past experience for improved estimation and adaptation.\n    *   **Novel Technique**: An online feature alignment method that dynamically aligns feature distributions across different time steps using Layer Normalization statistics, acting as a regularization to maintain consistent learned weights in non-stationary environments.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on the KITTI odometry dataset \\cite{li20208tg} (sequences 00-08 for training, 09-10 for online test). The abstract also mentions validation on unseen outdoor scenes, virtual-to-real world, and outdoor-to-indoor environments.\n    *   **Key Performance Metrics**: Translational Root Mean Square Error (RMSE) drift (terr, %) and Rotational RMSE drift (rerr, °/100m) were used, calculated on full trajectories using the KITTI evaluation toolkit.\n    *   **Comparison Results**: The proposed method consistently and considerably outperforms state-of-the-art self-supervised VO baselines, including SfMLearner \\cite{li20208tg}, Vid2Depth, Zhan et al., GeoNet, and SA VO \\cite{li20208tg}. For example, on KITTI Seq. 09, it achieved a terr of 5.89% and rerr of 3.34°/100m, significantly better than SA VO's \\cite{li20208tg} 9.52% and 3.64°/100m. On Seq. 10, it achieved 4.79% terr and 0.83°/100m rerr, compared to SA VO's \\cite{li20208tg} 6.45% and 2.41°/100m. The method also achieves real-time performance at 32 FPS on a Geforce 1080Ti GPU.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper primarily addresses the domain shift problem in self-supervised monocular VO. While it improves generalization, the inherent challenges of monocular VO (e.g., scale ambiguity) are still present. The effectiveness of feature alignment relies on the assumption that feature distributions should be similar across continuously observed, albeit changing, scenes.\n    *   **Scope of Applicability**: The method is applicable to self-supervised deep visual odometry in dynamic, open-world environments where continuous adaptation is required. It is demonstrated on outdoor driving scenes (KITTI) and is claimed to generalize to virtual-to-real and outdoor-to-indoor scenarios.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the state-of-the-art in self-supervised VO by providing a robust solution to the critical domain shift problem. By enabling continuous, real-time adaptation without ground truth, it makes learning-based VO more viable for practical, open-world applications.\n    *   **Potential Impact**: The proposed online meta-learning framework, combined with spatial-temporal aggregation and feature alignment, offers a powerful paradigm for developing more robust and adaptable deep learning models in other sequential perception tasks where data distributions are non-stationary. It paves the way for more reliable deployment of learning-based VO in autonomous systems, robotics, and augmented/mixed reality.",
      "intriguing_abstract": "The promise of self-supervised Visual Odometry (VO) for autonomous systems is often hampered by a critical challenge: catastrophic performance degradation when deployed in environments different from training data – the pervasive \"domain shift\" problem. Current learning-based VO struggles to continuously and rapidly adapt to the dynamic, non-stationary real world without expensive ground truth, limiting their practical utility.\n\nWe introduce a novel, real-time online meta-learning framework for self-supervised VO that fundamentally addresses this limitation. Our approach integrates three key innovations: an online meta-learning objective that optimizes for future adaptation performance, a **ConvLSTM-based spatial-temporal aggregation** module to leverage long-term dependencies and mitigate error accumulation, and an **online feature alignment** mechanism to stabilize learning in continuously changing scenes. This synergistic combination enables our network to continuously adapt to unseen environments in a self-supervised manner, without requiring any ground truth.\n\nExtensive experiments on the KITTI dataset and diverse unseen scenarios demonstrate superior robustness and accuracy, significantly outperforming state-of-the-art self-supervised VO methods while operating in real-time. This work represents a crucial step towards deploying truly adaptable and reliable deep learning-based VO in open-world applications like autonomous driving and robotics.",
      "keywords": [
        "Self-supervised Visual Odometry (VO)",
        "domain shift",
        "online meta-learning",
        "continuous adaptation",
        "spatial-temporal aggregation",
        "ConvLSTM",
        "online feature alignment",
        "non-stationary environments",
        "real-time performance",
        "autonomous driving and robotics",
        "generalization across domains",
        "error accumulation mitigation"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/9e1ea0a5a29a19baf531aa5d9f32ca51d240d575.pdf",
      "citation_key": "li20208tg",
      "metadata": {
        "title": "Self-Supervised Deep Visual Odometry With Online Adaptation",
        "authors": [
          "Shunkai Li",
          "Xin Wang",
          "Yingdian Cao",
          "Fei Xue",
          "Zike Yan",
          "H. Zha"
        ],
        "published_date": "2020",
        "abstract": "Self-supervised VO methods have shown great success in jointly estimating camera pose and depth from videos. However, like most data-driven methods, existing VO networks suffer from a notable decrease in performance when confronted with scenes different from the training data, which makes them unsuitable for practical applications. In this paper, we propose an online meta-learning algorithm to enable VO networks to continuously adapt to new environments in a self-supervised manner. The proposed method utilizes convolutional long short-term memory (convLSTM) to aggregate rich spatial-temporal information in the past. The network is able to memorize and learn from its past experience for better estimation and fast adaptation to the current frame. When running VO in the open world, in order to deal with the changing environment, we propose an online feature alignment method by aligning feature distributions at different time. Our VO network is able to seamlessly adapt to different environments. Extensive experiments on unseen outdoor scenes, virtual to real world and outdoor to indoor environments demonstrate that our method consistently outperforms state-of-the-art self-supervised VO baselines considerably.",
        "file_path": "paper_data/Deep_Meta-Learning/info/9e1ea0a5a29a19baf531aa5d9f32ca51d240d575.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 73,
        "score": 14.600000000000001,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Existing self-supervised Visual Odometry (VO) networks suffer a significant performance drop when deployed in environments different from their training data (i.e., domain shift). This \"closed-world assumption\" makes them impractical for real-world applications like autonomous driving or robotics, where scenes continuously change \\cite{li20208tg}.\n    *   **Importance & Challenge**: VO is crucial for many real-world applications. The challenge lies in enabling VO networks to continuously and rapidly adapt to new, unseen, and non-stationary environments in a self-supervised, real-time manner, without requiring pre-collected ground truth data for fine-tuning \\cite{li20208tg}. Naive online learning approaches are limited by a small temporal perceptive field, leading to oscillating parameters, inconsistent gradients, and slow convergence.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon self-supervised VO methods like SfM-Learner \\cite{li20208tg} and SA VO \\cite{li20208tg}, which use photometric loss and 3D geometric constraints. It also draws inspiration from meta-learning, particularly Model Agnostic Meta-Learning (MAML) \\cite{li20208tg}, and domain adaptation techniques for feature alignment.\n    *   **Limitations of Previous Solutions**:\n        *   Classic SLAM/VO methods fail in challenging conditions (e.g., dynamic objects, textureless regions).\n        *   Learning-based VO methods (e.g., DeepVO) often require expensive ground truth data.\n        *   Self-supervised VO methods (e.g., SfM-Learner \\cite{li20208tg}) typically focus on local structure from motion and fail to exploit spatial-temporal correlations over long sequences, leading to poor generalization across domains.\n        *   Conventional online learning struggles with non-stationary data distributions and slow convergence due to limited temporal context.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes an online meta-learning algorithm for self-supervised VO that enables continuous adaptation to new environments.\n        *   **Online Meta-Learning Objective**: Instead of minimizing the loss on the current data `D_i`, the objective is extended to minimize the loss on the *next* data `D_{i+1}` after adapting to `D_i` (Eq. 3). This effectively incorporates the online adaptation process into the learning objective, motivating the network to learn parameters that perform well consistently over time. This is analogous to MAML \\cite{li20208tg}.\n        *   **Two-Stage Gradient Descent**: An inner loop updates parameters on `D_i`, and an outer loop evaluates the updated model on `D_{i+1}`. Taylor expansion shows this maximizes the similarity between gradients at `D_i` and `D_{i+1}`, ensuring consistent gradient directions and faster adaptation.\n        *   **Spatial-Temporal Aggregation with ConvLSTM**: Convolutional Long Short-Term Memory (convLSTM) units are embedded into the encoder of the DepthNet and PoseNet. This allows the network to aggregate rich spatial-temporal information from a sliding window of `N` consecutive frames, leveraging past experience for better estimation and faster adaptation, and mitigating error accumulation.\n        *   **Online Feature Alignment**: A method is introduced to align non-stationary feature distributions at different times. It uses Layer Normalization statistics (mean and variance) and an exponential moving average to update feature statistics, ensuring consistency across changing scenes.\n    *   **Novelty/Difference**: The key innovation is the integration of online meta-learning with spatial-temporal aggregation (convLSTM) and online feature alignment within a self-supervised VO framework. This allows for real-time, continuous adaptation to unseen and changing environments without external supervision, directly addressing the domain shift problem that plagues existing learning-based VO methods \\cite{li20208tg}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: An online meta-learning algorithm specifically tailored for self-supervised VO, which optimizes for future performance after adaptation to the current data.\n    *   **Architectural Innovation**: Integration of convLSTM into the DepthNet and PoseNet encoders to effectively aggregate spatial-temporal information and leverage past experience for improved estimation and adaptation.\n    *   **Novel Technique**: An online feature alignment method that dynamically aligns feature distributions across different time steps using Layer Normalization statistics, acting as a regularization to maintain consistent learned weights in non-stationary environments.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed on the KITTI odometry dataset \\cite{li20208tg} (sequences 00-08 for training, 09-10 for online test). The abstract also mentions validation on unseen outdoor scenes, virtual-to-real world, and outdoor-to-indoor environments.\n    *   **Key Performance Metrics**: Translational Root Mean Square Error (RMSE) drift (terr, %) and Rotational RMSE drift (rerr, °/100m) were used, calculated on full trajectories using the KITTI evaluation toolkit.\n    *   **Comparison Results**: The proposed method consistently and considerably outperforms state-of-the-art self-supervised VO baselines, including SfMLearner \\cite{li20208tg}, Vid2Depth, Zhan et al., GeoNet, and SA VO \\cite{li20208tg}. For example, on KITTI Seq. 09, it achieved a terr of 5.89% and rerr of 3.34°/100m, significantly better than SA VO's \\cite{li20208tg} 9.52% and 3.64°/100m. On Seq. 10, it achieved 4.79% terr and 0.83°/100m rerr, compared to SA VO's \\cite{li20208tg} 6.45% and 2.41°/100m. The method also achieves real-time performance at 32 FPS on a Geforce 1080Ti GPU.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper primarily addresses the domain shift problem in self-supervised monocular VO. While it improves generalization, the inherent challenges of monocular VO (e.g., scale ambiguity) are still present. The effectiveness of feature alignment relies on the assumption that feature distributions should be similar across continuously observed, albeit changing, scenes.\n    *   **Scope of Applicability**: The method is applicable to self-supervised deep visual odometry in dynamic, open-world environments where continuous adaptation is required. It is demonstrated on outdoor driving scenes (KITTI) and is claimed to generalize to virtual-to-real and outdoor-to-indoor scenarios.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the state-of-the-art in self-supervised VO by providing a robust solution to the critical domain shift problem. By enabling continuous, real-time adaptation without ground truth, it makes learning-based VO more viable for practical, open-world applications.\n    *   **Potential Impact**: The proposed online meta-learning framework, combined with spatial-temporal aggregation and feature alignment, offers a powerful paradigm for developing more robust and adaptable deep learning models in other sequential perception tasks where data distributions are non-stationary. It paves the way for more reliable deployment of learning-based VO in autonomous systems, robotics, and augmented/mixed reality.",
        "keywords": [
          "Self-supervised Visual Odometry (VO)",
          "domain shift",
          "online meta-learning",
          "continuous adaptation",
          "spatial-temporal aggregation",
          "ConvLSTM",
          "online feature alignment",
          "non-stationary environments",
          "real-time performance",
          "autonomous driving and robotics",
          "generalization across domains",
          "error accumulation mitigation"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** an online meta-learning algorithm,\" \"the **proposed method utilizes** convolutional long short-term memory (convlstm),\" and \"we **propose** an online feature alignment method.\" these phrases directly align with the \"technical\" classification criteria.\n*   the introduction discusses a \"technical problem\" (domain shift in learning-based vo) and sets the stage for their \"proposed solution.\"\n*   while \"extensive experiments... demonstrate that our method consistently outperforms...\" indicates an empirical component, this is the validation of the *new method*, making the primary contribution technical.\n\ntherefore, the paper type is:\n\n**technical**"
      },
      "file_name": "9e1ea0a5a29a19baf531aa5d9f32ca51d240d575.pdf"
    },
    {
      "success": true,
      "doc_id": "d2ce2d776c9015c2738b47aa4c0effd5",
      "summary": "Recently, pre-trained programming language models such as Code-BERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages with relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer learning framework where an initial program representation model is pre-trained on a large corpus of common programming languages (such as Java and Python), and is further adapted to domain-specific languages such as Solidity and SQL. Un-like cross-language CodeBERT, which is directly fine-tuned in the target language, CDCS adapts a few-shot meta-learning algorithm called MAML to learn the good initialization of model parameters, which can be best reused in a domain-specific language. We evaluate the proposed approach on two domain-specific languages, namely Solidity and SQL, with model transferred from two widely used languages (Python and Java). Experimental results show that CDCS significantly outperforms conventional pre-trained code models that are directly fine-tuned in domain-specific languages, and it is particularly effective for scarce data.",
      "intriguing_abstract": "Recently, pre-trained programming language models such as Code-BERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages with relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer learning framework where an initial program representation model is pre-trained on a large corpus of common programming languages (such as Java and Python), and is further adapted to domain-specific languages such as Solidity and SQL. Un-like cross-language CodeBERT, which is directly fine-tuned in the target language, CDCS adapts a few-shot meta-learning algorithm called MAML to learn the good initialization of model parameters, which can be best reused in a domain-specific language. We evaluate the proposed approach on two domain-specific languages, namely Solidity and SQL, with model transferred from two widely used languages (Python and Java). Experimental results show that CDCS significantly outperforms conventional pre-trained code models that are directly fine-tuned in domain-specific languages, and it is particularly effective for scarce data.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/190ae56a68a94620d7ddfdc7c4b1424673f78b97.pdf",
      "citation_key": "chai2022kv5",
      "metadata": {
        "title": "Cross-Domain Deep Code Search with Meta Learning",
        "authors": [
          "Yitian Chai",
          "Hongyu Zhang",
          "Beijun Shen",
          "Xiaodong Gu"
        ],
        "published_date": "2022",
        "abstract": "Recently, pre-trained programming language models such as Code-BERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages with relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer learning framework where an initial program representation model is pre-trained on a large corpus of common programming languages (such as Java and Python), and is further adapted to domain-specific languages such as Solidity and SQL. Un-like cross-language CodeBERT, which is directly fine-tuned in the target language, CDCS adapts a few-shot meta-learning algorithm called MAML to learn the good initialization of model parameters, which can be best reused in a domain-specific language. We evaluate the proposed approach on two domain-specific languages, namely Solidity and SQL, with model transferred from two widely used languages (Python and Java). Experimental results show that CDCS significantly outperforms conventional pre-trained code models that are directly fine-tuned in domain-specific languages, and it is particularly effective for scarce data.",
        "file_path": "paper_data/Deep_Meta-Learning/info/190ae56a68a94620d7ddfdc7c4b1424673f78b97.pdf",
        "venue": "International Conference on Software Engineering",
        "citationCount": 43,
        "score": 14.333333333333332,
        "summary": "Recently, pre-trained programming language models such as Code-BERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages with relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer learning framework where an initial program representation model is pre-trained on a large corpus of common programming languages (such as Java and Python), and is further adapted to domain-specific languages such as Solidity and SQL. Un-like cross-language CodeBERT, which is directly fine-tuned in the target language, CDCS adapts a few-shot meta-learning algorithm called MAML to learn the good initialization of model parameters, which can be best reused in a domain-specific language. We evaluate the proposed approach on two domain-specific languages, namely Solidity and SQL, with model transferred from two widely used languages (Python and Java). Experimental results show that CDCS significantly outperforms conventional pre-trained code models that are directly fine-tuned in domain-specific languages, and it is particularly effective for scarce data.",
        "keywords": []
      },
      "file_name": "190ae56a68a94620d7ddfdc7c4b1424673f78b97.pdf"
    },
    {
      "success": true,
      "doc_id": "671cfecfa6136b5187d73226de490229",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/acf3b693d1c04070f2f4cc7bbe839d9e50329e34.pdf",
      "citation_key": "yi2021547",
      "metadata": {
        "title": "An Automated Hyperparameter Search-Based Deep Learning Model for Highway Traffic Prediction",
        "authors": [
          "Hongsuk Yi",
          "Khac-Hoai Nam Bui"
        ],
        "published_date": "2021",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/acf3b693d1c04070f2f4cc7bbe839d9e50329e34.pdf",
        "venue": "IEEE transactions on intelligent transportation systems (Print)",
        "citationCount": 57,
        "score": 14.25,
        "summary": "",
        "keywords": []
      },
      "file_name": "acf3b693d1c04070f2f4cc7bbe839d9e50329e34.pdf"
    },
    {
      "success": true,
      "doc_id": "c9e1278ee7fe021f230dcd640d35c610",
      "summary": "Active learning (AL) aims to enable training high performance classifiers with low annotation cost by predicting which subset of unlabelled instances would be most beneficial to label. The importance of AL has motivated extensive research, proposing a wide variety of manually designed AL algorithms with diverse theoretical and intuitive motivations. In contrast to this body of research, we propose to treat active learning algorithm design as a meta-learning problem and learn the best criterion from data. We model an active learning algorithm as a deep neural network that inputs the base learner state and the unlabelled point set and predicts the best point to annotate next. Training this active query policy network with reinforcement learning, produces the best non-myopic policy for a given dataset. The key challenge in achieving a general solution to AL then becomes that of learner generalisation, particularly across heterogeneous datasets. We propose a multi-task dataset-embedding approach that allows dataset-agnostic active learners to be trained. Our evaluation shows that AL algorithms trained in this way can directly generalise across diverse problems.",
      "intriguing_abstract": "Active learning (AL) aims to enable training high performance classifiers with low annotation cost by predicting which subset of unlabelled instances would be most beneficial to label. The importance of AL has motivated extensive research, proposing a wide variety of manually designed AL algorithms with diverse theoretical and intuitive motivations. In contrast to this body of research, we propose to treat active learning algorithm design as a meta-learning problem and learn the best criterion from data. We model an active learning algorithm as a deep neural network that inputs the base learner state and the unlabelled point set and predicts the best point to annotate next. Training this active query policy network with reinforcement learning, produces the best non-myopic policy for a given dataset. The key challenge in achieving a general solution to AL then becomes that of learner generalisation, particularly across heterogeneous datasets. We propose a multi-task dataset-embedding approach that allows dataset-agnostic active learners to be trained. Our evaluation shows that AL algorithms trained in this way can directly generalise across diverse problems.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/fd66dfb9ca3eb16b365b621bcdf1145b3a29f51e.pdf",
      "citation_key": "pang2018qqo",
      "metadata": {
        "title": "Meta-Learning Transferable Active Learning Policies by Deep Reinforcement Learning",
        "authors": [
          "Kunkun Pang",
          "Mingzhi Dong",
          "Yang Wu",
          "Timothy M. Hospedales"
        ],
        "published_date": "2018",
        "abstract": "Active learning (AL) aims to enable training high performance classifiers with low annotation cost by predicting which subset of unlabelled instances would be most beneficial to label. The importance of AL has motivated extensive research, proposing a wide variety of manually designed AL algorithms with diverse theoretical and intuitive motivations. In contrast to this body of research, we propose to treat active learning algorithm design as a meta-learning problem and learn the best criterion from data. We model an active learning algorithm as a deep neural network that inputs the base learner state and the unlabelled point set and predicts the best point to annotate next. Training this active query policy network with reinforcement learning, produces the best non-myopic policy for a given dataset. The key challenge in achieving a general solution to AL then becomes that of learner generalisation, particularly across heterogeneous datasets. We propose a multi-task dataset-embedding approach that allows dataset-agnostic active learners to be trained. Our evaluation shows that AL algorithms trained in this way can directly generalise across diverse problems.",
        "file_path": "paper_data/Deep_Meta-Learning/info/fd66dfb9ca3eb16b365b621bcdf1145b3a29f51e.pdf",
        "venue": "arXiv.org",
        "citationCount": 91,
        "score": 13.0,
        "summary": "Active learning (AL) aims to enable training high performance classifiers with low annotation cost by predicting which subset of unlabelled instances would be most beneficial to label. The importance of AL has motivated extensive research, proposing a wide variety of manually designed AL algorithms with diverse theoretical and intuitive motivations. In contrast to this body of research, we propose to treat active learning algorithm design as a meta-learning problem and learn the best criterion from data. We model an active learning algorithm as a deep neural network that inputs the base learner state and the unlabelled point set and predicts the best point to annotate next. Training this active query policy network with reinforcement learning, produces the best non-myopic policy for a given dataset. The key challenge in achieving a general solution to AL then becomes that of learner generalisation, particularly across heterogeneous datasets. We propose a multi-task dataset-embedding approach that allows dataset-agnostic active learners to be trained. Our evaluation shows that AL algorithms trained in this way can directly generalise across diverse problems.",
        "keywords": []
      },
      "file_name": "fd66dfb9ca3eb16b365b621bcdf1145b3a29f51e.pdf"
    },
    {
      "success": true,
      "doc_id": "b62b0ef707ece5b8cfa59870f38fb1e8",
      "summary": "X-ray Computed Tomography (CT) is widely used in clinical applications such as diagnosis and image-guided interventions. In this paper, we propose a new deep learning based model for CT image reconstruction with the backbone network architecture built by unrolling an iterative algorithm. However, unlike the existing strategy to include as many data-adaptive components in the unrolled dynamics model as possible, we find that it is enough to only learn the parts where traditional designs mostly rely on intuitions and experience. More specifically, we propose to learn an initializer for the conjugate gradient (CG) algorithm that involved in one of the subproblems of the backbone model. Other components, such as image priors and hyperparameters, are kept as the original design. Since a hypernetwork is introduced to inference on the initialization of the CG module, it makes the proposed model a certain meta-learning model. Therefore, we shall call the proposed model the meta-inversion network (MetaInv-Net). The proposed MetaInv-Net can be designed with much less trainable parameters while still preserves its superior image reconstruction performance than some state-of-the-art deep models in CT imaging. In simulated and real data experiments, MetaInv-Net performs very well and can be generalized beyond the training setting, i.e., to other scanning settings, noise levels, and data sets.",
      "intriguing_abstract": "X-ray Computed Tomography (CT) is widely used in clinical applications such as diagnosis and image-guided interventions. In this paper, we propose a new deep learning based model for CT image reconstruction with the backbone network architecture built by unrolling an iterative algorithm. However, unlike the existing strategy to include as many data-adaptive components in the unrolled dynamics model as possible, we find that it is enough to only learn the parts where traditional designs mostly rely on intuitions and experience. More specifically, we propose to learn an initializer for the conjugate gradient (CG) algorithm that involved in one of the subproblems of the backbone model. Other components, such as image priors and hyperparameters, are kept as the original design. Since a hypernetwork is introduced to inference on the initialization of the CG module, it makes the proposed model a certain meta-learning model. Therefore, we shall call the proposed model the meta-inversion network (MetaInv-Net). The proposed MetaInv-Net can be designed with much less trainable parameters while still preserves its superior image reconstruction performance than some state-of-the-art deep models in CT imaging. In simulated and real data experiments, MetaInv-Net performs very well and can be generalized beyond the training setting, i.e., to other scanning settings, noise levels, and data sets.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/4c5f9062192728d20c8d15fe4abf2d68d462db80.pdf",
      "citation_key": "zhang2020s15",
      "metadata": {
        "title": "MetaInv-Net: Meta Inversion Network for Sparse View CT Image Reconstruction",
        "authors": [
          "Haimiao Zhang",
          "Baodong Liu",
          "Hengyong Yu",
          "Bin Dong"
        ],
        "published_date": "2020",
        "abstract": "X-ray Computed Tomography (CT) is widely used in clinical applications such as diagnosis and image-guided interventions. In this paper, we propose a new deep learning based model for CT image reconstruction with the backbone network architecture built by unrolling an iterative algorithm. However, unlike the existing strategy to include as many data-adaptive components in the unrolled dynamics model as possible, we find that it is enough to only learn the parts where traditional designs mostly rely on intuitions and experience. More specifically, we propose to learn an initializer for the conjugate gradient (CG) algorithm that involved in one of the subproblems of the backbone model. Other components, such as image priors and hyperparameters, are kept as the original design. Since a hypernetwork is introduced to inference on the initialization of the CG module, it makes the proposed model a certain meta-learning model. Therefore, we shall call the proposed model the meta-inversion network (MetaInv-Net). The proposed MetaInv-Net can be designed with much less trainable parameters while still preserves its superior image reconstruction performance than some state-of-the-art deep models in CT imaging. In simulated and real data experiments, MetaInv-Net performs very well and can be generalized beyond the training setting, i.e., to other scanning settings, noise levels, and data sets.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4c5f9062192728d20c8d15fe4abf2d68d462db80.pdf",
        "venue": "IEEE Transactions on Medical Imaging",
        "citationCount": 64,
        "score": 12.8,
        "summary": "X-ray Computed Tomography (CT) is widely used in clinical applications such as diagnosis and image-guided interventions. In this paper, we propose a new deep learning based model for CT image reconstruction with the backbone network architecture built by unrolling an iterative algorithm. However, unlike the existing strategy to include as many data-adaptive components in the unrolled dynamics model as possible, we find that it is enough to only learn the parts where traditional designs mostly rely on intuitions and experience. More specifically, we propose to learn an initializer for the conjugate gradient (CG) algorithm that involved in one of the subproblems of the backbone model. Other components, such as image priors and hyperparameters, are kept as the original design. Since a hypernetwork is introduced to inference on the initialization of the CG module, it makes the proposed model a certain meta-learning model. Therefore, we shall call the proposed model the meta-inversion network (MetaInv-Net). The proposed MetaInv-Net can be designed with much less trainable parameters while still preserves its superior image reconstruction performance than some state-of-the-art deep models in CT imaging. In simulated and real data experiments, MetaInv-Net performs very well and can be generalized beyond the training setting, i.e., to other scanning settings, noise levels, and data sets.",
        "keywords": []
      },
      "file_name": "4c5f9062192728d20c8d15fe4abf2d68d462db80.pdf"
    },
    {
      "success": true,
      "doc_id": "fa14857373e4033f868f2a16447f4c1e",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c7629a4d7e1c87fd1ea73850bcb800538fd0aa4b.pdf",
      "citation_key": "zintgraf2021lv1",
      "metadata": {
        "title": "VariBAD: Variational Bayes-Adaptive Deep RL via Meta-Learning",
        "authors": [
          "Luisa M. Zintgraf",
          "Sebastian Schulze",
          "Cong Lu",
          "Leo Feng",
          "Maximilian Igl",
          "Kyriacos Shiarlis",
          "Y. Gal",
          "Katja Hofmann",
          "S. Whiteson"
        ],
        "published_date": "2021",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/c7629a4d7e1c87fd1ea73850bcb800538fd0aa4b.pdf",
        "venue": "Journal of machine learning research",
        "citationCount": 51,
        "score": 12.75,
        "summary": "",
        "keywords": []
      },
      "file_name": "c7629a4d7e1c87fd1ea73850bcb800538fd0aa4b.pdf"
    },
    {
      "success": true,
      "doc_id": "13c831249eeee1521dd0db887392b2d7",
      "summary": "Click-through rate (CTR) prediction is one of the most central tasks in online advertising systems. Recent deep learning-based models that exploit feature embedding and high-order data nonlinearity have shown dramatic successes in CTR prediction. However, these models work poorly on cold-start ads with new IDs, whose embeddings are not well learned yet. In this paper, we propose Graph Meta Embedding (GME) models that can rapidly learn how to generate desirable initial embeddings for new ad IDs based on graph neural networks and meta learning. Previous works address this problem from the new ad itself, but ignore possibly useful information contained in existing old ads. In contrast, GMEs simultaneously consider two information sources: the new ad and existing old ads. For the new ad, GMEs exploit its associated attributes. For existing old ads, GMEs first build a graph to connect them with new ads, and then adaptively distill useful information. We propose three specific GMEs from different perspectives to explore what kind of information to use and how to distill information. In particular, GME-P uses Pre-trained neighbor ID embeddings, GME-G uses Generated neighbor ID embeddings and GME-A uses neighbor Attributes. Experimental results on three real-world datasets show that GMEs can significantly improve the prediction performance in both cold-start (i.e., no training data is available) and warm-up (i.e., a small number of training samples are collected) scenarios over five major deep learning-based CTR prediction models. GMEs can be applied to conversion rate (CVR) prediction as well.",
      "intriguing_abstract": "Click-through rate (CTR) prediction is one of the most central tasks in online advertising systems. Recent deep learning-based models that exploit feature embedding and high-order data nonlinearity have shown dramatic successes in CTR prediction. However, these models work poorly on cold-start ads with new IDs, whose embeddings are not well learned yet. In this paper, we propose Graph Meta Embedding (GME) models that can rapidly learn how to generate desirable initial embeddings for new ad IDs based on graph neural networks and meta learning. Previous works address this problem from the new ad itself, but ignore possibly useful information contained in existing old ads. In contrast, GMEs simultaneously consider two information sources: the new ad and existing old ads. For the new ad, GMEs exploit its associated attributes. For existing old ads, GMEs first build a graph to connect them with new ads, and then adaptively distill useful information. We propose three specific GMEs from different perspectives to explore what kind of information to use and how to distill information. In particular, GME-P uses Pre-trained neighbor ID embeddings, GME-G uses Generated neighbor ID embeddings and GME-A uses neighbor Attributes. Experimental results on three real-world datasets show that GMEs can significantly improve the prediction performance in both cold-start (i.e., no training data is available) and warm-up (i.e., a small number of training samples are collected) scenarios over five major deep learning-based CTR prediction models. GMEs can be applied to conversion rate (CVR) prediction as well.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/8db32b965c10c7dc9f1e3ab357c5298f37d1b86f.pdf",
      "citation_key": "ouyang2021c4t",
      "metadata": {
        "title": "Learning Graph Meta Embeddings for Cold-Start Ads in Click-Through Rate Prediction",
        "authors": [
          "W. Ouyang",
          "Xiuwu Zhang",
          "Shukui Ren",
          "Li Li",
          "Kun Zhang",
          "Jinmei Luo",
          "Zhaojie Liu",
          "Yanlong Du"
        ],
        "published_date": "2021",
        "abstract": "Click-through rate (CTR) prediction is one of the most central tasks in online advertising systems. Recent deep learning-based models that exploit feature embedding and high-order data nonlinearity have shown dramatic successes in CTR prediction. However, these models work poorly on cold-start ads with new IDs, whose embeddings are not well learned yet. In this paper, we propose Graph Meta Embedding (GME) models that can rapidly learn how to generate desirable initial embeddings for new ad IDs based on graph neural networks and meta learning. Previous works address this problem from the new ad itself, but ignore possibly useful information contained in existing old ads. In contrast, GMEs simultaneously consider two information sources: the new ad and existing old ads. For the new ad, GMEs exploit its associated attributes. For existing old ads, GMEs first build a graph to connect them with new ads, and then adaptively distill useful information. We propose three specific GMEs from different perspectives to explore what kind of information to use and how to distill information. In particular, GME-P uses Pre-trained neighbor ID embeddings, GME-G uses Generated neighbor ID embeddings and GME-A uses neighbor Attributes. Experimental results on three real-world datasets show that GMEs can significantly improve the prediction performance in both cold-start (i.e., no training data is available) and warm-up (i.e., a small number of training samples are collected) scenarios over five major deep learning-based CTR prediction models. GMEs can be applied to conversion rate (CVR) prediction as well.",
        "file_path": "paper_data/Deep_Meta-Learning/info/8db32b965c10c7dc9f1e3ab357c5298f37d1b86f.pdf",
        "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
        "citationCount": 51,
        "score": 12.75,
        "summary": "Click-through rate (CTR) prediction is one of the most central tasks in online advertising systems. Recent deep learning-based models that exploit feature embedding and high-order data nonlinearity have shown dramatic successes in CTR prediction. However, these models work poorly on cold-start ads with new IDs, whose embeddings are not well learned yet. In this paper, we propose Graph Meta Embedding (GME) models that can rapidly learn how to generate desirable initial embeddings for new ad IDs based on graph neural networks and meta learning. Previous works address this problem from the new ad itself, but ignore possibly useful information contained in existing old ads. In contrast, GMEs simultaneously consider two information sources: the new ad and existing old ads. For the new ad, GMEs exploit its associated attributes. For existing old ads, GMEs first build a graph to connect them with new ads, and then adaptively distill useful information. We propose three specific GMEs from different perspectives to explore what kind of information to use and how to distill information. In particular, GME-P uses Pre-trained neighbor ID embeddings, GME-G uses Generated neighbor ID embeddings and GME-A uses neighbor Attributes. Experimental results on three real-world datasets show that GMEs can significantly improve the prediction performance in both cold-start (i.e., no training data is available) and warm-up (i.e., a small number of training samples are collected) scenarios over five major deep learning-based CTR prediction models. GMEs can be applied to conversion rate (CVR) prediction as well.",
        "keywords": []
      },
      "file_name": "8db32b965c10c7dc9f1e3ab357c5298f37d1b86f.pdf"
    },
    {
      "success": true,
      "doc_id": "4bb4b1ad850422f21720bc825cd90cb6",
      "summary": "Visual navigation is a task of training an embodied agent by intelligently navigating to a target object (e.g., television) using only visual observations. A key challenge for current deep reinforcement learning models lies in the requirements for a large amount of training data. It is exceedingly expensive to construct sufficient 3D synthetic environments annotated with the target object information. In this paper, we focus on visual navigation in the low-resource setting, where we have only a few training environments annotated with object information. We propose a novel unsupervised reinforcement learning approach to learn transferable meta-skills (e.g., bypass obstacles, go straight) from unannotated environments without any supervisory signals. The agent can then fast adapt to visual navigation through learning a high-level master policy to combine these meta-skills, when the visual-navigation-specified reward is provided. Experimental results show that our method significantly outperforms the baseline by 53.34% relatively on SPL, and further qualitative analysis demonstrates that our method learns transferable motor primitives for visual navigation.",
      "intriguing_abstract": "Visual navigation is a task of training an embodied agent by intelligently navigating to a target object (e.g., television) using only visual observations. A key challenge for current deep reinforcement learning models lies in the requirements for a large amount of training data. It is exceedingly expensive to construct sufficient 3D synthetic environments annotated with the target object information. In this paper, we focus on visual navigation in the low-resource setting, where we have only a few training environments annotated with object information. We propose a novel unsupervised reinforcement learning approach to learn transferable meta-skills (e.g., bypass obstacles, go straight) from unannotated environments without any supervisory signals. The agent can then fast adapt to visual navigation through learning a high-level master policy to combine these meta-skills, when the visual-navigation-specified reward is provided. Experimental results show that our method significantly outperforms the baseline by 53.34% relatively on SPL, and further qualitative analysis demonstrates that our method learns transferable motor primitives for visual navigation.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3f787ac280c3d0dbb16eb2456e62ffbf1a56ff62.pdf",
      "citation_key": "li2019gpj",
      "metadata": {
        "title": "Unsupervised Reinforcement Learning of Transferable Meta-Skills for Embodied Navigation",
        "authors": [
          "Juncheng Li",
          "X. Wang",
          "Siliang Tang",
          "Haizhou Shi",
          "Fei Wu",
          "Yueting Zhuang",
          "William Yang Wang"
        ],
        "published_date": "2019",
        "abstract": "Visual navigation is a task of training an embodied agent by intelligently navigating to a target object (e.g., television) using only visual observations. A key challenge for current deep reinforcement learning models lies in the requirements for a large amount of training data. It is exceedingly expensive to construct sufficient 3D synthetic environments annotated with the target object information. In this paper, we focus on visual navigation in the low-resource setting, where we have only a few training environments annotated with object information. We propose a novel unsupervised reinforcement learning approach to learn transferable meta-skills (e.g., bypass obstacles, go straight) from unannotated environments without any supervisory signals. The agent can then fast adapt to visual navigation through learning a high-level master policy to combine these meta-skills, when the visual-navigation-specified reward is provided. Experimental results show that our method significantly outperforms the baseline by 53.34% relatively on SPL, and further qualitative analysis demonstrates that our method learns transferable motor primitives for visual navigation.",
        "file_path": "paper_data/Deep_Meta-Learning/info/3f787ac280c3d0dbb16eb2456e62ffbf1a56ff62.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 76,
        "score": 12.666666666666666,
        "summary": "Visual navigation is a task of training an embodied agent by intelligently navigating to a target object (e.g., television) using only visual observations. A key challenge for current deep reinforcement learning models lies in the requirements for a large amount of training data. It is exceedingly expensive to construct sufficient 3D synthetic environments annotated with the target object information. In this paper, we focus on visual navigation in the low-resource setting, where we have only a few training environments annotated with object information. We propose a novel unsupervised reinforcement learning approach to learn transferable meta-skills (e.g., bypass obstacles, go straight) from unannotated environments without any supervisory signals. The agent can then fast adapt to visual navigation through learning a high-level master policy to combine these meta-skills, when the visual-navigation-specified reward is provided. Experimental results show that our method significantly outperforms the baseline by 53.34% relatively on SPL, and further qualitative analysis demonstrates that our method learns transferable motor primitives for visual navigation.",
        "keywords": []
      },
      "file_name": "3f787ac280c3d0dbb16eb2456e62ffbf1a56ff62.pdf"
    },
    {
      "success": true,
      "doc_id": "17363f289d766b47dc6f7a82f0cbddb7",
      "summary": "Here's a focused summary of the technical paper \\cite{yu2019o41} for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenges of Inverse Reinforcement Learning (IRL) in real-world applications:\n        1.  Existing IRL methods are data-inefficient, requiring large numbers of demonstrations to infer a reward function for each task from scratch.\n        2.  They typically assume homogeneous demonstrations for a single behavior or task, whereas real-world datasets are often heterogeneous but related.\n    *   **Importance and Challenge**: Manually designing reward functions for Reinforcement Learning (RL) is difficult, time-consuming, and prone to mis-specification, which can hamper learning. While IRL offers a solution by learning rewards from demonstrations, its data inefficiency and inability to handle diverse, unstructured demonstrations limit its practical applicability. Meta-learning holds promise for rapid adaptation, but prior Meta-IRL approaches were restricted to tabular MDPs or required pre-defined task distributions, which are hard to obtain in practice.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{yu2019o41} builds upon Maximum Entropy Inverse Reinforcement Learning (MaxEnt IRL) and its adversarial approximation (AIRL), as well as context-based meta-learning and deep latent variable generative models.\n    *   **Limitations of Previous Solutions**:\n        *   **Single-task IRL**: Data-inefficient, learns rewards from scratch for each task, and assumes homogeneous demonstrations.\n        *   **Imitation Learning**: Lacks the ability to transfer learned policies to new environments with changed dynamics, as it doesn't recover a transferable reward function.\n        *   **Prior Meta-IRL approaches** \\cite{xu2018meta, gleave2019meta}: Limited to discrete tabular MDPs or required explicit task distributions and grouped demonstrations, making them less applicable to complex, unstructured real-world data.\n        *   **One-shot imitation learning**: Often requires paired demonstrations from each task, which can be restrictive.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{yu2019o41} proposes Probabilistic Embeddings for Meta-Inverse Reinforcement Learning (PEMIRL), a deep latent variable model. It integrates context-based meta-learning, deep latent variable generative models, and maximum entropy inverse RL into a unified graphical model.\n    *   **Novelty/Difference**:\n        *   **Unsupervised Learning from Unstructured Data**: PEMIRL can learn robust reward functions from demonstrations of *distinct but related tasks in an unsupervised way*, without requiring specified task groupings or labels for each demonstration.\n        *   **Few-Shot Reward Inference**: It can infer rewards for *new, structurally-similar tasks from a single demonstration*, significantly improving data efficiency compared to traditional IRL.\n        *   **Mutual Information Regularization**: A key innovation is the use of mutual information regularization between the probabilistic context variable `m` and the trajectories `τ` to ensure the learned reward function `f(s,a,m)` effectively utilizes the inferred context, preventing the model from ignoring `m`.\n        *   **Sampling-Based Tractability**: It leverages an augmented adversarial IRL framework (with a context-conditional adaptive sampler `π_φ(a|s;m)` and discriminator `D_θ(s,a;m)`) and a generative process to achieve tractability for optimizing the mutual information objective.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: The PEMIRL framework itself, which is a novel combination of MaxEnt IRL, context-based meta-learning, and deep latent variable models for few-shot reward inference from unstructured multi-task demonstrations.\n    *   **Specific Techniques**:\n        *   Formulation of Meta-IRL as a constrained optimization problem, aiming to match conditional and posterior distributions of trajectories and context variables.\n        *   Introduction of a mutual information term `I_p(m; τ)` in the objective to establish a strong connection between the reward function and the latent context variable `m`.\n        *   Derivation of sampling-based gradient estimators for the mutual information term, relying on the optimality of the adaptive sampler in the adversarial framework (Lemma 1 and Lemma 2).\n        *   A generative process `τ ~ p_E(τ); m ~ q_φ(m|τ)` to synthesize latent context variables, approximating the prior task distribution when the model is trained.\n    *   **System Design**: A unified graphical model that bridges few-shot reward inference and learning from unstructured, heterogeneous demonstrations.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: \\cite{yu2019o41} evaluated PEMIRL on multiple continuous control tasks.\n    *   **Key Performance Metrics and Comparison Results**: The experiments demonstrated the effectiveness and scalability of PEMIRL compared to state-of-the-art imitation and inverse reinforcement learning methods. The tasks included:\n        *   Point-Maze\n        *   Ant\n        *   Sweeper\n        *   Sawyer Pusher\n        (While the abstract claims effectiveness and scalability, the provided text does not detail specific numerical metrics or direct comparison results, only the types of tasks used.)\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Assumes that the state space, action space, initial state distribution, and transition dynamics are independent of the context variable `m`.\n        *   Relies on the assumption that the adaptive sampler in the adversarial framework is trained to optimality for unbiased gradient estimation.\n    *   **Scope of Applicability**: PEMIRL is designed for complex domains with continuous state-action spaces and for learning rewards for *structurally-similar* tasks. It operates without prior knowledge of the task distribution `p(m)`, the latent context variable `m` for each demonstration, or the environment's transition dynamics during meta-training.\n\n*   **7. Technical Significance**\n    *   **Advance State-of-the-Art**: \\cite{yu2019o41} significantly advances the technical state-of-the-art by:\n        *   Overcoming the data inefficiency of traditional IRL by enabling few-shot reward inference.\n        *   Addressing the limitation of prior Meta-IRL methods by learning from unstructured, heterogeneous multi-task demonstrations in continuous control settings.\n        *   Providing a robust framework for disentangling reward functions from environment dynamics, making them more transferable.\n    *   **Potential Impact on Future Research**: This work opens new avenues for applying IRL in real-world scenarios where collecting large, perfectly labeled, and homogeneous demonstration datasets is impractical. It paves the way for more generalizable and adaptable reward learning systems, reducing the burden of reward engineering and facilitating the deployment of RL agents in diverse and dynamic environments.",
      "intriguing_abstract": "Designing effective reward functions for Reinforcement Learning remains a formidable challenge, often leading to mis-specification and hindering real-world deployment. While Inverse Reinforcement Learning (IRL) offers a path to learn rewards from demonstrations, existing methods are notoriously data-inefficient and struggle with heterogeneous, unstructured multi-task datasets. We introduce Probabilistic Embeddings for Meta-Inverse Reinforcement Learning (PEMIRL), a novel deep latent variable model that revolutionizes reward inference.\n\nPEMIRL uniquely enables unsupervised learning of robust reward functions from diverse, unlabeled demonstrations, overcoming the need for explicit task groupings. Crucially, it achieves few-shot reward inference for new, structurally similar tasks, often from a single demonstration. Our framework integrates context-based meta-learning with maximum entropy IRL, leveraging mutual information regularization to ensure the learned reward effectively utilizes inferred latent task contexts. This significantly enhances data efficiency and transferability, making IRL practical for complex continuous control domains. PEMIRL paves the way for generalizable reward learning, drastically reducing the burden of reward engineering and accelerating the deployment of adaptable RL agents in dynamic, real-world environments.",
      "keywords": [
        "Probabilistic Embeddings for Meta-IRL (PEMIRL)",
        "Inverse Reinforcement Learning",
        "Meta-learning",
        "Few-shot reward inference",
        "Unsupervised learning from unstructured demonstrations",
        "Deep latent variable models",
        "Mutual information regularization",
        "Maximum Entropy IRL",
        "Adversarial IRL",
        "Continuous control tasks",
        "Data efficiency",
        "Heterogeneous multi-task demonstrations",
        "Generalizable reward learning",
        "Sampling-based gradient estimators"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/13b00c6c8e6fd35a540b08904824aff0d6b66897.pdf",
      "citation_key": "yu2019o41",
      "metadata": {
        "title": "Meta-Inverse Reinforcement Learning with Probabilistic Context Variables",
        "authors": [
          "Lantao Yu",
          "Tianhe Yu",
          "Chelsea Finn",
          "Stefano Ermon"
        ],
        "published_date": "2019",
        "abstract": "Reinforcement learning demands a reward function, which is often difficult to provide or design in real world applications. While inverse reinforcement learning (IRL) holds promise for automatically learning reward functions from demonstrations, several major challenges remain. First, existing IRL methods learn reward functions from scratch, requiring large numbers of demonstrations to correctly infer the reward for each task the agent may need to perform. Second, and more subtly, existing methods typically assume demonstrations for one, isolated behavior or task, while in practice, it is significantly more natural and scalable to provide datasets of heterogeneous behaviors. To this end, we propose a deep latent variable model that is capable of learning rewards from unstructured, multi-task demonstration data, and critically, use this experience to infer robust rewards for new, structurally-similar tasks from a single demonstration. Our experiments on multiple continuous control tasks demonstrate the effectiveness of our approach compared to state-of-the-art imitation and inverse reinforcement learning methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/13b00c6c8e6fd35a540b08904824aff0d6b66897.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 75,
        "score": 12.5,
        "summary": "Here's a focused summary of the technical paper \\cite{yu2019o41} for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenges of Inverse Reinforcement Learning (IRL) in real-world applications:\n        1.  Existing IRL methods are data-inefficient, requiring large numbers of demonstrations to infer a reward function for each task from scratch.\n        2.  They typically assume homogeneous demonstrations for a single behavior or task, whereas real-world datasets are often heterogeneous but related.\n    *   **Importance and Challenge**: Manually designing reward functions for Reinforcement Learning (RL) is difficult, time-consuming, and prone to mis-specification, which can hamper learning. While IRL offers a solution by learning rewards from demonstrations, its data inefficiency and inability to handle diverse, unstructured demonstrations limit its practical applicability. Meta-learning holds promise for rapid adaptation, but prior Meta-IRL approaches were restricted to tabular MDPs or required pre-defined task distributions, which are hard to obtain in practice.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: \\cite{yu2019o41} builds upon Maximum Entropy Inverse Reinforcement Learning (MaxEnt IRL) and its adversarial approximation (AIRL), as well as context-based meta-learning and deep latent variable generative models.\n    *   **Limitations of Previous Solutions**:\n        *   **Single-task IRL**: Data-inefficient, learns rewards from scratch for each task, and assumes homogeneous demonstrations.\n        *   **Imitation Learning**: Lacks the ability to transfer learned policies to new environments with changed dynamics, as it doesn't recover a transferable reward function.\n        *   **Prior Meta-IRL approaches** \\cite{xu2018meta, gleave2019meta}: Limited to discrete tabular MDPs or required explicit task distributions and grouped demonstrations, making them less applicable to complex, unstructured real-world data.\n        *   **One-shot imitation learning**: Often requires paired demonstrations from each task, which can be restrictive.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: \\cite{yu2019o41} proposes Probabilistic Embeddings for Meta-Inverse Reinforcement Learning (PEMIRL), a deep latent variable model. It integrates context-based meta-learning, deep latent variable generative models, and maximum entropy inverse RL into a unified graphical model.\n    *   **Novelty/Difference**:\n        *   **Unsupervised Learning from Unstructured Data**: PEMIRL can learn robust reward functions from demonstrations of *distinct but related tasks in an unsupervised way*, without requiring specified task groupings or labels for each demonstration.\n        *   **Few-Shot Reward Inference**: It can infer rewards for *new, structurally-similar tasks from a single demonstration*, significantly improving data efficiency compared to traditional IRL.\n        *   **Mutual Information Regularization**: A key innovation is the use of mutual information regularization between the probabilistic context variable `m` and the trajectories `τ` to ensure the learned reward function `f(s,a,m)` effectively utilizes the inferred context, preventing the model from ignoring `m`.\n        *   **Sampling-Based Tractability**: It leverages an augmented adversarial IRL framework (with a context-conditional adaptive sampler `π_φ(a|s;m)` and discriminator `D_θ(s,a;m)`) and a generative process to achieve tractability for optimizing the mutual information objective.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: The PEMIRL framework itself, which is a novel combination of MaxEnt IRL, context-based meta-learning, and deep latent variable models for few-shot reward inference from unstructured multi-task demonstrations.\n    *   **Specific Techniques**:\n        *   Formulation of Meta-IRL as a constrained optimization problem, aiming to match conditional and posterior distributions of trajectories and context variables.\n        *   Introduction of a mutual information term `I_p(m; τ)` in the objective to establish a strong connection between the reward function and the latent context variable `m`.\n        *   Derivation of sampling-based gradient estimators for the mutual information term, relying on the optimality of the adaptive sampler in the adversarial framework (Lemma 1 and Lemma 2).\n        *   A generative process `τ ~ p_E(τ); m ~ q_φ(m|τ)` to synthesize latent context variables, approximating the prior task distribution when the model is trained.\n    *   **System Design**: A unified graphical model that bridges few-shot reward inference and learning from unstructured, heterogeneous demonstrations.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: \\cite{yu2019o41} evaluated PEMIRL on multiple continuous control tasks.\n    *   **Key Performance Metrics and Comparison Results**: The experiments demonstrated the effectiveness and scalability of PEMIRL compared to state-of-the-art imitation and inverse reinforcement learning methods. The tasks included:\n        *   Point-Maze\n        *   Ant\n        *   Sweeper\n        *   Sawyer Pusher\n        (While the abstract claims effectiveness and scalability, the provided text does not detail specific numerical metrics or direct comparison results, only the types of tasks used.)\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Assumes that the state space, action space, initial state distribution, and transition dynamics are independent of the context variable `m`.\n        *   Relies on the assumption that the adaptive sampler in the adversarial framework is trained to optimality for unbiased gradient estimation.\n    *   **Scope of Applicability**: PEMIRL is designed for complex domains with continuous state-action spaces and for learning rewards for *structurally-similar* tasks. It operates without prior knowledge of the task distribution `p(m)`, the latent context variable `m` for each demonstration, or the environment's transition dynamics during meta-training.\n\n*   **7. Technical Significance**\n    *   **Advance State-of-the-Art**: \\cite{yu2019o41} significantly advances the technical state-of-the-art by:\n        *   Overcoming the data inefficiency of traditional IRL by enabling few-shot reward inference.\n        *   Addressing the limitation of prior Meta-IRL methods by learning from unstructured, heterogeneous multi-task demonstrations in continuous control settings.\n        *   Providing a robust framework for disentangling reward functions from environment dynamics, making them more transferable.\n    *   **Potential Impact on Future Research**: This work opens new avenues for applying IRL in real-world scenarios where collecting large, perfectly labeled, and homogeneous demonstration datasets is impractical. It paves the way for more generalizable and adaptable reward learning systems, reducing the burden of reward engineering and facilitating the deployment of RL agents in diverse and dynamic environments.",
        "keywords": [
          "Probabilistic Embeddings for Meta-IRL (PEMIRL)",
          "Inverse Reinforcement Learning",
          "Meta-learning",
          "Few-shot reward inference",
          "Unsupervised learning from unstructured demonstrations",
          "Deep latent variable models",
          "Mutual information regularization",
          "Maximum Entropy IRL",
          "Adversarial IRL",
          "Continuous control tasks",
          "Data efficiency",
          "Heterogeneous multi-task demonstrations",
          "Generalizable reward learning",
          "Sampling-based gradient estimators"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** a deep latent variable model\" and describes its capabilities (\"our model can infer rewards for new... tasks\"). this directly aligns with the \"technical\" criterion: \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\".\n*   the introduction discusses a \"technical problem\" (reward specification in rl and limitations of existing irl methods) and sets the stage for the \"proposed solution\" (the model mentioned in the abstract).\n*   the abstract also mentions \"our experiments... demonstrate the effectiveness of our approach,\" indicating an empirical evaluation of the proposed technical method. however, the primary contribution is the *new method* itself, which is then validated empirically.\n\ntherefore, the paper's primary classification is **technical**."
      },
      "file_name": "13b00c6c8e6fd35a540b08904824aff0d6b66897.pdf"
    },
    {
      "success": true,
      "doc_id": "8f40917e1cb276a37a29fe731f175832",
      "summary": "We derive a novel information-theoretic analysis of the generalization property of meta-learning algorithms. Concretely, our analysis proposes a generic understanding of both the conventional learning-to-learn framework and the modern model-agnostic meta-learning (MAML) algorithms. Moreover, we provide a data-dependent generalization bound for a stochastic variant of MAML, which is non-vacuous for deep few-shot learning. As compared to previous bounds that depend on the square norm of gradients, empirical validations on both simulated data and a well-known few-shot benchmark show that our bound is orders of magnitude tighter in most situations.",
      "intriguing_abstract": "We derive a novel information-theoretic analysis of the generalization property of meta-learning algorithms. Concretely, our analysis proposes a generic understanding of both the conventional learning-to-learn framework and the modern model-agnostic meta-learning (MAML) algorithms. Moreover, we provide a data-dependent generalization bound for a stochastic variant of MAML, which is non-vacuous for deep few-shot learning. As compared to previous bounds that depend on the square norm of gradients, empirical validations on both simulated data and a well-known few-shot benchmark show that our bound is orders of magnitude tighter in most situations.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b49f0998b4f8e356a8e3f4313917585cb6a33f57.pdf",
      "citation_key": "chen2021j5t",
      "metadata": {
        "title": "Generalization Bounds For Meta-Learning: An Information-Theoretic Analysis",
        "authors": [
          "Qi Chen",
          "Changjian Shui",
          "M. Marchand"
        ],
        "published_date": "2021",
        "abstract": "We derive a novel information-theoretic analysis of the generalization property of meta-learning algorithms. Concretely, our analysis proposes a generic understanding of both the conventional learning-to-learn framework and the modern model-agnostic meta-learning (MAML) algorithms. Moreover, we provide a data-dependent generalization bound for a stochastic variant of MAML, which is non-vacuous for deep few-shot learning. As compared to previous bounds that depend on the square norm of gradients, empirical validations on both simulated data and a well-known few-shot benchmark show that our bound is orders of magnitude tighter in most situations.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b49f0998b4f8e356a8e3f4313917585cb6a33f57.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 49,
        "score": 12.25,
        "summary": "We derive a novel information-theoretic analysis of the generalization property of meta-learning algorithms. Concretely, our analysis proposes a generic understanding of both the conventional learning-to-learn framework and the modern model-agnostic meta-learning (MAML) algorithms. Moreover, we provide a data-dependent generalization bound for a stochastic variant of MAML, which is non-vacuous for deep few-shot learning. As compared to previous bounds that depend on the square norm of gradients, empirical validations on both simulated data and a well-known few-shot benchmark show that our bound is orders of magnitude tighter in most situations.",
        "keywords": []
      },
      "file_name": "b49f0998b4f8e356a8e3f4313917585cb6a33f57.pdf"
    },
    {
      "success": true,
      "doc_id": "65a95cb38abbb14526b5509a13f252c5",
      "summary": "Agents that interact with other agents often do not know a priori what the other agents' strategies are, but have to maximise their own online return while interacting with and learning about others. The optimal adaptive behaviour under uncertainty over the other agents' strategies w.r.t. some prior can in principle be computed using the Interactive Bayesian Reinforcement Learning framework. Unfortunately, doing so is intractable in most settings, and existing approximation methods are restricted to small tasks. To overcome this, we propose to meta-learn approximate belief inference and Bayes-optimal behaviour for a given prior. To model beliefs over other agents, we combine sequential and hierarchical Variational Auto-Encoders, and meta-train this inference model alongside the policy. We show empirically that our approach outperforms existing methods that use a model-free approach, sample from the approximate posterior, maintain memory-free models of others, or do not fully utilise the known structure of the environment.",
      "intriguing_abstract": "Agents that interact with other agents often do not know a priori what the other agents' strategies are, but have to maximise their own online return while interacting with and learning about others. The optimal adaptive behaviour under uncertainty over the other agents' strategies w.r.t. some prior can in principle be computed using the Interactive Bayesian Reinforcement Learning framework. Unfortunately, doing so is intractable in most settings, and existing approximation methods are restricted to small tasks. To overcome this, we propose to meta-learn approximate belief inference and Bayes-optimal behaviour for a given prior. To model beliefs over other agents, we combine sequential and hierarchical Variational Auto-Encoders, and meta-train this inference model alongside the policy. We show empirically that our approach outperforms existing methods that use a model-free approach, sample from the approximate posterior, maintain memory-free models of others, or do not fully utilise the known structure of the environment.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/754878242a3b480b2ca9031bff623f2c557f2caa.pdf",
      "citation_key": "zintgraf2021hoc",
      "metadata": {
        "title": "Deep Interactive Bayesian Reinforcement Learning via Meta-Learning",
        "authors": [
          "Luisa M. Zintgraf",
          "Sam Devlin",
          "K. Ciosek",
          "S. Whiteson",
          "Katja Hofmann"
        ],
        "published_date": "2021",
        "abstract": "Agents that interact with other agents often do not know a priori what the other agents' strategies are, but have to maximise their own online return while interacting with and learning about others. The optimal adaptive behaviour under uncertainty over the other agents' strategies w.r.t. some prior can in principle be computed using the Interactive Bayesian Reinforcement Learning framework. Unfortunately, doing so is intractable in most settings, and existing approximation methods are restricted to small tasks. To overcome this, we propose to meta-learn approximate belief inference and Bayes-optimal behaviour for a given prior. To model beliefs over other agents, we combine sequential and hierarchical Variational Auto-Encoders, and meta-train this inference model alongside the policy. We show empirically that our approach outperforms existing methods that use a model-free approach, sample from the approximate posterior, maintain memory-free models of others, or do not fully utilise the known structure of the environment.",
        "file_path": "paper_data/Deep_Meta-Learning/info/754878242a3b480b2ca9031bff623f2c557f2caa.pdf",
        "venue": "Adaptive Agents and Multi-Agent Systems",
        "citationCount": 48,
        "score": 12.0,
        "summary": "Agents that interact with other agents often do not know a priori what the other agents' strategies are, but have to maximise their own online return while interacting with and learning about others. The optimal adaptive behaviour under uncertainty over the other agents' strategies w.r.t. some prior can in principle be computed using the Interactive Bayesian Reinforcement Learning framework. Unfortunately, doing so is intractable in most settings, and existing approximation methods are restricted to small tasks. To overcome this, we propose to meta-learn approximate belief inference and Bayes-optimal behaviour for a given prior. To model beliefs over other agents, we combine sequential and hierarchical Variational Auto-Encoders, and meta-train this inference model alongside the policy. We show empirically that our approach outperforms existing methods that use a model-free approach, sample from the approximate posterior, maintain memory-free models of others, or do not fully utilise the known structure of the environment.",
        "keywords": []
      },
      "file_name": "754878242a3b480b2ca9031bff623f2c557f2caa.pdf"
    },
    {
      "success": true,
      "doc_id": "8df9c6e24e6e523e66b616aba19ccd63",
      "summary": "In recent years, data-driven methods have been developed to learn dynamical systems and partial differential equations (PDE). The goal of such work is discovering unknown physics and the corresponding equations. However, prior to achieving this goal, major challenges remain to be resolved, including learning PDE under noisy data and limited discrete data. To overcome these challenges, in this work, a deep-learning based data-driven method, called DL-PDE, is developed to discover the governing PDEs of underlying physical processes. The DL-PDE method combines deep learning via neural networks and data-driven discovery of PDE via sparse regressions. In the DL-PDE, a neural network is first trained, and then a large amount of meta-data is generated, and the required derivatives are calculated by automatic differentiation. Finally, the form of PDE is discovered by sparse regression. The proposed method is tested with physical processes, governed by groundwater flow equation, convection-diffusion equation, Burgers equation and Korteweg-de Vries (KdV) equation, for proof-of-concept and applications in real-world engineering settings. The proposed method achieves satisfactory results when data are noisy and limited.",
      "intriguing_abstract": "In recent years, data-driven methods have been developed to learn dynamical systems and partial differential equations (PDE). The goal of such work is discovering unknown physics and the corresponding equations. However, prior to achieving this goal, major challenges remain to be resolved, including learning PDE under noisy data and limited discrete data. To overcome these challenges, in this work, a deep-learning based data-driven method, called DL-PDE, is developed to discover the governing PDEs of underlying physical processes. The DL-PDE method combines deep learning via neural networks and data-driven discovery of PDE via sparse regressions. In the DL-PDE, a neural network is first trained, and then a large amount of meta-data is generated, and the required derivatives are calculated by automatic differentiation. Finally, the form of PDE is discovered by sparse regression. The proposed method is tested with physical processes, governed by groundwater flow equation, convection-diffusion equation, Burgers equation and Korteweg-de Vries (KdV) equation, for proof-of-concept and applications in real-world engineering settings. The proposed method achieves satisfactory results when data are noisy and limited.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/64a85b9e330315364739766bf170c11b4889dc68.pdf",
      "citation_key": "xu20199h0",
      "metadata": {
        "title": "DL-PDE: Deep-learning based data-driven discovery of partial differential equations from discrete and noisy data",
        "authors": [
          "Hao Xu",
          "Haibin Chang",
          "Dongxiao Zhang"
        ],
        "published_date": "2019",
        "abstract": "In recent years, data-driven methods have been developed to learn dynamical systems and partial differential equations (PDE). The goal of such work is discovering unknown physics and the corresponding equations. However, prior to achieving this goal, major challenges remain to be resolved, including learning PDE under noisy data and limited discrete data. To overcome these challenges, in this work, a deep-learning based data-driven method, called DL-PDE, is developed to discover the governing PDEs of underlying physical processes. The DL-PDE method combines deep learning via neural networks and data-driven discovery of PDE via sparse regressions. In the DL-PDE, a neural network is first trained, and then a large amount of meta-data is generated, and the required derivatives are calculated by automatic differentiation. Finally, the form of PDE is discovered by sparse regression. The proposed method is tested with physical processes, governed by groundwater flow equation, convection-diffusion equation, Burgers equation and Korteweg-de Vries (KdV) equation, for proof-of-concept and applications in real-world engineering settings. The proposed method achieves satisfactory results when data are noisy and limited.",
        "file_path": "paper_data/Deep_Meta-Learning/info/64a85b9e330315364739766bf170c11b4889dc68.pdf",
        "venue": "Communications in Computational Physics",
        "citationCount": 71,
        "score": 11.833333333333332,
        "summary": "In recent years, data-driven methods have been developed to learn dynamical systems and partial differential equations (PDE). The goal of such work is discovering unknown physics and the corresponding equations. However, prior to achieving this goal, major challenges remain to be resolved, including learning PDE under noisy data and limited discrete data. To overcome these challenges, in this work, a deep-learning based data-driven method, called DL-PDE, is developed to discover the governing PDEs of underlying physical processes. The DL-PDE method combines deep learning via neural networks and data-driven discovery of PDE via sparse regressions. In the DL-PDE, a neural network is first trained, and then a large amount of meta-data is generated, and the required derivatives are calculated by automatic differentiation. Finally, the form of PDE is discovered by sparse regression. The proposed method is tested with physical processes, governed by groundwater flow equation, convection-diffusion equation, Burgers equation and Korteweg-de Vries (KdV) equation, for proof-of-concept and applications in real-world engineering settings. The proposed method achieves satisfactory results when data are noisy and limited.",
        "keywords": []
      },
      "file_name": "64a85b9e330315364739766bf170c11b4889dc68.pdf"
    },
    {
      "success": true,
      "doc_id": "7f1c04cc30dbe7791150cd687d6f8f02",
      "summary": "Inspired by the extensive success of deep learning, graph neural networks (GNNs) have been proposed to learn expressive node representations and demonstrated promising performance in various graph learning tasks. However, existing endeavors predominately focus on the conventional semi-supervised setting where relatively abundant gold-labeled nodes are provided. While it is often impractical due to the fact that data labeling is unbearably laborious and requires intensive domain knowledge, especially when considering the heterogeneity of graph-structured data. Under the few-shot semi-supervised setting, the performance of most of the existing GNNs is inevitably undermined by the overfitting and oversmoothing issues, largely owing to the shortage of labeled data. In this paper, we propose a decoupled network architecture equipped with a novel meta-learning algorithm to solve this problem. In essence, our framework Meta-PN infers high-quality pseudo labels on unlabeled nodes via a meta-learned label propagation strategy, which effectively augments the scarce labeled data while enabling large receptive fields during training. Extensive experiments demonstrate that our approach offers easy and substantial performance gains compared to existing techniques on various benchmark datasets. The implementation and extended manuscript of this work are publicly available at https://github.com/kaize0409/Meta-PN.",
      "intriguing_abstract": "Inspired by the extensive success of deep learning, graph neural networks (GNNs) have been proposed to learn expressive node representations and demonstrated promising performance in various graph learning tasks. However, existing endeavors predominately focus on the conventional semi-supervised setting where relatively abundant gold-labeled nodes are provided. While it is often impractical due to the fact that data labeling is unbearably laborious and requires intensive domain knowledge, especially when considering the heterogeneity of graph-structured data. Under the few-shot semi-supervised setting, the performance of most of the existing GNNs is inevitably undermined by the overfitting and oversmoothing issues, largely owing to the shortage of labeled data. In this paper, we propose a decoupled network architecture equipped with a novel meta-learning algorithm to solve this problem. In essence, our framework Meta-PN infers high-quality pseudo labels on unlabeled nodes via a meta-learned label propagation strategy, which effectively augments the scarce labeled data while enabling large receptive fields during training. Extensive experiments demonstrate that our approach offers easy and substantial performance gains compared to existing techniques on various benchmark datasets. The implementation and extended manuscript of this work are publicly available at https://github.com/kaize0409/Meta-PN.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/f10a78ca84de4c255095ff44c5281c2e70f6385c.pdf",
      "citation_key": "ding2021284",
      "metadata": {
        "title": "Meta Propagation Networks for Graph Few-shot Semi-supervised Learning",
        "authors": [
          "Kaize Ding",
          "Jianling Wang",
          "James Caverlee",
          "Huan Liu"
        ],
        "published_date": "2021",
        "abstract": "Inspired by the extensive success of deep learning, graph neural networks (GNNs) have been proposed to learn expressive node representations and demonstrated promising performance in various graph learning tasks. However, existing endeavors predominately focus on the conventional semi-supervised setting where relatively abundant gold-labeled nodes are provided. While it is often impractical due to the fact that data labeling is unbearably laborious and requires intensive domain knowledge, especially when considering the heterogeneity of graph-structured data. Under the few-shot semi-supervised setting, the performance of most of the existing GNNs is inevitably undermined by the overfitting and oversmoothing issues, largely owing to the shortage of labeled data. In this paper, we propose a decoupled network architecture equipped with a novel meta-learning algorithm to solve this problem. In essence, our framework Meta-PN infers high-quality pseudo labels on unlabeled nodes via a meta-learned label propagation strategy, which effectively augments the scarce labeled data while enabling large receptive fields during training. Extensive experiments demonstrate that our approach offers easy and substantial performance gains compared to existing techniques on various benchmark datasets. The implementation and extended manuscript of this work are publicly available at https://github.com/kaize0409/Meta-PN.",
        "file_path": "paper_data/Deep_Meta-Learning/info/f10a78ca84de4c255095ff44c5281c2e70f6385c.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 45,
        "score": 11.25,
        "summary": "Inspired by the extensive success of deep learning, graph neural networks (GNNs) have been proposed to learn expressive node representations and demonstrated promising performance in various graph learning tasks. However, existing endeavors predominately focus on the conventional semi-supervised setting where relatively abundant gold-labeled nodes are provided. While it is often impractical due to the fact that data labeling is unbearably laborious and requires intensive domain knowledge, especially when considering the heterogeneity of graph-structured data. Under the few-shot semi-supervised setting, the performance of most of the existing GNNs is inevitably undermined by the overfitting and oversmoothing issues, largely owing to the shortage of labeled data. In this paper, we propose a decoupled network architecture equipped with a novel meta-learning algorithm to solve this problem. In essence, our framework Meta-PN infers high-quality pseudo labels on unlabeled nodes via a meta-learned label propagation strategy, which effectively augments the scarce labeled data while enabling large receptive fields during training. Extensive experiments demonstrate that our approach offers easy and substantial performance gains compared to existing techniques on various benchmark datasets. The implementation and extended manuscript of this work are publicly available at https://github.com/kaize0409/Meta-PN.",
        "keywords": []
      },
      "file_name": "f10a78ca84de4c255095ff44c5281c2e70f6385c.pdf"
    },
    {
      "success": true,
      "doc_id": "313bfd095342434d612b9a93bdda58d5",
      "summary": "Deep autoregressive models have shown state-of-the-art performance in density estimation for natural images on large-scale datasets such as ImageNet. However, such models require many thousands of gradient-based weight updates and unique image examples for training. Ideally, the models would rapidly learn visual concepts from only a handful of examples, similar to the manner in which humans learns across many vision tasks. In this paper, we show how 1) neural attention and 2) meta learning techniques can be used in combination with autoregressive models to enable effective few-shot density estimation. Our proposed modifications to PixelCNN result in state-of-the art few-shot density estimation on the Omniglot dataset. Furthermore, we visualize the learned attention policy and find that it learns intuitive algorithms for simple tasks such as image mirroring on ImageNet and handwriting on Omniglot without supervision. Finally, we extend the model to natural images and demonstrate few-shot image generation on the Stanford Online Products dataset.",
      "intriguing_abstract": "Deep autoregressive models have shown state-of-the-art performance in density estimation for natural images on large-scale datasets such as ImageNet. However, such models require many thousands of gradient-based weight updates and unique image examples for training. Ideally, the models would rapidly learn visual concepts from only a handful of examples, similar to the manner in which humans learns across many vision tasks. In this paper, we show how 1) neural attention and 2) meta learning techniques can be used in combination with autoregressive models to enable effective few-shot density estimation. Our proposed modifications to PixelCNN result in state-of-the art few-shot density estimation on the Omniglot dataset. Furthermore, we visualize the learned attention policy and find that it learns intuitive algorithms for simple tasks such as image mirroring on ImageNet and handwriting on Omniglot without supervision. Finally, we extend the model to natural images and demonstrate few-shot image generation on the Stanford Online Products dataset.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/bbe13b72314fffcc2f35b0660195f2f6607c00a0.pdf",
      "citation_key": "reed2017sxd",
      "metadata": {
        "title": "Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions",
        "authors": [
          "Scott E. Reed",
          "Yutian Chen",
          "T. Paine",
          "Aäron van den Oord",
          "S. Eslami",
          "Danilo Jimenez Rezende",
          "O. Vinyals",
          "Nando de Freitas"
        ],
        "published_date": "2017",
        "abstract": "Deep autoregressive models have shown state-of-the-art performance in density estimation for natural images on large-scale datasets such as ImageNet. However, such models require many thousands of gradient-based weight updates and unique image examples for training. Ideally, the models would rapidly learn visual concepts from only a handful of examples, similar to the manner in which humans learns across many vision tasks. In this paper, we show how 1) neural attention and 2) meta learning techniques can be used in combination with autoregressive models to enable effective few-shot density estimation. Our proposed modifications to PixelCNN result in state-of-the art few-shot density estimation on the Omniglot dataset. Furthermore, we visualize the learned attention policy and find that it learns intuitive algorithms for simple tasks such as image mirroring on ImageNet and handwriting on Omniglot without supervision. Finally, we extend the model to natural images and demonstrate few-shot image generation on the Stanford Online Products dataset.",
        "file_path": "paper_data/Deep_Meta-Learning/info/bbe13b72314fffcc2f35b0660195f2f6607c00a0.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 88,
        "score": 11.0,
        "summary": "Deep autoregressive models have shown state-of-the-art performance in density estimation for natural images on large-scale datasets such as ImageNet. However, such models require many thousands of gradient-based weight updates and unique image examples for training. Ideally, the models would rapidly learn visual concepts from only a handful of examples, similar to the manner in which humans learns across many vision tasks. In this paper, we show how 1) neural attention and 2) meta learning techniques can be used in combination with autoregressive models to enable effective few-shot density estimation. Our proposed modifications to PixelCNN result in state-of-the art few-shot density estimation on the Omniglot dataset. Furthermore, we visualize the learned attention policy and find that it learns intuitive algorithms for simple tasks such as image mirroring on ImageNet and handwriting on Omniglot without supervision. Finally, we extend the model to natural images and demonstrate few-shot image generation on the Stanford Online Products dataset.",
        "keywords": []
      },
      "file_name": "bbe13b72314fffcc2f35b0660195f2f6607c00a0.pdf"
    },
    {
      "success": true,
      "doc_id": "02a8a79014581a9c51296e16bc907edf",
      "summary": "Palmprint is one of the discriminant biometric modalities of humans. Recently, deep learning-based palmprint recognition algorithms have improved the accuracy and robustness of recognition results to a new level. Most of them require a large amount of labeled training samples to guarantee satisfactory performance. However, getting enough labeled data is difficult due to time consumption and privacy issues. Therefore, in this article, a novel meta-Siamese network (MSN) is proposed to exploit few-shot learning for small-sample palmprint recognition. During each episode-based training iteration, a few images are selected as sample and query sets to simulate the support and testing sets in the test set. Specifically, the model is trained episodically with a flexible framework to learn both the feature embedding and deep similarity metric function. In addition, two distance-based losses are introduced to assist the optimization. After training, the model can learn the ability to get similarity scores between two images for few-shot testing. Adequate experiments conducted on several constrained and unconstrained benchmark palmprint databases show that MSN can obtain competitive improvements compared with baseline methods, where the best accuracy can be up to 100%.",
      "intriguing_abstract": "Palmprint is one of the discriminant biometric modalities of humans. Recently, deep learning-based palmprint recognition algorithms have improved the accuracy and robustness of recognition results to a new level. Most of them require a large amount of labeled training samples to guarantee satisfactory performance. However, getting enough labeled data is difficult due to time consumption and privacy issues. Therefore, in this article, a novel meta-Siamese network (MSN) is proposed to exploit few-shot learning for small-sample palmprint recognition. During each episode-based training iteration, a few images are selected as sample and query sets to simulate the support and testing sets in the test set. Specifically, the model is trained episodically with a flexible framework to learn both the feature embedding and deep similarity metric function. In addition, two distance-based losses are introduced to assist the optimization. After training, the model can learn the ability to get similarity scores between two images for few-shot testing. Adequate experiments conducted on several constrained and unconstrained benchmark palmprint databases show that MSN can obtain competitive improvements compared with baseline methods, where the best accuracy can be up to 100%.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/6bf147de5839aae8abb201afbd1c84c64eb9ce99.pdf",
      "citation_key": "shao2021loj",
      "metadata": {
        "title": "Few-Shot Learning for Palmprint Recognition via Meta-Siamese Network",
        "authors": [
          "Huikai Shao",
          "Dexing Zhong",
          "Xuefeng Du",
          "S. Du",
          "R. Veldhuis"
        ],
        "published_date": "2021",
        "abstract": "Palmprint is one of the discriminant biometric modalities of humans. Recently, deep learning-based palmprint recognition algorithms have improved the accuracy and robustness of recognition results to a new level. Most of them require a large amount of labeled training samples to guarantee satisfactory performance. However, getting enough labeled data is difficult due to time consumption and privacy issues. Therefore, in this article, a novel meta-Siamese network (MSN) is proposed to exploit few-shot learning for small-sample palmprint recognition. During each episode-based training iteration, a few images are selected as sample and query sets to simulate the support and testing sets in the test set. Specifically, the model is trained episodically with a flexible framework to learn both the feature embedding and deep similarity metric function. In addition, two distance-based losses are introduced to assist the optimization. After training, the model can learn the ability to get similarity scores between two images for few-shot testing. Adequate experiments conducted on several constrained and unconstrained benchmark palmprint databases show that MSN can obtain competitive improvements compared with baseline methods, where the best accuracy can be up to 100%.",
        "file_path": "paper_data/Deep_Meta-Learning/info/6bf147de5839aae8abb201afbd1c84c64eb9ce99.pdf",
        "venue": "IEEE Transactions on Instrumentation and Measurement",
        "citationCount": 44,
        "score": 11.0,
        "summary": "Palmprint is one of the discriminant biometric modalities of humans. Recently, deep learning-based palmprint recognition algorithms have improved the accuracy and robustness of recognition results to a new level. Most of them require a large amount of labeled training samples to guarantee satisfactory performance. However, getting enough labeled data is difficult due to time consumption and privacy issues. Therefore, in this article, a novel meta-Siamese network (MSN) is proposed to exploit few-shot learning for small-sample palmprint recognition. During each episode-based training iteration, a few images are selected as sample and query sets to simulate the support and testing sets in the test set. Specifically, the model is trained episodically with a flexible framework to learn both the feature embedding and deep similarity metric function. In addition, two distance-based losses are introduced to assist the optimization. After training, the model can learn the ability to get similarity scores between two images for few-shot testing. Adequate experiments conducted on several constrained and unconstrained benchmark palmprint databases show that MSN can obtain competitive improvements compared with baseline methods, where the best accuracy can be up to 100%.",
        "keywords": []
      },
      "file_name": "6bf147de5839aae8abb201afbd1c84c64eb9ce99.pdf"
    },
    {
      "success": true,
      "doc_id": "001273cfec49587e86b3e9159688e4ab",
      "summary": "Meta-learning, or learning to learn, is a machine learning approach that utilizes prior learning experiences to expedite the learning process on unseen tasks. As a data-driven approach, meta-learning requires meta-features that represent the primary learning tasks or datasets, and are estimated traditonally as engineered dataset statistics that require expert domain knowledge tailored for every meta-task. In this paper, first, we propose a meta-feature extractor called Dataset2Vec that combines the versatility of engineered dataset meta-features with the expressivity of meta-features learned by deep neural networks. Primary learning tasks or datasets are represented as hierarchical sets, i.e., as a set of sets, esp. as a set of predictor/target pairs, and then a DeepSet architecture is employed to regress meta-features on them. Second, we propose a novel auxiliary meta-learning task with abundant data called dataset similarity learning that aims to predict if two batches stem from the same dataset or different ones. In an experiment on a large-scale hyperparameter optimization task for 120 UCI datasets with varying schemas as a meta-learning task, we show that the meta-features of Dataset2Vec outperform the expert engineered meta-features and thus demonstrate the usefulness of learned meta-features for datasets with varying schemas for the first time.",
      "intriguing_abstract": "Meta-learning, or learning to learn, is a machine learning approach that utilizes prior learning experiences to expedite the learning process on unseen tasks. As a data-driven approach, meta-learning requires meta-features that represent the primary learning tasks or datasets, and are estimated traditonally as engineered dataset statistics that require expert domain knowledge tailored for every meta-task. In this paper, first, we propose a meta-feature extractor called Dataset2Vec that combines the versatility of engineered dataset meta-features with the expressivity of meta-features learned by deep neural networks. Primary learning tasks or datasets are represented as hierarchical sets, i.e., as a set of sets, esp. as a set of predictor/target pairs, and then a DeepSet architecture is employed to regress meta-features on them. Second, we propose a novel auxiliary meta-learning task with abundant data called dataset similarity learning that aims to predict if two batches stem from the same dataset or different ones. In an experiment on a large-scale hyperparameter optimization task for 120 UCI datasets with varying schemas as a meta-learning task, we show that the meta-features of Dataset2Vec outperform the expert engineered meta-features and thus demonstrate the usefulness of learned meta-features for datasets with varying schemas for the first time.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/f068074f6ad44fcd512cb15ec2510bbba373f405.pdf",
      "citation_key": "jomaa20190ul",
      "metadata": {
        "title": "Dataset2Vec: learning dataset meta-features",
        "authors": [
          "H. Jomaa",
          "Josif Grabocka",
          "L. Schmidt-Thieme"
        ],
        "published_date": "2019",
        "abstract": "Meta-learning, or learning to learn, is a machine learning approach that utilizes prior learning experiences to expedite the learning process on unseen tasks. As a data-driven approach, meta-learning requires meta-features that represent the primary learning tasks or datasets, and are estimated traditonally as engineered dataset statistics that require expert domain knowledge tailored for every meta-task. In this paper, first, we propose a meta-feature extractor called Dataset2Vec that combines the versatility of engineered dataset meta-features with the expressivity of meta-features learned by deep neural networks. Primary learning tasks or datasets are represented as hierarchical sets, i.e., as a set of sets, esp. as a set of predictor/target pairs, and then a DeepSet architecture is employed to regress meta-features on them. Second, we propose a novel auxiliary meta-learning task with abundant data called dataset similarity learning that aims to predict if two batches stem from the same dataset or different ones. In an experiment on a large-scale hyperparameter optimization task for 120 UCI datasets with varying schemas as a meta-learning task, we show that the meta-features of Dataset2Vec outperform the expert engineered meta-features and thus demonstrate the usefulness of learned meta-features for datasets with varying schemas for the first time.",
        "file_path": "paper_data/Deep_Meta-Learning/info/f068074f6ad44fcd512cb15ec2510bbba373f405.pdf",
        "venue": "Data mining and knowledge discovery",
        "citationCount": 66,
        "score": 11.0,
        "summary": "Meta-learning, or learning to learn, is a machine learning approach that utilizes prior learning experiences to expedite the learning process on unseen tasks. As a data-driven approach, meta-learning requires meta-features that represent the primary learning tasks or datasets, and are estimated traditonally as engineered dataset statistics that require expert domain knowledge tailored for every meta-task. In this paper, first, we propose a meta-feature extractor called Dataset2Vec that combines the versatility of engineered dataset meta-features with the expressivity of meta-features learned by deep neural networks. Primary learning tasks or datasets are represented as hierarchical sets, i.e., as a set of sets, esp. as a set of predictor/target pairs, and then a DeepSet architecture is employed to regress meta-features on them. Second, we propose a novel auxiliary meta-learning task with abundant data called dataset similarity learning that aims to predict if two batches stem from the same dataset or different ones. In an experiment on a large-scale hyperparameter optimization task for 120 UCI datasets with varying schemas as a meta-learning task, we show that the meta-features of Dataset2Vec outperform the expert engineered meta-features and thus demonstrate the usefulness of learned meta-features for datasets with varying schemas for the first time.",
        "keywords": []
      },
      "file_name": "f068074f6ad44fcd512cb15ec2510bbba373f405.pdf"
    },
    {
      "success": true,
      "doc_id": "8303e7fdf6e0f7f09cb32f1d80b58a0c",
      "summary": "Deep learning has been actively applied to time series forecasting, leading to a deluge of new methods, belonging to the class of historical-value models. Yet, despite the attractive properties of time-index models, such as being able to model the continuous nature of underlying time series dynamics, little attention has been given to them. Indeed, while naive deep time-index models are far more expressive than the manually predefined function representations of classical time-index models, they are inadequate for forecasting, being unable to generalize to unseen time steps due to the lack of inductive bias. In this paper, we propose DeepTime, a meta-optimization framework to learn deep time-index models which overcome these limitations, yielding an efficient and accurate forecasting model. Extensive experiments on real world datasets in the long sequence time-series forecasting setting demonstrate that our approach achieves competitive results with state-of-the-art methods, and is highly efficient. Code is available at https://github.com/salesforce/DeepTime.",
      "intriguing_abstract": "Deep learning has been actively applied to time series forecasting, leading to a deluge of new methods, belonging to the class of historical-value models. Yet, despite the attractive properties of time-index models, such as being able to model the continuous nature of underlying time series dynamics, little attention has been given to them. Indeed, while naive deep time-index models are far more expressive than the manually predefined function representations of classical time-index models, they are inadequate for forecasting, being unable to generalize to unseen time steps due to the lack of inductive bias. In this paper, we propose DeepTime, a meta-optimization framework to learn deep time-index models which overcome these limitations, yielding an efficient and accurate forecasting model. Extensive experiments on real world datasets in the long sequence time-series forecasting setting demonstrate that our approach achieves competitive results with state-of-the-art methods, and is highly efficient. Code is available at https://github.com/salesforce/DeepTime.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/a9f1e05bb2f6f2eeaf92fe1fc5ca3f0eb498f673.pdf",
      "citation_key": "woo2022f3e",
      "metadata": {
        "title": "Learning Deep Time-index Models for Time Series Forecasting",
        "authors": [
          "Gerald Woo",
          "Chenghao Liu",
          "Doyen Sahoo",
          "Akshat Kumar",
          "S. Hoi"
        ],
        "published_date": "2022",
        "abstract": "Deep learning has been actively applied to time series forecasting, leading to a deluge of new methods, belonging to the class of historical-value models. Yet, despite the attractive properties of time-index models, such as being able to model the continuous nature of underlying time series dynamics, little attention has been given to them. Indeed, while naive deep time-index models are far more expressive than the manually predefined function representations of classical time-index models, they are inadequate for forecasting, being unable to generalize to unseen time steps due to the lack of inductive bias. In this paper, we propose DeepTime, a meta-optimization framework to learn deep time-index models which overcome these limitations, yielding an efficient and accurate forecasting model. Extensive experiments on real world datasets in the long sequence time-series forecasting setting demonstrate that our approach achieves competitive results with state-of-the-art methods, and is highly efficient. Code is available at https://github.com/salesforce/DeepTime.",
        "file_path": "paper_data/Deep_Meta-Learning/info/a9f1e05bb2f6f2eeaf92fe1fc5ca3f0eb498f673.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 32,
        "score": 10.666666666666666,
        "summary": "Deep learning has been actively applied to time series forecasting, leading to a deluge of new methods, belonging to the class of historical-value models. Yet, despite the attractive properties of time-index models, such as being able to model the continuous nature of underlying time series dynamics, little attention has been given to them. Indeed, while naive deep time-index models are far more expressive than the manually predefined function representations of classical time-index models, they are inadequate for forecasting, being unable to generalize to unseen time steps due to the lack of inductive bias. In this paper, we propose DeepTime, a meta-optimization framework to learn deep time-index models which overcome these limitations, yielding an efficient and accurate forecasting model. Extensive experiments on real world datasets in the long sequence time-series forecasting setting demonstrate that our approach achieves competitive results with state-of-the-art methods, and is highly efficient. Code is available at https://github.com/salesforce/DeepTime.",
        "keywords": []
      },
      "file_name": "a9f1e05bb2f6f2eeaf92fe1fc5ca3f0eb498f673.pdf"
    },
    {
      "success": true,
      "doc_id": "a9cdbc75829387c1453905309a6fd8b7",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/fa1aa587c53c293a88a31bd1ed3e9161c96f4e04.pdf",
      "citation_key": "park2020m5z",
      "metadata": {
        "title": "Meta Variance Transfer: Learning to Augment from the Others",
        "authors": [
          "Seongho Park",
          "S. Han",
          "Ji-Won Baek",
          "Insoo Kim",
          "Juhwan Song",
          "Haebeom Lee",
          "Jae-Joon Han",
          "Sung Ju Hwang"
        ],
        "published_date": "2020",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/fa1aa587c53c293a88a31bd1ed3e9161c96f4e04.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 51,
        "score": 10.200000000000001,
        "summary": "",
        "keywords": []
      },
      "file_name": "fa1aa587c53c293a88a31bd1ed3e9161c96f4e04.pdf"
    },
    {
      "success": true,
      "doc_id": "98b4d9f2769dbefa0d74d106bde3a96d",
      "summary": "In this paper, we present a deep meta metric learning (DMML) approach for visual recognition. Unlike most existing deep metric learning methods formulating the learning process by an overall objective, our DMML formulates the metric learning in a meta way, and proves that softmax and triplet loss are consistent in the meta space. Specifically, we sample some subsets from the original training set and learn metrics across different subsets. In each sampled sub-task, we split the training data into a support set as well as a query set, and learn the set-based distance, instead of sample-based one, to verify the query cell from multiple support cells. In addition, we introduce hard sample mining for set-based distance to encourage the intra-class compactness. Experimental results on three visual recognition applications including person re-identification, vehicle re-identification and face verification show that the proposed DMML method outperforms most existing approaches.",
      "intriguing_abstract": "In this paper, we present a deep meta metric learning (DMML) approach for visual recognition. Unlike most existing deep metric learning methods formulating the learning process by an overall objective, our DMML formulates the metric learning in a meta way, and proves that softmax and triplet loss are consistent in the meta space. Specifically, we sample some subsets from the original training set and learn metrics across different subsets. In each sampled sub-task, we split the training data into a support set as well as a query set, and learn the set-based distance, instead of sample-based one, to verify the query cell from multiple support cells. In addition, we introduce hard sample mining for set-based distance to encourage the intra-class compactness. Experimental results on three visual recognition applications including person re-identification, vehicle re-identification and face verification show that the proposed DMML method outperforms most existing approaches.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/4e0a735ee8f7606dd13633a88de15f6dfe3348ac.pdf",
      "citation_key": "chen2019oep",
      "metadata": {
        "title": "Deep Meta Metric Learning",
        "authors": [
          "Guangyi Chen",
          "Tianren Zhang",
          "Jiwen Lu",
          "Jie Zhou"
        ],
        "published_date": "2019",
        "abstract": "In this paper, we present a deep meta metric learning (DMML) approach for visual recognition. Unlike most existing deep metric learning methods formulating the learning process by an overall objective, our DMML formulates the metric learning in a meta way, and proves that softmax and triplet loss are consistent in the meta space. Specifically, we sample some subsets from the original training set and learn metrics across different subsets. In each sampled sub-task, we split the training data into a support set as well as a query set, and learn the set-based distance, instead of sample-based one, to verify the query cell from multiple support cells. In addition, we introduce hard sample mining for set-based distance to encourage the intra-class compactness. Experimental results on three visual recognition applications including person re-identification, vehicle re-identification and face verification show that the proposed DMML method outperforms most existing approaches.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4e0a735ee8f7606dd13633a88de15f6dfe3348ac.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 61,
        "score": 10.166666666666666,
        "summary": "In this paper, we present a deep meta metric learning (DMML) approach for visual recognition. Unlike most existing deep metric learning methods formulating the learning process by an overall objective, our DMML formulates the metric learning in a meta way, and proves that softmax and triplet loss are consistent in the meta space. Specifically, we sample some subsets from the original training set and learn metrics across different subsets. In each sampled sub-task, we split the training data into a support set as well as a query set, and learn the set-based distance, instead of sample-based one, to verify the query cell from multiple support cells. In addition, we introduce hard sample mining for set-based distance to encourage the intra-class compactness. Experimental results on three visual recognition applications including person re-identification, vehicle re-identification and face verification show that the proposed DMML method outperforms most existing approaches.",
        "keywords": []
      },
      "file_name": "4e0a735ee8f7606dd13633a88de15f6dfe3348ac.pdf"
    },
    {
      "success": true,
      "doc_id": "c2c96586755b8c43e82cf89b4731b536",
      "summary": "Deep learning is very effective at jointly learning feature representations and classification models, especially when dealing with high dimensional input patterns. Probabilistic logic reasoning, on the other hand, is capable to take consistent and robust decisions in complex environments. The integration of deep learning and logic reasoning is still an open-research problem and it is considered to be the key for the development of real intelligent agents. This paper presents Deep Logic Models, which are deep graphical models integrating deep learning and logic reasoning both for learning and inference. Deep Logic Models create an end-to-end differentiable architecture, where deep learners are embedded into a network implementing a continuous relaxation of the logic knowledge. The learning process allows to jointly learn the weights of the deep learners and the meta-parameters controlling the high-level reasoning. The experimental results show that the proposed methodology overtakes the limitations of the other approaches that have been proposed to bridge deep learning and reasoning.",
      "intriguing_abstract": "Deep learning is very effective at jointly learning feature representations and classification models, especially when dealing with high dimensional input patterns. Probabilistic logic reasoning, on the other hand, is capable to take consistent and robust decisions in complex environments. The integration of deep learning and logic reasoning is still an open-research problem and it is considered to be the key for the development of real intelligent agents. This paper presents Deep Logic Models, which are deep graphical models integrating deep learning and logic reasoning both for learning and inference. Deep Logic Models create an end-to-end differentiable architecture, where deep learners are embedded into a network implementing a continuous relaxation of the logic knowledge. The learning process allows to jointly learn the weights of the deep learners and the meta-parameters controlling the high-level reasoning. The experimental results show that the proposed methodology overtakes the limitations of the other approaches that have been proposed to bridge deep learning and reasoning.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/6867458654058f9a401b5871d666227cd5135360.pdf",
      "citation_key": "marra20192vv",
      "metadata": {
        "title": "Integrating Learning and Reasoning with Deep Logic Models",
        "authors": [
          "G. Marra",
          "Francesco Giannini",
          "Michelangelo Diligenti",
          "M. Gori"
        ],
        "published_date": "2019",
        "abstract": "Deep learning is very effective at jointly learning feature representations and classification models, especially when dealing with high dimensional input patterns. Probabilistic logic reasoning, on the other hand, is capable to take consistent and robust decisions in complex environments. The integration of deep learning and logic reasoning is still an open-research problem and it is considered to be the key for the development of real intelligent agents. This paper presents Deep Logic Models, which are deep graphical models integrating deep learning and logic reasoning both for learning and inference. Deep Logic Models create an end-to-end differentiable architecture, where deep learners are embedded into a network implementing a continuous relaxation of the logic knowledge. The learning process allows to jointly learn the weights of the deep learners and the meta-parameters controlling the high-level reasoning. The experimental results show that the proposed methodology overtakes the limitations of the other approaches that have been proposed to bridge deep learning and reasoning.",
        "file_path": "paper_data/Deep_Meta-Learning/info/6867458654058f9a401b5871d666227cd5135360.pdf",
        "venue": "ECML/PKDD",
        "citationCount": 59,
        "score": 9.833333333333332,
        "summary": "Deep learning is very effective at jointly learning feature representations and classification models, especially when dealing with high dimensional input patterns. Probabilistic logic reasoning, on the other hand, is capable to take consistent and robust decisions in complex environments. The integration of deep learning and logic reasoning is still an open-research problem and it is considered to be the key for the development of real intelligent agents. This paper presents Deep Logic Models, which are deep graphical models integrating deep learning and logic reasoning both for learning and inference. Deep Logic Models create an end-to-end differentiable architecture, where deep learners are embedded into a network implementing a continuous relaxation of the logic knowledge. The learning process allows to jointly learn the weights of the deep learners and the meta-parameters controlling the high-level reasoning. The experimental results show that the proposed methodology overtakes the limitations of the other approaches that have been proposed to bridge deep learning and reasoning.",
        "keywords": []
      },
      "file_name": "6867458654058f9a401b5871d666227cd5135360.pdf"
    },
    {
      "success": true,
      "doc_id": "dc17097519d2ff1494b56428aab6ed71",
      "summary": "Adaptive filtering algorithms are pervasive throughout signal processing and have had a material impact on a wide variety of domains including audio processing, telecommunications, biomedical sensing, astrophysics and cosmology, seismology, and many more. Adaptive filters typically operate via specialized online, iterative optimization methods such as least-mean squares or recursive least squares and aim to process signals in unknown or nonstationary environments. Such algorithms, however, can be slow and laborious to develop, require domain expertise to create, and necessitate mathematical insight for improvement. In this work, we seek to improve upon hand-derived adaptive filter algorithms and present a comprehensive framework for learning online, adaptive signal processing algorithms or update rules directly from data. To do so, we frame the development of adaptive filters as a meta-learning problem in the context of deep learning and use a form of self-supervision to learn online iterative update rules for adaptive filters. To demonstrate our approach, we focus on audio applications and systematically develop meta-learned adaptive filters for five canonical audio problems including system identification, acoustic echo cancellation, blind equalization, multi-channel dereverberation, and beamforming.We compare our approach against common baselines and/or recent state-of-the-art methods. We show we can learn high-performing adaptive filters that operate in real-time and, in most cases, significantly outperform each method we compare against – all using a single general-purpose configuration of our approach.",
      "intriguing_abstract": "Adaptive filtering algorithms are pervasive throughout signal processing and have had a material impact on a wide variety of domains including audio processing, telecommunications, biomedical sensing, astrophysics and cosmology, seismology, and many more. Adaptive filters typically operate via specialized online, iterative optimization methods such as least-mean squares or recursive least squares and aim to process signals in unknown or nonstationary environments. Such algorithms, however, can be slow and laborious to develop, require domain expertise to create, and necessitate mathematical insight for improvement. In this work, we seek to improve upon hand-derived adaptive filter algorithms and present a comprehensive framework for learning online, adaptive signal processing algorithms or update rules directly from data. To do so, we frame the development of adaptive filters as a meta-learning problem in the context of deep learning and use a form of self-supervision to learn online iterative update rules for adaptive filters. To demonstrate our approach, we focus on audio applications and systematically develop meta-learned adaptive filters for five canonical audio problems including system identification, acoustic echo cancellation, blind equalization, multi-channel dereverberation, and beamforming.We compare our approach against common baselines and/or recent state-of-the-art methods. We show we can learn high-performing adaptive filters that operate in real-time and, in most cases, significantly outperform each method we compare against – all using a single general-purpose configuration of our approach.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/82b7f2ab4faec66f16a62b9b5c610c7a5aa1e410.pdf",
      "citation_key": "casebeer20225fs",
      "metadata": {
        "title": "Meta-AF: Meta-Learning for Adaptive Filters",
        "authors": [
          "Jonah Casebeer",
          "Nicholas J. Bryan",
          "Paris Smaragdis"
        ],
        "published_date": "2022",
        "abstract": "Adaptive filtering algorithms are pervasive throughout signal processing and have had a material impact on a wide variety of domains including audio processing, telecommunications, biomedical sensing, astrophysics and cosmology, seismology, and many more. Adaptive filters typically operate via specialized online, iterative optimization methods such as least-mean squares or recursive least squares and aim to process signals in unknown or nonstationary environments. Such algorithms, however, can be slow and laborious to develop, require domain expertise to create, and necessitate mathematical insight for improvement. In this work, we seek to improve upon hand-derived adaptive filter algorithms and present a comprehensive framework for learning online, adaptive signal processing algorithms or update rules directly from data. To do so, we frame the development of adaptive filters as a meta-learning problem in the context of deep learning and use a form of self-supervision to learn online iterative update rules for adaptive filters. To demonstrate our approach, we focus on audio applications and systematically develop meta-learned adaptive filters for five canonical audio problems including system identification, acoustic echo cancellation, blind equalization, multi-channel dereverberation, and beamforming.We compare our approach against common baselines and/or recent state-of-the-art methods. We show we can learn high-performing adaptive filters that operate in real-time and, in most cases, significantly outperform each method we compare against – all using a single general-purpose configuration of our approach.",
        "file_path": "paper_data/Deep_Meta-Learning/info/82b7f2ab4faec66f16a62b9b5c610c7a5aa1e410.pdf",
        "venue": "IEEE/ACM Transactions on Audio Speech and Language Processing",
        "citationCount": 29,
        "score": 9.666666666666666,
        "summary": "Adaptive filtering algorithms are pervasive throughout signal processing and have had a material impact on a wide variety of domains including audio processing, telecommunications, biomedical sensing, astrophysics and cosmology, seismology, and many more. Adaptive filters typically operate via specialized online, iterative optimization methods such as least-mean squares or recursive least squares and aim to process signals in unknown or nonstationary environments. Such algorithms, however, can be slow and laborious to develop, require domain expertise to create, and necessitate mathematical insight for improvement. In this work, we seek to improve upon hand-derived adaptive filter algorithms and present a comprehensive framework for learning online, adaptive signal processing algorithms or update rules directly from data. To do so, we frame the development of adaptive filters as a meta-learning problem in the context of deep learning and use a form of self-supervision to learn online iterative update rules for adaptive filters. To demonstrate our approach, we focus on audio applications and systematically develop meta-learned adaptive filters for five canonical audio problems including system identification, acoustic echo cancellation, blind equalization, multi-channel dereverberation, and beamforming.We compare our approach against common baselines and/or recent state-of-the-art methods. We show we can learn high-performing adaptive filters that operate in real-time and, in most cases, significantly outperform each method we compare against – all using a single general-purpose configuration of our approach.",
        "keywords": []
      },
      "file_name": "82b7f2ab4faec66f16a62b9b5c610c7a5aa1e410.pdf"
    },
    {
      "success": true,
      "doc_id": "8ee03759a2ab2da32afe2426b94a15cd",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/8a59e5fd6250ccb286c52c27e2ea1ad00565e56b.pdf",
      "citation_key": "nobakht2022p86",
      "metadata": {
        "title": "DEMD-IoT: a deep ensemble model for IoT malware detection using CNNs and network traffic",
        "authors": [
          "Mehrnoosh Nobakht",
          "R. Javidan",
          "A. Pourebrahimi"
        ],
        "published_date": "2022",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/8a59e5fd6250ccb286c52c27e2ea1ad00565e56b.pdf",
        "venue": "Evolutionary Systematics",
        "citationCount": 29,
        "score": 9.666666666666666,
        "summary": "",
        "keywords": []
      },
      "file_name": "8a59e5fd6250ccb286c52c27e2ea1ad00565e56b.pdf"
    },
    {
      "success": true,
      "doc_id": "944c0bce7bab100ec522adad0d013ebb",
      "summary": "We investigate the impact of aliasing on generalization in Deep Convolutional Networks and show that data augmentation schemes alone are unable to prevent it due to structural limitations in widely used architectures. Drawing insights from frequency analysis theory, we take a closer look at ResNet and EfficientNet architectures and review the trade-off between aliasing and information loss in each of their major components. We show how to mitigate aliasing by inserting non-trainable low-pass filters at key locations, particularly where networks lack the capacity to learn them. These simple architectural changes lead to substantial improvements in generalization on i.i.d. and even more on out-of-distribution conditions, such as image classification under natural corruptions on ImageNet-C [11] and few-shot learning on Meta-Dataset [26]. State-of-the art results are achieved on both datasets without introducing additional trainable parameters and using the default hyper-parameters of open source codebases.",
      "intriguing_abstract": "We investigate the impact of aliasing on generalization in Deep Convolutional Networks and show that data augmentation schemes alone are unable to prevent it due to structural limitations in widely used architectures. Drawing insights from frequency analysis theory, we take a closer look at ResNet and EfficientNet architectures and review the trade-off between aliasing and information loss in each of their major components. We show how to mitigate aliasing by inserting non-trainable low-pass filters at key locations, particularly where networks lack the capacity to learn them. These simple architectural changes lead to substantial improvements in generalization on i.i.d. and even more on out-of-distribution conditions, such as image classification under natural corruptions on ImageNet-C [11] and few-shot learning on Meta-Dataset [26]. State-of-the art results are achieved on both datasets without introducing additional trainable parameters and using the default hyper-parameters of open source codebases.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/15d7105b4e334468a4eddb14f681583cbc8a5dd0.pdf",
      "citation_key": "vasconcelos2021fn3",
      "metadata": {
        "title": "Impact of Aliasing on Generalization in Deep Convolutional Networks",
        "authors": [
          "C. Vasconcelos",
          "H. Larochelle",
          "Vincent Dumoulin",
          "Rob Romijnders",
          "Nicolas Le Roux",
          "Ross Goroshin"
        ],
        "published_date": "2021",
        "abstract": "We investigate the impact of aliasing on generalization in Deep Convolutional Networks and show that data augmentation schemes alone are unable to prevent it due to structural limitations in widely used architectures. Drawing insights from frequency analysis theory, we take a closer look at ResNet and EfficientNet architectures and review the trade-off between aliasing and information loss in each of their major components. We show how to mitigate aliasing by inserting non-trainable low-pass filters at key locations, particularly where networks lack the capacity to learn them. These simple architectural changes lead to substantial improvements in generalization on i.i.d. and even more on out-of-distribution conditions, such as image classification under natural corruptions on ImageNet-C [11] and few-shot learning on Meta-Dataset [26]. State-of-the art results are achieved on both datasets without introducing additional trainable parameters and using the default hyper-parameters of open source codebases.",
        "file_path": "paper_data/Deep_Meta-Learning/info/15d7105b4e334468a4eddb14f681583cbc8a5dd0.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 38,
        "score": 9.5,
        "summary": "We investigate the impact of aliasing on generalization in Deep Convolutional Networks and show that data augmentation schemes alone are unable to prevent it due to structural limitations in widely used architectures. Drawing insights from frequency analysis theory, we take a closer look at ResNet and EfficientNet architectures and review the trade-off between aliasing and information loss in each of their major components. We show how to mitigate aliasing by inserting non-trainable low-pass filters at key locations, particularly where networks lack the capacity to learn them. These simple architectural changes lead to substantial improvements in generalization on i.i.d. and even more on out-of-distribution conditions, such as image classification under natural corruptions on ImageNet-C [11] and few-shot learning on Meta-Dataset [26]. State-of-the art results are achieved on both datasets without introducing additional trainable parameters and using the default hyper-parameters of open source codebases.",
        "keywords": []
      },
      "file_name": "15d7105b4e334468a4eddb14f681583cbc8a5dd0.pdf"
    },
    {
      "success": true,
      "doc_id": "cd973066ea132cee52ede4af12d2880c",
      "summary": "Epidemics of infectious diseases are an important threat to public health and global economies. Yet, the development of prevention strategies remains a challenging process, as epidemics are non-linear and complex processes. For this reason, we investigate a deep reinforcement learning approach to automatically learn prevention strategies in the context of pandemic influenza. Firstly, we construct a new epidemiological meta-population model, with 379 patches (one for each administrative district in Great Britain), that adequately captures the infection process of pandemic influenza. Our model balances complexity and computational efficiency such that the use of reinforcement learning techniques becomes attainable. Secondly, we set up a ground truth such that we can evaluate the performance of the 'Proximal Policy Optimization' algorithm to learn in a single district of this epidemiological model. Finally, we consider a large-scale problem, by conducting an experiment where we aim to learn a joint policy to control the districts in a community of 11 tightly coupled districts, for which no ground truth can be established. This experiment shows that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models with a large state space. Moreover, through this experiment, we demonstrate that there can be an advantage to consider collaboration between districts when designing prevention strategies.",
      "intriguing_abstract": "Epidemics of infectious diseases are an important threat to public health and global economies. Yet, the development of prevention strategies remains a challenging process, as epidemics are non-linear and complex processes. For this reason, we investigate a deep reinforcement learning approach to automatically learn prevention strategies in the context of pandemic influenza. Firstly, we construct a new epidemiological meta-population model, with 379 patches (one for each administrative district in Great Britain), that adequately captures the infection process of pandemic influenza. Our model balances complexity and computational efficiency such that the use of reinforcement learning techniques becomes attainable. Secondly, we set up a ground truth such that we can evaluate the performance of the 'Proximal Policy Optimization' algorithm to learn in a single district of this epidemiological model. Finally, we consider a large-scale problem, by conducting an experiment where we aim to learn a joint policy to control the districts in a community of 11 tightly coupled districts, for which no ground truth can be established. This experiment shows that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models with a large state space. Moreover, through this experiment, we demonstrate that there can be an advantage to consider collaboration between districts when designing prevention strategies.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/91f09ff4b588dcd9e5f27cb5c8ce18481b8fcced.pdf",
      "citation_key": "libin2020x8v",
      "metadata": {
        "title": "Deep reinforcement learning for large-scale epidemic control",
        "authors": [
          "Pieter J. K. Libin",
          "Arno Moonens",
          "T. Verstraeten",
          "F. Perez-Sanjines",
          "N. Hens",
          "P. Lemey",
          "Ann Now'e"
        ],
        "published_date": "2020",
        "abstract": "Epidemics of infectious diseases are an important threat to public health and global economies. Yet, the development of prevention strategies remains a challenging process, as epidemics are non-linear and complex processes. For this reason, we investigate a deep reinforcement learning approach to automatically learn prevention strategies in the context of pandemic influenza. Firstly, we construct a new epidemiological meta-population model, with 379 patches (one for each administrative district in Great Britain), that adequately captures the infection process of pandemic influenza. Our model balances complexity and computational efficiency such that the use of reinforcement learning techniques becomes attainable. Secondly, we set up a ground truth such that we can evaluate the performance of the 'Proximal Policy Optimization' algorithm to learn in a single district of this epidemiological model. Finally, we consider a large-scale problem, by conducting an experiment where we aim to learn a joint policy to control the districts in a community of 11 tightly coupled districts, for which no ground truth can be established. This experiment shows that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models with a large state space. Moreover, through this experiment, we demonstrate that there can be an advantage to consider collaboration between districts when designing prevention strategies.",
        "file_path": "paper_data/Deep_Meta-Learning/info/91f09ff4b588dcd9e5f27cb5c8ce18481b8fcced.pdf",
        "venue": "ECML/PKDD",
        "citationCount": 47,
        "score": 9.4,
        "summary": "Epidemics of infectious diseases are an important threat to public health and global economies. Yet, the development of prevention strategies remains a challenging process, as epidemics are non-linear and complex processes. For this reason, we investigate a deep reinforcement learning approach to automatically learn prevention strategies in the context of pandemic influenza. Firstly, we construct a new epidemiological meta-population model, with 379 patches (one for each administrative district in Great Britain), that adequately captures the infection process of pandemic influenza. Our model balances complexity and computational efficiency such that the use of reinforcement learning techniques becomes attainable. Secondly, we set up a ground truth such that we can evaluate the performance of the 'Proximal Policy Optimization' algorithm to learn in a single district of this epidemiological model. Finally, we consider a large-scale problem, by conducting an experiment where we aim to learn a joint policy to control the districts in a community of 11 tightly coupled districts, for which no ground truth can be established. This experiment shows that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models with a large state space. Moreover, through this experiment, we demonstrate that there can be an advantage to consider collaboration between districts when designing prevention strategies.",
        "keywords": []
      },
      "file_name": "91f09ff4b588dcd9e5f27cb5c8ce18481b8fcced.pdf"
    },
    {
      "success": true,
      "doc_id": "fd76e454f4b687bba253de1d650e7d37",
      "summary": "The existence of noisy labels in the dataset causes significant performance degradation for deep neural networks (DNNs). To address this problem, we propose a Meta Soft Label Generation algorithm called MSLG, which can jointly generate soft labels using meta-learning techniques and learn DNN parameters in an end-to-end fashion. Our approach adapts the meta-learning paradigm to estimate optimal label distribution by checking gradient directions on both noisy training data and noise-free meta-data. In order to iteratively update soft labels, meta-gradient descent step is performed on estimated labels, which would minimize the loss of noise-free meta samples. In each iteration, the base classifier is trained on estimated meta labels. MSLG is model-agnostic and can be added on top of any existing model at hand with ease. We performed extensive experiments on CIFAR10, Clothing1M and Food101N datasets. Results show that our approach outperforms other state-of-the-art methods by a large margin. Our code is available at https://github.com/gorkemalgan/MSLG_noisy_label.",
      "intriguing_abstract": "The existence of noisy labels in the dataset causes significant performance degradation for deep neural networks (DNNs). To address this problem, we propose a Meta Soft Label Generation algorithm called MSLG, which can jointly generate soft labels using meta-learning techniques and learn DNN parameters in an end-to-end fashion. Our approach adapts the meta-learning paradigm to estimate optimal label distribution by checking gradient directions on both noisy training data and noise-free meta-data. In order to iteratively update soft labels, meta-gradient descent step is performed on estimated labels, which would minimize the loss of noise-free meta samples. In each iteration, the base classifier is trained on estimated meta labels. MSLG is model-agnostic and can be added on top of any existing model at hand with ease. We performed extensive experiments on CIFAR10, Clothing1M and Food101N datasets. Results show that our approach outperforms other state-of-the-art methods by a large margin. Our code is available at https://github.com/gorkemalgan/MSLG_noisy_label.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/0341673e7ed78a096b9b9b51fbdbeff08beed660.pdf",
      "citation_key": "algan2020u0v",
      "metadata": {
        "title": "Meta Soft Label Generation for Noisy Labels",
        "authors": [
          "G. Algan",
          "I. Ulusoy"
        ],
        "published_date": "2020",
        "abstract": "The existence of noisy labels in the dataset causes significant performance degradation for deep neural networks (DNNs). To address this problem, we propose a Meta Soft Label Generation algorithm called MSLG, which can jointly generate soft labels using meta-learning techniques and learn DNN parameters in an end-to-end fashion. Our approach adapts the meta-learning paradigm to estimate optimal label distribution by checking gradient directions on both noisy training data and noise-free meta-data. In order to iteratively update soft labels, meta-gradient descent step is performed on estimated labels, which would minimize the loss of noise-free meta samples. In each iteration, the base classifier is trained on estimated meta labels. MSLG is model-agnostic and can be added on top of any existing model at hand with ease. We performed extensive experiments on CIFAR10, Clothing1M and Food101N datasets. Results show that our approach outperforms other state-of-the-art methods by a large margin. Our code is available at https://github.com/gorkemalgan/MSLG_noisy_label.",
        "file_path": "paper_data/Deep_Meta-Learning/info/0341673e7ed78a096b9b9b51fbdbeff08beed660.pdf",
        "venue": "International Conference on Pattern Recognition",
        "citationCount": 43,
        "score": 8.6,
        "summary": "The existence of noisy labels in the dataset causes significant performance degradation for deep neural networks (DNNs). To address this problem, we propose a Meta Soft Label Generation algorithm called MSLG, which can jointly generate soft labels using meta-learning techniques and learn DNN parameters in an end-to-end fashion. Our approach adapts the meta-learning paradigm to estimate optimal label distribution by checking gradient directions on both noisy training data and noise-free meta-data. In order to iteratively update soft labels, meta-gradient descent step is performed on estimated labels, which would minimize the loss of noise-free meta samples. In each iteration, the base classifier is trained on estimated meta labels. MSLG is model-agnostic and can be added on top of any existing model at hand with ease. We performed extensive experiments on CIFAR10, Clothing1M and Food101N datasets. Results show that our approach outperforms other state-of-the-art methods by a large margin. Our code is available at https://github.com/gorkemalgan/MSLG_noisy_label.",
        "keywords": []
      },
      "file_name": "0341673e7ed78a096b9b9b51fbdbeff08beed660.pdf"
    },
    {
      "success": true,
      "doc_id": "51aeb3cfbfb69a08b3a220632b3c86ef",
      "summary": "Despite significant progress, deep reinforcement learning (RL) suffers from data-inefficiency and limited generalization. Recent efforts apply meta-learning to learn a meta-learner from a set of RL tasks such that a novel but related task could be solved quickly. Though specific in some ways, different tasks in meta-RL are generally similar at a high level. However, most meta-RL methods do not explicitly and adequately model the specific and shared information among different tasks, which limits their ability to learn training tasks and to generalize to novel tasks. In this paper, we propose to capture the shared information on the one hand and meta-learn how to quickly abstract the specific information about a task on the other hand. Methodologically, we train an SGD meta-learner to quickly optimize a task encoder for each task, which generates a task embedding based on past experience. Meanwhile, we learn a policy which is shared across all tasks and conditioned on task embeddings. Empirical results on four simulated tasks demonstrate that our method has better learning capacity on both training and novel tasks and attains up to 3 to 4 times higher returns compared to baselines.",
      "intriguing_abstract": "Despite significant progress, deep reinforcement learning (RL) suffers from data-inefficiency and limited generalization. Recent efforts apply meta-learning to learn a meta-learner from a set of RL tasks such that a novel but related task could be solved quickly. Though specific in some ways, different tasks in meta-RL are generally similar at a high level. However, most meta-RL methods do not explicitly and adequately model the specific and shared information among different tasks, which limits their ability to learn training tasks and to generalize to novel tasks. In this paper, we propose to capture the shared information on the one hand and meta-learn how to quickly abstract the specific information about a task on the other hand. Methodologically, we train an SGD meta-learner to quickly optimize a task encoder for each task, which generates a task embedding based on past experience. Meanwhile, we learn a policy which is shared across all tasks and conditioned on task embeddings. Empirical results on four simulated tasks demonstrate that our method has better learning capacity on both training and novel tasks and attains up to 3 to 4 times higher returns compared to baselines.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/7bd95a62fd6320730cbb24a0e4fafac97d840652.pdf",
      "citation_key": "lan20196o7",
      "metadata": {
        "title": "Meta Reinforcement Learning with Task Embedding and Shared Policy",
        "authors": [
          "Lin Lan",
          "Zhenguo Li",
          "X. Guan",
          "P. Wang"
        ],
        "published_date": "2019",
        "abstract": "Despite significant progress, deep reinforcement learning (RL) suffers from data-inefficiency and limited generalization. Recent efforts apply meta-learning to learn a meta-learner from a set of RL tasks such that a novel but related task could be solved quickly. Though specific in some ways, different tasks in meta-RL are generally similar at a high level. However, most meta-RL methods do not explicitly and adequately model the specific and shared information among different tasks, which limits their ability to learn training tasks and to generalize to novel tasks. In this paper, we propose to capture the shared information on the one hand and meta-learn how to quickly abstract the specific information about a task on the other hand. Methodologically, we train an SGD meta-learner to quickly optimize a task encoder for each task, which generates a task embedding based on past experience. Meanwhile, we learn a policy which is shared across all tasks and conditioned on task embeddings. Empirical results on four simulated tasks demonstrate that our method has better learning capacity on both training and novel tasks and attains up to 3 to 4 times higher returns compared to baselines.",
        "file_path": "paper_data/Deep_Meta-Learning/info/7bd95a62fd6320730cbb24a0e4fafac97d840652.pdf",
        "venue": "International Joint Conference on Artificial Intelligence",
        "citationCount": 51,
        "score": 8.5,
        "summary": "Despite significant progress, deep reinforcement learning (RL) suffers from data-inefficiency and limited generalization. Recent efforts apply meta-learning to learn a meta-learner from a set of RL tasks such that a novel but related task could be solved quickly. Though specific in some ways, different tasks in meta-RL are generally similar at a high level. However, most meta-RL methods do not explicitly and adequately model the specific and shared information among different tasks, which limits their ability to learn training tasks and to generalize to novel tasks. In this paper, we propose to capture the shared information on the one hand and meta-learn how to quickly abstract the specific information about a task on the other hand. Methodologically, we train an SGD meta-learner to quickly optimize a task encoder for each task, which generates a task embedding based on past experience. Meanwhile, we learn a policy which is shared across all tasks and conditioned on task embeddings. Empirical results on four simulated tasks demonstrate that our method has better learning capacity on both training and novel tasks and attains up to 3 to 4 times higher returns compared to baselines.",
        "keywords": []
      },
      "file_name": "7bd95a62fd6320730cbb24a0e4fafac97d840652.pdf"
    },
    {
      "success": true,
      "doc_id": "47cc62013da1798c811d783a5afb29d0",
      "summary": "Deep learning techniques for point clouds have achieved strong performance on a range of 3D vision tasks. However, it is costly to annotate large-scale point sets, making it critical to learn generalizable representations that can transfer well across different point sets. In this paper, we study a new problem of 3D Domain Generalization (3DDG) with the goal to generalize the model to other unseen domains of point clouds without any access to them in the training process. It is a challenging problem due to the substantial geometry shift from simulated to real data, such that most existing 3D models underperform due to overfitting the complete geometries in the source domain. We propose to tackle this problem via MetaSets, which meta-learns point cloud representations from a group of classification tasks on carefully-designed transformed point sets containing specific geometry priors. The learned representations are more generalizable to various unseen domains of different geometries. We design two benchmarks for Sim-to-Real transfer of 3D point clouds. Experimental results show that MetaSets outperforms existing 3D deep learning methods by large margins.",
      "intriguing_abstract": "Deep learning techniques for point clouds have achieved strong performance on a range of 3D vision tasks. However, it is costly to annotate large-scale point sets, making it critical to learn generalizable representations that can transfer well across different point sets. In this paper, we study a new problem of 3D Domain Generalization (3DDG) with the goal to generalize the model to other unseen domains of point clouds without any access to them in the training process. It is a challenging problem due to the substantial geometry shift from simulated to real data, such that most existing 3D models underperform due to overfitting the complete geometries in the source domain. We propose to tackle this problem via MetaSets, which meta-learns point cloud representations from a group of classification tasks on carefully-designed transformed point sets containing specific geometry priors. The learned representations are more generalizable to various unseen domains of different geometries. We design two benchmarks for Sim-to-Real transfer of 3D point clouds. Experimental results show that MetaSets outperforms existing 3D deep learning methods by large margins.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/0833bed96c0a571782b4b31e90c730726b702595.pdf",
      "citation_key": "huang20214b2",
      "metadata": {
        "title": "MetaSets: Meta-Learning on Point Sets for Generalizable Representations",
        "authors": [
          "Chao Huang",
          "Zhangjie Cao",
          "Yunbo Wang",
          "Jianmin Wang",
          "Mingsheng Long"
        ],
        "published_date": "2021",
        "abstract": "Deep learning techniques for point clouds have achieved strong performance on a range of 3D vision tasks. However, it is costly to annotate large-scale point sets, making it critical to learn generalizable representations that can transfer well across different point sets. In this paper, we study a new problem of 3D Domain Generalization (3DDG) with the goal to generalize the model to other unseen domains of point clouds without any access to them in the training process. It is a challenging problem due to the substantial geometry shift from simulated to real data, such that most existing 3D models underperform due to overfitting the complete geometries in the source domain. We propose to tackle this problem via MetaSets, which meta-learns point cloud representations from a group of classification tasks on carefully-designed transformed point sets containing specific geometry priors. The learned representations are more generalizable to various unseen domains of different geometries. We design two benchmarks for Sim-to-Real transfer of 3D point clouds. Experimental results show that MetaSets outperforms existing 3D deep learning methods by large margins.",
        "file_path": "paper_data/Deep_Meta-Learning/info/0833bed96c0a571782b4b31e90c730726b702595.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 33,
        "score": 8.25,
        "summary": "Deep learning techniques for point clouds have achieved strong performance on a range of 3D vision tasks. However, it is costly to annotate large-scale point sets, making it critical to learn generalizable representations that can transfer well across different point sets. In this paper, we study a new problem of 3D Domain Generalization (3DDG) with the goal to generalize the model to other unseen domains of point clouds without any access to them in the training process. It is a challenging problem due to the substantial geometry shift from simulated to real data, such that most existing 3D models underperform due to overfitting the complete geometries in the source domain. We propose to tackle this problem via MetaSets, which meta-learns point cloud representations from a group of classification tasks on carefully-designed transformed point sets containing specific geometry priors. The learned representations are more generalizable to various unseen domains of different geometries. We design two benchmarks for Sim-to-Real transfer of 3D point clouds. Experimental results show that MetaSets outperforms existing 3D deep learning methods by large margins.",
        "keywords": []
      },
      "file_name": "0833bed96c0a571782b4b31e90c730726b702595.pdf"
    },
    {
      "success": true,
      "doc_id": "2d090273c8ad10cfcd8f5ec18c804b1a",
      "summary": "Here's a focused summary of the paper \"META-LEARNING ADAPTIVE DEEP KERNEL GAUSSIAN PROCESSES FOR MOLECULAR PROPERTY PREDICTION\" \\cite{chen2022z45} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of making robust predictions with well-calibrated uncertainty from very limited training data, particularly in applications like drug discovery \\cite{chen2022z45}.\n    *   **Importance & Challenge:** Drug discovery requires accurate predictions and reliable uncertainty estimates for techniques like Bayesian optimization (BO). While Gaussian Processes (GPs) offer reliable uncertainty, traditional GPs on hand-engineered features struggle with complex, high-dimensional data (e.g., molecules). Deep Kernel GPs, which use neural networks to learn features, lack a clear consensus on training methods: maximizing marginal likelihood (DKL) overfits on small datasets, while pure meta-learning (DKT) or fully-Bayesian approaches make strong, often unrealistic assumptions \\cite{chen2022z45}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work introduces ADKF-IFT as a generalization and unification of two prominent deep kernel GP training methods: Deep Kernel Learning (DKL) \\cite{chen2022z45} and Deep Kernel Transfer (DKT) \\cite{chen2022z45}.\n    *   **Limitations of Previous Solutions:**\n        *   **DKL** (minimizing negative log marginal likelihood on a single dataset) is prone to severe overfitting on small datasets \\cite{chen2022z45}.\n        *   **DKT** (pure meta-learning) prevents overfitting but makes strong assumptions that all tasks come from an identical distribution, including the same noise level, amplitude, and characteristic lengthscales, which is often unrealistic \\cite{chen2022z45}.\n        *   Other regularization methods for DKL are often designed for continuous inputs, limiting their applicability to structured data like molecules \\cite{chen2022z45}.\n        *   Many general meta-learning algorithms are designed for neural networks (which lack reliable uncertainty estimates) or are classification-specific, unlike ADKF-IFT which is for deep kernel GPs and suited for both regression and classification \\cite{chen2022z45}.\n        *   Model-agnostic meta-learning frameworks like MAML often require coarse approximations of the hypergradient \\cite{chen2022z45}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT), a novel framework for training deep kernel GPs \\cite{chen2022z45}.\n    *   **Novelty:**\n        *   ADKF-IFT employs a bilevel optimization objective: it meta-learns a subset of parameters (e.g., feature extractor parameters $\\phi$) to find generally useful feature representations across tasks, while another subset of parameters (e.g., base kernel parameters $\\theta$) are adapted specifically for each individual task \\cite{chen2022z45}.\n        *   The nested optimization problem is efficiently solved using the Implicit Function Theorem (IFT) to compute exact hypergradients, which avoids the computationally expensive process of tracking gradients through many iterations of the inner optimization \\cite{chen2022z45}.\n        *   A key practical instantiation is highlighted where all feature extractor parameters are meta-learned, and all base kernel parameters are adapted per task, offering an intuitive balance between generalization and task-specificity \\cite{chen2022z45}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   The ADKF-IFT framework itself, formulated as a bilevel optimization problem for deep kernel GP training \\cite{chen2022z45}.\n        *   An efficient meta-training algorithm that leverages the Implicit Function Theorem (IFT) to compute exact hypergradients for the outer optimization, enabling gradient-based optimization of meta-learned parameters \\cite{chen2022z45}.\n    *   **Theoretical Insights:**\n        *   Demonstrates that ADKF-IFT is a strictly more general framework that unifies DKL (no parameters meta-learned) and DKT (all parameters meta-learned) as special cases \\cite{chen2022z45}.\n        *   Conjectures that adapting only the base kernel parameters allows ADKF-IFT to achieve a better balance between overfitting (like DKL) and underfitting (like DKT) \\cite{chen2022z45}.\n    *   **System Design/Architectural Innovations:**\n        *   Proposes a specific, practical instantiation where feature extractor parameters ($\\phi$) are meta-learned and base kernel parameters ($\\theta$) are adapted. This choice is beneficial because the small number of base kernel parameters allows for exact computation and inversion of the Hessian matrix required by IFT, obviating the need for approximations \\cite{chen2022z45}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** The authors performed an extensive empirical evaluation focused on molecular property prediction and optimization tasks, arguing that this domain greatly benefits from improved GP models \\cite{chen2022z45}.\n        *   Evaluated on four commonly used benchmark tasks from MoleculeNet (Tox21, SIDER, MUV, ToxCast) in a few-shot setting (2-way 10-shot) \\cite{chen2022z45}.\n        *   Evaluated on the larger-scale FS-Mol benchmark \\cite{chen2022z45}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   ADKF-IFT significantly outperforms previous state-of-the-art methods on a variety of real-world few-shot molecular property prediction tasks \\cite{chen2022z45}.\n        *   Achieves state-of-the-art results on most MoleculeNet tasks, demonstrating superior AUROC scores (e.g., 98.18% on MUV, 72.07% on ToxCast) \\cite{chen2022z45}.\n        *   Is identified as the best-performing method on the FS-Mol benchmark \\cite{chen2022z45}.\n        *   The empirical results support the hypothesis that ADKF-IFT achieves a better balance between overfitting and underfitting compared to DKL and DKT \\cite{chen2022z45}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The exact computation and inversion of the Hessian matrix in the IFT-based hypergradient calculation (Equation 5) is most efficient and practical when the number of task-specific adaptive parameters ($|\\mathcal{A}_{\\text{adapt}}|$) is small. For larger sets of adaptive parameters, approximations to the inverse Hessian would be necessary \\cite{chen2022z45}.\n    *   **Scope of Applicability:** While a general method, ADKF-IFT is argued to be \"especially well-suited for drug discovery problems\" and other applications requiring robust predictions with well-calibrated uncertainty from small datasets \\cite{chen2022z45}. It is applicable to both regression and classification tasks \\cite{chen2022z45}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** ADKF-IFT provides a novel, general, and effective framework for training deep kernel GPs, particularly excelling in few-shot learning scenarios and on small datasets where reliable uncertainty estimates are crucial \\cite{chen2022z45}.\n    *   **Potential Impact on Future Research:**\n        *   Offers a principled approach to combine the benefits of meta-learning (preventing overfitting by learning general representations) with task-specific adaptation (avoiding underfitting by allowing flexibility in base kernel parameters), leading to more robust and accurate deep kernel GP models \\cite{chen2022z45}.\n        *   Its strong empirical performance in molecular property prediction suggests significant potential for advancing drug discovery and other scientific domains reliant on high-quality uncertainty estimates and few-shot learning \\cite{chen2022z45}.\n        *   The unification of DKL and DKT within a single framework provides a deeper theoretical understanding of deep kernel GP training strategies \\cite{chen2022z45}.",
      "intriguing_abstract": "Reliable predictions with well-calibrated uncertainty are critical for accelerating scientific discovery, especially in data-scarce domains like drug discovery and Bayesian optimization. While Deep Kernel Gaussian Processes (DKGPs) offer robust uncertainty, current training paradigms like Deep Kernel Learning (DKL) often overfit small datasets, and Deep Kernel Transfer (DKT) relies on unrealistic task distribution assumptions.\n\nWe introduce Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT), a novel meta-learning framework that unifies and generalizes DKL and DKT. ADKF-IFT employs bilevel optimization, meta-learning general feature representations while adaptively fitting base kernel parameters for each task. This crucial balance prevents both overfitting and underfitting. Leveraging the Implicit Function Theorem, we efficiently compute exact hypergradients, enabling principled optimization. Empirically, ADKF-IFT achieves state-of-the-art performance on challenging few-shot molecular property prediction benchmarks, including MoleculeNet and FS-Mol. Our method provides superior accuracy and reliable uncertainty quantification, offering a powerful tool to accelerate drug discovery and other data-scarce applications.",
      "keywords": [
        "ADKF-IFT framework",
        "Deep Kernel Gaussian Processes",
        "Meta-learning",
        "Bilevel optimization",
        "Implicit Function Theorem",
        "Exact hypergradients",
        "Molecular property prediction",
        "Drug discovery",
        "Few-shot learning",
        "Uncertainty estimation",
        "DKL and DKT unification",
        "Adaptive base kernel parameters",
        "Overfitting/underfitting balance",
        "State-of-the-art performance"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/1aed7b21007519b7482ac4a005d5f2e0c7a1d047.pdf",
      "citation_key": "chen2022z45",
      "metadata": {
        "title": "Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction",
        "authors": [
          "Wenlin Chen",
          "Austin Tripp",
          "José Miguel Hernández-Lobato"
        ],
        "published_date": "2022",
        "abstract": "We propose Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT), a novel framework for learning deep kernel Gaussian processes (GPs) by interpolating between meta-learning and conventional deep kernel learning. Our approach employs a bilevel optimization objective where we meta-learn generally useful feature representations across tasks, in the sense that task-specific GP models estimated on top of such features achieve the lowest possible predictive loss on average. We solve the resulting nested optimization problem using the implicit function theorem (IFT). We show that our ADKF-IFT framework contains previously proposed Deep Kernel Learning (DKL) and Deep Kernel Transfer (DKT) as special cases. Although ADKF-IFT is a completely general method, we argue that it is especially well-suited for drug discovery problems and demonstrate that it significantly outperforms previous state-of-the-art methods on a variety of real-world few-shot molecular property prediction tasks and out-of-domain molecular property prediction and optimization tasks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/1aed7b21007519b7482ac4a005d5f2e0c7a1d047.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 24,
        "score": 8.0,
        "summary": "Here's a focused summary of the paper \"META-LEARNING ADAPTIVE DEEP KERNEL GAUSSIAN PROCESSES FOR MOLECULAR PROPERTY PREDICTION\" \\cite{chen2022z45} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of making robust predictions with well-calibrated uncertainty from very limited training data, particularly in applications like drug discovery \\cite{chen2022z45}.\n    *   **Importance & Challenge:** Drug discovery requires accurate predictions and reliable uncertainty estimates for techniques like Bayesian optimization (BO). While Gaussian Processes (GPs) offer reliable uncertainty, traditional GPs on hand-engineered features struggle with complex, high-dimensional data (e.g., molecules). Deep Kernel GPs, which use neural networks to learn features, lack a clear consensus on training methods: maximizing marginal likelihood (DKL) overfits on small datasets, while pure meta-learning (DKT) or fully-Bayesian approaches make strong, often unrealistic assumptions \\cite{chen2022z45}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work introduces ADKF-IFT as a generalization and unification of two prominent deep kernel GP training methods: Deep Kernel Learning (DKL) \\cite{chen2022z45} and Deep Kernel Transfer (DKT) \\cite{chen2022z45}.\n    *   **Limitations of Previous Solutions:**\n        *   **DKL** (minimizing negative log marginal likelihood on a single dataset) is prone to severe overfitting on small datasets \\cite{chen2022z45}.\n        *   **DKT** (pure meta-learning) prevents overfitting but makes strong assumptions that all tasks come from an identical distribution, including the same noise level, amplitude, and characteristic lengthscales, which is often unrealistic \\cite{chen2022z45}.\n        *   Other regularization methods for DKL are often designed for continuous inputs, limiting their applicability to structured data like molecules \\cite{chen2022z45}.\n        *   Many general meta-learning algorithms are designed for neural networks (which lack reliable uncertainty estimates) or are classification-specific, unlike ADKF-IFT which is for deep kernel GPs and suited for both regression and classification \\cite{chen2022z45}.\n        *   Model-agnostic meta-learning frameworks like MAML often require coarse approximations of the hypergradient \\cite{chen2022z45}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT), a novel framework for training deep kernel GPs \\cite{chen2022z45}.\n    *   **Novelty:**\n        *   ADKF-IFT employs a bilevel optimization objective: it meta-learns a subset of parameters (e.g., feature extractor parameters $\\phi$) to find generally useful feature representations across tasks, while another subset of parameters (e.g., base kernel parameters $\\theta$) are adapted specifically for each individual task \\cite{chen2022z45}.\n        *   The nested optimization problem is efficiently solved using the Implicit Function Theorem (IFT) to compute exact hypergradients, which avoids the computationally expensive process of tracking gradients through many iterations of the inner optimization \\cite{chen2022z45}.\n        *   A key practical instantiation is highlighted where all feature extractor parameters are meta-learned, and all base kernel parameters are adapted per task, offering an intuitive balance between generalization and task-specificity \\cite{chen2022z45}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   The ADKF-IFT framework itself, formulated as a bilevel optimization problem for deep kernel GP training \\cite{chen2022z45}.\n        *   An efficient meta-training algorithm that leverages the Implicit Function Theorem (IFT) to compute exact hypergradients for the outer optimization, enabling gradient-based optimization of meta-learned parameters \\cite{chen2022z45}.\n    *   **Theoretical Insights:**\n        *   Demonstrates that ADKF-IFT is a strictly more general framework that unifies DKL (no parameters meta-learned) and DKT (all parameters meta-learned) as special cases \\cite{chen2022z45}.\n        *   Conjectures that adapting only the base kernel parameters allows ADKF-IFT to achieve a better balance between overfitting (like DKL) and underfitting (like DKT) \\cite{chen2022z45}.\n    *   **System Design/Architectural Innovations:**\n        *   Proposes a specific, practical instantiation where feature extractor parameters ($\\phi$) are meta-learned and base kernel parameters ($\\theta$) are adapted. This choice is beneficial because the small number of base kernel parameters allows for exact computation and inversion of the Hessian matrix required by IFT, obviating the need for approximations \\cite{chen2022z45}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** The authors performed an extensive empirical evaluation focused on molecular property prediction and optimization tasks, arguing that this domain greatly benefits from improved GP models \\cite{chen2022z45}.\n        *   Evaluated on four commonly used benchmark tasks from MoleculeNet (Tox21, SIDER, MUV, ToxCast) in a few-shot setting (2-way 10-shot) \\cite{chen2022z45}.\n        *   Evaluated on the larger-scale FS-Mol benchmark \\cite{chen2022z45}.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   ADKF-IFT significantly outperforms previous state-of-the-art methods on a variety of real-world few-shot molecular property prediction tasks \\cite{chen2022z45}.\n        *   Achieves state-of-the-art results on most MoleculeNet tasks, demonstrating superior AUROC scores (e.g., 98.18% on MUV, 72.07% on ToxCast) \\cite{chen2022z45}.\n        *   Is identified as the best-performing method on the FS-Mol benchmark \\cite{chen2022z45}.\n        *   The empirical results support the hypothesis that ADKF-IFT achieves a better balance between overfitting and underfitting compared to DKL and DKT \\cite{chen2022z45}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The exact computation and inversion of the Hessian matrix in the IFT-based hypergradient calculation (Equation 5) is most efficient and practical when the number of task-specific adaptive parameters ($|\\mathcal{A}_{\\text{adapt}}|$) is small. For larger sets of adaptive parameters, approximations to the inverse Hessian would be necessary \\cite{chen2022z45}.\n    *   **Scope of Applicability:** While a general method, ADKF-IFT is argued to be \"especially well-suited for drug discovery problems\" and other applications requiring robust predictions with well-calibrated uncertainty from small datasets \\cite{chen2022z45}. It is applicable to both regression and classification tasks \\cite{chen2022z45}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** ADKF-IFT provides a novel, general, and effective framework for training deep kernel GPs, particularly excelling in few-shot learning scenarios and on small datasets where reliable uncertainty estimates are crucial \\cite{chen2022z45}.\n    *   **Potential Impact on Future Research:**\n        *   Offers a principled approach to combine the benefits of meta-learning (preventing overfitting by learning general representations) with task-specific adaptation (avoiding underfitting by allowing flexibility in base kernel parameters), leading to more robust and accurate deep kernel GP models \\cite{chen2022z45}.\n        *   Its strong empirical performance in molecular property prediction suggests significant potential for advancing drug discovery and other scientific domains reliant on high-quality uncertainty estimates and few-shot learning \\cite{chen2022z45}.\n        *   The unification of DKL and DKT within a single framework provides a deeper theoretical understanding of deep kernel GP training strategies \\cite{chen2022z45}.",
        "keywords": [
          "ADKF-IFT framework",
          "Deep Kernel Gaussian Processes",
          "Meta-learning",
          "Bilevel optimization",
          "Implicit Function Theorem",
          "Exact hypergradients",
          "Molecular property prediction",
          "Drug discovery",
          "Few-shot learning",
          "Uncertainty estimation",
          "DKL and DKT unification",
          "Adaptive base kernel parameters",
          "Overfitting/underfitting balance",
          "State-of-the-art performance"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** adaptive deep kernel fitting with implicit function theorem (adkf-ift), a **novel framework** for learning deep kernel gaussian processes (gps)...\"\n*   it describes the components of this framework: \"our approach employs a **bilevel optimization objective** where we meta-learn generally useful feature representations...\", \"we **solve** the resulting nested optimization problem using the **implicit function theorem (ift)**.\"\n*   the introduction further elaborates on the problem the proposed method addresses (robust predictions with limited data, uncertainty estimates for drug discovery) and positions adkf-ift as the solution.\n*   while there is a strong empirical component (\"demonstrate that it significantly outperforms previous state-of-the-art methods\"), this is presented as validation of the *new method* rather than the primary focus of the paper being a data-driven study of existing phenomena.\n\nthese points align perfectly with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\".\n\n**classification: technical**"
      },
      "file_name": "1aed7b21007519b7482ac4a005d5f2e0c7a1d047.pdf"
    },
    {
      "success": true,
      "doc_id": "314437dd189907ddd68bc7ea9f83205c",
      "summary": "Multimodal meta-learning is a recent problem that extends conventional few-shot meta-learning by generalizing its setup to diverse multimodal task distributions. This setup makes a step towards mimicking how humans make use of a diverse set of prior skills to learn new skills. Previous work has achieved encouraging performance. In particular, in spite of the diversity of the multimodal tasks, previous work claims that a single meta-learner trained on a multimodal distribution can sometimes outperform multiple specialized meta-learners trained on individual unimodal distributions. The improvement is attributed to knowledge transfer between different modes of task distributions. However, there is no deep investigation to verify and understand the knowledge transfer between multimodal tasks. Our work makes two contributions to multimodal meta-learning. First, we propose a method to quantify knowledge transfer between tasks of different modes at a micro-level. Our quantitative, task-level analysis is inspired by the recent transference idea from multi-task learning. Second, inspired by hard parameter sharing in multi-task learning and a new interpretation of related work, we propose a new multimodal meta-learner that outperforms existing work by considerable margins. While the major focus is on multimodal meta-learning, our work also attempts to shed light on task interaction in conventional meta-learning. The code for this project is available at https://miladabd.github.io/KML.",
      "intriguing_abstract": "Multimodal meta-learning is a recent problem that extends conventional few-shot meta-learning by generalizing its setup to diverse multimodal task distributions. This setup makes a step towards mimicking how humans make use of a diverse set of prior skills to learn new skills. Previous work has achieved encouraging performance. In particular, in spite of the diversity of the multimodal tasks, previous work claims that a single meta-learner trained on a multimodal distribution can sometimes outperform multiple specialized meta-learners trained on individual unimodal distributions. The improvement is attributed to knowledge transfer between different modes of task distributions. However, there is no deep investigation to verify and understand the knowledge transfer between multimodal tasks. Our work makes two contributions to multimodal meta-learning. First, we propose a method to quantify knowledge transfer between tasks of different modes at a micro-level. Our quantitative, task-level analysis is inspired by the recent transference idea from multi-task learning. Second, inspired by hard parameter sharing in multi-task learning and a new interpretation of related work, we propose a new multimodal meta-learner that outperforms existing work by considerable margins. While the major focus is on multimodal meta-learning, our work also attempts to shed light on task interaction in conventional meta-learning. The code for this project is available at https://miladabd.github.io/KML.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/77c6cfe76bfc9ebb23cd895747f721a9790445e7.pdf",
      "citation_key": "abdollahzadeh2021zfy",
      "metadata": {
        "title": "Revisit Multimodal Meta-Learning through the Lens of Multi-Task Learning",
        "authors": [
          "Milad Abdollahzadeh",
          "Touba Malekzadeh",
          "Ngai-Man Cheung"
        ],
        "published_date": "2021",
        "abstract": "Multimodal meta-learning is a recent problem that extends conventional few-shot meta-learning by generalizing its setup to diverse multimodal task distributions. This setup makes a step towards mimicking how humans make use of a diverse set of prior skills to learn new skills. Previous work has achieved encouraging performance. In particular, in spite of the diversity of the multimodal tasks, previous work claims that a single meta-learner trained on a multimodal distribution can sometimes outperform multiple specialized meta-learners trained on individual unimodal distributions. The improvement is attributed to knowledge transfer between different modes of task distributions. However, there is no deep investigation to verify and understand the knowledge transfer between multimodal tasks. Our work makes two contributions to multimodal meta-learning. First, we propose a method to quantify knowledge transfer between tasks of different modes at a micro-level. Our quantitative, task-level analysis is inspired by the recent transference idea from multi-task learning. Second, inspired by hard parameter sharing in multi-task learning and a new interpretation of related work, we propose a new multimodal meta-learner that outperforms existing work by considerable margins. While the major focus is on multimodal meta-learning, our work also attempts to shed light on task interaction in conventional meta-learning. The code for this project is available at https://miladabd.github.io/KML.",
        "file_path": "paper_data/Deep_Meta-Learning/info/77c6cfe76bfc9ebb23cd895747f721a9790445e7.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 32,
        "score": 8.0,
        "summary": "Multimodal meta-learning is a recent problem that extends conventional few-shot meta-learning by generalizing its setup to diverse multimodal task distributions. This setup makes a step towards mimicking how humans make use of a diverse set of prior skills to learn new skills. Previous work has achieved encouraging performance. In particular, in spite of the diversity of the multimodal tasks, previous work claims that a single meta-learner trained on a multimodal distribution can sometimes outperform multiple specialized meta-learners trained on individual unimodal distributions. The improvement is attributed to knowledge transfer between different modes of task distributions. However, there is no deep investigation to verify and understand the knowledge transfer between multimodal tasks. Our work makes two contributions to multimodal meta-learning. First, we propose a method to quantify knowledge transfer between tasks of different modes at a micro-level. Our quantitative, task-level analysis is inspired by the recent transference idea from multi-task learning. Second, inspired by hard parameter sharing in multi-task learning and a new interpretation of related work, we propose a new multimodal meta-learner that outperforms existing work by considerable margins. While the major focus is on multimodal meta-learning, our work also attempts to shed light on task interaction in conventional meta-learning. The code for this project is available at https://miladabd.github.io/KML.",
        "keywords": []
      },
      "file_name": "77c6cfe76bfc9ebb23cd895747f721a9790445e7.pdf"
    },
    {
      "success": true,
      "doc_id": "5d343c354ef440daef166738ffeb6d58",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/f8438509b55749850fa6078aea3fa940a4dbcaab.pdf",
      "citation_key": "chen2019xg0",
      "metadata": {
        "title": "MetaQuant: Learning to Quantize by Learning to Penetrate Non-differentiable Quantization",
        "authors": [
          "Shangyu Chen",
          "Wenya Wang",
          "Sinno Jialin Pan"
        ],
        "published_date": "2019",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/f8438509b55749850fa6078aea3fa940a4dbcaab.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 48,
        "score": 8.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "f8438509b55749850fa6078aea3fa940a4dbcaab.pdf"
    },
    {
      "success": true,
      "doc_id": "c6d1cbd88bf6d37c3fbe938ce800f670",
      "summary": "The performance of off-policy learning, including deep Q-learning and deep deterministic policy gradient (DDPG), critically depends on the choice of the exploration policy. Existing exploration methods are mostly based on adding noise to the on-going actor policy and can only explore \\emph{local} regions close to what the actor policy dictates. In this work, we develop a simple meta-policy gradient algorithm that allows us to adaptively learn the exploration policy in DDPG. Our algorithm allows us to train flexible exploration behaviors that are independent of the actor policy, yielding a \\emph{global exploration} that significantly speeds up the learning process. With an extensive study, we show that our method significantly improves the sample-efficiency of DDPG on a variety of reinforcement learning tasks.",
      "intriguing_abstract": "The performance of off-policy learning, including deep Q-learning and deep deterministic policy gradient (DDPG), critically depends on the choice of the exploration policy. Existing exploration methods are mostly based on adding noise to the on-going actor policy and can only explore \\emph{local} regions close to what the actor policy dictates. In this work, we develop a simple meta-policy gradient algorithm that allows us to adaptively learn the exploration policy in DDPG. Our algorithm allows us to train flexible exploration behaviors that are independent of the actor policy, yielding a \\emph{global exploration} that significantly speeds up the learning process. With an extensive study, we show that our method significantly improves the sample-efficiency of DDPG on a variety of reinforcement learning tasks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/7f567f1e8972ff31a7ced59c329e7d75da645baf.pdf",
      "citation_key": "xu2018rdh",
      "metadata": {
        "title": "Learning to Explore with Meta-Policy Gradient",
        "authors": [
          "Tianbing Xu",
          "Qiang Liu",
          "Liang Zhao",
          "Jian Peng"
        ],
        "published_date": "2018",
        "abstract": "The performance of off-policy learning, including deep Q-learning and deep deterministic policy gradient (DDPG), critically depends on the choice of the exploration policy. Existing exploration methods are mostly based on adding noise to the on-going actor policy and can only explore \\emph{local} regions close to what the actor policy dictates. In this work, we develop a simple meta-policy gradient algorithm that allows us to adaptively learn the exploration policy in DDPG. Our algorithm allows us to train flexible exploration behaviors that are independent of the actor policy, yielding a \\emph{global exploration} that significantly speeds up the learning process. With an extensive study, we show that our method significantly improves the sample-efficiency of DDPG on a variety of reinforcement learning tasks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/7f567f1e8972ff31a7ced59c329e7d75da645baf.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 54,
        "score": 7.7142857142857135,
        "summary": "The performance of off-policy learning, including deep Q-learning and deep deterministic policy gradient (DDPG), critically depends on the choice of the exploration policy. Existing exploration methods are mostly based on adding noise to the on-going actor policy and can only explore \\emph{local} regions close to what the actor policy dictates. In this work, we develop a simple meta-policy gradient algorithm that allows us to adaptively learn the exploration policy in DDPG. Our algorithm allows us to train flexible exploration behaviors that are independent of the actor policy, yielding a \\emph{global exploration} that significantly speeds up the learning process. With an extensive study, we show that our method significantly improves the sample-efficiency of DDPG on a variety of reinforcement learning tasks.",
        "keywords": []
      },
      "file_name": "7f567f1e8972ff31a7ced59c329e7d75da645baf.pdf"
    },
    {
      "success": true,
      "doc_id": "e88ccf00fcd317ff8ec2137db3c0cfd2",
      "summary": "In recent years, radar-based hand gesture recognition (HGR) has attracted much attention in the field of human-computer interaction (HCI) due to its benefits of high recognition accuracy and independence from lighting conditions. Conventional deep learning (DL) based models for HGR rely on a large amount of labelled data for training to achieve a satisfactory recognition accuracy. However, it is usually time-consuming and labor-intensive for collecting large amounts of radar data and also difficult to cover all possible hand gesture classes. In this paper, we introduce meta-learning to address the few-shot learning problem for frequency modulated continuous wave (FMCW) radar based HGR. We propose a meta-learning network to learn a model that can quickly adapt to unseen hand gesture tasks with few training observations. In particular, we propose a 3D convolutional neural network (CNN) based dual-channel fusion network for feature extraction by exploiting the correlations of multiple features in radar echo signals to improve the recognition accuracy. In addition, we also develop a learnable relation module with neural networks as a non-linear classifier to measure the similarity between the samples of different hand gestures, which can be more applicable for the HGR task. Finally, we evaluate the performance of the proposed model by conducting experiments on an FMCW radar hardware system. Experimental results show that the proposed meta-learning model substantially enhances the recognition accuracy compared with the state-of-the-art methods including DL and meta-learning based models for FMCW radar-based HGR.",
      "intriguing_abstract": "In recent years, radar-based hand gesture recognition (HGR) has attracted much attention in the field of human-computer interaction (HCI) due to its benefits of high recognition accuracy and independence from lighting conditions. Conventional deep learning (DL) based models for HGR rely on a large amount of labelled data for training to achieve a satisfactory recognition accuracy. However, it is usually time-consuming and labor-intensive for collecting large amounts of radar data and also difficult to cover all possible hand gesture classes. In this paper, we introduce meta-learning to address the few-shot learning problem for frequency modulated continuous wave (FMCW) radar based HGR. We propose a meta-learning network to learn a model that can quickly adapt to unseen hand gesture tasks with few training observations. In particular, we propose a 3D convolutional neural network (CNN) based dual-channel fusion network for feature extraction by exploiting the correlations of multiple features in radar echo signals to improve the recognition accuracy. In addition, we also develop a learnable relation module with neural networks as a non-linear classifier to measure the similarity between the samples of different hand gestures, which can be more applicable for the HGR task. Finally, we evaluate the performance of the proposed model by conducting experiments on an FMCW radar hardware system. Experimental results show that the proposed meta-learning model substantially enhances the recognition accuracy compared with the state-of-the-art methods including DL and meta-learning based models for FMCW radar-based HGR.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/84600a7e8737b525d3bb86545b2859379ed084aa.pdf",
      "citation_key": "shen2022kdk",
      "metadata": {
        "title": "ML-HGR-Net: A Meta-Learning Network for FMCW Radar Based Hand Gesture Recognition",
        "authors": [
          "Xiangyu Shen",
          "Haifeng Zheng",
          "Xinxin Feng",
          "Jin-Jia Hu"
        ],
        "published_date": "2022",
        "abstract": "In recent years, radar-based hand gesture recognition (HGR) has attracted much attention in the field of human-computer interaction (HCI) due to its benefits of high recognition accuracy and independence from lighting conditions. Conventional deep learning (DL) based models for HGR rely on a large amount of labelled data for training to achieve a satisfactory recognition accuracy. However, it is usually time-consuming and labor-intensive for collecting large amounts of radar data and also difficult to cover all possible hand gesture classes. In this paper, we introduce meta-learning to address the few-shot learning problem for frequency modulated continuous wave (FMCW) radar based HGR. We propose a meta-learning network to learn a model that can quickly adapt to unseen hand gesture tasks with few training observations. In particular, we propose a 3D convolutional neural network (CNN) based dual-channel fusion network for feature extraction by exploiting the correlations of multiple features in radar echo signals to improve the recognition accuracy. In addition, we also develop a learnable relation module with neural networks as a non-linear classifier to measure the similarity between the samples of different hand gestures, which can be more applicable for the HGR task. Finally, we evaluate the performance of the proposed model by conducting experiments on an FMCW radar hardware system. Experimental results show that the proposed meta-learning model substantially enhances the recognition accuracy compared with the state-of-the-art methods including DL and meta-learning based models for FMCW radar-based HGR.",
        "file_path": "paper_data/Deep_Meta-Learning/info/84600a7e8737b525d3bb86545b2859379ed084aa.pdf",
        "venue": "IEEE Sensors Journal",
        "citationCount": 23,
        "score": 7.666666666666666,
        "summary": "In recent years, radar-based hand gesture recognition (HGR) has attracted much attention in the field of human-computer interaction (HCI) due to its benefits of high recognition accuracy and independence from lighting conditions. Conventional deep learning (DL) based models for HGR rely on a large amount of labelled data for training to achieve a satisfactory recognition accuracy. However, it is usually time-consuming and labor-intensive for collecting large amounts of radar data and also difficult to cover all possible hand gesture classes. In this paper, we introduce meta-learning to address the few-shot learning problem for frequency modulated continuous wave (FMCW) radar based HGR. We propose a meta-learning network to learn a model that can quickly adapt to unseen hand gesture tasks with few training observations. In particular, we propose a 3D convolutional neural network (CNN) based dual-channel fusion network for feature extraction by exploiting the correlations of multiple features in radar echo signals to improve the recognition accuracy. In addition, we also develop a learnable relation module with neural networks as a non-linear classifier to measure the similarity between the samples of different hand gestures, which can be more applicable for the HGR task. Finally, we evaluate the performance of the proposed model by conducting experiments on an FMCW radar hardware system. Experimental results show that the proposed meta-learning model substantially enhances the recognition accuracy compared with the state-of-the-art methods including DL and meta-learning based models for FMCW radar-based HGR.",
        "keywords": []
      },
      "file_name": "84600a7e8737b525d3bb86545b2859379ed084aa.pdf"
    },
    {
      "success": true,
      "doc_id": "acd2f4acdfb9aeaf1c941c29404f8f93",
      "summary": "Deep Learning techniques have been widely used in detecting anomalies from complex data. Most of these techniques are either unsupervised or semi-supervised because of a lack of a large number of labeled anomalies. However, they typically rely on a clean training data not polluted by anomalies to learn the distribution of the normal data. Otherwise, the learned distribution tends to be distorted and hence ineffective in distinguishing between normal and abnormal data. To solve this problem, we propose a novel approach called ELITE that uses a small number of labeled examples to infer the anomalies hidden in the training samples. It then turns these anomalies into useful signals that help to better detect anomalies from user data. Unlike the classical semi-supervised classification strategy which uses labeled examples as training data, ELITE uses them as validation set. It leverages the gradient of the validation loss to predict if one training sample is abnormal. The intuition is that correctly identifying the hidden anomalies could produce a better deep anomaly model with reduced validation loss. Our experiments on public benchmark datasets show that ELITE achieves up to 30% improvement in ROC AUC comparing to the state-of-the-art, yet robust to polluted training data.",
      "intriguing_abstract": "Deep Learning techniques have been widely used in detecting anomalies from complex data. Most of these techniques are either unsupervised or semi-supervised because of a lack of a large number of labeled anomalies. However, they typically rely on a clean training data not polluted by anomalies to learn the distribution of the normal data. Otherwise, the learned distribution tends to be distorted and hence ineffective in distinguishing between normal and abnormal data. To solve this problem, we propose a novel approach called ELITE that uses a small number of labeled examples to infer the anomalies hidden in the training samples. It then turns these anomalies into useful signals that help to better detect anomalies from user data. Unlike the classical semi-supervised classification strategy which uses labeled examples as training data, ELITE uses them as validation set. It leverages the gradient of the validation loss to predict if one training sample is abnormal. The intuition is that correctly identifying the hidden anomalies could produce a better deep anomaly model with reduced validation loss. Our experiments on public benchmark datasets show that ELITE achieves up to 30% improvement in ROC AUC comparing to the state-of-the-art, yet robust to polluted training data.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/0d13ff7e27e0a1fb06c57efaeacfc90ccaef3452.pdf",
      "citation_key": "zhang2021hh1",
      "metadata": {
        "title": "ELITE: Robust Deep Anomaly Detection with Meta Gradient",
        "authors": [
          "Huayi Zhang",
          "Lei Cao",
          "Peter M. VanNostrand",
          "S. Madden",
          "Elke A. Rundensteiner"
        ],
        "published_date": "2021",
        "abstract": "Deep Learning techniques have been widely used in detecting anomalies from complex data. Most of these techniques are either unsupervised or semi-supervised because of a lack of a large number of labeled anomalies. However, they typically rely on a clean training data not polluted by anomalies to learn the distribution of the normal data. Otherwise, the learned distribution tends to be distorted and hence ineffective in distinguishing between normal and abnormal data. To solve this problem, we propose a novel approach called ELITE that uses a small number of labeled examples to infer the anomalies hidden in the training samples. It then turns these anomalies into useful signals that help to better detect anomalies from user data. Unlike the classical semi-supervised classification strategy which uses labeled examples as training data, ELITE uses them as validation set. It leverages the gradient of the validation loss to predict if one training sample is abnormal. The intuition is that correctly identifying the hidden anomalies could produce a better deep anomaly model with reduced validation loss. Our experiments on public benchmark datasets show that ELITE achieves up to 30% improvement in ROC AUC comparing to the state-of-the-art, yet robust to polluted training data.",
        "file_path": "paper_data/Deep_Meta-Learning/info/0d13ff7e27e0a1fb06c57efaeacfc90ccaef3452.pdf",
        "venue": "Knowledge Discovery and Data Mining",
        "citationCount": 30,
        "score": 7.5,
        "summary": "Deep Learning techniques have been widely used in detecting anomalies from complex data. Most of these techniques are either unsupervised or semi-supervised because of a lack of a large number of labeled anomalies. However, they typically rely on a clean training data not polluted by anomalies to learn the distribution of the normal data. Otherwise, the learned distribution tends to be distorted and hence ineffective in distinguishing between normal and abnormal data. To solve this problem, we propose a novel approach called ELITE that uses a small number of labeled examples to infer the anomalies hidden in the training samples. It then turns these anomalies into useful signals that help to better detect anomalies from user data. Unlike the classical semi-supervised classification strategy which uses labeled examples as training data, ELITE uses them as validation set. It leverages the gradient of the validation loss to predict if one training sample is abnormal. The intuition is that correctly identifying the hidden anomalies could produce a better deep anomaly model with reduced validation loss. Our experiments on public benchmark datasets show that ELITE achieves up to 30% improvement in ROC AUC comparing to the state-of-the-art, yet robust to polluted training data.",
        "keywords": []
      },
      "file_name": "0d13ff7e27e0a1fb06c57efaeacfc90ccaef3452.pdf"
    },
    {
      "success": true,
      "doc_id": "78fb29c3e2e1feb2303c33be4c5277e8",
      "summary": "Image-based deep learning method for plant disease diagnosing is promising but relies on large-scale dataset. Currently, the shortage of data has become an obstacle to leverage deep learning methods. Few-shot learning can generalize to new categories with the supports of few samples, which is very helpful for those plant disease categories where only few samples are available. However, two challenging problems are existing in few-shot learning: (1) the feature extracted from few shots is very limited; (2) generalizing to new categories, especially to another domain is very tough. In response to the two issues, we propose a network based on the Meta-Baseline few-shot learning method, and combine cascaded multi-scale features and channel attention. The network takes advantage of multi-scale features to rich the feature representation, uses channel attention as a compensation module efficiently to learn more from the significant channels of the fused features. Meanwhile, we propose a group of training strategies from data configuration perspective to match various generalization requirements. Through extensive experiments, it is verified that the combination of multi-scale feature fusion and channel attention can alleviate the problem of limited features caused by few shots. To imitate different generalization scenarios, we set different data settings and suggest the optimal training strategies for intra-domain case and cross-domain case, respectively. The effects of important factors in few-shot learning paradigm are analyzed. With the optimal configuration, the accuracy of 1-shot task and 5-shot task achieve at 61.24% and 77.43% respectively in the task targeting to single-plant, and achieve at 82.52% and 92.83% in the task targeting to multi-plants. Our results outperform the existing related works. It demonstrates that the few-shot learning is a feasible potential solution for plant disease recognition in the future application.",
      "intriguing_abstract": "Image-based deep learning method for plant disease diagnosing is promising but relies on large-scale dataset. Currently, the shortage of data has become an obstacle to leverage deep learning methods. Few-shot learning can generalize to new categories with the supports of few samples, which is very helpful for those plant disease categories where only few samples are available. However, two challenging problems are existing in few-shot learning: (1) the feature extracted from few shots is very limited; (2) generalizing to new categories, especially to another domain is very tough. In response to the two issues, we propose a network based on the Meta-Baseline few-shot learning method, and combine cascaded multi-scale features and channel attention. The network takes advantage of multi-scale features to rich the feature representation, uses channel attention as a compensation module efficiently to learn more from the significant channels of the fused features. Meanwhile, we propose a group of training strategies from data configuration perspective to match various generalization requirements. Through extensive experiments, it is verified that the combination of multi-scale feature fusion and channel attention can alleviate the problem of limited features caused by few shots. To imitate different generalization scenarios, we set different data settings and suggest the optimal training strategies for intra-domain case and cross-domain case, respectively. The effects of important factors in few-shot learning paradigm are analyzed. With the optimal configuration, the accuracy of 1-shot task and 5-shot task achieve at 61.24% and 77.43% respectively in the task targeting to single-plant, and achieve at 82.52% and 92.83% in the task targeting to multi-plants. Our results outperform the existing related works. It demonstrates that the few-shot learning is a feasible potential solution for plant disease recognition in the future application.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/447d48d47d8854a5224138ea5def956c69932738.pdf",
      "citation_key": "lin2022i6k",
      "metadata": {
        "title": "Few-shot learning approach with multi-scale feature fusion and attention for plant disease recognition",
        "authors": [
          "Hong Lin",
          "Rita Tse",
          "Su-Kit Tang",
          "Z. Qiang",
          "Giovanni Pau"
        ],
        "published_date": "2022",
        "abstract": "Image-based deep learning method for plant disease diagnosing is promising but relies on large-scale dataset. Currently, the shortage of data has become an obstacle to leverage deep learning methods. Few-shot learning can generalize to new categories with the supports of few samples, which is very helpful for those plant disease categories where only few samples are available. However, two challenging problems are existing in few-shot learning: (1) the feature extracted from few shots is very limited; (2) generalizing to new categories, especially to another domain is very tough. In response to the two issues, we propose a network based on the Meta-Baseline few-shot learning method, and combine cascaded multi-scale features and channel attention. The network takes advantage of multi-scale features to rich the feature representation, uses channel attention as a compensation module efficiently to learn more from the significant channels of the fused features. Meanwhile, we propose a group of training strategies from data configuration perspective to match various generalization requirements. Through extensive experiments, it is verified that the combination of multi-scale feature fusion and channel attention can alleviate the problem of limited features caused by few shots. To imitate different generalization scenarios, we set different data settings and suggest the optimal training strategies for intra-domain case and cross-domain case, respectively. The effects of important factors in few-shot learning paradigm are analyzed. With the optimal configuration, the accuracy of 1-shot task and 5-shot task achieve at 61.24% and 77.43% respectively in the task targeting to single-plant, and achieve at 82.52% and 92.83% in the task targeting to multi-plants. Our results outperform the existing related works. It demonstrates that the few-shot learning is a feasible potential solution for plant disease recognition in the future application.",
        "file_path": "paper_data/Deep_Meta-Learning/info/447d48d47d8854a5224138ea5def956c69932738.pdf",
        "venue": "Frontiers in Plant Science",
        "citationCount": 22,
        "score": 7.333333333333333,
        "summary": "Image-based deep learning method for plant disease diagnosing is promising but relies on large-scale dataset. Currently, the shortage of data has become an obstacle to leverage deep learning methods. Few-shot learning can generalize to new categories with the supports of few samples, which is very helpful for those plant disease categories where only few samples are available. However, two challenging problems are existing in few-shot learning: (1) the feature extracted from few shots is very limited; (2) generalizing to new categories, especially to another domain is very tough. In response to the two issues, we propose a network based on the Meta-Baseline few-shot learning method, and combine cascaded multi-scale features and channel attention. The network takes advantage of multi-scale features to rich the feature representation, uses channel attention as a compensation module efficiently to learn more from the significant channels of the fused features. Meanwhile, we propose a group of training strategies from data configuration perspective to match various generalization requirements. Through extensive experiments, it is verified that the combination of multi-scale feature fusion and channel attention can alleviate the problem of limited features caused by few shots. To imitate different generalization scenarios, we set different data settings and suggest the optimal training strategies for intra-domain case and cross-domain case, respectively. The effects of important factors in few-shot learning paradigm are analyzed. With the optimal configuration, the accuracy of 1-shot task and 5-shot task achieve at 61.24% and 77.43% respectively in the task targeting to single-plant, and achieve at 82.52% and 92.83% in the task targeting to multi-plants. Our results outperform the existing related works. It demonstrates that the few-shot learning is a feasible potential solution for plant disease recognition in the future application.",
        "keywords": []
      },
      "file_name": "447d48d47d8854a5224138ea5def956c69932738.pdf"
    },
    {
      "success": true,
      "doc_id": "0767b82559bdfea65be79dc9a52f4db7",
      "summary": "With the growing attention on learning-to-learn new tasks using only a few examples, meta-learning has been widely used in numerous problems such as few-shot classification, reinforcement learning, and domain generalization. However, meta-learning models are prone to overfitting when there are no sufficient training tasks for the meta-learners to generalize. Although existing approaches such as Dropout are widely used to address the overfitting problem, these methods are typically designed for regularizing models of a single task in supervised training. In this paper, we introduce a simple yet effective method to alleviate the risk of overfitting for gradient-based meta-learning. Specifically, during the gradient-based adaptation stage, we randomly drop the gradient in the inner-loop optimization of each parameter in deep neural networks, such that the augmented gradients improve generalization to new tasks. We present a general form of the proposed gradient dropout regularization and show that this term can be sampled from either the Bernoulli or Gaussian distribution. To validate the proposed method, we conduct extensive experiments and analysis on numerous computer vision tasks, demonstrating that the gradient dropout regularization mitigates the overfitting problem and improves the performance upon various gradient-based meta-learning frameworks.",
      "intriguing_abstract": "With the growing attention on learning-to-learn new tasks using only a few examples, meta-learning has been widely used in numerous problems such as few-shot classification, reinforcement learning, and domain generalization. However, meta-learning models are prone to overfitting when there are no sufficient training tasks for the meta-learners to generalize. Although existing approaches such as Dropout are widely used to address the overfitting problem, these methods are typically designed for regularizing models of a single task in supervised training. In this paper, we introduce a simple yet effective method to alleviate the risk of overfitting for gradient-based meta-learning. Specifically, during the gradient-based adaptation stage, we randomly drop the gradient in the inner-loop optimization of each parameter in deep neural networks, such that the augmented gradients improve generalization to new tasks. We present a general form of the proposed gradient dropout regularization and show that this term can be sampled from either the Bernoulli or Gaussian distribution. To validate the proposed method, we conduct extensive experiments and analysis on numerous computer vision tasks, demonstrating that the gradient dropout regularization mitigates the overfitting problem and improves the performance upon various gradient-based meta-learning frameworks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/7b201e42e32430d951458916810a7dbf1e946a6d.pdf",
      "citation_key": "tseng2020m83",
      "metadata": {
        "title": "Regularizing Meta-Learning via Gradient Dropout",
        "authors": [
          "Hung-Yu Tseng",
          "Yi-Wen Chen",
          "Yi-Hsuan Tsai",
          "Sifei Liu",
          "Yen-Yu Lin",
          "Ming-Hsuan Yang"
        ],
        "published_date": "2020",
        "abstract": "With the growing attention on learning-to-learn new tasks using only a few examples, meta-learning has been widely used in numerous problems such as few-shot classification, reinforcement learning, and domain generalization. However, meta-learning models are prone to overfitting when there are no sufficient training tasks for the meta-learners to generalize. Although existing approaches such as Dropout are widely used to address the overfitting problem, these methods are typically designed for regularizing models of a single task in supervised training. In this paper, we introduce a simple yet effective method to alleviate the risk of overfitting for gradient-based meta-learning. Specifically, during the gradient-based adaptation stage, we randomly drop the gradient in the inner-loop optimization of each parameter in deep neural networks, such that the augmented gradients improve generalization to new tasks. We present a general form of the proposed gradient dropout regularization and show that this term can be sampled from either the Bernoulli or Gaussian distribution. To validate the proposed method, we conduct extensive experiments and analysis on numerous computer vision tasks, demonstrating that the gradient dropout regularization mitigates the overfitting problem and improves the performance upon various gradient-based meta-learning frameworks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/7b201e42e32430d951458916810a7dbf1e946a6d.pdf",
        "venue": "Asian Conference on Computer Vision",
        "citationCount": 36,
        "score": 7.2,
        "summary": "With the growing attention on learning-to-learn new tasks using only a few examples, meta-learning has been widely used in numerous problems such as few-shot classification, reinforcement learning, and domain generalization. However, meta-learning models are prone to overfitting when there are no sufficient training tasks for the meta-learners to generalize. Although existing approaches such as Dropout are widely used to address the overfitting problem, these methods are typically designed for regularizing models of a single task in supervised training. In this paper, we introduce a simple yet effective method to alleviate the risk of overfitting for gradient-based meta-learning. Specifically, during the gradient-based adaptation stage, we randomly drop the gradient in the inner-loop optimization of each parameter in deep neural networks, such that the augmented gradients improve generalization to new tasks. We present a general form of the proposed gradient dropout regularization and show that this term can be sampled from either the Bernoulli or Gaussian distribution. To validate the proposed method, we conduct extensive experiments and analysis on numerous computer vision tasks, demonstrating that the gradient dropout regularization mitigates the overfitting problem and improves the performance upon various gradient-based meta-learning frameworks.",
        "keywords": []
      },
      "file_name": "7b201e42e32430d951458916810a7dbf1e946a6d.pdf"
    },
    {
      "success": true,
      "doc_id": "a83630fc0d37bdb5748a2ad7ec4a9cad",
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n---\n\n### Analysis of \"A Comprehensive Overview and Survey of Recent Advances in Meta-Learning\" \\cite{peng20209of}\n\n**1. Research Problem & Motivation**\n*   **Specific Technical Problem:** The paper addresses the challenge of enabling machine learning models to rapidly and accurately adapt to *unseen* and *vastly different* tasks, particularly in scenarios characterized by *few-shot* high-dimensional datasets \\cite{peng20209of}.\n*   **Importance & Challenge:**\n    *   Traditional deep learning models primarily focus on in-sample prediction and demand extensive labeled data, rendering them ineffective for few-shot or out-of-distribution tasks \\cite{peng20209of}.\n    *   Achieving highly autonomous AI necessitates models capable of continuous self-improvement and dynamic adaptation without the prohibitive cost of re-training from scratch \\cite{peng20209of}.\n    *   Many complex tasks are intractable when models are trained from scratch; meta-learning aims to solve these by leveraging past experiences and identifying deep similarity relations across tasks \\cite{peng20209of}.\n    *   The goal is to mimic human-like learning, where new concepts are acquired from minimal demonstrations and prior knowledge is efficiently applied \\cite{peng20209of}.\n\n**2. Related Work & Positioning**\n*   **Relation to Existing Approaches:**\n    *   **Deep Learning:** Meta-learning serves as a crucial generalization block, extending deep learning's capabilities to out-of-sample prediction and few-shot learning, where deep learning alone falls short \\cite{peng20209of}.\n    *   **Transfer Learning:** While both involve adapting pre-trained models, meta-learning distinguishes itself by focusing on adaptation to *vastly different* tasks through the discovery of fundamental similarity structures, whereas transfer learning typically targets *similar* tasks \\cite{peng20209of}.\n    *   **Lifelong Learning:** Shares the goal of developing a general framework applicable across diverse settings, but meta-learning specifically emphasizes mining fundamental rules and adaptable machine learning structures \\cite{peng20209of}.\n    *   **Early Meta-learning:** The field's origins include significant work on hyper-parameter optimization and autonomous model selection (e.g., AutoML) \\cite{peng20209of}.\n*   **Limitations of Previous Solutions:**\n    *   Deep learning models inherently lack mechanisms for robust generalization to out-of-distribution scenarios and are heavily reliant on large datasets \\cite{peng20209of}.\n    *   Training reinforcement learning models from scratch is computationally expensive and often yields insufficient solutions for highly complex tasks \\cite{peng20209of}.\n    *   Transfer learning can suffer from \"negative transfer\" when the source and target tasks are too dissimilar, leading to degraded performance \\cite{peng20209of}.\n\n**3. Technical Approach & Innovation**\n*   **Core Technical Methods:** The paper surveys meta-learning methodologies, broadly categorizing them into:\n    *   **Black-box Meta-learning:** Approaches that generalize deep learning models to unseen tasks by treating the base learner as a black box \\cite{peng20209of}.\n    *   **Metric-based Meta-learning:** Methods that jointly train feature extraction mechanisms and distance measures to explicitly model and leverage task similarity (e.g., Siamese, Matching, Prototypical networks) \\cite{peng20209of}.\n    *   **Layered Meta-learning:** Architectures comprising a task-specific \"base learner\" and one or more \"meta-learners\" designed to capture shared similarities across tasks, often involving multiple layers for different generalization scopes (e.g., meta-LSTM, MAML) \\cite{peng20209of}.\n    *   **Bayesian Meta-learning:** Frameworks that integrate probabilistic methodologies for uncertainty estimation and can employ generative models to augment training data \\cite{peng20209of}.\n*   **Novelty/Differentiation:**\n    *   **Explicit/Implicit Task Similarity Modeling:** A core innovation is the ability to model similarity between tasks, either explicitly through metrics or implicitly through meta-learners, enabling adaptation to vastly different scenarios \\cite{peng20209of}.\n    *   **Model-Agnosticism:** Approaches like MAML (Model-Agnostic Meta-Learning) \\cite{peng20209of} are highlighted for their broad applicability to any learner model optimized with stochastic gradient descent, offering significant flexibility.\n    *   **Continual Self-Improvement:** The integration of evolutionary algorithms and agent-environment interaction drives continual self-improvement, providing solutions for complex tasks that are otherwise unreachable \\cite{peng20209of}.\n    *   **Integrated Problem Solutions:** Recent advances focus on integrating meta-learning with other machine learning frameworks (e.g., meta-reinforcement learning, meta-imitation learning) to provide feasible solutions for complex applications like robotics \\cite{peng20209of}.\n\n**4. Key Technical Contributions**\n*   **Novel Algorithms, Methods, or Techniques:**\n    *   Provides a comprehensive categorization and overview of diverse meta-learning methodologies, including black-box, metric-based, layered, and Bayesian frameworks \\cite{peng20209of}.\n    *   Emphasizes Model-Agnostic Meta-Learning (MAML) as a significant advancement due to its broad applicability to SGD-optimized learners \\cite{peng20209of}.\n    *   Discusses methods that autonomously learn optimizers, demonstrating potential for faster convergence compared to standard stochastic gradient descent \\cite{peng20209of}.\n*   **System Design or Architectural Innovations:**\n    *   Introduces the concept of a meta-hierarchy, consisting of base learners and multiple levels of meta-learners, designed for effective task decomposition and generalization \\cite{peng20209of}.\n    *   Positions meta-learning as an essential generalization block for deep learning models, enabling them to handle out-of-distribution tasks more effectively \\cite{peng20209of}.\n    *   Highlights architectures like Memory-augmented Neural Networks (MANN) that store and retrieve relevant past model experiences for efficient adaptation to new tasks \\cite{peng20209of}.\n*   **Theoretical Insights or Analysis:**\n    *   Formalizes meta-learning as \"learning-to-learn,\" emphasizing its goal of rapid and accurate adaptation to unseen tasks \\cite{peng20209of}.\n    *   Underlines the critical role of modeling task similarity (either explicitly through metrics or implicitly through meta-learners) as a fundamental principle for effective generalization \\cite{peng20209of}.\n    *   Clearly distinguishes meta-learning from transfer learning based on the degree of task dissimilarity they are designed to handle, providing a clearer conceptual boundary \\cite{peng20209of}.\n\n**5. Experimental Validation**\n*   As a survey paper, this article *reviews* the empirical evidence and performance claims from the literature rather than presenting new experimental results.\n*   **Key Performance Metrics and Comparison Results (as discussed in the survey):**\n    *   **Few-shot Learning:** Meta-learning methods are shown to effectively provide representation models for few-shot tasks (N-class K-shot problems with K<10) without requiring large amounts of labeled data, a significant advantage over traditional deep learning \\cite{peng20209of}.\n    *   **Convergence Speed:** Approaches that autonomously learn optimizers (e.g., in meta-imitation learning) have demonstrated faster convergence and superior performance compared to standard stochastic gradient descent \\cite{peng20209of}.\n    *   **Generalization Capability:** Meta-learning, particularly when combined with coevolutionary schemes, has been shown to provide predictive solutions for complex environments that are otherwise unreachable by training from scratch, indicating strong generalization to out-of-distribution tasks \\cite{peng20209of}.\n    *   **Prediction Accuracy:** The integration of meta-learning with domain adaptation techniques has led to improved prediction accuracy in few-shot image classification tasks \\cite{peng20209of}.\n    *   **Computational Efficiency:** Meta-learning offers benefits in saving computation by avoiding the need to re-train deep models from scratch and by increasing reaction speed through rapid adaptation to dynamic environmental conditions \\cite{peng20209of}.\n\n**6. Limitations & Scope**\n*   **Technical Limitations or Assumptions:**\n    *   A fundamental assumption underlying meta-learning is that tasks share a *sufficient degree of similarity* to be solvable within a common meta-learning framework \\cite{peng20209of}. The effectiveness of the approach hinges on the ability to accurately model this similarity.\n    *   The distinctions between various meta-learning methodologies are not always rigid, and methods frequently combine, suggesting that a single, universally optimal framework is yet to be established \\cite{peng20209of}.\n*   **Scope of Applicability:**\n    *   The paper primarily focuses on applications in highly automated AI, few-shot learning (especially image classification), natural language processing, and robotics (through meta-reinforcement learning and meta-imitation learning) \\cite{peng20209of}.\n    *   Meta-learning is particularly applicable to scenarios demanding rapid adaptation to unseen tasks and robust predictive performance in out-of-distribution situations \\cite{peng20209of}.\n    *   Model-agnostic approaches like MAML extend its applicability to any learner model that can be optimized using stochastic gradient descent \\cite{peng20209of}.\n\n**7. Technical Significance**\n*   **Advancement of the Technical State-of-the-Art:**\n    *   Establishes meta-learning as a pivotal paradigm for achieving strong AI by enabling models to \"learn how to learn\" and engage in continuous self-improvement \\cite{peng20209of}.\n    *   Offers a robust framework for addressing data scarcity in high-dimensional, few-shot learning problems, a critical limitation for conventional deep learning \\cite{peng20209of}.\n    *   Provides solutions for complex, dynamic environments where training from scratch is impractical or insufficient, particularly through coevolutionary and adaptive mechanisms \\cite{peng20209of}.\n    *   Expands the scope of meta-learning beyond simple hyper-parameter optimization to include autonomous model selection, optimizer learning, and deep model adaptation across vastly different tasks \\cite{peng20209of}.\n*   **Potential Impact on Future Research:**\n    *   Encourages further integration of meta-learning with other advanced ML frameworks (e.g., reinforcement learning, imitation learning, unsupervised learning) to foster the development of more autonomous and intelligent agents \\cite{peng20209of}.\n    *   Promotes research into more sophisticated and flexible methods for modeling task similarity, aiming to relax current assumptions and enhance generalization across an even wider spectrum of diverse tasks \\cite{peng20209of}.\n    *   Drives the development of advanced AutoML systems capable of efficiently searching for optimal neural architectures and parameters with minimal human intervention \\cite{peng20209of}.\n    *   Highlights the importance of developing meta-learning solutions for online and unsupervised settings, thereby extending its applicability to real-world, continuously evolving data streams \\cite{peng20209of}.\n\n---",
      "intriguing_abstract": "The quest for truly autonomous AI hinges on models that can rapidly adapt to novel, unseen tasks with minimal data, a challenge where traditional deep learning often falters. This comprehensive survey delves into the transformative paradigm of **meta-learning**, or \"learning-to-learn,\" which empowers models to acquire new skills from few examples by leveraging deep similarity relations across diverse tasks. We meticulously categorize recent advances, exploring **black-box**, **metric-based** (e.g., Prototypical Networks), **layered** (e.g., **Model-Agnostic Meta-Learning (MAML)**), and **Bayesian meta-learning** frameworks. A core innovation lies in explicitly or implicitly modeling **task similarity**, enabling robust **few-shot learning** and **out-of-distribution generalization** far beyond the capabilities of conventional **transfer learning**. This paper highlights how meta-learning, through mechanisms like autonomously learned optimizers and integration with **meta-reinforcement learning**, drives continuous self-improvement and provides feasible solutions for complex applications like **robotics** and advanced **AutoML**. By offering a foundational understanding of these methodologies, this survey illuminates meta-learning's pivotal role in shaping the next generation of intelligent, adaptable AI systems.",
      "keywords": [
        "Meta-learning",
        "Few-shot learning",
        "Rapid adaptation",
        "Out-of-distribution generalization",
        "Task similarity modeling",
        "Model-Agnostic Meta-Learning (MAML)",
        "Metric-based meta-learning",
        "Layered meta-learning",
        "Learning-to-learn",
        "Autonomous AI",
        "Meta-reinforcement learning",
        "Continuous self-improvement",
        "Computational efficiency",
        "Deep learning extension"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/d0eb13325d77e50a60102139e84484a9beaf62ff.pdf",
      "citation_key": "peng20209of",
      "metadata": {
        "title": "A Comprehensive Overview and Survey of Recent Advances in Meta-Learning",
        "authors": [
          "Huimin Peng"
        ],
        "published_date": "2020",
        "abstract": "This article reviews meta-learning also known as learning-to-learn which seeks rapid and accurate model adaptation to unseen tasks with applications in strong AI, few-shot learning, natural language processing and robotics. Unlike deep learning, meta-learning can be applied to few-shot high-dimensional datasets and considers further improving model generalization to unseen tasks. Deep learning is focused upon in-sample prediction and meta-learning concerns model adaptation for out-of-sample prediction. Meta-learning can continually perform self-improvement to achieve highly autonomous AI. Meta-learning may serve as an additional generalization block complementary for original deep learning model. Meta-learning seeks adaptation of machine learning models to unseen tasks which are vastly different from trained tasks. Meta-learning with coevolution between agent and environment provides solutions for complex tasks unsolvable by training from scratch. Meta-learning methodology covers a wide range of great minds and thoughts. We briefly summarize meta-learning methodologies into the following categories: black-box meta-learning, metric-based meta-learning, layered meta-learning and Bayesian meta-learning framework. Recent applications concentrate upon the integration of meta-learning with other machine learning framework to provide feasible integrated problem solutions. We briefly present recent meta-learning advances and discuss potential future research directions.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d0eb13325d77e50a60102139e84484a9beaf62ff.pdf",
        "venue": "arXiv.org",
        "citationCount": 36,
        "score": 7.2,
        "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n---\n\n### Analysis of \"A Comprehensive Overview and Survey of Recent Advances in Meta-Learning\" \\cite{peng20209of}\n\n**1. Research Problem & Motivation**\n*   **Specific Technical Problem:** The paper addresses the challenge of enabling machine learning models to rapidly and accurately adapt to *unseen* and *vastly different* tasks, particularly in scenarios characterized by *few-shot* high-dimensional datasets \\cite{peng20209of}.\n*   **Importance & Challenge:**\n    *   Traditional deep learning models primarily focus on in-sample prediction and demand extensive labeled data, rendering them ineffective for few-shot or out-of-distribution tasks \\cite{peng20209of}.\n    *   Achieving highly autonomous AI necessitates models capable of continuous self-improvement and dynamic adaptation without the prohibitive cost of re-training from scratch \\cite{peng20209of}.\n    *   Many complex tasks are intractable when models are trained from scratch; meta-learning aims to solve these by leveraging past experiences and identifying deep similarity relations across tasks \\cite{peng20209of}.\n    *   The goal is to mimic human-like learning, where new concepts are acquired from minimal demonstrations and prior knowledge is efficiently applied \\cite{peng20209of}.\n\n**2. Related Work & Positioning**\n*   **Relation to Existing Approaches:**\n    *   **Deep Learning:** Meta-learning serves as a crucial generalization block, extending deep learning's capabilities to out-of-sample prediction and few-shot learning, where deep learning alone falls short \\cite{peng20209of}.\n    *   **Transfer Learning:** While both involve adapting pre-trained models, meta-learning distinguishes itself by focusing on adaptation to *vastly different* tasks through the discovery of fundamental similarity structures, whereas transfer learning typically targets *similar* tasks \\cite{peng20209of}.\n    *   **Lifelong Learning:** Shares the goal of developing a general framework applicable across diverse settings, but meta-learning specifically emphasizes mining fundamental rules and adaptable machine learning structures \\cite{peng20209of}.\n    *   **Early Meta-learning:** The field's origins include significant work on hyper-parameter optimization and autonomous model selection (e.g., AutoML) \\cite{peng20209of}.\n*   **Limitations of Previous Solutions:**\n    *   Deep learning models inherently lack mechanisms for robust generalization to out-of-distribution scenarios and are heavily reliant on large datasets \\cite{peng20209of}.\n    *   Training reinforcement learning models from scratch is computationally expensive and often yields insufficient solutions for highly complex tasks \\cite{peng20209of}.\n    *   Transfer learning can suffer from \"negative transfer\" when the source and target tasks are too dissimilar, leading to degraded performance \\cite{peng20209of}.\n\n**3. Technical Approach & Innovation**\n*   **Core Technical Methods:** The paper surveys meta-learning methodologies, broadly categorizing them into:\n    *   **Black-box Meta-learning:** Approaches that generalize deep learning models to unseen tasks by treating the base learner as a black box \\cite{peng20209of}.\n    *   **Metric-based Meta-learning:** Methods that jointly train feature extraction mechanisms and distance measures to explicitly model and leverage task similarity (e.g., Siamese, Matching, Prototypical networks) \\cite{peng20209of}.\n    *   **Layered Meta-learning:** Architectures comprising a task-specific \"base learner\" and one or more \"meta-learners\" designed to capture shared similarities across tasks, often involving multiple layers for different generalization scopes (e.g., meta-LSTM, MAML) \\cite{peng20209of}.\n    *   **Bayesian Meta-learning:** Frameworks that integrate probabilistic methodologies for uncertainty estimation and can employ generative models to augment training data \\cite{peng20209of}.\n*   **Novelty/Differentiation:**\n    *   **Explicit/Implicit Task Similarity Modeling:** A core innovation is the ability to model similarity between tasks, either explicitly through metrics or implicitly through meta-learners, enabling adaptation to vastly different scenarios \\cite{peng20209of}.\n    *   **Model-Agnosticism:** Approaches like MAML (Model-Agnostic Meta-Learning) \\cite{peng20209of} are highlighted for their broad applicability to any learner model optimized with stochastic gradient descent, offering significant flexibility.\n    *   **Continual Self-Improvement:** The integration of evolutionary algorithms and agent-environment interaction drives continual self-improvement, providing solutions for complex tasks that are otherwise unreachable \\cite{peng20209of}.\n    *   **Integrated Problem Solutions:** Recent advances focus on integrating meta-learning with other machine learning frameworks (e.g., meta-reinforcement learning, meta-imitation learning) to provide feasible solutions for complex applications like robotics \\cite{peng20209of}.\n\n**4. Key Technical Contributions**\n*   **Novel Algorithms, Methods, or Techniques:**\n    *   Provides a comprehensive categorization and overview of diverse meta-learning methodologies, including black-box, metric-based, layered, and Bayesian frameworks \\cite{peng20209of}.\n    *   Emphasizes Model-Agnostic Meta-Learning (MAML) as a significant advancement due to its broad applicability to SGD-optimized learners \\cite{peng20209of}.\n    *   Discusses methods that autonomously learn optimizers, demonstrating potential for faster convergence compared to standard stochastic gradient descent \\cite{peng20209of}.\n*   **System Design or Architectural Innovations:**\n    *   Introduces the concept of a meta-hierarchy, consisting of base learners and multiple levels of meta-learners, designed for effective task decomposition and generalization \\cite{peng20209of}.\n    *   Positions meta-learning as an essential generalization block for deep learning models, enabling them to handle out-of-distribution tasks more effectively \\cite{peng20209of}.\n    *   Highlights architectures like Memory-augmented Neural Networks (MANN) that store and retrieve relevant past model experiences for efficient adaptation to new tasks \\cite{peng20209of}.\n*   **Theoretical Insights or Analysis:**\n    *   Formalizes meta-learning as \"learning-to-learn,\" emphasizing its goal of rapid and accurate adaptation to unseen tasks \\cite{peng20209of}.\n    *   Underlines the critical role of modeling task similarity (either explicitly through metrics or implicitly through meta-learners) as a fundamental principle for effective generalization \\cite{peng20209of}.\n    *   Clearly distinguishes meta-learning from transfer learning based on the degree of task dissimilarity they are designed to handle, providing a clearer conceptual boundary \\cite{peng20209of}.\n\n**5. Experimental Validation**\n*   As a survey paper, this article *reviews* the empirical evidence and performance claims from the literature rather than presenting new experimental results.\n*   **Key Performance Metrics and Comparison Results (as discussed in the survey):**\n    *   **Few-shot Learning:** Meta-learning methods are shown to effectively provide representation models for few-shot tasks (N-class K-shot problems with K<10) without requiring large amounts of labeled data, a significant advantage over traditional deep learning \\cite{peng20209of}.\n    *   **Convergence Speed:** Approaches that autonomously learn optimizers (e.g., in meta-imitation learning) have demonstrated faster convergence and superior performance compared to standard stochastic gradient descent \\cite{peng20209of}.\n    *   **Generalization Capability:** Meta-learning, particularly when combined with coevolutionary schemes, has been shown to provide predictive solutions for complex environments that are otherwise unreachable by training from scratch, indicating strong generalization to out-of-distribution tasks \\cite{peng20209of}.\n    *   **Prediction Accuracy:** The integration of meta-learning with domain adaptation techniques has led to improved prediction accuracy in few-shot image classification tasks \\cite{peng20209of}.\n    *   **Computational Efficiency:** Meta-learning offers benefits in saving computation by avoiding the need to re-train deep models from scratch and by increasing reaction speed through rapid adaptation to dynamic environmental conditions \\cite{peng20209of}.\n\n**6. Limitations & Scope**\n*   **Technical Limitations or Assumptions:**\n    *   A fundamental assumption underlying meta-learning is that tasks share a *sufficient degree of similarity* to be solvable within a common meta-learning framework \\cite{peng20209of}. The effectiveness of the approach hinges on the ability to accurately model this similarity.\n    *   The distinctions between various meta-learning methodologies are not always rigid, and methods frequently combine, suggesting that a single, universally optimal framework is yet to be established \\cite{peng20209of}.\n*   **Scope of Applicability:**\n    *   The paper primarily focuses on applications in highly automated AI, few-shot learning (especially image classification), natural language processing, and robotics (through meta-reinforcement learning and meta-imitation learning) \\cite{peng20209of}.\n    *   Meta-learning is particularly applicable to scenarios demanding rapid adaptation to unseen tasks and robust predictive performance in out-of-distribution situations \\cite{peng20209of}.\n    *   Model-agnostic approaches like MAML extend its applicability to any learner model that can be optimized using stochastic gradient descent \\cite{peng20209of}.\n\n**7. Technical Significance**\n*   **Advancement of the Technical State-of-the-Art:**\n    *   Establishes meta-learning as a pivotal paradigm for achieving strong AI by enabling models to \"learn how to learn\" and engage in continuous self-improvement \\cite{peng20209of}.\n    *   Offers a robust framework for addressing data scarcity in high-dimensional, few-shot learning problems, a critical limitation for conventional deep learning \\cite{peng20209of}.\n    *   Provides solutions for complex, dynamic environments where training from scratch is impractical or insufficient, particularly through coevolutionary and adaptive mechanisms \\cite{peng20209of}.\n    *   Expands the scope of meta-learning beyond simple hyper-parameter optimization to include autonomous model selection, optimizer learning, and deep model adaptation across vastly different tasks \\cite{peng20209of}.\n*   **Potential Impact on Future Research:**\n    *   Encourages further integration of meta-learning with other advanced ML frameworks (e.g., reinforcement learning, imitation learning, unsupervised learning) to foster the development of more autonomous and intelligent agents \\cite{peng20209of}.\n    *   Promotes research into more sophisticated and flexible methods for modeling task similarity, aiming to relax current assumptions and enhance generalization across an even wider spectrum of diverse tasks \\cite{peng20209of}.\n    *   Drives the development of advanced AutoML systems capable of efficiently searching for optimal neural architectures and parameters with minimal human intervention \\cite{peng20209of}.\n    *   Highlights the importance of developing meta-learning solutions for online and unsupervised settings, thereby extending its applicability to real-world, continuously evolving data streams \\cite{peng20209of}.\n\n---",
        "keywords": [
          "Meta-learning",
          "Few-shot learning",
          "Rapid adaptation",
          "Out-of-distribution generalization",
          "Task similarity modeling",
          "Model-Agnostic Meta-Learning (MAML)",
          "Metric-based meta-learning",
          "Layered meta-learning",
          "Learning-to-learn",
          "Autonomous AI",
          "Meta-reinforcement learning",
          "Continuous self-improvement",
          "Computational efficiency",
          "Deep learning extension"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **survey**.\n\nhere's why:\n\n*   **title:** \"a comprehensive overview and **survey** of recent advances in meta-learning\" explicitly uses the word \"survey\".\n*   **abstract:**\n    *   \"this article **reviews** meta-learning...\"\n    *   \"we brieﬂy **introduce** meta-learning methodologies in the following categories...\" (indicating organization and presentation of existing knowledge)\n    *   \"we brieﬂy **present recent meta-learning advances and discuss potential future research directions**.\" (typical components of a survey)\n*   **introduction:**\n    *   provides historical context (\"meta-learning was ﬁrst proposed by jürgen schmidhuber in 1987 [ 1]\").\n    *   explains foundational concepts and related work (rnn, lstm, coevolution) with multiple citations, indicating a review of existing literature.\n\nthese points align perfectly with the criteria for a \"survey\" paper."
      },
      "file_name": "d0eb13325d77e50a60102139e84484a9beaf62ff.pdf"
    },
    {
      "success": true,
      "doc_id": "f9ef74d6ef683b5e6988945c156aa4b0",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/78d2f29d9b5af247250e04ae1e686b0c6886b2b1.pdf",
      "citation_key": "fong20183q5",
      "metadata": {
        "title": "How meta-heuristic algorithms contribute to deep learning in the hype of big data analytics",
        "authors": [
          "S. Fong",
          "S. Deb",
          "Xin-She Yang"
        ],
        "published_date": "2018",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/78d2f29d9b5af247250e04ae1e686b0c6886b2b1.pdf",
        "venue": "",
        "citationCount": 50,
        "score": 7.142857142857142,
        "summary": "",
        "keywords": []
      },
      "file_name": "78d2f29d9b5af247250e04ae1e686b0c6886b2b1.pdf"
    },
    {
      "success": true,
      "doc_id": "935bb1795507c6d7972da57d254e353b",
      "summary": "Convolutional Neural Networks have achieved remarkable success in face recognition, in part due to the abundant availability of data. However, the data used for training CNNs is often imbalanced. Prior works largely focus on the long-tailed nature of face datasets in data volume per identity, or focus on single bias variation. In this paper, we show that many bias variations such as ethnicity, head pose, occlusion and blur can jointly affect the accuracy significantly. We propose a sample level weighting approach termed Multi-variation Cosine Margin (MvCoM), to simultaneously consider the multiple variation factors, which orthogonally enhances the face recognition losses to incorporate the importance of training samples. Further, we leverage a learning to learn approach, guided by a held-out meta learning set and use an additive modeling to predict the MvCoM. Extensive experiments on challenging face recognition benchmarks demonstrate the advantages of our method in jointly handling imbalances due to multiple variations.",
      "intriguing_abstract": "Convolutional Neural Networks have achieved remarkable success in face recognition, in part due to the abundant availability of data. However, the data used for training CNNs is often imbalanced. Prior works largely focus on the long-tailed nature of face datasets in data volume per identity, or focus on single bias variation. In this paper, we show that many bias variations such as ethnicity, head pose, occlusion and blur can jointly affect the accuracy significantly. We propose a sample level weighting approach termed Multi-variation Cosine Margin (MvCoM), to simultaneously consider the multiple variation factors, which orthogonally enhances the face recognition losses to incorporate the importance of training samples. Further, we leverage a learning to learn approach, guided by a held-out meta learning set and use an additive modeling to predict the MvCoM. Extensive experiments on challenging face recognition benchmarks demonstrate the advantages of our method in jointly handling imbalances due to multiple variations.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/6ac73bcb953640dcc9c5b7f730f57ad135593d8e.pdf",
      "citation_key": "liu2022tgc",
      "metadata": {
        "title": "Learning to Learn across Diverse Data Biases in Deep Face Recognition",
        "authors": [
          "Chang Liu",
          "Xiang Yu",
          "Yao-Hung Hubert Tsai",
          "M. Faraki",
          "Ramin Moslemi",
          "Manmohan Chandraker",
          "Y. Fu"
        ],
        "published_date": "2022",
        "abstract": "Convolutional Neural Networks have achieved remarkable success in face recognition, in part due to the abundant availability of data. However, the data used for training CNNs is often imbalanced. Prior works largely focus on the long-tailed nature of face datasets in data volume per identity, or focus on single bias variation. In this paper, we show that many bias variations such as ethnicity, head pose, occlusion and blur can jointly affect the accuracy significantly. We propose a sample level weighting approach termed Multi-variation Cosine Margin (MvCoM), to simultaneously consider the multiple variation factors, which orthogonally enhances the face recognition losses to incorporate the importance of training samples. Further, we leverage a learning to learn approach, guided by a held-out meta learning set and use an additive modeling to predict the MvCoM. Extensive experiments on challenging face recognition benchmarks demonstrate the advantages of our method in jointly handling imbalances due to multiple variations.",
        "file_path": "paper_data/Deep_Meta-Learning/info/6ac73bcb953640dcc9c5b7f730f57ad135593d8e.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 21,
        "score": 7.0,
        "summary": "Convolutional Neural Networks have achieved remarkable success in face recognition, in part due to the abundant availability of data. However, the data used for training CNNs is often imbalanced. Prior works largely focus on the long-tailed nature of face datasets in data volume per identity, or focus on single bias variation. In this paper, we show that many bias variations such as ethnicity, head pose, occlusion and blur can jointly affect the accuracy significantly. We propose a sample level weighting approach termed Multi-variation Cosine Margin (MvCoM), to simultaneously consider the multiple variation factors, which orthogonally enhances the face recognition losses to incorporate the importance of training samples. Further, we leverage a learning to learn approach, guided by a held-out meta learning set and use an additive modeling to predict the MvCoM. Extensive experiments on challenging face recognition benchmarks demonstrate the advantages of our method in jointly handling imbalances due to multiple variations.",
        "keywords": []
      },
      "file_name": "6ac73bcb953640dcc9c5b7f730f57ad135593d8e.pdf"
    },
    {
      "success": true,
      "doc_id": "ce10490479295d48811f91b946838169",
      "summary": "Although deep reinforcement learning has recently been very successful at learning complex behaviors, it requires a tremendous amount of data to learn a task. One of the fundamental reasons causing this limitation lies in the nature of the trial-and-error learning paradigm of reinforcement learning, where the agent communicates with the environment and pro-gresses in the learning only relying on the reward signal. This is implicit and rather insufficient to learn a task well. On the con-trary, humans are usually taught new skills via natural language instructions. Utilizing language instructions for robotic motion control to improve the adaptability is a recently emerged topic and challenging. In this paper, we present a meta-RL algorithm that addresses the challenge of learning skills with language instructions in multiple manipulation tasks. On the one hand, our algorithm utilizes the language instructions to shape its in-terpretation of the task, on the other hand, it still learns to solve task in a trial-and-error process. We evaluate our algorithm on the robotic manipulation benchmark (Meta-World) and it significantly outperforms state-of-the-art methods in terms of training and testing task success rates. Codes are available at https://tumi6robot.wixsite.com/million.",
      "intriguing_abstract": "Although deep reinforcement learning has recently been very successful at learning complex behaviors, it requires a tremendous amount of data to learn a task. One of the fundamental reasons causing this limitation lies in the nature of the trial-and-error learning paradigm of reinforcement learning, where the agent communicates with the environment and pro-gresses in the learning only relying on the reward signal. This is implicit and rather insufficient to learn a task well. On the con-trary, humans are usually taught new skills via natural language instructions. Utilizing language instructions for robotic motion control to improve the adaptability is a recently emerged topic and challenging. In this paper, we present a meta-RL algorithm that addresses the challenge of learning skills with language instructions in multiple manipulation tasks. On the one hand, our algorithm utilizes the language instructions to shape its in-terpretation of the task, on the other hand, it still learns to solve task in a trial-and-error process. We evaluate our algorithm on the robotic manipulation benchmark (Meta-World) and it significantly outperforms state-of-the-art methods in terms of training and testing task success rates. Codes are available at https://tumi6robot.wixsite.com/million.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d1ad1bfa0bb76002b10e7f211b937842baeb28d9.pdf",
      "citation_key": "bing2022xo7",
      "metadata": {
        "title": "Meta-Reinforcement Learning via Language Instructions",
        "authors": [
          "Zhenshan Bing",
          "A. Koch",
          "Xiangtong Yao",
          "Kai Huang",
          "Alois Knoll"
        ],
        "published_date": "2022",
        "abstract": "Although deep reinforcement learning has recently been very successful at learning complex behaviors, it requires a tremendous amount of data to learn a task. One of the fundamental reasons causing this limitation lies in the nature of the trial-and-error learning paradigm of reinforcement learning, where the agent communicates with the environment and pro-gresses in the learning only relying on the reward signal. This is implicit and rather insufficient to learn a task well. On the con-trary, humans are usually taught new skills via natural language instructions. Utilizing language instructions for robotic motion control to improve the adaptability is a recently emerged topic and challenging. In this paper, we present a meta-RL algorithm that addresses the challenge of learning skills with language instructions in multiple manipulation tasks. On the one hand, our algorithm utilizes the language instructions to shape its in-terpretation of the task, on the other hand, it still learns to solve task in a trial-and-error process. We evaluate our algorithm on the robotic manipulation benchmark (Meta-World) and it significantly outperforms state-of-the-art methods in terms of training and testing task success rates. Codes are available at https://tumi6robot.wixsite.com/million.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d1ad1bfa0bb76002b10e7f211b937842baeb28d9.pdf",
        "venue": "IEEE International Conference on Robotics and Automation",
        "citationCount": 21,
        "score": 7.0,
        "summary": "Although deep reinforcement learning has recently been very successful at learning complex behaviors, it requires a tremendous amount of data to learn a task. One of the fundamental reasons causing this limitation lies in the nature of the trial-and-error learning paradigm of reinforcement learning, where the agent communicates with the environment and pro-gresses in the learning only relying on the reward signal. This is implicit and rather insufficient to learn a task well. On the con-trary, humans are usually taught new skills via natural language instructions. Utilizing language instructions for robotic motion control to improve the adaptability is a recently emerged topic and challenging. In this paper, we present a meta-RL algorithm that addresses the challenge of learning skills with language instructions in multiple manipulation tasks. On the one hand, our algorithm utilizes the language instructions to shape its in-terpretation of the task, on the other hand, it still learns to solve task in a trial-and-error process. We evaluate our algorithm on the robotic manipulation benchmark (Meta-World) and it significantly outperforms state-of-the-art methods in terms of training and testing task success rates. Codes are available at https://tumi6robot.wixsite.com/million.",
        "keywords": []
      },
      "file_name": "d1ad1bfa0bb76002b10e7f211b937842baeb28d9.pdf"
    },
    {
      "success": true,
      "doc_id": "a197f6295c354304fd9e35b8f8a2b4a9",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5ed35dc0dee7970d0408100ef152fca4b17bc637.pdf",
      "citation_key": "nakasi2020w5x",
      "metadata": {
        "title": "A new approach for microscopic diagnosis of malaria parasites in thick blood smears using pre-trained deep learning models",
        "authors": [
          "Rose Nakasi",
          "Ernest Mwebaze",
          "A. Zawedde",
          "Tusubira Francis Jeremy",
          "Benjamin Akera",
          "Gilbert Maiga"
        ],
        "published_date": "2020",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/5ed35dc0dee7970d0408100ef152fca4b17bc637.pdf",
        "venue": "SN Applied Sciences",
        "citationCount": 35,
        "score": 7.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "5ed35dc0dee7970d0408100ef152fca4b17bc637.pdf"
    },
    {
      "success": true,
      "doc_id": "4b9215aefbac75cdfefbb2929fd87dca",
      "summary": "Here's a focused summary of the paper \"HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks\" by Przewi˛e´zlikowski et al. \\cite{przewiezlikowski2022d4y} for a literature review:\n\n---\n\n### Technical Paper Analysis: HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks \\cite{przewiezlikowski2022d4y}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the limitation of Model-Agnostic Meta-Learning (MAML) in Few-Shot learning, where the gradient-based inner-loop adaptation may not sufficiently modify model weights for complex tasks in a few steps.\n    *   **Importance & Challenge:** Few-Shot learning aims to enable models to adapt to new tasks with minimal data, mimicking human learning. MAML, while elegant, struggles with tasks requiring significant weight shifts, leading to suboptimal performance, unstable training, and potential overfitting if many gradient steps are used. The challenge is to enable more substantial and efficient weight updates without the computational overhead and limitations of gradient descent.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** HyperMAML is positioned as a generalization of MAML, belonging to the optimization-based meta-learning family. It shares MAML's core idea of learning universal weights that are then adapted to specific tasks.\n    *   **Limitations of Previous Solutions (MAML):**\n        *   MAML relies on gradient descent for task-specific weight updates, which may not be powerful enough to make essential modifications in a few steps.\n        *   Using many gradient steps leads to a complex, time-consuming optimization procedure (second-order optimization) that is hard to train and prone to overfitting.\n        *   MAML's gradient-based updates are considered biologically implausible.\n    *   **HyperMAML's Distinction:** Unlike MAML, which uses gradient descent, HyperMAML employs a trainable Hypernetwork to directly generate weight updates in a single step. It differs from other meta-optimizers by not requiring loss calculation or gradient backpropagation during the update generation, making it more computationally efficient.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** HyperMAML replaces the gradient-based inner-loop adaptation of MAML with a trainable Hypernetwork.\n    *   **Mechanism:**\n        *   A base model `fθ` (target classifier) has universal parameters `θ`.\n        *   An encoder `Eγ` transforms support set examples into low-dimensional embeddings.\n        *   A Hypernetwork `Hη` takes as input the encoded support set embeddings, the base model's predictions on the support set, and the ground-truth labels of the support set.\n        *   The Hypernetwork `Hη` directly outputs the weight update `∆θ`.\n        *   The task-specific parameters `θ'` are computed as `θ' = θ + ∆θ`.\n    *   **Training:** The encoder `Eγ`, Hypernetwork `Hη`, and universal weights `θ` are all meta-trained end-to-end using stochastic gradient descent to optimize the performance of `fθ'` on query sets. This avoids the second-order optimization of MAML.\n    *   **Few-Shot Extension:** For K-shot scenarios, support examples from the same class are aggregated (mean operation) for embeddings and predictions before being fed to the Hypernetwork.\n    *   **Warming-up:** Universal weights `θ` are pre-trained on a subset of tasks to provide a robust starting point.\n    *   **Novelty:** The key innovation is the replacement of a fixed, gradient-based update rule with a learned, data-driven Hypernetwork that can generate more flexible and significant weight modifications in a single step, without relying on loss or gradient calculations during the update phase.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm:** Introduction of HyperMAML, a novel generalization of MAML that uses a Hypernetwork for direct, trainable weight updates in Few-Shot learning \\cite{przewiezlikowski2022d4y}.\n    *   **Update Mechanism Innovation:** The Hypernetwork aggregates information from the support set (embeddings, base model predictions, true labels) to directly produce `∆θ`, eliminating the need for loss calculation or gradient backpropagation for task-specific adaptation.\n    *   **Computational Efficiency:** By avoiding gradient-based inner loops and second-order optimization, HyperMAML offers a more computationally efficient training procedure compared to classical MAML.\n    *   **Enhanced Adaptation Capability:** The learned update mechanism allows for more significant and flexible weight modifications, overcoming MAML's limitation of insufficient updates in a few gradient steps.\n    *   **Biological Feasibility:** The approach moves away from gradient descent for adaptation, aligning with hypotheses about non-gradient-based learning in biological systems.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The authors conducted experiments comparing HyperMAML against classical MAML and other state-of-the-art Few-Shot learning techniques. A 2D toy example (Figure 1) visually demonstrates HyperMAML's superior adaptation in a single step compared to MAML requiring multiple steps.\n    *   **Key Performance Metrics:** Accuracy is the primary metric used for comparison.\n    *   **Comparison Results:**\n        *   HyperMAML consistently outperforms classical MAML across numerous standard Few-Shot learning benchmarks.\n        *   HyperMAML performs comparably to other state-of-the-art techniques.\n        *   The toy example illustrates HyperMAML's ability to achieve optimal task adaptation with a single update, where MAML requires multiple gradient steps to reach a similar level of performance.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations:** The paper does not explicitly list limitations of HyperMAML itself in the provided text. However, the \"warming-up\" phase for universal weights suggests that a good initial `θ` is beneficial. The complexity of training a Hypernetwork can sometimes be a challenge, though the paper claims computational efficiency benefits over MAML.\n    *   **Scope of Applicability:** HyperMAML is designed for Few-Shot learning tasks where models need to quickly adapt to new, unseen tasks with limited data. It is particularly beneficial for scenarios where MAML's gradient-based updates are insufficient or computationally expensive.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** HyperMAML significantly advances the technical state-of-the-art in meta-learning by providing a more powerful and efficient adaptation mechanism than MAML, addressing its core limitations \\cite{przewiezlikowski2022d4y}.\n    *   **Potential Impact on Future Research:**\n        *   It opens new avenues for exploring non-gradient-based, learned adaptation strategies in meta-learning, potentially inspiring more biologically plausible AI.\n        *   Encourages further research into the design and application of Hypernetworks for generating complex and targeted weight updates in various deep learning contexts.\n        *   Offers a computationally more efficient alternative to MAML, which could be crucial for scaling meta-learning to larger models and datasets.",
      "intriguing_abstract": "Few-Shot learning demands models that can rapidly adapt to novel tasks with minimal data, a challenge where Model-Agnostic Meta-Learning (MAML) has shown promise but struggles with insufficient gradient-based adaptation and computational overhead. We introduce HyperMAML, a novel meta-learning framework that revolutionizes task-specific adaptation by replacing MAML's gradient-driven inner loop with a powerful, trainable Hypernetwork. This Hypernetwork directly generates comprehensive weight updates (∆θ) in a single step, leveraging support set embeddings, predictions, and labels, critically bypassing the need for loss calculation or gradient backpropagation during adaptation.\n\nThis innovative approach enables significantly more flexible and substantial model modifications, overcoming MAML's limitations. HyperMAML demonstrates superior performance over classical MAML across standard benchmarks, achieving comparable results to state-of-the-art methods while offering enhanced computational efficiency by avoiding complex second-order optimization. Our end-to-end meta-training of the Hypernetwork, encoder, and universal weights provides a robust and biologically plausible learning mechanism. HyperMAML marks a significant advancement in optimization-based meta-learning, paving the way for more efficient, adaptable, and scalable deep models in data-scarce environments.",
      "keywords": [
        "HyperMAML",
        "Few-Shot learning",
        "Hypernetwork",
        "Meta-learning",
        "MAML limitations",
        "Direct weight updates",
        "Learned adaptation",
        "Computational efficiency",
        "Enhanced adaptation",
        "Non-gradient-based adaptation",
        "End-to-end meta-training",
        "Support set information aggregation"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/859e953bba919a6f989d440b6c23ab19a8cb855b.pdf",
      "citation_key": "przewiezlikowski2022d4y",
      "metadata": {
        "title": "HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks",
        "authors": [
          "Marcin Przewiezlikowski",
          "P. Przybysz",
          "J. Tabor",
          "Maciej Ziȩba",
          "P. Spurek"
        ],
        "published_date": "2022",
        "abstract": "The aim of Few-Shot learning methods is to train models which can easily adapt to previously unseen tasks, based on small amounts of data. One of the most popular and elegant Few-Shot learning approaches is Model-Agnostic Meta-Learning (MAML). The main idea behind this method is to learn the general weights of the meta-model, which are further adapted to specific problems in a small number of gradient steps. However, the model's main limitation lies in the fact that the update procedure is realized by gradient-based optimisation. In consequence, MAML cannot always modify weights to the essential level in one or even a few gradient iterations. On the other hand, using many gradient steps results in a complex and time-consuming optimization procedure, which is hard to train in practice, and may lead to overfitting. In this paper, we propose HyperMAML, a novel generalization of MAML, where the training of the update procedure is also part of the model. Namely, in HyperMAML, instead of updating the weights with gradient descent, we use for this purpose a trainable Hypernetwork. Consequently, in this framework, the model can generate significant updates whose range is not limited to a fixed number of gradient steps. Experiments show that HyperMAML consistently outperforms MAML and performs comparably to other state-of-the-art techniques in a number of standard Few-Shot learning benchmarks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/859e953bba919a6f989d440b6c23ab19a8cb855b.pdf",
        "venue": "Neurocomputing",
        "citationCount": 21,
        "score": 7.0,
        "summary": "Here's a focused summary of the paper \"HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks\" by Przewi˛e´zlikowski et al. \\cite{przewiezlikowski2022d4y} for a literature review:\n\n---\n\n### Technical Paper Analysis: HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks \\cite{przewiezlikowski2022d4y}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the limitation of Model-Agnostic Meta-Learning (MAML) in Few-Shot learning, where the gradient-based inner-loop adaptation may not sufficiently modify model weights for complex tasks in a few steps.\n    *   **Importance & Challenge:** Few-Shot learning aims to enable models to adapt to new tasks with minimal data, mimicking human learning. MAML, while elegant, struggles with tasks requiring significant weight shifts, leading to suboptimal performance, unstable training, and potential overfitting if many gradient steps are used. The challenge is to enable more substantial and efficient weight updates without the computational overhead and limitations of gradient descent.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** HyperMAML is positioned as a generalization of MAML, belonging to the optimization-based meta-learning family. It shares MAML's core idea of learning universal weights that are then adapted to specific tasks.\n    *   **Limitations of Previous Solutions (MAML):**\n        *   MAML relies on gradient descent for task-specific weight updates, which may not be powerful enough to make essential modifications in a few steps.\n        *   Using many gradient steps leads to a complex, time-consuming optimization procedure (second-order optimization) that is hard to train and prone to overfitting.\n        *   MAML's gradient-based updates are considered biologically implausible.\n    *   **HyperMAML's Distinction:** Unlike MAML, which uses gradient descent, HyperMAML employs a trainable Hypernetwork to directly generate weight updates in a single step. It differs from other meta-optimizers by not requiring loss calculation or gradient backpropagation during the update generation, making it more computationally efficient.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** HyperMAML replaces the gradient-based inner-loop adaptation of MAML with a trainable Hypernetwork.\n    *   **Mechanism:**\n        *   A base model `fθ` (target classifier) has universal parameters `θ`.\n        *   An encoder `Eγ` transforms support set examples into low-dimensional embeddings.\n        *   A Hypernetwork `Hη` takes as input the encoded support set embeddings, the base model's predictions on the support set, and the ground-truth labels of the support set.\n        *   The Hypernetwork `Hη` directly outputs the weight update `∆θ`.\n        *   The task-specific parameters `θ'` are computed as `θ' = θ + ∆θ`.\n    *   **Training:** The encoder `Eγ`, Hypernetwork `Hη`, and universal weights `θ` are all meta-trained end-to-end using stochastic gradient descent to optimize the performance of `fθ'` on query sets. This avoids the second-order optimization of MAML.\n    *   **Few-Shot Extension:** For K-shot scenarios, support examples from the same class are aggregated (mean operation) for embeddings and predictions before being fed to the Hypernetwork.\n    *   **Warming-up:** Universal weights `θ` are pre-trained on a subset of tasks to provide a robust starting point.\n    *   **Novelty:** The key innovation is the replacement of a fixed, gradient-based update rule with a learned, data-driven Hypernetwork that can generate more flexible and significant weight modifications in a single step, without relying on loss or gradient calculations during the update phase.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithm:** Introduction of HyperMAML, a novel generalization of MAML that uses a Hypernetwork for direct, trainable weight updates in Few-Shot learning \\cite{przewiezlikowski2022d4y}.\n    *   **Update Mechanism Innovation:** The Hypernetwork aggregates information from the support set (embeddings, base model predictions, true labels) to directly produce `∆θ`, eliminating the need for loss calculation or gradient backpropagation for task-specific adaptation.\n    *   **Computational Efficiency:** By avoiding gradient-based inner loops and second-order optimization, HyperMAML offers a more computationally efficient training procedure compared to classical MAML.\n    *   **Enhanced Adaptation Capability:** The learned update mechanism allows for more significant and flexible weight modifications, overcoming MAML's limitation of insufficient updates in a few gradient steps.\n    *   **Biological Feasibility:** The approach moves away from gradient descent for adaptation, aligning with hypotheses about non-gradient-based learning in biological systems.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The authors conducted experiments comparing HyperMAML against classical MAML and other state-of-the-art Few-Shot learning techniques. A 2D toy example (Figure 1) visually demonstrates HyperMAML's superior adaptation in a single step compared to MAML requiring multiple steps.\n    *   **Key Performance Metrics:** Accuracy is the primary metric used for comparison.\n    *   **Comparison Results:**\n        *   HyperMAML consistently outperforms classical MAML across numerous standard Few-Shot learning benchmarks.\n        *   HyperMAML performs comparably to other state-of-the-art techniques.\n        *   The toy example illustrates HyperMAML's ability to achieve optimal task adaptation with a single update, where MAML requires multiple gradient steps to reach a similar level of performance.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations:** The paper does not explicitly list limitations of HyperMAML itself in the provided text. However, the \"warming-up\" phase for universal weights suggests that a good initial `θ` is beneficial. The complexity of training a Hypernetwork can sometimes be a challenge, though the paper claims computational efficiency benefits over MAML.\n    *   **Scope of Applicability:** HyperMAML is designed for Few-Shot learning tasks where models need to quickly adapt to new, unseen tasks with limited data. It is particularly beneficial for scenarios where MAML's gradient-based updates are insufficient or computationally expensive.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** HyperMAML significantly advances the technical state-of-the-art in meta-learning by providing a more powerful and efficient adaptation mechanism than MAML, addressing its core limitations \\cite{przewiezlikowski2022d4y}.\n    *   **Potential Impact on Future Research:**\n        *   It opens new avenues for exploring non-gradient-based, learned adaptation strategies in meta-learning, potentially inspiring more biologically plausible AI.\n        *   Encourages further research into the design and application of Hypernetworks for generating complex and targeted weight updates in various deep learning contexts.\n        *   Offers a computationally more efficient alternative to MAML, which could be crucial for scaling meta-learning to larger models and datasets.",
        "keywords": [
          "HyperMAML",
          "Few-Shot learning",
          "Hypernetwork",
          "Meta-learning",
          "MAML limitations",
          "Direct weight updates",
          "Learned adaptation",
          "Computational efficiency",
          "Enhanced adaptation",
          "Non-gradient-based adaptation",
          "End-to-end meta-training",
          "Support set information aggregation"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"in this paper, we **propose hypermaml, a novel generalization of maml**\".\n*   it describes the new method: \"instead of updating the weights with gradient descent, we use for this purpose a trainable hypernetwork.\"\n*   the introduction discusses a technical problem (limitations of maml's gradient-based optimization) and sets the stage for their proposed solution.\n*   while it mentions \"experiments show that hypermaml consistently outperforms maml...\", this is the validation of the proposed method, making the paper primarily **technical** with an empirical evaluation component, rather than a purely empirical study of existing methods or phenomena.\n\nthis aligns perfectly with the criteria for a **technical** paper: \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'. introduction discusses: technical problem, proposed solution.\"\n\n**classification: technical**"
      },
      "file_name": "859e953bba919a6f989d440b6c23ab19a8cb855b.pdf"
    },
    {
      "success": true,
      "doc_id": "b542f5693a29556061d388e1d0606733",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/40df15ce1de6eb0366179f4726aa55a3e50141fc.pdf",
      "citation_key": "xu2018rjq",
      "metadata": {
        "title": "Learning to Explore via Meta-Policy Gradient",
        "authors": [
          "Tianbing Xu",
          "Qiang Liu",
          "Liang Zhao",
          "Jian Peng"
        ],
        "published_date": "2018",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/40df15ce1de6eb0366179f4726aa55a3e50141fc.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 48,
        "score": 6.857142857142857,
        "summary": "",
        "keywords": []
      },
      "file_name": "40df15ce1de6eb0366179f4726aa55a3e50141fc.pdf"
    },
    {
      "success": true,
      "doc_id": "4d896e335565a19a46c78ac211936b51",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5b470924b4c62bb7bb579e37653cc7c660ac49e3.pdf",
      "citation_key": "ding2019a79",
      "metadata": {
        "title": "Multi-scale Relation Network for Few-Shot Learning Based on Meta-learning",
        "authors": [
          "Yue Ding",
          "Xia Tian",
          "Lirong Yin",
          "Xiaobing Chen",
          "Shan Liu",
          "Bo Yang",
          "Wenfeng Zheng"
        ],
        "published_date": "2019",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/5b470924b4c62bb7bb579e37653cc7c660ac49e3.pdf",
        "venue": "International Conference on Virtual Storytelling",
        "citationCount": 41,
        "score": 6.833333333333333,
        "summary": "",
        "keywords": []
      },
      "file_name": "5b470924b4c62bb7bb579e37653cc7c660ac49e3.pdf"
    },
    {
      "success": true,
      "doc_id": "cae670ba0cc1a78f39eee66b5194ca35",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/769c5e812f0c3c7393b5fae215bd731694667ba2.pdf",
      "citation_key": "dorfman2020gku",
      "metadata": {
        "title": "Offline Meta Learning of Exploration",
        "authors": [
          "Ron Dorfman",
          "Aviv Tamar"
        ],
        "published_date": "2020",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/769c5e812f0c3c7393b5fae215bd731694667ba2.pdf",
        "venue": "",
        "citationCount": 34,
        "score": 6.800000000000001,
        "summary": "",
        "keywords": []
      },
      "file_name": "769c5e812f0c3c7393b5fae215bd731694667ba2.pdf"
    },
    {
      "success": true,
      "doc_id": "a0d06ae5bfcb6fcf4e8feec36a32cc22",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/a4de6509a26d4f31deea44194581c46b4ebab04c.pdf",
      "citation_key": "wang20210y3",
      "metadata": {
        "title": "Learning to Learn Dense Gaussian Processes for Few-Shot Learning",
        "authors": [
          "Ze Wang",
          "Zichen Miao",
          "Xiantong Zhen",
          "Qiang Qiu"
        ],
        "published_date": "2021",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/a4de6509a26d4f31deea44194581c46b4ebab04c.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 27,
        "score": 6.75,
        "summary": "",
        "keywords": []
      },
      "file_name": "a4de6509a26d4f31deea44194581c46b4ebab04c.pdf"
    },
    {
      "success": true,
      "doc_id": "a4e3ca0e8a6652b7822cfb91b2a4c179",
      "summary": "Deep reinforcement learning (DRL) has achieved significant results in many Machine Learning (ML) benchmarks. In this short survey we provide an overview of DRL applied to trading on financial markets, including a short meta-analysis using Google Scholar, with an emphasis on using hierarchy for dividing the problem space as well as using model-based RL to learn a world model of the trading environment which can be used for prediction. In addition, multiple risk measures are defined and discussed, which not only provide a way of quantifying the performance of various algorithms, but they can also act as (dense) reward-shaping mechanisms for the agent. We discuss in detail the various state representations used for financial markets, which we consider critical for the success and efficiency of such DRL agents. The market in focus for this survey is the cryptocurrency market.",
      "intriguing_abstract": "Deep reinforcement learning (DRL) has achieved significant results in many Machine Learning (ML) benchmarks. In this short survey we provide an overview of DRL applied to trading on financial markets, including a short meta-analysis using Google Scholar, with an emphasis on using hierarchy for dividing the problem space as well as using model-based RL to learn a world model of the trading environment which can be used for prediction. In addition, multiple risk measures are defined and discussed, which not only provide a way of quantifying the performance of various algorithms, but they can also act as (dense) reward-shaping mechanisms for the agent. We discuss in detail the various state representations used for financial markets, which we consider critical for the success and efficiency of such DRL agents. The market in focus for this survey is the cryptocurrency market.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3e0298554f27de660bbd10a0bc1d680c507812ae.pdf",
      "citation_key": "millea2021bfu",
      "metadata": {
        "title": "Deep Reinforcement Learning for Trading - A Critical Survey",
        "authors": [
          "Adrian Millea"
        ],
        "published_date": "2021",
        "abstract": "Deep reinforcement learning (DRL) has achieved significant results in many Machine Learning (ML) benchmarks. In this short survey we provide an overview of DRL applied to trading on financial markets, including a short meta-analysis using Google Scholar, with an emphasis on using hierarchy for dividing the problem space as well as using model-based RL to learn a world model of the trading environment which can be used for prediction. In addition, multiple risk measures are defined and discussed, which not only provide a way of quantifying the performance of various algorithms, but they can also act as (dense) reward-shaping mechanisms for the agent. We discuss in detail the various state representations used for financial markets, which we consider critical for the success and efficiency of such DRL agents. The market in focus for this survey is the cryptocurrency market.",
        "file_path": "paper_data/Deep_Meta-Learning/info/3e0298554f27de660bbd10a0bc1d680c507812ae.pdf",
        "venue": "International Conference on Data Technologies and Applications",
        "citationCount": 27,
        "score": 6.75,
        "summary": "Deep reinforcement learning (DRL) has achieved significant results in many Machine Learning (ML) benchmarks. In this short survey we provide an overview of DRL applied to trading on financial markets, including a short meta-analysis using Google Scholar, with an emphasis on using hierarchy for dividing the problem space as well as using model-based RL to learn a world model of the trading environment which can be used for prediction. In addition, multiple risk measures are defined and discussed, which not only provide a way of quantifying the performance of various algorithms, but they can also act as (dense) reward-shaping mechanisms for the agent. We discuss in detail the various state representations used for financial markets, which we consider critical for the success and efficiency of such DRL agents. The market in focus for this survey is the cryptocurrency market.",
        "keywords": []
      },
      "file_name": "3e0298554f27de660bbd10a0bc1d680c507812ae.pdf"
    },
    {
      "success": true,
      "doc_id": "4655dd7794f17adf5ffeeb4d55580d1b",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of implementing credit assignment in deep neural networks using biologically plausible mechanisms, specifically avoiding the biologically implausible requirements of backpropagation such as weight transport (feedback weights being tied to feedforward weights) and the application of derivatives of forward-pass nonlinearities during feedback \\cite{lindsey202075a}.\n    *   **Importance & Challenge**: This problem is crucial for advancing connections between deep learning and neuroscience, and for overcoming backpropagation's shortcomings in tasks like online and continual learning. Developing local synaptic learning rules that match deep network performance remains an open challenge \\cite{lindsey202075a}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Previous research explored alternatives to backpropagation, including random feedback weights \\cite{lindsey202075a}, target propagation (approximating inverse feedforward pathways) \\cite{lindsey202075a}, and local circuit mechanisms to enforce approximate weight symmetry \\cite{lindsey202075a}. Gradient-based meta-learning (e.g., MAML, OML) has addressed few-shot and continual learning by meta-optimizing network initialization or inner-loop gradient steps \\cite{lindsey202075a}. Some meta-learning works use Hebbian rules but often restrict plasticity or rely on global reward \\cite{lindsey202075a}.\n    *   **Limitations of Previous Solutions**: Random feedback and target propagation scale poorly to complex tasks \\cite{lindsey202075a}. Many recent biologically-inspired methods still aim to *approximate* gradient descent by enforcing approximate weight symmetry \\cite{lindsey202075a}. Standard deep learning with SGD struggles with few-shot learning and online learning from nonstationary data streams \\cite{lindsey202075a}. Other meta-learning approaches with Hebbian rules do not fully address the deep credit assignment problem \\cite{lindsey202075a}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method (FLP - Feedback and Local Plasticity)**: The proposed method involves three stages:\n        1.  **Feedforward Processing**: A multi-layer network propagates input `x` to produce `y_hat`.\n        2.  **Feedback Updates**: The target `y` (or prediction error `y - y_hat`) is propagated through *separate, fixed* feedback weights `B_i` directly to each layer. Layer activations `x_i` are updated as `x_i' = (1 - gamma_i)x_i + gamma_i * ReLU(B_i * y + b)`, where `gamma_i` controls feedback strength \\cite{lindsey202075a}.\n        3.  **Weight Updates**: Synaptic weights `W_i` are updated using a *local learning rule* (Oja's rule: `w = w + eta * (ab - b^2w)`) based on pre- and post-synaptic activity *after* feedback \\cite{lindsey202075a}.\n    *   **Novelty & Difference**:\n        *   **Decoupled Feedforward and Feedback Weights**: Crucially, the feedback weights `B_i` are *not* tied to the feedforward weights `W_i`, avoiding the biologically implausible weight transport problem \\cite{lindsey202075a}.\n        *   **Meta-learning for Credit Assignment**: The feedback weights `B_i`, initial feedforward weights `W_i`, plasticity coefficients `eta`, and feedback strength `gamma_i` are meta-learned (optimized in an outer loop) to enable effective inner-loop learning, treating credit assignment itself as an optimization problem \\cite{lindsey202075a}.\n        *   **Biologically Inspired Local Plasticity**: Employs Oja's rule, a local Hebbian-style rule, for synaptic updates, which is more biologically plausible than gradient descent \\cite{lindsey202075a}.\n        *   **Direct Feedback Injection**: Error/target signals are injected directly into upstream layers without requiring derivative computations \\cite{lindsey202075a}.\n        *   **Universality Proof**: The paper provides a theoretical proof that FLP, with sufficiently wide and deep networks, can approximate any learning algorithm, highlighting the key role of decoupled feedforward and feedback weights in online learning \\cite{lindsey202075a}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of the Feedback and Local Plasticity (FLP) framework, which combines meta-learning with decoupled feedback pathways and local synaptic plasticity rules to achieve deep credit assignment \\cite{lindsey202075a}.\n    *   **System Design/Architectural Innovations**: A network architecture where feedback information is carried by separate, direct, and fixed linear transformations (`B_i`) from the output to each layer, and where layer-specific `gamma_i` parameters modulate the influence of feedback on activations \\cite{lindsey202075a}.\n    *   **Theoretical Insights/Analysis**: A universality theorem demonstrating that FLP can approximate any learning rule, emphasizing the importance of decoupled feedforward and feedback weights for online, continual learning \\cite{lindsey202075a}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The method was evaluated on online regression (Incremental Sine Waves) and online, few-shot classification (Omniglot, Mini-Imagenet) tasks, including both i.i.d. and continual learning variants \\cite{lindsey202075a}. Experiments varied the number of plastic layers, including a \"feature reuse\" control where only output weights were plastic \\cite{lindsey202075a}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **Deep Credit Assignment**: Enabling plasticity in non-readout layers consistently improved performance across all tasks compared to the \"feature reuse\" baseline, confirming successful deep credit assignment \\cite{lindsey202075a}.\n        *   **Comparison to Gradient-based Meta-learner**: FLP matched or slightly exceeded the performance of a state-of-the-art gradient-based online meta-learning baseline (modified OML) on i.i.d. regression and all classification tasks \\cite{lindsey202075a}.\n        *   **Superiority in Continual Learning**: FLP *significantly outperformed* the gradient-based baseline on continual learning variants of the regression task (e.g., 0.0016 MSE for FLP vs. 0.069 MSE for gradient-based with 2 plastic layers), demonstrating a key advantage in scenarios where gradient-based methods struggle \\cite{lindsey202075a}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The current feedback pathways are direct, shallow, and fixed linear transformations; more complex feedback architectures are noted as future work \\cite{lindsey202075a}. The analysis of the specific learning strategies uncovered by meta-learning is preliminary \\cite{lindsey202075a}.\n    *   **Scope of Applicability**: The method is demonstrated for online regression and few-shot classification, particularly excelling in continual learning settings \\cite{lindsey202075a}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: FLP provides a biologically plausible learning mechanism that not only matches gradient descent-based meta-learning but also overcomes its limitations, particularly in continual learning \\cite{lindsey202075a}. It demonstrates that effective credit assignment does not necessarily require approximating gradient signals \\cite{lindsey202075a}.\n    *   **Potential Impact on Future Research**: This work suggests a new class of biologically plausible learning mechanisms for deep networks, opening avenues for future research in biologically inspired AI and potentially guiding neuroscientific understanding of feedback connections in the brain \\cite{lindsey202075a}. It also offers new inductive biases for machine learning practitioners, especially for online and continual learning problems \\cite{lindsey202075a}.",
      "intriguing_abstract": "The biological implausibility of backpropagation, particularly its reliance on weight transport and derivative computations, remains a critical barrier to developing brain-inspired deep learning. We introduce Feedback and Local Plasticity (FLP), a novel framework that resolves the deep credit assignment problem using biologically plausible mechanisms. FLP fundamentally decouples feedforward and feedback pathways, employing separate, fixed feedback weights and local synaptic plasticity rules (e.g., Oja's rule) for synaptic updates. Crucially, the entire credit assignment process—including feedback weights, initial feedforward weights, and plasticity parameters—is meta-learned, enabling the network to discover effective learning strategies without approximating gradient descent. We theoretically prove FLP's universality, demonstrating its capacity to approximate any learning algorithm, highlighting the importance of decoupled weights for online learning. Experimentally, FLP matches state-of-the-art gradient-based meta-learning on few-shot classification and online regression, while *significantly outperforming* it in challenging continual learning scenarios. This work presents a powerful, biologically inspired alternative to backpropagation, opening new avenues for robust online learning in deep neural networks and bridging the gap between artificial intelligence and neuroscience.",
      "keywords": [
        "Feedback and Local Plasticity (FLP)",
        "biologically plausible credit assignment",
        "decoupled feedforward and feedback weights",
        "meta-learning for credit assignment",
        "local synaptic plasticity (Oja's rule)",
        "weight transport problem",
        "online learning",
        "continual learning",
        "few-shot classification",
        "universality theorem",
        "deep neural networks",
        "avoiding gradient approximation",
        "neuroscience-inspired AI"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/f6271880cc1d7ff6514672366fe124fdb1212fb2.pdf",
      "citation_key": "lindsey202075a",
      "metadata": {
        "title": "Learning to Learn with Feedback and Local Plasticity",
        "authors": [
          "Jack W Lindsey",
          "Ashok Litwin-Kumar"
        ],
        "published_date": "2020",
        "abstract": "Interest in biologically inspired alternatives to backpropagation is driven by the desire to both advance connections between deep learning and neuroscience and address backpropagation's shortcomings on tasks such as online, continual learning. However, local synaptic learning rules like those employed by the brain have so far failed to match the performance of backpropagation in deep networks. In this study, we employ meta-learning to discover networks that learn using feedback connections and local, biologically inspired learning rules. Importantly, the feedback connections are not tied to the feedforward weights, avoiding biologically implausible weight transport. Our experiments show that meta-trained networks effectively use feedback connections to perform online credit assignment in multi-layer architectures. Surprisingly, this approach matches or exceeds a state-of-the-art gradient-based online meta-learning algorithm on regression and classification tasks, excelling in particular at continual learning. Analysis of the weight updates employed by these models reveals that they differ qualitatively from gradient descent in a way that reduces interference between updates. Our results suggest the existence of a class of biologically plausible learning mechanisms that not only match gradient descent-based learning, but also overcome its limitations.",
        "file_path": "paper_data/Deep_Meta-Learning/info/f6271880cc1d7ff6514672366fe124fdb1212fb2.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 33,
        "score": 6.6000000000000005,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of implementing credit assignment in deep neural networks using biologically plausible mechanisms, specifically avoiding the biologically implausible requirements of backpropagation such as weight transport (feedback weights being tied to feedforward weights) and the application of derivatives of forward-pass nonlinearities during feedback \\cite{lindsey202075a}.\n    *   **Importance & Challenge**: This problem is crucial for advancing connections between deep learning and neuroscience, and for overcoming backpropagation's shortcomings in tasks like online and continual learning. Developing local synaptic learning rules that match deep network performance remains an open challenge \\cite{lindsey202075a}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Previous research explored alternatives to backpropagation, including random feedback weights \\cite{lindsey202075a}, target propagation (approximating inverse feedforward pathways) \\cite{lindsey202075a}, and local circuit mechanisms to enforce approximate weight symmetry \\cite{lindsey202075a}. Gradient-based meta-learning (e.g., MAML, OML) has addressed few-shot and continual learning by meta-optimizing network initialization or inner-loop gradient steps \\cite{lindsey202075a}. Some meta-learning works use Hebbian rules but often restrict plasticity or rely on global reward \\cite{lindsey202075a}.\n    *   **Limitations of Previous Solutions**: Random feedback and target propagation scale poorly to complex tasks \\cite{lindsey202075a}. Many recent biologically-inspired methods still aim to *approximate* gradient descent by enforcing approximate weight symmetry \\cite{lindsey202075a}. Standard deep learning with SGD struggles with few-shot learning and online learning from nonstationary data streams \\cite{lindsey202075a}. Other meta-learning approaches with Hebbian rules do not fully address the deep credit assignment problem \\cite{lindsey202075a}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method (FLP - Feedback and Local Plasticity)**: The proposed method involves three stages:\n        1.  **Feedforward Processing**: A multi-layer network propagates input `x` to produce `y_hat`.\n        2.  **Feedback Updates**: The target `y` (or prediction error `y - y_hat`) is propagated through *separate, fixed* feedback weights `B_i` directly to each layer. Layer activations `x_i` are updated as `x_i' = (1 - gamma_i)x_i + gamma_i * ReLU(B_i * y + b)`, where `gamma_i` controls feedback strength \\cite{lindsey202075a}.\n        3.  **Weight Updates**: Synaptic weights `W_i` are updated using a *local learning rule* (Oja's rule: `w = w + eta * (ab - b^2w)`) based on pre- and post-synaptic activity *after* feedback \\cite{lindsey202075a}.\n    *   **Novelty & Difference**:\n        *   **Decoupled Feedforward and Feedback Weights**: Crucially, the feedback weights `B_i` are *not* tied to the feedforward weights `W_i`, avoiding the biologically implausible weight transport problem \\cite{lindsey202075a}.\n        *   **Meta-learning for Credit Assignment**: The feedback weights `B_i`, initial feedforward weights `W_i`, plasticity coefficients `eta`, and feedback strength `gamma_i` are meta-learned (optimized in an outer loop) to enable effective inner-loop learning, treating credit assignment itself as an optimization problem \\cite{lindsey202075a}.\n        *   **Biologically Inspired Local Plasticity**: Employs Oja's rule, a local Hebbian-style rule, for synaptic updates, which is more biologically plausible than gradient descent \\cite{lindsey202075a}.\n        *   **Direct Feedback Injection**: Error/target signals are injected directly into upstream layers without requiring derivative computations \\cite{lindsey202075a}.\n        *   **Universality Proof**: The paper provides a theoretical proof that FLP, with sufficiently wide and deep networks, can approximate any learning algorithm, highlighting the key role of decoupled feedforward and feedback weights in online learning \\cite{lindsey202075a}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of the Feedback and Local Plasticity (FLP) framework, which combines meta-learning with decoupled feedback pathways and local synaptic plasticity rules to achieve deep credit assignment \\cite{lindsey202075a}.\n    *   **System Design/Architectural Innovations**: A network architecture where feedback information is carried by separate, direct, and fixed linear transformations (`B_i`) from the output to each layer, and where layer-specific `gamma_i` parameters modulate the influence of feedback on activations \\cite{lindsey202075a}.\n    *   **Theoretical Insights/Analysis**: A universality theorem demonstrating that FLP can approximate any learning rule, emphasizing the importance of decoupled feedforward and feedback weights for online, continual learning \\cite{lindsey202075a}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The method was evaluated on online regression (Incremental Sine Waves) and online, few-shot classification (Omniglot, Mini-Imagenet) tasks, including both i.i.d. and continual learning variants \\cite{lindsey202075a}. Experiments varied the number of plastic layers, including a \"feature reuse\" control where only output weights were plastic \\cite{lindsey202075a}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   **Deep Credit Assignment**: Enabling plasticity in non-readout layers consistently improved performance across all tasks compared to the \"feature reuse\" baseline, confirming successful deep credit assignment \\cite{lindsey202075a}.\n        *   **Comparison to Gradient-based Meta-learner**: FLP matched or slightly exceeded the performance of a state-of-the-art gradient-based online meta-learning baseline (modified OML) on i.i.d. regression and all classification tasks \\cite{lindsey202075a}.\n        *   **Superiority in Continual Learning**: FLP *significantly outperformed* the gradient-based baseline on continual learning variants of the regression task (e.g., 0.0016 MSE for FLP vs. 0.069 MSE for gradient-based with 2 plastic layers), demonstrating a key advantage in scenarios where gradient-based methods struggle \\cite{lindsey202075a}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The current feedback pathways are direct, shallow, and fixed linear transformations; more complex feedback architectures are noted as future work \\cite{lindsey202075a}. The analysis of the specific learning strategies uncovered by meta-learning is preliminary \\cite{lindsey202075a}.\n    *   **Scope of Applicability**: The method is demonstrated for online regression and few-shot classification, particularly excelling in continual learning settings \\cite{lindsey202075a}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: FLP provides a biologically plausible learning mechanism that not only matches gradient descent-based meta-learning but also overcomes its limitations, particularly in continual learning \\cite{lindsey202075a}. It demonstrates that effective credit assignment does not necessarily require approximating gradient signals \\cite{lindsey202075a}.\n    *   **Potential Impact on Future Research**: This work suggests a new class of biologically plausible learning mechanisms for deep networks, opening avenues for future research in biologically inspired AI and potentially guiding neuroscientific understanding of feedback connections in the brain \\cite{lindsey202075a}. It also offers new inductive biases for machine learning practitioners, especially for online and continual learning problems \\cite{lindsey202075a}.",
        "keywords": [
          "Feedback and Local Plasticity (FLP)",
          "biologically plausible credit assignment",
          "decoupled feedforward and feedback weights",
          "meta-learning for credit assignment",
          "local synaptic plasticity (Oja's rule)",
          "weight transport problem",
          "online learning",
          "continual learning",
          "few-shot classification",
          "universality theorem",
          "deep neural networks",
          "avoiding gradient approximation",
          "neuroscience-inspired AI"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n1.  **new method/paradigm proposed:** the introduction explicitly states, \"we propose a learning paradigm that aims to solve the credit assignment problem in more biologically plausible fashion. our approach is as follows...\" this is a clear indicator of presenting a new method or system.\n2.  **focus on \"how\":** the abstract describes *how* they achieve their results: \"we employ meta-learning to discover networks that learn using feedback connections and local, biologically inspired learning rules.\"\n3.  **empirical validation of new method:** while the paper clearly involves experiments (\"our experiments show...\", \"on regression and classiﬁcation tasks\"), these experiments are conducted to validate the effectiveness and properties of the *new learning paradigm* they are proposing. the empirical results serve to demonstrate the success of their technical contribution.\n4.  **addressing a technical problem:** the introduction details a technical problem in deep learning and neuroscience (biological implausibility of backpropagation, credit assignment problem) and then presents their proposed solution.\n\nthe paper's primary contribution is the development and presentation of a novel learning paradigm, which is then rigorously tested. this aligns perfectly with the \"technical\" classification criteria."
      },
      "file_name": "f6271880cc1d7ff6514672366fe124fdb1212fb2.pdf"
    },
    {
      "success": true,
      "doc_id": "cdb1c28a34dcd2067377abe31c7230ae",
      "summary": "The existing indoor fingerprinting methods based on received signal strength (RSS) are rather accurate after intensive offline calibration for a specific scenario, but the well-calibrated localization model (can be a pure statistical one or a data-driven one) will present poor generalization ability in a new scenario, which results in big loss in knowledge and human effort. To break the scenario-specific localization bottleneck, we propose a new-fashioned data-driven fingerprinting method for localization based on meta-learning, named by MetaLoc, that can adapt itself rapidly to a new, possibly unseen, scenario with very little calibration work. Specifically, the underlying localization model is taken to be a deep neural network (NN), and we train an optimal set of group-specific meta-parameters by leveraging historical data collected from diverse well-calibrated indoor scenarios and the maximum mean discrepancy criterion. Simulation results confirm that the meta-parameters obtained for MetaLoc achieves very rapid adaptation to new scenarios, competitive localization accuracy, and high resistance to significantly reduced reference points (RPs), saving a lot of calibration effort.",
      "intriguing_abstract": "The existing indoor fingerprinting methods based on received signal strength (RSS) are rather accurate after intensive offline calibration for a specific scenario, but the well-calibrated localization model (can be a pure statistical one or a data-driven one) will present poor generalization ability in a new scenario, which results in big loss in knowledge and human effort. To break the scenario-specific localization bottleneck, we propose a new-fashioned data-driven fingerprinting method for localization based on meta-learning, named by MetaLoc, that can adapt itself rapidly to a new, possibly unseen, scenario with very little calibration work. Specifically, the underlying localization model is taken to be a deep neural network (NN), and we train an optimal set of group-specific meta-parameters by leveraging historical data collected from diverse well-calibrated indoor scenarios and the maximum mean discrepancy criterion. Simulation results confirm that the meta-parameters obtained for MetaLoc achieves very rapid adaptation to new scenarios, competitive localization accuracy, and high resistance to significantly reduced reference points (RPs), saving a lot of calibration effort.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/0e8827f439152cf1f5670a3ab391db6148abc7e0.pdf",
      "citation_key": "gao2022y3s",
      "metadata": {
        "title": "MetaLoc: Learning to Learn Indoor RSS Fingerprinting Localization over Multiple Scenarios",
        "authors": [
          "Jun Gao",
          "Ceyao Zhang",
          "Qinglei Kong",
          "F. Yin",
          "Lexi Xu",
          "K. Niu"
        ],
        "published_date": "2022",
        "abstract": "The existing indoor fingerprinting methods based on received signal strength (RSS) are rather accurate after intensive offline calibration for a specific scenario, but the well-calibrated localization model (can be a pure statistical one or a data-driven one) will present poor generalization ability in a new scenario, which results in big loss in knowledge and human effort. To break the scenario-specific localization bottleneck, we propose a new-fashioned data-driven fingerprinting method for localization based on meta-learning, named by MetaLoc, that can adapt itself rapidly to a new, possibly unseen, scenario with very little calibration work. Specifically, the underlying localization model is taken to be a deep neural network (NN), and we train an optimal set of group-specific meta-parameters by leveraging historical data collected from diverse well-calibrated indoor scenarios and the maximum mean discrepancy criterion. Simulation results confirm that the meta-parameters obtained for MetaLoc achieves very rapid adaptation to new scenarios, competitive localization accuracy, and high resistance to significantly reduced reference points (RPs), saving a lot of calibration effort.",
        "file_path": "paper_data/Deep_Meta-Learning/info/0e8827f439152cf1f5670a3ab391db6148abc7e0.pdf",
        "venue": "ICC 2022 - IEEE International Conference on Communications",
        "citationCount": 19,
        "score": 6.333333333333333,
        "summary": "The existing indoor fingerprinting methods based on received signal strength (RSS) are rather accurate after intensive offline calibration for a specific scenario, but the well-calibrated localization model (can be a pure statistical one or a data-driven one) will present poor generalization ability in a new scenario, which results in big loss in knowledge and human effort. To break the scenario-specific localization bottleneck, we propose a new-fashioned data-driven fingerprinting method for localization based on meta-learning, named by MetaLoc, that can adapt itself rapidly to a new, possibly unseen, scenario with very little calibration work. Specifically, the underlying localization model is taken to be a deep neural network (NN), and we train an optimal set of group-specific meta-parameters by leveraging historical data collected from diverse well-calibrated indoor scenarios and the maximum mean discrepancy criterion. Simulation results confirm that the meta-parameters obtained for MetaLoc achieves very rapid adaptation to new scenarios, competitive localization accuracy, and high resistance to significantly reduced reference points (RPs), saving a lot of calibration effort.",
        "keywords": []
      },
      "file_name": "0e8827f439152cf1f5670a3ab391db6148abc7e0.pdf"
    },
    {
      "success": true,
      "doc_id": "88299f13a8b6eeeee9fc5838f7156628",
      "summary": "Considering the low coverage of roadside cooperative devices at the current time, automated driving should detect all road markings relevant to driving safety, such as traffic signs that tend to be of great variety but are fewer in number. In this work, we propose an innovative few-shot object detection framework, namely Meta-YOLO, whose challenge is to generalize to the unseen classes by using only a few seen classes. Simply integrating the YOLO mechanism into a meta-learning pipeline will encounter problems in terms of computational efficiency and mistake detection. Therefore, we construct a two-stage meta-learner ℱ model that can learn the learner initialization, the learner update direction and learning rate, all in a single meta-learning process. To facilitate deep networks with learning, the fidelity features of the targets improve the performance of meta-learner ℱ, but we also design a feature decorrelation module (FDM), which firstly transforms non-linear features into computable linear features based on RFF, and secondly perceives and removes global correlations by iteratively saving and reloading the features and sample weights of the model. We introduce a three-head module to learn global, local and patch correlations with the category detection result outputted by the aggregation in meta-learner ℱ, which endows a multi-scale ability with detector ϕ. In our experiments, the proposed algorithm outperforms the three benchmark algorithms and improves the mAP of few-shot detection by 39.8%.",
      "intriguing_abstract": "Considering the low coverage of roadside cooperative devices at the current time, automated driving should detect all road markings relevant to driving safety, such as traffic signs that tend to be of great variety but are fewer in number. In this work, we propose an innovative few-shot object detection framework, namely Meta-YOLO, whose challenge is to generalize to the unseen classes by using only a few seen classes. Simply integrating the YOLO mechanism into a meta-learning pipeline will encounter problems in terms of computational efficiency and mistake detection. Therefore, we construct a two-stage meta-learner ℱ model that can learn the learner initialization, the learner update direction and learning rate, all in a single meta-learning process. To facilitate deep networks with learning, the fidelity features of the targets improve the performance of meta-learner ℱ, but we also design a feature decorrelation module (FDM), which firstly transforms non-linear features into computable linear features based on RFF, and secondly perceives and removes global correlations by iteratively saving and reloading the features and sample weights of the model. We introduce a three-head module to learn global, local and patch correlations with the category detection result outputted by the aggregation in meta-learner ℱ, which endows a multi-scale ability with detector ϕ. In our experiments, the proposed algorithm outperforms the three benchmark algorithms and improves the mAP of few-shot detection by 39.8%.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/fd005bd79cb75e247c8e52255a3aa0228c93ae3b.pdf",
      "citation_key": "ren2022fc5",
      "metadata": {
        "title": "Meta-YOLO: Meta-Learning for Few-Shot Traffic Sign Detection via Decoupling Dependencies",
        "authors": [
          "Xinyue Ren",
          "Weiwei Zhang",
          "Ming-hui Wu",
          "Chuanchang Li",
          "Xiaolan Wang"
        ],
        "published_date": "2022",
        "abstract": "Considering the low coverage of roadside cooperative devices at the current time, automated driving should detect all road markings relevant to driving safety, such as traffic signs that tend to be of great variety but are fewer in number. In this work, we propose an innovative few-shot object detection framework, namely Meta-YOLO, whose challenge is to generalize to the unseen classes by using only a few seen classes. Simply integrating the YOLO mechanism into a meta-learning pipeline will encounter problems in terms of computational efficiency and mistake detection. Therefore, we construct a two-stage meta-learner ℱ model that can learn the learner initialization, the learner update direction and learning rate, all in a single meta-learning process. To facilitate deep networks with learning, the fidelity features of the targets improve the performance of meta-learner ℱ, but we also design a feature decorrelation module (FDM), which firstly transforms non-linear features into computable linear features based on RFF, and secondly perceives and removes global correlations by iteratively saving and reloading the features and sample weights of the model. We introduce a three-head module to learn global, local and patch correlations with the category detection result outputted by the aggregation in meta-learner ℱ, which endows a multi-scale ability with detector ϕ. In our experiments, the proposed algorithm outperforms the three benchmark algorithms and improves the mAP of few-shot detection by 39.8%.",
        "file_path": "paper_data/Deep_Meta-Learning/info/fd005bd79cb75e247c8e52255a3aa0228c93ae3b.pdf",
        "venue": "Applied Sciences",
        "citationCount": 19,
        "score": 6.333333333333333,
        "summary": "Considering the low coverage of roadside cooperative devices at the current time, automated driving should detect all road markings relevant to driving safety, such as traffic signs that tend to be of great variety but are fewer in number. In this work, we propose an innovative few-shot object detection framework, namely Meta-YOLO, whose challenge is to generalize to the unseen classes by using only a few seen classes. Simply integrating the YOLO mechanism into a meta-learning pipeline will encounter problems in terms of computational efficiency and mistake detection. Therefore, we construct a two-stage meta-learner ℱ model that can learn the learner initialization, the learner update direction and learning rate, all in a single meta-learning process. To facilitate deep networks with learning, the fidelity features of the targets improve the performance of meta-learner ℱ, but we also design a feature decorrelation module (FDM), which firstly transforms non-linear features into computable linear features based on RFF, and secondly perceives and removes global correlations by iteratively saving and reloading the features and sample weights of the model. We introduce a three-head module to learn global, local and patch correlations with the category detection result outputted by the aggregation in meta-learner ℱ, which endows a multi-scale ability with detector ϕ. In our experiments, the proposed algorithm outperforms the three benchmark algorithms and improves the mAP of few-shot detection by 39.8%.",
        "keywords": []
      },
      "file_name": "fd005bd79cb75e247c8e52255a3aa0228c93ae3b.pdf"
    },
    {
      "success": true,
      "doc_id": "fe8db00091a2744b890daacdc259b5d6",
      "summary": "In recent years, deep learning (DL)-based methods have been widely used in code vulnerability detection. The DL-based methods typically extract structural information from source code, e.g., code structure graph, and adopt neural networks such as Graph Neural Networks (GNNs) to learn the graph representations. However, these methods fail to consider the heterogeneous relations in the code structure graph, i.e., the heterogeneous relations mean that the different types of edges connect different types of nodes in the graph, which may obstruct the graph representation learning. Besides, these methods are limited in capturing long-range dependencies due to the deep levels in the code structure graph. In this paper, we propose a Meta-path based Attentional Graph learning model for code vulNErability deTection, called MAGNET. MAGNET constructs a multi-granularity meta-path graph for each code snippet, in which the heterogeneous relations are denoted as meta-paths to represent the structural information. A meta-path based hierarchical attentional graph neural network is also proposed to capture the relations between distant nodes in the graph. We evaluate MAGNET on three public datasets and the results show that MAGNET outperforms the best baseline method in terms of F1 score by 6.32%, 21.50%, and 25.40%, respectively. MAGNET also achieves the best performance among all the baseline methods in detecting Top-25 most dangerous Common Weakness Enumerations (CWEs), further demonstrating its effectiveness in vulnerability detection.",
      "intriguing_abstract": "In recent years, deep learning (DL)-based methods have been widely used in code vulnerability detection. The DL-based methods typically extract structural information from source code, e.g., code structure graph, and adopt neural networks such as Graph Neural Networks (GNNs) to learn the graph representations. However, these methods fail to consider the heterogeneous relations in the code structure graph, i.e., the heterogeneous relations mean that the different types of edges connect different types of nodes in the graph, which may obstruct the graph representation learning. Besides, these methods are limited in capturing long-range dependencies due to the deep levels in the code structure graph. In this paper, we propose a Meta-path based Attentional Graph learning model for code vulNErability deTection, called MAGNET. MAGNET constructs a multi-granularity meta-path graph for each code snippet, in which the heterogeneous relations are denoted as meta-paths to represent the structural information. A meta-path based hierarchical attentional graph neural network is also proposed to capture the relations between distant nodes in the graph. We evaluate MAGNET on three public datasets and the results show that MAGNET outperforms the best baseline method in terms of F1 score by 6.32%, 21.50%, and 25.40%, respectively. MAGNET also achieves the best performance among all the baseline methods in detecting Top-25 most dangerous Common Weakness Enumerations (CWEs), further demonstrating its effectiveness in vulnerability detection.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/bc06b836e8011c7c9e2f95dd86783e2157baccfa.pdf",
      "citation_key": "wen2022sql",
      "metadata": {
        "title": "Meta-Path Based Attentional Graph Learning Model for Vulnerability Detection",
        "authors": [
          "Xin-Cheng Wen",
          "Cuiyun Gao",
          "Jiaxin Ye",
          "Zhihong Tian",
          "Yan Jia",
          "X. Wang"
        ],
        "published_date": "2022",
        "abstract": "In recent years, deep learning (DL)-based methods have been widely used in code vulnerability detection. The DL-based methods typically extract structural information from source code, e.g., code structure graph, and adopt neural networks such as Graph Neural Networks (GNNs) to learn the graph representations. However, these methods fail to consider the heterogeneous relations in the code structure graph, i.e., the heterogeneous relations mean that the different types of edges connect different types of nodes in the graph, which may obstruct the graph representation learning. Besides, these methods are limited in capturing long-range dependencies due to the deep levels in the code structure graph. In this paper, we propose a Meta-path based Attentional Graph learning model for code vulNErability deTection, called MAGNET. MAGNET constructs a multi-granularity meta-path graph for each code snippet, in which the heterogeneous relations are denoted as meta-paths to represent the structural information. A meta-path based hierarchical attentional graph neural network is also proposed to capture the relations between distant nodes in the graph. We evaluate MAGNET on three public datasets and the results show that MAGNET outperforms the best baseline method in terms of F1 score by 6.32%, 21.50%, and 25.40%, respectively. MAGNET also achieves the best performance among all the baseline methods in detecting Top-25 most dangerous Common Weakness Enumerations (CWEs), further demonstrating its effectiveness in vulnerability detection.",
        "file_path": "paper_data/Deep_Meta-Learning/info/bc06b836e8011c7c9e2f95dd86783e2157baccfa.pdf",
        "venue": "IEEE Transactions on Software Engineering",
        "citationCount": 19,
        "score": 6.333333333333333,
        "summary": "In recent years, deep learning (DL)-based methods have been widely used in code vulnerability detection. The DL-based methods typically extract structural information from source code, e.g., code structure graph, and adopt neural networks such as Graph Neural Networks (GNNs) to learn the graph representations. However, these methods fail to consider the heterogeneous relations in the code structure graph, i.e., the heterogeneous relations mean that the different types of edges connect different types of nodes in the graph, which may obstruct the graph representation learning. Besides, these methods are limited in capturing long-range dependencies due to the deep levels in the code structure graph. In this paper, we propose a Meta-path based Attentional Graph learning model for code vulNErability deTection, called MAGNET. MAGNET constructs a multi-granularity meta-path graph for each code snippet, in which the heterogeneous relations are denoted as meta-paths to represent the structural information. A meta-path based hierarchical attentional graph neural network is also proposed to capture the relations between distant nodes in the graph. We evaluate MAGNET on three public datasets and the results show that MAGNET outperforms the best baseline method in terms of F1 score by 6.32%, 21.50%, and 25.40%, respectively. MAGNET also achieves the best performance among all the baseline methods in detecting Top-25 most dangerous Common Weakness Enumerations (CWEs), further demonstrating its effectiveness in vulnerability detection.",
        "keywords": []
      },
      "file_name": "bc06b836e8011c7c9e2f95dd86783e2157baccfa.pdf"
    },
    {
      "success": true,
      "doc_id": "338862d08c0fa7e0af59425e056282d9",
      "summary": "Here is a focused summary of the technical paper for a literature review, adhering to the specified citation requirements:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{vecoven2018hc1}\" when referencing this paper.\n\n---\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep Neural Networks (DNNs) currently struggle with efficient generalization and adaptation to new, unforeseen problems based on past experiences \\cite{vecoven2018hc1}.\n    *   **Importance and Challenge**: Animals demonstrate remarkable efficiency in adapting their intentions, attention, and actions to rich, unpredictable, and ever-changing external worlds, a capability intelligent machines largely lack. This biological adaptation relies heavily on cellular neuromodulation, a mechanism that dynamically controls intrinsic properties of neurons and their response to stimuli in a context-dependent manner \\cite{vecoven2018hc1}. Developing DNN architectures that can mimic this adaptive capacity is crucial for advancing artificial intelligence.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work relates to previous efforts in:\n        *   Networks inspired by Hebbian plasticity that feature dynamically tunable (plastic) weights \\cite{vecoven2018hc1}.\n        *   Approaches that learn a neuromodulatory signal to dictate when and which connections should be plastic \\cite{vecoven2018hc1}.\n        *   Hypernetworks, where one network computes the weights for another network \\cite{vecoven2018hc1}.\n        *   Recent works focused on learning fixed activation functions \\cite{vecoven2018hc1}.\n    *   **Limitations of Previous Solutions / Positioning**: Unlike hypernetworks that typically modulate connection weights, the proposed Neuro-Modulated Network (NMN) architecture modulates the parameters of activation functions \\cite{vecoven2018hc1}. This distinction is critical as the number of newly introduced parameters in NMN scales linearly with the number of neurons in the main network, rather than linearly with the number of connections. This makes the NMN approach more easily extensible to very large networks \\cite{vecoven2018hc1}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper introduces the Neuro-Modulated Network (NMN) architecture, which is inspired by biological cellular neuromodulation \\cite{vecoven2018hc1}.\n        *   The NMN comprises two interacting neural networks: a **main network** and a **neuromodulatory network** \\cite{vecoven2018hc1}.\n        *   The main network is a feed-forward DNN composed of neurons equipped with **parametric activation functions** \\cite{vecoven2018hc1}.\n        *   The neuromodulatory network dynamically controls the neuronal properties of the main network by tuning the **slope (`ws`) and bias (`wb`) parameters** of these activation functions \\cite{vecoven2018hc1}.\n        *   The neuromodulatory signal `z` is shared across all neuromodulated neurons and is computed by the neuromodulatory network based on contextual and feedback inputs (`c`). The main network processes other primary inputs (`x`) \\cite{vecoven2018hc1}.\n        *   The neuromodulated activation function is defined as `NMN(x;z;ws;wb) = z^T(x*ws + wb)`, where `z` is the context-dependent neuromodulatory signal \\cite{vecoven2018hc1}.\n    *   **Novelty**: The approach is novel in its direct inspiration from cellular neuromodulation to dynamically tune the input/output behavior of neurons within a DNN by modulating activation function parameters (slope and bias) in a context-dependent manner, rather than solely relying on synaptic plasticity or weight modulation \\cite{vecoven2018hc1}. The linear scaling of new parameters with the number of neurons also represents a significant architectural advantage for scalability \\cite{vecoven2018hc1}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Architecture**: Introduction of the Neuro-Modulated Network (NMN) architecture, specifically designed to learn adaptive behaviors by integrating a dedicated neuromodulatory network with a main processing network \\cite{vecoven2018hc1}.\n    *   **Dynamic Activation Function Modulation**: A new mechanism for adaptation where a neuromodulatory network dynamically tunes the slope and bias parameters of the main network's activation functions, enabling context-dependent neuron behavior \\cite{vecoven2018hc1}.\n    *   **Efficient Parameter Scaling**: The design ensures that the number of newly introduced parameters scales linearly with the number of neurons in the main network, offering a more scalable solution for large networks compared to weight-modulating approaches like hypernetworks \\cite{vecoven2018hc1}.\n    *   **Context-Dependent Signal Generation**: The neuromodulatory network processes feedback and contextual data to generate a dynamic neuromodulatory signal, allowing the main network to adapt its processing based on evolving environmental information \\cite{vecoven2018hc1}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   The NMN architecture was evaluated in a meta-reinforcement learning (meta-RL) context, comparing its performance against standard Recurrent Neural Networks (RNNs) \\cite{vecoven2018hc1}.\n        *   Both NMNs and RNNs were used to model the actor and critic components of an Advantage Actor-Critic (A2C) algorithm, trained with Generalized Advantage Estimation (GAE) and Proximal Policy Updates (PPO) \\cite{vecoven2018hc1}.\n        *   Experiments were conducted on three custom navigation benchmarks with continuous action spaces, designed to test adaptation to varying task parameters (e.g., target bias, wind direction, reward valence) \\cite{vecoven2018hc1}.\n        *   The neuromodulatory network was implemented as an RNN, processing historical context and feedback, while the main network received the current state \\cite{vecoven2018hc1}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Learning Performance**: NMNs consistently learned faster (requiring fewer episodes) and converged to better policies (achieving higher cumulative rewards) than standard RNNs across all three benchmarks \\cite{vecoven2018hc1}.\n        *   **Stability**: NMNs demonstrated significantly more stable training, exhibiting smaller variances over different random seeds compared to RNNs \\cite{vecoven2018hc1}.\n        *   **Near-Optimal Adaptation**: On the simplest benchmark, NMNs achieved an expected sum of rewards (4534) very close to the theoretical optimal Bayesian policy (4679), indicating their ability to learn highly adaptive and efficient behaviors \\cite{vecoven2018hc1}.\n        *   **Dynamic Adaptation Analysis**: Analysis of the neuromodulatory signal `z` showed its dynamic evolution within an episode, initially reflecting uncertainty and progressively converging to a context-dependent value as more task information became available. This adaptation was reflected in the continuous tuning of neuron scale factors, including slope inversion and deactivation of neurons for specific contexts \\cite{vecoven2018hc1}.\n        *   **Robustness**: The agent demonstrated the ability to perform well even when the neuromodulatory signal had not fully converged, indicating effective action with sufficient but incomplete information about the current task \\cite{vecoven2018hc1}.\n\n6.  **Limitations & Scope**\n    *   **Activation Function Sensitivity**: The main network primarily utilized saturated rectified linear unit (sReLU) activation functions, with sigmoidal functions yielding appreciably inferior results, suggesting that the choice of base activation function might influence performance \\cite{vecoven2018hc1}.\n    *   **Interpretability Complexity**: For more complex benchmarks, the interpretation of the neuromodulatory signal `z` became more challenging, indicating it might encode intricate combinations of task and state information \\cite{vecoven2018hc1}.\n    *   **Benchmark Specificity**: The experiments were conducted on custom navigation benchmarks, which, while effective for demonstrating adaptation, represent a specific set of environments and tasks \\cite{vecoven2018hc1}.\n    *   **Scope of Applicability**: The primary focus is on meta-reinforcement learning for adaptive behaviors in environments with continuous action spaces.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The NMN architecture represents a significant advancement in designing DNNs capable of learning adaptive behaviors, outperforming conventional RNNs in meta-RL tasks \\cite{vecoven2018hc1}.\n    *   **Biologically Inspired AI**: It provides a concrete, biologically inspired mechanism (cellular neuromodulation) for enhancing the adaptive capabilities of artificial neural networks, offering a new paradigm for architectural design \\cite{vecoven2018hc1}.\n    *   **Novel Adaptation Mechanism**: The paper demonstrates that dynamically modulating activation function parameters is an effective, scalable, and powerful method for achieving context-dependent adaptation in deep learning models \\cite{vecoven2018hc1}.\n    *   **Future Research Impact**: This work opens promising avenues for future research in developing more generalizable, robust, and adaptive artificial intelligence systems, particularly in domains requiring continuous learning and rapid adjustment to dynamic and unpredictable environments \\cite{vecoven2018hc1}.",
      "intriguing_abstract": "Deep Neural Networks (DNNs) often struggle with efficient generalization and adaptation, a stark contrast to the dynamic adaptability observed in biological systems through cellular neuromodulation. We introduce Neuro-Modulated Networks (NMNs) \\cite{vecoven2018hc1}, a novel architecture directly inspired by this biological mechanism. Unlike traditional approaches that modulate connection weights, NMNs feature a dedicated neuromodulatory network that dynamically tunes the *slope and bias parameters* of the main network's activation functions in a context-dependent manner. This innovative design offers superior scalability, with new parameters scaling linearly with the number of neurons, not connections.\n\nEvaluated in challenging meta-reinforcement learning (meta-RL) tasks, NMNs significantly outperform standard Recurrent Neural Networks (RNNs). Our experiments demonstrate faster learning, convergence to superior policies, and remarkably stable training across diverse navigation benchmarks. NMNs achieved near-optimal adaptation, dynamically adjusting neuron behavior, including activation and deactivation, based on evolving contextual information. This work presents a powerful, biologically-inspired paradigm for building truly adaptive and generalizable artificial intelligence systems, paving the way for robust AI capable of rapid, context-aware decision-making in unpredictable environments.",
      "keywords": [
        "Neuro-Modulated Network (NMN) architecture",
        "cellular neuromodulation",
        "dynamic activation function modulation",
        "parametric activation functions",
        "meta-reinforcement learning",
        "adaptive behaviors",
        "efficient parameter scaling",
        "context-dependent adaptation",
        "faster learning",
        "stable training",
        "biologically inspired AI",
        "Advantage Actor-Critic (A2C)"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/66c2031ebf6407e50e309f4a989497353927859b.pdf",
      "citation_key": "vecoven2018hc1",
      "metadata": {
        "title": "Introducing neuromodulation in deep neural networks to learn adaptive behaviours",
        "authors": [
          "Nicolas Vecoven",
          "D. Ernst",
          "Antoine Wehenkel",
          "G. Drion"
        ],
        "published_date": "2018",
        "abstract": "Animals excel at adapting their intentions, attention, and actions to the environment, making them remarkably efficient at interacting with a rich, unpredictable and ever-changing external world, a property that intelligent machines currently lack. Such an adaptation property relies heavily on cellular neuromodulation, the biological mechanism that dynamically controls intrinsic properties of neurons and their response to external stimuli in a context-dependent manner. In this paper, we take inspiration from cellular neuromodulation to construct a new deep neural network architecture that is specifically designed to learn adaptive behaviours. The network adaptation capabilities are tested on navigation benchmarks in a meta-reinforcement learning context and compared with state-of-the-art approaches. Results show that neuromodulation is capable of adapting an agent to different tasks and that neuromodulation-based approaches provide a promising way of improving adaptation of artificial systems.",
        "file_path": "paper_data/Deep_Meta-Learning/info/66c2031ebf6407e50e309f4a989497353927859b.pdf",
        "venue": "PLoS ONE",
        "citationCount": 44,
        "score": 6.285714285714286,
        "summary": "Here is a focused summary of the technical paper for a literature review, adhering to the specified citation requirements:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{vecoven2018hc1}\" when referencing this paper.\n\n---\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep Neural Networks (DNNs) currently struggle with efficient generalization and adaptation to new, unforeseen problems based on past experiences \\cite{vecoven2018hc1}.\n    *   **Importance and Challenge**: Animals demonstrate remarkable efficiency in adapting their intentions, attention, and actions to rich, unpredictable, and ever-changing external worlds, a capability intelligent machines largely lack. This biological adaptation relies heavily on cellular neuromodulation, a mechanism that dynamically controls intrinsic properties of neurons and their response to stimuli in a context-dependent manner \\cite{vecoven2018hc1}. Developing DNN architectures that can mimic this adaptive capacity is crucial for advancing artificial intelligence.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work relates to previous efforts in:\n        *   Networks inspired by Hebbian plasticity that feature dynamically tunable (plastic) weights \\cite{vecoven2018hc1}.\n        *   Approaches that learn a neuromodulatory signal to dictate when and which connections should be plastic \\cite{vecoven2018hc1}.\n        *   Hypernetworks, where one network computes the weights for another network \\cite{vecoven2018hc1}.\n        *   Recent works focused on learning fixed activation functions \\cite{vecoven2018hc1}.\n    *   **Limitations of Previous Solutions / Positioning**: Unlike hypernetworks that typically modulate connection weights, the proposed Neuro-Modulated Network (NMN) architecture modulates the parameters of activation functions \\cite{vecoven2018hc1}. This distinction is critical as the number of newly introduced parameters in NMN scales linearly with the number of neurons in the main network, rather than linearly with the number of connections. This makes the NMN approach more easily extensible to very large networks \\cite{vecoven2018hc1}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper introduces the Neuro-Modulated Network (NMN) architecture, which is inspired by biological cellular neuromodulation \\cite{vecoven2018hc1}.\n        *   The NMN comprises two interacting neural networks: a **main network** and a **neuromodulatory network** \\cite{vecoven2018hc1}.\n        *   The main network is a feed-forward DNN composed of neurons equipped with **parametric activation functions** \\cite{vecoven2018hc1}.\n        *   The neuromodulatory network dynamically controls the neuronal properties of the main network by tuning the **slope (`ws`) and bias (`wb`) parameters** of these activation functions \\cite{vecoven2018hc1}.\n        *   The neuromodulatory signal `z` is shared across all neuromodulated neurons and is computed by the neuromodulatory network based on contextual and feedback inputs (`c`). The main network processes other primary inputs (`x`) \\cite{vecoven2018hc1}.\n        *   The neuromodulated activation function is defined as `NMN(x;z;ws;wb) = z^T(x*ws + wb)`, where `z` is the context-dependent neuromodulatory signal \\cite{vecoven2018hc1}.\n    *   **Novelty**: The approach is novel in its direct inspiration from cellular neuromodulation to dynamically tune the input/output behavior of neurons within a DNN by modulating activation function parameters (slope and bias) in a context-dependent manner, rather than solely relying on synaptic plasticity or weight modulation \\cite{vecoven2018hc1}. The linear scaling of new parameters with the number of neurons also represents a significant architectural advantage for scalability \\cite{vecoven2018hc1}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Architecture**: Introduction of the Neuro-Modulated Network (NMN) architecture, specifically designed to learn adaptive behaviors by integrating a dedicated neuromodulatory network with a main processing network \\cite{vecoven2018hc1}.\n    *   **Dynamic Activation Function Modulation**: A new mechanism for adaptation where a neuromodulatory network dynamically tunes the slope and bias parameters of the main network's activation functions, enabling context-dependent neuron behavior \\cite{vecoven2018hc1}.\n    *   **Efficient Parameter Scaling**: The design ensures that the number of newly introduced parameters scales linearly with the number of neurons in the main network, offering a more scalable solution for large networks compared to weight-modulating approaches like hypernetworks \\cite{vecoven2018hc1}.\n    *   **Context-Dependent Signal Generation**: The neuromodulatory network processes feedback and contextual data to generate a dynamic neuromodulatory signal, allowing the main network to adapt its processing based on evolving environmental information \\cite{vecoven2018hc1}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   The NMN architecture was evaluated in a meta-reinforcement learning (meta-RL) context, comparing its performance against standard Recurrent Neural Networks (RNNs) \\cite{vecoven2018hc1}.\n        *   Both NMNs and RNNs were used to model the actor and critic components of an Advantage Actor-Critic (A2C) algorithm, trained with Generalized Advantage Estimation (GAE) and Proximal Policy Updates (PPO) \\cite{vecoven2018hc1}.\n        *   Experiments were conducted on three custom navigation benchmarks with continuous action spaces, designed to test adaptation to varying task parameters (e.g., target bias, wind direction, reward valence) \\cite{vecoven2018hc1}.\n        *   The neuromodulatory network was implemented as an RNN, processing historical context and feedback, while the main network received the current state \\cite{vecoven2018hc1}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Learning Performance**: NMNs consistently learned faster (requiring fewer episodes) and converged to better policies (achieving higher cumulative rewards) than standard RNNs across all three benchmarks \\cite{vecoven2018hc1}.\n        *   **Stability**: NMNs demonstrated significantly more stable training, exhibiting smaller variances over different random seeds compared to RNNs \\cite{vecoven2018hc1}.\n        *   **Near-Optimal Adaptation**: On the simplest benchmark, NMNs achieved an expected sum of rewards (4534) very close to the theoretical optimal Bayesian policy (4679), indicating their ability to learn highly adaptive and efficient behaviors \\cite{vecoven2018hc1}.\n        *   **Dynamic Adaptation Analysis**: Analysis of the neuromodulatory signal `z` showed its dynamic evolution within an episode, initially reflecting uncertainty and progressively converging to a context-dependent value as more task information became available. This adaptation was reflected in the continuous tuning of neuron scale factors, including slope inversion and deactivation of neurons for specific contexts \\cite{vecoven2018hc1}.\n        *   **Robustness**: The agent demonstrated the ability to perform well even when the neuromodulatory signal had not fully converged, indicating effective action with sufficient but incomplete information about the current task \\cite{vecoven2018hc1}.\n\n6.  **Limitations & Scope**\n    *   **Activation Function Sensitivity**: The main network primarily utilized saturated rectified linear unit (sReLU) activation functions, with sigmoidal functions yielding appreciably inferior results, suggesting that the choice of base activation function might influence performance \\cite{vecoven2018hc1}.\n    *   **Interpretability Complexity**: For more complex benchmarks, the interpretation of the neuromodulatory signal `z` became more challenging, indicating it might encode intricate combinations of task and state information \\cite{vecoven2018hc1}.\n    *   **Benchmark Specificity**: The experiments were conducted on custom navigation benchmarks, which, while effective for demonstrating adaptation, represent a specific set of environments and tasks \\cite{vecoven2018hc1}.\n    *   **Scope of Applicability**: The primary focus is on meta-reinforcement learning for adaptive behaviors in environments with continuous action spaces.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The NMN architecture represents a significant advancement in designing DNNs capable of learning adaptive behaviors, outperforming conventional RNNs in meta-RL tasks \\cite{vecoven2018hc1}.\n    *   **Biologically Inspired AI**: It provides a concrete, biologically inspired mechanism (cellular neuromodulation) for enhancing the adaptive capabilities of artificial neural networks, offering a new paradigm for architectural design \\cite{vecoven2018hc1}.\n    *   **Novel Adaptation Mechanism**: The paper demonstrates that dynamically modulating activation function parameters is an effective, scalable, and powerful method for achieving context-dependent adaptation in deep learning models \\cite{vecoven2018hc1}.\n    *   **Future Research Impact**: This work opens promising avenues for future research in developing more generalizable, robust, and adaptive artificial intelligence systems, particularly in domains requiring continuous learning and rapid adjustment to dynamic and unpredictable environments \\cite{vecoven2018hc1}.",
        "keywords": [
          "Neuro-Modulated Network (NMN) architecture",
          "cellular neuromodulation",
          "dynamic activation function modulation",
          "parametric activation functions",
          "meta-reinforcement learning",
          "adaptive behaviors",
          "efficient parameter scaling",
          "context-dependent adaptation",
          "faster learning",
          "stable training",
          "biologically inspired AI",
          "Advantage Actor-Critic (A2C)"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n*   **abstract:** explicitly states \"we take inspiration from cellular neuromodulation to construct a new deep neural network architecture that is specifically designed to learn adaptive behaviours.\" this directly aligns with the \"technical\" criterion of presenting new methods, algorithms, or systems (\"propose\", \"develop\", \"present\", \"algorithm\", \"method\").\n*   **introduction:** discusses the need for \"novel architectures specifically designed to enhance adaptation capabilities of current dnns,\" further reinforcing the focus on developing a new solution.\n*   while the paper also includes empirical evaluation (\"the network adaptation capabilities are tested on navigation benchmarks... results show...\"), the primary contribution highlighted is the *construction of a new architecture*. the empirical part serves to validate this new technical contribution."
      },
      "file_name": "66c2031ebf6407e50e309f4a989497353927859b.pdf"
    },
    {
      "success": true,
      "doc_id": "553d5e27bb8022b396ac13c0833d77a4",
      "summary": "Recently, deep learning-based methods outperform others in hyperspectral image (HSI) classification. However, the deep learning methods require sufficient labeled samples to improve performance, which is unfeasible in practice. The training labels are usually limited in HSIs that need to be classified (namely target domain), while other available labels in multisource HSIs (namely source domain) are not utilized effectively. To mitigate these issues, an attention multisource fusion method of few-shot learning (AMF-FSL) is proposed for small-sized HSI classification. AMF-FSL is an implementation of few-shot learning (FSL) in the meta-learning field, which can transfer the learned ability of classification from multiple source data to target data. The process of learning to classify in AMF-FSL is not restricted by the traditional requirement of the same distribution between the source and target domains, which can learn from the source domain and apply it to a different distribution in the target domain. Moreover, the multisource domain adaption in AMF-FSL has the capacity of extracting features from fused homogeneous and heterogeneous data in the source domain, which can improve the generalization of the classification model in the cross domains. Specifically, the multisource domain adaption contains three modules, namely the target-based class alignment, domain attention assignment, and multisource data fusion, which are responsible for aligning the class space, paying band-level attention, and merging the distributions of homogeneous and heterogeneous data in the source domain. The experimental results demonstrate the effectiveness of the multisource domain adaption and the superiority of AMF-FSL over other state-of-the-art methods in small-sized HSI classification.",
      "intriguing_abstract": "Recently, deep learning-based methods outperform others in hyperspectral image (HSI) classification. However, the deep learning methods require sufficient labeled samples to improve performance, which is unfeasible in practice. The training labels are usually limited in HSIs that need to be classified (namely target domain), while other available labels in multisource HSIs (namely source domain) are not utilized effectively. To mitigate these issues, an attention multisource fusion method of few-shot learning (AMF-FSL) is proposed for small-sized HSI classification. AMF-FSL is an implementation of few-shot learning (FSL) in the meta-learning field, which can transfer the learned ability of classification from multiple source data to target data. The process of learning to classify in AMF-FSL is not restricted by the traditional requirement of the same distribution between the source and target domains, which can learn from the source domain and apply it to a different distribution in the target domain. Moreover, the multisource domain adaption in AMF-FSL has the capacity of extracting features from fused homogeneous and heterogeneous data in the source domain, which can improve the generalization of the classification model in the cross domains. Specifically, the multisource domain adaption contains three modules, namely the target-based class alignment, domain attention assignment, and multisource data fusion, which are responsible for aligning the class space, paying band-level attention, and merging the distributions of homogeneous and heterogeneous data in the source domain. The experimental results demonstrate the effectiveness of the multisource domain adaption and the superiority of AMF-FSL over other state-of-the-art methods in small-sized HSI classification.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/4da500f57577b4ee207ab80b4cde0e1ee338f948.pdf",
      "citation_key": "liang2021juf",
      "metadata": {
        "title": "Attention Multisource Fusion-Based Deep Few-Shot Learning for Hyperspectral Image Classification",
        "authors": [
          "Xuejian Liang",
          "Yehui Zhang",
          "Junping Zhang"
        ],
        "published_date": "2021",
        "abstract": "Recently, deep learning-based methods outperform others in hyperspectral image (HSI) classification. However, the deep learning methods require sufficient labeled samples to improve performance, which is unfeasible in practice. The training labels are usually limited in HSIs that need to be classified (namely target domain), while other available labels in multisource HSIs (namely source domain) are not utilized effectively. To mitigate these issues, an attention multisource fusion method of few-shot learning (AMF-FSL) is proposed for small-sized HSI classification. AMF-FSL is an implementation of few-shot learning (FSL) in the meta-learning field, which can transfer the learned ability of classification from multiple source data to target data. The process of learning to classify in AMF-FSL is not restricted by the traditional requirement of the same distribution between the source and target domains, which can learn from the source domain and apply it to a different distribution in the target domain. Moreover, the multisource domain adaption in AMF-FSL has the capacity of extracting features from fused homogeneous and heterogeneous data in the source domain, which can improve the generalization of the classification model in the cross domains. Specifically, the multisource domain adaption contains three modules, namely the target-based class alignment, domain attention assignment, and multisource data fusion, which are responsible for aligning the class space, paying band-level attention, and merging the distributions of homogeneous and heterogeneous data in the source domain. The experimental results demonstrate the effectiveness of the multisource domain adaption and the superiority of AMF-FSL over other state-of-the-art methods in small-sized HSI classification.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4da500f57577b4ee207ab80b4cde0e1ee338f948.pdf",
        "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "citationCount": 25,
        "score": 6.25,
        "summary": "Recently, deep learning-based methods outperform others in hyperspectral image (HSI) classification. However, the deep learning methods require sufficient labeled samples to improve performance, which is unfeasible in practice. The training labels are usually limited in HSIs that need to be classified (namely target domain), while other available labels in multisource HSIs (namely source domain) are not utilized effectively. To mitigate these issues, an attention multisource fusion method of few-shot learning (AMF-FSL) is proposed for small-sized HSI classification. AMF-FSL is an implementation of few-shot learning (FSL) in the meta-learning field, which can transfer the learned ability of classification from multiple source data to target data. The process of learning to classify in AMF-FSL is not restricted by the traditional requirement of the same distribution between the source and target domains, which can learn from the source domain and apply it to a different distribution in the target domain. Moreover, the multisource domain adaption in AMF-FSL has the capacity of extracting features from fused homogeneous and heterogeneous data in the source domain, which can improve the generalization of the classification model in the cross domains. Specifically, the multisource domain adaption contains three modules, namely the target-based class alignment, domain attention assignment, and multisource data fusion, which are responsible for aligning the class space, paying band-level attention, and merging the distributions of homogeneous and heterogeneous data in the source domain. The experimental results demonstrate the effectiveness of the multisource domain adaption and the superiority of AMF-FSL over other state-of-the-art methods in small-sized HSI classification.",
        "keywords": []
      },
      "file_name": "4da500f57577b4ee207ab80b4cde0e1ee338f948.pdf"
    },
    {
      "success": true,
      "doc_id": "83b2bfdf1f6625cac8a6da33aa413866",
      "summary": "The success of deep learning methods hinges on the availability of large training datasets annotated for the task of interest. In contrast to human intelligence, these methods lack versatility and struggle to learn and adapt quickly to new tasks, where labeled data is scarce. Meta-learning aims to solve this problem by training a model on a large number of few-shot tasks, with an objective to learn new tasks quickly from a small number of examples. In this paper, we propose a meta-learning framework for few-shot word sense disambiguation (WSD), where the goal is to learn to disambiguate unseen words from only a few labeled instances. Meta-learning approaches have so far been typically tested in an N-way, K-shot classification setting where each task has N classes with K examples per class. Owing to its nature, WSD deviates from this controlled setup and requires the models to handle a large number of highly unbalanced classes. We extend several popular meta-learning approaches to this scenario, and analyze their strengths and weaknesses in this new challenging setting.",
      "intriguing_abstract": "The success of deep learning methods hinges on the availability of large training datasets annotated for the task of interest. In contrast to human intelligence, these methods lack versatility and struggle to learn and adapt quickly to new tasks, where labeled data is scarce. Meta-learning aims to solve this problem by training a model on a large number of few-shot tasks, with an objective to learn new tasks quickly from a small number of examples. In this paper, we propose a meta-learning framework for few-shot word sense disambiguation (WSD), where the goal is to learn to disambiguate unseen words from only a few labeled instances. Meta-learning approaches have so far been typically tested in an N-way, K-shot classification setting where each task has N classes with K examples per class. Owing to its nature, WSD deviates from this controlled setup and requires the models to handle a large number of highly unbalanced classes. We extend several popular meta-learning approaches to this scenario, and analyze their strengths and weaknesses in this new challenging setting.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c317d2faa26b38250960cf3d2e6cf095b9d5b92d.pdf",
      "citation_key": "holla2020r6z",
      "metadata": {
        "title": "Learning to Learn to Disambiguate: Meta-Learning for Few-Shot Word Sense Disambiguation",
        "authors": [
          "Nithin Holla",
          "Pushkar Mishra",
          "H. Yannakoudakis",
          "Ekaterina Shutova"
        ],
        "published_date": "2020",
        "abstract": "The success of deep learning methods hinges on the availability of large training datasets annotated for the task of interest. In contrast to human intelligence, these methods lack versatility and struggle to learn and adapt quickly to new tasks, where labeled data is scarce. Meta-learning aims to solve this problem by training a model on a large number of few-shot tasks, with an objective to learn new tasks quickly from a small number of examples. In this paper, we propose a meta-learning framework for few-shot word sense disambiguation (WSD), where the goal is to learn to disambiguate unseen words from only a few labeled instances. Meta-learning approaches have so far been typically tested in an N-way, K-shot classification setting where each task has N classes with K examples per class. Owing to its nature, WSD deviates from this controlled setup and requires the models to handle a large number of highly unbalanced classes. We extend several popular meta-learning approaches to this scenario, and analyze their strengths and weaknesses in this new challenging setting.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c317d2faa26b38250960cf3d2e6cf095b9d5b92d.pdf",
        "venue": "Findings",
        "citationCount": 29,
        "score": 5.800000000000001,
        "summary": "The success of deep learning methods hinges on the availability of large training datasets annotated for the task of interest. In contrast to human intelligence, these methods lack versatility and struggle to learn and adapt quickly to new tasks, where labeled data is scarce. Meta-learning aims to solve this problem by training a model on a large number of few-shot tasks, with an objective to learn new tasks quickly from a small number of examples. In this paper, we propose a meta-learning framework for few-shot word sense disambiguation (WSD), where the goal is to learn to disambiguate unseen words from only a few labeled instances. Meta-learning approaches have so far been typically tested in an N-way, K-shot classification setting where each task has N classes with K examples per class. Owing to its nature, WSD deviates from this controlled setup and requires the models to handle a large number of highly unbalanced classes. We extend several popular meta-learning approaches to this scenario, and analyze their strengths and weaknesses in this new challenging setting.",
        "keywords": []
      },
      "file_name": "c317d2faa26b38250960cf3d2e6cf095b9d5b92d.pdf"
    },
    {
      "success": true,
      "doc_id": "14c07c1d1301296b4a679663845712c7",
      "summary": "The scope of the Baldwin effect was recently called into question by two papers that closely examined the seminal work of Hinton and Nowlan. To this date there has been no demonstration of its necessity in empirically challenging tasks. Here we show that the Baldwin effect is capable of evolving few-shot supervised and reinforcement learning mechanisms, by shaping the hyperparameters and the initial parameters of deep learning algorithms. Furthermore it can genetically accommodate strong learning biases on the same set of problems as a recent machine learning algorithm called MAML \"Model Agnostic Meta-Learning\" which uses second-order gradients instead of evolution to learn a set of reference parameters (initial weights) that can allow rapid adaptation to tasks sampled from a distribution. Whilst in simple cases MAML is more data efficient than the Baldwin effect, the Baldwin effect is more general in that it does not require gradients to be backpropagated to the reference parameters or hyperparameters, and permits effectively any number of gradient updates in the inner loop. The Baldwin effect learns strong learning dependent biases, rather than purely genetically accommodating fixed behaviours in a learning independent manner.",
      "intriguing_abstract": "The scope of the Baldwin effect was recently called into question by two papers that closely examined the seminal work of Hinton and Nowlan. To this date there has been no demonstration of its necessity in empirically challenging tasks. Here we show that the Baldwin effect is capable of evolving few-shot supervised and reinforcement learning mechanisms, by shaping the hyperparameters and the initial parameters of deep learning algorithms. Furthermore it can genetically accommodate strong learning biases on the same set of problems as a recent machine learning algorithm called MAML \"Model Agnostic Meta-Learning\" which uses second-order gradients instead of evolution to learn a set of reference parameters (initial weights) that can allow rapid adaptation to tasks sampled from a distribution. Whilst in simple cases MAML is more data efficient than the Baldwin effect, the Baldwin effect is more general in that it does not require gradients to be backpropagated to the reference parameters or hyperparameters, and permits effectively any number of gradient updates in the inner loop. The Baldwin effect learns strong learning dependent biases, rather than purely genetically accommodating fixed behaviours in a learning independent manner.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/26b07c6309ef12034571f20973097691a22d7116.pdf",
      "citation_key": "fernando2018lt5",
      "metadata": {
        "title": "Meta-learning by the Baldwin effect",
        "authors": [
          "Chrisantha Fernando",
          "Jakub Sygnowski",
          "Simon Osindero",
          "Jane X. Wang",
          "T. Schaul",
          "Denis Teplyashin",
          "P. Sprechmann",
          "A. Pritzel",
          "Andrei A. Rusu"
        ],
        "published_date": "2018",
        "abstract": "The scope of the Baldwin effect was recently called into question by two papers that closely examined the seminal work of Hinton and Nowlan. To this date there has been no demonstration of its necessity in empirically challenging tasks. Here we show that the Baldwin effect is capable of evolving few-shot supervised and reinforcement learning mechanisms, by shaping the hyperparameters and the initial parameters of deep learning algorithms. Furthermore it can genetically accommodate strong learning biases on the same set of problems as a recent machine learning algorithm called MAML \"Model Agnostic Meta-Learning\" which uses second-order gradients instead of evolution to learn a set of reference parameters (initial weights) that can allow rapid adaptation to tasks sampled from a distribution. Whilst in simple cases MAML is more data efficient than the Baldwin effect, the Baldwin effect is more general in that it does not require gradients to be backpropagated to the reference parameters or hyperparameters, and permits effectively any number of gradient updates in the inner loop. The Baldwin effect learns strong learning dependent biases, rather than purely genetically accommodating fixed behaviours in a learning independent manner.",
        "file_path": "paper_data/Deep_Meta-Learning/info/26b07c6309ef12034571f20973097691a22d7116.pdf",
        "venue": "Annual Conference on Genetic and Evolutionary Computation",
        "citationCount": 40,
        "score": 5.7142857142857135,
        "summary": "The scope of the Baldwin effect was recently called into question by two papers that closely examined the seminal work of Hinton and Nowlan. To this date there has been no demonstration of its necessity in empirically challenging tasks. Here we show that the Baldwin effect is capable of evolving few-shot supervised and reinforcement learning mechanisms, by shaping the hyperparameters and the initial parameters of deep learning algorithms. Furthermore it can genetically accommodate strong learning biases on the same set of problems as a recent machine learning algorithm called MAML \"Model Agnostic Meta-Learning\" which uses second-order gradients instead of evolution to learn a set of reference parameters (initial weights) that can allow rapid adaptation to tasks sampled from a distribution. Whilst in simple cases MAML is more data efficient than the Baldwin effect, the Baldwin effect is more general in that it does not require gradients to be backpropagated to the reference parameters or hyperparameters, and permits effectively any number of gradient updates in the inner loop. The Baldwin effect learns strong learning dependent biases, rather than purely genetically accommodating fixed behaviours in a learning independent manner.",
        "keywords": []
      },
      "file_name": "26b07c6309ef12034571f20973097691a22d7116.pdf"
    },
    {
      "success": true,
      "doc_id": "0dcc7f5f3c25765ea27108220e91b8aa",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/475468f90bd44d34e30991873a37c38e75ff3ffe.pdf",
      "citation_key": "jankowski20138zb",
      "metadata": {
        "title": "Meta-Learning in Computational Intelligence",
        "authors": [
          "Norbert Jankowski",
          "Wlodzislaw Duch",
          "Krzysztof Grabczewski"
        ],
        "published_date": "2013",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/475468f90bd44d34e30991873a37c38e75ff3ffe.pdf",
        "venue": "Meta-Learning in Computational Intelligence",
        "citationCount": 67,
        "score": 5.583333333333333,
        "summary": "",
        "keywords": []
      },
      "file_name": "475468f90bd44d34e30991873a37c38e75ff3ffe.pdf"
    },
    {
      "success": true,
      "doc_id": "ef07132bd779ed566ed6bcdd3dcd5469",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/dfd4135cc81c6dfe5ccc4d6d54b4652fa3dd831f.pdf",
      "citation_key": "banayeeanzade2021zke",
      "metadata": {
        "title": "Generative vs. Discriminative: Rethinking The Meta-Continual Learning",
        "authors": [
          "Mohammadamin Banayeeanzade",
          "Rasoul Mirzaiezadeh",
          "Hosein Hasani",
          "Mahdieh Soleymani"
        ],
        "published_date": "2021",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/dfd4135cc81c6dfe5ccc4d6d54b4652fa3dd831f.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 22,
        "score": 5.5,
        "summary": "",
        "keywords": []
      },
      "file_name": "dfd4135cc81c6dfe5ccc4d6d54b4652fa3dd831f.pdf"
    },
    {
      "success": true,
      "doc_id": "639bb8bd5ea440c07512cc7bd7bf8a6e",
      "summary": "In the last 20 years, terrorism has led to hundreds of thousands of deaths and massive economic, political, and humanitarian crises in several regions of the world. Using real-world data on attacks occurred in Afghanistan and Iraq from 2001 to 2018, we propose the use of temporal meta-graphs and deep learning to forecast future terrorist targets. Focusing on three event dimensions, i.e., employed weapons, deployed tactics and chosen targets, meta-graphs map the connections among temporally close attacks, capturing their operational similarities and dependencies. From these temporal meta-graphs, we derive 2-day-based time series that measure the centrality of each feature within each dimension over time. Formulating the problem in the context of the strategic behavior of terrorist actors, these multivariate temporal sequences are then utilized to learn what target types are at the highest risk of being chosen. The paper makes two contributions. First, it demonstrates that engineering the feature space via temporal meta-graphs produces richer knowledge than shallow time-series that only rely on frequency of feature occurrences. Second, the performed experiments reveal that bi-directional LSTM networks achieve superior forecasting performance compared to other algorithms, calling for future research aiming at fully discovering the potential of artificial intelligence to counter terrorist violence.",
      "intriguing_abstract": "In the last 20 years, terrorism has led to hundreds of thousands of deaths and massive economic, political, and humanitarian crises in several regions of the world. Using real-world data on attacks occurred in Afghanistan and Iraq from 2001 to 2018, we propose the use of temporal meta-graphs and deep learning to forecast future terrorist targets. Focusing on three event dimensions, i.e., employed weapons, deployed tactics and chosen targets, meta-graphs map the connections among temporally close attacks, capturing their operational similarities and dependencies. From these temporal meta-graphs, we derive 2-day-based time series that measure the centrality of each feature within each dimension over time. Formulating the problem in the context of the strategic behavior of terrorist actors, these multivariate temporal sequences are then utilized to learn what target types are at the highest risk of being chosen. The paper makes two contributions. First, it demonstrates that engineering the feature space via temporal meta-graphs produces richer knowledge than shallow time-series that only rely on frequency of feature occurrences. Second, the performed experiments reveal that bi-directional LSTM networks achieve superior forecasting performance compared to other algorithms, calling for future research aiming at fully discovering the potential of artificial intelligence to counter terrorist violence.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/0c7081bbc26a62aaf7d4ec161a8c59a2b8d162eb.pdf",
      "citation_key": "campedelli2021jja",
      "metadata": {
        "title": "Learning future terrorist targets through temporal meta-graphs",
        "authors": [
          "G. Campedelli",
          "Mihovil Bartulovic",
          "K. Carley"
        ],
        "published_date": "2021",
        "abstract": "In the last 20 years, terrorism has led to hundreds of thousands of deaths and massive economic, political, and humanitarian crises in several regions of the world. Using real-world data on attacks occurred in Afghanistan and Iraq from 2001 to 2018, we propose the use of temporal meta-graphs and deep learning to forecast future terrorist targets. Focusing on three event dimensions, i.e., employed weapons, deployed tactics and chosen targets, meta-graphs map the connections among temporally close attacks, capturing their operational similarities and dependencies. From these temporal meta-graphs, we derive 2-day-based time series that measure the centrality of each feature within each dimension over time. Formulating the problem in the context of the strategic behavior of terrorist actors, these multivariate temporal sequences are then utilized to learn what target types are at the highest risk of being chosen. The paper makes two contributions. First, it demonstrates that engineering the feature space via temporal meta-graphs produces richer knowledge than shallow time-series that only rely on frequency of feature occurrences. Second, the performed experiments reveal that bi-directional LSTM networks achieve superior forecasting performance compared to other algorithms, calling for future research aiming at fully discovering the potential of artificial intelligence to counter terrorist violence.",
        "file_path": "paper_data/Deep_Meta-Learning/info/0c7081bbc26a62aaf7d4ec161a8c59a2b8d162eb.pdf",
        "venue": "Scientific Reports",
        "citationCount": 22,
        "score": 5.5,
        "summary": "In the last 20 years, terrorism has led to hundreds of thousands of deaths and massive economic, political, and humanitarian crises in several regions of the world. Using real-world data on attacks occurred in Afghanistan and Iraq from 2001 to 2018, we propose the use of temporal meta-graphs and deep learning to forecast future terrorist targets. Focusing on three event dimensions, i.e., employed weapons, deployed tactics and chosen targets, meta-graphs map the connections among temporally close attacks, capturing their operational similarities and dependencies. From these temporal meta-graphs, we derive 2-day-based time series that measure the centrality of each feature within each dimension over time. Formulating the problem in the context of the strategic behavior of terrorist actors, these multivariate temporal sequences are then utilized to learn what target types are at the highest risk of being chosen. The paper makes two contributions. First, it demonstrates that engineering the feature space via temporal meta-graphs produces richer knowledge than shallow time-series that only rely on frequency of feature occurrences. Second, the performed experiments reveal that bi-directional LSTM networks achieve superior forecasting performance compared to other algorithms, calling for future research aiming at fully discovering the potential of artificial intelligence to counter terrorist violence.",
        "keywords": []
      },
      "file_name": "0c7081bbc26a62aaf7d4ec161a8c59a2b8d162eb.pdf"
    },
    {
      "success": true,
      "doc_id": "04cc1ced94ef1b10e18c6e78c40f8135",
      "summary": "Recently, deep metric learning (DML) has achieved great success. Some existing DML methods propose adaptive sample mining strategies, which learn to weight the samples, leading to interesting performance. However, these methods suffer from a small memory (e.g., one training batch), limiting their efficacy. In this work, we introduce a data-driven method, meta-mining strategy with semiglobal information (MMSI), to apply meta-learning to learn to weight samples during the whole training, leading to an adaptive mining strategy. To introduce richer information than one training batch only, we elaborately take advantage of the validation set of meta-learning by implicitly adding additional validation sample information to training. Furthermore, motivated by the latest self-supervised learning, we introduce a dictionary (memory) that maintains very large and diverse information. Together with the validation set, this dictionary presents much richer information to the training, leading to promising performance. In addition, we propose a new theoretical framework that can formulate pairwise and tripletwise metric learning loss functions in a unified framework. This framework brings new insights to society and facilitates us to generalize our MMSI to many existing DML methods. We conduct extensive experiments on three public datasets, CUB200-2011, Cars-196, and Stanford Online Products (SOP). Results show that our method can achieve the state of the art or very competitive performance. Our source codes have been made available at https://github.com/NUST-Machine-Intelligence-Laboratory/MMSI.",
      "intriguing_abstract": "Recently, deep metric learning (DML) has achieved great success. Some existing DML methods propose adaptive sample mining strategies, which learn to weight the samples, leading to interesting performance. However, these methods suffer from a small memory (e.g., one training batch), limiting their efficacy. In this work, we introduce a data-driven method, meta-mining strategy with semiglobal information (MMSI), to apply meta-learning to learn to weight samples during the whole training, leading to an adaptive mining strategy. To introduce richer information than one training batch only, we elaborately take advantage of the validation set of meta-learning by implicitly adding additional validation sample information to training. Furthermore, motivated by the latest self-supervised learning, we introduce a dictionary (memory) that maintains very large and diverse information. Together with the validation set, this dictionary presents much richer information to the training, leading to promising performance. In addition, we propose a new theoretical framework that can formulate pairwise and tripletwise metric learning loss functions in a unified framework. This framework brings new insights to society and facilitates us to generalize our MMSI to many existing DML methods. We conduct extensive experiments on three public datasets, CUB200-2011, Cars-196, and Stanford Online Products (SOP). Results show that our method can achieve the state of the art or very competitive performance. Our source codes have been made available at https://github.com/NUST-Machine-Intelligence-Laboratory/MMSI.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2d8d30eb2f6d554d13be811d8cee541387573bd9.pdf",
      "citation_key": "jiang20220tg",
      "metadata": {
        "title": "Deep Metric Learning Based on Meta-Mining Strategy With Semiglobal Information",
        "authors": [
          "Xiruo Jiang",
          "Sheng Liu",
          "Xili Dai",
          "Guosheng Hu",
          "Xingguo Huang",
          "Yazhou Yao",
          "Guosen Xie",
          "Ling Shao"
        ],
        "published_date": "2022",
        "abstract": "Recently, deep metric learning (DML) has achieved great success. Some existing DML methods propose adaptive sample mining strategies, which learn to weight the samples, leading to interesting performance. However, these methods suffer from a small memory (e.g., one training batch), limiting their efficacy. In this work, we introduce a data-driven method, meta-mining strategy with semiglobal information (MMSI), to apply meta-learning to learn to weight samples during the whole training, leading to an adaptive mining strategy. To introduce richer information than one training batch only, we elaborately take advantage of the validation set of meta-learning by implicitly adding additional validation sample information to training. Furthermore, motivated by the latest self-supervised learning, we introduce a dictionary (memory) that maintains very large and diverse information. Together with the validation set, this dictionary presents much richer information to the training, leading to promising performance. In addition, we propose a new theoretical framework that can formulate pairwise and tripletwise metric learning loss functions in a unified framework. This framework brings new insights to society and facilitates us to generalize our MMSI to many existing DML methods. We conduct extensive experiments on three public datasets, CUB200-2011, Cars-196, and Stanford Online Products (SOP). Results show that our method can achieve the state of the art or very competitive performance. Our source codes have been made available at https://github.com/NUST-Machine-Intelligence-Laboratory/MMSI.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2d8d30eb2f6d554d13be811d8cee541387573bd9.pdf",
        "venue": "IEEE Transactions on Neural Networks and Learning Systems",
        "citationCount": 16,
        "score": 5.333333333333333,
        "summary": "Recently, deep metric learning (DML) has achieved great success. Some existing DML methods propose adaptive sample mining strategies, which learn to weight the samples, leading to interesting performance. However, these methods suffer from a small memory (e.g., one training batch), limiting their efficacy. In this work, we introduce a data-driven method, meta-mining strategy with semiglobal information (MMSI), to apply meta-learning to learn to weight samples during the whole training, leading to an adaptive mining strategy. To introduce richer information than one training batch only, we elaborately take advantage of the validation set of meta-learning by implicitly adding additional validation sample information to training. Furthermore, motivated by the latest self-supervised learning, we introduce a dictionary (memory) that maintains very large and diverse information. Together with the validation set, this dictionary presents much richer information to the training, leading to promising performance. In addition, we propose a new theoretical framework that can formulate pairwise and tripletwise metric learning loss functions in a unified framework. This framework brings new insights to society and facilitates us to generalize our MMSI to many existing DML methods. We conduct extensive experiments on three public datasets, CUB200-2011, Cars-196, and Stanford Online Products (SOP). Results show that our method can achieve the state of the art or very competitive performance. Our source codes have been made available at https://github.com/NUST-Machine-Intelligence-Laboratory/MMSI.",
        "keywords": []
      },
      "file_name": "2d8d30eb2f6d554d13be811d8cee541387573bd9.pdf"
    },
    {
      "success": true,
      "doc_id": "3553552f12828ff83f82a15916a70a27",
      "summary": "The goal of diagnosing the coronavirus disease 2019 (COVID‐19) from suspected pneumonia cases, that is, recognizing COVID‐19 from chest X‐ray or computed tomography (CT) images, is to improve diagnostic accuracy, leading to faster intervention. The most important and challenging problem here is to design an effective and robust diagnosis model. To this end, there are three challenges to overcome: (1) The lack of training samples limits the success of existing deep‐learning‐based methods. (2) Many public COVID‐19 data sets contain only a few images without fine‐grained labels. (3) Due to the explosive growth of suspected cases, it is urgent and important to diagnose not only COVID‐19 cases but also the cases of other types of pneumonia that are similar to the symptoms of COVID‐19. To address these issues, we propose a novel framework called Unsupervised Meta‐Learning with Self‐Knowledge Distillation to address the problem of differentiating COVID‐19 from pneumonia cases. During training, our model cannot use any true labels and aims to gain the ability of learning to learn by itself. In particular, we first present a deep diagnosis model based on a relation network to capture and memorize the relation among different images. Second, to enhance the performance of our model, we design a self‐knowledge distillation mechanism that distills knowledge within our model itself. Our network is divided into several parts, and the knowledge in the deeper parts is squeezed into the shallow ones. The final results are derived from our model by learning to compare the features of images. Experimental results demonstrate that our approach achieves significantly higher performance than other state‐of‐the‐art methods. Moreover, we construct a new COVID‐19 pneumonia data set based on text mining, consisting of 2696 COVID‐19 images (347 X‐ray + 2349 CT), 10,155 images (9661 X‐ray + 494 CT) about other types of pneumonia, and the fine‐grained labels of all. Our data set considers not only a bacterial infection or viral infection which causes pneumonia but also a viral infection derived from the influenza virus or coronavirus.",
      "intriguing_abstract": "The goal of diagnosing the coronavirus disease 2019 (COVID‐19) from suspected pneumonia cases, that is, recognizing COVID‐19 from chest X‐ray or computed tomography (CT) images, is to improve diagnostic accuracy, leading to faster intervention. The most important and challenging problem here is to design an effective and robust diagnosis model. To this end, there are three challenges to overcome: (1) The lack of training samples limits the success of existing deep‐learning‐based methods. (2) Many public COVID‐19 data sets contain only a few images without fine‐grained labels. (3) Due to the explosive growth of suspected cases, it is urgent and important to diagnose not only COVID‐19 cases but also the cases of other types of pneumonia that are similar to the symptoms of COVID‐19. To address these issues, we propose a novel framework called Unsupervised Meta‐Learning with Self‐Knowledge Distillation to address the problem of differentiating COVID‐19 from pneumonia cases. During training, our model cannot use any true labels and aims to gain the ability of learning to learn by itself. In particular, we first present a deep diagnosis model based on a relation network to capture and memorize the relation among different images. Second, to enhance the performance of our model, we design a self‐knowledge distillation mechanism that distills knowledge within our model itself. Our network is divided into several parts, and the knowledge in the deeper parts is squeezed into the shallow ones. The final results are derived from our model by learning to compare the features of images. Experimental results demonstrate that our approach achieves significantly higher performance than other state‐of‐the‐art methods. Moreover, we construct a new COVID‐19 pneumonia data set based on text mining, consisting of 2696 COVID‐19 images (347 X‐ray + 2349 CT), 10,155 images (9661 X‐ray + 494 CT) about other types of pneumonia, and the fine‐grained labels of all. Our data set considers not only a bacterial infection or viral infection which causes pneumonia but also a viral infection derived from the influenza virus or coronavirus.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5ffee7480bdb997a0f8452829016eee71cb8bbce.pdf",
      "citation_key": "zheng2021olf",
      "metadata": {
        "title": "Learning to learn by yourself: Unsupervised meta‐learning with self‐knowledge distillation for COVID‐19 diagnosis from pneumonia cases",
        "authors": [
          "Wenbo Zheng",
          "Lan Yan",
          "Chao Gou",
          "Zhi-Cheng Zhang",
          "J. Zhang",
          "Ming Hu",
          "Fei-Yue Wang"
        ],
        "published_date": "2021",
        "abstract": "The goal of diagnosing the coronavirus disease 2019 (COVID‐19) from suspected pneumonia cases, that is, recognizing COVID‐19 from chest X‐ray or computed tomography (CT) images, is to improve diagnostic accuracy, leading to faster intervention. The most important and challenging problem here is to design an effective and robust diagnosis model. To this end, there are three challenges to overcome: (1) The lack of training samples limits the success of existing deep‐learning‐based methods. (2) Many public COVID‐19 data sets contain only a few images without fine‐grained labels. (3) Due to the explosive growth of suspected cases, it is urgent and important to diagnose not only COVID‐19 cases but also the cases of other types of pneumonia that are similar to the symptoms of COVID‐19. To address these issues, we propose a novel framework called Unsupervised Meta‐Learning with Self‐Knowledge Distillation to address the problem of differentiating COVID‐19 from pneumonia cases. During training, our model cannot use any true labels and aims to gain the ability of learning to learn by itself. In particular, we first present a deep diagnosis model based on a relation network to capture and memorize the relation among different images. Second, to enhance the performance of our model, we design a self‐knowledge distillation mechanism that distills knowledge within our model itself. Our network is divided into several parts, and the knowledge in the deeper parts is squeezed into the shallow ones. The final results are derived from our model by learning to compare the features of images. Experimental results demonstrate that our approach achieves significantly higher performance than other state‐of‐the‐art methods. Moreover, we construct a new COVID‐19 pneumonia data set based on text mining, consisting of 2696 COVID‐19 images (347 X‐ray + 2349 CT), 10,155 images (9661 X‐ray + 494 CT) about other types of pneumonia, and the fine‐grained labels of all. Our data set considers not only a bacterial infection or viral infection which causes pneumonia but also a viral infection derived from the influenza virus or coronavirus.",
        "file_path": "paper_data/Deep_Meta-Learning/info/5ffee7480bdb997a0f8452829016eee71cb8bbce.pdf",
        "venue": "International Journal of Intelligent Systems",
        "citationCount": 21,
        "score": 5.25,
        "summary": "The goal of diagnosing the coronavirus disease 2019 (COVID‐19) from suspected pneumonia cases, that is, recognizing COVID‐19 from chest X‐ray or computed tomography (CT) images, is to improve diagnostic accuracy, leading to faster intervention. The most important and challenging problem here is to design an effective and robust diagnosis model. To this end, there are three challenges to overcome: (1) The lack of training samples limits the success of existing deep‐learning‐based methods. (2) Many public COVID‐19 data sets contain only a few images without fine‐grained labels. (3) Due to the explosive growth of suspected cases, it is urgent and important to diagnose not only COVID‐19 cases but also the cases of other types of pneumonia that are similar to the symptoms of COVID‐19. To address these issues, we propose a novel framework called Unsupervised Meta‐Learning with Self‐Knowledge Distillation to address the problem of differentiating COVID‐19 from pneumonia cases. During training, our model cannot use any true labels and aims to gain the ability of learning to learn by itself. In particular, we first present a deep diagnosis model based on a relation network to capture and memorize the relation among different images. Second, to enhance the performance of our model, we design a self‐knowledge distillation mechanism that distills knowledge within our model itself. Our network is divided into several parts, and the knowledge in the deeper parts is squeezed into the shallow ones. The final results are derived from our model by learning to compare the features of images. Experimental results demonstrate that our approach achieves significantly higher performance than other state‐of‐the‐art methods. Moreover, we construct a new COVID‐19 pneumonia data set based on text mining, consisting of 2696 COVID‐19 images (347 X‐ray + 2349 CT), 10,155 images (9661 X‐ray + 494 CT) about other types of pneumonia, and the fine‐grained labels of all. Our data set considers not only a bacterial infection or viral infection which causes pneumonia but also a viral infection derived from the influenza virus or coronavirus.",
        "keywords": []
      },
      "file_name": "5ffee7480bdb997a0f8452829016eee71cb8bbce.pdf"
    },
    {
      "success": true,
      "doc_id": "c558ee6da813e6ad047f7ac31d60f487",
      "summary": "Complex networks (CNs) have gained much attention in recent years due to their importance and popularity. The rapid growth in the size of CNs leads to more difficulties in the analysis of CNs tasks. Community Detection (CD) is an important multidisciplinary research area where many machine/deep learning-based methods have been applied to map CNs into a low-dimensional representation for extracting information similarity among members of CNs. Currently, Deep Learning (DL) is one of the promising methods to extract knowledge and learn information from high dimensional space and represent it in low dimensional space. However, designing an accurate and efficient DL-based CD method especially when dealing with large CNs is always an on-going research endeavor to pursue. Meta-Heuristic (MH) algorithms have shown their potentials in improving DL models in terms of solution quality and computational cost. In addition, parallel computing is a feasible solution for building efficient DL models. The algorithmic principle of MH is parallel in nature; however, its computation framework in DL training that is reported in the literature is not really implemented in a parallel computing setup. In this paper, we present a systematic review of CD in CNs from conventional machine learning to DL methods and point out the gap of applying DL-based CD methods in large CNs. In addition, the relevant studies on DL with parallel and MH approaches are reviewed and their implications on DL models are highlighted to prospect effective solutions to overcome the challenges of DL-based CD methods. We also point out research challenges in the field of CD and suggest possible future research directions.",
      "intriguing_abstract": "Complex networks (CNs) have gained much attention in recent years due to their importance and popularity. The rapid growth in the size of CNs leads to more difficulties in the analysis of CNs tasks. Community Detection (CD) is an important multidisciplinary research area where many machine/deep learning-based methods have been applied to map CNs into a low-dimensional representation for extracting information similarity among members of CNs. Currently, Deep Learning (DL) is one of the promising methods to extract knowledge and learn information from high dimensional space and represent it in low dimensional space. However, designing an accurate and efficient DL-based CD method especially when dealing with large CNs is always an on-going research endeavor to pursue. Meta-Heuristic (MH) algorithms have shown their potentials in improving DL models in terms of solution quality and computational cost. In addition, parallel computing is a feasible solution for building efficient DL models. The algorithmic principle of MH is parallel in nature; however, its computation framework in DL training that is reported in the literature is not really implemented in a parallel computing setup. In this paper, we present a systematic review of CD in CNs from conventional machine learning to DL methods and point out the gap of applying DL-based CD methods in large CNs. In addition, the relevant studies on DL with parallel and MH approaches are reviewed and their implications on DL models are highlighted to prospect effective solutions to overcome the challenges of DL-based CD methods. We also point out research challenges in the field of CD and suggest possible future research directions.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/af0d2f8b21334ea9d6dd05254923707f605635d6.pdf",
      "citation_key": "alandoli2021pqm",
      "metadata": {
        "title": "A Review on Community Detection in Large Complex Networks from Conventional to Deep Learning Methods: A Call for the Use of Parallel Meta-Heuristic Algorithms",
        "authors": [
          "M. Al-Andoli",
          "Shing Chiang Tan",
          "W. Cheah",
          "Sin Yin Tan"
        ],
        "published_date": "2021",
        "abstract": "Complex networks (CNs) have gained much attention in recent years due to their importance and popularity. The rapid growth in the size of CNs leads to more difficulties in the analysis of CNs tasks. Community Detection (CD) is an important multidisciplinary research area where many machine/deep learning-based methods have been applied to map CNs into a low-dimensional representation for extracting information similarity among members of CNs. Currently, Deep Learning (DL) is one of the promising methods to extract knowledge and learn information from high dimensional space and represent it in low dimensional space. However, designing an accurate and efficient DL-based CD method especially when dealing with large CNs is always an on-going research endeavor to pursue. Meta-Heuristic (MH) algorithms have shown their potentials in improving DL models in terms of solution quality and computational cost. In addition, parallel computing is a feasible solution for building efficient DL models. The algorithmic principle of MH is parallel in nature; however, its computation framework in DL training that is reported in the literature is not really implemented in a parallel computing setup. In this paper, we present a systematic review of CD in CNs from conventional machine learning to DL methods and point out the gap of applying DL-based CD methods in large CNs. In addition, the relevant studies on DL with parallel and MH approaches are reviewed and their implications on DL models are highlighted to prospect effective solutions to overcome the challenges of DL-based CD methods. We also point out research challenges in the field of CD and suggest possible future research directions.",
        "file_path": "paper_data/Deep_Meta-Learning/info/af0d2f8b21334ea9d6dd05254923707f605635d6.pdf",
        "venue": "IEEE Access",
        "citationCount": 21,
        "score": 5.25,
        "summary": "Complex networks (CNs) have gained much attention in recent years due to their importance and popularity. The rapid growth in the size of CNs leads to more difficulties in the analysis of CNs tasks. Community Detection (CD) is an important multidisciplinary research area where many machine/deep learning-based methods have been applied to map CNs into a low-dimensional representation for extracting information similarity among members of CNs. Currently, Deep Learning (DL) is one of the promising methods to extract knowledge and learn information from high dimensional space and represent it in low dimensional space. However, designing an accurate and efficient DL-based CD method especially when dealing with large CNs is always an on-going research endeavor to pursue. Meta-Heuristic (MH) algorithms have shown their potentials in improving DL models in terms of solution quality and computational cost. In addition, parallel computing is a feasible solution for building efficient DL models. The algorithmic principle of MH is parallel in nature; however, its computation framework in DL training that is reported in the literature is not really implemented in a parallel computing setup. In this paper, we present a systematic review of CD in CNs from conventional machine learning to DL methods and point out the gap of applying DL-based CD methods in large CNs. In addition, the relevant studies on DL with parallel and MH approaches are reviewed and their implications on DL models are highlighted to prospect effective solutions to overcome the challenges of DL-based CD methods. We also point out research challenges in the field of CD and suggest possible future research directions.",
        "keywords": []
      },
      "file_name": "af0d2f8b21334ea9d6dd05254923707f605635d6.pdf"
    },
    {
      "success": true,
      "doc_id": "3888ad5fc8136fbdc714c9f4156c7ad8",
      "summary": "We introduce here the idea of Meta Learning for training EEG BCI decoders. Meta Learning is a way of training machine learning systems so they learn to learn. We apply here meta learning to a simple Deep Learning BCI architecture and compare it to transfer learning on the same architecture. Our Meta learning strategy operates by finding optimal parameters for the BCI decoder so that it can quickly generalise between different users and recording sessions - thereby also generalising to new users or new sessions quickly. We tested our algorithm on the Physionet EEG motor imagery dataset. Our approach increased motor imagery classification accuracy between 60 to 80%, outperforming other algorithms under the little-data condition. We believe that establishing the meta learning or learning-to-learn approach will help neural engineering and human interfacing with the challenges of quickly setting up decoders of neural signals to make them more suitable for daily-life.",
      "intriguing_abstract": "We introduce here the idea of Meta Learning for training EEG BCI decoders. Meta Learning is a way of training machine learning systems so they learn to learn. We apply here meta learning to a simple Deep Learning BCI architecture and compare it to transfer learning on the same architecture. Our Meta learning strategy operates by finding optimal parameters for the BCI decoder so that it can quickly generalise between different users and recording sessions - thereby also generalising to new users or new sessions quickly. We tested our algorithm on the Physionet EEG motor imagery dataset. Our approach increased motor imagery classification accuracy between 60 to 80%, outperforming other algorithms under the little-data condition. We believe that establishing the meta learning or learning-to-learn approach will help neural engineering and human interfacing with the challenges of quickly setting up decoders of neural signals to make them more suitable for daily-life.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/56fcd0f932d4ea5c06fcc42c717fc7ea88b4b6eb.pdf",
      "citation_key": "li2021tkg",
      "metadata": {
        "title": "Model-Agnostic Meta-Learning for EEG Motor Imagery Decoding in Brain-Computer-Interfacing",
        "authors": [
          "Denghao Li",
          "Pablo Ortega",
          "Xia Wei",
          "A. Faisal"
        ],
        "published_date": "2021",
        "abstract": "We introduce here the idea of Meta Learning for training EEG BCI decoders. Meta Learning is a way of training machine learning systems so they learn to learn. We apply here meta learning to a simple Deep Learning BCI architecture and compare it to transfer learning on the same architecture. Our Meta learning strategy operates by finding optimal parameters for the BCI decoder so that it can quickly generalise between different users and recording sessions - thereby also generalising to new users or new sessions quickly. We tested our algorithm on the Physionet EEG motor imagery dataset. Our approach increased motor imagery classification accuracy between 60 to 80%, outperforming other algorithms under the little-data condition. We believe that establishing the meta learning or learning-to-learn approach will help neural engineering and human interfacing with the challenges of quickly setting up decoders of neural signals to make them more suitable for daily-life.",
        "file_path": "paper_data/Deep_Meta-Learning/info/56fcd0f932d4ea5c06fcc42c717fc7ea88b4b6eb.pdf",
        "venue": "International IEEE/EMBS Conference on Neural Engineering",
        "citationCount": 21,
        "score": 5.25,
        "summary": "We introduce here the idea of Meta Learning for training EEG BCI decoders. Meta Learning is a way of training machine learning systems so they learn to learn. We apply here meta learning to a simple Deep Learning BCI architecture and compare it to transfer learning on the same architecture. Our Meta learning strategy operates by finding optimal parameters for the BCI decoder so that it can quickly generalise between different users and recording sessions - thereby also generalising to new users or new sessions quickly. We tested our algorithm on the Physionet EEG motor imagery dataset. Our approach increased motor imagery classification accuracy between 60 to 80%, outperforming other algorithms under the little-data condition. We believe that establishing the meta learning or learning-to-learn approach will help neural engineering and human interfacing with the challenges of quickly setting up decoders of neural signals to make them more suitable for daily-life.",
        "keywords": []
      },
      "file_name": "56fcd0f932d4ea5c06fcc42c717fc7ea88b4b6eb.pdf"
    },
    {
      "success": true,
      "doc_id": "6d3891171c31f6000e1b6fb98b11d7a7",
      "summary": "The explainable artificial intelligence (xAI) is one of the interesting issues that has emerged recently. Many researchers are trying to deal with the subject with different dimensions and interesting results that have come out. However, we are still at the beginning of the way to understand these types of models. The forthcoming years are expected to be years in which the openness of deep learning models is discussed. In classical artificial intelligence approaches, we frequently encounter deep learning methods available today. These deep learning methods can yield highly effective results according to the data set size, data set quality, the methods used in feature extraction, the hyper parameter set used in deep learning models, the activation functions, and the optimization algorithms. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network-based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. This is an important open point in artificial neural networks and deep learning models. For these reasons, it is necessary to make serious efforts on the explainability and interpretability of black box models.",
      "intriguing_abstract": "The explainable artificial intelligence (xAI) is one of the interesting issues that has emerged recently. Many researchers are trying to deal with the subject with different dimensions and interesting results that have come out. However, we are still at the beginning of the way to understand these types of models. The forthcoming years are expected to be years in which the openness of deep learning models is discussed. In classical artificial intelligence approaches, we frequently encounter deep learning methods available today. These deep learning methods can yield highly effective results according to the data set size, data set quality, the methods used in feature extraction, the hyper parameter set used in deep learning models, the activation functions, and the optimization algorithms. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network-based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. This is an important open point in artificial neural networks and deep learning models. For these reasons, it is necessary to make serious efforts on the explainability and interpretability of black box models.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5ad8802447f81bd8574a3bee0c2d1a6456d1533b.pdf",
      "citation_key": "daglarli2020nzw",
      "metadata": {
        "title": "Explainable Artificial Intelligence (xAI) Approaches and Deep Meta-Learning Models",
        "authors": [
          "Evren Daglarli"
        ],
        "published_date": "2020",
        "abstract": "The explainable artificial intelligence (xAI) is one of the interesting issues that has emerged recently. Many researchers are trying to deal with the subject with different dimensions and interesting results that have come out. However, we are still at the beginning of the way to understand these types of models. The forthcoming years are expected to be years in which the openness of deep learning models is discussed. In classical artificial intelligence approaches, we frequently encounter deep learning methods available today. These deep learning methods can yield highly effective results according to the data set size, data set quality, the methods used in feature extraction, the hyper parameter set used in deep learning models, the activation functions, and the optimization algorithms. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network-based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. This is an important open point in artificial neural networks and deep learning models. For these reasons, it is necessary to make serious efforts on the explainability and interpretability of black box models.",
        "file_path": "paper_data/Deep_Meta-Learning/info/5ad8802447f81bd8574a3bee0c2d1a6456d1533b.pdf",
        "venue": "Advances and Applications in Deep Learning",
        "citationCount": 25,
        "score": 5.0,
        "summary": "The explainable artificial intelligence (xAI) is one of the interesting issues that has emerged recently. Many researchers are trying to deal with the subject with different dimensions and interesting results that have come out. However, we are still at the beginning of the way to understand these types of models. The forthcoming years are expected to be years in which the openness of deep learning models is discussed. In classical artificial intelligence approaches, we frequently encounter deep learning methods available today. These deep learning methods can yield highly effective results according to the data set size, data set quality, the methods used in feature extraction, the hyper parameter set used in deep learning models, the activation functions, and the optimization algorithms. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network-based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. This is an important open point in artificial neural networks and deep learning models. For these reasons, it is necessary to make serious efforts on the explainability and interpretability of black box models.",
        "keywords": []
      },
      "file_name": "5ad8802447f81bd8574a3bee0c2d1a6456d1533b.pdf"
    },
    {
      "success": true,
      "doc_id": "788b48fabd766bf929467c61710b3fcc",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/6c026fcb8d676d64c3e42a74068b918145616a6a.pdf",
      "citation_key": "phaphuangwittayakul2022api",
      "metadata": {
        "title": "Few-shot image generation based on contrastive meta-learning generative adversarial network",
        "authors": [
          "Aniwat Phaphuangwittayakul",
          "Fangli Ying",
          "Yi Guo",
          "Liting Zhou",
          "N. Chakpitak"
        ],
        "published_date": "2022",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/6c026fcb8d676d64c3e42a74068b918145616a6a.pdf",
        "venue": "The Visual Computer",
        "citationCount": 15,
        "score": 5.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "6c026fcb8d676d64c3e42a74068b918145616a6a.pdf"
    },
    {
      "success": true,
      "doc_id": "99c17aed9faf830e4d468f201ac23819",
      "summary": "Due to the high cost of data collection for magnetization detection of media, the sample size is limited, it is not suitable to use deep learning method to predict its change trend. The prediction of physical and chemical properties of magnetized water and fertilizer (PCPMWF) by meta-learning can help to explore the effects of magnetized water and fertilizer irrigation on crops. In this article, we propose a meta-learning optimization model based on the meta-learner LSTM in the field of regression prediction of PCPMWF. In meta-learning, LSTM is used to replace MAML’s gradient descent optimizer for regression tasks, enables the meta-learner to learn the update rules of the LSTM, and apply it to update the parameters of the model. The proposed method is compared with the experimental results of MAML and LSTM to verify the feasibility and correctness. The average absolute percentage error of the meta-learning optimization model of meta-learner LSTM is reduced by 0.37% compared with the MAML model, and by 4.16% compared with the LSTM model. The loss value of the meta-learning optimization model in the iterative process drops the fastest and steadily compared to the MAML model and the LSTM model. In cross-domain experiments, the average accuracy of the meta-learning optimized model can still reach 0.833. In the case of few sample, the proposed model is superior to the traditional LSTM model and the basic MAML model. And in the training of cross-domain datasets, this model performs best.",
      "intriguing_abstract": "Due to the high cost of data collection for magnetization detection of media, the sample size is limited, it is not suitable to use deep learning method to predict its change trend. The prediction of physical and chemical properties of magnetized water and fertilizer (PCPMWF) by meta-learning can help to explore the effects of magnetized water and fertilizer irrigation on crops. In this article, we propose a meta-learning optimization model based on the meta-learner LSTM in the field of regression prediction of PCPMWF. In meta-learning, LSTM is used to replace MAML’s gradient descent optimizer for regression tasks, enables the meta-learner to learn the update rules of the LSTM, and apply it to update the parameters of the model. The proposed method is compared with the experimental results of MAML and LSTM to verify the feasibility and correctness. The average absolute percentage error of the meta-learning optimization model of meta-learner LSTM is reduced by 0.37% compared with the MAML model, and by 4.16% compared with the LSTM model. The loss value of the meta-learning optimization model in the iterative process drops the fastest and steadily compared to the MAML model and the LSTM model. In cross-domain experiments, the average accuracy of the meta-learning optimized model can still reach 0.833. In the case of few sample, the proposed model is superior to the traditional LSTM model and the basic MAML model. And in the training of cross-domain datasets, this model performs best.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/da8828a4b93f96daa0c863406ba595c6ee27255a.pdf",
      "citation_key": "nie2021pcz",
      "metadata": {
        "title": "Meta-learning prediction of physical and chemical properties of magnetized water and fertilizer based on LSTM",
        "authors": [
          "Jing Nie",
          "Nianyi Wang",
          "Jingbin Li",
          "Kang Wang",
          "Hongkun Wang"
        ],
        "published_date": "2021",
        "abstract": "Due to the high cost of data collection for magnetization detection of media, the sample size is limited, it is not suitable to use deep learning method to predict its change trend. The prediction of physical and chemical properties of magnetized water and fertilizer (PCPMWF) by meta-learning can help to explore the effects of magnetized water and fertilizer irrigation on crops. In this article, we propose a meta-learning optimization model based on the meta-learner LSTM in the field of regression prediction of PCPMWF. In meta-learning, LSTM is used to replace MAML’s gradient descent optimizer for regression tasks, enables the meta-learner to learn the update rules of the LSTM, and apply it to update the parameters of the model. The proposed method is compared with the experimental results of MAML and LSTM to verify the feasibility and correctness. The average absolute percentage error of the meta-learning optimization model of meta-learner LSTM is reduced by 0.37% compared with the MAML model, and by 4.16% compared with the LSTM model. The loss value of the meta-learning optimization model in the iterative process drops the fastest and steadily compared to the MAML model and the LSTM model. In cross-domain experiments, the average accuracy of the meta-learning optimized model can still reach 0.833. In the case of few sample, the proposed model is superior to the traditional LSTM model and the basic MAML model. And in the training of cross-domain datasets, this model performs best.",
        "file_path": "paper_data/Deep_Meta-Learning/info/da8828a4b93f96daa0c863406ba595c6ee27255a.pdf",
        "venue": "Plant Methods",
        "citationCount": 20,
        "score": 5.0,
        "summary": "Due to the high cost of data collection for magnetization detection of media, the sample size is limited, it is not suitable to use deep learning method to predict its change trend. The prediction of physical and chemical properties of magnetized water and fertilizer (PCPMWF) by meta-learning can help to explore the effects of magnetized water and fertilizer irrigation on crops. In this article, we propose a meta-learning optimization model based on the meta-learner LSTM in the field of regression prediction of PCPMWF. In meta-learning, LSTM is used to replace MAML’s gradient descent optimizer for regression tasks, enables the meta-learner to learn the update rules of the LSTM, and apply it to update the parameters of the model. The proposed method is compared with the experimental results of MAML and LSTM to verify the feasibility and correctness. The average absolute percentage error of the meta-learning optimization model of meta-learner LSTM is reduced by 0.37% compared with the MAML model, and by 4.16% compared with the LSTM model. The loss value of the meta-learning optimization model in the iterative process drops the fastest and steadily compared to the MAML model and the LSTM model. In cross-domain experiments, the average accuracy of the meta-learning optimized model can still reach 0.833. In the case of few sample, the proposed model is superior to the traditional LSTM model and the basic MAML model. And in the training of cross-domain datasets, this model performs best.",
        "keywords": []
      },
      "file_name": "da8828a4b93f96daa0c863406ba595c6ee27255a.pdf"
    },
    {
      "success": true,
      "doc_id": "dadbf9e7f12f6fb60ba14826db05014c",
      "summary": "In this paper, we propose a deep metric learning via adaptive learnable assessment (DML-ALA) method for image retrieval and clustering, which aims to learn a sample assessment strategy to maximize the generalization of the trained metric. Unlike existing deep metric learning methods that usually utilize a fixed sampling strategy like hard negative mining, we propose a sequence-aware learnable assessor which re-weights each training example to train the metric towards good generalization. We formulate the learning of this assessor as a meta-learning problem, where we employ an episode-based training scheme and update the assessor at each iteration to adapt to the current model status. We construct each episode by sampling two subsets of disjoint labels to simulate the procedure of training and testing and use the performance of one-gradient-updated metric on the validation subset as the meta-objective of the assessor. Experimental results on the widely used CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate the effectiveness of the proposed approach.",
      "intriguing_abstract": "In this paper, we propose a deep metric learning via adaptive learnable assessment (DML-ALA) method for image retrieval and clustering, which aims to learn a sample assessment strategy to maximize the generalization of the trained metric. Unlike existing deep metric learning methods that usually utilize a fixed sampling strategy like hard negative mining, we propose a sequence-aware learnable assessor which re-weights each training example to train the metric towards good generalization. We formulate the learning of this assessor as a meta-learning problem, where we employ an episode-based training scheme and update the assessor at each iteration to adapt to the current model status. We construct each episode by sampling two subsets of disjoint labels to simulate the procedure of training and testing and use the performance of one-gradient-updated metric on the validation subset as the meta-objective of the assessor. Experimental results on the widely used CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate the effectiveness of the proposed approach.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3bd02411eaa798a158aa780a4d75d0cbfa0af790.pdf",
      "citation_key": "zheng20200ig",
      "metadata": {
        "title": "Deep Metric Learning via Adaptive Learnable Assessment",
        "authors": [
          "Wenzhao Zheng",
          "Jiwen Lu",
          "Jie Zhou"
        ],
        "published_date": "2020",
        "abstract": "In this paper, we propose a deep metric learning via adaptive learnable assessment (DML-ALA) method for image retrieval and clustering, which aims to learn a sample assessment strategy to maximize the generalization of the trained metric. Unlike existing deep metric learning methods that usually utilize a fixed sampling strategy like hard negative mining, we propose a sequence-aware learnable assessor which re-weights each training example to train the metric towards good generalization. We formulate the learning of this assessor as a meta-learning problem, where we employ an episode-based training scheme and update the assessor at each iteration to adapt to the current model status. We construct each episode by sampling two subsets of disjoint labels to simulate the procedure of training and testing and use the performance of one-gradient-updated metric on the validation subset as the meta-objective of the assessor. Experimental results on the widely used CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate the effectiveness of the proposed approach.",
        "file_path": "paper_data/Deep_Meta-Learning/info/3bd02411eaa798a158aa780a4d75d0cbfa0af790.pdf",
        "venue": "Computer Vision and Pattern Recognition",
        "citationCount": 25,
        "score": 5.0,
        "summary": "In this paper, we propose a deep metric learning via adaptive learnable assessment (DML-ALA) method for image retrieval and clustering, which aims to learn a sample assessment strategy to maximize the generalization of the trained metric. Unlike existing deep metric learning methods that usually utilize a fixed sampling strategy like hard negative mining, we propose a sequence-aware learnable assessor which re-weights each training example to train the metric towards good generalization. We formulate the learning of this assessor as a meta-learning problem, where we employ an episode-based training scheme and update the assessor at each iteration to adapt to the current model status. We construct each episode by sampling two subsets of disjoint labels to simulate the procedure of training and testing and use the performance of one-gradient-updated metric on the validation subset as the meta-objective of the assessor. Experimental results on the widely used CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate the effectiveness of the proposed approach.",
        "keywords": []
      },
      "file_name": "3bd02411eaa798a158aa780a4d75d0cbfa0af790.pdf"
    },
    {
      "success": true,
      "doc_id": "c4e755d1d571475c69f6422bda2fbb3b",
      "summary": "Well-annotated medical datasets enable deep neural networks (DNNs) to gain strong power in extracting lesion-related features. Building such large and well-designed medical datasets is costly due to the need for high-level expertise. Model pre-training based on ImageNet is a common practice to gain better generalization when the data amount is limited. However, it suffers from the domain gap between natural and medical images. In this work, we pre-train DNNs on ultrasound (US) domains instead of ImageNet to reduce the domain gap in medical US applications. To learn US image representations based on unlabeled US videos, we propose a novel meta-learning-based contrastive learning method, namely Meta Ultrasound Contrastive Learning (Meta-USCL). To tackle the key challenge of obtaining semantically consistent sample pairs for contrastive learning, we present a positive pair generation module along with an automatic sample weighting module based on meta-learning. Experimental results on multiple computer-aided diagnosis (CAD) problems, including pneumonia detection, breast cancer classification, and breast tumor segmentation, show that the proposed self-supervised method reaches state-of-the-art (SOTA). The codes are available at https://github.com/Schuture/Meta-USCL.",
      "intriguing_abstract": "Well-annotated medical datasets enable deep neural networks (DNNs) to gain strong power in extracting lesion-related features. Building such large and well-designed medical datasets is costly due to the need for high-level expertise. Model pre-training based on ImageNet is a common practice to gain better generalization when the data amount is limited. However, it suffers from the domain gap between natural and medical images. In this work, we pre-train DNNs on ultrasound (US) domains instead of ImageNet to reduce the domain gap in medical US applications. To learn US image representations based on unlabeled US videos, we propose a novel meta-learning-based contrastive learning method, namely Meta Ultrasound Contrastive Learning (Meta-USCL). To tackle the key challenge of obtaining semantically consistent sample pairs for contrastive learning, we present a positive pair generation module along with an automatic sample weighting module based on meta-learning. Experimental results on multiple computer-aided diagnosis (CAD) problems, including pneumonia detection, breast cancer classification, and breast tumor segmentation, show that the proposed self-supervised method reaches state-of-the-art (SOTA). The codes are available at https://github.com/Schuture/Meta-USCL.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e874da1570e0ca85da39ec74d7d4a012d6413828.pdf",
      "citation_key": "chen2022ccz",
      "metadata": {
        "title": "Generating and Weighting Semantically Consistent Sample Pairs for Ultrasound Contrastive Learning",
        "authors": [
          "Yixiong Chen",
          "Chunhui Zhang",
          "C. Ding",
          "Li Liu"
        ],
        "published_date": "2022",
        "abstract": "Well-annotated medical datasets enable deep neural networks (DNNs) to gain strong power in extracting lesion-related features. Building such large and well-designed medical datasets is costly due to the need for high-level expertise. Model pre-training based on ImageNet is a common practice to gain better generalization when the data amount is limited. However, it suffers from the domain gap between natural and medical images. In this work, we pre-train DNNs on ultrasound (US) domains instead of ImageNet to reduce the domain gap in medical US applications. To learn US image representations based on unlabeled US videos, we propose a novel meta-learning-based contrastive learning method, namely Meta Ultrasound Contrastive Learning (Meta-USCL). To tackle the key challenge of obtaining semantically consistent sample pairs for contrastive learning, we present a positive pair generation module along with an automatic sample weighting module based on meta-learning. Experimental results on multiple computer-aided diagnosis (CAD) problems, including pneumonia detection, breast cancer classification, and breast tumor segmentation, show that the proposed self-supervised method reaches state-of-the-art (SOTA). The codes are available at https://github.com/Schuture/Meta-USCL.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e874da1570e0ca85da39ec74d7d4a012d6413828.pdf",
        "venue": "IEEE Transactions on Medical Imaging",
        "citationCount": 15,
        "score": 5.0,
        "summary": "Well-annotated medical datasets enable deep neural networks (DNNs) to gain strong power in extracting lesion-related features. Building such large and well-designed medical datasets is costly due to the need for high-level expertise. Model pre-training based on ImageNet is a common practice to gain better generalization when the data amount is limited. However, it suffers from the domain gap between natural and medical images. In this work, we pre-train DNNs on ultrasound (US) domains instead of ImageNet to reduce the domain gap in medical US applications. To learn US image representations based on unlabeled US videos, we propose a novel meta-learning-based contrastive learning method, namely Meta Ultrasound Contrastive Learning (Meta-USCL). To tackle the key challenge of obtaining semantically consistent sample pairs for contrastive learning, we present a positive pair generation module along with an automatic sample weighting module based on meta-learning. Experimental results on multiple computer-aided diagnosis (CAD) problems, including pneumonia detection, breast cancer classification, and breast tumor segmentation, show that the proposed self-supervised method reaches state-of-the-art (SOTA). The codes are available at https://github.com/Schuture/Meta-USCL.",
        "keywords": []
      },
      "file_name": "e874da1570e0ca85da39ec74d7d4a012d6413828.pdf"
    },
    {
      "success": true,
      "doc_id": "5660179d4ade2604eab35b6fb6e4d2d2",
      "summary": "Parking occupancy prediction (POP) plays a vital role in many parking-related smart services for better parking management. However, an issue hinders its mass deployment: many parking facilities cannot collect enough data to feed data-hungry machine learning models. To tackle the challenges in small-sample POP, we propose an approach named Adaptation and Learning to Learn (ALL) by adopting the capability of advanced deep learning and federated learning. ALL integrates two novel ideas: (1) Adaptation: by leveraging the Asynchronous Advantage Actor-Critic (A3C) reinforcement learning technique, an auto-selector module is implemented, which can group and select data-scarce parks automatically as supporting sources to enable the knowledge adaptation in model training; and (2) Learning to learn: by applying federated meta-learning on selected supporting sources, a meta-learner module is designed, which can train a high-performance local prediction model in a collaborative and privacy-preserving manner. Results of an evaluation with 42 parking lots in two Chinese cities (Shenzhen and Guangzhou) show that, compared to state-of-the-art baselines: (1) the auto-selector can reduce the model variance by about 17.8%; (2) the meta-learner can train a converged model 102× faster; and (3) finally, ALL can boost the forecasting performance by about 29.8%. Through the integration of advanced machine learning methods, i.e., reinforcement learning, meta-learning, and federated learning, the proposed approach ALL represents a significant step forward in solving small-sample issues in parking occupancy prediction.",
      "intriguing_abstract": "Parking occupancy prediction (POP) plays a vital role in many parking-related smart services for better parking management. However, an issue hinders its mass deployment: many parking facilities cannot collect enough data to feed data-hungry machine learning models. To tackle the challenges in small-sample POP, we propose an approach named Adaptation and Learning to Learn (ALL) by adopting the capability of advanced deep learning and federated learning. ALL integrates two novel ideas: (1) Adaptation: by leveraging the Asynchronous Advantage Actor-Critic (A3C) reinforcement learning technique, an auto-selector module is implemented, which can group and select data-scarce parks automatically as supporting sources to enable the knowledge adaptation in model training; and (2) Learning to learn: by applying federated meta-learning on selected supporting sources, a meta-learner module is designed, which can train a high-performance local prediction model in a collaborative and privacy-preserving manner. Results of an evaluation with 42 parking lots in two Chinese cities (Shenzhen and Guangzhou) show that, compared to state-of-the-art baselines: (1) the auto-selector can reduce the model variance by about 17.8%; (2) the meta-learner can train a converged model 102× faster; and (3) finally, ALL can boost the forecasting performance by about 29.8%. Through the integration of advanced machine learning methods, i.e., reinforcement learning, meta-learning, and federated learning, the proposed approach ALL represents a significant step forward in solving small-sample issues in parking occupancy prediction.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/8f12add50397f697631b3fff04608d5efa957867.pdf",
      "citation_key": "qu2022mu6",
      "metadata": {
        "title": "Adaptation and Learning to Learn (ALL): An Integrated Approach for Small-Sample Parking Occupancy Prediction",
        "authors": [
          "H. Qu",
          "Sheng Liu",
          "Jun Li",
          "Yuren Zhou",
          "R. Liu"
        ],
        "published_date": "2022",
        "abstract": "Parking occupancy prediction (POP) plays a vital role in many parking-related smart services for better parking management. However, an issue hinders its mass deployment: many parking facilities cannot collect enough data to feed data-hungry machine learning models. To tackle the challenges in small-sample POP, we propose an approach named Adaptation and Learning to Learn (ALL) by adopting the capability of advanced deep learning and federated learning. ALL integrates two novel ideas: (1) Adaptation: by leveraging the Asynchronous Advantage Actor-Critic (A3C) reinforcement learning technique, an auto-selector module is implemented, which can group and select data-scarce parks automatically as supporting sources to enable the knowledge adaptation in model training; and (2) Learning to learn: by applying federated meta-learning on selected supporting sources, a meta-learner module is designed, which can train a high-performance local prediction model in a collaborative and privacy-preserving manner. Results of an evaluation with 42 parking lots in two Chinese cities (Shenzhen and Guangzhou) show that, compared to state-of-the-art baselines: (1) the auto-selector can reduce the model variance by about 17.8%; (2) the meta-learner can train a converged model 102× faster; and (3) finally, ALL can boost the forecasting performance by about 29.8%. Through the integration of advanced machine learning methods, i.e., reinforcement learning, meta-learning, and federated learning, the proposed approach ALL represents a significant step forward in solving small-sample issues in parking occupancy prediction.",
        "file_path": "paper_data/Deep_Meta-Learning/info/8f12add50397f697631b3fff04608d5efa957867.pdf",
        "venue": "Mathematics",
        "citationCount": 14,
        "score": 4.666666666666666,
        "summary": "Parking occupancy prediction (POP) plays a vital role in many parking-related smart services for better parking management. However, an issue hinders its mass deployment: many parking facilities cannot collect enough data to feed data-hungry machine learning models. To tackle the challenges in small-sample POP, we propose an approach named Adaptation and Learning to Learn (ALL) by adopting the capability of advanced deep learning and federated learning. ALL integrates two novel ideas: (1) Adaptation: by leveraging the Asynchronous Advantage Actor-Critic (A3C) reinforcement learning technique, an auto-selector module is implemented, which can group and select data-scarce parks automatically as supporting sources to enable the knowledge adaptation in model training; and (2) Learning to learn: by applying federated meta-learning on selected supporting sources, a meta-learner module is designed, which can train a high-performance local prediction model in a collaborative and privacy-preserving manner. Results of an evaluation with 42 parking lots in two Chinese cities (Shenzhen and Guangzhou) show that, compared to state-of-the-art baselines: (1) the auto-selector can reduce the model variance by about 17.8%; (2) the meta-learner can train a converged model 102× faster; and (3) finally, ALL can boost the forecasting performance by about 29.8%. Through the integration of advanced machine learning methods, i.e., reinforcement learning, meta-learning, and federated learning, the proposed approach ALL represents a significant step forward in solving small-sample issues in parking occupancy prediction.",
        "keywords": []
      },
      "file_name": "8f12add50397f697631b3fff04608d5efa957867.pdf"
    },
    {
      "success": true,
      "doc_id": "ce2da9ad7ee22bb27be2b672acf93aed",
      "summary": "Scene classification has become an important research topic in remote sensing (RS) field. The typical solution relies on labeling a large enough set of the RS scenes manually using expert opinion, then training the algorithm on this set to learn how to classify other new scenes correctly. The best performance deep learning models required a large labeled dataset for training. Accordingly, there is a great need to develop an intelligent machine learning algorithm that can learn to classify RS datasets containing new unseen classes from a few labeled samples only, which is known as few-shot machine learning. In this work, we develop a deep few-shot learning method for the classification of RS scenes. The proposed method is based on Model Agnostic Meta-Learning (MAML), one of the recently introduced and most popular meta-learning algorithms. In this paper, we report preliminary results using the UC Merced, OPTIMAL-31, and AID RS scene datasets.",
      "intriguing_abstract": "Scene classification has become an important research topic in remote sensing (RS) field. The typical solution relies on labeling a large enough set of the RS scenes manually using expert opinion, then training the algorithm on this set to learn how to classify other new scenes correctly. The best performance deep learning models required a large labeled dataset for training. Accordingly, there is a great need to develop an intelligent machine learning algorithm that can learn to classify RS datasets containing new unseen classes from a few labeled samples only, which is known as few-shot machine learning. In this work, we develop a deep few-shot learning method for the classification of RS scenes. The proposed method is based on Model Agnostic Meta-Learning (MAML), one of the recently introduced and most popular meta-learning algorithms. In this paper, we report preliminary results using the UC Merced, OPTIMAL-31, and AID RS scene datasets.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/756b3e51e8ac2951bfd7d5b5322f1502442eab8e.pdf",
      "citation_key": "alajaji2020b6c",
      "metadata": {
        "title": "Few Shot Scene Classification in Remote Sensing using Meta-Agnostic Machine",
        "authors": [
          "D. Alajaji",
          "H. Alhichri"
        ],
        "published_date": "2020",
        "abstract": "Scene classification has become an important research topic in remote sensing (RS) field. The typical solution relies on labeling a large enough set of the RS scenes manually using expert opinion, then training the algorithm on this set to learn how to classify other new scenes correctly. The best performance deep learning models required a large labeled dataset for training. Accordingly, there is a great need to develop an intelligent machine learning algorithm that can learn to classify RS datasets containing new unseen classes from a few labeled samples only, which is known as few-shot machine learning. In this work, we develop a deep few-shot learning method for the classification of RS scenes. The proposed method is based on Model Agnostic Meta-Learning (MAML), one of the recently introduced and most popular meta-learning algorithms. In this paper, we report preliminary results using the UC Merced, OPTIMAL-31, and AID RS scene datasets.",
        "file_path": "paper_data/Deep_Meta-Learning/info/756b3e51e8ac2951bfd7d5b5322f1502442eab8e.pdf",
        "venue": "2020 6th Conference on Data Science and Machine Learning Applications (CDMA)",
        "citationCount": 23,
        "score": 4.6000000000000005,
        "summary": "Scene classification has become an important research topic in remote sensing (RS) field. The typical solution relies on labeling a large enough set of the RS scenes manually using expert opinion, then training the algorithm on this set to learn how to classify other new scenes correctly. The best performance deep learning models required a large labeled dataset for training. Accordingly, there is a great need to develop an intelligent machine learning algorithm that can learn to classify RS datasets containing new unseen classes from a few labeled samples only, which is known as few-shot machine learning. In this work, we develop a deep few-shot learning method for the classification of RS scenes. The proposed method is based on Model Agnostic Meta-Learning (MAML), one of the recently introduced and most popular meta-learning algorithms. In this paper, we report preliminary results using the UC Merced, OPTIMAL-31, and AID RS scene datasets.",
        "keywords": []
      },
      "file_name": "756b3e51e8ac2951bfd7d5b5322f1502442eab8e.pdf"
    },
    {
      "success": true,
      "doc_id": "828bbc53acd7c4d7668c417ef98a984f",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/80444838b08f8f96b7d18bcc2fd348dad248f2a7.pdf",
      "citation_key": "jiang2021uo6",
      "metadata": {
        "title": "Continual meta-learning algorithm",
        "authors": [
          "Mengjuan Jiang",
          "Fanzhang Li",
          "Li Liu"
        ],
        "published_date": "2021",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/80444838b08f8f96b7d18bcc2fd348dad248f2a7.pdf",
        "venue": "Applied intelligence (Boston)",
        "citationCount": 18,
        "score": 4.5,
        "summary": "",
        "keywords": []
      },
      "file_name": "80444838b08f8f96b7d18bcc2fd348dad248f2a7.pdf"
    },
    {
      "success": true,
      "doc_id": "395cdcc9c6a721ae346b7ebb41070d6c",
      "summary": "Network slicing remains one of the key technologies in 5G and beyond 5G networks (B5G). By leveraging SDN and NVF techniques, it enables the coexistence of several heterogeneous virtual networks (VNs) on top of the same physical infrastructure. Despite the advantages it brings to network operators, network slicing raises a major challenge: Resource allocation of VNs, also known as the virtual network embedding problem (VNEP). VNEP is known to be an NP-Hard problem. Several heuristics, meta-heuristics and Deep Reinforcement Learning (DRL) based solutions were proposed in the literature to solve it. Regarding the first two categories, they can provide a solution for large scale problems within a reasonable time, but the solution is usually suboptimal, which leads to an inefficient utilization of the resources and increases the cost of the allocation process. For DRL-based approaches and due to the exploration-exploitation dilemma, the solution can be infeasible. To overcome these issues, we combine, in this work, deep reinforcement learning and relational graph convolutional neural networks in order to automatically learn how to improve the quality of VNEP heuristics. Simulation results show the effectiveness of our approach. Starting with an initial solution given by the heuristics our approach can find an amelioration, with an improvement in the order of 35%.",
      "intriguing_abstract": "Network slicing remains one of the key technologies in 5G and beyond 5G networks (B5G). By leveraging SDN and NVF techniques, it enables the coexistence of several heterogeneous virtual networks (VNs) on top of the same physical infrastructure. Despite the advantages it brings to network operators, network slicing raises a major challenge: Resource allocation of VNs, also known as the virtual network embedding problem (VNEP). VNEP is known to be an NP-Hard problem. Several heuristics, meta-heuristics and Deep Reinforcement Learning (DRL) based solutions were proposed in the literature to solve it. Regarding the first two categories, they can provide a solution for large scale problems within a reasonable time, but the solution is usually suboptimal, which leads to an inefficient utilization of the resources and increases the cost of the allocation process. For DRL-based approaches and due to the exploration-exploitation dilemma, the solution can be infeasible. To overcome these issues, we combine, in this work, deep reinforcement learning and relational graph convolutional neural networks in order to automatically learn how to improve the quality of VNEP heuristics. Simulation results show the effectiveness of our approach. Starting with an initial solution given by the heuristics our approach can find an amelioration, with an improvement in the order of 35%.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e07f94238e5362922cf8e8c4d004ad26df52cc9d.pdf",
      "citation_key": "rkhami2021c1c",
      "metadata": {
        "title": "Learn to improve: A novel deep reinforcement learning approach for beyond 5G network slicing",
        "authors": [
          "Anouar Rkhami",
          "Yassine Hadjadj-Aoul",
          "A. Outtagarts"
        ],
        "published_date": "2021",
        "abstract": "Network slicing remains one of the key technologies in 5G and beyond 5G networks (B5G). By leveraging SDN and NVF techniques, it enables the coexistence of several heterogeneous virtual networks (VNs) on top of the same physical infrastructure. Despite the advantages it brings to network operators, network slicing raises a major challenge: Resource allocation of VNs, also known as the virtual network embedding problem (VNEP). VNEP is known to be an NP-Hard problem. Several heuristics, meta-heuristics and Deep Reinforcement Learning (DRL) based solutions were proposed in the literature to solve it. Regarding the first two categories, they can provide a solution for large scale problems within a reasonable time, but the solution is usually suboptimal, which leads to an inefficient utilization of the resources and increases the cost of the allocation process. For DRL-based approaches and due to the exploration-exploitation dilemma, the solution can be infeasible. To overcome these issues, we combine, in this work, deep reinforcement learning and relational graph convolutional neural networks in order to automatically learn how to improve the quality of VNEP heuristics. Simulation results show the effectiveness of our approach. Starting with an initial solution given by the heuristics our approach can find an amelioration, with an improvement in the order of 35%.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e07f94238e5362922cf8e8c4d004ad26df52cc9d.pdf",
        "venue": "Consumer Communications and Networking Conference",
        "citationCount": 18,
        "score": 4.5,
        "summary": "Network slicing remains one of the key technologies in 5G and beyond 5G networks (B5G). By leveraging SDN and NVF techniques, it enables the coexistence of several heterogeneous virtual networks (VNs) on top of the same physical infrastructure. Despite the advantages it brings to network operators, network slicing raises a major challenge: Resource allocation of VNs, also known as the virtual network embedding problem (VNEP). VNEP is known to be an NP-Hard problem. Several heuristics, meta-heuristics and Deep Reinforcement Learning (DRL) based solutions were proposed in the literature to solve it. Regarding the first two categories, they can provide a solution for large scale problems within a reasonable time, but the solution is usually suboptimal, which leads to an inefficient utilization of the resources and increases the cost of the allocation process. For DRL-based approaches and due to the exploration-exploitation dilemma, the solution can be infeasible. To overcome these issues, we combine, in this work, deep reinforcement learning and relational graph convolutional neural networks in order to automatically learn how to improve the quality of VNEP heuristics. Simulation results show the effectiveness of our approach. Starting with an initial solution given by the heuristics our approach can find an amelioration, with an improvement in the order of 35%.",
        "keywords": []
      },
      "file_name": "e07f94238e5362922cf8e8c4d004ad26df52cc9d.pdf"
    },
    {
      "success": true,
      "doc_id": "94be28c4f8aba82e3a3515a4040db848",
      "summary": "Here's a focused summary of the paper for a literature review, adhering to the specified citation requirements and bullet format:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep learning models suffer from catastrophic forgetting when continuously learning from sequential streams of data, especially in Natural Language Processing (NLP) tasks \\cite{holla20202od}. This means they lose previously acquired knowledge when adapting to new tasks due to shifts in data distributions.\n    *   **Importance & Challenge**: Lifelong learning (or continual learning) is crucial for real-world applications where data is non-stationary and models need to learn incrementally without forgetting. The challenge lies in designing robust mechanisms that can efficiently transfer knowledge from past experiences while minimizing interference with existing knowledge, often under realistic constraints like single passes over data, no task identifiers, and limited computational/memory resources \\cite{holla20202od}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon meta-learning (specifically optimization-based methods like MAML and Reptile) and memory-based continual learning (experience replay) \\cite{holla20202od}. It extends online meta-learning (OML) and a neuromodulatory meta-learning algorithm (ANML) to the NLP domain.\n    *   **Limitations of Previous Solutions**:\n        *   Many existing continual learning approaches, particularly in NLP, rely on unrealistic experimental setups: assuming explicit task identifiers, distinct output heads per task, multiple training passes, and abundant computational/memory resources \\cite{holla20202od}.\n        *   High rates of experience replay, while mitigating forgetting, often resemble multi-task learning more than true lifelong learning and are computationally expensive \\cite{holla20202od}.\n        *   Specific NLP methods like MbPA++ have slow inference, Meta-MbPA uses a high memory sampling rate, and others require task identifiers or multiple training epochs \\cite{holla20202od}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel approach combining meta-learning with *sparse experience replay* for lifelong language learning \\cite{holla20202od}.\n        *   It extends two meta-learning algorithms, Online Meta-Learning (OML) and a Neuromodulatory Meta-Learning algorithm (ANML), by augmenting them with an episodic memory module for experience replay, naming them OML-ER and ANML-ER \\cite{holla20202od}.\n        *   These methods utilize a pre-trained language model (BERT) as the Representation Learning Network (RLN) and a single linear layer as the Prediction Learning Network (PLN) \\cite{holla20202od}.\n        *   Experience replay is performed *sparsely* (low replay rate `r`, high replay interval `RI`) and the replayed examples from memory are explicitly used as the *query set* in the meta-learning outer-loop objective. This directly optimizes the model to prevent forgetting by maximizing the dot product between support and query set gradients \\cite{holla20202od}.\n    *   **Novelty/Difference**:\n        *   First to investigate meta-learning with *sparse experience replay* in the context of large-scale pre-trained language models for lifelong NLP \\cite{holla20202od}.\n        *   Operates under a *realistic lifelong learning setup*: single pass over data, no task identifiers, shared output head, and constraints on replay rate, time, compute, and memory \\cite{holla20202od}.\n        *   Directly optimizes to prevent forgetting by integrating previously seen examples into the query set of a first-order MAML framework \\cite{holla20202od}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of OML-ER and ANML-ER, which extend existing meta-learning algorithms for conventional continual learning by incorporating sparse experience replay where replayed examples form the query set for direct forgetting prevention \\cite{holla20202od}.\n    *   **System Design/Architectural Innovations**: Integration of pre-trained BERT as a frozen or partially fine-tuned RLN with a simple linear PLN, allowing most weight updates to occur on the linear layer, contributing to efficiency \\cite{holla20202od}.\n    *   **Theoretical Insights/Analysis**: Motivation for using replayed examples as query sets is grounded in the objective function of first-order MAML, which implicitly seeks to minimize query loss and maximize the dot product between support and query set gradients, thereby minimizing interference and maximizing transfer \\cite{holla20202od}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The methods were evaluated on lifelong text classification and relation extraction benchmarks \\cite{holla20202od}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   Achieved state-of-the-art performance on both benchmarks when compared against current methods under the *same realistic setting* (single pass, no task IDs, sparse replay) \\cite{holla20202od}.\n        *   Demonstrated low computational and space complexity: OML-ER with BERT performs most weight updates on a single linear layer, uses limited memory during training, and requires no network adaptation during test-time \\cite{holla20202od}.\n        *   The effectiveness of sparse replay (low `r`, high `RI`) was empirically validated, showing that even with limited replay, catastrophic forgetting can be mitigated \\cite{holla20202od}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper primarily highlights how its approach *overcomes* limitations of previous work. While claiming efficiency, the inherent computational overhead of meta-learning (even first-order approximations) compared to simpler methods might still exist, though the paper argues it's significantly reduced for their specific setup. The scope is limited to supervised lifelong language learning tasks (text classification, relation extraction) with a single pass over data and no task identifiers \\cite{holla20202od}.\n    *   **Scope of Applicability**: Applicable to lifelong learning scenarios in NLP where data arrives sequentially, task boundaries are unknown, and computational/memory resources are constrained. The approach is particularly suited for leveraging large pre-trained language models in a continual learning setting \\cite{holla20202od}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: Advances the technical state-of-the-art in lifelong NLP by providing a robust and efficient method that achieves superior performance under realistic and challenging continual learning conditions \\cite{holla20202od}. It demonstrates that meta-learning, when combined with sparse experience replay and pre-trained LMs, can effectively prevent catastrophic forgetting without the unrealistic assumptions of prior work \\cite{holla20202od}.\n    *   **Potential Impact on Future Research**:\n        *   Informs the NLP community about appropriate experimental design for continual learning, emphasizing realistic constraints \\cite{holla20202od}.\n        *   Highlights the potential of meta-learning methods for efficient lifelong learning with limited replay and memory capacity \\cite{holla20202od}.\n        *   Provides a strong baseline and publicly available code for future research in continual learning for NLP, especially concerning the integration of large pre-trained models \\cite{holla20202od}.",
      "intriguing_abstract": "Deep learning models face a critical bottleneck: **catastrophic forgetting** when continuously learning from sequential data streams, severely limiting their utility in real-world **Natural Language Processing (NLP)** applications. Existing **continual learning** methods often rely on unrealistic assumptions, such as explicit task identifiers or abundant computational resources, hindering practical deployment. We introduce a novel approach that synergistically combines **meta-learning** with **sparse experience replay** to overcome this challenge under truly realistic **lifelong learning** conditions.\n\nOur method extends Online Meta-Learning (OML-ER) and a Neuromodulatory Meta-Learning algorithm (ANML-ER) by strategically using sparsely replayed examples as the *query set* in the meta-learning outer-loop objective. This directly optimizes the model to prevent forgetting by maximizing knowledge transfer and minimizing interference. Leveraging **pre-trained language models** like **BERT**, our algorithms achieve state-of-the-art performance on lifelong **text classification** and **relation extraction** benchmarks, demonstrating superior robustness and efficiency with a single pass over data and no task identifiers. This work sets a new standard for practical continual learning in NLP, offering a powerful, resource-efficient solution to enable truly adaptive language intelligence.",
      "keywords": [
        "Catastrophic forgetting",
        "Lifelong learning",
        "Natural Language Processing (NLP)",
        "Meta-learning",
        "Sparse experience replay",
        "OML-ER and ANML-ER algorithms",
        "Pre-trained language models (BERT)",
        "Realistic lifelong learning setup",
        "Query set optimization",
        "Forgetting prevention",
        "Lifelong text classification and relation extraction",
        "State-of-the-art performance",
        "Computational efficiency"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/737ee2562b31437146de4df7e2948d1027ef2ecd.pdf",
      "citation_key": "holla20202od",
      "metadata": {
        "title": "Meta-Learning with Sparse Experience Replay for Lifelong Language Learning",
        "authors": [
          "Nithin Holla",
          "Pushkar Mishra",
          "H. Yannakoudakis",
          "Ekaterina Shutova"
        ],
        "published_date": "2020",
        "abstract": "Lifelong learning requires models that can continuously learn from sequential streams of data without suffering catastrophic forgetting due to shifts in data distributions. Deep learning models have thrived in the non-sequential learning paradigm; however, when used to learn a sequence of tasks, they fail to retain past knowledge and learn incrementally. We propose a novel approach to lifelong learning of language tasks based on meta-learning with sparse experience replay that directly optimizes to prevent forgetting. We show that under the realistic setting of performing a single pass on a stream of tasks and without any task identifiers, our method obtains state-of-the-art results on lifelong text classification and relation extraction. We analyze the effectiveness of our approach and further demonstrate its low computational and space complexity.",
        "file_path": "paper_data/Deep_Meta-Learning/info/737ee2562b31437146de4df7e2948d1027ef2ecd.pdf",
        "venue": "arXiv.org",
        "citationCount": 22,
        "score": 4.4,
        "summary": "Here's a focused summary of the paper for a literature review, adhering to the specified citation requirements and bullet format:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep learning models suffer from catastrophic forgetting when continuously learning from sequential streams of data, especially in Natural Language Processing (NLP) tasks \\cite{holla20202od}. This means they lose previously acquired knowledge when adapting to new tasks due to shifts in data distributions.\n    *   **Importance & Challenge**: Lifelong learning (or continual learning) is crucial for real-world applications where data is non-stationary and models need to learn incrementally without forgetting. The challenge lies in designing robust mechanisms that can efficiently transfer knowledge from past experiences while minimizing interference with existing knowledge, often under realistic constraints like single passes over data, no task identifiers, and limited computational/memory resources \\cite{holla20202od}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon meta-learning (specifically optimization-based methods like MAML and Reptile) and memory-based continual learning (experience replay) \\cite{holla20202od}. It extends online meta-learning (OML) and a neuromodulatory meta-learning algorithm (ANML) to the NLP domain.\n    *   **Limitations of Previous Solutions**:\n        *   Many existing continual learning approaches, particularly in NLP, rely on unrealistic experimental setups: assuming explicit task identifiers, distinct output heads per task, multiple training passes, and abundant computational/memory resources \\cite{holla20202od}.\n        *   High rates of experience replay, while mitigating forgetting, often resemble multi-task learning more than true lifelong learning and are computationally expensive \\cite{holla20202od}.\n        *   Specific NLP methods like MbPA++ have slow inference, Meta-MbPA uses a high memory sampling rate, and others require task identifiers or multiple training epochs \\cite{holla20202od}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel approach combining meta-learning with *sparse experience replay* for lifelong language learning \\cite{holla20202od}.\n        *   It extends two meta-learning algorithms, Online Meta-Learning (OML) and a Neuromodulatory Meta-Learning algorithm (ANML), by augmenting them with an episodic memory module for experience replay, naming them OML-ER and ANML-ER \\cite{holla20202od}.\n        *   These methods utilize a pre-trained language model (BERT) as the Representation Learning Network (RLN) and a single linear layer as the Prediction Learning Network (PLN) \\cite{holla20202od}.\n        *   Experience replay is performed *sparsely* (low replay rate `r`, high replay interval `RI`) and the replayed examples from memory are explicitly used as the *query set* in the meta-learning outer-loop objective. This directly optimizes the model to prevent forgetting by maximizing the dot product between support and query set gradients \\cite{holla20202od}.\n    *   **Novelty/Difference**:\n        *   First to investigate meta-learning with *sparse experience replay* in the context of large-scale pre-trained language models for lifelong NLP \\cite{holla20202od}.\n        *   Operates under a *realistic lifelong learning setup*: single pass over data, no task identifiers, shared output head, and constraints on replay rate, time, compute, and memory \\cite{holla20202od}.\n        *   Directly optimizes to prevent forgetting by integrating previously seen examples into the query set of a first-order MAML framework \\cite{holla20202od}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**: Introduction of OML-ER and ANML-ER, which extend existing meta-learning algorithms for conventional continual learning by incorporating sparse experience replay where replayed examples form the query set for direct forgetting prevention \\cite{holla20202od}.\n    *   **System Design/Architectural Innovations**: Integration of pre-trained BERT as a frozen or partially fine-tuned RLN with a simple linear PLN, allowing most weight updates to occur on the linear layer, contributing to efficiency \\cite{holla20202od}.\n    *   **Theoretical Insights/Analysis**: Motivation for using replayed examples as query sets is grounded in the objective function of first-order MAML, which implicitly seeks to minimize query loss and maximize the dot product between support and query set gradients, thereby minimizing interference and maximizing transfer \\cite{holla20202od}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The methods were evaluated on lifelong text classification and relation extraction benchmarks \\cite{holla20202od}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   Achieved state-of-the-art performance on both benchmarks when compared against current methods under the *same realistic setting* (single pass, no task IDs, sparse replay) \\cite{holla20202od}.\n        *   Demonstrated low computational and space complexity: OML-ER with BERT performs most weight updates on a single linear layer, uses limited memory during training, and requires no network adaptation during test-time \\cite{holla20202od}.\n        *   The effectiveness of sparse replay (low `r`, high `RI`) was empirically validated, showing that even with limited replay, catastrophic forgetting can be mitigated \\cite{holla20202od}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper primarily highlights how its approach *overcomes* limitations of previous work. While claiming efficiency, the inherent computational overhead of meta-learning (even first-order approximations) compared to simpler methods might still exist, though the paper argues it's significantly reduced for their specific setup. The scope is limited to supervised lifelong language learning tasks (text classification, relation extraction) with a single pass over data and no task identifiers \\cite{holla20202od}.\n    *   **Scope of Applicability**: Applicable to lifelong learning scenarios in NLP where data arrives sequentially, task boundaries are unknown, and computational/memory resources are constrained. The approach is particularly suited for leveraging large pre-trained language models in a continual learning setting \\cite{holla20202od}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: Advances the technical state-of-the-art in lifelong NLP by providing a robust and efficient method that achieves superior performance under realistic and challenging continual learning conditions \\cite{holla20202od}. It demonstrates that meta-learning, when combined with sparse experience replay and pre-trained LMs, can effectively prevent catastrophic forgetting without the unrealistic assumptions of prior work \\cite{holla20202od}.\n    *   **Potential Impact on Future Research**:\n        *   Informs the NLP community about appropriate experimental design for continual learning, emphasizing realistic constraints \\cite{holla20202od}.\n        *   Highlights the potential of meta-learning methods for efficient lifelong learning with limited replay and memory capacity \\cite{holla20202od}.\n        *   Provides a strong baseline and publicly available code for future research in continual learning for NLP, especially concerning the integration of large pre-trained models \\cite{holla20202od}.",
        "keywords": [
          "Catastrophic forgetting",
          "Lifelong learning",
          "Natural Language Processing (NLP)",
          "Meta-learning",
          "Sparse experience replay",
          "OML-ER and ANML-ER algorithms",
          "Pre-trained language models (BERT)",
          "Realistic lifelong learning setup",
          "Query set optimization",
          "Forgetting prevention",
          "Lifelong text classification and relation extraction",
          "State-of-the-art performance",
          "Computational efficiency"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose a novel approach** to lifelong learning of language tasks based on **meta-learning with sparse experience replay** that directly optimizes to prevent forgetting.\" it then discusses the results and analysis of this method.\n*   the introduction sets up a technical problem (catastrophic forgetting in deep learning for sequential tasks) and the need for \"more robust machine learning mechanisms.\"\n\nthese phrases directly align with the criteria for a **technical** paper: \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\" and \"introduction discusses: technical problem, proposed solution.\"\n\ntherefore, the paper type is: **technical**"
      },
      "file_name": "737ee2562b31437146de4df7e2948d1027ef2ecd.pdf"
    },
    {
      "success": true,
      "doc_id": "9aa8e9409873376a88a0d96e62417f8a",
      "summary": "Intent detection and slot filling are the two main tasks in natural language understanding module in goal oriented conversational agents. Models which optimize these two objectives simultaneously within a single network (joint models) have proven themselves to be superior to mono-objective networks. However, these data-intensive deep learning approaches have not been successful in catering the demand of the industry for adaptable, multilingual dialogue systems. To this end, we cast joint intent detection as an n-way k-shot classification problem and establish it within meta learning setup. Our approach is motivated by the success of meta learning on few-shot image classification tasks. We empirically demonstrate that, our approach can meta-learn a prior from similar tasks under highly resource constrained settings which enable rapid inference on target tasks. First, we show the adaptability of proposed approach by meta learning n-way k-shot joint intent detection using set of intents and evaluating on a completely new set of intents. Second, we exemplify the cross-lingual adaptability by learning a prior, utilizing English utterances and evaluating on Spanish and Thai utterances. Compared to random initialization, our method significantly improves the accuracy in both intent detection and slot-filling.",
      "intriguing_abstract": "Intent detection and slot filling are the two main tasks in natural language understanding module in goal oriented conversational agents. Models which optimize these two objectives simultaneously within a single network (joint models) have proven themselves to be superior to mono-objective networks. However, these data-intensive deep learning approaches have not been successful in catering the demand of the industry for adaptable, multilingual dialogue systems. To this end, we cast joint intent detection as an n-way k-shot classification problem and establish it within meta learning setup. Our approach is motivated by the success of meta learning on few-shot image classification tasks. We empirically demonstrate that, our approach can meta-learn a prior from similar tasks under highly resource constrained settings which enable rapid inference on target tasks. First, we show the adaptability of proposed approach by meta learning n-way k-shot joint intent detection using set of intents and evaluating on a completely new set of intents. Second, we exemplify the cross-lingual adaptability by learning a prior, utilizing English utterances and evaluating on Spanish and Thai utterances. Compared to random initialization, our method significantly improves the accuracy in both intent detection and slot-filling.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3b479d5df78cd259989d8bbac5d68926d846d3ba.pdf",
      "citation_key": "bhathiya2020avm",
      "metadata": {
        "title": "Meta Learning for Few-Shot Joint Intent Detection and Slot-Filling",
        "authors": [
          "H. S. Bhathiya",
          "Uthayasanker Thayasivam"
        ],
        "published_date": "2020",
        "abstract": "Intent detection and slot filling are the two main tasks in natural language understanding module in goal oriented conversational agents. Models which optimize these two objectives simultaneously within a single network (joint models) have proven themselves to be superior to mono-objective networks. However, these data-intensive deep learning approaches have not been successful in catering the demand of the industry for adaptable, multilingual dialogue systems. To this end, we cast joint intent detection as an n-way k-shot classification problem and establish it within meta learning setup. Our approach is motivated by the success of meta learning on few-shot image classification tasks. We empirically demonstrate that, our approach can meta-learn a prior from similar tasks under highly resource constrained settings which enable rapid inference on target tasks. First, we show the adaptability of proposed approach by meta learning n-way k-shot joint intent detection using set of intents and evaluating on a completely new set of intents. Second, we exemplify the cross-lingual adaptability by learning a prior, utilizing English utterances and evaluating on Spanish and Thai utterances. Compared to random initialization, our method significantly improves the accuracy in both intent detection and slot-filling.",
        "file_path": "paper_data/Deep_Meta-Learning/info/3b479d5df78cd259989d8bbac5d68926d846d3ba.pdf",
        "venue": "International Conference on Machine Learning Technologies",
        "citationCount": 22,
        "score": 4.4,
        "summary": "Intent detection and slot filling are the two main tasks in natural language understanding module in goal oriented conversational agents. Models which optimize these two objectives simultaneously within a single network (joint models) have proven themselves to be superior to mono-objective networks. However, these data-intensive deep learning approaches have not been successful in catering the demand of the industry for adaptable, multilingual dialogue systems. To this end, we cast joint intent detection as an n-way k-shot classification problem and establish it within meta learning setup. Our approach is motivated by the success of meta learning on few-shot image classification tasks. We empirically demonstrate that, our approach can meta-learn a prior from similar tasks under highly resource constrained settings which enable rapid inference on target tasks. First, we show the adaptability of proposed approach by meta learning n-way k-shot joint intent detection using set of intents and evaluating on a completely new set of intents. Second, we exemplify the cross-lingual adaptability by learning a prior, utilizing English utterances and evaluating on Spanish and Thai utterances. Compared to random initialization, our method significantly improves the accuracy in both intent detection and slot-filling.",
        "keywords": []
      },
      "file_name": "3b479d5df78cd259989d8bbac5d68926d846d3ba.pdf"
    },
    {
      "success": true,
      "doc_id": "49a07c12c8a2bfda25a00b0dd4aa1e16",
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{bernacchia20211r0}\" when referencing this paper.\n\n---\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** `\\cite{bernacchia20211r0}` addresses the performance of meta-learning algorithms, specifically MAML, in scenarios where target tasks have scarce data. It investigates the optimal setting and necessity of the inner loop learning rate during meta-training.\n    *   **Importance & Challenge:** Meta-learning is crucial for enabling deep learning models to perform well with limited data by transferring knowledge across tasks. However, there's an ongoing debate in the literature regarding the effectiveness and necessity of the inner loop (task-specific adaptation via gradient descent) during meta-training. Recent empirical studies offer conflicting evidence, with some suggesting that removing the inner loop (equivalent to a zero learning rate) works equally well or better, while others find it beneficial. This lack of theoretical understanding makes it challenging to design and optimize meta-learning strategies.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** `\\cite{bernacchia20211r0}` positions itself within the meta-learning literature, particularly focusing on MAML. It extends existing theoretical work that uses random matrix theory (RMT) and exact solutions for linear regression by applying these techniques to the multi-task meta-learning setting. It also leverages the Neural Tangent Kernel (NTK) framework to analyze wide neural networks.\n    *   **Limitations of Previous Solutions:**\n        *   Previous RMT/exact solution studies were limited to single-task linear regression and did not address multi-task meta-learning.\n        *   Existing theoretical work on mixed linear regression in the context of meta-learning did not investigate the critical effect of learning rates.\n        *   Prior theoretical analyses of MAML (e.g., on universality, convergence, or the general effect of the inner loop) did not specifically examine the impact of the inner loop learning rate on performance, which is the central focus of this work.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** `\\cite{bernacchia20211r0}` employs a rigorous theoretical approach to derive an algebraic expression for the average test loss of MAML. This is achieved through:\n        *   **Random Matrix Theory (RMT):** Used to analyze the statistical properties of the data and model parameters in the context of mixed linear regression.\n        *   **Exact Solutions of Linear Models:** For mixed linear regression, the outer loop optimization is assumed to converge, allowing for an exact analytical solution of the meta-parameter.\n        *   **Neural Tangent Kernel (NTK) Framework:** For extending the analysis to nonlinear regression with infinitely wide neural networks, approximating the network's behavior as linear in its parameters (lazy training regime).\n    *   **Novelty/Difference:**\n        *   **First application of RMT and exact solutions to multi-task meta-learning:** This provides a novel and powerful analytical framework for understanding MAML's behavior.\n        *   **Discovery of optimal negative inner loop learning rate:** The most significant innovation is the theoretical finding that the optimal inner loop learning rate during *meta-training* (`\\(\\eta_t\\)`) is *negative*. This is a counter-intuitive and previously unexplored setting, contrasting sharply with the typically positive learning rate used for adaptation during meta-testing (`\\(\\eta_r\\)`).\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   Derivation of exact algebraic expressions for MAML's test loss in mixed linear regression for both overparameterized (`\\(p > n_v m\\)`) and underparameterized (`\\(p < n_v m\\)`) regimes \\cite{bernacchia20211r0}.\n        *   Extension of this analytical framework to nonlinear regression using the Neural Tangent Kernel approximation, providing insights into the behavior of wide neural networks in meta-learning \\cite{bernacchia20211r0}.\n    *   **Theoretical Insights or Analysis:**\n        *   Proof that the optimal inner loop learning rate for *adaptation* (meta-testing, `\\(\\eta_r\\)`) is always positive, aligning with intuitive understanding \\cite{bernacchia20211r0}.\n        *   Groundbreaking theoretical finding that the optimal inner loop learning rate for *meta-training* (`\\(\\eta_t\\)`) is *negative* in overparameterized mixed linear regression, and also for underparameterized models around zero \\cite{bernacchia20211r0}. This challenges conventional assumptions about gradient descent in meta-learning.\n        *   Clarification of the conditions under which the inner loop is beneficial and how its learning rate should be set for optimal performance, providing a theoretical basis for empirical observations \\cite{bernacchia20211r0}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** `\\cite{bernacchia20211r0}` conducted extensive empirical experiments using MAML on mixed linear regression problems to validate their theoretical findings. Preliminary experiments were also performed for nonlinear regression with wide neural networks.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   The primary performance metric was the average test loss of MAML.\n        *   **Mixed Linear Regression:** For both overparameterized and underparameterized cases, empirical results closely matched the theoretically derived algebraic expressions for test loss as a function of `\\(\\eta_r\\)` and `\\(\\eta_t\\)` (Figures 2 and 3). Experiments confirmed that the optimal `\\(\\eta_r\\)` is positive. Crucially, experiments validated the theoretical prediction that the optimal `\\(\\eta_t\\)` is negative, showing a clear minimum at negative values.\n        *   **Nonlinear Regression (NTK):** Preliminary experiments suggested that the finding of an optimal negative `\\(\\eta_t\\)` also holds in this more complex setting, although a formal proof was not provided.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   **Linear Models:** The primary theoretical results are derived for mixed linear regression, which is a simplification of complex deep learning problems.\n        *   **One-step Gradient Descent:** The MAML inner loop is simplified to a single gradient step.\n        *   **Gaussian Distributions:** Assumes Gaussian distributions for inputs, weights, and noise.\n        *   **Exact Outer Loop Optimization:** Assumes the outer loop optimization converges to an exact solution, which may not hold in practice for complex deep learning models.\n        *   **NTK Approximation:** The extension to nonlinear models relies on the Neural Tangent Kernel approximation, which is valid for infinitely wide networks and \"lazy training\" regimes.\n    *   **Scope of Applicability:** The theoretical findings are most directly applicable to MAML-like meta-learning algorithms, particularly in settings that can be approximated by linear models or wide neural networks. The insights are valuable for understanding the role of inner loop learning rates in meta-learning, especially in overparameterized models.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** `\\cite{bernacchia20211r0}` significantly advances the theoretical understanding of meta-learning by providing the first exact analytical expressions for MAML's test loss in multi-task settings. The discovery of an optimal *negative* inner loop learning rate during meta-training is a paradigm shift, challenging the common assumption that learning rates must be positive and offering a new perspective on meta-optimization.\n    *   **Potential Impact on Future Research:**\n        *   **Rethinking Meta-learning Optimization:** The findings suggest that meta-learning algorithms might benefit from explicitly incorporating negative learning rates in their inner loops during meta-training, potentially leading to improved performance.\n        *   **Guiding Algorithm Design:** The theoretical framework can guide the design of more effective meta-learning algorithms and hyperparameter tuning strategies.\n        *   **Resolving Empirical Debates:** It provides a theoretical basis to resolve the ongoing debate about the utility of the inner loop in meta-learning, explaining *when* and *how* its learning rate should be set for optimal performance.\n        *   **Further Theoretical Exploration:** Opens avenues for exploring the implications of negative learning rates in other meta-learning contexts and for developing more general theories of meta-optimization.",
      "intriguing_abstract": "Meta-learning's promise of rapid adaptation with scarce data hinges on effective inner-loop optimization, yet the optimal setting of its learning rate remains a contentious empirical and theoretical challenge. We present a groundbreaking theoretical framework, leveraging Random Matrix Theory (RMT) and exact solutions for mixed linear regression, extended to wide neural networks via the Neural Tangent Kernel (NTK) approximation, to derive an algebraic expression for MAML's average test loss. Our analysis reveals a profoundly counter-intuitive discovery: while the inner loop learning rate for *adaptation* (meta-testing) is optimally positive, the optimal inner loop learning rate during *meta-training* is demonstrably **negative**. This paradigm-shifting finding, rigorously validated empirically, challenges conventional assumptions about gradient descent in meta-learning. It provides a crucial theoretical basis to resolve ongoing debates, guiding the design of more efficient meta-learning algorithms and fundamentally rethinking meta-optimization strategies for overparameterized models, paving the way for significantly improved few-shot learning performance.",
      "keywords": [
        "Meta-learning",
        "MAML",
        "inner loop learning rate",
        "optimal negative inner loop learning rate",
        "Random Matrix Theory (RMT)",
        "Neural Tangent Kernel (NTK) framework",
        "mixed linear regression",
        "multi-task meta-learning",
        "exact analytical expressions",
        "overparameterized models",
        "scarce data scenarios",
        "theoretical understanding of meta-learning",
        "gradient descent optimization"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/4454a763c891afb3fb8fa6567a367d05b1938e97.pdf",
      "citation_key": "bernacchia20211r0",
      "metadata": {
        "title": "Meta-learning with negative learning rates",
        "authors": [
          "A. Bernacchia"
        ],
        "published_date": "2021",
        "abstract": "Deep learning models require a large amount of data to perform well. When data is scarce for a target task, we can transfer the knowledge gained by training on similar tasks to quickly learn the target. A successful approach is meta-learning, or learning to learn a distribution of tasks, where learning is represented by an outer loop, and to learn by an inner loop of gradient descent. However, a number of recent empirical studies argue that the inner loop is unnecessary and more simple models work equally well or even better. We study the performance of MAML as a function of the learning rate of the inner loop, where zero learning rate implies that there is no inner loop. Using random matrix theory and exact solutions of linear models, we calculate an algebraic expression for the test loss of MAML applied to mixed linear regression and nonlinear regression with overparameterized models. Surprisingly, while the optimal learning rate for adaptation is positive, we find that the optimal learning rate for training is always negative, a setting that has never been considered before. Therefore, not only does the performance increase by decreasing the learning rate to zero, as suggested by recent work, but it can be increased even further by decreasing the learning rate to negative values. These results help clarify under what circumstances meta-learning performs best.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4454a763c891afb3fb8fa6567a367d05b1938e97.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 17,
        "score": 4.25,
        "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{bernacchia20211r0}\" when referencing this paper.\n\n---\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** `\\cite{bernacchia20211r0}` addresses the performance of meta-learning algorithms, specifically MAML, in scenarios where target tasks have scarce data. It investigates the optimal setting and necessity of the inner loop learning rate during meta-training.\n    *   **Importance & Challenge:** Meta-learning is crucial for enabling deep learning models to perform well with limited data by transferring knowledge across tasks. However, there's an ongoing debate in the literature regarding the effectiveness and necessity of the inner loop (task-specific adaptation via gradient descent) during meta-training. Recent empirical studies offer conflicting evidence, with some suggesting that removing the inner loop (equivalent to a zero learning rate) works equally well or better, while others find it beneficial. This lack of theoretical understanding makes it challenging to design and optimize meta-learning strategies.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** `\\cite{bernacchia20211r0}` positions itself within the meta-learning literature, particularly focusing on MAML. It extends existing theoretical work that uses random matrix theory (RMT) and exact solutions for linear regression by applying these techniques to the multi-task meta-learning setting. It also leverages the Neural Tangent Kernel (NTK) framework to analyze wide neural networks.\n    *   **Limitations of Previous Solutions:**\n        *   Previous RMT/exact solution studies were limited to single-task linear regression and did not address multi-task meta-learning.\n        *   Existing theoretical work on mixed linear regression in the context of meta-learning did not investigate the critical effect of learning rates.\n        *   Prior theoretical analyses of MAML (e.g., on universality, convergence, or the general effect of the inner loop) did not specifically examine the impact of the inner loop learning rate on performance, which is the central focus of this work.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** `\\cite{bernacchia20211r0}` employs a rigorous theoretical approach to derive an algebraic expression for the average test loss of MAML. This is achieved through:\n        *   **Random Matrix Theory (RMT):** Used to analyze the statistical properties of the data and model parameters in the context of mixed linear regression.\n        *   **Exact Solutions of Linear Models:** For mixed linear regression, the outer loop optimization is assumed to converge, allowing for an exact analytical solution of the meta-parameter.\n        *   **Neural Tangent Kernel (NTK) Framework:** For extending the analysis to nonlinear regression with infinitely wide neural networks, approximating the network's behavior as linear in its parameters (lazy training regime).\n    *   **Novelty/Difference:**\n        *   **First application of RMT and exact solutions to multi-task meta-learning:** This provides a novel and powerful analytical framework for understanding MAML's behavior.\n        *   **Discovery of optimal negative inner loop learning rate:** The most significant innovation is the theoretical finding that the optimal inner loop learning rate during *meta-training* (`\\(\\eta_t\\)`) is *negative*. This is a counter-intuitive and previously unexplored setting, contrasting sharply with the typically positive learning rate used for adaptation during meta-testing (`\\(\\eta_r\\)`).\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   Derivation of exact algebraic expressions for MAML's test loss in mixed linear regression for both overparameterized (`\\(p > n_v m\\)`) and underparameterized (`\\(p < n_v m\\)`) regimes \\cite{bernacchia20211r0}.\n        *   Extension of this analytical framework to nonlinear regression using the Neural Tangent Kernel approximation, providing insights into the behavior of wide neural networks in meta-learning \\cite{bernacchia20211r0}.\n    *   **Theoretical Insights or Analysis:**\n        *   Proof that the optimal inner loop learning rate for *adaptation* (meta-testing, `\\(\\eta_r\\)`) is always positive, aligning with intuitive understanding \\cite{bernacchia20211r0}.\n        *   Groundbreaking theoretical finding that the optimal inner loop learning rate for *meta-training* (`\\(\\eta_t\\)`) is *negative* in overparameterized mixed linear regression, and also for underparameterized models around zero \\cite{bernacchia20211r0}. This challenges conventional assumptions about gradient descent in meta-learning.\n        *   Clarification of the conditions under which the inner loop is beneficial and how its learning rate should be set for optimal performance, providing a theoretical basis for empirical observations \\cite{bernacchia20211r0}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** `\\cite{bernacchia20211r0}` conducted extensive empirical experiments using MAML on mixed linear regression problems to validate their theoretical findings. Preliminary experiments were also performed for nonlinear regression with wide neural networks.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   The primary performance metric was the average test loss of MAML.\n        *   **Mixed Linear Regression:** For both overparameterized and underparameterized cases, empirical results closely matched the theoretically derived algebraic expressions for test loss as a function of `\\(\\eta_r\\)` and `\\(\\eta_t\\)` (Figures 2 and 3). Experiments confirmed that the optimal `\\(\\eta_r\\)` is positive. Crucially, experiments validated the theoretical prediction that the optimal `\\(\\eta_t\\)` is negative, showing a clear minimum at negative values.\n        *   **Nonlinear Regression (NTK):** Preliminary experiments suggested that the finding of an optimal negative `\\(\\eta_t\\)` also holds in this more complex setting, although a formal proof was not provided.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   **Linear Models:** The primary theoretical results are derived for mixed linear regression, which is a simplification of complex deep learning problems.\n        *   **One-step Gradient Descent:** The MAML inner loop is simplified to a single gradient step.\n        *   **Gaussian Distributions:** Assumes Gaussian distributions for inputs, weights, and noise.\n        *   **Exact Outer Loop Optimization:** Assumes the outer loop optimization converges to an exact solution, which may not hold in practice for complex deep learning models.\n        *   **NTK Approximation:** The extension to nonlinear models relies on the Neural Tangent Kernel approximation, which is valid for infinitely wide networks and \"lazy training\" regimes.\n    *   **Scope of Applicability:** The theoretical findings are most directly applicable to MAML-like meta-learning algorithms, particularly in settings that can be approximated by linear models or wide neural networks. The insights are valuable for understanding the role of inner loop learning rates in meta-learning, especially in overparameterized models.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** `\\cite{bernacchia20211r0}` significantly advances the theoretical understanding of meta-learning by providing the first exact analytical expressions for MAML's test loss in multi-task settings. The discovery of an optimal *negative* inner loop learning rate during meta-training is a paradigm shift, challenging the common assumption that learning rates must be positive and offering a new perspective on meta-optimization.\n    *   **Potential Impact on Future Research:**\n        *   **Rethinking Meta-learning Optimization:** The findings suggest that meta-learning algorithms might benefit from explicitly incorporating negative learning rates in their inner loops during meta-training, potentially leading to improved performance.\n        *   **Guiding Algorithm Design:** The theoretical framework can guide the design of more effective meta-learning algorithms and hyperparameter tuning strategies.\n        *   **Resolving Empirical Debates:** It provides a theoretical basis to resolve the ongoing debate about the utility of the inner loop in meta-learning, explaining *when* and *how* its learning rate should be set for optimal performance.\n        *   **Further Theoretical Exploration:** Opens avenues for exploring the implications of negative learning rates in other meta-learning contexts and for developing more general theories of meta-optimization.",
        "keywords": [
          "Meta-learning",
          "MAML",
          "inner loop learning rate",
          "optimal negative inner loop learning rate",
          "Random Matrix Theory (RMT)",
          "Neural Tangent Kernel (NTK) framework",
          "mixed linear regression",
          "multi-task meta-learning",
          "exact analytical expressions",
          "overparameterized models",
          "scarce data scenarios",
          "theoretical understanding of meta-learning",
          "gradient descent optimization"
        ],
        "paper_type": "the paper should be classified as **theoretical**.\n\nhere's why:\n\n*   **abstract mentions:** \"using random matrix theory and exact solutions of linear models, we calculate an algebraic expression for the test loss...\", \"we ﬁnd that the optimal learning rate for training is always negative...\", \"these results help clarify under what circumstances meta-learning performs best.\"\n*   **introduction discusses:** \"there is little theory available to explain these ﬁndings.\", \"in this work, using random matrix theory and exact solutions of linear models, we derive an algebraic expression of the average test loss of maml...\", \"we prove that the optimal learning rate is always negative in overparameterized models.\"\n*   **content includes:** \"theorem 1\", \"theorem 2\", \"proof\" sections, and mathematical derivations.\n\nwhile the paper also includes empirical validation, its core contribution, as highlighted in the abstract and introduction, is the mathematical analysis, derivation of algebraic expressions, and formal proofs to explain and predict the behavior of meta-learning algorithms. this aligns perfectly with the \"mathematical analysis, proofs, formal models\" criterion for a theoretical paper."
      },
      "file_name": "4454a763c891afb3fb8fa6567a367d05b1938e97.pdf"
    },
    {
      "success": true,
      "doc_id": "6612bceb9aefa97489072605a6ac67ba",
      "summary": "We present a framework combining hierarchical and multi-agent deep reinforcement learning approaches to solve coordination problems among a multitude of agents using a semi-decentralized model. The framework extends the multi-agent learning setup by introducing a meta-controller that guides the communication between agent pairs, enabling agents to focus on communicating with only one other agent at any step. This hierarchical decomposition of the task allows for efficient exploration to learn policies that identify globally optimal solutions even as the number of collaborating agents increases. We show promising initial experimental results on a simulated distributed scheduling problem.",
      "intriguing_abstract": "We present a framework combining hierarchical and multi-agent deep reinforcement learning approaches to solve coordination problems among a multitude of agents using a semi-decentralized model. The framework extends the multi-agent learning setup by introducing a meta-controller that guides the communication between agent pairs, enabling agents to focus on communicating with only one other agent at any step. This hierarchical decomposition of the task allows for efficient exploration to learn policies that identify globally optimal solutions even as the number of collaborating agents increases. We show promising initial experimental results on a simulated distributed scheduling problem.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/39226d30f6f76843ef4fe0c2a5c7c334b3beba2e.pdf",
      "citation_key": "kumar2017p0v",
      "metadata": {
        "title": "Federated Control with Hierarchical Multi-Agent Deep Reinforcement Learning",
        "authors": [
          "Saurabh Kumar",
          "Pararth Shah",
          "Dilek Z. Hakkani-Tür",
          "Larry Heck"
        ],
        "published_date": "2017",
        "abstract": "We present a framework combining hierarchical and multi-agent deep reinforcement learning approaches to solve coordination problems among a multitude of agents using a semi-decentralized model. The framework extends the multi-agent learning setup by introducing a meta-controller that guides the communication between agent pairs, enabling agents to focus on communicating with only one other agent at any step. This hierarchical decomposition of the task allows for efficient exploration to learn policies that identify globally optimal solutions even as the number of collaborating agents increases. We show promising initial experimental results on a simulated distributed scheduling problem.",
        "file_path": "paper_data/Deep_Meta-Learning/info/39226d30f6f76843ef4fe0c2a5c7c334b3beba2e.pdf",
        "venue": "arXiv.org",
        "citationCount": 34,
        "score": 4.25,
        "summary": "We present a framework combining hierarchical and multi-agent deep reinforcement learning approaches to solve coordination problems among a multitude of agents using a semi-decentralized model. The framework extends the multi-agent learning setup by introducing a meta-controller that guides the communication between agent pairs, enabling agents to focus on communicating with only one other agent at any step. This hierarchical decomposition of the task allows for efficient exploration to learn policies that identify globally optimal solutions even as the number of collaborating agents increases. We show promising initial experimental results on a simulated distributed scheduling problem.",
        "keywords": []
      },
      "file_name": "39226d30f6f76843ef4fe0c2a5c7c334b3beba2e.pdf"
    },
    {
      "success": true,
      "doc_id": "516d14e6cf7fd1d17c0066cb0fa43550",
      "summary": "Today, the effects of promising technologies such as explainable artificial intelligence (xAI) and meta-learning (ML) on the internet of things (IoT) and the cyber-physical systems (CPS), which are important components of Industry 4.0, are increasingly intensified. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. For these reasons, it is necessary to make serious efforts on the explanability and interpretability of black box models. In the near future, the integration of explainable artificial intelligence and meta-learning approaches to cyber-physical systems will have effects on a high level of virtualization and simulation infrastructure, real-time supply chain, cyber factories with smart machines communicating over the internet, maximizing production efficiency, analysis of service quality and competition level.",
      "intriguing_abstract": "Today, the effects of promising technologies such as explainable artificial intelligence (xAI) and meta-learning (ML) on the internet of things (IoT) and the cyber-physical systems (CPS), which are important components of Industry 4.0, are increasingly intensified. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. For these reasons, it is necessary to make serious efforts on the explanability and interpretability of black box models. In the near future, the integration of explainable artificial intelligence and meta-learning approaches to cyber-physical systems will have effects on a high level of virtualization and simulation infrastructure, real-time supply chain, cyber factories with smart machines communicating over the internet, maximizing production efficiency, analysis of service quality and competition level.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/641ea570259679b9913d1cacadd8356ed1398149.pdf",
      "citation_key": "daglarli20216fl",
      "metadata": {
        "title": "Explainable Artificial Intelligence (xAI) Approaches and Deep Meta-Learning Models for Cyber-Physical Systems",
        "authors": [
          "Evren Daglarli"
        ],
        "published_date": "2021",
        "abstract": "Today, the effects of promising technologies such as explainable artificial intelligence (xAI) and meta-learning (ML) on the internet of things (IoT) and the cyber-physical systems (CPS), which are important components of Industry 4.0, are increasingly intensified. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. For these reasons, it is necessary to make serious efforts on the explanability and interpretability of black box models. In the near future, the integration of explainable artificial intelligence and meta-learning approaches to cyber-physical systems will have effects on a high level of virtualization and simulation infrastructure, real-time supply chain, cyber factories with smart machines communicating over the internet, maximizing production efficiency, analysis of service quality and competition level.",
        "file_path": "paper_data/Deep_Meta-Learning/info/641ea570259679b9913d1cacadd8356ed1398149.pdf",
        "venue": "Advances in Systems Analysis, Software Engineering, and High Performance Computing",
        "citationCount": 16,
        "score": 4.0,
        "summary": "Today, the effects of promising technologies such as explainable artificial intelligence (xAI) and meta-learning (ML) on the internet of things (IoT) and the cyber-physical systems (CPS), which are important components of Industry 4.0, are increasingly intensified. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. For these reasons, it is necessary to make serious efforts on the explanability and interpretability of black box models. In the near future, the integration of explainable artificial intelligence and meta-learning approaches to cyber-physical systems will have effects on a high level of virtualization and simulation infrastructure, real-time supply chain, cyber factories with smart machines communicating over the internet, maximizing production efficiency, analysis of service quality and competition level.",
        "keywords": []
      },
      "file_name": "641ea570259679b9913d1cacadd8356ed1398149.pdf"
    },
    {
      "success": true,
      "doc_id": "4965f9ef3124e335292d45649d7b7191",
      "summary": "Although deep neural networks are capable of achieving performance superior to humans on various tasks, they are notorious for requiring large amounts of data and computing resources, restricting their success to domains where such resources are available. Metalearning methods can address this problem by transferring knowledge from related tasks, thus reducing the amount of data and computing resources needed to learn new tasks. We organize the MetaDL competition series, which provide opportunities for research groups all over the world to create and experimentally assess new meta-(deep)learning solutions for real problems. In this paper, authored collaboratively between the competition organizers and the top-ranked participants, we describe the design of the competition, the datasets, the best experimental results, as well as the top-ranked methods in the NeurIPS 2021 challenge, which attracted 15 active teams who made it to the final phase (by outperforming the baseline), making over 100 code submissions during the feedback phase. The solutions of the top participants have been open-sourced. The lessons learned include that learning good representations is essential for effective transfer learning.",
      "intriguing_abstract": "Although deep neural networks are capable of achieving performance superior to humans on various tasks, they are notorious for requiring large amounts of data and computing resources, restricting their success to domains where such resources are available. Metalearning methods can address this problem by transferring knowledge from related tasks, thus reducing the amount of data and computing resources needed to learn new tasks. We organize the MetaDL competition series, which provide opportunities for research groups all over the world to create and experimentally assess new meta-(deep)learning solutions for real problems. In this paper, authored collaboratively between the competition organizers and the top-ranked participants, we describe the design of the competition, the datasets, the best experimental results, as well as the top-ranked methods in the NeurIPS 2021 challenge, which attracted 15 active teams who made it to the final phase (by outperforming the baseline), making over 100 code submissions during the feedback phase. The solutions of the top participants have been open-sourced. The lessons learned include that learning good representations is essential for effective transfer learning.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/1845ece5be61f96292d0b3ea3ecec251b2510909.pdf",
      "citation_key": "baz2022n78",
      "metadata": {
        "title": "Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification",
        "authors": [
          "Adrian El Baz",
          "André Carvalho",
          "Hong Chen",
          "Fábio Ferreira",
          "H. Gouk",
          "S. Hu",
          "F. Hutter",
          "Zhengying Liu",
          "F. Mohr",
          "J. V. Rijn",
          "Xin Wang",
          "Isabelle M Guyon"
        ],
        "published_date": "2022",
        "abstract": "Although deep neural networks are capable of achieving performance superior to humans on various tasks, they are notorious for requiring large amounts of data and computing resources, restricting their success to domains where such resources are available. Metalearning methods can address this problem by transferring knowledge from related tasks, thus reducing the amount of data and computing resources needed to learn new tasks. We organize the MetaDL competition series, which provide opportunities for research groups all over the world to create and experimentally assess new meta-(deep)learning solutions for real problems. In this paper, authored collaboratively between the competition organizers and the top-ranked participants, we describe the design of the competition, the datasets, the best experimental results, as well as the top-ranked methods in the NeurIPS 2021 challenge, which attracted 15 active teams who made it to the final phase (by outperforming the baseline), making over 100 code submissions during the feedback phase. The solutions of the top participants have been open-sourced. The lessons learned include that learning good representations is essential for effective transfer learning.",
        "file_path": "paper_data/Deep_Meta-Learning/info/1845ece5be61f96292d0b3ea3ecec251b2510909.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 12,
        "score": 4.0,
        "summary": "Although deep neural networks are capable of achieving performance superior to humans on various tasks, they are notorious for requiring large amounts of data and computing resources, restricting their success to domains where such resources are available. Metalearning methods can address this problem by transferring knowledge from related tasks, thus reducing the amount of data and computing resources needed to learn new tasks. We organize the MetaDL competition series, which provide opportunities for research groups all over the world to create and experimentally assess new meta-(deep)learning solutions for real problems. In this paper, authored collaboratively between the competition organizers and the top-ranked participants, we describe the design of the competition, the datasets, the best experimental results, as well as the top-ranked methods in the NeurIPS 2021 challenge, which attracted 15 active teams who made it to the final phase (by outperforming the baseline), making over 100 code submissions during the feedback phase. The solutions of the top participants have been open-sourced. The lessons learned include that learning good representations is essential for effective transfer learning.",
        "keywords": []
      },
      "file_name": "1845ece5be61f96292d0b3ea3ecec251b2510909.pdf"
    },
    {
      "success": true,
      "doc_id": "afeeec9467b62ac4220b841c3db5200c",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the **Offline Meta Reinforcement Learning (OMRL)** problem: given offline training logs from *N* conventional RL agents on *N* different tasks, learn a meta-agent that can quickly maximize reward in a new, unseen task from the same distribution \\cite{dorfman2020mgv}.\n    *   This problem is important because online meta-RL training is often prohibitively expensive in real-world domains (e.g., robotics, healthcare). It is challenging because the meta-agent must learn effective *exploration* strategies for unknown tasks from data where conventional agents primarily *exploited* known task-specific goals, leading to potentially different behaviors (e.g., searching for a goal vs. navigating directly to it). A new identifiability issue, termed **MDP ambiguity**, arises when inferring beliefs from offline data \\cite{dorfman2020mgv}.\n\n*   **Related Work & Positioning**\n    *   This work builds upon Meta-RL and Bayesian RL (BRL) frameworks, specifically extending the **VariBAD** algorithm \\cite{dorfman2020mgv}.\n    *   Most prior meta-RL studies, including VariBAD, focused on the *online* setting, where the meta-RL policy continually collects data. This limits applicability in data-scarce or expensive domains. The paper positions itself as the first to study meta-learning exploration in the *offline* setting \\cite{dorfman2020mgv}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **Bayesian Offline Reinforcement Learning (BOReL)** \\cite{dorfman2020mgv}, an off-policy variant of the VariBAD algorithm.\n    *   **Off-policy VariBAD**: It replaces VariBAD's on-policy policy gradient optimization with an off-policy Q-learning (for discrete actions) or Soft Actor-Critic (SAC, for continuous actions) approach. This is enabled by \"state relabeling,\" where the VariBAD VAE encoder is used to augment each state in the offline trajectories with a neural belief estimate, effectively transforming the data into a Bayes-Adaptive MDP (BAMDP) format.\n    *   **MDP Ambiguity**: The paper identifies and formalizes **MDP ambiguity** \\cite{dorfman2020mgv}, a problem where the offline data might not contain sufficient information to distinguish between different underlying MDPs, making it impossible to learn an accurate belief update.\n    *   **Resolutions for Ambiguity**: It proposes principled data collection strategies (e.g., ensuring identifying state-action pairs are visited) and a \"reward relabeling trick\" for cases where ambiguity is solely due to reward differences \\cite{dorfman2020mgv}.\n\n*   **Key Technical Contributions**\n    *   First study of meta-learning exploration in the offline setting \\cite{dorfman2020mgv}.\n    *   Provides the necessary theoretical foundation (Proposition 1) to extend VariBAD to off-policy RL.\n    *   Formulates **MDP ambiguity** \\cite{dorfman2020mgv}, characterizing the solvability of problems under the offline BRL setting, and proposes principled data collection/modification strategies to mitigate it.\n    *   Introduces **BOReL** \\cite{dorfman2020mgv}, a practical off-policy BRL algorithm.\n    *   The developed off-policy algorithm significantly improves the sample efficiency of conventional VariBAD, even in the online setting, which is an independent contribution.\n\n*   **Experimental Validation**\n    *   Experiments were conducted on a diverse set of domains, including challenging sparse reward tasks (e.g., Semi-Circle navigation, Ant-Maze).\n    *   Key performance metrics included the effectiveness of learned exploration policies and accumulated reward.\n    *   BOReL \\cite{dorfman2020mgv} demonstrated significantly better exploration capabilities compared to meta-RL methods based on Thompson sampling (e.g., PEARL), even when these baselines were allowed to train online.\n    *   The paper also practically explored MDP ambiguity and showed that the proposed solutions successfully mitigate it when applicable. Qualitatively, BOReL learned exploration behaviors (e.g., systematic searching) that were distinct from the exploitative behaviors present in the original offline data.\n\n*   **Limitations & Scope**\n    *   The primary technical limitation is **MDP ambiguity** \\cite{dorfman2020mgv}, which implies that not all offline datasets are suitable for learning effective meta-exploration without careful consideration of data collection. The proposed solutions for ambiguity rely on specific conditions (e.g., sufficient data coverage of identifying state-action pairs).\n    *   The scope is focused on learning from data collected by conventional RL agents, assuming complete trajectories are available for state relabeling.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by enabling meta-learning of exploration from *offline* data, addressing a critical bottleneck for applying meta-RL in data-expensive real-world scenarios \\cite{dorfman2020mgv}.\n    *   The formalization of MDP ambiguity provides a crucial theoretical insight into the identifiability challenges of offline meta-RL, guiding future research and data collection strategies.\n    *   BOReL \\cite{dorfman2020mgv} offers a practical and effective algorithm that outperforms online baselines, demonstrating the feasibility and potential of offline meta-exploration.\n    *   The improved sample efficiency of the off-policy VariBAD variant also has broader implications for online meta-RL.",
      "intriguing_abstract": "Real-world applications of Meta Reinforcement Learning (Meta-RL) are often bottlenecked by the prohibitive cost of online data collection. We tackle the critical challenge of **Offline Meta Reinforcement Learning (OMRL)**, aiming to learn rapid adaptation and effective *exploration* strategies for novel tasks solely from pre-existing, *exploitation*-focused offline datasets. This presents a unique identifiability problem: how to infer task beliefs and learn exploratory behaviors when the data primarily reflects goal-directed actions.\n\nOur work introduces and formalizes **MDP ambiguity**, a fundamental issue where offline data may lack sufficient information to distinguish between underlying task dynamics, hindering effective belief learning. To overcome this, we propose **Bayesian Offline Reinforcement Learning (BOReL)**, an innovative off-policy variant of VariBAD. BOReL leverages \"state relabeling\" to transform offline trajectories into a Bayes-Adaptive MDP (BAMDP) format, enabling robust learning via off-policy Q-learning or Soft Actor-Critic (SAC). We also provide principled strategies to mitigate MDP ambiguity.\n\nExperiments across diverse sparse-reward environments demonstrate that BOReL significantly outperforms state-of-the-art online meta-RL baselines in learning superior exploration policies. This work not only provides the first comprehensive study of meta-learning exploration in the offline setting but also offers crucial theoretical insights and a practical algorithm, paving the way for scalable and impactful Meta-RL in data-scarce domains.",
      "keywords": [
        "Offline Meta Reinforcement Learning (OMRL)",
        "MDP ambiguity",
        "Bayesian Offline Reinforcement Learning (BOReL)",
        "Meta-learning exploration",
        "Off-policy VariBAD",
        "Bayes-Adaptive MDP (BAMDP)",
        "State relabeling",
        "Reward relabeling trick",
        "Sample efficiency",
        "Identifiability challenges",
        "Offline data collection strategies",
        "Robotics",
        "healthcare"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/9342fce9c5a69f545a778ca7e885ba9d63af928f.pdf",
      "citation_key": "dorfman2020mgv",
      "metadata": {
        "title": "Offline Meta Reinforcement Learning",
        "authors": [
          "Ron Dorfman",
          "Aviv Tamar"
        ],
        "published_date": "2020",
        "abstract": "Consider the following problem, which we term Offline Meta Reinforcement Learning (OMRL): given the complete training histories of $N$ conventional RL agents, trained on $N$ different tasks, design a learning agent that can quickly maximize reward in a new, unseen task from the same task distribution. In particular, while each conventional RL agent explored and exploited its own different task, the OMRL agent must identify regularities in the data that lead to effective exploration/exploitation in the unseen task. To solve OMRL, we take a Bayesian RL (BRL) view, and seek to learn a Bayes-optimal policy from the offline data. We extend the recently proposed VariBAD BRL algorithm to the off-policy setting, and demonstrate learning of Bayes-optimal exploration strategies from offline data using deep neural networks. Furthermore, when applied to the online meta-RL setting (agent simultaneously collects data and improves its meta-RL policy), our method is significantly more sample efficient than the conventional VariBAD.",
        "file_path": "paper_data/Deep_Meta-Learning/info/9342fce9c5a69f545a778ca7e885ba9d63af928f.pdf",
        "venue": "arXiv.org",
        "citationCount": 20,
        "score": 4.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the **Offline Meta Reinforcement Learning (OMRL)** problem: given offline training logs from *N* conventional RL agents on *N* different tasks, learn a meta-agent that can quickly maximize reward in a new, unseen task from the same distribution \\cite{dorfman2020mgv}.\n    *   This problem is important because online meta-RL training is often prohibitively expensive in real-world domains (e.g., robotics, healthcare). It is challenging because the meta-agent must learn effective *exploration* strategies for unknown tasks from data where conventional agents primarily *exploited* known task-specific goals, leading to potentially different behaviors (e.g., searching for a goal vs. navigating directly to it). A new identifiability issue, termed **MDP ambiguity**, arises when inferring beliefs from offline data \\cite{dorfman2020mgv}.\n\n*   **Related Work & Positioning**\n    *   This work builds upon Meta-RL and Bayesian RL (BRL) frameworks, specifically extending the **VariBAD** algorithm \\cite{dorfman2020mgv}.\n    *   Most prior meta-RL studies, including VariBAD, focused on the *online* setting, where the meta-RL policy continually collects data. This limits applicability in data-scarce or expensive domains. The paper positions itself as the first to study meta-learning exploration in the *offline* setting \\cite{dorfman2020mgv}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **Bayesian Offline Reinforcement Learning (BOReL)** \\cite{dorfman2020mgv}, an off-policy variant of the VariBAD algorithm.\n    *   **Off-policy VariBAD**: It replaces VariBAD's on-policy policy gradient optimization with an off-policy Q-learning (for discrete actions) or Soft Actor-Critic (SAC, for continuous actions) approach. This is enabled by \"state relabeling,\" where the VariBAD VAE encoder is used to augment each state in the offline trajectories with a neural belief estimate, effectively transforming the data into a Bayes-Adaptive MDP (BAMDP) format.\n    *   **MDP Ambiguity**: The paper identifies and formalizes **MDP ambiguity** \\cite{dorfman2020mgv}, a problem where the offline data might not contain sufficient information to distinguish between different underlying MDPs, making it impossible to learn an accurate belief update.\n    *   **Resolutions for Ambiguity**: It proposes principled data collection strategies (e.g., ensuring identifying state-action pairs are visited) and a \"reward relabeling trick\" for cases where ambiguity is solely due to reward differences \\cite{dorfman2020mgv}.\n\n*   **Key Technical Contributions**\n    *   First study of meta-learning exploration in the offline setting \\cite{dorfman2020mgv}.\n    *   Provides the necessary theoretical foundation (Proposition 1) to extend VariBAD to off-policy RL.\n    *   Formulates **MDP ambiguity** \\cite{dorfman2020mgv}, characterizing the solvability of problems under the offline BRL setting, and proposes principled data collection/modification strategies to mitigate it.\n    *   Introduces **BOReL** \\cite{dorfman2020mgv}, a practical off-policy BRL algorithm.\n    *   The developed off-policy algorithm significantly improves the sample efficiency of conventional VariBAD, even in the online setting, which is an independent contribution.\n\n*   **Experimental Validation**\n    *   Experiments were conducted on a diverse set of domains, including challenging sparse reward tasks (e.g., Semi-Circle navigation, Ant-Maze).\n    *   Key performance metrics included the effectiveness of learned exploration policies and accumulated reward.\n    *   BOReL \\cite{dorfman2020mgv} demonstrated significantly better exploration capabilities compared to meta-RL methods based on Thompson sampling (e.g., PEARL), even when these baselines were allowed to train online.\n    *   The paper also practically explored MDP ambiguity and showed that the proposed solutions successfully mitigate it when applicable. Qualitatively, BOReL learned exploration behaviors (e.g., systematic searching) that were distinct from the exploitative behaviors present in the original offline data.\n\n*   **Limitations & Scope**\n    *   The primary technical limitation is **MDP ambiguity** \\cite{dorfman2020mgv}, which implies that not all offline datasets are suitable for learning effective meta-exploration without careful consideration of data collection. The proposed solutions for ambiguity rely on specific conditions (e.g., sufficient data coverage of identifying state-action pairs).\n    *   The scope is focused on learning from data collected by conventional RL agents, assuming complete trajectories are available for state relabeling.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by enabling meta-learning of exploration from *offline* data, addressing a critical bottleneck for applying meta-RL in data-expensive real-world scenarios \\cite{dorfman2020mgv}.\n    *   The formalization of MDP ambiguity provides a crucial theoretical insight into the identifiability challenges of offline meta-RL, guiding future research and data collection strategies.\n    *   BOReL \\cite{dorfman2020mgv} offers a practical and effective algorithm that outperforms online baselines, demonstrating the feasibility and potential of offline meta-exploration.\n    *   The improved sample efficiency of the off-policy VariBAD variant also has broader implications for online meta-RL.",
        "keywords": [
          "Offline Meta Reinforcement Learning (OMRL)",
          "MDP ambiguity",
          "Bayesian Offline Reinforcement Learning (BOReL)",
          "Meta-learning exploration",
          "Off-policy VariBAD",
          "Bayes-Adaptive MDP (BAMDP)",
          "State relabeling",
          "Reward relabeling trick",
          "Sample efficiency",
          "Identifiability challenges",
          "Offline data collection strategies",
          "Robotics",
          "healthcare"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we develop an off-policy brl method that learns to plan an exploration strategy...\" and \"we characterize the problem, and suggest resolutions...\". it also mentions evaluating the framework.\n*   the introduction sets up a technical problem in reinforcement learning (how to learn quickly in new environments) and discusses existing approaches (meta-rl, brl) before the paper's specific contribution.\n\nthese points strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems. the empirical evaluation mentioned in the abstract is a common component of technical papers to validate the proposed method.\n\n**classification: technical**"
      },
      "file_name": "9342fce9c5a69f545a778ca7e885ba9d63af928f.pdf"
    },
    {
      "success": true,
      "doc_id": "1040a94ad4396f41f1c59c2129f72d98",
      "summary": "Using neural networks in practical settings would benefit from the ability of the networks to learn new tasks throughout their lifetimes without forgetting the previous tasks. This ability is limited in the current deep neural networks by a problem called catastrophic forgetting, where training on new tasks tends to severely degrade performance on previous tasks. One way to lessen the impact of the forgetting problem is to constrain parameters that are important to previous tasks to stay close to the optimal parameters. Recently, multiple competitive approaches for computing the importance of the parameters with respect to the previous tasks have been presented. In this paper, we propose a learning to optimize algorithm for mitigating catastrophic forgetting. Instead of trying to formulate a new constraint function ourselves, we propose to train another neural network to predict parameter update steps that respect the importance of parameters to the previous tasks. In the proposed meta-training scheme, the update predictor is trained to minimize loss on a combination of current and past tasks. We show experimentally that the proposed approach works in the continual learning setting.",
      "intriguing_abstract": "Using neural networks in practical settings would benefit from the ability of the networks to learn new tasks throughout their lifetimes without forgetting the previous tasks. This ability is limited in the current deep neural networks by a problem called catastrophic forgetting, where training on new tasks tends to severely degrade performance on previous tasks. One way to lessen the impact of the forgetting problem is to constrain parameters that are important to previous tasks to stay close to the optimal parameters. Recently, multiple competitive approaches for computing the importance of the parameters with respect to the previous tasks have been presented. In this paper, we propose a learning to optimize algorithm for mitigating catastrophic forgetting. Instead of trying to formulate a new constraint function ourselves, we propose to train another neural network to predict parameter update steps that respect the importance of parameters to the previous tasks. In the proposed meta-training scheme, the update predictor is trained to minimize loss on a combination of current and past tasks. We show experimentally that the proposed approach works in the continual learning setting.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b1493cac304d3fea710b375fa09e4b943a8a7de9.pdf",
      "citation_key": "vuorio2018gwb",
      "metadata": {
        "title": "Meta Continual Learning",
        "authors": [
          "Risto Vuorio",
          "D.-Y. Cho",
          "Daejoong Kim",
          "Jiwon Kim"
        ],
        "published_date": "2018",
        "abstract": "Using neural networks in practical settings would benefit from the ability of the networks to learn new tasks throughout their lifetimes without forgetting the previous tasks. This ability is limited in the current deep neural networks by a problem called catastrophic forgetting, where training on new tasks tends to severely degrade performance on previous tasks. One way to lessen the impact of the forgetting problem is to constrain parameters that are important to previous tasks to stay close to the optimal parameters. Recently, multiple competitive approaches for computing the importance of the parameters with respect to the previous tasks have been presented. In this paper, we propose a learning to optimize algorithm for mitigating catastrophic forgetting. Instead of trying to formulate a new constraint function ourselves, we propose to train another neural network to predict parameter update steps that respect the importance of parameters to the previous tasks. In the proposed meta-training scheme, the update predictor is trained to minimize loss on a combination of current and past tasks. We show experimentally that the proposed approach works in the continual learning setting.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b1493cac304d3fea710b375fa09e4b943a8a7de9.pdf",
        "venue": "arXiv.org",
        "citationCount": 28,
        "score": 4.0,
        "summary": "Using neural networks in practical settings would benefit from the ability of the networks to learn new tasks throughout their lifetimes without forgetting the previous tasks. This ability is limited in the current deep neural networks by a problem called catastrophic forgetting, where training on new tasks tends to severely degrade performance on previous tasks. One way to lessen the impact of the forgetting problem is to constrain parameters that are important to previous tasks to stay close to the optimal parameters. Recently, multiple competitive approaches for computing the importance of the parameters with respect to the previous tasks have been presented. In this paper, we propose a learning to optimize algorithm for mitigating catastrophic forgetting. Instead of trying to formulate a new constraint function ourselves, we propose to train another neural network to predict parameter update steps that respect the importance of parameters to the previous tasks. In the proposed meta-training scheme, the update predictor is trained to minimize loss on a combination of current and past tasks. We show experimentally that the proposed approach works in the continual learning setting.",
        "keywords": []
      },
      "file_name": "b1493cac304d3fea710b375fa09e4b943a8a7de9.pdf"
    },
    {
      "success": true,
      "doc_id": "77558414f8dd5bfd2df594289a1e9c59",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/cc8f827346abea33f1eef838653a2507fc82de6b.pdf",
      "citation_key": "ma2021kfz",
      "metadata": {
        "title": "ML-CGAN: Conditional Generative Adversarial Network with a Meta-learner Structure for High-Quality Image Generation with Few Training Data",
        "authors": [
          "Ying Ma",
          "G. Zhong",
          "Wen Liu",
          "Yanan Wang",
          "Peng Jiang",
          "Rui Zhang"
        ],
        "published_date": "2021",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/cc8f827346abea33f1eef838653a2507fc82de6b.pdf",
        "venue": "Cognitive Computation",
        "citationCount": 16,
        "score": 4.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "cc8f827346abea33f1eef838653a2507fc82de6b.pdf"
    },
    {
      "success": true,
      "doc_id": "9f8cf18dced357b49d366864b7a557f9",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/12f851dd2148fff930064b99e88664aec732b8d0.pdf",
      "citation_key": "tian2016j46",
      "metadata": {
        "title": "Survey of Meta-Heuristic Algorithms for Deep Learning Training",
        "authors": [
          "Zhonghuan Tian",
          "S. Fong"
        ],
        "published_date": "2016",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/12f851dd2148fff930064b99e88664aec732b8d0.pdf",
        "venue": "",
        "citationCount": 35,
        "score": 3.888888888888889,
        "summary": "",
        "keywords": []
      },
      "file_name": "12f851dd2148fff930064b99e88664aec732b8d0.pdf"
    },
    {
      "success": true,
      "doc_id": "2a1a52887fc64aa7b30a03d2731e63e8",
      "summary": "Recent work has shown the efficiency of deep learning models such as Fully Convolutional Networks (FCN) or Recurrent Neural Networks (RNN) to deal with Time Series Regression (TSR) problems. These models sometimes need a lot of data to be able to generalize, yet the time series are sometimes not long enough to be able to learn patterns. Therefore, it is important to make use of information across time series to improve learning. In this paper, we will explore the idea of using meta-learning for quickly adapting model parameters to new short-history time series by modifying the original idea of Model Agnostic Meta-Learning (MAML) \\cite{finn2017model}. Moreover, based on prior work on multimodal MAML \\cite{vuorio2019multimodal}, we propose a method for conditioning parameters of the model through an auxiliary network that encodes global information of the time series to extract meta-features. Finally, we apply the data to time series of different domains, such as pollution measurements, heart-rate sensors, and electrical battery data. We show empirically that our proposed meta-learning method learns TSR with few data fast and outperforms the baselines in 9 of 12 experiments.",
      "intriguing_abstract": "Recent work has shown the efficiency of deep learning models such as Fully Convolutional Networks (FCN) or Recurrent Neural Networks (RNN) to deal with Time Series Regression (TSR) problems. These models sometimes need a lot of data to be able to generalize, yet the time series are sometimes not long enough to be able to learn patterns. Therefore, it is important to make use of information across time series to improve learning. In this paper, we will explore the idea of using meta-learning for quickly adapting model parameters to new short-history time series by modifying the original idea of Model Agnostic Meta-Learning (MAML) \\cite{finn2017model}. Moreover, based on prior work on multimodal MAML \\cite{vuorio2019multimodal}, we propose a method for conditioning parameters of the model through an auxiliary network that encodes global information of the time series to extract meta-features. Finally, we apply the data to time series of different domains, such as pollution measurements, heart-rate sensors, and electrical battery data. We show empirically that our proposed meta-learning method learns TSR with few data fast and outperforms the baselines in 9 of 12 experiments.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/72cb23c88bd98b1aff0c13302a565be071a4728d.pdf",
      "citation_key": "pinedaarango2021254",
      "metadata": {
        "title": "Multimodal Meta-Learning for Time Series Regression",
        "authors": [
          "Sebastian Pineda-Arango",
          "Felix Heinrich",
          "Kiran Madhusudhanan",
          "L. Schmidt-Thieme"
        ],
        "published_date": "2021",
        "abstract": "Recent work has shown the efficiency of deep learning models such as Fully Convolutional Networks (FCN) or Recurrent Neural Networks (RNN) to deal with Time Series Regression (TSR) problems. These models sometimes need a lot of data to be able to generalize, yet the time series are sometimes not long enough to be able to learn patterns. Therefore, it is important to make use of information across time series to improve learning. In this paper, we will explore the idea of using meta-learning for quickly adapting model parameters to new short-history time series by modifying the original idea of Model Agnostic Meta-Learning (MAML) \\cite{finn2017model}. Moreover, based on prior work on multimodal MAML \\cite{vuorio2019multimodal}, we propose a method for conditioning parameters of the model through an auxiliary network that encodes global information of the time series to extract meta-features. Finally, we apply the data to time series of different domains, such as pollution measurements, heart-rate sensors, and electrical battery data. We show empirically that our proposed meta-learning method learns TSR with few data fast and outperforms the baselines in 9 of 12 experiments.",
        "file_path": "paper_data/Deep_Meta-Learning/info/72cb23c88bd98b1aff0c13302a565be071a4728d.pdf",
        "venue": "AALTD@ECML/PKDD",
        "citationCount": 15,
        "score": 3.75,
        "summary": "Recent work has shown the efficiency of deep learning models such as Fully Convolutional Networks (FCN) or Recurrent Neural Networks (RNN) to deal with Time Series Regression (TSR) problems. These models sometimes need a lot of data to be able to generalize, yet the time series are sometimes not long enough to be able to learn patterns. Therefore, it is important to make use of information across time series to improve learning. In this paper, we will explore the idea of using meta-learning for quickly adapting model parameters to new short-history time series by modifying the original idea of Model Agnostic Meta-Learning (MAML) \\cite{finn2017model}. Moreover, based on prior work on multimodal MAML \\cite{vuorio2019multimodal}, we propose a method for conditioning parameters of the model through an auxiliary network that encodes global information of the time series to extract meta-features. Finally, we apply the data to time series of different domains, such as pollution measurements, heart-rate sensors, and electrical battery data. We show empirically that our proposed meta-learning method learns TSR with few data fast and outperforms the baselines in 9 of 12 experiments.",
        "keywords": []
      },
      "file_name": "72cb23c88bd98b1aff0c13302a565be071a4728d.pdf"
    },
    {
      "success": true,
      "doc_id": "e5a9f9339c9d8d354613def9807c4716",
      "summary": "Radio based positioning of a user equipment (UE) based on deep learning (DL) methods using channel state information (CSI) fingerprints have shown promising results. DL models are able to capture complex properties embedded in the CSI about a particular environment and map UE’s CSI to the UE’s position. However, the CSI fingerprints and the DL models trained on such fingerprints are highly dependent on a particular propagation environment, which generally limits the transfer of knowledge of the DL models from one environment to another. In this paper, we propose a DL model consisting of two parts: the first part aims to learn environment independent features while the second part combines those features depending on the particular environment. To improve transfer learning, we propose a meta learning scheme for training the first part over multiple environments. We show that for positioning in a new environment, initializing a DL model with the meta learned environment independent function achieves higher UE positioning accuracy compared to regular transfer learning from one environment to the new environment, or compared to training the DL model from scratch with only fingerprints from the new environment. Our proposed scheme is able to create an environment independent function which can embed knowledge from multiple environments and more effectively learn from a new environment.",
      "intriguing_abstract": "Radio based positioning of a user equipment (UE) based on deep learning (DL) methods using channel state information (CSI) fingerprints have shown promising results. DL models are able to capture complex properties embedded in the CSI about a particular environment and map UE’s CSI to the UE’s position. However, the CSI fingerprints and the DL models trained on such fingerprints are highly dependent on a particular propagation environment, which generally limits the transfer of knowledge of the DL models from one environment to another. In this paper, we propose a DL model consisting of two parts: the first part aims to learn environment independent features while the second part combines those features depending on the particular environment. To improve transfer learning, we propose a meta learning scheme for training the first part over multiple environments. We show that for positioning in a new environment, initializing a DL model with the meta learned environment independent function achieves higher UE positioning accuracy compared to regular transfer learning from one environment to the new environment, or compared to training the DL model from scratch with only fingerprints from the new environment. Our proposed scheme is able to create an environment independent function which can embed knowledge from multiple environments and more effectively learn from a new environment.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/a1d8d2784d3e468c92410124072bc2eb4c3ace5b.pdf",
      "citation_key": "foliadis20223y2",
      "metadata": {
        "title": "Multi-Environment based Meta-Learning with CSI Fingerprints for Radio Based Positioning",
        "authors": [
          "Anastasios Foliadis",
          "M. H. C. García",
          "R. Stirling-Gallacher",
          "R. Thomä"
        ],
        "published_date": "2022",
        "abstract": "Radio based positioning of a user equipment (UE) based on deep learning (DL) methods using channel state information (CSI) fingerprints have shown promising results. DL models are able to capture complex properties embedded in the CSI about a particular environment and map UE’s CSI to the UE’s position. However, the CSI fingerprints and the DL models trained on such fingerprints are highly dependent on a particular propagation environment, which generally limits the transfer of knowledge of the DL models from one environment to another. In this paper, we propose a DL model consisting of two parts: the first part aims to learn environment independent features while the second part combines those features depending on the particular environment. To improve transfer learning, we propose a meta learning scheme for training the first part over multiple environments. We show that for positioning in a new environment, initializing a DL model with the meta learned environment independent function achieves higher UE positioning accuracy compared to regular transfer learning from one environment to the new environment, or compared to training the DL model from scratch with only fingerprints from the new environment. Our proposed scheme is able to create an environment independent function which can embed knowledge from multiple environments and more effectively learn from a new environment.",
        "file_path": "paper_data/Deep_Meta-Learning/info/a1d8d2784d3e468c92410124072bc2eb4c3ace5b.pdf",
        "venue": "IEEE Wireless Communications and Networking Conference",
        "citationCount": 11,
        "score": 3.6666666666666665,
        "summary": "Radio based positioning of a user equipment (UE) based on deep learning (DL) methods using channel state information (CSI) fingerprints have shown promising results. DL models are able to capture complex properties embedded in the CSI about a particular environment and map UE’s CSI to the UE’s position. However, the CSI fingerprints and the DL models trained on such fingerprints are highly dependent on a particular propagation environment, which generally limits the transfer of knowledge of the DL models from one environment to another. In this paper, we propose a DL model consisting of two parts: the first part aims to learn environment independent features while the second part combines those features depending on the particular environment. To improve transfer learning, we propose a meta learning scheme for training the first part over multiple environments. We show that for positioning in a new environment, initializing a DL model with the meta learned environment independent function achieves higher UE positioning accuracy compared to regular transfer learning from one environment to the new environment, or compared to training the DL model from scratch with only fingerprints from the new environment. Our proposed scheme is able to create an environment independent function which can embed knowledge from multiple environments and more effectively learn from a new environment.",
        "keywords": []
      },
      "file_name": "a1d8d2784d3e468c92410124072bc2eb4c3ace5b.pdf"
    },
    {
      "success": true,
      "doc_id": "9d4e59e2994a930e35d0555e8cc47255",
      "summary": "Systems for learning parameters often have meta-parameters such as step sizes, initial weights, or dimensional weightings. With a given setting of the meta-parameters, the learning system is complete and capable of finding parameters that are suited to the task, but its efficiency typically depends on the particular choice of metaparameters. This has led to interest in learning processes that can find good choices for meta-parameters automatically from experience. These higher-level learning methods are often characterized as “learning to learn” or, as we shall call them here, metalearning. Meta-learning has been explored extensively within machine learning for many years (e.g., see Thrun & Pratt 1998). A class of meta-learning methods that appears particularly powerful and that has attracted considerable recent attention are those based on stochastic gradient descent or ascent (e.g., Andrychowicz et al. 2016; Finn, Abeel & Levine 2017; Xu, van Hasselt & Silver 2018). The rise of deep learning has shown that gradient methods can be surprisingly effective in the base learning system (e.g., AlphaZero (Silver et al. 2018), DeepStack (Moravč́ık et al. 2017), Alexnet (Krizhevsky et al. 2012)), so it is natural to consider gradient methods for learning meta-parameters. Let us call such gradient methods for meta-learning meta-gradient methods, after Xu et al. (2018). Almost all meta-gradient methods use a gradient method in the base learning system as well. Meta-gradient methods have shown promise; they are very general and, in some cases, have achieved learning performance equal to that for hand-tuned meta-parameters. Let us briefly consider the origins of meta-gradient learning methods and the major steps leading to recent developments. The meta-parameter learned in all of the earliest meta-gradient methods was the step size or “learning rate” of supervised learning systems. To our knowledge the first meta-gradient method was a method for setting the step-size (gain) meta-parameter",
      "intriguing_abstract": "Systems for learning parameters often have meta-parameters such as step sizes, initial weights, or dimensional weightings. With a given setting of the meta-parameters, the learning system is complete and capable of finding parameters that are suited to the task, but its efficiency typically depends on the particular choice of metaparameters. This has led to interest in learning processes that can find good choices for meta-parameters automatically from experience. These higher-level learning methods are often characterized as “learning to learn” or, as we shall call them here, metalearning. Meta-learning has been explored extensively within machine learning for many years (e.g., see Thrun & Pratt 1998). A class of meta-learning methods that appears particularly powerful and that has attracted considerable recent attention are those based on stochastic gradient descent or ascent (e.g., Andrychowicz et al. 2016; Finn, Abeel & Levine 2017; Xu, van Hasselt & Silver 2018). The rise of deep learning has shown that gradient methods can be surprisingly effective in the base learning system (e.g., AlphaZero (Silver et al. 2018), DeepStack (Moravč́ık et al. 2017), Alexnet (Krizhevsky et al. 2012)), so it is natural to consider gradient methods for learning meta-parameters. Let us call such gradient methods for meta-learning meta-gradient methods, after Xu et al. (2018). Almost all meta-gradient methods use a gradient method in the base learning system as well. Meta-gradient methods have shown promise; they are very general and, in some cases, have achieved learning performance equal to that for hand-tuned meta-parameters. Let us briefly consider the origins of meta-gradient learning methods and the major steps leading to recent developments. The meta-parameter learned in all of the earliest meta-gradient methods was the step size or “learning rate” of supervised learning systems. To our knowledge the first meta-gradient method was a method for setting the step-size (gain) meta-parameter",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3c4831e493dc7a362359cdb1883e8c16d084c55b.pdf",
      "citation_key": "sutton2022jss",
      "metadata": {
        "title": "A History of Meta-gradient: Gradient Methods for Meta-learning",
        "authors": [
          "R. Sutton"
        ],
        "published_date": "2022",
        "abstract": "Systems for learning parameters often have meta-parameters such as step sizes, initial weights, or dimensional weightings. With a given setting of the meta-parameters, the learning system is complete and capable of finding parameters that are suited to the task, but its efficiency typically depends on the particular choice of metaparameters. This has led to interest in learning processes that can find good choices for meta-parameters automatically from experience. These higher-level learning methods are often characterized as “learning to learn” or, as we shall call them here, metalearning. Meta-learning has been explored extensively within machine learning for many years (e.g., see Thrun & Pratt 1998). A class of meta-learning methods that appears particularly powerful and that has attracted considerable recent attention are those based on stochastic gradient descent or ascent (e.g., Andrychowicz et al. 2016; Finn, Abeel & Levine 2017; Xu, van Hasselt & Silver 2018). The rise of deep learning has shown that gradient methods can be surprisingly effective in the base learning system (e.g., AlphaZero (Silver et al. 2018), DeepStack (Moravč́ık et al. 2017), Alexnet (Krizhevsky et al. 2012)), so it is natural to consider gradient methods for learning meta-parameters. Let us call such gradient methods for meta-learning meta-gradient methods, after Xu et al. (2018). Almost all meta-gradient methods use a gradient method in the base learning system as well. Meta-gradient methods have shown promise; they are very general and, in some cases, have achieved learning performance equal to that for hand-tuned meta-parameters. Let us briefly consider the origins of meta-gradient learning methods and the major steps leading to recent developments. The meta-parameter learned in all of the earliest meta-gradient methods was the step size or “learning rate” of supervised learning systems. To our knowledge the first meta-gradient method was a method for setting the step-size (gain) meta-parameter",
        "file_path": "paper_data/Deep_Meta-Learning/info/3c4831e493dc7a362359cdb1883e8c16d084c55b.pdf",
        "venue": "arXiv.org",
        "citationCount": 11,
        "score": 3.6666666666666665,
        "summary": "Systems for learning parameters often have meta-parameters such as step sizes, initial weights, or dimensional weightings. With a given setting of the meta-parameters, the learning system is complete and capable of finding parameters that are suited to the task, but its efficiency typically depends on the particular choice of metaparameters. This has led to interest in learning processes that can find good choices for meta-parameters automatically from experience. These higher-level learning methods are often characterized as “learning to learn” or, as we shall call them here, metalearning. Meta-learning has been explored extensively within machine learning for many years (e.g., see Thrun & Pratt 1998). A class of meta-learning methods that appears particularly powerful and that has attracted considerable recent attention are those based on stochastic gradient descent or ascent (e.g., Andrychowicz et al. 2016; Finn, Abeel & Levine 2017; Xu, van Hasselt & Silver 2018). The rise of deep learning has shown that gradient methods can be surprisingly effective in the base learning system (e.g., AlphaZero (Silver et al. 2018), DeepStack (Moravč́ık et al. 2017), Alexnet (Krizhevsky et al. 2012)), so it is natural to consider gradient methods for learning meta-parameters. Let us call such gradient methods for meta-learning meta-gradient methods, after Xu et al. (2018). Almost all meta-gradient methods use a gradient method in the base learning system as well. Meta-gradient methods have shown promise; they are very general and, in some cases, have achieved learning performance equal to that for hand-tuned meta-parameters. Let us briefly consider the origins of meta-gradient learning methods and the major steps leading to recent developments. The meta-parameter learned in all of the earliest meta-gradient methods was the step size or “learning rate” of supervised learning systems. To our knowledge the first meta-gradient method was a method for setting the step-size (gain) meta-parameter",
        "keywords": []
      },
      "file_name": "3c4831e493dc7a362359cdb1883e8c16d084c55b.pdf"
    },
    {
      "success": true,
      "doc_id": "9369d8b697a1bf81774ce39164f4d7ad",
      "summary": "In a <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula>-best detector for multiple-input-multiple-output (MIMO) systems, the value of <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> needs to be sufficiently large to achieve near-maximum-likelihood (ML) performance. By treating <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> as a variable that can be adjusted according to a fitting function of some learnable coefficients, an intelligent MIMO detection network based on deep neural networks (DNN) is proposed to reduce complexity of the detection algorithm with little performance degradation. In particular, the proposed intelligent detection algorithm uses meta learning to learn the coefficients of the fitting function for <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> to circumvent the problem of learning <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> directly. The idea of network fusion is used to combine the learning results of the meta learning component networks. Simulation results show that the proposed scheme achieves near-ML detection performance while its complexity is close to that of linear detectors. Besides, it also exhibits strong ability of fast training.",
      "intriguing_abstract": "In a <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula>-best detector for multiple-input-multiple-output (MIMO) systems, the value of <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> needs to be sufficiently large to achieve near-maximum-likelihood (ML) performance. By treating <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> as a variable that can be adjusted according to a fitting function of some learnable coefficients, an intelligent MIMO detection network based on deep neural networks (DNN) is proposed to reduce complexity of the detection algorithm with little performance degradation. In particular, the proposed intelligent detection algorithm uses meta learning to learn the coefficients of the fitting function for <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> to circumvent the problem of learning <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> directly. The idea of network fusion is used to combine the learning results of the meta learning component networks. Simulation results show that the proposed scheme achieves near-ML detection performance while its complexity is close to that of linear detectors. Besides, it also exhibits strong ability of fast training.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e457c9edc3ff2dec29d4f46597c03c56c59708af.pdf",
      "citation_key": "huo2022rp4",
      "metadata": {
        "title": "Intelligent MIMO Detection Using Meta Learning",
        "authors": [
          "Haomiao Huo",
          "Jindan Xu",
          "Gege Su",
          "Wei Xu",
          "Ning Wang"
        ],
        "published_date": "2022",
        "abstract": "In a <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula>-best detector for multiple-input-multiple-output (MIMO) systems, the value of <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> needs to be sufficiently large to achieve near-maximum-likelihood (ML) performance. By treating <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> as a variable that can be adjusted according to a fitting function of some learnable coefficients, an intelligent MIMO detection network based on deep neural networks (DNN) is proposed to reduce complexity of the detection algorithm with little performance degradation. In particular, the proposed intelligent detection algorithm uses meta learning to learn the coefficients of the fitting function for <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> to circumvent the problem of learning <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> directly. The idea of network fusion is used to combine the learning results of the meta learning component networks. Simulation results show that the proposed scheme achieves near-ML detection performance while its complexity is close to that of linear detectors. Besides, it also exhibits strong ability of fast training.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e457c9edc3ff2dec29d4f46597c03c56c59708af.pdf",
        "venue": "IEEE Wireless Communications Letters",
        "citationCount": 10,
        "score": 3.333333333333333,
        "summary": "In a <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula>-best detector for multiple-input-multiple-output (MIMO) systems, the value of <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> needs to be sufficiently large to achieve near-maximum-likelihood (ML) performance. By treating <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> as a variable that can be adjusted according to a fitting function of some learnable coefficients, an intelligent MIMO detection network based on deep neural networks (DNN) is proposed to reduce complexity of the detection algorithm with little performance degradation. In particular, the proposed intelligent detection algorithm uses meta learning to learn the coefficients of the fitting function for <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> to circumvent the problem of learning <inline-formula> <tex-math notation=\"LaTeX\">${K}$ </tex-math></inline-formula> directly. The idea of network fusion is used to combine the learning results of the meta learning component networks. Simulation results show that the proposed scheme achieves near-ML detection performance while its complexity is close to that of linear detectors. Besides, it also exhibits strong ability of fast training.",
        "keywords": []
      },
      "file_name": "e457c9edc3ff2dec29d4f46597c03c56c59708af.pdf"
    },
    {
      "success": true,
      "doc_id": "ce598ce056e0d8250ec63a00a79bb046",
      "summary": "Continuous learning occurs naturally in human beings. However, Deep Learning methods suffer from a problem known as Catastrophic Forgetting (CF) that consists of a model drastically decreasing its performance on previously learned tasks when it is sequentially trained on new tasks. This situation, known as task interference, occurs when a network modifies relevant weight values as it learns a new task. In this work, we propose two main strategies to face the problem of task interference in convolutional neural networks. First, we use a sparse coding technique to adaptively allocate model capacity to different tasks avoiding interference between them. Specifically, we use a strategy based on group sparse regularization to specialize groups of parameters to learn each task. Afterward, by adding binary masks, we can freeze these groups of parameters, using the rest of the network to learn new tasks. Second, we use a meta learning technique to foster knowledge transfer among tasks, encouraging weight reusability instead of overwriting. Specifically, we use an optimization strategy based on episodic training to foster learning weights that are expected to be useful to solve future tasks. Together, these two strategies help us to avoid interference by preserving compatibility with previous and future weight values. Using this approach, we achieve state-of-the-art results on popular benchmarks used to test techniques to avoid CF. In particular, we conduct an ablation study to identify the contribution of each component of the proposed method, demonstrating its ability to avoid retroactive interference with previous tasks and to promote knowledge transfer to future tasks.",
      "intriguing_abstract": "Continuous learning occurs naturally in human beings. However, Deep Learning methods suffer from a problem known as Catastrophic Forgetting (CF) that consists of a model drastically decreasing its performance on previously learned tasks when it is sequentially trained on new tasks. This situation, known as task interference, occurs when a network modifies relevant weight values as it learns a new task. In this work, we propose two main strategies to face the problem of task interference in convolutional neural networks. First, we use a sparse coding technique to adaptively allocate model capacity to different tasks avoiding interference between them. Specifically, we use a strategy based on group sparse regularization to specialize groups of parameters to learn each task. Afterward, by adding binary masks, we can freeze these groups of parameters, using the rest of the network to learn new tasks. Second, we use a meta learning technique to foster knowledge transfer among tasks, encouraging weight reusability instead of overwriting. Specifically, we use an optimization strategy based on episodic training to foster learning weights that are expected to be useful to solve future tasks. Together, these two strategies help us to avoid interference by preserving compatibility with previous and future weight values. Using this approach, we achieve state-of-the-art results on popular benchmarks used to test techniques to avoid CF. In particular, we conduct an ablation study to identify the contribution of each component of the proposed method, demonstrating its ability to avoid retroactive interference with previous tasks and to promote knowledge transfer to future tasks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/a38500c3448189abd05e72e35332224b96e24a32.pdf",
      "citation_key": "hurtado2021h2q",
      "metadata": {
        "title": "Overcoming Catastrophic Forgetting Using Sparse Coding and Meta Learning",
        "authors": [
          "J. Hurtado",
          "Hans Lobel",
          "Álvaro Soto"
        ],
        "published_date": "2021",
        "abstract": "Continuous learning occurs naturally in human beings. However, Deep Learning methods suffer from a problem known as Catastrophic Forgetting (CF) that consists of a model drastically decreasing its performance on previously learned tasks when it is sequentially trained on new tasks. This situation, known as task interference, occurs when a network modifies relevant weight values as it learns a new task. In this work, we propose two main strategies to face the problem of task interference in convolutional neural networks. First, we use a sparse coding technique to adaptively allocate model capacity to different tasks avoiding interference between them. Specifically, we use a strategy based on group sparse regularization to specialize groups of parameters to learn each task. Afterward, by adding binary masks, we can freeze these groups of parameters, using the rest of the network to learn new tasks. Second, we use a meta learning technique to foster knowledge transfer among tasks, encouraging weight reusability instead of overwriting. Specifically, we use an optimization strategy based on episodic training to foster learning weights that are expected to be useful to solve future tasks. Together, these two strategies help us to avoid interference by preserving compatibility with previous and future weight values. Using this approach, we achieve state-of-the-art results on popular benchmarks used to test techniques to avoid CF. In particular, we conduct an ablation study to identify the contribution of each component of the proposed method, demonstrating its ability to avoid retroactive interference with previous tasks and to promote knowledge transfer to future tasks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/a38500c3448189abd05e72e35332224b96e24a32.pdf",
        "venue": "IEEE Access",
        "citationCount": 13,
        "score": 3.25,
        "summary": "Continuous learning occurs naturally in human beings. However, Deep Learning methods suffer from a problem known as Catastrophic Forgetting (CF) that consists of a model drastically decreasing its performance on previously learned tasks when it is sequentially trained on new tasks. This situation, known as task interference, occurs when a network modifies relevant weight values as it learns a new task. In this work, we propose two main strategies to face the problem of task interference in convolutional neural networks. First, we use a sparse coding technique to adaptively allocate model capacity to different tasks avoiding interference between them. Specifically, we use a strategy based on group sparse regularization to specialize groups of parameters to learn each task. Afterward, by adding binary masks, we can freeze these groups of parameters, using the rest of the network to learn new tasks. Second, we use a meta learning technique to foster knowledge transfer among tasks, encouraging weight reusability instead of overwriting. Specifically, we use an optimization strategy based on episodic training to foster learning weights that are expected to be useful to solve future tasks. Together, these two strategies help us to avoid interference by preserving compatibility with previous and future weight values. Using this approach, we achieve state-of-the-art results on popular benchmarks used to test techniques to avoid CF. In particular, we conduct an ablation study to identify the contribution of each component of the proposed method, demonstrating its ability to avoid retroactive interference with previous tasks and to promote knowledge transfer to future tasks.",
        "keywords": []
      },
      "file_name": "a38500c3448189abd05e72e35332224b96e24a32.pdf"
    },
    {
      "success": true,
      "doc_id": "949b0679a6ad61a753c175de4026f914",
      "summary": "Deep learning based natural language processing (NLP) has become the mainstream of research in recent years and significantly outperforms conventional methods. However, deep learning models are notorious for being data and computation hungry. These downsides limit the application of such models from deployment to different domains, languages, countries, or styles, since collecting in-genre data and model training from scratch are costly. The long-tail nature of human language makes challenges even more significant. Meta-learning, or ‘Learning to Learn’, aims to learn better learning algorithms, including better parameter initialization, optimization strategy, network architecture, distance metrics, and beyond. Meta-learning has been shown to allow faster fine-tuning, converge to better performance, and achieve amazing results for few-shot learning in many applications. Meta-learning is one of the most important new techniques in machine learning in recent years. There is a related tutorial in ICML 2019 and a related course at Stanford, but most of the example applications given in these materials are about image processing. It is believed that meta-learning has great potential to be applied in NLP, and some works have been proposed with notable achievements in several relevant problems, e.g., relation extraction, machine translation, and dialogue generation and state tracking. However, it does not catch the same level of attention as in the image processing community. In the tutorial, we will first introduce Meta-learning approaches and the theory behind them, and then review the works of applying this technology to NLP problems. This tutorial intends to facilitate researchers in the NLP community to understand this new technology better and promote more research studies using this new technology.",
      "intriguing_abstract": "Deep learning based natural language processing (NLP) has become the mainstream of research in recent years and significantly outperforms conventional methods. However, deep learning models are notorious for being data and computation hungry. These downsides limit the application of such models from deployment to different domains, languages, countries, or styles, since collecting in-genre data and model training from scratch are costly. The long-tail nature of human language makes challenges even more significant. Meta-learning, or ‘Learning to Learn’, aims to learn better learning algorithms, including better parameter initialization, optimization strategy, network architecture, distance metrics, and beyond. Meta-learning has been shown to allow faster fine-tuning, converge to better performance, and achieve amazing results for few-shot learning in many applications. Meta-learning is one of the most important new techniques in machine learning in recent years. There is a related tutorial in ICML 2019 and a related course at Stanford, but most of the example applications given in these materials are about image processing. It is believed that meta-learning has great potential to be applied in NLP, and some works have been proposed with notable achievements in several relevant problems, e.g., relation extraction, machine translation, and dialogue generation and state tracking. However, it does not catch the same level of attention as in the image processing community. In the tutorial, we will first introduce Meta-learning approaches and the theory behind them, and then review the works of applying this technology to NLP problems. This tutorial intends to facilitate researchers in the NLP community to understand this new technology better and promote more research studies using this new technology.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3a4840ecfddc5e938e715379462af6fdbaa5e9b6.pdf",
      "citation_key": "lee2021jou",
      "metadata": {
        "title": "Meta Learning and Its Applications to Natural Language Processing",
        "authors": [
          "Hung-yi Lee",
          "Ngoc Thang Vu",
          "Shang-Wen Li"
        ],
        "published_date": "2021",
        "abstract": "Deep learning based natural language processing (NLP) has become the mainstream of research in recent years and significantly outperforms conventional methods. However, deep learning models are notorious for being data and computation hungry. These downsides limit the application of such models from deployment to different domains, languages, countries, or styles, since collecting in-genre data and model training from scratch are costly. The long-tail nature of human language makes challenges even more significant. Meta-learning, or ‘Learning to Learn’, aims to learn better learning algorithms, including better parameter initialization, optimization strategy, network architecture, distance metrics, and beyond. Meta-learning has been shown to allow faster fine-tuning, converge to better performance, and achieve amazing results for few-shot learning in many applications. Meta-learning is one of the most important new techniques in machine learning in recent years. There is a related tutorial in ICML 2019 and a related course at Stanford, but most of the example applications given in these materials are about image processing. It is believed that meta-learning has great potential to be applied in NLP, and some works have been proposed with notable achievements in several relevant problems, e.g., relation extraction, machine translation, and dialogue generation and state tracking. However, it does not catch the same level of attention as in the image processing community. In the tutorial, we will first introduce Meta-learning approaches and the theory behind them, and then review the works of applying this technology to NLP problems. This tutorial intends to facilitate researchers in the NLP community to understand this new technology better and promote more research studies using this new technology.",
        "file_path": "paper_data/Deep_Meta-Learning/info/3a4840ecfddc5e938e715379462af6fdbaa5e9b6.pdf",
        "venue": "Annual Meeting of the Association for Computational Linguistics",
        "citationCount": 12,
        "score": 3.0,
        "summary": "Deep learning based natural language processing (NLP) has become the mainstream of research in recent years and significantly outperforms conventional methods. However, deep learning models are notorious for being data and computation hungry. These downsides limit the application of such models from deployment to different domains, languages, countries, or styles, since collecting in-genre data and model training from scratch are costly. The long-tail nature of human language makes challenges even more significant. Meta-learning, or ‘Learning to Learn’, aims to learn better learning algorithms, including better parameter initialization, optimization strategy, network architecture, distance metrics, and beyond. Meta-learning has been shown to allow faster fine-tuning, converge to better performance, and achieve amazing results for few-shot learning in many applications. Meta-learning is one of the most important new techniques in machine learning in recent years. There is a related tutorial in ICML 2019 and a related course at Stanford, but most of the example applications given in these materials are about image processing. It is believed that meta-learning has great potential to be applied in NLP, and some works have been proposed with notable achievements in several relevant problems, e.g., relation extraction, machine translation, and dialogue generation and state tracking. However, it does not catch the same level of attention as in the image processing community. In the tutorial, we will first introduce Meta-learning approaches and the theory behind them, and then review the works of applying this technology to NLP problems. This tutorial intends to facilitate researchers in the NLP community to understand this new technology better and promote more research studies using this new technology.",
        "keywords": []
      },
      "file_name": "3a4840ecfddc5e938e715379462af6fdbaa5e9b6.pdf"
    },
    {
      "success": true,
      "doc_id": "b2ec11df83d3741adccc1b735cf1282c",
      "summary": "Detecting violence in videos through automatic means is significant for law enforcement and analysis of surveillance cameras with the intent of maintaining public safety. Moreover, it may be a great tool for protecting children from accessing inappropriate content and help parents make a better informed decision about what their kids should watch. However, this is a challenging problem since the very definition of violence is broad and highly subjective. Hence, detecting such nuances from videos with no human supervision is not only technical, but also a conceptual problem. With this in mind, we explore how to better describe the idea of violence for a convolutional neural network by breaking it into more objective and concrete parts. Initially, our method uses independent networks to learn features for more specific concepts related to violence, such as fights, explosions, blood, etc. Then we use these features to classify each concept and later fuse them in a meta-classification to describe violence. We also explore how to represent time-based events in still-images as network inputs; since many violent acts are described in terms of movement. We show that using more specific concepts is an intuitive and effective solution, besides being complementary to form a more robust definition of violence. When compared to other methods for violence detection, this approach holds better classification quality while using only automatic features.",
      "intriguing_abstract": "Detecting violence in videos through automatic means is significant for law enforcement and analysis of surveillance cameras with the intent of maintaining public safety. Moreover, it may be a great tool for protecting children from accessing inappropriate content and help parents make a better informed decision about what their kids should watch. However, this is a challenging problem since the very definition of violence is broad and highly subjective. Hence, detecting such nuances from videos with no human supervision is not only technical, but also a conceptual problem. With this in mind, we explore how to better describe the idea of violence for a convolutional neural network by breaking it into more objective and concrete parts. Initially, our method uses independent networks to learn features for more specific concepts related to violence, such as fights, explosions, blood, etc. Then we use these features to classify each concept and later fuse them in a meta-classification to describe violence. We also explore how to represent time-based events in still-images as network inputs; since many violent acts are described in terms of movement. We show that using more specific concepts is an intuitive and effective solution, besides being complementary to form a more robust definition of violence. When compared to other methods for violence detection, this approach holds better classification quality while using only automatic features.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/ecf89ea7a615c8442c3dca737482235a57223d37.pdf",
      "citation_key": "peixoto20180pd",
      "metadata": {
        "title": "Breaking down violence: A deep-learning strategy to model and classify violence in videos",
        "authors": [
          "B. Peixoto",
          "S. Avila",
          "Zanoni Dias",
          "A. Rocha"
        ],
        "published_date": "2018",
        "abstract": "Detecting violence in videos through automatic means is significant for law enforcement and analysis of surveillance cameras with the intent of maintaining public safety. Moreover, it may be a great tool for protecting children from accessing inappropriate content and help parents make a better informed decision about what their kids should watch. However, this is a challenging problem since the very definition of violence is broad and highly subjective. Hence, detecting such nuances from videos with no human supervision is not only technical, but also a conceptual problem. With this in mind, we explore how to better describe the idea of violence for a convolutional neural network by breaking it into more objective and concrete parts. Initially, our method uses independent networks to learn features for more specific concepts related to violence, such as fights, explosions, blood, etc. Then we use these features to classify each concept and later fuse them in a meta-classification to describe violence. We also explore how to represent time-based events in still-images as network inputs; since many violent acts are described in terms of movement. We show that using more specific concepts is an intuitive and effective solution, besides being complementary to form a more robust definition of violence. When compared to other methods for violence detection, this approach holds better classification quality while using only automatic features.",
        "file_path": "paper_data/Deep_Meta-Learning/info/ecf89ea7a615c8442c3dca737482235a57223d37.pdf",
        "venue": "ARES",
        "citationCount": 20,
        "score": 2.8571428571428568,
        "summary": "Detecting violence in videos through automatic means is significant for law enforcement and analysis of surveillance cameras with the intent of maintaining public safety. Moreover, it may be a great tool for protecting children from accessing inappropriate content and help parents make a better informed decision about what their kids should watch. However, this is a challenging problem since the very definition of violence is broad and highly subjective. Hence, detecting such nuances from videos with no human supervision is not only technical, but also a conceptual problem. With this in mind, we explore how to better describe the idea of violence for a convolutional neural network by breaking it into more objective and concrete parts. Initially, our method uses independent networks to learn features for more specific concepts related to violence, such as fights, explosions, blood, etc. Then we use these features to classify each concept and later fuse them in a meta-classification to describe violence. We also explore how to represent time-based events in still-images as network inputs; since many violent acts are described in terms of movement. We show that using more specific concepts is an intuitive and effective solution, besides being complementary to form a more robust definition of violence. When compared to other methods for violence detection, this approach holds better classification quality while using only automatic features.",
        "keywords": []
      },
      "file_name": "ecf89ea7a615c8442c3dca737482235a57223d37.pdf"
    },
    {
      "success": true,
      "doc_id": "3483ddbabf7b48e84ee74e16207848d7",
      "summary": "Deep Neural Networks (or DNNs) must constantly cope with distribution changes in the input data when the task of interest or the data collection protocol changes. Retraining a network from scratch to combat this issue poses a significant cost. Meta-learning aims to deliver an adaptive model that is sensitive to these underlying distribution changes, but requires many tasks during the meta-training process. In this paper, we propose a tAsk-auGmented actIve meta-LEarning (AGILE) method to efficiently adapt DNNs to new tasks by using a small number of training examples. AGILE combines a meta-learning algorithm with a novel task augmentation technique which we use to generate an initial adaptive model. It then uses Bayesian dropout uncertainty estimates to actively select the most difficult samples when updating the model to a new task. This allows AGILE to learn with fewer tasks and a few informative samples, achieving high performance with a limited dataset. We perform our experiments using the brain cell classification task and compare the results to a plain meta-learning model trained from scratch. We show that the proposed task-augmented meta-learning framework can learn to classify new cell types after a single gradient step with a limited number of training samples. We show that active learning with Bayesian uncertainty can further improve the performance when the number of training samples is extremely small. Using only 1% of the training data and a single update step, we achieved 90% accuracy on the new cell type classification task, a 50% points improvement over a state-of-the-art meta-learning algorithm.",
      "intriguing_abstract": "Deep Neural Networks (or DNNs) must constantly cope with distribution changes in the input data when the task of interest or the data collection protocol changes. Retraining a network from scratch to combat this issue poses a significant cost. Meta-learning aims to deliver an adaptive model that is sensitive to these underlying distribution changes, but requires many tasks during the meta-training process. In this paper, we propose a tAsk-auGmented actIve meta-LEarning (AGILE) method to efficiently adapt DNNs to new tasks by using a small number of training examples. AGILE combines a meta-learning algorithm with a novel task augmentation technique which we use to generate an initial adaptive model. It then uses Bayesian dropout uncertainty estimates to actively select the most difficult samples when updating the model to a new task. This allows AGILE to learn with fewer tasks and a few informative samples, achieving high performance with a limited dataset. We perform our experiments using the brain cell classification task and compare the results to a plain meta-learning model trained from scratch. We show that the proposed task-augmented meta-learning framework can learn to classify new cell types after a single gradient step with a limited number of training samples. We show that active learning with Bayesian uncertainty can further improve the performance when the number of training samples is extremely small. Using only 1% of the training data and a single update step, we achieved 90% accuracy on the new cell type classification task, a 50% points improvement over a state-of-the-art meta-learning algorithm.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/a8286ccd3dd83d1bd97582daa09d8db94724d799.pdf",
      "citation_key": "yuan20205j8",
      "metadata": {
        "title": "Few Is Enough: Task-Augmented Active Meta-Learning for Brain Cell Classification",
        "authors": [
          "Pengyu Yuan",
          "Aryan Mobiny",
          "J. Jahanipour",
          "Xiaoyang Li",
          "P. Cicalese",
          "B. Roysam",
          "Vishal M. Patel",
          "Maric Dragan",
          "H. Nguyen"
        ],
        "published_date": "2020",
        "abstract": "Deep Neural Networks (or DNNs) must constantly cope with distribution changes in the input data when the task of interest or the data collection protocol changes. Retraining a network from scratch to combat this issue poses a significant cost. Meta-learning aims to deliver an adaptive model that is sensitive to these underlying distribution changes, but requires many tasks during the meta-training process. In this paper, we propose a tAsk-auGmented actIve meta-LEarning (AGILE) method to efficiently adapt DNNs to new tasks by using a small number of training examples. AGILE combines a meta-learning algorithm with a novel task augmentation technique which we use to generate an initial adaptive model. It then uses Bayesian dropout uncertainty estimates to actively select the most difficult samples when updating the model to a new task. This allows AGILE to learn with fewer tasks and a few informative samples, achieving high performance with a limited dataset. We perform our experiments using the brain cell classification task and compare the results to a plain meta-learning model trained from scratch. We show that the proposed task-augmented meta-learning framework can learn to classify new cell types after a single gradient step with a limited number of training samples. We show that active learning with Bayesian uncertainty can further improve the performance when the number of training samples is extremely small. Using only 1% of the training data and a single update step, we achieved 90% accuracy on the new cell type classification task, a 50% points improvement over a state-of-the-art meta-learning algorithm.",
        "file_path": "paper_data/Deep_Meta-Learning/info/a8286ccd3dd83d1bd97582daa09d8db94724d799.pdf",
        "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
        "citationCount": 14,
        "score": 2.8000000000000003,
        "summary": "Deep Neural Networks (or DNNs) must constantly cope with distribution changes in the input data when the task of interest or the data collection protocol changes. Retraining a network from scratch to combat this issue poses a significant cost. Meta-learning aims to deliver an adaptive model that is sensitive to these underlying distribution changes, but requires many tasks during the meta-training process. In this paper, we propose a tAsk-auGmented actIve meta-LEarning (AGILE) method to efficiently adapt DNNs to new tasks by using a small number of training examples. AGILE combines a meta-learning algorithm with a novel task augmentation technique which we use to generate an initial adaptive model. It then uses Bayesian dropout uncertainty estimates to actively select the most difficult samples when updating the model to a new task. This allows AGILE to learn with fewer tasks and a few informative samples, achieving high performance with a limited dataset. We perform our experiments using the brain cell classification task and compare the results to a plain meta-learning model trained from scratch. We show that the proposed task-augmented meta-learning framework can learn to classify new cell types after a single gradient step with a limited number of training samples. We show that active learning with Bayesian uncertainty can further improve the performance when the number of training samples is extremely small. Using only 1% of the training data and a single update step, we achieved 90% accuracy on the new cell type classification task, a 50% points improvement over a state-of-the-art meta-learning algorithm.",
        "keywords": []
      },
      "file_name": "a8286ccd3dd83d1bd97582daa09d8db94724d799.pdf"
    },
    {
      "success": true,
      "doc_id": "fca6769e50087b1b09636ae59305cddb",
      "summary": "Deep learning technologies have been widely exploited to predict mobile traffic. However, individually training deep learning models for various traffic prediction tasks is not only time consuming but also unrealistic, sometimes due to limited traffic records. In this article, we propose a novel deep meta-learning based mobile traffic prediction framework, namely, dmTP, which can adaptively learn to learn the proper prediction model for each distinct prediction task from accumulated meta-knowledge of previously learned prediction tasks. In dmTP, we regard each mobile traffic prediction task as a base-task and adopt an LSTM network with a fixed structure as the base-learner for each base-task. In order to improve the base-learner's prediction accuracy and learning efficiency, we further employ an MLP as the meta-learner to find the optimal hyper-parameter value and initial training status for the base-learner of a new base-task according to its meta-features. Extensive experiments with real-world datasets demonstrate that while guaranteeing a similar or even better prediction accuracy, meta-learning in the proposed dmTP reduces the numbers of epochs and base-samples needed to train the base-learners by around 75 percent and 81 percent, respectively, as compared with the existing prediction models.",
      "intriguing_abstract": "Deep learning technologies have been widely exploited to predict mobile traffic. However, individually training deep learning models for various traffic prediction tasks is not only time consuming but also unrealistic, sometimes due to limited traffic records. In this article, we propose a novel deep meta-learning based mobile traffic prediction framework, namely, dmTP, which can adaptively learn to learn the proper prediction model for each distinct prediction task from accumulated meta-knowledge of previously learned prediction tasks. In dmTP, we regard each mobile traffic prediction task as a base-task and adopt an LSTM network with a fixed structure as the base-learner for each base-task. In order to improve the base-learner's prediction accuracy and learning efficiency, we further employ an MLP as the meta-learner to find the optimal hyper-parameter value and initial training status for the base-learner of a new base-task according to its meta-features. Extensive experiments with real-world datasets demonstrate that while guaranteeing a similar or even better prediction accuracy, meta-learning in the proposed dmTP reduces the numbers of epochs and base-samples needed to train the base-learners by around 75 percent and 81 percent, respectively, as compared with the existing prediction models.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/741c64927fb615689ca08235c67ff0c3a5cb25ec.pdf",
      "citation_key": "zhang2021yox",
      "metadata": {
        "title": "dmTP: A Deep Meta-Learning Based Framework for Mobile Traffic Prediction",
        "authors": [
          "Zitian Zhang",
          "Fuyou Li",
          "Xiaoli Chu",
          "Yuguang Fang",
          "J. Zhang"
        ],
        "published_date": "2021",
        "abstract": "Deep learning technologies have been widely exploited to predict mobile traffic. However, individually training deep learning models for various traffic prediction tasks is not only time consuming but also unrealistic, sometimes due to limited traffic records. In this article, we propose a novel deep meta-learning based mobile traffic prediction framework, namely, dmTP, which can adaptively learn to learn the proper prediction model for each distinct prediction task from accumulated meta-knowledge of previously learned prediction tasks. In dmTP, we regard each mobile traffic prediction task as a base-task and adopt an LSTM network with a fixed structure as the base-learner for each base-task. In order to improve the base-learner's prediction accuracy and learning efficiency, we further employ an MLP as the meta-learner to find the optimal hyper-parameter value and initial training status for the base-learner of a new base-task according to its meta-features. Extensive experiments with real-world datasets demonstrate that while guaranteeing a similar or even better prediction accuracy, meta-learning in the proposed dmTP reduces the numbers of epochs and base-samples needed to train the base-learners by around 75 percent and 81 percent, respectively, as compared with the existing prediction models.",
        "file_path": "paper_data/Deep_Meta-Learning/info/741c64927fb615689ca08235c67ff0c3a5cb25ec.pdf",
        "venue": "IEEE wireless communications",
        "citationCount": 11,
        "score": 2.75,
        "summary": "Deep learning technologies have been widely exploited to predict mobile traffic. However, individually training deep learning models for various traffic prediction tasks is not only time consuming but also unrealistic, sometimes due to limited traffic records. In this article, we propose a novel deep meta-learning based mobile traffic prediction framework, namely, dmTP, which can adaptively learn to learn the proper prediction model for each distinct prediction task from accumulated meta-knowledge of previously learned prediction tasks. In dmTP, we regard each mobile traffic prediction task as a base-task and adopt an LSTM network with a fixed structure as the base-learner for each base-task. In order to improve the base-learner's prediction accuracy and learning efficiency, we further employ an MLP as the meta-learner to find the optimal hyper-parameter value and initial training status for the base-learner of a new base-task according to its meta-features. Extensive experiments with real-world datasets demonstrate that while guaranteeing a similar or even better prediction accuracy, meta-learning in the proposed dmTP reduces the numbers of epochs and base-samples needed to train the base-learners by around 75 percent and 81 percent, respectively, as compared with the existing prediction models.",
        "keywords": []
      },
      "file_name": "741c64927fb615689ca08235c67ff0c3a5cb25ec.pdf"
    },
    {
      "success": true,
      "doc_id": "9b8edd0b8d87894d6a54a9ef616ddbb4",
      "summary": "How deep neural networks (DNNs) learn from noisy labels has been studied extensively in image classification but much less in image segmentation. So far, our understanding of the learning behavior of DNNs trained by noisy segmentation labels remains limited. In this study, we address this deficiency in both binary segmentation of biological microscopy images and multi-class segmentation of natural images. We generate extremely noisy labels by randomly sampling a small fraction (e.g., 10%) or flipping a large fraction (e.g., 90%) of the ground truth labels. When trained with these noisy labels, DNNs provide largely the same segmentation performance as trained by the original ground truth. This indicates that DNNs learn structures hidden in labels rather than pixel-level labels per se in their supervised training for semantic segmentation. We refer to these hidden structures in labels as meta-structures. When DNNs are trained by labels with different perturbations to the meta-structure, we find consistent degradation in their segmentation performance. In contrast, incorporation of meta-structure information substantially improves performance of an unsupervised segmentation model developed for binary semantic segmentation. We define meta-structures mathematically as spatial density distributions and show both theoretically and experimentally how this formulation explains key observed learning behavior of DNNs.",
      "intriguing_abstract": "How deep neural networks (DNNs) learn from noisy labels has been studied extensively in image classification but much less in image segmentation. So far, our understanding of the learning behavior of DNNs trained by noisy segmentation labels remains limited. In this study, we address this deficiency in both binary segmentation of biological microscopy images and multi-class segmentation of natural images. We generate extremely noisy labels by randomly sampling a small fraction (e.g., 10%) or flipping a large fraction (e.g., 90%) of the ground truth labels. When trained with these noisy labels, DNNs provide largely the same segmentation performance as trained by the original ground truth. This indicates that DNNs learn structures hidden in labels rather than pixel-level labels per se in their supervised training for semantic segmentation. We refer to these hidden structures in labels as meta-structures. When DNNs are trained by labels with different perturbations to the meta-structure, we find consistent degradation in their segmentation performance. In contrast, incorporation of meta-structure information substantially improves performance of an unsupervised segmentation model developed for binary semantic segmentation. We define meta-structures mathematically as spatial density distributions and show both theoretically and experimentally how this formulation explains key observed learning behavior of DNNs.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/83565158dc845dc75024db60e5be6bcc25eb0257.pdf",
      "citation_key": "luo202123f",
      "metadata": {
        "title": "Deep Neural Networks Learn Meta-Structures from Noisy Labels in Semantic Segmentation",
        "authors": [
          "Yaoru Luo",
          "Guole Liu",
          "Yuanhao Guo",
          "Ge Yang"
        ],
        "published_date": "2021",
        "abstract": "How deep neural networks (DNNs) learn from noisy labels has been studied extensively in image classification but much less in image segmentation. So far, our understanding of the learning behavior of DNNs trained by noisy segmentation labels remains limited. In this study, we address this deficiency in both binary segmentation of biological microscopy images and multi-class segmentation of natural images. We generate extremely noisy labels by randomly sampling a small fraction (e.g., 10%) or flipping a large fraction (e.g., 90%) of the ground truth labels. When trained with these noisy labels, DNNs provide largely the same segmentation performance as trained by the original ground truth. This indicates that DNNs learn structures hidden in labels rather than pixel-level labels per se in their supervised training for semantic segmentation. We refer to these hidden structures in labels as meta-structures. When DNNs are trained by labels with different perturbations to the meta-structure, we find consistent degradation in their segmentation performance. In contrast, incorporation of meta-structure information substantially improves performance of an unsupervised segmentation model developed for binary semantic segmentation. We define meta-structures mathematically as spatial density distributions and show both theoretically and experimentally how this formulation explains key observed learning behavior of DNNs.",
        "file_path": "paper_data/Deep_Meta-Learning/info/83565158dc845dc75024db60e5be6bcc25eb0257.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 11,
        "score": 2.75,
        "summary": "How deep neural networks (DNNs) learn from noisy labels has been studied extensively in image classification but much less in image segmentation. So far, our understanding of the learning behavior of DNNs trained by noisy segmentation labels remains limited. In this study, we address this deficiency in both binary segmentation of biological microscopy images and multi-class segmentation of natural images. We generate extremely noisy labels by randomly sampling a small fraction (e.g., 10%) or flipping a large fraction (e.g., 90%) of the ground truth labels. When trained with these noisy labels, DNNs provide largely the same segmentation performance as trained by the original ground truth. This indicates that DNNs learn structures hidden in labels rather than pixel-level labels per se in their supervised training for semantic segmentation. We refer to these hidden structures in labels as meta-structures. When DNNs are trained by labels with different perturbations to the meta-structure, we find consistent degradation in their segmentation performance. In contrast, incorporation of meta-structure information substantially improves performance of an unsupervised segmentation model developed for binary semantic segmentation. We define meta-structures mathematically as spatial density distributions and show both theoretically and experimentally how this formulation explains key observed learning behavior of DNNs.",
        "keywords": []
      },
      "file_name": "83565158dc845dc75024db60e5be6bcc25eb0257.pdf"
    },
    {
      "success": true,
      "doc_id": "c13a23ee01922a6f51d228104620655d",
      "summary": "Generally, deep networks learn to recognize a category of objects by training on a large number of annotated images accurately. However, a meta-learning problem known as a low-shot image recognition task occurs when a few images with annotations are available for learning a recognition model for a single category. Consequently, the objects in testing/query and training/support image datasets are likely to vary in terms of size, location, style, and so on. In this paper, we propose a method, cascaded feature matching network (CFMN), to solve this problem. We train the meta-learner to learn a more fine-grained and adaptive deep distance metric using feature matching block, which aligns associated features together and naturally ignores non-discriminative features. By applying the proposed feature matching block in different layers of the network, multi-scale information among the compared images is incorporated into the final cascaded matching feature, which boosts the recognition performance and generalizes better by learning on relationships. Moreover, the experiments for few-shot learning (FSL) using two standard datasets: miniImageNet and Omniglot, confirm the effectiveness of our proposed method. Besides, the multi-label few-shot task is first studied on a new data split of the COCO dataset, which further shows the superiority of the proposed feature matching network when performing the FSL in complex images.",
      "intriguing_abstract": "Generally, deep networks learn to recognize a category of objects by training on a large number of annotated images accurately. However, a meta-learning problem known as a low-shot image recognition task occurs when a few images with annotations are available for learning a recognition model for a single category. Consequently, the objects in testing/query and training/support image datasets are likely to vary in terms of size, location, style, and so on. In this paper, we propose a method, cascaded feature matching network (CFMN), to solve this problem. We train the meta-learner to learn a more fine-grained and adaptive deep distance metric using feature matching block, which aligns associated features together and naturally ignores non-discriminative features. By applying the proposed feature matching block in different layers of the network, multi-scale information among the compared images is incorporated into the final cascaded matching feature, which boosts the recognition performance and generalizes better by learning on relationships. Moreover, the experiments for few-shot learning (FSL) using two standard datasets: miniImageNet and Omniglot, confirm the effectiveness of our proposed method. Besides, the multi-label few-shot task is first studied on a new data split of the COCO dataset, which further shows the superiority of the proposed feature matching network when performing the FSL in complex images.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d91ce56b1905e22bde9fccfed8abdeb751537b38.pdf",
      "citation_key": "chen2021yqh",
      "metadata": {
        "title": "Learning to focus: cascaded feature matching network for few-shot image recognition",
        "authors": [
          "Mengting Chen",
          "Xinggang Wang",
          "Heng Luo",
          "Yifeng Geng",
          "Wenyu Liu"
        ],
        "published_date": "2021",
        "abstract": "Generally, deep networks learn to recognize a category of objects by training on a large number of annotated images accurately. However, a meta-learning problem known as a low-shot image recognition task occurs when a few images with annotations are available for learning a recognition model for a single category. Consequently, the objects in testing/query and training/support image datasets are likely to vary in terms of size, location, style, and so on. In this paper, we propose a method, cascaded feature matching network (CFMN), to solve this problem. We train the meta-learner to learn a more fine-grained and adaptive deep distance metric using feature matching block, which aligns associated features together and naturally ignores non-discriminative features. By applying the proposed feature matching block in different layers of the network, multi-scale information among the compared images is incorporated into the final cascaded matching feature, which boosts the recognition performance and generalizes better by learning on relationships. Moreover, the experiments for few-shot learning (FSL) using two standard datasets: miniImageNet and Omniglot, confirm the effectiveness of our proposed method. Besides, the multi-label few-shot task is first studied on a new data split of the COCO dataset, which further shows the superiority of the proposed feature matching network when performing the FSL in complex images.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d91ce56b1905e22bde9fccfed8abdeb751537b38.pdf",
        "venue": "Science China Information Sciences",
        "citationCount": 11,
        "score": 2.75,
        "summary": "Generally, deep networks learn to recognize a category of objects by training on a large number of annotated images accurately. However, a meta-learning problem known as a low-shot image recognition task occurs when a few images with annotations are available for learning a recognition model for a single category. Consequently, the objects in testing/query and training/support image datasets are likely to vary in terms of size, location, style, and so on. In this paper, we propose a method, cascaded feature matching network (CFMN), to solve this problem. We train the meta-learner to learn a more fine-grained and adaptive deep distance metric using feature matching block, which aligns associated features together and naturally ignores non-discriminative features. By applying the proposed feature matching block in different layers of the network, multi-scale information among the compared images is incorporated into the final cascaded matching feature, which boosts the recognition performance and generalizes better by learning on relationships. Moreover, the experiments for few-shot learning (FSL) using two standard datasets: miniImageNet and Omniglot, confirm the effectiveness of our proposed method. Besides, the multi-label few-shot task is first studied on a new data split of the COCO dataset, which further shows the superiority of the proposed feature matching network when performing the FSL in complex images.",
        "keywords": []
      },
      "file_name": "d91ce56b1905e22bde9fccfed8abdeb751537b38.pdf"
    },
    {
      "success": true,
      "doc_id": "e7cdd7f89484ed6e781024ec144209e8",
      "summary": "Personal robots and driverless cars need to be able to operate in novel environments and thus quickly and efficiently learn to recognise new object classes. We address this problem by considering the task of video object segmentation. Previous accurate methods for this task finetune a model using the first annotated frame, and/or use additional inputs such as optical flow and complex post-processing. In contrast, we develop a fast, causal algorithm that requires no finetuning, auxiliary inputs or post-processing, and segments a variable number of objects in a single forward-pass. We represent an object with clusters, or \"visual words\", in the embedding space, which correspond to object parts in the image space. This allows us to robustly match to the reference objects throughout the video, because although the global appearance of an object changes as it undergoes occlusions and deformations, the appearance of more local parts may stay consistent. We learn these visual words in an unsupervised manner, using meta-learning to ensure that our training objective matches our inference procedure. We achieve comparable accuracy to finetuning based methods (whilst being 1 to 2 orders of magnitude faster), and state-of-the-art in terms of speed/accuracy trade-offs on four video segmentation datasets. Code is available at https://github.com/harkiratbehl/MetaVOS.",
      "intriguing_abstract": "Personal robots and driverless cars need to be able to operate in novel environments and thus quickly and efficiently learn to recognise new object classes. We address this problem by considering the task of video object segmentation. Previous accurate methods for this task finetune a model using the first annotated frame, and/or use additional inputs such as optical flow and complex post-processing. In contrast, we develop a fast, causal algorithm that requires no finetuning, auxiliary inputs or post-processing, and segments a variable number of objects in a single forward-pass. We represent an object with clusters, or \"visual words\", in the embedding space, which correspond to object parts in the image space. This allows us to robustly match to the reference objects throughout the video, because although the global appearance of an object changes as it undergoes occlusions and deformations, the appearance of more local parts may stay consistent. We learn these visual words in an unsupervised manner, using meta-learning to ensure that our training objective matches our inference procedure. We achieve comparable accuracy to finetuning based methods (whilst being 1 to 2 orders of magnitude faster), and state-of-the-art in terms of speed/accuracy trade-offs on four video segmentation datasets. Code is available at https://github.com/harkiratbehl/MetaVOS.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b1b9bd8d6bc72132f092cb465cc31c19c3a9b589.pdf",
      "citation_key": "behl2018rjm",
      "metadata": {
        "title": "Meta-Learning Deep Visual Words for Fast Video Object Segmentation",
        "authors": [
          "Harkirat Singh Behl",
          "M. Najafi",
          "Philip H. S. Torr"
        ],
        "published_date": "2018",
        "abstract": "Personal robots and driverless cars need to be able to operate in novel environments and thus quickly and efficiently learn to recognise new object classes. We address this problem by considering the task of video object segmentation. Previous accurate methods for this task finetune a model using the first annotated frame, and/or use additional inputs such as optical flow and complex post-processing. In contrast, we develop a fast, causal algorithm that requires no finetuning, auxiliary inputs or post-processing, and segments a variable number of objects in a single forward-pass. We represent an object with clusters, or \"visual words\", in the embedding space, which correspond to object parts in the image space. This allows us to robustly match to the reference objects throughout the video, because although the global appearance of an object changes as it undergoes occlusions and deformations, the appearance of more local parts may stay consistent. We learn these visual words in an unsupervised manner, using meta-learning to ensure that our training objective matches our inference procedure. We achieve comparable accuracy to finetuning based methods (whilst being 1 to 2 orders of magnitude faster), and state-of-the-art in terms of speed/accuracy trade-offs on four video segmentation datasets. Code is available at https://github.com/harkiratbehl/MetaVOS.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b1b9bd8d6bc72132f092cb465cc31c19c3a9b589.pdf",
        "venue": "IEEE/RJS International Conference on Intelligent RObots and Systems",
        "citationCount": 19,
        "score": 2.714285714285714,
        "summary": "Personal robots and driverless cars need to be able to operate in novel environments and thus quickly and efficiently learn to recognise new object classes. We address this problem by considering the task of video object segmentation. Previous accurate methods for this task finetune a model using the first annotated frame, and/or use additional inputs such as optical flow and complex post-processing. In contrast, we develop a fast, causal algorithm that requires no finetuning, auxiliary inputs or post-processing, and segments a variable number of objects in a single forward-pass. We represent an object with clusters, or \"visual words\", in the embedding space, which correspond to object parts in the image space. This allows us to robustly match to the reference objects throughout the video, because although the global appearance of an object changes as it undergoes occlusions and deformations, the appearance of more local parts may stay consistent. We learn these visual words in an unsupervised manner, using meta-learning to ensure that our training objective matches our inference procedure. We achieve comparable accuracy to finetuning based methods (whilst being 1 to 2 orders of magnitude faster), and state-of-the-art in terms of speed/accuracy trade-offs on four video segmentation datasets. Code is available at https://github.com/harkiratbehl/MetaVOS.",
        "keywords": []
      },
      "file_name": "b1b9bd8d6bc72132f092cb465cc31c19c3a9b589.pdf"
    },
    {
      "success": true,
      "doc_id": "d966974d86d811c75d427e53cc0b51a3",
      "summary": "In recent years, deep reinforcement learning methods have achieved impressive performance in many different fields, including playing games, robotics, and dialogue systems. However, there are still a lot of restrictions here, one of which is the demand for massive amounts of sampled data. In this paper, a hierarchical meta-learning method based on the actor-critic algorithm is proposed for sample efficient learning. This method provides the transferable knowledge that can efficiently train an actor on a new task with a few trials. Specifically, a global basic critic, meta critic, and task specified network are shared within a distribution of tasks and are capable of criticizing any actor trying to solve any specified task. The hierarchical framework is applied to a critic network in the actor-critic algorithm for distilling meta-knowledge above the task level and addressing distinct tasks. The proposed method is evaluated on multiple classic control tasks with reinforcement learning algorithms, including the start-of-the-art meta-learning methods. The experimental results statistically demonstrate that the proposed method achieves state-of-the-art performance and attains better results with more depth of meta critic network.",
      "intriguing_abstract": "In recent years, deep reinforcement learning methods have achieved impressive performance in many different fields, including playing games, robotics, and dialogue systems. However, there are still a lot of restrictions here, one of which is the demand for massive amounts of sampled data. In this paper, a hierarchical meta-learning method based on the actor-critic algorithm is proposed for sample efficient learning. This method provides the transferable knowledge that can efficiently train an actor on a new task with a few trials. Specifically, a global basic critic, meta critic, and task specified network are shared within a distribution of tasks and are capable of criticizing any actor trying to solve any specified task. The hierarchical framework is applied to a critic network in the actor-critic algorithm for distilling meta-knowledge above the task level and addressing distinct tasks. The proposed method is evaluated on multiple classic control tasks with reinforcement learning algorithms, including the start-of-the-art meta-learning methods. The experimental results statistically demonstrate that the proposed method achieves state-of-the-art performance and attains better results with more depth of meta critic network.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/98b41528c58e6f5b7b28be5b54029e52ca90c4ab.pdf",
      "citation_key": "xu2019brv",
      "metadata": {
        "title": "Learning to Learn: Hierarchical Meta-Critic Networks",
        "authors": [
          "Zhixiong Xu",
          "Lei Cao",
          "Xi-liang Chen"
        ],
        "published_date": "2019",
        "abstract": "In recent years, deep reinforcement learning methods have achieved impressive performance in many different fields, including playing games, robotics, and dialogue systems. However, there are still a lot of restrictions here, one of which is the demand for massive amounts of sampled data. In this paper, a hierarchical meta-learning method based on the actor-critic algorithm is proposed for sample efficient learning. This method provides the transferable knowledge that can efficiently train an actor on a new task with a few trials. Specifically, a global basic critic, meta critic, and task specified network are shared within a distribution of tasks and are capable of criticizing any actor trying to solve any specified task. The hierarchical framework is applied to a critic network in the actor-critic algorithm for distilling meta-knowledge above the task level and addressing distinct tasks. The proposed method is evaluated on multiple classic control tasks with reinforcement learning algorithms, including the start-of-the-art meta-learning methods. The experimental results statistically demonstrate that the proposed method achieves state-of-the-art performance and attains better results with more depth of meta critic network.",
        "file_path": "paper_data/Deep_Meta-Learning/info/98b41528c58e6f5b7b28be5b54029e52ca90c4ab.pdf",
        "venue": "IEEE Access",
        "citationCount": 16,
        "score": 2.6666666666666665,
        "summary": "In recent years, deep reinforcement learning methods have achieved impressive performance in many different fields, including playing games, robotics, and dialogue systems. However, there are still a lot of restrictions here, one of which is the demand for massive amounts of sampled data. In this paper, a hierarchical meta-learning method based on the actor-critic algorithm is proposed for sample efficient learning. This method provides the transferable knowledge that can efficiently train an actor on a new task with a few trials. Specifically, a global basic critic, meta critic, and task specified network are shared within a distribution of tasks and are capable of criticizing any actor trying to solve any specified task. The hierarchical framework is applied to a critic network in the actor-critic algorithm for distilling meta-knowledge above the task level and addressing distinct tasks. The proposed method is evaluated on multiple classic control tasks with reinforcement learning algorithms, including the start-of-the-art meta-learning methods. The experimental results statistically demonstrate that the proposed method achieves state-of-the-art performance and attains better results with more depth of meta critic network.",
        "keywords": []
      },
      "file_name": "98b41528c58e6f5b7b28be5b54029e52ca90c4ab.pdf"
    },
    {
      "success": true,
      "doc_id": "8f9f43ca39e4616ca1e1ae47c1bf1eec",
      "summary": "The Travelling Salesman Problem (TSP) is a classical combinatorial optimisation problem. Deep learning has been successfully extended to meta-learning, where previous solving efforts assist in learning how to optimise future optimisation instances. In recent years, learning to optimise approaches have shown success in solving TSP problems. However, they focus on one type of TSP problem, namely ones where the points are uniformly distributed in Euclidean spaces and have issues in generalising to other embedding spaces, e.g., spherical distance spaces, and to TSP instances where the points are distributed in a non-uniform manner. An aim of learning to optimise is to train once and solve across a broad spectrum of (TSP) problems. Although supervised learning approaches have shown to achieve more optimal solutions than unsupervised approaches, they do require the generation of training data and running a solver to obtain solutions to learn from, which can be time-consuming and difficult to find reasonable solutions for harder TSP instances. Hence this paper introduces a new learning-based approach to solve a variety of different and common TSP problems that are trained on easier instances which are faster to train and are easier to obtain better solutions. We name this approach the non-Euclidean TSP network (NETSP-Net). The approach is evaluated on various TSP instances using the benchmark TSPLIB dataset and popular instance generator used in the literature. We performed extensive experiments that indicate our approach generalises across many types of instances and scales to instances that are larger than what was used during training.",
      "intriguing_abstract": "The Travelling Salesman Problem (TSP) is a classical combinatorial optimisation problem. Deep learning has been successfully extended to meta-learning, where previous solving efforts assist in learning how to optimise future optimisation instances. In recent years, learning to optimise approaches have shown success in solving TSP problems. However, they focus on one type of TSP problem, namely ones where the points are uniformly distributed in Euclidean spaces and have issues in generalising to other embedding spaces, e.g., spherical distance spaces, and to TSP instances where the points are distributed in a non-uniform manner. An aim of learning to optimise is to train once and solve across a broad spectrum of (TSP) problems. Although supervised learning approaches have shown to achieve more optimal solutions than unsupervised approaches, they do require the generation of training data and running a solver to obtain solutions to learn from, which can be time-consuming and difficult to find reasonable solutions for harder TSP instances. Hence this paper introduces a new learning-based approach to solve a variety of different and common TSP problems that are trained on easier instances which are faster to train and are easier to obtain better solutions. We name this approach the non-Euclidean TSP network (NETSP-Net). The approach is evaluated on various TSP instances using the benchmark TSPLIB dataset and popular instance generator used in the literature. We performed extensive experiments that indicate our approach generalises across many types of instances and scales to instances that are larger than what was used during training.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3805c99f092f961f81538bea1d3727f552b72727.pdf",
      "citation_key": "sultana202094g",
      "metadata": {
        "title": "Learning to Optimise General TSP Instances",
        "authors": [
          "N. Sultana",
          "Jeffrey Chan",
          "A. K. Qin"
        ],
        "published_date": "2020",
        "abstract": "The Travelling Salesman Problem (TSP) is a classical combinatorial optimisation problem. Deep learning has been successfully extended to meta-learning, where previous solving efforts assist in learning how to optimise future optimisation instances. In recent years, learning to optimise approaches have shown success in solving TSP problems. However, they focus on one type of TSP problem, namely ones where the points are uniformly distributed in Euclidean spaces and have issues in generalising to other embedding spaces, e.g., spherical distance spaces, and to TSP instances where the points are distributed in a non-uniform manner. An aim of learning to optimise is to train once and solve across a broad spectrum of (TSP) problems. Although supervised learning approaches have shown to achieve more optimal solutions than unsupervised approaches, they do require the generation of training data and running a solver to obtain solutions to learn from, which can be time-consuming and difficult to find reasonable solutions for harder TSP instances. Hence this paper introduces a new learning-based approach to solve a variety of different and common TSP problems that are trained on easier instances which are faster to train and are easier to obtain better solutions. We name this approach the non-Euclidean TSP network (NETSP-Net). The approach is evaluated on various TSP instances using the benchmark TSPLIB dataset and popular instance generator used in the literature. We performed extensive experiments that indicate our approach generalises across many types of instances and scales to instances that are larger than what was used during training.",
        "file_path": "paper_data/Deep_Meta-Learning/info/3805c99f092f961f81538bea1d3727f552b72727.pdf",
        "venue": "arXiv.org",
        "citationCount": 13,
        "score": 2.6,
        "summary": "The Travelling Salesman Problem (TSP) is a classical combinatorial optimisation problem. Deep learning has been successfully extended to meta-learning, where previous solving efforts assist in learning how to optimise future optimisation instances. In recent years, learning to optimise approaches have shown success in solving TSP problems. However, they focus on one type of TSP problem, namely ones where the points are uniformly distributed in Euclidean spaces and have issues in generalising to other embedding spaces, e.g., spherical distance spaces, and to TSP instances where the points are distributed in a non-uniform manner. An aim of learning to optimise is to train once and solve across a broad spectrum of (TSP) problems. Although supervised learning approaches have shown to achieve more optimal solutions than unsupervised approaches, they do require the generation of training data and running a solver to obtain solutions to learn from, which can be time-consuming and difficult to find reasonable solutions for harder TSP instances. Hence this paper introduces a new learning-based approach to solve a variety of different and common TSP problems that are trained on easier instances which are faster to train and are easier to obtain better solutions. We name this approach the non-Euclidean TSP network (NETSP-Net). The approach is evaluated on various TSP instances using the benchmark TSPLIB dataset and popular instance generator used in the literature. We performed extensive experiments that indicate our approach generalises across many types of instances and scales to instances that are larger than what was used during training.",
        "keywords": []
      },
      "file_name": "3805c99f092f961f81538bea1d3727f552b72727.pdf"
    },
    {
      "success": true,
      "doc_id": "35d46f4779f2da7ce98afaf17665a11f",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3ffafa982182e5b3d41b89ad6627e3fd9865c7e8.pdf",
      "citation_key": "furfaro20197q6",
      "metadata": {
        "title": "Space Debris Identification and Characterization via Deep Meta-Learning",
        "authors": [
          "R. Furfaro",
          "T. Campbell",
          "R. Linares",
          "V. Reddy"
        ],
        "published_date": "2019",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/3ffafa982182e5b3d41b89ad6627e3fd9865c7e8.pdf",
        "venue": "",
        "citationCount": 15,
        "score": 2.5,
        "summary": "",
        "keywords": []
      },
      "file_name": "3ffafa982182e5b3d41b89ad6627e3fd9865c7e8.pdf"
    },
    {
      "success": true,
      "doc_id": "e4717c4d1632ed637098eae09462c813",
      "summary": "The question of how neurons embedded in a network update their synaptic weights to collectively achieve behavioral goals is a longstanding problem in systems neuroscience. Since Hebb’s hypothesis [10] that cells that fire together strengthen their connections, cellular studies [6] have shed light on potential synaptic mechanisms underlying learning. These mechanisms have directly driven the careful hand design of biologically plausible models of learning and memory in computational neuroscience [1]. However, these hand designed rules have yet to achieve satisfying success training large neural networks, and are dramatically outperformed by biologically implausible approaches such as backprop. We propose an alternative paradigm for designing biologically plausible learning rules: using meta-learning to learn a parametric synaptic update rule which is capable of training deep networks. We demonstrate this approach by meta-learning an update rule for semi-supervised tasks, where sparse labels are provided to a deep network but the majority of inputs are unlabeled. The meta-learned plasticity rule integrates bottom-up, top-down, and recurrent inputs to each neuron, and generates weight updates as the product of pre- and post- synaptic neuronal outputs. The way in which the inputs to each neuron are combined to produce a learning signal, however, is itself a meta-learned function, parameterized by a neural network. Critically, the meta-learned update rule integrates only neuron-local information when proposing updates–that is, our learning rule is spatially localized to individual neurons. After meta-learning, the resulting synaptic update rule is capable of driving task-relevant learning for semi-supervised tasks. We demonstrate this capability on two simple classification problems. In general, we believe meta-learning to be a powerful approach to finding more effective synaptic plasticity rules, which will motivate new hypotheses for biological neural networks, and new algorithms for artificial neural networks.",
      "intriguing_abstract": "The question of how neurons embedded in a network update their synaptic weights to collectively achieve behavioral goals is a longstanding problem in systems neuroscience. Since Hebb’s hypothesis [10] that cells that fire together strengthen their connections, cellular studies [6] have shed light on potential synaptic mechanisms underlying learning. These mechanisms have directly driven the careful hand design of biologically plausible models of learning and memory in computational neuroscience [1]. However, these hand designed rules have yet to achieve satisfying success training large neural networks, and are dramatically outperformed by biologically implausible approaches such as backprop. We propose an alternative paradigm for designing biologically plausible learning rules: using meta-learning to learn a parametric synaptic update rule which is capable of training deep networks. We demonstrate this approach by meta-learning an update rule for semi-supervised tasks, where sparse labels are provided to a deep network but the majority of inputs are unlabeled. The meta-learned plasticity rule integrates bottom-up, top-down, and recurrent inputs to each neuron, and generates weight updates as the product of pre- and post- synaptic neuronal outputs. The way in which the inputs to each neuron are combined to produce a learning signal, however, is itself a meta-learned function, parameterized by a neural network. Critically, the meta-learned update rule integrates only neuron-local information when proposing updates–that is, our learning rule is spatially localized to individual neurons. After meta-learning, the resulting synaptic update rule is capable of driving task-relevant learning for semi-supervised tasks. We demonstrate this capability on two simple classification problems. In general, we believe meta-learning to be a powerful approach to finding more effective synaptic plasticity rules, which will motivate new hypotheses for biological neural networks, and new algorithms for artificial neural networks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/47da3a722b007cef7238299a075c0595fed8632e.pdf",
      "citation_key": "gu2019tvc",
      "metadata": {
        "title": "Meta-Learning Biologically Plausible Semi-Supervised Update Rules",
        "authors": [
          "Keren Gu",
          "S. Greydanus",
          "Luke Metz",
          "Niru Maheswaranathan",
          "Jascha Narain Sohl-Dickstein"
        ],
        "published_date": "2019",
        "abstract": "The question of how neurons embedded in a network update their synaptic weights to collectively achieve behavioral goals is a longstanding problem in systems neuroscience. Since Hebb’s hypothesis [10] that cells that fire together strengthen their connections, cellular studies [6] have shed light on potential synaptic mechanisms underlying learning. These mechanisms have directly driven the careful hand design of biologically plausible models of learning and memory in computational neuroscience [1]. However, these hand designed rules have yet to achieve satisfying success training large neural networks, and are dramatically outperformed by biologically implausible approaches such as backprop. We propose an alternative paradigm for designing biologically plausible learning rules: using meta-learning to learn a parametric synaptic update rule which is capable of training deep networks. We demonstrate this approach by meta-learning an update rule for semi-supervised tasks, where sparse labels are provided to a deep network but the majority of inputs are unlabeled. The meta-learned plasticity rule integrates bottom-up, top-down, and recurrent inputs to each neuron, and generates weight updates as the product of pre- and post- synaptic neuronal outputs. The way in which the inputs to each neuron are combined to produce a learning signal, however, is itself a meta-learned function, parameterized by a neural network. Critically, the meta-learned update rule integrates only neuron-local information when proposing updates–that is, our learning rule is spatially localized to individual neurons. After meta-learning, the resulting synaptic update rule is capable of driving task-relevant learning for semi-supervised tasks. We demonstrate this capability on two simple classification problems. In general, we believe meta-learning to be a powerful approach to finding more effective synaptic plasticity rules, which will motivate new hypotheses for biological neural networks, and new algorithms for artificial neural networks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/47da3a722b007cef7238299a075c0595fed8632e.pdf",
        "venue": "bioRxiv",
        "citationCount": 15,
        "score": 2.5,
        "summary": "The question of how neurons embedded in a network update their synaptic weights to collectively achieve behavioral goals is a longstanding problem in systems neuroscience. Since Hebb’s hypothesis [10] that cells that fire together strengthen their connections, cellular studies [6] have shed light on potential synaptic mechanisms underlying learning. These mechanisms have directly driven the careful hand design of biologically plausible models of learning and memory in computational neuroscience [1]. However, these hand designed rules have yet to achieve satisfying success training large neural networks, and are dramatically outperformed by biologically implausible approaches such as backprop. We propose an alternative paradigm for designing biologically plausible learning rules: using meta-learning to learn a parametric synaptic update rule which is capable of training deep networks. We demonstrate this approach by meta-learning an update rule for semi-supervised tasks, where sparse labels are provided to a deep network but the majority of inputs are unlabeled. The meta-learned plasticity rule integrates bottom-up, top-down, and recurrent inputs to each neuron, and generates weight updates as the product of pre- and post- synaptic neuronal outputs. The way in which the inputs to each neuron are combined to produce a learning signal, however, is itself a meta-learned function, parameterized by a neural network. Critically, the meta-learned update rule integrates only neuron-local information when proposing updates–that is, our learning rule is spatially localized to individual neurons. After meta-learning, the resulting synaptic update rule is capable of driving task-relevant learning for semi-supervised tasks. We demonstrate this capability on two simple classification problems. In general, we believe meta-learning to be a powerful approach to finding more effective synaptic plasticity rules, which will motivate new hypotheses for biological neural networks, and new algorithms for artificial neural networks.",
        "keywords": []
      },
      "file_name": "47da3a722b007cef7238299a075c0595fed8632e.pdf"
    },
    {
      "success": true,
      "doc_id": "71c41fdf5eb35ca7327bf0069afb29b5",
      "summary": "The training of a deep face recognition system usually faces the interference of label noise in the training data. However, it is difficult to obtain a high-precision cleaning model to remove these noises. In this paper, we propose an adaptive label noise cleaning algorithm based on meta-learning for face recognition datasets, which can learn the distribution of the data to be cleaned and make automatic adjustments based on class differences. It first learns re-liable cleaning knowledge from well-labeled noisy data, then gradually transfers it to the target data with meta-supervision to improve performance. A threshold adapter module is also proposed to address the drift problem in transfer learning methods. Extensive experiments clean two noisy in-the-wild face recognition datasets and show the effectiveness of the proposed method to reach state-of-the-art performance on the IJB-C face recognition benchmark.",
      "intriguing_abstract": "The training of a deep face recognition system usually faces the interference of label noise in the training data. However, it is difficult to obtain a high-precision cleaning model to remove these noises. In this paper, we propose an adaptive label noise cleaning algorithm based on meta-learning for face recognition datasets, which can learn the distribution of the data to be cleaned and make automatic adjustments based on class differences. It first learns re-liable cleaning knowledge from well-labeled noisy data, then gradually transfers it to the target data with meta-supervision to improve performance. A threshold adapter module is also proposed to address the drift problem in transfer learning methods. Extensive experiments clean two noisy in-the-wild face recognition datasets and show the effectiveness of the proposed method to reach state-of-the-art performance on the IJB-C face recognition benchmark.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c67de8be8b033362e94d98dcefae88e4b75dd6c7.pdf",
      "citation_key": "zhang2021p9j",
      "metadata": {
        "title": "Adaptive Label Noise Cleaning with Meta-Supervision for Deep Face Recognition",
        "authors": [
          "Yaobin Zhang",
          "Weihong Deng",
          "Yaoyao Zhong",
          "Jiani Hu",
          "Dongchao Wen"
        ],
        "published_date": "2021",
        "abstract": "The training of a deep face recognition system usually faces the interference of label noise in the training data. However, it is difficult to obtain a high-precision cleaning model to remove these noises. In this paper, we propose an adaptive label noise cleaning algorithm based on meta-learning for face recognition datasets, which can learn the distribution of the data to be cleaned and make automatic adjustments based on class differences. It first learns re-liable cleaning knowledge from well-labeled noisy data, then gradually transfers it to the target data with meta-supervision to improve performance. A threshold adapter module is also proposed to address the drift problem in transfer learning methods. Extensive experiments clean two noisy in-the-wild face recognition datasets and show the effectiveness of the proposed method to reach state-of-the-art performance on the IJB-C face recognition benchmark.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c67de8be8b033362e94d98dcefae88e4b75dd6c7.pdf",
        "venue": "IEEE International Conference on Computer Vision",
        "citationCount": 10,
        "score": 2.5,
        "summary": "The training of a deep face recognition system usually faces the interference of label noise in the training data. However, it is difficult to obtain a high-precision cleaning model to remove these noises. In this paper, we propose an adaptive label noise cleaning algorithm based on meta-learning for face recognition datasets, which can learn the distribution of the data to be cleaned and make automatic adjustments based on class differences. It first learns re-liable cleaning knowledge from well-labeled noisy data, then gradually transfers it to the target data with meta-supervision to improve performance. A threshold adapter module is also proposed to address the drift problem in transfer learning methods. Extensive experiments clean two noisy in-the-wild face recognition datasets and show the effectiveness of the proposed method to reach state-of-the-art performance on the IJB-C face recognition benchmark.",
        "keywords": []
      },
      "file_name": "c67de8be8b033362e94d98dcefae88e4b75dd6c7.pdf"
    },
    {
      "success": true,
      "doc_id": "abbb63130b9e0a66c9747501b2ad9be2",
      "summary": "Both complex and evolving nature of time series structure make forecasting among one of the most important and challenging tasks in time series analysis. Typical methods for forecasting are designed to model time-evolving dependencies between data observations. However, it is generally accepted that none of them is universally valid for every application. Therefore, methods for learning heterogeneous ensembles by combining a diverse set of forecasts together appear as a promising solution to tackle this task. Several approaches, ranging from simple and enhanced averaging tactics to applying meta-learning methods, have been proposed to learn how to combine individual models in an ensemble. However, finding the optimal strategy for ensemble aggregation remains an open research question, particularly, when the ensemble needs to be adapted in real time. In this paper, we leverage a deep reinforcement learning framework for learning linearly weighted ensembles as a meta-learning method. In this framework, the combination policy in ensembles is modelled as a sequential decision making process, and an actor-critic model aims at learning the optimal weights in a continuous action space. The policy is updated following a drift detection mechanism for tracking performance shifts of the ensemble model. An extensive empirical study on many real-world datasets demonstrates that our method achieves excellent or on par results in comparison to the state-of-the-art approaches as well as several baselines.",
      "intriguing_abstract": "Both complex and evolving nature of time series structure make forecasting among one of the most important and challenging tasks in time series analysis. Typical methods for forecasting are designed to model time-evolving dependencies between data observations. However, it is generally accepted that none of them is universally valid for every application. Therefore, methods for learning heterogeneous ensembles by combining a diverse set of forecasts together appear as a promising solution to tackle this task. Several approaches, ranging from simple and enhanced averaging tactics to applying meta-learning methods, have been proposed to learn how to combine individual models in an ensemble. However, finding the optimal strategy for ensemble aggregation remains an open research question, particularly, when the ensemble needs to be adapted in real time. In this paper, we leverage a deep reinforcement learning framework for learning linearly weighted ensembles as a meta-learning method. In this framework, the combination policy in ensembles is modelled as a sequential decision making process, and an actor-critic model aims at learning the optimal weights in a continuous action space. The policy is updated following a drift detection mechanism for tracking performance shifts of the ensemble model. An extensive empirical study on many real-world datasets demonstrates that our method achieves excellent or on par results in comparison to the state-of-the-art approaches as well as several baselines.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e34c14773be68f14bde61badad2e697e1b1330f2.pdf",
      "citation_key": "saadallah2021ihn",
      "metadata": {
        "title": "Online Ensemble Aggregation using Deep Reinforcement Learning for Time Series Forecasting",
        "authors": [
          "A. Saadallah",
          "K. Morik"
        ],
        "published_date": "2021",
        "abstract": "Both complex and evolving nature of time series structure make forecasting among one of the most important and challenging tasks in time series analysis. Typical methods for forecasting are designed to model time-evolving dependencies between data observations. However, it is generally accepted that none of them is universally valid for every application. Therefore, methods for learning heterogeneous ensembles by combining a diverse set of forecasts together appear as a promising solution to tackle this task. Several approaches, ranging from simple and enhanced averaging tactics to applying meta-learning methods, have been proposed to learn how to combine individual models in an ensemble. However, finding the optimal strategy for ensemble aggregation remains an open research question, particularly, when the ensemble needs to be adapted in real time. In this paper, we leverage a deep reinforcement learning framework for learning linearly weighted ensembles as a meta-learning method. In this framework, the combination policy in ensembles is modelled as a sequential decision making process, and an actor-critic model aims at learning the optimal weights in a continuous action space. The policy is updated following a drift detection mechanism for tracking performance shifts of the ensemble model. An extensive empirical study on many real-world datasets demonstrates that our method achieves excellent or on par results in comparison to the state-of-the-art approaches as well as several baselines.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e34c14773be68f14bde61badad2e697e1b1330f2.pdf",
        "venue": "International Conference on Data Science and Advanced Analytics",
        "citationCount": 10,
        "score": 2.5,
        "summary": "Both complex and evolving nature of time series structure make forecasting among one of the most important and challenging tasks in time series analysis. Typical methods for forecasting are designed to model time-evolving dependencies between data observations. However, it is generally accepted that none of them is universally valid for every application. Therefore, methods for learning heterogeneous ensembles by combining a diverse set of forecasts together appear as a promising solution to tackle this task. Several approaches, ranging from simple and enhanced averaging tactics to applying meta-learning methods, have been proposed to learn how to combine individual models in an ensemble. However, finding the optimal strategy for ensemble aggregation remains an open research question, particularly, when the ensemble needs to be adapted in real time. In this paper, we leverage a deep reinforcement learning framework for learning linearly weighted ensembles as a meta-learning method. In this framework, the combination policy in ensembles is modelled as a sequential decision making process, and an actor-critic model aims at learning the optimal weights in a continuous action space. The policy is updated following a drift detection mechanism for tracking performance shifts of the ensemble model. An extensive empirical study on many real-world datasets demonstrates that our method achieves excellent or on par results in comparison to the state-of-the-art approaches as well as several baselines.",
        "keywords": []
      },
      "file_name": "e34c14773be68f14bde61badad2e697e1b1330f2.pdf"
    },
    {
      "success": true,
      "doc_id": "354410e475ac4bbf3b46c3a4a9d195cb",
      "summary": "Optimal statistical procedures are constructed using deep adversarial learning to optimize play in a two-player game. Traditionally, statistical procedures have been derived via analytic calculations whose validity often relies on sample size growing to infinity. We use tools from deep learning to develop a new approach, adversarial Monte Carlo meta-learning, for constructing optimal statistical procedures. Statistical problems are framed as two-player games in which Nature adversarially selects a distribution that makes it difficult for a statistician to answer the scientific question using data drawn from this distribution. The players’ strategies are parameterized via neural networks, and optimal play is learned by modifying the network weights over many repetitions of the game. Given sufficient computing time, the statistician’s strategy is (nearly) optimal at the finite observed sample size, rather than in the hypothetical scenario where sample size grows to infinity. In numerical experiments and data examples, this approach performs favorably compared to standard practice in point estimation, individual-level predictions, and interval estimation.",
      "intriguing_abstract": "Optimal statistical procedures are constructed using deep adversarial learning to optimize play in a two-player game. Traditionally, statistical procedures have been derived via analytic calculations whose validity often relies on sample size growing to infinity. We use tools from deep learning to develop a new approach, adversarial Monte Carlo meta-learning, for constructing optimal statistical procedures. Statistical problems are framed as two-player games in which Nature adversarially selects a distribution that makes it difficult for a statistician to answer the scientific question using data drawn from this distribution. The players’ strategies are parameterized via neural networks, and optimal play is learned by modifying the network weights over many repetitions of the game. Given sufficient computing time, the statistician’s strategy is (nearly) optimal at the finite observed sample size, rather than in the hypothetical scenario where sample size grows to infinity. In numerical experiments and data examples, this approach performs favorably compared to standard practice in point estimation, individual-level predictions, and interval estimation.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/20b19232cfbb86d9130101ab0ad5fab02188ab0f.pdf",
      "citation_key": "luedtke2020uub",
      "metadata": {
        "title": "Learning to learn from data: Using deep adversarial learning to construct optimal statistical procedures",
        "authors": [
          "Alexander Luedtke",
          "M. Carone",
          "N. Simon",
          "Oleg Sofrygin"
        ],
        "published_date": "2020",
        "abstract": "Optimal statistical procedures are constructed using deep adversarial learning to optimize play in a two-player game. Traditionally, statistical procedures have been derived via analytic calculations whose validity often relies on sample size growing to infinity. We use tools from deep learning to develop a new approach, adversarial Monte Carlo meta-learning, for constructing optimal statistical procedures. Statistical problems are framed as two-player games in which Nature adversarially selects a distribution that makes it difficult for a statistician to answer the scientific question using data drawn from this distribution. The players’ strategies are parameterized via neural networks, and optimal play is learned by modifying the network weights over many repetitions of the game. Given sufficient computing time, the statistician’s strategy is (nearly) optimal at the finite observed sample size, rather than in the hypothetical scenario where sample size grows to infinity. In numerical experiments and data examples, this approach performs favorably compared to standard practice in point estimation, individual-level predictions, and interval estimation.",
        "file_path": "paper_data/Deep_Meta-Learning/info/20b19232cfbb86d9130101ab0ad5fab02188ab0f.pdf",
        "venue": "Science Advances",
        "citationCount": 12,
        "score": 2.4000000000000004,
        "summary": "Optimal statistical procedures are constructed using deep adversarial learning to optimize play in a two-player game. Traditionally, statistical procedures have been derived via analytic calculations whose validity often relies on sample size growing to infinity. We use tools from deep learning to develop a new approach, adversarial Monte Carlo meta-learning, for constructing optimal statistical procedures. Statistical problems are framed as two-player games in which Nature adversarially selects a distribution that makes it difficult for a statistician to answer the scientific question using data drawn from this distribution. The players’ strategies are parameterized via neural networks, and optimal play is learned by modifying the network weights over many repetitions of the game. Given sufficient computing time, the statistician’s strategy is (nearly) optimal at the finite observed sample size, rather than in the hypothetical scenario where sample size grows to infinity. In numerical experiments and data examples, this approach performs favorably compared to standard practice in point estimation, individual-level predictions, and interval estimation.",
        "keywords": []
      },
      "file_name": "20b19232cfbb86d9130101ab0ad5fab02188ab0f.pdf"
    },
    {
      "success": true,
      "doc_id": "16c9f07653917286a490cca1ddb15d65",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/634807a85a6805d6b20863738bc3b287747aeb18.pdf",
      "citation_key": "nasrabadi201801h",
      "metadata": {
        "title": "Format-aware learn&fuzz: deep test data generation for efficient fuzzing",
        "authors": [
          "Morteza Zakeri Nasrabadi",
          "S. Parsa",
          "A. Kalaee"
        ],
        "published_date": "2018",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/634807a85a6805d6b20863738bc3b287747aeb18.pdf",
        "venue": "Neural computing & applications (Print)",
        "citationCount": 16,
        "score": 2.2857142857142856,
        "summary": "",
        "keywords": []
      },
      "file_name": "634807a85a6805d6b20863738bc3b287747aeb18.pdf"
    },
    {
      "success": true,
      "doc_id": "2cc09b63164a5fb0fbc9b006aaaec822",
      "summary": "The ability of deep neural networks to extract complex statistics and learn high level features from vast datasets is proven. Yet current deep learning approaches suffer from poor sample efficiency in stark contrast to human perception. Few shot learning algorithms such as matching networks or Model Agnostic Meta Learning (MAML) mitigate this problem, enabling fast learning with few examples. In this paper, we extend the MAML algorithm to point cloud data using a PointNet Architecture. We construct N$\\times$K-shot classification tasks from the ModelNet40 point cloud dataset to show that this method performs classification as well as supervised deep learning methods with the added benefit of being able to adapt after a single gradient step on a single N$\\times$K task. We empirically search for optimal values of N and K for few shot classification and show our method to achieve 90% meta test accuracy compared to traditional PointNet with 89.2%. We also adapt a meta-trained PointNet to a support set of 9, N=3, K=3, never before seen point clouds which are drawn from an entirely different dataset, ShapeNet. Once adapted the model achieves 7.1/9 classification accuracy on average across 100 query sets of the same classes with new, unique instances. This result far exceeds the supervised Stochastic Gradient Descent (SGD) training result of 3.1/9 accuracy on the query sets which is equivalent to a random baseline.",
      "intriguing_abstract": "The ability of deep neural networks to extract complex statistics and learn high level features from vast datasets is proven. Yet current deep learning approaches suffer from poor sample efficiency in stark contrast to human perception. Few shot learning algorithms such as matching networks or Model Agnostic Meta Learning (MAML) mitigate this problem, enabling fast learning with few examples. In this paper, we extend the MAML algorithm to point cloud data using a PointNet Architecture. We construct N$\\times$K-shot classification tasks from the ModelNet40 point cloud dataset to show that this method performs classification as well as supervised deep learning methods with the added benefit of being able to adapt after a single gradient step on a single N$\\times$K task. We empirically search for optimal values of N and K for few shot classification and show our method to achieve 90% meta test accuracy compared to traditional PointNet with 89.2%. We also adapt a meta-trained PointNet to a support set of 9, N=3, K=3, never before seen point clouds which are drawn from an entirely different dataset, ShapeNet. Once adapted the model achieves 7.1/9 classification accuracy on average across 100 query sets of the same classes with new, unique instances. This result far exceeds the supervised Stochastic Gradient Descent (SGD) training result of 3.1/9 accuracy on the query sets which is equivalent to a random baseline.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/434d8baa964856bcf4bbe9d1bf49dc70ac2128ab.pdf",
      "citation_key": "puri20202sx",
      "metadata": {
        "title": "Few Shot Learning For Point Cloud Data Using Model Agnostic Meta Learning",
        "authors": [
          "R. Puri",
          "A. Zakhor",
          "Raul Puri"
        ],
        "published_date": "2020",
        "abstract": "The ability of deep neural networks to extract complex statistics and learn high level features from vast datasets is proven. Yet current deep learning approaches suffer from poor sample efficiency in stark contrast to human perception. Few shot learning algorithms such as matching networks or Model Agnostic Meta Learning (MAML) mitigate this problem, enabling fast learning with few examples. In this paper, we extend the MAML algorithm to point cloud data using a PointNet Architecture. We construct N$\\times$K-shot classification tasks from the ModelNet40 point cloud dataset to show that this method performs classification as well as supervised deep learning methods with the added benefit of being able to adapt after a single gradient step on a single N$\\times$K task. We empirically search for optimal values of N and K for few shot classification and show our method to achieve 90% meta test accuracy compared to traditional PointNet with 89.2%. We also adapt a meta-trained PointNet to a support set of 9, N=3, K=3, never before seen point clouds which are drawn from an entirely different dataset, ShapeNet. Once adapted the model achieves 7.1/9 classification accuracy on average across 100 query sets of the same classes with new, unique instances. This result far exceeds the supervised Stochastic Gradient Descent (SGD) training result of 3.1/9 accuracy on the query sets which is equivalent to a random baseline.",
        "file_path": "paper_data/Deep_Meta-Learning/info/434d8baa964856bcf4bbe9d1bf49dc70ac2128ab.pdf",
        "venue": "International Conference on Information Photonics",
        "citationCount": 11,
        "score": 2.2,
        "summary": "The ability of deep neural networks to extract complex statistics and learn high level features from vast datasets is proven. Yet current deep learning approaches suffer from poor sample efficiency in stark contrast to human perception. Few shot learning algorithms such as matching networks or Model Agnostic Meta Learning (MAML) mitigate this problem, enabling fast learning with few examples. In this paper, we extend the MAML algorithm to point cloud data using a PointNet Architecture. We construct N$\\times$K-shot classification tasks from the ModelNet40 point cloud dataset to show that this method performs classification as well as supervised deep learning methods with the added benefit of being able to adapt after a single gradient step on a single N$\\times$K task. We empirically search for optimal values of N and K for few shot classification and show our method to achieve 90% meta test accuracy compared to traditional PointNet with 89.2%. We also adapt a meta-trained PointNet to a support set of 9, N=3, K=3, never before seen point clouds which are drawn from an entirely different dataset, ShapeNet. Once adapted the model achieves 7.1/9 classification accuracy on average across 100 query sets of the same classes with new, unique instances. This result far exceeds the supervised Stochastic Gradient Descent (SGD) training result of 3.1/9 accuracy on the query sets which is equivalent to a random baseline.",
        "keywords": []
      },
      "file_name": "434d8baa964856bcf4bbe9d1bf49dc70ac2128ab.pdf"
    },
    {
      "success": true,
      "doc_id": "1518136b5bf67636e2d576a02b0dbed4",
      "summary": "While deep reinforcement learning (RL) has fueled multiple high-profile successes in machine learning, it is held back from more widespread adoption by its often poor data efficiency and the limited generality of the policies it produces. A promising approach for alleviating these limitations is to cast the development of better RL algorithms as a machine learning problem itself in a process called meta-RL. Meta-RL is most commonly studied in a problem setting where, given a distribution of tasks, the goal is to learn a policy that is capable of adapting to any new task from the task distribution with as little data as possible. In this survey, we describe the meta-RL problem setting in detail as well as its major variations. We discuss how, at a high level, meta-RL research can be clustered based on the presence of a task distribution and the learning budget available for each individual task. Using these clusters, we then survey meta-RL algorithms and applications. We conclude by presenting the open problems on the path to making meta-RL part of the standard toolbox for a deep RL practitioner.",
      "intriguing_abstract": "While deep reinforcement learning (RL) has fueled multiple high-profile successes in machine learning, it is held back from more widespread adoption by its often poor data efficiency and the limited generality of the policies it produces. A promising approach for alleviating these limitations is to cast the development of better RL algorithms as a machine learning problem itself in a process called meta-RL. Meta-RL is most commonly studied in a problem setting where, given a distribution of tasks, the goal is to learn a policy that is capable of adapting to any new task from the task distribution with as little data as possible. In this survey, we describe the meta-RL problem setting in detail as well as its major variations. We discuss how, at a high level, meta-RL research can be clustered based on the presence of a task distribution and the learning budget available for each individual task. Using these clusters, we then survey meta-RL algorithms and applications. We conclude by presenting the open problems on the path to making meta-RL part of the standard toolbox for a deep RL practitioner.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5af8c7c650e9ec50d91a16be287ce54b16075fe7.pdf",
      "citation_key": "beck2023x24",
      "metadata": {
        "title": "A Tutorial on Meta-Reinforcement Learning",
        "authors": [
          "Jacob Beck",
          "Risto Vuorio",
          "E. Liu",
          "Zheng Xiong",
          "Luisa M. Zintgraf",
          "Chelsea Finn",
          "S. Whiteson"
        ],
        "published_date": "2023",
        "abstract": "While deep reinforcement learning (RL) has fueled multiple high-profile successes in machine learning, it is held back from more widespread adoption by its often poor data efficiency and the limited generality of the policies it produces. A promising approach for alleviating these limitations is to cast the development of better RL algorithms as a machine learning problem itself in a process called meta-RL. Meta-RL is most commonly studied in a problem setting where, given a distribution of tasks, the goal is to learn a policy that is capable of adapting to any new task from the task distribution with as little data as possible. In this survey, we describe the meta-RL problem setting in detail as well as its major variations. We discuss how, at a high level, meta-RL research can be clustered based on the presence of a task distribution and the learning budget available for each individual task. Using these clusters, we then survey meta-RL algorithms and applications. We conclude by presenting the open problems on the path to making meta-RL part of the standard toolbox for a deep RL practitioner.",
        "file_path": "paper_data/Deep_Meta-Learning/info/5af8c7c650e9ec50d91a16be287ce54b16075fe7.pdf",
        "venue": "Found. Trends Mach. Learn.",
        "citationCount": 121,
        "score": 60.5,
        "summary": "While deep reinforcement learning (RL) has fueled multiple high-profile successes in machine learning, it is held back from more widespread adoption by its often poor data efficiency and the limited generality of the policies it produces. A promising approach for alleviating these limitations is to cast the development of better RL algorithms as a machine learning problem itself in a process called meta-RL. Meta-RL is most commonly studied in a problem setting where, given a distribution of tasks, the goal is to learn a policy that is capable of adapting to any new task from the task distribution with as little data as possible. In this survey, we describe the meta-RL problem setting in detail as well as its major variations. We discuss how, at a high level, meta-RL research can be clustered based on the presence of a task distribution and the learning budget available for each individual task. Using these clusters, we then survey meta-RL algorithms and applications. We conclude by presenting the open problems on the path to making meta-RL part of the standard toolbox for a deep RL practitioner.",
        "keywords": []
      },
      "file_name": "5af8c7c650e9ec50d91a16be287ce54b16075fe7.pdf"
    },
    {
      "success": true,
      "doc_id": "c32cb87f106b6423521f20c2ddd422a4",
      "summary": "Equipping a deep model the ability of few-shot learning (FSL) is a core challenge for artificial intelligence. Gradient-based meta-learning effectively addresses the challenge by learning how to learn novel tasks. Its key idea is learning a deep model in a bi-level optimization manner, where the outer-loop process learns a shared gradient descent algorithm (called meta-optimizer), while the inner-loop process leverages it to optimize a task-specific base learner with few examples. Although these methods have shown superior performance on FSL, the outer-loop process requires calculating second-order derivatives along the inner-loop path, which imposes considerable memory burdens and the risk of vanishing gradients. This degrades meta-learning performance. Inspired by recent diffusion models, we find that the inner-loop gradient descent process can be viewed as a reverse process (i.e., denoising) of diffusion where the target of denoising is the weight of base learner but origin data. Based on this fact, we propose to model the gradient descent algorithm as a diffusion model and then present a novel conditional diffusion-based meta-learning, called MetaDiff, that effectively models the optimization process of base learner weights from Gaussian initialization to target weights in a denoising manner. Thanks to the training efficiency of diffusion models, our MetaDiff does not need to differentiate through the inner-loop path such that the memory burdens and the risk of vanishing gradients can be effectively alleviated for improving FSL. Experimental results show that our MetaDiff outperforms state-of-the-art gradient-based meta-learning family on FSL tasks.",
      "intriguing_abstract": "Equipping a deep model the ability of few-shot learning (FSL) is a core challenge for artificial intelligence. Gradient-based meta-learning effectively addresses the challenge by learning how to learn novel tasks. Its key idea is learning a deep model in a bi-level optimization manner, where the outer-loop process learns a shared gradient descent algorithm (called meta-optimizer), while the inner-loop process leverages it to optimize a task-specific base learner with few examples. Although these methods have shown superior performance on FSL, the outer-loop process requires calculating second-order derivatives along the inner-loop path, which imposes considerable memory burdens and the risk of vanishing gradients. This degrades meta-learning performance. Inspired by recent diffusion models, we find that the inner-loop gradient descent process can be viewed as a reverse process (i.e., denoising) of diffusion where the target of denoising is the weight of base learner but origin data. Based on this fact, we propose to model the gradient descent algorithm as a diffusion model and then present a novel conditional diffusion-based meta-learning, called MetaDiff, that effectively models the optimization process of base learner weights from Gaussian initialization to target weights in a denoising manner. Thanks to the training efficiency of diffusion models, our MetaDiff does not need to differentiate through the inner-loop path such that the memory burdens and the risk of vanishing gradients can be effectively alleviated for improving FSL. Experimental results show that our MetaDiff outperforms state-of-the-art gradient-based meta-learning family on FSL tasks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/da1e2e79ec61158876c69bdfa0f3918806c7073f.pdf",
      "citation_key": "zhang2023t7k",
      "metadata": {
        "title": "MetaDiff: Meta-Learning with Conditional Diffusion for Few-Shot Learning",
        "authors": [
          "Baoquan Zhang",
          "Demin Yu"
        ],
        "published_date": "2023",
        "abstract": "Equipping a deep model the ability of few-shot learning (FSL) is a core challenge for artificial intelligence. Gradient-based meta-learning effectively addresses the challenge by learning how to learn novel tasks. Its key idea is learning a deep model in a bi-level optimization manner, where the outer-loop process learns a shared gradient descent algorithm (called meta-optimizer), while the inner-loop process leverages it to optimize a task-specific base learner with few examples. Although these methods have shown superior performance on FSL, the outer-loop process requires calculating second-order derivatives along the inner-loop path, which imposes considerable memory burdens and the risk of vanishing gradients. This degrades meta-learning performance. Inspired by recent diffusion models, we find that the inner-loop gradient descent process can be viewed as a reverse process (i.e., denoising) of diffusion where the target of denoising is the weight of base learner but origin data. Based on this fact, we propose to model the gradient descent algorithm as a diffusion model and then present a novel conditional diffusion-based meta-learning, called MetaDiff, that effectively models the optimization process of base learner weights from Gaussian initialization to target weights in a denoising manner. Thanks to the training efficiency of diffusion models, our MetaDiff does not need to differentiate through the inner-loop path such that the memory burdens and the risk of vanishing gradients can be effectively alleviated for improving FSL. Experimental results show that our MetaDiff outperforms state-of-the-art gradient-based meta-learning family on FSL tasks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/da1e2e79ec61158876c69bdfa0f3918806c7073f.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 59,
        "score": 29.5,
        "summary": "Equipping a deep model the ability of few-shot learning (FSL) is a core challenge for artificial intelligence. Gradient-based meta-learning effectively addresses the challenge by learning how to learn novel tasks. Its key idea is learning a deep model in a bi-level optimization manner, where the outer-loop process learns a shared gradient descent algorithm (called meta-optimizer), while the inner-loop process leverages it to optimize a task-specific base learner with few examples. Although these methods have shown superior performance on FSL, the outer-loop process requires calculating second-order derivatives along the inner-loop path, which imposes considerable memory burdens and the risk of vanishing gradients. This degrades meta-learning performance. Inspired by recent diffusion models, we find that the inner-loop gradient descent process can be viewed as a reverse process (i.e., denoising) of diffusion where the target of denoising is the weight of base learner but origin data. Based on this fact, we propose to model the gradient descent algorithm as a diffusion model and then present a novel conditional diffusion-based meta-learning, called MetaDiff, that effectively models the optimization process of base learner weights from Gaussian initialization to target weights in a denoising manner. Thanks to the training efficiency of diffusion models, our MetaDiff does not need to differentiate through the inner-loop path such that the memory burdens and the risk of vanishing gradients can be effectively alleviated for improving FSL. Experimental results show that our MetaDiff outperforms state-of-the-art gradient-based meta-learning family on FSL tasks.",
        "keywords": []
      },
      "file_name": "da1e2e79ec61158876c69bdfa0f3918806c7073f.pdf"
    },
    {
      "success": true,
      "doc_id": "32b2f474e56a38b78737c687dd5fc814",
      "summary": "Here's a focused summary of the technical paper \\cite{khoee2024ksk} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep neural networks (DNNs) exhibit significant performance degradation when faced with out-of-distribution (OOD) data due to inevitable domain shifts in real-world applications. This limitation stems from the common assumption that training and testing data share the same distribution, which is frequently violated in practice.\n    *   **Importance and Challenge**: Traditional machine learning models struggle with distributional shifts and limited labeled data, leading to overfitting and poor generalization across various tasks and domains. Domain Generalization (DG) is particularly challenging as it aims for models to perform well on *unseen* target domains without any access to target domain data during training, making it more applicable but harder than Domain Adaptation (DA). Collecting labeled data for every new \"unseen\" domain is often costly, time-consuming, or impossible.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The paper positions itself as the first comprehensive survey specifically dedicated to the intersection of meta-learning and domain generalization. It acknowledges existing surveys on domain generalization (e.g., \\cite{wang2021generalizing, zhou2022domain}), OOD generalization \\cite{liu2021out}, and meta-learning (e.g., \\cite{viltala2020meta, huisman2021survey, hospedales2020meta, vettoruzzo2023meta}).\n    *   **Limitations of Previous Solutions**: Previous surveys on meta-learning did not specifically focus on its application to domain generalization, nor did they offer a novel taxonomy or decision graph tailored to this specific problem space. This work fills that gap by providing a focused perspective on how meta-learning addresses the challenges of generalizing to unseen domains.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: As a survey paper, the core \"method\" is a systematic review and synthesis of existing meta-learning approaches for domain generalization. The paper introduces a novel framework for understanding and categorizing these methods.\n    *   **Novelty/Difference**:\n        *   It is presented as the *first survey* to exclusively collect and highlight the potential of meta-learning for domain generalization \\cite{khoee2024ksk}.\n        *   It introduces a *novel taxonomy* for classifying meta-learning methodologies for DG, based on the feature extraction strategy and the classifier learning methodology.\n        *   It provides a *decision graph* to guide researchers and practitioners in navigating this taxonomy, assisting in selecting and developing appropriate models based on data availability and domain shift characteristics.\n        *   It offers a formalization of meta-learning for domain generalization, clarifying its promises and challenges.\n\n*   **Key Technical Contributions**\n    *   **Novel Taxonomy**: A new classification framework for meta-learning methods in DG, categorizing them based on their feature extraction and classifier learning strategies. This provides a structured way to understand the diverse approaches in the field.\n    *   **Decision Graph**: A practical tool that helps users navigate the proposed taxonomy, enabling informed model selection based on specific problem requirements (e.g., data availability, type of domain shift).\n    *   **Comprehensive Review and Formalization**: Provides a systematic overview of existing methods, their theoretical foundations, and a formalization of meta-learning in the DG context, clarifying its unique aspects compared to other learning paradigms.\n    *   **Identification of Research Directions**: Discusses key challenges and promising future research avenues in meta-learning for DG.\n\n*   **Experimental Validation**\n    *   As a survey paper, \\cite{khoee2024ksk} does not conduct its own experiments. Instead, it *reviews* and *discusses* the experimental validation practices within the field of meta-learning for domain generalization.\n    *   **Reviewed Experiments**: The paper surveys widely adopted datasets (e.g., PACS \\cite{li2017deeper}, Visual Decathlon \\cite{rebuffi2017learning}) and evaluation protocols prevalent in this research area.\n    *   **Key Performance Metrics and Comparison Results**: It implicitly covers the performance metrics and comparison results by analyzing the methods presented in the surveyed literature, highlighting how these methods aim to improve generalization performance on unseen domains.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations of Meta-Learning for DG (as discussed in the paper)**:\n        *   Requires sufficient diversity of learning tasks during meta-training to generalize effectively to completely new domains.\n        *   Performance can be sensitive to the degree of distributional shift between training and test domains.\n        *   While designed for sample efficiency, meta-learning often requires a large number of *tasks* (not necessarily samples per task) to achieve high performance, which may not always be feasible.\n        *   Meta-learning algorithms might not inherently capture causal relationships within data without proper inductive biases or domain knowledge integration.\n    *   **Scope of Applicability**: The survey's scope is strictly focused on the intersection of meta-learning and domain generalization, providing a deep dive into this specific area rather than a broad overview of all OOD generalization techniques.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{khoee2024ksk} advances the technical state-of-the-art by providing the first dedicated and comprehensive overview of meta-learning for domain generalization. Its novel taxonomy and decision graph offer a structured understanding of the field, which was previously lacking.\n    *   **Potential Impact on Future Research**: It serves as an extensive reference for researchers and practitioners, guiding them in understanding, categorizing, and developing new meta-learning models for DG. By mapping out fundamentals, highlighting strengths and limitations, and pointing out principal challenges and open questions, it is expected to stimulate further advancements and more targeted research in this crucial area of AI.",
      "intriguing_abstract": "Deep neural networks (DNNs) face a critical challenge: their performance degrades significantly when confronted with out-of-distribution (OOD) data due to inevitable domain shifts in real-world applications. Achieving robust **Domain Generalization (DG)**—enabling models to perform well on *unseen* target domains without any target data during training—remains a formidable frontier in AI. This paper presents the *first comprehensive survey* exclusively dedicated to the burgeoning intersection of **meta-learning** and **domain generalization**, offering a timely and crucial resource for the AI community.\n\nWe introduce a novel, systematic **taxonomy** that classifies meta-learning methodologies for DG based on their distinct feature extraction and classifier learning strategies. Complementing this, a practical **decision graph** is provided to guide researchers and practitioners in selecting and developing appropriate models tailored to specific data availability and domain shift characteristics. By formalizing meta-learning for DG, clarifying its promises and challenges, and identifying key future research directions, this work provides an indispensable roadmap. It aims to accelerate the development of robust, generalizable AI systems capable of thriving in dynamic, unpredictable environments, thereby advancing the state-of-the-art in OOD generalization.",
      "keywords": [
        "Domain Generalization (DG)",
        "Meta-learning",
        "Out-of-distribution (OOD) data",
        "Domain shifts",
        "Novel taxonomy",
        "Decision graph",
        "Systematic review",
        "Unseen target domains",
        "Feature extraction strategy",
        "Classifier learning methodology",
        "Formalization of meta-learning for DG",
        "Future research directions",
        "Performance degradation",
        "Meta-training task diversity"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/f8ee167e718cb152d816f06d42c66efec729a536.pdf",
      "citation_key": "khoee2024ksk",
      "metadata": {
        "title": "Domain Generalization through Meta-Learning: A Survey",
        "authors": [
          "Arsham Gholamzadeh Khoee",
          "Yinan Yu",
          "R. Feldt"
        ],
        "published_date": "2024",
        "abstract": "Deep neural networks (DNNs) have revolutionized artificial intelligence but often lack performance when faced with out-of-distribution data, a common scenario due to the inevitable domain shifts in real-world applications. This limitation stems from the common assumption that training and testing data share the same distribution-an assumption frequently violated in practice. Despite their effectiveness with large amounts of data and computational power, DNNs struggle with distributional shifts and limited labeled data, leading to overfitting and poor generalization across various tasks and domains. Meta-learning presents a promising approach by employing algorithms that acquire transferable knowledge across various tasks for fast adaptation, eliminating the need to learn each task from scratch. This survey paper delves into the realm of meta-learning with a focus on its contribution to domain generalization. We first clarify the concept of meta-learning for domain generalization and introduce a novel taxonomy based on the feature extraction strategy and the classifier learning methodology, offering a granular view of methodologies. Additionally, we present a decision graph to assist readers in navigating the taxonomy based on data availability and domain shifts, enabling them to select and develop a proper model tailored to their specific problem requirements. Through an exhaustive review of existing methods and underlying theories, we map out the fundamentals of the field. Our survey provides practical insights and an informed discussion on promising research directions.",
        "file_path": "paper_data/Deep_Meta-Learning/info/f8ee167e718cb152d816f06d42c66efec729a536.pdf",
        "venue": "Artificial Intelligence Review",
        "citationCount": 28,
        "score": 28.0,
        "summary": "Here's a focused summary of the technical paper \\cite{khoee2024ksk} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Deep neural networks (DNNs) exhibit significant performance degradation when faced with out-of-distribution (OOD) data due to inevitable domain shifts in real-world applications. This limitation stems from the common assumption that training and testing data share the same distribution, which is frequently violated in practice.\n    *   **Importance and Challenge**: Traditional machine learning models struggle with distributional shifts and limited labeled data, leading to overfitting and poor generalization across various tasks and domains. Domain Generalization (DG) is particularly challenging as it aims for models to perform well on *unseen* target domains without any access to target domain data during training, making it more applicable but harder than Domain Adaptation (DA). Collecting labeled data for every new \"unseen\" domain is often costly, time-consuming, or impossible.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The paper positions itself as the first comprehensive survey specifically dedicated to the intersection of meta-learning and domain generalization. It acknowledges existing surveys on domain generalization (e.g., \\cite{wang2021generalizing, zhou2022domain}), OOD generalization \\cite{liu2021out}, and meta-learning (e.g., \\cite{viltala2020meta, huisman2021survey, hospedales2020meta, vettoruzzo2023meta}).\n    *   **Limitations of Previous Solutions**: Previous surveys on meta-learning did not specifically focus on its application to domain generalization, nor did they offer a novel taxonomy or decision graph tailored to this specific problem space. This work fills that gap by providing a focused perspective on how meta-learning addresses the challenges of generalizing to unseen domains.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: As a survey paper, the core \"method\" is a systematic review and synthesis of existing meta-learning approaches for domain generalization. The paper introduces a novel framework for understanding and categorizing these methods.\n    *   **Novelty/Difference**:\n        *   It is presented as the *first survey* to exclusively collect and highlight the potential of meta-learning for domain generalization \\cite{khoee2024ksk}.\n        *   It introduces a *novel taxonomy* for classifying meta-learning methodologies for DG, based on the feature extraction strategy and the classifier learning methodology.\n        *   It provides a *decision graph* to guide researchers and practitioners in navigating this taxonomy, assisting in selecting and developing appropriate models based on data availability and domain shift characteristics.\n        *   It offers a formalization of meta-learning for domain generalization, clarifying its promises and challenges.\n\n*   **Key Technical Contributions**\n    *   **Novel Taxonomy**: A new classification framework for meta-learning methods in DG, categorizing them based on their feature extraction and classifier learning strategies. This provides a structured way to understand the diverse approaches in the field.\n    *   **Decision Graph**: A practical tool that helps users navigate the proposed taxonomy, enabling informed model selection based on specific problem requirements (e.g., data availability, type of domain shift).\n    *   **Comprehensive Review and Formalization**: Provides a systematic overview of existing methods, their theoretical foundations, and a formalization of meta-learning in the DG context, clarifying its unique aspects compared to other learning paradigms.\n    *   **Identification of Research Directions**: Discusses key challenges and promising future research avenues in meta-learning for DG.\n\n*   **Experimental Validation**\n    *   As a survey paper, \\cite{khoee2024ksk} does not conduct its own experiments. Instead, it *reviews* and *discusses* the experimental validation practices within the field of meta-learning for domain generalization.\n    *   **Reviewed Experiments**: The paper surveys widely adopted datasets (e.g., PACS \\cite{li2017deeper}, Visual Decathlon \\cite{rebuffi2017learning}) and evaluation protocols prevalent in this research area.\n    *   **Key Performance Metrics and Comparison Results**: It implicitly covers the performance metrics and comparison results by analyzing the methods presented in the surveyed literature, highlighting how these methods aim to improve generalization performance on unseen domains.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations of Meta-Learning for DG (as discussed in the paper)**:\n        *   Requires sufficient diversity of learning tasks during meta-training to generalize effectively to completely new domains.\n        *   Performance can be sensitive to the degree of distributional shift between training and test domains.\n        *   While designed for sample efficiency, meta-learning often requires a large number of *tasks* (not necessarily samples per task) to achieve high performance, which may not always be feasible.\n        *   Meta-learning algorithms might not inherently capture causal relationships within data without proper inductive biases or domain knowledge integration.\n    *   **Scope of Applicability**: The survey's scope is strictly focused on the intersection of meta-learning and domain generalization, providing a deep dive into this specific area rather than a broad overview of all OOD generalization techniques.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{khoee2024ksk} advances the technical state-of-the-art by providing the first dedicated and comprehensive overview of meta-learning for domain generalization. Its novel taxonomy and decision graph offer a structured understanding of the field, which was previously lacking.\n    *   **Potential Impact on Future Research**: It serves as an extensive reference for researchers and practitioners, guiding them in understanding, categorizing, and developing new meta-learning models for DG. By mapping out fundamentals, highlighting strengths and limitations, and pointing out principal challenges and open questions, it is expected to stimulate further advancements and more targeted research in this crucial area of AI.",
        "keywords": [
          "Domain Generalization (DG)",
          "Meta-learning",
          "Out-of-distribution (OOD) data",
          "Domain shifts",
          "Novel taxonomy",
          "Decision graph",
          "Systematic review",
          "Unseen target domains",
          "Feature extraction strategy",
          "Classifier learning methodology",
          "Formalization of meta-learning for DG",
          "Future research directions",
          "Performance degradation",
          "Meta-training task diversity"
        ],
        "paper_type": "based on the provided abstract, introduction, and metadata:\n\n*   **title:** \"domain generalization through meta-learning: a survey\" directly indicates its type.\n*   **venue:** \"artificial intelligence review\" is a journal known for publishing review articles.\n*   **abstract:**\n    *   explicitly states: \"this **survey paper** delves into the realm of meta-learning...\"\n    *   mentions: \"introduce a **novel taxonomy**\", \"present a **decision graph**\", \"through an **exhaustive review of existing methods and underlying theories**\", \"map out the fundamentals of the field\", \"provides practical insights and an informed discussion on **promising research directions**.\"\n*   **introduction:** sets the stage for reviewing existing techniques (dg and da).\n\nall these points strongly align with the criteria for a **survey** paper.\n\n**classification: survey**"
      },
      "file_name": "f8ee167e718cb152d816f06d42c66efec729a536.pdf"
    },
    {
      "success": true,
      "doc_id": "696e522b867e989075d7f07245a1477a",
      "summary": "Internet of Things (IoT) networks are often subject to many malicious attacks in untrusted environments, and automatic modulation classification (AMC) is an effective way to combat IoT physical-layer threats. However, most existing AMC methods assume sufficient labeled signals and invariant signal distribution, which is often impossible in untrusted environments. In this article, a new meta-learning method is proposed for a few-shot AMC with distribution bias. First, a multi-frequency octave ResNet (MFOR) is constructed to learn coarse (low-frequency) and fine (high-frequency) features, which can efficiently identify the modulation type of the signal while saving computational resources. Second, a large number of classification-related meta-tasks are established for training MFOR to explore general knowledge in signal classification, and then transfer it to the AMC. Different with deep neural networks (DNNs) that learn a mapping by multiple instances, the MFOR with meta-learning (denoted as M-MFOR) can improve the generalization ability of new AMC tasks with very few instances and distribution bias. Furthermore, we find that the distribution bias between data can be reduced by adjusting the normalized distribution and propose a class-related mixup. Extensive experiments are taken on several datasets to investigate the effectiveness of M-MFOR. The results show its feasibility and superiority over existing methods.",
      "intriguing_abstract": "Internet of Things (IoT) networks are often subject to many malicious attacks in untrusted environments, and automatic modulation classification (AMC) is an effective way to combat IoT physical-layer threats. However, most existing AMC methods assume sufficient labeled signals and invariant signal distribution, which is often impossible in untrusted environments. In this article, a new meta-learning method is proposed for a few-shot AMC with distribution bias. First, a multi-frequency octave ResNet (MFOR) is constructed to learn coarse (low-frequency) and fine (high-frequency) features, which can efficiently identify the modulation type of the signal while saving computational resources. Second, a large number of classification-related meta-tasks are established for training MFOR to explore general knowledge in signal classification, and then transfer it to the AMC. Different with deep neural networks (DNNs) that learn a mapping by multiple instances, the MFOR with meta-learning (denoted as M-MFOR) can improve the generalization ability of new AMC tasks with very few instances and distribution bias. Furthermore, we find that the distribution bias between data can be reduced by adjusting the normalized distribution and propose a class-related mixup. Extensive experiments are taken on several datasets to investigate the effectiveness of M-MFOR. The results show its feasibility and superiority over existing methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b2058b849f29e99ed4052e2d82b248acc4d6685f.pdf",
      "citation_key": "hao2023zfk",
      "metadata": {
        "title": "Automatic Modulation Classification via Meta-Learning",
        "authors": [
          "Xiaoyang Hao",
          "Zhixi Feng",
          "Shuyuan Yang",
          "Min Wang",
          "Licheng Jiao"
        ],
        "published_date": "2023",
        "abstract": "Internet of Things (IoT) networks are often subject to many malicious attacks in untrusted environments, and automatic modulation classification (AMC) is an effective way to combat IoT physical-layer threats. However, most existing AMC methods assume sufficient labeled signals and invariant signal distribution, which is often impossible in untrusted environments. In this article, a new meta-learning method is proposed for a few-shot AMC with distribution bias. First, a multi-frequency octave ResNet (MFOR) is constructed to learn coarse (low-frequency) and fine (high-frequency) features, which can efficiently identify the modulation type of the signal while saving computational resources. Second, a large number of classification-related meta-tasks are established for training MFOR to explore general knowledge in signal classification, and then transfer it to the AMC. Different with deep neural networks (DNNs) that learn a mapping by multiple instances, the MFOR with meta-learning (denoted as M-MFOR) can improve the generalization ability of new AMC tasks with very few instances and distribution bias. Furthermore, we find that the distribution bias between data can be reduced by adjusting the normalized distribution and propose a class-related mixup. Extensive experiments are taken on several datasets to investigate the effectiveness of M-MFOR. The results show its feasibility and superiority over existing methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b2058b849f29e99ed4052e2d82b248acc4d6685f.pdf",
        "venue": "IEEE Internet of Things Journal",
        "citationCount": 29,
        "score": 14.5,
        "summary": "Internet of Things (IoT) networks are often subject to many malicious attacks in untrusted environments, and automatic modulation classification (AMC) is an effective way to combat IoT physical-layer threats. However, most existing AMC methods assume sufficient labeled signals and invariant signal distribution, which is often impossible in untrusted environments. In this article, a new meta-learning method is proposed for a few-shot AMC with distribution bias. First, a multi-frequency octave ResNet (MFOR) is constructed to learn coarse (low-frequency) and fine (high-frequency) features, which can efficiently identify the modulation type of the signal while saving computational resources. Second, a large number of classification-related meta-tasks are established for training MFOR to explore general knowledge in signal classification, and then transfer it to the AMC. Different with deep neural networks (DNNs) that learn a mapping by multiple instances, the MFOR with meta-learning (denoted as M-MFOR) can improve the generalization ability of new AMC tasks with very few instances and distribution bias. Furthermore, we find that the distribution bias between data can be reduced by adjusting the normalized distribution and propose a class-related mixup. Extensive experiments are taken on several datasets to investigate the effectiveness of M-MFOR. The results show its feasibility and superiority over existing methods.",
        "keywords": []
      },
      "file_name": "b2058b849f29e99ed4052e2d82b248acc4d6685f.pdf"
    },
    {
      "success": true,
      "doc_id": "178fb03491c5b6f358434000351c4086",
      "summary": "Here's a focused summary of the technical paper \\cite{nathaniel2023ycu} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical challenge of **data sparsity** in climate science and ecology, particularly for in-situ observations of carbon fluxes (Gross Primary Production - GPP, and Ecosystem Respiration - Reco).\n    *   Existing global networks like FLUXNET2015 provide high-quality data but are spatially and temporally sparse, with unbalanced distribution, especially lacking in **tropics and semi-arid regions**. These regions are crucial for understanding the global carbon cycle and its interannual variability.\n    *   This data scarcity hinders a comprehensive understanding of climate processes and the global carbon cycle, particularly in the context of climate change. There is a need for globally continuous, high-resolution datasets that accurately represent these critical, data-sparse areas.\n\n*   **Related Work & Positioning**\n    *   The machine-learning community has explored solutions like few-shot learning to tackle data sparsity.\n    *   Meta-learning, which \"learns how to learn from different tasks,\" is a promising approach but has seen limited application in climate and environmental sciences, especially for sparse and extreme spatiotemporal observations.\n    *   The authors highlight that, to their knowledge, no prior upscaling effort has utilized an **ensemble of meta-trained deep models** to produce a spatiotemporally continuous climate product from sparse observations. This work positions itself as a novel application of meta-learning to bridge this gap.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **meta-learning**, specifically an optimization-based approach adapted from Model-Agnostic Meta-Learning (MAML) \\cite{nathaniel2023ycu}.\n    *   Meta-learning involves two stages: **meta-training** (where the model learns intermediate parameters from data-abundant \"base tasks\") and **meta-update** (where these parameters are fine-tuned on data-sparse \"target tasks\"). This process ensures the model learns broad features and efficiently adapts to new, poorly sampled tasks without being biased towards data-abundant regions.\n    *   The approach uses an **ensemble of deep learning models** (Multilayer Perceptron - MLP, Long Short-Term Memory - LSTM, and Bi-directional LSTM - BiLSTM) to quantify uncertainty and reduce individual model bias. LSTM and BiLSTM are specifically chosen to capture temporal dependencies crucial for environmental processes like water stress.\n    *   The models are trained on 206 FLUXNET2015 sites using a combination of ERA5 reanalysis (meteorological data) and MODIS remote sensing (LAI) products.\n    *   For upscaling, the meta-trained ensemble generates global GPP and Reco products at 0.25-degree spatial resolution, daily and monthly timescales, from 2001 to 2021.\n\n*   **Key Technical Contributions**\n    *   **Novel application of meta-learning**: First known application of an ensemble of meta-trained deep models for upscaling sparse in-situ carbon flux observations to a globally continuous, high-resolution product in climate science \\cite{nathaniel2023ycu}.\n    *   **Robustness to data sparsity and extremes**: The meta-learning framework is specifically designed to learn efficiently from sparse data and demonstrate enhanced robustness in predicting extreme flux events.\n    *   **Ensemble modeling for uncertainty quantification**: The use of a five-member ensemble for each deep learning architecture (MLP, LSTM, BiLSTM) provides estimates of both the mean flux and its uncertainty (standard deviation).\n    *   **Integration of diverse data sources**: Combines high-quality point-source FLUXNET data with global reanalysis (ERA5) and remote sensing (MODIS) products for comprehensive input features.\n\n*   **Experimental Validation**\n    *   **Site-level performance**: Meta-trained ensembles consistently showed **lower validation RMSE** compared to their non-meta-trained counterparts. For GPP, meta-trained MLP had 5–7% lower error (3.13 gC m⁻² d⁻¹ ± 0.06 vs. 3.47 gC m⁻² d⁻¹ ± 0.07 for baseline). Similar improvements were observed for Reco.\n    *   **Robustness to extreme observations**: Meta-trained models demonstrated significantly **lower errors (4–24%)** when predicting extreme GPP and Reco fluxes, indicating improved reliability in critical conditions.\n    *   **Temporal model superiority**: Models incorporating temporal information (LSTM and BiLSTM) generally outperformed MLP, confirming the importance of memory processes for environmental variables like water stress.\n    *   **Global-level validation**: The upscaled MetaFlux product was evaluated for its seasonality, interannual trends, and interannual variability (using coefficient of variation).\n    *   **Correlation with SIF**: MetaFlux GPP showed **higher Pearson correlation with satellite-based Solar-Induced Fluorescence (SIF)** (from CSIF and TROPOMI) compared to the Fluxcom data-driven product, particularly in the **tropics and semi-arid regions (10–40% improvement)**. This is a strong indicator of improved GPP estimates in these critical, data-sparse areas.\n\n*   **Limitations & Scope**\n    *   The dataset covers GPP and Reco, specifically focusing on the terrestrial carbon cycle.\n    *   The spatial resolution is 0.25-degree, and temporal resolutions are daily and monthly, spanning 2001-2021.\n    *   Cold regions (Arctic circle and Antarctica) are masked out.\n    *   While the paper demonstrates improved correlation with SIF, it acknowledges that a higher correlation is not always universally indicative of a \"better\" GPP estimate due to varying ecosystem regimes and physiological characteristics.\n    *   The specific architectures and hyperparameters were determined via k-fold cross-validation on the training set.\n\n*   **Technical Significance**\n    *   MetaFlux significantly **advances the technical state-of-the-art** by providing a novel, robust method for generating high-resolution, continuous global carbon flux data from sparse observations.\n    *   The successful application of meta-learning to climate science, particularly for handling data sparsity and extreme events, opens new avenues for **future research** in applying advanced machine learning techniques to other environmental and climate variables facing similar data challenges.\n    *   The improved accuracy, especially in data-sparse and critical regions like the tropics and semi-arids, offers a more reliable dataset for studying biogeochemical processes, understanding the global carbon cycle, and assessing the impacts of climate change.\n    *   The publicly available dataset and code facilitate reproducibility and further research in this domain.",
      "intriguing_abstract": "Understanding the global carbon cycle is critically hampered by pervasive **data sparsity**, particularly for in-situ **carbon flux** observations (Gross Primary Production - **GPP**, and Ecosystem Respiration - **Reco**) in crucial, yet under-sampled, regions like the **tropics and semi-arid zones**. This paper introduces a novel **meta-learning** framework, inspired by **Model-Agnostic Meta-Learning (MAML)**, to overcome this challenge. We present the first known application of an **ensemble of meta-trained deep models** (MLP, LSTM, BiLSTM) for **upscaling** sparse **FLUXNET** observations into a globally continuous, high-resolution (0.25-degree, daily/monthly) **MetaFlux** product spanning 2001-2021.\n\nOur approach uniquely \"learns how to learn\" from diverse tasks, enabling robust adaptation to **data sparsity** and significantly enhancing predictions of **extreme flux events**. Validation reveals that meta-trained models consistently outperform non-meta-trained counterparts, with up to 24% lower errors for extreme fluxes. Crucially, MetaFlux GPP exhibits 10-40% higher correlation with **Solar-Induced Fluorescence (SIF)** in data-sparse tropics and semi-arid regions compared to existing products, providing unprecedented accuracy where it's most needed. This work advances the technical state-of-the-art in climate science, offering a more reliable dataset for studying biogeochemical processes and the impacts of **climate change**, while opening new avenues for applying advanced **machine learning** to environmental challenges.",
      "keywords": [
        "Data sparsity",
        "carbon fluxes (GPP",
        "Reco)",
        "meta-learning",
        "ensemble deep learning models",
        "upscaling sparse observations",
        "tropics and semi-arid regions",
        "uncertainty quantification",
        "robustness to extreme events",
        "MetaFlux product",
        "global carbon cycle",
        "spatiotemporally continuous data",
        "Solar-Induced Fluorescence (SIF) correlation"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/1d421d179a2520ba23dc1375fe2989e4ba79b437.pdf",
      "citation_key": "nathaniel2023ycu",
      "metadata": {
        "title": "MetaFlux: Meta-learning global carbon fluxes from sparse spatiotemporal observations",
        "authors": [
          "Juan Nathaniel",
          "Jiangong Liu",
          "P. Gentine"
        ],
        "published_date": "2023",
        "abstract": "We provide a global, long-term carbon flux dataset of gross primary production and ecosystem respiration generated using meta-learning, called MetaFlux . The idea behind meta-learning stems from the need to learn efficiently given sparse data by learning how to learn broad features across tasks to better infer other poorly sampled ones. Using meta-trained ensemble of deep models, we generate global carbon products on daily and monthly timescales at a 0.25-degree spatial resolution from 2001 to 2021, through a combination of reanalysis and remote-sensing products. Site-level validation finds that MetaFlux ensembles have lower validation error by 5–7% compared to their non-meta-trained counterparts. In addition, they are more robust to extreme observations, with 4–24% lower errors. We also checked for seasonality, interannual variability, and correlation to solar-induced fluorescence of the upscaled product and found that MetaFlux outperformed other machine-learning based carbon product, especially in the tropics and semi-arids by 10–40%. Overall, MetaFlux can be used to study a wide range of biogeochemical processes.",
        "file_path": "paper_data/Deep_Meta-Learning/info/1d421d179a2520ba23dc1375fe2989e4ba79b437.pdf",
        "venue": "Scientific Data",
        "citationCount": 25,
        "score": 12.5,
        "summary": "Here's a focused summary of the technical paper \\cite{nathaniel2023ycu} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical challenge of **data sparsity** in climate science and ecology, particularly for in-situ observations of carbon fluxes (Gross Primary Production - GPP, and Ecosystem Respiration - Reco).\n    *   Existing global networks like FLUXNET2015 provide high-quality data but are spatially and temporally sparse, with unbalanced distribution, especially lacking in **tropics and semi-arid regions**. These regions are crucial for understanding the global carbon cycle and its interannual variability.\n    *   This data scarcity hinders a comprehensive understanding of climate processes and the global carbon cycle, particularly in the context of climate change. There is a need for globally continuous, high-resolution datasets that accurately represent these critical, data-sparse areas.\n\n*   **Related Work & Positioning**\n    *   The machine-learning community has explored solutions like few-shot learning to tackle data sparsity.\n    *   Meta-learning, which \"learns how to learn from different tasks,\" is a promising approach but has seen limited application in climate and environmental sciences, especially for sparse and extreme spatiotemporal observations.\n    *   The authors highlight that, to their knowledge, no prior upscaling effort has utilized an **ensemble of meta-trained deep models** to produce a spatiotemporally continuous climate product from sparse observations. This work positions itself as a novel application of meta-learning to bridge this gap.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is **meta-learning**, specifically an optimization-based approach adapted from Model-Agnostic Meta-Learning (MAML) \\cite{nathaniel2023ycu}.\n    *   Meta-learning involves two stages: **meta-training** (where the model learns intermediate parameters from data-abundant \"base tasks\") and **meta-update** (where these parameters are fine-tuned on data-sparse \"target tasks\"). This process ensures the model learns broad features and efficiently adapts to new, poorly sampled tasks without being biased towards data-abundant regions.\n    *   The approach uses an **ensemble of deep learning models** (Multilayer Perceptron - MLP, Long Short-Term Memory - LSTM, and Bi-directional LSTM - BiLSTM) to quantify uncertainty and reduce individual model bias. LSTM and BiLSTM are specifically chosen to capture temporal dependencies crucial for environmental processes like water stress.\n    *   The models are trained on 206 FLUXNET2015 sites using a combination of ERA5 reanalysis (meteorological data) and MODIS remote sensing (LAI) products.\n    *   For upscaling, the meta-trained ensemble generates global GPP and Reco products at 0.25-degree spatial resolution, daily and monthly timescales, from 2001 to 2021.\n\n*   **Key Technical Contributions**\n    *   **Novel application of meta-learning**: First known application of an ensemble of meta-trained deep models for upscaling sparse in-situ carbon flux observations to a globally continuous, high-resolution product in climate science \\cite{nathaniel2023ycu}.\n    *   **Robustness to data sparsity and extremes**: The meta-learning framework is specifically designed to learn efficiently from sparse data and demonstrate enhanced robustness in predicting extreme flux events.\n    *   **Ensemble modeling for uncertainty quantification**: The use of a five-member ensemble for each deep learning architecture (MLP, LSTM, BiLSTM) provides estimates of both the mean flux and its uncertainty (standard deviation).\n    *   **Integration of diverse data sources**: Combines high-quality point-source FLUXNET data with global reanalysis (ERA5) and remote sensing (MODIS) products for comprehensive input features.\n\n*   **Experimental Validation**\n    *   **Site-level performance**: Meta-trained ensembles consistently showed **lower validation RMSE** compared to their non-meta-trained counterparts. For GPP, meta-trained MLP had 5–7% lower error (3.13 gC m⁻² d⁻¹ ± 0.06 vs. 3.47 gC m⁻² d⁻¹ ± 0.07 for baseline). Similar improvements were observed for Reco.\n    *   **Robustness to extreme observations**: Meta-trained models demonstrated significantly **lower errors (4–24%)** when predicting extreme GPP and Reco fluxes, indicating improved reliability in critical conditions.\n    *   **Temporal model superiority**: Models incorporating temporal information (LSTM and BiLSTM) generally outperformed MLP, confirming the importance of memory processes for environmental variables like water stress.\n    *   **Global-level validation**: The upscaled MetaFlux product was evaluated for its seasonality, interannual trends, and interannual variability (using coefficient of variation).\n    *   **Correlation with SIF**: MetaFlux GPP showed **higher Pearson correlation with satellite-based Solar-Induced Fluorescence (SIF)** (from CSIF and TROPOMI) compared to the Fluxcom data-driven product, particularly in the **tropics and semi-arid regions (10–40% improvement)**. This is a strong indicator of improved GPP estimates in these critical, data-sparse areas.\n\n*   **Limitations & Scope**\n    *   The dataset covers GPP and Reco, specifically focusing on the terrestrial carbon cycle.\n    *   The spatial resolution is 0.25-degree, and temporal resolutions are daily and monthly, spanning 2001-2021.\n    *   Cold regions (Arctic circle and Antarctica) are masked out.\n    *   While the paper demonstrates improved correlation with SIF, it acknowledges that a higher correlation is not always universally indicative of a \"better\" GPP estimate due to varying ecosystem regimes and physiological characteristics.\n    *   The specific architectures and hyperparameters were determined via k-fold cross-validation on the training set.\n\n*   **Technical Significance**\n    *   MetaFlux significantly **advances the technical state-of-the-art** by providing a novel, robust method for generating high-resolution, continuous global carbon flux data from sparse observations.\n    *   The successful application of meta-learning to climate science, particularly for handling data sparsity and extreme events, opens new avenues for **future research** in applying advanced machine learning techniques to other environmental and climate variables facing similar data challenges.\n    *   The improved accuracy, especially in data-sparse and critical regions like the tropics and semi-arids, offers a more reliable dataset for studying biogeochemical processes, understanding the global carbon cycle, and assessing the impacts of climate change.\n    *   The publicly available dataset and code facilitate reproducibility and further research in this domain.",
        "keywords": [
          "Data sparsity",
          "carbon fluxes (GPP",
          "Reco)",
          "meta-learning",
          "ensemble deep learning models",
          "upscaling sparse observations",
          "tropics and semi-arid regions",
          "uncertainty quantification",
          "robustness to extreme events",
          "MetaFlux product",
          "global carbon cycle",
          "spatiotemporally continuous data",
          "Solar-Induced Fluorescence (SIF) correlation"
        ],
        "paper_type": "the paper type is **technical**.\n\n**reasoning:**\n\n*   **abstract:** explicitly states \"we provide a global, long-term carbon flux dataset... generated using meta-learning, called metaflux.\" it then details the technical approach: \"the idea behind meta-learning stems from the need to learn efficiently given sparse data by learning how to learn broad features across tasks to better infer other poorly sampled ones. using meta-trained ensemble of deep models, we generate global carbon products...\" this clearly describes a new method/system (\"meta-learning,\" \"meta-trained ensemble of deep models\") used to \"generate\" a new product/dataset.\n*   **introduction:** discusses a \"prevalent challenge in climate science and ecology\" (data sparsity), which is the technical problem the paper addresses. it then highlights the performance of their proposed solution: \"metaflux outperformed other machine-learning based carbon product, especially in the tropics and semi-arids by 10–40%.\" this indicates the presentation and evaluation of a new method or system.\n\nthe language used (\"generated using meta-learning,\" \"meta-trained ensemble of deep models,\" \"we generate,\" \"outperformed other machine-learning based carbon product\") directly aligns with the criteria for a **technical** paper, which \"presents new methods, algorithms, or systems.\""
      },
      "file_name": "1d421d179a2520ba23dc1375fe2989e4ba79b437.pdf"
    },
    {
      "success": true,
      "doc_id": "e91a6c6c8f281750bb532398e340c973",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/63275bb3009b3ec76a51491f5732ab130621b813.pdf",
      "citation_key": "singh2023zo5",
      "metadata": {
        "title": "Meta-Health: Learning-to-Learn (Meta-learning) as a Next Generation of Deep Learning Exploring Healthcare Challenges and Solutions for Rare Disorders: A Systematic Analysis",
        "authors": [
          "Kuljeet Singh",
          "Deepti Malhotra"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/63275bb3009b3ec76a51491f5732ab130621b813.pdf",
        "venue": "Archives of Computational Methods in Engineering",
        "citationCount": 22,
        "score": 11.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "63275bb3009b3ec76a51491f5732ab130621b813.pdf"
    },
    {
      "success": true,
      "doc_id": "b6519fd245fdffab91ce924fa05b10ae",
      "summary": "Deep learning for bearing fault diagnosis often requires a large quantity of comprehensive data to give support in the field of rotating machinery fault diagnosis. However, large-quantity datasets for model training are difficult to obtain in actual working environments. Therefore, bearing fault diagnosis problems under practical working conditions are often considered few-shot problems. Meta-learning can be adopted to solve these few-shot problems. Traditional meta-learning methods, however, can lead to model overfitting, and shallow neural networks are usually used to avoid overfitting. As a result, the features extracted by the shallow neural network are insufficiently rich to exploit the optimal performance of the model. A few-shot fault diagnosis method based on meta-learning, named meta-transfer learning with freezing operation (MTLFO), is proposed in this study to solve these problems. MTLFO can learn new knowledge rapidly through a small number of samples. The hyperparameter self-regulation ability of meta-learning is adopted by MTLFO, and a freezing operation is used to deal with the neuronal nature of meta-learning to ensure that the neurons from different tasks are transferred by utilizing scaling and shifting. MTLFO avoids the overfitting problem in traditional meta-learning methods and presents more advantages in solving few-shot problems in fault diagnosis compared with other types of methods.",
      "intriguing_abstract": "Deep learning for bearing fault diagnosis often requires a large quantity of comprehensive data to give support in the field of rotating machinery fault diagnosis. However, large-quantity datasets for model training are difficult to obtain in actual working environments. Therefore, bearing fault diagnosis problems under practical working conditions are often considered few-shot problems. Meta-learning can be adopted to solve these few-shot problems. Traditional meta-learning methods, however, can lead to model overfitting, and shallow neural networks are usually used to avoid overfitting. As a result, the features extracted by the shallow neural network are insufficiently rich to exploit the optimal performance of the model. A few-shot fault diagnosis method based on meta-learning, named meta-transfer learning with freezing operation (MTLFO), is proposed in this study to solve these problems. MTLFO can learn new knowledge rapidly through a small number of samples. The hyperparameter self-regulation ability of meta-learning is adopted by MTLFO, and a freezing operation is used to deal with the neuronal nature of meta-learning to ensure that the neurons from different tasks are transferred by utilizing scaling and shifting. MTLFO avoids the overfitting problem in traditional meta-learning methods and presents more advantages in solving few-shot problems in fault diagnosis compared with other types of methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5a8a079d30d40fc24565db7f1687d22dc323d24e.pdf",
      "citation_key": "wang2023srr",
      "metadata": {
        "title": "A new meta-transfer learning method with freezing operation for few-shot bearing fault diagnosis",
        "authors": [
          "Peiqi Wang",
          "Jingde Li",
          "Shubei Wang",
          "Fusheng Zhang",
          "Juanjuan Shi",
          "Changqing Shen"
        ],
        "published_date": "2023",
        "abstract": "Deep learning for bearing fault diagnosis often requires a large quantity of comprehensive data to give support in the field of rotating machinery fault diagnosis. However, large-quantity datasets for model training are difficult to obtain in actual working environments. Therefore, bearing fault diagnosis problems under practical working conditions are often considered few-shot problems. Meta-learning can be adopted to solve these few-shot problems. Traditional meta-learning methods, however, can lead to model overfitting, and shallow neural networks are usually used to avoid overfitting. As a result, the features extracted by the shallow neural network are insufficiently rich to exploit the optimal performance of the model. A few-shot fault diagnosis method based on meta-learning, named meta-transfer learning with freezing operation (MTLFO), is proposed in this study to solve these problems. MTLFO can learn new knowledge rapidly through a small number of samples. The hyperparameter self-regulation ability of meta-learning is adopted by MTLFO, and a freezing operation is used to deal with the neuronal nature of meta-learning to ensure that the neurons from different tasks are transferred by utilizing scaling and shifting. MTLFO avoids the overfitting problem in traditional meta-learning methods and presents more advantages in solving few-shot problems in fault diagnosis compared with other types of methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/5a8a079d30d40fc24565db7f1687d22dc323d24e.pdf",
        "venue": "Measurement science and technology",
        "citationCount": 21,
        "score": 10.5,
        "summary": "Deep learning for bearing fault diagnosis often requires a large quantity of comprehensive data to give support in the field of rotating machinery fault diagnosis. However, large-quantity datasets for model training are difficult to obtain in actual working environments. Therefore, bearing fault diagnosis problems under practical working conditions are often considered few-shot problems. Meta-learning can be adopted to solve these few-shot problems. Traditional meta-learning methods, however, can lead to model overfitting, and shallow neural networks are usually used to avoid overfitting. As a result, the features extracted by the shallow neural network are insufficiently rich to exploit the optimal performance of the model. A few-shot fault diagnosis method based on meta-learning, named meta-transfer learning with freezing operation (MTLFO), is proposed in this study to solve these problems. MTLFO can learn new knowledge rapidly through a small number of samples. The hyperparameter self-regulation ability of meta-learning is adopted by MTLFO, and a freezing operation is used to deal with the neuronal nature of meta-learning to ensure that the neurons from different tasks are transferred by utilizing scaling and shifting. MTLFO avoids the overfitting problem in traditional meta-learning methods and presents more advantages in solving few-shot problems in fault diagnosis compared with other types of methods.",
        "keywords": []
      },
      "file_name": "5a8a079d30d40fc24565db7f1687d22dc323d24e.pdf"
    },
    {
      "success": true,
      "doc_id": "16dc80dbd169a4fb8448f28c8f473c27",
      "summary": "Machine learning, especially deep learning, has been highly successful in data-intensive applications, however, the performance of these models will drop significantly when the amount of the training data amount does not meet the requirement. This leads to the so-called Few-Shot Learning (FSL) problem, which requires the model rapidly generalize to new tasks that containing only a few labeled samples. In this paper, we proposed a new deep model, called deep convolutional meta-learning networks (DCMLN), to address the low performance of generalization under limited data for bearing fault diagnosis. The essential of our approach is to learn a base model from the multiple learning tasks using a support dataset and finetune the learnt parameters using few-shot tasks before it can adapt to the new learning task based on limited training data. The proposed method was compared to several few-shot learning methods, including methods with and without pre-training the embedding mapping, and methods with finetuning the classifier or the whole model by utilizing the few-shot data from the target domain. The comparisons are carried out on one-shot and ten-shot tasks using the CWRU bearing dataset and a cylindrical roller bearing dataset. The experimental result illustrates that our method has good performance on the bearing fault diagnosis across various few-shot conditions. In addition, we found that the pre-training process does not always improve the prediction accuracy.",
      "intriguing_abstract": "Machine learning, especially deep learning, has been highly successful in data-intensive applications, however, the performance of these models will drop significantly when the amount of the training data amount does not meet the requirement. This leads to the so-called Few-Shot Learning (FSL) problem, which requires the model rapidly generalize to new tasks that containing only a few labeled samples. In this paper, we proposed a new deep model, called deep convolutional meta-learning networks (DCMLN), to address the low performance of generalization under limited data for bearing fault diagnosis. The essential of our approach is to learn a base model from the multiple learning tasks using a support dataset and finetune the learnt parameters using few-shot tasks before it can adapt to the new learning task based on limited training data. The proposed method was compared to several few-shot learning methods, including methods with and without pre-training the embedding mapping, and methods with finetuning the classifier or the whole model by utilizing the few-shot data from the target domain. The comparisons are carried out on one-shot and ten-shot tasks using the CWRU bearing dataset and a cylindrical roller bearing dataset. The experimental result illustrates that our method has good performance on the bearing fault diagnosis across various few-shot conditions. In addition, we found that the pre-training process does not always improve the prediction accuracy.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c51a16812ae6aaf4fc6692eadb96878c1a1d26d3.pdf",
      "citation_key": "liang2023zzh",
      "metadata": {
        "title": "A Novel Deep Model with Meta-learning for Rolling Bearing Few-shot Fault Diagnosis",
        "authors": [
          "Xiaoxia Liang",
          "M. Zhang",
          "Guojin Feng",
          "Yuchun Yu",
          "D. Zhen",
          "F. Gu"
        ],
        "published_date": "2023",
        "abstract": "Machine learning, especially deep learning, has been highly successful in data-intensive applications, however, the performance of these models will drop significantly when the amount of the training data amount does not meet the requirement. This leads to the so-called Few-Shot Learning (FSL) problem, which requires the model rapidly generalize to new tasks that containing only a few labeled samples. In this paper, we proposed a new deep model, called deep convolutional meta-learning networks (DCMLN), to address the low performance of generalization under limited data for bearing fault diagnosis. The essential of our approach is to learn a base model from the multiple learning tasks using a support dataset and finetune the learnt parameters using few-shot tasks before it can adapt to the new learning task based on limited training data. The proposed method was compared to several few-shot learning methods, including methods with and without pre-training the embedding mapping, and methods with finetuning the classifier or the whole model by utilizing the few-shot data from the target domain. The comparisons are carried out on one-shot and ten-shot tasks using the CWRU bearing dataset and a cylindrical roller bearing dataset. The experimental result illustrates that our method has good performance on the bearing fault diagnosis across various few-shot conditions. In addition, we found that the pre-training process does not always improve the prediction accuracy.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c51a16812ae6aaf4fc6692eadb96878c1a1d26d3.pdf",
        "venue": "Journal of Dynamics Monitoring and Diagnostics",
        "citationCount": 19,
        "score": 9.5,
        "summary": "Machine learning, especially deep learning, has been highly successful in data-intensive applications, however, the performance of these models will drop significantly when the amount of the training data amount does not meet the requirement. This leads to the so-called Few-Shot Learning (FSL) problem, which requires the model rapidly generalize to new tasks that containing only a few labeled samples. In this paper, we proposed a new deep model, called deep convolutional meta-learning networks (DCMLN), to address the low performance of generalization under limited data for bearing fault diagnosis. The essential of our approach is to learn a base model from the multiple learning tasks using a support dataset and finetune the learnt parameters using few-shot tasks before it can adapt to the new learning task based on limited training data. The proposed method was compared to several few-shot learning methods, including methods with and without pre-training the embedding mapping, and methods with finetuning the classifier or the whole model by utilizing the few-shot data from the target domain. The comparisons are carried out on one-shot and ten-shot tasks using the CWRU bearing dataset and a cylindrical roller bearing dataset. The experimental result illustrates that our method has good performance on the bearing fault diagnosis across various few-shot conditions. In addition, we found that the pre-training process does not always improve the prediction accuracy.",
        "keywords": []
      },
      "file_name": "c51a16812ae6aaf4fc6692eadb96878c1a1d26d3.pdf"
    },
    {
      "success": true,
      "doc_id": "a17f4de08826c8e667bde8dc80edf429",
      "summary": "Meta-learning provides a promising way for deep learning models to efficiently learn in few-shot learning. With this capacity, many deep learning systems can be applied in many real applications. However, many existing meta-learning based few-shot learning systems suffer from vulnerable generalization when new tasks are from unseen domains (a.k.a, cross-domain few-shot learning). In this work, we consider this problem from the perspective of designing a model-agnostic meta-training framework to improve the generalization of existing meta-learning methods in cross-domain few-shot learning. In this way, compared with focusing on elaborately designing modules for a specific meta-learning model, our method is endowed with the ability to be compatible with different meta-learning models in various few-shot problems. To achieve this goal, a novel adversarial meta-training framework is proposed. The proposed framework utilizes max-min episodic iteration. In the episode of maximization, our framework focuses on how to dynamically generate appropriate pseudo tasks which benefit learning cross-domain knowledge. In the episode of minimization, our method aims to solve how to help meta-learning model learn cross-task and robust meta-knowledge. To comprehensively evaluate our framework, experiments are conducted on two few-shot learning settings, three meta-learning models, and eight datasets. These results demonstrate that our method is applicable to various meta-learning models in different few-shot learning problems. The superiority of our method is verified compared with existing state-of-the-art methods.",
      "intriguing_abstract": "Meta-learning provides a promising way for deep learning models to efficiently learn in few-shot learning. With this capacity, many deep learning systems can be applied in many real applications. However, many existing meta-learning based few-shot learning systems suffer from vulnerable generalization when new tasks are from unseen domains (a.k.a, cross-domain few-shot learning). In this work, we consider this problem from the perspective of designing a model-agnostic meta-training framework to improve the generalization of existing meta-learning methods in cross-domain few-shot learning. In this way, compared with focusing on elaborately designing modules for a specific meta-learning model, our method is endowed with the ability to be compatible with different meta-learning models in various few-shot problems. To achieve this goal, a novel adversarial meta-training framework is proposed. The proposed framework utilizes max-min episodic iteration. In the episode of maximization, our framework focuses on how to dynamically generate appropriate pseudo tasks which benefit learning cross-domain knowledge. In the episode of minimization, our method aims to solve how to help meta-learning model learn cross-task and robust meta-knowledge. To comprehensively evaluate our framework, experiments are conducted on two few-shot learning settings, three meta-learning models, and eight datasets. These results demonstrate that our method is applicable to various meta-learning models in different few-shot learning problems. The superiority of our method is verified compared with existing state-of-the-art methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/eeb0407b2f47857fe7b44c948c08ef23469a8ad2.pdf",
      "citation_key": "tian2023iyh",
      "metadata": {
        "title": "An Adversarial Meta-Training Framework for Cross-Domain Few-Shot Learning",
        "authors": [
          "Pinzhuo Tian",
          "Shaorong Xie"
        ],
        "published_date": "2023",
        "abstract": "Meta-learning provides a promising way for deep learning models to efficiently learn in few-shot learning. With this capacity, many deep learning systems can be applied in many real applications. However, many existing meta-learning based few-shot learning systems suffer from vulnerable generalization when new tasks are from unseen domains (a.k.a, cross-domain few-shot learning). In this work, we consider this problem from the perspective of designing a model-agnostic meta-training framework to improve the generalization of existing meta-learning methods in cross-domain few-shot learning. In this way, compared with focusing on elaborately designing modules for a specific meta-learning model, our method is endowed with the ability to be compatible with different meta-learning models in various few-shot problems. To achieve this goal, a novel adversarial meta-training framework is proposed. The proposed framework utilizes max-min episodic iteration. In the episode of maximization, our framework focuses on how to dynamically generate appropriate pseudo tasks which benefit learning cross-domain knowledge. In the episode of minimization, our method aims to solve how to help meta-learning model learn cross-task and robust meta-knowledge. To comprehensively evaluate our framework, experiments are conducted on two few-shot learning settings, three meta-learning models, and eight datasets. These results demonstrate that our method is applicable to various meta-learning models in different few-shot learning problems. The superiority of our method is verified compared with existing state-of-the-art methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/eeb0407b2f47857fe7b44c948c08ef23469a8ad2.pdf",
        "venue": "IEEE transactions on multimedia",
        "citationCount": 19,
        "score": 9.5,
        "summary": "Meta-learning provides a promising way for deep learning models to efficiently learn in few-shot learning. With this capacity, many deep learning systems can be applied in many real applications. However, many existing meta-learning based few-shot learning systems suffer from vulnerable generalization when new tasks are from unseen domains (a.k.a, cross-domain few-shot learning). In this work, we consider this problem from the perspective of designing a model-agnostic meta-training framework to improve the generalization of existing meta-learning methods in cross-domain few-shot learning. In this way, compared with focusing on elaborately designing modules for a specific meta-learning model, our method is endowed with the ability to be compatible with different meta-learning models in various few-shot problems. To achieve this goal, a novel adversarial meta-training framework is proposed. The proposed framework utilizes max-min episodic iteration. In the episode of maximization, our framework focuses on how to dynamically generate appropriate pseudo tasks which benefit learning cross-domain knowledge. In the episode of minimization, our method aims to solve how to help meta-learning model learn cross-task and robust meta-knowledge. To comprehensively evaluate our framework, experiments are conducted on two few-shot learning settings, three meta-learning models, and eight datasets. These results demonstrate that our method is applicable to various meta-learning models in different few-shot learning problems. The superiority of our method is verified compared with existing state-of-the-art methods.",
        "keywords": []
      },
      "file_name": "eeb0407b2f47857fe7b44c948c08ef23469a8ad2.pdf"
    },
    {
      "success": true,
      "doc_id": "a3203d399e0b53677187b5e808985cf7",
      "summary": "Using single-task deep learning methods to reconstruct Magnetic Resonance Imaging (MRI) data acquired with different imaging sequences is inherently challenging. The trained deep learning model typically lacks generalizability, and the dissimilarity among image datasets with different types of contrast leads to suboptimal learning performance. This paper proposes a meta-learning approach to efficiently learn image features from multiple MRI datasets. Our algorithm can perform multi-task learning to simultaneously reconstruct MRI images acquired using different imaging sequences with various image contrasts. We have developed a proximal gradient descent-inspired optimization method to learn image features across image and k-space domains, ensuring high-performance learning for every image contrast. Meanwhile, meta-learning, a \"learning-to-learn\" process, is incorporated into our framework to improve the learning of mutual features embedded in multiple image contrasts. The experimental results reveal that our proposed multi-task meta-learning approach surpasses state-of-the-art single-task learning methods at high acceleration rates. Our meta-learning consistently delivers accurate and detailed reconstructions, achieves the lowest pixel-wise errors, and significantly enhances qualitative performance across all tested acceleration rates. We have demonstrated the ability of our new meta-learning reconstruction method to successfully reconstruct highly-undersampled k-space data from multiple MRI datasets simultaneously, outperforming other compelling reconstruction methods previously developed for single-task learning.",
      "intriguing_abstract": "Using single-task deep learning methods to reconstruct Magnetic Resonance Imaging (MRI) data acquired with different imaging sequences is inherently challenging. The trained deep learning model typically lacks generalizability, and the dissimilarity among image datasets with different types of contrast leads to suboptimal learning performance. This paper proposes a meta-learning approach to efficiently learn image features from multiple MRI datasets. Our algorithm can perform multi-task learning to simultaneously reconstruct MRI images acquired using different imaging sequences with various image contrasts. We have developed a proximal gradient descent-inspired optimization method to learn image features across image and k-space domains, ensuring high-performance learning for every image contrast. Meanwhile, meta-learning, a \"learning-to-learn\" process, is incorporated into our framework to improve the learning of mutual features embedded in multiple image contrasts. The experimental results reveal that our proposed multi-task meta-learning approach surpasses state-of-the-art single-task learning methods at high acceleration rates. Our meta-learning consistently delivers accurate and detailed reconstructions, achieves the lowest pixel-wise errors, and significantly enhances qualitative performance across all tested acceleration rates. We have demonstrated the ability of our new meta-learning reconstruction method to successfully reconstruct highly-undersampled k-space data from multiple MRI datasets simultaneously, outperforming other compelling reconstruction methods previously developed for single-task learning.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b8a16fd8d823cfe683c19d58bec77a023b5bf1ef.pdf",
      "citation_key": "bian2024041",
      "metadata": {
        "title": "Multi-task Magnetic Resonance Imaging Reconstruction using Meta-learning",
        "authors": [
          "Wanyu Bian",
          "Albert Jang",
          "Fang Liu"
        ],
        "published_date": "2024",
        "abstract": "Using single-task deep learning methods to reconstruct Magnetic Resonance Imaging (MRI) data acquired with different imaging sequences is inherently challenging. The trained deep learning model typically lacks generalizability, and the dissimilarity among image datasets with different types of contrast leads to suboptimal learning performance. This paper proposes a meta-learning approach to efficiently learn image features from multiple MRI datasets. Our algorithm can perform multi-task learning to simultaneously reconstruct MRI images acquired using different imaging sequences with various image contrasts. We have developed a proximal gradient descent-inspired optimization method to learn image features across image and k-space domains, ensuring high-performance learning for every image contrast. Meanwhile, meta-learning, a \"learning-to-learn\" process, is incorporated into our framework to improve the learning of mutual features embedded in multiple image contrasts. The experimental results reveal that our proposed multi-task meta-learning approach surpasses state-of-the-art single-task learning methods at high acceleration rates. Our meta-learning consistently delivers accurate and detailed reconstructions, achieves the lowest pixel-wise errors, and significantly enhances qualitative performance across all tested acceleration rates. We have demonstrated the ability of our new meta-learning reconstruction method to successfully reconstruct highly-undersampled k-space data from multiple MRI datasets simultaneously, outperforming other compelling reconstruction methods previously developed for single-task learning.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b8a16fd8d823cfe683c19d58bec77a023b5bf1ef.pdf",
        "venue": "Magnetic Resonance Imaging",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Using single-task deep learning methods to reconstruct Magnetic Resonance Imaging (MRI) data acquired with different imaging sequences is inherently challenging. The trained deep learning model typically lacks generalizability, and the dissimilarity among image datasets with different types of contrast leads to suboptimal learning performance. This paper proposes a meta-learning approach to efficiently learn image features from multiple MRI datasets. Our algorithm can perform multi-task learning to simultaneously reconstruct MRI images acquired using different imaging sequences with various image contrasts. We have developed a proximal gradient descent-inspired optimization method to learn image features across image and k-space domains, ensuring high-performance learning for every image contrast. Meanwhile, meta-learning, a \"learning-to-learn\" process, is incorporated into our framework to improve the learning of mutual features embedded in multiple image contrasts. The experimental results reveal that our proposed multi-task meta-learning approach surpasses state-of-the-art single-task learning methods at high acceleration rates. Our meta-learning consistently delivers accurate and detailed reconstructions, achieves the lowest pixel-wise errors, and significantly enhances qualitative performance across all tested acceleration rates. We have demonstrated the ability of our new meta-learning reconstruction method to successfully reconstruct highly-undersampled k-space data from multiple MRI datasets simultaneously, outperforming other compelling reconstruction methods previously developed for single-task learning.",
        "keywords": []
      },
      "file_name": "b8a16fd8d823cfe683c19d58bec77a023b5bf1ef.pdf"
    },
    {
      "success": true,
      "doc_id": "951a183e9d7f735bdc886ba3abdc44c7",
      "summary": "Recent work in Deep Learning has re-imagined the representation of data as functions mapping from a coordinate space to an underlying continuous signal. When such functions are approximated by neural networks this introduces a compelling alternative to the more common multi-dimensional array representation. Recent work on such Implicit Neural Representations (INRs) has shown that - following careful architecture search - INRs can outperform established compression methods such as JPEG (e.g. Dupont et al., 2021). In this paper, we propose crucial steps towards making such ideas scalable: Firstly, we employ state-of-the-art network sparsification techniques to drastically improve compression. Secondly, introduce the first method allowing for sparsification to be employed in the inner-loop of commonly used Meta-Learning algorithms, drastically improving both compression and the computational cost of learning INRs. The generality of this formalism allows us to present results on diverse data modalities such as images, manifolds, signed distance functions, 3D shapes and scenes, several of which establish new state-of-the-art results.",
      "intriguing_abstract": "Recent work in Deep Learning has re-imagined the representation of data as functions mapping from a coordinate space to an underlying continuous signal. When such functions are approximated by neural networks this introduces a compelling alternative to the more common multi-dimensional array representation. Recent work on such Implicit Neural Representations (INRs) has shown that - following careful architecture search - INRs can outperform established compression methods such as JPEG (e.g. Dupont et al., 2021). In this paper, we propose crucial steps towards making such ideas scalable: Firstly, we employ state-of-the-art network sparsification techniques to drastically improve compression. Secondly, introduce the first method allowing for sparsification to be employed in the inner-loop of commonly used Meta-Learning algorithms, drastically improving both compression and the computational cost of learning INRs. The generality of this formalism allows us to present results on diverse data modalities such as images, manifolds, signed distance functions, 3D shapes and scenes, several of which establish new state-of-the-art results.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2270ebe7d3ee925abbc062b937aa43805c702cf9.pdf",
      "citation_key": "schwarz2022jfu",
      "metadata": {
        "title": "Meta-Learning Sparse Compression Networks",
        "authors": [
          "Jonathan Schwarz",
          "Y. Teh"
        ],
        "published_date": "2022",
        "abstract": "Recent work in Deep Learning has re-imagined the representation of data as functions mapping from a coordinate space to an underlying continuous signal. When such functions are approximated by neural networks this introduces a compelling alternative to the more common multi-dimensional array representation. Recent work on such Implicit Neural Representations (INRs) has shown that - following careful architecture search - INRs can outperform established compression methods such as JPEG (e.g. Dupont et al., 2021). In this paper, we propose crucial steps towards making such ideas scalable: Firstly, we employ state-of-the-art network sparsification techniques to drastically improve compression. Secondly, introduce the first method allowing for sparsification to be employed in the inner-loop of commonly used Meta-Learning algorithms, drastically improving both compression and the computational cost of learning INRs. The generality of this formalism allows us to present results on diverse data modalities such as images, manifolds, signed distance functions, 3D shapes and scenes, several of which establish new state-of-the-art results.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2270ebe7d3ee925abbc062b937aa43805c702cf9.pdf",
        "venue": "Trans. Mach. Learn. Res.",
        "citationCount": 27,
        "score": 9.0,
        "summary": "Recent work in Deep Learning has re-imagined the representation of data as functions mapping from a coordinate space to an underlying continuous signal. When such functions are approximated by neural networks this introduces a compelling alternative to the more common multi-dimensional array representation. Recent work on such Implicit Neural Representations (INRs) has shown that - following careful architecture search - INRs can outperform established compression methods such as JPEG (e.g. Dupont et al., 2021). In this paper, we propose crucial steps towards making such ideas scalable: Firstly, we employ state-of-the-art network sparsification techniques to drastically improve compression. Secondly, introduce the first method allowing for sparsification to be employed in the inner-loop of commonly used Meta-Learning algorithms, drastically improving both compression and the computational cost of learning INRs. The generality of this formalism allows us to present results on diverse data modalities such as images, manifolds, signed distance functions, 3D shapes and scenes, several of which establish new state-of-the-art results.",
        "keywords": []
      },
      "file_name": "2270ebe7d3ee925abbc062b937aa43805c702cf9.pdf"
    },
    {
      "success": true,
      "doc_id": "62a04cf3ce2ac0c3499f581f47a9680e",
      "summary": "Over the past decade, deep neural networks have demonstrated significant success using the training scheme that involves mini-batch stochastic gradient descent on extensive datasets. Expanding upon this accomplishment, there has been a surge in research exploring the application of neural networks in other learning scenarios. One notable framework that has garnered significant attention is meta-learning. Often described as “learning to learn,” meta-learning is a data-driven approach to optimize the learning algorithm. Other branches of interest are continual learning and online learning, both of which involve incrementally updating a model with streaming data. While these frameworks were initially developed independently, recent works have started investigating their combinations, proposing novel problem settings and learning algorithms. However, due to the elevated complexity and lack of unified terminology, discerning differences between the learning frameworks can be challenging even for experienced researchers. To facilitate a clear understanding, this paper provides a comprehensive survey that organizes various problem settings using consistent terminology and formal descriptions. By offering an overview of these learning paradigms, our work aims to foster further advancements in this promising area of research.",
      "intriguing_abstract": "Over the past decade, deep neural networks have demonstrated significant success using the training scheme that involves mini-batch stochastic gradient descent on extensive datasets. Expanding upon this accomplishment, there has been a surge in research exploring the application of neural networks in other learning scenarios. One notable framework that has garnered significant attention is meta-learning. Often described as “learning to learn,” meta-learning is a data-driven approach to optimize the learning algorithm. Other branches of interest are continual learning and online learning, both of which involve incrementally updating a model with streaming data. While these frameworks were initially developed independently, recent works have started investigating their combinations, proposing novel problem settings and learning algorithms. However, due to the elevated complexity and lack of unified terminology, discerning differences between the learning frameworks can be challenging even for experienced researchers. To facilitate a clear understanding, this paper provides a comprehensive survey that organizes various problem settings using consistent terminology and formal descriptions. By offering an overview of these learning paradigms, our work aims to foster further advancements in this promising area of research.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/04396f17e2bdc848300b8670104895b0b3fee84f.pdf",
      "citation_key": "son2023lda",
      "metadata": {
        "title": "When Meta-Learning Meets Online and Continual Learning: A Survey",
        "authors": [
          "Jaehyeon Son",
          "Soochan Lee",
          "Gunhee Kim"
        ],
        "published_date": "2023",
        "abstract": "Over the past decade, deep neural networks have demonstrated significant success using the training scheme that involves mini-batch stochastic gradient descent on extensive datasets. Expanding upon this accomplishment, there has been a surge in research exploring the application of neural networks in other learning scenarios. One notable framework that has garnered significant attention is meta-learning. Often described as “learning to learn,” meta-learning is a data-driven approach to optimize the learning algorithm. Other branches of interest are continual learning and online learning, both of which involve incrementally updating a model with streaming data. While these frameworks were initially developed independently, recent works have started investigating their combinations, proposing novel problem settings and learning algorithms. However, due to the elevated complexity and lack of unified terminology, discerning differences between the learning frameworks can be challenging even for experienced researchers. To facilitate a clear understanding, this paper provides a comprehensive survey that organizes various problem settings using consistent terminology and formal descriptions. By offering an overview of these learning paradigms, our work aims to foster further advancements in this promising area of research.",
        "file_path": "paper_data/Deep_Meta-Learning/info/04396f17e2bdc848300b8670104895b0b3fee84f.pdf",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "citationCount": 16,
        "score": 8.0,
        "summary": "Over the past decade, deep neural networks have demonstrated significant success using the training scheme that involves mini-batch stochastic gradient descent on extensive datasets. Expanding upon this accomplishment, there has been a surge in research exploring the application of neural networks in other learning scenarios. One notable framework that has garnered significant attention is meta-learning. Often described as “learning to learn,” meta-learning is a data-driven approach to optimize the learning algorithm. Other branches of interest are continual learning and online learning, both of which involve incrementally updating a model with streaming data. While these frameworks were initially developed independently, recent works have started investigating their combinations, proposing novel problem settings and learning algorithms. However, due to the elevated complexity and lack of unified terminology, discerning differences between the learning frameworks can be challenging even for experienced researchers. To facilitate a clear understanding, this paper provides a comprehensive survey that organizes various problem settings using consistent terminology and formal descriptions. By offering an overview of these learning paradigms, our work aims to foster further advancements in this promising area of research.",
        "keywords": []
      },
      "file_name": "04396f17e2bdc848300b8670104895b0b3fee84f.pdf"
    },
    {
      "success": true,
      "doc_id": "877c74dcd7b9764f1a023c0c5f3b2f86",
      "summary": "The fluctuation of pantograph–catenary contact force seriously affects the current collection quality, maintenance cost, and operation safety of high-speed trains. In recent years, agents developed with deep reinforcement learning (DRL) technology have achieved significant success. However, most of these jobs are restricted to narrow task distributions and stationary environments, which require a large amount of training data and cannot adapt quickly to the new task. We propose a contrastive learning-based Bayes-adaptive meta-reinforcement learning (CBAMRL) algorithm that addresses these limitations, enabling agents to learn new skills from a few transitions and adapt to the new environment. We first introduce a Bayes-adaptive training strategy, achieving zero-shot adaptation in nonstationary environments with high sample efficiency and competitive asymptotic performance. We proposed a contrastive learning-based contextual encoder to represent complex task distributions with similar structures, providing compact and sufficient task representation without modeling irrelevant dependencies. We evaluate the proposed method on a validated pantograph–catenary system (PCS) benchmark. Compared to the state-of-the-art DRL approach and traditional solutions, the experiment result demonstrates that the proposed algorithm can swiftly adapt to new operating circumstances and unknown perturbations with well-structured task representation and zero-shot adaptation.",
      "intriguing_abstract": "The fluctuation of pantograph–catenary contact force seriously affects the current collection quality, maintenance cost, and operation safety of high-speed trains. In recent years, agents developed with deep reinforcement learning (DRL) technology have achieved significant success. However, most of these jobs are restricted to narrow task distributions and stationary environments, which require a large amount of training data and cannot adapt quickly to the new task. We propose a contrastive learning-based Bayes-adaptive meta-reinforcement learning (CBAMRL) algorithm that addresses these limitations, enabling agents to learn new skills from a few transitions and adapt to the new environment. We first introduce a Bayes-adaptive training strategy, achieving zero-shot adaptation in nonstationary environments with high sample efficiency and competitive asymptotic performance. We proposed a contrastive learning-based contextual encoder to represent complex task distributions with similar structures, providing compact and sufficient task representation without modeling irrelevant dependencies. We evaluate the proposed method on a validated pantograph–catenary system (PCS) benchmark. Compared to the state-of-the-art DRL approach and traditional solutions, the experiment result demonstrates that the proposed algorithm can swiftly adapt to new operating circumstances and unknown perturbations with well-structured task representation and zero-shot adaptation.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/8d6d320dbe9bdd6a1ea844faaf3dc0f5fff2543b.pdf",
      "citation_key": "wang2024d09",
      "metadata": {
        "title": "Contrastive Learning-Based Bayes-Adaptive Meta-Reinforcement Learning for Active Pantograph Control in High-Speed Railways",
        "authors": [
          "Hui Wang",
          "Zhiwei Han",
          "Xufan Wang",
          "Yanbo Wu",
          "Zhigang Liu"
        ],
        "published_date": "2024",
        "abstract": "The fluctuation of pantograph–catenary contact force seriously affects the current collection quality, maintenance cost, and operation safety of high-speed trains. In recent years, agents developed with deep reinforcement learning (DRL) technology have achieved significant success. However, most of these jobs are restricted to narrow task distributions and stationary environments, which require a large amount of training data and cannot adapt quickly to the new task. We propose a contrastive learning-based Bayes-adaptive meta-reinforcement learning (CBAMRL) algorithm that addresses these limitations, enabling agents to learn new skills from a few transitions and adapt to the new environment. We first introduce a Bayes-adaptive training strategy, achieving zero-shot adaptation in nonstationary environments with high sample efficiency and competitive asymptotic performance. We proposed a contrastive learning-based contextual encoder to represent complex task distributions with similar structures, providing compact and sufficient task representation without modeling irrelevant dependencies. We evaluate the proposed method on a validated pantograph–catenary system (PCS) benchmark. Compared to the state-of-the-art DRL approach and traditional solutions, the experiment result demonstrates that the proposed algorithm can swiftly adapt to new operating circumstances and unknown perturbations with well-structured task representation and zero-shot adaptation.",
        "file_path": "paper_data/Deep_Meta-Learning/info/8d6d320dbe9bdd6a1ea844faaf3dc0f5fff2543b.pdf",
        "venue": "IEEE Transactions on Transportation Electrification",
        "citationCount": 8,
        "score": 8.0,
        "summary": "The fluctuation of pantograph–catenary contact force seriously affects the current collection quality, maintenance cost, and operation safety of high-speed trains. In recent years, agents developed with deep reinforcement learning (DRL) technology have achieved significant success. However, most of these jobs are restricted to narrow task distributions and stationary environments, which require a large amount of training data and cannot adapt quickly to the new task. We propose a contrastive learning-based Bayes-adaptive meta-reinforcement learning (CBAMRL) algorithm that addresses these limitations, enabling agents to learn new skills from a few transitions and adapt to the new environment. We first introduce a Bayes-adaptive training strategy, achieving zero-shot adaptation in nonstationary environments with high sample efficiency and competitive asymptotic performance. We proposed a contrastive learning-based contextual encoder to represent complex task distributions with similar structures, providing compact and sufficient task representation without modeling irrelevant dependencies. We evaluate the proposed method on a validated pantograph–catenary system (PCS) benchmark. Compared to the state-of-the-art DRL approach and traditional solutions, the experiment result demonstrates that the proposed algorithm can swiftly adapt to new operating circumstances and unknown perturbations with well-structured task representation and zero-shot adaptation.",
        "keywords": []
      },
      "file_name": "8d6d320dbe9bdd6a1ea844faaf3dc0f5fff2543b.pdf"
    },
    {
      "success": true,
      "doc_id": "790183219cb70db9be385f2622c24b25",
      "summary": "With rapid advancements in depth sensors and deep learning, skeleton-based person re-identification (re-ID) models have recently achieved remarkable progress with many advantages. Most existing solutions learn single-level skeleton features from body joints with the assumption of equal skeleton importance, while they typically lack the ability to exploit more informative skeleton features from various levels such as limb level with more global body patterns. The label dependency of these methods also limits their flexibility in learning more general skeleton representations. This paper proposes a generic unsupervised Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) approach with Hard Skeleton Mining (HSM) for person re-ID with unlabeled 3D skeletons. Firstly, we construct hierarchical representations of skeletons to model coarse-to-fine body and motion features from the levels of body joints, components, and limbs. Then a hierarchical meta-prototype contrastive learning model is proposed to cluster and contrast the most typical skeleton features (\"prototypes\") from different-level skeletons. By converting original prototypes into meta-prototypes with multiple homogeneous transformations, we induce the model to learn the inherent consistency of prototypes to capture more effective skeleton features for person re-ID. Furthermore, we devise a hard skeleton mining mechanism to adaptively infer the informative importance of each skeleton, so as to focus on harder skeletons to learn more discriminative skeleton representations. Extensive evaluations on five datasets demonstrate that our approach outperforms a wide variety of state-of-the-art skeleton-based methods. We further show the general applicability of our method to cross-view person re-ID and RGB-based scenarios with estimated skeletons.",
      "intriguing_abstract": "With rapid advancements in depth sensors and deep learning, skeleton-based person re-identification (re-ID) models have recently achieved remarkable progress with many advantages. Most existing solutions learn single-level skeleton features from body joints with the assumption of equal skeleton importance, while they typically lack the ability to exploit more informative skeleton features from various levels such as limb level with more global body patterns. The label dependency of these methods also limits their flexibility in learning more general skeleton representations. This paper proposes a generic unsupervised Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) approach with Hard Skeleton Mining (HSM) for person re-ID with unlabeled 3D skeletons. Firstly, we construct hierarchical representations of skeletons to model coarse-to-fine body and motion features from the levels of body joints, components, and limbs. Then a hierarchical meta-prototype contrastive learning model is proposed to cluster and contrast the most typical skeleton features (\"prototypes\") from different-level skeletons. By converting original prototypes into meta-prototypes with multiple homogeneous transformations, we induce the model to learn the inherent consistency of prototypes to capture more effective skeleton features for person re-ID. Furthermore, we devise a hard skeleton mining mechanism to adaptively infer the informative importance of each skeleton, so as to focus on harder skeletons to learn more discriminative skeleton representations. Extensive evaluations on five datasets demonstrate that our approach outperforms a wide variety of state-of-the-art skeleton-based methods. We further show the general applicability of our method to cross-view person re-ID and RGB-based scenarios with estimated skeletons.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/9d951d22e54e49d60cbc001be6446a03ce4898b1.pdf",
      "citation_key": "rao20232e3",
      "metadata": {
        "title": "Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard Skeleton Mining for Unsupervised Person Re-Identification",
        "authors": [
          "Haocong Rao",
          "Cyril Leung",
          "Chun Miao"
        ],
        "published_date": "2023",
        "abstract": "With rapid advancements in depth sensors and deep learning, skeleton-based person re-identification (re-ID) models have recently achieved remarkable progress with many advantages. Most existing solutions learn single-level skeleton features from body joints with the assumption of equal skeleton importance, while they typically lack the ability to exploit more informative skeleton features from various levels such as limb level with more global body patterns. The label dependency of these methods also limits their flexibility in learning more general skeleton representations. This paper proposes a generic unsupervised Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) approach with Hard Skeleton Mining (HSM) for person re-ID with unlabeled 3D skeletons. Firstly, we construct hierarchical representations of skeletons to model coarse-to-fine body and motion features from the levels of body joints, components, and limbs. Then a hierarchical meta-prototype contrastive learning model is proposed to cluster and contrast the most typical skeleton features (\"prototypes\") from different-level skeletons. By converting original prototypes into meta-prototypes with multiple homogeneous transformations, we induce the model to learn the inherent consistency of prototypes to capture more effective skeleton features for person re-ID. Furthermore, we devise a hard skeleton mining mechanism to adaptively infer the informative importance of each skeleton, so as to focus on harder skeletons to learn more discriminative skeleton representations. Extensive evaluations on five datasets demonstrate that our approach outperforms a wide variety of state-of-the-art skeleton-based methods. We further show the general applicability of our method to cross-view person re-ID and RGB-based scenarios with estimated skeletons.",
        "file_path": "paper_data/Deep_Meta-Learning/info/9d951d22e54e49d60cbc001be6446a03ce4898b1.pdf",
        "venue": "International Journal of Computer Vision",
        "citationCount": 16,
        "score": 8.0,
        "summary": "With rapid advancements in depth sensors and deep learning, skeleton-based person re-identification (re-ID) models have recently achieved remarkable progress with many advantages. Most existing solutions learn single-level skeleton features from body joints with the assumption of equal skeleton importance, while they typically lack the ability to exploit more informative skeleton features from various levels such as limb level with more global body patterns. The label dependency of these methods also limits their flexibility in learning more general skeleton representations. This paper proposes a generic unsupervised Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) approach with Hard Skeleton Mining (HSM) for person re-ID with unlabeled 3D skeletons. Firstly, we construct hierarchical representations of skeletons to model coarse-to-fine body and motion features from the levels of body joints, components, and limbs. Then a hierarchical meta-prototype contrastive learning model is proposed to cluster and contrast the most typical skeleton features (\"prototypes\") from different-level skeletons. By converting original prototypes into meta-prototypes with multiple homogeneous transformations, we induce the model to learn the inherent consistency of prototypes to capture more effective skeleton features for person re-ID. Furthermore, we devise a hard skeleton mining mechanism to adaptively infer the informative importance of each skeleton, so as to focus on harder skeletons to learn more discriminative skeleton representations. Extensive evaluations on five datasets demonstrate that our approach outperforms a wide variety of state-of-the-art skeleton-based methods. We further show the general applicability of our method to cross-view person re-ID and RGB-based scenarios with estimated skeletons.",
        "keywords": []
      },
      "file_name": "9d951d22e54e49d60cbc001be6446a03ce4898b1.pdf"
    },
    {
      "success": true,
      "doc_id": "5818bea8db2806bc75ab2f6187600d52",
      "summary": "Autonomous underwater vehicles (AUVs) may deviate from their predetermined trajectory in underwater currents due to the complex effects of hydrodynamics on their maneuverability. Model-based control methods are commonly employed to address this problem, but they suffer from issues related to the time-variability of parameters and the inaccuracy of mathematical models. To improve these, a meta-learning and self-adaptation hybrid approach is proposed in this paper to enable an underwater robot to adapt to ocean currents. Instead of using a traditional complex mathematical model, a deep neural network (DNN) serving as the basis function is trained to learn a high-order hydrodynamic model offline; then, a set of linear coefficients is adjusted dynamically by an adaptive law online. By conjoining these two strategies for real-time thrust compensation, the proposed method leverages the potent representational capacity of DNN along with the rapid response of adaptive control. This combination achieves a significant enhancement in tracking performance compared to alternative controllers, as observed in simulations. These findings substantiate that the AUV can adeptly adapt to new speeds of ocean currents.",
      "intriguing_abstract": "Autonomous underwater vehicles (AUVs) may deviate from their predetermined trajectory in underwater currents due to the complex effects of hydrodynamics on their maneuverability. Model-based control methods are commonly employed to address this problem, but they suffer from issues related to the time-variability of parameters and the inaccuracy of mathematical models. To improve these, a meta-learning and self-adaptation hybrid approach is proposed in this paper to enable an underwater robot to adapt to ocean currents. Instead of using a traditional complex mathematical model, a deep neural network (DNN) serving as the basis function is trained to learn a high-order hydrodynamic model offline; then, a set of linear coefficients is adjusted dynamically by an adaptive law online. By conjoining these two strategies for real-time thrust compensation, the proposed method leverages the potent representational capacity of DNN along with the rapid response of adaptive control. This combination achieves a significant enhancement in tracking performance compared to alternative controllers, as observed in simulations. These findings substantiate that the AUV can adeptly adapt to new speeds of ocean currents.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/cfd039fd9a929ddd08a9e65385690604070ca795.pdf",
      "citation_key": "zhang2023jz8",
      "metadata": {
        "title": "Real-Time Ocean Current Compensation for AUV Trajectory Tracking Control Using a Meta-Learning and Self-Adaptation Hybrid Approach",
        "authors": [
          "Yiqiang Zhang",
          "Jiaxing Che",
          "Yijun Hu",
          "Jiankuo Cui",
          "Jun-hong Cui"
        ],
        "published_date": "2023",
        "abstract": "Autonomous underwater vehicles (AUVs) may deviate from their predetermined trajectory in underwater currents due to the complex effects of hydrodynamics on their maneuverability. Model-based control methods are commonly employed to address this problem, but they suffer from issues related to the time-variability of parameters and the inaccuracy of mathematical models. To improve these, a meta-learning and self-adaptation hybrid approach is proposed in this paper to enable an underwater robot to adapt to ocean currents. Instead of using a traditional complex mathematical model, a deep neural network (DNN) serving as the basis function is trained to learn a high-order hydrodynamic model offline; then, a set of linear coefficients is adjusted dynamically by an adaptive law online. By conjoining these two strategies for real-time thrust compensation, the proposed method leverages the potent representational capacity of DNN along with the rapid response of adaptive control. This combination achieves a significant enhancement in tracking performance compared to alternative controllers, as observed in simulations. These findings substantiate that the AUV can adeptly adapt to new speeds of ocean currents.",
        "file_path": "paper_data/Deep_Meta-Learning/info/cfd039fd9a929ddd08a9e65385690604070ca795.pdf",
        "venue": "Italian National Conference on Sensors",
        "citationCount": 15,
        "score": 7.5,
        "summary": "Autonomous underwater vehicles (AUVs) may deviate from their predetermined trajectory in underwater currents due to the complex effects of hydrodynamics on their maneuverability. Model-based control methods are commonly employed to address this problem, but they suffer from issues related to the time-variability of parameters and the inaccuracy of mathematical models. To improve these, a meta-learning and self-adaptation hybrid approach is proposed in this paper to enable an underwater robot to adapt to ocean currents. Instead of using a traditional complex mathematical model, a deep neural network (DNN) serving as the basis function is trained to learn a high-order hydrodynamic model offline; then, a set of linear coefficients is adjusted dynamically by an adaptive law online. By conjoining these two strategies for real-time thrust compensation, the proposed method leverages the potent representational capacity of DNN along with the rapid response of adaptive control. This combination achieves a significant enhancement in tracking performance compared to alternative controllers, as observed in simulations. These findings substantiate that the AUV can adeptly adapt to new speeds of ocean currents.",
        "keywords": []
      },
      "file_name": "cfd039fd9a929ddd08a9e65385690604070ca795.pdf"
    },
    {
      "success": true,
      "doc_id": "fcf9206509d066cf96956f7bc61a4015",
      "summary": "Task scheduling is a complex problem in cloud computing, and attracts many researchers’ interests. Recently, many deep reinforcement learning (DRL)-based methods have been proposed to learn the scheduling policy through interacting with the environment. However, most DRL methods focus on a specific environment, which may lead to a weak adaptability to new environments because they have low sample efficiency and require full retraining to learn updated policies for new environments. To overcome the weakness and reduce the time consumption of adapting to new environment, we propose a task scheduling method based on meta reinforcement learning called MRLCC. Through comparing MRLCC and baseline algorithms on the performance of shortening makespan in different environments, we can find that MRLCC is able to adapt to different environments quickly and has a high sample efficiency. Besides, the experimental results demonstrate that MRLCC can maintain a high utilization rate over all baseline algorithms after a few steps of gradient update.",
      "intriguing_abstract": "Task scheduling is a complex problem in cloud computing, and attracts many researchers’ interests. Recently, many deep reinforcement learning (DRL)-based methods have been proposed to learn the scheduling policy through interacting with the environment. However, most DRL methods focus on a specific environment, which may lead to a weak adaptability to new environments because they have low sample efficiency and require full retraining to learn updated policies for new environments. To overcome the weakness and reduce the time consumption of adapting to new environment, we propose a task scheduling method based on meta reinforcement learning called MRLCC. Through comparing MRLCC and baseline algorithms on the performance of shortening makespan in different environments, we can find that MRLCC is able to adapt to different environments quickly and has a high sample efficiency. Besides, the experimental results demonstrate that MRLCC can maintain a high utilization rate over all baseline algorithms after a few steps of gradient update.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/07f72693aff855ca920dd303ae2e49b057087d5f.pdf",
      "citation_key": "xiu2023ga8",
      "metadata": {
        "title": "MRLCC: an adaptive cloud task scheduling method based on meta reinforcement learning",
        "authors": [
          "Xi Xiu",
          "Jialun Li",
          "Yujie Long",
          "Weigang Wu"
        ],
        "published_date": "2023",
        "abstract": "Task scheduling is a complex problem in cloud computing, and attracts many researchers’ interests. Recently, many deep reinforcement learning (DRL)-based methods have been proposed to learn the scheduling policy through interacting with the environment. However, most DRL methods focus on a specific environment, which may lead to a weak adaptability to new environments because they have low sample efficiency and require full retraining to learn updated policies for new environments. To overcome the weakness and reduce the time consumption of adapting to new environment, we propose a task scheduling method based on meta reinforcement learning called MRLCC. Through comparing MRLCC and baseline algorithms on the performance of shortening makespan in different environments, we can find that MRLCC is able to adapt to different environments quickly and has a high sample efficiency. Besides, the experimental results demonstrate that MRLCC can maintain a high utilization rate over all baseline algorithms after a few steps of gradient update.",
        "file_path": "paper_data/Deep_Meta-Learning/info/07f72693aff855ca920dd303ae2e49b057087d5f.pdf",
        "venue": "Journal of Cloud Computing",
        "citationCount": 14,
        "score": 7.0,
        "summary": "Task scheduling is a complex problem in cloud computing, and attracts many researchers’ interests. Recently, many deep reinforcement learning (DRL)-based methods have been proposed to learn the scheduling policy through interacting with the environment. However, most DRL methods focus on a specific environment, which may lead to a weak adaptability to new environments because they have low sample efficiency and require full retraining to learn updated policies for new environments. To overcome the weakness and reduce the time consumption of adapting to new environment, we propose a task scheduling method based on meta reinforcement learning called MRLCC. Through comparing MRLCC and baseline algorithms on the performance of shortening makespan in different environments, we can find that MRLCC is able to adapt to different environments quickly and has a high sample efficiency. Besides, the experimental results demonstrate that MRLCC can maintain a high utilization rate over all baseline algorithms after a few steps of gradient update.",
        "keywords": []
      },
      "file_name": "07f72693aff855ca920dd303ae2e49b057087d5f.pdf"
    },
    {
      "success": true,
      "doc_id": "43cf10f928600a305ba187201e94f307",
      "summary": "The widespread popularity of the Internet of human life has been accompanied by a significant increase in the cost of protecting private data from malicious attacks. Researchers have proposed many deep learning-based intrusion detection methods. However, traditional methods rely on a large number of unpolluted data to learn benign data distributions, while nonidentical distributions will affect the performance in distinguishing normal and abnormal data. To address this problem, this article proposes an intrusion detection method feedback semi-supervised learning with meta-gradient for intrusion detection (FSMG) based on feedback deep semi-supervised learning. FSMG constructs a lightweight evaluation network with slight data augmentation and nonprocessing on the same input, respectively, and uses a small amount of labeled data to infer nonidentically distributed data flows hidden in the training dataset. Then, FSMG converts malicious flows into useful information, continuously track and update the model, reducing data labeling errors. Furthermore, for the updating of gradients in the model, a bilevel nested optimization is used to ensure the model converges within $O({\\mathrm{C}}/{\\sqrt{T}})$. Unlike other semisupervised algorithms, FSMG uses labeled data and nonidentically distributed unlabeled data proportionally to construct the training dataset, achieving higher classification accuracy, and better robustness even with an 80% polluted rate.",
      "intriguing_abstract": "The widespread popularity of the Internet of human life has been accompanied by a significant increase in the cost of protecting private data from malicious attacks. Researchers have proposed many deep learning-based intrusion detection methods. However, traditional methods rely on a large number of unpolluted data to learn benign data distributions, while nonidentical distributions will affect the performance in distinguishing normal and abnormal data. To address this problem, this article proposes an intrusion detection method feedback semi-supervised learning with meta-gradient for intrusion detection (FSMG) based on feedback deep semi-supervised learning. FSMG constructs a lightweight evaluation network with slight data augmentation and nonprocessing on the same input, respectively, and uses a small amount of labeled data to infer nonidentically distributed data flows hidden in the training dataset. Then, FSMG converts malicious flows into useful information, continuously track and update the model, reducing data labeling errors. Furthermore, for the updating of gradients in the model, a bilevel nested optimization is used to ensure the model converges within $O({\\mathrm{C}}/{\\sqrt{T}})$. Unlike other semisupervised algorithms, FSMG uses labeled data and nonidentically distributed unlabeled data proportionally to construct the training dataset, achieving higher classification accuracy, and better robustness even with an 80% polluted rate.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/0be1e53ccf4320e6e140523a75d55bac57d4d3e2.pdf",
      "citation_key": "cai2023ro7",
      "metadata": {
        "title": "A Feedback Semi-Supervised Learning With Meta-Gradient for Intrusion Detection",
        "authors": [
          "Shaokang Cai",
          "Dezhi Han",
          "Dun Li"
        ],
        "published_date": "2023",
        "abstract": "The widespread popularity of the Internet of human life has been accompanied by a significant increase in the cost of protecting private data from malicious attacks. Researchers have proposed many deep learning-based intrusion detection methods. However, traditional methods rely on a large number of unpolluted data to learn benign data distributions, while nonidentical distributions will affect the performance in distinguishing normal and abnormal data. To address this problem, this article proposes an intrusion detection method feedback semi-supervised learning with meta-gradient for intrusion detection (FSMG) based on feedback deep semi-supervised learning. FSMG constructs a lightweight evaluation network with slight data augmentation and nonprocessing on the same input, respectively, and uses a small amount of labeled data to infer nonidentically distributed data flows hidden in the training dataset. Then, FSMG converts malicious flows into useful information, continuously track and update the model, reducing data labeling errors. Furthermore, for the updating of gradients in the model, a bilevel nested optimization is used to ensure the model converges within $O({\\mathrm{C}}/{\\sqrt{T}})$. Unlike other semisupervised algorithms, FSMG uses labeled data and nonidentically distributed unlabeled data proportionally to construct the training dataset, achieving higher classification accuracy, and better robustness even with an 80% polluted rate.",
        "file_path": "paper_data/Deep_Meta-Learning/info/0be1e53ccf4320e6e140523a75d55bac57d4d3e2.pdf",
        "venue": "IEEE Systems Journal",
        "citationCount": 12,
        "score": 6.0,
        "summary": "The widespread popularity of the Internet of human life has been accompanied by a significant increase in the cost of protecting private data from malicious attacks. Researchers have proposed many deep learning-based intrusion detection methods. However, traditional methods rely on a large number of unpolluted data to learn benign data distributions, while nonidentical distributions will affect the performance in distinguishing normal and abnormal data. To address this problem, this article proposes an intrusion detection method feedback semi-supervised learning with meta-gradient for intrusion detection (FSMG) based on feedback deep semi-supervised learning. FSMG constructs a lightweight evaluation network with slight data augmentation and nonprocessing on the same input, respectively, and uses a small amount of labeled data to infer nonidentically distributed data flows hidden in the training dataset. Then, FSMG converts malicious flows into useful information, continuously track and update the model, reducing data labeling errors. Furthermore, for the updating of gradients in the model, a bilevel nested optimization is used to ensure the model converges within $O({\\mathrm{C}}/{\\sqrt{T}})$. Unlike other semisupervised algorithms, FSMG uses labeled data and nonidentically distributed unlabeled data proportionally to construct the training dataset, achieving higher classification accuracy, and better robustness even with an 80% polluted rate.",
        "keywords": []
      },
      "file_name": "0be1e53ccf4320e6e140523a75d55bac57d4d3e2.pdf"
    },
    {
      "success": true,
      "doc_id": "b1b5a8e1c9eebba9ac0df3e0e1cd78fe",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/9bc63d773bc04cca984ad6b9f80949b64e56e536.pdf",
      "citation_key": "lee20230j8",
      "metadata": {
        "title": "Parameterizing Non-Parametric Meta-Reinforcement Learning Tasks via Subtask Decomposition",
        "authors": [
          "Suyoung Lee",
          "Myungsik Cho",
          "Young-Jin Sung"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/9bc63d773bc04cca984ad6b9f80949b64e56e536.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 12,
        "score": 6.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "9bc63d773bc04cca984ad6b9f80949b64e56e536.pdf"
    },
    {
      "success": true,
      "doc_id": "2520f81c449decd63bc04d4da28b0b0f",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of accurate network Traffic Classification (TC) in the face of increasing traffic encryption (HTTPS, QUIC, DNS-SEC), which significantly reduces network visibility.\n    *   **Importance & Challenge**: Traditional Deep Learning (DL) models for TC heavily depend on large, task-specific labeled datasets. This creates an \"infinite loop\" of data collection and model retraining to keep up with evolving traffic patterns. The core challenge is to find better ways to learn generalized representations that are valid across different TC tasks, reducing the dependency on extensive labeled data for new scenarios \\cite{guarino2023zsq}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: The paper positions itself against existing ML-based (e.g., tree-based) and monolithic DL models, and previous applications of transfer learning, meta-learning (often referred to as Few-Shot Learning, FSL), and contrastive learning in TC.\n    *   **Limitations of Previous Solutions**:\n        *   Many prior FSL/meta-learning studies in TC do not follow conventional meta-learning training protocols (e.g., disjoint train/val/test classes), potentially biasing their findings \\cite{guarino2023zsq}.\n        *   Limited investigation of contrastive learning in TC, with only a few studies and none using state-of-the-art transfer learning techniques \\cite{guarino2023zsq}.\n        *   Little attention has been paid to benchmarking ML tree-based approaches against modern DL methods.\n        *   Most studies use small numbers of classes (up to 20), which may not be sufficient to thoroughly evaluate the pros and cons of different training methodologies \\cite{guarino2023zsq}.\n        *   Reliance on payload bytes as input can be computationally costly for monitoring systems \\cite{guarino2023zsq}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper conducts a comprehensive comparative study of 16 different DL methods across transfer learning, meta-learning, and contrastive learning paradigms, benchmarked against reference ML tree-based and monolithic DL models for encrypted traffic classification \\cite{guarino2023zsq}.\n    *   **Novelty/Differentiation**:\n        *   It is the first work to systematically compare state-of-the-art transfer learning techniques (e.g., Baseline, RFS variants), popular meta-learning methods (ProtoNet, RelationNet, MAML), and contrastive learning approaches (SimCLR, SupCon) within the TC domain \\cite{guarino2023zsq}.\n        *   The study rigorously adheres to proper meta-learning training protocols (e.g., ensuring disjoint classes for meta-train, meta-validation, and meta-test), addressing a significant methodological gap in prior TC literature \\cite{guarino2023zsq}.\n        *   It utilizes larger and more diverse datasets (MIRAGE19 with 40 classes, AppClassNet with 500 classes) to better understand the generalizability and scalability of these methods \\cite{guarino2023zsq}.\n\n*   **Key Technical Contributions**\n    *   **Comprehensive Benchmark**: Provides a rigorous, large-scale benchmark of 16 diverse representation learning methods for encrypted traffic classification, offering clear empirical evidence of their relative strengths and weaknesses \\cite{guarino2023zsq}.\n    *   **Empirical Insights into Representation Learning**: Demonstrates that DL methods, when trained on large datasets, can learn more general representations. Specifically, contrastive learning methods are shown to be highly effective in yielding superior performance among DL techniques \\cite{guarino2023zsq}.\n    *   **Challenging Meta-learning Efficacy**: Empirically shows that meta-learning methods, contrary to some expectations in FSL literature, perform the worst in this comprehensive TC assessment (e.g., -14/18% from the best alternative) \\cite{guarino2023zsq}.\n    *   **Performance Gap Analysis**: Quantifies that while tree-based models remain strong for small tasks, the best DL alternatives are effectively closing the performance gap, even for scenarios with few samples per class \\cite{guarino2023zsq}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The study involved extensive experiments comparing 16 DL methods (transfer, meta, contrastive learning variants) and reference ML tree-based and monolithic DL models.\n    *   **Datasets**: Two publicly available datasets were used:\n        *   MIRAGE19 (40 classes)\n        *   AppClassNet (500 classes) \\cite{guarino2023zsq}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   DL methods, especially when trained on large datasets, can obtain more general representations \\cite{guarino2023zsq}.\n        *   Contrastive learning methods consistently yielded the best performance among DL approaches \\cite{guarino2023zsq}.\n        *   Meta-learning methods performed the worst in the assessment, showing significantly lower performance (e.g., -14/18% from the best alternative) \\cite{guarino2023zsq}.\n        *   Tree-based models were found to be superior in overall performance but become impractical for very large tasks (e.g., a 500-class model on AppClassNet could reach a depth of 117 and a file size of 416GB) \\cite{guarino2023zsq}.\n        *   The best DL alternatives are effectively closing the performance gap against tree-based models, even for tasks with few samples per class \\cite{guarino2023zsq}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**:\n        *   Contrastive learning, despite its high performance, suffers from significant computational costs \\cite{guarino2023zsq}.\n        *   Tree-based models, while effective for smaller tasks, are impractical for large-scale classification problems due to their size and complexity \\cite{guarino2023zsq}.\n        *   The study's findings suggest that meta-learning, at least with the evaluated methods and protocols, is not as effective for TC as other representation learning techniques \\cite{guarino2023zsq}.\n    *   **Scope of Applicability**: The research focuses on encrypted traffic classification, particularly investigating the ability of different DL paradigms to learn generalizable representations from varying numbers of samples and classes.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: This work significantly advances the technical state-of-the-art in encrypted TC by providing the first comprehensive and methodologically rigorous benchmark of modern representation learning techniques. It offers critical empirical evidence to guide future research and development in this challenging domain \\cite{guarino2023zsq}.\n    *   **Potential Impact on Future Research**:\n        *   It challenges the prevailing assumptions about the efficacy of meta-learning in TC, suggesting a re-evaluation of its application.\n        *   It strongly advocates for the adoption of contrastive learning as a highly promising approach for learning robust and generalizable representations in TC, especially when leveraging large datasets.\n        *   The findings encourage future research to focus on developing more efficient and adaptable TC solutions that can cope with reduced visibility and evolving traffic patterns without constant retraining on extensive, task-specific datasets \\cite{guarino2023zsq}.",
      "intriguing_abstract": "The escalating challenge of accurate network Traffic Classification (TC) in the era of pervasive encryption demands novel solutions that transcend the limitations of data-hungry Deep Learning (DL) models. This paper presents the first comprehensive and methodologically rigorous benchmark of 16 state-of-the-art representation learning techniques—including transfer learning, meta-learning (Few-Shot Learning), and contrastive learning—against traditional ML and monolithic DL baselines for encrypted traffic. Rigorously adhering to proper meta-learning protocols and utilizing large-scale datasets (MIRAGE19, AppClassNet), our study uncovers critical insights. We demonstrate that contrastive learning methods consistently yield superior generalizable representations among DL approaches, effectively closing the performance gap with powerful but impractical tree-based models, even in few-shot scenarios. Surprisingly, meta-learning methods performed the worst, challenging prevailing assumptions about their efficacy in TC. This work provides crucial empirical evidence, advocating for contrastive learning as a highly promising paradigm to overcome data dependency and advance robust, scalable encrypted TC, thereby guiding future research towards more efficient and adaptable solutions.",
      "keywords": [
        "Network Traffic Classification",
        "Encrypted Traffic",
        "Deep Learning",
        "Representation Learning",
        "Transfer Learning",
        "Meta-learning",
        "Contrastive Learning",
        "Comparative Benchmark",
        "Generalizable Representations",
        "Few-Shot Learning",
        "Tree-based Models",
        "Meta-learning Efficacy",
        "Computational Costs"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/dea00783b876b41e852adc0ad1954e1005324edd.pdf",
      "citation_key": "guarino2023zsq",
      "metadata": {
        "title": "Many or Few Samples?: Comparing Transfer, Contrastive and Meta-Learning in Encrypted Traffic Classification",
        "authors": [
          "Idio Guarino",
          "Chao Wang",
          "A. Finamore",
          "A. Pescapé",
          "Dario Rossi"
        ],
        "published_date": "2023",
        "abstract": "The popularity of Deep Learning (DL), coupled with network traffic visibility reduction due to the increased adoption of HTTPS, QUIC, and DNS-SEC, re-ignited interest towards Traffic Classification (TC). However, to tame the dependency from task-specific large labeled datasets, we need to find better ways to learn representations that are valid across tasks. In this work we investigate this problem comparing transfer learning, meta-learning and contrastive learning against reference Machine Learning (ML) tree-based and monolithic DL models (16 methods total). Using two publicly available datasets, namely MIRAGE19 (40 classes) and AppClassNet (500 classes), we show that ($i$) by using DL methods on large datasets we can obtain more general representations with (i i) contrastive learning methods yielding the best performance and (iii) meta-learning the worst one. While (iv) tree-based models can be impractical for large tasks but fit well small tasks, (v) DL methods that reuse better learned representations are closing their performance gap against trees also for small tasks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/dea00783b876b41e852adc0ad1954e1005324edd.pdf",
        "venue": "Traffic Monitoring and Analysis",
        "citationCount": 11,
        "score": 5.5,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of accurate network Traffic Classification (TC) in the face of increasing traffic encryption (HTTPS, QUIC, DNS-SEC), which significantly reduces network visibility.\n    *   **Importance & Challenge**: Traditional Deep Learning (DL) models for TC heavily depend on large, task-specific labeled datasets. This creates an \"infinite loop\" of data collection and model retraining to keep up with evolving traffic patterns. The core challenge is to find better ways to learn generalized representations that are valid across different TC tasks, reducing the dependency on extensive labeled data for new scenarios \\cite{guarino2023zsq}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: The paper positions itself against existing ML-based (e.g., tree-based) and monolithic DL models, and previous applications of transfer learning, meta-learning (often referred to as Few-Shot Learning, FSL), and contrastive learning in TC.\n    *   **Limitations of Previous Solutions**:\n        *   Many prior FSL/meta-learning studies in TC do not follow conventional meta-learning training protocols (e.g., disjoint train/val/test classes), potentially biasing their findings \\cite{guarino2023zsq}.\n        *   Limited investigation of contrastive learning in TC, with only a few studies and none using state-of-the-art transfer learning techniques \\cite{guarino2023zsq}.\n        *   Little attention has been paid to benchmarking ML tree-based approaches against modern DL methods.\n        *   Most studies use small numbers of classes (up to 20), which may not be sufficient to thoroughly evaluate the pros and cons of different training methodologies \\cite{guarino2023zsq}.\n        *   Reliance on payload bytes as input can be computationally costly for monitoring systems \\cite{guarino2023zsq}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper conducts a comprehensive comparative study of 16 different DL methods across transfer learning, meta-learning, and contrastive learning paradigms, benchmarked against reference ML tree-based and monolithic DL models for encrypted traffic classification \\cite{guarino2023zsq}.\n    *   **Novelty/Differentiation**:\n        *   It is the first work to systematically compare state-of-the-art transfer learning techniques (e.g., Baseline, RFS variants), popular meta-learning methods (ProtoNet, RelationNet, MAML), and contrastive learning approaches (SimCLR, SupCon) within the TC domain \\cite{guarino2023zsq}.\n        *   The study rigorously adheres to proper meta-learning training protocols (e.g., ensuring disjoint classes for meta-train, meta-validation, and meta-test), addressing a significant methodological gap in prior TC literature \\cite{guarino2023zsq}.\n        *   It utilizes larger and more diverse datasets (MIRAGE19 with 40 classes, AppClassNet with 500 classes) to better understand the generalizability and scalability of these methods \\cite{guarino2023zsq}.\n\n*   **Key Technical Contributions**\n    *   **Comprehensive Benchmark**: Provides a rigorous, large-scale benchmark of 16 diverse representation learning methods for encrypted traffic classification, offering clear empirical evidence of their relative strengths and weaknesses \\cite{guarino2023zsq}.\n    *   **Empirical Insights into Representation Learning**: Demonstrates that DL methods, when trained on large datasets, can learn more general representations. Specifically, contrastive learning methods are shown to be highly effective in yielding superior performance among DL techniques \\cite{guarino2023zsq}.\n    *   **Challenging Meta-learning Efficacy**: Empirically shows that meta-learning methods, contrary to some expectations in FSL literature, perform the worst in this comprehensive TC assessment (e.g., -14/18% from the best alternative) \\cite{guarino2023zsq}.\n    *   **Performance Gap Analysis**: Quantifies that while tree-based models remain strong for small tasks, the best DL alternatives are effectively closing the performance gap, even for scenarios with few samples per class \\cite{guarino2023zsq}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The study involved extensive experiments comparing 16 DL methods (transfer, meta, contrastive learning variants) and reference ML tree-based and monolithic DL models.\n    *   **Datasets**: Two publicly available datasets were used:\n        *   MIRAGE19 (40 classes)\n        *   AppClassNet (500 classes) \\cite{guarino2023zsq}.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   DL methods, especially when trained on large datasets, can obtain more general representations \\cite{guarino2023zsq}.\n        *   Contrastive learning methods consistently yielded the best performance among DL approaches \\cite{guarino2023zsq}.\n        *   Meta-learning methods performed the worst in the assessment, showing significantly lower performance (e.g., -14/18% from the best alternative) \\cite{guarino2023zsq}.\n        *   Tree-based models were found to be superior in overall performance but become impractical for very large tasks (e.g., a 500-class model on AppClassNet could reach a depth of 117 and a file size of 416GB) \\cite{guarino2023zsq}.\n        *   The best DL alternatives are effectively closing the performance gap against tree-based models, even for tasks with few samples per class \\cite{guarino2023zsq}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**:\n        *   Contrastive learning, despite its high performance, suffers from significant computational costs \\cite{guarino2023zsq}.\n        *   Tree-based models, while effective for smaller tasks, are impractical for large-scale classification problems due to their size and complexity \\cite{guarino2023zsq}.\n        *   The study's findings suggest that meta-learning, at least with the evaluated methods and protocols, is not as effective for TC as other representation learning techniques \\cite{guarino2023zsq}.\n    *   **Scope of Applicability**: The research focuses on encrypted traffic classification, particularly investigating the ability of different DL paradigms to learn generalizable representations from varying numbers of samples and classes.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: This work significantly advances the technical state-of-the-art in encrypted TC by providing the first comprehensive and methodologically rigorous benchmark of modern representation learning techniques. It offers critical empirical evidence to guide future research and development in this challenging domain \\cite{guarino2023zsq}.\n    *   **Potential Impact on Future Research**:\n        *   It challenges the prevailing assumptions about the efficacy of meta-learning in TC, suggesting a re-evaluation of its application.\n        *   It strongly advocates for the adoption of contrastive learning as a highly promising approach for learning robust and generalizable representations in TC, especially when leveraging large datasets.\n        *   The findings encourage future research to focus on developing more efficient and adaptable TC solutions that can cope with reduced visibility and evolving traffic patterns without constant retraining on extensive, task-specific datasets \\cite{guarino2023zsq}.",
        "keywords": [
          "Network Traffic Classification",
          "Encrypted Traffic",
          "Deep Learning",
          "Representation Learning",
          "Transfer Learning",
          "Meta-learning",
          "Contrastive Learning",
          "Comparative Benchmark",
          "Generalizable Representations",
          "Few-Shot Learning",
          "Tree-based Models",
          "Meta-learning Efficacy",
          "Computational Costs"
        ],
        "paper_type": "based on the abstract and introduction, this paper is a **empirical** type.\n\nhere's why:\n\n*   **abstract mentions:**\n    *   \"we investigate this problem comparing transfer learning, meta-learning and contrastive learning against reference machine learning (ml) tree-based and monolithic dl models (16 methods total).\" - this describes a study comparing different methods.\n    *   \"using two publicly available datasets, namely mirage19 (40 classes) and appclassnet (500 classes)\" - explicitly mentions the use of data.\n    *   \"we show that (i) by using dl methods on large datasets we can obtain more general representations with (ii) contrastive learning methods yielding the best performance and (iii) meta-learning the worst one. while (iv) tree-based models can be impractical for large tasks but fit well small tasks, (v) dl methods that reuse better learned representations are closing their performance gap against trees also for small tasks.\" - these are clear findings and results derived from the data-driven comparison.\n\n*   **introduction discusses:**\n    *   the problem (dependency on large labeled datasets for traffic classification) and the goal (training more generalized models, adapting them). the abstract then details how this problem is investigated through comparison on datasets.\n\nthese elements strongly align with the \"empirical\" criteria: \"data-driven studies with statistical analysis\" and mentions of \"study,\" \"experiment,\" \"data,\" and \"findings.\""
      },
      "file_name": "dea00783b876b41e852adc0ad1954e1005324edd.pdf"
    },
    {
      "success": true,
      "doc_id": "049267f5e38beef0bddecdbe99b7c790",
      "summary": "So-called unsupervised anomaly detection is better described as semi-supervised, as it assumes all training data are nominal. This assumption simplifies training but requires manual data curation, introducing bias and limiting adaptability. We propose Confident Meta-learning (CoMet), a novel training strategy that enables deep anomaly detection models to learn from uncurated datasets where nominal and anomalous samples coexist, eliminating the need for explicit filtering. Our approach integrates Soft Confident Learning, which assigns lower weights to low-confidence samples, and Meta-Learning, which stabilizes training by regularizing updates based on training validation loss covariance. This prevents overfitting and enhances robustness to noisy data. CoMet is model-agnostic and can be applied to any anomaly detection method trainable via gradient descent. Experiments on MVTec-AD, VIADUCT, and KSDD2 with two state-of-the-art models demonstrate the effectiveness of our approach, consistently improving over the baseline methods, remaining insensitive to anomalies in the training set, and setting a new state-of-the-art across all datasets.",
      "intriguing_abstract": "So-called unsupervised anomaly detection is better described as semi-supervised, as it assumes all training data are nominal. This assumption simplifies training but requires manual data curation, introducing bias and limiting adaptability. We propose Confident Meta-learning (CoMet), a novel training strategy that enables deep anomaly detection models to learn from uncurated datasets where nominal and anomalous samples coexist, eliminating the need for explicit filtering. Our approach integrates Soft Confident Learning, which assigns lower weights to low-confidence samples, and Meta-Learning, which stabilizes training by regularizing updates based on training validation loss covariance. This prevents overfitting and enhances robustness to noisy data. CoMet is model-agnostic and can be applied to any anomaly detection method trainable via gradient descent. Experiments on MVTec-AD, VIADUCT, and KSDD2 with two state-of-the-art models demonstrate the effectiveness of our approach, consistently improving over the baseline methods, remaining insensitive to anomalies in the training set, and setting a new state-of-the-art across all datasets.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d726e991e68ed892bd4c42c8c8150ebc71ae1b9e.pdf",
      "citation_key": "aqeel2025zql",
      "metadata": {
        "title": "Towards Real Unsupervised Anomaly Detection Via Confident Meta-Learning",
        "authors": [
          "Muhammad Aqeel",
          "Shakiba Sharifi",
          "Marco Cristani",
          "Francesco Setti"
        ],
        "published_date": "2025",
        "abstract": "So-called unsupervised anomaly detection is better described as semi-supervised, as it assumes all training data are nominal. This assumption simplifies training but requires manual data curation, introducing bias and limiting adaptability. We propose Confident Meta-learning (CoMet), a novel training strategy that enables deep anomaly detection models to learn from uncurated datasets where nominal and anomalous samples coexist, eliminating the need for explicit filtering. Our approach integrates Soft Confident Learning, which assigns lower weights to low-confidence samples, and Meta-Learning, which stabilizes training by regularizing updates based on training validation loss covariance. This prevents overfitting and enhances robustness to noisy data. CoMet is model-agnostic and can be applied to any anomaly detection method trainable via gradient descent. Experiments on MVTec-AD, VIADUCT, and KSDD2 with two state-of-the-art models demonstrate the effectiveness of our approach, consistently improving over the baseline methods, remaining insensitive to anomalies in the training set, and setting a new state-of-the-art across all datasets.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d726e991e68ed892bd4c42c8c8150ebc71ae1b9e.pdf",
        "venue": "arXiv.org",
        "citationCount": 5,
        "score": 5.0,
        "summary": "So-called unsupervised anomaly detection is better described as semi-supervised, as it assumes all training data are nominal. This assumption simplifies training but requires manual data curation, introducing bias and limiting adaptability. We propose Confident Meta-learning (CoMet), a novel training strategy that enables deep anomaly detection models to learn from uncurated datasets where nominal and anomalous samples coexist, eliminating the need for explicit filtering. Our approach integrates Soft Confident Learning, which assigns lower weights to low-confidence samples, and Meta-Learning, which stabilizes training by regularizing updates based on training validation loss covariance. This prevents overfitting and enhances robustness to noisy data. CoMet is model-agnostic and can be applied to any anomaly detection method trainable via gradient descent. Experiments on MVTec-AD, VIADUCT, and KSDD2 with two state-of-the-art models demonstrate the effectiveness of our approach, consistently improving over the baseline methods, remaining insensitive to anomalies in the training set, and setting a new state-of-the-art across all datasets.",
        "keywords": []
      },
      "file_name": "d726e991e68ed892bd4c42c8c8150ebc71ae1b9e.pdf"
    },
    {
      "success": true,
      "doc_id": "ecf6c18c8fc54cbb6749eb12506a7af2",
      "summary": "Here's a focused summary of the technical paper for a literature review, highlighting its innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** Mitigating catastrophic forgetting in deep neural networks during continual learning (CL) on non-stationary data streams, while leveraging the robustness of classical statistical models that are immune to forgetting but lack representational power for complex real-world data.\n    *   **Importance and Challenge:** Continual learning is crucial for intelligent agents, but deep learning models suffer from catastrophic forgetting when trained sequentially with stochastic gradient descent (SGD). While sequential Bayesian updates in simple statistical models are inherently immune to forgetting, these models are often too simplistic for high-dimensional, complex data. The challenge is to combine the strong representational power of neural networks with the forgetting robustness of ideal Bayesian updates.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work positions itself within the meta-continual learning (MCL) paradigm, aiming to meta-learn CL abilities in a data-driven manner. It contrasts with prior Bayesian CL approaches that attempt to update intractable posteriors of neural network parameters, often relying on approximations \\cite{lee2024snq}. It also differs from replay-buffer-based methods that partially preserve sufficient statistics.\n    *   **Limitations of Previous Solutions:** Existing deep learning CL methods struggle with catastrophic forgetting. Bayesian CL for neural networks requires significant approximations, deviating from ideal Bayesian updates. Simple statistical models, while robust to forgetting, are too limited in expressivity for complex data.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper introduces Sequential Bayesian Meta-Continual Learning (SB-MCL) \\cite{lee2024snq}. This framework decouples the learning process: continual learning occurs *only* within simple statistical models via ideal sequential Bayesian update rules, while neural networks are meta-learned to bridge raw data to these statistical models.\n    *   **Novelty:** The key innovation is that the neural networks (termed \"learner\" and \"model\") remain *fixed* during the actual continual learning phase (inner loop), thereby protecting them from catastrophic forgetting. The approach leverages the Fisher-Darmois-Koopman-Pitman theorem, which states that exponential family distributions are the only ones capable of efficient and lossless sequential Bayesian updates with fixed-dimension sufficient statistics. SB-MCL employs an exponential family posterior (e.g., factorized Gaussian) for the statistical model, with the meta-learned neural network \"learner\" producing the necessary parameters for exact Bayesian updates.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Framework:** Introduction of SB-MCL, a general meta-continual learning framework that inherently prevents catastrophic forgetting in neural networks by fixing their parameters during CL and offloading sequential updates to robust statistical models \\cite{lee2024snq}.\n    *   **System Design/Architectural Innovation:** A bi-level optimization scheme where neural networks are meta-trained (outer loop) to map complex data to a latent space suitable for simple statistical models, which then perform exact sequential Bayesian updates (inner loop) without gradient descent.\n    *   **Theoretical Insights:** Explicitly grounding the approach in the Fisher-Darmois-Koopman-Pitman theorem to justify the use of exponential family distributions for ideal, lossless, and efficient sequential Bayesian updates, ensuring immunity to forgetting.\n    *   **Efficiency:** The CL process involves only forward passes of the learner and exact Bayesian updates, eliminating the need for gradient descent during sequential learning. Meta-training can benefit from parallel processing for batch inference, unlike SGD-based MCL approaches.\n    *   **Generality:** The framework is domain-agnostic and model-agnostic, supporting both supervised and unsupervised learning, and can be integrated with existing model architectures.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** The paper reports \"extensive experiments on a wide range of benchmarks\" \\cite{lee2024snq}. While specific datasets are not detailed in the provided text, the figures indicate comparisons across various supervised and unsupervised MCL settings.\n    *   **Key Performance Metrics and Comparison Results:** SB-MCL achieves \"significantly improved performance\" compared to baselines (e.g., ALPaCA, PN, GeMCL, OML, MAML, Reptile, Standard Online, Offline TF) \\cite{lee2024snq}. It also demonstrates \"excellent scalability\" and uses \"substantially less resources,\" suggesting efficiency benefits.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The effectiveness relies on the meta-learned neural networks' ability to accurately transform complex raw data into a representation suitable for the chosen exponential family statistical model. The expressivity of the underlying statistical model is inherently limited, though compensated by the neural network's representational power.\n    *   **Scope of Applicability:** SB-MCL is designed to be domain-agnostic and model-agnostic, making it broadly applicable across various continual learning problems and compatible with diverse neural network architectures \\cite{lee2024snq}. It supports both supervised and unsupervised learning paradigms.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:** SB-MCL offers a principled and robust solution to catastrophic forgetting by fundamentally decoupling the roles of deep representation learning and sequential knowledge integration \\cite{lee2024snq}. It provides a novel way to combine the strengths of deep neural networks with the theoretical guarantees of Bayesian updates for forgetting immunity.\n    *   **Potential Impact:** This framework could lead to more stable and efficient continual learning systems, particularly in scenarios requiring long-term knowledge retention. Its scalability and resource efficiency could make CL more practical for real-world applications. The generalizability of the approach suggests broad applicability and potential for integration into various existing deep learning pipelines.",
      "intriguing_abstract": "Catastrophic forgetting remains a formidable barrier to developing truly adaptive deep neural networks for continual learning on non-stationary data streams. This paper introduces Sequential Bayesian Meta-Continual Learning (SB-MCL), a novel framework that fundamentally redefines how deep models acquire knowledge sequentially without forgetting. Our core innovation decouples the powerful representational learning of neural networks from the sequential knowledge integration process.\n\nInstead of attempting intractable Bayesian updates on neural network parameters, SB-MCL meta-learns neural networks to map complex raw data to a latent space suitable for simple statistical models. Crucially, these neural networks remain *fixed* during continual learning, inherently preventing catastrophic forgetting. Knowledge updates occur *only* within these statistical models via exact, lossless sequential Bayesian updates, rigorously grounded in the Fisher-Darmois-Koopman-Pitman theorem and leveraging exponential family distributions. This bi-level optimization scheme eliminates gradient descent during sequential learning, offering unparalleled efficiency and scalability. Extensive experiments demonstrate SB-MCL's superior performance across diverse benchmarks, significantly outperforming existing meta-continual learning and Bayesian CL methods while using substantially fewer resources. SB-MCL offers a principled, generalizable, and robust solution, paving the way for stable and efficient intelligent agents capable of lifelong learning.",
      "keywords": [
        "Catastrophic forgetting",
        "Continual learning",
        "Deep neural networks",
        "Sequential Bayesian Meta-Continual Learning (SB-MCL)",
        "Exact sequential Bayesian updates",
        "Exponential family distributions",
        "Fisher-Darmois-Koopman-Pitman theorem",
        "Decoupling learning process",
        "Fixed neural network parameters",
        "Bi-level optimization",
        "Resource efficiency",
        "Scalability",
        "Domain-agnostic framework",
        "Meta-continual learning"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/37a349a7a46a9339cb59ac02f81d3848a62d3885.pdf",
      "citation_key": "lee2024snq",
      "metadata": {
        "title": "Learning to Continually Learn with the Bayesian Principle",
        "authors": [
          "Soochan Lee",
          "Hyeonseong Jeon",
          "Jaehyeon Son",
          "Gunhee Kim"
        ],
        "published_date": "2024",
        "abstract": "In the present era of deep learning, continual learning research is mainly focused on mitigating forgetting when training a neural network with stochastic gradient descent on a non-stationary stream of data. On the other hand, in the more classical literature of statistical machine learning, many models have sequential Bayesian update rules that yield the same learning outcome as the batch training, i.e., they are completely immune to catastrophic forgetting. However, they are often overly simple to model complex real-world data. In this work, we adopt the meta-learning paradigm to combine the strong representational power of neural networks and simple statistical models' robustness to forgetting. In our novel meta-continual learning framework, continual learning takes place only in statistical models via ideal sequential Bayesian update rules, while neural networks are meta-learned to bridge the raw data and the statistical models. Since the neural networks remain fixed during continual learning, they are protected from catastrophic forgetting. This approach not only achieves significantly improved performance but also exhibits excellent scalability. Since our approach is domain-agnostic and model-agnostic, it can be applied to a wide range of problems and easily integrated with existing model architectures.",
        "file_path": "paper_data/Deep_Meta-Learning/info/37a349a7a46a9339cb59ac02f81d3848a62d3885.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Here's a focused summary of the technical paper for a literature review, highlighting its innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** Mitigating catastrophic forgetting in deep neural networks during continual learning (CL) on non-stationary data streams, while leveraging the robustness of classical statistical models that are immune to forgetting but lack representational power for complex real-world data.\n    *   **Importance and Challenge:** Continual learning is crucial for intelligent agents, but deep learning models suffer from catastrophic forgetting when trained sequentially with stochastic gradient descent (SGD). While sequential Bayesian updates in simple statistical models are inherently immune to forgetting, these models are often too simplistic for high-dimensional, complex data. The challenge is to combine the strong representational power of neural networks with the forgetting robustness of ideal Bayesian updates.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work positions itself within the meta-continual learning (MCL) paradigm, aiming to meta-learn CL abilities in a data-driven manner. It contrasts with prior Bayesian CL approaches that attempt to update intractable posteriors of neural network parameters, often relying on approximations \\cite{lee2024snq}. It also differs from replay-buffer-based methods that partially preserve sufficient statistics.\n    *   **Limitations of Previous Solutions:** Existing deep learning CL methods struggle with catastrophic forgetting. Bayesian CL for neural networks requires significant approximations, deviating from ideal Bayesian updates. Simple statistical models, while robust to forgetting, are too limited in expressivity for complex data.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper introduces Sequential Bayesian Meta-Continual Learning (SB-MCL) \\cite{lee2024snq}. This framework decouples the learning process: continual learning occurs *only* within simple statistical models via ideal sequential Bayesian update rules, while neural networks are meta-learned to bridge raw data to these statistical models.\n    *   **Novelty:** The key innovation is that the neural networks (termed \"learner\" and \"model\") remain *fixed* during the actual continual learning phase (inner loop), thereby protecting them from catastrophic forgetting. The approach leverages the Fisher-Darmois-Koopman-Pitman theorem, which states that exponential family distributions are the only ones capable of efficient and lossless sequential Bayesian updates with fixed-dimension sufficient statistics. SB-MCL employs an exponential family posterior (e.g., factorized Gaussian) for the statistical model, with the meta-learned neural network \"learner\" producing the necessary parameters for exact Bayesian updates.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Framework:** Introduction of SB-MCL, a general meta-continual learning framework that inherently prevents catastrophic forgetting in neural networks by fixing their parameters during CL and offloading sequential updates to robust statistical models \\cite{lee2024snq}.\n    *   **System Design/Architectural Innovation:** A bi-level optimization scheme where neural networks are meta-trained (outer loop) to map complex data to a latent space suitable for simple statistical models, which then perform exact sequential Bayesian updates (inner loop) without gradient descent.\n    *   **Theoretical Insights:** Explicitly grounding the approach in the Fisher-Darmois-Koopman-Pitman theorem to justify the use of exponential family distributions for ideal, lossless, and efficient sequential Bayesian updates, ensuring immunity to forgetting.\n    *   **Efficiency:** The CL process involves only forward passes of the learner and exact Bayesian updates, eliminating the need for gradient descent during sequential learning. Meta-training can benefit from parallel processing for batch inference, unlike SGD-based MCL approaches.\n    *   **Generality:** The framework is domain-agnostic and model-agnostic, supporting both supervised and unsupervised learning, and can be integrated with existing model architectures.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** The paper reports \"extensive experiments on a wide range of benchmarks\" \\cite{lee2024snq}. While specific datasets are not detailed in the provided text, the figures indicate comparisons across various supervised and unsupervised MCL settings.\n    *   **Key Performance Metrics and Comparison Results:** SB-MCL achieves \"significantly improved performance\" compared to baselines (e.g., ALPaCA, PN, GeMCL, OML, MAML, Reptile, Standard Online, Offline TF) \\cite{lee2024snq}. It also demonstrates \"excellent scalability\" and uses \"substantially less resources,\" suggesting efficiency benefits.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The effectiveness relies on the meta-learned neural networks' ability to accurately transform complex raw data into a representation suitable for the chosen exponential family statistical model. The expressivity of the underlying statistical model is inherently limited, though compensated by the neural network's representational power.\n    *   **Scope of Applicability:** SB-MCL is designed to be domain-agnostic and model-agnostic, making it broadly applicable across various continual learning problems and compatible with diverse neural network architectures \\cite{lee2024snq}. It supports both supervised and unsupervised learning paradigms.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:** SB-MCL offers a principled and robust solution to catastrophic forgetting by fundamentally decoupling the roles of deep representation learning and sequential knowledge integration \\cite{lee2024snq}. It provides a novel way to combine the strengths of deep neural networks with the theoretical guarantees of Bayesian updates for forgetting immunity.\n    *   **Potential Impact:** This framework could lead to more stable and efficient continual learning systems, particularly in scenarios requiring long-term knowledge retention. Its scalability and resource efficiency could make CL more practical for real-world applications. The generalizability of the approach suggests broad applicability and potential for integration into various existing deep learning pipelines.",
        "keywords": [
          "Catastrophic forgetting",
          "Continual learning",
          "Deep neural networks",
          "Sequential Bayesian Meta-Continual Learning (SB-MCL)",
          "Exact sequential Bayesian updates",
          "Exponential family distributions",
          "Fisher-Darmois-Koopman-Pitman theorem",
          "Decoupling learning process",
          "Fixed neural network parameters",
          "Bi-level optimization",
          "Resource efficiency",
          "Scalability",
          "Domain-agnostic framework",
          "Meta-continual learning"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"in this work, we adopt the meta-learning paradigm to combine...\", \"in our novel meta-continual learning framework, continual learning takes place...\", and describes \"this approach\" and \"our approach\".\n*   the introduction discusses a significant technical challenge (continual learning) and introduces \"meta-continual learning (mcl)\" as a promising avenue, implying the paper will present a solution within this area.\n*   the paper proposes a \"novel meta-continual learning framework\" and an \"approach\" to mitigate catastrophic forgetting by combining neural networks with statistical models using bayesian update rules.\n*   it mentions achieving \"significantly improved performance\" and \"excellent scalability,\" which are results of the proposed method.\n\nthese points strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems to solve a technical problem. while it uses theoretical concepts (bayesian principle) and likely includes empirical results (improved performance), the core contribution described is the development and presentation of a novel framework/approach.\n\n**classification: technical**"
      },
      "file_name": "37a349a7a46a9339cb59ac02f81d3848a62d3885.pdf"
    },
    {
      "success": true,
      "doc_id": "501cab903d8d0bf00d8733c42e5ad05b",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c6c048fda390e834651090c6f0d4a057528c2028.pdf",
      "citation_key": "li2023asx",
      "metadata": {
        "title": "CoraL: interpretable contrastive meta-learning for the prediction of cancer-associated ncRNA-encoded small peptides",
        "authors": [
          "Zhongshen Li",
          "Junru Jin",
          "Wenjia He",
          "Wentao Long",
          "Haoqing Yu",
          "Xin Gao",
          "Kenta Nakai",
          "Quan Zou",
          "Leyi Wei"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/c6c048fda390e834651090c6f0d4a057528c2028.pdf",
        "venue": "Briefings Bioinform.",
        "citationCount": 9,
        "score": 4.5,
        "summary": "",
        "keywords": []
      },
      "file_name": "c6c048fda390e834651090c6f0d4a057528c2028.pdf"
    },
    {
      "success": true,
      "doc_id": "cb3663d74aaef7799278f96098a603c2",
      "summary": "We propose that in order to harness our understanding of neuroscience toward machine learning, we must first have powerful tools for training brain-like models of learning. Although substantial progress has been made toward understanding the dynamics of learning in the brain, neuroscience-derived models of learning have yet to demonstrate the same performance capabilities as methods in deep learning such as gradient descent. Inspired by the successes of machine learning using gradient descent, we introduce a bi-level optimization framework that seeks to both solve online learning tasks and improve the ability to learn online using models of plasticity from neuroscience. We demonstrate that models of three-factor learning with synaptic plasticity taken from the neuroscience literature can be trained in Spiking Neural Networks (SNNs) with gradient descent via a framework of learning-to-learn to address challenging online learning problems. This framework opens a new path toward developing neuroscience inspired online learning algorithms.",
      "intriguing_abstract": "We propose that in order to harness our understanding of neuroscience toward machine learning, we must first have powerful tools for training brain-like models of learning. Although substantial progress has been made toward understanding the dynamics of learning in the brain, neuroscience-derived models of learning have yet to demonstrate the same performance capabilities as methods in deep learning such as gradient descent. Inspired by the successes of machine learning using gradient descent, we introduce a bi-level optimization framework that seeks to both solve online learning tasks and improve the ability to learn online using models of plasticity from neuroscience. We demonstrate that models of three-factor learning with synaptic plasticity taken from the neuroscience literature can be trained in Spiking Neural Networks (SNNs) with gradient descent via a framework of learning-to-learn to address challenging online learning problems. This framework opens a new path toward developing neuroscience inspired online learning algorithms.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/1a1879f7e1abaa056db71ebf2123d01bf6d6a7cf.pdf",
      "citation_key": "schmidgall20238t4",
      "metadata": {
        "title": "Meta-SpikePropamine: learning to learn with synaptic plasticity in spiking neural networks",
        "authors": [
          "Samuel Schmidgall",
          "Joe Hays"
        ],
        "published_date": "2023",
        "abstract": "We propose that in order to harness our understanding of neuroscience toward machine learning, we must first have powerful tools for training brain-like models of learning. Although substantial progress has been made toward understanding the dynamics of learning in the brain, neuroscience-derived models of learning have yet to demonstrate the same performance capabilities as methods in deep learning such as gradient descent. Inspired by the successes of machine learning using gradient descent, we introduce a bi-level optimization framework that seeks to both solve online learning tasks and improve the ability to learn online using models of plasticity from neuroscience. We demonstrate that models of three-factor learning with synaptic plasticity taken from the neuroscience literature can be trained in Spiking Neural Networks (SNNs) with gradient descent via a framework of learning-to-learn to address challenging online learning problems. This framework opens a new path toward developing neuroscience inspired online learning algorithms.",
        "file_path": "paper_data/Deep_Meta-Learning/info/1a1879f7e1abaa056db71ebf2123d01bf6d6a7cf.pdf",
        "venue": "Frontiers in Neuroscience",
        "citationCount": 8,
        "score": 4.0,
        "summary": "We propose that in order to harness our understanding of neuroscience toward machine learning, we must first have powerful tools for training brain-like models of learning. Although substantial progress has been made toward understanding the dynamics of learning in the brain, neuroscience-derived models of learning have yet to demonstrate the same performance capabilities as methods in deep learning such as gradient descent. Inspired by the successes of machine learning using gradient descent, we introduce a bi-level optimization framework that seeks to both solve online learning tasks and improve the ability to learn online using models of plasticity from neuroscience. We demonstrate that models of three-factor learning with synaptic plasticity taken from the neuroscience literature can be trained in Spiking Neural Networks (SNNs) with gradient descent via a framework of learning-to-learn to address challenging online learning problems. This framework opens a new path toward developing neuroscience inspired online learning algorithms.",
        "keywords": []
      },
      "file_name": "1a1879f7e1abaa056db71ebf2123d01bf6d6a7cf.pdf"
    },
    {
      "success": true,
      "doc_id": "12f3b58f846e711ffcd9d3c9e69af4b8",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the technical problem of **few-shot short utterance speaker verification (SV)** \\cite{wang2023x5w}.\n    *   This problem is important because existing SV methods typically require long speech (over 15 seconds) or tens of utterances for accuracy, limiting their widespread application. Researching SV for short utterances (2-10 seconds) is crucial for practical scenarios like online payments and application logins \\cite{wang2023x5w}.\n    *   It is challenging because deep learning-based SV methods depend on large-scale datasets with thousands of speakers, and optimizing only for speakers within given meta-tasks in meta-learning may not be sufficient to learn truly distinctive speaker features \\cite{wang2023x5w}.\n\n*   **Related Work & Positioning**\n    *   **Existing approaches** include conventional methods like i-vector and GMM, and deep learning methods utilizing architectures such as TDNN, ResNet, Transformer, and LSTM, often with aggregation strategies (e.g., ASP, SAP) and attention mechanisms \\cite{wang2023x5w}.\n    *   **Meta-learning approaches**, particularly Prototypical Networks (PN), have been used for speaker embedding and SV, learning a metric space to distinguish speakers \\cite{wang2023x5w}. Some work combined PN with global classification for imbalanced utterance lengths.\n    *   **Limitations of previous solutions** include the reliance of deep learning methods on large-scale datasets and long utterances, and the potential insufficiency of meta-learning approaches that optimize only for classes within specific meta-tasks to learn broadly distinctive speaker features \\cite{wang2023x5w}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a **meta-learning approach with an episodic training strategy** for few-shot short utterance SV \\cite{wang2023x5w}.\n    *   The approach is novel by:\n        *   Integrating **Emphasized Channel Attention, Propagation and Aggregation in TDNN (ECAPA-TDNN)** as the feature extractor within a Prototypical Network (PN), termed **ETP (ECAPA-TDNN-inspired Prototypical network)**. ECAPA-TDNN provides a robust nonlinear mapping from input to a discriminative metric space \\cite{wang2023x5w}.\n        *   Designing an **episodic training strategy** that combines the Prototypical Network loss with a **global classification (GC)** objective. This strategy ensures that the classes in the support and query sets correspond to the classes of the *entire* training set, addressing the limitation of meta-tasks alone and improving the learning of distinctive speaker features \\cite{wang2023x5w}.\n        *   Leveraging ECAPA-TDNN's architecture, including SE-Res2Blocks with dilated convolutions (Res2Dilated Conv1D) and Attention Statistical Pooling (ASP), to effectively capture multi-scale and long-term speaker characteristics \\cite{wang2023x5w}.\n\n*   **Key Technical Contributions**\n    *   **Novel algorithms/methods:** Formulation of a meta-learning approach with episodic training specifically for few-shot short utterance SV \\cite{wang2023x5w}.\n    *   **System design/architectural innovations:** Introduction of ETP, which integrates the powerful ECAPA-TDNN architecture into the prototypical network framework for enhanced speaker embedding learning \\cite{wang2023x5w}.\n    *   **Training strategy innovation:** Development of an episodic training strategy that combines prototypical network loss with global classification, enabling the model to learn more discriminative speaker features across the entire training set \\cite{wang2023x5w}.\n\n*   **Experimental Validation**\n    *   **Experiments conducted:** The proposed model's performance was evaluated against comparison models \\cite{wang2023x5w}.\n    *   **Dataset:** Experiments were performed on the **VoxCeleb1 dataset** \\cite{wang2023x5w}.\n    *   **Key results:** The proposed model **outperforms comparison models** on the VoxCeleb1 dataset \\cite{wang2023x5w}. (Specific metrics like EER or minDCF are not detailed in the provided abstract but are standard for SV).\n\n*   **Limitations & Scope**\n    *   **Technical limitations/assumptions:** The paper does not explicitly state technical limitations in the provided text. It assumes the effectiveness of meta-learning for few-shot tasks and the strong feature extraction capabilities of ECAPA-TDNN.\n    *   **Scope of applicability:** The method is applicable to **few-shot short utterance speaker verification** and is highlighted for its \"wide range of practical applications\" \\cite{wang2023x5w}.\n\n*   **Technical Significance**\n    *   This work advances the technical state-of-the-art in few-shot short utterance SV by providing a robust meta-learning framework that combines a powerful feature extractor (ECAPA-TDNN) with an improved episodic training strategy \\cite{wang2023x5w}.\n    *   The **potential impact** is significant for real-world applications requiring user identity verification with limited speech data, such as online payments and application logins, making SV technology more practical and accessible \\cite{wang2023x5w}. The episodic training strategy could also inspire similar improvements in other meta-learning tasks.",
      "intriguing_abstract": "Imagine unlocking your device or authorizing a payment with just a few seconds of speech. This vision is hampered by the limitations of current speaker verification (SV) systems, which demand extensive audio or numerous utterances. We introduce a novel meta-learning framework for **few-shot short utterance speaker verification**, addressing this critical gap.\n\nOur approach, termed **ETP (ECAPA-TDNN-inspired Prototypical network)**, leverages the robust feature extraction capabilities of **ECAPA-TDNN**, incorporating **SE-Res2Blocks** and **Attention Statistical Pooling**, to generate highly discriminative **speaker embeddings** from minimal audio. Crucially, we design an innovative **episodic training strategy** that synergistically combines the **Prototypical Network loss** with a **global classification** objective. This unique dual-loss mechanism overcomes the inherent limitations of meta-tasks by ensuring the model learns broadly distinctive speaker features across the entire training set, rather than just within specific episodes.\n\nEvaluated on the challenging **VoxCeleb1 dataset**, our ETP model significantly outperforms state-of-the-art comparison methods. This breakthrough advances the technical state-of-the-art in few-shot SV, paving the way for highly practical and secure identity verification in real-world applications like online payments and application logins, even with extremely limited speech data.",
      "keywords": [
        "few-shot short utterance speaker verification",
        "meta-learning",
        "Prototypical Networks",
        "ECAPA-TDNN",
        "ETP (ECAPA-TDNN-inspired Prototypical network)",
        "episodic training strategy",
        "global classification",
        "speaker embedding",
        "discriminative speaker features",
        "VoxCeleb1 dataset",
        "outperforms comparison models",
        "online payments",
        "application logins"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/2dc6799265db441bfa53eb9346cf67fec9a27e39.pdf",
      "citation_key": "wang2023x5w",
      "metadata": {
        "title": "Few-shot short utterance speaker verification using meta-learning",
        "authors": [
          "Weijie Wang",
          "Hong Zhao",
          "Yikun Yang",
          "Youkang Chang",
          "Haojie You"
        ],
        "published_date": "2023",
        "abstract": "Short utterance speaker verification (SV) in the actual application is the task of accepting or rejecting the identity claim of a speaker based on a few enrollment utterances. Traditional methods have used deep neural networks to extract speaker representations for verification. Recently, several meta-learning approaches have learned a deep distance metric to distinguish speakers within meta-tasks. Among them, a prototypical network learns a metric space that may be used to compute the distance to the prototype center of speakers, in order to classify speaker identity. We use emphasized channel attention, propagation and aggregation in TDNN (ECAPA-TDNN) to implement the necessary function for the prototypical network, which is a nonlinear mapping from the input space to the metric space for either few-shot SV task. In addition, optimizing only for speakers in given meta-tasks cannot be sufficient to learn distinctive speaker features. Thus, we used an episodic training strategy, in which the classes of the support and query sets correspond to the classes of the entire training set, further improving the model performance. The proposed model outperforms comparison models on the VoxCeleb1 dataset and has a wide range of practical applications.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2dc6799265db441bfa53eb9346cf67fec9a27e39.pdf",
        "venue": "PeerJ Computer Science",
        "citationCount": 8,
        "score": 4.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the technical problem of **few-shot short utterance speaker verification (SV)** \\cite{wang2023x5w}.\n    *   This problem is important because existing SV methods typically require long speech (over 15 seconds) or tens of utterances for accuracy, limiting their widespread application. Researching SV for short utterances (2-10 seconds) is crucial for practical scenarios like online payments and application logins \\cite{wang2023x5w}.\n    *   It is challenging because deep learning-based SV methods depend on large-scale datasets with thousands of speakers, and optimizing only for speakers within given meta-tasks in meta-learning may not be sufficient to learn truly distinctive speaker features \\cite{wang2023x5w}.\n\n*   **Related Work & Positioning**\n    *   **Existing approaches** include conventional methods like i-vector and GMM, and deep learning methods utilizing architectures such as TDNN, ResNet, Transformer, and LSTM, often with aggregation strategies (e.g., ASP, SAP) and attention mechanisms \\cite{wang2023x5w}.\n    *   **Meta-learning approaches**, particularly Prototypical Networks (PN), have been used for speaker embedding and SV, learning a metric space to distinguish speakers \\cite{wang2023x5w}. Some work combined PN with global classification for imbalanced utterance lengths.\n    *   **Limitations of previous solutions** include the reliance of deep learning methods on large-scale datasets and long utterances, and the potential insufficiency of meta-learning approaches that optimize only for classes within specific meta-tasks to learn broadly distinctive speaker features \\cite{wang2023x5w}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a **meta-learning approach with an episodic training strategy** for few-shot short utterance SV \\cite{wang2023x5w}.\n    *   The approach is novel by:\n        *   Integrating **Emphasized Channel Attention, Propagation and Aggregation in TDNN (ECAPA-TDNN)** as the feature extractor within a Prototypical Network (PN), termed **ETP (ECAPA-TDNN-inspired Prototypical network)**. ECAPA-TDNN provides a robust nonlinear mapping from input to a discriminative metric space \\cite{wang2023x5w}.\n        *   Designing an **episodic training strategy** that combines the Prototypical Network loss with a **global classification (GC)** objective. This strategy ensures that the classes in the support and query sets correspond to the classes of the *entire* training set, addressing the limitation of meta-tasks alone and improving the learning of distinctive speaker features \\cite{wang2023x5w}.\n        *   Leveraging ECAPA-TDNN's architecture, including SE-Res2Blocks with dilated convolutions (Res2Dilated Conv1D) and Attention Statistical Pooling (ASP), to effectively capture multi-scale and long-term speaker characteristics \\cite{wang2023x5w}.\n\n*   **Key Technical Contributions**\n    *   **Novel algorithms/methods:** Formulation of a meta-learning approach with episodic training specifically for few-shot short utterance SV \\cite{wang2023x5w}.\n    *   **System design/architectural innovations:** Introduction of ETP, which integrates the powerful ECAPA-TDNN architecture into the prototypical network framework for enhanced speaker embedding learning \\cite{wang2023x5w}.\n    *   **Training strategy innovation:** Development of an episodic training strategy that combines prototypical network loss with global classification, enabling the model to learn more discriminative speaker features across the entire training set \\cite{wang2023x5w}.\n\n*   **Experimental Validation**\n    *   **Experiments conducted:** The proposed model's performance was evaluated against comparison models \\cite{wang2023x5w}.\n    *   **Dataset:** Experiments were performed on the **VoxCeleb1 dataset** \\cite{wang2023x5w}.\n    *   **Key results:** The proposed model **outperforms comparison models** on the VoxCeleb1 dataset \\cite{wang2023x5w}. (Specific metrics like EER or minDCF are not detailed in the provided abstract but are standard for SV).\n\n*   **Limitations & Scope**\n    *   **Technical limitations/assumptions:** The paper does not explicitly state technical limitations in the provided text. It assumes the effectiveness of meta-learning for few-shot tasks and the strong feature extraction capabilities of ECAPA-TDNN.\n    *   **Scope of applicability:** The method is applicable to **few-shot short utterance speaker verification** and is highlighted for its \"wide range of practical applications\" \\cite{wang2023x5w}.\n\n*   **Technical Significance**\n    *   This work advances the technical state-of-the-art in few-shot short utterance SV by providing a robust meta-learning framework that combines a powerful feature extractor (ECAPA-TDNN) with an improved episodic training strategy \\cite{wang2023x5w}.\n    *   The **potential impact** is significant for real-world applications requiring user identity verification with limited speech data, such as online payments and application logins, making SV technology more practical and accessible \\cite{wang2023x5w}. The episodic training strategy could also inspire similar improvements in other meta-learning tasks.",
        "keywords": [
          "few-shot short utterance speaker verification",
          "meta-learning",
          "Prototypical Networks",
          "ECAPA-TDNN",
          "ETP (ECAPA-TDNN-inspired Prototypical network)",
          "episodic training strategy",
          "global classification",
          "speaker embedding",
          "discriminative speaker features",
          "VoxCeleb1 dataset",
          "outperforms comparison models",
          "online payments",
          "application logins"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the **abstract** explicitly states: \"we use emphasized channel attention, propagation and aggregation in tdnn (ecapa-tdnn) to implement the necessary function for the prototypical network...\", and \"thus, we used an episodic training strategy... further improving the model performance.\" it then concludes: \"the proposed model outperforms comparison models on the voxceleb1 dataset...\" these phrases (\"we use,\" \"we used,\" \"proposed model\") are strong indicators of presenting a new method or a novel application/combination of existing methods.\n*   the **introduction** identifies a specific technical problem: \"existing sv methods need to use long speech... which limits the wide application... therefore, researching for short utterances... is of great significance to sv technology.\" this sets the stage for a technical solution.\n\nthe paper is focused on presenting a new approach (a specific implementation using ecapa-tdnn with a prototypical network and an episodic training strategy) to solve a technical problem (few-shot short utterance speaker verification) and demonstrating its performance. while it includes empirical results, these results serve to validate the effectiveness of the *proposed method*.\n\ntherefore, the most appropriate classification is **technical**."
      },
      "file_name": "2dc6799265db441bfa53eb9346cf67fec9a27e39.pdf"
    },
    {
      "success": true,
      "doc_id": "8702254d7b71fb3a15a9cf4c1115d11b",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3732faadd5df5e6fa097f7f24be871249e6875dd.pdf",
      "citation_key": "wang2023ryf",
      "metadata": {
        "title": "MetaScleraSeg: an effective meta-learning framework for generalized sclera segmentation",
        "authors": [
          "Caiyong Wang",
          "Haiqing Li",
          "Wen-bin Ma",
          "Guangzhe Zhao",
          "Zhaofeng He"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/3732faadd5df5e6fa097f7f24be871249e6875dd.pdf",
        "venue": "Neural computing & applications (Print)",
        "citationCount": 7,
        "score": 3.5,
        "summary": "",
        "keywords": []
      },
      "file_name": "3732faadd5df5e6fa097f7f24be871249e6875dd.pdf"
    },
    {
      "success": true,
      "doc_id": "01b75f3155f3abc5bd036ffc26d156a9",
      "summary": "The use of deep learning (DL)-based hyperspectral image (HSI) classification has been made remarkable progress in recent years. However, obtaining sufficient labeled samples for training DL models remains a challenge. Transfer learning is effective in addressing the problem of HSI classification with limited labeled samples. However, cross-domain HSI classification using transfer learning remain difficult, as differences in ground object categories between two datasets make it challenging to transfer and learn accurate. To address this issue, we propose a simple yet effective method for HSI classification using model-agnostic meta-learning (MAML) and Regularized Fine-tuning (MRFSL). Our method uses optimized 3-D convolutional neural networks (3D-CNNs) model, aided by MAML and cutout data augmentation to enable cross-domain transfer learning and carry out the HSI classification with limited target samples. Experiments conducted on three HSI datasets demonstrate that the MRFSL method achieves excellent results compared to existing methods. Specifically, the overall accuracy (OA) of our proposed MRFSL method reached 91.81%, 71.04%, and 88.35%, when only five labeled samples for each category were randomly extracted from the Salinas, Indian Pines (IPs), and University of Pavia (UP) datasets, respectively.",
      "intriguing_abstract": "The use of deep learning (DL)-based hyperspectral image (HSI) classification has been made remarkable progress in recent years. However, obtaining sufficient labeled samples for training DL models remains a challenge. Transfer learning is effective in addressing the problem of HSI classification with limited labeled samples. However, cross-domain HSI classification using transfer learning remain difficult, as differences in ground object categories between two datasets make it challenging to transfer and learn accurate. To address this issue, we propose a simple yet effective method for HSI classification using model-agnostic meta-learning (MAML) and Regularized Fine-tuning (MRFSL). Our method uses optimized 3-D convolutional neural networks (3D-CNNs) model, aided by MAML and cutout data augmentation to enable cross-domain transfer learning and carry out the HSI classification with limited target samples. Experiments conducted on three HSI datasets demonstrate that the MRFSL method achieves excellent results compared to existing methods. Specifically, the overall accuracy (OA) of our proposed MRFSL method reached 91.81%, 71.04%, and 88.35%, when only five labeled samples for each category were randomly extracted from the Salinas, Indian Pines (IPs), and University of Pavia (UP) datasets, respectively.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/069cce0ffad769451fe6008e67a6cd27f9eaa281.pdf",
      "citation_key": "li2023fhe",
      "metadata": {
        "title": "Few-Shot Hyperspectral Image Classification Using Meta Learning and Regularized Finetuning",
        "authors": [
          "Wenmei Li",
          "Qing Liu",
          "Yu Zhang",
          "Yu Wang",
          "Yuan Yuan",
          "Yan Jia",
          "Yuhong He"
        ],
        "published_date": "2023",
        "abstract": "The use of deep learning (DL)-based hyperspectral image (HSI) classification has been made remarkable progress in recent years. However, obtaining sufficient labeled samples for training DL models remains a challenge. Transfer learning is effective in addressing the problem of HSI classification with limited labeled samples. However, cross-domain HSI classification using transfer learning remain difficult, as differences in ground object categories between two datasets make it challenging to transfer and learn accurate. To address this issue, we propose a simple yet effective method for HSI classification using model-agnostic meta-learning (MAML) and Regularized Fine-tuning (MRFSL). Our method uses optimized 3-D convolutional neural networks (3D-CNNs) model, aided by MAML and cutout data augmentation to enable cross-domain transfer learning and carry out the HSI classification with limited target samples. Experiments conducted on three HSI datasets demonstrate that the MRFSL method achieves excellent results compared to existing methods. Specifically, the overall accuracy (OA) of our proposed MRFSL method reached 91.81%, 71.04%, and 88.35%, when only five labeled samples for each category were randomly extracted from the Salinas, Indian Pines (IPs), and University of Pavia (UP) datasets, respectively.",
        "file_path": "paper_data/Deep_Meta-Learning/info/069cce0ffad769451fe6008e67a6cd27f9eaa281.pdf",
        "venue": "IEEE Transactions on Geoscience and Remote Sensing",
        "citationCount": 7,
        "score": 3.5,
        "summary": "The use of deep learning (DL)-based hyperspectral image (HSI) classification has been made remarkable progress in recent years. However, obtaining sufficient labeled samples for training DL models remains a challenge. Transfer learning is effective in addressing the problem of HSI classification with limited labeled samples. However, cross-domain HSI classification using transfer learning remain difficult, as differences in ground object categories between two datasets make it challenging to transfer and learn accurate. To address this issue, we propose a simple yet effective method for HSI classification using model-agnostic meta-learning (MAML) and Regularized Fine-tuning (MRFSL). Our method uses optimized 3-D convolutional neural networks (3D-CNNs) model, aided by MAML and cutout data augmentation to enable cross-domain transfer learning and carry out the HSI classification with limited target samples. Experiments conducted on three HSI datasets demonstrate that the MRFSL method achieves excellent results compared to existing methods. Specifically, the overall accuracy (OA) of our proposed MRFSL method reached 91.81%, 71.04%, and 88.35%, when only five labeled samples for each category were randomly extracted from the Salinas, Indian Pines (IPs), and University of Pavia (UP) datasets, respectively.",
        "keywords": []
      },
      "file_name": "069cce0ffad769451fe6008e67a6cd27f9eaa281.pdf"
    },
    {
      "success": true,
      "doc_id": "d56fe472298b626bf89bb38a7ab9b3e0",
      "summary": "Deep learning (DL) has become a dominating type of workloads on AI computing platforms. The performance of such platforms highly depends on how distributed DL jobs are scheduled. Reinforcement learning (RL)-based schedulers have been extensively studied and are capable of modeling interferences between concurrent jobs competing for resources. However, existing RL-based schedulers must learn from large number of samples and adapt to workload changes in real systems, which is a huge cost for production clusters. This paper proposes an intelligent, autonomous scheduler that employs sample-efficient RL for real-world resource scheduling on complex DL clusters. Specifically, we design a closed-loop meta-RL-based worker placement algorithm for DL training jobs. Instead of random exploration, we encourage the scheduler to explore combinatorial subspaces, where the performance model might be inaccurate, to improve the sampling efficiency of the scheduler agent. Extensive experimental results demonstrate that our algorithm outperforms other baselines in terms of average job completion time with 12.29% to 16.24% improvements. Further experiments with workload variations yield 15.76% to 22.13% improvements.",
      "intriguing_abstract": "Deep learning (DL) has become a dominating type of workloads on AI computing platforms. The performance of such platforms highly depends on how distributed DL jobs are scheduled. Reinforcement learning (RL)-based schedulers have been extensively studied and are capable of modeling interferences between concurrent jobs competing for resources. However, existing RL-based schedulers must learn from large number of samples and adapt to workload changes in real systems, which is a huge cost for production clusters. This paper proposes an intelligent, autonomous scheduler that employs sample-efficient RL for real-world resource scheduling on complex DL clusters. Specifically, we design a closed-loop meta-RL-based worker placement algorithm for DL training jobs. Instead of random exploration, we encourage the scheduler to explore combinatorial subspaces, where the performance model might be inaccurate, to improve the sampling efficiency of the scheduler agent. Extensive experimental results demonstrate that our algorithm outperforms other baselines in terms of average job completion time with 12.29% to 16.24% improvements. Further experiments with workload variations yield 15.76% to 22.13% improvements.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/42ac39327eb25d2e757b55eb5eb180f6a55dd020.pdf",
      "citation_key": "yang20238th",
      "metadata": {
        "title": "On a Meta Learning-Based Scheduler for Deep Learning Clusters",
        "authors": [
          "Jin Yang",
          "Liang Bao",
          "Wenjing Liu",
          "Rong Yang",
          "C. Wu"
        ],
        "published_date": "2023",
        "abstract": "Deep learning (DL) has become a dominating type of workloads on AI computing platforms. The performance of such platforms highly depends on how distributed DL jobs are scheduled. Reinforcement learning (RL)-based schedulers have been extensively studied and are capable of modeling interferences between concurrent jobs competing for resources. However, existing RL-based schedulers must learn from large number of samples and adapt to workload changes in real systems, which is a huge cost for production clusters. This paper proposes an intelligent, autonomous scheduler that employs sample-efficient RL for real-world resource scheduling on complex DL clusters. Specifically, we design a closed-loop meta-RL-based worker placement algorithm for DL training jobs. Instead of random exploration, we encourage the scheduler to explore combinatorial subspaces, where the performance model might be inaccurate, to improve the sampling efficiency of the scheduler agent. Extensive experimental results demonstrate that our algorithm outperforms other baselines in terms of average job completion time with 12.29% to 16.24% improvements. Further experiments with workload variations yield 15.76% to 22.13% improvements.",
        "file_path": "paper_data/Deep_Meta-Learning/info/42ac39327eb25d2e757b55eb5eb180f6a55dd020.pdf",
        "venue": "IEEE Transactions on Cloud Computing",
        "citationCount": 6,
        "score": 3.0,
        "summary": "Deep learning (DL) has become a dominating type of workloads on AI computing platforms. The performance of such platforms highly depends on how distributed DL jobs are scheduled. Reinforcement learning (RL)-based schedulers have been extensively studied and are capable of modeling interferences between concurrent jobs competing for resources. However, existing RL-based schedulers must learn from large number of samples and adapt to workload changes in real systems, which is a huge cost for production clusters. This paper proposes an intelligent, autonomous scheduler that employs sample-efficient RL for real-world resource scheduling on complex DL clusters. Specifically, we design a closed-loop meta-RL-based worker placement algorithm for DL training jobs. Instead of random exploration, we encourage the scheduler to explore combinatorial subspaces, where the performance model might be inaccurate, to improve the sampling efficiency of the scheduler agent. Extensive experimental results demonstrate that our algorithm outperforms other baselines in terms of average job completion time with 12.29% to 16.24% improvements. Further experiments with workload variations yield 15.76% to 22.13% improvements.",
        "keywords": []
      },
      "file_name": "42ac39327eb25d2e757b55eb5eb180f6a55dd020.pdf"
    },
    {
      "success": true,
      "doc_id": "a2633ee5186357223cda2c50a5440ccf",
      "summary": "Autism Spectrum Disorder (ASD) is a complicated neurodevelopment disorder that is becoming more common day by day around the world. The literature that uses machine learning (ML) and deep learning (DL) approaches gained interest due to their ability to increase the accuracy of diagnosing disorders and reduce the physician’s workload. These artificial intelligence-based applications can learn and detect patterns automatically through the collection of data. ML approaches are used in various applications where the traditional algorithms have failed to obtain better results. The major advantage of the ML algorithm is its ability to produce consistent and better performance predictions with the help of non-linear and complex relationships among the features. In this paper, deep learning with a meta-heuristic (MH) approach is proposed to perform the feature extraction and feature selection processes. The proposed feature selection phase has two sub-phases, such as DL-based feature extraction and MH-based feature selection. The effective convolutional neural network (CNN) model is implemented to extract the core features that will learn the relevant data representation in a lower-dimensional space. The hybrid meta-heuristic algorithm called Seagull-Elephant Herding Optimization Algorithm (SEHOA) is used to select the most relevant and important features from the CNN extracted features. Autism disorder patients are identified using long-term short-term memory as a classifier. This will detect the ASD using the fMRI image dataset ABIDE (Autism Brain Imaging Data Exchange) and obtain promising results. There are five evaluation metrics such as accuracy, precision, recall, f1-score, and area under the curve (AUC) used. The validated results show that the proposed model performed better, with an accuracy of 98.6%.",
      "intriguing_abstract": "Autism Spectrum Disorder (ASD) is a complicated neurodevelopment disorder that is becoming more common day by day around the world. The literature that uses machine learning (ML) and deep learning (DL) approaches gained interest due to their ability to increase the accuracy of diagnosing disorders and reduce the physician’s workload. These artificial intelligence-based applications can learn and detect patterns automatically through the collection of data. ML approaches are used in various applications where the traditional algorithms have failed to obtain better results. The major advantage of the ML algorithm is its ability to produce consistent and better performance predictions with the help of non-linear and complex relationships among the features. In this paper, deep learning with a meta-heuristic (MH) approach is proposed to perform the feature extraction and feature selection processes. The proposed feature selection phase has two sub-phases, such as DL-based feature extraction and MH-based feature selection. The effective convolutional neural network (CNN) model is implemented to extract the core features that will learn the relevant data representation in a lower-dimensional space. The hybrid meta-heuristic algorithm called Seagull-Elephant Herding Optimization Algorithm (SEHOA) is used to select the most relevant and important features from the CNN extracted features. Autism disorder patients are identified using long-term short-term memory as a classifier. This will detect the ASD using the fMRI image dataset ABIDE (Autism Brain Imaging Data Exchange) and obtain promising results. There are five evaluation metrics such as accuracy, precision, recall, f1-score, and area under the curve (AUC) used. The validated results show that the proposed model performed better, with an accuracy of 98.6%.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/1c741e0d5a1d730830392bf4061f9eba3e9af568.pdf",
      "citation_key": "raja2023hco",
      "metadata": {
        "title": "Deep learning-based feature selection and prediction system for autism spectrum disorder using a hybrid meta-heuristics approach",
        "authors": [
          "K. Raja",
          "S. Kannimuthu"
        ],
        "published_date": "2023",
        "abstract": "Autism Spectrum Disorder (ASD) is a complicated neurodevelopment disorder that is becoming more common day by day around the world. The literature that uses machine learning (ML) and deep learning (DL) approaches gained interest due to their ability to increase the accuracy of diagnosing disorders and reduce the physician’s workload. These artificial intelligence-based applications can learn and detect patterns automatically through the collection of data. ML approaches are used in various applications where the traditional algorithms have failed to obtain better results. The major advantage of the ML algorithm is its ability to produce consistent and better performance predictions with the help of non-linear and complex relationships among the features. In this paper, deep learning with a meta-heuristic (MH) approach is proposed to perform the feature extraction and feature selection processes. The proposed feature selection phase has two sub-phases, such as DL-based feature extraction and MH-based feature selection. The effective convolutional neural network (CNN) model is implemented to extract the core features that will learn the relevant data representation in a lower-dimensional space. The hybrid meta-heuristic algorithm called Seagull-Elephant Herding Optimization Algorithm (SEHOA) is used to select the most relevant and important features from the CNN extracted features. Autism disorder patients are identified using long-term short-term memory as a classifier. This will detect the ASD using the fMRI image dataset ABIDE (Autism Brain Imaging Data Exchange) and obtain promising results. There are five evaluation metrics such as accuracy, precision, recall, f1-score, and area under the curve (AUC) used. The validated results show that the proposed model performed better, with an accuracy of 98.6%.",
        "file_path": "paper_data/Deep_Meta-Learning/info/1c741e0d5a1d730830392bf4061f9eba3e9af568.pdf",
        "venue": "Journal of Intelligent & Fuzzy Systems",
        "citationCount": 6,
        "score": 3.0,
        "summary": "Autism Spectrum Disorder (ASD) is a complicated neurodevelopment disorder that is becoming more common day by day around the world. The literature that uses machine learning (ML) and deep learning (DL) approaches gained interest due to their ability to increase the accuracy of diagnosing disorders and reduce the physician’s workload. These artificial intelligence-based applications can learn and detect patterns automatically through the collection of data. ML approaches are used in various applications where the traditional algorithms have failed to obtain better results. The major advantage of the ML algorithm is its ability to produce consistent and better performance predictions with the help of non-linear and complex relationships among the features. In this paper, deep learning with a meta-heuristic (MH) approach is proposed to perform the feature extraction and feature selection processes. The proposed feature selection phase has two sub-phases, such as DL-based feature extraction and MH-based feature selection. The effective convolutional neural network (CNN) model is implemented to extract the core features that will learn the relevant data representation in a lower-dimensional space. The hybrid meta-heuristic algorithm called Seagull-Elephant Herding Optimization Algorithm (SEHOA) is used to select the most relevant and important features from the CNN extracted features. Autism disorder patients are identified using long-term short-term memory as a classifier. This will detect the ASD using the fMRI image dataset ABIDE (Autism Brain Imaging Data Exchange) and obtain promising results. There are five evaluation metrics such as accuracy, precision, recall, f1-score, and area under the curve (AUC) used. The validated results show that the proposed model performed better, with an accuracy of 98.6%.",
        "keywords": []
      },
      "file_name": "1c741e0d5a1d730830392bf4061f9eba3e9af568.pdf"
    },
    {
      "success": true,
      "doc_id": "70fbf51908bd2fe9dbddf2f9ea109b0f",
      "summary": "Objective: The behavior monitoring of older adults in their own home and enabling daily-life activity analysis to healthcare practitioner is a key challenge. Methods and procedures: Our framework replicates the elderly home in digital space which can provide an unobtrusive way to monitor the resident&ahat;s daily life activities. The learning challenges posed by different performed activities at home are solved by introducing the deep meta-class sequence model. The notion is to group the set of activities into a single meta-class according to the nature of the activities. It helps the learning process, which is based on long short-term memory (LSTM) to learn feature space abstraction. Each meta-class abstraction is further decomposed to an individual activity performed by the elderly at home. Results: The experiments are carried out over the Center for Advanced Studies in Adaptive Systems dataset and proposed model outperforms as compared to baseline models. Clinical impact: Our findings demonstrate a robust framework to digitally monitor the elderly behavior, which is beneficial for healthcare practitioners to understand the level of support the elderly needed to perform the daily tasks or potential risk of an emergency in their own homes.",
      "intriguing_abstract": "Objective: The behavior monitoring of older adults in their own home and enabling daily-life activity analysis to healthcare practitioner is a key challenge. Methods and procedures: Our framework replicates the elderly home in digital space which can provide an unobtrusive way to monitor the resident&ahat;s daily life activities. The learning challenges posed by different performed activities at home are solved by introducing the deep meta-class sequence model. The notion is to group the set of activities into a single meta-class according to the nature of the activities. It helps the learning process, which is based on long short-term memory (LSTM) to learn feature space abstraction. Each meta-class abstraction is further decomposed to an individual activity performed by the elderly at home. Results: The experiments are carried out over the Center for Advanced Studies in Adaptive Systems dataset and proposed model outperforms as compared to baseline models. Clinical impact: Our findings demonstrate a robust framework to digitally monitor the elderly behavior, which is beneficial for healthcare practitioners to understand the level of support the elderly needed to perform the daily tasks or potential risk of an emergency in their own homes.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2b39fc628eb7dca420809d931b0086f1d3161990.pdf",
      "citation_key": "fahim2023jsu",
      "metadata": {
        "title": "Healthy Aging: A Deep Meta-Class Sequence Model to Integrate Intelligence in Digital Twin",
        "authors": [
          "M. Fahim",
          "Vishal Sharma",
          "R. Hunter",
          "T. Duong"
        ],
        "published_date": "2023",
        "abstract": "Objective: The behavior monitoring of older adults in their own home and enabling daily-life activity analysis to healthcare practitioner is a key challenge. Methods and procedures: Our framework replicates the elderly home in digital space which can provide an unobtrusive way to monitor the resident&ahat;s daily life activities. The learning challenges posed by different performed activities at home are solved by introducing the deep meta-class sequence model. The notion is to group the set of activities into a single meta-class according to the nature of the activities. It helps the learning process, which is based on long short-term memory (LSTM) to learn feature space abstraction. Each meta-class abstraction is further decomposed to an individual activity performed by the elderly at home. Results: The experiments are carried out over the Center for Advanced Studies in Adaptive Systems dataset and proposed model outperforms as compared to baseline models. Clinical impact: Our findings demonstrate a robust framework to digitally monitor the elderly behavior, which is beneficial for healthcare practitioners to understand the level of support the elderly needed to perform the daily tasks or potential risk of an emergency in their own homes.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2b39fc628eb7dca420809d931b0086f1d3161990.pdf",
        "venue": "IEEE Journal of Translational Engineering in Health and Medicine",
        "citationCount": 6,
        "score": 3.0,
        "summary": "Objective: The behavior monitoring of older adults in their own home and enabling daily-life activity analysis to healthcare practitioner is a key challenge. Methods and procedures: Our framework replicates the elderly home in digital space which can provide an unobtrusive way to monitor the resident&ahat;s daily life activities. The learning challenges posed by different performed activities at home are solved by introducing the deep meta-class sequence model. The notion is to group the set of activities into a single meta-class according to the nature of the activities. It helps the learning process, which is based on long short-term memory (LSTM) to learn feature space abstraction. Each meta-class abstraction is further decomposed to an individual activity performed by the elderly at home. Results: The experiments are carried out over the Center for Advanced Studies in Adaptive Systems dataset and proposed model outperforms as compared to baseline models. Clinical impact: Our findings demonstrate a robust framework to digitally monitor the elderly behavior, which is beneficial for healthcare practitioners to understand the level of support the elderly needed to perform the daily tasks or potential risk of an emergency in their own homes.",
        "keywords": []
      },
      "file_name": "2b39fc628eb7dca420809d931b0086f1d3161990.pdf"
    },
    {
      "success": true,
      "doc_id": "88b22f35bc0d4392ac1ed35b8b175fdd",
      "summary": "Adversarial examples have raised great concerns about the security of deep learning models. Substitute training makes it possible to conduct black-box substitute attacks in real-world scenarios where the attacker does not need access to the structure, parameters, and training set of the target model. However, existing substitute training methods require a large number of queries on the target model and suffer from low attack success rates. To alleviate these problems, we propose a novel black-box adversarial attack method, named substitute meta-learning (SML), which combines meta-learning with the training of the substitute model. Different from existing substitute training methods that rely on data augmentation tactics or refined loss functions, we aim to boost the learning efficiency of the substitute model to improve training efficiency and attack performance. Specifically, we introduce meta-learning to enable the substitute model to learn the knowledge of the target model using a few queries. Extensive experiments are conducted on MNIST and CIFAR-10 datasets. The experimental results show that the proposed SML can improve the attack success rate from 46.1% to 61.3% while requiring fewer queries.",
      "intriguing_abstract": "Adversarial examples have raised great concerns about the security of deep learning models. Substitute training makes it possible to conduct black-box substitute attacks in real-world scenarios where the attacker does not need access to the structure, parameters, and training set of the target model. However, existing substitute training methods require a large number of queries on the target model and suffer from low attack success rates. To alleviate these problems, we propose a novel black-box adversarial attack method, named substitute meta-learning (SML), which combines meta-learning with the training of the substitute model. Different from existing substitute training methods that rely on data augmentation tactics or refined loss functions, we aim to boost the learning efficiency of the substitute model to improve training efficiency and attack performance. Specifically, we introduce meta-learning to enable the substitute model to learn the knowledge of the target model using a few queries. Extensive experiments are conducted on MNIST and CIFAR-10 datasets. The experimental results show that the proposed SML can improve the attack success rate from 46.1% to 61.3% while requiring fewer queries.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/4317f6713cbb5fd05fb818fbf535097948b176a3.pdf",
      "citation_key": "hu2022y0i",
      "metadata": {
        "title": "Substitute Meta-Learning for Black-Box Adversarial Attack",
        "authors": [
          "Cong Hu",
          "Haoji Xu",
          "Xiaojun Wu"
        ],
        "published_date": "2022",
        "abstract": "Adversarial examples have raised great concerns about the security of deep learning models. Substitute training makes it possible to conduct black-box substitute attacks in real-world scenarios where the attacker does not need access to the structure, parameters, and training set of the target model. However, existing substitute training methods require a large number of queries on the target model and suffer from low attack success rates. To alleviate these problems, we propose a novel black-box adversarial attack method, named substitute meta-learning (SML), which combines meta-learning with the training of the substitute model. Different from existing substitute training methods that rely on data augmentation tactics or refined loss functions, we aim to boost the learning efficiency of the substitute model to improve training efficiency and attack performance. Specifically, we introduce meta-learning to enable the substitute model to learn the knowledge of the target model using a few queries. Extensive experiments are conducted on MNIST and CIFAR-10 datasets. The experimental results show that the proposed SML can improve the attack success rate from 46.1% to 61.3% while requiring fewer queries.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4317f6713cbb5fd05fb818fbf535097948b176a3.pdf",
        "venue": "IEEE Signal Processing Letters",
        "citationCount": 9,
        "score": 3.0,
        "summary": "Adversarial examples have raised great concerns about the security of deep learning models. Substitute training makes it possible to conduct black-box substitute attacks in real-world scenarios where the attacker does not need access to the structure, parameters, and training set of the target model. However, existing substitute training methods require a large number of queries on the target model and suffer from low attack success rates. To alleviate these problems, we propose a novel black-box adversarial attack method, named substitute meta-learning (SML), which combines meta-learning with the training of the substitute model. Different from existing substitute training methods that rely on data augmentation tactics or refined loss functions, we aim to boost the learning efficiency of the substitute model to improve training efficiency and attack performance. Specifically, we introduce meta-learning to enable the substitute model to learn the knowledge of the target model using a few queries. Extensive experiments are conducted on MNIST and CIFAR-10 datasets. The experimental results show that the proposed SML can improve the attack success rate from 46.1% to 61.3% while requiring fewer queries.",
        "keywords": []
      },
      "file_name": "4317f6713cbb5fd05fb818fbf535097948b176a3.pdf"
    },
    {
      "success": true,
      "doc_id": "bdf91e9cfeeb6434bb947996dc72ab09",
      "summary": "Existing malicious encrypted traffic detection approaches need to be trained with many samples to achieve effective detection of a specified class of encrypted traffic data. With the rapid development of encryption technology, various new types of encrypted traffic are emerging and difficult to label. Therefore, it is an urgent problem to train a deep learning model using only a small number of samples to detect new classes of malicious encrypted traffic. This paper proposes a few-shot malicious encrypted traffic detection (FMETD) approach based on model-agnostic meta-learning (MAML), integrating feature selection and classification into an end-to-end framework. The FMETD approach first converts the raw traffic data into two-dimensional grayscale images. Then, FMETD trains a deep learning model (2D-CNN) using the MAML, which is to learn an optimal set of model initialization parameters for the model from a set of classification tasks consisting of grayscale images. The model with this set of parameters can detect new classes of maliciously encrypted traffic data efficiently with a few samples by a few iterations steps. The experimental results show that the FMETD approach has 99.8% accuracy for two-class classification encrypted traffic and 98.5% average accuracy for multi-classification. When the number of grayscale images of each class in the support set and validation set is reduced to 20, the accuracy of our approach to multi-class classification is 97.9% for new classes of traffic.",
      "intriguing_abstract": "Existing malicious encrypted traffic detection approaches need to be trained with many samples to achieve effective detection of a specified class of encrypted traffic data. With the rapid development of encryption technology, various new types of encrypted traffic are emerging and difficult to label. Therefore, it is an urgent problem to train a deep learning model using only a small number of samples to detect new classes of malicious encrypted traffic. This paper proposes a few-shot malicious encrypted traffic detection (FMETD) approach based on model-agnostic meta-learning (MAML), integrating feature selection and classification into an end-to-end framework. The FMETD approach first converts the raw traffic data into two-dimensional grayscale images. Then, FMETD trains a deep learning model (2D-CNN) using the MAML, which is to learn an optimal set of model initialization parameters for the model from a set of classification tasks consisting of grayscale images. The model with this set of parameters can detect new classes of maliciously encrypted traffic data efficiently with a few samples by a few iterations steps. The experimental results show that the FMETD approach has 99.8% accuracy for two-class classification encrypted traffic and 98.5% average accuracy for multi-classification. When the number of grayscale images of each class in the support set and validation set is reduced to 20, the accuracy of our approach to multi-class classification is 97.9% for new classes of traffic.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/7ecab7276a1a0360ad594ae08a0fa91a26ecb025.pdf",
      "citation_key": "wang2023kho",
      "metadata": {
        "title": "A Few-Shot Malicious Encrypted Traffic Detection Approach Based on Model-Agnostic Meta-Learning",
        "authors": [
          "Zhiqiang Wang",
          "Man Li",
          "H. Ou",
          "Shufang Pang",
          "Z. Yue"
        ],
        "published_date": "2023",
        "abstract": "Existing malicious encrypted traffic detection approaches need to be trained with many samples to achieve effective detection of a specified class of encrypted traffic data. With the rapid development of encryption technology, various new types of encrypted traffic are emerging and difficult to label. Therefore, it is an urgent problem to train a deep learning model using only a small number of samples to detect new classes of malicious encrypted traffic. This paper proposes a few-shot malicious encrypted traffic detection (FMETD) approach based on model-agnostic meta-learning (MAML), integrating feature selection and classification into an end-to-end framework. The FMETD approach first converts the raw traffic data into two-dimensional grayscale images. Then, FMETD trains a deep learning model (2D-CNN) using the MAML, which is to learn an optimal set of model initialization parameters for the model from a set of classification tasks consisting of grayscale images. The model with this set of parameters can detect new classes of maliciously encrypted traffic data efficiently with a few samples by a few iterations steps. The experimental results show that the FMETD approach has 99.8% accuracy for two-class classification encrypted traffic and 98.5% average accuracy for multi-classification. When the number of grayscale images of each class in the support set and validation set is reduced to 20, the accuracy of our approach to multi-class classification is 97.9% for new classes of traffic.",
        "file_path": "paper_data/Deep_Meta-Learning/info/7ecab7276a1a0360ad594ae08a0fa91a26ecb025.pdf",
        "venue": "Security and Communication Networks",
        "citationCount": 5,
        "score": 2.5,
        "summary": "Existing malicious encrypted traffic detection approaches need to be trained with many samples to achieve effective detection of a specified class of encrypted traffic data. With the rapid development of encryption technology, various new types of encrypted traffic are emerging and difficult to label. Therefore, it is an urgent problem to train a deep learning model using only a small number of samples to detect new classes of malicious encrypted traffic. This paper proposes a few-shot malicious encrypted traffic detection (FMETD) approach based on model-agnostic meta-learning (MAML), integrating feature selection and classification into an end-to-end framework. The FMETD approach first converts the raw traffic data into two-dimensional grayscale images. Then, FMETD trains a deep learning model (2D-CNN) using the MAML, which is to learn an optimal set of model initialization parameters for the model from a set of classification tasks consisting of grayscale images. The model with this set of parameters can detect new classes of maliciously encrypted traffic data efficiently with a few samples by a few iterations steps. The experimental results show that the FMETD approach has 99.8% accuracy for two-class classification encrypted traffic and 98.5% average accuracy for multi-classification. When the number of grayscale images of each class in the support set and validation set is reduced to 20, the accuracy of our approach to multi-class classification is 97.9% for new classes of traffic.",
        "keywords": []
      },
      "file_name": "7ecab7276a1a0360ad594ae08a0fa91a26ecb025.pdf"
    },
    {
      "success": true,
      "doc_id": "7350280e301b60e3471be050f2c08348",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Problem**: Training deep learning text classification models typically requires a large amount of labeled data, which is labor-intensive and time-consuming. Few-shot text classification aims to predict unknown samples using only a few labeled examples \\cite{li2023zn0}.\n    *   **Importance & Challenge**: While metric-based meta-learning has shown promise in few-shot text classification, existing models primarily focus on learning from a small number of labeled samples and neglect the vast amount of knowledge available in unlabeled data. The challenge is to effectively exploit this unlabeled knowledge to improve the generalization performance of meta-networks \\cite{li2023zn0}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to existing approaches**: This work builds upon metric-based meta-learning methods for few-shot text classification, which use episodic training to enhance generalization \\cite{li2023zn0}. It also incorporates self-supervised learning and knowledge distillation techniques.\n    *   **Limitations of previous solutions**: Existing metric-based meta-learning models for few-shot text classification primarily learn from a few labeled samples, overlooking the valuable information present in a much larger number of unlabeled samples \\cite{li2023zn0}. Furthermore, existing knowledge distillation methods may not effectively transfer self-supervised knowledge to meta-networks in a way that enriches the meta-learning representation itself \\cite{li2023zn0}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes Self-supervised Information Enhanced Meta-Learning (SEML), a two-stage training pipeline \\cite{li2023zn0}.\n        1.  **Self-supervised Training Stage**: A feature encoder (BERT) is trained on unlabeled samples using a self-supervised approach (specifically, self-guided contrastive learning) to learn general knowledge \\cite{li2023zn0}.\n        2.  **Meta-training Stage**:\n            *   The pre-trained self-supervised encoder extracts features for all samples in a given task.\n            *   A novel **graph aggregation method** is employed to efficiently interact query set information with support set information within each task, generating a more discriminative feature representation \\cite{li2023zn0}.\n            *   A novel **knowledge distillation method** is introduced to expand and enrich the meta-learning representation with the self-supervised information learned in the first stage. This fuses all information into a unified distribution to train a meta-network with stronger generalization capability \\cite{li2023zn0}.\n    *   **Novelty**: SEML's novelty lies in its effective integration of self-supervised learning from unlabeled data into metric-based meta-learning for few-shot text classification \\cite{li2023zn0}. Specifically, it introduces:\n        *   A new knowledge distillation method that *enriches* the meta-learning representation with self-supervised information, rather than merely providing additional supervised signals \\cite{li2023zn0}.\n        *   A graph aggregation method with trainable parameters to facilitate effective interaction between support and query sets, leading to more discriminative feature representations \\cite{li2023zn0}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques**:\n        *   A novel knowledge distillation method designed to merge self-supervised knowledge into meta-feature vectors, thereby expanding and enriching the original representation and improving the meta-network's generalization ability \\cite{li2023zn0}.\n        *   A graph aggregation method utilizing a graph structure with trainable parameters to aggregate node information, enabling effective interaction between support and query sets to generate more discriminative feature representations \\cite{li2023zn0}.\n    *   **System design or architectural innovations**: A two-stage training pipeline that first leverages self-supervised learning on unlabeled data and then integrates this knowledge into a meta-training process via a specialized knowledge distillation and graph aggregation module \\cite{li2023zn0}.\n\n*   **5. Experimental Validation**\n    *   **Experiments conducted**: Extensive experiments were performed on three public few-shot text classification datasets \\cite{li2023zn0}.\n    *   **Key performance metrics and comparison results**: The model's performance was evaluated using multiple metrics. Experimental results demonstrate that SEML outperforms state-of-the-art models in both 5-way 1-shot and 5-way 5-shot few-shot text classification scenarios \\cite{li2023zn0}.\n\n*   **6. Limitations & Scope**\n    *   **Technical limitations or assumptions**: The paper does not explicitly detail limitations of SEML itself, but it addresses the limitations of prior work in neglecting unlabeled data. The self-supervised stage relies on a specific contrastive learning approach (self-guided contrastive learning) \\cite{li2023zn0}.\n    *   **Scope of applicability**: The method is specifically designed for few-shot text classification tasks, particularly N-way K-shot settings (e.g., 5-way 1-shot and 5-way 5-shot) \\cite{li2023zn0}.\n\n*   **7. Technical Significance**\n    *   **Advancement of state-of-the-art**: SEML significantly advances the technical state-of-the-art in few-shot text classification by effectively integrating self-supervised learning from unlabeled data into meta-learning, leading to improved generalization capabilities and superior performance compared to existing models \\cite{li2023zn0}.\n    *   **Potential impact on future research**: This work highlights the critical role of unlabeled data in few-shot learning and provides a novel framework for its exploitation. The proposed knowledge distillation and graph aggregation techniques could inspire future research in developing more robust and generalizable meta-learning models across various few-shot tasks, especially where unlabeled data is abundant \\cite{li2023zn0}.",
      "intriguing_abstract": "The scarcity of labeled data remains a critical bottleneck in few-shot text classification, with current meta-learning approaches often overlooking the vast potential of unlabeled information. We introduce Self-supervised Information Enhanced Meta-Learning (SEML), a novel framework that fundamentally redefines how meta-networks leverage data for superior generalization. SEML employs a two-stage pipeline: first, a BERT-based feature encoder is pre-trained via self-guided contrastive learning on unlabeled samples to capture robust general knowledge. Crucially, during meta-training, this self-supervised knowledge is *enriched* into the meta-learning representation through a novel knowledge distillation method, expanding its expressive power. Concurrently, a trainable graph aggregation mechanism facilitates dynamic interaction between support and query sets, generating highly discriminative feature embeddings. Extensive experiments on three public datasets demonstrate that SEML significantly outperforms state-of-the-art models in both 5-way 1-shot and 5-way 5-shot scenarios. Our work offers a powerful paradigm for exploiting unlabeled data in few-shot learning, paving the way for more robust and generalizable text classification systems.",
      "keywords": [
        "Few-shot text classification",
        "meta-learning",
        "self-supervised learning",
        "unlabeled data exploitation",
        "Self-supervised Information Enhanced Meta-Learning (SEML)",
        "knowledge distillation",
        "graph aggregation method",
        "two-stage training pipeline",
        "BERT encoder",
        "contrastive learning",
        "generalization performance",
        "state-of-the-art performance",
        "discriminative feature representation"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/2e3e8a56981df1e33d93284be43f81704abc5795.pdf",
      "citation_key": "li2023zn0",
      "metadata": {
        "title": "SEML: Self-Supervised Information-Enhanced Meta-learning for Few-Shot Text Classification",
        "authors": [
          "Hui Li",
          "Guimin Huang",
          "Yiqun Li",
          "Xiaowei Zhang",
          "Yabing Wang",
          "Jun Li"
        ],
        "published_date": "2023",
        "abstract": "Training a deep-learning text classification model usually requires a large amount of labeled data, yet labeling data are usually labor-intensive and time-consuming. Few-shot text classification focuses on predicting unknown samples using only a few labeled samples. Recently, metric-based meta-learning methods have achieved promising results in few-shot text classification. They use episodic training in labeled samples to enhance the model’s generalization ability. However, existing models only focus on learning from a few labeled samples but neglect to learn from a large number of unlabeled samples. In this paper, we exploit the knowledge learned by the model in unlabeled samples to improve the generalization performance of the meta-network. Specifically, we introduce a novel knowledge distillation method that expands and enriches the meta-learning representation with self-supervised information. Meanwhile, we design a graph aggregation method that efficiently interacts the query set information with the support set information in each task and outputs a more discriminative representation. We conducted experiments on three public few-shot text classification datasets. The experimental results show that our model performs better than the state-of-the-art models in 5-way 1-shot and 5-way 5-shot cases.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2e3e8a56981df1e33d93284be43f81704abc5795.pdf",
        "venue": "International Journal of Computational Intelligence Systems",
        "citationCount": 5,
        "score": 2.5,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Problem**: Training deep learning text classification models typically requires a large amount of labeled data, which is labor-intensive and time-consuming. Few-shot text classification aims to predict unknown samples using only a few labeled examples \\cite{li2023zn0}.\n    *   **Importance & Challenge**: While metric-based meta-learning has shown promise in few-shot text classification, existing models primarily focus on learning from a small number of labeled samples and neglect the vast amount of knowledge available in unlabeled data. The challenge is to effectively exploit this unlabeled knowledge to improve the generalization performance of meta-networks \\cite{li2023zn0}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to existing approaches**: This work builds upon metric-based meta-learning methods for few-shot text classification, which use episodic training to enhance generalization \\cite{li2023zn0}. It also incorporates self-supervised learning and knowledge distillation techniques.\n    *   **Limitations of previous solutions**: Existing metric-based meta-learning models for few-shot text classification primarily learn from a few labeled samples, overlooking the valuable information present in a much larger number of unlabeled samples \\cite{li2023zn0}. Furthermore, existing knowledge distillation methods may not effectively transfer self-supervised knowledge to meta-networks in a way that enriches the meta-learning representation itself \\cite{li2023zn0}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes Self-supervised Information Enhanced Meta-Learning (SEML), a two-stage training pipeline \\cite{li2023zn0}.\n        1.  **Self-supervised Training Stage**: A feature encoder (BERT) is trained on unlabeled samples using a self-supervised approach (specifically, self-guided contrastive learning) to learn general knowledge \\cite{li2023zn0}.\n        2.  **Meta-training Stage**:\n            *   The pre-trained self-supervised encoder extracts features for all samples in a given task.\n            *   A novel **graph aggregation method** is employed to efficiently interact query set information with support set information within each task, generating a more discriminative feature representation \\cite{li2023zn0}.\n            *   A novel **knowledge distillation method** is introduced to expand and enrich the meta-learning representation with the self-supervised information learned in the first stage. This fuses all information into a unified distribution to train a meta-network with stronger generalization capability \\cite{li2023zn0}.\n    *   **Novelty**: SEML's novelty lies in its effective integration of self-supervised learning from unlabeled data into metric-based meta-learning for few-shot text classification \\cite{li2023zn0}. Specifically, it introduces:\n        *   A new knowledge distillation method that *enriches* the meta-learning representation with self-supervised information, rather than merely providing additional supervised signals \\cite{li2023zn0}.\n        *   A graph aggregation method with trainable parameters to facilitate effective interaction between support and query sets, leading to more discriminative feature representations \\cite{li2023zn0}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques**:\n        *   A novel knowledge distillation method designed to merge self-supervised knowledge into meta-feature vectors, thereby expanding and enriching the original representation and improving the meta-network's generalization ability \\cite{li2023zn0}.\n        *   A graph aggregation method utilizing a graph structure with trainable parameters to aggregate node information, enabling effective interaction between support and query sets to generate more discriminative feature representations \\cite{li2023zn0}.\n    *   **System design or architectural innovations**: A two-stage training pipeline that first leverages self-supervised learning on unlabeled data and then integrates this knowledge into a meta-training process via a specialized knowledge distillation and graph aggregation module \\cite{li2023zn0}.\n\n*   **5. Experimental Validation**\n    *   **Experiments conducted**: Extensive experiments were performed on three public few-shot text classification datasets \\cite{li2023zn0}.\n    *   **Key performance metrics and comparison results**: The model's performance was evaluated using multiple metrics. Experimental results demonstrate that SEML outperforms state-of-the-art models in both 5-way 1-shot and 5-way 5-shot few-shot text classification scenarios \\cite{li2023zn0}.\n\n*   **6. Limitations & Scope**\n    *   **Technical limitations or assumptions**: The paper does not explicitly detail limitations of SEML itself, but it addresses the limitations of prior work in neglecting unlabeled data. The self-supervised stage relies on a specific contrastive learning approach (self-guided contrastive learning) \\cite{li2023zn0}.\n    *   **Scope of applicability**: The method is specifically designed for few-shot text classification tasks, particularly N-way K-shot settings (e.g., 5-way 1-shot and 5-way 5-shot) \\cite{li2023zn0}.\n\n*   **7. Technical Significance**\n    *   **Advancement of state-of-the-art**: SEML significantly advances the technical state-of-the-art in few-shot text classification by effectively integrating self-supervised learning from unlabeled data into meta-learning, leading to improved generalization capabilities and superior performance compared to existing models \\cite{li2023zn0}.\n    *   **Potential impact on future research**: This work highlights the critical role of unlabeled data in few-shot learning and provides a novel framework for its exploitation. The proposed knowledge distillation and graph aggregation techniques could inspire future research in developing more robust and generalizable meta-learning models across various few-shot tasks, especially where unlabeled data is abundant \\cite{li2023zn0}.",
        "keywords": [
          "Few-shot text classification",
          "meta-learning",
          "self-supervised learning",
          "unlabeled data exploitation",
          "Self-supervised Information Enhanced Meta-Learning (SEML)",
          "knowledge distillation",
          "graph aggregation method",
          "two-stage training pipeline",
          "BERT encoder",
          "contrastive learning",
          "generalization performance",
          "state-of-the-art performance",
          "discriminative feature representation"
        ],
        "paper_type": "based on the abstract and introduction, this paper clearly falls under the **technical** type.\n\nhere's why:\n\n*   **abstract mentions:**\n    *   \"we exploit the knowledge learned by the model... to improve the generalization performance...\" (implies a new approach/method)\n    *   \"we introduce a novel knowledge distillation method...\" (explicitly states a \"novel method\")\n    *   \"we design a graph aggregation method...\" (explicitly states designing a \"method\")\n    *   \"our model performs better than the state-of-the-art models...\" (evaluating a proposed system/method)\n*   **introduction discusses:**\n    *   a technical problem: \"few-shot text classiﬁcation\" and the limitations of existing approaches (\"existing models only focus on learning from a few labeled samples but neglect to learn from a large number of unlabeled samples\").\n    *   sets the stage for the proposed solution (which is then detailed in the abstract).\n\nthe paper's primary contribution is the development and presentation of new methods (seml, knowledge distillation, graph aggregation) to solve a specific technical challenge in few-shot text classification. the experiments are conducted to validate these proposed methods."
      },
      "file_name": "2e3e8a56981df1e33d93284be43f81704abc5795.pdf"
    },
    {
      "success": true,
      "doc_id": "db06ecbe608a46ba29870dd2865c60ae",
      "summary": "Practical natural language processing (NLP) tasks often exhibit long-tailed distributions accompanied by noisy labels, posing significant challenges to the generalization and robustness of complex models such as Deep Neural Networks (DNNs). Traditional resampling techniques like oversampling or undersampling, while commonly employed, can easily lead to overfitting. A growing trend involves leveraging small amounts of metadata to learn data weights, alongside the demonstrated benefits of self-supervised pre-training, particularly for under-represented data. In this work, we propose a general framework that addresses both the long-tail and noisy label issues. Our model is adaptively tailored to the problem domain using a contrastive learning approach. The re-weighting module, a feed-forward network, learns explicit weighting functions and adjusts weights based on metadata. Additionally, our framework modifies the weights of terms in the loss function through a combination of polynomial expansion of the cross-entropy loss and focal loss. Extensive experiments consistently demonstrate the superior performance of our proposed framework compared to baseline methods. Finally, our comprehensive sensitivity analysis underscores the efficacy of the proposed framework in handling long-tailed problems and mitigating the adverse effects of noisy labels.",
      "intriguing_abstract": "Practical natural language processing (NLP) tasks often exhibit long-tailed distributions accompanied by noisy labels, posing significant challenges to the generalization and robustness of complex models such as Deep Neural Networks (DNNs). Traditional resampling techniques like oversampling or undersampling, while commonly employed, can easily lead to overfitting. A growing trend involves leveraging small amounts of metadata to learn data weights, alongside the demonstrated benefits of self-supervised pre-training, particularly for under-represented data. In this work, we propose a general framework that addresses both the long-tail and noisy label issues. Our model is adaptively tailored to the problem domain using a contrastive learning approach. The re-weighting module, a feed-forward network, learns explicit weighting functions and adjusts weights based on metadata. Additionally, our framework modifies the weights of terms in the loss function through a combination of polynomial expansion of the cross-entropy loss and focal loss. Extensive experiments consistently demonstrate the superior performance of our proposed framework compared to baseline methods. Finally, our comprehensive sensitivity analysis underscores the efficacy of the proposed framework in handling long-tailed problems and mitigating the adverse effects of noisy labels.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/6da2203f2cbd3c9530764fab58ef74acb8a2c585.pdf",
      "citation_key": "chi20235vq",
      "metadata": {
        "title": "APAM: Adaptive Pre-Training and Adaptive Meta Learning in Language Model for Noisy Labels and Long-Tailed Learning",
        "authors": [
          "Sunyi Chi",
          "B. Dong",
          "Yiming Xu",
          "Zhenyu Shi",
          "Zheng Du"
        ],
        "published_date": "2023",
        "abstract": "Practical natural language processing (NLP) tasks often exhibit long-tailed distributions accompanied by noisy labels, posing significant challenges to the generalization and robustness of complex models such as Deep Neural Networks (DNNs). Traditional resampling techniques like oversampling or undersampling, while commonly employed, can easily lead to overfitting. A growing trend involves leveraging small amounts of metadata to learn data weights, alongside the demonstrated benefits of self-supervised pre-training, particularly for under-represented data. In this work, we propose a general framework that addresses both the long-tail and noisy label issues. Our model is adaptively tailored to the problem domain using a contrastive learning approach. The re-weighting module, a feed-forward network, learns explicit weighting functions and adjusts weights based on metadata. Additionally, our framework modifies the weights of terms in the loss function through a combination of polynomial expansion of the cross-entropy loss and focal loss. Extensive experiments consistently demonstrate the superior performance of our proposed framework compared to baseline methods. Finally, our comprehensive sensitivity analysis underscores the efficacy of the proposed framework in handling long-tailed problems and mitigating the adverse effects of noisy labels.",
        "file_path": "paper_data/Deep_Meta-Learning/info/6da2203f2cbd3c9530764fab58ef74acb8a2c585.pdf",
        "venue": "International Conference on Machine Learning and Applications",
        "citationCount": 5,
        "score": 2.5,
        "summary": "Practical natural language processing (NLP) tasks often exhibit long-tailed distributions accompanied by noisy labels, posing significant challenges to the generalization and robustness of complex models such as Deep Neural Networks (DNNs). Traditional resampling techniques like oversampling or undersampling, while commonly employed, can easily lead to overfitting. A growing trend involves leveraging small amounts of metadata to learn data weights, alongside the demonstrated benefits of self-supervised pre-training, particularly for under-represented data. In this work, we propose a general framework that addresses both the long-tail and noisy label issues. Our model is adaptively tailored to the problem domain using a contrastive learning approach. The re-weighting module, a feed-forward network, learns explicit weighting functions and adjusts weights based on metadata. Additionally, our framework modifies the weights of terms in the loss function through a combination of polynomial expansion of the cross-entropy loss and focal loss. Extensive experiments consistently demonstrate the superior performance of our proposed framework compared to baseline methods. Finally, our comprehensive sensitivity analysis underscores the efficacy of the proposed framework in handling long-tailed problems and mitigating the adverse effects of noisy labels.",
        "keywords": []
      },
      "file_name": "6da2203f2cbd3c9530764fab58ef74acb8a2c585.pdf"
    },
    {
      "success": true,
      "doc_id": "302ccf3f8f9a1211ccccc29b83bb1f66",
      "summary": "Centralized chiller plants with multiple chillers are typically over-provisioned. Therefore, intelligent scheduling is required for the supply (operating chillers) to efficiently meet the demand (actual cooling load of buildings). Traditional cooling-load based control (CLC) may result in poor part-loaded efficiency. Recent data-driven approaches to chiller control either unrealistically assume perfect knowledge of individual chiller power at various leaving chilled water temperatures (LWTs) or control all chillers with same LWT. We complement existing work with iChill, an end-to-end learning-based intelligent chiller power prediction and scheduling strategy. First, given a dataset of chillers of varying capacities, each of which operates at a fixed LWT and varying loads, iChill meta-learns a model for power prediction. Specifically, for an unseen target chiller, the meta-learned model is re-trained with known LWT to predict power at unseen LWT. Second, given the configuration of a chiller plant and a cooling load profile, iChill learns to schedule individual chillers by jointly deciding the ON/OFF status and LWT; using deep reinforcement learning (DRL). We train and evaluate iChill in a simulated environment with real-world data from a chiller plant of 22 chillers. Specifically, we compare iChill's (1) meta-learned power model with regular transfer learning; and (2) DRL scheduling with multiple baselines including CLC and an oracle model-based predictive control (MPC) strategy with perfect knowledge. We find that iChill's (1) meta-learning improves over transfer learning by up to 15.5%; and (2) DRL scheduling saves 11.5% energy over CLC and is comparable with oracle MPC (12% over CLC). Finally, off-line pre-training of iChill's DRL on the meta-learned chiller models reduces the need for real-world training experimentation by 11x from 3 years to 96 days.",
      "intriguing_abstract": "Centralized chiller plants with multiple chillers are typically over-provisioned. Therefore, intelligent scheduling is required for the supply (operating chillers) to efficiently meet the demand (actual cooling load of buildings). Traditional cooling-load based control (CLC) may result in poor part-loaded efficiency. Recent data-driven approaches to chiller control either unrealistically assume perfect knowledge of individual chiller power at various leaving chilled water temperatures (LWTs) or control all chillers with same LWT. We complement existing work with iChill, an end-to-end learning-based intelligent chiller power prediction and scheduling strategy. First, given a dataset of chillers of varying capacities, each of which operates at a fixed LWT and varying loads, iChill meta-learns a model for power prediction. Specifically, for an unseen target chiller, the meta-learned model is re-trained with known LWT to predict power at unseen LWT. Second, given the configuration of a chiller plant and a cooling load profile, iChill learns to schedule individual chillers by jointly deciding the ON/OFF status and LWT; using deep reinforcement learning (DRL). We train and evaluate iChill in a simulated environment with real-world data from a chiller plant of 22 chillers. Specifically, we compare iChill's (1) meta-learned power model with regular transfer learning; and (2) DRL scheduling with multiple baselines including CLC and an oracle model-based predictive control (MPC) strategy with perfect knowledge. We find that iChill's (1) meta-learning improves over transfer learning by up to 15.5%; and (2) DRL scheduling saves 11.5% energy over CLC and is comparable with oracle MPC (12% over CLC). Finally, off-line pre-training of iChill's DRL on the meta-learned chiller models reduces the need for real-world training experimentation by 11x from 3 years to 96 days.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2c8e887bc26c2021c683fe701dd794dd7467e695.pdf",
      "citation_key": "manoharan2021r46",
      "metadata": {
        "title": "Learn to chill: intelligent chiller scheduling using meta-learning and deep reinforcement learning",
        "authors": [
          "Praveen Manoharan",
          "Malini Pooni Venkat",
          "S. Nagarathinam",
          "Arunchandar Vasan"
        ],
        "published_date": "2021",
        "abstract": "Centralized chiller plants with multiple chillers are typically over-provisioned. Therefore, intelligent scheduling is required for the supply (operating chillers) to efficiently meet the demand (actual cooling load of buildings). Traditional cooling-load based control (CLC) may result in poor part-loaded efficiency. Recent data-driven approaches to chiller control either unrealistically assume perfect knowledge of individual chiller power at various leaving chilled water temperatures (LWTs) or control all chillers with same LWT. We complement existing work with iChill, an end-to-end learning-based intelligent chiller power prediction and scheduling strategy. First, given a dataset of chillers of varying capacities, each of which operates at a fixed LWT and varying loads, iChill meta-learns a model for power prediction. Specifically, for an unseen target chiller, the meta-learned model is re-trained with known LWT to predict power at unseen LWT. Second, given the configuration of a chiller plant and a cooling load profile, iChill learns to schedule individual chillers by jointly deciding the ON/OFF status and LWT; using deep reinforcement learning (DRL). We train and evaluate iChill in a simulated environment with real-world data from a chiller plant of 22 chillers. Specifically, we compare iChill's (1) meta-learned power model with regular transfer learning; and (2) DRL scheduling with multiple baselines including CLC and an oracle model-based predictive control (MPC) strategy with perfect knowledge. We find that iChill's (1) meta-learning improves over transfer learning by up to 15.5%; and (2) DRL scheduling saves 11.5% energy over CLC and is comparable with oracle MPC (12% over CLC). Finally, off-line pre-training of iChill's DRL on the meta-learned chiller models reduces the need for real-world training experimentation by 11x from 3 years to 96 days.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2c8e887bc26c2021c683fe701dd794dd7467e695.pdf",
        "venue": "International Conference on Systems for Energy-Efficient Built Environments",
        "citationCount": 9,
        "score": 2.25,
        "summary": "Centralized chiller plants with multiple chillers are typically over-provisioned. Therefore, intelligent scheduling is required for the supply (operating chillers) to efficiently meet the demand (actual cooling load of buildings). Traditional cooling-load based control (CLC) may result in poor part-loaded efficiency. Recent data-driven approaches to chiller control either unrealistically assume perfect knowledge of individual chiller power at various leaving chilled water temperatures (LWTs) or control all chillers with same LWT. We complement existing work with iChill, an end-to-end learning-based intelligent chiller power prediction and scheduling strategy. First, given a dataset of chillers of varying capacities, each of which operates at a fixed LWT and varying loads, iChill meta-learns a model for power prediction. Specifically, for an unseen target chiller, the meta-learned model is re-trained with known LWT to predict power at unseen LWT. Second, given the configuration of a chiller plant and a cooling load profile, iChill learns to schedule individual chillers by jointly deciding the ON/OFF status and LWT; using deep reinforcement learning (DRL). We train and evaluate iChill in a simulated environment with real-world data from a chiller plant of 22 chillers. Specifically, we compare iChill's (1) meta-learned power model with regular transfer learning; and (2) DRL scheduling with multiple baselines including CLC and an oracle model-based predictive control (MPC) strategy with perfect knowledge. We find that iChill's (1) meta-learning improves over transfer learning by up to 15.5%; and (2) DRL scheduling saves 11.5% energy over CLC and is comparable with oracle MPC (12% over CLC). Finally, off-line pre-training of iChill's DRL on the meta-learned chiller models reduces the need for real-world training experimentation by 11x from 3 years to 96 days.",
        "keywords": []
      },
      "file_name": "2c8e887bc26c2021c683fe701dd794dd7467e695.pdf"
    },
    {
      "success": true,
      "doc_id": "7d1bcac9d8335c19ffdb9d3c8543bcaa",
      "summary": "This paper presents an adaptive energy-aware prediction and planning framework for vehicles navigating over terrains with varying and unknown properties. A novel feature of the method is the use of a deep meta-learning framework to learn a prior energy model, which can efficiently adapt to the local terrain conditions based on small quantities of exteroceptive and proprioceptive data. A meta-adaptive heuristic function is also proposed for the integration of the energy model into an A* path planner. The performance of the proposed approach is assessed in a 3D-body dynamic simulator over several typologies of deformable terrains and compared with alternative machine learning solutions. We provide evidence of the advantages of the proposed method to adapt to unforeseen terrain conditions, thereby yielding more informed estimations and energy-efficient paths when navigating on unknown terrains.",
      "intriguing_abstract": "This paper presents an adaptive energy-aware prediction and planning framework for vehicles navigating over terrains with varying and unknown properties. A novel feature of the method is the use of a deep meta-learning framework to learn a prior energy model, which can efficiently adapt to the local terrain conditions based on small quantities of exteroceptive and proprioceptive data. A meta-adaptive heuristic function is also proposed for the integration of the energy model into an A* path planner. The performance of the proposed approach is assessed in a 3D-body dynamic simulator over several typologies of deformable terrains and compared with alternative machine learning solutions. We provide evidence of the advantages of the proposed method to adapt to unforeseen terrain conditions, thereby yielding more informed estimations and energy-efficient paths when navigating on unknown terrains.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/61b03c891489247bcb5ad432b4d485784a274fb4.pdf",
      "citation_key": "visca20217nt",
      "metadata": {
        "title": "Deep Meta-Learning Energy-Aware Path Planner for Unmanned Ground Vehicles in Unknown Terrains",
        "authors": [
          "Marco Visca",
          "R. Powell",
          "Yang Gao",
          "Saber Fallah"
        ],
        "published_date": "2021",
        "abstract": "This paper presents an adaptive energy-aware prediction and planning framework for vehicles navigating over terrains with varying and unknown properties. A novel feature of the method is the use of a deep meta-learning framework to learn a prior energy model, which can efficiently adapt to the local terrain conditions based on small quantities of exteroceptive and proprioceptive data. A meta-adaptive heuristic function is also proposed for the integration of the energy model into an A* path planner. The performance of the proposed approach is assessed in a 3D-body dynamic simulator over several typologies of deformable terrains and compared with alternative machine learning solutions. We provide evidence of the advantages of the proposed method to adapt to unforeseen terrain conditions, thereby yielding more informed estimations and energy-efficient paths when navigating on unknown terrains.",
        "file_path": "paper_data/Deep_Meta-Learning/info/61b03c891489247bcb5ad432b4d485784a274fb4.pdf",
        "venue": "IEEE Access",
        "citationCount": 8,
        "score": 2.0,
        "summary": "This paper presents an adaptive energy-aware prediction and planning framework for vehicles navigating over terrains with varying and unknown properties. A novel feature of the method is the use of a deep meta-learning framework to learn a prior energy model, which can efficiently adapt to the local terrain conditions based on small quantities of exteroceptive and proprioceptive data. A meta-adaptive heuristic function is also proposed for the integration of the energy model into an A* path planner. The performance of the proposed approach is assessed in a 3D-body dynamic simulator over several typologies of deformable terrains and compared with alternative machine learning solutions. We provide evidence of the advantages of the proposed method to adapt to unforeseen terrain conditions, thereby yielding more informed estimations and energy-efficient paths when navigating on unknown terrains.",
        "keywords": []
      },
      "file_name": "61b03c891489247bcb5ad432b4d485784a274fb4.pdf"
    },
    {
      "success": true,
      "doc_id": "845cc6cd6dd5472a8baa2928c11b7214",
      "summary": "Meta-learning has emerged as a new paradigm in AI to challenge the limitation of conventional deep learning to acquire only task-specific knowledge. Meta-learning transcends this limitation by extracting the general concepts when learning tasks to apply these concepts later when learning new tasks. One popular meta-learning approach is model-agnostic meta-learning (MAML) which learns tasks by optimizing parameters towards highest generalizability of future tasks. The present paper applied a practical implementation of MAML to conduct an image classification task. Results showed that performance on learning new tasks neared training performance without overfitting. Furthermore, optimal values for inner-loop and outer-loop learning rate were close to default parameter values. Smaller batch sizes with more epochs improved learning in earlier epochs compared to larger batch sizes with fewer epochs. These findings show that MAML is able to transfer the concepts extracted during training effectively on to new tasks which it had not been trained on, similarly to how humans transfer knowledge.",
      "intriguing_abstract": "Meta-learning has emerged as a new paradigm in AI to challenge the limitation of conventional deep learning to acquire only task-specific knowledge. Meta-learning transcends this limitation by extracting the general concepts when learning tasks to apply these concepts later when learning new tasks. One popular meta-learning approach is model-agnostic meta-learning (MAML) which learns tasks by optimizing parameters towards highest generalizability of future tasks. The present paper applied a practical implementation of MAML to conduct an image classification task. Results showed that performance on learning new tasks neared training performance without overfitting. Furthermore, optimal values for inner-loop and outer-loop learning rate were close to default parameter values. Smaller batch sizes with more epochs improved learning in earlier epochs compared to larger batch sizes with fewer epochs. These findings show that MAML is able to transfer the concepts extracted during training effectively on to new tasks which it had not been trained on, similarly to how humans transfer knowledge.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/1eee17fd5f7a36a64c771d89dbbb00319935c6a8.pdf",
      "citation_key": "so2021y48",
      "metadata": {
        "title": "Exploring Meta Learning: Parameterizing the Learning-to-learn Process for Image Classification",
        "authors": [
          "Chaehan So"
        ],
        "published_date": "2021",
        "abstract": "Meta-learning has emerged as a new paradigm in AI to challenge the limitation of conventional deep learning to acquire only task-specific knowledge. Meta-learning transcends this limitation by extracting the general concepts when learning tasks to apply these concepts later when learning new tasks. One popular meta-learning approach is model-agnostic meta-learning (MAML) which learns tasks by optimizing parameters towards highest generalizability of future tasks. The present paper applied a practical implementation of MAML to conduct an image classification task. Results showed that performance on learning new tasks neared training performance without overfitting. Furthermore, optimal values for inner-loop and outer-loop learning rate were close to default parameter values. Smaller batch sizes with more epochs improved learning in earlier epochs compared to larger batch sizes with fewer epochs. These findings show that MAML is able to transfer the concepts extracted during training effectively on to new tasks which it had not been trained on, similarly to how humans transfer knowledge.",
        "file_path": "paper_data/Deep_Meta-Learning/info/1eee17fd5f7a36a64c771d89dbbb00319935c6a8.pdf",
        "venue": "Digital Signal Processing and Signal Processing Education Workshop",
        "citationCount": 8,
        "score": 2.0,
        "summary": "Meta-learning has emerged as a new paradigm in AI to challenge the limitation of conventional deep learning to acquire only task-specific knowledge. Meta-learning transcends this limitation by extracting the general concepts when learning tasks to apply these concepts later when learning new tasks. One popular meta-learning approach is model-agnostic meta-learning (MAML) which learns tasks by optimizing parameters towards highest generalizability of future tasks. The present paper applied a practical implementation of MAML to conduct an image classification task. Results showed that performance on learning new tasks neared training performance without overfitting. Furthermore, optimal values for inner-loop and outer-loop learning rate were close to default parameter values. Smaller batch sizes with more epochs improved learning in earlier epochs compared to larger batch sizes with fewer epochs. These findings show that MAML is able to transfer the concepts extracted during training effectively on to new tasks which it had not been trained on, similarly to how humans transfer knowledge.",
        "keywords": []
      },
      "file_name": "1eee17fd5f7a36a64c771d89dbbb00319935c6a8.pdf"
    },
    {
      "success": true,
      "doc_id": "8c500c50496919b937365305836b4823",
      "summary": "Multi-user multiple-input multiple-output (MU-MIMO) beamforming design is typically formulated as a non-convex weighted sum rate (WSR) maximization problem that is known to be NP-hard. This problem is solved either by iterative algorithms, which suffer from slow convergence, or more recently by using deep learning tools, which require time-consuming pre-training process. In this paper, we propose a low-complexity meta-learning based gradient descent algorithm. A meta network with lightweight architecture is applied to learn an adaptive gradient descent update rule to directly optimize the beamformer. This lightweight network is trained during the iterative optimization process, which we refer to as training while solving, which removes both the training process and the data-dependency of existing deep learning based solutions. Extensive simulations show that the proposed method achieves superior WSR performance compared to existing learning-based approaches as well as the conventional weighted minimum mean square error (WMMSE) algorithm, while enjoying much lower computational load.",
      "intriguing_abstract": "Multi-user multiple-input multiple-output (MU-MIMO) beamforming design is typically formulated as a non-convex weighted sum rate (WSR) maximization problem that is known to be NP-hard. This problem is solved either by iterative algorithms, which suffer from slow convergence, or more recently by using deep learning tools, which require time-consuming pre-training process. In this paper, we propose a low-complexity meta-learning based gradient descent algorithm. A meta network with lightweight architecture is applied to learn an adaptive gradient descent update rule to directly optimize the beamformer. This lightweight network is trained during the iterative optimization process, which we refer to as training while solving, which removes both the training process and the data-dependency of existing deep learning based solutions. Extensive simulations show that the proposed method achieves superior WSR performance compared to existing learning-based approaches as well as the conventional weighted minimum mean square error (WMMSE) algorithm, while enjoying much lower computational load.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/28194a351abc44fb9553ccc89d9be3f03b544889.pdf",
      "citation_key": "yang2022oxf",
      "metadata": {
        "title": "A Meta-Learning based Gradient Descent Algorithm for MU-MIMO Beamforming",
        "authors": [
          "Zhixiong Yang",
          "Jingyuan Xia",
          "T. Qiu",
          "Huaizhang Liao",
          "Deniz Gündüz"
        ],
        "published_date": "2022",
        "abstract": "Multi-user multiple-input multiple-output (MU-MIMO) beamforming design is typically formulated as a non-convex weighted sum rate (WSR) maximization problem that is known to be NP-hard. This problem is solved either by iterative algorithms, which suffer from slow convergence, or more recently by using deep learning tools, which require time-consuming pre-training process. In this paper, we propose a low-complexity meta-learning based gradient descent algorithm. A meta network with lightweight architecture is applied to learn an adaptive gradient descent update rule to directly optimize the beamformer. This lightweight network is trained during the iterative optimization process, which we refer to as training while solving, which removes both the training process and the data-dependency of existing deep learning based solutions. Extensive simulations show that the proposed method achieves superior WSR performance compared to existing learning-based approaches as well as the conventional weighted minimum mean square error (WMMSE) algorithm, while enjoying much lower computational load.",
        "file_path": "paper_data/Deep_Meta-Learning/info/28194a351abc44fb9553ccc89d9be3f03b544889.pdf",
        "venue": "International Conference on Wireless Communications and Signal Processing",
        "citationCount": 6,
        "score": 2.0,
        "summary": "Multi-user multiple-input multiple-output (MU-MIMO) beamforming design is typically formulated as a non-convex weighted sum rate (WSR) maximization problem that is known to be NP-hard. This problem is solved either by iterative algorithms, which suffer from slow convergence, or more recently by using deep learning tools, which require time-consuming pre-training process. In this paper, we propose a low-complexity meta-learning based gradient descent algorithm. A meta network with lightweight architecture is applied to learn an adaptive gradient descent update rule to directly optimize the beamformer. This lightweight network is trained during the iterative optimization process, which we refer to as training while solving, which removes both the training process and the data-dependency of existing deep learning based solutions. Extensive simulations show that the proposed method achieves superior WSR performance compared to existing learning-based approaches as well as the conventional weighted minimum mean square error (WMMSE) algorithm, while enjoying much lower computational load.",
        "keywords": []
      },
      "file_name": "28194a351abc44fb9553ccc89d9be3f03b544889.pdf"
    },
    {
      "success": true,
      "doc_id": "2dcbf976d7f2e847e6217c89bfb252fa",
      "summary": "Most of the existing works in supervised spatio-temporal video super-resolution (STVSR) heavily rely on a large-scale external dataset consisting of paired low-resolution low-frame rate (LR-LFR) and high-resolution high-frame-rate (HR-HFR) videos. Despite their remarkable performance, these methods make a prior assumption that the low-resolution video is obtained by down-scaling the high-resolution video using a known degradation kernel, which does not hold in practical settings. Another problem with these methods is that they cannot exploit instance-specific internal information of a video at testing time. Recently, deep internal learning approaches have gained attention due to their ability to utilize the instance-specific statistics of a video. However, these methods have a large inference time as they require thousands of gradient updates to learn the intrinsic structure of the data. In this work, we present Adaptive VideoSuper-Resolution (Ada-VSR) which leverages external, as well as internal, information through meta-transfer learning and internal learning, respectively. Specifically, meta-learning is employed to obtain adaptive parameters, using a large-scale external dataset, that can adapt quickly to the novel condition (degradation model) of the given test video during the internal learning task, thereby exploiting external and internal information of a video for super-resolution. The model trained using our approach can quickly adapt to a specific video condition with only a few gradient updates, which reduces the inference time significantly. Extensive experiments on standard datasets demonstrate that our method performs favorably against various state-of-the-art approaches.",
      "intriguing_abstract": "Most of the existing works in supervised spatio-temporal video super-resolution (STVSR) heavily rely on a large-scale external dataset consisting of paired low-resolution low-frame rate (LR-LFR) and high-resolution high-frame-rate (HR-HFR) videos. Despite their remarkable performance, these methods make a prior assumption that the low-resolution video is obtained by down-scaling the high-resolution video using a known degradation kernel, which does not hold in practical settings. Another problem with these methods is that they cannot exploit instance-specific internal information of a video at testing time. Recently, deep internal learning approaches have gained attention due to their ability to utilize the instance-specific statistics of a video. However, these methods have a large inference time as they require thousands of gradient updates to learn the intrinsic structure of the data. In this work, we present Adaptive VideoSuper-Resolution (Ada-VSR) which leverages external, as well as internal, information through meta-transfer learning and internal learning, respectively. Specifically, meta-learning is employed to obtain adaptive parameters, using a large-scale external dataset, that can adapt quickly to the novel condition (degradation model) of the given test video during the internal learning task, thereby exploiting external and internal information of a video for super-resolution. The model trained using our approach can quickly adapt to a specific video condition with only a few gradient updates, which reduces the inference time significantly. Extensive experiments on standard datasets demonstrate that our method performs favorably against various state-of-the-art approaches.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/a968524df2c59fb0ed8892603546f55b731d6439.pdf",
      "citation_key": "gupta2021fbg",
      "metadata": {
        "title": "Ada-VSR: Adaptive Video Super-Resolution with Meta-Learning",
        "authors": [
          "Akash Gupta",
          "P. Jonnalagedda",
          "B. Bhanu",
          "A. Roy-Chowdhury"
        ],
        "published_date": "2021",
        "abstract": "Most of the existing works in supervised spatio-temporal video super-resolution (STVSR) heavily rely on a large-scale external dataset consisting of paired low-resolution low-frame rate (LR-LFR) and high-resolution high-frame-rate (HR-HFR) videos. Despite their remarkable performance, these methods make a prior assumption that the low-resolution video is obtained by down-scaling the high-resolution video using a known degradation kernel, which does not hold in practical settings. Another problem with these methods is that they cannot exploit instance-specific internal information of a video at testing time. Recently, deep internal learning approaches have gained attention due to their ability to utilize the instance-specific statistics of a video. However, these methods have a large inference time as they require thousands of gradient updates to learn the intrinsic structure of the data. In this work, we present Adaptive VideoSuper-Resolution (Ada-VSR) which leverages external, as well as internal, information through meta-transfer learning and internal learning, respectively. Specifically, meta-learning is employed to obtain adaptive parameters, using a large-scale external dataset, that can adapt quickly to the novel condition (degradation model) of the given test video during the internal learning task, thereby exploiting external and internal information of a video for super-resolution. The model trained using our approach can quickly adapt to a specific video condition with only a few gradient updates, which reduces the inference time significantly. Extensive experiments on standard datasets demonstrate that our method performs favorably against various state-of-the-art approaches.",
        "file_path": "paper_data/Deep_Meta-Learning/info/a968524df2c59fb0ed8892603546f55b731d6439.pdf",
        "venue": "ACM Multimedia",
        "citationCount": 7,
        "score": 1.75,
        "summary": "Most of the existing works in supervised spatio-temporal video super-resolution (STVSR) heavily rely on a large-scale external dataset consisting of paired low-resolution low-frame rate (LR-LFR) and high-resolution high-frame-rate (HR-HFR) videos. Despite their remarkable performance, these methods make a prior assumption that the low-resolution video is obtained by down-scaling the high-resolution video using a known degradation kernel, which does not hold in practical settings. Another problem with these methods is that they cannot exploit instance-specific internal information of a video at testing time. Recently, deep internal learning approaches have gained attention due to their ability to utilize the instance-specific statistics of a video. However, these methods have a large inference time as they require thousands of gradient updates to learn the intrinsic structure of the data. In this work, we present Adaptive VideoSuper-Resolution (Ada-VSR) which leverages external, as well as internal, information through meta-transfer learning and internal learning, respectively. Specifically, meta-learning is employed to obtain adaptive parameters, using a large-scale external dataset, that can adapt quickly to the novel condition (degradation model) of the given test video during the internal learning task, thereby exploiting external and internal information of a video for super-resolution. The model trained using our approach can quickly adapt to a specific video condition with only a few gradient updates, which reduces the inference time significantly. Extensive experiments on standard datasets demonstrate that our method performs favorably against various state-of-the-art approaches.",
        "keywords": []
      },
      "file_name": "a968524df2c59fb0ed8892603546f55b731d6439.pdf"
    },
    {
      "success": true,
      "doc_id": "d9bd3a08b8510930ec85ef1f1500c102",
      "summary": "Mask wearing has been considered as an effective measure to prevent the spread of COVID-19 during the current pandemic. However, most advanced face recognition approaches are not adequate for masked face recognition, particularly in dealing with the issue of training through the datasets covering only a limited number of images with ground-truth labels. In this work, we propose to learn from the large scale of web images and corresponding tags without any manual annotations along with limited fully annotated datasets. In particular, inspired by the recent success of webly supervised learning in deep neural networks, we capitalize on readily-available web images with noisy annotations to learn a robust representation for masked faces. Besides, except for the conventional spatial representation learning, we propose to leverage the power of frequency domain to capture the local representative information of un-occluded facial parts. This approach learns robust feature embeddings derived from our feature fusion architecture to make joint and full use of information from both spatial and frequency domains. Experimental results on seven benchmarks show that the proposed approach significantly improves the performance compared with other state-of-the-art methods.",
      "intriguing_abstract": "Mask wearing has been considered as an effective measure to prevent the spread of COVID-19 during the current pandemic. However, most advanced face recognition approaches are not adequate for masked face recognition, particularly in dealing with the issue of training through the datasets covering only a limited number of images with ground-truth labels. In this work, we propose to learn from the large scale of web images and corresponding tags without any manual annotations along with limited fully annotated datasets. In particular, inspired by the recent success of webly supervised learning in deep neural networks, we capitalize on readily-available web images with noisy annotations to learn a robust representation for masked faces. Besides, except for the conventional spatial representation learning, we propose to leverage the power of frequency domain to capture the local representative information of un-occluded facial parts. This approach learns robust feature embeddings derived from our feature fusion architecture to make joint and full use of information from both spatial and frequency domains. Experimental results on seven benchmarks show that the proposed approach significantly improves the performance compared with other state-of-the-art methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/1c421007b21a145c53600ca0241783945580bf84.pdf",
      "citation_key": "zheng2021dx4",
      "metadata": {
        "title": "Learning from the Web: Webly Supervised Meta-Learning for Masked Face Recognition",
        "authors": [
          "Wenbo Zheng",
          "Lan Yan",
          "Fei-Yue Wang",
          "Chao Gou"
        ],
        "published_date": "2021",
        "abstract": "Mask wearing has been considered as an effective measure to prevent the spread of COVID-19 during the current pandemic. However, most advanced face recognition approaches are not adequate for masked face recognition, particularly in dealing with the issue of training through the datasets covering only a limited number of images with ground-truth labels. In this work, we propose to learn from the large scale of web images and corresponding tags without any manual annotations along with limited fully annotated datasets. In particular, inspired by the recent success of webly supervised learning in deep neural networks, we capitalize on readily-available web images with noisy annotations to learn a robust representation for masked faces. Besides, except for the conventional spatial representation learning, we propose to leverage the power of frequency domain to capture the local representative information of un-occluded facial parts. This approach learns robust feature embeddings derived from our feature fusion architecture to make joint and full use of information from both spatial and frequency domains. Experimental results on seven benchmarks show that the proposed approach significantly improves the performance compared with other state-of-the-art methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/1c421007b21a145c53600ca0241783945580bf84.pdf",
        "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
        "citationCount": 6,
        "score": 1.5,
        "summary": "Mask wearing has been considered as an effective measure to prevent the spread of COVID-19 during the current pandemic. However, most advanced face recognition approaches are not adequate for masked face recognition, particularly in dealing with the issue of training through the datasets covering only a limited number of images with ground-truth labels. In this work, we propose to learn from the large scale of web images and corresponding tags without any manual annotations along with limited fully annotated datasets. In particular, inspired by the recent success of webly supervised learning in deep neural networks, we capitalize on readily-available web images with noisy annotations to learn a robust representation for masked faces. Besides, except for the conventional spatial representation learning, we propose to leverage the power of frequency domain to capture the local representative information of un-occluded facial parts. This approach learns robust feature embeddings derived from our feature fusion architecture to make joint and full use of information from both spatial and frequency domains. Experimental results on seven benchmarks show that the proposed approach significantly improves the performance compared with other state-of-the-art methods.",
        "keywords": []
      },
      "file_name": "1c421007b21a145c53600ca0241783945580bf84.pdf"
    },
    {
      "success": true,
      "doc_id": "599995faf8e147c538b9729dec064b08",
      "summary": "Deep learning models have been successfully applied to polarimetric synthetic aperture radar (PolSAR) image terrain classification. However, they usually need many labeled samples from the current PolSAR image to be classified to train the model parameters, which fundamentally limits their application. In this paper, we propose a metric-based meta-learning framework for few-shot terrain classification (MML-FSTC) of PolSAR image. The proposed MML-FSTC firstly utilizes the collected base labeled samples (BLS) from typical PolSAR systems to learn an effective transferable three-dimensional convolutional neural network (3DCNN) to extract features for terrain classification. Then, by mimicking the few-shot learning of human, MML-FSTC integrates additional samples, whose label spaces are probably different from those of BLS, and proposes a meta-learning strategy for terrain classification that consists of multiple few-shot training episodes, each of which has very few labeled terrain samples and potentially different labeled space. By minimizing the cosine distance of the support and query deep features, MML-FSTC finetunes the pre-trained 3DCNN in the meta-learning stage, and utilizes a metric-based cosine distance function to predict the classification. The classification results demonstrate the superiority of MML-FSTC for few-shot PolSAR image terrain classification.",
      "intriguing_abstract": "Deep learning models have been successfully applied to polarimetric synthetic aperture radar (PolSAR) image terrain classification. However, they usually need many labeled samples from the current PolSAR image to be classified to train the model parameters, which fundamentally limits their application. In this paper, we propose a metric-based meta-learning framework for few-shot terrain classification (MML-FSTC) of PolSAR image. The proposed MML-FSTC firstly utilizes the collected base labeled samples (BLS) from typical PolSAR systems to learn an effective transferable three-dimensional convolutional neural network (3DCNN) to extract features for terrain classification. Then, by mimicking the few-shot learning of human, MML-FSTC integrates additional samples, whose label spaces are probably different from those of BLS, and proposes a meta-learning strategy for terrain classification that consists of multiple few-shot training episodes, each of which has very few labeled terrain samples and potentially different labeled space. By minimizing the cosine distance of the support and query deep features, MML-FSTC finetunes the pre-trained 3DCNN in the meta-learning stage, and utilizes a metric-based cosine distance function to predict the classification. The classification results demonstrate the superiority of MML-FSTC for few-shot PolSAR image terrain classification.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/4e6dbd91bf635f2e9698782daf084b8c779c880d.pdf",
      "citation_key": "zhang2021sbz",
      "metadata": {
        "title": "Metric-based Meta-Learning Model for Few-Shot PolSAR Image Terrain Classification",
        "authors": [
          "Peng Zhang",
          "Chenbing Liu",
          "Xingshuo Chang",
          "Ya-chao Li",
          "Ming Li"
        ],
        "published_date": "2021",
        "abstract": "Deep learning models have been successfully applied to polarimetric synthetic aperture radar (PolSAR) image terrain classification. However, they usually need many labeled samples from the current PolSAR image to be classified to train the model parameters, which fundamentally limits their application. In this paper, we propose a metric-based meta-learning framework for few-shot terrain classification (MML-FSTC) of PolSAR image. The proposed MML-FSTC firstly utilizes the collected base labeled samples (BLS) from typical PolSAR systems to learn an effective transferable three-dimensional convolutional neural network (3DCNN) to extract features for terrain classification. Then, by mimicking the few-shot learning of human, MML-FSTC integrates additional samples, whose label spaces are probably different from those of BLS, and proposes a meta-learning strategy for terrain classification that consists of multiple few-shot training episodes, each of which has very few labeled terrain samples and potentially different labeled space. By minimizing the cosine distance of the support and query deep features, MML-FSTC finetunes the pre-trained 3DCNN in the meta-learning stage, and utilizes a metric-based cosine distance function to predict the classification. The classification results demonstrate the superiority of MML-FSTC for few-shot PolSAR image terrain classification.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4e6dbd91bf635f2e9698782daf084b8c779c880d.pdf",
        "venue": "Radar",
        "citationCount": 5,
        "score": 1.25,
        "summary": "Deep learning models have been successfully applied to polarimetric synthetic aperture radar (PolSAR) image terrain classification. However, they usually need many labeled samples from the current PolSAR image to be classified to train the model parameters, which fundamentally limits their application. In this paper, we propose a metric-based meta-learning framework for few-shot terrain classification (MML-FSTC) of PolSAR image. The proposed MML-FSTC firstly utilizes the collected base labeled samples (BLS) from typical PolSAR systems to learn an effective transferable three-dimensional convolutional neural network (3DCNN) to extract features for terrain classification. Then, by mimicking the few-shot learning of human, MML-FSTC integrates additional samples, whose label spaces are probably different from those of BLS, and proposes a meta-learning strategy for terrain classification that consists of multiple few-shot training episodes, each of which has very few labeled terrain samples and potentially different labeled space. By minimizing the cosine distance of the support and query deep features, MML-FSTC finetunes the pre-trained 3DCNN in the meta-learning stage, and utilizes a metric-based cosine distance function to predict the classification. The classification results demonstrate the superiority of MML-FSTC for few-shot PolSAR image terrain classification.",
        "keywords": []
      },
      "file_name": "4e6dbd91bf635f2e9698782daf084b8c779c880d.pdf"
    },
    {
      "success": true,
      "doc_id": "a92cc279b9f8bb813e04f2ce750527db",
      "summary": "Today's deep learning methods focus on how to design the most appropriate objective functions so that the prediction results of the model can be closest to the ground truth. Meanwhile, an appropriate architecture that can facilitate acquisition of enough information for prediction has to be designed. Existing methods ignore a fact that when input data undergoes layer-by-layer feature extraction and spatial transformation, large amount of information will be lost. This paper will delve into the important issues of data loss when data is transmitted through deep networks, namely information bottleneck and reversible functions. We proposed the concept of programmable gradient information (PGI) to cope with the various changes required by deep networks to achieve multiple objectives. PGI can provide complete input information for the target task to calculate objective function, so that reliable gradient information can be obtained to update network weights. In addition, a new lightweight network architecture -- Generalized Efficient Layer Aggregation Network (GELAN), based on gradient path planning is designed. GELAN's architecture confirms that PGI has gained superior results on lightweight models. We verified the proposed GELAN and PGI on MS COCO dataset based object detection. The results show that GELAN only uses conventional convolution operators to achieve better parameter utilization than the state-of-the-art methods developed based on depth-wise convolution. PGI can be used for variety of models from lightweight to large. It can be used to obtain complete information, so that train-from-scratch models can achieve better results than state-of-the-art models pre-trained using large datasets, the comparison results are shown in Figure 1. The source codes are at: https://github.com/WongKinYiu/yolov9.",
      "intriguing_abstract": "Today's deep learning methods focus on how to design the most appropriate objective functions so that the prediction results of the model can be closest to the ground truth. Meanwhile, an appropriate architecture that can facilitate acquisition of enough information for prediction has to be designed. Existing methods ignore a fact that when input data undergoes layer-by-layer feature extraction and spatial transformation, large amount of information will be lost. This paper will delve into the important issues of data loss when data is transmitted through deep networks, namely information bottleneck and reversible functions. We proposed the concept of programmable gradient information (PGI) to cope with the various changes required by deep networks to achieve multiple objectives. PGI can provide complete input information for the target task to calculate objective function, so that reliable gradient information can be obtained to update network weights. In addition, a new lightweight network architecture -- Generalized Efficient Layer Aggregation Network (GELAN), based on gradient path planning is designed. GELAN's architecture confirms that PGI has gained superior results on lightweight models. We verified the proposed GELAN and PGI on MS COCO dataset based object detection. The results show that GELAN only uses conventional convolution operators to achieve better parameter utilization than the state-of-the-art methods developed based on depth-wise convolution. PGI can be used for variety of models from lightweight to large. It can be used to obtain complete information, so that train-from-scratch models can achieve better results than state-of-the-art models pre-trained using large datasets, the comparison results are shown in Figure 1. The source codes are at: https://github.com/WongKinYiu/yolov9.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/cf70392a3b1ae92fdb1b70448aaddcbd03726d3d.pdf",
      "citation_key": "wang2024jzu",
      "metadata": {
        "title": "YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information",
        "authors": [
          "Chien-Yao Wang",
          "I-Hau Yeh",
          "Hongpeng Liao"
        ],
        "published_date": "2024",
        "abstract": "Today's deep learning methods focus on how to design the most appropriate objective functions so that the prediction results of the model can be closest to the ground truth. Meanwhile, an appropriate architecture that can facilitate acquisition of enough information for prediction has to be designed. Existing methods ignore a fact that when input data undergoes layer-by-layer feature extraction and spatial transformation, large amount of information will be lost. This paper will delve into the important issues of data loss when data is transmitted through deep networks, namely information bottleneck and reversible functions. We proposed the concept of programmable gradient information (PGI) to cope with the various changes required by deep networks to achieve multiple objectives. PGI can provide complete input information for the target task to calculate objective function, so that reliable gradient information can be obtained to update network weights. In addition, a new lightweight network architecture -- Generalized Efficient Layer Aggregation Network (GELAN), based on gradient path planning is designed. GELAN's architecture confirms that PGI has gained superior results on lightweight models. We verified the proposed GELAN and PGI on MS COCO dataset based object detection. The results show that GELAN only uses conventional convolution operators to achieve better parameter utilization than the state-of-the-art methods developed based on depth-wise convolution. PGI can be used for variety of models from lightweight to large. It can be used to obtain complete information, so that train-from-scratch models can achieve better results than state-of-the-art models pre-trained using large datasets, the comparison results are shown in Figure 1. The source codes are at: https://github.com/WongKinYiu/yolov9.",
        "file_path": "paper_data/Deep_Meta-Learning/info/cf70392a3b1ae92fdb1b70448aaddcbd03726d3d.pdf",
        "venue": "European Conference on Computer Vision",
        "citationCount": 1831,
        "score": 1831.0,
        "summary": "Today's deep learning methods focus on how to design the most appropriate objective functions so that the prediction results of the model can be closest to the ground truth. Meanwhile, an appropriate architecture that can facilitate acquisition of enough information for prediction has to be designed. Existing methods ignore a fact that when input data undergoes layer-by-layer feature extraction and spatial transformation, large amount of information will be lost. This paper will delve into the important issues of data loss when data is transmitted through deep networks, namely information bottleneck and reversible functions. We proposed the concept of programmable gradient information (PGI) to cope with the various changes required by deep networks to achieve multiple objectives. PGI can provide complete input information for the target task to calculate objective function, so that reliable gradient information can be obtained to update network weights. In addition, a new lightweight network architecture -- Generalized Efficient Layer Aggregation Network (GELAN), based on gradient path planning is designed. GELAN's architecture confirms that PGI has gained superior results on lightweight models. We verified the proposed GELAN and PGI on MS COCO dataset based object detection. The results show that GELAN only uses conventional convolution operators to achieve better parameter utilization than the state-of-the-art methods developed based on depth-wise convolution. PGI can be used for variety of models from lightweight to large. It can be used to obtain complete information, so that train-from-scratch models can achieve better results than state-of-the-art models pre-trained using large datasets, the comparison results are shown in Figure 1. The source codes are at: https://github.com/WongKinYiu/yolov9.",
        "keywords": []
      },
      "file_name": "cf70392a3b1ae92fdb1b70448aaddcbd03726d3d.pdf"
    },
    {
      "success": true,
      "doc_id": "0a8c561d196584d1803c102e06889e34",
      "summary": "Reconfigurable intelligent surface (RIS) has become a promising technology to realize the programmable wireless environment via steering the incident signal in fully customizable ways. However, a major challenge in RIS-aided communication systems is the simultaneous design of the precoding matrix at the base station (BS) and the phase shifting matrix of the RIS elements. This is mainly attributed to the highly non-convex optimization space of variables at both the BS and the RIS, and the diversity of communication environments. Generally, traditional optimization methods for this problem suffer from the high complexity, while existing deep learning based methods are lacking in robustness in various scenarios. To address these issues, we introduce a gradient-based manifold meta learning method (GMML), which works without pre-training and has strong robustness for RIS-aided communications. Specifically, the proposed method fuses meta learning and manifold learning to improve the overall spectral efficiency, and reduce the overhead of the high-dimensional signal process. Unlike traditional deep learning based methods which directly take channel state information as input, GMML feeds the gradients of the precoding matrix and phase shifting matrix into neural networks. Coherently, we design a differential regulator to constrain the phase shifting matrix of the RIS. Numerical results show that the proposed GMML can improve the spectral efficiency by up to 7.31%, and speed up the convergence by 23 times faster compared to traditional approaches. Moreover, they also demonstrate remarkable robustness and adaptability in dynamic settings.",
      "intriguing_abstract": "Reconfigurable intelligent surface (RIS) has become a promising technology to realize the programmable wireless environment via steering the incident signal in fully customizable ways. However, a major challenge in RIS-aided communication systems is the simultaneous design of the precoding matrix at the base station (BS) and the phase shifting matrix of the RIS elements. This is mainly attributed to the highly non-convex optimization space of variables at both the BS and the RIS, and the diversity of communication environments. Generally, traditional optimization methods for this problem suffer from the high complexity, while existing deep learning based methods are lacking in robustness in various scenarios. To address these issues, we introduce a gradient-based manifold meta learning method (GMML), which works without pre-training and has strong robustness for RIS-aided communications. Specifically, the proposed method fuses meta learning and manifold learning to improve the overall spectral efficiency, and reduce the overhead of the high-dimensional signal process. Unlike traditional deep learning based methods which directly take channel state information as input, GMML feeds the gradients of the precoding matrix and phase shifting matrix into neural networks. Coherently, we design a differential regulator to constrain the phase shifting matrix of the RIS. Numerical results show that the proposed GMML can improve the spectral efficiency by up to 7.31%, and speed up the convergence by 23 times faster compared to traditional approaches. Moreover, they also demonstrate remarkable robustness and adaptability in dynamic settings.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2be63f81ae867082dcb7f94fd8c0aa2ac3ee6e25.pdf",
      "citation_key": "zhu20249wq",
      "metadata": {
        "title": "Robust Beamforming for RIS-Aided Communications: Gradient-Based Manifold Meta Learning",
        "authors": [
          "Fenghao Zhu",
          "Xinquan Wang",
          "Chongwen Huang",
          "Zhaohui Yang",
          "Xiaoming Chen",
          "Ahmed Al Hammadi",
          "Zhaoyang Zhang",
          "Chau Yuen",
          "Mérouane Debbah"
        ],
        "published_date": "2024",
        "abstract": "Reconfigurable intelligent surface (RIS) has become a promising technology to realize the programmable wireless environment via steering the incident signal in fully customizable ways. However, a major challenge in RIS-aided communication systems is the simultaneous design of the precoding matrix at the base station (BS) and the phase shifting matrix of the RIS elements. This is mainly attributed to the highly non-convex optimization space of variables at both the BS and the RIS, and the diversity of communication environments. Generally, traditional optimization methods for this problem suffer from the high complexity, while existing deep learning based methods are lacking in robustness in various scenarios. To address these issues, we introduce a gradient-based manifold meta learning method (GMML), which works without pre-training and has strong robustness for RIS-aided communications. Specifically, the proposed method fuses meta learning and manifold learning to improve the overall spectral efficiency, and reduce the overhead of the high-dimensional signal process. Unlike traditional deep learning based methods which directly take channel state information as input, GMML feeds the gradients of the precoding matrix and phase shifting matrix into neural networks. Coherently, we design a differential regulator to constrain the phase shifting matrix of the RIS. Numerical results show that the proposed GMML can improve the spectral efficiency by up to 7.31%, and speed up the convergence by 23 times faster compared to traditional approaches. Moreover, they also demonstrate remarkable robustness and adaptability in dynamic settings.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2be63f81ae867082dcb7f94fd8c0aa2ac3ee6e25.pdf",
        "venue": "IEEE Transactions on Wireless Communications",
        "citationCount": 49,
        "score": 49.0,
        "summary": "Reconfigurable intelligent surface (RIS) has become a promising technology to realize the programmable wireless environment via steering the incident signal in fully customizable ways. However, a major challenge in RIS-aided communication systems is the simultaneous design of the precoding matrix at the base station (BS) and the phase shifting matrix of the RIS elements. This is mainly attributed to the highly non-convex optimization space of variables at both the BS and the RIS, and the diversity of communication environments. Generally, traditional optimization methods for this problem suffer from the high complexity, while existing deep learning based methods are lacking in robustness in various scenarios. To address these issues, we introduce a gradient-based manifold meta learning method (GMML), which works without pre-training and has strong robustness for RIS-aided communications. Specifically, the proposed method fuses meta learning and manifold learning to improve the overall spectral efficiency, and reduce the overhead of the high-dimensional signal process. Unlike traditional deep learning based methods which directly take channel state information as input, GMML feeds the gradients of the precoding matrix and phase shifting matrix into neural networks. Coherently, we design a differential regulator to constrain the phase shifting matrix of the RIS. Numerical results show that the proposed GMML can improve the spectral efficiency by up to 7.31%, and speed up the convergence by 23 times faster compared to traditional approaches. Moreover, they also demonstrate remarkable robustness and adaptability in dynamic settings.",
        "keywords": []
      },
      "file_name": "2be63f81ae867082dcb7f94fd8c0aa2ac3ee6e25.pdf"
    },
    {
      "success": true,
      "doc_id": "5d203ff04c4060573caf941566f33fd3",
      "summary": "Artificial neural networks (ANN), machine learning (ML), deep learning (DL), and ensemble learning (EL) are four outstanding approaches that enable algorithms to extract information from data and make predictions or decisions autonomously without the need for direct instructions. ANN, ML, DL, and EL models have found extensive application in predicting geotechnical and geoenvironmental parameters. This research aims to provide a comprehensive assessment of the applications of ANN, ML, DL, and EL in addressing forecasting within the field related to geotechnical engineering, including soil mechanics, foundation engineering, rock mechanics, environmental geotechnics, and transportation geotechnics. Previous studies have not collectively examined all four algorithms—ANN, ML, DL, and EL—and have not explored their advantages and disadvantages in the field of geotechnical engineering. This research aims to categorize and address this gap in the existing literature systematically. An extensive dataset of relevant research studies was gathered from the Web of Science and subjected to an analysis based on their approach, primary focus and objectives, year of publication, geographical distribution, and results. Additionally, this study included a co-occurrence keyword analysis that covered ANN, ML, DL, and EL techniques, systematic reviews, geotechnical engineering, and review articles that the data, sourced from the Scopus database through the Elsevier Journal, were then visualized using VOS Viewer for further examination. The results demonstrated that ANN is widely utilized despite the proven potential of ML, DL, and EL methods in geotechnical engineering due to the need for real-world laboratory data that civil and geotechnical engineers often encounter. However, when it comes to predicting behavior in geotechnical scenarios, EL techniques outperform all three other methods. Additionally, the techniques discussed here assist geotechnical engineering in understanding the benefits and disadvantages of ANN, ML, DL, and EL within the geo techniques area. This understanding enables geotechnical practitioners to select the most suitable techniques for creating a certainty and resilient ecosystem.",
      "intriguing_abstract": "Artificial neural networks (ANN), machine learning (ML), deep learning (DL), and ensemble learning (EL) are four outstanding approaches that enable algorithms to extract information from data and make predictions or decisions autonomously without the need for direct instructions. ANN, ML, DL, and EL models have found extensive application in predicting geotechnical and geoenvironmental parameters. This research aims to provide a comprehensive assessment of the applications of ANN, ML, DL, and EL in addressing forecasting within the field related to geotechnical engineering, including soil mechanics, foundation engineering, rock mechanics, environmental geotechnics, and transportation geotechnics. Previous studies have not collectively examined all four algorithms—ANN, ML, DL, and EL—and have not explored their advantages and disadvantages in the field of geotechnical engineering. This research aims to categorize and address this gap in the existing literature systematically. An extensive dataset of relevant research studies was gathered from the Web of Science and subjected to an analysis based on their approach, primary focus and objectives, year of publication, geographical distribution, and results. Additionally, this study included a co-occurrence keyword analysis that covered ANN, ML, DL, and EL techniques, systematic reviews, geotechnical engineering, and review articles that the data, sourced from the Scopus database through the Elsevier Journal, were then visualized using VOS Viewer for further examination. The results demonstrated that ANN is widely utilized despite the proven potential of ML, DL, and EL methods in geotechnical engineering due to the need for real-world laboratory data that civil and geotechnical engineers often encounter. However, when it comes to predicting behavior in geotechnical scenarios, EL techniques outperform all three other methods. Additionally, the techniques discussed here assist geotechnical engineering in understanding the benefits and disadvantages of ANN, ML, DL, and EL within the geo techniques area. This understanding enables geotechnical practitioners to select the most suitable techniques for creating a certainty and resilient ecosystem.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d31b38a6f29f9e3705eea312b69561ec8cfb2a68.pdf",
      "citation_key": "yaghoubi2024j56",
      "metadata": {
        "title": "A systematic review and meta-analysis of artificial neural network, machine learning, deep learning, and ensemble learning approaches in field of geotechnical engineering",
        "authors": [
          "Elaheh Yaghoubi",
          "Elnaz Yaghoubi",
          "Ahmed Khamees",
          "A. Vakili"
        ],
        "published_date": "2024",
        "abstract": "Artificial neural networks (ANN), machine learning (ML), deep learning (DL), and ensemble learning (EL) are four outstanding approaches that enable algorithms to extract information from data and make predictions or decisions autonomously without the need for direct instructions. ANN, ML, DL, and EL models have found extensive application in predicting geotechnical and geoenvironmental parameters. This research aims to provide a comprehensive assessment of the applications of ANN, ML, DL, and EL in addressing forecasting within the field related to geotechnical engineering, including soil mechanics, foundation engineering, rock mechanics, environmental geotechnics, and transportation geotechnics. Previous studies have not collectively examined all four algorithms—ANN, ML, DL, and EL—and have not explored their advantages and disadvantages in the field of geotechnical engineering. This research aims to categorize and address this gap in the existing literature systematically. An extensive dataset of relevant research studies was gathered from the Web of Science and subjected to an analysis based on their approach, primary focus and objectives, year of publication, geographical distribution, and results. Additionally, this study included a co-occurrence keyword analysis that covered ANN, ML, DL, and EL techniques, systematic reviews, geotechnical engineering, and review articles that the data, sourced from the Scopus database through the Elsevier Journal, were then visualized using VOS Viewer for further examination. The results demonstrated that ANN is widely utilized despite the proven potential of ML, DL, and EL methods in geotechnical engineering due to the need for real-world laboratory data that civil and geotechnical engineers often encounter. However, when it comes to predicting behavior in geotechnical scenarios, EL techniques outperform all three other methods. Additionally, the techniques discussed here assist geotechnical engineering in understanding the benefits and disadvantages of ANN, ML, DL, and EL within the geo techniques area. This understanding enables geotechnical practitioners to select the most suitable techniques for creating a certainty and resilient ecosystem.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d31b38a6f29f9e3705eea312b69561ec8cfb2a68.pdf",
        "venue": "Neural computing & applications (Print)",
        "citationCount": 42,
        "score": 42.0,
        "summary": "Artificial neural networks (ANN), machine learning (ML), deep learning (DL), and ensemble learning (EL) are four outstanding approaches that enable algorithms to extract information from data and make predictions or decisions autonomously without the need for direct instructions. ANN, ML, DL, and EL models have found extensive application in predicting geotechnical and geoenvironmental parameters. This research aims to provide a comprehensive assessment of the applications of ANN, ML, DL, and EL in addressing forecasting within the field related to geotechnical engineering, including soil mechanics, foundation engineering, rock mechanics, environmental geotechnics, and transportation geotechnics. Previous studies have not collectively examined all four algorithms—ANN, ML, DL, and EL—and have not explored their advantages and disadvantages in the field of geotechnical engineering. This research aims to categorize and address this gap in the existing literature systematically. An extensive dataset of relevant research studies was gathered from the Web of Science and subjected to an analysis based on their approach, primary focus and objectives, year of publication, geographical distribution, and results. Additionally, this study included a co-occurrence keyword analysis that covered ANN, ML, DL, and EL techniques, systematic reviews, geotechnical engineering, and review articles that the data, sourced from the Scopus database through the Elsevier Journal, were then visualized using VOS Viewer for further examination. The results demonstrated that ANN is widely utilized despite the proven potential of ML, DL, and EL methods in geotechnical engineering due to the need for real-world laboratory data that civil and geotechnical engineers often encounter. However, when it comes to predicting behavior in geotechnical scenarios, EL techniques outperform all three other methods. Additionally, the techniques discussed here assist geotechnical engineering in understanding the benefits and disadvantages of ANN, ML, DL, and EL within the geo techniques area. This understanding enables geotechnical practitioners to select the most suitable techniques for creating a certainty and resilient ecosystem.",
        "keywords": []
      },
      "file_name": "d31b38a6f29f9e3705eea312b69561ec8cfb2a68.pdf"
    },
    {
      "success": true,
      "doc_id": "1cc298bce47657bf91e3042a590a48d0",
      "summary": "Intelligent fault diagnosis models have de- monstrated superior performance in industrial prognostics health management scenarios. However, these models may struggle to generalize in complicated industrial environments, when encountering new working conditions and handling low-resource and heterogeneous data. To cope with the aforementioned issues, we focus on constructing a universal training framework with a domain generalization technique that will encourage fault diagnosis models to generalize well in unseen working conditions. First, a model-agnostic meta-learning-based training framework called Meta-GENE is proposed for homogeneous and heterogeneous domain generalization. Second, a gradient aligning algorithm is introduced in a meta-learning framework to learn a domain-invariant strategy for robust prediction under unseen working conditions. Third, a semantic matching technique is proposed for utilizing heterogeneous data to alleviate low-resource problems. Our method has yielded excellent performance on the PHM09 fault diagnosis dataset and achieved superior results on a set of generalization tasks across various working conditions.",
      "intriguing_abstract": "Intelligent fault diagnosis models have de- monstrated superior performance in industrial prognostics health management scenarios. However, these models may struggle to generalize in complicated industrial environments, when encountering new working conditions and handling low-resource and heterogeneous data. To cope with the aforementioned issues, we focus on constructing a universal training framework with a domain generalization technique that will encourage fault diagnosis models to generalize well in unseen working conditions. First, a model-agnostic meta-learning-based training framework called Meta-GENE is proposed for homogeneous and heterogeneous domain generalization. Second, a gradient aligning algorithm is introduced in a meta-learning framework to learn a domain-invariant strategy for robust prediction under unseen working conditions. Third, a semantic matching technique is proposed for utilizing heterogeneous data to alleviate low-resource problems. Our method has yielded excellent performance on the PHM09 fault diagnosis dataset and achieved superior results on a set of generalization tasks across various working conditions.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d38e8979ed6cda06aee13efecc6f9a217ece0132.pdf",
      "citation_key": "ren20242qj",
      "metadata": {
        "title": "Meta-learning Based Domain Generalization Framework for Fault Diagnosis With Gradient Aligning and Semantic Matching",
        "authors": [
          "Lei Ren",
          "Tingyu Mo",
          "Xuejun Cheng"
        ],
        "published_date": "2024",
        "abstract": "Intelligent fault diagnosis models have de- monstrated superior performance in industrial prognostics health management scenarios. However, these models may struggle to generalize in complicated industrial environments, when encountering new working conditions and handling low-resource and heterogeneous data. To cope with the aforementioned issues, we focus on constructing a universal training framework with a domain generalization technique that will encourage fault diagnosis models to generalize well in unseen working conditions. First, a model-agnostic meta-learning-based training framework called Meta-GENE is proposed for homogeneous and heterogeneous domain generalization. Second, a gradient aligning algorithm is introduced in a meta-learning framework to learn a domain-invariant strategy for robust prediction under unseen working conditions. Third, a semantic matching technique is proposed for utilizing heterogeneous data to alleviate low-resource problems. Our method has yielded excellent performance on the PHM09 fault diagnosis dataset and achieved superior results on a set of generalization tasks across various working conditions.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d38e8979ed6cda06aee13efecc6f9a217ece0132.pdf",
        "venue": "IEEE Transactions on Industrial Informatics",
        "citationCount": 37,
        "score": 37.0,
        "summary": "Intelligent fault diagnosis models have de- monstrated superior performance in industrial prognostics health management scenarios. However, these models may struggle to generalize in complicated industrial environments, when encountering new working conditions and handling low-resource and heterogeneous data. To cope with the aforementioned issues, we focus on constructing a universal training framework with a domain generalization technique that will encourage fault diagnosis models to generalize well in unseen working conditions. First, a model-agnostic meta-learning-based training framework called Meta-GENE is proposed for homogeneous and heterogeneous domain generalization. Second, a gradient aligning algorithm is introduced in a meta-learning framework to learn a domain-invariant strategy for robust prediction under unseen working conditions. Third, a semantic matching technique is proposed for utilizing heterogeneous data to alleviate low-resource problems. Our method has yielded excellent performance on the PHM09 fault diagnosis dataset and achieved superior results on a set of generalization tasks across various working conditions.",
        "keywords": []
      },
      "file_name": "d38e8979ed6cda06aee13efecc6f9a217ece0132.pdf"
    },
    {
      "success": true,
      "doc_id": "b8c81814a3560db586d958dd0f1d7cd9",
      "summary": "Medical datasets often have a skewed class distribution and a lack of high-quality annotated images. However, deep learning methods require a large amount of labeled data for classification. In this study, we present a few-shot learning approach for the classification of ultrasound breast cancer images using meta-learning methods. We used prototypical networks and model agnostic meta-learning (MAML) algorithms as meta-learning methods. The breast ultrasound images (BUSI) dataset, which has three classes and is difficult to use in meta-learning, was used for meta-testing in a cross-domain approach along with other datasets for meta-training. Our proposed approach yielded an accuracy range of 0.882–0.889, achieved by implementing the ResNet50 backbone with ProtoNet in a 10-shot setting. These results represent a significant improvement ranging from 6.27 to 7.10% over the baseline accuracy of 0.831. The results showed that ProtoNet outperformed the MAML method for all k-shot settings. In addition, the use of ResNet models as the backbone network for feature extraction was found to be more successful than the use of a four-layer convolutional model. Our proposed method is the first attempt to apply meta-learning for few-shot classification in the BUSI dataset while providing higher accuracy compared to deep learning methods for medical images with small-scale datasets and few classes. The methodology used in this study can be adapted to other datasets with similar problems.",
      "intriguing_abstract": "Medical datasets often have a skewed class distribution and a lack of high-quality annotated images. However, deep learning methods require a large amount of labeled data for classification. In this study, we present a few-shot learning approach for the classification of ultrasound breast cancer images using meta-learning methods. We used prototypical networks and model agnostic meta-learning (MAML) algorithms as meta-learning methods. The breast ultrasound images (BUSI) dataset, which has three classes and is difficult to use in meta-learning, was used for meta-testing in a cross-domain approach along with other datasets for meta-training. Our proposed approach yielded an accuracy range of 0.882–0.889, achieved by implementing the ResNet50 backbone with ProtoNet in a 10-shot setting. These results represent a significant improvement ranging from 6.27 to 7.10% over the baseline accuracy of 0.831. The results showed that ProtoNet outperformed the MAML method for all k-shot settings. In addition, the use of ResNet models as the backbone network for feature extraction was found to be more successful than the use of a four-layer convolutional model. Our proposed method is the first attempt to apply meta-learning for few-shot classification in the BUSI dataset while providing higher accuracy compared to deep learning methods for medical images with small-scale datasets and few classes. The methodology used in this study can be adapted to other datasets with similar problems.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e0f1ae0ea72e74587dc74883853331d13adad05d.pdf",
      "citation_key": "ik20248rp",
      "metadata": {
        "title": "Few-shot classification of ultrasound breast cancer images using meta-learning algorithms",
        "authors": [
          "Gültekin Işık",
          "Ishak Paçal"
        ],
        "published_date": "2024",
        "abstract": "Medical datasets often have a skewed class distribution and a lack of high-quality annotated images. However, deep learning methods require a large amount of labeled data for classification. In this study, we present a few-shot learning approach for the classification of ultrasound breast cancer images using meta-learning methods. We used prototypical networks and model agnostic meta-learning (MAML) algorithms as meta-learning methods. The breast ultrasound images (BUSI) dataset, which has three classes and is difficult to use in meta-learning, was used for meta-testing in a cross-domain approach along with other datasets for meta-training. Our proposed approach yielded an accuracy range of 0.882–0.889, achieved by implementing the ResNet50 backbone with ProtoNet in a 10-shot setting. These results represent a significant improvement ranging from 6.27 to 7.10% over the baseline accuracy of 0.831. The results showed that ProtoNet outperformed the MAML method for all k-shot settings. In addition, the use of ResNet models as the backbone network for feature extraction was found to be more successful than the use of a four-layer convolutional model. Our proposed method is the first attempt to apply meta-learning for few-shot classification in the BUSI dataset while providing higher accuracy compared to deep learning methods for medical images with small-scale datasets and few classes. The methodology used in this study can be adapted to other datasets with similar problems.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e0f1ae0ea72e74587dc74883853331d13adad05d.pdf",
        "venue": "Neural computing & applications (Print)",
        "citationCount": 37,
        "score": 37.0,
        "summary": "Medical datasets often have a skewed class distribution and a lack of high-quality annotated images. However, deep learning methods require a large amount of labeled data for classification. In this study, we present a few-shot learning approach for the classification of ultrasound breast cancer images using meta-learning methods. We used prototypical networks and model agnostic meta-learning (MAML) algorithms as meta-learning methods. The breast ultrasound images (BUSI) dataset, which has three classes and is difficult to use in meta-learning, was used for meta-testing in a cross-domain approach along with other datasets for meta-training. Our proposed approach yielded an accuracy range of 0.882–0.889, achieved by implementing the ResNet50 backbone with ProtoNet in a 10-shot setting. These results represent a significant improvement ranging from 6.27 to 7.10% over the baseline accuracy of 0.831. The results showed that ProtoNet outperformed the MAML method for all k-shot settings. In addition, the use of ResNet models as the backbone network for feature extraction was found to be more successful than the use of a four-layer convolutional model. Our proposed method is the first attempt to apply meta-learning for few-shot classification in the BUSI dataset while providing higher accuracy compared to deep learning methods for medical images with small-scale datasets and few classes. The methodology used in this study can be adapted to other datasets with similar problems.",
        "keywords": []
      },
      "file_name": "e0f1ae0ea72e74587dc74883853331d13adad05d.pdf"
    },
    {
      "success": true,
      "doc_id": "8cbc9e92e97b68968507b81baccf542e",
      "summary": "Biological neural networks do not only include long-term memory and weight multiplication capabilities, as commonly assumed in artificial neural networks, but also more complex functions such as short-term memory, short-term plasticity, and meta-plasticity - all collocated within each synapse. Here, we demonstrate memristive nano-devices based on SrTiO3 that inherently emulate all these synaptic functions. These memristors operate in a non-filamentary, low conductance regime, which enables stable and energy efficient operation. They can act as multi-functional hardware synapses in a class of bio-inspired deep neural networks (DNN) that make use of both long- and short-term synaptic dynamics and are capable of meta-learning or learning-to-learn. The resulting bio-inspired DNN is then trained to play the video game Atari Pong, a complex reinforcement learning task in a dynamic environment. Our analysis shows that the energy consumption of the DNN with multi-functional memristive synapses decreases by about two orders of magnitude as compared to a pure GPU implementation. Based on this finding, we infer that memristive devices with a better emulation of the synaptic functionalities do not only broaden the applicability of neuromorphic computing, but could also improve the performance and energy costs of certain artificial intelligence applications.",
      "intriguing_abstract": "Biological neural networks do not only include long-term memory and weight multiplication capabilities, as commonly assumed in artificial neural networks, but also more complex functions such as short-term memory, short-term plasticity, and meta-plasticity - all collocated within each synapse. Here, we demonstrate memristive nano-devices based on SrTiO3 that inherently emulate all these synaptic functions. These memristors operate in a non-filamentary, low conductance regime, which enables stable and energy efficient operation. They can act as multi-functional hardware synapses in a class of bio-inspired deep neural networks (DNN) that make use of both long- and short-term synaptic dynamics and are capable of meta-learning or learning-to-learn. The resulting bio-inspired DNN is then trained to play the video game Atari Pong, a complex reinforcement learning task in a dynamic environment. Our analysis shows that the energy consumption of the DNN with multi-functional memristive synapses decreases by about two orders of magnitude as compared to a pure GPU implementation. Based on this finding, we infer that memristive devices with a better emulation of the synaptic functionalities do not only broaden the applicability of neuromorphic computing, but could also improve the performance and energy costs of certain artificial intelligence applications.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/24411be9cbb7ca4bc27fb6e3285601405e39061f.pdf",
      "citation_key": "weilenmann2024ve2",
      "metadata": {
        "title": "Single neuromorphic memristor closely emulates multiple synaptic mechanisms for energy efficient neural networks",
        "authors": [
          "C. Weilenmann",
          "A. Ziogas",
          "T. Zellweger",
          "K. Portner",
          "Marko Mladenovi'c",
          "M. Kaniselvan",
          "Timoleon Moraitis",
          "Mathieu Luisier",
          "A. Emboras"
        ],
        "published_date": "2024",
        "abstract": "Biological neural networks do not only include long-term memory and weight multiplication capabilities, as commonly assumed in artificial neural networks, but also more complex functions such as short-term memory, short-term plasticity, and meta-plasticity - all collocated within each synapse. Here, we demonstrate memristive nano-devices based on SrTiO3 that inherently emulate all these synaptic functions. These memristors operate in a non-filamentary, low conductance regime, which enables stable and energy efficient operation. They can act as multi-functional hardware synapses in a class of bio-inspired deep neural networks (DNN) that make use of both long- and short-term synaptic dynamics and are capable of meta-learning or learning-to-learn. The resulting bio-inspired DNN is then trained to play the video game Atari Pong, a complex reinforcement learning task in a dynamic environment. Our analysis shows that the energy consumption of the DNN with multi-functional memristive synapses decreases by about two orders of magnitude as compared to a pure GPU implementation. Based on this finding, we infer that memristive devices with a better emulation of the synaptic functionalities do not only broaden the applicability of neuromorphic computing, but could also improve the performance and energy costs of certain artificial intelligence applications.",
        "file_path": "paper_data/Deep_Meta-Learning/info/24411be9cbb7ca4bc27fb6e3285601405e39061f.pdf",
        "venue": "Nature Communications",
        "citationCount": 33,
        "score": 33.0,
        "summary": "Biological neural networks do not only include long-term memory and weight multiplication capabilities, as commonly assumed in artificial neural networks, but also more complex functions such as short-term memory, short-term plasticity, and meta-plasticity - all collocated within each synapse. Here, we demonstrate memristive nano-devices based on SrTiO3 that inherently emulate all these synaptic functions. These memristors operate in a non-filamentary, low conductance regime, which enables stable and energy efficient operation. They can act as multi-functional hardware synapses in a class of bio-inspired deep neural networks (DNN) that make use of both long- and short-term synaptic dynamics and are capable of meta-learning or learning-to-learn. The resulting bio-inspired DNN is then trained to play the video game Atari Pong, a complex reinforcement learning task in a dynamic environment. Our analysis shows that the energy consumption of the DNN with multi-functional memristive synapses decreases by about two orders of magnitude as compared to a pure GPU implementation. Based on this finding, we infer that memristive devices with a better emulation of the synaptic functionalities do not only broaden the applicability of neuromorphic computing, but could also improve the performance and energy costs of certain artificial intelligence applications.",
        "keywords": []
      },
      "file_name": "24411be9cbb7ca4bc27fb6e3285601405e39061f.pdf"
    },
    {
      "success": true,
      "doc_id": "5e906eeebed500995ad99b40489e81ea",
      "summary": "Learning based approaches have witnessed great successes in blind single image super-resolution (SISR) tasks, however, handcrafted kernel priors and learning based kernel priors are typically required. In this paper, we propose a meta-learning and Markov Chain Monte Carlo (MCMC) based SISR approach to learn kernel priors from organized randomness. In concrete, a lightweight network is adopted as kernel generator, and is optimized via learning from the MCMC simulation on random Gaussian distributions. This procedure provides an approximation for the rational blur kernel, and introduces a network-level Langevin dynamics into SISR optimization processes, which contributes to preventing bad local optimal solutions for kernel estimation. Meanwhile, a meta-learning based alternating optimization procedure is proposed to optimize the kernel generator and image restorer, respectively. In contrast to the conventional alternating minimization strategy, a meta-learning based framework is applied to learn an adaptive optimization strategy, which is less-greedy and results in better convergence performance. These two procedures are iteratively processed in a plug-and-play fashion, for the first time, realizing a learning-based but plug-and-play blind SISR solution in unsupervised inference. Extensive simulations demonstrate the superior performance and generalization ability of the proposed approach when compared with the Start-of-the-Art solutions on synthesis and real-world datasets.",
      "intriguing_abstract": "Learning based approaches have witnessed great successes in blind single image super-resolution (SISR) tasks, however, handcrafted kernel priors and learning based kernel priors are typically required. In this paper, we propose a meta-learning and Markov Chain Monte Carlo (MCMC) based SISR approach to learn kernel priors from organized randomness. In concrete, a lightweight network is adopted as kernel generator, and is optimized via learning from the MCMC simulation on random Gaussian distributions. This procedure provides an approximation for the rational blur kernel, and introduces a network-level Langevin dynamics into SISR optimization processes, which contributes to preventing bad local optimal solutions for kernel estimation. Meanwhile, a meta-learning based alternating optimization procedure is proposed to optimize the kernel generator and image restorer, respectively. In contrast to the conventional alternating minimization strategy, a meta-learning based framework is applied to learn an adaptive optimization strategy, which is less-greedy and results in better convergence performance. These two procedures are iteratively processed in a plug-and-play fashion, for the first time, realizing a learning-based but plug-and-play blind SISR solution in unsupervised inference. Extensive simulations demonstrate the superior performance and generalization ability of the proposed approach when compared with the Start-of-the-Art solutions on synthesis and real-world datasets.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/fdbe673ffb7408cd626f09a64d0427171354cd5c.pdf",
      "citation_key": "xia2024qx2",
      "metadata": {
        "title": "Blind Super-Resolution via Meta-Learning and Markov Chain Monte Carlo Simulation",
        "authors": [
          "Jingyuan Xia",
          "Zhixiong Yang",
          "Shengxi Li",
          "Shuanghui Zhang",
          "Yaowen Fu",
          "Deniz Gündüz",
          "Xiang Li"
        ],
        "published_date": "2024",
        "abstract": "Learning based approaches have witnessed great successes in blind single image super-resolution (SISR) tasks, however, handcrafted kernel priors and learning based kernel priors are typically required. In this paper, we propose a meta-learning and Markov Chain Monte Carlo (MCMC) based SISR approach to learn kernel priors from organized randomness. In concrete, a lightweight network is adopted as kernel generator, and is optimized via learning from the MCMC simulation on random Gaussian distributions. This procedure provides an approximation for the rational blur kernel, and introduces a network-level Langevin dynamics into SISR optimization processes, which contributes to preventing bad local optimal solutions for kernel estimation. Meanwhile, a meta-learning based alternating optimization procedure is proposed to optimize the kernel generator and image restorer, respectively. In contrast to the conventional alternating minimization strategy, a meta-learning based framework is applied to learn an adaptive optimization strategy, which is less-greedy and results in better convergence performance. These two procedures are iteratively processed in a plug-and-play fashion, for the first time, realizing a learning-based but plug-and-play blind SISR solution in unsupervised inference. Extensive simulations demonstrate the superior performance and generalization ability of the proposed approach when compared with the Start-of-the-Art solutions on synthesis and real-world datasets.",
        "file_path": "paper_data/Deep_Meta-Learning/info/fdbe673ffb7408cd626f09a64d0427171354cd5c.pdf",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "citationCount": 31,
        "score": 31.0,
        "summary": "Learning based approaches have witnessed great successes in blind single image super-resolution (SISR) tasks, however, handcrafted kernel priors and learning based kernel priors are typically required. In this paper, we propose a meta-learning and Markov Chain Monte Carlo (MCMC) based SISR approach to learn kernel priors from organized randomness. In concrete, a lightweight network is adopted as kernel generator, and is optimized via learning from the MCMC simulation on random Gaussian distributions. This procedure provides an approximation for the rational blur kernel, and introduces a network-level Langevin dynamics into SISR optimization processes, which contributes to preventing bad local optimal solutions for kernel estimation. Meanwhile, a meta-learning based alternating optimization procedure is proposed to optimize the kernel generator and image restorer, respectively. In contrast to the conventional alternating minimization strategy, a meta-learning based framework is applied to learn an adaptive optimization strategy, which is less-greedy and results in better convergence performance. These two procedures are iteratively processed in a plug-and-play fashion, for the first time, realizing a learning-based but plug-and-play blind SISR solution in unsupervised inference. Extensive simulations demonstrate the superior performance and generalization ability of the proposed approach when compared with the Start-of-the-Art solutions on synthesis and real-world datasets.",
        "keywords": []
      },
      "file_name": "fdbe673ffb7408cd626f09a64d0427171354cd5c.pdf"
    },
    {
      "success": true,
      "doc_id": "2d6c0df15f9ed974378ad71390db495e",
      "summary": "Objectives Knee osteoarthritis (KOA), a prevalent degenerative joint disease, is primarily diagnosed through X-ray imaging. The Kellgren-Lawrence grading system (K-L) is the gold standard for evaluating KOA severity through X-ray analysis. However, this method is highly subjective and non-quantifiable, limiting its effectiveness in detecting subtle joint changes on X-rays. Recent researchers have been directed towards developing deep-learning (DL) techniques for a more accurate diagnosis of KOA using X-ray images. Despite advancements in these intelligent methods, the debate over their diagnostic sensitivity continues. Hence, we conducted the current meta-analysis. Methods A comprehensive search was conducted in PubMed, Cochrane, Embase, Web of Science, and IEEE up to July 11, 2023. The QUADAS-2 tool was employed to assess the risk of bias in the included studies. Given the multi-classification nature of DL tasks, the sensitivity of DL across different K-L grades was meta-analyzed. Results A total of 19 studies were included, encompassing 62,158 images. These images consisted of 22,388 for K-L0, 13,415 for K-L1, 15,597 for K-L2, 7768 for K-L3, and 2990 for K-L4. The meta-analysis demonstrated that the sensitivity of DL was 86.74% for K-L0 (95% CI: 80.01%–92.28%), 64.00% for K-L1 (95% CI: 51.81%–75.35%), 75.03% for K-L2 (95% CI: 66.00%–83.09%), 84.76% for K-L3 (95% CI: 78.34%–90.25%), and 90.32% for K-L4 (95% CI: 85.39%–94.40%). Conclusions The DL multi-classification methods based on X-ray imaging generally demonstrate a favorable sensitivity rate (over 50%) in distinguishing between K-L0-K-L4. Specifically, for K-L4, the sensitivity is highly satisfactory at 90.32%. In contrast, the sensitivity rates for K-L1-2 still need improvement. Clinical relevance statement Deep-learning methods have been useful to some extent in assessing the effectiveness of X-rays for osteoarthritis of the knee. However, this requires further research and reliable data to provide specific recommendations for clinical practice. Key Points X-ray deep-learning (DL) methods are debatable for evaluating knee osteoarthritis (KOA) under The Kellgren-Lawrence system (K-L). Multi-classification deep-learning methods are more clinically relevant for assessing K-L grading than dichotomous results. For K-L3 and K-L4, X-ray-based DL has high diagnostic performance; early KOA needs to be further improved.",
      "intriguing_abstract": "Objectives Knee osteoarthritis (KOA), a prevalent degenerative joint disease, is primarily diagnosed through X-ray imaging. The Kellgren-Lawrence grading system (K-L) is the gold standard for evaluating KOA severity through X-ray analysis. However, this method is highly subjective and non-quantifiable, limiting its effectiveness in detecting subtle joint changes on X-rays. Recent researchers have been directed towards developing deep-learning (DL) techniques for a more accurate diagnosis of KOA using X-ray images. Despite advancements in these intelligent methods, the debate over their diagnostic sensitivity continues. Hence, we conducted the current meta-analysis. Methods A comprehensive search was conducted in PubMed, Cochrane, Embase, Web of Science, and IEEE up to July 11, 2023. The QUADAS-2 tool was employed to assess the risk of bias in the included studies. Given the multi-classification nature of DL tasks, the sensitivity of DL across different K-L grades was meta-analyzed. Results A total of 19 studies were included, encompassing 62,158 images. These images consisted of 22,388 for K-L0, 13,415 for K-L1, 15,597 for K-L2, 7768 for K-L3, and 2990 for K-L4. The meta-analysis demonstrated that the sensitivity of DL was 86.74% for K-L0 (95% CI: 80.01%–92.28%), 64.00% for K-L1 (95% CI: 51.81%–75.35%), 75.03% for K-L2 (95% CI: 66.00%–83.09%), 84.76% for K-L3 (95% CI: 78.34%–90.25%), and 90.32% for K-L4 (95% CI: 85.39%–94.40%). Conclusions The DL multi-classification methods based on X-ray imaging generally demonstrate a favorable sensitivity rate (over 50%) in distinguishing between K-L0-K-L4. Specifically, for K-L4, the sensitivity is highly satisfactory at 90.32%. In contrast, the sensitivity rates for K-L1-2 still need improvement. Clinical relevance statement Deep-learning methods have been useful to some extent in assessing the effectiveness of X-rays for osteoarthritis of the knee. However, this requires further research and reliable data to provide specific recommendations for clinical practice. Key Points X-ray deep-learning (DL) methods are debatable for evaluating knee osteoarthritis (KOA) under The Kellgren-Lawrence system (K-L). Multi-classification deep-learning methods are more clinically relevant for assessing K-L grading than dichotomous results. For K-L3 and K-L4, X-ray-based DL has high diagnostic performance; early KOA needs to be further improved.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2cc2b10a8482e854e16e50df3a5fb087788556ad.pdf",
      "citation_key": "zhao2024f4b",
      "metadata": {
        "title": "The value of deep learning-based X-ray techniques in detecting and classifying K-L grades of knee osteoarthritis: a systematic review and meta-analysis",
        "authors": [
          "Haoming Zhao",
          "Liang Ou",
          "Ziming Zhang",
          "Le Zhang",
          "Ke Liu",
          "Jianjun Kuang"
        ],
        "published_date": "2024",
        "abstract": "Objectives Knee osteoarthritis (KOA), a prevalent degenerative joint disease, is primarily diagnosed through X-ray imaging. The Kellgren-Lawrence grading system (K-L) is the gold standard for evaluating KOA severity through X-ray analysis. However, this method is highly subjective and non-quantifiable, limiting its effectiveness in detecting subtle joint changes on X-rays. Recent researchers have been directed towards developing deep-learning (DL) techniques for a more accurate diagnosis of KOA using X-ray images. Despite advancements in these intelligent methods, the debate over their diagnostic sensitivity continues. Hence, we conducted the current meta-analysis. Methods A comprehensive search was conducted in PubMed, Cochrane, Embase, Web of Science, and IEEE up to July 11, 2023. The QUADAS-2 tool was employed to assess the risk of bias in the included studies. Given the multi-classification nature of DL tasks, the sensitivity of DL across different K-L grades was meta-analyzed. Results A total of 19 studies were included, encompassing 62,158 images. These images consisted of 22,388 for K-L0, 13,415 for K-L1, 15,597 for K-L2, 7768 for K-L3, and 2990 for K-L4. The meta-analysis demonstrated that the sensitivity of DL was 86.74% for K-L0 (95% CI: 80.01%–92.28%), 64.00% for K-L1 (95% CI: 51.81%–75.35%), 75.03% for K-L2 (95% CI: 66.00%–83.09%), 84.76% for K-L3 (95% CI: 78.34%–90.25%), and 90.32% for K-L4 (95% CI: 85.39%–94.40%). Conclusions The DL multi-classification methods based on X-ray imaging generally demonstrate a favorable sensitivity rate (over 50%) in distinguishing between K-L0-K-L4. Specifically, for K-L4, the sensitivity is highly satisfactory at 90.32%. In contrast, the sensitivity rates for K-L1-2 still need improvement. Clinical relevance statement Deep-learning methods have been useful to some extent in assessing the effectiveness of X-rays for osteoarthritis of the knee. However, this requires further research and reliable data to provide specific recommendations for clinical practice. Key Points X-ray deep-learning (DL) methods are debatable for evaluating knee osteoarthritis (KOA) under The Kellgren-Lawrence system (K-L). Multi-classification deep-learning methods are more clinically relevant for assessing K-L grading than dichotomous results. For K-L3 and K-L4, X-ray-based DL has high diagnostic performance; early KOA needs to be further improved.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2cc2b10a8482e854e16e50df3a5fb087788556ad.pdf",
        "venue": "European Radiology",
        "citationCount": 29,
        "score": 29.0,
        "summary": "Objectives Knee osteoarthritis (KOA), a prevalent degenerative joint disease, is primarily diagnosed through X-ray imaging. The Kellgren-Lawrence grading system (K-L) is the gold standard for evaluating KOA severity through X-ray analysis. However, this method is highly subjective and non-quantifiable, limiting its effectiveness in detecting subtle joint changes on X-rays. Recent researchers have been directed towards developing deep-learning (DL) techniques for a more accurate diagnosis of KOA using X-ray images. Despite advancements in these intelligent methods, the debate over their diagnostic sensitivity continues. Hence, we conducted the current meta-analysis. Methods A comprehensive search was conducted in PubMed, Cochrane, Embase, Web of Science, and IEEE up to July 11, 2023. The QUADAS-2 tool was employed to assess the risk of bias in the included studies. Given the multi-classification nature of DL tasks, the sensitivity of DL across different K-L grades was meta-analyzed. Results A total of 19 studies were included, encompassing 62,158 images. These images consisted of 22,388 for K-L0, 13,415 for K-L1, 15,597 for K-L2, 7768 for K-L3, and 2990 for K-L4. The meta-analysis demonstrated that the sensitivity of DL was 86.74% for K-L0 (95% CI: 80.01%–92.28%), 64.00% for K-L1 (95% CI: 51.81%–75.35%), 75.03% for K-L2 (95% CI: 66.00%–83.09%), 84.76% for K-L3 (95% CI: 78.34%–90.25%), and 90.32% for K-L4 (95% CI: 85.39%–94.40%). Conclusions The DL multi-classification methods based on X-ray imaging generally demonstrate a favorable sensitivity rate (over 50%) in distinguishing between K-L0-K-L4. Specifically, for K-L4, the sensitivity is highly satisfactory at 90.32%. In contrast, the sensitivity rates for K-L1-2 still need improvement. Clinical relevance statement Deep-learning methods have been useful to some extent in assessing the effectiveness of X-rays for osteoarthritis of the knee. However, this requires further research and reliable data to provide specific recommendations for clinical practice. Key Points X-ray deep-learning (DL) methods are debatable for evaluating knee osteoarthritis (KOA) under The Kellgren-Lawrence system (K-L). Multi-classification deep-learning methods are more clinically relevant for assessing K-L grading than dichotomous results. For K-L3 and K-L4, X-ray-based DL has high diagnostic performance; early KOA needs to be further improved.",
        "keywords": []
      },
      "file_name": "2cc2b10a8482e854e16e50df3a5fb087788556ad.pdf"
    },
    {
      "success": true,
      "doc_id": "24f758a1bf1fc724961189f8b21b49e6",
      "summary": "This paper proposes an active coordinated fault tolerance load frequency control (AFCT-LFC) method, which effectively prevents sudden frequency changes caused by unit actuator failures or unplanned decommissioning in a multi-area interconnected grid subject to the performance-based frequency regulation market mechanism. It can also reduce regulation mileage payments and achieve multi-objective active fault-tolerant control. In addition, this paper proposes a brain-Inspired deep meta-deterministic policy gradient algorithm (BIMA-DMDPG), which adopts multi-agent centralized training, equates the controller of each area as an agent capable of independent decision making, and implements distributed training by dividing the environment into multiple environments. In addition, meta-reinforcement learning is employed to realize multi-task collaborative learning. The optimal policy is actively selected under different fault conditions to achieve active fault-tolerant control. The superior performance of the method is verified in a four-area LFC model of the China Southern Grid (CSG), in which it is tested alongside a selection of existing algorithms. Note to Practitioners—AFCT-LFC is based on advanced artificial intelligence algorithm, which can effectively identify any fault in multi-area grids and make rapid response to achieve active fault-tolerant control. Compared with the existing model-based fault-tolerant control methods, the BIMA-DMDPG algorithm proposed in this paper does not need to rely on accurate mathematical models, and can be applied to practice through simple training, which is very suitable for practical applications. Therefore, AFCT-LFC is an advanced adaptive active fault-tolerant control method that can be truly applied in practice because of its fast-decision-making ability and performance.",
      "intriguing_abstract": "This paper proposes an active coordinated fault tolerance load frequency control (AFCT-LFC) method, which effectively prevents sudden frequency changes caused by unit actuator failures or unplanned decommissioning in a multi-area interconnected grid subject to the performance-based frequency regulation market mechanism. It can also reduce regulation mileage payments and achieve multi-objective active fault-tolerant control. In addition, this paper proposes a brain-Inspired deep meta-deterministic policy gradient algorithm (BIMA-DMDPG), which adopts multi-agent centralized training, equates the controller of each area as an agent capable of independent decision making, and implements distributed training by dividing the environment into multiple environments. In addition, meta-reinforcement learning is employed to realize multi-task collaborative learning. The optimal policy is actively selected under different fault conditions to achieve active fault-tolerant control. The superior performance of the method is verified in a four-area LFC model of the China Southern Grid (CSG), in which it is tested alongside a selection of existing algorithms. Note to Practitioners—AFCT-LFC is based on advanced artificial intelligence algorithm, which can effectively identify any fault in multi-area grids and make rapid response to achieve active fault-tolerant control. Compared with the existing model-based fault-tolerant control methods, the BIMA-DMDPG algorithm proposed in this paper does not need to rely on accurate mathematical models, and can be applied to practice through simple training, which is very suitable for practical applications. Therefore, AFCT-LFC is an advanced adaptive active fault-tolerant control method that can be truly applied in practice because of its fast-decision-making ability and performance.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/cb596495788a5fa432a2342fc28f1c623e75d12e.pdf",
      "citation_key": "li20242rv",
      "metadata": {
        "title": "Brain-Inspired Deep Meta-Reinforcement Learning for Active Coordinated Fault-Tolerant Load Frequency Control of Multi-Area Grids",
        "authors": [
          "Jiawen Li",
          "Tao Zhou",
          "Haoyan Cui"
        ],
        "published_date": "2024",
        "abstract": "This paper proposes an active coordinated fault tolerance load frequency control (AFCT-LFC) method, which effectively prevents sudden frequency changes caused by unit actuator failures or unplanned decommissioning in a multi-area interconnected grid subject to the performance-based frequency regulation market mechanism. It can also reduce regulation mileage payments and achieve multi-objective active fault-tolerant control. In addition, this paper proposes a brain-Inspired deep meta-deterministic policy gradient algorithm (BIMA-DMDPG), which adopts multi-agent centralized training, equates the controller of each area as an agent capable of independent decision making, and implements distributed training by dividing the environment into multiple environments. In addition, meta-reinforcement learning is employed to realize multi-task collaborative learning. The optimal policy is actively selected under different fault conditions to achieve active fault-tolerant control. The superior performance of the method is verified in a four-area LFC model of the China Southern Grid (CSG), in which it is tested alongside a selection of existing algorithms. Note to Practitioners—AFCT-LFC is based on advanced artificial intelligence algorithm, which can effectively identify any fault in multi-area grids and make rapid response to achieve active fault-tolerant control. Compared with the existing model-based fault-tolerant control methods, the BIMA-DMDPG algorithm proposed in this paper does not need to rely on accurate mathematical models, and can be applied to practice through simple training, which is very suitable for practical applications. Therefore, AFCT-LFC is an advanced adaptive active fault-tolerant control method that can be truly applied in practice because of its fast-decision-making ability and performance.",
        "file_path": "paper_data/Deep_Meta-Learning/info/cb596495788a5fa432a2342fc28f1c623e75d12e.pdf",
        "venue": "IEEE Transactions on Automation Science and Engineering",
        "citationCount": 28,
        "score": 28.0,
        "summary": "This paper proposes an active coordinated fault tolerance load frequency control (AFCT-LFC) method, which effectively prevents sudden frequency changes caused by unit actuator failures or unplanned decommissioning in a multi-area interconnected grid subject to the performance-based frequency regulation market mechanism. It can also reduce regulation mileage payments and achieve multi-objective active fault-tolerant control. In addition, this paper proposes a brain-Inspired deep meta-deterministic policy gradient algorithm (BIMA-DMDPG), which adopts multi-agent centralized training, equates the controller of each area as an agent capable of independent decision making, and implements distributed training by dividing the environment into multiple environments. In addition, meta-reinforcement learning is employed to realize multi-task collaborative learning. The optimal policy is actively selected under different fault conditions to achieve active fault-tolerant control. The superior performance of the method is verified in a four-area LFC model of the China Southern Grid (CSG), in which it is tested alongside a selection of existing algorithms. Note to Practitioners—AFCT-LFC is based on advanced artificial intelligence algorithm, which can effectively identify any fault in multi-area grids and make rapid response to achieve active fault-tolerant control. Compared with the existing model-based fault-tolerant control methods, the BIMA-DMDPG algorithm proposed in this paper does not need to rely on accurate mathematical models, and can be applied to practice through simple training, which is very suitable for practical applications. Therefore, AFCT-LFC is an advanced adaptive active fault-tolerant control method that can be truly applied in practice because of its fast-decision-making ability and performance.",
        "keywords": []
      },
      "file_name": "cb596495788a5fa432a2342fc28f1c623e75d12e.pdf"
    },
    {
      "success": true,
      "doc_id": "7fad7949f1bc890f0f3a295351e595ae",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n**1. Research Problem & Motivation**\n\n*   **Specific Technical Problem**: The paper addresses the fundamental challenge of fully capturing and leveraging *spatiotemporal heterogeneity* in spatiotemporal time series forecasting \\cite{dong2024110}.\n*   **Importance and Challenge**:\n    *   Accurate spatiotemporal forecasting is crucial for real-world applications such as transportation, weather, and economics \\cite{dong2024110}.\n    *   Spatiotemporal data inherently exhibits significant heterogeneity:\n        *   **Spatial heterogeneity**: Distinct patterns are observed across different location types during the same time period (e.g., downtown vs. residential areas have different traffic dynamics) \\cite{dong2024110}.\n        *   **Temporal heterogeneity**: Unique patterns are observed at the same location across different time periods (e.g., weekdays vs. weekends, morning peak vs. nighttime off-peak hours) \\cite{dong2024110}.\n    *   Effectively modeling this heterogeneity is critical for accurate forecasting, as it requires identifying and distinguishing varied spatiotemporal contexts \\cite{dong2024110}.\n\n**2. Related Work & Positioning**\n\n*   **Relation to Existing Approaches**:\n    *   **Graph-based methods**: Attempt to capture heterogeneity using handcrafted features like graph topology or similarity metrics \\cite{dong2024110}.\n    *   **Meta-learning techniques**: Apply multiple parameter sets across different spatial locations, often relying on auxiliary characteristics such as Points-of-Interests (POIs) or sensor placements \\cite{dong2024110}.\n    *   **Representation learning methods**: Identify heterogeneity through input embeddings \\cite{dong2024110}.\n    *   **Self-supervised learning methods**: Capture spatiotemporal heterogeneity by designing additional tasks \\cite{dong2024110}.\n*   **Limitations of Previous Solutions**:\n    *   **Reliance on auxiliary features**: Many prior methods depend heavily on pre-defined representations or external data, limiting their adaptability and generalizability \\cite{dong2024110}.\n    *   **High computational and memory costs**: Some meta-learning approaches are computationally expensive, restricting their applicability to large-scale datasets \\cite{dong2024110}.\n    *   **Failure to fully leverage captured heterogeneity**: Representation learning methods often employ oversimplified downstream processing, failing to fully exploit the representational power of learned embeddings \\cite{dong2024110}.\n    *   **Difficulties with end-to-end optimization**: Self-supervised methods face challenges in achieving seamless end-to-end joint optimization for spatiotemporal forecasting \\cite{dong2024110}.\n    *   **Incomplete heterogeneity modeling**: Existing work generally lacks a comprehensive approach to *fully leveraging* spatiotemporal heterogeneity across all dimensions (temporal, spatial, and their joint interactions) \\cite{dong2024110}.\n\n**3. Technical Approach & Innovation**\n\n*   **Core Technical Method**: The paper proposes a novel **Heterogeneity-Informed Meta-Parameter Learning scheme** and implements it in the **Heterogeneity-Informed Spatiotemporal Meta-Network (HimNet)** \\cite{dong2024110}.\n    *   **Implicit Heterogeneity Characterization**: HimNet implicitly captures spatiotemporal heterogeneity by learning spatial and temporal embeddings from a \"clustering view.\" During training, these embeddings gradually differentiate and form distinct clusters, representing underlying spatiotemporal contexts without requiring auxiliary data or explicit clustering constraints \\cite{dong2024110}.\n        *   **Temporal Embeddings**: Utilizes learnable time-of-day and day-of-week embedding dictionaries to capture fine-grained periodic patterns (e.g., peak/off-peak hours) and longer-term patterns (e.g., weekdays/weekends) \\cite{dong2024110}.\n        *   **Spatial Embeddings**: Employs a learnable spatial embedding matrix where each location is associated with a unique vector, accounting for inherent functional differences between locations without needing auxiliary geographical data \\cite{dong2024110}.\n    *   **Spatiotemporal Meta-Parameter Learning Paradigm**: To fully leverage the captured heterogeneity, HimNet introduces a paradigm where unique parameter sets are learned for each spatiotemporal context \\cite{dong2024110}.\n        *   Instead of optimizing prohibitively large parameter spaces, it maintains *small meta-parameter pools* (containing `k` candidates, where `k` is significantly smaller than the total timesteps or locations) \\cite{dong2024110}.\n        *   Meta-parameters are dynamically generated as a weighted combination of candidates from these pools, using the learned spatiotemporal embeddings as queries \\cite{dong2024110}.\n        *   This includes generating **Temporal Meta-Parameters** (from temporal embeddings), **Spatial Meta-Parameters** (from spatial embeddings), and **ST-Mixed Meta-Parameters** (derived from an encoded representation of the input time series itself, as direct joint embeddings are too large to optimize) \\cite{dong2024110}.\n*   **Novelty/Difference**:\n    *   **Data-Driven and Auxiliary-Free Heterogeneity Capture**: Implicitly characterizes heterogeneity through learnable embeddings, avoiding reliance on handcrafted features or external auxiliary data \\cite{dong2024110}.\n    *   **Full Heterogeneity Leveraging**: It is presented as the first method to not only capture but also *fully leverage* spatiotemporal heterogeneity by informing meta-parameter learning across temporal, spatial, and joint dimensions concurrently \\cite{dong2024110}.\n    *   **Computational Efficiency**: Addresses the high computational cost of meta-learning by using compact meta-parameter pools, reducing complexity from `O(TN)` to `O(k)` \\cite{dong2024110}.\n    *   **End-to-End Design**: HimNet is designed as an end-to-end network, facilitating joint optimization for spatiotemporal forecasting \\cite{dong2024110}.\n\n**4. Key Technical Contributions**\n\n*   **Novel Algorithms/Methods**:\n    *   **Heterogeneity-Informed Meta-Parameter Learning scheme**: A novel paradigm that uses learnable spatiotemporal embeddings to dynamically generate context-specific parameters from compact meta-parameter pools \\cite{dong2024110}.\n    *   **Implicit Spatiotemporal Heterogeneity Modeling**: Captures inherent heterogeneity through learnable spatial and temporal embeddings that naturally form clusters representing distinct contexts during training \\cite{dong2024110}.\n    *   **Concurrent Meta-Parameter Generation**: Generates temporal, spatial, and spatiotemporal-mixed meta-parameters simultaneously, ensuring maximum adaptability to diverse contexts \\cite{dong2024110}.\n*   **System Design/Architectural Innovations**:\n    *   **HimNet (Heterogeneity-Informed Spatiotemporal Meta-Network)**: An end-to-end network architecture that seamlessly integrates the proposed heterogeneity modeling and meta-parameter learning for robust spatiotemporal forecasting \\cite{dong2024110}.\n*   **Theoretical Insights/Analysis**:\n    *   The concept that learnable embeddings can perform a dynamic clustering process, where representations differentiate and form clusters corresponding to typical spatiotemporal contexts, without requiring explicit clustering constraints \\cite{dong2024110}.\n    *   Demonstrates that leveraging captured heterogeneity to *inform* parameter learning significantly enhances model adaptability and generalizability \\cite{dong2024110}.\n\n**5. Experimental Validation**\n\n*   **Experiments Conducted**: Extensive experiments were performed on five widely-used benchmarks to evaluate HimNet's performance \\cite{dong2024110}.\n*   **Key Performance Metrics and Comparison Results**:\n    *   HimNet achieves **state-of-the-art performance** across all five benchmarks, outperforming existing methods \\cite{dong2024110}.\n    *   It exhibits **superior interpretability** through its meta-parameters, which was further illustrated by visualization experiments \\cite{dong2024110}.\n    *   The method demonstrates **competitive efficiency** alongside its superior forecasting performance \\cite{dong2024110}.\n\n**6. Limitations & Scope**\n\n*   **Technical Limitations/Assumptions**:\n    *   The paper does not explicitly detail specific technical limitations of HimNet itself.\n    *   An implicit assumption is that the chosen size `k` for the meta-parameter pools is sufficient to encapsulate the variety of different contexts, which may require careful tuning \\cite{dong2024110}.\n    *   The choice of encoding function `F_enc` for ST-Mixed Meta-Parameters (e.g., linear projection, TCN, GRU) is flexible but represents a design decision that could influence performance \\cite{dong2024110}.\n*   **Scope of Applicability**:\n    *   Primarily focused on **spatiotemporal time series forecasting** in domains characterized by heterogeneous data, such as urban environments (e.g., transportation, weather, economics) \\cite{dong2024110}.\n    *   The approach is designed to be **flexible for various domains** due to its data-independent nature and concurrent learning scheme, making it broadly applicable where spatiotemporal heterogeneity is a key factor \\cite{dong2024110}.\n\n**7. Technical Significance**\n\n*   **Advancement of State-of-the-Art**:\n    *   HimNet significantly advances the state-of-the-art in spatiotemporal time series forecasting by providing a robust and efficient solution to the long-standing challenge of fully capturing and leveraging spatiotemporal heterogeneity \\cite{dong2024110}.\n    *   It introduces a paradigm shift from merely capturing heterogeneity to *explicitly using it* to inform model parameter learning, leading to models with enhanced adaptability and generalizability \\cite{dong2024110}.\n    *   Its superior performance on multiple benchmarks, coupled with competitive efficiency and strong interpretability, sets a new benchmark for spatiotemporal forecasting models \\cite{dong2024110}.\n*   **Potential Impact on Future Research**:\n    *   The proposed \"heterogeneity-informed meta-parameter learning\" framework and the \"clustering view\" of learnable embeddings could inspire new research directions in adaptive modeling for complex, heterogeneous data across various domains beyond spatiotemporal forecasting \\cite{dong2024110}.\n    *   Its data-independent nature and concurrent learning scheme offer a blueprint for developing more flexible and generalizable models that do not rely on auxiliary features \\cite{dong2024110}.\n    *   The demonstrated interpretability through meta-parameters could foster further research into developing more transparent and explainable AI models for time series analysis and other complex data types \\cite{dong2024110}.",
      "intriguing_abstract": "Spatiotemporal time series forecasting is critical for diverse applications, yet accurately modeling pervasive spatiotemporal heterogeneity—where patterns vary across locations and times—remains a significant challenge. Existing methods often rely on auxiliary data, incur high computational costs, or incompletely leverage this crucial variability. We introduce **HimNet (Heterogeneity-Informed Spatiotemporal Meta-Network)**, a novel, end-to-end framework that revolutionizes how heterogeneity is handled. HimNet implicitly characterizes spatiotemporal contexts through learnable spatial and temporal embeddings, which dynamically cluster without requiring auxiliary features or explicit constraints. Crucially, it pioneers a **Heterogeneity-Informed Meta-Parameter Learning scheme**, dynamically generating context-specific model parameters from compact meta-parameter pools across temporal, spatial, and joint dimensions. This auxiliary-free, computationally efficient approach fully leverages heterogeneity, leading to unprecedented adaptability. HimNet achieves state-of-the-art performance on five benchmarks, demonstrating superior interpretability and efficiency. This work sets a new paradigm for adaptive modeling, paving the way for more robust and generalizable spatiotemporal forecasting systems.",
      "keywords": [
        "Spatiotemporal time series forecasting",
        "Spatiotemporal heterogeneity",
        "Heterogeneity-Informed Meta-Parameter Learning",
        "HimNet",
        "Implicit heterogeneity characterization",
        "Learnable spatial and temporal embeddings",
        "Meta-parameter pools",
        "Auxiliary-free modeling",
        "Full heterogeneity leveraging",
        "Concurrent meta-parameter generation",
        "State-of-the-art performance",
        "Computational efficiency",
        "Model interpretability",
        "Adaptive modeling"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/c09d2846ff81c5dbdf4f8662bd2d9bb4dd61b396.pdf",
      "citation_key": "dong2024110",
      "metadata": {
        "title": "Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series Forecasting",
        "authors": [
          "Zheng Dong",
          "Renhe Jiang",
          "Haotian Gao",
          "Hangchen Liu",
          "Jinliang Deng",
          "Qingsong Wen",
          "Xuan Song"
        ],
        "published_date": "2024",
        "abstract": "Spatiotemporal time series forecasting plays a key role in a wide range of real-world applications. While significant progress has been made in this area, fully capturing and leveraging spatiotemporal heterogeneity remains a fundamental challenge. Therefore, we propose a novel Heterogeneity-Informed Meta-Parameter Learning scheme. Specifically, our approach implicitly captures spatiotemporal heterogeneity through learning spatial and temporal embeddings, which can be viewed as a clustering process. Then, a novel spatiotemporal meta-parameter learning paradigm is proposed to learn spatiotemporal-specific parameters from meta-parameter pools, which is informed by the captured heterogeneity. Based on these ideas, we develop a Heterogeneity-Informed Spatiotemporal Meta-Network (HimNet) for spatiotemporal time series forecasting. Extensive experiments on five widely-used benchmarks demonstrate our method achieves state-of-the-art performance while exhibiting superior interpretability. Our code is available at https://github.com/XDZhelheim/HimNet.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c09d2846ff81c5dbdf4f8662bd2d9bb4dd61b396.pdf",
        "venue": "Knowledge Discovery and Data Mining",
        "citationCount": 27,
        "score": 27.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n**1. Research Problem & Motivation**\n\n*   **Specific Technical Problem**: The paper addresses the fundamental challenge of fully capturing and leveraging *spatiotemporal heterogeneity* in spatiotemporal time series forecasting \\cite{dong2024110}.\n*   **Importance and Challenge**:\n    *   Accurate spatiotemporal forecasting is crucial for real-world applications such as transportation, weather, and economics \\cite{dong2024110}.\n    *   Spatiotemporal data inherently exhibits significant heterogeneity:\n        *   **Spatial heterogeneity**: Distinct patterns are observed across different location types during the same time period (e.g., downtown vs. residential areas have different traffic dynamics) \\cite{dong2024110}.\n        *   **Temporal heterogeneity**: Unique patterns are observed at the same location across different time periods (e.g., weekdays vs. weekends, morning peak vs. nighttime off-peak hours) \\cite{dong2024110}.\n    *   Effectively modeling this heterogeneity is critical for accurate forecasting, as it requires identifying and distinguishing varied spatiotemporal contexts \\cite{dong2024110}.\n\n**2. Related Work & Positioning**\n\n*   **Relation to Existing Approaches**:\n    *   **Graph-based methods**: Attempt to capture heterogeneity using handcrafted features like graph topology or similarity metrics \\cite{dong2024110}.\n    *   **Meta-learning techniques**: Apply multiple parameter sets across different spatial locations, often relying on auxiliary characteristics such as Points-of-Interests (POIs) or sensor placements \\cite{dong2024110}.\n    *   **Representation learning methods**: Identify heterogeneity through input embeddings \\cite{dong2024110}.\n    *   **Self-supervised learning methods**: Capture spatiotemporal heterogeneity by designing additional tasks \\cite{dong2024110}.\n*   **Limitations of Previous Solutions**:\n    *   **Reliance on auxiliary features**: Many prior methods depend heavily on pre-defined representations or external data, limiting their adaptability and generalizability \\cite{dong2024110}.\n    *   **High computational and memory costs**: Some meta-learning approaches are computationally expensive, restricting their applicability to large-scale datasets \\cite{dong2024110}.\n    *   **Failure to fully leverage captured heterogeneity**: Representation learning methods often employ oversimplified downstream processing, failing to fully exploit the representational power of learned embeddings \\cite{dong2024110}.\n    *   **Difficulties with end-to-end optimization**: Self-supervised methods face challenges in achieving seamless end-to-end joint optimization for spatiotemporal forecasting \\cite{dong2024110}.\n    *   **Incomplete heterogeneity modeling**: Existing work generally lacks a comprehensive approach to *fully leveraging* spatiotemporal heterogeneity across all dimensions (temporal, spatial, and their joint interactions) \\cite{dong2024110}.\n\n**3. Technical Approach & Innovation**\n\n*   **Core Technical Method**: The paper proposes a novel **Heterogeneity-Informed Meta-Parameter Learning scheme** and implements it in the **Heterogeneity-Informed Spatiotemporal Meta-Network (HimNet)** \\cite{dong2024110}.\n    *   **Implicit Heterogeneity Characterization**: HimNet implicitly captures spatiotemporal heterogeneity by learning spatial and temporal embeddings from a \"clustering view.\" During training, these embeddings gradually differentiate and form distinct clusters, representing underlying spatiotemporal contexts without requiring auxiliary data or explicit clustering constraints \\cite{dong2024110}.\n        *   **Temporal Embeddings**: Utilizes learnable time-of-day and day-of-week embedding dictionaries to capture fine-grained periodic patterns (e.g., peak/off-peak hours) and longer-term patterns (e.g., weekdays/weekends) \\cite{dong2024110}.\n        *   **Spatial Embeddings**: Employs a learnable spatial embedding matrix where each location is associated with a unique vector, accounting for inherent functional differences between locations without needing auxiliary geographical data \\cite{dong2024110}.\n    *   **Spatiotemporal Meta-Parameter Learning Paradigm**: To fully leverage the captured heterogeneity, HimNet introduces a paradigm where unique parameter sets are learned for each spatiotemporal context \\cite{dong2024110}.\n        *   Instead of optimizing prohibitively large parameter spaces, it maintains *small meta-parameter pools* (containing `k` candidates, where `k` is significantly smaller than the total timesteps or locations) \\cite{dong2024110}.\n        *   Meta-parameters are dynamically generated as a weighted combination of candidates from these pools, using the learned spatiotemporal embeddings as queries \\cite{dong2024110}.\n        *   This includes generating **Temporal Meta-Parameters** (from temporal embeddings), **Spatial Meta-Parameters** (from spatial embeddings), and **ST-Mixed Meta-Parameters** (derived from an encoded representation of the input time series itself, as direct joint embeddings are too large to optimize) \\cite{dong2024110}.\n*   **Novelty/Difference**:\n    *   **Data-Driven and Auxiliary-Free Heterogeneity Capture**: Implicitly characterizes heterogeneity through learnable embeddings, avoiding reliance on handcrafted features or external auxiliary data \\cite{dong2024110}.\n    *   **Full Heterogeneity Leveraging**: It is presented as the first method to not only capture but also *fully leverage* spatiotemporal heterogeneity by informing meta-parameter learning across temporal, spatial, and joint dimensions concurrently \\cite{dong2024110}.\n    *   **Computational Efficiency**: Addresses the high computational cost of meta-learning by using compact meta-parameter pools, reducing complexity from `O(TN)` to `O(k)` \\cite{dong2024110}.\n    *   **End-to-End Design**: HimNet is designed as an end-to-end network, facilitating joint optimization for spatiotemporal forecasting \\cite{dong2024110}.\n\n**4. Key Technical Contributions**\n\n*   **Novel Algorithms/Methods**:\n    *   **Heterogeneity-Informed Meta-Parameter Learning scheme**: A novel paradigm that uses learnable spatiotemporal embeddings to dynamically generate context-specific parameters from compact meta-parameter pools \\cite{dong2024110}.\n    *   **Implicit Spatiotemporal Heterogeneity Modeling**: Captures inherent heterogeneity through learnable spatial and temporal embeddings that naturally form clusters representing distinct contexts during training \\cite{dong2024110}.\n    *   **Concurrent Meta-Parameter Generation**: Generates temporal, spatial, and spatiotemporal-mixed meta-parameters simultaneously, ensuring maximum adaptability to diverse contexts \\cite{dong2024110}.\n*   **System Design/Architectural Innovations**:\n    *   **HimNet (Heterogeneity-Informed Spatiotemporal Meta-Network)**: An end-to-end network architecture that seamlessly integrates the proposed heterogeneity modeling and meta-parameter learning for robust spatiotemporal forecasting \\cite{dong2024110}.\n*   **Theoretical Insights/Analysis**:\n    *   The concept that learnable embeddings can perform a dynamic clustering process, where representations differentiate and form clusters corresponding to typical spatiotemporal contexts, without requiring explicit clustering constraints \\cite{dong2024110}.\n    *   Demonstrates that leveraging captured heterogeneity to *inform* parameter learning significantly enhances model adaptability and generalizability \\cite{dong2024110}.\n\n**5. Experimental Validation**\n\n*   **Experiments Conducted**: Extensive experiments were performed on five widely-used benchmarks to evaluate HimNet's performance \\cite{dong2024110}.\n*   **Key Performance Metrics and Comparison Results**:\n    *   HimNet achieves **state-of-the-art performance** across all five benchmarks, outperforming existing methods \\cite{dong2024110}.\n    *   It exhibits **superior interpretability** through its meta-parameters, which was further illustrated by visualization experiments \\cite{dong2024110}.\n    *   The method demonstrates **competitive efficiency** alongside its superior forecasting performance \\cite{dong2024110}.\n\n**6. Limitations & Scope**\n\n*   **Technical Limitations/Assumptions**:\n    *   The paper does not explicitly detail specific technical limitations of HimNet itself.\n    *   An implicit assumption is that the chosen size `k` for the meta-parameter pools is sufficient to encapsulate the variety of different contexts, which may require careful tuning \\cite{dong2024110}.\n    *   The choice of encoding function `F_enc` for ST-Mixed Meta-Parameters (e.g., linear projection, TCN, GRU) is flexible but represents a design decision that could influence performance \\cite{dong2024110}.\n*   **Scope of Applicability**:\n    *   Primarily focused on **spatiotemporal time series forecasting** in domains characterized by heterogeneous data, such as urban environments (e.g., transportation, weather, economics) \\cite{dong2024110}.\n    *   The approach is designed to be **flexible for various domains** due to its data-independent nature and concurrent learning scheme, making it broadly applicable where spatiotemporal heterogeneity is a key factor \\cite{dong2024110}.\n\n**7. Technical Significance**\n\n*   **Advancement of State-of-the-Art**:\n    *   HimNet significantly advances the state-of-the-art in spatiotemporal time series forecasting by providing a robust and efficient solution to the long-standing challenge of fully capturing and leveraging spatiotemporal heterogeneity \\cite{dong2024110}.\n    *   It introduces a paradigm shift from merely capturing heterogeneity to *explicitly using it* to inform model parameter learning, leading to models with enhanced adaptability and generalizability \\cite{dong2024110}.\n    *   Its superior performance on multiple benchmarks, coupled with competitive efficiency and strong interpretability, sets a new benchmark for spatiotemporal forecasting models \\cite{dong2024110}.\n*   **Potential Impact on Future Research**:\n    *   The proposed \"heterogeneity-informed meta-parameter learning\" framework and the \"clustering view\" of learnable embeddings could inspire new research directions in adaptive modeling for complex, heterogeneous data across various domains beyond spatiotemporal forecasting \\cite{dong2024110}.\n    *   Its data-independent nature and concurrent learning scheme offer a blueprint for developing more flexible and generalizable models that do not rely on auxiliary features \\cite{dong2024110}.\n    *   The demonstrated interpretability through meta-parameters could foster further research into developing more transparent and explainable AI models for time series analysis and other complex data types \\cite{dong2024110}.",
        "keywords": [
          "Spatiotemporal time series forecasting",
          "Spatiotemporal heterogeneity",
          "Heterogeneity-Informed Meta-Parameter Learning",
          "HimNet",
          "Implicit heterogeneity characterization",
          "Learnable spatial and temporal embeddings",
          "Meta-parameter pools",
          "Auxiliary-free modeling",
          "Full heterogeneity leveraging",
          "Concurrent meta-parameter generation",
          "State-of-the-art performance",
          "Computational efficiency",
          "Model interpretability",
          "Adaptive modeling"
        ],
        "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose** a novel heterogeneity-informed meta-parameter learning scheme,\" \"a novel spatiotemporal meta-parameter learning paradigm is **proposed**,\" and \"we **develop** a heterogeneity- informed spatiatiotemporal meta-network (himnet).\"\n*   it describes the components and mechanisms of this new approach (\"implicitly captures spatiotemporal heterogeneity through learning spatial and temporal embeddings\").\n*   it mentions \"extensive experiments on five widely-used benchmarks demonstrate our method achieves state-of-the-art performance,\" which is typical for validating a new technical contribution.\n*   the introduction identifies a \"major challenge\" that existing methods face, setting the stage for the proposed solution.\n\nthese phrases directly align with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and uses keywords like \"propose,\" \"develop,\" \"method,\" and discusses a \"technical problem\" and \"proposed solution.\"\n\ntherefore, the paper type is: **technical**"
      },
      "file_name": "c09d2846ff81c5dbdf4f8662bd2d9bb4dd61b396.pdf"
    },
    {
      "success": true,
      "doc_id": "80f5d157972d39929606630526e67efb",
      "summary": "This paper focuses on generating Inverse Synthetic Aperture Radar (ISAR) images from optical images, in particular, for orbit space targets. ISAR images are widely applied in space target observation and classification tasks, whereas, limited to the expensive cost of ISAR sample collection, training deep learning-based ISAR image classifiers with insufficient samples and generating ISAR samples from emulation optical images via image translation techniques have attracted increasing attention. Image translation has highlighted significant success and popularity in computer vision, remote sensing and data generation societies. However, most of the existing methods are implemented under the discipline of extracting the explicit pixel-level features and do not perform effectively while entailing translation to domains with specific implicit features, such as ISAR image does. We propose a meta-learning based domain prior to implicit feature modelling and apply it to CycleGAN and UNIT models to realize effective translations between the ISAR and optical domains. Two representative implicit features, ISAR scattering distribution feature from the physical domain and the classification identifying feature from the task domain, are elaborately formulated with explicit modelling in statistic form. A meta-learning based training scheme is introduced to leverage the mutual knowledge of domain priors across different samples, and thus allows few-shot learning capacity with dramatically reduced training samples. Extensive simulations validate that the obtained ISAR images have better visible-authenticity and training-effectiveness than the existing image translation approaches on various synthetic datasets. Source codes are available at https://github.com/XYLGroup/MLDP.",
      "intriguing_abstract": "This paper focuses on generating Inverse Synthetic Aperture Radar (ISAR) images from optical images, in particular, for orbit space targets. ISAR images are widely applied in space target observation and classification tasks, whereas, limited to the expensive cost of ISAR sample collection, training deep learning-based ISAR image classifiers with insufficient samples and generating ISAR samples from emulation optical images via image translation techniques have attracted increasing attention. Image translation has highlighted significant success and popularity in computer vision, remote sensing and data generation societies. However, most of the existing methods are implemented under the discipline of extracting the explicit pixel-level features and do not perform effectively while entailing translation to domains with specific implicit features, such as ISAR image does. We propose a meta-learning based domain prior to implicit feature modelling and apply it to CycleGAN and UNIT models to realize effective translations between the ISAR and optical domains. Two representative implicit features, ISAR scattering distribution feature from the physical domain and the classification identifying feature from the task domain, are elaborately formulated with explicit modelling in statistic form. A meta-learning based training scheme is introduced to leverage the mutual knowledge of domain priors across different samples, and thus allows few-shot learning capacity with dramatically reduced training samples. Extensive simulations validate that the obtained ISAR images have better visible-authenticity and training-effectiveness than the existing image translation approaches on various synthetic datasets. Source codes are available at https://github.com/XYLGroup/MLDP.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c8905a4c9c5cbeff6e905687c5077e8af47b8ce4.pdf",
      "citation_key": "liao2024o1z",
      "metadata": {
        "title": "Meta-Learning Based Domain Prior With Application to Optical-ISAR Image Translation",
        "authors": [
          "Huaizhang Liao",
          "Jingyuan Xia",
          "Zhixiong Yang",
          "Fulin Pan",
          "Zhen Liu",
          "Yongxiang Liu"
        ],
        "published_date": "2024",
        "abstract": "This paper focuses on generating Inverse Synthetic Aperture Radar (ISAR) images from optical images, in particular, for orbit space targets. ISAR images are widely applied in space target observation and classification tasks, whereas, limited to the expensive cost of ISAR sample collection, training deep learning-based ISAR image classifiers with insufficient samples and generating ISAR samples from emulation optical images via image translation techniques have attracted increasing attention. Image translation has highlighted significant success and popularity in computer vision, remote sensing and data generation societies. However, most of the existing methods are implemented under the discipline of extracting the explicit pixel-level features and do not perform effectively while entailing translation to domains with specific implicit features, such as ISAR image does. We propose a meta-learning based domain prior to implicit feature modelling and apply it to CycleGAN and UNIT models to realize effective translations between the ISAR and optical domains. Two representative implicit features, ISAR scattering distribution feature from the physical domain and the classification identifying feature from the task domain, are elaborately formulated with explicit modelling in statistic form. A meta-learning based training scheme is introduced to leverage the mutual knowledge of domain priors across different samples, and thus allows few-shot learning capacity with dramatically reduced training samples. Extensive simulations validate that the obtained ISAR images have better visible-authenticity and training-effectiveness than the existing image translation approaches on various synthetic datasets. Source codes are available at https://github.com/XYLGroup/MLDP.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c8905a4c9c5cbeff6e905687c5077e8af47b8ce4.pdf",
        "venue": "IEEE transactions on circuits and systems for video technology (Print)",
        "citationCount": 26,
        "score": 26.0,
        "summary": "This paper focuses on generating Inverse Synthetic Aperture Radar (ISAR) images from optical images, in particular, for orbit space targets. ISAR images are widely applied in space target observation and classification tasks, whereas, limited to the expensive cost of ISAR sample collection, training deep learning-based ISAR image classifiers with insufficient samples and generating ISAR samples from emulation optical images via image translation techniques have attracted increasing attention. Image translation has highlighted significant success and popularity in computer vision, remote sensing and data generation societies. However, most of the existing methods are implemented under the discipline of extracting the explicit pixel-level features and do not perform effectively while entailing translation to domains with specific implicit features, such as ISAR image does. We propose a meta-learning based domain prior to implicit feature modelling and apply it to CycleGAN and UNIT models to realize effective translations between the ISAR and optical domains. Two representative implicit features, ISAR scattering distribution feature from the physical domain and the classification identifying feature from the task domain, are elaborately formulated with explicit modelling in statistic form. A meta-learning based training scheme is introduced to leverage the mutual knowledge of domain priors across different samples, and thus allows few-shot learning capacity with dramatically reduced training samples. Extensive simulations validate that the obtained ISAR images have better visible-authenticity and training-effectiveness than the existing image translation approaches on various synthetic datasets. Source codes are available at https://github.com/XYLGroup/MLDP.",
        "keywords": []
      },
      "file_name": "c8905a4c9c5cbeff6e905687c5077e8af47b8ce4.pdf"
    },
    {
      "success": true,
      "doc_id": "9f948964a018f826d43cd8bfcd5bba97",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b48894f4f4cdebfaa290720960440b024675698c.pdf",
      "citation_key": "naskar202446a",
      "metadata": {
        "title": "Deepfake detection using deep feature stacking and meta-learning",
        "authors": [
          "Gourab Naskar",
          "Sk Mohiuddin",
          "Samir Malakar",
          "Erik Cuevas",
          "Ram Sarkar"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/b48894f4f4cdebfaa290720960440b024675698c.pdf",
        "venue": "Heliyon",
        "citationCount": 25,
        "score": 25.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "b48894f4f4cdebfaa290720960440b024675698c.pdf"
    },
    {
      "success": true,
      "doc_id": "726b0d937e8bd312b22a73060f1cce38",
      "summary": "Large-scale pretraining followed by task-specific finetuning has achieved great success in various NLP tasks. Since finetuning all parameters of large pretrained models poses substantial computational and memory challenges, several efficient finetuning methods have been developed. Among them, low-rank adaptation (LoRA), which finetunes low-rank incremental update matrices on top of frozen pretrained weights, has proven particularly effective. Nonetheless, LoRA’s uniform rank assignment across all layers, along with its reliance on an exhaustive search to find the best rank, leads to high computation costs and suboptimal finetuning performance. To address these limitations, we introduce AutoLoRA, a meta learning based framework for automatically identifying the optimal rank of each LoRA layer. AutoLoRA associates each rank-1 matrix in a low-rank update matrix with a selection variable, which determines whether the rank-1 matrix should be discarded. A meta learning based method is developed to learn these selection variables. The optimal rank is determined by thresholding the values of these variables. Our comprehensive experiments on natural language understanding, generation, and sequence labeling demonstrate the effectiveness of AutoLoRA. The code is publicly available at https://github.com/ruz048/AutoLoRA",
      "intriguing_abstract": "Large-scale pretraining followed by task-specific finetuning has achieved great success in various NLP tasks. Since finetuning all parameters of large pretrained models poses substantial computational and memory challenges, several efficient finetuning methods have been developed. Among them, low-rank adaptation (LoRA), which finetunes low-rank incremental update matrices on top of frozen pretrained weights, has proven particularly effective. Nonetheless, LoRA’s uniform rank assignment across all layers, along with its reliance on an exhaustive search to find the best rank, leads to high computation costs and suboptimal finetuning performance. To address these limitations, we introduce AutoLoRA, a meta learning based framework for automatically identifying the optimal rank of each LoRA layer. AutoLoRA associates each rank-1 matrix in a low-rank update matrix with a selection variable, which determines whether the rank-1 matrix should be discarded. A meta learning based method is developed to learn these selection variables. The optimal rank is determined by thresholding the values of these variables. Our comprehensive experiments on natural language understanding, generation, and sequence labeling demonstrate the effectiveness of AutoLoRA. The code is publicly available at https://github.com/ruz048/AutoLoRA",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/78da960c61d41c9c0fc2711fecacc5f5f29660ff.pdf",
      "citation_key": "zhang2024a5a",
      "metadata": {
        "title": "AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning",
        "authors": [
          "Ruiyi Zhang",
          "Rushi Qiang",
          "Sai Ashish Somayajula",
          "Pengtao Xie"
        ],
        "published_date": "2024",
        "abstract": "Large-scale pretraining followed by task-specific finetuning has achieved great success in various NLP tasks. Since finetuning all parameters of large pretrained models poses substantial computational and memory challenges, several efficient finetuning methods have been developed. Among them, low-rank adaptation (LoRA), which finetunes low-rank incremental update matrices on top of frozen pretrained weights, has proven particularly effective. Nonetheless, LoRA’s uniform rank assignment across all layers, along with its reliance on an exhaustive search to find the best rank, leads to high computation costs and suboptimal finetuning performance. To address these limitations, we introduce AutoLoRA, a meta learning based framework for automatically identifying the optimal rank of each LoRA layer. AutoLoRA associates each rank-1 matrix in a low-rank update matrix with a selection variable, which determines whether the rank-1 matrix should be discarded. A meta learning based method is developed to learn these selection variables. The optimal rank is determined by thresholding the values of these variables. Our comprehensive experiments on natural language understanding, generation, and sequence labeling demonstrate the effectiveness of AutoLoRA. The code is publicly available at https://github.com/ruz048/AutoLoRA",
        "file_path": "paper_data/Deep_Meta-Learning/info/78da960c61d41c9c0fc2711fecacc5f5f29660ff.pdf",
        "venue": "North American Chapter of the Association for Computational Linguistics",
        "citationCount": 24,
        "score": 24.0,
        "summary": "Large-scale pretraining followed by task-specific finetuning has achieved great success in various NLP tasks. Since finetuning all parameters of large pretrained models poses substantial computational and memory challenges, several efficient finetuning methods have been developed. Among them, low-rank adaptation (LoRA), which finetunes low-rank incremental update matrices on top of frozen pretrained weights, has proven particularly effective. Nonetheless, LoRA’s uniform rank assignment across all layers, along with its reliance on an exhaustive search to find the best rank, leads to high computation costs and suboptimal finetuning performance. To address these limitations, we introduce AutoLoRA, a meta learning based framework for automatically identifying the optimal rank of each LoRA layer. AutoLoRA associates each rank-1 matrix in a low-rank update matrix with a selection variable, which determines whether the rank-1 matrix should be discarded. A meta learning based method is developed to learn these selection variables. The optimal rank is determined by thresholding the values of these variables. Our comprehensive experiments on natural language understanding, generation, and sequence labeling demonstrate the effectiveness of AutoLoRA. The code is publicly available at https://github.com/ruz048/AutoLoRA",
        "keywords": []
      },
      "file_name": "78da960c61d41c9c0fc2711fecacc5f5f29660ff.pdf"
    },
    {
      "success": true,
      "doc_id": "8ca656007e3f9f4715b4c82288941062",
      "summary": "Resource-constrained edge devices can not efficiently handle the explosive growth of mobile data and the increasing computational demand of modern-day user applications. Task offloading allows the migration of complex tasks from user devices to the remote edge-cloud servers thereby reducing their computational burden and energy consumption while also improving the efficiency of task processing. However, obtaining the optimal offloading strategy in a multi-task offloading decision-making process is an NP-hard problem. Existing Deep learning techniques with slow learning rates and weak adaptability are not suitable for dynamic multi-user scenarios. In this article, we propose a novel deep meta-reinforcement learning-based approach to the multi-task offloading problem using a combination of first-order meta-learning and deep Q-learning methods. We establish the meta-generalization bounds for the proposed algorithm and demonstrate that it can reduce the time and energy consumption of IoT applications by up to 15%. Through rigorous simulations, we show that our method achieves near-optimal offloading solutions while also being able to adapt to dynamic edge-cloud environments.",
      "intriguing_abstract": "Resource-constrained edge devices can not efficiently handle the explosive growth of mobile data and the increasing computational demand of modern-day user applications. Task offloading allows the migration of complex tasks from user devices to the remote edge-cloud servers thereby reducing their computational burden and energy consumption while also improving the efficiency of task processing. However, obtaining the optimal offloading strategy in a multi-task offloading decision-making process is an NP-hard problem. Existing Deep learning techniques with slow learning rates and weak adaptability are not suitable for dynamic multi-user scenarios. In this article, we propose a novel deep meta-reinforcement learning-based approach to the multi-task offloading problem using a combination of first-order meta-learning and deep Q-learning methods. We establish the meta-generalization bounds for the proposed algorithm and demonstrate that it can reduce the time and energy consumption of IoT applications by up to 15%. Through rigorous simulations, we show that our method achieves near-optimal offloading solutions while also being able to adapt to dynamic edge-cloud environments.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c91e61d0d8c2c218bc5ad68e217b7d93b80a655c.pdf",
      "citation_key": "sharma2024zlw",
      "metadata": {
        "title": "Deep Meta Q-Learning Based Multi-Task Offloading in Edge-Cloud Systems",
        "authors": [
          "Nelson Sharma",
          "Aswini Ghosh",
          "R. Misra",
          "Sajal k. Das"
        ],
        "published_date": "2024",
        "abstract": "Resource-constrained edge devices can not efficiently handle the explosive growth of mobile data and the increasing computational demand of modern-day user applications. Task offloading allows the migration of complex tasks from user devices to the remote edge-cloud servers thereby reducing their computational burden and energy consumption while also improving the efficiency of task processing. However, obtaining the optimal offloading strategy in a multi-task offloading decision-making process is an NP-hard problem. Existing Deep learning techniques with slow learning rates and weak adaptability are not suitable for dynamic multi-user scenarios. In this article, we propose a novel deep meta-reinforcement learning-based approach to the multi-task offloading problem using a combination of first-order meta-learning and deep Q-learning methods. We establish the meta-generalization bounds for the proposed algorithm and demonstrate that it can reduce the time and energy consumption of IoT applications by up to 15%. Through rigorous simulations, we show that our method achieves near-optimal offloading solutions while also being able to adapt to dynamic edge-cloud environments.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c91e61d0d8c2c218bc5ad68e217b7d93b80a655c.pdf",
        "venue": "IEEE Transactions on Mobile Computing",
        "citationCount": 23,
        "score": 23.0,
        "summary": "Resource-constrained edge devices can not efficiently handle the explosive growth of mobile data and the increasing computational demand of modern-day user applications. Task offloading allows the migration of complex tasks from user devices to the remote edge-cloud servers thereby reducing their computational burden and energy consumption while also improving the efficiency of task processing. However, obtaining the optimal offloading strategy in a multi-task offloading decision-making process is an NP-hard problem. Existing Deep learning techniques with slow learning rates and weak adaptability are not suitable for dynamic multi-user scenarios. In this article, we propose a novel deep meta-reinforcement learning-based approach to the multi-task offloading problem using a combination of first-order meta-learning and deep Q-learning methods. We establish the meta-generalization bounds for the proposed algorithm and demonstrate that it can reduce the time and energy consumption of IoT applications by up to 15%. Through rigorous simulations, we show that our method achieves near-optimal offloading solutions while also being able to adapt to dynamic edge-cloud environments.",
        "keywords": []
      },
      "file_name": "c91e61d0d8c2c218bc5ad68e217b7d93b80a655c.pdf"
    },
    {
      "success": true,
      "doc_id": "2aa4c49b9aa9c030c46cad34866f7f29",
      "summary": "Due to the complexity of the actual operating conditions of lithium-ion batteries, accurately estimating their state-of-health (SOH) often requires a significant amount of battery data, but most of the current SOH estimation methods lack generalizability. To address this issue, this article proposes a meta-learning SOH estimation method, which combines the meta-learning model with the convolutional neural network with a long short-term memory model to improve the generalization of lithium-ion battery SOH estimation. It not only possesses better generalization ability but also has higher estimation accuracy. In addition, regardless of the four different types of CALCE datasets or lithium-ion battery datasets in the laboratory, the maximum root-mean-square error and mean absolute error of the proposed method is 2.31% and 2.03%, which indicates the good performance of the proposed method for SOH estimation. Compared with two prevalent deep learning methods, this method enhances the estimation accuracy by an average of 25% across different battery data.",
      "intriguing_abstract": "Due to the complexity of the actual operating conditions of lithium-ion batteries, accurately estimating their state-of-health (SOH) often requires a significant amount of battery data, but most of the current SOH estimation methods lack generalizability. To address this issue, this article proposes a meta-learning SOH estimation method, which combines the meta-learning model with the convolutional neural network with a long short-term memory model to improve the generalization of lithium-ion battery SOH estimation. It not only possesses better generalization ability but also has higher estimation accuracy. In addition, regardless of the four different types of CALCE datasets or lithium-ion battery datasets in the laboratory, the maximum root-mean-square error and mean absolute error of the proposed method is 2.31% and 2.03%, which indicates the good performance of the proposed method for SOH estimation. Compared with two prevalent deep learning methods, this method enhances the estimation accuracy by an average of 25% across different battery data.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/ba3281b764913926ef1b7bd0995a58fcc83079fe.pdf",
      "citation_key": "ouyang2024xj0",
      "metadata": {
        "title": "Combined Meta-Learning With CNN-LSTM Algorithms for State-of-Health Estimation of Lithium-Ion Battery",
        "authors": [
          "Tiancheng Ouyang",
          "Yingying Su",
          "Chengchao Wang",
          "Song Jin"
        ],
        "published_date": "2024",
        "abstract": "Due to the complexity of the actual operating conditions of lithium-ion batteries, accurately estimating their state-of-health (SOH) often requires a significant amount of battery data, but most of the current SOH estimation methods lack generalizability. To address this issue, this article proposes a meta-learning SOH estimation method, which combines the meta-learning model with the convolutional neural network with a long short-term memory model to improve the generalization of lithium-ion battery SOH estimation. It not only possesses better generalization ability but also has higher estimation accuracy. In addition, regardless of the four different types of CALCE datasets or lithium-ion battery datasets in the laboratory, the maximum root-mean-square error and mean absolute error of the proposed method is 2.31% and 2.03%, which indicates the good performance of the proposed method for SOH estimation. Compared with two prevalent deep learning methods, this method enhances the estimation accuracy by an average of 25% across different battery data.",
        "file_path": "paper_data/Deep_Meta-Learning/info/ba3281b764913926ef1b7bd0995a58fcc83079fe.pdf",
        "venue": "IEEE transactions on power electronics",
        "citationCount": 22,
        "score": 22.0,
        "summary": "Due to the complexity of the actual operating conditions of lithium-ion batteries, accurately estimating their state-of-health (SOH) often requires a significant amount of battery data, but most of the current SOH estimation methods lack generalizability. To address this issue, this article proposes a meta-learning SOH estimation method, which combines the meta-learning model with the convolutional neural network with a long short-term memory model to improve the generalization of lithium-ion battery SOH estimation. It not only possesses better generalization ability but also has higher estimation accuracy. In addition, regardless of the four different types of CALCE datasets or lithium-ion battery datasets in the laboratory, the maximum root-mean-square error and mean absolute error of the proposed method is 2.31% and 2.03%, which indicates the good performance of the proposed method for SOH estimation. Compared with two prevalent deep learning methods, this method enhances the estimation accuracy by an average of 25% across different battery data.",
        "keywords": []
      },
      "file_name": "ba3281b764913926ef1b7bd0995a58fcc83079fe.pdf"
    },
    {
      "success": true,
      "doc_id": "606a8772693ee3f1f67f39e8619d512f",
      "summary": "To alleviate data distribution under different operating conditions, domain generalization (DG) has been applied in mechanical diagnosis. Still, its effectiveness is limited when unknown fault states appear in the target domain. Consequently, open set DG (OSDG) has emerged to identify unknown classes in unknown domains. However, data collection costs and safety concerns have resulted in a significant class imbalance in OSDG. This imbalance causes the decision boundary to be skewed toward abundant positive classes, ultimately leading to misclassifying unknown states and increasing security risks. Currently, there is a lack of methods to simultaneously address domain shift and class shift in an imbalanced unknown domain. To tackle this issue, this article proposes a multisource domain-class gradient coordination meta-learning (MDGCML) framework, which can learn the generalized boundaries of all tasks by coordinating gradients between interdomains and interclasses. Based on the MDGCML, a joint learning paradigm involving the sharing of parameters between open-set classifiers and closed-set classifiers is constructed to enable quick adaption of the model to unknown domains. The superior performance of the proposed framework has been verified on two datasets.",
      "intriguing_abstract": "To alleviate data distribution under different operating conditions, domain generalization (DG) has been applied in mechanical diagnosis. Still, its effectiveness is limited when unknown fault states appear in the target domain. Consequently, open set DG (OSDG) has emerged to identify unknown classes in unknown domains. However, data collection costs and safety concerns have resulted in a significant class imbalance in OSDG. This imbalance causes the decision boundary to be skewed toward abundant positive classes, ultimately leading to misclassifying unknown states and increasing security risks. Currently, there is a lack of methods to simultaneously address domain shift and class shift in an imbalanced unknown domain. To tackle this issue, this article proposes a multisource domain-class gradient coordination meta-learning (MDGCML) framework, which can learn the generalized boundaries of all tasks by coordinating gradients between interdomains and interclasses. Based on the MDGCML, a joint learning paradigm involving the sharing of parameters between open-set classifiers and closed-set classifiers is constructed to enable quick adaption of the model to unknown domains. The superior performance of the proposed framework has been verified on two datasets.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/a4a7e66408e7fd7e4b7b01db23d76c054ee2ee79.pdf",
      "citation_key": "wang2025zze",
      "metadata": {
        "title": "Learning to Imbalanced Open Set Generalize: A Meta-Learning Framework for Enhanced Mechanical Diagnosis",
        "authors": [
          "Changdong Wang",
          "Zhou Shu",
          "Jingli Yang",
          "Zhenyu Zhao",
          "Huamin Jie",
          "Yongqi Chang",
          "Shiqi Jiang",
          "K. See"
        ],
        "published_date": "2025",
        "abstract": "To alleviate data distribution under different operating conditions, domain generalization (DG) has been applied in mechanical diagnosis. Still, its effectiveness is limited when unknown fault states appear in the target domain. Consequently, open set DG (OSDG) has emerged to identify unknown classes in unknown domains. However, data collection costs and safety concerns have resulted in a significant class imbalance in OSDG. This imbalance causes the decision boundary to be skewed toward abundant positive classes, ultimately leading to misclassifying unknown states and increasing security risks. Currently, there is a lack of methods to simultaneously address domain shift and class shift in an imbalanced unknown domain. To tackle this issue, this article proposes a multisource domain-class gradient coordination meta-learning (MDGCML) framework, which can learn the generalized boundaries of all tasks by coordinating gradients between interdomains and interclasses. Based on the MDGCML, a joint learning paradigm involving the sharing of parameters between open-set classifiers and closed-set classifiers is constructed to enable quick adaption of the model to unknown domains. The superior performance of the proposed framework has been verified on two datasets.",
        "file_path": "paper_data/Deep_Meta-Learning/info/a4a7e66408e7fd7e4b7b01db23d76c054ee2ee79.pdf",
        "venue": "IEEE Transactions on Cybernetics",
        "citationCount": 21,
        "score": 21.0,
        "summary": "To alleviate data distribution under different operating conditions, domain generalization (DG) has been applied in mechanical diagnosis. Still, its effectiveness is limited when unknown fault states appear in the target domain. Consequently, open set DG (OSDG) has emerged to identify unknown classes in unknown domains. However, data collection costs and safety concerns have resulted in a significant class imbalance in OSDG. This imbalance causes the decision boundary to be skewed toward abundant positive classes, ultimately leading to misclassifying unknown states and increasing security risks. Currently, there is a lack of methods to simultaneously address domain shift and class shift in an imbalanced unknown domain. To tackle this issue, this article proposes a multisource domain-class gradient coordination meta-learning (MDGCML) framework, which can learn the generalized boundaries of all tasks by coordinating gradients between interdomains and interclasses. Based on the MDGCML, a joint learning paradigm involving the sharing of parameters between open-set classifiers and closed-set classifiers is constructed to enable quick adaption of the model to unknown domains. The superior performance of the proposed framework has been verified on two datasets.",
        "keywords": []
      },
      "file_name": "a4a7e66408e7fd7e4b7b01db23d76c054ee2ee79.pdf"
    },
    {
      "success": true,
      "doc_id": "d627309e3c76dc698c5149bac7b3a236",
      "summary": "Endo‐microscopy is crucial for real‐time 3D visualization of internal tissues and subcellular structures. Conventional methods rely on axial movement of optical components for precise focus adjustment, limiting miniaturization and complicating procedures. Meta‐device, composed of artificial nanostructures, is an emerging optical flat device that can freely manipulate the phase and amplitude of light. Here, an intelligent fluorescence endo‐microscope is developed based on varifocal meta‐lens and deep learning (DL). The breakthrough enables in vivo 3D imaging of mouse brains, where varifocal meta‐lens focal length adjusts through relative rotation angle. The system offers key advantages such as invariant magnification, a large field‐of‐view, and optical sectioning at a maximum focal length tuning range of ≈2 mm with 3 µm lateral resolution. Using a DL network, image acquisition time and system complexity are significantly reduced, and in vivo high‐resolution brain images of detailed vessels and surrounding perivascular space are clearly observed within 0.1 s (≈50 times faster). The approach will benefit various surgical procedures, such as gastrointestinal biopsies, neural imaging, brain surgery, etc.",
      "intriguing_abstract": "Endo‐microscopy is crucial for real‐time 3D visualization of internal tissues and subcellular structures. Conventional methods rely on axial movement of optical components for precise focus adjustment, limiting miniaturization and complicating procedures. Meta‐device, composed of artificial nanostructures, is an emerging optical flat device that can freely manipulate the phase and amplitude of light. Here, an intelligent fluorescence endo‐microscope is developed based on varifocal meta‐lens and deep learning (DL). The breakthrough enables in vivo 3D imaging of mouse brains, where varifocal meta‐lens focal length adjusts through relative rotation angle. The system offers key advantages such as invariant magnification, a large field‐of‐view, and optical sectioning at a maximum focal length tuning range of ≈2 mm with 3 µm lateral resolution. Using a DL network, image acquisition time and system complexity are significantly reduced, and in vivo high‐resolution brain images of detailed vessels and surrounding perivascular space are clearly observed within 0.1 s (≈50 times faster). The approach will benefit various surgical procedures, such as gastrointestinal biopsies, neural imaging, brain surgery, etc.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/59c6f21af0db0411928abf56cd8607c3dcaa61bf.pdf",
      "citation_key": "chia2024ltk",
      "metadata": {
        "title": "In Vivo Intelligent Fluorescence Endo‐Microscopy by Varifocal Meta‐Device and Deep Learning",
        "authors": [
          "Yu-Hsin Chia",
          "Wei-Hao Liao",
          "S. Vyas",
          "Cheng Hung Chu",
          "Takeshi Yamaguchi",
          "Xiaoyuan Liu",
          "Takuo Tanaka",
          "Yi-You Huang",
          "M. Chen",
          "Wen-Shiang Chen",
          "Din Ping Tsai",
          "Yuan Luo"
        ],
        "published_date": "2024",
        "abstract": "Endo‐microscopy is crucial for real‐time 3D visualization of internal tissues and subcellular structures. Conventional methods rely on axial movement of optical components for precise focus adjustment, limiting miniaturization and complicating procedures. Meta‐device, composed of artificial nanostructures, is an emerging optical flat device that can freely manipulate the phase and amplitude of light. Here, an intelligent fluorescence endo‐microscope is developed based on varifocal meta‐lens and deep learning (DL). The breakthrough enables in vivo 3D imaging of mouse brains, where varifocal meta‐lens focal length adjusts through relative rotation angle. The system offers key advantages such as invariant magnification, a large field‐of‐view, and optical sectioning at a maximum focal length tuning range of ≈2 mm with 3 µm lateral resolution. Using a DL network, image acquisition time and system complexity are significantly reduced, and in vivo high‐resolution brain images of detailed vessels and surrounding perivascular space are clearly observed within 0.1 s (≈50 times faster). The approach will benefit various surgical procedures, such as gastrointestinal biopsies, neural imaging, brain surgery, etc.",
        "file_path": "paper_data/Deep_Meta-Learning/info/59c6f21af0db0411928abf56cd8607c3dcaa61bf.pdf",
        "venue": "Advancement of science",
        "citationCount": 20,
        "score": 20.0,
        "summary": "Endo‐microscopy is crucial for real‐time 3D visualization of internal tissues and subcellular structures. Conventional methods rely on axial movement of optical components for precise focus adjustment, limiting miniaturization and complicating procedures. Meta‐device, composed of artificial nanostructures, is an emerging optical flat device that can freely manipulate the phase and amplitude of light. Here, an intelligent fluorescence endo‐microscope is developed based on varifocal meta‐lens and deep learning (DL). The breakthrough enables in vivo 3D imaging of mouse brains, where varifocal meta‐lens focal length adjusts through relative rotation angle. The system offers key advantages such as invariant magnification, a large field‐of‐view, and optical sectioning at a maximum focal length tuning range of ≈2 mm with 3 µm lateral resolution. Using a DL network, image acquisition time and system complexity are significantly reduced, and in vivo high‐resolution brain images of detailed vessels and surrounding perivascular space are clearly observed within 0.1 s (≈50 times faster). The approach will benefit various surgical procedures, such as gastrointestinal biopsies, neural imaging, brain surgery, etc.",
        "keywords": []
      },
      "file_name": "59c6f21af0db0411928abf56cd8607c3dcaa61bf.pdf"
    },
    {
      "success": true,
      "doc_id": "f5238b89e7f41f7700dd4fd701763eff",
      "summary": "Video streaming is one of the most popular Internet applications that makes up a large amount of Internet traffic. A fundamental mechanism in video streaming is adaptive bitrate (ABR) selection which decides the proper compression level for each chunk of a video to optimize the users’ quality of experience (QoE). The existing ABR algorithms require significant tuning and do not generalize to diverse network conditions and personalized QoE objectives. In this article, we propose a novel framework for meta-learning based ABR design and discuss challenges of deploying learning based ABR mechanism in real-world video streaming systems. We utilize the proposed framework to design MetaABR, a novel adaptive bitrate selection algorithm based on meta-reinforcement learning to maximize users’ QoE. By jointly training multiple learning tasks with a shared meta-critic, it can provide transferrable meta-knowledge to supervise bitrate selection across tasks, and can be applied to efficiently learn a new task in unseen environment with only a few trials. We implement MetaABR on an emulation platform which connects to the Linux network protocol stack through virtual network interfaces. Extensive experiments based on real-world traces and wireless testbed show that MetaABR achieves the best comprehensive QoE compared with the state-of-the-art ABR algorithms in a variety of network environments.",
      "intriguing_abstract": "Video streaming is one of the most popular Internet applications that makes up a large amount of Internet traffic. A fundamental mechanism in video streaming is adaptive bitrate (ABR) selection which decides the proper compression level for each chunk of a video to optimize the users’ quality of experience (QoE). The existing ABR algorithms require significant tuning and do not generalize to diverse network conditions and personalized QoE objectives. In this article, we propose a novel framework for meta-learning based ABR design and discuss challenges of deploying learning based ABR mechanism in real-world video streaming systems. We utilize the proposed framework to design MetaABR, a novel adaptive bitrate selection algorithm based on meta-reinforcement learning to maximize users’ QoE. By jointly training multiple learning tasks with a shared meta-critic, it can provide transferrable meta-knowledge to supervise bitrate selection across tasks, and can be applied to efficiently learn a new task in unseen environment with only a few trials. We implement MetaABR on an emulation platform which connects to the Linux network protocol stack through virtual network interfaces. Extensive experiments based on real-world traces and wireless testbed show that MetaABR achieves the best comprehensive QoE compared with the state-of-the-art ABR algorithms in a variety of network environments.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/fe10bf13aeb8728a955f1f8fd312ce77773b59ec.pdf",
      "citation_key": "li20246fg",
      "metadata": {
        "title": "MetaABR: A Meta-Learning Approach on Adaptative Bitrate Selection for Video Streaming",
        "authors": [
          "Wenzhong Li",
          "Xiang Li",
          "Yeting Xu",
          "Yezhou Yang",
          "Sanglu Lu"
        ],
        "published_date": "2024",
        "abstract": "Video streaming is one of the most popular Internet applications that makes up a large amount of Internet traffic. A fundamental mechanism in video streaming is adaptive bitrate (ABR) selection which decides the proper compression level for each chunk of a video to optimize the users’ quality of experience (QoE). The existing ABR algorithms require significant tuning and do not generalize to diverse network conditions and personalized QoE objectives. In this article, we propose a novel framework for meta-learning based ABR design and discuss challenges of deploying learning based ABR mechanism in real-world video streaming systems. We utilize the proposed framework to design MetaABR, a novel adaptive bitrate selection algorithm based on meta-reinforcement learning to maximize users’ QoE. By jointly training multiple learning tasks with a shared meta-critic, it can provide transferrable meta-knowledge to supervise bitrate selection across tasks, and can be applied to efficiently learn a new task in unseen environment with only a few trials. We implement MetaABR on an emulation platform which connects to the Linux network protocol stack through virtual network interfaces. Extensive experiments based on real-world traces and wireless testbed show that MetaABR achieves the best comprehensive QoE compared with the state-of-the-art ABR algorithms in a variety of network environments.",
        "file_path": "paper_data/Deep_Meta-Learning/info/fe10bf13aeb8728a955f1f8fd312ce77773b59ec.pdf",
        "venue": "IEEE Transactions on Mobile Computing",
        "citationCount": 20,
        "score": 20.0,
        "summary": "Video streaming is one of the most popular Internet applications that makes up a large amount of Internet traffic. A fundamental mechanism in video streaming is adaptive bitrate (ABR) selection which decides the proper compression level for each chunk of a video to optimize the users’ quality of experience (QoE). The existing ABR algorithms require significant tuning and do not generalize to diverse network conditions and personalized QoE objectives. In this article, we propose a novel framework for meta-learning based ABR design and discuss challenges of deploying learning based ABR mechanism in real-world video streaming systems. We utilize the proposed framework to design MetaABR, a novel adaptive bitrate selection algorithm based on meta-reinforcement learning to maximize users’ QoE. By jointly training multiple learning tasks with a shared meta-critic, it can provide transferrable meta-knowledge to supervise bitrate selection across tasks, and can be applied to efficiently learn a new task in unseen environment with only a few trials. We implement MetaABR on an emulation platform which connects to the Linux network protocol stack through virtual network interfaces. Extensive experiments based on real-world traces and wireless testbed show that MetaABR achieves the best comprehensive QoE compared with the state-of-the-art ABR algorithms in a variety of network environments.",
        "keywords": []
      },
      "file_name": "fe10bf13aeb8728a955f1f8fd312ce77773b59ec.pdf"
    },
    {
      "success": true,
      "doc_id": "12f7f2145c708deb8d6ee3dfbf128c57",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/ac002147f56f0053d5c82968648dace155b6c1dc.pdf",
      "citation_key": "yang2024rh9",
      "metadata": {
        "title": "Meta-learning with deep flow kernel network for few shot cross-domain remaining useful life prediction",
        "authors": [
          "Jing Yang",
          "Xiaomin Wang"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/ac002147f56f0053d5c82968648dace155b6c1dc.pdf",
        "venue": "Reliability Engineering & System Safety",
        "citationCount": 19,
        "score": 19.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "ac002147f56f0053d5c82968648dace155b6c1dc.pdf"
    },
    {
      "success": true,
      "doc_id": "5d1f5585b8e90e367451d71109777999",
      "summary": "Optical metasurfaces with pronounced spectral characteristics are promising for sensor applications. Currently, deep learning (DL) offers a rapid manner to design various metasurfaces. However, conventional DL models are usually assumed as black boxes, which is difficult to explain how a DL model learns physical features, and they usually predict optical responses of metasurfaces in a fuzzy way. This makes them incapable of capturing critical spectral features precisely, such as high quality (Q) resonances, and hinders their use in designing metasurface sensors. Here, a transformer‐based explainable DL model named Metaformer for the high‐intelligence design, which adopts a spectrum‐splitting scheme to elevate 99% prediction accuracy through reducing 99% training parameters, is established. Based on the Metaformer, all‐dielectric metasurfaces based on quasi‐bound states in the continuum (Q‐BIC) for high‐performance metasensing are designed, and fabrication experiments are guided potently. The explainable learning relies on spectral position encoding and multi‐head attention of meta‐optics features, which overwhelms traditional black‐box models dramatically. The meta‐attention mechanism provides deep physics insights on metasurface sensors, and will inspire more powerful DL design applications on other optical devices.",
      "intriguing_abstract": "Optical metasurfaces with pronounced spectral characteristics are promising for sensor applications. Currently, deep learning (DL) offers a rapid manner to design various metasurfaces. However, conventional DL models are usually assumed as black boxes, which is difficult to explain how a DL model learns physical features, and they usually predict optical responses of metasurfaces in a fuzzy way. This makes them incapable of capturing critical spectral features precisely, such as high quality (Q) resonances, and hinders their use in designing metasurface sensors. Here, a transformer‐based explainable DL model named Metaformer for the high‐intelligence design, which adopts a spectrum‐splitting scheme to elevate 99% prediction accuracy through reducing 99% training parameters, is established. Based on the Metaformer, all‐dielectric metasurfaces based on quasi‐bound states in the continuum (Q‐BIC) for high‐performance metasensing are designed, and fabrication experiments are guided potently. The explainable learning relies on spectral position encoding and multi‐head attention of meta‐optics features, which overwhelms traditional black‐box models dramatically. The meta‐attention mechanism provides deep physics insights on metasurface sensors, and will inspire more powerful DL design applications on other optical devices.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/58b1daf9437248f253a6f6a2c5bf260272e7646a.pdf",
      "citation_key": "gao20242uv",
      "metadata": {
        "title": "Meta‐Attention Deep Learning for Smart Development of Metasurface Sensors",
        "authors": [
          "Yuan Gao",
          "Wei Chen",
          "Fajun Li",
          "Mingyong Zhuang",
          "Yiming Yan",
          "Jun Wang",
          "Xiang Wang",
          "Zhaogang Dong",
          "Wei Ma",
          "Jinfeng Zhu"
        ],
        "published_date": "2024",
        "abstract": "Optical metasurfaces with pronounced spectral characteristics are promising for sensor applications. Currently, deep learning (DL) offers a rapid manner to design various metasurfaces. However, conventional DL models are usually assumed as black boxes, which is difficult to explain how a DL model learns physical features, and they usually predict optical responses of metasurfaces in a fuzzy way. This makes them incapable of capturing critical spectral features precisely, such as high quality (Q) resonances, and hinders their use in designing metasurface sensors. Here, a transformer‐based explainable DL model named Metaformer for the high‐intelligence design, which adopts a spectrum‐splitting scheme to elevate 99% prediction accuracy through reducing 99% training parameters, is established. Based on the Metaformer, all‐dielectric metasurfaces based on quasi‐bound states in the continuum (Q‐BIC) for high‐performance metasensing are designed, and fabrication experiments are guided potently. The explainable learning relies on spectral position encoding and multi‐head attention of meta‐optics features, which overwhelms traditional black‐box models dramatically. The meta‐attention mechanism provides deep physics insights on metasurface sensors, and will inspire more powerful DL design applications on other optical devices.",
        "file_path": "paper_data/Deep_Meta-Learning/info/58b1daf9437248f253a6f6a2c5bf260272e7646a.pdf",
        "venue": "Advancement of science",
        "citationCount": 17,
        "score": 17.0,
        "summary": "Optical metasurfaces with pronounced spectral characteristics are promising for sensor applications. Currently, deep learning (DL) offers a rapid manner to design various metasurfaces. However, conventional DL models are usually assumed as black boxes, which is difficult to explain how a DL model learns physical features, and they usually predict optical responses of metasurfaces in a fuzzy way. This makes them incapable of capturing critical spectral features precisely, such as high quality (Q) resonances, and hinders their use in designing metasurface sensors. Here, a transformer‐based explainable DL model named Metaformer for the high‐intelligence design, which adopts a spectrum‐splitting scheme to elevate 99% prediction accuracy through reducing 99% training parameters, is established. Based on the Metaformer, all‐dielectric metasurfaces based on quasi‐bound states in the continuum (Q‐BIC) for high‐performance metasensing are designed, and fabrication experiments are guided potently. The explainable learning relies on spectral position encoding and multi‐head attention of meta‐optics features, which overwhelms traditional black‐box models dramatically. The meta‐attention mechanism provides deep physics insights on metasurface sensors, and will inspire more powerful DL design applications on other optical devices.",
        "keywords": []
      },
      "file_name": "58b1daf9437248f253a6f6a2c5bf260272e7646a.pdf"
    },
    {
      "success": true,
      "doc_id": "63f1d0efd7bd03755b204ae094c12288",
      "summary": "Multi-omics data integration is a promising field combining various types of omics data, such as genomics, transcriptomics, and proteomics, to comprehensively understand the molecular mechanisms underlying life and disease. However, the inherent noise, heterogeneity, and high dimensionality of multi-omics data present challenges for existing methods to extract meaningful biological information without overfitting. This paper introduces a novel Multi-Omics Meta-learning Algorithm (MUMA) that employs self-adaptive sample weighting and interaction-based regularization for enhanced diagnostic performance and interpretability in multi-omics data analysis. Specifically, MUMA captures crucial biological processes across different omics layers by learning a flexible sample reweighting function adaptable to various noise scenarios. Additionally, MUMA incorporates an interaction-based regularization term, encouraging the model to learn from the relationships among different omics modalities. We evaluate MUMA using simulations and eighteen real datasets, demonstrating its superior performance compared to state-of-the-art methods in classifying biological samples (e.g., cancer subtypes) and selecting relevant biomarkers from noisy multi-omics data. As a powerful tool for multi-omics data integration, MUMA can assist researchers in achieving a deeper understanding of the biological systems involved.",
      "intriguing_abstract": "Multi-omics data integration is a promising field combining various types of omics data, such as genomics, transcriptomics, and proteomics, to comprehensively understand the molecular mechanisms underlying life and disease. However, the inherent noise, heterogeneity, and high dimensionality of multi-omics data present challenges for existing methods to extract meaningful biological information without overfitting. This paper introduces a novel Multi-Omics Meta-learning Algorithm (MUMA) that employs self-adaptive sample weighting and interaction-based regularization for enhanced diagnostic performance and interpretability in multi-omics data analysis. Specifically, MUMA captures crucial biological processes across different omics layers by learning a flexible sample reweighting function adaptable to various noise scenarios. Additionally, MUMA incorporates an interaction-based regularization term, encouraging the model to learn from the relationships among different omics modalities. We evaluate MUMA using simulations and eighteen real datasets, demonstrating its superior performance compared to state-of-the-art methods in classifying biological samples (e.g., cancer subtypes) and selecting relevant biomarkers from noisy multi-omics data. As a powerful tool for multi-omics data integration, MUMA can assist researchers in achieving a deeper understanding of the biological systems involved.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/2dd01e77768b82dcb9c0a760e75efe528dacf6c9.pdf",
      "citation_key": "huang2024hlo",
      "metadata": {
        "title": "MUMA: A Multi-Omics Meta-Learning Algorithm for Data Interpretation and Classification",
        "authors": [
          "Hai-Hui Huang",
          "Jun Shu",
          "Yong Liang"
        ],
        "published_date": "2024",
        "abstract": "Multi-omics data integration is a promising field combining various types of omics data, such as genomics, transcriptomics, and proteomics, to comprehensively understand the molecular mechanisms underlying life and disease. However, the inherent noise, heterogeneity, and high dimensionality of multi-omics data present challenges for existing methods to extract meaningful biological information without overfitting. This paper introduces a novel Multi-Omics Meta-learning Algorithm (MUMA) that employs self-adaptive sample weighting and interaction-based regularization for enhanced diagnostic performance and interpretability in multi-omics data analysis. Specifically, MUMA captures crucial biological processes across different omics layers by learning a flexible sample reweighting function adaptable to various noise scenarios. Additionally, MUMA incorporates an interaction-based regularization term, encouraging the model to learn from the relationships among different omics modalities. We evaluate MUMA using simulations and eighteen real datasets, demonstrating its superior performance compared to state-of-the-art methods in classifying biological samples (e.g., cancer subtypes) and selecting relevant biomarkers from noisy multi-omics data. As a powerful tool for multi-omics data integration, MUMA can assist researchers in achieving a deeper understanding of the biological systems involved.",
        "file_path": "paper_data/Deep_Meta-Learning/info/2dd01e77768b82dcb9c0a760e75efe528dacf6c9.pdf",
        "venue": "IEEE journal of biomedical and health informatics",
        "citationCount": 17,
        "score": 17.0,
        "summary": "Multi-omics data integration is a promising field combining various types of omics data, such as genomics, transcriptomics, and proteomics, to comprehensively understand the molecular mechanisms underlying life and disease. However, the inherent noise, heterogeneity, and high dimensionality of multi-omics data present challenges for existing methods to extract meaningful biological information without overfitting. This paper introduces a novel Multi-Omics Meta-learning Algorithm (MUMA) that employs self-adaptive sample weighting and interaction-based regularization for enhanced diagnostic performance and interpretability in multi-omics data analysis. Specifically, MUMA captures crucial biological processes across different omics layers by learning a flexible sample reweighting function adaptable to various noise scenarios. Additionally, MUMA incorporates an interaction-based regularization term, encouraging the model to learn from the relationships among different omics modalities. We evaluate MUMA using simulations and eighteen real datasets, demonstrating its superior performance compared to state-of-the-art methods in classifying biological samples (e.g., cancer subtypes) and selecting relevant biomarkers from noisy multi-omics data. As a powerful tool for multi-omics data integration, MUMA can assist researchers in achieving a deeper understanding of the biological systems involved.",
        "keywords": []
      },
      "file_name": "2dd01e77768b82dcb9c0a760e75efe528dacf6c9.pdf"
    },
    {
      "success": true,
      "doc_id": "967500625f4ca4cfdf9169d26d1d11e3",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/af531719c3ed74a3a858cdb12c6f488fcfafb8c6.pdf",
      "citation_key": "liu2024hko",
      "metadata": {
        "title": "Meta Inverse Constrained Reinforcement Learning: Convergence Guarantee and Generalization Analysis",
        "authors": [
          "Shicheng Liu",
          "Minghui Zhu"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/af531719c3ed74a3a858cdb12c6f488fcfafb8c6.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 17,
        "score": 17.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "af531719c3ed74a3a858cdb12c6f488fcfafb8c6.pdf"
    },
    {
      "success": true,
      "doc_id": "9a552b5c46b59998527bb2007b376348",
      "summary": "This article proposes a data-driven active fault tolerance load frequency control (DDAFT-LFC) method for island microgrids. It is demonstrated that DDAFT-LFC can effectively prevent frequency control loss caused by sudden off-grid faults affecting regulating units and emergency faults in microgrids, as well as reduce the total generation cost and improve the frequency stability of an island microgrid relying on a high renewable energy input. The method adopts an active fault tolerance strategy which can adapt to the complex stochastic environment, thus improving the robustness of the LFC strategy and achieving multiobjective optimization of dynamic performance and economic efficiency via regulation of the controller’s control strategy. In order to realize active fault-tolerance, this article proposes a deep meta-deterministic policy gradient (DMDPG) algorithm, which employs a meta-reinforcement learning method to help the agent to perform multitask collaborative learning in order to adapt to changes in microgrid environment parameters caused by changes in the unit combinations. The method is validated in an experiment of the island microgrid of the China Southern Power Grid (CSG).",
      "intriguing_abstract": "This article proposes a data-driven active fault tolerance load frequency control (DDAFT-LFC) method for island microgrids. It is demonstrated that DDAFT-LFC can effectively prevent frequency control loss caused by sudden off-grid faults affecting regulating units and emergency faults in microgrids, as well as reduce the total generation cost and improve the frequency stability of an island microgrid relying on a high renewable energy input. The method adopts an active fault tolerance strategy which can adapt to the complex stochastic environment, thus improving the robustness of the LFC strategy and achieving multiobjective optimization of dynamic performance and economic efficiency via regulation of the controller’s control strategy. In order to realize active fault-tolerance, this article proposes a deep meta-deterministic policy gradient (DMDPG) algorithm, which employs a meta-reinforcement learning method to help the agent to perform multitask collaborative learning in order to adapt to changes in microgrid environment parameters caused by changes in the unit combinations. The method is validated in an experiment of the island microgrid of the China Southern Power Grid (CSG).",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/1ba77e063014a8616a621bed8dd43e18f83712de.pdf",
      "citation_key": "li2024x2t",
      "metadata": {
        "title": "Deep Meta-Reinforcement Learning-Based Data-Driven Active Fault Tolerance Load Frequency Control for Islanded Microgrids Considering Internet of Things",
        "authors": [
          "Jiawen Li",
          "Yuanyuan Cheng"
        ],
        "published_date": "2024",
        "abstract": "This article proposes a data-driven active fault tolerance load frequency control (DDAFT-LFC) method for island microgrids. It is demonstrated that DDAFT-LFC can effectively prevent frequency control loss caused by sudden off-grid faults affecting regulating units and emergency faults in microgrids, as well as reduce the total generation cost and improve the frequency stability of an island microgrid relying on a high renewable energy input. The method adopts an active fault tolerance strategy which can adapt to the complex stochastic environment, thus improving the robustness of the LFC strategy and achieving multiobjective optimization of dynamic performance and economic efficiency via regulation of the controller’s control strategy. In order to realize active fault-tolerance, this article proposes a deep meta-deterministic policy gradient (DMDPG) algorithm, which employs a meta-reinforcement learning method to help the agent to perform multitask collaborative learning in order to adapt to changes in microgrid environment parameters caused by changes in the unit combinations. The method is validated in an experiment of the island microgrid of the China Southern Power Grid (CSG).",
        "file_path": "paper_data/Deep_Meta-Learning/info/1ba77e063014a8616a621bed8dd43e18f83712de.pdf",
        "venue": "IEEE Internet of Things Journal",
        "citationCount": 16,
        "score": 16.0,
        "summary": "This article proposes a data-driven active fault tolerance load frequency control (DDAFT-LFC) method for island microgrids. It is demonstrated that DDAFT-LFC can effectively prevent frequency control loss caused by sudden off-grid faults affecting regulating units and emergency faults in microgrids, as well as reduce the total generation cost and improve the frequency stability of an island microgrid relying on a high renewable energy input. The method adopts an active fault tolerance strategy which can adapt to the complex stochastic environment, thus improving the robustness of the LFC strategy and achieving multiobjective optimization of dynamic performance and economic efficiency via regulation of the controller’s control strategy. In order to realize active fault-tolerance, this article proposes a deep meta-deterministic policy gradient (DMDPG) algorithm, which employs a meta-reinforcement learning method to help the agent to perform multitask collaborative learning in order to adapt to changes in microgrid environment parameters caused by changes in the unit combinations. The method is validated in an experiment of the island microgrid of the China Southern Power Grid (CSG).",
        "keywords": []
      },
      "file_name": "1ba77e063014a8616a621bed8dd43e18f83712de.pdf"
    },
    {
      "success": true,
      "doc_id": "6ef3676f3576adac012035b4e76ca660",
      "summary": "Here's a focused summary of the paper \\cite{khattar2024sr6} for a literature review:\n\n### Technical Paper Analysis: A CMDP-WITHIN-ONLINE FRAMEWORK FOR META-SAFE REINFORCEMENT LEARNING \\cite{khattar2024sr6}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the problem of meta-safe reinforcement learning (Meta-SRL), where an agent needs to quickly adapt to unseen tasks while strictly adhering to safety constraints.\n    *   **Importance & Challenge**: This problem is crucial for real-world applications of RL, where safety constraints are paramount and dynamic environments require rapid adaptation. Existing meta-RL methods do not adequately address constraint violations, while traditional safe RL algorithms (CMDPs) are not designed for efficient generalization across tasks. Challenges include:\n        *   Handling multiple, coupled, and often non-convex losses (reward and constraints).\n        *   The impracticality of assuming globally optimal policies or exact loss function estimators for CMDPs.\n        *   The complex interplay between non-convexity, stochasticity, and generalization considerations.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work bridges the gap between meta-reinforcement learning (meta-RL) and safe reinforcement learning (Safe RL).\n        *   **Meta-RL**: Existing meta-RL frameworks (e.g., Finn et al., 2017) enable learning-to-learn for unseen tasks with limited experience but largely neglect safety constraints.\n        *   **Safe RL (CMDPs)**: CMDP algorithms (e.g., Altman, 1999) focus on maximizing rewards while satisfying constraints but are not designed to generalize efficiently over unseen tasks (Paternain et al., 2022; Ding et al., 2021a).\n    *   **Limitations of Previous Solutions**:\n        *   Meta-RL approaches lack mechanisms for provable constraint satisfaction.\n        *   CMDP algorithms require extensive experience for each new task, hindering rapid adaptation.\n        *   Existing online learning theories often assume convex losses or exact/unbiased estimators, which are not applicable to the complex, non-convex, and stochastic nature of CMDPs.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel \"CMDP-within-online\" framework.\n        *   **Within-task**: Each individual task is a Constrained Markov Decision Process (CMDP), solved by a safe RL algorithm (exemplified by CRPO \\cite{xu2021crpo}).\n        *   **Meta-learner (Online Framework)**: A meta-learner encapsulates the within-task algorithm, sequentially updating the meta-initialization policy ($\\pi_{t,0}$) and the learning rate ($\\alpha_t$) for each task.\n        *   **Inexact Learning**: The meta-learner operates on *inexact* upper bounds of the within-task optimality gap and constraint violations, rather than exact values. These upper bounds are estimated using off-policy stationary distribution corrections.\n        *   **Estimation of Upper Bounds**: DualDICE \\cite{nachum2019dualdice} is employed to estimate the discounted state visitation distribution ($\\hat{\\nu}_t$) from collected trajectory data, which is then used to estimate the KL divergence terms in the upper bounds.\n        *   **Online Gradient Descent (OGD)**: OGD is applied to these estimated upper bounds to update $\\pi_{t,0}$ and $\\alpha_t$.\n    *   **Novelty/Difference**:\n        *   **First Provable Guarantees**: Establishes the first provable guarantees for meta-safe RL in terms of task-averaged regret for both reward maximization (TAOG) and constraint violations (TACV).\n        *   **Inexactness Handling**: Explicitly addresses the challenge of inexact optimal policies and state visitation distributions, making the framework practical.\n        *   **Adaptive Learning Rates**: Enables learning rates to be adapted for every task, improving performance in dynamic environments.\n        *   **Task-Similarity/Relatedness**: Shows that performance improves with task-similarity (static environment) or task-relatedness (dynamic environment).\n\n4.  **Key Technical Contributions**\n    *   **Novel Framework**: Introduction of the \"CMDP-within-online\" framework for Meta-SRL, providing a principled way to combine meta-learning with safe RL.\n    *   **Provable Guarantees**: Derivation of task-averaged regret bounds for optimality gap (TAOG) and constraint violations (TACV), showing improvement with task-similarity and number of tasks.\n        *   Static environment: Regret of $O\\left(\\frac{1}{\\sqrt{M}}\\sqrt{\\frac{\\log T}{T} + \\hat{D}^{*2}}\\right)$ \\cite{khattar2024sr6}[Theorem 3.2].\n        *   Dynamic environment: Improved rate of $O\\left(\\frac{1}{M^{3/4}\\sqrt{T}}\\left(E_T + \\sqrt{E_T T + \\hat{V}_{\\psi}^2}\\right)\\right)$ \\cite{khattar2024sr6}[Corollary 1].\n    *   **Inexact Estimation Methodology**: A practical approach to estimate upper bounds on within-task performance using off-policy stationary distribution corrections (DualDICE) and bounding the estimation error \\cite{khattar2024sr6}[Theorem 3.1].\n    *   **Theoretical Insights into CMDP Optimization Landscape**: Studies the optimization landscape of CMDPs using tame geometry and subgradient flow systems, providing an algorithmic-agnostic growth condition (Kurdyka-Lojasiewicz inequality) around optima, which is crucial for bounding policy distances and estimation errors \\cite{khattar2024sr6}[Theorem 3.1, Appendix F]. This differs from prior work restricted to policy gradient settings.\n    *   **Generalized Regret Bounds**: Provides static and dynamic regret bounds for inexact online gradient descent, which are leveraged for the main theoretical results.\n\n5.  **Experimental Validation**\n    *   The paper states that \"experiments are conducted to demonstrate the effectiveness of our approach.\" However, the provided text does not detail the specific experiments, performance metrics, or comparative results.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   **Assumption 1 (Shrinkage Simplex Set)**: Requires meta-initialization policies to have full support over the state-action space, ensuring KL divergence terms are finite and providing necessary Lipschitz, smoothness, and strong convexity properties.\n        *   **Assumption 2 (O-minimal Structure)**: Assumes objective and constraint functions, and parametric policies are definable in some o-minimal structure, which is a mild condition for many real-world functions but a theoretical requirement for the growth condition analysis.\n        *   The within-task algorithm is exemplified by CRPO, a primal-based approach.\n    *   **Scope of Applicability**: Primarily focuses on CMDPs with softmax parametrization and primal-based safe RL algorithms. The theoretical guarantees are for task-averaged regret.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work represents a significant step forward by providing the first provable guarantees for meta-safe reinforcement learning, addressing a critical gap in existing literature. It moves beyond stylized settings to offer a practical framework for real-world applications.\n    *   **Potential Impact**:\n        *   Enables the deployment of RL agents in safety-critical applications (e.g., robotics, autonomous systems) where both rapid adaptation and strict constraint adherence are necessary.\n        *   The methodology for handling inexactness and leveraging task-similarity/relatedness can inspire future research in robust and efficient meta-learning for constrained problems.\n        *   The theoretical contributions regarding the CMDP optimization landscape (tame geometry) are of independent interest and could benefit broader safe RL research.",
      "intriguing_abstract": "Deploying reinforcement learning in safety-critical domains demands agents that can rapidly adapt to new tasks while strictly adhering to constraints. Current meta-RL excels at adaptation but largely neglects safety, while traditional Safe RL (CMDPs) struggles with efficient generalization across tasks. We introduce a novel **CMDP-within-online framework** for **Meta-Safe Reinforcement Learning (Meta-SRL)**, bridging this critical gap. Our approach uniquely integrates a CMDP solver within an online meta-learner, which adaptively updates meta-initialization policies and learning rates. Crucially, we provide the **first provable guarantees** for Meta-SRL, establishing tight **task-averaged regret bounds** for both reward maximization and constraint violations, even under **inexact optimization**. This is achieved by leveraging **off-policy stationary distribution corrections** via **DualDICE** and pioneering an analysis of the CMDP optimization landscape using **tame geometry** and the **Kurdyka-Lojasiewicz inequality**. This framework offers a practical and theoretically robust solution for developing intelligent agents that are both agile and reliably safe, paving the way for trustworthy AI in complex, dynamic environments.",
      "keywords": [
        "Meta-safe reinforcement learning (Meta-SRL)",
        "CMDP-within-online framework",
        "safety constraints",
        "Constrained Markov Decision Processes (CMDPs)",
        "provable guarantees",
        "task-averaged regret bounds",
        "inexact learning",
        "off-policy stationary distribution corrections",
        "CMDP optimization landscape",
        "rapid adaptation",
        "real-world safety-critical applications",
        "adaptive learning rates",
        "task-similarity"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/a1c68c32b11d83c9d48c48163f2a445ce359069e.pdf",
      "citation_key": "khattar2024sr6",
      "metadata": {
        "title": "A CMDP-within-online framework for Meta-Safe Reinforcement Learning",
        "authors": [
          "Vanshaj Khattar",
          "Yuhao Ding",
          "Bilgehan Sel",
          "J. Lavaei",
          "Ming Jin"
        ],
        "published_date": "2024",
        "abstract": "Meta-reinforcement learning has widely been used as a learning-to-learn framework to solve unseen tasks with limited experience. However, the aspect of constraint violations has not been adequately addressed in the existing works, making their application restricted in real-world settings. In this paper, we study the problem of meta-safe reinforcement learning (Meta-SRL) through the CMDP-within-online framework to establish the first provable guarantees in this important setting. We obtain task-averaged regret bounds for the reward maximization (optimality gap) and constraint violations using gradient-based meta-learning and show that the task-averaged optimality gap and constraint satisfaction improve with task-similarity in a static environment or task-relatedness in a dynamic environment. Several technical challenges arise when making this framework practical. To this end, we propose a meta-algorithm that performs inexact online learning on the upper bounds of within-task optimality gap and constraint violations estimated by off-policy stationary distribution corrections. Furthermore, we enable the learning rates to be adapted for every task and extend our approach to settings with a competing dynamically changing oracle. Finally, experiments are conducted to demonstrate the effectiveness of our approach.",
        "file_path": "paper_data/Deep_Meta-Learning/info/a1c68c32b11d83c9d48c48163f2a445ce359069e.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 15,
        "score": 15.0,
        "summary": "Here's a focused summary of the paper \\cite{khattar2024sr6} for a literature review:\n\n### Technical Paper Analysis: A CMDP-WITHIN-ONLINE FRAMEWORK FOR META-SAFE REINFORCEMENT LEARNING \\cite{khattar2024sr6}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the problem of meta-safe reinforcement learning (Meta-SRL), where an agent needs to quickly adapt to unseen tasks while strictly adhering to safety constraints.\n    *   **Importance & Challenge**: This problem is crucial for real-world applications of RL, where safety constraints are paramount and dynamic environments require rapid adaptation. Existing meta-RL methods do not adequately address constraint violations, while traditional safe RL algorithms (CMDPs) are not designed for efficient generalization across tasks. Challenges include:\n        *   Handling multiple, coupled, and often non-convex losses (reward and constraints).\n        *   The impracticality of assuming globally optimal policies or exact loss function estimators for CMDPs.\n        *   The complex interplay between non-convexity, stochasticity, and generalization considerations.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work bridges the gap between meta-reinforcement learning (meta-RL) and safe reinforcement learning (Safe RL).\n        *   **Meta-RL**: Existing meta-RL frameworks (e.g., Finn et al., 2017) enable learning-to-learn for unseen tasks with limited experience but largely neglect safety constraints.\n        *   **Safe RL (CMDPs)**: CMDP algorithms (e.g., Altman, 1999) focus on maximizing rewards while satisfying constraints but are not designed to generalize efficiently over unseen tasks (Paternain et al., 2022; Ding et al., 2021a).\n    *   **Limitations of Previous Solutions**:\n        *   Meta-RL approaches lack mechanisms for provable constraint satisfaction.\n        *   CMDP algorithms require extensive experience for each new task, hindering rapid adaptation.\n        *   Existing online learning theories often assume convex losses or exact/unbiased estimators, which are not applicable to the complex, non-convex, and stochastic nature of CMDPs.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a novel \"CMDP-within-online\" framework.\n        *   **Within-task**: Each individual task is a Constrained Markov Decision Process (CMDP), solved by a safe RL algorithm (exemplified by CRPO \\cite{xu2021crpo}).\n        *   **Meta-learner (Online Framework)**: A meta-learner encapsulates the within-task algorithm, sequentially updating the meta-initialization policy ($\\pi_{t,0}$) and the learning rate ($\\alpha_t$) for each task.\n        *   **Inexact Learning**: The meta-learner operates on *inexact* upper bounds of the within-task optimality gap and constraint violations, rather than exact values. These upper bounds are estimated using off-policy stationary distribution corrections.\n        *   **Estimation of Upper Bounds**: DualDICE \\cite{nachum2019dualdice} is employed to estimate the discounted state visitation distribution ($\\hat{\\nu}_t$) from collected trajectory data, which is then used to estimate the KL divergence terms in the upper bounds.\n        *   **Online Gradient Descent (OGD)**: OGD is applied to these estimated upper bounds to update $\\pi_{t,0}$ and $\\alpha_t$.\n    *   **Novelty/Difference**:\n        *   **First Provable Guarantees**: Establishes the first provable guarantees for meta-safe RL in terms of task-averaged regret for both reward maximization (TAOG) and constraint violations (TACV).\n        *   **Inexactness Handling**: Explicitly addresses the challenge of inexact optimal policies and state visitation distributions, making the framework practical.\n        *   **Adaptive Learning Rates**: Enables learning rates to be adapted for every task, improving performance in dynamic environments.\n        *   **Task-Similarity/Relatedness**: Shows that performance improves with task-similarity (static environment) or task-relatedness (dynamic environment).\n\n4.  **Key Technical Contributions**\n    *   **Novel Framework**: Introduction of the \"CMDP-within-online\" framework for Meta-SRL, providing a principled way to combine meta-learning with safe RL.\n    *   **Provable Guarantees**: Derivation of task-averaged regret bounds for optimality gap (TAOG) and constraint violations (TACV), showing improvement with task-similarity and number of tasks.\n        *   Static environment: Regret of $O\\left(\\frac{1}{\\sqrt{M}}\\sqrt{\\frac{\\log T}{T} + \\hat{D}^{*2}}\\right)$ \\cite{khattar2024sr6}[Theorem 3.2].\n        *   Dynamic environment: Improved rate of $O\\left(\\frac{1}{M^{3/4}\\sqrt{T}}\\left(E_T + \\sqrt{E_T T + \\hat{V}_{\\psi}^2}\\right)\\right)$ \\cite{khattar2024sr6}[Corollary 1].\n    *   **Inexact Estimation Methodology**: A practical approach to estimate upper bounds on within-task performance using off-policy stationary distribution corrections (DualDICE) and bounding the estimation error \\cite{khattar2024sr6}[Theorem 3.1].\n    *   **Theoretical Insights into CMDP Optimization Landscape**: Studies the optimization landscape of CMDPs using tame geometry and subgradient flow systems, providing an algorithmic-agnostic growth condition (Kurdyka-Lojasiewicz inequality) around optima, which is crucial for bounding policy distances and estimation errors \\cite{khattar2024sr6}[Theorem 3.1, Appendix F]. This differs from prior work restricted to policy gradient settings.\n    *   **Generalized Regret Bounds**: Provides static and dynamic regret bounds for inexact online gradient descent, which are leveraged for the main theoretical results.\n\n5.  **Experimental Validation**\n    *   The paper states that \"experiments are conducted to demonstrate the effectiveness of our approach.\" However, the provided text does not detail the specific experiments, performance metrics, or comparative results.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   **Assumption 1 (Shrinkage Simplex Set)**: Requires meta-initialization policies to have full support over the state-action space, ensuring KL divergence terms are finite and providing necessary Lipschitz, smoothness, and strong convexity properties.\n        *   **Assumption 2 (O-minimal Structure)**: Assumes objective and constraint functions, and parametric policies are definable in some o-minimal structure, which is a mild condition for many real-world functions but a theoretical requirement for the growth condition analysis.\n        *   The within-task algorithm is exemplified by CRPO, a primal-based approach.\n    *   **Scope of Applicability**: Primarily focuses on CMDPs with softmax parametrization and primal-based safe RL algorithms. The theoretical guarantees are for task-averaged regret.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work represents a significant step forward by providing the first provable guarantees for meta-safe reinforcement learning, addressing a critical gap in existing literature. It moves beyond stylized settings to offer a practical framework for real-world applications.\n    *   **Potential Impact**:\n        *   Enables the deployment of RL agents in safety-critical applications (e.g., robotics, autonomous systems) where both rapid adaptation and strict constraint adherence are necessary.\n        *   The methodology for handling inexactness and leveraging task-similarity/relatedness can inspire future research in robust and efficient meta-learning for constrained problems.\n        *   The theoretical contributions regarding the CMDP optimization landscape (tame geometry) are of independent interest and could benefit broader safe RL research.",
        "keywords": [
          "Meta-safe reinforcement learning (Meta-SRL)",
          "CMDP-within-online framework",
          "safety constraints",
          "Constrained Markov Decision Processes (CMDPs)",
          "provable guarantees",
          "task-averaged regret bounds",
          "inexact learning",
          "off-policy stationary distribution corrections",
          "CMDP optimization landscape",
          "rapid adaptation",
          "real-world safety-critical applications",
          "adaptive learning rates",
          "task-similarity"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n1.  **presents new methods, algorithms, or systems:** the abstract explicitly states, \"we study the problem of meta-safe reinforcement learning (meta-srl) through the cmdp-within-online framework to establish the first provable guarantees in this important setting.\" and \"to this end, we propose a meta-algorithm that performs inexact online learning...\". the introduction further reinforces this with \"we propose a provably low-regret online learning framework that extends the current meta-learning algorithms to safe rl settings.\" and lists \"inexact cmdp-within-online framework: we propose a novel cmdp-within-online framework\" as its first main contribution.\n2.  **technical problem, proposed solution:** the paper identifies a gap in existing meta-rl works regarding constraint violations and proposes a new framework and algorithm (meta-srl) to address this.\n3.  **theoretical and empirical support:** while the paper contains significant theoretical analysis (provable guarantees, regret bounds, theorems, lemmas) and empirical experiments to demonstrate effectiveness, these elements serve to validate and support the *proposed new framework and algorithm*. the core contribution is the development of this new technical solution."
      },
      "file_name": "a1c68c32b11d83c9d48c48163f2a445ce359069e.pdf"
    },
    {
      "success": true,
      "doc_id": "736399ec093da0748fb8a09db142a361",
      "summary": "(1) Background: This meta-analysis assessed the diagnostic accuracy of deep learning model-based osteoporosis prediction using plain X-ray images. (2) Methods: We searched PubMed, Web of Science, SCOPUS, and Google Scholar from no set beginning date to 28 February 2023, for eligible studies that applied deep learning methods for diagnosing osteoporosis using X-ray images. The quality of studies was assessed using the Quality Assessment of Diagnostic Accuracy Studies-2 criteria. The area under the receiver operating characteristic curve (AUROC) was used to quantify the predictive performance. Subgroup, meta-regression, and sensitivity analyses were performed to identify the potential sources of study heterogeneity. (3) Results: Six studies were included; the pooled AUROC, sensitivity, and specificity were 0.88 (95% confidence interval [CI] 0.85–0.91), 0.81 (95% CI 0.78–0.84), and 0.87 (95% CI 0.81–0.92), respectively, indicating good performance. Moderate heterogeneity was observed. Mega-regression and subgroup analyses were not performed due to the limited number of studies included. (4) Conclusion: Deep learning methods effectively extract bone density information from plain radiographs, highlighting their potential for opportunistic screening. Nevertheless, additional prospective multicenter studies involving diverse patient populations are required to confirm the applicability of this novel technique.",
      "intriguing_abstract": "(1) Background: This meta-analysis assessed the diagnostic accuracy of deep learning model-based osteoporosis prediction using plain X-ray images. (2) Methods: We searched PubMed, Web of Science, SCOPUS, and Google Scholar from no set beginning date to 28 February 2023, for eligible studies that applied deep learning methods for diagnosing osteoporosis using X-ray images. The quality of studies was assessed using the Quality Assessment of Diagnostic Accuracy Studies-2 criteria. The area under the receiver operating characteristic curve (AUROC) was used to quantify the predictive performance. Subgroup, meta-regression, and sensitivity analyses were performed to identify the potential sources of study heterogeneity. (3) Results: Six studies were included; the pooled AUROC, sensitivity, and specificity were 0.88 (95% confidence interval [CI] 0.85–0.91), 0.81 (95% CI 0.78–0.84), and 0.87 (95% CI 0.81–0.92), respectively, indicating good performance. Moderate heterogeneity was observed. Mega-regression and subgroup analyses were not performed due to the limited number of studies included. (4) Conclusion: Deep learning methods effectively extract bone density information from plain radiographs, highlighting their potential for opportunistic screening. Nevertheless, additional prospective multicenter studies involving diverse patient populations are required to confirm the applicability of this novel technique.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e4f618eb2e62d986f9746c9fbda2e234fe4c0a40.pdf",
      "citation_key": "yen2024cxp",
      "metadata": {
        "title": "Diagnostic Accuracy of Deep Learning for the Prediction of Osteoporosis Using Plain X-rays: A Systematic Review and Meta-Analysis",
        "authors": [
          "Tzu-Yun Yen",
          "Chan-Shien Ho",
          "Yueh-peng Chen",
          "Yu-Cheng Pei"
        ],
        "published_date": "2024",
        "abstract": "(1) Background: This meta-analysis assessed the diagnostic accuracy of deep learning model-based osteoporosis prediction using plain X-ray images. (2) Methods: We searched PubMed, Web of Science, SCOPUS, and Google Scholar from no set beginning date to 28 February 2023, for eligible studies that applied deep learning methods for diagnosing osteoporosis using X-ray images. The quality of studies was assessed using the Quality Assessment of Diagnostic Accuracy Studies-2 criteria. The area under the receiver operating characteristic curve (AUROC) was used to quantify the predictive performance. Subgroup, meta-regression, and sensitivity analyses were performed to identify the potential sources of study heterogeneity. (3) Results: Six studies were included; the pooled AUROC, sensitivity, and specificity were 0.88 (95% confidence interval [CI] 0.85–0.91), 0.81 (95% CI 0.78–0.84), and 0.87 (95% CI 0.81–0.92), respectively, indicating good performance. Moderate heterogeneity was observed. Mega-regression and subgroup analyses were not performed due to the limited number of studies included. (4) Conclusion: Deep learning methods effectively extract bone density information from plain radiographs, highlighting their potential for opportunistic screening. Nevertheless, additional prospective multicenter studies involving diverse patient populations are required to confirm the applicability of this novel technique.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e4f618eb2e62d986f9746c9fbda2e234fe4c0a40.pdf",
        "venue": "Diagnostics",
        "citationCount": 14,
        "score": 14.0,
        "summary": "(1) Background: This meta-analysis assessed the diagnostic accuracy of deep learning model-based osteoporosis prediction using plain X-ray images. (2) Methods: We searched PubMed, Web of Science, SCOPUS, and Google Scholar from no set beginning date to 28 February 2023, for eligible studies that applied deep learning methods for diagnosing osteoporosis using X-ray images. The quality of studies was assessed using the Quality Assessment of Diagnostic Accuracy Studies-2 criteria. The area under the receiver operating characteristic curve (AUROC) was used to quantify the predictive performance. Subgroup, meta-regression, and sensitivity analyses were performed to identify the potential sources of study heterogeneity. (3) Results: Six studies were included; the pooled AUROC, sensitivity, and specificity were 0.88 (95% confidence interval [CI] 0.85–0.91), 0.81 (95% CI 0.78–0.84), and 0.87 (95% CI 0.81–0.92), respectively, indicating good performance. Moderate heterogeneity was observed. Mega-regression and subgroup analyses were not performed due to the limited number of studies included. (4) Conclusion: Deep learning methods effectively extract bone density information from plain radiographs, highlighting their potential for opportunistic screening. Nevertheless, additional prospective multicenter studies involving diverse patient populations are required to confirm the applicability of this novel technique.",
        "keywords": []
      },
      "file_name": "e4f618eb2e62d986f9746c9fbda2e234fe4c0a40.pdf"
    },
    {
      "success": true,
      "doc_id": "518eb2e16aea549ccd98207607859faa",
      "summary": "Recent booming successes of electric vehicles (EVs) motivate emerging exploration of spatio-temporal (ST) EV charging demand forecasting to inform policy making. Recent studies have contributed to remarkable accuracy improvement by developing deep learning methods. However, when they access massive amounts of data and frequently exchange data through the Internet of Things (IoT), data silos and inefficient training emerge as main challenges. To tackle these challenges, this study proposes an integrated approach for regional EV charging demand forecasting, named federated meta learning-based graph convolutional network, which consists of two modules, namely, 1) ST learning module, which introduces spatial and temporal attentions to capture the underlying charging patterns between different regions and cities effectively and 2) distributed pretraining module, which incorporates federated learning and meta-learning to enhance the adaptivity and generalisability of the forecasting model. A comprehensive evaluation based on a real-world data set of 25246 public EV charging piles shows that the proposed model outperforms other representative models with 1) an average improvement of 29.9% in forecasting errors; 2) an acceleration of 65% in convergence speed; and 3) a sound adaptability to support varying charging demand.",
      "intriguing_abstract": "Recent booming successes of electric vehicles (EVs) motivate emerging exploration of spatio-temporal (ST) EV charging demand forecasting to inform policy making. Recent studies have contributed to remarkable accuracy improvement by developing deep learning methods. However, when they access massive amounts of data and frequently exchange data through the Internet of Things (IoT), data silos and inefficient training emerge as main challenges. To tackle these challenges, this study proposes an integrated approach for regional EV charging demand forecasting, named federated meta learning-based graph convolutional network, which consists of two modules, namely, 1) ST learning module, which introduces spatial and temporal attentions to capture the underlying charging patterns between different regions and cities effectively and 2) distributed pretraining module, which incorporates federated learning and meta-learning to enhance the adaptivity and generalisability of the forecasting model. A comprehensive evaluation based on a real-world data set of 25246 public EV charging piles shows that the proposed model outperforms other representative models with 1) an average improvement of 29.9% in forecasting errors; 2) an acceleration of 65% in convergence speed; and 3) a sound adaptability to support varying charging demand.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b1c2df70f8c287c98e8735d82185bdadf2d4d24b.pdf",
      "citation_key": "you2024xuq",
      "metadata": {
        "title": "FMGCN: Federated Meta Learning-Augmented Graph Convolutional Network for EV Charging Demand Forecasting",
        "authors": [
          "Linlin You",
          "Qiyang Chen",
          "Haohao Qu",
          "Rui Zhu",
          "Jinyue Yan",
          "Paolo Santi",
          "Carlo Ratti"
        ],
        "published_date": "2024",
        "abstract": "Recent booming successes of electric vehicles (EVs) motivate emerging exploration of spatio-temporal (ST) EV charging demand forecasting to inform policy making. Recent studies have contributed to remarkable accuracy improvement by developing deep learning methods. However, when they access massive amounts of data and frequently exchange data through the Internet of Things (IoT), data silos and inefficient training emerge as main challenges. To tackle these challenges, this study proposes an integrated approach for regional EV charging demand forecasting, named federated meta learning-based graph convolutional network, which consists of two modules, namely, 1) ST learning module, which introduces spatial and temporal attentions to capture the underlying charging patterns between different regions and cities effectively and 2) distributed pretraining module, which incorporates federated learning and meta-learning to enhance the adaptivity and generalisability of the forecasting model. A comprehensive evaluation based on a real-world data set of 25246 public EV charging piles shows that the proposed model outperforms other representative models with 1) an average improvement of 29.9% in forecasting errors; 2) an acceleration of 65% in convergence speed; and 3) a sound adaptability to support varying charging demand.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b1c2df70f8c287c98e8735d82185bdadf2d4d24b.pdf",
        "venue": "IEEE Internet of Things Journal",
        "citationCount": 13,
        "score": 13.0,
        "summary": "Recent booming successes of electric vehicles (EVs) motivate emerging exploration of spatio-temporal (ST) EV charging demand forecasting to inform policy making. Recent studies have contributed to remarkable accuracy improvement by developing deep learning methods. However, when they access massive amounts of data and frequently exchange data through the Internet of Things (IoT), data silos and inefficient training emerge as main challenges. To tackle these challenges, this study proposes an integrated approach for regional EV charging demand forecasting, named federated meta learning-based graph convolutional network, which consists of two modules, namely, 1) ST learning module, which introduces spatial and temporal attentions to capture the underlying charging patterns between different regions and cities effectively and 2) distributed pretraining module, which incorporates federated learning and meta-learning to enhance the adaptivity and generalisability of the forecasting model. A comprehensive evaluation based on a real-world data set of 25246 public EV charging piles shows that the proposed model outperforms other representative models with 1) an average improvement of 29.9% in forecasting errors; 2) an acceleration of 65% in convergence speed; and 3) a sound adaptability to support varying charging demand.",
        "keywords": []
      },
      "file_name": "b1c2df70f8c287c98e8735d82185bdadf2d4d24b.pdf"
    },
    {
      "success": true,
      "doc_id": "644bfe060a2836e149e4b505fa11538e",
      "summary": "Automatic modulation classification (AMC) has a wide range of applications in both civilian and military fields, such as industrial Internet of Things (IIoT) security, communication spectrum management, and military electronic countermeasures. However, label mislabeling often occurs in practical scenarios, significantly impacting the performance and robustness of deep neural networks (DNNs). In this article, we propose a meta-learning guided label noise distillation method to enhance the robustness of AMC models against label noise or errors. Specifically, we propose a teacher-student heterogeneous network (TSHN) to discriminate and distill label noise. Following the notion that labels represent information, a teacher network, utilizing trusted few-shot labeled samples, reevaluates and corrects labels for a considerable number of untrusted labeled samples through meta-learning. By dividing and conquering untrusted labeled samples according to their confidence levels, the student network learns more effectively. Additionally, we propose a multiview signal (MVS) method to further enhance the performance of hard-to-classify categories with few-shot trusted labeled samples. Extensive experiments on the RadioML2016 and HisarMod2019.1 data sets demonstrate that our methods significantly improve accuracy and robustness in signal AMC across diverse label noise scenarios, including symmetric, asymmetric, and mixed label noise. For example, compared to the baseline convolutional neural network with the cross-entropy loss, our proposed TSHN achieves a remarkable 1.26% to 36.84% accuracy improvement under symmetric label noise and 0.12% to 38.59% accuracy improvement under mixed label noise. Moreover, TSHN exhibits greater robustness to varying label noise rates compared to existing methods.",
      "intriguing_abstract": "Automatic modulation classification (AMC) has a wide range of applications in both civilian and military fields, such as industrial Internet of Things (IIoT) security, communication spectrum management, and military electronic countermeasures. However, label mislabeling often occurs in practical scenarios, significantly impacting the performance and robustness of deep neural networks (DNNs). In this article, we propose a meta-learning guided label noise distillation method to enhance the robustness of AMC models against label noise or errors. Specifically, we propose a teacher-student heterogeneous network (TSHN) to discriminate and distill label noise. Following the notion that labels represent information, a teacher network, utilizing trusted few-shot labeled samples, reevaluates and corrects labels for a considerable number of untrusted labeled samples through meta-learning. By dividing and conquering untrusted labeled samples according to their confidence levels, the student network learns more effectively. Additionally, we propose a multiview signal (MVS) method to further enhance the performance of hard-to-classify categories with few-shot trusted labeled samples. Extensive experiments on the RadioML2016 and HisarMod2019.1 data sets demonstrate that our methods significantly improve accuracy and robustness in signal AMC across diverse label noise scenarios, including symmetric, asymmetric, and mixed label noise. For example, compared to the baseline convolutional neural network with the cross-entropy loss, our proposed TSHN achieves a remarkable 1.26% to 36.84% accuracy improvement under symmetric label noise and 0.12% to 38.59% accuracy improvement under mixed label noise. Moreover, TSHN exhibits greater robustness to varying label noise rates compared to existing methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/59654fcc571a9040ae2f6d02f78543f1903e5a04.pdf",
      "citation_key": "hao2024dyp",
      "metadata": {
        "title": "Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification",
        "authors": [
          "Xiaoyang Hao",
          "Zhixi Feng",
          "Tongqing Peng",
          "Shuyuan Yang"
        ],
        "published_date": "2024",
        "abstract": "Automatic modulation classification (AMC) has a wide range of applications in both civilian and military fields, such as industrial Internet of Things (IIoT) security, communication spectrum management, and military electronic countermeasures. However, label mislabeling often occurs in practical scenarios, significantly impacting the performance and robustness of deep neural networks (DNNs). In this article, we propose a meta-learning guided label noise distillation method to enhance the robustness of AMC models against label noise or errors. Specifically, we propose a teacher-student heterogeneous network (TSHN) to discriminate and distill label noise. Following the notion that labels represent information, a teacher network, utilizing trusted few-shot labeled samples, reevaluates and corrects labels for a considerable number of untrusted labeled samples through meta-learning. By dividing and conquering untrusted labeled samples according to their confidence levels, the student network learns more effectively. Additionally, we propose a multiview signal (MVS) method to further enhance the performance of hard-to-classify categories with few-shot trusted labeled samples. Extensive experiments on the RadioML2016 and HisarMod2019.1 data sets demonstrate that our methods significantly improve accuracy and robustness in signal AMC across diverse label noise scenarios, including symmetric, asymmetric, and mixed label noise. For example, compared to the baseline convolutional neural network with the cross-entropy loss, our proposed TSHN achieves a remarkable 1.26% to 36.84% accuracy improvement under symmetric label noise and 0.12% to 38.59% accuracy improvement under mixed label noise. Moreover, TSHN exhibits greater robustness to varying label noise rates compared to existing methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/59654fcc571a9040ae2f6d02f78543f1903e5a04.pdf",
        "venue": "IEEE Internet of Things Journal",
        "citationCount": 13,
        "score": 13.0,
        "summary": "Automatic modulation classification (AMC) has a wide range of applications in both civilian and military fields, such as industrial Internet of Things (IIoT) security, communication spectrum management, and military electronic countermeasures. However, label mislabeling often occurs in practical scenarios, significantly impacting the performance and robustness of deep neural networks (DNNs). In this article, we propose a meta-learning guided label noise distillation method to enhance the robustness of AMC models against label noise or errors. Specifically, we propose a teacher-student heterogeneous network (TSHN) to discriminate and distill label noise. Following the notion that labels represent information, a teacher network, utilizing trusted few-shot labeled samples, reevaluates and corrects labels for a considerable number of untrusted labeled samples through meta-learning. By dividing and conquering untrusted labeled samples according to their confidence levels, the student network learns more effectively. Additionally, we propose a multiview signal (MVS) method to further enhance the performance of hard-to-classify categories with few-shot trusted labeled samples. Extensive experiments on the RadioML2016 and HisarMod2019.1 data sets demonstrate that our methods significantly improve accuracy and robustness in signal AMC across diverse label noise scenarios, including symmetric, asymmetric, and mixed label noise. For example, compared to the baseline convolutional neural network with the cross-entropy loss, our proposed TSHN achieves a remarkable 1.26% to 36.84% accuracy improvement under symmetric label noise and 0.12% to 38.59% accuracy improvement under mixed label noise. Moreover, TSHN exhibits greater robustness to varying label noise rates compared to existing methods.",
        "keywords": []
      },
      "file_name": "59654fcc571a9040ae2f6d02f78543f1903e5a04.pdf"
    },
    {
      "success": true,
      "doc_id": "5cc42c47928375702770d755351dd87e",
      "summary": "In this paper, a full-reference image quality assessment (FR-IQA) model based on deep meta-learning and Conformer is proposed. We combine the Conformer architecture with a Siamese network to extract the feature vectors of the reference and distorted images and calculate the similarity of these feature vectors as the predicted score of the image. We use meta-learning to help the model identify different types of image distortion. First, because the information taken as input by the human visual system (HVS) ranges in scale from local to global, we use a Conformer network as a feature extractor to obtain the global and local features of the pristine and distorted images and use a Siamese network to reduce the number of parameters in our model. Second, we use meta-learning to carry out bilevel gradient descent from the query set to the support set in the training stage and fine-tune the model parameters on a few images with unknown distortion types in the testing stage to improve the generalization ability of the model. Experiments show that our method is competitive with existing FR-IQA methods on three standard IQA datasets.",
      "intriguing_abstract": "In this paper, a full-reference image quality assessment (FR-IQA) model based on deep meta-learning and Conformer is proposed. We combine the Conformer architecture with a Siamese network to extract the feature vectors of the reference and distorted images and calculate the similarity of these feature vectors as the predicted score of the image. We use meta-learning to help the model identify different types of image distortion. First, because the information taken as input by the human visual system (HVS) ranges in scale from local to global, we use a Conformer network as a feature extractor to obtain the global and local features of the pristine and distorted images and use a Siamese network to reduce the number of parameters in our model. Second, we use meta-learning to carry out bilevel gradient descent from the query set to the support set in the training stage and fine-tune the model parameters on a few images with unknown distortion types in the testing stage to improve the generalization ability of the model. Experiments show that our method is competitive with existing FR-IQA methods on three standard IQA datasets.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e5638e677d40c9ea67401b9b5241f381a73be6fd.pdf",
      "citation_key": "lang20246m8",
      "metadata": {
        "title": "A Full-Reference Image Quality Assessment Method via Deep Meta-Learning and Conformer",
        "authors": [
          "Shujun Lang",
          "Xu Liu",
          "Mingliang Zhou",
          "Jun Luo",
          "Huayan Pu",
          "Zhuang Xu",
          "Jason Wang",
          "Xuekai Wei",
          "Taiping Zhang",
          "Yong Feng",
          "Zhaowei Shang"
        ],
        "published_date": "2024",
        "abstract": "In this paper, a full-reference image quality assessment (FR-IQA) model based on deep meta-learning and Conformer is proposed. We combine the Conformer architecture with a Siamese network to extract the feature vectors of the reference and distorted images and calculate the similarity of these feature vectors as the predicted score of the image. We use meta-learning to help the model identify different types of image distortion. First, because the information taken as input by the human visual system (HVS) ranges in scale from local to global, we use a Conformer network as a feature extractor to obtain the global and local features of the pristine and distorted images and use a Siamese network to reduce the number of parameters in our model. Second, we use meta-learning to carry out bilevel gradient descent from the query set to the support set in the training stage and fine-tune the model parameters on a few images with unknown distortion types in the testing stage to improve the generalization ability of the model. Experiments show that our method is competitive with existing FR-IQA methods on three standard IQA datasets.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e5638e677d40c9ea67401b9b5241f381a73be6fd.pdf",
        "venue": "IEEE transactions on broadcasting",
        "citationCount": 12,
        "score": 12.0,
        "summary": "In this paper, a full-reference image quality assessment (FR-IQA) model based on deep meta-learning and Conformer is proposed. We combine the Conformer architecture with a Siamese network to extract the feature vectors of the reference and distorted images and calculate the similarity of these feature vectors as the predicted score of the image. We use meta-learning to help the model identify different types of image distortion. First, because the information taken as input by the human visual system (HVS) ranges in scale from local to global, we use a Conformer network as a feature extractor to obtain the global and local features of the pristine and distorted images and use a Siamese network to reduce the number of parameters in our model. Second, we use meta-learning to carry out bilevel gradient descent from the query set to the support set in the training stage and fine-tune the model parameters on a few images with unknown distortion types in the testing stage to improve the generalization ability of the model. Experiments show that our method is competitive with existing FR-IQA methods on three standard IQA datasets.",
        "keywords": []
      },
      "file_name": "e5638e677d40c9ea67401b9b5241f381a73be6fd.pdf"
    },
    {
      "success": true,
      "doc_id": "b23327e838b49c577a7da63c13329a2c",
      "summary": "—Dynamic Flexible Job Shop Scheduling (DFJSS) is a critical combinatorial optimisation problem known for its dynamic nature and flexibility of machines. Traditional scheduling methods face limitations in adapting to such dynamic and flexible environments. Recently, there has been a trend in employing reinforcement learning (RL) to train scheduling agents for selecting manual scheduling heuristics at various decision points for DFJSS. However, the effectiveness of RL is constrained by the limited efficacy of the manually designed scheduling heuristics. Additionally, the process of manually designing diverse scheduling heuristics as the actions demands significant expert knowledge. In response, this paper proposes a Niching genetic programming (GP)-assisted RL method that leverages the evolutionary capabilities of GP to help RL solve the DFJSS problem effectively. Specifically, instead of using those manual scheduling heuristics, the RL actions are replaced with scheduling heuristics evolved by the Niching GP to optimise and adapt these heuristics based on real-time feedback from the environment. Experimental results demonstrate the effectiveness of the proposed method in comparison to the widely used manual scheduling heuristics and the baseline deep RL method. Further analyses reveal that the effectiveness of the proposed method is due to the behavioral differences among heuristics learned by the Niching GP, serving as actions for the RL. In addition, the effectiveness of the proposed algorithm benefits from the comparable percentages of contributions made by these learned heuristics throughout the long-term scheduling process.",
      "intriguing_abstract": "—Dynamic Flexible Job Shop Scheduling (DFJSS) is a critical combinatorial optimisation problem known for its dynamic nature and flexibility of machines. Traditional scheduling methods face limitations in adapting to such dynamic and flexible environments. Recently, there has been a trend in employing reinforcement learning (RL) to train scheduling agents for selecting manual scheduling heuristics at various decision points for DFJSS. However, the effectiveness of RL is constrained by the limited efficacy of the manually designed scheduling heuristics. Additionally, the process of manually designing diverse scheduling heuristics as the actions demands significant expert knowledge. In response, this paper proposes a Niching genetic programming (GP)-assisted RL method that leverages the evolutionary capabilities of GP to help RL solve the DFJSS problem effectively. Specifically, instead of using those manual scheduling heuristics, the RL actions are replaced with scheduling heuristics evolved by the Niching GP to optimise and adapt these heuristics based on real-time feedback from the environment. Experimental results demonstrate the effectiveness of the proposed method in comparison to the widely used manual scheduling heuristics and the baseline deep RL method. Further analyses reveal that the effectiveness of the proposed method is due to the behavioral differences among heuristics learned by the Niching GP, serving as actions for the RL. In addition, the effectiveness of the proposed algorithm benefits from the comparable percentages of contributions made by these learned heuristics throughout the long-term scheduling process.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/ac353dc230e18a9f778caedd44c6e2ae70b8c08e.pdf",
      "citation_key": "xu2024ywn",
      "metadata": {
        "title": "Niching Genetic Programming to Learn Actions for Deep Reinforcement Learning in Dynamic Flexible Scheduling",
        "authors": [
          "Meng Xu",
          "Yi Mei",
          "Fangfang Zhang",
          "Mengjie Zhang"
        ],
        "published_date": "2024",
        "abstract": "—Dynamic Flexible Job Shop Scheduling (DFJSS) is a critical combinatorial optimisation problem known for its dynamic nature and flexibility of machines. Traditional scheduling methods face limitations in adapting to such dynamic and flexible environments. Recently, there has been a trend in employing reinforcement learning (RL) to train scheduling agents for selecting manual scheduling heuristics at various decision points for DFJSS. However, the effectiveness of RL is constrained by the limited efficacy of the manually designed scheduling heuristics. Additionally, the process of manually designing diverse scheduling heuristics as the actions demands significant expert knowledge. In response, this paper proposes a Niching genetic programming (GP)-assisted RL method that leverages the evolutionary capabilities of GP to help RL solve the DFJSS problem effectively. Specifically, instead of using those manual scheduling heuristics, the RL actions are replaced with scheduling heuristics evolved by the Niching GP to optimise and adapt these heuristics based on real-time feedback from the environment. Experimental results demonstrate the effectiveness of the proposed method in comparison to the widely used manual scheduling heuristics and the baseline deep RL method. Further analyses reveal that the effectiveness of the proposed method is due to the behavioral differences among heuristics learned by the Niching GP, serving as actions for the RL. In addition, the effectiveness of the proposed algorithm benefits from the comparable percentages of contributions made by these learned heuristics throughout the long-term scheduling process.",
        "file_path": "paper_data/Deep_Meta-Learning/info/ac353dc230e18a9f778caedd44c6e2ae70b8c08e.pdf",
        "venue": "IEEE Transactions on Evolutionary Computation",
        "citationCount": 12,
        "score": 12.0,
        "summary": "—Dynamic Flexible Job Shop Scheduling (DFJSS) is a critical combinatorial optimisation problem known for its dynamic nature and flexibility of machines. Traditional scheduling methods face limitations in adapting to such dynamic and flexible environments. Recently, there has been a trend in employing reinforcement learning (RL) to train scheduling agents for selecting manual scheduling heuristics at various decision points for DFJSS. However, the effectiveness of RL is constrained by the limited efficacy of the manually designed scheduling heuristics. Additionally, the process of manually designing diverse scheduling heuristics as the actions demands significant expert knowledge. In response, this paper proposes a Niching genetic programming (GP)-assisted RL method that leverages the evolutionary capabilities of GP to help RL solve the DFJSS problem effectively. Specifically, instead of using those manual scheduling heuristics, the RL actions are replaced with scheduling heuristics evolved by the Niching GP to optimise and adapt these heuristics based on real-time feedback from the environment. Experimental results demonstrate the effectiveness of the proposed method in comparison to the widely used manual scheduling heuristics and the baseline deep RL method. Further analyses reveal that the effectiveness of the proposed method is due to the behavioral differences among heuristics learned by the Niching GP, serving as actions for the RL. In addition, the effectiveness of the proposed algorithm benefits from the comparable percentages of contributions made by these learned heuristics throughout the long-term scheduling process.",
        "keywords": []
      },
      "file_name": "ac353dc230e18a9f778caedd44c6e2ae70b8c08e.pdf"
    },
    {
      "success": true,
      "doc_id": "c210d9a7e7031f5f097266993a836d2e",
      "summary": "Background The use of the deep learning (DL) approach has been suggested or applied to identify childhood autism spectrum disorder (ASD). The capacity to predict ASD, however, differs across investigations. Our study’s objective was to conduct a meta-analysis to determine the DL for ASD in children’s classification accuracy. Methods Eligibility criteria were designed according to the purpose of the meta-analysis; PubMed, EMBASE, Cochrane Library, and Web of Science Database were searched for articles published up to April 16, 2023, on the accuracy of DL methods for ASD classification. Using the Revised Tool for the Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) to assess the quality of the included studies. Sensitivity, specificity, areas under the curve (AUC), summary receiver operating characteristic (SROC), and corresponding 95% confidence intervals (CIs) were compiled by using the bivariate random-effects models. Results A total of 11 predictive trials based on DL models were included, involving 9495 ASD patients from 6 different databases. According to bivariate random-effects models’ results, the overall sensitivity, specificity, and AUC of the DL technique for ASD were, 0.95 (95% CI = 0.88–0.98), 0.93 (95% CI = 0.85–0.97), and 0.98 (95%CI: 0.97–0.99), respectively. Subgroup analysis results found that different datasets did not cause heterogeneity (meta-regression P = 0.55). The Kaggle dataset’s sensitivity and specificity were 0.94 (95%CI: 0.82-1.00) and 0.91 (95%CI: 0.76-1.00), and with 0.97 (95%CI: 0.92-1.00) and 0.97 (95%CI: 0.92-1.00) for ABIDE dataset. Conclusions DL techniques has satisfactory sensitivity, specificity, and AUC in ASD classification. However, the major heterogeneity of the included studies limited the effectiveness of this meta-analysis. Further trials need to be performed to demonstrate the clinical practicability of DL diagnosis. Supplementary Information The online version contains supplementary material available at 10.1186/s12888-024-06116-0.",
      "intriguing_abstract": "Background The use of the deep learning (DL) approach has been suggested or applied to identify childhood autism spectrum disorder (ASD). The capacity to predict ASD, however, differs across investigations. Our study’s objective was to conduct a meta-analysis to determine the DL for ASD in children’s classification accuracy. Methods Eligibility criteria were designed according to the purpose of the meta-analysis; PubMed, EMBASE, Cochrane Library, and Web of Science Database were searched for articles published up to April 16, 2023, on the accuracy of DL methods for ASD classification. Using the Revised Tool for the Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) to assess the quality of the included studies. Sensitivity, specificity, areas under the curve (AUC), summary receiver operating characteristic (SROC), and corresponding 95% confidence intervals (CIs) were compiled by using the bivariate random-effects models. Results A total of 11 predictive trials based on DL models were included, involving 9495 ASD patients from 6 different databases. According to bivariate random-effects models’ results, the overall sensitivity, specificity, and AUC of the DL technique for ASD were, 0.95 (95% CI = 0.88–0.98), 0.93 (95% CI = 0.85–0.97), and 0.98 (95%CI: 0.97–0.99), respectively. Subgroup analysis results found that different datasets did not cause heterogeneity (meta-regression P = 0.55). The Kaggle dataset’s sensitivity and specificity were 0.94 (95%CI: 0.82-1.00) and 0.91 (95%CI: 0.76-1.00), and with 0.97 (95%CI: 0.92-1.00) and 0.97 (95%CI: 0.92-1.00) for ABIDE dataset. Conclusions DL techniques has satisfactory sensitivity, specificity, and AUC in ASD classification. However, the major heterogeneity of the included studies limited the effectiveness of this meta-analysis. Further trials need to be performed to demonstrate the clinical practicability of DL diagnosis. Supplementary Information The online version contains supplementary material available at 10.1186/s12888-024-06116-0.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d87b248c029c7a6a3eab838b73460c834542913e.pdf",
      "citation_key": "ding2024jjo",
      "metadata": {
        "title": "Deep learning approach to predict autism spectrum disorder: a systematic review and meta-analysis",
        "authors": [
          "Yang Ding",
          "Heng Zhang",
          "Ting Qiu"
        ],
        "published_date": "2024",
        "abstract": "Background The use of the deep learning (DL) approach has been suggested or applied to identify childhood autism spectrum disorder (ASD). The capacity to predict ASD, however, differs across investigations. Our study’s objective was to conduct a meta-analysis to determine the DL for ASD in children’s classification accuracy. Methods Eligibility criteria were designed according to the purpose of the meta-analysis; PubMed, EMBASE, Cochrane Library, and Web of Science Database were searched for articles published up to April 16, 2023, on the accuracy of DL methods for ASD classification. Using the Revised Tool for the Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) to assess the quality of the included studies. Sensitivity, specificity, areas under the curve (AUC), summary receiver operating characteristic (SROC), and corresponding 95% confidence intervals (CIs) were compiled by using the bivariate random-effects models. Results A total of 11 predictive trials based on DL models were included, involving 9495 ASD patients from 6 different databases. According to bivariate random-effects models’ results, the overall sensitivity, specificity, and AUC of the DL technique for ASD were, 0.95 (95% CI = 0.88–0.98), 0.93 (95% CI = 0.85–0.97), and 0.98 (95%CI: 0.97–0.99), respectively. Subgroup analysis results found that different datasets did not cause heterogeneity (meta-regression P = 0.55). The Kaggle dataset’s sensitivity and specificity were 0.94 (95%CI: 0.82-1.00) and 0.91 (95%CI: 0.76-1.00), and with 0.97 (95%CI: 0.92-1.00) and 0.97 (95%CI: 0.92-1.00) for ABIDE dataset. Conclusions DL techniques has satisfactory sensitivity, specificity, and AUC in ASD classification. However, the major heterogeneity of the included studies limited the effectiveness of this meta-analysis. Further trials need to be performed to demonstrate the clinical practicability of DL diagnosis. Supplementary Information The online version contains supplementary material available at 10.1186/s12888-024-06116-0.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d87b248c029c7a6a3eab838b73460c834542913e.pdf",
        "venue": "BMC Psychiatry",
        "citationCount": 12,
        "score": 12.0,
        "summary": "Background The use of the deep learning (DL) approach has been suggested or applied to identify childhood autism spectrum disorder (ASD). The capacity to predict ASD, however, differs across investigations. Our study’s objective was to conduct a meta-analysis to determine the DL for ASD in children’s classification accuracy. Methods Eligibility criteria were designed according to the purpose of the meta-analysis; PubMed, EMBASE, Cochrane Library, and Web of Science Database were searched for articles published up to April 16, 2023, on the accuracy of DL methods for ASD classification. Using the Revised Tool for the Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) to assess the quality of the included studies. Sensitivity, specificity, areas under the curve (AUC), summary receiver operating characteristic (SROC), and corresponding 95% confidence intervals (CIs) were compiled by using the bivariate random-effects models. Results A total of 11 predictive trials based on DL models were included, involving 9495 ASD patients from 6 different databases. According to bivariate random-effects models’ results, the overall sensitivity, specificity, and AUC of the DL technique for ASD were, 0.95 (95% CI = 0.88–0.98), 0.93 (95% CI = 0.85–0.97), and 0.98 (95%CI: 0.97–0.99), respectively. Subgroup analysis results found that different datasets did not cause heterogeneity (meta-regression P = 0.55). The Kaggle dataset’s sensitivity and specificity were 0.94 (95%CI: 0.82-1.00) and 0.91 (95%CI: 0.76-1.00), and with 0.97 (95%CI: 0.92-1.00) and 0.97 (95%CI: 0.92-1.00) for ABIDE dataset. Conclusions DL techniques has satisfactory sensitivity, specificity, and AUC in ASD classification. However, the major heterogeneity of the included studies limited the effectiveness of this meta-analysis. Further trials need to be performed to demonstrate the clinical practicability of DL diagnosis. Supplementary Information The online version contains supplementary material available at 10.1186/s12888-024-06116-0.",
        "keywords": []
      },
      "file_name": "d87b248c029c7a6a3eab838b73460c834542913e.pdf"
    },
    {
      "success": true,
      "doc_id": "b02867906383cfbf7e5fd1744ceb801c",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: Existing prompt tuning methods for Vision-Language Models (VLMs), such as Context Optimization (CoOp), suffer from severe overfitting to base classes and exhibit poor generalization capabilities to novel (unseen) classes \\cite{wang2024dai}.\n    *   **Importance & Challenge**: Adapting large pre-trained VLMs to diverse downstream vision tasks with limited data is crucial. However, the limited capacity of adaptable prompt vectors compared to the vast scale of pre-trained models makes it challenging for these vectors to absorb knowledge relevant to novel classes, leading to the observed overfitting and poor generalization \\cite{wang2024dai}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: The paper builds upon prompt tuning methods like CoOp \\cite{wang2024dai}, which use learnable context vectors as text prompts. Other related works include CoCoOp \\cite{wang2024dai} (introduces image prompts) and KgCoOp \\cite{wang2024dai} (minimizes disparity between learnable and manual prompts).\n    *   **Limitations of Previous Solutions**: CoOp-based methods are prone to overfitting, where accuracy on base classes initially rises then declines, while accuracy on new classes consistently drops \\cite{wang2024dai}. CoCoOp still shows a marked decrease in accuracy in later training stages, and KgCoOp, while alleviating overfitting to some extent, still exhibits limitations \\cite{wang2024dai}. The core limitation identified is the insufficient consideration of input data organization during prompt tuning, leading to text knowledge being overly tailored to base classes \\cite{wang2024dai}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method**: The paper proposes \"Learning to Learn\" (LoL), a meta-learning-informed prompt tuning method. It treats prompt tuning as a meta-learning problem, specifically adopting an N-way K-shot episodic training framework for learning prompts \\cite{wang2024dai}.\n    *   **Two-Stage Process**:\n        1.  **Prompt-tuning Stage**: Initial fine-tuning on base classes using a CoOp-based approach to learn context vectors, leveraging the pre-trained CLIP model \\cite{wang2024dai}.\n        2.  **Meta-Learning Stage**: Further fine-tuning is performed on the base classes in an N-way K-shot manner. This involves sampling multiple classification tasks from the base classes, where the model optimizes itself to perform well on these tasks through inner-loop (support set) and outer-loop (query set) gradient updates, akin to MAML \\cite{wang2024dai}.\n    *   **Novelty**: The primary innovation lies in integrating meta-learning's N-way K-shot episodic training strategy into prompt tuning. This approach to organizing input data during training is novel for prompt tuning, allowing the limited capacity of adaptable vectors to better absorb and transfer knowledge to novel classes by minimizing overfitting to base classes \\cite{wang2024dai}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of a meta-learning-grounded visual prompt tuning baseline (LoL) that explicitly addresses the base-to-new generalization problem \\cite{wang2024dai}.\n    *   **Training Strategy**: A two-stage training strategy combining initial CoOp-based prompt tuning with a subsequent meta-learning stage using N-way K-shot episodic training on base classes \\cite{wang2024dai}.\n    *   **Problem Resolution**: Effectively tackles the challenge of excessive overfitting of textual knowledge on base classes, thereby improving generalization to novel classes \\cite{wang2024dai}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed to evaluate the generalization capability from base classes to new classes across 7 image classification datasets \\cite{wang2024dai}.\n    *   **Performance Metrics & Comparison**: The method was evaluated using \"Base\" (accuracy on base classes), \"New\" (accuracy on novel classes), and \"H\" (harmonic mean of Base and New) accuracy. Comparisons were made against state-of-the-art prompt tuning methods including CoOp, CoCoOp, and KgCoOp, using ViT-B/16 and ResNet-50 backbones for various K-shot settings (K=1, 2, 4, 8, 16) \\cite{wang2024dai}.\n    *   **Key Results**: LoL consistently achieved significantly higher performance on novel classes (\"New\" accuracy) and a higher harmonic mean (\"H\") across all K-shot settings and backbones compared to existing approaches \\cite{wang2024dai}. For instance, with ViT-B/16 and K=16, LoL achieved 91.59% on new classes, substantially outperforming CoOp (70.90%), CoCoOp (69.43%), and KgCoOp (76.52%) \\cite{wang2024dai}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The paper does not explicitly state technical limitations of the LoL method itself within the provided text.\n    *   **Scope of Applicability**: The method is primarily demonstrated for adapting pre-trained Vision-Language Models (specifically CLIP) to downstream image classification tasks, focusing on improving generalization to novel classes in few-shot settings \\cite{wang2024dai}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: LoL significantly advances the technical state-of-the-art in prompt tuning for VLMs by providing a robust optimization strategy that effectively mitigates overfitting and dramatically improves generalization to novel classes \\cite{wang2024dai}.\n    *   **Potential Impact**: This work highlights the potential of integrating meta-learning principles into prompt engineering, opening new avenues for research in developing more generalizable and efficient adaptation strategies for large pre-trained models in low-data regimes \\cite{wang2024dai}.",
      "intriguing_abstract": "Adapting powerful Vision-Language Models (VLMs) to new tasks with limited data is crucial, yet existing prompt tuning methods like CoOp struggle with severe overfitting to base classes, leading to poor generalization on novel categories. This fundamental limitation stems from the restricted capacity of prompt vectors to absorb transferable knowledge. We introduce \"Learning to Learn\" (LoL), a novel meta-learning-informed prompt tuning framework designed to overcome this challenge. LoL re-frames prompt tuning as an N-way K-shot episodic training problem, employing a two-stage strategy: initial CoOp-based fine-tuning followed by a meta-learning stage on base classes. This innovative approach to input data organization dramatically mitigates overfitting, enabling prompt vectors to learn more generalizable representations. Extensive experiments across 7 datasets demonstrate LoL's superior performance, achieving significantly higher accuracy on novel classes and harmonic mean compared to state-of-the-art methods like CoOp, CoCoOp, and KgCoOp, particularly in few-shot settings. Our work establishes a new baseline for VLM adaptation, highlighting the transformative potential of integrating meta-learning principles to unlock truly generalizable prompt tuning.",
      "keywords": [
        "Prompt tuning",
        "Vision-Language Models (VLMs)",
        "Overfitting to base classes",
        "Generalization to novel classes",
        "Meta-learning",
        "\"Learning to Learn\" (LoL)",
        "N-way K-shot episodic training",
        "Two-stage training strategy",
        "CLIP model",
        "Image classification",
        "Few-shot settings",
        "Base-to-new generalization",
        "Mitigating overfitting",
        "Harmonic mean accuracy"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/c267e53f823a2ef9e9e6bbc26196d68b789fb4c2.pdf",
      "citation_key": "wang2024dai",
      "metadata": {
        "title": "Learning to Learn Better Visual Prompts",
        "authors": [
          "Fengxiang Wang",
          "Wanrong Huang",
          "Shaowu Yang",
          "Qi Fan",
          "Long Lan"
        ],
        "published_date": "2024",
        "abstract": "Prompt tuning provides a low-cost way of adapting vision-language models (VLMs) for various downstream vision tasks without requiring updating the huge pre-trained parameters. Dispensing with the conventional manual crafting of prompts, the recent prompt tuning method of Context Optimization (CoOp) introduces adaptable vectors as text prompts. Nevertheless, several previous works point out that the CoOp-based approaches are easy to overfit to the base classes and hard to generalize to novel classes. In this paper, we reckon that the prompt tuning works well only in the base classes because of the limited capacity of the adaptable vectors. The scale of the pre-trained model is hundreds times the scale of the adaptable vector, thus the learned vector has a very limited ability to absorb the knowledge of novel classes. To minimize this excessive overfitting of textual knowledge on the base class, we view prompt tuning as learning to learn (LoL) and learn the prompt in the way of meta-learning, the training manner of dividing the base classes into many different subclasses could fully exert the limited capacity of prompt tuning and thus transfer it power to recognize the novel classes. To be specific, we initially perform fine-tuning on the base class based on the CoOp method for pre-trained CLIP. Subsequently, predicated on the fine-tuned CLIP model, we carry out further fine-tuning in an N-way K-shot manner from the perspective of meta-learning on the base classes. We finally apply the learned textual vector and VLM for unseen classes.Extensive experiments on benchmark datasets validate the efficacy of our meta-learning-informed prompt tuning, affirming its role as a robust optimization strategy for VLMs.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c267e53f823a2ef9e9e6bbc26196d68b789fb4c2.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 12,
        "score": 12.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: Existing prompt tuning methods for Vision-Language Models (VLMs), such as Context Optimization (CoOp), suffer from severe overfitting to base classes and exhibit poor generalization capabilities to novel (unseen) classes \\cite{wang2024dai}.\n    *   **Importance & Challenge**: Adapting large pre-trained VLMs to diverse downstream vision tasks with limited data is crucial. However, the limited capacity of adaptable prompt vectors compared to the vast scale of pre-trained models makes it challenging for these vectors to absorb knowledge relevant to novel classes, leading to the observed overfitting and poor generalization \\cite{wang2024dai}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: The paper builds upon prompt tuning methods like CoOp \\cite{wang2024dai}, which use learnable context vectors as text prompts. Other related works include CoCoOp \\cite{wang2024dai} (introduces image prompts) and KgCoOp \\cite{wang2024dai} (minimizes disparity between learnable and manual prompts).\n    *   **Limitations of Previous Solutions**: CoOp-based methods are prone to overfitting, where accuracy on base classes initially rises then declines, while accuracy on new classes consistently drops \\cite{wang2024dai}. CoCoOp still shows a marked decrease in accuracy in later training stages, and KgCoOp, while alleviating overfitting to some extent, still exhibits limitations \\cite{wang2024dai}. The core limitation identified is the insufficient consideration of input data organization during prompt tuning, leading to text knowledge being overly tailored to base classes \\cite{wang2024dai}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method**: The paper proposes \"Learning to Learn\" (LoL), a meta-learning-informed prompt tuning method. It treats prompt tuning as a meta-learning problem, specifically adopting an N-way K-shot episodic training framework for learning prompts \\cite{wang2024dai}.\n    *   **Two-Stage Process**:\n        1.  **Prompt-tuning Stage**: Initial fine-tuning on base classes using a CoOp-based approach to learn context vectors, leveraging the pre-trained CLIP model \\cite{wang2024dai}.\n        2.  **Meta-Learning Stage**: Further fine-tuning is performed on the base classes in an N-way K-shot manner. This involves sampling multiple classification tasks from the base classes, where the model optimizes itself to perform well on these tasks through inner-loop (support set) and outer-loop (query set) gradient updates, akin to MAML \\cite{wang2024dai}.\n    *   **Novelty**: The primary innovation lies in integrating meta-learning's N-way K-shot episodic training strategy into prompt tuning. This approach to organizing input data during training is novel for prompt tuning, allowing the limited capacity of adaptable vectors to better absorb and transfer knowledge to novel classes by minimizing overfitting to base classes \\cite{wang2024dai}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: Introduction of a meta-learning-grounded visual prompt tuning baseline (LoL) that explicitly addresses the base-to-new generalization problem \\cite{wang2024dai}.\n    *   **Training Strategy**: A two-stage training strategy combining initial CoOp-based prompt tuning with a subsequent meta-learning stage using N-way K-shot episodic training on base classes \\cite{wang2024dai}.\n    *   **Problem Resolution**: Effectively tackles the challenge of excessive overfitting of textual knowledge on base classes, thereby improving generalization to novel classes \\cite{wang2024dai}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed to evaluate the generalization capability from base classes to new classes across 7 image classification datasets \\cite{wang2024dai}.\n    *   **Performance Metrics & Comparison**: The method was evaluated using \"Base\" (accuracy on base classes), \"New\" (accuracy on novel classes), and \"H\" (harmonic mean of Base and New) accuracy. Comparisons were made against state-of-the-art prompt tuning methods including CoOp, CoCoOp, and KgCoOp, using ViT-B/16 and ResNet-50 backbones for various K-shot settings (K=1, 2, 4, 8, 16) \\cite{wang2024dai}.\n    *   **Key Results**: LoL consistently achieved significantly higher performance on novel classes (\"New\" accuracy) and a higher harmonic mean (\"H\") across all K-shot settings and backbones compared to existing approaches \\cite{wang2024dai}. For instance, with ViT-B/16 and K=16, LoL achieved 91.59% on new classes, substantially outperforming CoOp (70.90%), CoCoOp (69.43%), and KgCoOp (76.52%) \\cite{wang2024dai}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The paper does not explicitly state technical limitations of the LoL method itself within the provided text.\n    *   **Scope of Applicability**: The method is primarily demonstrated for adapting pre-trained Vision-Language Models (specifically CLIP) to downstream image classification tasks, focusing on improving generalization to novel classes in few-shot settings \\cite{wang2024dai}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: LoL significantly advances the technical state-of-the-art in prompt tuning for VLMs by providing a robust optimization strategy that effectively mitigates overfitting and dramatically improves generalization to novel classes \\cite{wang2024dai}.\n    *   **Potential Impact**: This work highlights the potential of integrating meta-learning principles into prompt engineering, opening new avenues for research in developing more generalizable and efficient adaptation strategies for large pre-trained models in low-data regimes \\cite{wang2024dai}.",
        "keywords": [
          "Prompt tuning",
          "Vision-Language Models (VLMs)",
          "Overfitting to base classes",
          "Generalization to novel classes",
          "Meta-learning",
          "\"Learning to Learn\" (LoL)",
          "N-way K-shot episodic training",
          "Two-stage training strategy",
          "CLIP model",
          "Image classification",
          "Few-shot settings",
          "Base-to-new generalization",
          "Mitigating overfitting",
          "Harmonic mean accuracy"
        ],
        "paper_type": "the paper type is **technical**.\n\n**reasoning:**\n\n1.  **problem identification:** the abstract and introduction clearly identify a technical problem with existing prompt tuning methods (specifically coop), stating that they \"are easy to overfit to the base classes and hard to generalize to novel classes.\"\n2.  **proposed solution/method:** the paper explicitly \"proposes\" a new approach: \"we view prompt tuning as learning to learn (lol) and learn the prompt in the way of meta-learning.\" it then details the specific steps of this new \"meta-learning-informed prompt tuning\" method.\n3.  **algorithm/system description:** the abstract describes the method's implementation: \"we initially perform fine-tuning... subsequently, predicated on the fine-tuned clip model, we carry out further fine-tuning in an n-way k-shot manner from the perspective of meta-learning...\"\n4.  **validation:** the abstract concludes by mentioning \"extensive experiments on benchmark datasets validate the efficacy of our meta-learning-informed prompt tuning,\" which is typical for technical papers presenting a new method.\n\nthese elements strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems to solve a technical problem. while it includes empirical validation, the core contribution described is the novel method itself, making it primarily technical rather than purely empirical."
      },
      "file_name": "c267e53f823a2ef9e9e6bbc26196d68b789fb4c2.pdf"
    },
    {
      "success": true,
      "doc_id": "33dd26c89b54d96cdb8d4c325201bdcb",
      "summary": "",
      "intriguing_abstract": "",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b0e2151301e613daabd42c310d76d3a489bd4cdc.pdf",
      "citation_key": "nussenbaum2024z82",
      "metadata": {
        "title": "Understanding the development of reward learning through the lens of meta-learning",
        "authors": [
          "Kate Nussenbaum",
          "Catherine A. Hartley"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/Deep_Meta-Learning/info/b0e2151301e613daabd42c310d76d3a489bd4cdc.pdf",
        "venue": "Nature Reviews Psychology",
        "citationCount": 12,
        "score": 12.0,
        "summary": "",
        "keywords": []
      },
      "file_name": "b0e2151301e613daabd42c310d76d3a489bd4cdc.pdf"
    },
    {
      "success": true,
      "doc_id": "d0b29db9946887243ce08c6e026c66dc",
      "summary": "Deep learning has attained state-of-the-art results in general image segmentation problems; however, it requires a substantial number of annotated images to achieve the desired outcomes. In the medical field, the availability of annotated images is often limited. To address this challenge, few-shot learning techniques have been successfully adapted to rapidly generalize to new tasks with only a few samples, leveraging prior knowledge. In this paper, we employ a gradient-based method known as Model-Agnostic Meta-Learning (MAML) for medical image segmentation. MAML is a meta-learning algorithm that quickly adapts to new tasks by updating a model’s parameters based on a limited set of training samples. Additionally, we use an enhanced 3D U-Net as the foundational network for our models. The enhanced 3D U-Net is a convolutional neural network specifically designed for medical image segmentation. We evaluate our approach on the TotalSegmentator dataset, considering a few annotated images for four tasks: liver, spleen, right kidney, and left kidney. The results demonstrate that our approach facilitates rapid adaptation to new tasks using only a few annotated images. In 10-shot settings, our approach achieved mean dice coefficients of 93.70%, 85.98%, 81.20%, and 89.58% for liver, spleen, right kidney, and left kidney segmentation, respectively. In five-shot sittings, the approach attained mean Dice coefficients of 90.27%, 83.89%, 77.53%, and 87.01% for liver, spleen, right kidney, and left kidney segmentation, respectively. Finally, we assess the effectiveness of our proposed approach on a dataset collected from a local hospital. Employing five-shot sittings, we achieve mean Dice coefficients of 90.62%, 79.86%, 79.87%, and 78.21% for liver, spleen, right kidney, and left kidney segmentation, respectively.",
      "intriguing_abstract": "Deep learning has attained state-of-the-art results in general image segmentation problems; however, it requires a substantial number of annotated images to achieve the desired outcomes. In the medical field, the availability of annotated images is often limited. To address this challenge, few-shot learning techniques have been successfully adapted to rapidly generalize to new tasks with only a few samples, leveraging prior knowledge. In this paper, we employ a gradient-based method known as Model-Agnostic Meta-Learning (MAML) for medical image segmentation. MAML is a meta-learning algorithm that quickly adapts to new tasks by updating a model’s parameters based on a limited set of training samples. Additionally, we use an enhanced 3D U-Net as the foundational network for our models. The enhanced 3D U-Net is a convolutional neural network specifically designed for medical image segmentation. We evaluate our approach on the TotalSegmentator dataset, considering a few annotated images for four tasks: liver, spleen, right kidney, and left kidney. The results demonstrate that our approach facilitates rapid adaptation to new tasks using only a few annotated images. In 10-shot settings, our approach achieved mean dice coefficients of 93.70%, 85.98%, 81.20%, and 89.58% for liver, spleen, right kidney, and left kidney segmentation, respectively. In five-shot sittings, the approach attained mean Dice coefficients of 90.27%, 83.89%, 77.53%, and 87.01% for liver, spleen, right kidney, and left kidney segmentation, respectively. Finally, we assess the effectiveness of our proposed approach on a dataset collected from a local hospital. Employing five-shot sittings, we achieve mean Dice coefficients of 90.62%, 79.86%, 79.87%, and 78.21% for liver, spleen, right kidney, and left kidney segmentation, respectively.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/8f338e2bfc051b35ddbfd743d31681187f3618ab.pdf",
      "citation_key": "alsaleh2024vdv",
      "metadata": {
        "title": "Few-Shot Learning for Medical Image Segmentation Using 3D U-Net and Model-Agnostic Meta-Learning (MAML)",
        "authors": [
          "Aqilah M. Alsaleh",
          "Eid Albalawi",
          "A. Algosaibi",
          "Salman S. Albakheet",
          "S. B. Khan"
        ],
        "published_date": "2024",
        "abstract": "Deep learning has attained state-of-the-art results in general image segmentation problems; however, it requires a substantial number of annotated images to achieve the desired outcomes. In the medical field, the availability of annotated images is often limited. To address this challenge, few-shot learning techniques have been successfully adapted to rapidly generalize to new tasks with only a few samples, leveraging prior knowledge. In this paper, we employ a gradient-based method known as Model-Agnostic Meta-Learning (MAML) for medical image segmentation. MAML is a meta-learning algorithm that quickly adapts to new tasks by updating a model’s parameters based on a limited set of training samples. Additionally, we use an enhanced 3D U-Net as the foundational network for our models. The enhanced 3D U-Net is a convolutional neural network specifically designed for medical image segmentation. We evaluate our approach on the TotalSegmentator dataset, considering a few annotated images for four tasks: liver, spleen, right kidney, and left kidney. The results demonstrate that our approach facilitates rapid adaptation to new tasks using only a few annotated images. In 10-shot settings, our approach achieved mean dice coefficients of 93.70%, 85.98%, 81.20%, and 89.58% for liver, spleen, right kidney, and left kidney segmentation, respectively. In five-shot sittings, the approach attained mean Dice coefficients of 90.27%, 83.89%, 77.53%, and 87.01% for liver, spleen, right kidney, and left kidney segmentation, respectively. Finally, we assess the effectiveness of our proposed approach on a dataset collected from a local hospital. Employing five-shot sittings, we achieve mean Dice coefficients of 90.62%, 79.86%, 79.87%, and 78.21% for liver, spleen, right kidney, and left kidney segmentation, respectively.",
        "file_path": "paper_data/Deep_Meta-Learning/info/8f338e2bfc051b35ddbfd743d31681187f3618ab.pdf",
        "venue": "Diagnostics",
        "citationCount": 12,
        "score": 12.0,
        "summary": "Deep learning has attained state-of-the-art results in general image segmentation problems; however, it requires a substantial number of annotated images to achieve the desired outcomes. In the medical field, the availability of annotated images is often limited. To address this challenge, few-shot learning techniques have been successfully adapted to rapidly generalize to new tasks with only a few samples, leveraging prior knowledge. In this paper, we employ a gradient-based method known as Model-Agnostic Meta-Learning (MAML) for medical image segmentation. MAML is a meta-learning algorithm that quickly adapts to new tasks by updating a model’s parameters based on a limited set of training samples. Additionally, we use an enhanced 3D U-Net as the foundational network for our models. The enhanced 3D U-Net is a convolutional neural network specifically designed for medical image segmentation. We evaluate our approach on the TotalSegmentator dataset, considering a few annotated images for four tasks: liver, spleen, right kidney, and left kidney. The results demonstrate that our approach facilitates rapid adaptation to new tasks using only a few annotated images. In 10-shot settings, our approach achieved mean dice coefficients of 93.70%, 85.98%, 81.20%, and 89.58% for liver, spleen, right kidney, and left kidney segmentation, respectively. In five-shot sittings, the approach attained mean Dice coefficients of 90.27%, 83.89%, 77.53%, and 87.01% for liver, spleen, right kidney, and left kidney segmentation, respectively. Finally, we assess the effectiveness of our proposed approach on a dataset collected from a local hospital. Employing five-shot sittings, we achieve mean Dice coefficients of 90.62%, 79.86%, 79.87%, and 78.21% for liver, spleen, right kidney, and left kidney segmentation, respectively.",
        "keywords": []
      },
      "file_name": "8f338e2bfc051b35ddbfd743d31681187f3618ab.pdf"
    },
    {
      "success": true,
      "doc_id": "757fcfea3ae6f5099718e1d8e45085f4",
      "summary": "Recent advances in AI-based learning models have significantly increased the accuracy of Automatic Personality Recognition (APR). However, these methods either require training data from the same subject or the meta-information from the training set to learn the personality-related features (i.e., subject-dependency). The variance of feature extraction for different subjects compromises the possibility of designing a dependency-free system for APR. To address this problem, we present an unsupervised multimodal learning framework to infer personality traits from audio, visual, and verbal modalities. Our method both extracts the handcraft features and transfers deep-learning based embeddings from other tasks (e.g., emotion recognition) to recognize personality traits. Since these representations are extracted locally in the time domain, we present an unsupervised temporal aggregation method to aggregate the extracted features over the temporal dimension. We evaluate our method on the ChaLearn dataset, the most widely referenced dataset for APR, using a dependency-free split of the dataset. Our results show that the proposed feature extraction and temporal aggregation modules do not require personality annotations in training but still outperform other state-of-the-art baseline methods. We also address the problem of subject-dependency in the original split of the ChaLearn dataset. The newly proposed split (i.e., data for training, validation, and testing) of the dataset can benefit the community by providing a more accurate method to validate the subject-generalizability of APR algorithms.",
      "intriguing_abstract": "Recent advances in AI-based learning models have significantly increased the accuracy of Automatic Personality Recognition (APR). However, these methods either require training data from the same subject or the meta-information from the training set to learn the personality-related features (i.e., subject-dependency). The variance of feature extraction for different subjects compromises the possibility of designing a dependency-free system for APR. To address this problem, we present an unsupervised multimodal learning framework to infer personality traits from audio, visual, and verbal modalities. Our method both extracts the handcraft features and transfers deep-learning based embeddings from other tasks (e.g., emotion recognition) to recognize personality traits. Since these representations are extracted locally in the time domain, we present an unsupervised temporal aggregation method to aggregate the extracted features over the temporal dimension. We evaluate our method on the ChaLearn dataset, the most widely referenced dataset for APR, using a dependency-free split of the dataset. Our results show that the proposed feature extraction and temporal aggregation modules do not require personality annotations in training but still outperform other state-of-the-art baseline methods. We also address the problem of subject-dependency in the original split of the ChaLearn dataset. The newly proposed split (i.e., data for training, validation, and testing) of the dataset can benefit the community by providing a more accurate method to validate the subject-generalizability of APR algorithms.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/610c416cc6a9007547a4a0b8771bb210d73bc3fa.pdf",
      "citation_key": "ghassemi20241ek",
      "metadata": {
        "title": "Unsupervised Multimodal Learning for Dependency-Free Personality Recognition",
        "authors": [
          "Sina Ghassemi",
          "Tianyi Zhang",
          "Ward van Breda",
          "Antonis Koutsoumpis",
          "J. Oostrom",
          "D. Holtrop",
          "Reinout E. de Vries"
        ],
        "published_date": "2024",
        "abstract": "Recent advances in AI-based learning models have significantly increased the accuracy of Automatic Personality Recognition (APR). However, these methods either require training data from the same subject or the meta-information from the training set to learn the personality-related features (i.e., subject-dependency). The variance of feature extraction for different subjects compromises the possibility of designing a dependency-free system for APR. To address this problem, we present an unsupervised multimodal learning framework to infer personality traits from audio, visual, and verbal modalities. Our method both extracts the handcraft features and transfers deep-learning based embeddings from other tasks (e.g., emotion recognition) to recognize personality traits. Since these representations are extracted locally in the time domain, we present an unsupervised temporal aggregation method to aggregate the extracted features over the temporal dimension. We evaluate our method on the ChaLearn dataset, the most widely referenced dataset for APR, using a dependency-free split of the dataset. Our results show that the proposed feature extraction and temporal aggregation modules do not require personality annotations in training but still outperform other state-of-the-art baseline methods. We also address the problem of subject-dependency in the original split of the ChaLearn dataset. The newly proposed split (i.e., data for training, validation, and testing) of the dataset can benefit the community by providing a more accurate method to validate the subject-generalizability of APR algorithms.",
        "file_path": "paper_data/Deep_Meta-Learning/info/610c416cc6a9007547a4a0b8771bb210d73bc3fa.pdf",
        "venue": "IEEE Transactions on Affective Computing",
        "citationCount": 11,
        "score": 11.0,
        "summary": "Recent advances in AI-based learning models have significantly increased the accuracy of Automatic Personality Recognition (APR). However, these methods either require training data from the same subject or the meta-information from the training set to learn the personality-related features (i.e., subject-dependency). The variance of feature extraction for different subjects compromises the possibility of designing a dependency-free system for APR. To address this problem, we present an unsupervised multimodal learning framework to infer personality traits from audio, visual, and verbal modalities. Our method both extracts the handcraft features and transfers deep-learning based embeddings from other tasks (e.g., emotion recognition) to recognize personality traits. Since these representations are extracted locally in the time domain, we present an unsupervised temporal aggregation method to aggregate the extracted features over the temporal dimension. We evaluate our method on the ChaLearn dataset, the most widely referenced dataset for APR, using a dependency-free split of the dataset. Our results show that the proposed feature extraction and temporal aggregation modules do not require personality annotations in training but still outperform other state-of-the-art baseline methods. We also address the problem of subject-dependency in the original split of the ChaLearn dataset. The newly proposed split (i.e., data for training, validation, and testing) of the dataset can benefit the community by providing a more accurate method to validate the subject-generalizability of APR algorithms.",
        "keywords": []
      },
      "file_name": "610c416cc6a9007547a4a0b8771bb210d73bc3fa.pdf"
    },
    {
      "success": true,
      "doc_id": "ace05f18fe2b869312185e8917da55ce",
      "summary": "A data-driven integrated active fault-tolerant control (IAFT) strategy for controlling the solid oxide fuel cell (SOFC) output voltage is proposed, which maintains satisfactory dynamic performance and eliminates constraint violations in the event of system failure. In addition, this article introduces an efficient replay deep meta-deterministic policy gradient (ER-DMDPG) for IAFTs, which combines priority experience replay and meta-learning techniques to improve the robustness and multitask cooperative learning capability of the IAFTs. The algorithm combines the controllers of the fuel reformer and direct current-direct current (dc-dc) converter into a single independent agent, which is trained by a cooperative meta-learner and a base learner to achieve multiobjective optimal active fault-tolerant control (FTC). It is experimentally demonstrated that the proposed method can maintain better dynamic performance and prevent constraint violations of fuel utilization across a wide range of working conditions.",
      "intriguing_abstract": "A data-driven integrated active fault-tolerant control (IAFT) strategy for controlling the solid oxide fuel cell (SOFC) output voltage is proposed, which maintains satisfactory dynamic performance and eliminates constraint violations in the event of system failure. In addition, this article introduces an efficient replay deep meta-deterministic policy gradient (ER-DMDPG) for IAFTs, which combines priority experience replay and meta-learning techniques to improve the robustness and multitask cooperative learning capability of the IAFTs. The algorithm combines the controllers of the fuel reformer and direct current-direct current (dc-dc) converter into a single independent agent, which is trained by a cooperative meta-learner and a base learner to achieve multiobjective optimal active fault-tolerant control (FTC). It is experimentally demonstrated that the proposed method can maintain better dynamic performance and prevent constraint violations of fuel utilization across a wide range of working conditions.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/34fb233e68187fe8e9d3ca017137ad0914993270.pdf",
      "citation_key": "li20254kd",
      "metadata": {
        "title": "Efficient Replay Deep Meta-Reinforcement Learning for Active Fault-Tolerant Control of Solid Oxide Fuel Cell Systems Considering Multivariable Coordination",
        "authors": [
          "Jiawen Li",
          "Tao Zhou"
        ],
        "published_date": "2025",
        "abstract": "A data-driven integrated active fault-tolerant control (IAFT) strategy for controlling the solid oxide fuel cell (SOFC) output voltage is proposed, which maintains satisfactory dynamic performance and eliminates constraint violations in the event of system failure. In addition, this article introduces an efficient replay deep meta-deterministic policy gradient (ER-DMDPG) for IAFTs, which combines priority experience replay and meta-learning techniques to improve the robustness and multitask cooperative learning capability of the IAFTs. The algorithm combines the controllers of the fuel reformer and direct current-direct current (dc-dc) converter into a single independent agent, which is trained by a cooperative meta-learner and a base learner to achieve multiobjective optimal active fault-tolerant control (FTC). It is experimentally demonstrated that the proposed method can maintain better dynamic performance and prevent constraint violations of fuel utilization across a wide range of working conditions.",
        "file_path": "paper_data/Deep_Meta-Learning/info/34fb233e68187fe8e9d3ca017137ad0914993270.pdf",
        "venue": "IEEE Transactions on Transportation Electrification",
        "citationCount": 11,
        "score": 11.0,
        "summary": "A data-driven integrated active fault-tolerant control (IAFT) strategy for controlling the solid oxide fuel cell (SOFC) output voltage is proposed, which maintains satisfactory dynamic performance and eliminates constraint violations in the event of system failure. In addition, this article introduces an efficient replay deep meta-deterministic policy gradient (ER-DMDPG) for IAFTs, which combines priority experience replay and meta-learning techniques to improve the robustness and multitask cooperative learning capability of the IAFTs. The algorithm combines the controllers of the fuel reformer and direct current-direct current (dc-dc) converter into a single independent agent, which is trained by a cooperative meta-learner and a base learner to achieve multiobjective optimal active fault-tolerant control (FTC). It is experimentally demonstrated that the proposed method can maintain better dynamic performance and prevent constraint violations of fuel utilization across a wide range of working conditions.",
        "keywords": []
      },
      "file_name": "34fb233e68187fe8e9d3ca017137ad0914993270.pdf"
    },
    {
      "success": true,
      "doc_id": "355153f384a6c0b84a4a8118311604de",
      "summary": "Encrypted Traffic Classification (ETC) is crucial for network security management and Quality of Service (QoS) improvement. There have been many attempts to tackle various ETC tasks, however, which generally suffer from task dependency and limited adaptability, falling short of meeting practical requirements. Under the realistic assumptions of complex network environments, diverse encryption techniques and ever-changing application landscapes coexist. It is highly desirable to learn the generic encrypted traffic representations to investigate the common knowledge across different ETC tasks and rapidly adapt to the dynamic shifts. To fill the gap, we propose MetaRockETC, a generic encrypted traffic classification framework, which extracts protocol-agnostic features to learn the common knowledge and rapidly adapt to novel ETC tasks and evolving network environments. In MetaRockETC, we first model packet length sequences of encrypted sessions as multivariate time series and perform random convolution kernel transformations to summarize discriminatory behavioral patterns across channels. By integrating MetaRockETC into an advanced Model-Agnostic Meta-Learning (MAML) framework, we learn a task-adaptive loss function to facilitate better generalization and transferability across diverse ETC tasks. Extensive experimental results demonstrate the superiority of MetaRockETC in both across-task and few-shot scenarios, highlighting its potential to provide a practical solution for encrypted traffic classification in real-world scenarios.",
      "intriguing_abstract": "Encrypted Traffic Classification (ETC) is crucial for network security management and Quality of Service (QoS) improvement. There have been many attempts to tackle various ETC tasks, however, which generally suffer from task dependency and limited adaptability, falling short of meeting practical requirements. Under the realistic assumptions of complex network environments, diverse encryption techniques and ever-changing application landscapes coexist. It is highly desirable to learn the generic encrypted traffic representations to investigate the common knowledge across different ETC tasks and rapidly adapt to the dynamic shifts. To fill the gap, we propose MetaRockETC, a generic encrypted traffic classification framework, which extracts protocol-agnostic features to learn the common knowledge and rapidly adapt to novel ETC tasks and evolving network environments. In MetaRockETC, we first model packet length sequences of encrypted sessions as multivariate time series and perform random convolution kernel transformations to summarize discriminatory behavioral patterns across channels. By integrating MetaRockETC into an advanced Model-Agnostic Meta-Learning (MAML) framework, we learn a task-adaptive loss function to facilitate better generalization and transferability across diverse ETC tasks. Extensive experimental results demonstrate the superiority of MetaRockETC in both across-task and few-shot scenarios, highlighting its potential to provide a practical solution for encrypted traffic classification in real-world scenarios.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/9adc67e027edfea39a7904d96f7d436cd3ec3dff.pdf",
      "citation_key": "zhao202420b",
      "metadata": {
        "title": "MetaRockETC: Adaptive Encrypted Traffic Classification in Complex Network Environments via Time Series Analysis and Meta-Learning",
        "authors": [
          "Jianjin Zhao",
          "Qi Li",
          "Yueping Hong",
          "Meng Shen"
        ],
        "published_date": "2024",
        "abstract": "Encrypted Traffic Classification (ETC) is crucial for network security management and Quality of Service (QoS) improvement. There have been many attempts to tackle various ETC tasks, however, which generally suffer from task dependency and limited adaptability, falling short of meeting practical requirements. Under the realistic assumptions of complex network environments, diverse encryption techniques and ever-changing application landscapes coexist. It is highly desirable to learn the generic encrypted traffic representations to investigate the common knowledge across different ETC tasks and rapidly adapt to the dynamic shifts. To fill the gap, we propose MetaRockETC, a generic encrypted traffic classification framework, which extracts protocol-agnostic features to learn the common knowledge and rapidly adapt to novel ETC tasks and evolving network environments. In MetaRockETC, we first model packet length sequences of encrypted sessions as multivariate time series and perform random convolution kernel transformations to summarize discriminatory behavioral patterns across channels. By integrating MetaRockETC into an advanced Model-Agnostic Meta-Learning (MAML) framework, we learn a task-adaptive loss function to facilitate better generalization and transferability across diverse ETC tasks. Extensive experimental results demonstrate the superiority of MetaRockETC in both across-task and few-shot scenarios, highlighting its potential to provide a practical solution for encrypted traffic classification in real-world scenarios.",
        "file_path": "paper_data/Deep_Meta-Learning/info/9adc67e027edfea39a7904d96f7d436cd3ec3dff.pdf",
        "venue": "IEEE Transactions on Network and Service Management",
        "citationCount": 11,
        "score": 11.0,
        "summary": "Encrypted Traffic Classification (ETC) is crucial for network security management and Quality of Service (QoS) improvement. There have been many attempts to tackle various ETC tasks, however, which generally suffer from task dependency and limited adaptability, falling short of meeting practical requirements. Under the realistic assumptions of complex network environments, diverse encryption techniques and ever-changing application landscapes coexist. It is highly desirable to learn the generic encrypted traffic representations to investigate the common knowledge across different ETC tasks and rapidly adapt to the dynamic shifts. To fill the gap, we propose MetaRockETC, a generic encrypted traffic classification framework, which extracts protocol-agnostic features to learn the common knowledge and rapidly adapt to novel ETC tasks and evolving network environments. In MetaRockETC, we first model packet length sequences of encrypted sessions as multivariate time series and perform random convolution kernel transformations to summarize discriminatory behavioral patterns across channels. By integrating MetaRockETC into an advanced Model-Agnostic Meta-Learning (MAML) framework, we learn a task-adaptive loss function to facilitate better generalization and transferability across diverse ETC tasks. Extensive experimental results demonstrate the superiority of MetaRockETC in both across-task and few-shot scenarios, highlighting its potential to provide a practical solution for encrypted traffic classification in real-world scenarios.",
        "keywords": []
      },
      "file_name": "9adc67e027edfea39a7904d96f7d436cd3ec3dff.pdf"
    },
    {
      "success": true,
      "doc_id": "2faf7f1fd4faa792b8ca201a8dbfa277",
      "summary": "Despite providing high-performance solutions for computer vision tasks, the deep neural network (DNN) model has been proved to be extremely vulnerable to adversarial attacks. Current defense mainly focuses on the known attacks, but the adversarial robustness to the unknown attacks is seriously overlooked. Besides, commonly used adaptive learning and fine-tuning technique is unsuitable for adversarial defense since it is essentially a zero-shot problem when deployed. Thus, to tackle this challenge, we propose an attack-agnostic defense method named Meta Invariance Defense (MID). Specifically, various combinations of adversarial attacks are randomly sampled from a manually constructed Attacker Pool to constitute different defense tasks against unknown attacks, in which a student encoder is supervised by multi-consistency distillation to learn the attack-invariant features via a meta principle. The proposed MID has two merits: 1) Full distillation from pixel-, feature- and prediction-level between benign and adversarial samples facilitates the discovery of attack-invariance. 2) The model simultaneously achieves robustness to the imperceptible adversarial perturbations in high-level image classification and attack-suppression in low-level robust image regeneration. Theoretical and empirical studies on numerous benchmarks such as ImageNet verify the generalizable robustness and superiority of MID under various attacks.",
      "intriguing_abstract": "Despite providing high-performance solutions for computer vision tasks, the deep neural network (DNN) model has been proved to be extremely vulnerable to adversarial attacks. Current defense mainly focuses on the known attacks, but the adversarial robustness to the unknown attacks is seriously overlooked. Besides, commonly used adaptive learning and fine-tuning technique is unsuitable for adversarial defense since it is essentially a zero-shot problem when deployed. Thus, to tackle this challenge, we propose an attack-agnostic defense method named Meta Invariance Defense (MID). Specifically, various combinations of adversarial attacks are randomly sampled from a manually constructed Attacker Pool to constitute different defense tasks against unknown attacks, in which a student encoder is supervised by multi-consistency distillation to learn the attack-invariant features via a meta principle. The proposed MID has two merits: 1) Full distillation from pixel-, feature- and prediction-level between benign and adversarial samples facilitates the discovery of attack-invariance. 2) The model simultaneously achieves robustness to the imperceptible adversarial perturbations in high-level image classification and attack-suppression in low-level robust image regeneration. Theoretical and empirical studies on numerous benchmarks such as ImageNet verify the generalizable robustness and superiority of MID under various attacks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/27e13096c66a52de889573cdb4e6f2649782d995.pdf",
      "citation_key": "zhang2024xg0",
      "metadata": {
        "title": "Meta Invariance Defense Towards Generalizable Robustness to Unknown Adversarial Attacks",
        "authors": [
          "Lei Zhang",
          "Yuhang Zhou",
          "Yi Yang",
          "Xinbo Gao"
        ],
        "published_date": "2024",
        "abstract": "Despite providing high-performance solutions for computer vision tasks, the deep neural network (DNN) model has been proved to be extremely vulnerable to adversarial attacks. Current defense mainly focuses on the known attacks, but the adversarial robustness to the unknown attacks is seriously overlooked. Besides, commonly used adaptive learning and fine-tuning technique is unsuitable for adversarial defense since it is essentially a zero-shot problem when deployed. Thus, to tackle this challenge, we propose an attack-agnostic defense method named Meta Invariance Defense (MID). Specifically, various combinations of adversarial attacks are randomly sampled from a manually constructed Attacker Pool to constitute different defense tasks against unknown attacks, in which a student encoder is supervised by multi-consistency distillation to learn the attack-invariant features via a meta principle. The proposed MID has two merits: 1) Full distillation from pixel-, feature- and prediction-level between benign and adversarial samples facilitates the discovery of attack-invariance. 2) The model simultaneously achieves robustness to the imperceptible adversarial perturbations in high-level image classification and attack-suppression in low-level robust image regeneration. Theoretical and empirical studies on numerous benchmarks such as ImageNet verify the generalizable robustness and superiority of MID under various attacks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/27e13096c66a52de889573cdb4e6f2649782d995.pdf",
        "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "citationCount": 10,
        "score": 10.0,
        "summary": "Despite providing high-performance solutions for computer vision tasks, the deep neural network (DNN) model has been proved to be extremely vulnerable to adversarial attacks. Current defense mainly focuses on the known attacks, but the adversarial robustness to the unknown attacks is seriously overlooked. Besides, commonly used adaptive learning and fine-tuning technique is unsuitable for adversarial defense since it is essentially a zero-shot problem when deployed. Thus, to tackle this challenge, we propose an attack-agnostic defense method named Meta Invariance Defense (MID). Specifically, various combinations of adversarial attacks are randomly sampled from a manually constructed Attacker Pool to constitute different defense tasks against unknown attacks, in which a student encoder is supervised by multi-consistency distillation to learn the attack-invariant features via a meta principle. The proposed MID has two merits: 1) Full distillation from pixel-, feature- and prediction-level between benign and adversarial samples facilitates the discovery of attack-invariance. 2) The model simultaneously achieves robustness to the imperceptible adversarial perturbations in high-level image classification and attack-suppression in low-level robust image regeneration. Theoretical and empirical studies on numerous benchmarks such as ImageNet verify the generalizable robustness and superiority of MID under various attacks.",
        "keywords": []
      },
      "file_name": "27e13096c66a52de889573cdb4e6f2649782d995.pdf"
    },
    {
      "success": true,
      "doc_id": "7269ac94f5f4b16bffc8831fb70bde23",
      "summary": "Earth scientists study a variety of problems with remote sensing data, but they most often consider them in isolation from each other, which limits information flows across disciplines. In this work, we present METEOR, a meta-learning methodology for Earth observation problems across different resolutions. METEOR is an adaptive deep meta-learning model with several modifications that allow it to ingest images with a variable number of spectral channels and to predict a varying number of classes per downstream task. It uses knowledge mined from land cover information worldwide to adapt to new unseen target problems with few training examples. METEOR outperforms competing self-supervised approaches on five downstream tasks, showing its relevance to addressing novel and impactful geospatial problems with only a handful of labels.",
      "intriguing_abstract": "Earth scientists study a variety of problems with remote sensing data, but they most often consider them in isolation from each other, which limits information flows across disciplines. In this work, we present METEOR, a meta-learning methodology for Earth observation problems across different resolutions. METEOR is an adaptive deep meta-learning model with several modifications that allow it to ingest images with a variable number of spectral channels and to predict a varying number of classes per downstream task. It uses knowledge mined from land cover information worldwide to adapt to new unseen target problems with few training examples. METEOR outperforms competing self-supervised approaches on five downstream tasks, showing its relevance to addressing novel and impactful geospatial problems with only a handful of labels.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/ccdc15a014009d0b4d7f411b3708fb44c562bcff.pdf",
      "citation_key": "ruwurm2024806",
      "metadata": {
        "title": "Meta-learning to address diverse Earth observation problems across resolutions",
        "authors": [
          "Marc Rußwurm",
          "Sherrie Wang",
          "B. Kellenberger",
          "R. Roscher",
          "D. Tuia"
        ],
        "published_date": "2024",
        "abstract": "Earth scientists study a variety of problems with remote sensing data, but they most often consider them in isolation from each other, which limits information flows across disciplines. In this work, we present METEOR, a meta-learning methodology for Earth observation problems across different resolutions. METEOR is an adaptive deep meta-learning model with several modifications that allow it to ingest images with a variable number of spectral channels and to predict a varying number of classes per downstream task. It uses knowledge mined from land cover information worldwide to adapt to new unseen target problems with few training examples. METEOR outperforms competing self-supervised approaches on five downstream tasks, showing its relevance to addressing novel and impactful geospatial problems with only a handful of labels.",
        "file_path": "paper_data/Deep_Meta-Learning/info/ccdc15a014009d0b4d7f411b3708fb44c562bcff.pdf",
        "venue": "Communications Earth &amp; Environment",
        "citationCount": 10,
        "score": 10.0,
        "summary": "Earth scientists study a variety of problems with remote sensing data, but they most often consider them in isolation from each other, which limits information flows across disciplines. In this work, we present METEOR, a meta-learning methodology for Earth observation problems across different resolutions. METEOR is an adaptive deep meta-learning model with several modifications that allow it to ingest images with a variable number of spectral channels and to predict a varying number of classes per downstream task. It uses knowledge mined from land cover information worldwide to adapt to new unseen target problems with few training examples. METEOR outperforms competing self-supervised approaches on five downstream tasks, showing its relevance to addressing novel and impactful geospatial problems with only a handful of labels.",
        "keywords": []
      },
      "file_name": "ccdc15a014009d0b4d7f411b3708fb44c562bcff.pdf"
    },
    {
      "success": true,
      "doc_id": "cd5ce1be9e9e53984e57ac220bc61fbc",
      "summary": "Recent advances in deep learning (DL) have led many contemporary automatic modulation classification (AMC) techniques to use deep networks in classifying the modulation type of incoming signals at the receiver. However, current DL-based methods face scalability challenges, particularly when encountering unseen modulations or input signals from environments not present during model training, making them less suitable for real-world applications like software-defined radio devices. In this paper, we introduce a scalable AMC scheme that provides flexibility for new modulations and adaptability to input signals with diverse configurations. We propose the Meta-Transformer, a meta-learning framework based on few-shot learning (FSL) to acquire general knowledge and a learning method for AMC tasks. This approach empowers the model to identify new unseen modulations using only a very small number of samples, eliminating the need for complete model retraining. Furthermore, we enhance the scalability of the classifier by leveraging main-sub transformer-based encoders, enabling efficient processing of input signals with diverse setups. Extensive evaluations demonstrate that the proposed AMC method outperforms existing techniques across all signal-to-noise ratios (SNRs) on RadioML2018.01A. The source code and pre-trained models are released at https://github.com/cheeseBG/meta-transformer-amc.",
      "intriguing_abstract": "Recent advances in deep learning (DL) have led many contemporary automatic modulation classification (AMC) techniques to use deep networks in classifying the modulation type of incoming signals at the receiver. However, current DL-based methods face scalability challenges, particularly when encountering unseen modulations or input signals from environments not present during model training, making them less suitable for real-world applications like software-defined radio devices. In this paper, we introduce a scalable AMC scheme that provides flexibility for new modulations and adaptability to input signals with diverse configurations. We propose the Meta-Transformer, a meta-learning framework based on few-shot learning (FSL) to acquire general knowledge and a learning method for AMC tasks. This approach empowers the model to identify new unseen modulations using only a very small number of samples, eliminating the need for complete model retraining. Furthermore, we enhance the scalability of the classifier by leveraging main-sub transformer-based encoders, enabling efficient processing of input signals with diverse setups. Extensive evaluations demonstrate that the proposed AMC method outperforms existing techniques across all signal-to-noise ratios (SNRs) on RadioML2018.01A. The source code and pre-trained models are released at https://github.com/cheeseBG/meta-transformer-amc.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d404afdbe65110393771e6eff571491444a910ab.pdf",
      "citation_key": "jang2024pyi",
      "metadata": {
        "title": "Meta-Transformer: A Meta-Learning Framework for Scalable Automatic Modulation Classification",
        "authors": [
          "Jungik Jang",
          "Jisung Pyo",
          "Young-il Yoon",
          "Jaehyuk Choi"
        ],
        "published_date": "2024",
        "abstract": "Recent advances in deep learning (DL) have led many contemporary automatic modulation classification (AMC) techniques to use deep networks in classifying the modulation type of incoming signals at the receiver. However, current DL-based methods face scalability challenges, particularly when encountering unseen modulations or input signals from environments not present during model training, making them less suitable for real-world applications like software-defined radio devices. In this paper, we introduce a scalable AMC scheme that provides flexibility for new modulations and adaptability to input signals with diverse configurations. We propose the Meta-Transformer, a meta-learning framework based on few-shot learning (FSL) to acquire general knowledge and a learning method for AMC tasks. This approach empowers the model to identify new unseen modulations using only a very small number of samples, eliminating the need for complete model retraining. Furthermore, we enhance the scalability of the classifier by leveraging main-sub transformer-based encoders, enabling efficient processing of input signals with diverse setups. Extensive evaluations demonstrate that the proposed AMC method outperforms existing techniques across all signal-to-noise ratios (SNRs) on RadioML2018.01A. The source code and pre-trained models are released at https://github.com/cheeseBG/meta-transformer-amc.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d404afdbe65110393771e6eff571491444a910ab.pdf",
        "venue": "IEEE Access",
        "citationCount": 10,
        "score": 10.0,
        "summary": "Recent advances in deep learning (DL) have led many contemporary automatic modulation classification (AMC) techniques to use deep networks in classifying the modulation type of incoming signals at the receiver. However, current DL-based methods face scalability challenges, particularly when encountering unseen modulations or input signals from environments not present during model training, making them less suitable for real-world applications like software-defined radio devices. In this paper, we introduce a scalable AMC scheme that provides flexibility for new modulations and adaptability to input signals with diverse configurations. We propose the Meta-Transformer, a meta-learning framework based on few-shot learning (FSL) to acquire general knowledge and a learning method for AMC tasks. This approach empowers the model to identify new unseen modulations using only a very small number of samples, eliminating the need for complete model retraining. Furthermore, we enhance the scalability of the classifier by leveraging main-sub transformer-based encoders, enabling efficient processing of input signals with diverse setups. Extensive evaluations demonstrate that the proposed AMC method outperforms existing techniques across all signal-to-noise ratios (SNRs) on RadioML2018.01A. The source code and pre-trained models are released at https://github.com/cheeseBG/meta-transformer-amc.",
        "keywords": []
      },
      "file_name": "d404afdbe65110393771e6eff571491444a910ab.pdf"
    },
    {
      "success": true,
      "doc_id": "303f84695ce57e4df7140977e73aa3b7",
      "summary": "Recently, deep learning has made brilliant achievements in wind turbine bearing fault diagnosis field. However, there are two problems that cannot be ignored: 1) the fault data are so scarce that it is time-consuming to acquire a well-behaved deep learning model and 2) much unlabeled data cannot be adequately utilized to explore useful fault information without prior. Therefore, a novel semi-supervised temporal meta-learning (SSTML) method is proposed, which can not only probe representative deep features from massive raw unlabeled vibration data adequately but also make the best of small annotation data to complete fault identification tasks. Transplanting meta-learning ideas into semi-supervised learning (SSL), a novel deep learning framework—SeMeF—is proposed. The proposed SeMeF is capable of drawing on the advantages of two mechanisms to exert efficiency beyond themselves. Furthermore, a temporal convolutional module is proposed to relieve overfitting due to the depth of the model, which can fully excavate temporal features along the depth of the network. The superiority of the proposed method is demonstrated on the wind turbine bearing dataset. Experimental results indicate that the model proposed can reach high diagnostic accuracy with limited annotation data, which outperforms many advanced deep learning models.",
      "intriguing_abstract": "Recently, deep learning has made brilliant achievements in wind turbine bearing fault diagnosis field. However, there are two problems that cannot be ignored: 1) the fault data are so scarce that it is time-consuming to acquire a well-behaved deep learning model and 2) much unlabeled data cannot be adequately utilized to explore useful fault information without prior. Therefore, a novel semi-supervised temporal meta-learning (SSTML) method is proposed, which can not only probe representative deep features from massive raw unlabeled vibration data adequately but also make the best of small annotation data to complete fault identification tasks. Transplanting meta-learning ideas into semi-supervised learning (SSL), a novel deep learning framework—SeMeF—is proposed. The proposed SeMeF is capable of drawing on the advantages of two mechanisms to exert efficiency beyond themselves. Furthermore, a temporal convolutional module is proposed to relieve overfitting due to the depth of the model, which can fully excavate temporal features along the depth of the network. The superiority of the proposed method is demonstrated on the wind turbine bearing dataset. Experimental results indicate that the model proposed can reach high diagnostic accuracy with limited annotation data, which outperforms many advanced deep learning models.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/4b02a48d5204d2e81794776a68d255d69f6e421e.pdf",
      "citation_key": "su2024h1g",
      "metadata": {
        "title": "Semi-Supervised Temporal Meta-Learning Framework for Wind Turbine Bearing Fault Diagnosis Under Limited Annotation Data",
        "authors": [
          "Hao Su",
          "Qingtao Yao",
          "Ling Xiang",
          "Aijun Hu"
        ],
        "published_date": "2024",
        "abstract": "Recently, deep learning has made brilliant achievements in wind turbine bearing fault diagnosis field. However, there are two problems that cannot be ignored: 1) the fault data are so scarce that it is time-consuming to acquire a well-behaved deep learning model and 2) much unlabeled data cannot be adequately utilized to explore useful fault information without prior. Therefore, a novel semi-supervised temporal meta-learning (SSTML) method is proposed, which can not only probe representative deep features from massive raw unlabeled vibration data adequately but also make the best of small annotation data to complete fault identification tasks. Transplanting meta-learning ideas into semi-supervised learning (SSL), a novel deep learning framework—SeMeF—is proposed. The proposed SeMeF is capable of drawing on the advantages of two mechanisms to exert efficiency beyond themselves. Furthermore, a temporal convolutional module is proposed to relieve overfitting due to the depth of the model, which can fully excavate temporal features along the depth of the network. The superiority of the proposed method is demonstrated on the wind turbine bearing dataset. Experimental results indicate that the model proposed can reach high diagnostic accuracy with limited annotation data, which outperforms many advanced deep learning models.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4b02a48d5204d2e81794776a68d255d69f6e421e.pdf",
        "venue": "IEEE Transactions on Instrumentation and Measurement",
        "citationCount": 10,
        "score": 10.0,
        "summary": "Recently, deep learning has made brilliant achievements in wind turbine bearing fault diagnosis field. However, there are two problems that cannot be ignored: 1) the fault data are so scarce that it is time-consuming to acquire a well-behaved deep learning model and 2) much unlabeled data cannot be adequately utilized to explore useful fault information without prior. Therefore, a novel semi-supervised temporal meta-learning (SSTML) method is proposed, which can not only probe representative deep features from massive raw unlabeled vibration data adequately but also make the best of small annotation data to complete fault identification tasks. Transplanting meta-learning ideas into semi-supervised learning (SSL), a novel deep learning framework—SeMeF—is proposed. The proposed SeMeF is capable of drawing on the advantages of two mechanisms to exert efficiency beyond themselves. Furthermore, a temporal convolutional module is proposed to relieve overfitting due to the depth of the model, which can fully excavate temporal features along the depth of the network. The superiority of the proposed method is demonstrated on the wind turbine bearing dataset. Experimental results indicate that the model proposed can reach high diagnostic accuracy with limited annotation data, which outperforms many advanced deep learning models.",
        "keywords": []
      },
      "file_name": "4b02a48d5204d2e81794776a68d255d69f6e421e.pdf"
    },
    {
      "success": true,
      "doc_id": "8cfe4e99fd1435fd717bf161b1f93e12",
      "summary": "With the emergence of smartphones, Android has become a widely used mobile operating system. However, it is vulnerable when encountering various types of attacks. Every day, new malware threatens the security of users’ devices and private data. Many methods have been proposed to classify malicious applications, utilizing static or dynamic analysis for classification. However, previous methods still suffer from unsatisfactory performance due to two challenges. First, they are unable to address the imbalanced data distribution problem, leading to poor performance for malware families with few members. Second, they are unable to address the zero-day malware (zero-day malware refers to malicious applications that exploit unknown vulnerabilities) classification problem. In this article, we introduce an innovative meta-learning approach for multi-family Android malware classification named Meta-MAMC, which uses meta-learning technology to learn meta-knowledge (i.e., the similarities and differences among different malware families) of few-family samples and combines new sampling algorithms to solve the above challenges. Meta-MAMC integrates (i) the meta-knowledge contained within the dataset to guide models in learning to identify unknown malware; and (ii) more accurate and diverse tasks based on novel sampling strategies, as well as directly adapting meta-learning to a new few-sample and zero-sample task to classify families. We have evaluated Meta-MAMC on two popular datasets and a corpus of real-world Android applications. The results demonstrate its efficacy in accurately classifying malicious applications belonging to certain malware families, even achieving 100% classification in some families.",
      "intriguing_abstract": "With the emergence of smartphones, Android has become a widely used mobile operating system. However, it is vulnerable when encountering various types of attacks. Every day, new malware threatens the security of users’ devices and private data. Many methods have been proposed to classify malicious applications, utilizing static or dynamic analysis for classification. However, previous methods still suffer from unsatisfactory performance due to two challenges. First, they are unable to address the imbalanced data distribution problem, leading to poor performance for malware families with few members. Second, they are unable to address the zero-day malware (zero-day malware refers to malicious applications that exploit unknown vulnerabilities) classification problem. In this article, we introduce an innovative meta-learning approach for multi-family Android malware classification named Meta-MAMC, which uses meta-learning technology to learn meta-knowledge (i.e., the similarities and differences among different malware families) of few-family samples and combines new sampling algorithms to solve the above challenges. Meta-MAMC integrates (i) the meta-knowledge contained within the dataset to guide models in learning to identify unknown malware; and (ii) more accurate and diverse tasks based on novel sampling strategies, as well as directly adapting meta-learning to a new few-sample and zero-sample task to classify families. We have evaluated Meta-MAMC on two popular datasets and a corpus of real-world Android applications. The results demonstrate its efficacy in accurately classifying malicious applications belonging to certain malware families, even achieving 100% classification in some families.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/7d0216a7331ee4031fe488c8ff1da2adfcc59a0c.pdf",
      "citation_key": "li20246zp",
      "metadata": {
        "title": "Meta-Learning for Multi-Family Android Malware Classification",
        "authors": [
          "Yao Li",
          "Dawei Yuan",
          "Tao Zhang",
          "Haipeng Cai",
          "David Lo",
          "Cuiyun Gao",
          "Xiapu Luo",
          "He Jiang"
        ],
        "published_date": "2024",
        "abstract": "With the emergence of smartphones, Android has become a widely used mobile operating system. However, it is vulnerable when encountering various types of attacks. Every day, new malware threatens the security of users’ devices and private data. Many methods have been proposed to classify malicious applications, utilizing static or dynamic analysis for classification. However, previous methods still suffer from unsatisfactory performance due to two challenges. First, they are unable to address the imbalanced data distribution problem, leading to poor performance for malware families with few members. Second, they are unable to address the zero-day malware (zero-day malware refers to malicious applications that exploit unknown vulnerabilities) classification problem. In this article, we introduce an innovative meta-learning approach for multi-family Android malware classification named Meta-MAMC, which uses meta-learning technology to learn meta-knowledge (i.e., the similarities and differences among different malware families) of few-family samples and combines new sampling algorithms to solve the above challenges. Meta-MAMC integrates (i) the meta-knowledge contained within the dataset to guide models in learning to identify unknown malware; and (ii) more accurate and diverse tasks based on novel sampling strategies, as well as directly adapting meta-learning to a new few-sample and zero-sample task to classify families. We have evaluated Meta-MAMC on two popular datasets and a corpus of real-world Android applications. The results demonstrate its efficacy in accurately classifying malicious applications belonging to certain malware families, even achieving 100% classification in some families.",
        "file_path": "paper_data/Deep_Meta-Learning/info/7d0216a7331ee4031fe488c8ff1da2adfcc59a0c.pdf",
        "venue": "ACM Transactions on Software Engineering and Methodology",
        "citationCount": 9,
        "score": 9.0,
        "summary": "With the emergence of smartphones, Android has become a widely used mobile operating system. However, it is vulnerable when encountering various types of attacks. Every day, new malware threatens the security of users’ devices and private data. Many methods have been proposed to classify malicious applications, utilizing static or dynamic analysis for classification. However, previous methods still suffer from unsatisfactory performance due to two challenges. First, they are unable to address the imbalanced data distribution problem, leading to poor performance for malware families with few members. Second, they are unable to address the zero-day malware (zero-day malware refers to malicious applications that exploit unknown vulnerabilities) classification problem. In this article, we introduce an innovative meta-learning approach for multi-family Android malware classification named Meta-MAMC, which uses meta-learning technology to learn meta-knowledge (i.e., the similarities and differences among different malware families) of few-family samples and combines new sampling algorithms to solve the above challenges. Meta-MAMC integrates (i) the meta-knowledge contained within the dataset to guide models in learning to identify unknown malware; and (ii) more accurate and diverse tasks based on novel sampling strategies, as well as directly adapting meta-learning to a new few-sample and zero-sample task to classify families. We have evaluated Meta-MAMC on two popular datasets and a corpus of real-world Android applications. The results demonstrate its efficacy in accurately classifying malicious applications belonging to certain malware families, even achieving 100% classification in some families.",
        "keywords": []
      },
      "file_name": "7d0216a7331ee4031fe488c8ff1da2adfcc59a0c.pdf"
    },
    {
      "success": true,
      "doc_id": "64dd77771b1ba8585c2c950e53d4ac77",
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of controlling off-road vehicles due to complex, dynamic, and difficult-to-model interactions with diverse terrains, particularly phenomena like slippage. Existing models (first-principles, kinematic) are insufficient to capture these dynamics, especially at performance boundaries or under non-uniform resistive forces.\n    *   **Importance and Challenge:** Reliable autonomous ground vehicle (AGV) operation in rugged environments (e.g., agriculture, search and rescue, planetary exploration) necessitates real-time adaptation to terrain. Slippage significantly degrades performance and can halt missions (e.g., Opportunity rover). Learning unmodeled dynamics from limited vehicle states is ill-posed, making visual information crucial. However, prior visual methods (e.g., segmentation-based) are too coarse, as terrains have infinite subcategories and similar appearances can induce different dynamic behaviors.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds on meta-learning (e.g., MAML, MOCA, DAIML/Neural-Fly) for rapid adaptation and composite adaptive control for online parameter estimation and tracking-error compensation. It also leverages Visual Foundation Models (VFMs) like DINOv2, which are self-supervised, robust, and generalize well for visual feature extraction.\n    *   **Limitations of Previous Solutions:** Kinematic models fail to capture complex ground dynamics or disturbances. Vision-based reinforcement learning (VRL) often lacks interpretability, safety, and robustness guarantees. Prior visual terrain categorization is insufficient for the nuanced dynamics of off-road environments. While meta-learning and adaptive control have been applied to ground vehicles, incorporating a *suitable terrain model that fits the adaptive control framework* with theoretical guarantees, especially using rich visual information, remains an open research area. This work is presented as a generalization and improvement of prior adaptive control methods (e.g., \\cite{lupu20249p4} references [27]) by integrating visual information and enhancing stability results.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** \\cite{lupu20249p4} introduces MAGICVFM, an approach that integrates a Visual Foundation Model (VFM) with an offline meta-learning algorithm and composite adaptive control.\n        1.  **VFM for Feature Extraction:** A pre-trained VFM processes terrain images to synthesize relevant visual features.\n        2.  **DNN for Residual Dynamics:** These VFM features, combined with the vehicle's internal state, are fed into a Deep Neural Network (DNN) that estimates the current actuation matrix, representing residual dynamics and disturbances.\n        3.  **Offline Meta-learning:** An offline meta-learning algorithm trains this DNN using continuous trajectory data, learning the terrain disturbance as a function of visual information and vehicle states.\n        4.  **Online Composite Adaptive Control:** A composite adaptive controller modifies the *last layer* of the DNN in real-time. These linear parameters, adapted online, are terrain-independent but encapsulate remaining disturbances not captured during offline training, enabling real-time adaptation to new terrain and vehicle conditions.\n    *   **Novelty/Difference:** This is presented as the first stable learning-based adaptive controller that incorporates visual foundation models for real-time terrain adaptation. Its novelty lies in the seamless integration of VFM-derived visual features directly into the control influence matrix adaptation within a theoretically grounded adaptive control framework, providing mathematical guarantees for stability and robustness.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   MAGICVFM: An offline meta-learning algorithm to construct a rapidly-tunable model of residual dynamics and disturbances using VFM features and vehicle states.\n        *   A novel online adaptation algorithm based on composite adaptive control that specifically modifies the last layer of the DNN.\n        *   A new control influence matrix adaptation method that leverages visual information.\n    *   **System Design/Architectural Innovations:** The proposed architecture integrates a pre-trained VFM for real-time visual feature extraction, feeding into a DNN whose final layer is dynamically adapted by a composite adaptive controller.\n    *   **Theoretical Insights/Analysis:** \\cite{lupu20249p4} provides mathematical guarantees of exponential stability and robustness against model errors for the adaptive controller, which incorporates both visual and state inputs. It also develops a position, attitude, and velocity tracking control formulation capable of handling various real-time perturbations, including unknown time-varying track/motor degradation and arbitrary time-varying disturbances.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** The method's effectiveness was validated through both simulations and hardware experiments. Hardware tests were performed on two heterogeneous robotic platforms: a tracked vehicle and a car-like robot. Experiments were conducted outdoors on different slopes with varying slippage and under actuator degradation disturbances (e.g., track degradation).\n    *   **Key Performance Metrics and Comparison Results:** The method was compared against a baseline adaptive controller that *did not* utilize VFM terrain features. \\cite{lupu20249p4} demonstrates significant improvement over this baseline in both hardware experimentation and simulation, indicating enhanced tracking performance and robustness.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The method requires specific hardware: sensors for internal robot state, exteroceptive sensors (cameras), the availability of a pre-trained VFM, and sufficient computational hardware to evaluate the VFM in real-time. It also relies on controllability assumptions for handling perturbations.\n    *   **Scope of Applicability:** MAGICVFM is applicable to any ground vehicle equipped with the specified sensors and computational capabilities, enabling adaptation to complex terrains, varying slippage conditions, and actuator degradation.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{lupu20249p4} significantly advances the technical state-of-the-art by presenting the first stable, learning-based adaptive controller that effectively integrates visual foundation models for real-time terrain adaptation, backed by mathematical guarantees. It addresses a critical gap in accurately modeling and adapting to complex ground interactions for AGVs.\n    *   **Potential Impact on Future Research:** This work provides a robust framework for combining powerful, general-purpose visual perception models (VFMs) with theoretically sound control methods. It paves the way for more reliable and robust autonomous navigation in challenging off-road environments and encourages further research into real-time adaptation to unknown and time-varying disturbances, including both environmental changes and vehicle degradation.",
      "intriguing_abstract": "Navigating rugged, unpredictable off-road terrains presents a formidable challenge for autonomous ground vehicles (AGVs), where complex ground interactions and pervasive slippage defy traditional modeling. Existing kinematic and first-principles models struggle to capture these dynamic phenomena, hindering reliable mission execution. We introduce MAGICVFM, a groundbreaking adaptive control framework that leverages Visual Foundation Models (VFMs) to achieve unprecedented real-time terrain adaptation.\n\nMAGICVFM integrates VFM-derived visual features with an offline meta-learning algorithm and an online composite adaptive controller. This novel architecture uses a Deep Neural Network (DNN) to estimate residual dynamics, with its final layer dynamically adapted in real-time based on visual and vehicle state inputs. This is the first stable learning-based adaptive controller to seamlessly incorporate VFMs for terrain adaptation, providing rigorous mathematical guarantees of exponential stability and robustness against model errors and disturbances. Validated across diverse hardware and challenging outdoor conditions, MAGICVFM significantly enhances tracking performance and resilience against slippage and actuator degradation. This work paves the way for truly robust and reliable autonomous navigation in the most demanding off-road environments.",
      "keywords": [
        "MAGICVFM",
        "Visual Foundation Models (VFMs)",
        "Composite Adaptive Control",
        "Off-road Vehicle Control",
        "Real-time Terrain Adaptation",
        "Slippage Mitigation",
        "Residual Dynamics Estimation",
        "Offline Meta-learning",
        "Online Adaptation",
        "Mathematical Guarantees",
        "Control Influence Matrix Adaptation",
        "Autonomous Ground Vehicles (AGVs)",
        "Hardware Validation"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/205770123d5779da5470ae58cf446bc3e9cfc195.pdf",
      "citation_key": "lupu20249p4",
      "metadata": {
        "title": "MAGICVFM-Meta-Learning Adaptation for Ground Interaction Control With Visual Foundation Models",
        "authors": [
          "E. Lupu",
          "Fengze Xie",
          "James A. Preiss",
          "Jedidiah Alindogan",
          "Matthew Anderson",
          "Soon-Jo Chung"
        ],
        "published_date": "2024",
        "abstract": "Control of off-road vehicles is challenging due to the complex dynamic interactions with the terrain. Accurate modeling of these interactions is important to optimize driving performance, but the relevant physical phenomena, such as slip, are too complex to model from first principles. Therefore, we present an offline meta-learning algorithm to construct a rapidly-tunable model of residual dynamics and disturbances. Our model processes terrain images into features using a visual foundation model (VFM), then maps these features and the vehicle state to an estimate of the current actuation matrix using a deep neural network (DNN). We then combine this model with composite adaptive control to modify the last layer of the DNN in real time, accounting for the remaining terrain interactions not captured during offline training. We provide mathematical guarantees of stability and robustness for our controller, and demonstrate the effectiveness of our method through simulations and hardware experiments with a tracked vehicle and a car-like robot. We evaluate our method outdoors on different slopes with varying slippage and actuator degradation disturbances, and compare against an adaptive controller that does not use the VFM terrain features. We show significant improvement over the baseline in both hardware experimentation and simulation.",
        "file_path": "paper_data/Deep_Meta-Learning/info/205770123d5779da5470ae58cf446bc3e9cfc195.pdf",
        "venue": "IEEE Transactions on robotics",
        "citationCount": 9,
        "score": 9.0,
        "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of controlling off-road vehicles due to complex, dynamic, and difficult-to-model interactions with diverse terrains, particularly phenomena like slippage. Existing models (first-principles, kinematic) are insufficient to capture these dynamics, especially at performance boundaries or under non-uniform resistive forces.\n    *   **Importance and Challenge:** Reliable autonomous ground vehicle (AGV) operation in rugged environments (e.g., agriculture, search and rescue, planetary exploration) necessitates real-time adaptation to terrain. Slippage significantly degrades performance and can halt missions (e.g., Opportunity rover). Learning unmodeled dynamics from limited vehicle states is ill-posed, making visual information crucial. However, prior visual methods (e.g., segmentation-based) are too coarse, as terrains have infinite subcategories and similar appearances can induce different dynamic behaviors.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds on meta-learning (e.g., MAML, MOCA, DAIML/Neural-Fly) for rapid adaptation and composite adaptive control for online parameter estimation and tracking-error compensation. It also leverages Visual Foundation Models (VFMs) like DINOv2, which are self-supervised, robust, and generalize well for visual feature extraction.\n    *   **Limitations of Previous Solutions:** Kinematic models fail to capture complex ground dynamics or disturbances. Vision-based reinforcement learning (VRL) often lacks interpretability, safety, and robustness guarantees. Prior visual terrain categorization is insufficient for the nuanced dynamics of off-road environments. While meta-learning and adaptive control have been applied to ground vehicles, incorporating a *suitable terrain model that fits the adaptive control framework* with theoretical guarantees, especially using rich visual information, remains an open research area. This work is presented as a generalization and improvement of prior adaptive control methods (e.g., \\cite{lupu20249p4} references [27]) by integrating visual information and enhancing stability results.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** \\cite{lupu20249p4} introduces MAGICVFM, an approach that integrates a Visual Foundation Model (VFM) with an offline meta-learning algorithm and composite adaptive control.\n        1.  **VFM for Feature Extraction:** A pre-trained VFM processes terrain images to synthesize relevant visual features.\n        2.  **DNN for Residual Dynamics:** These VFM features, combined with the vehicle's internal state, are fed into a Deep Neural Network (DNN) that estimates the current actuation matrix, representing residual dynamics and disturbances.\n        3.  **Offline Meta-learning:** An offline meta-learning algorithm trains this DNN using continuous trajectory data, learning the terrain disturbance as a function of visual information and vehicle states.\n        4.  **Online Composite Adaptive Control:** A composite adaptive controller modifies the *last layer* of the DNN in real-time. These linear parameters, adapted online, are terrain-independent but encapsulate remaining disturbances not captured during offline training, enabling real-time adaptation to new terrain and vehicle conditions.\n    *   **Novelty/Difference:** This is presented as the first stable learning-based adaptive controller that incorporates visual foundation models for real-time terrain adaptation. Its novelty lies in the seamless integration of VFM-derived visual features directly into the control influence matrix adaptation within a theoretically grounded adaptive control framework, providing mathematical guarantees for stability and robustness.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   MAGICVFM: An offline meta-learning algorithm to construct a rapidly-tunable model of residual dynamics and disturbances using VFM features and vehicle states.\n        *   A novel online adaptation algorithm based on composite adaptive control that specifically modifies the last layer of the DNN.\n        *   A new control influence matrix adaptation method that leverages visual information.\n    *   **System Design/Architectural Innovations:** The proposed architecture integrates a pre-trained VFM for real-time visual feature extraction, feeding into a DNN whose final layer is dynamically adapted by a composite adaptive controller.\n    *   **Theoretical Insights/Analysis:** \\cite{lupu20249p4} provides mathematical guarantees of exponential stability and robustness against model errors for the adaptive controller, which incorporates both visual and state inputs. It also develops a position, attitude, and velocity tracking control formulation capable of handling various real-time perturbations, including unknown time-varying track/motor degradation and arbitrary time-varying disturbances.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** The method's effectiveness was validated through both simulations and hardware experiments. Hardware tests were performed on two heterogeneous robotic platforms: a tracked vehicle and a car-like robot. Experiments were conducted outdoors on different slopes with varying slippage and under actuator degradation disturbances (e.g., track degradation).\n    *   **Key Performance Metrics and Comparison Results:** The method was compared against a baseline adaptive controller that *did not* utilize VFM terrain features. \\cite{lupu20249p4} demonstrates significant improvement over this baseline in both hardware experimentation and simulation, indicating enhanced tracking performance and robustness.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The method requires specific hardware: sensors for internal robot state, exteroceptive sensors (cameras), the availability of a pre-trained VFM, and sufficient computational hardware to evaluate the VFM in real-time. It also relies on controllability assumptions for handling perturbations.\n    *   **Scope of Applicability:** MAGICVFM is applicable to any ground vehicle equipped with the specified sensors and computational capabilities, enabling adaptation to complex terrains, varying slippage conditions, and actuator degradation.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** \\cite{lupu20249p4} significantly advances the technical state-of-the-art by presenting the first stable, learning-based adaptive controller that effectively integrates visual foundation models for real-time terrain adaptation, backed by mathematical guarantees. It addresses a critical gap in accurately modeling and adapting to complex ground interactions for AGVs.\n    *   **Potential Impact on Future Research:** This work provides a robust framework for combining powerful, general-purpose visual perception models (VFMs) with theoretically sound control methods. It paves the way for more reliable and robust autonomous navigation in challenging off-road environments and encourages further research into real-time adaptation to unknown and time-varying disturbances, including both environmental changes and vehicle degradation.",
        "keywords": [
          "MAGICVFM",
          "Visual Foundation Models (VFMs)",
          "Composite Adaptive Control",
          "Off-road Vehicle Control",
          "Real-time Terrain Adaptation",
          "Slippage Mitigation",
          "Residual Dynamics Estimation",
          "Offline Meta-learning",
          "Online Adaptation",
          "Mathematical Guarantees",
          "Control Influence Matrix Adaptation",
          "Autonomous Ground Vehicles (AGVs)",
          "Hardware Validation"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **\"present an offline meta-learning algorithm\"**\n2.  **\"construct a rapidly-tunable model\"**\n3.  **\"our model processes terrain images into features using a visual foundation model (vfm), then maps these features and the vehicle state to an estimate of the current actuation matrix using a deep neural network (dnn).\"**\n4.  **\"combine this model with composite adaptive control\"**\n5.  **\"demonstrate the effectiveness of our method\"**\n6.  **\"evaluate our method outdoors... and compare against an adaptive controller\"**\n7.  **\"show significant improvement over the baseline\"**\n8.  **\"provide mathematical guarantees of stability and robustness for our controller\"**\n\nthe core contribution is the **development and presentation of a new algorithm, model, and control system**. the mathematical guarantees and the empirical evaluations (simulations and hardware experiments) serve to support and validate this new technical contribution. while it has strong theoretical and empirical elements, these are in service of the primary goal of introducing a novel method.\n\ntherefore, the paper is best classified as:\n\n**technical**"
      },
      "file_name": "205770123d5779da5470ae58cf446bc3e9cfc195.pdf"
    },
    {
      "success": true,
      "doc_id": "8182fc13c6b57594764f118341cfa7a6",
      "summary": "Background Advances in high-throughput technologies have originated an ever-increasing availability of omics datasets. The integration of multiple heterogeneous data sources is currently an issue for biology and bioinformatics. Multiple kernel learning (MKL) has shown to be a flexible and valid approach to consider the diverse nature of multi-omics inputs, despite being an underused tool in genomic data mining. Results We provide novel MKL approaches based on different kernel fusion strategies. To learn from the meta-kernel of input kernels, we adapted unsupervised integration algorithms for supervised tasks with support vector machines. We also tested deep learning architectures for kernel fusion and classification. The results show that MKL-based models can outperform more complex, state-of-the-art, supervised multi-omics integrative approaches. Conclusion Multiple kernel learning offers a natural framework for predictive models in multi-omics data. It proved to provide a fast and reliable solution that can compete with and outperform more complex architectures. Our results offer a direction for bio-data mining research, biomarker discovery and further development of methods for heterogeneous data integration. Supplementary Information The online version contains supplementary material available at 10.1186/s13040-024-00406-9.",
      "intriguing_abstract": "Background Advances in high-throughput technologies have originated an ever-increasing availability of omics datasets. The integration of multiple heterogeneous data sources is currently an issue for biology and bioinformatics. Multiple kernel learning (MKL) has shown to be a flexible and valid approach to consider the diverse nature of multi-omics inputs, despite being an underused tool in genomic data mining. Results We provide novel MKL approaches based on different kernel fusion strategies. To learn from the meta-kernel of input kernels, we adapted unsupervised integration algorithms for supervised tasks with support vector machines. We also tested deep learning architectures for kernel fusion and classification. The results show that MKL-based models can outperform more complex, state-of-the-art, supervised multi-omics integrative approaches. Conclusion Multiple kernel learning offers a natural framework for predictive models in multi-omics data. It proved to provide a fast and reliable solution that can compete with and outperform more complex architectures. Our results offer a direction for bio-data mining research, biomarker discovery and further development of methods for heterogeneous data integration. Supplementary Information The online version contains supplementary material available at 10.1186/s13040-024-00406-9.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/88c8e710567d9e4d365944cf239bd304638a5a46.pdf",
      "citation_key": "briscik2024cpd",
      "metadata": {
        "title": "Supervised multiple kernel learning approaches for multi-omics data integration",
        "authors": [
          "Mitja Briscik",
          "Gabriele Tazza",
          "M. Dillies",
          "László Vidács",
          "Sébastien Déjean"
        ],
        "published_date": "2024",
        "abstract": "Background Advances in high-throughput technologies have originated an ever-increasing availability of omics datasets. The integration of multiple heterogeneous data sources is currently an issue for biology and bioinformatics. Multiple kernel learning (MKL) has shown to be a flexible and valid approach to consider the diverse nature of multi-omics inputs, despite being an underused tool in genomic data mining. Results We provide novel MKL approaches based on different kernel fusion strategies. To learn from the meta-kernel of input kernels, we adapted unsupervised integration algorithms for supervised tasks with support vector machines. We also tested deep learning architectures for kernel fusion and classification. The results show that MKL-based models can outperform more complex, state-of-the-art, supervised multi-omics integrative approaches. Conclusion Multiple kernel learning offers a natural framework for predictive models in multi-omics data. It proved to provide a fast and reliable solution that can compete with and outperform more complex architectures. Our results offer a direction for bio-data mining research, biomarker discovery and further development of methods for heterogeneous data integration. Supplementary Information The online version contains supplementary material available at 10.1186/s13040-024-00406-9.",
        "file_path": "paper_data/Deep_Meta-Learning/info/88c8e710567d9e4d365944cf239bd304638a5a46.pdf",
        "venue": "BioData Mining",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Background Advances in high-throughput technologies have originated an ever-increasing availability of omics datasets. The integration of multiple heterogeneous data sources is currently an issue for biology and bioinformatics. Multiple kernel learning (MKL) has shown to be a flexible and valid approach to consider the diverse nature of multi-omics inputs, despite being an underused tool in genomic data mining. Results We provide novel MKL approaches based on different kernel fusion strategies. To learn from the meta-kernel of input kernels, we adapted unsupervised integration algorithms for supervised tasks with support vector machines. We also tested deep learning architectures for kernel fusion and classification. The results show that MKL-based models can outperform more complex, state-of-the-art, supervised multi-omics integrative approaches. Conclusion Multiple kernel learning offers a natural framework for predictive models in multi-omics data. It proved to provide a fast and reliable solution that can compete with and outperform more complex architectures. Our results offer a direction for bio-data mining research, biomarker discovery and further development of methods for heterogeneous data integration. Supplementary Information The online version contains supplementary material available at 10.1186/s13040-024-00406-9.",
        "keywords": []
      },
      "file_name": "88c8e710567d9e4d365944cf239bd304638a5a46.pdf"
    },
    {
      "success": true,
      "doc_id": "c68085d7109ebc2eb01c38231a09f777",
      "summary": "Single-operator learning involves training a deep neural network to learn a specific operator, whereas recent work in multi-operator learning uses an operator embedding structure to train a single neural network on data from multiple operators. Thus, multi-operator learning is capable of predicting a range of operators within one model. In this work, we propose pretraining and fine-tuning strategies for solving PDEs using multi-operator learning. One key aspect is that by increasing the number of families of operators used in pretraining, a PDE foundation model can be fine-tuned to downstream tasks involving new PDEs with a limited number of samples, thus outperforming single operator neural networks. Specifically, a multi-operator learning model pre-trained with data from diverse PDE families can predict unseen operators after fine-tuning with only a limited number of operators from the new family, enabling them to serve as a data-free PDE solver. We also show that the proposed training and fine-tuning method is able to predict new operators in zero-shot prediction without samples. Additionally, we introduce a PDE-agnostic meta-learning algorithm to improve the adaptability of the model to various PDEs by providing a better parameter initialization process. To address the needs of applications with limited computing resources, we explore low-rank adaptation methods that reduce computational costs while enhancing solver accuracy. Lastly, by examining the scaling law with respect to the number of operator families, we establish and highlight its potential for broad adaptation in PDE-solving tasks.",
      "intriguing_abstract": "Single-operator learning involves training a deep neural network to learn a specific operator, whereas recent work in multi-operator learning uses an operator embedding structure to train a single neural network on data from multiple operators. Thus, multi-operator learning is capable of predicting a range of operators within one model. In this work, we propose pretraining and fine-tuning strategies for solving PDEs using multi-operator learning. One key aspect is that by increasing the number of families of operators used in pretraining, a PDE foundation model can be fine-tuned to downstream tasks involving new PDEs with a limited number of samples, thus outperforming single operator neural networks. Specifically, a multi-operator learning model pre-trained with data from diverse PDE families can predict unseen operators after fine-tuning with only a limited number of operators from the new family, enabling them to serve as a data-free PDE solver. We also show that the proposed training and fine-tuning method is able to predict new operators in zero-shot prediction without samples. Additionally, we introduce a PDE-agnostic meta-learning algorithm to improve the adaptability of the model to various PDEs by providing a better parameter initialization process. To address the needs of applications with limited computing resources, we explore low-rank adaptation methods that reduce computational costs while enhancing solver accuracy. Lastly, by examining the scaling law with respect to the number of operator families, we establish and highlight its potential for broad adaptation in PDE-solving tasks.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b237deb6c0234378238a6ee49b229b1299b7efe6.pdf",
      "citation_key": "sun2024kbv",
      "metadata": {
        "title": "LeMON: Learning to Learn Multi-Operator Networks",
        "authors": [
          "Jingmin Sun",
          "Zecheng Zhang",
          "Hayden Schaeffer"
        ],
        "published_date": "2024",
        "abstract": "Single-operator learning involves training a deep neural network to learn a specific operator, whereas recent work in multi-operator learning uses an operator embedding structure to train a single neural network on data from multiple operators. Thus, multi-operator learning is capable of predicting a range of operators within one model. In this work, we propose pretraining and fine-tuning strategies for solving PDEs using multi-operator learning. One key aspect is that by increasing the number of families of operators used in pretraining, a PDE foundation model can be fine-tuned to downstream tasks involving new PDEs with a limited number of samples, thus outperforming single operator neural networks. Specifically, a multi-operator learning model pre-trained with data from diverse PDE families can predict unseen operators after fine-tuning with only a limited number of operators from the new family, enabling them to serve as a data-free PDE solver. We also show that the proposed training and fine-tuning method is able to predict new operators in zero-shot prediction without samples. Additionally, we introduce a PDE-agnostic meta-learning algorithm to improve the adaptability of the model to various PDEs by providing a better parameter initialization process. To address the needs of applications with limited computing resources, we explore low-rank adaptation methods that reduce computational costs while enhancing solver accuracy. Lastly, by examining the scaling law with respect to the number of operator families, we establish and highlight its potential for broad adaptation in PDE-solving tasks.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b237deb6c0234378238a6ee49b229b1299b7efe6.pdf",
        "venue": "arXiv.org",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Single-operator learning involves training a deep neural network to learn a specific operator, whereas recent work in multi-operator learning uses an operator embedding structure to train a single neural network on data from multiple operators. Thus, multi-operator learning is capable of predicting a range of operators within one model. In this work, we propose pretraining and fine-tuning strategies for solving PDEs using multi-operator learning. One key aspect is that by increasing the number of families of operators used in pretraining, a PDE foundation model can be fine-tuned to downstream tasks involving new PDEs with a limited number of samples, thus outperforming single operator neural networks. Specifically, a multi-operator learning model pre-trained with data from diverse PDE families can predict unseen operators after fine-tuning with only a limited number of operators from the new family, enabling them to serve as a data-free PDE solver. We also show that the proposed training and fine-tuning method is able to predict new operators in zero-shot prediction without samples. Additionally, we introduce a PDE-agnostic meta-learning algorithm to improve the adaptability of the model to various PDEs by providing a better parameter initialization process. To address the needs of applications with limited computing resources, we explore low-rank adaptation methods that reduce computational costs while enhancing solver accuracy. Lastly, by examining the scaling law with respect to the number of operator families, we establish and highlight its potential for broad adaptation in PDE-solving tasks.",
        "keywords": []
      },
      "file_name": "b237deb6c0234378238a6ee49b229b1299b7efe6.pdf"
    },
    {
      "success": true,
      "doc_id": "1890cf650a0b9e36870b5f1cc6658acb",
      "summary": "The Simultaneously Transmitting and Reflecting Reconfigurable Intelligent Surface (STAR-RIS) technology is an innovative approach that aims to enhance the performance of sixth-generation (6G) wireless networks. This study focuses on a multi-STAR-RIS and full-duplex (FD) communication system aimed at providing ultra-reliable low-latency communication (URLLC) services. To maximize the total uplink (UL) and downlink (DL) rates, beamforming and combining vectors at the base station (BS), the transmit power of UL users, the amplitude attenuations, and phase shifts of the STAR-RISs are jointly optimized. These optimizations take into account the maximum transmit power constraints of the BS and UL users, as well as the quality of service requirements of UL and DL users. Given the non-convex nature of the optimization problem, this study proposes a novel deep reinforcement learning algorithm called Meta DDPG, which combines meta-learning and deep deterministic policy gradient. Numerical results demonstrate that a multi-STAR-RIS assisted system can obtain a higher system total rate compared to the conventional multi-RIS assisted system.",
      "intriguing_abstract": "The Simultaneously Transmitting and Reflecting Reconfigurable Intelligent Surface (STAR-RIS) technology is an innovative approach that aims to enhance the performance of sixth-generation (6G) wireless networks. This study focuses on a multi-STAR-RIS and full-duplex (FD) communication system aimed at providing ultra-reliable low-latency communication (URLLC) services. To maximize the total uplink (UL) and downlink (DL) rates, beamforming and combining vectors at the base station (BS), the transmit power of UL users, the amplitude attenuations, and phase shifts of the STAR-RISs are jointly optimized. These optimizations take into account the maximum transmit power constraints of the BS and UL users, as well as the quality of service requirements of UL and DL users. Given the non-convex nature of the optimization problem, this study proposes a novel deep reinforcement learning algorithm called Meta DDPG, which combines meta-learning and deep deterministic policy gradient. Numerical results demonstrate that a multi-STAR-RIS assisted system can obtain a higher system total rate compared to the conventional multi-RIS assisted system.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/bfb22a7d0f64625b897ebfe3a3f7498d5c71cbb1.pdf",
      "citation_key": "eghbali2024huh",
      "metadata": {
        "title": "Providing URLLC Service in Multi-STAR-RIS Assisted and Full-Duplex Cellular Wireless Systems: A Meta-Learning Approach",
        "authors": [
          "Y. Eghbali",
          "Shiva Kazemi Taskou",
          "Mohammad Robat Mili",
          "M. Rasti",
          "Ekram Hossain"
        ],
        "published_date": "2024",
        "abstract": "The Simultaneously Transmitting and Reflecting Reconfigurable Intelligent Surface (STAR-RIS) technology is an innovative approach that aims to enhance the performance of sixth-generation (6G) wireless networks. This study focuses on a multi-STAR-RIS and full-duplex (FD) communication system aimed at providing ultra-reliable low-latency communication (URLLC) services. To maximize the total uplink (UL) and downlink (DL) rates, beamforming and combining vectors at the base station (BS), the transmit power of UL users, the amplitude attenuations, and phase shifts of the STAR-RISs are jointly optimized. These optimizations take into account the maximum transmit power constraints of the BS and UL users, as well as the quality of service requirements of UL and DL users. Given the non-convex nature of the optimization problem, this study proposes a novel deep reinforcement learning algorithm called Meta DDPG, which combines meta-learning and deep deterministic policy gradient. Numerical results demonstrate that a multi-STAR-RIS assisted system can obtain a higher system total rate compared to the conventional multi-RIS assisted system.",
        "file_path": "paper_data/Deep_Meta-Learning/info/bfb22a7d0f64625b897ebfe3a3f7498d5c71cbb1.pdf",
        "venue": "IEEE Communications Letters",
        "citationCount": 8,
        "score": 8.0,
        "summary": "The Simultaneously Transmitting and Reflecting Reconfigurable Intelligent Surface (STAR-RIS) technology is an innovative approach that aims to enhance the performance of sixth-generation (6G) wireless networks. This study focuses on a multi-STAR-RIS and full-duplex (FD) communication system aimed at providing ultra-reliable low-latency communication (URLLC) services. To maximize the total uplink (UL) and downlink (DL) rates, beamforming and combining vectors at the base station (BS), the transmit power of UL users, the amplitude attenuations, and phase shifts of the STAR-RISs are jointly optimized. These optimizations take into account the maximum transmit power constraints of the BS and UL users, as well as the quality of service requirements of UL and DL users. Given the non-convex nature of the optimization problem, this study proposes a novel deep reinforcement learning algorithm called Meta DDPG, which combines meta-learning and deep deterministic policy gradient. Numerical results demonstrate that a multi-STAR-RIS assisted system can obtain a higher system total rate compared to the conventional multi-RIS assisted system.",
        "keywords": []
      },
      "file_name": "bfb22a7d0f64625b897ebfe3a3f7498d5c71cbb1.pdf"
    },
    {
      "success": true,
      "doc_id": "53f00546b08741f2cb3c137cbea23f98",
      "summary": "Deep learning based object detection methods have made significant progress in recent years. However, these methods often suffer from a substantial performance drop when domain shifts occur, making it difficult to generalize a source domain trained object detector to a new target domain. To address this problem, we propose an Online Meta Learning Framework (OMLF) for unsupervised domain adaptive object detection. In our proposed framework, we adopt the Polar Harmonic Fourier Moment (PHFM) to generate target-like intermediate data. The purpose is to construct a two-pair framework that learns meta knowledge (i.e. model initial parameters) from the pair of “source-to-intermediate” to assist another pair of “intermediate-to-target”. Moreover, the optimizing process requires a heavy computational load due to triggering higher-order gradients. To alleviate this problem, we introduce a shortest-path update strategy that accelerates optimization. When evaluated on several benchmark adaptation scenarios (i.e. normal-to-foggy weather, cross cameras, synthetic-to-real, and real-to-artistic), our OMLF achieves state-of-the-art results, demonstrating its effectiveness.",
      "intriguing_abstract": "Deep learning based object detection methods have made significant progress in recent years. However, these methods often suffer from a substantial performance drop when domain shifts occur, making it difficult to generalize a source domain trained object detector to a new target domain. To address this problem, we propose an Online Meta Learning Framework (OMLF) for unsupervised domain adaptive object detection. In our proposed framework, we adopt the Polar Harmonic Fourier Moment (PHFM) to generate target-like intermediate data. The purpose is to construct a two-pair framework that learns meta knowledge (i.e. model initial parameters) from the pair of “source-to-intermediate” to assist another pair of “intermediate-to-target”. Moreover, the optimizing process requires a heavy computational load due to triggering higher-order gradients. To alleviate this problem, we introduce a shortest-path update strategy that accelerates optimization. When evaluated on several benchmark adaptation scenarios (i.e. normal-to-foggy weather, cross cameras, synthetic-to-real, and real-to-artistic), our OMLF achieves state-of-the-art results, demonstrating its effectiveness.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e582dccc95d150d4fca3f2e40e3b67850451ad35.pdf",
      "citation_key": "zhu2024ok7",
      "metadata": {
        "title": "Intermediate Domain-Based Meta Learning Framework for Adaptive Object Detection",
        "authors": [
          "Yihuan Zhu",
          "Yunan Liu",
          "Chunpeng Wang",
          "Simiao Wang",
          "Mingyu Lu"
        ],
        "published_date": "2024",
        "abstract": "Deep learning based object detection methods have made significant progress in recent years. However, these methods often suffer from a substantial performance drop when domain shifts occur, making it difficult to generalize a source domain trained object detector to a new target domain. To address this problem, we propose an Online Meta Learning Framework (OMLF) for unsupervised domain adaptive object detection. In our proposed framework, we adopt the Polar Harmonic Fourier Moment (PHFM) to generate target-like intermediate data. The purpose is to construct a two-pair framework that learns meta knowledge (i.e. model initial parameters) from the pair of “source-to-intermediate” to assist another pair of “intermediate-to-target”. Moreover, the optimizing process requires a heavy computational load due to triggering higher-order gradients. To alleviate this problem, we introduce a shortest-path update strategy that accelerates optimization. When evaluated on several benchmark adaptation scenarios (i.e. normal-to-foggy weather, cross cameras, synthetic-to-real, and real-to-artistic), our OMLF achieves state-of-the-art results, demonstrating its effectiveness.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e582dccc95d150d4fca3f2e40e3b67850451ad35.pdf",
        "venue": "IEEE transactions on circuits and systems for video technology (Print)",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Deep learning based object detection methods have made significant progress in recent years. However, these methods often suffer from a substantial performance drop when domain shifts occur, making it difficult to generalize a source domain trained object detector to a new target domain. To address this problem, we propose an Online Meta Learning Framework (OMLF) for unsupervised domain adaptive object detection. In our proposed framework, we adopt the Polar Harmonic Fourier Moment (PHFM) to generate target-like intermediate data. The purpose is to construct a two-pair framework that learns meta knowledge (i.e. model initial parameters) from the pair of “source-to-intermediate” to assist another pair of “intermediate-to-target”. Moreover, the optimizing process requires a heavy computational load due to triggering higher-order gradients. To alleviate this problem, we introduce a shortest-path update strategy that accelerates optimization. When evaluated on several benchmark adaptation scenarios (i.e. normal-to-foggy weather, cross cameras, synthetic-to-real, and real-to-artistic), our OMLF achieves state-of-the-art results, demonstrating its effectiveness.",
        "keywords": []
      },
      "file_name": "e582dccc95d150d4fca3f2e40e3b67850451ad35.pdf"
    },
    {
      "success": true,
      "doc_id": "4a30357a413655f92a702fefb4d4fa3e",
      "summary": "Few-shot fault diagnosis aims to detect novel faults with only a few labeled samples in each category. Most of the few-shot learning (FSL)–based fault diagnosis models use meta-learning frameworks because of their effectiveness and simplicity. However, these models often fail to be generalized in unseen working conditions that exhibit domain shifts. This study focuses on the few-shot fault diagnosis while addressing the challenges in domain-shift scenarios by developing a customized meta-learning framework, which consists of three key contributions: 1) a fused deep feature learning strategy is designed using multidomain signals in time, frequency, and time–frequency to extract more discriminative features from a few labeled samples; 2) a domain shift–learned feature transformation layer is introduced by modulating the feature activations with affine transformations into the meta-learner to tackle challenges due to domain shifts under unseen working conditions; and 3) a Mahalanobis distance–based metric function is constructed leveraging an additional neural network to learn the spread variance of each fault pattern to ensure an accurate and robust label prediction. The proposed framework is tested using real-world datasets and the ablation study demonstrates the effectiveness of its key components. The results also show that the proposed framework outperforms the state-of-the-art FSL algorithms that fail to consider the domain-shift scenarios.",
      "intriguing_abstract": "Few-shot fault diagnosis aims to detect novel faults with only a few labeled samples in each category. Most of the few-shot learning (FSL)–based fault diagnosis models use meta-learning frameworks because of their effectiveness and simplicity. However, these models often fail to be generalized in unseen working conditions that exhibit domain shifts. This study focuses on the few-shot fault diagnosis while addressing the challenges in domain-shift scenarios by developing a customized meta-learning framework, which consists of three key contributions: 1) a fused deep feature learning strategy is designed using multidomain signals in time, frequency, and time–frequency to extract more discriminative features from a few labeled samples; 2) a domain shift–learned feature transformation layer is introduced by modulating the feature activations with affine transformations into the meta-learner to tackle challenges due to domain shifts under unseen working conditions; and 3) a Mahalanobis distance–based metric function is constructed leveraging an additional neural network to learn the spread variance of each fault pattern to ensure an accurate and robust label prediction. The proposed framework is tested using real-world datasets and the ablation study demonstrates the effectiveness of its key components. The results also show that the proposed framework outperforms the state-of-the-art FSL algorithms that fail to consider the domain-shift scenarios.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/dfc50bea60deca4a10216f1b2482ac517c4dcc96.pdf",
      "citation_key": "long202400t",
      "metadata": {
        "title": "A Customized Meta-Learning Framework for Diagnosing New Faults From Unseen Working Conditions With Few Labeled Data",
        "authors": [
          "Jianyu Long",
          "Rongxin Zhang",
          "Yibin Chen",
          "Rong Zhao",
          "Zhe Yang",
          "Yunwei Huang",
          "Chuan Li"
        ],
        "published_date": "2024",
        "abstract": "Few-shot fault diagnosis aims to detect novel faults with only a few labeled samples in each category. Most of the few-shot learning (FSL)–based fault diagnosis models use meta-learning frameworks because of their effectiveness and simplicity. However, these models often fail to be generalized in unseen working conditions that exhibit domain shifts. This study focuses on the few-shot fault diagnosis while addressing the challenges in domain-shift scenarios by developing a customized meta-learning framework, which consists of three key contributions: 1) a fused deep feature learning strategy is designed using multidomain signals in time, frequency, and time–frequency to extract more discriminative features from a few labeled samples; 2) a domain shift–learned feature transformation layer is introduced by modulating the feature activations with affine transformations into the meta-learner to tackle challenges due to domain shifts under unseen working conditions; and 3) a Mahalanobis distance–based metric function is constructed leveraging an additional neural network to learn the spread variance of each fault pattern to ensure an accurate and robust label prediction. The proposed framework is tested using real-world datasets and the ablation study demonstrates the effectiveness of its key components. The results also show that the proposed framework outperforms the state-of-the-art FSL algorithms that fail to consider the domain-shift scenarios.",
        "file_path": "paper_data/Deep_Meta-Learning/info/dfc50bea60deca4a10216f1b2482ac517c4dcc96.pdf",
        "venue": "IEEE/ASME transactions on mechatronics",
        "citationCount": 8,
        "score": 8.0,
        "summary": "Few-shot fault diagnosis aims to detect novel faults with only a few labeled samples in each category. Most of the few-shot learning (FSL)–based fault diagnosis models use meta-learning frameworks because of their effectiveness and simplicity. However, these models often fail to be generalized in unseen working conditions that exhibit domain shifts. This study focuses on the few-shot fault diagnosis while addressing the challenges in domain-shift scenarios by developing a customized meta-learning framework, which consists of three key contributions: 1) a fused deep feature learning strategy is designed using multidomain signals in time, frequency, and time–frequency to extract more discriminative features from a few labeled samples; 2) a domain shift–learned feature transformation layer is introduced by modulating the feature activations with affine transformations into the meta-learner to tackle challenges due to domain shifts under unseen working conditions; and 3) a Mahalanobis distance–based metric function is constructed leveraging an additional neural network to learn the spread variance of each fault pattern to ensure an accurate and robust label prediction. The proposed framework is tested using real-world datasets and the ablation study demonstrates the effectiveness of its key components. The results also show that the proposed framework outperforms the state-of-the-art FSL algorithms that fail to consider the domain-shift scenarios.",
        "keywords": []
      },
      "file_name": "dfc50bea60deca4a10216f1b2482ac517c4dcc96.pdf"
    },
    {
      "success": true,
      "doc_id": "8f4500c7d21bdecbdbbf8cd9e4a1fb9e",
      "summary": "Cloud computing has revolutionized the provisioning of computing resources, offering scalable, flexible, and on-demand services to meet the diverse requirements of modern applications. At the heart of efficient cloud operations are job scheduling and resource management, which are critical for optimizing system performance and ensuring timely and cost-effective service delivery. However, the dynamic and heterogeneous nature of cloud environments presents significant challenges for these tasks, as workloads and resource availability can fluctuate unpredictably. Traditional approaches, including heuristic and meta-heuristic algorithms, often struggle to adapt to these real-time changes due to their reliance on static models or predefined rules. Deep Reinforcement Learning (DRL) has emerged as a promising solution to these challenges by enabling systems to learn and adapt policies based on continuous observations of the environment, facilitating intelligent and responsive decision-making. This survey provides a comprehensive review of DRL-based algorithms for job scheduling and resource management in cloud computing, analyzing their methodologies, performance metrics, and practical applications. We also highlight emerging trends and future research directions, offering valuable insights into leveraging DRL to advance both job scheduling and resource management in cloud computing.",
      "intriguing_abstract": "Cloud computing has revolutionized the provisioning of computing resources, offering scalable, flexible, and on-demand services to meet the diverse requirements of modern applications. At the heart of efficient cloud operations are job scheduling and resource management, which are critical for optimizing system performance and ensuring timely and cost-effective service delivery. However, the dynamic and heterogeneous nature of cloud environments presents significant challenges for these tasks, as workloads and resource availability can fluctuate unpredictably. Traditional approaches, including heuristic and meta-heuristic algorithms, often struggle to adapt to these real-time changes due to their reliance on static models or predefined rules. Deep Reinforcement Learning (DRL) has emerged as a promising solution to these challenges by enabling systems to learn and adapt policies based on continuous observations of the environment, facilitating intelligent and responsive decision-making. This survey provides a comprehensive review of DRL-based algorithms for job scheduling and resource management in cloud computing, analyzing their methodologies, performance metrics, and practical applications. We also highlight emerging trends and future research directions, offering valuable insights into leveraging DRL to advance both job scheduling and resource management in cloud computing.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b18efa8feb5e8024546e0abe6bafd58b928a413b.pdf",
      "citation_key": "gu20252u3",
      "metadata": {
        "title": "Deep Reinforcement Learning for Job Scheduling and Resource Management in Cloud Computing: An Algorithm-Level Review",
        "authors": [
          "Yan Gu",
          "Zhaoze Liu",
          "Shuhong Dai",
          "Cong Liu",
          "Ying Wang",
          "Shen Wang",
          "Georgios Theodoropoulos",
          "Long Cheng"
        ],
        "published_date": "2025",
        "abstract": "Cloud computing has revolutionized the provisioning of computing resources, offering scalable, flexible, and on-demand services to meet the diverse requirements of modern applications. At the heart of efficient cloud operations are job scheduling and resource management, which are critical for optimizing system performance and ensuring timely and cost-effective service delivery. However, the dynamic and heterogeneous nature of cloud environments presents significant challenges for these tasks, as workloads and resource availability can fluctuate unpredictably. Traditional approaches, including heuristic and meta-heuristic algorithms, often struggle to adapt to these real-time changes due to their reliance on static models or predefined rules. Deep Reinforcement Learning (DRL) has emerged as a promising solution to these challenges by enabling systems to learn and adapt policies based on continuous observations of the environment, facilitating intelligent and responsive decision-making. This survey provides a comprehensive review of DRL-based algorithms for job scheduling and resource management in cloud computing, analyzing their methodologies, performance metrics, and practical applications. We also highlight emerging trends and future research directions, offering valuable insights into leveraging DRL to advance both job scheduling and resource management in cloud computing.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b18efa8feb5e8024546e0abe6bafd58b928a413b.pdf",
        "venue": "arXiv.org",
        "citationCount": 7,
        "score": 7.0,
        "summary": "Cloud computing has revolutionized the provisioning of computing resources, offering scalable, flexible, and on-demand services to meet the diverse requirements of modern applications. At the heart of efficient cloud operations are job scheduling and resource management, which are critical for optimizing system performance and ensuring timely and cost-effective service delivery. However, the dynamic and heterogeneous nature of cloud environments presents significant challenges for these tasks, as workloads and resource availability can fluctuate unpredictably. Traditional approaches, including heuristic and meta-heuristic algorithms, often struggle to adapt to these real-time changes due to their reliance on static models or predefined rules. Deep Reinforcement Learning (DRL) has emerged as a promising solution to these challenges by enabling systems to learn and adapt policies based on continuous observations of the environment, facilitating intelligent and responsive decision-making. This survey provides a comprehensive review of DRL-based algorithms for job scheduling and resource management in cloud computing, analyzing their methodologies, performance metrics, and practical applications. We also highlight emerging trends and future research directions, offering valuable insights into leveraging DRL to advance both job scheduling and resource management in cloud computing.",
        "keywords": []
      },
      "file_name": "b18efa8feb5e8024546e0abe6bafd58b928a413b.pdf"
    },
    {
      "success": true,
      "doc_id": "79c568d22a2ac46154429e19ed2ab152",
      "summary": "In typical unsupervised domain adaptive object detection, it is assumed that extensive unlabeled training data from the target domain can be easily obtained. However, in some access-constrained scenarios, massive target data cannot be guaranteed, but acquiring only a few target samples and annotating them may costs less. Therefore, inspired by the meta-learning success in few-shot tasks, we propose an Instance-level Prototype learning Network (IPNet) for solving the domain adaptive object detection under the supervised few-shot scenario in this work. To compensate for the target domain data deficiency, we fuse cropped instances from labeled images in both domains to learn a representative prototype for each class, by enforcing features of the same class’s instances but from different domains to be as close as possible. These prototypes are further employed to discriminate various features’ salience in an image, and separate foreground and background regions for respective domain alignment. Extensive experiments are conducted on several cross-domain scenarios, and their results show the consistent accuracy gains of the IPNet over state-of-the-art methods, e.g., 10.4% mAP increase on Cityscapes-to-FoggyCityscapes setting and 3.0% mAP increase on Sim10k-to-Cityscapes setting.",
      "intriguing_abstract": "In typical unsupervised domain adaptive object detection, it is assumed that extensive unlabeled training data from the target domain can be easily obtained. However, in some access-constrained scenarios, massive target data cannot be guaranteed, but acquiring only a few target samples and annotating them may costs less. Therefore, inspired by the meta-learning success in few-shot tasks, we propose an Instance-level Prototype learning Network (IPNet) for solving the domain adaptive object detection under the supervised few-shot scenario in this work. To compensate for the target domain data deficiency, we fuse cropped instances from labeled images in both domains to learn a representative prototype for each class, by enforcing features of the same class’s instances but from different domains to be as close as possible. These prototypes are further employed to discriminate various features’ salience in an image, and separate foreground and background regions for respective domain alignment. Extensive experiments are conducted on several cross-domain scenarios, and their results show the consistent accuracy gains of the IPNet over state-of-the-art methods, e.g., 10.4% mAP increase on Cityscapes-to-FoggyCityscapes setting and 3.0% mAP increase on Sim10k-to-Cityscapes setting.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/684b36d780bda6e7c4a4c99aa03390466d476476.pdf",
      "citation_key": "zhang2024mf0",
      "metadata": {
        "title": "Few-Shot Cross-Domain Object Detection With Instance-Level Prototype-Based Meta-Learning",
        "authors": [
          "Lin Zhang",
          "Bo Zhang",
          "Botian Shi",
          "Jiayuan Fan",
          "Tao Chen"
        ],
        "published_date": "2024",
        "abstract": "In typical unsupervised domain adaptive object detection, it is assumed that extensive unlabeled training data from the target domain can be easily obtained. However, in some access-constrained scenarios, massive target data cannot be guaranteed, but acquiring only a few target samples and annotating them may costs less. Therefore, inspired by the meta-learning success in few-shot tasks, we propose an Instance-level Prototype learning Network (IPNet) for solving the domain adaptive object detection under the supervised few-shot scenario in this work. To compensate for the target domain data deficiency, we fuse cropped instances from labeled images in both domains to learn a representative prototype for each class, by enforcing features of the same class’s instances but from different domains to be as close as possible. These prototypes are further employed to discriminate various features’ salience in an image, and separate foreground and background regions for respective domain alignment. Extensive experiments are conducted on several cross-domain scenarios, and their results show the consistent accuracy gains of the IPNet over state-of-the-art methods, e.g., 10.4% mAP increase on Cityscapes-to-FoggyCityscapes setting and 3.0% mAP increase on Sim10k-to-Cityscapes setting.",
        "file_path": "paper_data/Deep_Meta-Learning/info/684b36d780bda6e7c4a4c99aa03390466d476476.pdf",
        "venue": "IEEE transactions on circuits and systems for video technology (Print)",
        "citationCount": 7,
        "score": 7.0,
        "summary": "In typical unsupervised domain adaptive object detection, it is assumed that extensive unlabeled training data from the target domain can be easily obtained. However, in some access-constrained scenarios, massive target data cannot be guaranteed, but acquiring only a few target samples and annotating them may costs less. Therefore, inspired by the meta-learning success in few-shot tasks, we propose an Instance-level Prototype learning Network (IPNet) for solving the domain adaptive object detection under the supervised few-shot scenario in this work. To compensate for the target domain data deficiency, we fuse cropped instances from labeled images in both domains to learn a representative prototype for each class, by enforcing features of the same class’s instances but from different domains to be as close as possible. These prototypes are further employed to discriminate various features’ salience in an image, and separate foreground and background regions for respective domain alignment. Extensive experiments are conducted on several cross-domain scenarios, and their results show the consistent accuracy gains of the IPNet over state-of-the-art methods, e.g., 10.4% mAP increase on Cityscapes-to-FoggyCityscapes setting and 3.0% mAP increase on Sim10k-to-Cityscapes setting.",
        "keywords": []
      },
      "file_name": "684b36d780bda6e7c4a4c99aa03390466d476476.pdf"
    },
    {
      "success": true,
      "doc_id": "337be4492bad5551c5de67827e22870b",
      "summary": "Driver Distraction Detection (3D) is of great significance in helping intelligent vehicles decide whether to remind drivers or take over the driving task and avoid traffic accidents. However, the current centralized learning paradigm of 3D has become unpractical because of rising limitations on data sharing and increasing concerns about user privacy. In this context, 3D is further facing three emerging challenges, namely data islands, data heterogeneity, and the straggler issue. To jointly address these three issues and make the 3D model training and deployment more practical and efficient, this paper proposes an Asynchronous Federated Meta-learning framework called AFM3D. Specifically, AFM3D bridges data islands through Federated Learning (FL), a novel distributed learning paradigm that enables multiple clients (i.e., private vehicles with individual data of drivers) to learn a global model collaboratively without data exchange. Moreover, AFM3D further utilizes meta-learning to tackle data heterogeneity by training a meta-model that can adapt to new driver data quickly with satisfactory performance. Finally, AFM3D is designed to operate in an asynchronous mode to reduce delays caused by stragglers and achieve efficient learning. A temporally weighted aggregation strategy is also designed to handle stale models commonly encountered in the asynchronous mode and in turn, optimize the aggregation direction. Extensive experiment results show that AFM3D can boost performance in terms of model accuracy, recall, F1 score, test loss, and learning speed by 7.61%, 7.44%, 7.95%, 9.95%, and 50.91%, respectively, against five state-of-the-art methods.",
      "intriguing_abstract": "Driver Distraction Detection (3D) is of great significance in helping intelligent vehicles decide whether to remind drivers or take over the driving task and avoid traffic accidents. However, the current centralized learning paradigm of 3D has become unpractical because of rising limitations on data sharing and increasing concerns about user privacy. In this context, 3D is further facing three emerging challenges, namely data islands, data heterogeneity, and the straggler issue. To jointly address these three issues and make the 3D model training and deployment more practical and efficient, this paper proposes an Asynchronous Federated Meta-learning framework called AFM3D. Specifically, AFM3D bridges data islands through Federated Learning (FL), a novel distributed learning paradigm that enables multiple clients (i.e., private vehicles with individual data of drivers) to learn a global model collaboratively without data exchange. Moreover, AFM3D further utilizes meta-learning to tackle data heterogeneity by training a meta-model that can adapt to new driver data quickly with satisfactory performance. Finally, AFM3D is designed to operate in an asynchronous mode to reduce delays caused by stragglers and achieve efficient learning. A temporally weighted aggregation strategy is also designed to handle stale models commonly encountered in the asynchronous mode and in turn, optimize the aggregation direction. Extensive experiment results show that AFM3D can boost performance in terms of model accuracy, recall, F1 score, test loss, and learning speed by 7.61%, 7.44%, 7.95%, 9.95%, and 50.91%, respectively, against five state-of-the-art methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/3b32351004d1628329b875576323a7b1767e9e5a.pdf",
      "citation_key": "liu2024jz5",
      "metadata": {
        "title": "AFM3D: An Asynchronous Federated Meta-Learning Framework for Driver Distraction Detection",
        "authors": [
          "Sheng Liu",
          "Linlin You",
          "Rui Zhu",
          "Bing Liu",
          "Rui Liu",
          "Han Yu",
          "Chau Yuen"
        ],
        "published_date": "2024",
        "abstract": "Driver Distraction Detection (3D) is of great significance in helping intelligent vehicles decide whether to remind drivers or take over the driving task and avoid traffic accidents. However, the current centralized learning paradigm of 3D has become unpractical because of rising limitations on data sharing and increasing concerns about user privacy. In this context, 3D is further facing three emerging challenges, namely data islands, data heterogeneity, and the straggler issue. To jointly address these three issues and make the 3D model training and deployment more practical and efficient, this paper proposes an Asynchronous Federated Meta-learning framework called AFM3D. Specifically, AFM3D bridges data islands through Federated Learning (FL), a novel distributed learning paradigm that enables multiple clients (i.e., private vehicles with individual data of drivers) to learn a global model collaboratively without data exchange. Moreover, AFM3D further utilizes meta-learning to tackle data heterogeneity by training a meta-model that can adapt to new driver data quickly with satisfactory performance. Finally, AFM3D is designed to operate in an asynchronous mode to reduce delays caused by stragglers and achieve efficient learning. A temporally weighted aggregation strategy is also designed to handle stale models commonly encountered in the asynchronous mode and in turn, optimize the aggregation direction. Extensive experiment results show that AFM3D can boost performance in terms of model accuracy, recall, F1 score, test loss, and learning speed by 7.61%, 7.44%, 7.95%, 9.95%, and 50.91%, respectively, against five state-of-the-art methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/3b32351004d1628329b875576323a7b1767e9e5a.pdf",
        "venue": "IEEE transactions on intelligent transportation systems (Print)",
        "citationCount": 7,
        "score": 7.0,
        "summary": "Driver Distraction Detection (3D) is of great significance in helping intelligent vehicles decide whether to remind drivers or take over the driving task and avoid traffic accidents. However, the current centralized learning paradigm of 3D has become unpractical because of rising limitations on data sharing and increasing concerns about user privacy. In this context, 3D is further facing three emerging challenges, namely data islands, data heterogeneity, and the straggler issue. To jointly address these three issues and make the 3D model training and deployment more practical and efficient, this paper proposes an Asynchronous Federated Meta-learning framework called AFM3D. Specifically, AFM3D bridges data islands through Federated Learning (FL), a novel distributed learning paradigm that enables multiple clients (i.e., private vehicles with individual data of drivers) to learn a global model collaboratively without data exchange. Moreover, AFM3D further utilizes meta-learning to tackle data heterogeneity by training a meta-model that can adapt to new driver data quickly with satisfactory performance. Finally, AFM3D is designed to operate in an asynchronous mode to reduce delays caused by stragglers and achieve efficient learning. A temporally weighted aggregation strategy is also designed to handle stale models commonly encountered in the asynchronous mode and in turn, optimize the aggregation direction. Extensive experiment results show that AFM3D can boost performance in terms of model accuracy, recall, F1 score, test loss, and learning speed by 7.61%, 7.44%, 7.95%, 9.95%, and 50.91%, respectively, against five state-of-the-art methods.",
        "keywords": []
      },
      "file_name": "3b32351004d1628329b875576323a7b1767e9e5a.pdf"
    },
    {
      "success": true,
      "doc_id": "3e625e298407206008bdfb64f007d16f",
      "summary": "Following the introduction of Adam, several novel adaptive optimizers for deep learning have been proposed. These optimizers typically excel in some tasks but may not outperform Adam uniformly across all tasks. In this work, we introduce Meta-Adaptive Optimizers (MADA), a unified optimizer framework that can generalize several known optimizers and dynamically learn the most suitable one during training. The key idea in MADA is to parameterize the space of optimizers and dynamically search through it using hyper-gradient descent during training. We empirically compare MADA to other popular optimizers on vision and language tasks, and find that MADA consistently outperforms Adam and other popular optimizers, and is robust against sub-optimally tuned hyper-parameters. MADA achieves a greater validation performance improvement over Adam compared to other popular optimizers during GPT-2 training and fine-tuning. We also propose AVGrad, a modification of AMSGrad that replaces the maximum operator with averaging, which is more suitable for hyper-gradient optimization. Finally, we provide a convergence analysis to show that parameterized interpolations of optimizers can improve their error bounds (up to constants), hinting at an advantage for meta-optimizers.",
      "intriguing_abstract": "Following the introduction of Adam, several novel adaptive optimizers for deep learning have been proposed. These optimizers typically excel in some tasks but may not outperform Adam uniformly across all tasks. In this work, we introduce Meta-Adaptive Optimizers (MADA), a unified optimizer framework that can generalize several known optimizers and dynamically learn the most suitable one during training. The key idea in MADA is to parameterize the space of optimizers and dynamically search through it using hyper-gradient descent during training. We empirically compare MADA to other popular optimizers on vision and language tasks, and find that MADA consistently outperforms Adam and other popular optimizers, and is robust against sub-optimally tuned hyper-parameters. MADA achieves a greater validation performance improvement over Adam compared to other popular optimizers during GPT-2 training and fine-tuning. We also propose AVGrad, a modification of AMSGrad that replaces the maximum operator with averaging, which is more suitable for hyper-gradient optimization. Finally, we provide a convergence analysis to show that parameterized interpolations of optimizers can improve their error bounds (up to constants), hinting at an advantage for meta-optimizers.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/bef33d15c3e8d433261f97f7001cc41a5ae0ec32.pdf",
      "citation_key": "ozkara2024nst",
      "metadata": {
        "title": "MADA: Meta-Adaptive Optimizers through hyper-gradient Descent",
        "authors": [
          "Kaan Ozkara",
          "Can Karakus",
          "Parameswaran Raman",
          "Mingyi Hong",
          "Shoham Sabach",
          "B. Kveton",
          "V. Cevher"
        ],
        "published_date": "2024",
        "abstract": "Following the introduction of Adam, several novel adaptive optimizers for deep learning have been proposed. These optimizers typically excel in some tasks but may not outperform Adam uniformly across all tasks. In this work, we introduce Meta-Adaptive Optimizers (MADA), a unified optimizer framework that can generalize several known optimizers and dynamically learn the most suitable one during training. The key idea in MADA is to parameterize the space of optimizers and dynamically search through it using hyper-gradient descent during training. We empirically compare MADA to other popular optimizers on vision and language tasks, and find that MADA consistently outperforms Adam and other popular optimizers, and is robust against sub-optimally tuned hyper-parameters. MADA achieves a greater validation performance improvement over Adam compared to other popular optimizers during GPT-2 training and fine-tuning. We also propose AVGrad, a modification of AMSGrad that replaces the maximum operator with averaging, which is more suitable for hyper-gradient optimization. Finally, we provide a convergence analysis to show that parameterized interpolations of optimizers can improve their error bounds (up to constants), hinting at an advantage for meta-optimizers.",
        "file_path": "paper_data/Deep_Meta-Learning/info/bef33d15c3e8d433261f97f7001cc41a5ae0ec32.pdf",
        "venue": "International Conference on Machine Learning",
        "citationCount": 6,
        "score": 6.0,
        "summary": "Following the introduction of Adam, several novel adaptive optimizers for deep learning have been proposed. These optimizers typically excel in some tasks but may not outperform Adam uniformly across all tasks. In this work, we introduce Meta-Adaptive Optimizers (MADA), a unified optimizer framework that can generalize several known optimizers and dynamically learn the most suitable one during training. The key idea in MADA is to parameterize the space of optimizers and dynamically search through it using hyper-gradient descent during training. We empirically compare MADA to other popular optimizers on vision and language tasks, and find that MADA consistently outperforms Adam and other popular optimizers, and is robust against sub-optimally tuned hyper-parameters. MADA achieves a greater validation performance improvement over Adam compared to other popular optimizers during GPT-2 training and fine-tuning. We also propose AVGrad, a modification of AMSGrad that replaces the maximum operator with averaging, which is more suitable for hyper-gradient optimization. Finally, we provide a convergence analysis to show that parameterized interpolations of optimizers can improve their error bounds (up to constants), hinting at an advantage for meta-optimizers.",
        "keywords": []
      },
      "file_name": "bef33d15c3e8d433261f97f7001cc41a5ae0ec32.pdf"
    },
    {
      "success": true,
      "doc_id": "b3ea0d54c42396510272a3c16cb7895d",
      "summary": "Deep Image Hiding (DIH) aims to imperceptibly hide images within image. To improve its security performance, some DIH methods design Security Metrics (SMs) to guide the learning of their hiding networks. However, these methods focus on optimizing their anti-steganalysis ability on specific SMs, resulting in inferior generalization ability. To overcome these limitations, in this paper, we introduce meta-learning into DIH and propose Meta Security Metric-based DIH (MSM-DIH). In the MSM-DIH, the Invertible Neural Network (INN)-based hiding network is learned under the guidance of a learnable meta SM generalized from multiple fixed source SMs, and each SM is composed of a metric network and a contrastive loss function. Specifically, MSM-DIH is trained with bi-level optimization. In the outer optimization, a meta SM is learned to assign higher security scores for more advanced stego images. Besides, the domain knowledge of steganalysis is transferred from the multiple pre-trained source metric networks to the meta metric network, so as to enhance the generalization ability of the meta SM. In the inner optimization, the hiding network is learned to generate more secure stego images according to the learned meta SM. Experimental results show that our MSM-DIH has achieved the best security performance in most cases.",
      "intriguing_abstract": "Deep Image Hiding (DIH) aims to imperceptibly hide images within image. To improve its security performance, some DIH methods design Security Metrics (SMs) to guide the learning of their hiding networks. However, these methods focus on optimizing their anti-steganalysis ability on specific SMs, resulting in inferior generalization ability. To overcome these limitations, in this paper, we introduce meta-learning into DIH and propose Meta Security Metric-based DIH (MSM-DIH). In the MSM-DIH, the Invertible Neural Network (INN)-based hiding network is learned under the guidance of a learnable meta SM generalized from multiple fixed source SMs, and each SM is composed of a metric network and a contrastive loss function. Specifically, MSM-DIH is trained with bi-level optimization. In the outer optimization, a meta SM is learned to assign higher security scores for more advanced stego images. Besides, the domain knowledge of steganalysis is transferred from the multiple pre-trained source metric networks to the meta metric network, so as to enhance the generalization ability of the meta SM. In the inner optimization, the hiding network is learned to generate more secure stego images according to the learned meta SM. Experimental results show that our MSM-DIH has achieved the best security performance in most cases.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/7515c1ae5d78d4ddecbe380da3a9072ed0bdca01.pdf",
      "citation_key": "cui2024bov",
      "metadata": {
        "title": "Meta Security Metric Learning for Secure Deep Image Hiding",
        "authors": [
          "Qi Cui",
          "Weixuan Tang",
          "Zhili Zhou",
          "Ruohan Meng",
          "Gu Nan",
          "Yun-Qing Shi"
        ],
        "published_date": "2024",
        "abstract": "Deep Image Hiding (DIH) aims to imperceptibly hide images within image. To improve its security performance, some DIH methods design Security Metrics (SMs) to guide the learning of their hiding networks. However, these methods focus on optimizing their anti-steganalysis ability on specific SMs, resulting in inferior generalization ability. To overcome these limitations, in this paper, we introduce meta-learning into DIH and propose Meta Security Metric-based DIH (MSM-DIH). In the MSM-DIH, the Invertible Neural Network (INN)-based hiding network is learned under the guidance of a learnable meta SM generalized from multiple fixed source SMs, and each SM is composed of a metric network and a contrastive loss function. Specifically, MSM-DIH is trained with bi-level optimization. In the outer optimization, a meta SM is learned to assign higher security scores for more advanced stego images. Besides, the domain knowledge of steganalysis is transferred from the multiple pre-trained source metric networks to the meta metric network, so as to enhance the generalization ability of the meta SM. In the inner optimization, the hiding network is learned to generate more secure stego images according to the learned meta SM. Experimental results show that our MSM-DIH has achieved the best security performance in most cases.",
        "file_path": "paper_data/Deep_Meta-Learning/info/7515c1ae5d78d4ddecbe380da3a9072ed0bdca01.pdf",
        "venue": "IEEE Transactions on Dependable and Secure Computing",
        "citationCount": 6,
        "score": 6.0,
        "summary": "Deep Image Hiding (DIH) aims to imperceptibly hide images within image. To improve its security performance, some DIH methods design Security Metrics (SMs) to guide the learning of their hiding networks. However, these methods focus on optimizing their anti-steganalysis ability on specific SMs, resulting in inferior generalization ability. To overcome these limitations, in this paper, we introduce meta-learning into DIH and propose Meta Security Metric-based DIH (MSM-DIH). In the MSM-DIH, the Invertible Neural Network (INN)-based hiding network is learned under the guidance of a learnable meta SM generalized from multiple fixed source SMs, and each SM is composed of a metric network and a contrastive loss function. Specifically, MSM-DIH is trained with bi-level optimization. In the outer optimization, a meta SM is learned to assign higher security scores for more advanced stego images. Besides, the domain knowledge of steganalysis is transferred from the multiple pre-trained source metric networks to the meta metric network, so as to enhance the generalization ability of the meta SM. In the inner optimization, the hiding network is learned to generate more secure stego images according to the learned meta SM. Experimental results show that our MSM-DIH has achieved the best security performance in most cases.",
        "keywords": []
      },
      "file_name": "7515c1ae5d78d4ddecbe380da3a9072ed0bdca01.pdf"
    },
    {
      "success": true,
      "doc_id": "ab70b8a1a569aedf43a734598d014705",
      "summary": "In recent information retrieval systems, it is observed that the datasets used to train machine learning models can be biased, leading to systematic discrimination against certain demographic groups, which means the ranking utility of specific groups is often lower than others in a biased dataset. Training models on these datasets will further decrease the exposure of the minority groups. To address this problem, we propose a Meta Curriculum-based Fair Ranking framework (MCFR) which could alleviate the data bias issue through the weighted loss using gradient-based learning to learn. Specifically, we optimize a meta learner from a sampled dataset (meta-dataset), and meanwhile train a ranking model on the whole (biased) dataset. The meta-dataset is sampled with a curriculum learning scheduler to guide the meta learner's training to gradually mitigate the skewness towards biased attributes. The meta learner serves as a weighting function to make the ranking loss focus more on the minority group. We formulate the proposed MCFR as a bilevel optimization problem and solve it using gradients through gradients. Extensive experiments on real-world datasets demonstrate that our approach can be used as a generic framework to work with various ranking losses and fairness metrics.",
      "intriguing_abstract": "In recent information retrieval systems, it is observed that the datasets used to train machine learning models can be biased, leading to systematic discrimination against certain demographic groups, which means the ranking utility of specific groups is often lower than others in a biased dataset. Training models on these datasets will further decrease the exposure of the minority groups. To address this problem, we propose a Meta Curriculum-based Fair Ranking framework (MCFR) which could alleviate the data bias issue through the weighted loss using gradient-based learning to learn. Specifically, we optimize a meta learner from a sampled dataset (meta-dataset), and meanwhile train a ranking model on the whole (biased) dataset. The meta-dataset is sampled with a curriculum learning scheduler to guide the meta learner's training to gradually mitigate the skewness towards biased attributes. The meta learner serves as a weighting function to make the ranking loss focus more on the minority group. We formulate the proposed MCFR as a bilevel optimization problem and solve it using gradients through gradients. Extensive experiments on real-world datasets demonstrate that our approach can be used as a generic framework to work with various ranking losses and fairness metrics.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/287b8037b0f75caec9fab471dd48fe0b81090f74.pdf",
      "citation_key": "wang2024so2",
      "metadata": {
        "title": "A Unified Meta-Learning Framework for Fair Ranking With Curriculum Learning",
        "authors": [
          "Yuan Wang",
          "Zhiqiang Tao",
          "Yi Fang"
        ],
        "published_date": "2024",
        "abstract": "In recent information retrieval systems, it is observed that the datasets used to train machine learning models can be biased, leading to systematic discrimination against certain demographic groups, which means the ranking utility of specific groups is often lower than others in a biased dataset. Training models on these datasets will further decrease the exposure of the minority groups. To address this problem, we propose a Meta Curriculum-based Fair Ranking framework (MCFR) which could alleviate the data bias issue through the weighted loss using gradient-based learning to learn. Specifically, we optimize a meta learner from a sampled dataset (meta-dataset), and meanwhile train a ranking model on the whole (biased) dataset. The meta-dataset is sampled with a curriculum learning scheduler to guide the meta learner's training to gradually mitigate the skewness towards biased attributes. The meta learner serves as a weighting function to make the ranking loss focus more on the minority group. We formulate the proposed MCFR as a bilevel optimization problem and solve it using gradients through gradients. Extensive experiments on real-world datasets demonstrate that our approach can be used as a generic framework to work with various ranking losses and fairness metrics.",
        "file_path": "paper_data/Deep_Meta-Learning/info/287b8037b0f75caec9fab471dd48fe0b81090f74.pdf",
        "venue": "IEEE Transactions on Knowledge and Data Engineering",
        "citationCount": 6,
        "score": 6.0,
        "summary": "In recent information retrieval systems, it is observed that the datasets used to train machine learning models can be biased, leading to systematic discrimination against certain demographic groups, which means the ranking utility of specific groups is often lower than others in a biased dataset. Training models on these datasets will further decrease the exposure of the minority groups. To address this problem, we propose a Meta Curriculum-based Fair Ranking framework (MCFR) which could alleviate the data bias issue through the weighted loss using gradient-based learning to learn. Specifically, we optimize a meta learner from a sampled dataset (meta-dataset), and meanwhile train a ranking model on the whole (biased) dataset. The meta-dataset is sampled with a curriculum learning scheduler to guide the meta learner's training to gradually mitigate the skewness towards biased attributes. The meta learner serves as a weighting function to make the ranking loss focus more on the minority group. We formulate the proposed MCFR as a bilevel optimization problem and solve it using gradients through gradients. Extensive experiments on real-world datasets demonstrate that our approach can be used as a generic framework to work with various ranking losses and fairness metrics.",
        "keywords": []
      },
      "file_name": "287b8037b0f75caec9fab471dd48fe0b81090f74.pdf"
    },
    {
      "success": true,
      "doc_id": "e1deee1b4549c4932af37f52b3f2ad2d",
      "summary": "Multimodal learning is a promising area in artificial intelligence (AI) that can make the model understand different kinds of data. Existing works are trying to re-train a new model based on pre-trained models that requires much data, computation power, and time. However, it is difficult to achieve in low-resource or small-sample situations. Therefore, we propose VL-Meta, Vision Language Models for Multimodal Meta Learning. It (1) presents the vision-language mapper and multimodal fusion mapper, which are light model structures, to use the existing pre-trained models to make models understand images to language feature space and save training data, computation power, and time; (2) constructs the meta-task pool that can only use a small amount of data to construct enough training data and improve the generalization of the model to learn the data knowledge and task knowledge; (3) proposes the token-level training that can align inputs with the outputs during training to improve the model performance; and (4) adopts the multi-task fusion loss to learn the different abilities for the models. It achieves a good performance on the Visual Question Answering (VQA) task, which shows the feasibility and effectiveness of the model. This solution can help blind or visually impaired individuals obtain visual information.",
      "intriguing_abstract": "Multimodal learning is a promising area in artificial intelligence (AI) that can make the model understand different kinds of data. Existing works are trying to re-train a new model based on pre-trained models that requires much data, computation power, and time. However, it is difficult to achieve in low-resource or small-sample situations. Therefore, we propose VL-Meta, Vision Language Models for Multimodal Meta Learning. It (1) presents the vision-language mapper and multimodal fusion mapper, which are light model structures, to use the existing pre-trained models to make models understand images to language feature space and save training data, computation power, and time; (2) constructs the meta-task pool that can only use a small amount of data to construct enough training data and improve the generalization of the model to learn the data knowledge and task knowledge; (3) proposes the token-level training that can align inputs with the outputs during training to improve the model performance; and (4) adopts the multi-task fusion loss to learn the different abilities for the models. It achieves a good performance on the Visual Question Answering (VQA) task, which shows the feasibility and effectiveness of the model. This solution can help blind or visually impaired individuals obtain visual information.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b6efb87e4b609fb67304f73b8ee9c1984fce5e88.pdf",
      "citation_key": "ma2024vk4",
      "metadata": {
        "title": "VL-Meta: Vision-Language Models for Multimodal Meta-Learning",
        "authors": [
          "Han Ma",
          "Baoyu Fan",
          "B. Ng",
          "C. Lam"
        ],
        "published_date": "2024",
        "abstract": "Multimodal learning is a promising area in artificial intelligence (AI) that can make the model understand different kinds of data. Existing works are trying to re-train a new model based on pre-trained models that requires much data, computation power, and time. However, it is difficult to achieve in low-resource or small-sample situations. Therefore, we propose VL-Meta, Vision Language Models for Multimodal Meta Learning. It (1) presents the vision-language mapper and multimodal fusion mapper, which are light model structures, to use the existing pre-trained models to make models understand images to language feature space and save training data, computation power, and time; (2) constructs the meta-task pool that can only use a small amount of data to construct enough training data and improve the generalization of the model to learn the data knowledge and task knowledge; (3) proposes the token-level training that can align inputs with the outputs during training to improve the model performance; and (4) adopts the multi-task fusion loss to learn the different abilities for the models. It achieves a good performance on the Visual Question Answering (VQA) task, which shows the feasibility and effectiveness of the model. This solution can help blind or visually impaired individuals obtain visual information.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b6efb87e4b609fb67304f73b8ee9c1984fce5e88.pdf",
        "venue": "Mathematics",
        "citationCount": 6,
        "score": 6.0,
        "summary": "Multimodal learning is a promising area in artificial intelligence (AI) that can make the model understand different kinds of data. Existing works are trying to re-train a new model based on pre-trained models that requires much data, computation power, and time. However, it is difficult to achieve in low-resource or small-sample situations. Therefore, we propose VL-Meta, Vision Language Models for Multimodal Meta Learning. It (1) presents the vision-language mapper and multimodal fusion mapper, which are light model structures, to use the existing pre-trained models to make models understand images to language feature space and save training data, computation power, and time; (2) constructs the meta-task pool that can only use a small amount of data to construct enough training data and improve the generalization of the model to learn the data knowledge and task knowledge; (3) proposes the token-level training that can align inputs with the outputs during training to improve the model performance; and (4) adopts the multi-task fusion loss to learn the different abilities for the models. It achieves a good performance on the Visual Question Answering (VQA) task, which shows the feasibility and effectiveness of the model. This solution can help blind or visually impaired individuals obtain visual information.",
        "keywords": []
      },
      "file_name": "b6efb87e4b609fb67304f73b8ee9c1984fce5e88.pdf"
    },
    {
      "success": true,
      "doc_id": "9a1b170df06e2fcfe0cf81827b3c5b7a",
      "summary": "Dataset scaling, a.k.a. normalization, is an essential preprocessing step in a machine learning (ML) pipeline. It aims to adjust the scale of attributes in a way that they all vary within the same range. This transformation is known to improve the performance of classification models. Still, there are several scaling techniques (STs) to choose from, and no ST is guaranteed to be the best for a dataset regardless of the classifier chosen. It is thus a problem- and classifier-dependent decision. Furthermore, there can be a huge difference in performance when selecting the wrong technique; hence, it should not be neglected. That said, the trial-and-error process of finding the most suitable technique for a particular dataset can be unfeasible. As an alternative, we propose the Meta-scaler, which uses meta-learning (MtL) to build meta-models to automatically select the best ST for a given dataset and classification algorithm. The meta-models learn to represent the relationship between meta-features extracted from the datasets and the performance of specific classification algorithms on these datasets when scaled with different techniques. Our experiments using 12 base classifiers, 300 datasets, and five STs demonstrate the feasibility and effectiveness of the approach. When using the ST selected by the Meta-scaler for each dataset, 10 of 12 base models tested achieved statistically significantly better classification performance than any fixed choice of a single ST. The Meta-scaler also outperforms state-of-the-art MtL approaches for ST selection. The source code, data, and results from the experiments in this article are available at a GitHub repository (https://github.com/amorimlb/meta_scaler).",
      "intriguing_abstract": "Dataset scaling, a.k.a. normalization, is an essential preprocessing step in a machine learning (ML) pipeline. It aims to adjust the scale of attributes in a way that they all vary within the same range. This transformation is known to improve the performance of classification models. Still, there are several scaling techniques (STs) to choose from, and no ST is guaranteed to be the best for a dataset regardless of the classifier chosen. It is thus a problem- and classifier-dependent decision. Furthermore, there can be a huge difference in performance when selecting the wrong technique; hence, it should not be neglected. That said, the trial-and-error process of finding the most suitable technique for a particular dataset can be unfeasible. As an alternative, we propose the Meta-scaler, which uses meta-learning (MtL) to build meta-models to automatically select the best ST for a given dataset and classification algorithm. The meta-models learn to represent the relationship between meta-features extracted from the datasets and the performance of specific classification algorithms on these datasets when scaled with different techniques. Our experiments using 12 base classifiers, 300 datasets, and five STs demonstrate the feasibility and effectiveness of the approach. When using the ST selected by the Meta-scaler for each dataset, 10 of 12 base models tested achieved statistically significantly better classification performance than any fixed choice of a single ST. The Meta-scaler also outperforms state-of-the-art MtL approaches for ST selection. The source code, data, and results from the experiments in this article are available at a GitHub repository (https://github.com/amorimlb/meta_scaler).",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d8475d3f7ec9c656547985dffd4384fcb5670275.pdf",
      "citation_key": "amorim20240xf",
      "metadata": {
        "title": "Meta-Scaler: A Meta-Learning Framework for the Selection of Scaling Techniques",
        "authors": [
          "Lucas B V de Amorim",
          "George D. C. Cavalcanti",
          "Rafael M. O. Cruz"
        ],
        "published_date": "2024",
        "abstract": "Dataset scaling, a.k.a. normalization, is an essential preprocessing step in a machine learning (ML) pipeline. It aims to adjust the scale of attributes in a way that they all vary within the same range. This transformation is known to improve the performance of classification models. Still, there are several scaling techniques (STs) to choose from, and no ST is guaranteed to be the best for a dataset regardless of the classifier chosen. It is thus a problem- and classifier-dependent decision. Furthermore, there can be a huge difference in performance when selecting the wrong technique; hence, it should not be neglected. That said, the trial-and-error process of finding the most suitable technique for a particular dataset can be unfeasible. As an alternative, we propose the Meta-scaler, which uses meta-learning (MtL) to build meta-models to automatically select the best ST for a given dataset and classification algorithm. The meta-models learn to represent the relationship between meta-features extracted from the datasets and the performance of specific classification algorithms on these datasets when scaled with different techniques. Our experiments using 12 base classifiers, 300 datasets, and five STs demonstrate the feasibility and effectiveness of the approach. When using the ST selected by the Meta-scaler for each dataset, 10 of 12 base models tested achieved statistically significantly better classification performance than any fixed choice of a single ST. The Meta-scaler also outperforms state-of-the-art MtL approaches for ST selection. The source code, data, and results from the experiments in this article are available at a GitHub repository (https://github.com/amorimlb/meta_scaler).",
        "file_path": "paper_data/Deep_Meta-Learning/info/d8475d3f7ec9c656547985dffd4384fcb5670275.pdf",
        "venue": "IEEE Transactions on Neural Networks and Learning Systems",
        "citationCount": 6,
        "score": 6.0,
        "summary": "Dataset scaling, a.k.a. normalization, is an essential preprocessing step in a machine learning (ML) pipeline. It aims to adjust the scale of attributes in a way that they all vary within the same range. This transformation is known to improve the performance of classification models. Still, there are several scaling techniques (STs) to choose from, and no ST is guaranteed to be the best for a dataset regardless of the classifier chosen. It is thus a problem- and classifier-dependent decision. Furthermore, there can be a huge difference in performance when selecting the wrong technique; hence, it should not be neglected. That said, the trial-and-error process of finding the most suitable technique for a particular dataset can be unfeasible. As an alternative, we propose the Meta-scaler, which uses meta-learning (MtL) to build meta-models to automatically select the best ST for a given dataset and classification algorithm. The meta-models learn to represent the relationship between meta-features extracted from the datasets and the performance of specific classification algorithms on these datasets when scaled with different techniques. Our experiments using 12 base classifiers, 300 datasets, and five STs demonstrate the feasibility and effectiveness of the approach. When using the ST selected by the Meta-scaler for each dataset, 10 of 12 base models tested achieved statistically significantly better classification performance than any fixed choice of a single ST. The Meta-scaler also outperforms state-of-the-art MtL approaches for ST selection. The source code, data, and results from the experiments in this article are available at a GitHub repository (https://github.com/amorimlb/meta_scaler).",
        "keywords": []
      },
      "file_name": "d8475d3f7ec9c656547985dffd4384fcb5670275.pdf"
    },
    {
      "success": true,
      "doc_id": "e9dcf807869559178f6a75ba1da828ab",
      "summary": "This paper questions the effectiveness of a modern predictive uncertainty quantification approach, called \\emph{evidential deep learning} (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their perceived strong empirical performance on downstream tasks, a line of recent studies by Bengs et al. identify limitations of the existing methods to conclude their learned epistemic uncertainties are unreliable, e.g., in that they are non-vanishing even with infinite data. Building on and sharpening such analysis, we 1) provide a sharper understanding of the asymptotic behavior of a wide class of EDL methods by unifying various objective functions; 2) reveal that the EDL methods can be better interpreted as an out-of-distribution detection algorithm based on energy-based-models; and 3) conduct extensive ablation studies to better assess their empirical effectiveness with real-world datasets. Through all these analyses, we conclude that even when EDL methods are empirically effective on downstream tasks, this occurs despite their poor uncertainty quantification capabilities. Our investigation suggests that incorporating model uncertainty can help EDL methods faithfully quantify uncertainties and further improve performance on representative downstream tasks, albeit at the cost of additional computational complexity.",
      "intriguing_abstract": "This paper questions the effectiveness of a modern predictive uncertainty quantification approach, called \\emph{evidential deep learning} (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their perceived strong empirical performance on downstream tasks, a line of recent studies by Bengs et al. identify limitations of the existing methods to conclude their learned epistemic uncertainties are unreliable, e.g., in that they are non-vanishing even with infinite data. Building on and sharpening such analysis, we 1) provide a sharper understanding of the asymptotic behavior of a wide class of EDL methods by unifying various objective functions; 2) reveal that the EDL methods can be better interpreted as an out-of-distribution detection algorithm based on energy-based-models; and 3) conduct extensive ablation studies to better assess their empirical effectiveness with real-world datasets. Through all these analyses, we conclude that even when EDL methods are empirically effective on downstream tasks, this occurs despite their poor uncertainty quantification capabilities. Our investigation suggests that incorporating model uncertainty can help EDL methods faithfully quantify uncertainties and further improve performance on representative downstream tasks, albeit at the cost of additional computational complexity.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e5ff671a38bc7b115afc23a845a8e742c9529f3f.pdf",
      "citation_key": "shen2024hea",
      "metadata": {
        "title": "Are Uncertainty Quantification Capabilities of Evidential Deep Learning a Mirage?",
        "authors": [
          "Maohao Shen",
          "J. J. Ryu",
          "Soumya Ghosh",
          "Yuheng Bu",
          "P. Sattigeri",
          "Subhro Das",
          "Greg Wornell"
        ],
        "published_date": "2024",
        "abstract": "This paper questions the effectiveness of a modern predictive uncertainty quantification approach, called \\emph{evidential deep learning} (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their perceived strong empirical performance on downstream tasks, a line of recent studies by Bengs et al. identify limitations of the existing methods to conclude their learned epistemic uncertainties are unreliable, e.g., in that they are non-vanishing even with infinite data. Building on and sharpening such analysis, we 1) provide a sharper understanding of the asymptotic behavior of a wide class of EDL methods by unifying various objective functions; 2) reveal that the EDL methods can be better interpreted as an out-of-distribution detection algorithm based on energy-based-models; and 3) conduct extensive ablation studies to better assess their empirical effectiveness with real-world datasets. Through all these analyses, we conclude that even when EDL methods are empirically effective on downstream tasks, this occurs despite their poor uncertainty quantification capabilities. Our investigation suggests that incorporating model uncertainty can help EDL methods faithfully quantify uncertainties and further improve performance on representative downstream tasks, albeit at the cost of additional computational complexity.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e5ff671a38bc7b115afc23a845a8e742c9529f3f.pdf",
        "venue": "Neural Information Processing Systems",
        "citationCount": 5,
        "score": 5.0,
        "summary": "This paper questions the effectiveness of a modern predictive uncertainty quantification approach, called \\emph{evidential deep learning} (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their perceived strong empirical performance on downstream tasks, a line of recent studies by Bengs et al. identify limitations of the existing methods to conclude their learned epistemic uncertainties are unreliable, e.g., in that they are non-vanishing even with infinite data. Building on and sharpening such analysis, we 1) provide a sharper understanding of the asymptotic behavior of a wide class of EDL methods by unifying various objective functions; 2) reveal that the EDL methods can be better interpreted as an out-of-distribution detection algorithm based on energy-based-models; and 3) conduct extensive ablation studies to better assess their empirical effectiveness with real-world datasets. Through all these analyses, we conclude that even when EDL methods are empirically effective on downstream tasks, this occurs despite their poor uncertainty quantification capabilities. Our investigation suggests that incorporating model uncertainty can help EDL methods faithfully quantify uncertainties and further improve performance on representative downstream tasks, albeit at the cost of additional computational complexity.",
        "keywords": []
      },
      "file_name": "e5ff671a38bc7b115afc23a845a8e742c9529f3f.pdf"
    },
    {
      "success": true,
      "doc_id": "cce35e724cc8983031498abcad1effc0",
      "summary": "Recently, significant attention has been given to the idea of viewing relational databases as heterogeneous graphs, enabling the application of graph neural network (GNN) technology for predictive tasks. However, existing GNN methods struggle with the complexity of the heterogeneous graphs induced by databases with numerous tables and relations. Traditional approaches either consider all possible relational meta-paths, thus failing to scale with the number of relations, or rely on domain experts to identify relevant meta-paths. A recent solution does manage to learn informative meta-paths without expert supervision, but assumes that a node's class depends solely on the existence of a meta-path occurrence. In this work, we present a self-explainable heterogeneous GNN for relational data, that supports models in which class membership depends on aggregate information obtained from multiple occurrences of a meta-path. Experimental results show that in the context of relational databases, our approach effectively identifies informative meta-paths that faithfully capture the model's reasoning mechanisms. It significantly outperforms existing methods in both synthetic and real-world scenario.",
      "intriguing_abstract": "Recently, significant attention has been given to the idea of viewing relational databases as heterogeneous graphs, enabling the application of graph neural network (GNN) technology for predictive tasks. However, existing GNN methods struggle with the complexity of the heterogeneous graphs induced by databases with numerous tables and relations. Traditional approaches either consider all possible relational meta-paths, thus failing to scale with the number of relations, or rely on domain experts to identify relevant meta-paths. A recent solution does manage to learn informative meta-paths without expert supervision, but assumes that a node's class depends solely on the existence of a meta-path occurrence. In this work, we present a self-explainable heterogeneous GNN for relational data, that supports models in which class membership depends on aggregate information obtained from multiple occurrences of a meta-path. Experimental results show that in the context of relational databases, our approach effectively identifies informative meta-paths that faithfully capture the model's reasoning mechanisms. It significantly outperforms existing methods in both synthetic and real-world scenario.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c253896381b6763981e83dc67a726b6e5e1b6d8f.pdf",
      "citation_key": "ferrini20249g0",
      "metadata": {
        "title": "A Self-Explainable Heterogeneous GNN for Relational Deep Learning",
        "authors": [
          "Francesco Ferrini",
          "Antonio Longa",
          "Andrea Passerini",
          "Manfred Jaeger"
        ],
        "published_date": "2024",
        "abstract": "Recently, significant attention has been given to the idea of viewing relational databases as heterogeneous graphs, enabling the application of graph neural network (GNN) technology for predictive tasks. However, existing GNN methods struggle with the complexity of the heterogeneous graphs induced by databases with numerous tables and relations. Traditional approaches either consider all possible relational meta-paths, thus failing to scale with the number of relations, or rely on domain experts to identify relevant meta-paths. A recent solution does manage to learn informative meta-paths without expert supervision, but assumes that a node's class depends solely on the existence of a meta-path occurrence. In this work, we present a self-explainable heterogeneous GNN for relational data, that supports models in which class membership depends on aggregate information obtained from multiple occurrences of a meta-path. Experimental results show that in the context of relational databases, our approach effectively identifies informative meta-paths that faithfully capture the model's reasoning mechanisms. It significantly outperforms existing methods in both synthetic and real-world scenario.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c253896381b6763981e83dc67a726b6e5e1b6d8f.pdf",
        "venue": "Trans. Mach. Learn. Res.",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Recently, significant attention has been given to the idea of viewing relational databases as heterogeneous graphs, enabling the application of graph neural network (GNN) technology for predictive tasks. However, existing GNN methods struggle with the complexity of the heterogeneous graphs induced by databases with numerous tables and relations. Traditional approaches either consider all possible relational meta-paths, thus failing to scale with the number of relations, or rely on domain experts to identify relevant meta-paths. A recent solution does manage to learn informative meta-paths without expert supervision, but assumes that a node's class depends solely on the existence of a meta-path occurrence. In this work, we present a self-explainable heterogeneous GNN for relational data, that supports models in which class membership depends on aggregate information obtained from multiple occurrences of a meta-path. Experimental results show that in the context of relational databases, our approach effectively identifies informative meta-paths that faithfully capture the model's reasoning mechanisms. It significantly outperforms existing methods in both synthetic and real-world scenario.",
        "keywords": []
      },
      "file_name": "c253896381b6763981e83dc67a726b6e5e1b6d8f.pdf"
    },
    {
      "success": true,
      "doc_id": "20292260d6a8bb2d0ce903db53aa4757",
      "summary": "With the rapid development of location based services, multimodal spatio-temporal (ST) data including trajectories, transportation modes, traffic flow and social check-ins are being collected for deep learning based methods. These deep learning based methods learn ST correlations to support the downstream tasks in the fields such as smart mobility, smart city and other intelligent transportation systems. Despite their effectiveness, ST data fusion and forecasting methods face practical challenges in real-world scenarios. First, forecasting performance for ST data-insufficient area is inferior, making it necessary to transfer meta knowledge from heterogeneous area to enhance the sparse representations. Second, it is nontrivial to accurately forecast in multi-transportation-mode scenarios due to the fine-grained ST features of similar transportation modes, making it necessary to distinguish and measure the ST correlations to alleviate the influence caused by entangled ST features. At last, partial data modalities (e.g., transportation mode) are lost due to privacy or technical issues in certain scenarios, making it necessary to effectively fuse the multimodal sparse ST features and enrich the ST representations. To tackle these challenges, our research work aim to develop effective fusion and forecasting methods for multimodal ST data in smart mobility scenario. In this paper, we will introduce our recent works that investigates the challenges in terms of various real-world applications and establish the open challenges in this field for future work.",
      "intriguing_abstract": "With the rapid development of location based services, multimodal spatio-temporal (ST) data including trajectories, transportation modes, traffic flow and social check-ins are being collected for deep learning based methods. These deep learning based methods learn ST correlations to support the downstream tasks in the fields such as smart mobility, smart city and other intelligent transportation systems. Despite their effectiveness, ST data fusion and forecasting methods face practical challenges in real-world scenarios. First, forecasting performance for ST data-insufficient area is inferior, making it necessary to transfer meta knowledge from heterogeneous area to enhance the sparse representations. Second, it is nontrivial to accurately forecast in multi-transportation-mode scenarios due to the fine-grained ST features of similar transportation modes, making it necessary to distinguish and measure the ST correlations to alleviate the influence caused by entangled ST features. At last, partial data modalities (e.g., transportation mode) are lost due to privacy or technical issues in certain scenarios, making it necessary to effectively fuse the multimodal sparse ST features and enrich the ST representations. To tackle these challenges, our research work aim to develop effective fusion and forecasting methods for multimodal ST data in smart mobility scenario. In this paper, we will introduce our recent works that investigates the challenges in terms of various real-world applications and establish the open challenges in this field for future work.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/7efbdc4a651244d139708f7a5d4552562bdb351c.pdf",
      "citation_key": "wang2024tpb",
      "metadata": {
        "title": "Towards Effective Fusion and Forecasting of Multimodal Spatio-temporal Data for Smart Mobility",
        "authors": [
          "Chenxing Wang"
        ],
        "published_date": "2024",
        "abstract": "With the rapid development of location based services, multimodal spatio-temporal (ST) data including trajectories, transportation modes, traffic flow and social check-ins are being collected for deep learning based methods. These deep learning based methods learn ST correlations to support the downstream tasks in the fields such as smart mobility, smart city and other intelligent transportation systems. Despite their effectiveness, ST data fusion and forecasting methods face practical challenges in real-world scenarios. First, forecasting performance for ST data-insufficient area is inferior, making it necessary to transfer meta knowledge from heterogeneous area to enhance the sparse representations. Second, it is nontrivial to accurately forecast in multi-transportation-mode scenarios due to the fine-grained ST features of similar transportation modes, making it necessary to distinguish and measure the ST correlations to alleviate the influence caused by entangled ST features. At last, partial data modalities (e.g., transportation mode) are lost due to privacy or technical issues in certain scenarios, making it necessary to effectively fuse the multimodal sparse ST features and enrich the ST representations. To tackle these challenges, our research work aim to develop effective fusion and forecasting methods for multimodal ST data in smart mobility scenario. In this paper, we will introduce our recent works that investigates the challenges in terms of various real-world applications and establish the open challenges in this field for future work.",
        "file_path": "paper_data/Deep_Meta-Learning/info/7efbdc4a651244d139708f7a5d4552562bdb351c.pdf",
        "venue": "International Conference on Information and Knowledge Management",
        "citationCount": 5,
        "score": 5.0,
        "summary": "With the rapid development of location based services, multimodal spatio-temporal (ST) data including trajectories, transportation modes, traffic flow and social check-ins are being collected for deep learning based methods. These deep learning based methods learn ST correlations to support the downstream tasks in the fields such as smart mobility, smart city and other intelligent transportation systems. Despite their effectiveness, ST data fusion and forecasting methods face practical challenges in real-world scenarios. First, forecasting performance for ST data-insufficient area is inferior, making it necessary to transfer meta knowledge from heterogeneous area to enhance the sparse representations. Second, it is nontrivial to accurately forecast in multi-transportation-mode scenarios due to the fine-grained ST features of similar transportation modes, making it necessary to distinguish and measure the ST correlations to alleviate the influence caused by entangled ST features. At last, partial data modalities (e.g., transportation mode) are lost due to privacy or technical issues in certain scenarios, making it necessary to effectively fuse the multimodal sparse ST features and enrich the ST representations. To tackle these challenges, our research work aim to develop effective fusion and forecasting methods for multimodal ST data in smart mobility scenario. In this paper, we will introduce our recent works that investigates the challenges in terms of various real-world applications and establish the open challenges in this field for future work.",
        "keywords": []
      },
      "file_name": "7efbdc4a651244d139708f7a5d4552562bdb351c.pdf"
    },
    {
      "success": true,
      "doc_id": "f3f0ab90e2823ed7d3b2a6d99dc24db6",
      "summary": "Early fault detection (EFD) of rolling bearings aims at detecting the early symptoms of faults by monitoring small deviations of health states. Accurate EFD enables predictive maintenance and contributes to the stability of mechanical systems. In recent years, machine learning based methods have shown impressive performance on EFD. Most of the current machine learning‐based methods assume the availability for a large amount of data. However, in practice, the authors may only have a very limited amount of training data, which makes it hard to learn a reliable machine learning model. To address this concern, in this work, the authors propose to tackle EFD via meta learning. Specifically, the authors first formulate EFD as a few‐shot learning problem and then propose to tackle this problem with a metric‐based meta learning method. Furthermore, ensemble learning is further leveraged to improve the detection robustness. For the proposed method, the distribution difference from the working conditions and the bearings are considered. The experimental results on two bearing datasets show that the proposed method can achieve better EFD performance, that is, detecting incipient faults earlier while bringing in lower false alarms, compared with several frequently used EFD methods.",
      "intriguing_abstract": "Early fault detection (EFD) of rolling bearings aims at detecting the early symptoms of faults by monitoring small deviations of health states. Accurate EFD enables predictive maintenance and contributes to the stability of mechanical systems. In recent years, machine learning based methods have shown impressive performance on EFD. Most of the current machine learning‐based methods assume the availability for a large amount of data. However, in practice, the authors may only have a very limited amount of training data, which makes it hard to learn a reliable machine learning model. To address this concern, in this work, the authors propose to tackle EFD via meta learning. Specifically, the authors first formulate EFD as a few‐shot learning problem and then propose to tackle this problem with a metric‐based meta learning method. Furthermore, ensemble learning is further leveraged to improve the detection robustness. For the proposed method, the distribution difference from the working conditions and the bearings are considered. The experimental results on two bearing datasets show that the proposed method can achieve better EFD performance, that is, detecting incipient faults earlier while bringing in lower false alarms, compared with several frequently used EFD methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/644f33e831824777acb91c53a2be642d530f3848.pdf",
      "citation_key": "song2024epb",
      "metadata": {
        "title": "Early fault detection for rolling bearings: A meta‐learning approach",
        "authors": [
          "Wen-qi Song",
          "Di Wu",
          "Weiming Shen",
          "Benoit Boulet"
        ],
        "published_date": "2024",
        "abstract": "Early fault detection (EFD) of rolling bearings aims at detecting the early symptoms of faults by monitoring small deviations of health states. Accurate EFD enables predictive maintenance and contributes to the stability of mechanical systems. In recent years, machine learning based methods have shown impressive performance on EFD. Most of the current machine learning‐based methods assume the availability for a large amount of data. However, in practice, the authors may only have a very limited amount of training data, which makes it hard to learn a reliable machine learning model. To address this concern, in this work, the authors propose to tackle EFD via meta learning. Specifically, the authors first formulate EFD as a few‐shot learning problem and then propose to tackle this problem with a metric‐based meta learning method. Furthermore, ensemble learning is further leveraged to improve the detection robustness. For the proposed method, the distribution difference from the working conditions and the bearings are considered. The experimental results on two bearing datasets show that the proposed method can achieve better EFD performance, that is, detecting incipient faults earlier while bringing in lower false alarms, compared with several frequently used EFD methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/644f33e831824777acb91c53a2be642d530f3848.pdf",
        "venue": "IET Collaborative Intelligent Manufacturing",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Early fault detection (EFD) of rolling bearings aims at detecting the early symptoms of faults by monitoring small deviations of health states. Accurate EFD enables predictive maintenance and contributes to the stability of mechanical systems. In recent years, machine learning based methods have shown impressive performance on EFD. Most of the current machine learning‐based methods assume the availability for a large amount of data. However, in practice, the authors may only have a very limited amount of training data, which makes it hard to learn a reliable machine learning model. To address this concern, in this work, the authors propose to tackle EFD via meta learning. Specifically, the authors first formulate EFD as a few‐shot learning problem and then propose to tackle this problem with a metric‐based meta learning method. Furthermore, ensemble learning is further leveraged to improve the detection robustness. For the proposed method, the distribution difference from the working conditions and the bearings are considered. The experimental results on two bearing datasets show that the proposed method can achieve better EFD performance, that is, detecting incipient faults earlier while bringing in lower false alarms, compared with several frequently used EFD methods.",
        "keywords": []
      },
      "file_name": "644f33e831824777acb91c53a2be642d530f3848.pdf"
    },
    {
      "success": true,
      "doc_id": "e571df4cb18675f2c5eb982ca338f315",
      "summary": "Wireless traffic prediction is indispensable for network planning and resource management. Due to different population distributions and user behavior, there exist strong spatial-temporal variations in wireless traffic across different regions. Most of the conventional traffic prediction approaches can only tackle a particular spatial-temporal pattern and cannot capture such variations in wireless traffic. This motivates us to develop an adaptive approach which can tackle spatial-temporal variations and predict wireless traffic in different regions. In this paper, we formulate an adaptive traffic prediction problem from a probabilistic inference perspective and develop a variational spatial-temporal Bayesian meta-learning (VST-BML) algorithm. We model the traffic prediction in different regions as different prediction tasks. The proposed VST-BML algorithm can learn the common spatial-temporal features shared by all prediction tasks, and adaptively infer the task-specific parameters to tackle spatial-temporal variations. We evaluate the performance of our proposed VST-BML algorithm using a real-world traffic dataset. Experimental results show that the proposed algorithm can quickly adapt to different prediction tasks by using only a small number of data samples and provide accurate traffic prediction in different regions. When compared with five baseline methods, the proposed algorithm can reduce the root-mean-square error (RMSE) and mean absolute error (MAE) by 53.0% and 48.4%, respectively.",
      "intriguing_abstract": "Wireless traffic prediction is indispensable for network planning and resource management. Due to different population distributions and user behavior, there exist strong spatial-temporal variations in wireless traffic across different regions. Most of the conventional traffic prediction approaches can only tackle a particular spatial-temporal pattern and cannot capture such variations in wireless traffic. This motivates us to develop an adaptive approach which can tackle spatial-temporal variations and predict wireless traffic in different regions. In this paper, we formulate an adaptive traffic prediction problem from a probabilistic inference perspective and develop a variational spatial-temporal Bayesian meta-learning (VST-BML) algorithm. We model the traffic prediction in different regions as different prediction tasks. The proposed VST-BML algorithm can learn the common spatial-temporal features shared by all prediction tasks, and adaptively infer the task-specific parameters to tackle spatial-temporal variations. We evaluate the performance of our proposed VST-BML algorithm using a real-world traffic dataset. Experimental results show that the proposed algorithm can quickly adapt to different prediction tasks by using only a small number of data samples and provide accurate traffic prediction in different regions. When compared with five baseline methods, the proposed algorithm can reduce the root-mean-square error (RMSE) and mean absolute error (MAE) by 53.0% and 48.4%, respectively.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/d9956c775c776c1e4fd7980cd091fab70a55f37d.pdf",
      "citation_key": "wang20245h1",
      "metadata": {
        "title": "Bayesian Meta-Learning for Adaptive Traffic Prediction in Wireless Networks",
        "authors": [
          "Zih-Wei Wang",
          "Vincent W. S. Wong"
        ],
        "published_date": "2024",
        "abstract": "Wireless traffic prediction is indispensable for network planning and resource management. Due to different population distributions and user behavior, there exist strong spatial-temporal variations in wireless traffic across different regions. Most of the conventional traffic prediction approaches can only tackle a particular spatial-temporal pattern and cannot capture such variations in wireless traffic. This motivates us to develop an adaptive approach which can tackle spatial-temporal variations and predict wireless traffic in different regions. In this paper, we formulate an adaptive traffic prediction problem from a probabilistic inference perspective and develop a variational spatial-temporal Bayesian meta-learning (VST-BML) algorithm. We model the traffic prediction in different regions as different prediction tasks. The proposed VST-BML algorithm can learn the common spatial-temporal features shared by all prediction tasks, and adaptively infer the task-specific parameters to tackle spatial-temporal variations. We evaluate the performance of our proposed VST-BML algorithm using a real-world traffic dataset. Experimental results show that the proposed algorithm can quickly adapt to different prediction tasks by using only a small number of data samples and provide accurate traffic prediction in different regions. When compared with five baseline methods, the proposed algorithm can reduce the root-mean-square error (RMSE) and mean absolute error (MAE) by 53.0% and 48.4%, respectively.",
        "file_path": "paper_data/Deep_Meta-Learning/info/d9956c775c776c1e4fd7980cd091fab70a55f37d.pdf",
        "venue": "IEEE Transactions on Mobile Computing",
        "citationCount": 5,
        "score": 5.0,
        "summary": "Wireless traffic prediction is indispensable for network planning and resource management. Due to different population distributions and user behavior, there exist strong spatial-temporal variations in wireless traffic across different regions. Most of the conventional traffic prediction approaches can only tackle a particular spatial-temporal pattern and cannot capture such variations in wireless traffic. This motivates us to develop an adaptive approach which can tackle spatial-temporal variations and predict wireless traffic in different regions. In this paper, we formulate an adaptive traffic prediction problem from a probabilistic inference perspective and develop a variational spatial-temporal Bayesian meta-learning (VST-BML) algorithm. We model the traffic prediction in different regions as different prediction tasks. The proposed VST-BML algorithm can learn the common spatial-temporal features shared by all prediction tasks, and adaptively infer the task-specific parameters to tackle spatial-temporal variations. We evaluate the performance of our proposed VST-BML algorithm using a real-world traffic dataset. Experimental results show that the proposed algorithm can quickly adapt to different prediction tasks by using only a small number of data samples and provide accurate traffic prediction in different regions. When compared with five baseline methods, the proposed algorithm can reduce the root-mean-square error (RMSE) and mean absolute error (MAE) by 53.0% and 48.4%, respectively.",
        "keywords": []
      },
      "file_name": "d9956c775c776c1e4fd7980cd091fab70a55f37d.pdf"
    },
    {
      "success": true,
      "doc_id": "57dafd20975e4712c8650d59a9b9620a",
      "summary": "Here's a focused summary of the paper for a literature review:\n\n### Towards Robust and Interpretable EMG-based Hand Gesture Recognition using Deep Metric Meta Learning \\cite{tam2024a1h}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Current electromyography (EMG) pattern recognition (PR) models exhibit poor generalization in unconstrained real-world environments, hindering their adoption in applications like hand gesture control.\n    *   **Why Important & Challenging**:\n        *   Performance degradation is caused by external noise, interference, limb orientation, and sensor displacement.\n        *   Acquiring large, diverse EMG datasets is impractical due to user burden.\n        *   Supervised classification frameworks, especially deep learning (DL) models, are often black boxes, making interpretation of decisions and confidence levels difficult.\n        *   DL models trained with conventional cross-entropy loss are typically poorly calibrated and overconfident, posing significant risks in safety-critical systems (e.g., prostheses) where erroneous decisions are highly detrimental.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Traditional classification-based EMG HGR is leading but struggles with limited, user-specific data and generalization.\n        *   Decision rejection methods exist (e.g., using CNN posterior probabilities or evidence-based outputs) but rely heavily on training data quality and offer limited interpretability.\n        *   Metric center loss (e.g., CNNSC) improves feature discrimination but may require multiple models (e.g., autoencoders) per class and still depends on training data for generalization.\n        *   Meta-learning (e.g., MAML, FSL) has been explored in EMG for adaptation to signal variations or new users, but prior works largely overlooked model interpretability.\n    *   **Limitations of Previous Solutions**:\n        *   Poor generalization outside of controlled training conditions.\n        *   Lack of interpretability in black-box DL models, especially regarding confidence estimates.\n        *   Overconfidence and poor calibration in DL models trained with cross-entropy loss.\n        *   Existing decision rejection methods are often insufficient for out-of-domain data and lack transparent confidence measures.\n        *   Previous meta-learning efforts in EMG primarily focused on accuracy, not on generating interpretable and actionable signals like robust confidence.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**:\n        *   Re-frames EMG PR as a *representation learning problem* using a deep metric-based meta-learning framework.\n        *   **Siamese Deep Convolutional Neural Network (SDCNN)**: Serves as the front-end, trained to learn a semantically meaningful Euclidean embedding space from HD-EMG data.\n        *   **Contrastive Triplet Loss**: Guides the SDCNN training, enforcing proximity between same-class samples and maximizing distance between different-class samples in the embedding space.\n        *   **Nearest Centroid (NC) Classifier**: Used for inference, attributing test data to the class of the nearest centroid prototype in the learned embedding space. Centroids are computed from training data.\n        *   **Robust Class Proximity-Based Confidence Estimator**: Derived from the distances to class centroids in the embedding space, converted into class membership scores using a softmax function. This provides contextual information and informs decision rejection.\n    *   **Novelty or Difference**:\n        *   Shifts the paradigm from conventional classification to deep metric-based meta-learning for EMG PR, prioritizing interpretable representations.\n        *   Combines the feature extraction power of SDCNN with the transparent and intuitive nature of an NC classifier for both prediction and confidence estimation.\n        *   The confidence estimator is inherently derived from the learned data distributions in the embedding space, offering a more reliable and interpretable measure compared to typical softmax outputs of cross-entropy trained classifiers.\n        *   Leverages few-shot learning capabilities, allowing the handling of new prototypes without retraining the entire neural network.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   A novel deep metric-based meta-learning framework for EMG PR, integrating an SDCNN with contrastive triplet loss for supervised representation learning.\n        *   A nearest centroid classification approach coupled with a robust class proximity-based confidence estimator, providing interpretable decision-making and uncertainty quantification.\n    *   **System Design or Architectural Innovations**:\n        *   The SDCNN architecture is specifically designed for HD-EMG heat-map images, using 2D convolution blocks with shared parameters and no pooling layers (given low image resolution).\n        *   The overall system design separates feature embedding learning from classification and confidence estimation, enhancing modularity and interpretability.\n    *   **Theoretical Insights or Analysis**:\n        *   Demonstrates that framing EMG PR as a representation learning problem can effectively address generalization and interpretability challenges inherent in conventional classification.\n        *   Provides evidence that distance-based confidence derived from a semantically meaningful embedding space offers superior calibration and rejection capabilities, especially for out-of-domain data, compared to traditional softmax probabilities.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluated the model under three EMG PR test scenarios: in-domain, domain-divergent, and out-of-domain predictions.\n        *   Compared the proposed approach against a baseline Deep Convolutional Neural Network (DCNN) trained with categorical cross-entropy loss, a Support Vector Machine (SVM) with RBF kernel, and a CNNSC (CNN with center loss).\n        *   Utilized a custom HD-EMG dataset collected from 10 able-bodied users, comprising 6 static hand gestures and dynamic gesture sequences.\n        *   Standard EMG signal processing (filtering, DC offset removal, MA V envelope smoothing) was applied.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Accuracy-Rejection Curve (ARC)**: Measures the trade-off between accuracy and the rejection of uncertain predictions.\n        *   **Kullback-Leibler (KL) Divergence**: Quantifies the difference in confidence distributions between accurate and inaccurate predictions, indicating model calibration.\n        *   **Results**: The proposed meta-learning approach *outperformed comparable models* on both ARC and KL divergence metrics, demonstrating improved classifier precision in active decisions (after rejection) and better generalization and applicability.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper primarily focuses on addressing the limitations of *existing* approaches. While not explicitly stated as a limitation of their own method, the SDCNN architecture and hyperparameter choices are specific to the HD-EMG data format and may require re-tuning for different EMG sensor configurations or signal types. The dataset is from able-bodied users, implying the scope might need further validation for diverse user populations (e.g., amputees).\n    *   **Scope of Applicability**: The method is applicable to EMG-based hand gesture recognition, particularly in human-machine interfaces (HMI) where robust generalization, interpretability, and reliable decision rejection are critical (e.g., prosthetic control). It is designed to perform well in environments with limited training data and unconstrained conditions.\n\n7.  **Technical Significance**\n    *   **Advances the Technical State-of-the-Art**:\n        *   Offers a significant advancement in EMG PR by providing a deep learning framework that inherently addresses generalization, interpretability, and usability issues, moving beyond mere classification accuracy.\n        *   Introduces a robust and interpretable confidence estimation mechanism, crucial for safety-critical EMG-controlled devices, by leveraging a semantically meaningful embedding space.\n        *   Provides a practical solution for the inherent data limitations in EMG PR by adopting a meta-learning approach.\n    *   **Potential Impact on Future Research**:\n        *   Paves the way for developing more reliable, user-friendly, and safer EMG-based human-machine interfaces.\n        *   Encourages further research into deep metric learning and meta-learning for other physiological signal processing tasks requiring robust generalization and transparent uncertainty quantification.\n        *   Could inspire new directions in interpretable AI for biomedical applications, where understanding model decisions and confidence is paramount.",
      "intriguing_abstract": "Current EMG-based hand gesture recognition (HGR) systems falter in real-world environments due to poor generalization and the black-box nature of deep learning, posing significant risks in safety-critical applications. This paper introduces a paradigm-shifting deep metric meta-learning framework that re-frames EMG pattern recognition as a robust representation learning problem, inherently addressing these limitations.\n\nOur novel approach employs a Siamese Deep Convolutional Neural Network (SDCNN) trained with contrastive triplet loss to learn a semantically meaningful Euclidean embedding space from high-density EMG data. This enables a transparent Nearest Centroid classifier for prediction and, crucially, a robust class proximity-based confidence estimator. This estimator provides unprecedented interpretability and superior uncertainty quantification, allowing reliable decision rejection, especially for out-of-domain data. Leveraging few-shot learning capabilities, our framework adapts to new prototypes without extensive retraining. Validated across diverse scenarios, our method significantly outperforms existing models in generalization and calibration, paving the way for safer, more reliable, and user-adaptive human-machine interfaces, particularly in prosthetic control and other safety-critical HMI applications.",
      "keywords": [
        "EMG-based Hand Gesture Recognition",
        "Deep Metric Meta Learning",
        "Robust Generalization",
        "Model Interpretability",
        "Confidence Estimation",
        "Siamese Deep Convolutional Neural Network",
        "Contrastive Triplet Loss",
        "Nearest Centroid Classifier",
        "Representation Learning",
        "Uncertainty Quantification",
        "Few-Shot Learning",
        "Human-Machine Interfaces",
        "Classifier Calibration",
        "Decision Rejection"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/71c00beb70d83eab08f1cf6c32f48c112bd9bfdf.pdf",
      "citation_key": "tam2024a1h",
      "metadata": {
        "title": "Towards Robust and Interpretable EMG-based Hand Gesture Recognition using Deep Metric Meta Learning",
        "authors": [
          "S. Tam",
          "S. T. P. Raghu",
          "Étienne Buteau",
          "Erik J. Scheme",
          "Mounir Boukadoum",
          "Alexandre Campeau-Lecours",
          "Benoit Gosselin"
        ],
        "published_date": "2024",
        "abstract": "Current electromyography (EMG) pattern recognition (PR) models have been shown to generalize poorly in unconstrained environments, setting back their adoption in applications such as hand gesture control. This problem is often due to limited training data, exacerbated by the use of supervised classification frameworks that are known to be suboptimal in such settings. In this work, we propose a shift to deep metric-based meta-learning in EMG PR to supervise the creation of meaningful and interpretable representations. We use a Siamese Deep Convolutional Neural Network (SDCNN) and contrastive triplet loss to learn an EMG feature embedding space that captures the distribution of the different classes. A nearest-centroid approach is subsequently employed for inference, relying on how closely a test sample aligns with the established data distributions. We derive a robust class proximity-based confidence estimator that leads to a better rejection of incorrect decisions, i.e. false positives, especially when operating beyond the training data domain. We show our approach's efficacy by testing the trained SDCNN's predictions and confidence estimations on unseen data, both in and out of the training domain. The evaluation metrics include the accuracy-rejection curve and the Kullback-Leibler divergence between the confidence distributions of accurate and inaccurate predictions. Outperforming comparable models on both metrics, our results demonstrate that the proposed meta-learning approach improves the classifier's precision in active decisions (after rejection), thus leading to better generalization and applicability.",
        "file_path": "paper_data/Deep_Meta-Learning/info/71c00beb70d83eab08f1cf6c32f48c112bd9bfdf.pdf",
        "venue": "arXiv.org",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Here's a focused summary of the paper for a literature review:\n\n### Towards Robust and Interpretable EMG-based Hand Gesture Recognition using Deep Metric Meta Learning \\cite{tam2024a1h}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Current electromyography (EMG) pattern recognition (PR) models exhibit poor generalization in unconstrained real-world environments, hindering their adoption in applications like hand gesture control.\n    *   **Why Important & Challenging**:\n        *   Performance degradation is caused by external noise, interference, limb orientation, and sensor displacement.\n        *   Acquiring large, diverse EMG datasets is impractical due to user burden.\n        *   Supervised classification frameworks, especially deep learning (DL) models, are often black boxes, making interpretation of decisions and confidence levels difficult.\n        *   DL models trained with conventional cross-entropy loss are typically poorly calibrated and overconfident, posing significant risks in safety-critical systems (e.g., prostheses) where erroneous decisions are highly detrimental.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   Traditional classification-based EMG HGR is leading but struggles with limited, user-specific data and generalization.\n        *   Decision rejection methods exist (e.g., using CNN posterior probabilities or evidence-based outputs) but rely heavily on training data quality and offer limited interpretability.\n        *   Metric center loss (e.g., CNNSC) improves feature discrimination but may require multiple models (e.g., autoencoders) per class and still depends on training data for generalization.\n        *   Meta-learning (e.g., MAML, FSL) has been explored in EMG for adaptation to signal variations or new users, but prior works largely overlooked model interpretability.\n    *   **Limitations of Previous Solutions**:\n        *   Poor generalization outside of controlled training conditions.\n        *   Lack of interpretability in black-box DL models, especially regarding confidence estimates.\n        *   Overconfidence and poor calibration in DL models trained with cross-entropy loss.\n        *   Existing decision rejection methods are often insufficient for out-of-domain data and lack transparent confidence measures.\n        *   Previous meta-learning efforts in EMG primarily focused on accuracy, not on generating interpretable and actionable signals like robust confidence.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**:\n        *   Re-frames EMG PR as a *representation learning problem* using a deep metric-based meta-learning framework.\n        *   **Siamese Deep Convolutional Neural Network (SDCNN)**: Serves as the front-end, trained to learn a semantically meaningful Euclidean embedding space from HD-EMG data.\n        *   **Contrastive Triplet Loss**: Guides the SDCNN training, enforcing proximity between same-class samples and maximizing distance between different-class samples in the embedding space.\n        *   **Nearest Centroid (NC) Classifier**: Used for inference, attributing test data to the class of the nearest centroid prototype in the learned embedding space. Centroids are computed from training data.\n        *   **Robust Class Proximity-Based Confidence Estimator**: Derived from the distances to class centroids in the embedding space, converted into class membership scores using a softmax function. This provides contextual information and informs decision rejection.\n    *   **Novelty or Difference**:\n        *   Shifts the paradigm from conventional classification to deep metric-based meta-learning for EMG PR, prioritizing interpretable representations.\n        *   Combines the feature extraction power of SDCNN with the transparent and intuitive nature of an NC classifier for both prediction and confidence estimation.\n        *   The confidence estimator is inherently derived from the learned data distributions in the embedding space, offering a more reliable and interpretable measure compared to typical softmax outputs of cross-entropy trained classifiers.\n        *   Leverages few-shot learning capabilities, allowing the handling of new prototypes without retraining the entire neural network.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   A novel deep metric-based meta-learning framework for EMG PR, integrating an SDCNN with contrastive triplet loss for supervised representation learning.\n        *   A nearest centroid classification approach coupled with a robust class proximity-based confidence estimator, providing interpretable decision-making and uncertainty quantification.\n    *   **System Design or Architectural Innovations**:\n        *   The SDCNN architecture is specifically designed for HD-EMG heat-map images, using 2D convolution blocks with shared parameters and no pooling layers (given low image resolution).\n        *   The overall system design separates feature embedding learning from classification and confidence estimation, enhancing modularity and interpretability.\n    *   **Theoretical Insights or Analysis**:\n        *   Demonstrates that framing EMG PR as a representation learning problem can effectively address generalization and interpretability challenges inherent in conventional classification.\n        *   Provides evidence that distance-based confidence derived from a semantically meaningful embedding space offers superior calibration and rejection capabilities, especially for out-of-domain data, compared to traditional softmax probabilities.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   Evaluated the model under three EMG PR test scenarios: in-domain, domain-divergent, and out-of-domain predictions.\n        *   Compared the proposed approach against a baseline Deep Convolutional Neural Network (DCNN) trained with categorical cross-entropy loss, a Support Vector Machine (SVM) with RBF kernel, and a CNNSC (CNN with center loss).\n        *   Utilized a custom HD-EMG dataset collected from 10 able-bodied users, comprising 6 static hand gestures and dynamic gesture sequences.\n        *   Standard EMG signal processing (filtering, DC offset removal, MA V envelope smoothing) was applied.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Accuracy-Rejection Curve (ARC)**: Measures the trade-off between accuracy and the rejection of uncertain predictions.\n        *   **Kullback-Leibler (KL) Divergence**: Quantifies the difference in confidence distributions between accurate and inaccurate predictions, indicating model calibration.\n        *   **Results**: The proposed meta-learning approach *outperformed comparable models* on both ARC and KL divergence metrics, demonstrating improved classifier precision in active decisions (after rejection) and better generalization and applicability.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper primarily focuses on addressing the limitations of *existing* approaches. While not explicitly stated as a limitation of their own method, the SDCNN architecture and hyperparameter choices are specific to the HD-EMG data format and may require re-tuning for different EMG sensor configurations or signal types. The dataset is from able-bodied users, implying the scope might need further validation for diverse user populations (e.g., amputees).\n    *   **Scope of Applicability**: The method is applicable to EMG-based hand gesture recognition, particularly in human-machine interfaces (HMI) where robust generalization, interpretability, and reliable decision rejection are critical (e.g., prosthetic control). It is designed to perform well in environments with limited training data and unconstrained conditions.\n\n7.  **Technical Significance**\n    *   **Advances the Technical State-of-the-Art**:\n        *   Offers a significant advancement in EMG PR by providing a deep learning framework that inherently addresses generalization, interpretability, and usability issues, moving beyond mere classification accuracy.\n        *   Introduces a robust and interpretable confidence estimation mechanism, crucial for safety-critical EMG-controlled devices, by leveraging a semantically meaningful embedding space.\n        *   Provides a practical solution for the inherent data limitations in EMG PR by adopting a meta-learning approach.\n    *   **Potential Impact on Future Research**:\n        *   Paves the way for developing more reliable, user-friendly, and safer EMG-based human-machine interfaces.\n        *   Encourages further research into deep metric learning and meta-learning for other physiological signal processing tasks requiring robust generalization and transparent uncertainty quantification.\n        *   Could inspire new directions in interpretable AI for biomedical applications, where understanding model decisions and confidence is paramount.",
        "keywords": [
          "EMG-based Hand Gesture Recognition",
          "Deep Metric Meta Learning",
          "Robust Generalization",
          "Model Interpretability",
          "Confidence Estimation",
          "Siamese Deep Convolutional Neural Network",
          "Contrastive Triplet Loss",
          "Nearest Centroid Classifier",
          "Representation Learning",
          "Uncertainty Quantification",
          "Few-Shot Learning",
          "Human-Machine Interfaces",
          "Classifier Calibration",
          "Decision Rejection"
        ],
        "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n*   **abstract keywords:** \"we **propose** a shift to deep metric-based meta-learning\", \"we use a **siamese deep convolutional neural network (sdcnn)** and **contrastive triplet loss**\", \"a **nearest-centroid approach** is subsequently employed\", \"we **derive a robust class proximity-based confidence estimator**\". these phrases clearly indicate the development and presentation of new methods, algorithms, and system components.\n*   **introduction keywords:** \"we show our **approach’s efficacy by testing**...\", \"outperforming comparable models...\", \"the **proposed meta-learning approach** improves...\". while it mentions testing and evaluation (which are empirical aspects), these are used to demonstrate the effectiveness of the *new technical approach* being presented. the core contribution is the method itself.\n\nthe paper's primary focus is on introducing and detailing a novel deep metric meta-learning approach for emg-based hand gesture recognition, which aligns perfectly with the \"technical\" classification criteria. the empirical evaluation serves to validate this new technical contribution."
      },
      "file_name": "71c00beb70d83eab08f1cf6c32f48c112bd9bfdf.pdf"
    },
    {
      "success": true,
      "doc_id": "26b41f46e548cfb68d03cc56b76356a7",
      "summary": "This paper investigates the fronthaul compression problem in a user-centric cloud radio access network, in which single-antenna users are served by a central processor (CP) cooperatively via a cluster of remote radio heads (RRHs). To satisfy the fronthaul capacity constraint, this paper proposes a transform-compress-forward scheme, which consists of well-designed transformation matrices and uniform quantizers. The transformation matrices perform dimension reduction in the uplink and dimension expansion in the downlink. To reduce the communication overhead for designing the transformation matrices, this paper further proposes a deep learning framework to first learn a suboptimal transformation matrix at each RRH based on the local channel state information (CSI), and then to refine it iteratively. To facilitate the refinement process, we propose an efficient signaling scheme that only requires the transmission of low-dimensional effective CSI and its gradient between the CP and RRH, and further, a meta-learning based gated recurrent unit network to reduce the number of signaling transmission rounds. For the sum-rate maximization problem, simulation results show that the proposed two-stage neural network can perform close to the fully cooperative global CSI based benchmark with significantly reduced communication overhead for both the uplink and the downlink. Moreover, using the first stage alone can already outperform the existing local CSI based benchmark.",
      "intriguing_abstract": "This paper investigates the fronthaul compression problem in a user-centric cloud radio access network, in which single-antenna users are served by a central processor (CP) cooperatively via a cluster of remote radio heads (RRHs). To satisfy the fronthaul capacity constraint, this paper proposes a transform-compress-forward scheme, which consists of well-designed transformation matrices and uniform quantizers. The transformation matrices perform dimension reduction in the uplink and dimension expansion in the downlink. To reduce the communication overhead for designing the transformation matrices, this paper further proposes a deep learning framework to first learn a suboptimal transformation matrix at each RRH based on the local channel state information (CSI), and then to refine it iteratively. To facilitate the refinement process, we propose an efficient signaling scheme that only requires the transmission of low-dimensional effective CSI and its gradient between the CP and RRH, and further, a meta-learning based gated recurrent unit network to reduce the number of signaling transmission rounds. For the sum-rate maximization problem, simulation results show that the proposed two-stage neural network can perform close to the fully cooperative global CSI based benchmark with significantly reduced communication overhead for both the uplink and the downlink. Moreover, using the first stage alone can already outperform the existing local CSI based benchmark.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/17d70bb09b3be0601e5cdc3debbe81b2338b86ab.pdf",
      "citation_key": "qiao2024l71",
      "metadata": {
        "title": "Meta-Learning-Based Fronthaul Compression for Cloud Radio Access Networks",
        "authors": [
          "Ruihua Qiao",
          "Tao Jiang",
          "Weiyong Yu"
        ],
        "published_date": "2024",
        "abstract": "This paper investigates the fronthaul compression problem in a user-centric cloud radio access network, in which single-antenna users are served by a central processor (CP) cooperatively via a cluster of remote radio heads (RRHs). To satisfy the fronthaul capacity constraint, this paper proposes a transform-compress-forward scheme, which consists of well-designed transformation matrices and uniform quantizers. The transformation matrices perform dimension reduction in the uplink and dimension expansion in the downlink. To reduce the communication overhead for designing the transformation matrices, this paper further proposes a deep learning framework to first learn a suboptimal transformation matrix at each RRH based on the local channel state information (CSI), and then to refine it iteratively. To facilitate the refinement process, we propose an efficient signaling scheme that only requires the transmission of low-dimensional effective CSI and its gradient between the CP and RRH, and further, a meta-learning based gated recurrent unit network to reduce the number of signaling transmission rounds. For the sum-rate maximization problem, simulation results show that the proposed two-stage neural network can perform close to the fully cooperative global CSI based benchmark with significantly reduced communication overhead for both the uplink and the downlink. Moreover, using the first stage alone can already outperform the existing local CSI based benchmark.",
        "file_path": "paper_data/Deep_Meta-Learning/info/17d70bb09b3be0601e5cdc3debbe81b2338b86ab.pdf",
        "venue": "IEEE Transactions on Wireless Communications",
        "citationCount": 4,
        "score": 4.0,
        "summary": "This paper investigates the fronthaul compression problem in a user-centric cloud radio access network, in which single-antenna users are served by a central processor (CP) cooperatively via a cluster of remote radio heads (RRHs). To satisfy the fronthaul capacity constraint, this paper proposes a transform-compress-forward scheme, which consists of well-designed transformation matrices and uniform quantizers. The transformation matrices perform dimension reduction in the uplink and dimension expansion in the downlink. To reduce the communication overhead for designing the transformation matrices, this paper further proposes a deep learning framework to first learn a suboptimal transformation matrix at each RRH based on the local channel state information (CSI), and then to refine it iteratively. To facilitate the refinement process, we propose an efficient signaling scheme that only requires the transmission of low-dimensional effective CSI and its gradient between the CP and RRH, and further, a meta-learning based gated recurrent unit network to reduce the number of signaling transmission rounds. For the sum-rate maximization problem, simulation results show that the proposed two-stage neural network can perform close to the fully cooperative global CSI based benchmark with significantly reduced communication overhead for both the uplink and the downlink. Moreover, using the first stage alone can already outperform the existing local CSI based benchmark.",
        "keywords": []
      },
      "file_name": "17d70bb09b3be0601e5cdc3debbe81b2338b86ab.pdf"
    },
    {
      "success": true,
      "doc_id": "913803f785328ba72dfca1a839606b6b",
      "summary": "Repairing deep neural networks (DNNs) to maintain its performance during deployment presents significant challenges due to the potential occurrence of unknown but common environmental corruptions. Most existing DNN repair methods only focus on repairing DNN for each corruption separately, lacking the ability of generalizing to the myriad corruptions from the ever-changing deploying environment. In this work, we propose to repair DNN from a novel perspective, i.e. Learning to Repair (L2R), where the repairing of target DNN is realized as a general learning-to-learn, a.k.a. meta-learning, process. In specific, observing different corruptions are correlated on their data distributions, we propose to utilize previous DNN repair experiences as tasks for meta-learning how to repair the target corruption. With the meta-learning from different tasks, L2R learns a meta-knowledge that summarizes how the DNN is repaired under various environmental corruptions. The meta-knowledge essentially serves as a general repairing prior which enables the DNN quickly adapt to unknown corruptions, thus making our method generalizable to different type of corruptions. Practically, L2R benefits DNN repair with a general pipeline yet tailoring meta-learning for repairing DNN is not trivial. By re-designing the meta-learning components under DNN repair context, we further instantiate the proposed L2R strategy into a concrete model named MetaRepair with pragmatic assumption of experience availability. We conduct comprehensive experiments on the corrupted CIFAR-10 and tiny -ImageNet by applying MetaRepair to repair DenseNet, ConvNeXt and VAN. The experimental results confirmed the superior repairing and generalization capability of our proposed L2R strategy under various environmental corruptions.",
      "intriguing_abstract": "Repairing deep neural networks (DNNs) to maintain its performance during deployment presents significant challenges due to the potential occurrence of unknown but common environmental corruptions. Most existing DNN repair methods only focus on repairing DNN for each corruption separately, lacking the ability of generalizing to the myriad corruptions from the ever-changing deploying environment. In this work, we propose to repair DNN from a novel perspective, i.e. Learning to Repair (L2R), where the repairing of target DNN is realized as a general learning-to-learn, a.k.a. meta-learning, process. In specific, observing different corruptions are correlated on their data distributions, we propose to utilize previous DNN repair experiences as tasks for meta-learning how to repair the target corruption. With the meta-learning from different tasks, L2R learns a meta-knowledge that summarizes how the DNN is repaired under various environmental corruptions. The meta-knowledge essentially serves as a general repairing prior which enables the DNN quickly adapt to unknown corruptions, thus making our method generalizable to different type of corruptions. Practically, L2R benefits DNN repair with a general pipeline yet tailoring meta-learning for repairing DNN is not trivial. By re-designing the meta-learning components under DNN repair context, we further instantiate the proposed L2R strategy into a concrete model named MetaRepair with pragmatic assumption of experience availability. We conduct comprehensive experiments on the corrupted CIFAR-10 and tiny -ImageNet by applying MetaRepair to repair DenseNet, ConvNeXt and VAN. The experimental results confirmed the superior repairing and generalization capability of our proposed L2R strategy under various environmental corruptions.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/dae9960c44810cf0b9dc64ac8919eb34c19f3913.pdf",
      "citation_key": "xing2024n9q",
      "metadata": {
        "title": "MetaRepair: Learning to Repair Deep Neural Networks from Repairing Experiences",
        "authors": [
          "Yun Xing",
          "Qing Guo",
          "Xiaofeng Cao",
          "Ivor W. Tsang",
          "Lei Ma"
        ],
        "published_date": "2024",
        "abstract": "Repairing deep neural networks (DNNs) to maintain its performance during deployment presents significant challenges due to the potential occurrence of unknown but common environmental corruptions. Most existing DNN repair methods only focus on repairing DNN for each corruption separately, lacking the ability of generalizing to the myriad corruptions from the ever-changing deploying environment. In this work, we propose to repair DNN from a novel perspective, i.e. Learning to Repair (L2R), where the repairing of target DNN is realized as a general learning-to-learn, a.k.a. meta-learning, process. In specific, observing different corruptions are correlated on their data distributions, we propose to utilize previous DNN repair experiences as tasks for meta-learning how to repair the target corruption. With the meta-learning from different tasks, L2R learns a meta-knowledge that summarizes how the DNN is repaired under various environmental corruptions. The meta-knowledge essentially serves as a general repairing prior which enables the DNN quickly adapt to unknown corruptions, thus making our method generalizable to different type of corruptions. Practically, L2R benefits DNN repair with a general pipeline yet tailoring meta-learning for repairing DNN is not trivial. By re-designing the meta-learning components under DNN repair context, we further instantiate the proposed L2R strategy into a concrete model named MetaRepair with pragmatic assumption of experience availability. We conduct comprehensive experiments on the corrupted CIFAR-10 and tiny -ImageNet by applying MetaRepair to repair DenseNet, ConvNeXt and VAN. The experimental results confirmed the superior repairing and generalization capability of our proposed L2R strategy under various environmental corruptions.",
        "file_path": "paper_data/Deep_Meta-Learning/info/dae9960c44810cf0b9dc64ac8919eb34c19f3913.pdf",
        "venue": "ACM Multimedia",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Repairing deep neural networks (DNNs) to maintain its performance during deployment presents significant challenges due to the potential occurrence of unknown but common environmental corruptions. Most existing DNN repair methods only focus on repairing DNN for each corruption separately, lacking the ability of generalizing to the myriad corruptions from the ever-changing deploying environment. In this work, we propose to repair DNN from a novel perspective, i.e. Learning to Repair (L2R), where the repairing of target DNN is realized as a general learning-to-learn, a.k.a. meta-learning, process. In specific, observing different corruptions are correlated on their data distributions, we propose to utilize previous DNN repair experiences as tasks for meta-learning how to repair the target corruption. With the meta-learning from different tasks, L2R learns a meta-knowledge that summarizes how the DNN is repaired under various environmental corruptions. The meta-knowledge essentially serves as a general repairing prior which enables the DNN quickly adapt to unknown corruptions, thus making our method generalizable to different type of corruptions. Practically, L2R benefits DNN repair with a general pipeline yet tailoring meta-learning for repairing DNN is not trivial. By re-designing the meta-learning components under DNN repair context, we further instantiate the proposed L2R strategy into a concrete model named MetaRepair with pragmatic assumption of experience availability. We conduct comprehensive experiments on the corrupted CIFAR-10 and tiny -ImageNet by applying MetaRepair to repair DenseNet, ConvNeXt and VAN. The experimental results confirmed the superior repairing and generalization capability of our proposed L2R strategy under various environmental corruptions.",
        "keywords": []
      },
      "file_name": "dae9960c44810cf0b9dc64ac8919eb34c19f3913.pdf"
    },
    {
      "success": true,
      "doc_id": "9f763f8c0fe6a12fd908f49640dcb787",
      "summary": "Recent advances in deep learning-based methods have led to significant progress in the hyperspectral super-resolution (SR). However, the scarcity and the high dimension of data have hindered further development since deep models require sufficient data to learn stable patterns. Moreover, the huge domain differences between hyperspectral image (HSI) datasets pose a significant challenge in generalizability. To address these problems, we present a general hyperspectral SR framework via meta-transfer learning (MTL). We randomly sample various spectral ranges for SR tasks during MTL, allowing the model to accumulate diverse task experiences. Additionally, we implement a task schedule to gradually expand the number of bands, bridging the significant domain differences between datasets. By leveraging multiple datasets, we are able to achieve better performance and greater generalizability, making it applicable under various circumstances. Meanwhile, as a general framework, our scheme can be applied to existing methods to obtain performance improvements. In addition, we design an advanced network architecture based on the multifusion features to further improve the performance. Experiments demonstrate that our method not only achieves superior performance in both qualitative and quantitative terms but also can adapt robustly to a new and difficult sample, where few epochs can yield quite considerable results.",
      "intriguing_abstract": "Recent advances in deep learning-based methods have led to significant progress in the hyperspectral super-resolution (SR). However, the scarcity and the high dimension of data have hindered further development since deep models require sufficient data to learn stable patterns. Moreover, the huge domain differences between hyperspectral image (HSI) datasets pose a significant challenge in generalizability. To address these problems, we present a general hyperspectral SR framework via meta-transfer learning (MTL). We randomly sample various spectral ranges for SR tasks during MTL, allowing the model to accumulate diverse task experiences. Additionally, we implement a task schedule to gradually expand the number of bands, bridging the significant domain differences between datasets. By leveraging multiple datasets, we are able to achieve better performance and greater generalizability, making it applicable under various circumstances. Meanwhile, as a general framework, our scheme can be applied to existing methods to obtain performance improvements. In addition, we design an advanced network architecture based on the multifusion features to further improve the performance. Experiments demonstrate that our method not only achieves superior performance in both qualitative and quantitative terms but also can adapt robustly to a new and difficult sample, where few epochs can yield quite considerable results.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/272b071e05e960ef3adab2bc8a078fd165b268d5.pdf",
      "citation_key": "cheng2024mky",
      "metadata": {
        "title": "General Hyperspectral Image Super-Resolution via Meta-Transfer Learning",
        "authors": [
          "Yingsong Cheng",
          "Xinya Wang",
          "Yong Ma",
          "Xiaoguang Mei",
          "Minghui Wu",
          "Jiayi Ma"
        ],
        "published_date": "2024",
        "abstract": "Recent advances in deep learning-based methods have led to significant progress in the hyperspectral super-resolution (SR). However, the scarcity and the high dimension of data have hindered further development since deep models require sufficient data to learn stable patterns. Moreover, the huge domain differences between hyperspectral image (HSI) datasets pose a significant challenge in generalizability. To address these problems, we present a general hyperspectral SR framework via meta-transfer learning (MTL). We randomly sample various spectral ranges for SR tasks during MTL, allowing the model to accumulate diverse task experiences. Additionally, we implement a task schedule to gradually expand the number of bands, bridging the significant domain differences between datasets. By leveraging multiple datasets, we are able to achieve better performance and greater generalizability, making it applicable under various circumstances. Meanwhile, as a general framework, our scheme can be applied to existing methods to obtain performance improvements. In addition, we design an advanced network architecture based on the multifusion features to further improve the performance. Experiments demonstrate that our method not only achieves superior performance in both qualitative and quantitative terms but also can adapt robustly to a new and difficult sample, where few epochs can yield quite considerable results.",
        "file_path": "paper_data/Deep_Meta-Learning/info/272b071e05e960ef3adab2bc8a078fd165b268d5.pdf",
        "venue": "IEEE Transactions on Neural Networks and Learning Systems",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Recent advances in deep learning-based methods have led to significant progress in the hyperspectral super-resolution (SR). However, the scarcity and the high dimension of data have hindered further development since deep models require sufficient data to learn stable patterns. Moreover, the huge domain differences between hyperspectral image (HSI) datasets pose a significant challenge in generalizability. To address these problems, we present a general hyperspectral SR framework via meta-transfer learning (MTL). We randomly sample various spectral ranges for SR tasks during MTL, allowing the model to accumulate diverse task experiences. Additionally, we implement a task schedule to gradually expand the number of bands, bridging the significant domain differences between datasets. By leveraging multiple datasets, we are able to achieve better performance and greater generalizability, making it applicable under various circumstances. Meanwhile, as a general framework, our scheme can be applied to existing methods to obtain performance improvements. In addition, we design an advanced network architecture based on the multifusion features to further improve the performance. Experiments demonstrate that our method not only achieves superior performance in both qualitative and quantitative terms but also can adapt robustly to a new and difficult sample, where few epochs can yield quite considerable results.",
        "keywords": []
      },
      "file_name": "272b071e05e960ef3adab2bc8a078fd165b268d5.pdf"
    },
    {
      "success": true,
      "doc_id": "0d0ab8a085bce1a4dd46b6e9481da6e0",
      "summary": "Motor fault diagnosis is a fundamental aspect of ensuring the reliability of industrial equipment. However, industrial scenarios exhibit an inherent data scarcity problem, which imposes significant restrictions on the practical application of traditional deep learning-based intelligent fault diagnosis (IFD) methods. Typically, only a small volume of labeled data along with limited informative unlabeled data are available from industrial motors. Effectively utilizing informative unlabeled samples in the context of few-shot fault diagnosis poses a substantial challenge. In this article, a prototype refinement method for semi-supervised few-shot fault diagnosis based on deep reinforcement learning (DRL) is proposed. First, we propose to formalize a Markov decision process (MDP) of an iterative semi-supervised meta-learning strategy involving the selection of informative unlabeled samples and the refinement of category prototypes. Subsequently, we develop a mirror prototypical network (ProtoNet) structure for interaction with a DRL agent, which learns to adaptively select valuable samples to supervise the diagnosis process. Moreover, a state space involving feature embedding and category information is designed, and a comprehensive reward taking into account selection confidence, effectiveness, and representative is proposed. Extensive experiments on several motor experimental datasets verify the method’s effectiveness in few-shot diagnosis of unseen faults and new working conditions.",
      "intriguing_abstract": "Motor fault diagnosis is a fundamental aspect of ensuring the reliability of industrial equipment. However, industrial scenarios exhibit an inherent data scarcity problem, which imposes significant restrictions on the practical application of traditional deep learning-based intelligent fault diagnosis (IFD) methods. Typically, only a small volume of labeled data along with limited informative unlabeled data are available from industrial motors. Effectively utilizing informative unlabeled samples in the context of few-shot fault diagnosis poses a substantial challenge. In this article, a prototype refinement method for semi-supervised few-shot fault diagnosis based on deep reinforcement learning (DRL) is proposed. First, we propose to formalize a Markov decision process (MDP) of an iterative semi-supervised meta-learning strategy involving the selection of informative unlabeled samples and the refinement of category prototypes. Subsequently, we develop a mirror prototypical network (ProtoNet) structure for interaction with a DRL agent, which learns to adaptively select valuable samples to supervise the diagnosis process. Moreover, a state space involving feature embedding and category information is designed, and a comprehensive reward taking into account selection confidence, effectiveness, and representative is proposed. Extensive experiments on several motor experimental datasets verify the method’s effectiveness in few-shot diagnosis of unseen faults and new working conditions.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b079b1a459758b86c82ac7415dbe3eecee8b02e8.pdf",
      "citation_key": "xia20246dc",
      "metadata": {
        "title": "Learn to Supervise: Deep Reinforcement Learning-Based Prototype Refinement for Few-Shot Motor Fault Diagnosis",
        "authors": [
          "Pengcheng Xia",
          "Yixiang Huang",
          "Chengliang Liu",
          "Jie Liu"
        ],
        "published_date": "2024",
        "abstract": "Motor fault diagnosis is a fundamental aspect of ensuring the reliability of industrial equipment. However, industrial scenarios exhibit an inherent data scarcity problem, which imposes significant restrictions on the practical application of traditional deep learning-based intelligent fault diagnosis (IFD) methods. Typically, only a small volume of labeled data along with limited informative unlabeled data are available from industrial motors. Effectively utilizing informative unlabeled samples in the context of few-shot fault diagnosis poses a substantial challenge. In this article, a prototype refinement method for semi-supervised few-shot fault diagnosis based on deep reinforcement learning (DRL) is proposed. First, we propose to formalize a Markov decision process (MDP) of an iterative semi-supervised meta-learning strategy involving the selection of informative unlabeled samples and the refinement of category prototypes. Subsequently, we develop a mirror prototypical network (ProtoNet) structure for interaction with a DRL agent, which learns to adaptively select valuable samples to supervise the diagnosis process. Moreover, a state space involving feature embedding and category information is designed, and a comprehensive reward taking into account selection confidence, effectiveness, and representative is proposed. Extensive experiments on several motor experimental datasets verify the method’s effectiveness in few-shot diagnosis of unseen faults and new working conditions.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b079b1a459758b86c82ac7415dbe3eecee8b02e8.pdf",
        "venue": "IEEE Transactions on Neural Networks and Learning Systems",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Motor fault diagnosis is a fundamental aspect of ensuring the reliability of industrial equipment. However, industrial scenarios exhibit an inherent data scarcity problem, which imposes significant restrictions on the practical application of traditional deep learning-based intelligent fault diagnosis (IFD) methods. Typically, only a small volume of labeled data along with limited informative unlabeled data are available from industrial motors. Effectively utilizing informative unlabeled samples in the context of few-shot fault diagnosis poses a substantial challenge. In this article, a prototype refinement method for semi-supervised few-shot fault diagnosis based on deep reinforcement learning (DRL) is proposed. First, we propose to formalize a Markov decision process (MDP) of an iterative semi-supervised meta-learning strategy involving the selection of informative unlabeled samples and the refinement of category prototypes. Subsequently, we develop a mirror prototypical network (ProtoNet) structure for interaction with a DRL agent, which learns to adaptively select valuable samples to supervise the diagnosis process. Moreover, a state space involving feature embedding and category information is designed, and a comprehensive reward taking into account selection confidence, effectiveness, and representative is proposed. Extensive experiments on several motor experimental datasets verify the method’s effectiveness in few-shot diagnosis of unseen faults and new working conditions.",
        "keywords": []
      },
      "file_name": "b079b1a459758b86c82ac7415dbe3eecee8b02e8.pdf"
    },
    {
      "success": true,
      "doc_id": "b8ddd232871c74ebdfc20a246a0f188d",
      "summary": "Sketch-based image retrieval (SBIR) utilizes sketches to search for images containing similar objects or scenes. Due to the proliferation of touch-screen devices, sketching has become more accessible and therefore has received increasing attention. Deep learning has emerged as a potential tool for SBIR, allowing models to automatically extract image features and learn from large amounts of data. To the best of our knowledge, there is currently no systematic literature review (SLR) of SBIR with deep learning. Therefore, the aim of this review is to incorporate related works into a systematic study, highlighting the main contributions of individual researchers over the years, with a focus on past, present and future trends. To achieve the purpose of this study, 90 studies from 2016 to June 2023 in 4 databases were collected and analyzed using the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) framework. The specific models, datasets, evaluation metrics, and applications of deep learning in SBIR are discussed in detail. This study found that Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN) are the most widely used deep learning methods for SBIR. A commonly used dataset is Sketchy, especially in the latest Zero-shot sketch-based image retrieval (ZS-SBIR) task. The results show that Mean Average Precision (mAP) is the most commonly used metric for quantitative evaluation of SBIR. Finally, we provide some future directions and guidance for researchers based on the results of this review.",
      "intriguing_abstract": "Sketch-based image retrieval (SBIR) utilizes sketches to search for images containing similar objects or scenes. Due to the proliferation of touch-screen devices, sketching has become more accessible and therefore has received increasing attention. Deep learning has emerged as a potential tool for SBIR, allowing models to automatically extract image features and learn from large amounts of data. To the best of our knowledge, there is currently no systematic literature review (SLR) of SBIR with deep learning. Therefore, the aim of this review is to incorporate related works into a systematic study, highlighting the main contributions of individual researchers over the years, with a focus on past, present and future trends. To achieve the purpose of this study, 90 studies from 2016 to June 2023 in 4 databases were collected and analyzed using the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) framework. The specific models, datasets, evaluation metrics, and applications of deep learning in SBIR are discussed in detail. This study found that Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN) are the most widely used deep learning methods for SBIR. A commonly used dataset is Sketchy, especially in the latest Zero-shot sketch-based image retrieval (ZS-SBIR) task. The results show that Mean Average Precision (mAP) is the most commonly used metric for quantitative evaluation of SBIR. Finally, we provide some future directions and guidance for researchers based on the results of this review.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/51fa4c6047b661e596d1943fb8c54d03a8c85099.pdf",
      "citation_key": "yang20243gt",
      "metadata": {
        "title": "A Systematic Literature Review of Deep Learning Approaches for Sketch-Based Image Retrieval: Datasets, Metrics, and Future Directions",
        "authors": [
          "Fan Yang",
          "Nor Azman Ismail",
          "Y. Y. Pang",
          "V. Kebande",
          "Arafat Al-dhaqm",
          "T. W. Koh"
        ],
        "published_date": "2024",
        "abstract": "Sketch-based image retrieval (SBIR) utilizes sketches to search for images containing similar objects or scenes. Due to the proliferation of touch-screen devices, sketching has become more accessible and therefore has received increasing attention. Deep learning has emerged as a potential tool for SBIR, allowing models to automatically extract image features and learn from large amounts of data. To the best of our knowledge, there is currently no systematic literature review (SLR) of SBIR with deep learning. Therefore, the aim of this review is to incorporate related works into a systematic study, highlighting the main contributions of individual researchers over the years, with a focus on past, present and future trends. To achieve the purpose of this study, 90 studies from 2016 to June 2023 in 4 databases were collected and analyzed using the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) framework. The specific models, datasets, evaluation metrics, and applications of deep learning in SBIR are discussed in detail. This study found that Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN) are the most widely used deep learning methods for SBIR. A commonly used dataset is Sketchy, especially in the latest Zero-shot sketch-based image retrieval (ZS-SBIR) task. The results show that Mean Average Precision (mAP) is the most commonly used metric for quantitative evaluation of SBIR. Finally, we provide some future directions and guidance for researchers based on the results of this review.",
        "file_path": "paper_data/Deep_Meta-Learning/info/51fa4c6047b661e596d1943fb8c54d03a8c85099.pdf",
        "venue": "IEEE Access",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Sketch-based image retrieval (SBIR) utilizes sketches to search for images containing similar objects or scenes. Due to the proliferation of touch-screen devices, sketching has become more accessible and therefore has received increasing attention. Deep learning has emerged as a potential tool for SBIR, allowing models to automatically extract image features and learn from large amounts of data. To the best of our knowledge, there is currently no systematic literature review (SLR) of SBIR with deep learning. Therefore, the aim of this review is to incorporate related works into a systematic study, highlighting the main contributions of individual researchers over the years, with a focus on past, present and future trends. To achieve the purpose of this study, 90 studies from 2016 to June 2023 in 4 databases were collected and analyzed using the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) framework. The specific models, datasets, evaluation metrics, and applications of deep learning in SBIR are discussed in detail. This study found that Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN) are the most widely used deep learning methods for SBIR. A commonly used dataset is Sketchy, especially in the latest Zero-shot sketch-based image retrieval (ZS-SBIR) task. The results show that Mean Average Precision (mAP) is the most commonly used metric for quantitative evaluation of SBIR. Finally, we provide some future directions and guidance for researchers based on the results of this review.",
        "keywords": []
      },
      "file_name": "51fa4c6047b661e596d1943fb8c54d03a8c85099.pdf"
    },
    {
      "success": true,
      "doc_id": "e24408d5b90d1abcf906b8d695ee6aad",
      "summary": "Molecular property prediction is an important task in drug discovery. However, experimental data for many drug molecules are limited, especially for novel molecular structures or rare diseases which affect the accuracy of many deep learning methods that rely on large training datasets. To this end, we propose PG-DERN, a novel few-shot learning model for molecular property prediction. A dual-view encoder is introduced to learn a meaningful molecular representation by integrating information from node and subgraph. Next, a relation graph learning module is proposed to construct a relation graph based on the similarity between molecules, which improves the efficiency of information propagation and the accuracy of property prediction. In addition, we use a MAML-based meta-learning strategy to learn well-initialized meta-parameters. In order to guide the tuning of meta-parameters, a property-guided feature augmentation module is designed to transfer information from similar properties to the novel property to improve the comprehensiveness of the feature representation of molecules with novel property. A series of comparative experiments on four benchmark datasets demonstrate that the proposed PG-DERN outperforms state-of-the-art methods.",
      "intriguing_abstract": "Molecular property prediction is an important task in drug discovery. However, experimental data for many drug molecules are limited, especially for novel molecular structures or rare diseases which affect the accuracy of many deep learning methods that rely on large training datasets. To this end, we propose PG-DERN, a novel few-shot learning model for molecular property prediction. A dual-view encoder is introduced to learn a meaningful molecular representation by integrating information from node and subgraph. Next, a relation graph learning module is proposed to construct a relation graph based on the similarity between molecules, which improves the efficiency of information propagation and the accuracy of property prediction. In addition, we use a MAML-based meta-learning strategy to learn well-initialized meta-parameters. In order to guide the tuning of meta-parameters, a property-guided feature augmentation module is designed to transfer information from similar properties to the novel property to improve the comprehensiveness of the feature representation of molecules with novel property. A series of comparative experiments on four benchmark datasets demonstrate that the proposed PG-DERN outperforms state-of-the-art methods.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/52f37e9bd84547db2ecefed420715f312827c398.pdf",
      "citation_key": "zhang2024ycr",
      "metadata": {
        "title": "Property-Guided Few-Shot Learning for Molecular Property Prediction With Dual-View Encoder and Relation Graph Learning Network",
        "authors": [
          "Lianwei Zhang",
          "Dongjiang Niu",
          "Beiyi Zhang",
          "Qiang Zhang",
          "Zhen Li"
        ],
        "published_date": "2024",
        "abstract": "Molecular property prediction is an important task in drug discovery. However, experimental data for many drug molecules are limited, especially for novel molecular structures or rare diseases which affect the accuracy of many deep learning methods that rely on large training datasets. To this end, we propose PG-DERN, a novel few-shot learning model for molecular property prediction. A dual-view encoder is introduced to learn a meaningful molecular representation by integrating information from node and subgraph. Next, a relation graph learning module is proposed to construct a relation graph based on the similarity between molecules, which improves the efficiency of information propagation and the accuracy of property prediction. In addition, we use a MAML-based meta-learning strategy to learn well-initialized meta-parameters. In order to guide the tuning of meta-parameters, a property-guided feature augmentation module is designed to transfer information from similar properties to the novel property to improve the comprehensiveness of the feature representation of molecules with novel property. A series of comparative experiments on four benchmark datasets demonstrate that the proposed PG-DERN outperforms state-of-the-art methods.",
        "file_path": "paper_data/Deep_Meta-Learning/info/52f37e9bd84547db2ecefed420715f312827c398.pdf",
        "venue": "IEEE journal of biomedical and health informatics",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Molecular property prediction is an important task in drug discovery. However, experimental data for many drug molecules are limited, especially for novel molecular structures or rare diseases which affect the accuracy of many deep learning methods that rely on large training datasets. To this end, we propose PG-DERN, a novel few-shot learning model for molecular property prediction. A dual-view encoder is introduced to learn a meaningful molecular representation by integrating information from node and subgraph. Next, a relation graph learning module is proposed to construct a relation graph based on the similarity between molecules, which improves the efficiency of information propagation and the accuracy of property prediction. In addition, we use a MAML-based meta-learning strategy to learn well-initialized meta-parameters. In order to guide the tuning of meta-parameters, a property-guided feature augmentation module is designed to transfer information from similar properties to the novel property to improve the comprehensiveness of the feature representation of molecules with novel property. A series of comparative experiments on four benchmark datasets demonstrate that the proposed PG-DERN outperforms state-of-the-art methods.",
        "keywords": []
      },
      "file_name": "52f37e9bd84547db2ecefed420715f312827c398.pdf"
    },
    {
      "success": true,
      "doc_id": "0a47f0b66329be29261ed695b19068d1",
      "summary": "Humans can often quickly and efficiently solve new complex learning tasks given only a small set of examples. In contrast, modern artificially intelligent systems often require thousands or millions of observations in order to solve even the most basic tasks. Meta-learning aims to resolve this issue by leveraging past experiences from similar learning tasks to embed the appropriate inductive biases into the learning system. Historically methods for meta-learning components such as optimizers, parameter initializations, and more have led to significant performance increases. This thesis aims to explore the concept of meta-learning to improve performance, through the often-overlooked component of the loss function. The loss function is a vital component of a learning system, as it represents the primary learning objective, where success is determined and quantified by the system's ability to optimize for that objective successfully. In this thesis, we developed methods for meta-learning the loss function of deep neural networks. In particular, we first introduced a method for meta-learning symbolic model-agnostic loss function called Evolved Model Agnostic Loss (EvoMAL). This method consolidates recent advancements in loss function learning and enables the development of interpretable loss functions on commodity hardware. Through empirical and theoretical analysis, we uncovered patterns in the learned loss functions, which later inspired the development of Sparse Label Smoothing Regularization (SparseLSR), which is a significantly faster and more memory-efficient way to perform label smoothing regularization. Second, we challenged the conventional notion that a loss function must be a static function by developing Adaptive Loss Function Learning (AdaLFL), a method for meta-learning adaptive loss functions. Lastly, we developed Neural Procedural Bias Meta-Learning (NPBML) a task-adaptive few-shot learning method that meta-learns the parameter initialization, optimizer, and loss function simultaneously.",
      "intriguing_abstract": "Humans can often quickly and efficiently solve new complex learning tasks given only a small set of examples. In contrast, modern artificially intelligent systems often require thousands or millions of observations in order to solve even the most basic tasks. Meta-learning aims to resolve this issue by leveraging past experiences from similar learning tasks to embed the appropriate inductive biases into the learning system. Historically methods for meta-learning components such as optimizers, parameter initializations, and more have led to significant performance increases. This thesis aims to explore the concept of meta-learning to improve performance, through the often-overlooked component of the loss function. The loss function is a vital component of a learning system, as it represents the primary learning objective, where success is determined and quantified by the system's ability to optimize for that objective successfully. In this thesis, we developed methods for meta-learning the loss function of deep neural networks. In particular, we first introduced a method for meta-learning symbolic model-agnostic loss function called Evolved Model Agnostic Loss (EvoMAL). This method consolidates recent advancements in loss function learning and enables the development of interpretable loss functions on commodity hardware. Through empirical and theoretical analysis, we uncovered patterns in the learned loss functions, which later inspired the development of Sparse Label Smoothing Regularization (SparseLSR), which is a significantly faster and more memory-efficient way to perform label smoothing regularization. Second, we challenged the conventional notion that a loss function must be a static function by developing Adaptive Loss Function Learning (AdaLFL), a method for meta-learning adaptive loss functions. Lastly, we developed Neural Procedural Bias Meta-Learning (NPBML) a task-adaptive few-shot learning method that meta-learns the parameter initialization, optimizer, and loss function simultaneously.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5b32284df29baf5201cb8b2313dc077465b15838.pdf",
      "citation_key": "raymond202441h",
      "metadata": {
        "title": "Meta-Learning Loss Functions for Deep Neural Networks",
        "authors": [
          "Christian Raymond"
        ],
        "published_date": "2024",
        "abstract": "Humans can often quickly and efficiently solve new complex learning tasks given only a small set of examples. In contrast, modern artificially intelligent systems often require thousands or millions of observations in order to solve even the most basic tasks. Meta-learning aims to resolve this issue by leveraging past experiences from similar learning tasks to embed the appropriate inductive biases into the learning system. Historically methods for meta-learning components such as optimizers, parameter initializations, and more have led to significant performance increases. This thesis aims to explore the concept of meta-learning to improve performance, through the often-overlooked component of the loss function. The loss function is a vital component of a learning system, as it represents the primary learning objective, where success is determined and quantified by the system's ability to optimize for that objective successfully. In this thesis, we developed methods for meta-learning the loss function of deep neural networks. In particular, we first introduced a method for meta-learning symbolic model-agnostic loss function called Evolved Model Agnostic Loss (EvoMAL). This method consolidates recent advancements in loss function learning and enables the development of interpretable loss functions on commodity hardware. Through empirical and theoretical analysis, we uncovered patterns in the learned loss functions, which later inspired the development of Sparse Label Smoothing Regularization (SparseLSR), which is a significantly faster and more memory-efficient way to perform label smoothing regularization. Second, we challenged the conventional notion that a loss function must be a static function by developing Adaptive Loss Function Learning (AdaLFL), a method for meta-learning adaptive loss functions. Lastly, we developed Neural Procedural Bias Meta-Learning (NPBML) a task-adaptive few-shot learning method that meta-learns the parameter initialization, optimizer, and loss function simultaneously.",
        "file_path": "paper_data/Deep_Meta-Learning/info/5b32284df29baf5201cb8b2313dc077465b15838.pdf",
        "venue": "arXiv.org",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Humans can often quickly and efficiently solve new complex learning tasks given only a small set of examples. In contrast, modern artificially intelligent systems often require thousands or millions of observations in order to solve even the most basic tasks. Meta-learning aims to resolve this issue by leveraging past experiences from similar learning tasks to embed the appropriate inductive biases into the learning system. Historically methods for meta-learning components such as optimizers, parameter initializations, and more have led to significant performance increases. This thesis aims to explore the concept of meta-learning to improve performance, through the often-overlooked component of the loss function. The loss function is a vital component of a learning system, as it represents the primary learning objective, where success is determined and quantified by the system's ability to optimize for that objective successfully. In this thesis, we developed methods for meta-learning the loss function of deep neural networks. In particular, we first introduced a method for meta-learning symbolic model-agnostic loss function called Evolved Model Agnostic Loss (EvoMAL). This method consolidates recent advancements in loss function learning and enables the development of interpretable loss functions on commodity hardware. Through empirical and theoretical analysis, we uncovered patterns in the learned loss functions, which later inspired the development of Sparse Label Smoothing Regularization (SparseLSR), which is a significantly faster and more memory-efficient way to perform label smoothing regularization. Second, we challenged the conventional notion that a loss function must be a static function by developing Adaptive Loss Function Learning (AdaLFL), a method for meta-learning adaptive loss functions. Lastly, we developed Neural Procedural Bias Meta-Learning (NPBML) a task-adaptive few-shot learning method that meta-learns the parameter initialization, optimizer, and loss function simultaneously.",
        "keywords": []
      },
      "file_name": "5b32284df29baf5201cb8b2313dc077465b15838.pdf"
    },
    {
      "success": true,
      "doc_id": "da0566187e2452d86da779bc18656b70",
      "summary": ". The supremacy of deep learning in artificial intelligence (AI) contexts, including image and speech recognition, computer vision, and medical imaging, among others, has established it as AI’s dominant approach. Several studies have been conducted on the use of deep learning in physiological signals, especially in ECG signals, in recent years, but there has been a lack of comprehensive review on the use of deep learning in ECG for biometric systems. This review is divided into two main sections: it provides a comprehensive bibliographic review of deep learning for ECG classification towards assisting in disease diagnosis in the first part while presenting an overview of the field, pioneers, and landmark studies. The second part offers comprehensive information on the subject, starting with the mathematical background of deep learning algorithms, the ECG signal processing, and the function of the heart. Using a PRISMA framework, 309 research papers were initially identified through specified keywords. After applying inclusion criteria, 90 articles were retained for detailed analysis, excluding 24 documents based on exclusion criteria EC1 and the remainder due to EC2. Key findings reveal that deep learning models achieve an average accuracy improvement of 10-15% over traditional methods, with convolutional neural networks (CNNs) and recurrent neural networks (RNNs) demonstrating superior performance in capturing complex ECG patterns. Through ECG databases, deep learning algorithms, assessment frameworks, metrics, and code availability, this review designs a systematic view from different perspectives to highlight the trends, challenges, and opportunities of deep learning for ECG arrhythmia classification. This paper’s goal is to contribute to the knowledge of both new and experienced researchers and practitioners in the field so that they can learn and understand the various processes involved in ECG signal processing using deep learning.",
      "intriguing_abstract": ". The supremacy of deep learning in artificial intelligence (AI) contexts, including image and speech recognition, computer vision, and medical imaging, among others, has established it as AI’s dominant approach. Several studies have been conducted on the use of deep learning in physiological signals, especially in ECG signals, in recent years, but there has been a lack of comprehensive review on the use of deep learning in ECG for biometric systems. This review is divided into two main sections: it provides a comprehensive bibliographic review of deep learning for ECG classification towards assisting in disease diagnosis in the first part while presenting an overview of the field, pioneers, and landmark studies. The second part offers comprehensive information on the subject, starting with the mathematical background of deep learning algorithms, the ECG signal processing, and the function of the heart. Using a PRISMA framework, 309 research papers were initially identified through specified keywords. After applying inclusion criteria, 90 articles were retained for detailed analysis, excluding 24 documents based on exclusion criteria EC1 and the remainder due to EC2. Key findings reveal that deep learning models achieve an average accuracy improvement of 10-15% over traditional methods, with convolutional neural networks (CNNs) and recurrent neural networks (RNNs) demonstrating superior performance in capturing complex ECG patterns. Through ECG databases, deep learning algorithms, assessment frameworks, metrics, and code availability, this review designs a systematic view from different perspectives to highlight the trends, challenges, and opportunities of deep learning for ECG arrhythmia classification. This paper’s goal is to contribute to the knowledge of both new and experienced researchers and practitioners in the field so that they can learn and understand the various processes involved in ECG signal processing using deep learning.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/27c71dc136246f9e8a9c985af441cd7426e810ab.pdf",
      "citation_key": "khalid2024pss",
      "metadata": {
        "title": "The Applications of Deep Learning in ECG Classification for Disease Diagnosis: A Systematic Review and Meta-Data Analysis",
        "authors": [
          "Mudassar Khalid",
          "C. Pluempitiwiriyawej",
          "S. Wangsiripitak",
          "Ghulam Murtaza",
          "Abdulkadhem A Abdulkadhem"
        ],
        "published_date": "2024",
        "abstract": ". The supremacy of deep learning in artificial intelligence (AI) contexts, including image and speech recognition, computer vision, and medical imaging, among others, has established it as AI’s dominant approach. Several studies have been conducted on the use of deep learning in physiological signals, especially in ECG signals, in recent years, but there has been a lack of comprehensive review on the use of deep learning in ECG for biometric systems. This review is divided into two main sections: it provides a comprehensive bibliographic review of deep learning for ECG classification towards assisting in disease diagnosis in the first part while presenting an overview of the field, pioneers, and landmark studies. The second part offers comprehensive information on the subject, starting with the mathematical background of deep learning algorithms, the ECG signal processing, and the function of the heart. Using a PRISMA framework, 309 research papers were initially identified through specified keywords. After applying inclusion criteria, 90 articles were retained for detailed analysis, excluding 24 documents based on exclusion criteria EC1 and the remainder due to EC2. Key findings reveal that deep learning models achieve an average accuracy improvement of 10-15% over traditional methods, with convolutional neural networks (CNNs) and recurrent neural networks (RNNs) demonstrating superior performance in capturing complex ECG patterns. Through ECG databases, deep learning algorithms, assessment frameworks, metrics, and code availability, this review designs a systematic view from different perspectives to highlight the trends, challenges, and opportunities of deep learning for ECG arrhythmia classification. This paper’s goal is to contribute to the knowledge of both new and experienced researchers and practitioners in the field so that they can learn and understand the various processes involved in ECG signal processing using deep learning.",
        "file_path": "paper_data/Deep_Meta-Learning/info/27c71dc136246f9e8a9c985af441cd7426e810ab.pdf",
        "venue": "Engineering Journal",
        "citationCount": 4,
        "score": 4.0,
        "summary": ". The supremacy of deep learning in artificial intelligence (AI) contexts, including image and speech recognition, computer vision, and medical imaging, among others, has established it as AI’s dominant approach. Several studies have been conducted on the use of deep learning in physiological signals, especially in ECG signals, in recent years, but there has been a lack of comprehensive review on the use of deep learning in ECG for biometric systems. This review is divided into two main sections: it provides a comprehensive bibliographic review of deep learning for ECG classification towards assisting in disease diagnosis in the first part while presenting an overview of the field, pioneers, and landmark studies. The second part offers comprehensive information on the subject, starting with the mathematical background of deep learning algorithms, the ECG signal processing, and the function of the heart. Using a PRISMA framework, 309 research papers were initially identified through specified keywords. After applying inclusion criteria, 90 articles were retained for detailed analysis, excluding 24 documents based on exclusion criteria EC1 and the remainder due to EC2. Key findings reveal that deep learning models achieve an average accuracy improvement of 10-15% over traditional methods, with convolutional neural networks (CNNs) and recurrent neural networks (RNNs) demonstrating superior performance in capturing complex ECG patterns. Through ECG databases, deep learning algorithms, assessment frameworks, metrics, and code availability, this review designs a systematic view from different perspectives to highlight the trends, challenges, and opportunities of deep learning for ECG arrhythmia classification. This paper’s goal is to contribute to the knowledge of both new and experienced researchers and practitioners in the field so that they can learn and understand the various processes involved in ECG signal processing using deep learning.",
        "keywords": []
      },
      "file_name": "27c71dc136246f9e8a9c985af441cd7426e810ab.pdf"
    },
    {
      "success": true,
      "doc_id": "9bf2afc97d1e2473630ce430f3e9093f",
      "summary": "Modern natural language processing (NLP) state-of-the-art (SoTA) deep learning (DL) models have hundreds of millions of parameters, making them extremely complex. Large datasets are required for training these models, and while pretraining has reduced this requirement, human-labelled datasets are still necessary for fine-tuning. Few-shot learning (FSL) techniques, such as meta-learning, try to train models from smaller datasets to mitigate this cost. However, the tasks used to evaluate these meta-learners frequently diverge from the problems in the real world that they are meant to resolve. This work aims to apply meta-learning to a problem that is more pertinent to the real world: class incremental learning (IL). In this scenario, after completing its training, the model learns to classify newly introduced classes. One unique quality of meta-learners is that they can generalise from a small sample size to classes that have never been seen before, which makes them especially useful for class incremental learning (IL). The method describes how to emulate class IL using proxy new classes. This method allows a meta-learner to complete the task without the need for retraining. To generate predictions, the transformer-based aggregation function in a meta-learner that modifies data from examples across all classes has been proposed. The principal contributions of the model include concurrently considering the entire support and query sets, and prioritising attention to crucial samples, such as the question, to increase the significance of its impact during inference. The outcomes demonstrate that the model surpasses prevailing benchmarks in the industry. Notably, most meta-learners demonstrate significant generalisation in the context of class IL even without specific training for this task. This paper establishes a high-performing baseline for subsequent transformer-based aggregation techniques, thereby emphasising the practical significance of meta-learners in class IL.",
      "intriguing_abstract": "Modern natural language processing (NLP) state-of-the-art (SoTA) deep learning (DL) models have hundreds of millions of parameters, making them extremely complex. Large datasets are required for training these models, and while pretraining has reduced this requirement, human-labelled datasets are still necessary for fine-tuning. Few-shot learning (FSL) techniques, such as meta-learning, try to train models from smaller datasets to mitigate this cost. However, the tasks used to evaluate these meta-learners frequently diverge from the problems in the real world that they are meant to resolve. This work aims to apply meta-learning to a problem that is more pertinent to the real world: class incremental learning (IL). In this scenario, after completing its training, the model learns to classify newly introduced classes. One unique quality of meta-learners is that they can generalise from a small sample size to classes that have never been seen before, which makes them especially useful for class incremental learning (IL). The method describes how to emulate class IL using proxy new classes. This method allows a meta-learner to complete the task without the need for retraining. To generate predictions, the transformer-based aggregation function in a meta-learner that modifies data from examples across all classes has been proposed. The principal contributions of the model include concurrently considering the entire support and query sets, and prioritising attention to crucial samples, such as the question, to increase the significance of its impact during inference. The outcomes demonstrate that the model surpasses prevailing benchmarks in the industry. Notably, most meta-learners demonstrate significant generalisation in the context of class IL even without specific training for this task. This paper establishes a high-performing baseline for subsequent transformer-based aggregation techniques, thereby emphasising the practical significance of meta-learners in class IL.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5f72ae90072c4d0df0d4460e7818b6d5ee2cef00.pdf",
      "citation_key": "kumar2024he9",
      "metadata": {
        "title": "Meta-learning for real-world class incremental learning: a transformer-based approach",
        "authors": [
          "Sandeep Kumar",
          "Amit Sharma",
          "Vikrant Shokeen",
          "Ahmad Taher Azar",
          "Syed Umar Amin",
          "Zafar Iqbal Khan"
        ],
        "published_date": "2024",
        "abstract": "Modern natural language processing (NLP) state-of-the-art (SoTA) deep learning (DL) models have hundreds of millions of parameters, making them extremely complex. Large datasets are required for training these models, and while pretraining has reduced this requirement, human-labelled datasets are still necessary for fine-tuning. Few-shot learning (FSL) techniques, such as meta-learning, try to train models from smaller datasets to mitigate this cost. However, the tasks used to evaluate these meta-learners frequently diverge from the problems in the real world that they are meant to resolve. This work aims to apply meta-learning to a problem that is more pertinent to the real world: class incremental learning (IL). In this scenario, after completing its training, the model learns to classify newly introduced classes. One unique quality of meta-learners is that they can generalise from a small sample size to classes that have never been seen before, which makes them especially useful for class incremental learning (IL). The method describes how to emulate class IL using proxy new classes. This method allows a meta-learner to complete the task without the need for retraining. To generate predictions, the transformer-based aggregation function in a meta-learner that modifies data from examples across all classes has been proposed. The principal contributions of the model include concurrently considering the entire support and query sets, and prioritising attention to crucial samples, such as the question, to increase the significance of its impact during inference. The outcomes demonstrate that the model surpasses prevailing benchmarks in the industry. Notably, most meta-learners demonstrate significant generalisation in the context of class IL even without specific training for this task. This paper establishes a high-performing baseline for subsequent transformer-based aggregation techniques, thereby emphasising the practical significance of meta-learners in class IL.",
        "file_path": "paper_data/Deep_Meta-Learning/info/5f72ae90072c4d0df0d4460e7818b6d5ee2cef00.pdf",
        "venue": "Scientific Reports",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Modern natural language processing (NLP) state-of-the-art (SoTA) deep learning (DL) models have hundreds of millions of parameters, making them extremely complex. Large datasets are required for training these models, and while pretraining has reduced this requirement, human-labelled datasets are still necessary for fine-tuning. Few-shot learning (FSL) techniques, such as meta-learning, try to train models from smaller datasets to mitigate this cost. However, the tasks used to evaluate these meta-learners frequently diverge from the problems in the real world that they are meant to resolve. This work aims to apply meta-learning to a problem that is more pertinent to the real world: class incremental learning (IL). In this scenario, after completing its training, the model learns to classify newly introduced classes. One unique quality of meta-learners is that they can generalise from a small sample size to classes that have never been seen before, which makes them especially useful for class incremental learning (IL). The method describes how to emulate class IL using proxy new classes. This method allows a meta-learner to complete the task without the need for retraining. To generate predictions, the transformer-based aggregation function in a meta-learner that modifies data from examples across all classes has been proposed. The principal contributions of the model include concurrently considering the entire support and query sets, and prioritising attention to crucial samples, such as the question, to increase the significance of its impact during inference. The outcomes demonstrate that the model surpasses prevailing benchmarks in the industry. Notably, most meta-learners demonstrate significant generalisation in the context of class IL even without specific training for this task. This paper establishes a high-performing baseline for subsequent transformer-based aggregation techniques, thereby emphasising the practical significance of meta-learners in class IL.",
        "keywords": []
      },
      "file_name": "5f72ae90072c4d0df0d4460e7818b6d5ee2cef00.pdf"
    },
    {
      "success": true,
      "doc_id": "ead6400a357b57b1c9efd6b92e03ab00",
      "summary": "Current speech deepfake detection approaches perform satisfactorily against known adversaries; however, generalization to unseen attacks remains an open challenge. The proliferation of speech deepfakes on social media underscores the need for systems that can generalize to unseen attacks not observed during training. We address this problem from the perspective of meta-learning, aiming to learn attack-invariant features to adapt to unseen attacks with very few samples available. This approach is promising since generating of a high-scale training dataset is often expensive or infeasible. Our experiments demonstrated an improvement in the Equal Error Rate (EER) from 21.67% to 10.42% on the InTheWild dataset, using just 96 samples from the unseen dataset. Continuous few-shot adaptation ensures that the system remains up-to-date.",
      "intriguing_abstract": "Current speech deepfake detection approaches perform satisfactorily against known adversaries; however, generalization to unseen attacks remains an open challenge. The proliferation of speech deepfakes on social media underscores the need for systems that can generalize to unseen attacks not observed during training. We address this problem from the perspective of meta-learning, aiming to learn attack-invariant features to adapt to unseen attacks with very few samples available. This approach is promising since generating of a high-scale training dataset is often expensive or infeasible. Our experiments demonstrated an improvement in the Equal Error Rate (EER) from 21.67% to 10.42% on the InTheWild dataset, using just 96 samples from the unseen dataset. Continuous few-shot adaptation ensures that the system remains up-to-date.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/4481108a93744c5ad282a4ac2fea7883913184bb.pdf",
      "citation_key": "kukanov20249bs",
      "metadata": {
        "title": "Meta-Learning Approaches For Improving Detection of Unseen Speech Deepfakes",
        "authors": [
          "Ivan Kukanov",
          "Janne Laakkonen",
          "Tomi Kinnunen",
          "Ville Hautamäki"
        ],
        "published_date": "2024",
        "abstract": "Current speech deepfake detection approaches perform satisfactorily against known adversaries; however, generalization to unseen attacks remains an open challenge. The proliferation of speech deepfakes on social media underscores the need for systems that can generalize to unseen attacks not observed during training. We address this problem from the perspective of meta-learning, aiming to learn attack-invariant features to adapt to unseen attacks with very few samples available. This approach is promising since generating of a high-scale training dataset is often expensive or infeasible. Our experiments demonstrated an improvement in the Equal Error Rate (EER) from 21.67% to 10.42% on the InTheWild dataset, using just 96 samples from the unseen dataset. Continuous few-shot adaptation ensures that the system remains up-to-date.",
        "file_path": "paper_data/Deep_Meta-Learning/info/4481108a93744c5ad282a4ac2fea7883913184bb.pdf",
        "venue": "Spoken Language Technology Workshop",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Current speech deepfake detection approaches perform satisfactorily against known adversaries; however, generalization to unseen attacks remains an open challenge. The proliferation of speech deepfakes on social media underscores the need for systems that can generalize to unseen attacks not observed during training. We address this problem from the perspective of meta-learning, aiming to learn attack-invariant features to adapt to unseen attacks with very few samples available. This approach is promising since generating of a high-scale training dataset is often expensive or infeasible. Our experiments demonstrated an improvement in the Equal Error Rate (EER) from 21.67% to 10.42% on the InTheWild dataset, using just 96 samples from the unseen dataset. Continuous few-shot adaptation ensures that the system remains up-to-date.",
        "keywords": []
      },
      "file_name": "4481108a93744c5ad282a4ac2fea7883913184bb.pdf"
    },
    {
      "success": true,
      "doc_id": "4f55e0d824542c4280fd9160525ceaef",
      "summary": "Objective. Developing an efficient and generalizable method for inter-subject emotion recognition from neural signals is an emerging and challenging problem in affective computing. In particular, human subjects usually have heterogeneous neural signal characteristics and variable emotional activities that challenge the existing recognition algorithms from achieving high inter-subject emotion recognition accuracy. Approach. In this work, we propose a model-agnostic meta-learning algorithm to learn an adaptable and generalizable electroencephalogram-based emotion decoder at the subject’s population level. Different from many prior end-to-end emotion recognition algorithms, our learning algorithms include a pre-training step and an adaptation step. Specifically, our meta-decoder first learns on diverse known subjects and then further adapts it to unknown subjects with one-shot adaptation. More importantly, our algorithm is compatible with a variety of mainstream machine learning decoders for emotion recognition. Main results. We evaluate the adapted decoders obtained by our proposed algorithm on three Emotion-EEG datasets: SEED, DEAP, and DREAMER. Our comprehensive experimental results show that the adapted meta-emotion decoder achieves state-of-the-art inter-subject emotion recognition accuracy and outperforms the classical supervised learning baseline across different decoder architectures. Significance. Our results hold promise to incorporate the proposed meta-learning emotion recognition algorithm to effectively improve the inter-subject generalizability in designing future affective brain–computer interfaces.",
      "intriguing_abstract": "Objective. Developing an efficient and generalizable method for inter-subject emotion recognition from neural signals is an emerging and challenging problem in affective computing. In particular, human subjects usually have heterogeneous neural signal characteristics and variable emotional activities that challenge the existing recognition algorithms from achieving high inter-subject emotion recognition accuracy. Approach. In this work, we propose a model-agnostic meta-learning algorithm to learn an adaptable and generalizable electroencephalogram-based emotion decoder at the subject’s population level. Different from many prior end-to-end emotion recognition algorithms, our learning algorithms include a pre-training step and an adaptation step. Specifically, our meta-decoder first learns on diverse known subjects and then further adapts it to unknown subjects with one-shot adaptation. More importantly, our algorithm is compatible with a variety of mainstream machine learning decoders for emotion recognition. Main results. We evaluate the adapted decoders obtained by our proposed algorithm on three Emotion-EEG datasets: SEED, DEAP, and DREAMER. Our comprehensive experimental results show that the adapted meta-emotion decoder achieves state-of-the-art inter-subject emotion recognition accuracy and outperforms the classical supervised learning baseline across different decoder architectures. Significance. Our results hold promise to incorporate the proposed meta-learning emotion recognition algorithm to effectively improve the inter-subject generalizability in designing future affective brain–computer interfaces.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/5042c452912818d012274e9754a2c45cf203691d.pdf",
      "citation_key": "chen20245h8",
      "metadata": {
        "title": "Model-agnostic meta-learning for EEG-based inter-subject emotion recognition",
        "authors": [
          "Cheng Chen",
          "Hao Fang",
          "Yuxiao Yang",
          "Yi Zhou"
        ],
        "published_date": "2024",
        "abstract": "Objective. Developing an efficient and generalizable method for inter-subject emotion recognition from neural signals is an emerging and challenging problem in affective computing. In particular, human subjects usually have heterogeneous neural signal characteristics and variable emotional activities that challenge the existing recognition algorithms from achieving high inter-subject emotion recognition accuracy. Approach. In this work, we propose a model-agnostic meta-learning algorithm to learn an adaptable and generalizable electroencephalogram-based emotion decoder at the subject’s population level. Different from many prior end-to-end emotion recognition algorithms, our learning algorithms include a pre-training step and an adaptation step. Specifically, our meta-decoder first learns on diverse known subjects and then further adapts it to unknown subjects with one-shot adaptation. More importantly, our algorithm is compatible with a variety of mainstream machine learning decoders for emotion recognition. Main results. We evaluate the adapted decoders obtained by our proposed algorithm on three Emotion-EEG datasets: SEED, DEAP, and DREAMER. Our comprehensive experimental results show that the adapted meta-emotion decoder achieves state-of-the-art inter-subject emotion recognition accuracy and outperforms the classical supervised learning baseline across different decoder architectures. Significance. Our results hold promise to incorporate the proposed meta-learning emotion recognition algorithm to effectively improve the inter-subject generalizability in designing future affective brain–computer interfaces.",
        "file_path": "paper_data/Deep_Meta-Learning/info/5042c452912818d012274e9754a2c45cf203691d.pdf",
        "venue": "Journal of Neural Engineering",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Objective. Developing an efficient and generalizable method for inter-subject emotion recognition from neural signals is an emerging and challenging problem in affective computing. In particular, human subjects usually have heterogeneous neural signal characteristics and variable emotional activities that challenge the existing recognition algorithms from achieving high inter-subject emotion recognition accuracy. Approach. In this work, we propose a model-agnostic meta-learning algorithm to learn an adaptable and generalizable electroencephalogram-based emotion decoder at the subject’s population level. Different from many prior end-to-end emotion recognition algorithms, our learning algorithms include a pre-training step and an adaptation step. Specifically, our meta-decoder first learns on diverse known subjects and then further adapts it to unknown subjects with one-shot adaptation. More importantly, our algorithm is compatible with a variety of mainstream machine learning decoders for emotion recognition. Main results. We evaluate the adapted decoders obtained by our proposed algorithm on three Emotion-EEG datasets: SEED, DEAP, and DREAMER. Our comprehensive experimental results show that the adapted meta-emotion decoder achieves state-of-the-art inter-subject emotion recognition accuracy and outperforms the classical supervised learning baseline across different decoder architectures. Significance. Our results hold promise to incorporate the proposed meta-learning emotion recognition algorithm to effectively improve the inter-subject generalizability in designing future affective brain–computer interfaces.",
        "keywords": []
      },
      "file_name": "5042c452912818d012274e9754a2c45cf203691d.pdf"
    },
    {
      "success": true,
      "doc_id": "e542425f0d18a855b917b42ef315a21c",
      "summary": "Node classification is an essential problem in graph learning. However, many models typically obtain unsatisfactory performance when applied to few-shot scenarios. Some studies have attempted to combine meta-learning with graph neural networks to solve few-shot node classification on graphs. Despite their promising performance, some limitations remain. First, they employ the node encoding mechanism of homophilic graphs to learn node embeddings, even in heterophilic graphs. Second, existing models based on meta-learning ignore the interference of randomness in the learning process. Third, they are trained using only limited labeled nodes within the specific task, without explicitly utilizing numerous unlabeled nodes. Finally, they treat almost all sampled tasks equally without customizing them for their uniqueness. To address these issues, we propose a novel framework for few-shot node classification called Meta-GPS \\(++\\) . Specifically, we first adopt an efficient method to learn discriminative node representations on homophilic and heterophilic graphs. Then, we leverage a prototype-based approach to initialize parameters and contrastive learning for regularizing the distribution of node embeddings. Moreover, we apply self-training to extract valuable information from unlabeled nodes. Additionally, we adopt S \\({}^{2}\\) (scaling and shifting) transformation to learn transferable knowledge from diverse tasks. The results on real-world datasets show the superiority of Meta-GPS \\(++\\) . Our code is available here.",
      "intriguing_abstract": "Node classification is an essential problem in graph learning. However, many models typically obtain unsatisfactory performance when applied to few-shot scenarios. Some studies have attempted to combine meta-learning with graph neural networks to solve few-shot node classification on graphs. Despite their promising performance, some limitations remain. First, they employ the node encoding mechanism of homophilic graphs to learn node embeddings, even in heterophilic graphs. Second, existing models based on meta-learning ignore the interference of randomness in the learning process. Third, they are trained using only limited labeled nodes within the specific task, without explicitly utilizing numerous unlabeled nodes. Finally, they treat almost all sampled tasks equally without customizing them for their uniqueness. To address these issues, we propose a novel framework for few-shot node classification called Meta-GPS \\(++\\) . Specifically, we first adopt an efficient method to learn discriminative node representations on homophilic and heterophilic graphs. Then, we leverage a prototype-based approach to initialize parameters and contrastive learning for regularizing the distribution of node embeddings. Moreover, we apply self-training to extract valuable information from unlabeled nodes. Additionally, we adopt S \\({}^{2}\\) (scaling and shifting) transformation to learn transferable knowledge from diverse tasks. The results on real-world datasets show the superiority of Meta-GPS \\(++\\) . Our code is available here.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/588c69df5e7920db0037db76c41f933ee16c290d.pdf",
      "citation_key": "liu2024az5",
      "metadata": {
        "title": "Meta-GPS++: Enhancing Graph Meta-Learning with Contrastive Learning and Self-Training",
        "authors": [
          "Yonghao Liu",
          "Mengyu Li",
          "Ximing Li",
          "Lan Huang",
          "Fausto Giunchiglia",
          "Yanchun Liang",
          "Xiaoyue Feng",
          "Renchu Guan"
        ],
        "published_date": "2024",
        "abstract": "Node classification is an essential problem in graph learning. However, many models typically obtain unsatisfactory performance when applied to few-shot scenarios. Some studies have attempted to combine meta-learning with graph neural networks to solve few-shot node classification on graphs. Despite their promising performance, some limitations remain. First, they employ the node encoding mechanism of homophilic graphs to learn node embeddings, even in heterophilic graphs. Second, existing models based on meta-learning ignore the interference of randomness in the learning process. Third, they are trained using only limited labeled nodes within the specific task, without explicitly utilizing numerous unlabeled nodes. Finally, they treat almost all sampled tasks equally without customizing them for their uniqueness. To address these issues, we propose a novel framework for few-shot node classification called Meta-GPS \\(++\\) . Specifically, we first adopt an efficient method to learn discriminative node representations on homophilic and heterophilic graphs. Then, we leverage a prototype-based approach to initialize parameters and contrastive learning for regularizing the distribution of node embeddings. Moreover, we apply self-training to extract valuable information from unlabeled nodes. Additionally, we adopt S \\({}^{2}\\) (scaling and shifting) transformation to learn transferable knowledge from diverse tasks. The results on real-world datasets show the superiority of Meta-GPS \\(++\\) . Our code is available here.",
        "file_path": "paper_data/Deep_Meta-Learning/info/588c69df5e7920db0037db76c41f933ee16c290d.pdf",
        "venue": "ACM Transactions on Knowledge Discovery from Data",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Node classification is an essential problem in graph learning. However, many models typically obtain unsatisfactory performance when applied to few-shot scenarios. Some studies have attempted to combine meta-learning with graph neural networks to solve few-shot node classification on graphs. Despite their promising performance, some limitations remain. First, they employ the node encoding mechanism of homophilic graphs to learn node embeddings, even in heterophilic graphs. Second, existing models based on meta-learning ignore the interference of randomness in the learning process. Third, they are trained using only limited labeled nodes within the specific task, without explicitly utilizing numerous unlabeled nodes. Finally, they treat almost all sampled tasks equally without customizing them for their uniqueness. To address these issues, we propose a novel framework for few-shot node classification called Meta-GPS \\(++\\) . Specifically, we first adopt an efficient method to learn discriminative node representations on homophilic and heterophilic graphs. Then, we leverage a prototype-based approach to initialize parameters and contrastive learning for regularizing the distribution of node embeddings. Moreover, we apply self-training to extract valuable information from unlabeled nodes. Additionally, we adopt S \\({}^{2}\\) (scaling and shifting) transformation to learn transferable knowledge from diverse tasks. The results on real-world datasets show the superiority of Meta-GPS \\(++\\) . Our code is available here.",
        "keywords": []
      },
      "file_name": "588c69df5e7920db0037db76c41f933ee16c290d.pdf"
    },
    {
      "success": true,
      "doc_id": "fdc395d3454166190b0753e1f7ef0237",
      "summary": "Demand prediction is a crucial task for e-commerce and physical retail businesses, especially during high-stake sales events. However, the limited availability of historical data from these peak periods poses a significant challenge for traditional forecasting methods. In this paper, we propose a novel approach that leverages strategically chosen proxy data reflective of potential sales patterns from similar entities during non-peak periods, enriched by features learned from a graph neural networks (GNNs)-based forecasting model, to predict demand during peak events. We formulate the demand prediction as a meta-learning problem and develop the Feature-based First-Order Model-Agnostic Meta-Learning (F-FOMAML) algorithm that leverages proxy data from non-peak periods and GNN-generated relational metadata to learn feature-specific layer parameters, thereby adapting to demand forecasts for peak events. Theoretically, we show that by considering domain similarities through task-specific metadata, our model achieves improved generalization, where the excess risk decreases as the number of training tasks increases. Empirical evaluations on large-scale industrial datasets demonstrate the superiority of our approach. Compared to existing state-of-the-art models, our method demonstrates a notable improvement in demand prediction accuracy, reducing the Mean Absolute Error by 26.24% on an internal vending machine dataset and by 1.04% on the publicly accessible JD.com dataset.",
      "intriguing_abstract": "Demand prediction is a crucial task for e-commerce and physical retail businesses, especially during high-stake sales events. However, the limited availability of historical data from these peak periods poses a significant challenge for traditional forecasting methods. In this paper, we propose a novel approach that leverages strategically chosen proxy data reflective of potential sales patterns from similar entities during non-peak periods, enriched by features learned from a graph neural networks (GNNs)-based forecasting model, to predict demand during peak events. We formulate the demand prediction as a meta-learning problem and develop the Feature-based First-Order Model-Agnostic Meta-Learning (F-FOMAML) algorithm that leverages proxy data from non-peak periods and GNN-generated relational metadata to learn feature-specific layer parameters, thereby adapting to demand forecasts for peak events. Theoretically, we show that by considering domain similarities through task-specific metadata, our model achieves improved generalization, where the excess risk decreases as the number of training tasks increases. Empirical evaluations on large-scale industrial datasets demonstrate the superiority of our approach. Compared to existing state-of-the-art models, our method demonstrates a notable improvement in demand prediction accuracy, reducing the Mean Absolute Error by 26.24% on an internal vending machine dataset and by 1.04% on the publicly accessible JD.com dataset.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/fb0749b9bc04914e294f57c89199572e3cb5183c.pdf",
      "citation_key": "xu2024mf9",
      "metadata": {
        "title": "F-FOMAML: GNN-Enhanced Meta-Learning for Peak Period Demand Forecasting with Proxy Data",
        "authors": [
          "Zexing Xu",
          "Linjun Zhang",
          "Sitan Yang",
          "Rasoul Etesami",
          "Hanghang Tong",
          "Huan Zhang",
          "Jiawei Han"
        ],
        "published_date": "2024",
        "abstract": "Demand prediction is a crucial task for e-commerce and physical retail businesses, especially during high-stake sales events. However, the limited availability of historical data from these peak periods poses a significant challenge for traditional forecasting methods. In this paper, we propose a novel approach that leverages strategically chosen proxy data reflective of potential sales patterns from similar entities during non-peak periods, enriched by features learned from a graph neural networks (GNNs)-based forecasting model, to predict demand during peak events. We formulate the demand prediction as a meta-learning problem and develop the Feature-based First-Order Model-Agnostic Meta-Learning (F-FOMAML) algorithm that leverages proxy data from non-peak periods and GNN-generated relational metadata to learn feature-specific layer parameters, thereby adapting to demand forecasts for peak events. Theoretically, we show that by considering domain similarities through task-specific metadata, our model achieves improved generalization, where the excess risk decreases as the number of training tasks increases. Empirical evaluations on large-scale industrial datasets demonstrate the superiority of our approach. Compared to existing state-of-the-art models, our method demonstrates a notable improvement in demand prediction accuracy, reducing the Mean Absolute Error by 26.24% on an internal vending machine dataset and by 1.04% on the publicly accessible JD.com dataset.",
        "file_path": "paper_data/Deep_Meta-Learning/info/fb0749b9bc04914e294f57c89199572e3cb5183c.pdf",
        "venue": "arXiv.org",
        "citationCount": 4,
        "score": 4.0,
        "summary": "Demand prediction is a crucial task for e-commerce and physical retail businesses, especially during high-stake sales events. However, the limited availability of historical data from these peak periods poses a significant challenge for traditional forecasting methods. In this paper, we propose a novel approach that leverages strategically chosen proxy data reflective of potential sales patterns from similar entities during non-peak periods, enriched by features learned from a graph neural networks (GNNs)-based forecasting model, to predict demand during peak events. We formulate the demand prediction as a meta-learning problem and develop the Feature-based First-Order Model-Agnostic Meta-Learning (F-FOMAML) algorithm that leverages proxy data from non-peak periods and GNN-generated relational metadata to learn feature-specific layer parameters, thereby adapting to demand forecasts for peak events. Theoretically, we show that by considering domain similarities through task-specific metadata, our model achieves improved generalization, where the excess risk decreases as the number of training tasks increases. Empirical evaluations on large-scale industrial datasets demonstrate the superiority of our approach. Compared to existing state-of-the-art models, our method demonstrates a notable improvement in demand prediction accuracy, reducing the Mean Absolute Error by 26.24% on an internal vending machine dataset and by 1.04% on the publicly accessible JD.com dataset.",
        "keywords": []
      },
      "file_name": "fb0749b9bc04914e294f57c89199572e3cb5183c.pdf"
    },
    {
      "success": true,
      "doc_id": "96ef33080430ea5d0330e85fdcb9b690",
      "summary": "When dealing with data from distinct locations, machine learning algorithms tend to demonstrate an implicit preference of some locations over the others, which constitutes biases that sabotage the spatial fairness of the algorithm. This unfairness can easily introduce biases in subsequent decision-making given broad adoptions of learning-based solutions in practice. However, locational biases in AI are largely understudied. To mitigate biases over locations, we propose a locational meta-referee (Meta-Ref) to oversee the few-shot meta-training and meta-testing of a deep neural network. Meta-Ref dynamically adjusts the learning rates for training samples of given locations to advocate a fair performance across locations, through an explicit consideration of locational biases and the characteristics of input data. We present a three-phase training framework to learn both a meta-learning-based predictor and an integrated Meta-Ref that governs the fairness of the model. Once trained with a distribution of spatial tasks, Meta-Ref is applied to samples from new spatial tasks (i.e., regions outside the training area) to promote fairness during the fine-tune step. We carried out experiments with two case studies on crop monitoring and transportation safety, which show Meta-Ref can improve locational fairness while keeping the overall prediction quality at a similar level.",
      "intriguing_abstract": "When dealing with data from distinct locations, machine learning algorithms tend to demonstrate an implicit preference of some locations over the others, which constitutes biases that sabotage the spatial fairness of the algorithm. This unfairness can easily introduce biases in subsequent decision-making given broad adoptions of learning-based solutions in practice. However, locational biases in AI are largely understudied. To mitigate biases over locations, we propose a locational meta-referee (Meta-Ref) to oversee the few-shot meta-training and meta-testing of a deep neural network. Meta-Ref dynamically adjusts the learning rates for training samples of given locations to advocate a fair performance across locations, through an explicit consideration of locational biases and the characteristics of input data. We present a three-phase training framework to learn both a meta-learning-based predictor and an integrated Meta-Ref that governs the fairness of the model. Once trained with a distribution of spatial tasks, Meta-Ref is applied to samples from new spatial tasks (i.e., regions outside the training area) to promote fairness during the fine-tune step. We carried out experiments with two case studies on crop monitoring and transportation safety, which show Meta-Ref can improve locational fairness while keeping the overall prediction quality at a similar level.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/97718bcc9174ee43faf6ee4c105654a5ce7b35b1.pdf",
      "citation_key": "chen2024b4d",
      "metadata": {
        "title": "Referee-Meta-Learning for Fast Adaptation of Locational Fairness",
        "authors": [
          "Weiye Chen",
          "Yiqun Xie",
          "Xiaowei Jia",
          "Erhu He",
          "Han Bao",
          "Bang An",
          "Xun Zhou"
        ],
        "published_date": "2024",
        "abstract": "When dealing with data from distinct locations, machine learning algorithms tend to demonstrate an implicit preference of some locations over the others, which constitutes biases that sabotage the spatial fairness of the algorithm. This unfairness can easily introduce biases in subsequent decision-making given broad adoptions of learning-based solutions in practice. However, locational biases in AI are largely understudied. To mitigate biases over locations, we propose a locational meta-referee (Meta-Ref) to oversee the few-shot meta-training and meta-testing of a deep neural network. Meta-Ref dynamically adjusts the learning rates for training samples of given locations to advocate a fair performance across locations, through an explicit consideration of locational biases and the characteristics of input data. We present a three-phase training framework to learn both a meta-learning-based predictor and an integrated Meta-Ref that governs the fairness of the model. Once trained with a distribution of spatial tasks, Meta-Ref is applied to samples from new spatial tasks (i.e., regions outside the training area) to promote fairness during the fine-tune step. We carried out experiments with two case studies on crop monitoring and transportation safety, which show Meta-Ref can improve locational fairness while keeping the overall prediction quality at a similar level.",
        "file_path": "paper_data/Deep_Meta-Learning/info/97718bcc9174ee43faf6ee4c105654a5ce7b35b1.pdf",
        "venue": "AAAI Conference on Artificial Intelligence",
        "citationCount": 3,
        "score": 3.0,
        "summary": "When dealing with data from distinct locations, machine learning algorithms tend to demonstrate an implicit preference of some locations over the others, which constitutes biases that sabotage the spatial fairness of the algorithm. This unfairness can easily introduce biases in subsequent decision-making given broad adoptions of learning-based solutions in practice. However, locational biases in AI are largely understudied. To mitigate biases over locations, we propose a locational meta-referee (Meta-Ref) to oversee the few-shot meta-training and meta-testing of a deep neural network. Meta-Ref dynamically adjusts the learning rates for training samples of given locations to advocate a fair performance across locations, through an explicit consideration of locational biases and the characteristics of input data. We present a three-phase training framework to learn both a meta-learning-based predictor and an integrated Meta-Ref that governs the fairness of the model. Once trained with a distribution of spatial tasks, Meta-Ref is applied to samples from new spatial tasks (i.e., regions outside the training area) to promote fairness during the fine-tune step. We carried out experiments with two case studies on crop monitoring and transportation safety, which show Meta-Ref can improve locational fairness while keeping the overall prediction quality at a similar level.",
        "keywords": []
      },
      "file_name": "97718bcc9174ee43faf6ee4c105654a5ce7b35b1.pdf"
    },
    {
      "success": true,
      "doc_id": "66d5fa17139fb5c8b3fa3abac1162cb0",
      "summary": "Abstract Motivation High-throughput techniques have produced a large amount of high-dimensional multi-omics data, which makes it promising to predict patient survival outcomes more accurately. Recent work has showed the superiority of multi-omics data in survival analysis. However, it remains challenging to integrate multi-omics data to solve few-shot survival prediction problem, with only a few available training samples, especially for rare cancers. Results In this work, we propose a meta-learning framework for multi-omics few-shot survival analysis, namely MMOSurv, which enables to learn an effective multi-omics survival prediction model from a very few training samples of a specific cancer type, with the meta-knowledge across tasks from relevant cancer types. By assuming a deep Cox survival model with multiple omics, MMOSurv first learns an adaptable parameter initialization for the multi-omics survival model from abundant data of relevant cancers, and then adapts the parameters quickly and efficiently for the target cancer task with a very few training samples. Our experiments on eleven cancer types in The Cancer Genome Atlas datasets show that, compared to single-omics meta-learning methods, MMOSurv can better utilize the meta-information of similarities and relationships between different omics data from relevant cancer datasets to improve survival prediction of the target cancer with a very few multi-omics training samples. Furthermore, MMOSurv achieves better prediction performance than other state-of-the-art strategies such as multitask learning and pretraining. Availability and implementation MMOSurv is freely available at https://github.com/LiminLi-xjtu/MMOSurv",
      "intriguing_abstract": "Abstract Motivation High-throughput techniques have produced a large amount of high-dimensional multi-omics data, which makes it promising to predict patient survival outcomes more accurately. Recent work has showed the superiority of multi-omics data in survival analysis. However, it remains challenging to integrate multi-omics data to solve few-shot survival prediction problem, with only a few available training samples, especially for rare cancers. Results In this work, we propose a meta-learning framework for multi-omics few-shot survival analysis, namely MMOSurv, which enables to learn an effective multi-omics survival prediction model from a very few training samples of a specific cancer type, with the meta-knowledge across tasks from relevant cancer types. By assuming a deep Cox survival model with multiple omics, MMOSurv first learns an adaptable parameter initialization for the multi-omics survival model from abundant data of relevant cancers, and then adapts the parameters quickly and efficiently for the target cancer task with a very few training samples. Our experiments on eleven cancer types in The Cancer Genome Atlas datasets show that, compared to single-omics meta-learning methods, MMOSurv can better utilize the meta-information of similarities and relationships between different omics data from relevant cancer datasets to improve survival prediction of the target cancer with a very few multi-omics training samples. Furthermore, MMOSurv achieves better prediction performance than other state-of-the-art strategies such as multitask learning and pretraining. Availability and implementation MMOSurv is freely available at https://github.com/LiminLi-xjtu/MMOSurv",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/21f5dba5b14c4d78bd869e2a05b4bb9f74db2157.pdf",
      "citation_key": "wen2024xmk",
      "metadata": {
        "title": "MMOSurv: meta-learning for few-shot survival analysis with multi-omics data",
        "authors": [
          "Gang Wen",
          "Limin Li"
        ],
        "published_date": "2024",
        "abstract": "Abstract Motivation High-throughput techniques have produced a large amount of high-dimensional multi-omics data, which makes it promising to predict patient survival outcomes more accurately. Recent work has showed the superiority of multi-omics data in survival analysis. However, it remains challenging to integrate multi-omics data to solve few-shot survival prediction problem, with only a few available training samples, especially for rare cancers. Results In this work, we propose a meta-learning framework for multi-omics few-shot survival analysis, namely MMOSurv, which enables to learn an effective multi-omics survival prediction model from a very few training samples of a specific cancer type, with the meta-knowledge across tasks from relevant cancer types. By assuming a deep Cox survival model with multiple omics, MMOSurv first learns an adaptable parameter initialization for the multi-omics survival model from abundant data of relevant cancers, and then adapts the parameters quickly and efficiently for the target cancer task with a very few training samples. Our experiments on eleven cancer types in The Cancer Genome Atlas datasets show that, compared to single-omics meta-learning methods, MMOSurv can better utilize the meta-information of similarities and relationships between different omics data from relevant cancer datasets to improve survival prediction of the target cancer with a very few multi-omics training samples. Furthermore, MMOSurv achieves better prediction performance than other state-of-the-art strategies such as multitask learning and pretraining. Availability and implementation MMOSurv is freely available at https://github.com/LiminLi-xjtu/MMOSurv",
        "file_path": "paper_data/Deep_Meta-Learning/info/21f5dba5b14c4d78bd869e2a05b4bb9f74db2157.pdf",
        "venue": "Bioinformatics",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Abstract Motivation High-throughput techniques have produced a large amount of high-dimensional multi-omics data, which makes it promising to predict patient survival outcomes more accurately. Recent work has showed the superiority of multi-omics data in survival analysis. However, it remains challenging to integrate multi-omics data to solve few-shot survival prediction problem, with only a few available training samples, especially for rare cancers. Results In this work, we propose a meta-learning framework for multi-omics few-shot survival analysis, namely MMOSurv, which enables to learn an effective multi-omics survival prediction model from a very few training samples of a specific cancer type, with the meta-knowledge across tasks from relevant cancer types. By assuming a deep Cox survival model with multiple omics, MMOSurv first learns an adaptable parameter initialization for the multi-omics survival model from abundant data of relevant cancers, and then adapts the parameters quickly and efficiently for the target cancer task with a very few training samples. Our experiments on eleven cancer types in The Cancer Genome Atlas datasets show that, compared to single-omics meta-learning methods, MMOSurv can better utilize the meta-information of similarities and relationships between different omics data from relevant cancer datasets to improve survival prediction of the target cancer with a very few multi-omics training samples. Furthermore, MMOSurv achieves better prediction performance than other state-of-the-art strategies such as multitask learning and pretraining. Availability and implementation MMOSurv is freely available at https://github.com/LiminLi-xjtu/MMOSurv",
        "keywords": []
      },
      "file_name": "21f5dba5b14c4d78bd869e2a05b4bb9f74db2157.pdf"
    },
    {
      "success": true,
      "doc_id": "af4b47b0a7cc826b9761f3b21b98d36c",
      "summary": "Abstract Regulation on denitrifying microbiomes is crucial for sustainable industrial biotechnology and ecological nitrogen cycling. The holistic genetic profiles of microbiomes can be provided by meta‐omics. However, precise decryption and further applications of highly complex microbiomes and corresponding meta‐omics data sets remain great challenges. Here, we combined optogenetics and geometric deep learning to form a discover–model–learn–advance (DMLA) cycle for denitrification microbiome encryption and regulation. Graph neural networks (GNNs) exhibited superior performance in integrating biological knowledge and identifying coexpression gene panels, which could be utilized to predict unknown phenotypes, elucidate molecular biology mechanisms, and advance biotechnologies. Through the DMLA cycle, we discovered the wavelength‐divergent secretion system and nitrate‐superoxide coregulation, realizing increasing extracellular protein production by 83.8% and facilitating nitrate removal with 99.9% enhancement. Our study showcased the potential of GNNs‐empowered optogenetic approaches for regulating denitrification and accelerating the mechanistic discovery of microbiomes for in‐depth research and versatile applications.",
      "intriguing_abstract": "Abstract Regulation on denitrifying microbiomes is crucial for sustainable industrial biotechnology and ecological nitrogen cycling. The holistic genetic profiles of microbiomes can be provided by meta‐omics. However, precise decryption and further applications of highly complex microbiomes and corresponding meta‐omics data sets remain great challenges. Here, we combined optogenetics and geometric deep learning to form a discover–model–learn–advance (DMLA) cycle for denitrification microbiome encryption and regulation. Graph neural networks (GNNs) exhibited superior performance in integrating biological knowledge and identifying coexpression gene panels, which could be utilized to predict unknown phenotypes, elucidate molecular biology mechanisms, and advance biotechnologies. Through the DMLA cycle, we discovered the wavelength‐divergent secretion system and nitrate‐superoxide coregulation, realizing increasing extracellular protein production by 83.8% and facilitating nitrate removal with 99.9% enhancement. Our study showcased the potential of GNNs‐empowered optogenetic approaches for regulating denitrification and accelerating the mechanistic discovery of microbiomes for in‐depth research and versatile applications.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/7527e22accc5796290b4fe1b259c406b44a0b220.pdf",
      "citation_key": "liao2024jm9",
      "metadata": {
        "title": "From mechanism to application: Decrypting light‐regulated denitrifying microbiome through geometric deep learning",
        "authors": [
          "Yang Liao",
          "Jing Zhao",
          "Jiyong Bian",
          "Ziwei Zhang",
          "Siqi Xu",
          "Yi Qin",
          "S. Miao",
          "Rui Li",
          "Ruiping Liu",
          "Meng Zhang",
          "Wenwu Zhu",
          "Huijuan Liu",
          "Jiuhui Qu"
        ],
        "published_date": "2024",
        "abstract": "Abstract Regulation on denitrifying microbiomes is crucial for sustainable industrial biotechnology and ecological nitrogen cycling. The holistic genetic profiles of microbiomes can be provided by meta‐omics. However, precise decryption and further applications of highly complex microbiomes and corresponding meta‐omics data sets remain great challenges. Here, we combined optogenetics and geometric deep learning to form a discover–model–learn–advance (DMLA) cycle for denitrification microbiome encryption and regulation. Graph neural networks (GNNs) exhibited superior performance in integrating biological knowledge and identifying coexpression gene panels, which could be utilized to predict unknown phenotypes, elucidate molecular biology mechanisms, and advance biotechnologies. Through the DMLA cycle, we discovered the wavelength‐divergent secretion system and nitrate‐superoxide coregulation, realizing increasing extracellular protein production by 83.8% and facilitating nitrate removal with 99.9% enhancement. Our study showcased the potential of GNNs‐empowered optogenetic approaches for regulating denitrification and accelerating the mechanistic discovery of microbiomes for in‐depth research and versatile applications.",
        "file_path": "paper_data/Deep_Meta-Learning/info/7527e22accc5796290b4fe1b259c406b44a0b220.pdf",
        "venue": "iMeta",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Abstract Regulation on denitrifying microbiomes is crucial for sustainable industrial biotechnology and ecological nitrogen cycling. The holistic genetic profiles of microbiomes can be provided by meta‐omics. However, precise decryption and further applications of highly complex microbiomes and corresponding meta‐omics data sets remain great challenges. Here, we combined optogenetics and geometric deep learning to form a discover–model–learn–advance (DMLA) cycle for denitrification microbiome encryption and regulation. Graph neural networks (GNNs) exhibited superior performance in integrating biological knowledge and identifying coexpression gene panels, which could be utilized to predict unknown phenotypes, elucidate molecular biology mechanisms, and advance biotechnologies. Through the DMLA cycle, we discovered the wavelength‐divergent secretion system and nitrate‐superoxide coregulation, realizing increasing extracellular protein production by 83.8% and facilitating nitrate removal with 99.9% enhancement. Our study showcased the potential of GNNs‐empowered optogenetic approaches for regulating denitrification and accelerating the mechanistic discovery of microbiomes for in‐depth research and versatile applications.",
        "keywords": []
      },
      "file_name": "7527e22accc5796290b4fe1b259c406b44a0b220.pdf"
    },
    {
      "success": true,
      "doc_id": "c69ca4758e0f6db8a1c8bafe77f86a91",
      "summary": "Deep reinforcement learning has achieved great success in many challenging domains. However, sample efficiency and safety issues still prevent from applying deep reinforcement learning directly in robotics. Sim-to-real transfer learning is one feasible solution to tackle these problems and address the reality gap between simulation and reality. In this letter, we propose to combine meta-reinforcement learning and progressive neural network (PNN) by meta-training a policy for multiple source tasks and transferring it to the real-world robot via PNN (MetaPNN). We expect that training meta-policy over meta-tasks without considering dynamics discrepancy with our method can bridge the gap between simulation and reality with mismatched dynamics, and allow the agent to learn one single policy solving multiple tasks instead of using one policy network in PNN to solve one task. Meanwhile, the transferred meta-policy via PNN is expected to solve the target task and adapt to new situations at the same time. Our results in a variety of target tasks in AntPos and Reach with simulated manipulator show that MetaPNN can significantly improve the robot's learning efficiency and performance. Our further results in real-world Reach tasks with physical robot arm and a new task that is different from the meta-tasks show there might be a synergy between meta-learning and PNN.",
      "intriguing_abstract": "Deep reinforcement learning has achieved great success in many challenging domains. However, sample efficiency and safety issues still prevent from applying deep reinforcement learning directly in robotics. Sim-to-real transfer learning is one feasible solution to tackle these problems and address the reality gap between simulation and reality. In this letter, we propose to combine meta-reinforcement learning and progressive neural network (PNN) by meta-training a policy for multiple source tasks and transferring it to the real-world robot via PNN (MetaPNN). We expect that training meta-policy over meta-tasks without considering dynamics discrepancy with our method can bridge the gap between simulation and reality with mismatched dynamics, and allow the agent to learn one single policy solving multiple tasks instead of using one policy network in PNN to solve one task. Meanwhile, the transferred meta-policy via PNN is expected to solve the target task and adapt to new situations at the same time. Our results in a variety of target tasks in AntPos and Reach with simulated manipulator show that MetaPNN can significantly improve the robot's learning efficiency and performance. Our further results in real-world Reach tasks with physical robot arm and a new task that is different from the meta-tasks show there might be a synergy between meta-learning and PNN.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/c9b0ddbe27193d10f800943d91450b44324e6d57.pdf",
      "citation_key": "meng2024nqq",
      "metadata": {
        "title": "Transferring Meta-Policy From Simulation to Reality via Progressive Neural Network",
        "authors": [
          "Wei Meng",
          "Hao Ju",
          "Tongxu Ai",
          "Randy Gomez",
          "Eric Nichols",
          "Guangliang Li"
        ],
        "published_date": "2024",
        "abstract": "Deep reinforcement learning has achieved great success in many challenging domains. However, sample efficiency and safety issues still prevent from applying deep reinforcement learning directly in robotics. Sim-to-real transfer learning is one feasible solution to tackle these problems and address the reality gap between simulation and reality. In this letter, we propose to combine meta-reinforcement learning and progressive neural network (PNN) by meta-training a policy for multiple source tasks and transferring it to the real-world robot via PNN (MetaPNN). We expect that training meta-policy over meta-tasks without considering dynamics discrepancy with our method can bridge the gap between simulation and reality with mismatched dynamics, and allow the agent to learn one single policy solving multiple tasks instead of using one policy network in PNN to solve one task. Meanwhile, the transferred meta-policy via PNN is expected to solve the target task and adapt to new situations at the same time. Our results in a variety of target tasks in AntPos and Reach with simulated manipulator show that MetaPNN can significantly improve the robot's learning efficiency and performance. Our further results in real-world Reach tasks with physical robot arm and a new task that is different from the meta-tasks show there might be a synergy between meta-learning and PNN.",
        "file_path": "paper_data/Deep_Meta-Learning/info/c9b0ddbe27193d10f800943d91450b44324e6d57.pdf",
        "venue": "IEEE Robotics and Automation Letters",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Deep reinforcement learning has achieved great success in many challenging domains. However, sample efficiency and safety issues still prevent from applying deep reinforcement learning directly in robotics. Sim-to-real transfer learning is one feasible solution to tackle these problems and address the reality gap between simulation and reality. In this letter, we propose to combine meta-reinforcement learning and progressive neural network (PNN) by meta-training a policy for multiple source tasks and transferring it to the real-world robot via PNN (MetaPNN). We expect that training meta-policy over meta-tasks without considering dynamics discrepancy with our method can bridge the gap between simulation and reality with mismatched dynamics, and allow the agent to learn one single policy solving multiple tasks instead of using one policy network in PNN to solve one task. Meanwhile, the transferred meta-policy via PNN is expected to solve the target task and adapt to new situations at the same time. Our results in a variety of target tasks in AntPos and Reach with simulated manipulator show that MetaPNN can significantly improve the robot's learning efficiency and performance. Our further results in real-world Reach tasks with physical robot arm and a new task that is different from the meta-tasks show there might be a synergy between meta-learning and PNN.",
        "keywords": []
      },
      "file_name": "c9b0ddbe27193d10f800943d91450b44324e6d57.pdf"
    },
    {
      "success": true,
      "doc_id": "71f11f3910819236943b3747e6bd6d45",
      "summary": "Acquiring and utilizing accurate channel state information (CSI) can significantly improve transmission performance, thereby holding a crucial role in realizing the potential advantages of massive multiple-input multiple-output (MIMO) technology. Current prevailing CSI feedback approaches improve precision by employing advanced deep-learning methods to learn representative CSI features for a subsequent compression process. Diverging from previous works, we treat the CSI compression problem in the context of implicit neural representations. Specifically, each CSI matrix is viewed as a neural function that maps the CSI coordinates (antenna number and subchannel) to the corresponding channel gains. Instead of transmitting the parameters of the implicit neural functions directly, we transmit modulations based on the CSI matrix derived through a meta-learning algorithm. Modulations are then applied to a shared base network to generate the elements of the CSI matrix. Modulations corresponding to the CSI matrix are quantized and entropy-coded to further reduce the communication bandwidth, thus achieving extreme CSI compression ratios. Numerical results show that our proposed approach achieves state-of-the-art performance and showcases flexibility in feedback strategies.",
      "intriguing_abstract": "Acquiring and utilizing accurate channel state information (CSI) can significantly improve transmission performance, thereby holding a crucial role in realizing the potential advantages of massive multiple-input multiple-output (MIMO) technology. Current prevailing CSI feedback approaches improve precision by employing advanced deep-learning methods to learn representative CSI features for a subsequent compression process. Diverging from previous works, we treat the CSI compression problem in the context of implicit neural representations. Specifically, each CSI matrix is viewed as a neural function that maps the CSI coordinates (antenna number and subchannel) to the corresponding channel gains. Instead of transmitting the parameters of the implicit neural functions directly, we transmit modulations based on the CSI matrix derived through a meta-learning algorithm. Modulations are then applied to a shared base network to generate the elements of the CSI matrix. Modulations corresponding to the CSI matrix are quantized and entropy-coded to further reduce the communication bandwidth, thus achieving extreme CSI compression ratios. Numerical results show that our proposed approach achieves state-of-the-art performance and showcases flexibility in feedback strategies.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/8a44b6276a4c7375e21072e6a300d83fac3ffcf0.pdf",
      "citation_key": "wu2024v0z",
      "metadata": {
        "title": "MIMO Channel as a Neural Function: Implicit Neural Representations for Extreme CSI Compression in Massive MIMO Systems",
        "authors": [
          "Haotian Wu",
          "Maojun Zhang",
          "Yulin Shao",
          "K. Mikolajczyk",
          "Deniz Gündüz"
        ],
        "published_date": "2024",
        "abstract": "Acquiring and utilizing accurate channel state information (CSI) can significantly improve transmission performance, thereby holding a crucial role in realizing the potential advantages of massive multiple-input multiple-output (MIMO) technology. Current prevailing CSI feedback approaches improve precision by employing advanced deep-learning methods to learn representative CSI features for a subsequent compression process. Diverging from previous works, we treat the CSI compression problem in the context of implicit neural representations. Specifically, each CSI matrix is viewed as a neural function that maps the CSI coordinates (antenna number and subchannel) to the corresponding channel gains. Instead of transmitting the parameters of the implicit neural functions directly, we transmit modulations based on the CSI matrix derived through a meta-learning algorithm. Modulations are then applied to a shared base network to generate the elements of the CSI matrix. Modulations corresponding to the CSI matrix are quantized and entropy-coded to further reduce the communication bandwidth, thus achieving extreme CSI compression ratios. Numerical results show that our proposed approach achieves state-of-the-art performance and showcases flexibility in feedback strategies.",
        "file_path": "paper_data/Deep_Meta-Learning/info/8a44b6276a4c7375e21072e6a300d83fac3ffcf0.pdf",
        "venue": "arXiv.org",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Acquiring and utilizing accurate channel state information (CSI) can significantly improve transmission performance, thereby holding a crucial role in realizing the potential advantages of massive multiple-input multiple-output (MIMO) technology. Current prevailing CSI feedback approaches improve precision by employing advanced deep-learning methods to learn representative CSI features for a subsequent compression process. Diverging from previous works, we treat the CSI compression problem in the context of implicit neural representations. Specifically, each CSI matrix is viewed as a neural function that maps the CSI coordinates (antenna number and subchannel) to the corresponding channel gains. Instead of transmitting the parameters of the implicit neural functions directly, we transmit modulations based on the CSI matrix derived through a meta-learning algorithm. Modulations are then applied to a shared base network to generate the elements of the CSI matrix. Modulations corresponding to the CSI matrix are quantized and entropy-coded to further reduce the communication bandwidth, thus achieving extreme CSI compression ratios. Numerical results show that our proposed approach achieves state-of-the-art performance and showcases flexibility in feedback strategies.",
        "keywords": []
      },
      "file_name": "8a44b6276a4c7375e21072e6a300d83fac3ffcf0.pdf"
    },
    {
      "success": true,
      "doc_id": "282b0826ef82b8823037c216c06985b1",
      "summary": "In ecology and evolutionary biology, the synthesis and modelling of data from published literature are commonly used to generate insights and test theories across systems. However, the tasks of searching, screening, and extracting data from literature are often arduous. Researchers may manually process hundreds to thousands of articles for systematic reviews, meta-analyses, and compiling synthetic datasets. As relevant articles expand to tens or hundreds of thousands, computer-based approaches can increase the efficiency, transparency and reproducibility of literature-based research. Methods available for text mining are rapidly changing owing to developments in machine learning-based language models. We review the growing landscape of approaches, mapping them onto three broad paradigms (frequency-based approaches, traditional Natural Language Processing and deep learning-based language models). This serves as an entry point to learn foundational and cutting-edge concepts, vocabularies, and methods to foster integration of these tools into ecological and evolutionary research. We cover approaches for modelling ecological texts, generating training data, developing custom models and interacting with large language models and discuss challenges and possible solutions to implementing these methods in ecology and evolution.",
      "intriguing_abstract": "In ecology and evolutionary biology, the synthesis and modelling of data from published literature are commonly used to generate insights and test theories across systems. However, the tasks of searching, screening, and extracting data from literature are often arduous. Researchers may manually process hundreds to thousands of articles for systematic reviews, meta-analyses, and compiling synthetic datasets. As relevant articles expand to tens or hundreds of thousands, computer-based approaches can increase the efficiency, transparency and reproducibility of literature-based research. Methods available for text mining are rapidly changing owing to developments in machine learning-based language models. We review the growing landscape of approaches, mapping them onto three broad paradigms (frequency-based approaches, traditional Natural Language Processing and deep learning-based language models). This serves as an entry point to learn foundational and cutting-edge concepts, vocabularies, and methods to foster integration of these tools into ecological and evolutionary research. We cover approaches for modelling ecological texts, generating training data, developing custom models and interacting with large language models and discuss challenges and possible solutions to implementing these methods in ecology and evolution.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/ca48013d99a608e800ae34388fe9fba9ea6ca280.pdf",
      "citation_key": "farrell2024mpy",
      "metadata": {
        "title": "The changing landscape of text mining: a review of approaches for ecology and evolution",
        "authors": [
          "M. Farrell",
          "Nicolas Le Guillarme",
          "Liam Brierley",
          "Bronwen Hunter",
          "Daan Scheepens",
          "Anna Willoughby",
          "Andrew Yates",
          "N. Mideo"
        ],
        "published_date": "2024",
        "abstract": "In ecology and evolutionary biology, the synthesis and modelling of data from published literature are commonly used to generate insights and test theories across systems. However, the tasks of searching, screening, and extracting data from literature are often arduous. Researchers may manually process hundreds to thousands of articles for systematic reviews, meta-analyses, and compiling synthetic datasets. As relevant articles expand to tens or hundreds of thousands, computer-based approaches can increase the efficiency, transparency and reproducibility of literature-based research. Methods available for text mining are rapidly changing owing to developments in machine learning-based language models. We review the growing landscape of approaches, mapping them onto three broad paradigms (frequency-based approaches, traditional Natural Language Processing and deep learning-based language models). This serves as an entry point to learn foundational and cutting-edge concepts, vocabularies, and methods to foster integration of these tools into ecological and evolutionary research. We cover approaches for modelling ecological texts, generating training data, developing custom models and interacting with large language models and discuss challenges and possible solutions to implementing these methods in ecology and evolution.",
        "file_path": "paper_data/Deep_Meta-Learning/info/ca48013d99a608e800ae34388fe9fba9ea6ca280.pdf",
        "venue": "Proceedings B",
        "citationCount": 3,
        "score": 3.0,
        "summary": "In ecology and evolutionary biology, the synthesis and modelling of data from published literature are commonly used to generate insights and test theories across systems. However, the tasks of searching, screening, and extracting data from literature are often arduous. Researchers may manually process hundreds to thousands of articles for systematic reviews, meta-analyses, and compiling synthetic datasets. As relevant articles expand to tens or hundreds of thousands, computer-based approaches can increase the efficiency, transparency and reproducibility of literature-based research. Methods available for text mining are rapidly changing owing to developments in machine learning-based language models. We review the growing landscape of approaches, mapping them onto three broad paradigms (frequency-based approaches, traditional Natural Language Processing and deep learning-based language models). This serves as an entry point to learn foundational and cutting-edge concepts, vocabularies, and methods to foster integration of these tools into ecological and evolutionary research. We cover approaches for modelling ecological texts, generating training data, developing custom models and interacting with large language models and discuss challenges and possible solutions to implementing these methods in ecology and evolution.",
        "keywords": []
      },
      "file_name": "ca48013d99a608e800ae34388fe9fba9ea6ca280.pdf"
    },
    {
      "success": true,
      "doc_id": "e2fcab4bd4a630048ee20eaf2392a2b9",
      "summary": "Route selection can greatly affect vehicle fuel consumption and emissions. Finding the most fuel/energy-efficient route is known as the eco-routing problem. Existing eco-routing solutions do not effectively consider the critical traffic signal information and rely on fuel consumption models that may not be sufficiently accurate. To address the eco-routing problem in a signalized traffic network, this paper proposes a graph convolutional network based multi-objective meta-deep Q-learning (GM2DQL) method. The problem is formulated as dynamic multi-objective Markov decision processes (MOMDP) and is tackled through deep reinforcement learning and meta-learning. We identify that graph convolutional network (GCN) is an efficient and suitable feature representation for a signalized traffic network. GM2DQL can explore the optimal routes with respect to drivers’ different preferences on saving fuel and travel time. Through GM2DQL, the agent is trained under a series of learning environments that are characterized by historical vehicle trajectories, fuel consumption data, and traffic signal data in the remote data center. The vehicle requesting eco-routing service can download the model that represents the action value function of the historical dynamic driving conditions. The model in the vehicle can quickly adapt to the most recent driving condition through online one-shot learning and predict the optimal eco-routes for the subsequent unseen driving conditions of the signalized traffic network. Extensive proof-of-concept experiments validate that GM2DQL can effectively discover optimal eco-routes. It saves up to 71% travel time and 62% fuel, compared to the conventional shortest-path routing strategy that is widely used in navigation systems.",
      "intriguing_abstract": "Route selection can greatly affect vehicle fuel consumption and emissions. Finding the most fuel/energy-efficient route is known as the eco-routing problem. Existing eco-routing solutions do not effectively consider the critical traffic signal information and rely on fuel consumption models that may not be sufficiently accurate. To address the eco-routing problem in a signalized traffic network, this paper proposes a graph convolutional network based multi-objective meta-deep Q-learning (GM2DQL) method. The problem is formulated as dynamic multi-objective Markov decision processes (MOMDP) and is tackled through deep reinforcement learning and meta-learning. We identify that graph convolutional network (GCN) is an efficient and suitable feature representation for a signalized traffic network. GM2DQL can explore the optimal routes with respect to drivers’ different preferences on saving fuel and travel time. Through GM2DQL, the agent is trained under a series of learning environments that are characterized by historical vehicle trajectories, fuel consumption data, and traffic signal data in the remote data center. The vehicle requesting eco-routing service can download the model that represents the action value function of the historical dynamic driving conditions. The model in the vehicle can quickly adapt to the most recent driving condition through online one-shot learning and predict the optimal eco-routes for the subsequent unseen driving conditions of the signalized traffic network. Extensive proof-of-concept experiments validate that GM2DQL can effectively discover optimal eco-routes. It saves up to 71% travel time and 62% fuel, compared to the conventional shortest-path routing strategy that is widely used in navigation systems.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e1a8bf47ef1c51298f5bcf957062c6ee63a96bfb.pdf",
      "citation_key": "ma20243e9",
      "metadata": {
        "title": "Graph Convolutional Network Based Multi-Objective Meta-Deep Q-Learning for Eco-Routing",
        "authors": [
          "Xin Ma",
          "Yuanchang Xie",
          "Chunxiao Chigan"
        ],
        "published_date": "2024",
        "abstract": "Route selection can greatly affect vehicle fuel consumption and emissions. Finding the most fuel/energy-efficient route is known as the eco-routing problem. Existing eco-routing solutions do not effectively consider the critical traffic signal information and rely on fuel consumption models that may not be sufficiently accurate. To address the eco-routing problem in a signalized traffic network, this paper proposes a graph convolutional network based multi-objective meta-deep Q-learning (GM2DQL) method. The problem is formulated as dynamic multi-objective Markov decision processes (MOMDP) and is tackled through deep reinforcement learning and meta-learning. We identify that graph convolutional network (GCN) is an efficient and suitable feature representation for a signalized traffic network. GM2DQL can explore the optimal routes with respect to drivers’ different preferences on saving fuel and travel time. Through GM2DQL, the agent is trained under a series of learning environments that are characterized by historical vehicle trajectories, fuel consumption data, and traffic signal data in the remote data center. The vehicle requesting eco-routing service can download the model that represents the action value function of the historical dynamic driving conditions. The model in the vehicle can quickly adapt to the most recent driving condition through online one-shot learning and predict the optimal eco-routes for the subsequent unseen driving conditions of the signalized traffic network. Extensive proof-of-concept experiments validate that GM2DQL can effectively discover optimal eco-routes. It saves up to 71% travel time and 62% fuel, compared to the conventional shortest-path routing strategy that is widely used in navigation systems.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e1a8bf47ef1c51298f5bcf957062c6ee63a96bfb.pdf",
        "venue": "IEEE transactions on intelligent transportation systems (Print)",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Route selection can greatly affect vehicle fuel consumption and emissions. Finding the most fuel/energy-efficient route is known as the eco-routing problem. Existing eco-routing solutions do not effectively consider the critical traffic signal information and rely on fuel consumption models that may not be sufficiently accurate. To address the eco-routing problem in a signalized traffic network, this paper proposes a graph convolutional network based multi-objective meta-deep Q-learning (GM2DQL) method. The problem is formulated as dynamic multi-objective Markov decision processes (MOMDP) and is tackled through deep reinforcement learning and meta-learning. We identify that graph convolutional network (GCN) is an efficient and suitable feature representation for a signalized traffic network. GM2DQL can explore the optimal routes with respect to drivers’ different preferences on saving fuel and travel time. Through GM2DQL, the agent is trained under a series of learning environments that are characterized by historical vehicle trajectories, fuel consumption data, and traffic signal data in the remote data center. The vehicle requesting eco-routing service can download the model that represents the action value function of the historical dynamic driving conditions. The model in the vehicle can quickly adapt to the most recent driving condition through online one-shot learning and predict the optimal eco-routes for the subsequent unseen driving conditions of the signalized traffic network. Extensive proof-of-concept experiments validate that GM2DQL can effectively discover optimal eco-routes. It saves up to 71% travel time and 62% fuel, compared to the conventional shortest-path routing strategy that is widely used in navigation systems.",
        "keywords": []
      },
      "file_name": "e1a8bf47ef1c51298f5bcf957062c6ee63a96bfb.pdf"
    },
    {
      "success": true,
      "doc_id": "cedf21ecc6b5372beb4c59862f39db5c",
      "summary": "A precise incident wave angle estimation in aerial communication is a key enabler in sixth-generation wireless communication network. With this goal, a generic 3-dimensional (3D) channel model is analyzed for air-to-air (A2A) networks under antenna misalignment, radio frequency impairments and polarization loss. The unique aspects of each aerial node are highlighted and the few-shot learning as a model agnostic meta-learning (MAML) classifier is proposed for learning-to-learn (L2L) incident wave angle estimation by utilizing the received signal strength (RSS). Additionally, a more computationally efficient technique, first order model agnostic meta-learning (FOMAML) is implemented. It has been observed that the proposed approach reaches up to 85% training accuracy and 75.4% evaluation accuracy with MAML. Regarding this, a convergence rate and accuracy trade-off have been established for several cases of MAML and FOMAML. For different L2L models trained with limited data, heuristic accuracy performance is determined by an upper bound of the probability of confidence.",
      "intriguing_abstract": "A precise incident wave angle estimation in aerial communication is a key enabler in sixth-generation wireless communication network. With this goal, a generic 3-dimensional (3D) channel model is analyzed for air-to-air (A2A) networks under antenna misalignment, radio frequency impairments and polarization loss. The unique aspects of each aerial node are highlighted and the few-shot learning as a model agnostic meta-learning (MAML) classifier is proposed for learning-to-learn (L2L) incident wave angle estimation by utilizing the received signal strength (RSS). Additionally, a more computationally efficient technique, first order model agnostic meta-learning (FOMAML) is implemented. It has been observed that the proposed approach reaches up to 85% training accuracy and 75.4% evaluation accuracy with MAML. Regarding this, a convergence rate and accuracy trade-off have been established for several cases of MAML and FOMAML. For different L2L models trained with limited data, heuristic accuracy performance is determined by an upper bound of the probability of confidence.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/e3de80376d111cf6d282294d7c16023ec1eb2386.pdf",
      "citation_key": "gven2024a3n",
      "metadata": {
        "title": "Learning-to-Learn the Wave Angle Estimation",
        "authors": [
          "Eray Güven",
          "G. Kurt"
        ],
        "published_date": "2024",
        "abstract": "A precise incident wave angle estimation in aerial communication is a key enabler in sixth-generation wireless communication network. With this goal, a generic 3-dimensional (3D) channel model is analyzed for air-to-air (A2A) networks under antenna misalignment, radio frequency impairments and polarization loss. The unique aspects of each aerial node are highlighted and the few-shot learning as a model agnostic meta-learning (MAML) classifier is proposed for learning-to-learn (L2L) incident wave angle estimation by utilizing the received signal strength (RSS). Additionally, a more computationally efficient technique, first order model agnostic meta-learning (FOMAML) is implemented. It has been observed that the proposed approach reaches up to 85% training accuracy and 75.4% evaluation accuracy with MAML. Regarding this, a convergence rate and accuracy trade-off have been established for several cases of MAML and FOMAML. For different L2L models trained with limited data, heuristic accuracy performance is determined by an upper bound of the probability of confidence.",
        "file_path": "paper_data/Deep_Meta-Learning/info/e3de80376d111cf6d282294d7c16023ec1eb2386.pdf",
        "venue": "IEEE Transactions on Communications",
        "citationCount": 3,
        "score": 3.0,
        "summary": "A precise incident wave angle estimation in aerial communication is a key enabler in sixth-generation wireless communication network. With this goal, a generic 3-dimensional (3D) channel model is analyzed for air-to-air (A2A) networks under antenna misalignment, radio frequency impairments and polarization loss. The unique aspects of each aerial node are highlighted and the few-shot learning as a model agnostic meta-learning (MAML) classifier is proposed for learning-to-learn (L2L) incident wave angle estimation by utilizing the received signal strength (RSS). Additionally, a more computationally efficient technique, first order model agnostic meta-learning (FOMAML) is implemented. It has been observed that the proposed approach reaches up to 85% training accuracy and 75.4% evaluation accuracy with MAML. Regarding this, a convergence rate and accuracy trade-off have been established for several cases of MAML and FOMAML. For different L2L models trained with limited data, heuristic accuracy performance is determined by an upper bound of the probability of confidence.",
        "keywords": []
      },
      "file_name": "e3de80376d111cf6d282294d7c16023ec1eb2386.pdf"
    },
    {
      "success": true,
      "doc_id": "1248394de056e0da34b4358774c1d528",
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge in meta-learning where the common \"learning to learn\" paradigm, which models model initialization quality with a single-step gradient descent in the inner loop, often leads to underfitting in practice, contrary to theoretical expectations. This highlights a significant gap between theoretical understanding and practical implementation of meta-learning \\cite{wang2024bhk}.\n    *   **Importance and Challenge:** Meta-learning is crucial for adapting to unseen tasks with limited data. The current understanding's limitations (underfitting/overfitting depending on task complexity, as shown in empirical evidence \\cite{wang2024bhk}) hinder its effectiveness and generalization across diverse tasks. The challenge lies in developing a more robust and flexible meta-learning framework that can balance these issues without relying on computationally expensive data augmentation or model overparameterization \\cite{wang2024bhk}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Meta-learning methods are broadly categorized into optimization-based (e.g., MAML, Reptile, MetaOptNet) and metric-based (e.g., Siamese, Matching, Prototypical, Relation Networks) \\cite{wang2024bhk}. Both rely on bi-level optimization to learn general knowledge.\n    *   **Limitations of Previous Solutions:** Existing meta-learning methods, despite their adaptability, still face overfitting or underfitting issues on different tasks \\cite{wang2024bhk}. Some prior works attempt to address these by maintaining network overparameterization or enhancing data information content through augmentation strategies, which significantly increases computational overhead \\cite{wang2024bhk}. These methods primarily focus on changing data rather than re-evaluating the fundamental \"learning to learn\" strategy itself, where the theoretical-practical gap persists \\cite{wang2024bhk}. This paper positions itself by rethinking the core learning paradigm to identify and eliminate the root causes of these errors.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper rethinks meta-learning from a \"Learning\" lens, proposing that the meta-learning model Fθ comprises two interrelated components: model initialization layers and a \"meta-layer\" for task-specific fine-tuning \\cite{wang2024bhk}. Instead of modeling Fθ as a large MLP, which would be prohibitively large, the authors propose using a gradient optimization function to implement this nonlinear \"meta-layer\" \\cite{wang2024bhk}. This allows Fθ to be expressed as Fθ - ∂L/∂θ = fi_θ, aligning with bi-level optimization. To address modeling errors (overfitting/underfitting) due to task diversity, the paper introduces **TRLearner (Task Relation Learner)**, a plug-and-play method \\cite{wang2024bhk}. TRLearner first extracts task relation matrices using an adaptive sampler that considers task diversity, entropy, and difficulty. It then applies a relation-aware consistency regularization to guide optimization, constraining the model to produce similar performance on similar tasks after fine-tuning \\cite{wang2024bhk}.\n    *   **Novelty/Difference:**\n        *   **Rethinking Fθ Modeling:** Unlike prior work that largely overlooked how Fθ is modeled, this paper explicitly models Fθ as a combination of initialization layers and a novel \"meta-layer\" implemented via gradient optimization, reducing parameters while enhancing representational capacity \\cite{wang2024bhk}.\n        *   **Addressing Modeling Errors via Task Relations:** Instead of modifying data or model structure, the approach regulates task information by leveraging task relations. This is based on a theoretical insight that classifiers can benefit from similar tasks \\cite{wang2024bhk}.\n        *   **TRLearner:** The proposed TRLearner is a novel plug-and-play method that integrates task relation extraction and relation-aware consistency regularization to calibrate meta-learning, focusing the model on important task features \\cite{wang2024bhk}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Theoretical Insight:** Theoretical analysis (Theorem 1) indicates that models adapted to different tasks can mutually reinforce each other, and classifiers for specific tasks can leverage features from similar tasks to improve classification \\cite{wang2024bhk}. This underpins the task relation approach.\n    *   **Novel Model Formulation:** A new conceptualization of the meta-learning model Fθ, comprising model initialization layers and a \"meta-layer\" implemented via gradient optimization, which bridges the gap between theoretical understanding and practical implementation by offering flexibility in handling task complexity \\cite{wang2024bhk}.\n    *   **Novel Algorithm (TRLearner):** A plug-and-play method that calibrates meta-learning by:\n        *   Extracting task relation matrices using an adaptive sampler based on discriminative meta-data (considering task diversity, entropy, difficulty, etc.) \\cite{wang2024bhk}.\n        *   Applying a relation-aware consistency regularization term that constrains the meta-learning model to produce similar performance on similar tasks \\cite{wang2024bhk}.\n    *   **Theoretical Guarantees:** The introduction of TRLearner is theoretically shown to achieve smaller excess risk and better generalization performance \\cite{wang2024bhk}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** A toy experiment was conducted to empirically demonstrate the limitations of existing meta-learning methods (overfitting/underfitting) \\cite{wang2024bhk}.\n    *   **Setup:** 20 sets of tasks were sampled from miniImagenet, and two high-complexity (D1-D2) and two low-complexity (D3-D4) tasks were selected based on sampling scores (reflecting task diversity, entropy, difficulty) \\cite{wang2024bhk}. MAML was trained on these tasks, fine-tuning with one gradient descent step in the inner loop \\cite{wang2024bhk}.\n    *   **Key Performance Metrics:** Training loss and accuracy on previously unseen test tasks were recorded \\cite{wang2024bhk}.\n    *   **Comparison Results (Motivating Evidence):**\n        *   Models trained on low-complexity tasks (D4) exhibited an inflection point in training loss but performed worse on the test set, indicating overfitting \\cite{wang2024bhk}.\n        *   Models trained on high-complexity tasks (D1) showed lower performance after convergence and gradually improving test performance, indicating underfitting \\cite{wang2024bhk}.\n        *   These results empirically confirm that existing methods face significant overfitting and underfitting issues depending on task characteristics \\cite{wang2024bhk}.\n    *   **Further Validation:** The paper states that \"Extensive theoretical and empirical evaluations demonstrate its effectiveness\" for TRLearner, though specific results beyond the motivating experiment are not detailed in the provided abstract/introduction \\cite{wang2024bhk}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper acknowledges that determining a fixed number of meta-layers to suit all tasks is difficult due to task diversity, leading to modeling errors \\cite{wang2024bhk}. The proposed TRLearner aims to mitigate these errors by regulating task information rather than directly solving the \"optimal meta-layer count\" problem. The effectiveness relies on the quality of the extracted task relation matrices and the adaptive sampler \\cite{wang2024bhk}.\n    *   **Scope of Applicability:** TRLearner is presented as a \"plug-and-play\" method, suggesting broad applicability to existing meta-learning frameworks based on bi-level optimization \\cite{wang2024bhk}. The initial empirical validation is within the context of few-shot image classification (miniImagenet), but the theoretical insights about task relations could extend to other meta-learning domains.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This work significantly advances the technical state-of-the-art by providing a novel theoretical and practical framework for understanding and improving meta-learning. It bridges a critical gap between the theoretical \"one-step gradient descent\" ideal and the practical challenges of underfitting/overfitting \\cite{wang2024bhk}. The re-conceptualization of Fθ and the introduction of task relation-aware regularization offer a more robust approach to generalization.\n    *   **Potential Impact on Future Research:** The proposed \"Learning\" lens and the TRLearner method open new avenues for research into:\n        *   More sophisticated modeling of Fθ and its meta-layers.\n        *   Advanced methods for task relation extraction and integration into meta-learning.\n        *   Developing adaptive strategies for determining meta-layer complexity based on task characteristics.\n        *   Applying task relation calibration to other \"learning to learn\" paradigms beyond bi-level optimization \\cite{wang2024bhk}.",
      "intriguing_abstract": "Meta-learning, vital for adapting to novel tasks with limited data, is fundamentally challenged by a persistent gap: its \"learning to learn\" paradigm often leads to underfitting or overfitting, severely hindering practical generalization. Existing remedies, such as costly data augmentation or model overparameterization, merely skirt the core issue. We introduce a paradigm shift by re-conceptualizing the meta-learning model Fθ as a flexible architecture comprising initialization layers and a novel \"meta-layer\" implemented via gradient optimization, significantly enhancing representational capacity without excessive parameters.\n\nBuilding on this, we propose **TRLearner (Task Relation Learner)**, a novel plug-and-play method. TRLearner dynamically extracts intricate **task relation matrices** using an adaptive sampler that considers task diversity and difficulty. It then leverages these relations through a **consistency regularization** term, guiding optimization to ensure similar tasks yield consistent model behavior. This innovative approach theoretically guarantees smaller excess risk and superior **generalization performance**, effectively calibrating **bi-level optimization** in meta-learning. Extensive theoretical analysis and empirical evaluations demonstrate TRLearner's effectiveness in bridging the critical theory-practice gap, setting a new benchmark for robust **few-shot learning**.",
      "keywords": [
        "meta-learning",
        "\"learning to learn\" paradigm",
        "underfitting/overfitting",
        "bi-level optimization",
        "TRLearner (Task Relation Learner)",
        "task relation matrices",
        "relation-aware consistency regularization",
        "adaptive sampler",
        "Fθ modeling",
        "meta-layer",
        "theoretical-practical gap",
        "generalization performance",
        "plug-and-play method",
        "few-shot image classification"
      ],
      "file_path": "paper_data/Deep_Meta-Learning/a962dc06a19c08bb76184bde864e7f1e2e502150.pdf",
      "citation_key": "wang2024bhk",
      "metadata": {
        "title": "Rethinking Meta-Learning from a Learning Lens",
        "authors": [
          "Jingyao Wang",
          "Wenwen Qiang",
          "Jiangmeng Li",
          "Lingyu Si",
          "Changwen Zheng"
        ],
        "published_date": "2024",
        "abstract": "Meta-learning seeks to learn a well-generalized model initialization from training tasks to solve unseen tasks. From the\"learning to learn\"perspective, the quality of the initialization is modeled with one-step gradient decent in the inner loop. However, contrary to theoretical expectations, our empirical analysis reveals that this may expose meta-learning to underfitting. To bridge the gap between theoretical understanding and practical implementation, we reconsider meta-learning from the\"Learning\"lens. We propose that the meta-learning model comprises two interrelated components: parameters for model initialization and a meta-layer for task-specific fine-tuning. These components will lead to the risks of overfitting and underfitting depending on tasks, and their solutions, fewer parameters vs. more meta-layer, are often in conflict. To address this, we aim to regulate the task information the model receives without modifying the data or model structure. Our theoretical analysis indicates that models adapted to different tasks can mutually reinforce each other, highlighting the effective information. Based on this insight, we propose TRLearner, a plug-and-play method that leverages task relation to calibrate meta-learning. It first extracts task relation matrices and then applies relation-aware consistency regularization to guide optimization. Extensive theoretical and empirical evaluations demonstrate its effectiveness.",
        "file_path": "paper_data/Deep_Meta-Learning/info/a962dc06a19c08bb76184bde864e7f1e2e502150.pdf",
        "venue": "arXiv.org",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n### Focused Summary for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge in meta-learning where the common \"learning to learn\" paradigm, which models model initialization quality with a single-step gradient descent in the inner loop, often leads to underfitting in practice, contrary to theoretical expectations. This highlights a significant gap between theoretical understanding and practical implementation of meta-learning \\cite{wang2024bhk}.\n    *   **Importance and Challenge:** Meta-learning is crucial for adapting to unseen tasks with limited data. The current understanding's limitations (underfitting/overfitting depending on task complexity, as shown in empirical evidence \\cite{wang2024bhk}) hinder its effectiveness and generalization across diverse tasks. The challenge lies in developing a more robust and flexible meta-learning framework that can balance these issues without relying on computationally expensive data augmentation or model overparameterization \\cite{wang2024bhk}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Meta-learning methods are broadly categorized into optimization-based (e.g., MAML, Reptile, MetaOptNet) and metric-based (e.g., Siamese, Matching, Prototypical, Relation Networks) \\cite{wang2024bhk}. Both rely on bi-level optimization to learn general knowledge.\n    *   **Limitations of Previous Solutions:** Existing meta-learning methods, despite their adaptability, still face overfitting or underfitting issues on different tasks \\cite{wang2024bhk}. Some prior works attempt to address these by maintaining network overparameterization or enhancing data information content through augmentation strategies, which significantly increases computational overhead \\cite{wang2024bhk}. These methods primarily focus on changing data rather than re-evaluating the fundamental \"learning to learn\" strategy itself, where the theoretical-practical gap persists \\cite{wang2024bhk}. This paper positions itself by rethinking the core learning paradigm to identify and eliminate the root causes of these errors.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper rethinks meta-learning from a \"Learning\" lens, proposing that the meta-learning model Fθ comprises two interrelated components: model initialization layers and a \"meta-layer\" for task-specific fine-tuning \\cite{wang2024bhk}. Instead of modeling Fθ as a large MLP, which would be prohibitively large, the authors propose using a gradient optimization function to implement this nonlinear \"meta-layer\" \\cite{wang2024bhk}. This allows Fθ to be expressed as Fθ - ∂L/∂θ = fi_θ, aligning with bi-level optimization. To address modeling errors (overfitting/underfitting) due to task diversity, the paper introduces **TRLearner (Task Relation Learner)**, a plug-and-play method \\cite{wang2024bhk}. TRLearner first extracts task relation matrices using an adaptive sampler that considers task diversity, entropy, and difficulty. It then applies a relation-aware consistency regularization to guide optimization, constraining the model to produce similar performance on similar tasks after fine-tuning \\cite{wang2024bhk}.\n    *   **Novelty/Difference:**\n        *   **Rethinking Fθ Modeling:** Unlike prior work that largely overlooked how Fθ is modeled, this paper explicitly models Fθ as a combination of initialization layers and a novel \"meta-layer\" implemented via gradient optimization, reducing parameters while enhancing representational capacity \\cite{wang2024bhk}.\n        *   **Addressing Modeling Errors via Task Relations:** Instead of modifying data or model structure, the approach regulates task information by leveraging task relations. This is based on a theoretical insight that classifiers can benefit from similar tasks \\cite{wang2024bhk}.\n        *   **TRLearner:** The proposed TRLearner is a novel plug-and-play method that integrates task relation extraction and relation-aware consistency regularization to calibrate meta-learning, focusing the model on important task features \\cite{wang2024bhk}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Theoretical Insight:** Theoretical analysis (Theorem 1) indicates that models adapted to different tasks can mutually reinforce each other, and classifiers for specific tasks can leverage features from similar tasks to improve classification \\cite{wang2024bhk}. This underpins the task relation approach.\n    *   **Novel Model Formulation:** A new conceptualization of the meta-learning model Fθ, comprising model initialization layers and a \"meta-layer\" implemented via gradient optimization, which bridges the gap between theoretical understanding and practical implementation by offering flexibility in handling task complexity \\cite{wang2024bhk}.\n    *   **Novel Algorithm (TRLearner):** A plug-and-play method that calibrates meta-learning by:\n        *   Extracting task relation matrices using an adaptive sampler based on discriminative meta-data (considering task diversity, entropy, difficulty, etc.) \\cite{wang2024bhk}.\n        *   Applying a relation-aware consistency regularization term that constrains the meta-learning model to produce similar performance on similar tasks \\cite{wang2024bhk}.\n    *   **Theoretical Guarantees:** The introduction of TRLearner is theoretically shown to achieve smaller excess risk and better generalization performance \\cite{wang2024bhk}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** A toy experiment was conducted to empirically demonstrate the limitations of existing meta-learning methods (overfitting/underfitting) \\cite{wang2024bhk}.\n    *   **Setup:** 20 sets of tasks were sampled from miniImagenet, and two high-complexity (D1-D2) and two low-complexity (D3-D4) tasks were selected based on sampling scores (reflecting task diversity, entropy, difficulty) \\cite{wang2024bhk}. MAML was trained on these tasks, fine-tuning with one gradient descent step in the inner loop \\cite{wang2024bhk}.\n    *   **Key Performance Metrics:** Training loss and accuracy on previously unseen test tasks were recorded \\cite{wang2024bhk}.\n    *   **Comparison Results (Motivating Evidence):**\n        *   Models trained on low-complexity tasks (D4) exhibited an inflection point in training loss but performed worse on the test set, indicating overfitting \\cite{wang2024bhk}.\n        *   Models trained on high-complexity tasks (D1) showed lower performance after convergence and gradually improving test performance, indicating underfitting \\cite{wang2024bhk}.\n        *   These results empirically confirm that existing methods face significant overfitting and underfitting issues depending on task characteristics \\cite{wang2024bhk}.\n    *   **Further Validation:** The paper states that \"Extensive theoretical and empirical evaluations demonstrate its effectiveness\" for TRLearner, though specific results beyond the motivating experiment are not detailed in the provided abstract/introduction \\cite{wang2024bhk}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper acknowledges that determining a fixed number of meta-layers to suit all tasks is difficult due to task diversity, leading to modeling errors \\cite{wang2024bhk}. The proposed TRLearner aims to mitigate these errors by regulating task information rather than directly solving the \"optimal meta-layer count\" problem. The effectiveness relies on the quality of the extracted task relation matrices and the adaptive sampler \\cite{wang2024bhk}.\n    *   **Scope of Applicability:** TRLearner is presented as a \"plug-and-play\" method, suggesting broad applicability to existing meta-learning frameworks based on bi-level optimization \\cite{wang2024bhk}. The initial empirical validation is within the context of few-shot image classification (miniImagenet), but the theoretical insights about task relations could extend to other meta-learning domains.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This work significantly advances the technical state-of-the-art by providing a novel theoretical and practical framework for understanding and improving meta-learning. It bridges a critical gap between the theoretical \"one-step gradient descent\" ideal and the practical challenges of underfitting/overfitting \\cite{wang2024bhk}. The re-conceptualization of Fθ and the introduction of task relation-aware regularization offer a more robust approach to generalization.\n    *   **Potential Impact on Future Research:** The proposed \"Learning\" lens and the TRLearner method open new avenues for research into:\n        *   More sophisticated modeling of Fθ and its meta-layers.\n        *   Advanced methods for task relation extraction and integration into meta-learning.\n        *   Developing adaptive strategies for determining meta-layer complexity based on task characteristics.\n        *   Applying task relation calibration to other \"learning to learn\" paradigms beyond bi-level optimization \\cite{wang2024bhk}.",
        "keywords": [
          "meta-learning",
          "\"learning to learn\" paradigm",
          "underfitting/overfitting",
          "bi-level optimization",
          "TRLearner (Task Relation Learner)",
          "task relation matrices",
          "relation-aware consistency regularization",
          "adaptive sampler",
          "Fθ modeling",
          "meta-layer",
          "theoretical-practical gap",
          "generalization performance",
          "plug-and-play method",
          "few-shot image classification"
        ],
        "paper_type": "based on the abstract and introduction:\n\n1.  **abstract analysis:**\n    *   it identifies a problem: \"our empirical analysis reveals that this may expose meta-learning to underfitting.\"\n    *   it proposes a new conceptualization: \"we propose that the meta-learning model comprises two interrelated components...\"\n    *   it mentions theoretical analysis leading to an insight: \"our theoretical analysis indicates that models adapted to different tasks can mutually reinforce each other...\"\n    *   crucially, it proposes a new method/algorithm: \"based on this insight, we propose trlearner, a plug-and-play method that leverages task relation to calibrate meta-learning.\"\n    *   it describes the mechanism of this method: \"it first extracts task relation matrices and then applies relation-aware consistency regularization to guide optimization.\"\n    *   it mentions evaluation: \"extensive theoretical and empirical evaluations demonstrate its effectiveness.\"\n\n2.  **introduction analysis (first part):**\n    *   it defines meta-learning and its applications.\n    *   it focuses on specific meta-learning methods (bi-level optimization, optimization-based, metric-based).\n    *   it describes the technical process of meta-learning, including inner and outer loops, and the \"one gradient descent step\" issue. this sets up the technical context for the proposed solution.\n\n**classification criteria matching:**\n\n*   **survey**: not a survey. it doesn't primarily review existing literature comprehensively or discuss classification schemes.\n*   **technical**: this is a strong fit. the abstract explicitly states \"we propose trlearner, a plug-and-play method\" and describes its mechanism. the introduction sets up the technical problem and context. the theoretical and empirical analyses are used to inform, justify, and evaluate this proposed method.\n*   **theoretical**: while \"theoretical analysis\" is mentioned, it's used to derive an insight that *leads to the proposal of a method*. the primary contribution isn't just a new theorem or formal model, but a concrete algorithm/system.\n*   **empirical**: while \"empirical analysis\" is mentioned (both for problem identification and evaluation), the paper's core contribution is not solely data-driven findings but the development of a new method.\n*   **case_study**: not a case study. it's not a detailed analysis of a specific application.\n*   **position**: not a position paper. it proposes a concrete solution, not just an argument or viewpoint.\n*   **short**: no indicators to suggest it's a short paper or work-in-progress.\n\nthe paper's main contribution is the **proposal and description of a new method (trlearner)** to address a specific technical problem in meta-learning. the theoretical and empirical components support this technical contribution.\n\n**conclusion:** the paper clearly presents a new method/algorithm to solve a technical problem, supported by both theoretical and empirical analysis.\n\n**classification:** technical"
      },
      "file_name": "a962dc06a19c08bb76184bde864e7f1e2e502150.pdf"
    },
    {
      "success": true,
      "doc_id": "d6dea53da334309e2ce1dc74c5afbebe",
      "summary": "Neural network positioning technology, as one of the mainstream in indoor Wi-Fi positioning systems, is playing an increasingly important role in location-based services. The main challenge is that the samples are prone to be outdated as the indoor environment changes or the wireless signal varies over time, i.e., the samples’ Age of Information (AoI) is large, which leads to the trained model not being available. However, recollecting data to retrain the model is both time-consuming and labor-intensive. To address the above problem, this article proposes a fast adaptation approach based on Bayesian meta-learning that makes the pretrained model acquire a learned learning capability so that it can quickly learn new tasks based on the acquisition of existing knowledge. Specifically, first, a model-agnostic learning scheme is introduced to guide the learning process, which could automatically learn the optimal model parameters and hyperparameter settings. Second, to mitigate the effects of model uncertainty, especially to prevent the overfitting situation based on a limited number of samples, we combine the Stein variational gradient descent (SVGD) with the model-agnostic learning scheme, i.e., Bayesian meta-learning. Compared with traditional meta-learning algorithms, the proposed method makes the training more robust by inferring the Bayesian posterior from a probabilistic perspective. Extensive experimental results show that the proposed approach effectively overcomes the impact of large AoI on localization performance while decreasing labor consumption significantly.",
      "intriguing_abstract": "Neural network positioning technology, as one of the mainstream in indoor Wi-Fi positioning systems, is playing an increasingly important role in location-based services. The main challenge is that the samples are prone to be outdated as the indoor environment changes or the wireless signal varies over time, i.e., the samples’ Age of Information (AoI) is large, which leads to the trained model not being available. However, recollecting data to retrain the model is both time-consuming and labor-intensive. To address the above problem, this article proposes a fast adaptation approach based on Bayesian meta-learning that makes the pretrained model acquire a learned learning capability so that it can quickly learn new tasks based on the acquisition of existing knowledge. Specifically, first, a model-agnostic learning scheme is introduced to guide the learning process, which could automatically learn the optimal model parameters and hyperparameter settings. Second, to mitigate the effects of model uncertainty, especially to prevent the overfitting situation based on a limited number of samples, we combine the Stein variational gradient descent (SVGD) with the model-agnostic learning scheme, i.e., Bayesian meta-learning. Compared with traditional meta-learning algorithms, the proposed method makes the training more robust by inferring the Bayesian posterior from a probabilistic perspective. Extensive experimental results show that the proposed approach effectively overcomes the impact of large AoI on localization performance while decreasing labor consumption significantly.",
      "keywords": [],
      "file_path": "paper_data/Deep_Meta-Learning/b82a9500246176a6b32598ded8d2b96d1e29f61c.pdf",
      "citation_key": "pu2024m1b",
      "metadata": {
        "title": "Bayesian Meta-Learning: Toward Fast Adaptation in Neural Network Positioning Techniques",
        "authors": [
          "Q. Pu",
          "Youkun Chen",
          "Mu Zhou",
          "Joseph K. Y. Ng",
          "Rui Cai"
        ],
        "published_date": "2024",
        "abstract": "Neural network positioning technology, as one of the mainstream in indoor Wi-Fi positioning systems, is playing an increasingly important role in location-based services. The main challenge is that the samples are prone to be outdated as the indoor environment changes or the wireless signal varies over time, i.e., the samples’ Age of Information (AoI) is large, which leads to the trained model not being available. However, recollecting data to retrain the model is both time-consuming and labor-intensive. To address the above problem, this article proposes a fast adaptation approach based on Bayesian meta-learning that makes the pretrained model acquire a learned learning capability so that it can quickly learn new tasks based on the acquisition of existing knowledge. Specifically, first, a model-agnostic learning scheme is introduced to guide the learning process, which could automatically learn the optimal model parameters and hyperparameter settings. Second, to mitigate the effects of model uncertainty, especially to prevent the overfitting situation based on a limited number of samples, we combine the Stein variational gradient descent (SVGD) with the model-agnostic learning scheme, i.e., Bayesian meta-learning. Compared with traditional meta-learning algorithms, the proposed method makes the training more robust by inferring the Bayesian posterior from a probabilistic perspective. Extensive experimental results show that the proposed approach effectively overcomes the impact of large AoI on localization performance while decreasing labor consumption significantly.",
        "file_path": "paper_data/Deep_Meta-Learning/info/b82a9500246176a6b32598ded8d2b96d1e29f61c.pdf",
        "venue": "IEEE Internet of Things Journal",
        "citationCount": 3,
        "score": 3.0,
        "summary": "Neural network positioning technology, as one of the mainstream in indoor Wi-Fi positioning systems, is playing an increasingly important role in location-based services. The main challenge is that the samples are prone to be outdated as the indoor environment changes or the wireless signal varies over time, i.e., the samples’ Age of Information (AoI) is large, which leads to the trained model not being available. However, recollecting data to retrain the model is both time-consuming and labor-intensive. To address the above problem, this article proposes a fast adaptation approach based on Bayesian meta-learning that makes the pretrained model acquire a learned learning capability so that it can quickly learn new tasks based on the acquisition of existing knowledge. Specifically, first, a model-agnostic learning scheme is introduced to guide the learning process, which could automatically learn the optimal model parameters and hyperparameter settings. Second, to mitigate the effects of model uncertainty, especially to prevent the overfitting situation based on a limited number of samples, we combine the Stein variational gradient descent (SVGD) with the model-agnostic learning scheme, i.e., Bayesian meta-learning. Compared with traditional meta-learning algorithms, the proposed method makes the training more robust by inferring the Bayesian posterior from a probabilistic perspective. Extensive experimental results show that the proposed approach effectively overcomes the impact of large AoI on localization performance while decreasing labor consumption significantly.",
        "keywords": []
      },
      "file_name": "b82a9500246176a6b32598ded8d2b96d1e29f61c.pdf"
    }
  ]
}