\subsection{Learning a Good Initialization: MAML and its Variants}

A fundamental challenge in few-shot learning is to enable models to rapidly adapt to new tasks with minimal labeled data. Optimization-based meta-learning addresses this by learning an effective initial set of model parameters that can be quickly fine-tuned for novel tasks.

The seminal work in this area is Model-Agnostic Meta-Learning (MAML) \cite{Finn et al., 2017}, which proposes training a model's initial parameters such that a few gradient steps on a new task lead to significant performance improvement. MAML operates on a bi-level optimization structure: an inner loop performs task-specific adaptation by taking a few gradient steps on a support set, yielding adapted parameters. The outer loop then optimizes the initial parameters by evaluating the performance of these adapted parameters on a query set, using second-order gradients. This approach is inherently model-agnostic, meaning it can be applied to any model trained with gradient descent, making it broadly applicable across various deep learning architectures and tasks. While powerful for learning transferable knowledge, MAML's reliance on second-order derivatives can lead to substantial computational overhead and memory consumption, especially for large models, and it can be sensitive to hyperparameter choices.

To mitigate the computational burden associated with MAML's higher-order gradients, Reptile \cite{Nichol2018} was introduced as a computationally more efficient first-order approximation. Reptile simplifies the meta-learning process by repeatedly training on a task for several gradient steps and then moving the meta-parameters (the initial parameters) towards the task-specific parameters obtained after adaptation. This update rule, $\theta \leftarrow \theta + \epsilon (\phi - \theta)$ where $\phi$ are the task-adapted parameters, effectively approximates the MAML objective without explicitly computing second-order derivatives. This simplification significantly reduces the computational cost and memory footprint, allowing for greater scalability while maintaining competitive performance in many few-shot learning scenarios.

Further improving generalization and efficiency, particularly for complex models, is the Latent Embedding Optimization (LEO) framework \cite{Rusu et al., 2018}. LEO builds upon the optimization-based paradigm by learning a low-dimensional latent embedding for the model parameters. Instead of optimizing directly in the high-dimensional parameter space, LEO performs the inner-loop adaptation (task-specific fine-tuning) within this more compact and efficient latent space. The adapted latent parameters are then decoded back to the original parameter space for inference. This strategy enhances robustness and scalability by operating in a learned, more meaningful representation, which can lead to better generalization and faster adaptation compared to direct optimization in the full parameter space.

The model-agnostic nature of MAML has enabled its application across diverse domains, demonstrating its practical utility. For instance, in few-shot Hyperspectral Image (HSI) classification, MAML, combined with regularized fine-tuning, has been successfully employed to overcome the challenge of limited labeled samples and facilitate effective cross-domain transfer learning \cite{li2023fhe}. This application showcases MAML's ability to learn robust initializations that enable accurate classification even when only a handful of labeled examples are available for new HSI datasets, achieving high overall accuracy.

In conclusion, MAML and its variants represent a powerful paradigm within meta-learning, focusing on learning transferable initializations that enable rapid adaptation. While MAML laid the foundational groundwork with its bi-level optimization and model-agnosticism, its computational demands spurred the development of more efficient approximations like Reptile and advanced techniques like LEO, which optimize in learned latent spaces for improved generalization and efficiency. Despite these advancements, challenges persist in balancing computational cost, hyperparameter sensitivity, and ensuring robust generalization across highly diverse task distributions, pointing towards continued research in developing more robust and theoretically grounded optimization-based meta-learning algorithms.