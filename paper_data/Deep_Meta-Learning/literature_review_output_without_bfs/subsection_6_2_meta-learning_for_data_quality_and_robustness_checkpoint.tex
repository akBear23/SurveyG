\subsection{Meta-Learning for Data Quality and Robustness}

Real-world machine learning applications are frequently hampered by imperfect data, including noisy labels, imbalanced distributions, and varying data utility, all of which can severely degrade model performance and robustness. Meta-learning offers a powerful paradigm to address these challenges by enabling deep neural networks to "learn how to learn" from such imperfections, thereby enhancing data quality and improving model resilience.

A significant area of focus is making deep neural networks inherently noise-tolerant. \cite{li2018soc} pioneered a meta-learning based noise-tolerant (MLNT) training algorithm that optimizes a meta-objective to prevent overfitting to label noise. This approach innovatively generates synthetic noisy labels through a "random neighbor label transfer" method and enforces consistency with a stable self-ensembling teacher model, effectively learning parameters that are robust against a wide spectrum of label corruption. Building on this, \cite{algan2020u0v} introduced Meta Soft Label Generation (MSLG), a meta-learning algorithm that jointly generates optimal soft labels and learns deep neural network parameters. MSLG adapts the meta-learning paradigm to estimate label distributions by evaluating gradient directions on both noisy training data and a small, noise-free meta-dataset, iteratively refining soft labels to minimize loss on clean samples. This provides a more nuanced approach to handling label uncertainty compared to direct label correction. Further specializing in specific domains, \cite{zhang2021p9j} proposed an adaptive label noise cleaning algorithm based on meta-supervision for deep face recognition. This method learns reliable cleaning knowledge from well-labeled noisy data and gradually transfers it to target data, incorporating a threshold adapter to manage transfer learning drift and achieve state-of-the-art performance on noisy face datasets. Extending beyond simple label noise, \cite{liu2022tgc} tackled diverse data biases in deep face recognition, such as ethnicity, head pose, and occlusion. They proposed a sample-level weighting approach, Multi-variation Cosine Margin (MvCoM), guided by a meta-learning set to predict these weights, thereby simultaneously handling multiple variation factors and enhancing robustness against complex data imbalances.

Another critical aspect of data quality is data valuation, where meta-learning helps identify and leverage the most valuable data samples. \cite{yoon2019k84} addressed the computationally intensive nature of traditional data valuation methods (like Data Shapley) by proposing Data Valuation using Reinforcement Learning (DVRL). This meta-learning framework jointly optimizes a data value estimator (a neural network predicting sample selection probabilities) and a target task predictor model. Crucially, DVRL employs reinforcement learning to handle the non-differentiable process of data sampling, using the predictor's performance on a small validation set as a reward signal. This scalable and model-agnostic approach significantly outperforms prior methods in tasks like corrupted sample discovery, domain adaptation, and robust learning, demonstrating meta-learning's power in discerning data utility.

Beyond explicit label correction and data valuation, meta-learning also contributes to broader aspects of model robustness against data imperfections. For instance, in few-shot learning scenarios, the "hubness problem"—where certain class prototypes become the nearest neighbor for many test instances regardless of their true class—can arise from data distribution characteristics. \cite{fei20211x6} demonstrated that many few-shot learning methods suffer from this and proposed using z-score feature normalization during meta-training to mitigate its negative effects, thereby boosting the robustness and performance of existing methods. Furthermore, addressing biases in training data for fair ranking systems, \cite{wang2024so2} introduced a Meta Curriculum-based Fair Ranking (MCFR) framework. This framework utilizes a meta-learner to generate weighted losses, focusing more on minority groups to alleviate data bias. By formulating this as a bilevel optimization problem and integrating a curriculum learning scheduler for sampling the meta-dataset, MCFR learns to adaptively re-weight samples, ensuring fairer ranking outcomes.

In conclusion, meta-learning provides a versatile toolkit for enhancing data quality and model robustness in the face of real-world data imperfections. Techniques range from learning to correct or down-weight noisy labels, as seen in \cite{li2018soc} and \cite{algan2020u0v}, to sophisticated data valuation methods like DVRL \cite{yoon2019k84} that identify and prioritize valuable samples. Moreover, meta-learning contributes to mitigating broader data-induced issues such as hubness \cite{fei20211x6} and fairness biases \cite{wang2024so2}. A common limitation across many of these approaches, however, remains the reliance on a small, often clean, validation or meta-dataset to guide the meta-learning process, which may not always be available in extreme real-world scenarios. Future research could focus on developing meta-objectives that are less dependent on such clean auxiliary data, further improving the scalability and generalizability of meta-learning for data quality and robustness across an even wider range of tasks and data imperfections.