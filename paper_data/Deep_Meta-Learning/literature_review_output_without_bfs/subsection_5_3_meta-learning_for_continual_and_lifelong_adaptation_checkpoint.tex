\subsection{Meta-Learning for Continual and Lifelong Adaptation}
Intelligent agents operating in real-world environments face the fundamental challenge of continual and lifelong learning: they must adapt to non-stationary dynamics, sequentially encountered new tasks, and streaming data without succumbing to catastrophic forgetting \cite{son2023lda}. This necessitates developing systems that can continuously learn and evolve over time, retaining previously acquired knowledge while rapidly integrating new information. Meta-learning offers a powerful paradigm to address these issues by enabling models to "learn to learn" robust, efficient, and lifelong adaptation mechanisms, thereby moving towards truly autonomous AI agents. This section critically examines how meta-learning approaches, often synergistically combined with other techniques, facilitate continuous learning, knowledge retention, and rapid integration of new information, focusing on the mechanisms that enable models to overcome the plasticity-stability dilemma inherent in lifelong adaptation.

A primary challenge in continual learning is mitigating catastrophic forgetting, where acquiring new knowledge erodes previously learned skills. Meta-learning addresses this by learning how to adapt parameters or update rules in a way that preserves past knowledge while integrating new information. Architectural and biologically-inspired meta-learning approaches intrinsically manage the plasticity-stability dilemma through their design. For instance, Neuro-Modulated Networks (NMNs) \cite{vecoven2018hc1} demonstrated that a neuromodulatory network could dynamically tune activation functions, leading to faster and more stable adaptive behaviors than standard recurrent neural networks. Similarly, Feedback and Local Plasticity (FLP) \cite{lindsey202075a} introduced a meta-learning framework with decoupled feedback pathways and local synaptic plasticity rules, demonstrating superior performance in continual learning tasks and offering a universality proof for approximating any learning algorithm \cite{finn2017vrt}. These models highlight the potential of architectural innovations to build in mechanisms for knowledge retention. More recently, Sequential Bayesian Meta-Continual Learning (SB-MCL) \cite{lee2024snq} proposed a distinct framework that inherently prevents catastrophic forgetting by fixing neural network parameters during continual learning and offloading sequential updates to robust statistical models via meta-learned mappings. This approach decouples the expressive power of deep networks from the sequential update process, ensuring stability by leveraging the theoretical guarantees of Bayesian updates in exponential family distributions.

Optimization-based meta-learning, particularly Model-Agnostic Meta-Learning (MAML) \cite{finn20174c4}, has been instrumental in enabling rapid adaptation to new tasks by optimizing for a good initialization (as discussed in Section 3.1). However, its direct application to continual learning faces challenges such as meta-overfitting and insufficient weight modification in few gradient steps. To address these, various extensions have been proposed. \cite{tseng2020m83} introduced gradient dropout regularization during the inner-loop optimization of gradient-based meta-learning to improve generalization to new tasks in a sequence. HyperMAML \cite{przewiezlikowski2022d4y} replaced the gradient-based inner loop with a hypernetwork, allowing for more flexible and significant weight updates in a single step, which is crucial for adapting to diverse new tasks in a continual setting without repeated gradient computations. Furthermore, \cite{wang2024bhk} introduced TRLearner, which uses task relation matrices and consistency regularization to mitigate underfitting and overfitting in MAML for continual adaptation. For class-incremental settings, iTAML \cite{rajasegaran2020llk} developed an incremental task-agnostic meta-learning approach with a novel meta-update rule designed to maintain equilibrium across encountered tasks and effectively combat catastrophic forgetting. A distinct approach to learning the optimization process for continual learning was proposed by \cite{vuorio2018gwb}, which meta-trains a neural network to predict parameter update steps that respect the importance of parameters to previous tasks, thereby directly learning to mitigate forgetting. These optimization-based methods collectively aim to learn *how to update* parameters to balance new learning with old knowledge retention, offering algorithmic solutions that complement architectural designs for stability.

Beyond explicit parameter adaptation, meta-learning facilitates adaptation to non-stationary environments and dynamic task changes by learning more abstract adaptive strategies. As introduced in Section 5.1, early work by \cite{wang20167px} demonstrated that recurrent neural networks could implicitly learn a reinforcement learning algorithm within their recurrent dynamics for rapid task adaptation. Building on the probabilistic meta-learning frameworks for task inference and exploration discussed in Section 5.2, these methods have been extended to address online adaptation and robust exploration in lifelong settings. VariBAD \cite{zintgraf2019zat} and PEARL \cite{rakelly2019m09} leverage probabilistic context variables and latent MDP embeddings to enable structured online exploration and improved sample efficiency, which are crucial for dynamic environments where task identity might be unknown or changing. BOReL \cite{dorfman2020mgv} tackled Offline Meta-Reinforcement Learning, learning exploration from static datasets and mitigating "MDP ambiguity," a critical challenge for lifelong learning from diverse, pre-recorded data sources. For non-stationary and dynamic environments, \cite{bing2022om0} proposed a training strategy using Gaussian mixture models for task representation, achieving competitive asymptotic performance and superior zero-shot adaptation. While Meta-Safe Reinforcement Learning \cite{khattar2024sr6} is discussed in detail in Section 6.4, its CMDP-within-online framework is particularly relevant here for providing provable guarantees for task-averaged regret and constraint violations in dynamic environments, which is essential for reliable lifelong operation in safety-critical contexts.

Meta-learning has also been synergistically combined with other techniques to enhance continual adaptation, particularly in scenarios with realistic constraints. For instance, in lifelong language learning, \cite{holla20202od} effectively combated catastrophic forgetting by combining meta-learning with sparse experience replay. By using replayed examples as the query set in a first-order MAML framework, their approach directly optimizes the model to prevent forgetting, demonstrating state-of-the-art performance under realistic constraints like single passes over data and no task identifiers. This highlights the power of combining meta-learning's adaptive capabilities with memory management strategies. Furthermore, hierarchical meta-learning approaches \cite{yang2018p36, xu2019brv} have explored learning basic and compound skills or using meta-critic networks for sample-efficient learning and transferable knowledge, which are vital for accumulating complex behaviors over a lifetime. Skill-based meta-RL \cite{nam2022z75} further leveraged offline datasets to extract reusable skills, enabling efficient meta-learning on long-horizon, sparse-reward tasks.

The practical utility of meta-learning for continual adaptation is evident across diverse real-world applications. \cite{li20208tg} proposed an online meta-learning algorithm for self-supervised visual odometry, enabling continuous adaptation to new environments as a vehicle navigates. MAGICVFM \cite{lupu20249p4} introduced a stable adaptive controller for ground vehicles that integrates visual foundation models and meta-learning for real-time terrain adaptation, backed by mathematical stability guarantees, showcasing robust performance in dynamic physical systems. Similarly, \cite{ma20243e9} applied GCN-based multi-objective meta-Deep Q-Learning for eco-routing, demonstrating one-shot adaptation to new driving conditions. For high-speed railways, \cite{wang2024d09} developed a contrastive learning-based Bayes-adaptive meta-RL (CBAMRL) for active pantograph control, achieving zero-shot adaptation in non-stationary environments. In the domain of class-incremental learning, a transformer-based approach by \cite{kumar2024he9} demonstrated that meta-learners can exhibit significant generalization to newly introduced classes even without explicit training for this task, highlighting their inherent adaptability for integrating new categories over time. These applications underscore meta-learning's capacity to provide robust, efficient, and often theoretically grounded adaptation in complex, dynamic real-world systems.

Despite significant progress, challenges remain in scaling these approaches to truly open-ended, highly complex real-world scenarios. Key tensions exist between architectural solutions (e.g., NMNs, SB-MCL) that intrinsically manage plasticity and stability, and algorithmic solutions (e.g., iTAML, meta-optimizers for CL) that modify learning rules. While memory-based methods like sparse experience replay are effective, they are constrained by finite memory buffers, raising questions about their efficacy in truly open-ended lifelong scenarios where knowledge accumulation is unbounded. Future research must focus on developing more robust and generalizable meta-learning frameworks that can operate with minimal supervision, handle extreme non-stationarity, provide stronger theoretical guarantees for all aspects of lifelong adaptation, and efficiently integrate diverse knowledge sources. The development of robust evaluation benchmarks specifically for continual meta-learning will also be crucial to drive progress towards truly autonomous and adaptable AI agents.