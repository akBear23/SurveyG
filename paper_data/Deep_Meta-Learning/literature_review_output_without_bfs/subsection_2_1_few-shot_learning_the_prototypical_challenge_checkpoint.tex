\subsection{Few-Shot Learning: The Prototypical Challenge}

Few-shot learning (FSL) represents a quintessential and pervasive challenge for deep learning, demanding that models generalize effectively to novel classes or tasks when presented with only a handful of labeled examples \cite{huisman2020b7w, hospedales2020m37}. This scenario directly confronts the data-hungry nature of conventional deep learning models, which typically require vast amounts of annotated data to achieve robust performance. The prevalence of FSL is not merely an academic concern but a critical reality in numerous real-world applications where data annotation is prohibitively expensive, new categories emerge frequently, or data privacy concerns limit large-scale collection. Illustrative examples span diverse domains, including the medical diagnosis of rare diseases where labeled instances are inherently scarce, identifying emerging cyber threats like zero-day malware with minimal prior examples \cite{li20246zp}, or enabling robotic systems to acquire complex new skills from a single visual demonstration \cite{finn20174c4}. The inherent scarcity of data in such contexts establishes FSL as a primary driver for the development of meta-learning research.

Formally, a few-shot learning task is typically defined within an N-way K-shot classification paradigm \cite{son2023lda}. In this setup, a model is presented with a "support set" ($S$) containing $N$ novel classes, with $K$ labeled examples for each class. The goal is then to accurately classify instances in a "query set" ($Q$), which consists of unlabeled examples from these same $N$ novel classes. The meta-learning framework addresses this by employing an "episodic training" strategy. During the meta-training phase, the meta-learner is exposed to a large number of distinct FSL tasks, sampled from a distribution of related "base" tasks. Each meta-training episode simulates a few-shot scenario, allowing the model to learn how to rapidly adapt. In the subsequent meta-testing phase, the meta-learner is evaluated on truly novel tasks, drawn from a different set of classes unseen during meta-training, assessing its ability to quickly generalize with only the few examples provided in the support set of each new task \cite{son2023lda}.

Meta-learning offers a powerful framework to overcome the fundamental data scarcity inherent in FSL by leveraging prior experience from a distribution of related tasks \cite{huisman2020b7w}. Instead of learning a single task from scratch, a meta-learner acquires an inductive bias or an explicit adaptation strategy that enables it to quickly form robust representations or adaptation rules for novel tasks. This "learning to learn" paradigm is crucial because traditional deep learning models, when faced with only a few examples, are highly susceptible to overfitting or simply failing to learn any meaningful features. Meta-learning mitigates this by training a model to become an efficient learner itself, rather than just a task-specific performer. These meta-learning strategies broadly fall into distinct categories, such as optimization-based, metric-based, and model-based approaches, which will be explored in detail in Sections 3 and 4.

Despite the promise of meta-learning, FSL presents several persistent challenges that continue to drive research. One significant hurdle is the problem of generalization across diverse tasks, particularly when there are shifts in the underlying data distribution. For instance, cross-domain few-shot learning, where new tasks originate from domains unseen during meta-training, poses a formidable challenge to existing meta-learning methods, often leading to vulnerable generalization \cite{tian2023iyh}. Furthermore, the fundamental generalization capabilities of meta-learning algorithms themselves are under scrutiny, with studies highlighting issues of underfitting or overfitting depending on task complexity, revealing a gap between theoretical expectations and practical performance \cite{wang2024bhk}. Within metric-based FSL, which relies on learned embedding spaces, the "hubness problem" can arise, where certain class prototypes become the nearest neighbor for many test instances regardless of their true class, hindering classification accuracy \cite{fei20211x6}. Addressing these challenges necessitates stronger theoretical guarantees for generalization, moving beyond empirical observations to provide a deeper understanding of why and when meta-learning succeeds in data-scarce scenarios \cite{chen2021j5t}.

The principles of few-shot learning extend beyond supervised classification, serving as a critical driver for meta-learning research in other domains where rapid adaptation from limited experience is vital. In reinforcement learning, for example, the challenge of learning new policies with minimal interactions—often termed few-shot reinforcement learning—has led to seminal works exploring how agents can implicitly learn an RL algorithm \cite{wang20167px} or acquire new skills from a single demonstration in one-shot visual imitation learning \cite{finn20174c4}. The practical impact of FSL is also evident in diverse real-world applications, such as robust and interpretable EMG-based hand gesture recognition \cite{tam2024a1h} and few-shot Android malware classification \cite{li20246zp}, where the combination of data scarcity and the imperative for rapid adaptation makes FSL a central problem.

In conclusion, few-shot learning remains a cornerstone challenge that fundamentally shapes and propels innovation in meta-learning. It highlights the limitations of traditional deep learning in data-scarce environments and underscores the necessity for models that can "learn to learn." While meta-learning provides a powerful conceptual and algorithmic framework, ongoing research continues to address critical issues such as improving robustness to domain shifts, mitigating underfitting and overfitting across heterogeneous tasks, and developing more unified theoretical understandings to ensure reliable and efficient generalization in the face of limited data.