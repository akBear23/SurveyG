\subsection{Meta-Learning for Continual and Lifelong Learning}
Continual and lifelong learning aims to equip AI systems with the ability to sequentially acquire new knowledge from a stream of data without suffering from catastrophic forgetting, a pervasive challenge where models lose proficiency on previously learned tasks when adapting to new ones \cite{son2023lda}. Meta-learning, with its inherent "learning to learn" capability, offers a powerful paradigm for developing algorithmic solutions to this problem, enabling models to adapt efficiently and robustly over time while preserving past knowledge.

While early meta-learning research primarily focused on rapid adaptation to novel tasks or few-shot generalization at a single point in time, exemplified by methods like the Relation Network \cite{sung2017nc5} which learned a non-linear comparison function for few-shot classification, these approaches did not directly address the complexities of sequential knowledge accumulation and catastrophic forgetting in non-stationary environments. The field has since evolved to explicitly tackle the challenge of continual learning, integrating meta-learning principles with various strategies to mitigate forgetting.

A significant line of research adapts optimization-based meta-learning to the continual setting. These methods aim to learn an initialization or an update rule that is robust to sequential task shifts. For instance, \cite{rajasegaran2020llk} introduced iTAML (Incremental Task-Agnostic Meta-learning), a novel approach that seeks to maintain an equilibrium across all encountered tasks by learning a set of generalized parameters. iTAML proposes a new meta-update rule designed to explicitly avoid catastrophic forgetting. Unlike many continual learning methods that assume task boundaries, iTAML is task-agnostic, automatically identifying tasks and adapting rapidly with minimal updates, demonstrating substantial improvements in class-incremental settings on large-scale datasets like CIFAR100 and ImageNet. This highlights how meta-learning can be used to optimize the *process* of incremental learning itself, rather than just task-specific parameters.

Another crucial strategy involves combining meta-learning with memory-based mechanisms, particularly experience replay, to manage task interference and preserve past knowledge. The subsection's focus explicitly mentions methods combining meta-learning with experience replay, which is addressed by works like \cite{holla20202od}. They propose Meta-Learning with Sparse Experience Replay for Lifelong Language Learning, extending online meta-learning (OML) and neuromodulatory meta-learning (ANML) algorithms with an episodic memory module. Crucially, replayed examples from memory are used as the *query set* in the meta-learning outer-loop objective. This directly optimizes the model to prevent forgetting by maximizing the dot product between support and query set gradients, thereby minimizing interference and maximizing knowledge transfer. This approach operates under realistic lifelong learning constraints, such as single passes over data, no task identifiers, and sparse replay rates, demonstrating state-of-the-art performance in lifelong text classification and relation extraction. This integration of meta-learning with memory provides a powerful mechanism for balancing plasticity (learning new tasks) and stability (retaining old knowledge).

More recent advancements have explored principled statistical and Bayesian approaches to achieve robust forgetting immunity. \cite{lee2024snq} introduces Sequential Bayesian Meta-Continual Learning (SB-MCL), a novel framework that fundamentally rethinks forgetting immunity. This approach decouples deep representation learning from sequential knowledge updates. During meta-training, neural networks learn to transform complex raw data into a latent space suitable for robust statistical models. Crucially, during the actual continual learning phase, these deep neural networks remain fixed, preventing catastrophic forgetting. Instead, sequential knowledge updates are offloaded to simple statistical models that leverage *exact Bayesian updates*. This methodology is theoretically grounded in the Fisher-Darmois-Koopman-Pitman theorem, justifying the use of exponential family distributions for lossless and efficient sequential Bayesian updates, thereby providing a principled guarantee against forgetting. SB-MCL meta-learns the *ability to continually learn*, offering a domain-agnostic and model-agnostic solution that supports both supervised and unsupervised continual learning paradigms, and significantly enhances efficiency by eliminating the need for computationally expensive gradient descent during sequential learning.

The progression from optimization-based adaptation \cite{rajasegaran2020llk} and memory-augmented meta-learning \cite{holla20202od} to theoretically grounded Bayesian approaches \cite{lee2024snq} highlights the maturation of meta-learning for continual learning. While optimization- and replay-based methods offer flexibility and plasticity, they often face challenges in providing strong theoretical guarantees against forgetting. In contrast, SB-MCL's strength lies in its principled forgetting immunity, albeit by fixing the deep representation after meta-training, which might limit its adaptability to drastic domain shifts or novel task types that require fundamental changes in representation. The integration of meta-learning with modern architectures, such as transformer-based models for class incremental learning, as explored by \cite{kumar2024he9}, further demonstrates the field's dynamism, leveraging powerful pre-trained models to enhance generalization and mitigate forgetting in real-world scenarios.

Future research directions include scaling these principled Bayesian updates to extremely high-dimensional and complex scenarios, exploring hybrid frameworks that combine the plasticity of dynamic, experience-replay-based meta-learning strategies with the theoretical guarantees of Bayesian methods, and developing meta-learning approaches that can adapt both representations and learning rules continually. The overarching goal remains to create AI systems that can learn continuously throughout their operational lifespan, accumulating knowledge robustly and efficiently in dynamic real-world environments.