\subsection{Recurrent Neural Network (RNN) Based Meta-Learners}

Recurrent Neural Networks (RNNs), particularly architectures like Long Short-Term Memory (LSTM) networks and Gated Recurrent Units (GRUs), represent an early and distinct paradigm within model-based meta-learning. These approaches leverage the inherent sequential processing capabilities and internal memory of RNNs to achieve rapid adaptation to new tasks without relying on explicit gradient-based inner loops. The core idea is that an RNN can maintain a dynamic internal state that implicitly encodes task-specific information, allowing it to adapt its behavior or generate task-specific parameters by simply processing a few examples sequentially \cite{community_9, community_10, layer_1}. This enables RNNs to function as meta-optimizers, learning to generate model parameters or update rules, or as meta-generators of flexible behavior, offering a unique pathway to meta-learning and flexible behavior generation \cite{hospedales2020m37, huisman2020b7w}.

A foundational contribution to using RNNs as meta-optimizers is the work by \cite{andrychowicz2016learning}. This seminal paper demonstrated that an LSTM network could be trained to learn an optimization algorithm itself. In this framework, the LSTM takes as input the gradients of a base learner's parameters with respect to its loss function, along with its current parameters, and outputs the updated parameters. By processing this sequence of gradient information, the LSTM implicitly learns an effective update rule that can generalize across different optimization problems. This approach frames the optimization process as a sequential decision-making task, where the RNN's internal state dynamically captures the optimization history and guides subsequent parameter updates, effectively replacing hand-designed optimizers like Adam or SGD with a learned one.

Building on this concept, the Meta-Learner LSTM \cite{Ravi2017} specifically applied the idea of a learned optimizer to the few-shot classification setting. Here, an LSTM network is trained to process a small support set for a new task and then generate the parameter updates for a separate "learner" network. The LSTM's internal state accumulates information about the current task, allowing it to produce effective parameter adjustments for the learner network after only a few examples. This method bypasses the need for explicit second-order derivatives or extensive inner-loop gradient steps, as the adaptation logic is entirely encapsulated within the meta-learner LSTM's learned dynamics. The meta-learner implicitly learns how to initialize and update the learner network's weights to rapidly converge on new tasks.

Beyond parameter optimization, RNNs have also been shown to "learn to reinforcement learn" \cite{wang20167px}. In this deep meta-reinforcement learning framework, an LSTM-based agent is trained across a distribution of related reinforcement learning tasks. The LSTM processes sequences of previous actions, rewards, and observations as inputs. Through this meta-training, the RNN's recurrent dynamics implicitly learn an entire reinforcement learning algorithm, including exploration strategies and policy update rules. The agent's internal state dynamically encodes the current task context and accumulated experience, enabling rapid adaptation to new tasks within an episode without requiring explicit weight changes of the policy network during adaptation. This showcases the RNN's remarkable capacity to implicitly encode and execute complex learning procedures, effectively becoming a meta-policy that adapts its behavior based on in-context information.

More recently, RNN-based meta-learning has found applications in complex spatio-temporal prediction tasks, demonstrating their utility in adapting to dynamic real-world data. For instance, ST-MetaNet \cite{pan2019pue} for urban traffic prediction utilizes a sequence-to-sequence architecture where both the encoder and decoder incorporate "meta recurrent neural networks" alongside meta graph attention. These meta RNN components are specifically designed to capture and adapt to diverse temporal correlations present in traffic data. By processing historical traffic information and making step-by-step predictions, the RNNs enable the model to dynamically account for varying spatio-temporal patterns across different locations and times, demonstrating their capacity to generate context-specific predictions and adapt to complex, evolving dynamics.

While RNN-based meta-learners offer a powerful and distinct pathway to meta-learning, they come with specific challenges. A primary concern is the "black-box" nature of the learned adaptation rule \cite{hospedales2020m37}. Unlike explicit gradient-based methods, it is often difficult to interpret *what* optimization strategy or learning algorithm the RNN has implicitly learned, making analysis, debugging, and theoretical guarantees challenging. Furthermore, training these meta-architectures can be computationally intensive, especially when backpropagating through long unrolled optimization paths or extensive sequences of task data. The learned optimizers or adaptation strategies may also exhibit instability or poor generalization when faced with tasks significantly different from those seen during meta-training, leading to potential optimization instability on out-of-distribution tasks \cite{huisman2020b7w}. Comparative studies, such as \cite{finn2017vrt}, have also suggested that while recurrent models are expressive, gradient-based meta-learning can sometimes lead to learning strategies that generalize more widely, prompting a deeper understanding of the expressive power and generalization capabilities of each paradigm.

In conclusion, RNN-based meta-learners provide a compelling approach to meta-learning by leveraging their inherent ability to process sequential information and maintain an internal state for implicit adaptation. They have demonstrated success in learning optimization algorithms \cite{andrychowicz2016learning, Ravi2017} and entire reinforcement learning procedures \cite{wang20167px}. However, challenges related to interpretability, computational cost, and robust generalization remain. Future research may explore hybrid architectures that combine the strengths of RNNs with other meta-learning paradigms, such as attention mechanisms or more explicit memory architectures, to enhance their flexibility, scalability, and transparency.