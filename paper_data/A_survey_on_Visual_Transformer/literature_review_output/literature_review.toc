\contentsline {section}{\numberline {1}Introduction to Visual Transformers}{5}{section.1}%
\contentsline {subsection}{\numberline {1.1}The Rise of Transformers in Deep Learning}{5}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Motivation for Vision Transformers: Beyond CNNs}{7}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Scope and Structure of the Review}{9}{subsection.1.3}%
\contentsline {section}{\numberline {2}Foundational Vision Transformer Architectures and Early Optimizations}{11}{section.2}%
\contentsline {subsection}{\numberline {2.1}The Original Vision Transformer (ViT) Paradigm}{11}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Data-Efficient Training and Distillation}{13}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Enhancing Stability and Tokenization for Deeper Models}{16}{subsection.2.3}%
\contentsline {section}{\numberline {3}Hierarchical and Efficient Vision Transformer Architectures}{18}{section.3}%
\contentsline {subsection}{\numberline {3.1}Shifted Window-Based Attention for Hierarchical Processing}{18}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Pyramid Structures for Multi-Scale Feature Representation}{21}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Multi-Scale and Efficient Attention Mechanisms}{24}{subsection.3.3}%
\contentsline {section}{\numberline {4}Self-Supervised Learning Paradigms for Vision Transformers}{27}{section.4}%
\contentsline {subsection}{\numberline {4.1}Masked Image Modeling (MIM) for Representation Learning}{27}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Self-Distillation and Contrastive Learning without Labels}{29}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Scaling Self-Supervised ViTs to Foundation Models}{33}{subsection.4.3}%
\contentsline {section}{\numberline {5}Hybrid Architectures and Beyond Self-Attention}{36}{section.5}%
\contentsline {subsection}{\numberline {5.1}Integrating Convolutional Inductive Biases into Transformers}{36}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Rethinking Token Mixing: Alternatives to Self-Attention}{39}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}Modernizing CNNs with Vision Transformer Design Principles}{42}{subsection.5.3}%
\contentsline {subsection}{\numberline {5.4}Efficient and Lightweight Hybrid Designs for Deployment}{45}{subsection.5.4}%
\contentsline {section}{\numberline {6}Applications and Domain-Specific Adaptations of Visual Transformers}{45}{section.6}%
\contentsline {subsection}{\numberline {6.1}Object Detection and Semantic Segmentation}{45}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}Medical Image Analysis and 3D Segmentation}{47}{subsection.6.2}%
\contentsline {subsection}{\numberline {6.3}Remote Sensing and Environmental Monitoring}{49}{subsection.6.3}%
\contentsline {subsection}{\numberline {6.4}Lightweight and Real-time Applications}{52}{subsection.6.4}%
\contentsline {section}{\numberline {7}Future Directions and Open Challenges}{55}{section.7}%
\contentsline {subsection}{\numberline {7.1}Towards More Efficient and Scalable Architectures}{55}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Beyond Vision: Multimodal and Foundation Models}{58}{subsection.7.2}%
\contentsline {subsection}{\numberline {7.3}Novel Architectures and Beyond Attention Mechanisms}{61}{subsection.7.3}%
\contentsline {subsection}{\numberline {7.4}Ethical Considerations and Societal Impact}{63}{subsection.7.4}%
\contentsline {section}{\numberline {8}Conclusion}{66}{section.8}%
\contentsline {subsection}{\numberline {8.1}Summary of Key Developments}{66}{subsection.8.1}%
\contentsline {subsection}{\numberline {8.2}Unresolved Tensions and Future Outlook}{69}{subsection.8.2}%
\contentsline {section}{References}{73}{section*.2}%
