\subsection{Improved Tokenization and Local Feature Capture}
The foundational Vision Transformer (ViT) \cite{Dosovitskiy2020} introduced a paradigm shift in computer vision by treating images as sequences of non-overlapping patches, processed by a standard Transformer encoder. While this approach effectively captured global dependencies, it inherently lacked the inductive biases for local structural information that are central to Convolutional Neural Networks (CNNs). This deficiency meant vanilla ViTs often required immense pre-training datasets to learn robust local features, limiting their performance on smaller datasets and tasks demanding fine-grained visual understanding. Consequently, a significant line of research has focused on enhancing ViT's ability to capture local features from the very initial stages of processing, specifically by refining the image tokenization process and embedding local inductive biases into the patch embedding layers. The goal is to enable ViTs to learn fine-grained local features more effectively from scratch, thereby reducing their reliance on massive pre-training datasets and improving performance on tasks requiring detailed visual understanding.

One direct approach to enrich the initial token representation is through progressive token structuring. Tokens-to-Token ViT (T2T-ViT) \cite{Yuan2021} exemplifies this by introducing a "Tokens-to-Token" module that iteratively aggregates adjacent tokens into a single, more context-aware token. Instead of a single linear projection of raw, non-overlapping patches, T2T-ViT employs multiple stages where small patches are first linearly embedded, and then these initial tokens are progressively merged and re-embedded into a longer sequence. This hierarchical aggregation process allows the model to capture increasingly larger receptive fields and finer-grained local details before the main Transformer encoder processes the final token sequence. This refinement significantly improves the ViT's capacity to learn robust visual representations from scratch on datasets like ImageNet, thereby reducing its heavy reliance on massive pre-training. The progressive nature of T2T-ViT effectively builds a local hierarchy of features, mimicking some aspects of CNNs' early layers, but within a token-merging framework.

Beyond progressive merging, another critical direction involves embedding convolutional inductive biases directly into the initial patch embedding layer, often referred to as a "convolutional stem." This strategy leverages the inherent strengths of convolutions—locality, translation equivariance, and hierarchical feature extraction—at the very outset of the ViT pipeline. For instance, the Convolutional Vision Transformer (CvT) \cite{Li2021} replaces the standard linear projection for patch embedding with a series of convolutional layers. This not only generates visual tokens but also inherently incorporates local feature extraction and spatial downsampling, making the initial tokens more semantically rich and spatially aware. CvT further extends this idea by using convolutional projections within its attention layers, but the initial convolutional token embedding is a key aspect of local feature capture. Similarly, CeiT (Convolution-enhanced image Transformer) \cite{d_Ascoli2021} employs a convolutional stem to generate initial tokens, aiming to improve local feature extraction and reduce the number of parameters compared to a pure linear projection. These convolutional stems provide a more robust and efficient way to extract initial features, making ViTs more data-efficient and better suited for tasks requiring detailed local information, even with limited pre-training. The explicit integration of convolutions at this early stage directly addresses the ViT's lack of inherent local inductive biases, leading to improved performance, especially on smaller datasets.

Furthermore, the design of the initial patching mechanism itself has been revisited to enhance local context. The original ViT uses non-overlapping patches, which can lead to information loss at patch boundaries and a limited receptive field for individual tokens. To mitigate this, some approaches have introduced overlapping patch embeddings. By allowing patches to overlap, the model gains a denser sampling of the image and each token can incorporate information from its immediate neighbors, fostering a stronger sense of local connectivity. This simple yet effective modification can significantly contribute to improved local feature capture and robustness. For example, ViT-Lite \cite{Wu2021} explicitly incorporates overlapping patch embeddings to enhance the model's ability to perceive local structures and improve performance on various vision tasks without significantly increasing computational overhead. This approach is particularly beneficial for tasks where fine-grained spatial details are crucial, as it ensures that local contextual information is preserved and propagated more effectively into the Transformer layers.

In summary, the evolution of Vision Transformers has seen a dedicated focus on overcoming the original ViT's weakness in capturing fine-grained local structural information. Innovations at the initial tokenization stage, such as the progressive token merging in T2T-ViT \cite{Yuan2021}, the integration of convolutional stems in models like CvT \cite{Li2021} and CeiT \cite{d_Ascoli2021}, and the use of overlapping patch embeddings exemplified by approaches like ViT-Lite \cite{Wu2021}, have significantly enhanced the ViT's ability to learn rich local features. These advancements directly address the challenge of data efficiency and improve performance on tasks requiring detailed visual understanding by embedding crucial inductive biases early in the processing pipeline. By refining how images are initially converted into tokens, these methods bridge the gap between global reasoning and local inductive biases, laying a stronger foundation for the subsequent Transformer layers to build upon. This early-stage enhancement is distinct from, yet complementary to, later architectural developments that introduce hierarchical structures or hybrid designs, which are explored in subsequent sections.