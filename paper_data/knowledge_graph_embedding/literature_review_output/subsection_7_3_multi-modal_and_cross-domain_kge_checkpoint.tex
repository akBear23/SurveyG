\subsection{Multi-modal and Cross-Domain KGE}

The full potential of Knowledge Graph Embeddings (KGE) is unlocked by moving beyond structured triples to integrate diverse data modalities and enable knowledge transfer across different domains. This cutting-edge direction addresses the challenges of combining heterogeneous information sources to create richer entity and relation representations, while also tackling issues like semantic disparity and cold-start problems in multi-domain applications.

Initial efforts to enrich KGE representations extended beyond simple triplets to incorporate more complex structured information. For instance, \textcite{rosso2020} introduced HINGE, a hyper-relational KGE model that directly learns from facts composed of base triplets and associated key-value pairs, thereby capturing richer structural information than traditional triplet-based methods. Building on this, \textcite{li2021qr0} addressed the inherent structural heterogeneity within KGs by proposing a novel heterogeneous Graph Neural Network (GNN) framework. This framework leverages an attention mechanism to aggregate multiple types of semantic information from entity neighbor features under distinct relation-paths, allowing for a more nuanced understanding of diverse relationships.

A more direct approach to integrating diverse modalities involves combining different "views" of entities. \textcite{zhang2019} (Multi-view KGE) proposed a framework that unifies name, relation, and attribute views into comprehensive entity embeddings for alignment tasks. Their method introduces "soft alignment" for relations and attributes, significantly reducing the reliance on costly seed alignments, which is particularly beneficial in cross-domain scenarios. Expanding the scope of data types, \textcite{ji2024} tackled fuzzy spatiotemporal RDF knowledge graphs by employing quaternion embeddings. This approach represents relations as rotations and incorporates uncertainty via a bias factor, demonstrating how complex, non-standard data modalities can be effectively integrated into KGE models for multihop query answering. Furthermore, in specialized domains, \textcite{yang2025} developed SEConv for healthcare prediction, a semantic-enhanced KGE model that combines a resource-efficient self-attention mechanism with a multilayer Convolutional Neural Network (CNN) to extract deeper structural features from medical KGs, even drawing inspiration from AI-generated content (AIGC) principles for richer representations.

A fundamental aspect of cross-domain KGE is entity alignment (EA), which aims to bridge semantic gaps and mitigate cold-start issues between disparate knowledge graphs. Early work by \textcite{sun2018} (Bootstrapping EA) addressed the challenge of limited prior alignment by introducing a bootstrapping approach with global optimization and an alignment editing method, significantly improving EA precision. Building upon this, \textcite{pei2019} further enhanced semi-supervised EA by incorporating adversarial training to account for entity degree differences, thereby increasing robustness in data-scarce cross-domain settings. Recognizing that purely structural or attribute-based alignment can be insufficient, \textcite{xiang2021} proposed OntoEA, an ontology-guided EA method. OntoEA jointly embeds KGs and their associated ontologies, leveraging class hierarchies and disjointness to prevent "class conflict" errors and achieve more semantically consistent alignments across domains.

Beyond direct entity alignment, inductive KGE models enable broader knowledge transfer to entirely new domains or KGs. \textcite{chen2021} introduced MorsE, a meta-learning framework that learns "meta-knowledge" (transferable structural patterns) through an entity initializer and GNN modulator. This allows MorsE to produce embeddings for entirely unseen entities in new KGs, effectively addressing cold-start problems in novel domains without requiring full retraining. This meta-learning paradigm is extended by \textcite{sun2024} for dynamic KGE in evolving service ecosystems. Their MetaHG model utilizes a hybrid GNN framework (combining a standard GNN layer with a Hypergraph Neural Network layer) to capture both local and global structural information, facilitating continuous knowledge updates and generating high-quality embeddings for emerging entities in dynamic, multi-domain environments.

Multi-domain recommendation systems represent a key application area for cross-domain KGE. \textcite{liu2023} directly addressed this challenge with a "cross-domain knowledge graph chiasmal embedding approach" for multi-domain item-item recommendation. This method efficiently models both homo-domain item associations and hetero-domain item interactions, effectively tackling the cross-domain cold-start problem. Further enhancing recommendation, \textcite{yang2023} developed CKGE, which uses a KG-based Transformer to integrate contextualized neighbor semantics and high-order connections as "motivation-aware information," providing explainable recommendations in talent training, a multi-domain application. Earlier work by \textcite{sun2018} (Recurrent KGE) also demonstrated the utility of KGE in recommendation by automatically learning path semantics and fusing them into the recommendation process, offering explainable results. Comprehensive surveys such as \textcite{fanourakis2022} and \textcite{zhu2024} provide valuable overviews of entity alignment methods, highlighting the evolution of techniques and identifying multimodal EA as a crucial future direction.

In conclusion, the research trajectory in multi-modal and cross-domain KGE demonstrates a significant shift from static, structured-only representations towards more dynamic, context-aware, and domain-agnostic knowledge representation. While substantial progress has been made in integrating richer structured data, heterogeneous graph information, and multi-view entity features, challenges remain. These include the truly seamless and scalable integration of vastly different modalities (e.g., video, sensor data) into a unified embedding space, robust alignment and knowledge transfer in highly sparse or rapidly evolving cross-domain scenarios, and the development of more interpretable multi-modal KGE models that can explain their predictions derived from complex, heterogeneous inputs. Future work will likely focus on developing more generalized frameworks that can adapt to arbitrary new modalities and domains with minimal supervision, further unlocking the potential of KGE in real-world applications.