\section{Advanced KGE Architectures and Complex Geometric Spaces}
The evolution of Knowledge Graph Embedding (KGE) has progressed significantly beyond foundational models that relied on simple vector operations in Euclidean space. Modern KGE research is characterized by a concerted effort to enhance model expressiveness, capture intricate relational patterns, and address the complexities of real-world knowledge graphs, which often exhibit hierarchical, temporal, or uncertain structures. This advancement is driven by two primary thrusts: the integration of sophisticated deep learning architectures and the exploration of diverse, non-Euclidean geometric spaces. Deep learning models, including Convolutional Neural Networks (CNNs), Graph Neural Networks (GNNs) with attention mechanisms, and Transformer-based architectures, provide powerful tools for extracting rich features and contextualized embeddings. Concurrently, the adoption of complex geometric spaces, such as rotation-based models, hyperbolic and multi-curvature spaces, and compound geometric transformations, offers more natural and expressive ways to represent entities and relations, moving towards a more nuanced semantic modeling \cite{ge2023, cao2022}. The period spanning 2023 to 2025, as highlighted by recent research, showcases a dynamic progression towards KGE models that are not only powerful and expressive but also efficient, adaptable, robust, and trustworthy for increasingly complex and dynamic real-world applications. This section delves into these cutting-edge advancements, illustrating how KGE models are being equipped to handle the multifaceted nature of knowledge.

\subsection{Convolutional Neural Networks (CNNs) for KGE}
Convolutional Neural Networks (CNNs), initially popularized in computer vision, have proven highly effective in KGE by offering a powerful mechanism for local feature extraction and pattern recognition within the structured data of knowledge graphs. Unlike traditional KGE models that rely on simple scoring functions, CNNs can capture intricate interactions between entity and relation embeddings, treating them as multi-channel inputs. This allows for a more nuanced understanding of how entities and relations combine to form valid triples, moving beyond linear or bilinear assumptions. The application of CNNs in KGE typically involves transforming the concatenation of entity and relation embeddings into a feature map, which is then processed by convolutional filters to extract various patterns.

\subsubsection{Feature Aggregation and Interaction}
In the context of KGE, CNNs excel at aggregating features and modeling interactions by applying filters over local regions of concatenated embeddings. For a given triple $(h, r, t)$, the embeddings $\mathbf{h}$, $\mathbf{r}$, and $\mathbf{t}$ can be reshaped and concatenated to form an input matrix, which a CNN then processes. This allows the model to learn complex, non-linear interaction patterns between the components of a triple. For instance, \cite{hu2024} proposed CNN-ECFA (Convolutional Neural Network-based Entity-specific Common Feature Aggregation), a universal framework for KGE that leverages entity-specific common features to enhance representation learning. By using CNNs, CNN-ECFA can effectively aggregate and interact with these features, outperforming existing feature projection strategies. This approach demonstrates how CNNs can move beyond simple concatenation to capture more discriminative and context-rich features by focusing on shared characteristics among entities, thereby improving the overall quality of the learned embeddings. The ability of CNNs to detect local patterns makes them particularly suitable for identifying subtle cues within the embedding space that signify the plausibility of a triple.

\subsubsection{Hybrid CNN Architectures}
The utility of CNNs in KGE is further amplified through their integration into hybrid architectures, combining their local feature extraction capabilities with other neural network components or domain-specific enhancements. These hybrid models aim to leverage the strengths of CNNs while mitigating their limitations, such as a potentially restricted receptive field or difficulty in capturing global graph structure. For example, \cite{yang2025} introduced SEConv (Semantic Enhanced Knowledge Graph Embedding Model With AIGC), specifically designed for healthcare prediction. This model incorporates a multilayer CNN to extract deeper structural features from the knowledge graph. Crucially, SEConv also integrates an AI-generated content (AIGC) component and a resource-efficient self-attention mechanism to semantically enhance the embeddings, demonstrating a powerful hybrid approach. The CNN component focuses on local structural patterns, while AIGC and attention mechanisms contribute to broader semantic understanding and contextualization. Another example, although not explicitly detailed in the provided papers, is the general trend of multi-scale convolutional networks (e.g., M-DCN \cite{zhang2020}), which use different filter sizes to capture patterns at various granularities. Similarly, models like ReInceptionE \cite{xie2020} integrate inception-like modules with CNNs to capture joint local-global structural information, showcasing the versatility of CNNs in complex, multi-faceted KGE architectures.

\subsection{Graph Neural Networks (GNNs) and Attention Mechanisms}
Graph Neural Networks (GNNs) have emerged as a cornerstone of advanced KGE, fundamentally shifting the paradigm from learning isolated entity and relation embeddings to context-aware representations derived from the graph's topology. GNNs operate by iteratively aggregating information from an entity's neighborhood, allowing embeddings to capture rich structural context. The integration of attention mechanisms further refines this process by enabling the model to selectively focus on the most relevant neighbors and relations, thereby enhancing the expressiveness and interpretability of the learned representations. This approach is particularly powerful for knowledge graphs, where the meaning of an entity or relation is often deeply intertwined with its surrounding graph structure.

GNNs, such as Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs), propagate information across the graph, allowing entities to learn from their multi-hop neighbors. This is crucial for capturing complex, indirect relationships that are often missed by simpler KGE models. For instance, \cite{wu2021} proposed DisenKGAT (Knowledge Graph Embedding with Disentangled Graph Attention Network), which employs a novel relation-aware aggregation mechanism within a graph attention framework to learn disentangled entity representations. DisenKGAT addresses the challenge of entities having multiple facets or meanings depending on the context, by allowing different "components" of an entity's embedding to attend to different parts of its neighborhood. This disentanglement, combined with mutual information regularization, ensures that the learned components are independent and interpretable, leading to more robust and context-sensitive embeddings. The attention mechanism in DisenKGAT plays a critical role in dynamically weighing the importance of neighboring entities and relations, making the aggregation process adaptive to the specific context of a triple. Furthermore, GNNs are integral to models addressing dynamic KGE, such as \cite{sun2024}'s MetaHG, which leverages both local GNNs and global Hypergraph Neural Networks (HGNNs) to capture structural information from KG snapshots, especially for unseen entities in evolving service ecosystems. The power of GNNs combined with attention is also evident in \cite{shang2024}'s MGTCA, which uses a trainable convolutional attention network to autonomously switch GNNs and eliminate the need for pre-validating local structures, further demonstrating the adaptive capabilities enabled by attention in GNN-based KGE.

\subsection{Transformer-based Architectures}
Transformer-based architectures, initially groundbreaking in natural language processing, have been increasingly adapted for Knowledge Graph Embedding due to their unparalleled ability to model long-range dependencies and generate highly contextualized representations. Unlike traditional KGE models that treat triples in isolation, Transformers can process larger graph substructures or sequences of entities and relations, allowing for a richer understanding of context. This paradigm shift addresses the limitations of models that struggle with the inherent sequential or structural complexities of knowledge graphs.

\subsubsection{Contextualized Embeddings}
The core strength of Transformer models lies in their self-attention mechanism, which enables each element in an input sequence to weigh the importance of all other elements, thereby generating contextualized embeddings. In KGE, this translates to entities and relations being represented not as static vectors, but as dynamic embeddings that reflect their specific context within a given query or subgraph. Early work like CoKE (Contextualized Knowledge Graph Embedding) \cite{wang2019} demonstrated the potential of this approach by leveraging contextual information from entity descriptions and relational paths to enrich embeddings. By capturing how an entity's meaning shifts based on its surrounding textual and structural context, Transformer-based models can better handle issues like polysemy and provide more nuanced semantic representations. This moves KGE beyond simple structural patterns to incorporate a deeper, more human-like understanding of meaning.

\subsubsection{Position-Aware and Relational Transformers}
Adapting Transformers for KGE requires careful consideration of the graph's non-sequential nature and the distinct roles of entities and relations. To address this, researchers have developed specialized Transformer variants. \cite{li2023} introduced the Position-Aware Relational Transformer, which explicitly incorporates positional information into the self-attention mechanism, allowing the model to distinguish between different roles of entities and relations within a triple or path. This is crucial because, unlike natural language sentences, the "order" in a graph is not strictly linear, and the relative positions of entities and relations carry significant semantic weight. Building on this, \cite{shi2025} proposed TGformer (A Graph Transformer Framework for Knowledge Graph Embedding), a general graph transformer framework that is the first to integrate both triplet-level and graph-level structural features for *both static and temporal* KGs. TGformer constructs context-level subgraphs for predicted triplets and employs a Knowledge Graph Transformer Network (KGTN) to fully explore these multi-structural features. This ambitious framework aims to overcome the limitations of purely triplet-based (ignoring graph structure) and purely graph-based (ignoring node context) methods, representing a significant architectural advancement. The 2025 publication of TGformer signifies a forward-looking direction, pushing the architectural frontier for KGE by unifying the power of Transformers with the complex, multi-level structural information inherent in knowledge graphs.

\subsection{Rotation-Based Models}
Rotation-based models represent a powerful class of KGE approaches that interpret relations as geometric rotations in a continuous embedding space. This paradigm offers a highly expressive way to capture complex relational patterns, including symmetry, antisymmetry, inversion, and composition, which are often challenging for simpler translational or bilinear models. The core idea is that a relation transforms a head entity into a tail entity through a rotational operation, naturally encoding directional and compositional semantics.

\subsubsection{Extending Rotational Expressiveness}
The foundational work in this area is RotatE (Knowledge Graph Embedding by Relational Rotation in Complex Space) \cite{sun2018}. RotatE embeds entities and relations in a complex vector space, where a relation $r$ is represented as a rotation from the head entity $h$ to the tail entity $t$, such that $\mathbf{h} \circ \mathbf{r} \approx \mathbf{t}$ (element-wise product). This elegant formulation inherently models various relation patterns: symmetric relations correspond to rotations by $\pi$, antisymmetric relations to rotations by angles other than $\pi$, and inverse relations are simply rotations by the negative angle.

Building upon RotatE, subsequent research has significantly extended its expressiveness by exploring different embedding spaces and rotational mechanisms:
\begin{itemize}
    \item \textbf{Higher Dimensions and Complex Algebras}: Rotate3D \cite{gao2020} extended the concept to three-dimensional space, providing a richer geometric interpretation. More recently, \cite{chen2025} introduced ConQuatE (Contextualized Quaternion Embedding Towards Polysemy in Knowledge Graph), which leverages quaternion rotation in quaternion space. Quaternions, a non-commutative extension of complex numbers, offer even greater expressiveness for capturing diverse relational contexts and are specifically designed to address the challenging problem of polysemy, where entities have different meanings in different contexts. The 2025 publication of ConQuatE highlights a forward-looking direction, pushing boundaries with advanced mathematical algebras.
    \item \textbf{Hyperbolic Rotations}: \cite{liang2024} explored Fully Hyperbolic Rotation for KGE, demonstrating how rotational operations can be adapted to non-Euclidean hyperbolic spaces to capture hierarchical structures while maintaining the benefits of rotation.
    \item \textbf{Alternative Parameterizations and Projections}: HousE (Knowledge Graph Embedding with Householder Parameterization) \cite{li2022} introduced Householder transformations to parameterize rotations, offering a different perspective on rotational modeling. Rot-Pro (Modeling Transitivity by Projection in Knowledge Graph Embedding) \cite{song2021} combined rotational ideas with projections to capture transitivity more effectively.
    \item \textbf{Compositional Closure}: A significant theoretical advancement related to rotational models is HolmE (Knowledge graph embedding closed under composition) \cite{zheng2024}. While not exclusively rotational, HolmE proposes a KGE model where the relation embedding space is explicitly "closed under composition." This property ensures that the composition of any two relation embeddings remains within the space, fundamentally enhancing the model's ability to handle under-represented composition patterns and extrapolate to unseen relations. This theoretical grounding provides a robust framework for compositional reasoning, a property naturally supported by well-defined rotational operations.
\end{itemize}
These advancements collectively demonstrate a continuous drive to leverage the power of rotation for more expressive, theoretically sound, and context-aware KGE.

\subsection{Hyperbolic and Multi-Curvature Geometric Spaces}
The exploration of non-Euclidean geometric spaces, particularly hyperbolic and multi-curvature spaces, represents a significant paradigm shift in KGE. Euclidean space, with its uniform curvature, often struggles to efficiently represent hierarchical structures and complex relational patterns that are abundant in knowledge graphs. Hyperbolic spaces, characterized by negative curvature, naturally embed tree-like and hierarchical data with exponentially less distortion than Euclidean space. Multi-curvature spaces further extend this by combining different geometries, allowing models to adaptively capture diverse structural properties within a single knowledge graph.

\subsubsection{Pure Hyperbolic Models}
Hyperbolic geometry provides a natural fit for embedding hierarchical data, where entities at different levels of a hierarchy can be represented with varying distances that reflect their structural depth. In hyperbolic space, distances grow exponentially, allowing for the embedding of large hierarchies into low-dimensional spaces with minimal distortion. This is particularly advantageous for KGs, which often exhibit implicit or explicit hierarchical structures (e.g., "is-a" relations, class-subclass relationships). \cite{pan2021} proposed Hyperbolic Hierarchy-Aware Knowledge Graph Embedding for Link Prediction, explicitly leveraging the properties of hyperbolic space to capture hierarchical information. By embedding entities and relations in hyperbolic space, these models can more accurately reflect the tree-like nature of many real-world KGs, leading to improved performance in tasks like link prediction, especially for relations involving hierarchical concepts. Furthermore, the concept of rotation has also been extended to hyperbolic spaces, as seen in \cite{liang2024}'s Fully Hyperbolic Rotation for KGE, demonstrating how complex geometric operations can be adapted to these non-Euclidean settings to capture even richer relational semantics.

\subsubsection{Mixed Geometry Models}
While hyperbolic spaces excel at hierarchies, not all aspects of a knowledge graph are strictly hierarchical. Some relations might be better represented in Euclidean space (e.g., simple translations), while others might benefit from spherical spaces (e.g., periodic relations). This recognition has led to the development of mixed geometry models, which combine multiple curvature spaces to provide a more flexible and expressive embedding environment. These models adaptively learn which geometric space is most suitable for different parts of the knowledge graph or different types of relations.

A prominent area of application for mixed geometry models is Temporal Knowledge Graph Completion (TKGC). \cite{wang2024} introduced MADE (Multicurvature Adaptive Embedding), a model for TKGC that adaptively models temporal KGs in multicurvature spaces (Euclidean, hyperbolic, hyperspherical). MADE dynamically weights these spaces, allowing it to handle complex geometric structures and temporal dynamics simultaneously. Similarly, \cite{wang2024} proposed IME (Integrating Multi-curvature Shared and Specific Embedding), another TKGC model that embeds KGs into multi-curvature spaces. IME innovatively incorporates "space-shared" properties (for commonalities across spaces) and "space-specific" properties (for characteristic features), using an Adjustable Multi-curvature Pooling (AMP) and specialized loss functions to effectively integrate information from diverse geometries. Further advancing this, \cite{shang2024} presented MGTCA (Mixed Geometry Message and Trainable Convolutional Attention Network), which features a mixed geometry message function integrating hyperbolic, hypersphere, and Euclidean spaces. MGTCA combines this with a trainable convolutional attention network that enables autonomous switching of GNNs, demonstrating a sophisticated integration of diverse geometries with advanced neural architectures. These models collectively highlight a strong trend towards leveraging the complementary strengths of different geometric spaces to achieve more comprehensive and accurate KGE.

\subsection{Compound Geometric Transformations}
Compound geometric transformations represent a sophisticated evolution in KGE, moving beyond single, atomic operations (like simple translation or rotation) to combine multiple geometric transformations within a single model. This approach significantly enhances the expressiveness of KGE models, allowing them to capture more complex and nuanced relational patterns that might involve a combination of movement, orientation change, and scaling. By composing these fundamental operations, models can represent intricate semantic relationships that are difficult to encode with simpler transformations.

The pioneering work in this area includes CompoundE (Knowledge Graph Embedding with Translation, Rotation and Scaling Compound Operations) \cite{ge2022}. CompoundE explicitly models relations as a sequence of three distinct geometric operations: translation, rotation, and scaling. For a triple $(h, r, t)$, the model applies these operations sequentially to the head entity embedding to predict the tail entity. This allows CompoundE to capture a broader spectrum of relational semantics, as relations can now be interpreted not just as moving an entity, but also as changing its orientation and size in the embedding space. Building on this, \cite{ge2023} extended the concept to CompoundE3D (Knowledge Graph Embedding with 3D Compound Geometric Transformations), which applies these compound operations in a three-dimensional embedding space. The use of 3D transformations further enriches the model's capacity to represent complex spatial and semantic relationships, offering greater flexibility and expressiveness compared to 2D counterparts.

The ability of compound transformations to model diverse relational patterns is also implicitly addressed by models like MQuinE (a Cure for “Z-paradox” in Knowledge Graph Embedding) \cite{liu2024}. MQuinE directly tackles the "Z-paradox," a deficiency in the expressiveness of some popular KGE models, by ensuring strong expressiveness for various relation patterns, including symmetric/asymmetric, inverse, 1-N/N-1/N-N, and composition. While MQuinE's core contribution is theoretical justification for expressiveness, achieving this often necessitates underlying mechanisms that can perform complex transformations akin to compound operations. The 2024 publication of MQuinE signifies a critical self-reflection within the KGE community, identifying and rectifying fundamental expressiveness issues, and reinforcing the need for models capable of sophisticated, multi-faceted transformations to accurately represent the full spectrum of relational semantics. These compound models demonstrate a clear trajectory towards KGE systems that can mimic more complex real-world transformations and interactions.

\subsection{Entity as Geometric Shapes and Differentiated Representations}
A significant advancement in KGE involves moving beyond the simplistic representation of entities as single points or vectors to modeling them as more complex geometric shapes or differentiated representations. This approach acknowledges that entities often possess multiple facets, properties, or degrees of uncertainty that cannot be adequately captured by a single point in an embedding space. By representing entities as shapes (e.g., spheres, cones, hyper-ellipsoids) or by learning multiple, distinct representations for different contexts, KGE models can achieve a more nuanced and expressive semantic modeling.

The idea of representing entities as geometric shapes allows for a more flexible interpretation of relationships, where a triple $(h, r, t)$ might be plausible if the tail entity's shape overlaps with or is contained within a region defined by the head entity and relation. For instance, TransC (Knowledge Graph Embedding by Representing Entities as Concepts) \cite{xiao2015} introduced the idea of representing entities as concepts, which can be interpreted as regions or clusters rather than single points. Similarly, TranSHER (Translating Knowledge Graph Embedding with Hyper-Ellipsoidal Restriction) \cite{li2022} represented entities with hyper-ellipsoids, allowing for the modeling of uncertainty and fuzziness in entity definitions.

A particularly innovative approach is SpherE (Expressive and Interpretable Knowledge Graph Embedding for Set Retrieval) \cite{li2024}, published in 2024. SpherE builds upon rotational embedding methods but represents each entity as a **sphere** in the embedding space, rather than a point. This allows the model to more expressively capture complex many-to-many relations, where an entity might be related to a *set* of other entities. SpherE specifically addresses the "set retrieval" problem, a novel downstream task where users require an exact set of answers without ranking, which is challenging for point-based models. By modeling entities as spheres, SpherE can naturally encode the notion of "belonging to a set" or "being within a region of influence," providing both enhanced expressiveness and interpretability. This shift from points to shapes offers a powerful mechanism for modeling inherent uncertainty, cardinality, and the multi-faceted nature of entities, pushing KGE towards richer and more human-like semantic representations. The development of such models signifies a maturation in KGE research, moving towards more sophisticated and context-aware representations that can handle the inherent complexities of real-world knowledge.