\section*{7. Training Strategies, Evaluation, and Reproducibility}
The efficacy and trustworthiness of Knowledge Graph Embedding (KGE) models extend beyond their architectural design, deeply relying on the rigor of their training strategies, the fairness of their evaluation, and the transparency of their reproducibility. This section delves into these crucial meta-level aspects, highlighting how the field is evolving to ensure KGE models are not only powerful but also reliable, robust, and scientifically verifiable. It provides a comprehensive overview of negative sampling methods, which are fundamental for KGE training, and explores non-sampling alternatives that address their inherent challenges. Furthermore, it discusses the critical impact of hyperparameter tuning and robust model assessment strategies, reviews efforts towards standardized benchmarking and promoting reproducibility, and critically evaluates existing research practices. Additionally, it covers methods for calibrating model predictions to ensure reliability and highlights the emerging field of automated KGE model design and search for discovering optimal architectures, ultimately driving KGE research towards greater maturity and real-world applicability.

\subsection*{Negative Sampling Methods and Alternatives}
Negative sampling is a cornerstone of training most KGE models, particularly those optimized with margin-based or logistic losses. Its fundamental role is to provide "false" triples (negative samples) alongside true triples (positive samples) to enable the model to learn discriminative representations. Without negative samples, models could trivially assign high scores to all triples, failing to distinguish valid from invalid facts. The challenge lies in generating negative samples that are both efficient to produce and informative enough to guide the learning process effectively, pushing the decision boundary without introducing undue noise or computational overhead.

\subsubsection*{Surveys and General Approaches}
The critical importance of negative sampling has led to extensive research and systematic reviews dedicated to understanding and categorizing various approaches. A comprehensive survey by \cite{madushanka2024} provides a systematic review of negative sampling methods in Knowledge Graph Representation Learning, categorizing them, outlining their advantages and disadvantages, and identifying open research questions. This meta-analysis underscores that despite advancements in model architectures, the quality of negative samples remains a significant factor in KGE performance. Similarly, \cite{qian2021} offers insights into understanding negative sampling, highlighting the general goal of generating "hard" but plausible negative triples that force the model to learn finer distinctions between valid and invalid facts. These surveys consolidate knowledge, highlight best practices, and point to future research, signifying a mature field where foundational training aspects are still being rigorously examined and optimized. The continuous refinement of negative sampling techniques is crucial for the effective training of all KGE models, including advanced architectures like HolmE \cite{zheng2024} and TGformer \cite{shi2025}.

\subsubsection*{Efficient and Modality-Aware Sampling}
To address the computational cost and effectiveness of negative sampling, researchers have proposed various strategies. \cite{zhang2018} introduced NSCaching, a simple and efficient method that caches and reuses negative samples, significantly reducing the overhead of generating new samples in every training iteration. This efficiency is crucial for large-scale KGs where generating fresh negative samples can be a bottleneck. Beyond efficiency, the quality and relevance of negative samples are paramount. \cite{sun2018} proposed $\epsilon$-Truncated Uniform Negative Sampling, which limits the sampling scope to $s$-nearest neighbors in the embedding space. This strategy generates more challenging negative triples, forcing the model to learn finer distinctions and improving the capture of common semantics for tasks like entity alignment. For multi-modal KGE, \cite{zhang2023} developed Modality-Aware Negative Sampling (MANS), which generates negative samples relevant to specific modalities, ensuring that the negatives are informative within the multi-modal context. Furthermore, to address the reality of noisy KGs, \cite{shan2018} introduced a confidence-aware negative sampling method. This approach explicitly considers the potential unreliability of positive triples, improving KGE performance in environments where data quality is imperfect. This aligns with the broader goal of error-aware training, as exemplified by AEKE \cite{zhang2024}, which adaptively weights aggregation and loss based on triple confidence scores derived from entity attributes, effectively mitigating the impact of erroneous triples during training.

\subsubsection*{Non-Sampling Approaches}
While negative sampling is prevalent, it introduces challenges such as the need for careful hyperparameter tuning for sampling strategies and the potential for generating uninformative or overly hard samples. Consequently, non-sampling alternatives have emerged to circumvent these issues. These methods often reformulate the loss function or leverage global statistics to avoid the explicit generation of negative samples. For instance, \cite{li2021} explored efficient non-sampling knowledge graph embedding, demonstrating that it is possible to train effective KGE models without relying on a separate negative sampling step. Such approaches can simplify the training pipeline, reduce computational overhead associated with sample generation, and potentially avoid biases introduced by specific sampling strategies. By implicitly learning the boundaries between valid and invalid facts through global optimization or alternative loss formulations, non-sampling methods offer a different perspective on KGE training. While negative sampling remains dominant due to its proven effectiveness and flexibility, non-sampling approaches represent a valuable direction for future research, particularly in scenarios where sampling is computationally prohibitive or difficult to optimize.

\subsection*{Hyperparameter Tuning and Model Assessment}
The performance of KGE models is highly sensitive to their hyperparameters, ranging from learning rates and embedding dimensions to margin values and regularization strengths. However, the process of hyperparameter tuning is often heuristic, computationally expensive, and dataset-dependent, posing a significant challenge for achieving optimal model performance and ensuring fair comparisons. The vast search spaces and the intricate interactions between hyperparameters necessitate systematic approaches to tuning and robust strategies for model assessment.

A pivotal empirical study by \cite{lloyd2022} rigorously investigated the effects of hyperparameters on KGE quality. Their findings revealed substantial variability in hyperparameter sensitivities across different knowledge graphs, such as FB15k-237, UMLS, and WN18RR. This empirical evidence strongly suggests that optimal tuning strategies are dataset-specific, with characteristics like graph density and node degree distribution significantly influencing the importance of various hyperparameters. For instance, a margin value that performs well on a dense graph might be suboptimal for a sparse one. This highlights the inadequacy of a "one-size-fits-all" approach to tuning and underscores the need for adaptive or automated tuning mechanisms. Moreover, the quality of hyperparameter tuning directly impacts model assessment: if hyperparameters are poorly chosen, the model's true capabilities might be underestimated, leading to misleading comparisons. The study also contributed to the field by identifying and rectifying data leakage issues in the UMLS dataset, leading to the creation of UMLS-43, a more robust benchmark. This emphasizes that rigorous hyperparameter tuning must be coupled with sound model assessment practices to ensure the validity of experimental results.

\subsection*{Benchmarking, Reproducibility, and Critical Evaluation}
Standardized benchmarking and reproducibility are paramount for the scientific progress and practical adoption of KGE research. Historically, the field has faced challenges due to inconsistent evaluation protocols, a lack of shared codebases, and hidden biases in experimental setups, making it difficult to fairly compare models and verify reported performance gains. Addressing these issues is crucial for fostering trust and accelerating innovation.

A landmark effort in this direction is "Bringing Light Into the Dark: A Large-Scale Evaluation of Knowledge Graph Embedding Models Under a Unified Framework" by \cite{ali2020}. This paper conducted an extensive, standardized evaluation of numerous KGE models, revealing significant inconsistencies in previous evaluations and highlighting the critical need for unified protocols. By providing a common framework, it enabled a more objective comparison of models, identifying which methods truly advance the state-of-the-art. Complementing this, the development of libraries such as LibKGE \cite{broscheit2020} aims to promote reproducible research by offering a standardized environment for implementing, training, and evaluating KGE models. Such libraries reduce implementation variations, streamline experimental setups, and make it easier for researchers to replicate results. The work by \cite{rossi2020} on KGE for link prediction, while focused on a specific task, implicitly contributes to benchmarking by providing a common reference point for performance comparison. These initiatives collectively enable a more critical evaluation of existing research practices, helping to identify potential biases, such as data leakage (as identified in UMLS by \cite{lloyd2022}), and ensuring that reported performance improvements are genuinely attributable to methodological innovations rather than experimental artifacts. The ongoing development of robust benchmarks and reproducible frameworks is essential for the long-term health and credibility of KGE research.

\subsection*{Probability Calibration}
While KGE models are adept at generating scores that indicate the plausibility of a triple, these raw scores are not inherently well-calibrated probabilities. A score of 0.8, for instance, does not necessarily mean there is an 80\% chance of the triple being true. This distinction is crucial for applications requiring reliable decision-making, accurate uncertainty quantification, or probabilistic outputs for downstream tasks. Without proper calibration, the confidence conveyed by a model's score can be misleading, potentially leading to suboptimal decisions in real-world deployments.

The work by \cite{tabacof2019} specifically addresses this problem with "Probability Calibration for Knowledge Graph Embedding Models." This paper proposes methods to transform the raw plausibility scores output by KGE models into meaningful, well-calibrated probabilities. Techniques such as Platt scaling or isotonic regression can be applied post-training to adjust the model's output, ensuring that the predicted probabilities align with the true likelihoods of the triples. For example, if a calibrated model assigns a probability of 0.7 to 100 triples, approximately 70 of those triples should indeed be true. This calibration process enhances the trustworthiness of KGE predictions, moving beyond mere accuracy to provide reliable estimates of uncertainty. In the broader context of trustworthy AI, where transparency and reliability are increasingly emphasized, probability calibration is an indispensable step for KGE models, enabling their more responsible and effective integration into critical applications.

\subsection*{Automated Model Design and Search}
The manual design and selection of KGE models, including their architectures, scoring functions, and message aggregation mechanisms, is a time-consuming, labor-intensive, and expert-dependent process. This often involves trial-and-error, limiting the exploration of the vast design space. The emerging field of automated model design and search aims to mitigate these challenges by leveraging computational search strategies to discover optimal KGE architectures and components, thereby reducing human effort and potentially uncovering novel, high-performing designs.

A significant contribution in this area is AutoSF \cite{zhang2019}, which focuses on automatically searching for optimal scoring functions for KGE models. Instead of relying on predefined scoring functions (e.g., TransE's distance-based score or ComplEx's bilinear score), AutoSF can discover new, data-driven scoring mechanisms tailored to specific datasets or tasks. This represents a move towards more adaptive and less human-biased model design. Similarly, \cite{di2023} explores "Message Function Search for Knowledge Graph Embedding," specifically targeting the optimization of message aggregation functions within Graph Neural Network (GNN)-based KGE models. This fine-grained automation allows for the discovery of highly effective ways for entities to aggregate information from their neighbors, a core component of many modern KGE architectures. While not strictly an automated design method, the "Knowledge Graph Embedding Based on Multi-View Clustering Framework" by \cite{xiao2019} explores how different views of a KG can be leveraged, which could inform automated approaches by guiding the search for optimal combinations or transformations of embeddings. The benefits of automated model design are substantial: it reduces the need for extensive domain expertise, accelerates the development cycle, and holds the potential to discover architectures that human designers might overlook. However, challenges include the high computational cost of the search process, the definition of appropriate and constrained search spaces, and ensuring that the discovered models remain interpretable. This field aligns with the broader trend of AutoML, pushing KGE research towards greater efficiency and innovation in model discovery.

\subsubsection*{Section Taxonomies Summaries and Development Directions}
The provided sequence of papers, spanning 2023 to 2025, illustrates a dynamic and multi-faceted evolution in Knowledge Graph Embedding (KGE) research, particularly in the context of training strategies, evaluation, and reproducibility. The 2023 papers, presented as a "taxonomy of earlier papers," offered a snapshot of a mature field addressing diverse challenges from model expressiveness and scalability to real-world applications and explainability. The subsequent papers from 2024 and 2025 build upon this foundation, pushing the boundaries in fundamental relational reasoning, continual learning, robustness to data imperfections, and advanced architectural design, while a key survey consolidates understanding of a critical training component.

The 2024-2025 papers demonstrate a clear development path:
\begin{itemize}
    \item **Deepening Foundational Understanding and Rigor:** The "Negative Sampling in Knowledge Graph Representation Learning: A Review" \cite{madushanka2024} (2024) directly contributes to this section by consolidating knowledge on a fundamental training component. This survey highlights that even as models become more complex, foundational training aspects remain areas of active research and optimization, influencing the training of all KGE models, including those developed in 2023 and 2024.
    \item **Enhancing Robustness of Training to Data Imperfections:** "Integrating Entity Attributes for Error-Aware Knowledge Graph Embedding" (AEKE) \cite{zhang2024} (2024) addresses the critical issue of data quality in training. By leveraging entity attributes to calculate confidence scores and adaptively weight the loss, AEKE represents a sophisticated training strategy that makes KGE models more resilient to erroneous triples. This builds on earlier efforts like confidence-aware negative sampling \cite{shan2018}, moving towards more intelligent and adaptive training processes.
    \item **Enabling Dynamic and Continual Training:** "Fast and Continual Knowledge Graph Embedding via Incremental LoRA" (FastKGE) \cite{liu2024} (2024) introduces a novel training strategy for continual KGE. Its Incremental LoRA mechanism efficiently acquires new knowledge and preserves old knowledge, directly addressing the practical challenge of updating KGE models in dynamic environments without catastrophic forgetting. This is a crucial advancement in making KGE training adaptable and sustainable for real-world applications.
    \item **Developing Architectures that Demand Rigorous Evaluation:** "Knowledge graph embedding closed under composition" (HolmE) \cite{zheng2024} (2024) and "TGformer: A Graph Transformer Framework for Knowledge Graph Embedding" \cite{shi2025} (2025) represent significant architectural advancements. While not directly about training *strategies* or *evaluation methods*, these sophisticated models necessitate highly effective negative sampling, meticulous hyperparameter tuning, and robust evaluation protocols to fully demonstrate their capabilities in compositional reasoning and multi-structural feature integration. Their development underscores the continuous need for improved training and evaluation practices to validate increasingly complex KGE models.
\end{itemize}
This progression from 2023 to 2025 in KGE research demonstrates a holistic and forward-looking approach. The 2023 papers established a robust foundation by diversifying model types and addressing practical challenges. The 2024-2025 papers then built upon this by deepening the theoretical understanding of relational properties, developing robust solutions for dynamic KGs, enhancing resilience to data imperfections through advanced training strategies, advancing state-of-the-art architectures, and consolidating knowledge on fundamental training components. Collectively, this sequence illustrates a field rapidly maturing, moving towards KGE systems that are not only powerful and expressive but also efficient, adaptable, robust, and trustworthy for increasingly complex and dynamic real-world applications.