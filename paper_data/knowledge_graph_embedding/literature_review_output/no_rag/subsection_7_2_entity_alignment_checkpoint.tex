\subsection{Entity Alignment}
Entity Alignment (EA) is a critical task in knowledge graph integration, aiming to identify equivalent entities across different, often heterogeneous, knowledge graphs (KGs). The proliferation of KGs from diverse sources necessitates robust methods for their integration, which is fundamental for building comprehensive knowledge bases and enabling sophisticated cross-KG reasoning \cite{dai2020, choudhary2021}. Knowledge Graph Embeddings (KGEs) have emerged as a powerful, data-driven approach to tackle this challenge, transforming symbolic entities and relations into low-dimensional vector spaces where semantic correspondences can be identified through similarity measures \cite{yan2022, cao2022}. This approach leverages the ability of KGEs to capture intricate structural and semantic patterns, making them highly suitable for finding equivalences between disparate knowledge structures.

A significant hurdle in embedding-based entity alignment is the scarcity of labeled training data, which can limit the accuracy and generalizability of models. To address this, bootstrapping methods have been developed. For instance, \cite{sun2018} proposed an iterative bootstrapping approach that progressively labels likely entity alignments to augment the training data for learning alignment-oriented KG embeddings. This method strategically employs an alignment editing technique to mitigate the accumulation of errors during the iterative process, which is a common pitfall in self-training schemes. While effective in leveraging unlabeled data, the performance of such bootstrapping approaches can be sensitive to the quality of the initial seed alignments and the robustness of the error reduction mechanism, as false positives in early iterations can propagate and degrade overall accuracy.

Extending beyond purely bootstrapping, semi-supervised learning frameworks have been introduced to more effectively utilize both limited labeled data and abundant unlabeled information. \cite{pei2019} presented a semi-supervised entity alignment method (SEA) that not only leverages unlabeled entities but also incorporates an awareness of entity degree differences. This is crucial because entities with vastly different degrees (i.e., number of connections) can lead to biased embeddings, making alignment challenging, particularly between high-frequency and low-frequency entities. By employing adversarial training, SEA aims to learn more robust embeddings that are less affected by these structural disparities. This approach addresses a practical limitation of many KGE models, where embedding quality can be disproportionately influenced by highly connected entities, thereby improving alignment accuracy across the entire spectrum of entities. However, the complexity of adversarial training can introduce challenges in model stability and hyperparameter tuning.

Further enhancing the robustness and accuracy of EA, multi-view frameworks integrate diverse types of entity information. \cite{zhang2019} proposed a novel multi-view KGE framework that unifies entity names, relational structures, and attributes to learn more comprehensive embeddings for alignment. Traditional KGE methods often focus predominantly on relational structures, overlooking other rich features that can provide complementary semantic cues. By combining these multiple views with various strategies and designing cross-KG inference methods, this approach significantly improves alignment performance. The strength of multi-view learning lies in its ability to capture a broader spectrum of semantic information, making the embeddings more discriminative. Nevertheless, the challenge lies in effectively weighting and integrating potentially conflicting signals from different views, and the computational overhead increases with the number of views considered.

More recently, the integration of ontological information has provided another powerful dimension for entity alignment. \cite{xiang2021} introduced OntoEA, an ontology-guided entity alignment method that jointly embeds both KGs and their associated ontologies. This approach explicitly utilizes critical meta-information, such as class hierarchies and class disjointness constraints, which are often ignored by purely structural or attribute-based methods. By enforcing these ontological constraints during the embedding process, OntoEA can prevent false mappings and guide the alignment towards semantically coherent equivalences. This addresses a theoretical gap where KGEs, while powerful, often lack an explicit mechanism to incorporate higher-level schema knowledge. The effectiveness of OntoEA, however, is contingent on the availability and quality of consistent ontological information across the KGs being aligned, which may not always be present in real-world scenarios.

The collective advancements in these KGE-based EA methods underscore a clear evolution in the field. Early approaches focused on leveraging structural similarity, while subsequent methods have progressively integrated more semantic context, auxiliary information, and robust learning paradigms to overcome limitations like data scarcity and feature incompleteness. Comprehensive surveys and experimental reviews, such as those by \cite{zhu2024} and \cite{fanourakis2022}, further highlight the strengths and weaknesses of various KGE-based EA techniques. They emphasize the need for more robust noise filtering strategies, better utilization of additional information, and rigorous comparative analyses across diverse datasets to ensure generalizability. These meta-analyses confirm that KGEs provide a versatile and powerful foundation for integrating heterogeneous knowledge sources, enabling the construction of more comprehensive knowledge bases and facilitating complex cross-KG reasoning, which is crucial for advancing knowledge-driven AI applications.