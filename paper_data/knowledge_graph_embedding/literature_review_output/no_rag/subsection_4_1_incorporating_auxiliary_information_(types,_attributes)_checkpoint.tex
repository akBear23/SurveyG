\subsection{Incorporating Auxiliary Information (Types, Attributes)}
The effectiveness of Knowledge Graph Embedding (KGE) models, while primarily driven by structural information, can be significantly enhanced by integrating auxiliary semantic information such as entity types and attributes. This approach moves beyond the simplistic triplet structure, grounding embeddings in a richer context to yield more semantic, discriminative, and robust representations, particularly crucial when dealing with incomplete or noisy knowledge graphs (KGs). The intellectual trajectory in this area reflects a growing recognition that external, well-structured knowledge can bridge gaps that purely structural models cannot, contributing to the development of more inherently capable KGE models.

Early efforts to incorporate auxiliary information often focused on entity types. \cite{wang2021} proposed \textit{TransET}, a novel KGE model that leverages entity types to learn more semantic features. By utilizing circle convolution based on entity and entity type embeddings, TransET maps head and tail entities to type-specific representations, which are then used in a translation-based scoring function. This method demonstrated that even a relatively straightforward integration of type information could lead to improved performance in link prediction and triple classification tasks. Building on this, \cite{he2023} introduced \textit{TaKE}, a more universal \textit{Type-augmented Knowledge graph Embedding framework}. TaKE distinguishes itself by automatically capturing type features without explicit supervision and learning relation-specific type representations, allowing for a nuanced understanding of how entity types interact with different relations. Furthermore, TaKE incorporates a type-constrained negative sampling strategy, which is critical for constructing more effective negative samples during training, a fundamental aspect for KGE robustness \cite{sachan2020}. While TransET provided a specific model, TaKE offers a generalizable framework that can enhance various traditional KGE models, showcasing a methodological evolution towards broader applicability.

The utility of type information extends to domain-specific applications. \cite{hu2024} presented \textit{SR-KGE}, a \textit{GeoEntity-type constrained knowledge graph embedding} framework designed for predicting natural-language spatial relations. This approach integrates geoentity types as a constraint, combining graph structures with semantic attributes to capture spatial and semantic relations more accurately. While TaKE provides a universal type integration, SR-KGE exemplifies how tailored auxiliary information, when applied to a specific domain, can yield superior results for specialized tasks. The strength of these type-augmented methods lies in their ability to provide semantic guidance, making embeddings more discriminative by enforcing type consistency and enriching the relational context. However, a common limitation is their reliance on the availability and quality of type information; if types are sparse, noisy, or inconsistently defined, the benefits may diminish, and the complexity of integrating diverse type hierarchies can be substantial.

Beyond explicit types, entity attributes offer a richer, instance-specific form of auxiliary information. \cite{zhang2024} addressed the critical problem of erroneous triples in KGs by proposing \textit{AEKE}, a framework for \textit{Attributed Error-aware Knowledge Embedding}. AEKE leverages entity attributes to guide the KGE model in learning against the impact of erroneous triples. It designs triple-level hypergraphs to model both KG topological structures and attribute structures, jointly calculating confidence scores for each triple based on self-contradiction, structural consistency, and attribute homogeneity. These confidence scores then adaptively weigh contributions during multi-view graph learning and margin loss calculation, ensuring that potentially erroneous triples have minimal impact. AEKE represents a significant step towards enhancing KGE robustness, moving beyond merely completing KGs to making them more reliable. While type-based methods provide broad semantic categories, attribute-based approaches like AEKE offer fine-grained details that can be crucial for identifying and mitigating data quality issues.

The scope of auxiliary information also extends to hyper-relational facts, moving "beyond triplets" to capture richer contextual data. \cite{rosso2020} introduced \textit{HINGE}, a \textit{hyper-relational Knowledge Graph Embedding model} that directly learns from hyper-relational facts, where each fact includes a base triplet (\textit{h, r, t}) and associated key-value pairs (\textit{k, v}). HINGE captures not only the primary structural information of the KG but also the correlation between each triplet and its associated key-value pairs. This is a crucial distinction from type or attribute integration, as HINGE directly models additional structured facts that are part of the knowledge base, rather than meta-information about entities. This allows for a more comprehensive understanding of complex data semantics, outperforming models that rely solely on triplets or transform hyper-relational facts into less structured n-ary representations.

In synthesis, the integration of auxiliary information, whether through entity types \cite{wang2021, he2023, hu2024}, attributes \cite{zhang2024}, or hyper-relational facts \cite{rosso2020}, represents a vital direction in KGE research. These approaches collectively address the limitations of purely structural KGEs by providing richer semantic context, making embeddings more discriminative and robust to noise and incompleteness. The evolution from specific type integration (TransET) to universal frameworks (TaKE) and domain-specific applications (SR-KGE) highlights a growing sophistication. Furthermore, the focus on error-aware learning through attributes (AEKE) and the direct modeling of hyper-relational facts (HINGE) underscore the field's commitment to developing KGE models that can handle the complexities and imperfections of real-world knowledge graphs. A key trade-off, however, is the increased reliance on the availability and quality of this auxiliary data, which may not always be consistent across diverse KGs. Nevertheless, these advancements are crucial for pushing KGE towards greater practical utility and theoretical soundness, enabling more intelligent and reliable AI applications.