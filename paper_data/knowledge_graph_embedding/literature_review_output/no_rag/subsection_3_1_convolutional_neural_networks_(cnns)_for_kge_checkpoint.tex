\subsection{Convolutional Neural Networks (CNNs) for KGE}
Convolutional Neural Networks (CNNs) have emerged as a powerful paradigm in Knowledge Graph Embedding (KGE), offering a distinct advantage over traditional geometric models by automatically extracting local features and modeling intricate, non-linear interactions between entity and relation embeddings. Unlike models that rely on predefined geometric transformations, CNNs learn complex patterns directly from the data, enabling them to capture nuanced relational semantics that are often challenging for simpler approaches \cite{cao2022}. This shift represents a significant evolution in KGE, moving towards more expressive and data-driven architectures.

Early applications of CNNs in KGE, such as AcrE \cite{ren2020} and M-DCN \cite{zhang2020}, demonstrated their capability to enhance link prediction. AcrE, for instance, introduced atrous convolutions and residual learning to effectively increase feature interactions while maintaining a simpler structure and higher parameter efficiency. This approach addressed the limitation of conventional models in capturing diverse relation patterns by allowing for a broader receptive field without increasing the number of parameters. M-DCN further advanced this by proposing a multi-scale dynamic convolutional network, utilizing dynamic filters to extract richer and more expressive feature embeddings. M-DCN was particularly designed to handle complex relation patterns like 1-to-N, N-to-1, and N-to-N, which often pose significant challenges for translation-based or simple semantic matching models \cite{ge2023}. The dynamic nature of its filters, tailored to each relation, allowed for a more adaptive modeling of these complex interactions.

The integration of attention mechanisms further refined CNN-based KGE models. ReInceptionE \cite{xie2020} exemplified this by combining an Inception network with a relation-aware attention mechanism. The Inception network was employed to increase interactions between head and relation embeddings, while the attention mechanism enriched these embeddings with joint local and global structural information. This allowed ReInceptionE to adaptively utilize neighborhood context, a capability that purely convolutional models might partially miss, thereby bridging the gap between local feature extraction and broader graph topology awareness. This approach highlights an evolutionary trend within the "Deep Learning Architectures for KGE" subgroup, where models increasingly seek to combine the strengths of different neural components to capture a more comprehensive view of the knowledge graph.

More recent works continue to refine CNN-based techniques for KGE. CNN-ECFA \cite{hu2024} introduced a Convolutional Neural Network-based Entity-specific Common Feature Aggregation strategy, aiming to improve knowledge graph representation learning by leveraging common features that are specific to entities. This model demonstrates that by aggregating entity-specific features, CNNs can learn more effective representations, outperforming state-of-the-art feature projection strategies. Similarly, SEConv \cite{yang2025} proposed a semantic-enhanced KGE model, incorporating a less resource-consuming self-attention mechanism alongside a multi-layer CNN. The multi-layer CNN in SEConv is specifically designed to learn deeper structural features from triplets, while self-attention generates more expressive embedding representations. This model, with its application focus on healthcare prediction, underscores the practical utility of CNNs in learning discriminative features for specialized domains.

A key strength of CNN-based KGE models lies in their ability to automatically discover intricate, non-linear feature interactions, which contrasts with the hand-crafted transformations of geometric models (e.g., TransD \cite{ji2015} or TorusE \cite{ebisu2017}). This automatic feature learning often leads to superior performance in link prediction tasks, achieving state-of-the-art results on various benchmarks. However, this expressiveness comes with trade-offs. CNN models typically involve higher computational complexity and a larger number of parameters compared to simpler geometric models, potentially impacting scalability for extremely large knowledge graphs. Furthermore, while they excel at capturing local patterns, their ability to model long-range dependencies or global graph structures might be less direct than Graph Neural Networks (GNNs) or Transformer-based models, which are inherently designed for such tasks. The development trajectory of CNNs in KGE shows a clear progression from basic convolutional operations to more sophisticated designs incorporating multi-scale processing, dynamic filters, and attention, continually pushing the boundaries of what can be learned from entity-relation interactions.