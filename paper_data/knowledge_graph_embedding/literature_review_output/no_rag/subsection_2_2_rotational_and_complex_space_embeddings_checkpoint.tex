\subsection{Rotational and Complex Space Embeddings}
While foundational translational models like TransE and TransH \cite{wang2014} offered a significant step forward in knowledge graph embedding (KGE) by modeling relations as vector translations, they often struggled with capturing the full spectrum of complex relational semantics, such as symmetry, antisymmetry, inversion, and composition \cite{rossi2020}. This limitation spurred the development of models that leverage rotations in complex or higher-dimensional spaces, offering more nuanced and powerful transformations to represent these intricate logical patterns. This represents a key methodological shift within the "Core KGE Model Architectures and Expressiveness" and "Geometric and Algebraic KGE Models for Complex Relations" subgroups, moving beyond simpler linear operations to richer algebraic structures.

A seminal contribution in this direction is RotatE \cite{sun2018}, which defines each relation as a rotation from the head entity to the tail entity in a complex vector space. By representing entities as vectors and relations as Hadamard products with complex-valued relation vectors (which correspond to rotations), RotatE inherently captures symmetry (rotation by $\pi$), antisymmetry (rotation by non-$\pi$ angles), inversion (rotation by negative angle), and composition (sequential rotations). This elegant formulation proved highly effective for modeling complex patterns and significantly outperformed existing state-of-the-art models for link prediction on benchmark datasets \cite{sun2018}. The success of RotatE highlighted the expressive power of complex space embeddings, demonstrating how algebraic structures could directly encode logical properties.

Building upon this rotational paradigm, researchers explored extensions to higher-dimensional Euclidean and non-Euclidean spaces. Rotate3D \cite{gao2020} extends the concept of relations as rotations to a three-dimensional Euclidean space. A key motivation for Rotate3D was to capture non-commutative composition patterns, which are essential for multi-hop reasoning and are naturally supported by rotations in 3D space. While RotatE primarily operates in a 2D complex plane for each dimension, Rotate3D generalizes this to a full 3D rotation, allowing for a richer set of transformations. Similarly, Orthogonal Relation Transforms \cite{tang2019} further generalize this idea by employing high-dimensional orthogonal transforms, which encompass rotations and reflections, to model relations. This approach aims to retain the benefits of rotational models (symmetry, inversion, composition) while enhancing modeling capacity for complex relations like N-to-1 and 1-to-N by integrating graph context.

The pursuit of even more expressive geometric transformations led to models like HousE \cite{li2022}, which introduces Householder parameterization. Householder transformations, a type of reflection, can be generalized to represent rotations and projections in high-dimensional spaces. HousE aims to simultaneously capture crucial relation patterns and mapping properties, theoretically generalizing existing rotation-based models while extending rotations to higher dimensions. This exemplifies the continuous effort to find more powerful mathematical tools to encode relational semantics.

Further enhancing the complexity of transformations, CompoundE \cite{ge2022} and its 3D extension, CompoundE3D \cite{ge2023}, propose using compound geometric operations, including translation, rotation, and scaling. These models treat relations not as a single operation but as a cascade of multiple transformations, suggesting that a richer set of combined operations can lead to better modeling capacity. CompoundE, by framing itself within group theory, demonstrates that several existing KGE models are special cases of its generalized framework, highlighting a trend towards unifying diverse geometric approaches. While these compound operations offer increased expressiveness, they also introduce greater model complexity and potentially higher computational costs, a common trade-off in KGE research \cite{cao2022}.

A significant recent development is the use of quaternions, an extension of complex numbers to four dimensions, to represent relations. ConQuatE \cite{chen2025} leverages quaternion rotations to address the challenge of polysemy in knowledge graphs, where entities can exhibit different semantic characteristics depending on the relation. By incorporating contextual cues from various connected relations through efficient vector transformations in quaternion space, ConQuatE aims to capture diverse relational contexts without requiring extra information beyond original triples. This approach offers a novel way to handle the nuanced semantic variations that simpler rotational models might overlook, particularly for link prediction and multihop reasoning.

The "Geometric and Algebraic KGE Models for Complex Relations" subgroup analysis highlights that while these models achieve state-of-the-art performance, a common limitation is the potential for increased computational cost and parameter count, which can affect scalability to extremely large KGs. Moreover, the empirical validation often relies heavily on standard link prediction metrics, which may not fully capture the nuances of all the complex patterns these models aim to capture, especially for tasks like set retrieval or complex logical reasoning. For instance, MQuinE \cite{liu2024} identifies and addresses a theoretical deficiency, termed the "Z-paradox," in some popular KGE models, demonstrating that even advanced models can suffer from subtle expressiveness issues that degrade performance on challenging test samples. This underscores that merely introducing complex operations is insufficient; theoretical soundness and complete expressiveness are paramount.

The intellectual trajectory in this area, as noted in the "Core KGE Model Architectures and Expressiveness" subgroup, shows a clear progression from specific rotational models to more theoretically grounded and generalized orthogonal transformations. HolmE \cite{zheng2024} introduces a KGE model whose relation embedding space is "closed under composition," a crucial property for inherently modeling under-represented (long-tail) composition patterns and extrapolating to unseen relations. This addresses a theoretical gap where prior KGEs often considered relations compositional only if well-represented in training data. Similarly, GoldE \cite{li2024} proposes a universal orthogonal parameterization based on a generalized Householder reflection, aiming to unify dimensional extension and geometric unification with theoretical guarantees, thereby capturing both logical patterns and topological heterogeneity. SpherE \cite{li2024} further extends rotational embeddings by representing entities as spheres instead of vectors, specifically targeting the challenging problem of set retrieval and many-to-many relations, while maintaining interpretability. These advancements demonstrate a continuous drive to enhance the fundamental expressiveness of KGE models, ensuring they can effectively handle the complexities and imperfections of real-world knowledge graphs.