\subsection{Temporal Knowledge Graph Embedding (TKGE)}
The inherent dynamism of real-world knowledge necessitates models capable of capturing the temporal evolution of facts within knowledge graphs (KGs). Traditional Knowledge Graph Embedding (KGE) models, primarily designed for static KGs, fall short in tasks requiring reasoning over time or understanding the fluidity of information. Temporal Knowledge Graph Embedding (TKGE) addresses this by explicitly integrating time into the embedding process, moving beyond static representations to model evolving entities and relations \cite{dai2020}.

Early approaches to TKGE focused on explicitly structuring and modeling time itself. \cite{dasgupta2018} introduced \textit{HyTE}, a hyperplane-based method that associates each timestamp with a corresponding hyperplane in the entity-relation space. This allows for temporally guided KG inference and prediction of temporal scopes for facts, marking a significant step towards dynamic KGEs. While intuitive, HyTE's reliance on simple hyperplanes might struggle with highly complex, non-linear temporal dependencies. Another prominent method involves treating the entire fact set as a higher-order tensor, typically a fourth-order tensor (head, relation, tail, time), and applying tensor decomposition to learn dense, low-dimensional temporal embeddings \cite{lin2020}. This provides a robust mathematical framework for integrating time as a distinct dimension. Complementing this, \textit{ATiSE} models temporal evolution using additive time series decomposition, mapping representations into multi-dimensional Gaussian distributions where covariance captures temporal uncertainty, offering a probabilistic view of temporal dynamics \cite{xu2019}. More recently, \textit{TeAST} innovatively structures time by mapping relations onto an Archimedean spiral timeline, transforming the quadruple completion problem into a 3rd-order tensor completion task. This approach aims to ensure relations evolve orderly over time with a spiral regularizer, offering a degree of interpretability regarding temporal patterns \cite{li2023}. A common limitation across these tensor and time series methods is the computational cost associated with higher-order operations or complex decompositions, especially for very dense temporal data.

A significant advancement in TKGE involves leveraging geometric transformations to model temporal dynamics. \textit{TeRo} defines the temporal evolution of entity embeddings as a rotation from an initial time to the current time in a complex vector space, representing relations for time intervals with dual complex embeddings \cite{xu2020}. Building upon this, \textit{ChronoR} extends the concept by employing k-dimensional rotation transformations, parametrized by relation and time, to transform a head entity to fall near its tail entity. This effectively captures rich interactions between temporal and multi-relational characteristics \cite{sadeghian2021}. While powerful, the interpretability of complex rotations in high-dimensional spaces can be challenging, and the computational complexity associated with learning these transformations can be substantial, particularly for very large KGs or highly granular temporal data.

More advanced methods, particularly emerging in recent years, address the complexities of dynamic, spatiotemporal, and even fuzzy knowledge by moving beyond a single Euclidean space. \textit{MADE} and \textit{IME}, both published in 2024, represent a cutting-edge shift towards modeling TKGs in multi-curvature spaces, including Euclidean, hyperbolic, and hyperspherical geometries \cite{wang2024, wang2024a}. The rationale is that TKGs often contain interwoven complex geometric structures (e.g., hierarchical, ring, chain) that no single curvature space can optimally capture. MADE introduces an adaptive weighting mechanism to assign different weights to these spaces in a data-driven manner, along with a quadruplet distributor and temporal regularization for timestamp smoothness \cite{wang2024}. IME, on the other hand, incorporates "space-shared" properties to learn commonalities across spaces and alleviate spatial gaps, and "space-specific" properties to capture characteristic features, complemented by an Adjustable Multi-curvature Pooling (AMP) approach \cite{wang2024a}. While both achieve state-of-the-art results, MADE's adaptive weighting offers a more flexible approach to handling diverse geometric structures without requiring explicit design of shared/specific properties. The primary limitation for both is the increased complexity of optimizing embeddings across multiple, potentially disparate, geometric spaces, and the computational overhead.

Further extending these geometric transformations, recent works tackle fuzzy and spatiotemporal dimensions. \textit{FSTRE} uses projection and rotation in a complex vector space to embed spatial and temporal information, introducing fine-grained fuzziness through modal lengths of anisotropic vectors \cite{ji2024}. This addresses the insufficiency of prior KGE models for uncertain and dynamic knowledge. Building on this, \cite{ji2024a} leverages quaternion embeddings to jointly embed spatiotemporal entities, representing relations as rotations and exploiting the non-commutative compositional pattern of quaternions for multihop path reasoning and uncertainty modeling. This approach is particularly powerful for complex tasks like multihop querying on incomplete fuzzy spatiotemporal KGs, where previous methods overlooked uncertainty and spatiotemporal sensitivity during reasoning. These advanced models, while powerful, introduce additional complexity (fuzziness, spatiotemporal, quaternions) which can increase model intricacy and training demands.

Finally, \textit{TARGAT} offers an alternative paradigm by employing a time-aware relational graph attention model based on Graph Neural Networks (GNNs) \cite{xie2023}. It addresses the limitation of previous GNN-based models that struggle to directly capture multi-fact interactions at different timestamps by dynamically generating time-aware relational message transformation matrices. This GNN-based approach provides a unified way to process the entire graph of multi-facts over time. However, GNNs can face scalability challenges with extremely large and dense TKGs due to the computational intensity of message passing.

In summary, TKGE research has evolved from explicit temporal integration using hyperplanes or tensors to sophisticated geometric transformations (rotations, multi-curvature spaces) and advanced algebraic structures (quaternions) to handle the multifaceted nature of dynamic, spatiotemporal, and fuzzy knowledge. The trade-off between model expressiveness and computational complexity remains a persistent challenge, with recent models pushing the boundaries of what can be captured, often at the cost of increased model intricacy and optimization demands.