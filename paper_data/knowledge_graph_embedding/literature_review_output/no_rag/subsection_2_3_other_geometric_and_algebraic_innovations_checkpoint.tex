\subsection*{Other Geometric and Algebraic Innovations}
Beyond the foundational translational and rotational paradigms, Knowledge Graph Embedding (KGE) research has continuously sought to refine its mathematical underpinnings by exploring a broader spectrum of geometric spaces and algebraic transformations. This pursuit is driven by the need for more expressive, theoretically sound, and robust representations capable of capturing the intricate nuances of real-world knowledge graphs.

One significant direction involves embedding entities and relations within non-Euclidean spaces, particularly Lie groups, to circumvent inherent limitations of standard vector spaces. \cite{ebisu2017} introduced \textbf{TorusE}, a pioneering model that embeds entities on a Lie group, specifically a torus. The primary motivation for TorusE was to address the regularization problems encountered by models like TransE, where forcing entity embeddings onto a sphere in Euclidean space could warp representations and adversely affect link prediction accuracy. By leveraging the compact nature of a torus, TorusE naturally avoids the need for explicit regularization, as the space itself is bounded. While innovative in its choice of embedding space, TorusE still adheres to a translation-like principle, defining relations as translations within the Lie group. However, its geometric complexity, while elegant, might not inherently capture all forms of complex relation patterns, such as compositionality, as effectively as models designed with specific algebraic operations for such patterns.

Another critical area of innovation lies in scrutinizing and redefining the metric used within the embedding space. \cite{yang2021} presented \textbf{CyclE}, which critically examines the implications of the widely adopted Minkowski metric in KGE. The authors argue that the choice of metric significantly influences the expressiveness of the embedding space and propose a novel "Cycle metric" based on the oscillation property of periodic functions. Their quantitative analysis suggests that a smaller function period in the Cycle metric leads to superior expressive ability. CyclE, by combining this new metric with popular KGE models, demonstrated enhanced performance. This work highlights a fundamental aspect of geometric KGE: the distance function itself is a crucial design choice. However, focusing solely on the metric, while foundational, may not inherently provide the rich *transformations* required to model complex logical patterns like transitivity or hierarchy without further architectural or operational enhancements.

A more direct approach to enhancing modeling capacity involves introducing advanced algebraic transformations. \cite{li2022} proposed \textbf{HousE}, a powerful KGE framework that leverages Householder parameterization. HousE employs two types of Householder transformations: Householder rotations to achieve superior capacity for modeling relation patterns and Householder projections to handle sophisticated relation mapping properties (e.g., 1-to-N, N-to-1). Theoretically, HousE is capable of simultaneously modeling crucial relation patterns and mapping properties, and it generalizes existing rotation-based models by extending rotations to high-dimensional spaces. Empirically, HousE achieved state-of-the-art performance on several benchmarks, indicating its enhanced expressiveness compared to simpler rotation-based models like \cite{gao2020} Rotate3D or \cite{tang2019} Orthogonal Relation Transforms. The strength of HousE lies in its mathematically robust and versatile transformations, offering a richer set of operations than basic rotations.

Building upon the idea of combining multiple operations, \cite{ge2022} introduced \textbf{CompoundE}, which integrates translation, rotation, and scaling operations into a cascaded compound transformation. This model views relations as complex geometric manipulations, demonstrating that a synergy of these operations can lead to highly expressive embeddings. Further extending this concept, \cite{ge2023} developed \textbf{CompoundE3D}, which leverages 3D compound geometric transformations, including translation, rotation, scaling, reflection, and shear. CompoundE3D offers multiple design variants, allowing for flexibility to match the rich underlying characteristics of diverse knowledge graphs. These compound operation models represent a significant evolutionary step, as they generalize many existing scoring-function-based KGE models as special cases, effectively encompassing the strengths of both translational and rotational approaches while adding further dimensions of transformation. This contrasts with models like \cite{yang2019} TransMS, which focuses on multidirectional semantics within a translation framework, or \cite{peng2020} LineaRE, which models relations as simple linear functions.

Other notable algebraic innovations include \cite{song2021} \textbf{Rot-Pro}, which combines projection and relational rotation to specifically model transitivity, a common but challenging relation pattern. \cite{zhang2022} \textbf{TranS} introduces synthetic relation representations within transition-based frameworks to better handle complex scenarios where the same entity pair might have different relations. More recently, \cite{liu2024} proposed \textbf{MQuinE}, which directly addresses and cures a theoretical deficiency termed the "Z-paradox" in some popular KGE models, thereby ensuring stronger expressiveness and theoretical soundness. The use of advanced algebraic structures is further exemplified by \cite{chen2025} \textbf{ConQuatE}, which leverages quaternion rotations to capture diverse relational contexts and address the polysemy issue, where entities exhibit different semantic characteristics depending on the relation.

Collectively, these innovations highlight a continuous intellectual trajectory in KGE research: moving from simpler, single-operation models to more complex, multi-operation, multi-dimensional, and non-Euclidean spaces. This evolution is driven by the relentless quest to capture increasingly complex and nuanced relational patterns, thereby enhancing model expressiveness and theoretical rigor. While these models achieve state-of-the-art performance on various benchmarks, they often introduce increased mathematical complexity and computational costs, which can impact scalability, especially for extremely large knowledge graphs. Furthermore, the theoretical elegance of these geometric and algebraic models, while appealing, sometimes comes at the cost of interpretability, making it challenging to fully understand *why* certain transformations are optimal for specific relation patterns. The choice of the "best" geometric space or transformation remains highly dependent on the specific characteristics of the knowledge graph and the types of relations it contains.