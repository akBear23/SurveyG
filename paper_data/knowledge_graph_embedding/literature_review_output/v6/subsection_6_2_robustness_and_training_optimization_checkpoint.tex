\subsection{Robustness and Training Optimization}
While the preceding sections have explored the evolution of Knowledge Graph Embedding (KGE) models towards greater expressiveness (Section 2) and architectural sophistication (Section 3), and the critical need for efficiency and scalability (Subsection 6.1), the practical utility of these models hinges significantly on their robustness against real-world data imperfections and the optimization of their training processes. This subsection delves into methodologies that ensure KGE models learn accurate and reliable representations even from noisy, incomplete, or imbalanced data, leading to more trustworthy predictions and better generalization. The focus here is on enhancing the resilience of KGE models and refining the learning mechanisms that underpin their performance.

\subsubsection*{Probability Calibration for Reliable Predictions}
A critical, yet often overlooked, aspect of KGE model reliability is the calibration of their probability estimates. Many KGE models output raw scores that indicate plausibility, but these scores are frequently uncalibrated, meaning a score of, for instance, 0.8 does not reliably correspond to an 80\% chance of a triple being true. This unreliability can be detrimental in high-stakes applications requiring precise confidence levels. \cite{tabacof2019} explicitly addresses this problem, demonstrating that popular embedding models are indeed uncalibrated.

\textbf{Problem Solved:} \cite{tabacof2019} aims to make the probability estimates associated with predicted triples reliable, especially in scenarios where ground truth negatives, crucial for direct calibration, are scarce.
\textbf{Core Innovation:} The paper proposes a novel method to calibrate KGE models post-training, even without readily available ground truth negatives. It leverages established techniques like Platt scaling and isotonic regression, adapting them for the KGE context.
\textbf{Conditions for Success:} The method succeeds when the underlying KGE model provides a reasonably good ranking of triples, even if its raw scores are uncalibrated. It is a model-agnostic post-processing step, applicable to a wide range of KGE architectures.
\textbf{Theoretical Limitations:} Calibration is a post-hoc adjustment; it does not enhance the intrinsic discriminative power of the KGE model itself. Its effectiveness is bounded by the quality of the raw scores provided by the base model. Furthermore, the absence of true negatives for calibration introduces its own set of challenges, requiring careful proxy selection.
\textbf{Practical Limitations:} While effective, applying calibration methods like isotonic regression can be computationally intensive and may require a dedicated validation set for optimal performance, which might still be challenging to obtain with reliable negative samples.
\textbf{Comparison to Alternatives:} Unlike methods that directly improve embedding quality or filter noisy inputs, calibration focuses solely on the interpretability and trustworthiness of the *output scores*. It complements other robustness techniques by ensuring that the model's confidence in its predictions is well-aligned with reality. This addresses a different facet of robustness compared to the input-focused methods discussed next.
\textbf{Implications:} This work highlights that traditional KGE evaluation metrics (e.g., Hit@K, MRR) do not fully capture the reliability of predictions, advocating for a more comprehensive assessment of model trustworthiness.

\subsubsection*{Robustness Against Noisy Data and Imbalance}
Real-world knowledge graphs are often constructed automatically, inevitably introducing noise and conflicts. Most KGE models, however, implicitly assume clean data, leading to suboptimal or unreliable representations when trained on imperfect KGs. Concurrently, KGs frequently exhibit long-tail distributions, where a small fraction of entities and relations are highly frequent, while the vast majority are rare, leading to imbalanced training.

\textbf{Noise Filtering via Reinforcement Learning:}
\cite{zhang2021} addresses the challenge of noisy KGs by proposing a novel framework.
\textbf{Problem Solved:} This method tackles the degradation of KGE performance due to noisy triples and knowledge conflicts, which are prevalent in automatically constructed KGs.
\textbf{Core Innovation:} It introduces a multi-task reinforcement learning (RL) framework where an RL agent learns to dynamically select high-quality triples and filter out noisy ones during the training process. To enhance efficiency and leverage semantic similarities, the triple selection processes for semantically similar relations are trained collectively using multi-task learning.
\textbf{Conditions for Success:} The approach is particularly effective in scenarios where KGs are known to contain a significant amount of noise. It is general enough to be extended to popular KGE models like TransE, DistMult, ConvE, and RotatE.
\textbf{Theoretical Limitations:} RL-based training can be complex, requiring careful design of reward functions and state representations. The inherent uncertainty of identifying "true" noise in a large KG makes the optimal filtering strategy difficult to guarantee.
\textbf{Practical Limitations:} Integrating an RL agent significantly increases the complexity and computational cost of the training pipeline compared to standard KGE models. Hyperparameter tuning for the RL component can also be challenging and time-consuming.
\textbf{Comparison to Alternatives:} This approach represents a proactive, *in-training* mechanism for robustness, directly cleaning the input data stream. This contrasts with post-hoc calibration \cite{tabacof2019} or reactive negative sampling strategies, offering a more fundamental solution to input data quality issues.
\textbf{Implications:} This work signals a shift towards more adaptive and intelligent training paradigms that actively manage data quality, rather than passively accepting noisy inputs.

\textbf{Weighted Training for Imbalanced Data:}
\cite{zhang2023} addresses the pervasive data imbalance issue in KGs, where entities and relations follow a long-tail distribution.
\textbf{Problem Solved:} Existing KGE methods often assign equal weights to all entities and relations during training, leading to unreliable representations for infrequent (long-tail) elements due to insufficient training exposure.
\textbf{Core Innovation:} The proposed method, WeightE, employs a bilevel optimization scheme. The inner level focuses on learning reliable entity and relation embeddings, while the outer level dynamically assigns differential weights to entities and relations. It prioritizes infrequent entities and relations by endowing them with higher weights, ensuring they receive adequate training.
\textbf{Conditions for Success:} WeightE is particularly beneficial for KGs with pronounced long-tail distributions. Its weighting technique is designed to be general and flexible, applicable to a number of existing KGE models.
\textbf{Theoretical Limitations:} Bilevel optimization, while powerful, can be computationally more demanding than single-level optimization. The convergence properties and global optimality guarantees can be complex to establish, and the optimal weighting strategy might vary significantly across different KGs.
\textbf{Practical Limitations:} The added complexity of bilevel optimization can increase training time and resource consumption. Careful tuning of the outer-level optimization parameters is crucial for effective performance.
\textbf{Comparison to Alternatives:} WeightE tackles a different aspect of robustness: ensuring fair and effective learning across the entire spectrum of data frequency. This complements noise filtering by addressing data distribution issues and differs from calibration, which focuses on output reliability. It is a general training optimization technique that can be integrated with various KGE architectures.
\textbf{Implications:} This highlights the importance of considering data distribution characteristics in KGE training, moving beyond uniform treatment to ensure high-quality representations for all knowledge elements, which is vital for comprehensive knowledge reasoning.

\subsubsection*{The Crucial Role of Negative Sampling}
The training of KGE models typically relies on contrastive learning, which necessitates discriminating between positive (true) and negative (false) triples. Since KGs predominantly store only positive facts, the generation of effective negative samples is a critical and non-trivial aspect of the training process, profoundly impacting model accuracy and robustness. The evolution of negative sampling (NS) methods reflects a continuous effort to overcome the challenges of generating high-quality, informative negative examples.

\begin{table}[htbp]
    \centering
    \caption{Comparative Framework for Negative Sampling Strategies}
    \label{tab:negative_sampling_comparison}
    \begin{tabularx}{\textwidth}{|l|X|X|X|X|}
        \hline
        \textbf{Feature} & \textbf{Confidence-Aware NS \cite{shan2018}} & \textbf{NSCaching \cite{zhang2018}} & \textbf{Non-Sampling (NS-KGE) \cite{li2021}} & \textbf{Modality-Aware NS \cite{zhang2023_modality}} \\
        \hline
        \textbf{Problem Solved} & Training in noisy KGs, avoiding zero loss/false detection from uniform NS. & Efficiently finding "hard" negatives, avoiding complexity of GAN-based methods. & Instability and uncertainty inherent in all sampling procedures, considering all negatives. & Adapting NS for multi-modal KGEs, aligning structural and visual embeddings. \\
        \hline
        \textbf{Core Innovation} & Incorporating negative triple confidence to guide sampling in noisy environments. & Cache-based tracking and sampling of "hard" negative triplets. & Mathematical derivation to consider all negative instances without explicit sampling. & Aligning structural and visual embeddings during negative sample generation. \\
        \hline
        \textbf{Conditions for Success} & Noisy KGs where uniform sampling leads to issues; requires confidence estimation. & Scenarios where "hard" negatives are crucial for learning but are rare. & KGE models with square-loss or convertible loss functions; requires efficient mathematical optimization. & Multi-modal KGs where diverse data modalities need semantic alignment. \\
        \hline
        \textbf{Theoretical Limitations} & Relies on accurate confidence estimation, which can be challenging and noisy itself. & Still a heuristic sampling method; cache management introduces its own complexities. & Limited to specific loss functions; complexity reduction is often an approximation or specific to certain model forms. & Increased complexity due to modality fusion; optimal cross-modal alignment is difficult to define. \\
        \hline
        \textbf{Practical Limitations} & Adds complexity to the confidence estimation process and its integration into training. & Requires careful management of cache size and balancing exploration-exploitation. & Can have high initial computational cost and memory footprint without clever optimization. & Requires multi-modal data availability; complex fusion and sampling design. \\
        \hline
        \textbf{Comparison to Alternatives} & More robust than uniform NS in noisy settings; less complex than GAN-based methods. & Simpler and more efficient than GAN-based NS while achieving similar benefits of hard negative mining. & Offers more stable and accurate performance by removing sampling uncertainty, but with higher initial complexity. & Extends NS to a new domain; addresses multi-modal specific challenges, unlike purely structural NS. \\
        \hline
    \end{tabularx}
\end{table}

\textbf{Evolution of Negative Sampling Strategies:}
Early KGE models often relied on uniform random negative sampling, which, while simple, frequently generated "easy" negatives that provided little learning signal or "false negatives" that were actually true but unobserved. This led to issues like vanishing gradients or incorrect learning.

\textbf{Heuristic-based Negative Sampling:}
Mid-period research introduced more sophisticated heuristic-based sampling. \cite{shan2018} proposed a \textit{confidence-aware negative sampling method} to address the problem of noisy KGs.
\textbf{Core Innovation:} It introduces the concept of negative triple confidence, allowing the training process to better handle noisy environments where uniform sampling might lead to zero loss or false detection. By assigning confidence scores to negative samples, the model can learn more effectively from them.
\textbf{Comparison:} This method improves upon uniform sampling by making the negative generation process more intelligent and robust to input noise, complementing the noise filtering of \cite{zhang2021} by focusing on the negative side of the learning objective.

Building on the observation that "hard" negative triplets (those that are plausible but false) are crucial for effective learning, \cite{zhang2018} introduced \textit{NSCaching}.
\textbf{Core Innovation:} NSCaching efficiently tracks and samples these hard negatives using a cache. This approach aims to distill the benefits of more complex Generative Adversarial Network (GAN)-based negative sampling methods into a simpler, more efficient framework, avoiding the additional parameters and training complexities associated with GANs.
\textbf{Comparison:} NSCaching offers a practical and efficient alternative to GAN-based methods, achieving comparable performance gains by focusing on the most informative negative samples without the overhead of training a generative model.

\textbf{Non-Sampling Approaches and Comprehensive Reviews:}
A more radical departure from traditional negative sampling is presented by \cite{li2021} with \textit{Efficient Non-Sampling Knowledge Graph Embedding (NS-KGE)}.
\textbf{Core Innovation:} This method proposes to avoid negative sampling entirely by considering all negative instances in the KG for model learning. It leverages mathematical derivations to reduce the computational complexity of this "non-sampling" loss function, aiming for more stable and accurate performance by removing the inherent uncertainty and suboptimality of sampling.
\textbf{Comparison:} NS-KGE fundamentally challenges the assumption that sampling is necessary, offering a theoretically more sound approach by considering the full negative space. This contrasts sharply with all sampling-based methods, including those of \cite{shan2018} and \cite{zhang2018}, which are inherently heuristic. While it promises greater stability, its applicability is currently limited to square-loss based KGE models or those whose loss functions can be converted to a square loss.

As KGE models integrate more diverse data, negative sampling strategies also need adaptation. \cite{zhang2023_modality} introduces \textit{Modality-Aware Negative Sampling} for multi-modal KGE.
\textbf{Core Innovation:} This method recognizes that when incorporating multi-modal information (e.g., text, images), negative sampling must align structural and visual embeddings for entities. It ensures that negative samples are meaningful across all modalities, leading to better-aligned and more robust multi-modal embeddings.
\textbf{Comparison:} This extends the negative sampling problem to a new dimension, highlighting that as KGE models become more complex (as discussed in Subsection 4.3), their training components must also evolve to handle the increased complexity.

The critical importance of negative sampling is further underscored by comprehensive reviews. \cite{qian2021} and \cite{madushanka2024} provide systematic categorizations and analyses of existing negative sampling approaches.
\textbf{Implications:} These surveys consolidate knowledge, categorize methods into distinct families (e.g., static, dynamic, custom cluster-based), and identify open research questions, guiding future advancements in this vital area. They highlight that the "true" negative distribution remains unknown, making the design of optimal NS methods an ongoing heuristic challenge and a fundamental theoretical limitation that no current method fully resolves.

\textbf{Patterns and Tensions in Training Optimization:}
The research in robustness and training optimization reveals several key patterns and tensions. A recurring trade-off exists between the \textit{simplicity/efficiency} of a training method and its \textit{robustness/accuracy}. For instance, while uniform negative sampling is simple, it often yields suboptimal results in noisy or imbalanced settings, necessitating more complex solutions like confidence-aware sampling \cite{shan2018} or NSCaching \cite{zhang2018}. The emergence of non-sampling approaches \cite{li2021} represents a paradigm shift, challenging the long-standing assumption that negative sampling is an unavoidable necessity, but this comes with its own computational complexities that require clever mathematical derivations.

Another tension lies between \textit{proactive} and \textit{reactive} robustness. Methods like RL-based noise filtering \cite{zhang2021} proactively clean the input data during training, while probability calibration \cite{tabacof2019} reactively adjusts the model's output scores. Both contribute to overall trustworthiness but address different stages of the KGE pipeline. The field implicitly assumes that the benefits of these complex optimizations outweigh their increased computational cost and implementation complexity, a trade-off that is not always explicitly quantified across diverse application scenarios.

Collectively, these advancements in robustness and training optimization are vital for ensuring that KGE models learn accurate representations even from noisy or incomplete data, leading to more reliable predictions and better generalization. They bridge the gap between theoretically powerful KGE architectures and their practical deployment in real-world, imperfect knowledge environments.