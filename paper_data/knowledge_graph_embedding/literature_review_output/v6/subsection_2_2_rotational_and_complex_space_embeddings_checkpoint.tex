\subsection*{Rotational and Complex Space Embeddings}

Building upon the foundational translational models discussed previously, which primarily focused on vector addition in real Euclidean spaces, a significant paradigm shift in Knowledge Graph Embedding (KGE) research emerged with the introduction of rotational and complex space embeddings. These models address the inherent limitations of translational approaches, particularly their struggle to capture richer relational semantics such as symmetry, antisymmetry, inversion, and composition \cite{sun2018}. Translational models like TransE \cite{wang2014} inherently assume that relations are simple displacements, making it difficult to distinguish between $h \xrightarrow{r} t$ and $t \xrightarrow{r} h$ for symmetric relations, or to model $h \xrightarrow{r_1} i \xrightarrow{r_2} t$ as equivalent to $h \xrightarrow{r_3} t$ for compositional relations. Rotational models, by contrast, leverage the algebraic properties of complex numbers and higher-dimensional rotations to offer more nuanced and powerful transformations.

The seminal work in this area is \textbf{RotatE} (Knowledge Graph Embedding by Relational Rotation in Complex Space) \cite{sun2018}. RotatE claims to solve the problem of effectively modeling and inferring various complex relation patterns, including symmetry ($r \iff r^{-1}$), antisymmetry ($r \implies \neg r^{-1}$), inversion ($r \iff r'^{-1}$), and composition ($r_1 \circ r_2 \implies r_3$). Its core innovation lies in defining each entity as a vector in a complex vector space ($\mathbb{C}^k$) and each relation as an element-wise rotation from the head entity to the tail entity. Specifically, for a triple $(h, r, t)$, RotatE models the relation as $\mathbf{h} \circ \mathbf{r} \approx \mathbf{t}$, where $\mathbf{h}, \mathbf{r}, \mathbf{t} \in \mathbb{C}^k$ and $\circ$ denotes the Hadamard (element-wise) product. The relation vector $\mathbf{r}$ is constrained to have moduli of 1 for each dimension (i.e., $|r_i|=1$), ensuring it acts as a pure rotation. The scoring function is typically $f(h,r,t) = ||\mathbf{h} \circ \mathbf{r} - \mathbf{t}||_{L1/L2}$. This elegant formulation inherently captures the desired patterns:
\begin{itemize}
    \item \textbf{Symmetry}: If $r$ is symmetric, then $\mathbf{r}$ should be close to a vector of all 1s (no rotation), or $\mathbf{r}^2 \approx \mathbf{1}$.
    \item \textbf{Antisymmetry}: If $r$ is antisymmetric, then $\mathbf{r}$ should be far from a vector of all 1s.
    \item \textbf{Inversion}: If $r'$ is the inverse of $r$, then $\mathbf{r}' \approx \mathbf{r}^{-1}$ (element-wise conjugate).
    \item \textbf{Composition}: If $r_1 \circ r_2 \implies r_3$, then $\mathbf{r}_1 \circ \mathbf{r}_2 \approx \mathbf{r}_3$.
\end{itemize}
RotatE succeeds under conditions where KGs exhibit a rich variety of these logical patterns. Its theoretical advantage stems from the algebraic properties of complex numbers, which naturally encode rotations and their compositions. Empirically, RotatE significantly outperformed existing state-of-the-art models for link prediction on benchmark datasets like FB15k-237 and WN18RR, demonstrating its effectiveness \cite{sun2018}. A practical limitation of RotatE, while more expressive than TransE, is its increased computational cost due to complex number arithmetic, and it might still struggle with very high-dimensional or extremely sparse relations where the "pure rotation" assumption might be too restrictive.

The success of RotatE spurred further research into higher-dimensional rotational embeddings. \textbf{Rotate3D} \cite{gao2020} extends the concept of relations as rotations from 2D complex space to 3D Euclidean space. This model maps entities to 3D vectors and defines relations as 3D rotations, leveraging the non-commutative property of 3D rotations. This non-commutativity is particularly beneficial for modeling non-commutative composition patterns, which are essential for multi-hop reasoning where the order of relations matters. Rotate3D claims to solve the problem of capturing non-commutative composition, which RotatE, despite its compositional capabilities, might not fully exploit due to the element-wise nature of its complex rotations. The core innovation is using rotation matrices in 3D space, where $\mathbf{R}_r \in SO(3)$ is a 3D rotation matrix for relation $r$. The scoring function is $f(h,r,t) = ||\mathbf{R}_r \mathbf{h} - \mathbf{t}||_{L1/L2}$. Rotate3D demonstrated improved performance on link prediction and path query answering, especially for multi-hop reasoning tasks, compared to RotatE \cite{gao2020}. Its theoretical limitation is that 3D rotations, while powerful, are still a specific type of transformation and may not capture all possible complex relational dynamics. Practically, managing 3D rotation matrices might introduce more parameters or computational complexity than element-wise complex rotations, though it offers a more direct geometric interpretation for certain patterns.

Moving beyond 3D Euclidean space, the use of quaternions offers an even richer algebraic structure for modeling rotations and addressing challenges like polysemy. \textbf{ConQuatE} (Contextualized Quaternion Embedding Towards Polysemy in Knowledge Graph for Link Prediction) \cite{chen2025} is a recent model that leverages quaternion rotations. Quaternions, which extend complex numbers to four dimensions (one real, three imaginary components), can represent 3D rotations more compactly and efficiently than 3x3 matrices. ConQuatE claims to address the polysemy issue in KGs, where entities can exhibit different semantic characteristics depending on the relations they participate in. The core innovation is to incorporate contextual cues from various connected relations to enrich entity representations, which are then transformed using quaternion rotations. For a triple $(h, r, t)$, entities and relations are embedded as quaternions, and the relation $r$ acts as a quaternion rotation from $h$ to $t$. The multiple imaginary components of quaternions allow for a more expressive representation of diverse relational contexts, enabling the model to differentiate between different "senses" of an entity based on the relation. ConQuatE's theoretical advantage is its ability to capture more intricate interactions and context-dependent semantics due to the higher-dimensional algebraic properties of quaternions. Empirically, it outperforms state-of-the-art models for link prediction on datasets like FB15k-237 and WN18RR, particularly in scenarios where polysemy is prevalent \cite{chen2025}. A practical limitation is the increased complexity of quaternion arithmetic, which can be computationally more demanding than complex number operations.

\begin{table}[htbp]
    \centering
    \caption{Comparative Overview of Rotational and Complex Space KGE Models}
    \label{tab:rotational_models}
    \begin{tabularx}{\textwidth}{|l|X|X|X|X|}
        \hline
        \textbf{Model} & \textbf{Embedding Space} & \textbf{Core Operation} & \textbf{Key Patterns/Problems Addressed} & \textbf{Theoretical/Practical Considerations} \\
        \hline
        \textbf{RotatE} \cite{sun2018} & Complex Vector Space ($\mathbb{C}^k$) & Element-wise Rotation (Hadamard product) & Symmetry, Antisymmetry, Inversion, Composition & Elegant mathematical formulation, good expressiveness, moderate computational cost. \\
        \hline
        \textbf{Rotate3D} \cite{gao2020} & 3D Euclidean Space & 3D Rotation Matrix & Non-commutative Composition, Multi-hop Reasoning & Direct geometric interpretation, higher parameter count for matrices, captures order in composition. \\
        \hline
        \textbf{ConQuatE} \cite{chen2025} & Quaternion Space & Quaternion Rotation & Polysemy, Diverse Relational Contexts & Richer algebraic structure, compact 3D rotation, higher computational complexity than complex numbers. \\
        \hline
        \textbf{HousE} \cite{li2022} & Real Vector Space & Householder Transformations (Rotations & Projections) & General relation patterns, mapping properties, higher-dimensional rotations & Generalizes rotations, strong modeling capacity, increased complexity. \\
        \hline
        \textbf{CompoundE} \cite{ge2022} & Real Vector Space & Cascaded Translation, Rotation, Scaling & General relation patterns, diverse mapping properties & Unifies multiple operations, high expressiveness, potentially complex optimization. \\
        \hline
        \textbf{SpherE} \cite{li2024} & Spherical Space & Rotational (entity as sphere) & Many-to-many relations, Set Retrieval & Novel entity representation, good for set-based queries, interpretability. \\
        \hline
    \end{tabularx}
\end{table}

The intellectual trajectory in this domain demonstrates a clear progression from simpler translational models to increasingly complex algebraic structures. While translational models like TransH \cite{wang2014} and TransD \cite{ji2015} introduced relation-specific projections to handle one-to-many/many-to-one relations, they fundamentally relied on vector addition, limiting their ability to model patterns that require more sophisticated transformations. RotatE \cite{sun2018} directly addressed this by introducing rotations in complex space, demonstrating that the algebraic properties of complex numbers are inherently better suited for patterns like inversion and composition. This exemplifies the field's shift from a purely geometric interpretation to leveraging richer algebraic structures.

Further innovations in this family include \textbf{HousE} (Knowledge Graph Embedding with Householder Parameterization) \cite{li2022}, which proposes a more powerful KGE framework based on Householder transformations. Householder transformations can represent both reflections (a type of rotation) and projections, allowing HousE to achieve superior capacity for modeling relation patterns and handling sophisticated relation mapping properties simultaneously. HousE generalizes existing rotation-based models by extending rotations to high-dimensional real spaces, achieving state-of-the-art performance on several benchmarks \cite{li2022}. Its core innovation is the use of Householder matrices, which are orthogonal and symmetric, providing a theoretically sound way to perform rotations and reflections.

Another approach, \textbf{CompoundE} \cite{ge2022} and its 3D extension \textbf{CompoundE3D} \cite{ge2023}, takes a more generalized view by combining translation, rotation, and scaling operations. These models argue that a cascade of these fundamental geometric manipulations can capture a broader spectrum of relational semantics. CompoundE demonstrates that many existing scoring-function-based KGE models can be seen as special cases of its framework, highlighting a convergent research direction towards unifying different geometric operations. This approach offers high expressiveness but introduces a trade-off with increased model complexity and optimization challenges due to the compound nature of operations.

The concept of modeling transitivity, a specific type of compositional pattern, is addressed by \textbf{Rot-Pro} (Modeling Transitivity by Projection in Knowledge Graph Embedding) \cite{song2021}. Rot-Pro theoretically shows that transitive relations can be modeled with projections and combines this insight with relational rotation. It proves that this combination can infer all common relation patterns, including transitivity, and achieves state-of-the-art results on datasets with transitive relations \cite{song2021}. This work builds on the rotational paradigm by adding a projection component to specifically target transitivity, a pattern that even pure rotational models might not perfectly capture.

More recently, \textbf{MQuinE} \cite{liu2024} identifies and resolves a theoretical deficiency, termed "Z-paradox," in some popular KGE models, which can degrade performance, especially on challenging test samples. MQuinE proposes a new KGE model that avoids this paradox while preserving strong expressiveness for various relation patterns, including symmetric/asymmetric, inverse, 1-N/N-1/N-N, and composition relations. This highlights a critical analysis of the theoretical underpinnings of existing models, pushing for more robust and theoretically sound designs. Similarly, \textbf{SpherE} \cite{li2024} extends rotational embeddings by representing entities as spheres instead of vectors, specifically targeting many-to-many relations and enabling set retrieval. This novel entity representation, while inheriting the interpretability of rotational models, offers a unique way to handle set-based queries, a problem often overlooked by traditional KGEs.

The field also sees efforts to generalize orthogonal transformations. \textbf{GoldE} (Generalizing Knowledge Graph Embedding with Universal Orthogonal Parameterization) \cite{li2024} introduces a framework based on a generalized form of Householder reflection. This universal orthogonal parameterization allows for dimensional extension and geometric unification, enabling the framework to simultaneously capture crucial logical patterns and inherent topological heterogeneity. GoldE represents a culmination of efforts to create a unified and highly expressive framework for orthogonal transformations, demonstrating state-of-the-art performance across benchmarks \cite{li2024}.

A critical tension across these models is the trade-off between increased expressiveness and computational complexity. While models like RotatE \cite{sun2018} offer a good balance, extensions to 3D rotations or quaternions, or the use of Householder transformations \cite{li2022}, often come with higher parameter counts or more involved arithmetic operations. For instance, the parameter efficiency of TransD \cite{ji2015} (from the previous subsection) is a practical advantage that more complex rotational models sometimes sacrifice. Furthermore, the assumption that relations can be perfectly modeled by a single type of geometric transformation (e.g., pure rotation) might be an oversimplification for the vast diversity of real-world relations. The evaluation of these models primarily relies on link prediction metrics, which, while standard, may not fully capture the nuances of all the complex patterns they claim to model, especially for tasks like set retrieval (SpherE) or complex logical reasoning. The generalizability of these models to extremely large and sparse KGs, where the computational overhead of complex transformations can become prohibitive, remains an ongoing challenge. Despite these limitations, the shift to rotational and complex/higher-dimensional space embeddings marks a profound advancement, offering more nuanced and powerful transformations that move beyond the limitations of simpler translational approaches, thereby significantly enriching the semantic modeling capabilities of KGEs.