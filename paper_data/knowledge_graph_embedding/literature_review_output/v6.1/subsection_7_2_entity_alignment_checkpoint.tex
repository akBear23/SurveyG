\subsubsection*{Entity Alignment}
Entity alignment (EA) is a critical task in knowledge graph (KG) integration, aiming to identify equivalent entities across different, often heterogeneous, knowledge graphs. This process is fundamental for building comprehensive knowledge bases, enriching existing KGs, and enabling sophisticated cross-KG reasoning \cite{dai2020, choudhary2021}. Knowledge Graph Embeddings (KGEs) have emerged as a powerful, data-driven paradigm for EA, transforming the challenge of finding semantic correspondences between disparate knowledge structures into a problem of measuring vector space similarity \cite{yan2022, cao2022}. By representing entities and relations in low-dimensional, continuous vector spaces, KGEs can capture intricate semantic relationships that are difficult to discern from sparse symbolic representations alone.

Early applications of KGEs to EA often adapted foundational translational models, where entities from different KGs are projected into a shared embedding space, and alignment is determined by the proximity of their embeddings. However, a significant challenge for these embedding-based approaches is the inherent scarcity of labeled training data (i.e., pre-aligned entity pairs) \cite{sun2018}. To mitigate this, \cite{sun2018} proposed a **bootstrapping entity alignment** method. This approach iteratively labels likely entity alignments as training data, thereby expanding the initial seed set and refining the alignment-oriented KG embeddings. While effective in leveraging unlabeled data, a critical limitation of bootstrapping is the potential for error accumulation, where incorrectly labeled alignments in early iterations can propagate and degrade performance in subsequent steps, despite the inclusion of alignment editing methods \cite{sun2018}. This highlights a trade-off between leveraging more data and maintaining high precision in the iterative process.

Further addressing the data scarcity and robustness issues, **semi-supervised entity alignment** methods have gained prominence. \cite{pei2019} introduced a semi-supervised EA method (SEA) that not only utilizes both labeled and abundant unlabeled entity information but also incorporates an awareness of degree difference in entities. This is crucial because KGEs can be disproportionately affected by entities with vastly different degrees (number of connections), leading to less stable embeddings for low-degree entities or over-emphasized representations for high-degree ones. By performing adversarial training, SEA aims to make the embeddings more robust to these structural imbalances, thereby improving alignment accuracy, particularly for challenging cases involving entities with sparse connections. However, the effectiveness of such adversarial training can be sensitive to hyperparameter tuning and the specific characteristics of the KGs being aligned, potentially limiting its generalizability without careful adaptation.

To capture a more holistic view of entities and enhance alignment accuracy, **multi-view knowledge graph embedding** frameworks have been developed. \cite{zhang2019} proposed a novel framework that unifies multiple entity features, including entity names, relational structures, and attributes, to learn more robust embeddings for alignment. Traditional KGE-based EA often focused predominantly on relational structure, potentially overlooking rich semantic information embedded in entity names or descriptive attributes. By integrating these diverse views, the multi-view approach aims to overcome the limitations of single-view methods, which might suffer from data sparsity in one view or fail to capture complementary information. The challenge, however, lies in effectively combining these heterogeneous features, as different views may have varying levels of reliability or conflicting signals, requiring sophisticated combination strategies and cross-KG inference methods \cite{zhang2019}. The methodological limitation here is often the heuristic nature of combining these views, lacking a theoretically grounded optimal weighting.

Moving beyond structural and attribute information, approaches like \textbf{OntoEA} \cite{xiang2021} further integrate ontological information to guide entity alignment. Ontologies provide critical meta-information, such as class hierarchies and disjointness axioms, which can significantly enhance semantic consistency and prevent false mappings. By jointly embedding both KGs and their associated ontologies, OntoEA leverages these higher-level semantic constraints to achieve more accurate and logically sound alignments. This represents a significant step towards incorporating richer, human-defined knowledge into the embedding process, addressing a theoretical gap where purely data-driven KGEs might miss explicit logical relationships. However, the reliance on well-defined and consistent ontologies can be a practical constraint, as such resources are not universally available or perfectly aligned across all KGs, which limits its applicability in scenarios with less structured metadata.

Collectively, these methods demonstrate how KGEs provide a powerful, data-driven approach to integrate heterogeneous knowledge sources. The evolution from basic KGE adaptations to sophisticated bootstrapping, semi-supervised, multi-view, and ontology-guided frameworks reflects a continuous effort to address practical limitations like data scarcity and the need for richer semantic understanding \cite{zhu2024}. While KGEs offer significant advantages in scalability and efficiency over traditional symbolic methods, their generalizability across diverse KG characteristics (e.g., density, domain specificity, noise levels) remains an active area of research, as highlighted by experimental reviews \cite{fanourakis2022}. The trade-off often involves balancing the complexity of integrating multiple information sources with the computational cost and the availability of high-quality auxiliary data. Future directions in EA are likely to focus on more robust integration of diverse information, including temporal dynamics and multimodal data, and developing more sophisticated post-alignment modules to refine results and handle uncertainty \cite{zhu2024}.