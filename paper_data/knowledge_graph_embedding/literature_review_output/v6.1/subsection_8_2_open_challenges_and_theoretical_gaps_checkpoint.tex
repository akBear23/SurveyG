\subsection{Open Challenges and Theoretical Gaps}
Despite significant advancements in Knowledge Graph Embedding (KGE) research, several critical open challenges and theoretical gaps persist, representing fertile ground for future investigation. These issues often stem from inherent trade-offs between desirable model properties or the fundamental limitations of current methodologies.

One of the most enduring challenges is **balancing model expressiveness with computational complexity** \cite{zheng2024, li2024}. While sophisticated models, including those leveraging complex geometric spaces like hyperbolic embeddings \cite{liang2024, shang2024} or advanced deep learning architectures, offer superior expressiveness for capturing intricate relational patterns (e.g., composition, hierarchy), they often incur substantial computational costs for training and inference. For instance, models like HolmE \cite{zheng2024} and SpherE \cite{li2024} push the boundaries of expressiveness for compositional patterns and set retrieval, respectively, but their increased complexity can limit scalability. Efforts to mitigate this, such as knowledge distillation \cite{zhu2020}, embedding compression \cite{sachan2020, wang2021}, and parameter-efficient learning \cite{chen2023}, often come with a "minor loss in performance," as noted in analyses of efficiency-focused methods. While systems like GE2 \cite{zheng2024} and methods like Orthogonal Procrustes Analysis \cite{peng2021} offer impressive speedups, a universally efficient yet highly expressive KGE paradigm remains elusive, particularly for heterogeneous and dynamic graphs.

Another significant gap lies in **ensuring the interpretability of complex deep learning models**. As KGE increasingly adopts Graph Neural Networks (GNNs) and Transformer architectures, the "black box" nature of these models becomes a major concern, especially in high-stakes applications. While some works, such as Contextualized KGE for recommendation \cite{yang2023} and molecular-evaluated drug repurposing \cite{islam2023}, strive for explainability by identifying important paths or providing domain-specific validation, the explanations often remain at a high level or are specific to the model's internal mechanisms rather than intuitive for human users. Simpler geometric models might offer higher interpretability, but at the cost of expressiveness. The theoretical challenge is to design models that are both highly expressive and inherently interpretable, rather than relying on post-hoc explanation techniques.

The **efficient extraction and integration of high-quality rules** into KGE models also presents a persistent hurdle. Rule-based methods, such as RUGE \cite{guo2017} and RulE \cite{tang2022}, have demonstrated the value of injecting prior logical knowledge to enhance reasoning and consistency. However, the practical bottleneck lies in the automated discovery of high-quality, non-trivial rules from large, noisy KGs, and then effectively balancing adherence to these rules with the flexibility to capture exceptions. Current approaches often rely on separately extracted soft rules, whose quality can be uncertain, or on manually curated hard rules, which are scarce and labor-intensive. A theoretical framework for seamlessly and robustly learning and integrating rules directly from data, without extensive manual intervention or pre-processing, is still needed.

A fundamental theoretical issue revolves around **resolving problems related to the 'true' negative distribution in training**. Since knowledge graphs are inherently incomplete, the absence of a triple does not necessarily imply its falsehood. This makes negative sampling, a cornerstone of contrastive KGE training, a heuristic process. As highlighted by surveys \cite{qian2021, madushanka2024}, even sophisticated sampling methods like confidence-aware sampling \cite{shan2018} or caching strategies \cite{zhang2018} are approximations. While "Efficient Non-Sampling Knowledge Graph Embedding" \cite{li2021} attempts to circumvent sampling entirely, it introduces its own computational complexities. The theoretical gap lies in developing a robust training paradigm that does not rely on arbitrary negative sampling or can effectively model the uncertainty of missing facts, moving beyond the binary true/false assumption.

Furthermore, there is a pressing **need for more robust and unbiased evaluation metrics**. Existing benchmarks and evaluation protocols have been shown to suffer from reproducibility issues \cite{ali2020, broscheit2020}, biases due to entity over-representation \cite{rossi2020}, and vulnerabilities to data leakage \cite{lloyd2022}. The reliance on generic link prediction metrics often fails to capture the nuances of specific applications or the model's ability to generalize to different types of entities or relations. The development of domain-specific evaluation metrics, as demonstrated in drug repurposing \cite{islam2023}, points towards a future where evaluation is more tailored and verifiable, yet a generalized framework for such robust, context-aware evaluation is still nascent.

The **challenges of scalability for extremely large and dynamic knowledge graphs** remain paramount. While efforts in efficiency \cite{peng2021, zheng2024} and parallelization \cite{kochsiek2021, modak2024} have made strides, truly massive and continuously evolving KGs still pose significant hurdles. For dynamic KGE, balancing the efficiency of updates with the quality of embeddings for new knowledge and preventing catastrophic forgetting of old knowledge is a complex trade-off \cite{liu2024, sun2024}. The theoretical underpinnings for efficient, real-time updates and seamless integration of new information without compromising the integrity of the learned representation are still being developed.

Finally, the **development of truly generalizable inductive models** is a critical open challenge. Most KGE models are transductive, struggling to embed unseen entities without full retraining. While inductive approaches like neighborhood aggregation \cite{wang2018} and meta-learning \cite{chen2021} have emerged, they often rely on the presence of existing neighbors or transferable meta-knowledge. The ability to generalize to completely novel entities or subgraphs with minimal or no shared structural patterns remains a significant theoretical and practical barrier. Understanding *how* KGE models extrapolate to unseen data, as explored by \cite{li2021}, is a step in the right direction, but designing models that can robustly and universally achieve this inductive capability is a frontier of KGE research.