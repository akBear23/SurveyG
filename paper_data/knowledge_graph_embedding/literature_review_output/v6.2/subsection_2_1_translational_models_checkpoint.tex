\subsection*{Translational Models}
Translational models represent a foundational paradigm in knowledge graph embedding (KGE), interpreting relations as vector translations between entity embeddings in a continuous vector space. These models aim to capture the semantic relationships within a knowledge graph by ensuring that for a valid triple (head, relation, tail), the embedding of the head entity, when translated by the relation vector, approximates the embedding of the tail entity.

The journey into translational models began with TransE (Translating Embeddings) \cite{Bordes2013}, a pioneering model celebrated for its elegant simplicity and computational efficiency. TransE posits that for a factual triple $(h, r, t)$, the embedding of the head entity $\mathbf{h}$ plus the embedding of the relation $\mathbf{r}$ should be close to the embedding of the tail entity $\mathbf{t}$ (i.e., $\mathbf{h} + \mathbf{r} \approx \mathbf{t}$). While effective for many relations, TransE's core limitation stemmed from its assumption of a single, fixed vector representation for each entity, which struggled to adequately model complex relation types such as one-to-many, many-to-one, and many-to-many relations, where an entity might play different roles depending on the context.

To address TransE's shortcomings, particularly its difficulty with complex relation mapping properties, TransH (Translating on Hyperplanes) was introduced \cite{wang2014}. TransH innovatively projects entity embeddings onto relation-specific hyperplanes, allowing an entity to have distinct, distributed representations tailored to the specific relation it participates in. For a triple $(h, r, t)$, the head and tail entities are first projected onto a hyperplane defined by the relation's normal vector $\mathbf{w}_r$, and then a translation vector $\mathbf{d}_r$ (which lies within this hyperplane) is applied. This mechanism, coupled with an improved Bernoulli negative sampling strategy, significantly enhanced TransH's ability to model one-to-many, many-to-one, and many-to-many relations more accurately while maintaining computational efficiency comparable to TransE \cite{wang2014}.

Building upon the concept of relation-specific representations, subsequent models further refined the projection mechanism. TransR and CTransR (CTranslation) \cite{Lin2015} introduced the idea of mapping entities from their original entity space into distinct relation-specific spaces using relation-specific projection matrices. This allowed for even greater expressiveness, as entities could be represented differently not just on a hyperplane, but within an entirely separate vector space for each relation. However, the use of numerous relation-specific projection matrices could lead to a large number of parameters and increased computational cost. To mitigate this, TransD (Translation with Dynamic Mapping Matrix) \cite{Ji2015} proposed a more parameter-efficient approach by constructing dynamic mapping matrices for projections. These matrices are generated from the entity and relation vectors themselves, offering a flexible and adaptive way to project entities into relation-specific spaces without the heavy parameter load of fixed projection matrices.

A significant generalization within the geometric embedding paradigm is RotatE (Knowledge Graph Embedding by Relational Rotation in Complex Space) \cite{Sun2019}. While not strictly a "translation" in the Euclidean sense, RotatE extends the core idea of relations as transformations. It models relations as rotations from head to tail entities in a complex vector space, where entities and relations are represented by complex-valued embeddings. This rotational mechanism elegantly captures various relational patterns, including symmetric, antisymmetric, and compositional relations, offering a more powerful and unified framework for modeling diverse knowledge graph structures than purely translational approaches.

The evolution of translational models, from the foundational simplicity of TransE to the more sophisticated projections of TransH, TransR, CTransR, and TransD, and eventually to the rotational transformations of RotatE, showcases a continuous effort to enhance the expressiveness of KGE models. These models progressively addressed the limitations of fixed entity representations and the challenges of modeling complex relation types through increasingly nuanced geometric operations. While offering good interpretability and often reasonable efficiency, a common limitation across these models is their reliance on predefined geometric operations, which may not fully capture highly complex or implicit semantic patterns compared to more advanced, data-driven neural approaches that emerged later. Nevertheless, they established a critical baseline and intellectual trajectory for understanding and embedding relational data.