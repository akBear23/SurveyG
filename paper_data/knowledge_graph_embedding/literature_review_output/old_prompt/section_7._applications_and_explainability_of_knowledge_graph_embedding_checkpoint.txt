\section*{7. Applications and Explainability of Knowledge Graph Embedding}

Knowledge Graph Embedding (KGE) has transcended its foundational role in merely representing entities and relations in continuous vector spaces to become a pivotal technology underpinning a wide array of advanced Artificial Intelligence tasks. While link prediction and knowledge graph completion remain the primary evaluation benchmarks for KGE models, their true utility and impact are realized in complex downstream applications where structured knowledge can significantly enhance AI system performance. This section delves into the practical utility of KGE, showcasing its effectiveness in bridging the gap between symbolic knowledge and neural computation across diverse domains. From enabling intelligent question answering and seamless knowledge integration through entity alignment, to powering sophisticated recommendation systems and driving critical domain-specific discoveries, KGE has proven to be a versatile and powerful tool. Furthermore, as AI systems become more pervasive, the demand for transparency and interpretability has grown, leading to an increasing emphasis on developing explainable KGE models that can provide actionable insights and foster user trust. This evolution reflects a broader trend in AI research towards not just performance, but also utility, robustness, and transparency.

\subsection*{Core Tasks: Link Prediction and Knowledge Graph Completion}

Link prediction and knowledge graph completion (KGC) serve as the fundamental tasks for evaluating the efficacy of Knowledge Graph Embedding (KGE) models. These tasks are crucial for the continuous growth and refinement of knowledge graphs (KGs), addressing their inherent incompleteness by inferring missing facts \cite{rossi2020, dai2020, yan2022, ge2023}. In link prediction, the goal is to predict either the missing head entity ($?, r, t$), tail entity ($h, r, ?$), or relation ($h, ?, t$) within a triple. KGE models achieve this by learning low-dimensional vector representations for entities and relations such that a scoring function can accurately estimate the plausibility of a given triple. Models like TransE \cite{wang2014}, RotatE \cite{sun2018}, and ComplEx \cite{trouillon2016} (not cited in provided list, but a common baseline) represent entities and relations in different geometric spaces (e.g., Euclidean, complex, hyperbolic \cite{pan2021, liang2024, lu2024fsd}), each with specific inductive biases to capture different relational patterns.

Despite significant advancements, these core tasks present persistent challenges. A major limitation stems from the inherent sparsity and heterogeneity of real-world KGs, which can lead to poor generalization for entities and relations with limited observed triples. The complexity of relations, including one-to-many, many-to-one, and many-to-many mappings, also poses difficulties for simpler models. For instance, while RotatE \cite{sun2018} excels at modeling symmetric and antisymmetric relations by representing relations as rotations in complex space, it may struggle with highly diverse or hierarchical relation types without further augmentation. The quality of negative sampling, which generates "false" triples to train the model, is another critical factor. Naive negative sampling can lead to "easy" negatives, hindering effective learning, prompting the development of more sophisticated strategies like confidence-aware negative sampling for noisy KGs \cite{shan2018} or methods that consider entity types \cite{wang2021, he2023}. The choice of negative sampling strategy is crucial, as highlighted by recent reviews \cite{qian2021, madushanka2024}.

Furthermore, the static nature of many KGE models means they often fail to account for the temporal dynamics of facts, where the validity of a triple changes over time. This limitation, addressed by temporal KGEs (as discussed in Section 6), underscores the need for models that can capture not just static relationships but also their evolution. The experimental setups and choice of evaluation metrics (e.g., Mean Reciprocal Rank (MRR), Hits@K) also significantly affect generalizability. As \cite{lloyd2022} empirically demonstrated, hyperparameter sensitivities vary substantially between knowledge graphs, suggesting that optimal tuning strategies are dataset-specific and that a model performing well on one benchmark may not generalize to another without extensive re-tuning. This variability highlights a methodological limitation: the reliance on specific benchmarks may not fully reflect real-world performance or the robustness of a model across diverse KG characteristics. Ultimately, robust and accurate performance in these core tasks is a prerequisite for KGE's successful deployment in more complex, real-world applications.

\subsection*{KGE for Question Answering and Entity Alignment}

Beyond fundamental completion tasks, KGE has proven instrumental in powering more complex AI applications, particularly Question Answering (QA) over Knowledge Graphs and Entity Alignment. These applications leverage KGE's ability to capture semantic relationships in a continuous space, bridging the gap between natural language and structured knowledge, or between disparate knowledge sources.

For **Question Answering over Knowledge Graphs (KGQA)**, KGE models provide a powerful mechanism to interpret natural language queries and retrieve relevant information from KGs. Traditional KGQA systems often rely on complex semantic parsing or rule-based methods, which struggle with ambiguity and scalability. KGE-based approaches, however, embed both questions and KG components (entities, relations, paths) into a shared vector space, allowing for semantic matching. For instance, \cite{huang2019} explored KGE-based QA, demonstrating how embedding representations can facilitate direct matching between question semantics and KG facts. More recently, hybrid approaches combining KGE with large language models (LLMs) or BERT-like architectures have emerged. \cite{zhou2023} presented "Marie and BERT," a KGE-based QA system specifically for chemistry, showcasing how KGE can provide structured knowledge to enhance language models' understanding of domain-specific queries. Similarly, \cite{do2021mw0} developed a BERT-based triple classification model using KGE for QA systems. The strength of KGE in QA lies in its ability to handle semantic variations and provide a robust similarity measure. However, a critical limitation is its struggle with complex, multi-hop reasoning or questions requiring logical inference, which often necessitate augmenting KGE with symbolic reasoning components \cite{tang2022}. The semantic gap between the nuanced expressions in natural language and the rigid structure of KGs remains a challenge, often requiring sophisticated contextualization techniques \cite{wang2019}. Experimental setups for KGQA often rely on benchmark datasets that may not fully capture the diversity and complexity of real-world user queries, affecting generalizability.

**Entity Alignment (EA)** is another crucial application, vital for integrating heterogeneous KGs and building more comprehensive knowledge bases. Different KGs often describe the same real-world entities using different identifiers or schemas, leading to data silos. KGE facilitates EA by mapping entities from multiple KGs into a shared embedding space, where aligned entities are expected to have similar representations. \cite{sun2018} proposed a novel bootstrapping approach, BootEA, to address the challenge of limited prior alignment (labeled training data) in embedding-based EA. BootEA iteratively labels likely entity alignments and refines alignment-oriented KGEs, crucially employing a global optimal labeling strategy based on max-weighted matching and an alignment editing method to mitigate error accumulation. This approach significantly advances the state-of-the-art by making EA more robust in low-resource settings. Other works, such as \cite{zhang2019} and \cite{fanourakis2022}, also explore multi-view KGE and experimental reviews for EA. Ontology-guided EA, like OntoEA \cite{xiang2021}, further enhances alignment by incorporating ontological constraints. While KGE-based EA is powerful, its methodological limitations include sensitivity to the quality of initial embeddings and the challenge of handling highly heterogeneous KGs where structural similarities are minimal. The assumption of a shared embedding space might not hold perfectly for KGs with vastly different underlying schemas or data distributions. Furthermore, scalability for very large KGs remains a practical constraint, although solutions like large-scale EA via merging, partitioning, and embedding \cite{xin2022dam} are emerging. The "why" behind these limitations often stems from the inherent difficulty of reconciling diverse semantic contexts and structural biases present in independently constructed KGs, making perfect, unambiguous alignment a theoretically challenging problem.

\subsection*{Recommendation Systems and Domain-Specific Applications}

The ability of Knowledge Graph Embedding (KGE) to capture intricate relationships and rich semantic information has made it a transformative technology in **Recommendation Systems** and various **Domain-Specific Applications**.

In recommendation systems, KGE addresses critical challenges like data sparsity and cold-start problems by enriching user and item representations with structured knowledge from KGs. By embedding users, items, and their attributes (e.g., genre, director, brand) into a unified vector space, KGE models can infer latent preferences and relationships that are not explicitly present in interaction data. Early works, such as \cite{gradgyenge2017xdy} and \cite{sun2018}, demonstrated how recurrent KGE and graph embedding techniques could enhance recommendation accuracy. The field has since evolved to include more sophisticated approaches, such as hierarchical attentive KGE for personalized recommendations \cite{sha2019i3a, sha2019plw}, which can capture user preferences at different levels of abstraction. Cross-domain recommendation systems, which leverage knowledge from one domain to improve recommendations in another, also benefit significantly from KGE \cite{liu2023, huang2023grx}. KGE helps bridge semantic gaps between domains by finding common latent features. Furthermore, context-aware recommendation systems, which consider the dynamic context of user interactions, have integrated KGE to model temporal and situational factors \cite{mezni20218ml, mezni2021ezn}. The main trade-off in KGE-based recommendation is often between accuracy and interpretability, as complex embedding models can act as black boxes. Moreover, the quality and completeness of the underlying KG are paramount; a noisy or incomplete KG can propagate errors and lead to suboptimal recommendations. The dynamic nature of user preferences and item characteristics also presents a challenge, requiring continual learning or adaptive KGE models to maintain relevance.

Beyond general recommendations, KGE has found critical deployment in specialized, domain-specific applications:
\begin{itemize}
    \item \textbf{Healthcare and Drug Discovery:} KGE is a powerful tool for uncovering hidden relationships in biomedical knowledge. It has been successfully applied to drug repurposing \cite{sosa2019ih0, islam2023}, where it identifies new therapeutic uses for existing drugs by analyzing their interactions with diseases and targets. KGE also aids in predicting drug-drug interactions (DDIs) \cite{elebi20182bd, elebi2019bzc, su2023v6e, li2024gar, hao2022cl4}, which is crucial for patient safety. Other applications include predicting adverse drug reactions \cite{zhang2021wg7, li2024sgp}, identifying disease-gene associations \cite{wang2024c8z}, and even herb-target prediction \cite{duan2024d3f}. The "why" behind KGE's success here lies in its ability to process vast, heterogeneous biological data and infer non-obvious connections that traditional methods might miss. However, a significant practical constraint is the construction and curation of high-quality, comprehensive biomedical KGs, which is often labor-intensive and requires expert knowledge.
    \item \textbf{Industrial and Manufacturing:} KGE is increasingly used in Industry 4.0 scenarios. It supports defect diagnosis in additive manufacturing \cite{wang2023s70, dong2025l9k}, where KGs capture complex relationships between manufacturing processes, materials, and defects. KGE also facilitates manufacturing knowledge recommendation for collaborative design \cite{jing2024nxw} and enhances cognitive intelligent manufacturing by aggregating multi-hierarchical information \cite{li2021x10, liu2024tc2}.
    \item \textbf{Patent Analysis:} KGE can measure knowledge proximity between patents, aiding in technology landscape analysis and innovation management \cite{li2022}. By embedding patent metadata into a KG, researchers can identify related inventions and emerging technological trends.
    \item \textbf{Other Diverse Applications:} KGE has been applied to academic search engines for explicit semantic ranking \cite{xiong2017zqu, mai2018u0h}, financial news analysis for stock price prediction \cite{liu2018kvd}, urban flow pattern mining \cite{liu2021wqa}, ecotoxicological effect prediction \cite{myklebust201941l}, and even in the context of security knowledge graphs for relational reasoning \cite{liu2024mji} and mineral prospectivity mapping \cite{yan2024joa}.
\end{itemize}
The success of KGE in these diverse domains underscores its versatility. However, a common methodological limitation across these applications is the heavy reliance on the quality, completeness, and domain-specificity of the underlying KGs. Constructing and maintaining such KGs is often a significant practical constraint, and the generalizability of KGE models trained on one domain-specific KG to another can be limited due to different vocabularies and relational structures.

\subsection*{Towards Explainable Knowledge Graph Embedding}

As Knowledge Graph Embedding (KGE) models become increasingly integrated into critical AI applications, the demand for **explainability** has surged. Explainable AI (XAI) aims to make AI systems more transparent, understandable, and trustworthy, which is particularly vital for KGE-driven predictions in sensitive domains like healthcare or finance. The goal is to move beyond mere prediction accuracy to provide insights into *why* a particular prediction was made, *what* underlying knowledge contributed, and *how* the model arrived at its conclusion.

Early KGE models, especially simpler translational models like TransE, offered a degree of inherent interpretability due to their geometric intuition (e.g., $h + r \approx t$). However, as models grew in complexity (e.g., deep neural networks, graph attention networks), their black-box nature intensified, making direct interpretation challenging. This led to the development of methods specifically designed to enhance KGE explainability.

One prominent approach involves **path-based explanations**, where the model identifies and highlights relevant paths within the KG that support a prediction. For instance, \cite{jia201870f} and \cite{jia20207dd} explored path-specific KGE, where the semantic paths connecting entities are explicitly modeled and can be used to justify predictions. These methods provide local explanations by showing the chain of reasoning through the graph. Another direction leverages **attention mechanisms** within KGE models. Graph Attention Networks (GATs) in KGE, such as DisenKGAT \cite{wu2021}, can assign varying importance weights to different neighboring entities and relations during embedding aggregation. DisenKGAT, in particular, aims for disentangled entity representations, where different components capture distinct aspects of an entity. By analyzing which components and which neighbors are activated for a specific prediction, it offers insights into the contributing factors, thereby enhancing both accuracy and explainability. \cite{wang2020} also explored graph attenuated attention networks for KGE.

A powerful avenue for explainability is the **integration of KGE with symbolic rules**. Models like RulE \cite{tang2022} learn rule embeddings that can be combined with KGE for more transparent reasoning. Similarly, approaches that preserve soft logical regularity \cite{guo2017, guo2020, wang20199fe} aim to align numerical embeddings with symbolic rules, making the underlying logic more accessible. This hybrid approach attempts to combine the expressive power of embeddings with the interpretability of rules. For recommendation systems, Contextualized Knowledge Graph Embedding (CKGE) for explainable talent training course recommendation \cite{yang2023} introduces a local path mask prediction mechanism. This mechanism explicitly reveals the saliency of different meta-paths, providing direct, motivation-aware explanations for recommendations by highlighting *why* a course is recommended (e.g., "because you have skills X and Y, and this course enhances Z"). Other applications, such as inference reconciliation for robot actions \cite{daruna2022dmk}, also demonstrate the utility of explainable KGE in providing transparent decision-making.

Despite these advancements, significant challenges remain. There is an inherent trade-off between model expressiveness/accuracy and interpretability; more complex models often yield better performance but are harder to explain. The definition and quantification of "good" explanations are also subjective and context-dependent, making objective evaluation difficult. Current methods often provide local explanations for individual predictions but struggle to offer a global understanding of the entire model's behavior. The "why" behind these limitations often stems from the high-dimensional, non-linear nature of embedding spaces, which makes it difficult to map learned features back to human-understandable concepts. Future research directions include developing more robust metrics for explainability, exploring counterfactual explanations, and integrating KGE with Large Language Models (LLMs) to generate natural language explanations that are more intuitive for human users \cite{liu2024q3q, nie202499i}. The ultimate goal is to achieve user-centric explainability, where insights are not just technically sound but also actionable and relevant to the end-user's needs.