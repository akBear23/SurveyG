\subsection*{Link Prediction and Knowledge Graph Completion}

Link prediction, often synonymous with knowledge graph completion, stands as the most fundamental and widely studied application of knowledge graph embeddings (KGEs). Its primary objective is to infer missing facts or relationships between entities within an incomplete knowledge graph (KG), thereby enriching and maintaining the integrity of these crucial large-scale knowledge bases \cite{rossi2020}. The task is typically framed as predicting the missing head entity ($?$, $r$, $t$), tail entity ($h$, $r$, $?$), or even the relation ($h$, $?$, $t$) for a given triple. KGE models address this by learning low-dimensional vector representations (embeddings) for entities and relations, which are then used to compute a plausibility score for any given triple $(h, r, t)$. A higher score indicates a greater likelihood that the triple represents a true fact.

The general mechanism involves training KGE models to assign high scores to observed (true) triples and low scores to unobserved (false) triples. During inference, for a query such as $(h, r, ?)$, the model computes scores for all possible tail entities $t'$ (i.e., $(h, r, t')$) and ranks them. The entities with the highest scores are predicted as the most plausible missing links. This process is critical for various reasons: KGs are inherently incomplete, manually curating them is resource-intensive, and automated completion is essential for their continuous growth and utility in downstream AI applications.

The effectiveness of KGE models for link prediction is rigorously evaluated using a set of standard metrics. Key among these are Hits@k and Mean Reciprocal Rank (MRR). Hits@k measures the proportion of correct entities ranked within the top $k$ positions (e.g., Hits@1, Hits@3, Hits@10). A higher Hits@k value indicates that the model frequently ranks the correct answer among its top predictions. Mean Reciprocal Rank (MRR) calculates the average of the reciprocal ranks of the correct entities across all queries; it assigns a higher score if the correct entity is ranked higher. These metrics are typically reported in two settings: "raw" and "filtered" \cite{rossi2020}. The "raw" setting considers all candidate entities, including other true triples that might exist in the KG. The "filtered" setting, which is more commonly used and considered more indicative of a model's true predictive power, removes all other known true triples from the candidate list before ranking. This ensures that a model is not penalized for predicting another valid fact that happens to be different from the one in the test set. The comprehensive survey by \cite{rossi2020} provides a critical comparative analysis of 16 state-of-the-art KGE models, emphasizing the importance of these evaluation practices and how structural features of the training data influence predictive performance. Similarly, \cite{ferrari2022r82} conducted an extensive study comparing 13 models across six datasets, highlighting the high dependence between model performance and graph types, and advocating for fine-grained evaluation considering training times, memory, and carbon footprint.

Different KGE architectures contribute to inferring new facts by capturing distinct types of relational patterns. Foundational models, whether based on geometric transformations (e.g., translational models like TransE, TransH, TransD discussed in Section 2.1) or semantic matching (e.g., RESCAL, ComplEx discussed in Section 2.2 and 2.3), provide a scoring function that is used to rank all possible entities as potential completions for a given query. More advanced architectures, such as Graph Neural Networks (GNNs) and Transformers (Section 3.3), enhance link prediction by effectively capturing multi-hop structural context and neighborhood information, leading to more expressive and often inductive embeddings. Furthermore, the integration of temporal information (Section 4) allows models like HyTE \cite{dasgupta2018} to predict missing links while respecting the temporal validity of facts, adding a crucial dimension to knowledge graph completion.

The development of efficient and reproducible tools has also been instrumental in advancing link prediction research. Libraries like LibKGE \cite{broscheit2020} and TorchKGE \cite{boschin2020ki4} provide researchers with modular frameworks for training, hyperparameter optimization, and evaluation of KGE models specifically for link prediction. These platforms facilitate systematic experimentation, ensuring reproducibility and enabling deeper analysis of model components, which is vital for identifying robust solutions and pushing the boundaries of the field.

Despite significant progress, challenges in link prediction persist. Accurately predicting rare or long-tail relations, handling the open-world assumption (where unobserved facts are not necessarily false), and performing complex multi-hop reasoning remain active research areas. The computational cost of training and evaluating models on massive KGs is also a practical concern, necessitating scalable and efficient training paradigms (Section 5.2). Future research continues to explore more robust, generalizable, and efficient methods for link prediction, aiming to further enhance the completeness and utility of knowledge graphs across diverse domains.