\subsection*{Multi-Curvature and GNNs for Evolving KGs}

The inherent geometric complexity and intricate interactions within Temporal Knowledge Graphs (TKGs) pose significant challenges for traditional embedding methods. To address these limitations, recent advancements have explored sophisticated geometric spaces and Graph Neural Network (GNN) architectures, offering enhanced flexibility and expressiveness for dynamic knowledge representation. These cutting-edge approaches aim to capture the diverse underlying structures and complex temporal dependencies that characterize evolving KGs.

One prominent direction involves modeling TKGs in multi-curvature spaces, moving beyond the constraints of a single Euclidean space. \textcite{wang2024} introduced MADE (Multicurvature Adaptive Embedding), a novel model for Temporal Knowledge Graph Completion (TKGC) that embeds TKGs into a combination of Euclidean, hyperbolic, and hyperspherical spaces. MADE leverages a data-driven weighting mechanism to dynamically assign importance to each curvature space, allowing it to adaptively capture various geometric structures such as hierarchies, rings, and chains present in TKGs. It further incorporates a quadruplet distributor for information interaction and an innovative temporal regularization to ensure the smoothness of timestamp embeddings \cite{wang2024}.

Building upon this multi-curvature paradigm, \textcite{wang2024} further refined the approach with IME (Integrating Multi-curvature Shared and Specific Embedding). IME addresses the limitations of earlier multi-curvature methods, which often overlook the "spatial gap" and heterogeneity between different curvature spaces. It innovatively integrates both "space-shared" properties to capture commonalities across spaces and "space-specific" properties to model unique features of each curvature, effectively bridging inter-space semantic gaps. Furthermore, IME introduces an Adjustable Multi-curvature Pooling (AMP) mechanism that learns optimal pooling weights for superior information fusion and employs novel similarity, difference, and structure loss functions to guide the learning process, demonstrating superior performance in TKGC tasks \cite{wang2024}.

Complementary to these geometric embedding advancements, other research focuses on leveraging Graph Neural Networks (GNNs) to explicitly capture complex multi-fact interactions across different timestamps. \textcite{xie2023} proposed TARGAT (A Time-Aware Relational Graph Attention Model), which tackles the challenge of GNN-based models struggling to directly capture interactions among multiple facts occurring at varying timestamps. TARGAT treats multi-facts across different timestamps as a unified graph and introduces a dynamic time-aware relational generator that creates time-aware relational message transformation matrices. These matrices are then used for time-aware feature projection and aggregation, enabling the model to explicitly capture intricate multi-fact interactions and achieve state-of-the-art results on several benchmarks \cite{xie2023}.

In summary, both multi-curvature embedding models like MADE and IME, and GNN-based approaches such as TARGAT, represent significant strides in handling the complex temporal dependencies and geometric structures of evolving KGs. MADE and IME offer geometrically adaptive embeddings that can represent diverse structural patterns more accurately than single-space models, with IME further enhancing inter-space interaction and adaptive fusion. TARGAT, on the other hand, provides a robust GNN-centric framework for modeling dynamic, time-aware relational interactions. While these methods offer enhanced flexibility and expressiveness, they often introduce increased computational overhead due to multi-space embeddings or complex GNN architectures, and interpreting the precise contributions of different curvature spaces or attention mechanisms remains a challenge for future research.