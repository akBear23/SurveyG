\subsection{Hyperbolic Embeddings for Hierarchical Structures}

Knowledge graphs frequently exhibit intricate hierarchical or tree-like structures, which traditional Euclidean embedding spaces struggle to represent efficiently due to their inherent uniform curvature and limited capacity for exponential growth. Hyperbolic geometry, with its natural negative curvature and exponentially increasing volume, offers a compelling alternative for embedding such hierarchical data, allowing for more faithful and compact representations.

Early explorations into hyperbolic Knowledge Graph Embedding (KGE) models demonstrated their potential for capturing these complex hierarchies. \textcite{pan2021} introduced a novel KGE model that leverages an extended Poincaré Ball and a polar coordinate system within hyperbolic space. This approach specifically addressed the challenge of simultaneously modeling hierarchical structures and logical patterns by employing tangent space and exponential transformations for mapping vectors into the extended Poincaré Ball, along with a unique method for handling boundary conditions by expanding the modulus length. Their model achieved state-of-the-art results on certain link prediction tasks, showcasing the expressiveness of hyperbolic spaces for hierarchical knowledge. However, many initial hyperbolic KGE models, including those preceding \textcite{pan2021}, often relied on frequent and computationally intensive mappings between hyperbolic and tangent spaces during training. These "hybrid" approaches, while conceptually sound, introduced overhead and potential numerical instability due to the complex logarithmic and exponential functions involved.

Addressing these limitations, \textcite{liang2024} proposed the Fully Hyperbolic Rotation model (FHRE), which innovates by performing operations directly and entirely within hyperbolic space, specifically utilizing the Lorentz model. Unlike its predecessors, FHRE eliminates the need for iterative logarithmic and exponential mappings during training, instead performing a single mapping at initialization. In FHRE, relations are conceptualized as Lorentz rotations that transform head entity embeddings to tail entity embeddings, with triplet plausibility measured by a Lorentzian distance-based scoring function. This "fully hyperbolic" paradigm enhances both expressiveness and efficiency by fully leveraging the intrinsic properties of hyperbolic geometry, leading to improved stability and reduced computational burden. Experimental validation demonstrated that FHRE achieves state-of-the-art performance on challenging benchmarks, particularly those with diverse and complex relational patterns, by capturing fine-grained relational semantics more effectively than previous Euclidean, complex, and hybrid hyperbolic models.

The theoretical underpinnings of such geometric approaches are further explored in broader contexts. For instance, \textcite{zheng2024} introduced HolmE, a general Riemannian KGE framework that discusses the property of being "closed under composition" and leverages Riemannian geometry, including hyperbolic space, for efficient computation through extensions of Möbius addition. While HolmE provides a unifying perspective for models like TransE and RotatE, its direct application to the specific challenges of hierarchical representation in hyperbolic space is more about providing a theoretical umbrella rather than direct methodological innovation in hyperbolic geometry itself. Nonetheless, it underscores the growing recognition of non-Euclidean geometries in KGE.

In conclusion, hyperbolic embeddings have emerged as a powerful paradigm for representing hierarchical structures in knowledge graphs, offering a natural fit that Euclidean spaces lack. Models like \textcite{pan2021} and \textcite{liang2024} have progressively refined this approach, moving from hybrid mapping-based methods to fully hyperbolic operations, thereby enhancing expressiveness, efficiency, and stability. Despite these advancements, challenges remain in scaling these models to extremely large and dynamic knowledge graphs, integrating more diverse and complex relation types beyond simple hierarchies, and developing more interpretable hyperbolic operations. Future research could explore adaptive hyperbolic curvature, dynamic hyperbolic embeddings for evolving KGs, and novel ways to combine hyperbolic geometry with advanced neural architectures for even richer and more robust knowledge representation.