\subsection{Question Answering}

Intelligent Question Answering (QA) systems over knowledge graphs (KGs) represent a critical application area for Knowledge Graph Embeddings (KGEs), enabling users to query complex knowledge bases using natural language. The development in this field has progressed significantly, moving from foundational frameworks designed for simple questions to highly specialized and robust systems capable of handling intricate domain-specific queries, and more recently, integrating with large language models (LLMs). KGQA systems typically fall into two main paradigms: Information Retrieval (IR-QA) based methods, which retrieve relevant facts and then select an answer, and Semantic Parsing (SP-QA) based methods, which translate natural language questions into formal queries (e.g., SPARQL). KGEs play distinct, yet crucial, roles in both.

Early endeavors in KGE-based QA primarily focused on IR-QA, leveraging the semantic matching capabilities of embeddings. The Knowledge Embedding based Question Answering (KEQA) framework \cite{huang2019} exemplified this by addressing "simple questions" that require identifying a single head entity and a single predicate. KEQA's core innovation lay in its ability to jointly recover representations of the question's head entity, predicate, and potential tail entity within existing KG embedding spaces. By employing a joint distance metric, it identified the closest fact in the KG to derive an answer, demonstrating how pre-computed KGEs could bridge the lexical gap between natural language and structured knowledge. While effective for simple factoid queries, KEQA's reliance on direct triple matching limited its capacity for multi-hop reasoning or complex logical questions. Building on this, more recent IR-QA approaches continue to refine KGE-based selection. For instance, KGE-FEQ \cite{jafarzadeh202468v} (Knowledge Graph Embedding model for Factoid Entity Questions) introduces a two-step process for answering factoid entity questions. It first retrieves relevant triples from a textual knowledge graph based on semantic similarities to the question, and then employs a KGE approach for answer selection, positioning the answer entity's embedding close to the question entity's embedding, enriched by textual relations. KGE-FEQ demonstrates superior performance against state-of-the-art baselines, highlighting the continued relevance of KGEs for precise answer selection in factoid QA, particularly when leveraging textual context. However, these IR-QA methods often struggle with the combinatorial explosion of multi-hop paths and the nuanced interpretation of complex logical operators inherent in more sophisticated questions.

To address the limitations of simple factoid QA and enable more complex reasoning, KGEs have been integrated into SP-QA systems and advanced KGE models have been developed to capture richer relational semantics. A crucial development in enhancing KGEs for complex query answering is the concept of contextualized embeddings. For example, CoKE \cite{wang2019} (Contextualized Knowledge Graph Embedding) moved beyond static entity and relation representations by modeling them as a function of their specific graph context (e.g., edges, paths) using Transformer encoder blocks. This dynamic, context-aware approach significantly improved performance in tasks like "path query answering," which is fundamental to multi-hop QA. By capturing how an entity or relation's meaning shifts based on its surrounding graph structure, CoKE directly addresses the challenge of interpreting complex relational patterns in natural language queries, enabling more robust multi-hop reasoning than simpler, static KGEs.

The field has further progressed to highly specialized and robust KGQA systems, particularly in scientific domains. A prime example is the Marie and BERT system \cite{zhou2023} for chemistry. This system represents a substantial leap from answering simple questions to handling deep ontologies, numerical filtering, and intricate domain-specific mechanisms. Marie and BERT integrates a sophisticated architecture that leverages KGEs in multiple innovative ways: it employs **hybrid multi-embedding spaces**, querying diverse KGE models in parallel to capture a richer, more nuanced understanding of chemical entities and relations, exploiting the strengths of different embedding techniques for various knowledge types. A **BERT-based entity linking model** is incorporated to accurately identify and disambiguate chemical entities in natural language questions, a critical step for mapping linguistic input to KG entities. To address quantitative queries, **numerical embedding models** are utilized, enabling numerical filtering and answering questions involving specific values or ranges. Finally, the system integrates **semantic agents and semantic parsing** specifically tailored for chemical reactions, providing domain-specific intelligence to interpret complex chemical phenomena and navigate deep, intricate ontologies. While highly effective for its specialized domain, the complexity and domain-specific nature of Marie and BERT's semantic parsing components pose challenges for generalizability to other domains.

A major contemporary trend, addressing a key weakness of earlier KGE-based QA, is the synergy between KGEs and Large Language Models (LLMs). While LLMs excel at natural language understanding and generation, they often suffer from factual inaccuracies (hallucinations) and lack direct access to structured knowledge. KGEs provide a powerful mechanism to ground LLMs in factual knowledge, enhancing their accuracy and explainability. GETT-QA \cite{banerjee2023fdi} (Graph Embedding based T2T Transformer for Knowledge Graph Question Answering) exemplifies this integration. It uses T5, a text-to-text pre-trained language model, to generate a simpler form of SPARQL queries from natural language questions. Crucially, GETT-QA instructs T5 to produce a truncated version of the KG embedding for each entity and relation, enabling a finer search for disambiguation purposes during the grounding process. This integration allows the LLM to leverage its strong language understanding while KGEs provide the necessary precision for entity and relation mapping, significantly improving end-to-end KGQA performance on complex datasets like LC-QuAD 2.0 and SimpleQuestions-Wikidata. This approach highlights how KGEs can act as a "knowledge injection" mechanism, combining the strengths of symbolic (KGs) and sub-symbolic (LLMs, embeddings) AI to create more robust and factually grounded QA systems.

In conclusion, the trajectory of KGE-based QA systems demonstrates a clear progression from foundational IR-QA frameworks like KEQA \cite{huang2019} and KGE-FEQ \cite{jafarzadeh202468v}, which established the utility of KGEs for semantic matching, to sophisticated SP-QA systems like Marie and BERT \cite{zhou2023} that handle complex, domain-specific reasoning. The evolution is marked by advancements in KGE models themselves, such as contextualized embeddings in CoKE \cite{wang2019}, which enable more nuanced multi-hop reasoning. Most notably, the integration of KGEs with LLMs, as seen in GETT-QA \cite{banerjee2023fdi}, represents the current state-of-the-art, where KGEs provide critical factual grounding and disambiguation to mitigate LLM limitations. This continuous drive to enhance the capacity of KGEs to capture richer relational semantics, handle diverse contextual information, and integrate with advanced NLP techniques underscores their enduring power in developing intelligent and robust QA solutions for complex challenges. Future directions will likely involve further refinement of KGE-LLM synergy, improved explainability of answers, and broader applicability across an even wider array of specialized knowledge domains.