\subsection{Entity Alignment}
Entity Alignment (EA) is a fundamental task in knowledge graph (KG) integration, dedicated to identifying equivalent entities across disparate and often heterogeneous KGs. Knowledge Graph Embedding (KGE) methods have emerged as a powerful paradigm for EA, transforming entities and relations into continuous vector spaces where alignment can be performed by measuring embedding similarity. This approach offers a scalable and effective alternative to traditional symbolic matching techniques.

Early KGE-based EA approaches, while promising, often grappled with the scarcity of labeled training data, which could lead to suboptimal precision and the accumulation of errors. To mitigate this, \cite{sun2018} introduced BootEA, a semi-supervised bootstrapping framework. BootEA iteratively expands the training data by labeling highly confident entity alignments and incorporates an alignment editing mechanism to reduce error propagation. A key innovation was its limit-based objective function tailored for alignment-oriented KGE and a global optimal labeling strategy using max-weighted matching to ensure robust, one-to-one alignments. However, a critical limitation of bootstrapping is the inherent risk of propagating incorrect alignments, potentially leading to a "rich-get-richer" phenomenon where initial errors are amplified. Building on the semi-supervised paradigm, \cite{pei2019} further identified that disparities in entity degrees (frequency of participation in triples) could adversely affect EA performance. Their Semi-supervised Entity Alignment (SEA) method explicitly addresses this by integrating awareness of entity degree differences into KGE through adversarial training, thereby improving alignment consistency, particularly for less frequent entities.

A significant paradigm shift in KGE-based EA came with the advent of Graph Neural Networks (GNNs), which are inherently designed to leverage neighborhood information for learning structure-aware entity representations. Unlike earlier triple-based KGE models that primarily considered local structural patterns, GNNs aggregate information from an entity's multi-hop neighborhood, leading to richer and more contextualized embeddings. Foundational GNN-based models like GCN-Align \cite{wang2018cross} (not in provided papers, but foundational context) demonstrated the superior ability of graph convolutional networks to capture structural similarities, significantly outperforming previous methods. Subsequent advancements, such as RDGCN \cite{wu2019relation} (not in provided papers, but foundational context) and RREA \cite{mao2020rrea} (not in provided papers, but foundational context), further refined GNN architectures by incorporating relation-aware aggregation and attention mechanisms, enabling more nuanced capture of relational semantics. While GNNs offer enhanced expressiveness, their application to massive KGs introduces scalability challenges. To address this, \cite{xin2022dam} proposed a scalable GNN-based approach that combines KG merging, partitioning, and embedding. Their method introduces centrality-based subgraph generation to preserve landmark entities, employs self-supervised entity reconstruction to recover representations from incomplete subgraphs, and utilizes cross-subgraph negative sampling, ultimately merging subgraph embeddings for a unified alignment search. This highlights the continuous effort to balance the expressive power of GNNs with the practical demands of large-scale data.

Beyond structural information, the integration of diverse entity features and schema-level semantics has further enriched EA. Recognizing that previous methods often focused on only one or two feature types, \cite{zhang2019} proposed MultiKE, a framework that leverages diverse entity features—namely, name, relation, and attribute—into a unified embedding learning process. MultiKE employs view-specific embedding models (e.g., literal embedding for names, TransE for relations, CNN for attributes) and innovative cross-KG inference, including a "soft alignment" mechanism for relations and attributes that reduces dependency on pre-existing seed alignments. While powerful, the multi-view approach can incur higher computational costs due to managing multiple embedding spaces and their interactions. Further enriching the semantic context, \cite{xiang2021} introduced Ontology-guided Entity Alignment (OntoEA), addressing the critical, previously overlooked problem of "class conflicts" arising from the neglect of ontological schema (classes, hierarchies, and logical constraints). OntoEA integrates schema-level semantics by proposing a joint embedding framework for KGs and their associated ontologies. Its key innovations include a Class Conflict Matrix (CCM) to model inter-class conflicts (both explicit and implicit), a non-linear ontology embedding module, and a membership embedding module, effectively preventing logically inconsistent mappings. However, the effectiveness of OntoEA is inherently tied to the quality and completeness of the provided ontologies; incomplete or erroneous ontologies could degrade its performance.

The importance of leveraging diverse information sources and the effectiveness of various KGE and GNN methods for EA have been further validated through comprehensive empirical studies. \cite{fanourakis2022} provided a meta-level analysis, investigating the performance of relation-based versus attribute-based methods (including GNNs like RDGCN) under varying KG characteristics. Their findings revealed statistically significant correlations between method performance and KG meta-features (e.g., density, factual information richness), and identified interesting trade-offs between effectiveness and efficiency, suggesting that unsupervised or semi-supervised literal similarity methods can outperform supervised relation-based GNNs on sparse, fact-rich datasets. More recently, \cite{zhu2024} offered a comprehensive survey of embedding-based EA research, synthesizing the progression and emphasizing the crucial role of integrating global structural embedding with local semantic information. This survey highlights that representation learning-based EA methods significantly outperform traditional approaches and underscores the impact of alignment direction on performance.

Despite these advancements, several challenges persist in EA. Scalability to truly massive KGs remains a concern, particularly for GNN-based methods that involve extensive neighborhood aggregation, even with partitioning strategies \cite{xin2022dam}. The integration of truly heterogeneous data types, such as text, images, and temporal information, into a unified embedding space for robust multimodal EA is an active research area, as highlighted by \cite{zhu2024}. Furthermore, handling non-alignable entities, partial alignments (where only a subset of properties align), or the "dangling entity" problem (entities with no direct counterpart) requires more sophisticated mechanisms than simple similarity matching. Finally, providing explanations for alignment decisions, such as identifying the specific paths or attributes that support a predicted alignment, is crucial for building more trustworthy and interpretable KG integration systems, moving beyond black-box predictions.