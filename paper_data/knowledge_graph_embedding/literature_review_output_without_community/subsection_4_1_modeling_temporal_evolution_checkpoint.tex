\subsection*{Modeling Temporal Evolution}

The inherent dynamism of real-world knowledge necessitates knowledge graph embedding (KGE) models capable of capturing the temporal evolution of facts, entities, and relations. Moving beyond static representations, the field has progressed from explicitly incorporating discrete timestamps to modeling continuous evolution, uncertainty, and complex temporal patterns, culminating in sophisticated graph neural network (GNN)-based approaches.

Early approaches to temporal knowledge graph embedding (TKGE) primarily focused on explicitly integrating time into existing static KGE paradigms. A pioneering model, HyTE \cite{HyTE}, introduced hyperplane-based temporally aware embeddings. In HyTE, the validity of a fact at a given time is determined by whether its embedding lies on the correct side of a time-dependent hyperplane, effectively associating timestamps with these hyperplanes. This provided a foundational mechanism for capturing the time-dependent validity of individual facts. Building upon this translational framework, Hybrid-TE \cite{wang20198d2} further refined the approach by combining elements of TransD \cite{TransD} and HyTE. Hybrid-TE models both multi-relational facts and temporal information by building entity and relation embeddings in separate vector spaces, then explicitly learning time information via translational embedding on time-specific hyperplanes. Crucially, it projects a triplet to *all* time-specific hyperplanes on which it is temporally valid, enhancing its ability to handle diverse temporal scopes. Other early extensions of static models, such as TTransE \cite{TTransE} and TA-DistMult \cite{TA-DistMult}, similarly adapted translational and semantic matching models, respectively, to incorporate temporal information. While these models laid important groundwork for explicit temporal awareness, they often treated time as a discrete, deterministic variable, inherited limitations of their base models in capturing complex relation patterns, and struggled with continuous or uncertain temporal dynamics.

The need to model continuous evolution and the inherent uncertainty associated with temporal changes led to more sophisticated approaches. ATiSE \cite{ATiSE} advanced the field by conceptualizing entity and relation evolution not as discrete changes, but as multi-dimensional additive time series. A key innovation of ATiSE is its incorporation of Gaussian distributions to capture temporal uncertainty, specifically modeling the probability distribution of entity and relation embeddings over time. This allows for a more nuanced representation of how entities and relations change, enabling the model to not only predict future states but also to quantify the confidence in those predictions. However, ATiSE's additive time-series nature, while effective for continuous and uncertain dynamics, might be less expressive for highly non-linear, cyclical, or compositional temporal patterns, and its reliance on dense time series can be challenged by sparse temporal data.

Seeking alternative, more expressive geometric representations for continuous evolution, models like TeRo \cite{xu2020} emerged. Building directly upon the rotational paradigm for static graphs established by RotatE (see Section 2.3), TeRo introduced a novel approach by representing the temporal evolution of an entity embedding as an element-wise rotation from its initial, time-independent state to its current time-specific state within a complex vector space. This rotational approach, inspired by Euler's identity, offers a compact and interpretable way to model dynamic changes, where the phase and magnitude of rotation encode the temporal dynamics. TeRo is particularly adept at capturing complex relation patterns such as temporary, asymmetric, and reflexive relations, which often challenge simpler translational or additive models. Furthermore, TeRo robustly handles diverse time annotations, including time points and intervals, by employing a pair of dual complex relation embeddings ($r_b$ for beginning, $r_e$ for end) for facts with time intervals. This allows for flexible adaptation to various temporal granularities. ChronoR \cite{ChronoR} further refines this rotational embedding concept to specifically address the challenges of chronological order and duration of events, extending the framework to model start and end times more accurately. A distinct approach within complex/quaternion spaces is presented by TLT-KGE \cite{zhang2022muu}, which aims to embed semantic and temporal information as different axes of complex or quaternion space. This model explicitly separates semantic and temporal information while devising specific components to establish connections between them, offering a different perspective on integrating time into multi-dimensional embeddings compared to TeRo's direct temporal rotation. While these complex-space models offer enhanced expressiveness, their computational complexity can be higher, and parameter initialization becomes more critical.

Beyond triple-centric geometric transformations, a significant advancement in temporal KGE has been the adaptation of Graph Neural Network (GNN)-based architectures, which leverage neighborhood information and message passing to capture richer contextual and structural dynamics. TempCaps \cite{fu2022df2}, for instance, proposes a Capsule Network-based embedding model for temporal knowledge graph completion. It builds entity embeddings by dynamically routing retrieved temporal relation and neighbor information, leveraging the strengths of Capsule Networks to aggregate contextual information from the evolving graph structure. More recently, models like RE-GAT \cite{li2023y5q} (Recurrent Event Graph Attention Network) focus on future event prediction by modeling event knowledge graph sequences recurrently. RE-GAT employs attention-based modules for both historical and concurrent events, comprehensively considering latent patterns and influences. THOR \cite{lee2022hr9} (Three-tower grapH cOnvolution netwoRks) addresses the challenge of information sparsity in KG snapshots by proposing a self-supervised approach that jointly leverages temporal and atemporal dependencies between entities and structural dependencies between relations. A notable GNN-based innovation is TARGAT \cite{xie2023} (Time-Aware Relational Graph Attention Model). TARGAT specifically tackles the limitation of previous GNNs in directly capturing interactions of *multi-facts* occurring at *different timestamps*. It introduces a dynamic time-aware relational generator to unify the modeling of relations and timestamp information, projecting and aggregating neighborhood features in distinct time-aware spaces, and using a temporal Transformer classifier for prediction. GNN-based models offer superior capabilities in capturing multi-hop dependencies and broader graph context, but often entail higher computational costs and require robust mechanisms to handle the dynamic evolution of graph topology.

In summary, the evolution of temporal KGE models showcases a clear progression from explicit, discrete time integration in models like HyTE and Hybrid-TE, to continuous and probabilistic modeling with ATiSE, and further to expressive geometric transformations in complex spaces exemplified by TeRo, ChronoR, and TLT-KGE. The most recent frontier involves GNN-based approaches such as TempCaps, RE-GAT, THOR, and TARGAT, which leverage neighborhood aggregation and attention mechanisms to capture complex temporal and structural dependencies. While translational and rotational models excel at capturing specific relational patterns and temporal dynamics, GNNs offer a more holistic, context-aware view of the evolving graph.

Despite these advancements, significant challenges persist. Handling highly sparse temporal data, especially for long time horizons with irregular or missing observations, remains difficult; models relying on continuous time series (e.g., ATiSE) or dense neighborhood information (many GNNs) can struggle with interpolation or lack sufficient signal. Scalability for very large and rapidly changing KGs, particularly when dealing with high-frequency event streams in real-time, is another critical concern, as the computational overhead of complex rotations or extensive message passing in GNNs can be substantial. Furthermore, while some models address future event prediction (e.g., RE-GAT), robust long-range forecasting (extrapolation) remains a challenge for models primarily focused on interpolation. Developing adaptive temporal models that can learn varying rates of change, handle diverse temporal granularities (points, intervals, durations) without manual tuning, and integrate these dynamics with complex multi-hop reasoning tasks are crucial avenues for future research.