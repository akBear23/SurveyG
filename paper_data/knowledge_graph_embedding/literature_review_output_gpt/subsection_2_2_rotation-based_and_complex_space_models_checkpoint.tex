\subsection*{Rotation-based and Complex Space Models}

The challenge of capturing the rich and diverse relational semantics inherent in knowledge graphs, including patterns such as symmetry, antisymmetry, inversion, and composition, has led to the development of sophisticated embedding models that leverage geometric transformations in complex or higher-dimensional spaces. This paradigm offers an elegant and unified framework for modeling intricate relationships.

A pivotal innovation in this domain is RotatE \cite{sun2018}, which models relations as element-wise rotations from head entities to tail entities in a complex vector space. Specifically, for a triplet $(h, r, t)$, RotatE aims to satisfy $t_i \approx h_i \circ r_i$ for each dimension $i$, where $h_i, r_i, t_i$ are complex numbers and $r_i$ is constrained to have a modulus of 1. This elegant formulation inherently captures symmetric relations (when $r_i = \pm 1$), antisymmetric relations (when $r_i \neq \pm 1$), inversion (by $r_i^{-1}$), and compositional patterns ($r_1 \circ r_2$). RotatE employs a distance-based scoring function $||h \circ r - t||$ and introduces a self-adversarial negative sampling technique to enhance training efficiency and effectiveness, significantly outperforming prior models like TransE and ComplEx across various benchmarks.

Building upon the expressiveness of complex rotations, subsequent research extended this concept to temporal knowledge graphs (TKGs), which necessitate modeling the dynamic evolution of entities and relations over time. TeRo \cite{xu2020} was among the first to introduce a time-aware knowledge graph embedding via temporal rotation. It models the temporal evolution of entity embeddings as element-wise rotations from their initial, time-independent states to time-specific states in a complex vector space. For a quadruple $(s, r, o, t)$, TeRo derives time-specific entity embeddings $s_t = s \circ \phi_t$ and $o_t = o \circ \phi_t$, where $\phi_t$ is a complex vector representing the rotation for time $t$. This approach effectively handles diverse time annotations, including time intervals, by employing dual relation embeddings for the beginning and end of an interval, enabling it to capture temporary, asymmetric, and reflexive relations over time.

Further generalizing the rotation paradigm, ChronoR \cite{sadeghian2021} extends rotation to k-dimensions, proposing a novel inner product scoring function $g(h,r,t,\tau) := \langle Q_{r,\tau}(h), t \rangle$ where $Q_{r,\tau}$ is a k-dimensional rotation transformation parameterized by both relation $r$ and time $\tau$. This inner product formulation is theoretically shown to generalize scoring functions used in complex-domain models like ComplEx when $k=2$, offering a more robust measure in higher dimensions. ChronoR also incorporates advanced regularization techniques, including a tensor nuclear norm-inspired regularization and a 4-norm based temporal smoothness objective, to encourage consistent transformations for chronologically closer timestamps, thereby enhancing generalizability and capturing smooth temporal evolution. Its superior performance across temporal link prediction benchmarks demonstrates the power of high-dimensional rotation and sophisticated regularization for dynamic knowledge graphs.

The versatility of rotation-based models has also been explored in even more complex scenarios, integrating additional dimensions beyond time. FSTRE \cite{ji2024} introduces a fuzzy spatiotemporal RDF knowledge graph embedding model that leverages uncertain dynamic vector projection and rotation within a complex vector space. In FSTRE, spatial information is embedded using projection, while temporal information is captured through rotation. Fine-grained fuzziness is integrated into spatiotemporal five-tuples by utilizing the modal length of anisotropic vectors, allowing the model to effectively handle inherently uncertain and dynamic knowledge. This demonstrates how the core concept of geometric transformation, particularly rotation, can be adapted and combined with other operations to address multi-faceted challenges in knowledge representation.

The ongoing evolution of these models suggests a continuous push towards higher expressiveness and adaptability. Future work explores even higher-dimensional rotations, such as quaternion-based models, to capture more intricate semantic nuances like entity polysemy through contextualized embeddings, promising superior expressiveness for diverse relation types and complex semantic nuances. Despite their strengths in capturing complex patterns and temporal dynamics, challenges remain in scaling these models to extremely high dimensions without incurring significant computational overhead, and in enhancing the interpretability of the complex rotations and their interactions, especially when integrating multiple dimensions like fuzziness and spatial information.