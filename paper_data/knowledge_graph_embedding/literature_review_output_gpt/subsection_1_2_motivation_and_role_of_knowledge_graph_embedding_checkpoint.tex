\subsection*{Motivation and Role of Knowledge Graph Embedding}

Knowledge Graphs (KGs) represent factual information as symbolic triples (head entity, relation, tail entity), forming a structured repository of world knowledge. While powerful for explicit reasoning, these symbolic representations inherently suffer from several limitations that hinder their utility in large-scale, knowledge-intensive AI systems. The discrete and sparse nature of symbolic KGs makes them brittle, struggling with noisy or incomplete data, and computationally inefficient for complex inference tasks over vast networks \cite{Ji et al., 2016, Nickel et al., 2016}. Furthermore, symbolic representations lack the ability to inherently quantify semantic similarity between entities and relations, making generalization to unseen facts or entities challenging and integration with continuous-space machine learning models difficult \cite{Wang et al., 2021}.

To overcome these challenges, Knowledge Graph Embedding (KGE) emerged as a transformative paradigm, mapping discrete entities and relations into continuous, low-dimensional vector spaces. This process yields distributed representations that capture latent semantic information, enabling robust and scalable knowledge processing. Early foundational models, such as TransE \cite{Bordes et al., 2013}, demonstrated the power of representing relations as simple translations in an embedding space, allowing for the computation of semantic similarity and facilitating tasks like link prediction. Subsequent advancements, including TransH \cite{Wang et al., 2014} and TransR/CTransR \cite{Lin et al., 2015}, refined this translational approach by introducing relation-specific hyperplanes or projection matrices, addressing TransE's limitations in handling complex relation patterns like one-to-many or many-to-many.

Beyond translational models, semantic matching approaches like RESCAL \cite{Nickel et al., 2016} and ComplEx \cite{Trouillon et al., 2016} further highlighted the advantages of distributed representations. ComplEx, for instance, utilized complex-valued embeddings and a Hermitian dot product to elegantly capture symmetric and antisymmetric relations, demonstrating the expressiveness of algebraic operations in continuous spaces. The evolution continued with models like RotatE \cite{Sun et al., 2019}, which modeled relations as rotations in complex space, providing a unified framework for symmetric, antisymmetric, and compositional relation patterns. These continuous representations are crucial as they allow for gradient-based optimization, making KGE models amenable to integration with modern neural network architectures. For example, ConvE \cite{Dettmers et al., 2018} leveraged convolutional neural networks to learn rich, non-linear features from concatenated embeddings, significantly enhancing expressiveness and predictive power. More recently, KG-BERT \cite{Zhang et al., 2020} showcased the synergy between KGE and pre-trained language models, adapting BERT to score the validity of triples by integrating external textual knowledge, thereby bridging symbolic and linguistic representations.

The motivation for KGE becomes even more pronounced when dealing with dynamic, time-evolving knowledge graphs. Traditional static KGE models are inherently limited, as they cannot capture the temporal validity or evolution of facts. This led to the development of Temporal KGE (TKGE), which extends the benefits of distributed representations to the temporal domain. HyTE \cite{dasgupta2018} pioneered a geometric approach by associating each timestamp with a hyperplane, enabling temporally-guided inference and prediction of temporal scopes for facts. Building on this, ATiSE \cite{xu2019} innovated by modeling entity and relation evolution as additive time series with Gaussian distributions, explicitly accounting for temporal uncertaintyâ€”a crucial aspect that symbolic representations cannot capture. Further advancements in temporal modeling, such as TeRo \cite{xu2020} and ChronoR \cite{sadeghian2021}, leveraged rotations in complex or k-dimensional spaces to elegantly model temporal evolution, capturing diverse time-aware relation patterns and handling various time annotations. More recent works, like MADE \cite{wang2024} and IME \cite{wang2024}, address the complex geometric structures of temporal KGs by embedding them in multi-curvature spaces (Euclidean, hyperbolic, hyperspherical), demonstrating how KGE provides the flexibility to model intricate, evolving relationships. Similarly, TARGAT \cite{xie2023} introduced Graph Neural Networks (GNNs) with dynamic time-aware relational generators to explicitly capture multi-fact interactions across different timestamps, showcasing the enhanced reasoning capabilities offered by continuous representations. The ability of KGE to integrate fuzziness, spatial, and temporal dimensions, as demonstrated by FSTRE \cite{ji2024}, further underscores its role in representing uncertain and dynamic knowledge, which is beyond the scope of crisp symbolic systems.

Ultimately, KGE acts as a critical bridge, transforming discrete symbolic knowledge into a continuous, machine-readable format that enables scalability, generalization, and enhanced reasoning capabilities for knowledge-intensive AI systems. It facilitates tasks such as link prediction, entity alignment, question answering, and semantic search \cite{xiong2017zqu}. The integration of KGE with Large Language Models (LLMs) for tasks like fault diagnosis in complex industrial settings, as shown by \cite{liu2024q3q}, exemplifies this bridging role, where graph-structured knowledge is embedded to provide context-aware reasoning and overcome the limitations of purely text-based models. Despite significant progress, challenges remain in areas such as explainability of complex embedding models, handling extreme dynamism, and integrating multi-modal information, pointing towards continued research in developing more robust and interpretable KGE techniques.