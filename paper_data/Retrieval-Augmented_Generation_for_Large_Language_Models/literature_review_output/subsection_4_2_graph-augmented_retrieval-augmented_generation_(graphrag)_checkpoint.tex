\subsection{Graph-Augmented Retrieval-Augmented Generation (GraphRAG)}

Large Language Models (LLMs) often struggle with factual accuracy, outdated knowledge, and complex, multi-hop reasoning, leading to issues like hallucination \cite{gao20238ea}. While Retrieval-Augmented Generation (RAG) offers a powerful paradigm to ground LLMs with external knowledge \cite{lewis2020pwr}, traditional RAG systems primarily rely on semantic similarity over unstructured text chunks, often failing to capture the explicit structural and relational information critical for intricate queries \cite{peng2024mp3}. Graph-Augmented RAG (GraphRAG) emerges as a specialized solution, integrating structured knowledge, particularly Knowledge Graphs (KGs) or textual graphs, to enhance reasoning, factual accuracy, and context awareness by leveraging explicit relational information \cite{procko202417i, zhang2025gnc}.

Early GraphRAG research began to address the limitations of conventional RAG when confronted with complex, structured data. A pioneering effort is \cite{he20248lp}'s \textbf{G-Retriever}, which introduces the first RAG approach specifically designed for *general textual graphs*. G-Retriever tackles the challenges of hallucination and scalability inherent in processing complex graph structures by formulating subgraph retrieval as a Prize-Collecting Steiner Tree (PCST) optimization problem, enabling the precise extraction of contextually and structurally relevant graph portions. Building on this, \cite{xu202412d} demonstrates the practical benefits of integrating KGs for customer service question answering. Their approach constructs a novel dual-level KG that preserves both intra-issue structure and inter-issue relations from support tickets, employing an LLM-driven mechanism to translate natural language queries into graph database languages (e.g., Cypher) for highly precise subgraph retrieval. This significantly improved Mean Reciprocal Rank by 77.6\% and reduced issue resolution time by 28.6\% in a real-world deployment.

Further advancements in graph-aware retrieval and integration techniques have refined how LLMs interact with structured knowledge. \cite{hu2024eyw}'s \textbf{GRAG} extends RAG for *networked documents* by integrating joint textual and topological information. GRAG employs a divide-and-conquer strategy with soft pruning for efficient textual subgraph retrieval and a dual-view prompting mechanism that converts subgraphs into hierarchical text descriptions (hard prompts) and uses relevance-guided Graph Neural Networks (GNNs) for soft prompts. Complementing this, \cite{mavromatis2024ml9}'s \textbf{GNN-RAG} repurposes GNNs as powerful "dense subgraph reasoners" for precise retrieval of multi-hop answer candidates and their reasoning paths from KGs. These verbalized paths are then fed to an LLM, achieving state-of-the-art performance on KGQA benchmarks like WebQSP and CWQ with smaller LLMs, often outperforming larger models like GPT-4. Emphasizing efficiency, \cite{li2024hb4}'s \textbf{SubgraphRAG} proposes a lightweight MLP with Directional Distance Encoding (DDE) for scalable subgraph extraction, formulating retrieval as a triple factorization problem. This "simple is effective" approach allows unfine-tuned LLMs to achieve competitive accuracy on multi-hop KGQA tasks while significantly reducing hallucinations and improving explainability.

The field has also seen the emergence of sophisticated hybrid approaches and iterative reasoning paradigms. \cite{sarmah20245f3}'s \textbf{HybridRAG} combines the strengths of traditional VectorRAG and GraphRAG to overcome their individual limitations, particularly for complex, domain-specific texts like financial earnings call transcripts. This hybrid model leverages a two-tiered LLM chain for robust KG construction and amalgamates context from both retrieval mechanisms, demonstrating superior performance in information extraction. Taking iterative reasoning a step further, \cite{ma2024pwd}'s \textbf{Think-on-Graph 2.0 (ToG-2)} introduces a *tight-coupling* iterative exploration between KGs and unstructured text. ToG-2 alternates between knowledge-guided graph search and context retrieval, using LLMs for dynamic relation and entity pruning, enabling deeper and more faithful multi-step reasoning trajectories. Furthermore, \cite{gutierrez2024al5}'s \textbf{HippoRAG} offers a neurobiologically inspired framework for efficient *single-step multi-hop reasoning*. By extracting a schemaless KG and applying Personalized PageRank (PPR), HippoRAG achieves significant speed and cost advantages over iterative methods while outperforming single-step baselines on challenging multi-hop QA benchmarks.

In conclusion, GraphRAG represents a critical evolution in RAG, moving beyond semantic similarity to explicitly leverage the rich structural and relational information within knowledge graphs and textual graphs. These approaches significantly enhance LLM reasoning capabilities, improve factual accuracy, and mitigate hallucination, especially for complex, multi-hop queries. However, challenges remain in the automated construction and dynamic updating of high-quality knowledge graphs, optimizing the efficiency of subgraph extraction from massive graphs, and effectively balancing the depth of graph-based reasoning with the computational overhead it introduces \cite{zhang2025gnc}. Future research will likely focus on more adaptive and autonomous graph construction, real-time graph updates, and the seamless integration of diverse graph-aware retrieval and reasoning modules within increasingly intelligent RAG architectures.