\subsection{Multi-stage and Modular RAG Frameworks}

The foundational paradigm of Retrieval-Augmented Generation (RAG) typically operates on a straightforward "retrieve-then-generate" sequence \cite{lewis2020pwr}. However, as Large Language Models (LLMs) are increasingly tasked with complex, multi-faceted queries and dynamic information needs, this simple pipeline proves insufficient \cite{huang2024a59, zhao2024931}. This has spurred the evolution of RAG into more sophisticated, multi-stage, and modular architectures, where the LLM transcends a passive role to become an intelligent agent capable of proactive planning, dynamic decision-making, and the orchestration of various sub-tasks \cite{gao20238ea}. This section focuses on frameworks that empower LLMs to actively manage the information-seeking process through iterative planning, query decomposition, and the dynamic assembly of specialized modules. It is crucial to distinguish these proactive, agentic approaches from reactive or corrective mechanisms (e.g., self-correction, re-ranking) that primarily refine retrieval quality, which are discussed in detail in Section 3.

A significant advancement in modular RAG involves empowering LLMs to act as sophisticated planning agents, iteratively refining their information-seeking process and orchestrating multi-round interactions. \cite{lee2024hif} introduced PlanRAG, which extends the popular ReAct framework by incorporating explicit "Plan" and "Re-plan" steps. This allows LLMs to dynamically generate and iteratively refine analytical approaches based on intermediate retrieval results, effectively acting as decision-makers for complex data analysis tasks. Similarly, \cite{yang20243nb} presented IM-RAG, a multi-round RAG system that leverages learned inner monologues and a multi-agent reinforcement learning approach. In IM-RAG, an LLM-based "Reasoner" dynamically switches between a "Questioner" role (crafting queries) and an "Answerer" role, guided by mid-step rewards from a "Progress Tracker," leading to flexible and interpretable multi-round information gathering. Building on the concept of autonomous interaction, \cite{yu2024c32}'s Auto-RAG enables LLMs to engage in multi-turn dialogues with the retriever, systematically planning retrievals and refining queries until sufficient external information is gathered. This framework highlights the LLM's powerful decision-making capabilities, autonomously adjusting iterations based on query difficulty and knowledge utility. Another approach, \cite{wang2024zt3}'s M-RAG, proposes a multi-partition paradigm for external memories, employing a multi-agent reinforcement learning framework with an "Agent-S" for dynamic partition selection and an "Agent-R" for memory refinement. This enables more fine-grained and focused retrieval by orchestrating memory access across different knowledge partitions. To further optimize the interaction between these modular components, \cite{li20243nz}'s RAG-DDR (Differentiable Data Rewards) offers an end-to-end training method that aligns data preferences between different RAG modules (agents). By collecting rewards and evaluating the impact of perturbations on the entire system, RAG-DDR optimizes agents to produce outputs that enhance overall RAG performance, particularly for smaller LLMs. These agentic frameworks collectively transform RAG into a dynamic, adaptive system capable of tackling complex, multi-hop queries that require sophisticated reasoning and iterative information synthesis.

Beyond specific agentic planning algorithms, other modular architectures focus on meta-frameworks and system-level optimizations for orchestrating and deploying complex RAG pipelines. Given the proliferation of RAG modules and techniques, \cite{kim2024t1i}'s AutoRAG proposes an automated framework to identify optimal combinations of RAG modules for specific datasets. This meta-level modularity simplifies the complex task of RAG pipeline optimization, making it more accessible and efficient for researchers and practitioners. \cite{jin2024yhb}'s FlashRAG provides a comprehensive, modular toolkit specifically designed for efficient RAG research. It supports various complex RAG process flows, including sequential, branching, conditional, and loop-based pipelines, by offering fine-grained modularity at both component and pipeline levels. This enables researchers to easily swap, combine, and customize RAG workflows, accelerating the development and benchmarking of novel multi-stage RAG architectures. In a different vein, \cite{salemi2024bb6}'s uRAG introduces a unified retrieval engine designed to serve multiple downstream RAG systems, each with unique purposes like question answering or fact verification. This framework exemplifies modularity at a broader system level, standardizing communication and enabling a shared retrieval infrastructure, akin to a "search engine for machines" \cite{salemi2024bb6}. Similarly, \cite{pradeep2024n91}'s Ragnar√∂k provides a reusable RAG framework and baselines for evaluating RAG systems, contributing to the standardization and systematic assessment of these increasingly complex architectures.

It is also worth noting that Graph-Augmented RAG (GraphRAG), discussed in detail in Section 4.2, inherently represents a multi-stage and modular paradigm, necessitating specialized processing for structured knowledge before integration with LLMs.

In conclusion, the evolution towards multi-stage and modular RAG frameworks marks a significant advancement, transforming RAG from a simple pipeline into an intelligent, adaptive system. By enabling LLMs to engage in iterative refinement, agentic planning, and dynamic orchestration of sub-tasks, these architectures enhance robustness, reduce hallucinations, and improve the depth and faithfulness of generated responses, particularly for complex, multi-hop queries \cite{tang2024i5r}. However, this sophistication often introduces challenges related to increased computational overhead, the complexity of orchestrating multiple modules, and the need for robust evaluation methodologies that can accurately assess the contributions of each stage and the overall system performance. Benchmarks like \cite{friel20241ct}'s RAGBench, \cite{krishna2024qsh}'s FRAMES, and \cite{tang2024i5r}'s MultiHop-RAG highlight these challenges, emphasizing the need for explainable metrics and unified frameworks to evaluate the intricate interplay of retrieval, reasoning, and generation in these advanced systems. Future research will likely focus on optimizing the efficiency of these multi-stage processes, developing more autonomous and self-correcting agents, and creating more generalized frameworks that can seamlessly integrate diverse knowledge sources and reasoning paradigms while addressing the inherent trade-offs between complexity and efficiency.