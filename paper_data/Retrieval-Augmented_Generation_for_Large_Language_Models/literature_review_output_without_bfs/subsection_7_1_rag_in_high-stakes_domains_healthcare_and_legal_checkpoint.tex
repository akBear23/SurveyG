\subsection*{RAG in High-Stakes Domains: Healthcare and Legal}

In domains where factual accuracy, reliability, and precision are paramount, such as healthcare and legal, Retrieval-Augmented Generation (RAG) offers a critical solution to mitigate the inherent limitations of Large Language Models (LLMs), particularly their propensity for hallucination and reliance on outdated knowledge. The application of RAG in these high-stakes environments is driven by the need to optimize the interpretation of complex guidelines, enhance reasoning for critical decision-making, and improve sensitive customer or patient interactions, where errors can have severe consequences.

The foundational value of RAG in medicine is underscored by systematic evaluations. The \textit{MIRAGE} benchmark, introduced by \cite{xiong2024exb}, provides the first comprehensive assessment of RAG systems in medicine, demonstrating an accuracy improvement of up to 18\% for LLMs and enabling smaller models like GPT-3.5 and Mixtral to achieve performance comparable to unaugmented GPT-4. This work also identified challenges such as the "lost-in-the-middle" phenomenon, where LLMs struggle to utilize relevant information if it is not optimally positioned within the context. Complementing this, a systematic review and meta-analysis by \cite{liu2025p6t} further validates RAG's overall positive impact in biomedicine, reporting a 1.35 odds ratio increase in performance compared to baseline LLMs. Similarly, \cite{bora20242mq} highlights RAG's crucial role in enhancing the performance of LLMs for medical chatbot applications, particularly in resource-constrained environments.

To achieve the high accuracy and reliability demanded by clinical settings, researchers have focused on meticulous data preparation, domain-specific fine-tuning, and advanced architectural designs. \cite{kresevic2024uel} demonstrated the critical importance of converting complex, non-textual clinical guideline elements (e.g., tables from images) into structured text and employing advanced prompt engineering, achieving a remarkable 99\% accuracy in interpreting hepatological guidelines with GPT-4 Turbo. This highlights that data quality and presentation are often more impactful than few-shot learning. Building on this, \cite{ke20248bm} developed an optimized RAG pipeline for preoperative medicine, where GPT-4-RAG achieved 91.4\% accuracy, non-inferior to human experts, while significantly reducing response time. \cite{ke2025wm0} extended this by evaluating RAG's generalizability across ten different LLMs for medical fitness assessments, showing that top-performing RAG-augmented models (e.g., GPT-4) achieved superior accuracy (96.4\%) and consistency compared to human evaluators, with a near-absence of hallucinations. Further enhancing retrieval, \cite{lee20240to} introduced a dual RAG system for diabetes guidelines, optimizing both dense and sparse retrievers across Korean and English languages, demonstrating effective cross-regional capability. In radiology, \cite{weinert2025cxo} developed a radiology-specific RAG system using a vector database of 3,689 articles, significantly improving examination scores for GPT-4 (81.2\% vs. 75.5\%) and Command R+ (70.3\% vs. 62.0\%), showcasing the power of domain-specific corpus creation and retrieval for specialized medical knowledge tasks.

Advanced RAG architectures are also crucial for robust medical reasoning. \cite{jeong2024cey} proposed \textit{Self-BioRAG}, which enhances medical reasoning through domain-specific instruction sets, a specialized retriever, and a critic LM for self-reflection, showing significant improvements in multi-choice and long-form medical QA. This addresses the limitations of general Self-RAG in specialized contexts. Integrating structured knowledge, \cite{soman2023m86} developed a Knowledge Graph-based RAG (KG-RAG) framework for biomedicine, leveraging the SPOKE KG to generate token-optimized and robust responses, achieving over 50\% reduction in token consumption and significantly improving accuracy and robustness to prompt perturbations compared to traditional Cypher-RAG. Similarly, \cite{liu2025rz6} utilized a knowledge graph-based RAG with global search to detect emergencies in patient portal messages, achieving an accuracy of 0.99, showcasing the power of structured knowledge for critical triage. \cite{hammane2024hdb} further explored self-evaluation in RAG for medical reasoning, leveraging real-time clinical records to generate precise and informed responses. While not exclusively medical, the \textit{G-Retriever} by \cite{he20248lp}, which formulates subgraph retrieval as a Prize-Collecting Steiner Tree problem for textual graphs, offers a promising approach for handling complex, interconnected medical records by mitigating hallucination and improving scalability. Similarly, \cite{bechard2024834}'s work on reducing hallucination in structured outputs (e.g., JSON workflows) via a fine-tuned retriever is highly relevant for generating structured reports or interpreting structured data from Electronic Health Records (EHRs).

RAG's practical value extends to various clinical and patient-facing applications. For **clinical decision support and administrative automation**, \cite{unlu2024yc8} introduced \textit{RECTIFIER}, a RAG-enabled GPT-4 system for clinical trial screening from unstructured EHR notes, which outperformed human study staff in accuracy and efficiency, streamlining a labor-intensive process. \cite{tozuka2024nau} demonstrated that a RAG-LLM (NotebookLM) successfully performed lung cancer staging with 86\% diagnostic accuracy, outperforming GPT-4o and providing highly accurate reference locations. In **patient interaction and education**, \cite{ge20237yq} developed \textit{LiVersa}, a liver disease-specific, PHI-compliant RAG chatbot, further refined and evaluated by \cite{ge20246t5}, demonstrating a proof-of-concept for secure LLM deployment in healthcare. Addressing language-specific needs, \cite{zhou20249ba} created \textit{GastroBot}, a Chinese gastrointestinal disease chatbot that utilized a fine-tuned embedding model and a specialized knowledge base, achieving high context recall (95\%) and faithfulness (93.73\%). \cite{xu2024w5j} showed that a RAG-GPT system for breast cancer nursing care significantly improved response accuracy and overall patient satisfaction over direct GPT-4, without compromising empathy. In **public health and emergency settings**, \cite{ghadban2023j9e} applied RAG to build \textit{SMARThealth GPT} for frontline health worker education in low- and middle-income countries, emphasizing traceability, scalability, and adaptability to local guidelines. \cite{yazaki20245js} found that RAG-enhanced LLMs significantly improved emergency patient triage accuracy (70\% correct rate) compared to human EMTs and physicians, while substantially reducing under-triage rates.

The principles of RAG's success in healthcare translate directly to the **legal domain**, where the need for factual accuracy, precise citation, and the interpretation of complex, often lengthy, documents is equally critical. Legal texts are characterized by their specialized jargon, intricate logical structures, and the severe consequences of misinterpretation or hallucination. \cite{yang20248km} introduced \textit{CaseGPT}, a framework leveraging LLMs and RAG for case-based reasoning in both healthcare and legal sectors. In the legal context, CaseGPT enables fuzzy searches based on imprecise descriptions, improving the searchability of legal precedents and generating insightful recommendations for case strategy formulation, demonstrating RAG's ability to enhance legal research and decision-making.

A significant challenge in legal RAG is the precise retrieval of relevant information, which is paramount for accurate citation and avoiding context window overflow. \cite{pipitone2024sfx} addressed this by introducing \textit{LegalBench-RAG}, the first dedicated benchmark for evaluating the *retrieval component* of RAG systems in the legal domain. Unlike previous benchmarks like LegalBench, which focused on LLM generation given pre-selected context, LegalBench-RAG emphasizes extracting *minimal, highly relevant text snippets* (character-level spans) from legal documents. This meticulous approach, derived by tracing back contexts to original sources, directly tackles issues of LLM hallucination due to irrelevant information and the inability to generate precise citations. The benchmark, comprising 6,858 human-annotated query-answer pairs over 79 million characters, provides a robust framework for developing RAG systems that can handle the granular precision required in legal practice.

Despite these advancements across both domains, critical considerations remain for RAG deployment in high-stakes environments. A significant concern is **privacy**, as highlighted by \cite{zeng2024dzl}, who revealed that RAG systems are vulnerable to leakage of sensitive data from their external retrieval databases through targeted prompting attacks. This necessitates robust privacy-preserving designs, especially when handling Protected Health Information (PHI) in medicine or confidential client information in law. Both domains also share challenges in constructing and maintaining high-quality, unbiased datasets for comprehensive benchmarking, and the need for continuous knowledge updates to keep pace with evolving guidelines, laws, and medical research.

In conclusion, RAG has demonstrated transformative potential in both healthcare and legal domains, moving beyond theoretical promise to deliver tangible improvements in accuracy, efficiency, and reliability across diverse applications. From optimizing clinical guideline interpretation and patient triage to enhancing legal research and case reasoning, RAG's ability to ground LLM responses in verifiable, up-to-date knowledge is invaluable. However, the journey towards widespread, safe, and ethical deployment requires continued research into robust evaluation metrics that capture domain-specific nuances, advanced privacy-preserving RAG architectures, and seamless integration with existing professional workflows, particularly for handling multimodal data and ensuring continuous knowledge updates while mitigating risks like the "lost-in-the-middle" phenomenon.