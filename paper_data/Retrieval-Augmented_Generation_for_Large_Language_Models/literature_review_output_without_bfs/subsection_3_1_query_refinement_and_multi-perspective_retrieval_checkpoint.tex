\subsection{Query Refinement and Multi-Perspective Retrieval}

The initial effectiveness of Retrieval-Augmented Generation (RAG) systems \cite{lewis2020pwr} is frequently constrained by the quality of the user's input query. Ambiguous, underspecified, or inherently complex questions, such as those requiring multi-hop reasoning, often lead to the retrieval of irrelevant or insufficient context, thereby degrading the quality of the LLM's generated response \cite{tang2024i5r, huang2024a59}. This "query-context mismatch" is a critical bottleneck, as the retriever's performance is directly tied to how well the query expresses the underlying information need \cite{wu2024bpc}. Addressing this fundamental challenge, a significant body of research, categorized under "pre-retrieval" techniques by surveys like \cite{huang2024a59}, has emerged focusing on enhancing the query itself prior to retrieval, ensuring more precise and comprehensive information acquisition.

### Multi-Perspective Query Generation

One prominent strategy to overcome underspecified queries is to generate multiple query perspectives. This approach aims to broaden the search space and increase retrieval recall by exploring diverse semantic angles of the user's intent. A widely popularized technique in this category is RAG-Fusion \cite{rag-fusion-2023}. RAG-Fusion leverages the generative capabilities of LLMs to create several rephrased or expanded versions of the original query. For instance, a query like "What is RAG?" might be expanded into "Retrieval-Augmented Generation definition," "How does RAG work?", and "Benefits of RAG." These multiple perspectives are then used to perform parallel retrievals from the knowledge base. The results from these individual retrievals are subsequently combined, often using rank fusion algorithms such as Reciprocal Rank Fusion (RRF), to produce a consolidated, broader, and potentially more relevant set of documents. While effective in boosting recall by mitigating the risk of a single, poorly formulated query, this method inherently incurs higher computational costs due to multiple parallel retrieval calls and the overhead of rank fusion. Furthermore, the quality of the generated perspectives heavily depends on the LLM's ability to accurately infer the user's multifaceted intent.

Building on the idea of capturing diverse facets, RichRAG \cite{wang20245w8} introduces a "sub-aspect explorer" specifically designed for broad, open-ended queries that require comprehensive, long-form answers. Instead of simply rephrasing, the sub-aspect explorer identifies potential sub-intents or key aspects within a complex query. This allows a "multi-faceted retriever" to build a diverse candidate pool of documents, ensuring comprehensive coverage for generating rich responses. This approach moves beyond simple rephrasing by performing a more structured decomposition of the query's underlying information needs, thereby enhancing both the diversity and relevance of the retrieved context.

### LLM-Driven Query Rewriting and Decomposition

While generating multiple perspectives improves recall, an alternative line of research focuses on enhancing the precision of a single query through direct, model-driven rewriting or decomposition. This approach aims to produce a more focused and effective query, potentially reducing the need for extensive post-retrieval processing and lowering the inference cost compared to parallel multi-query retrieval. RQ-RAG \cite{chan2024u69} exemplifies this, introducing an end-to-end framework that trains a Llama2 model to dynamically rewrite, decompose complex questions into sub-questions, or disambiguate ambiguous queries. The innovation lies in its dataset construction pipeline, which uses a larger LLM (e.g., ChatGPT) to craft tailored search queries and contextually aligned answers for various refinement scenarios. By employing control tokens, the model is guided to perform specific actions (rewrite, decompose, disambiguate, or terminate search) at each step. This proactive, learned refinement significantly improves retrieval effectiveness, particularly for challenging multi-hop Question Answering (QA) tasks, achieving state-of-the-art results with remarkable data efficiency. The primary advantage of RQ-RAG is its ability to produce a more precise query, but it relies on the LLM's learned ability to correctly refine the query, and an incorrect refinement could lead to error propagation and poor retrieval.

Similarly, DPA-RAG \cite{dong2024qcd} introduces five novel query augmentation strategies aimed at aligning the retriever with the LLM's diverse knowledge preferences. This is a crucial insight: different LLMs might respond better to contexts retrieved by slightly different query formulations. By augmenting queries in ways that cater to the LLM's internal knowledge representation and reasoning patterns, DPA-RAG enhances the reliability and factual consistency of RAG systems. This highlights a shift from generic query optimization to LLM-specific query conditioning, recognizing the interplay between query formulation and the LLM's internal processing.

### Adaptive Query Strategies and Domain-Specific Refinement

Recognizing that not all queries are equally complex or require the same refinement strategy, researchers have also developed adaptive frameworks. Layered Query Retrieval (LQR) \cite{huang202465n} proposes an adaptive RAG framework that focuses on query complexity classification. It employs a semantic rule-based approach to distinguish between different levels of multi-hop queries. Based on this classification, LQR dynamically selects appropriate retrieval strategies, beginning with keyword-based retrieval and then using a Natural Language Inference (NLI) model to assess document relevance. This adaptive selection of strategies, guided by query complexity, aims to balance retrieval efficiency with accuracy, particularly for complex multi-hop questions. The core idea is to avoid over-engineering simple queries while applying sophisticated refinement only when necessary.

Query enhancement also extends to specialized domain-specific contexts. Telco-RAG \cite{bornea2024jde}, designed for the highly technical telecommunications domain, incorporates lexicon-enhanced queries using a custom glossary. It further refines queries with LLM-generated candidate answers to clarify intent, leveraging domain-specific knowledge to disambiguate technical jargon and improve precision. This demonstrates how general query refinement principles can be tailored and augmented with domain-specific resources to achieve superior performance in specialized applications.

### Critical Analysis and Remaining Challenges

The evolution of RAG systems clearly demonstrates a critical shift from passive context augmentation to active, intelligent pre-retrieval query processing. Techniques ranging from multi-perspective generation and LLM-driven rewriting to adaptive, corrective, and domain-specific query refinement significantly enhance the precision and recall of retrieved information. Multi-perspective approaches like RAG-Fusion prioritize recall and robustness against initial query ambiguity but come with increased computational costs due to multiple retrieval calls and the overhead of rank fusion. In contrast, LLM-driven rewriting (e.g., RQ-RAG) aims for higher precision and efficiency by generating a single, optimized query, but risks error propagation if the LLM's refinement is flawed or misinterprets the user's intent. Adaptive strategies, such as LQR, attempt to strike a balance by dynamically applying refinement based on query complexity, but require robust classification mechanisms that can accurately assess query difficulty without adding significant latency.

Despite these advancements, challenges remain. Optimizing the real-time performance of multi-stage refinement processes, especially for latency-sensitive applications, is crucial. Ensuring the generalizability of learned refinement strategies across diverse domains and query types without extensive re-training is another hurdle. Furthermore, developing robust mechanisms for dynamically selecting the most appropriate refinement approach for any given query without incurring excessive latency or computational overhead remains an open research question \cite{huang2024a59, zhao2024931}. The trade-off between the complexity of the refinement mechanism and its actual benefit in terms of downstream generation quality and efficiency requires continuous empirical investigation \cite{wu2024bpc}. These ongoing challenges highlight the need for further research into more efficient, robust, and context-aware query refinement techniques that can seamlessly integrate into real-world RAG deployments.