[
  {
    "success": true,
    "doc_id": "bee15ed280fb8a34788ca5917c723c14",
    "summary": "The Arcade Learning Environment (ALE) \\cite{bellemare2012sge} is a foundational platform for research in general artificial intelligence.\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of developing and rigorously evaluating general, domain-independent AI algorithms that can achieve competency across a wide variety of tasks without domain-specific tailoring.\n    *   **Importance & Challenge:**\n        *   Developing general AI is a longstanding goal, but evaluating \"general competency\" is difficult.\n        *   Traditional evaluation on a few parameterized benchmarks is flawed, prone to method overfitting, and underestimates the effort needed to transfer algorithms to new domains.\n        *   An ideal evaluation requires diverse, interesting, and independently created domains to avoid experimenter bias, which is hard to achieve at scale.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   Acknowledges theoretical frameworks for \"big AI\" (e.g., Russell, Hutter, Legg) and lifelong learning (Thrun & Mitchell).\n        *   Relates to the growing interest in general competency competitions like General Game Playing, Reinforcement Learning, and International Planning competitions.\n    *   **Limitations of Previous Solutions:**\n        *   Existing evaluation methods often rely on a small number of parameterized problems, which can lead to overfitting and fail to truly assess generality.\n        *   Lack of a standardized, large-scale, and diverse testbed for general AI research.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:**\n        *   **Arcade Learning Environment (ALE):** A software framework built on the Stella Atari 2600 emulator, providing a standardized interface to hundreds of diverse Atari 2600 game environments.\n        *   **Standardized RL Problem Formulation:** ALE includes a game-handling layer that transforms each game into a standard reinforcement learning problem, identifying accumulated score, game termination, and providing screen pixels (160x210, 128-color palette) or raw RAM as observations, and 18 discrete joystick actions.\n        *   **Evaluation Methodology:** Proposes a train/test split approach, where agents are tuned on a small set of \"training games\" and then evaluated on a larger, unseen set of \"testing games\" to assess true generalization.\n    *   **Novelty/Difference:**\n        *   **Scale and Diversity:** Offers access to over 500 distinct game environments, providing unprecedented diversity for evaluating general agents.\n        *   **Generative Model Capability:** Crucially, ALE provides functionality to save and restore the emulator's state, allowing it to be used as a perfect generative model for studying planning and model-based reinforcement learning, which is a significant enabler for these research areas.\n        *   **Open-Source Platform:** Released as free, open-source software, fostering community development and standardized benchmarking.\n\n*   **4. Key Technical Contributions**\n    *   **System Design/Architectural Innovations:**\n        *   The design of ALE itself as a robust, high-performance (up to 6000 frames/sec emulation) interface to a vast library of games.\n        *   The game-handling layer that abstracts diverse game mechanics into a uniform RL problem interface.\n        *   The save/restore state functionality, transforming the emulator into a powerful tool for model-based AI research.\n    *   **Novel Algorithms/Methods (as part of benchmarks):**\n        *   Development and benchmarking of several domain-independent feature construction methods for SARSA(λ) agents (Basic, BASS, DISCO, LSH, RAM) to demonstrate ALE's utility.\n        *   Application and benchmarking of traditional planning algorithms (Breadth-first Search, UCT) using ALE as a generative model.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:**\n        *   **Reinforcement Learning (RL):** Evaluated SARSA(λ) with linear function approximation using five different feature sets (Basic, BASS, DISCO, LSH, RAM) on 55 Atari 2600 games.\n        *   **Planning:** Evaluated Breadth-first Search and UCT algorithms using ALE's generative model capabilities on a subset of games.\n        *   **Methodology Validation:** Used a distinct training set (5 games) for parameter tuning and a testing set (50 unseen games) for final evaluation, demonstrating the proposed methodology.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Metric:** Average score achieved during 500 evaluation episodes (after 5,000 training episodes for RL agents).\n        *   **Baselines:** Compared against simple agents (Random, Const, Perturb) and non-expert human performance.\n        *   **RL Findings:**\n            *   Learning agents outperformed baselines in 40 out of 55 games.\n            *   BASS generally performed best among the learning methods.\n            *   The DISCO method showed a significant performance drop on unseen test games, validating the train/test methodology for assessing robustness.\n            *   RAM-based agents did not consistently outperform image-based methods, suggesting the screen image contains crucial structural information.\n        *   **Planning Findings:**\n            *   Planning agents (Breadth-first Search, UCT) significantly outperformed RL agents and baselines on some games (e.g., Asterix, Zaxxon).\n            *   UCT generally outperformed Breadth-first Search, especially on games requiring longer-term planning.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   Even with a perfect model, the vast state space and sparse rewards in Atari 2600 games make exhaustive search intractable for planning algorithms.\n        *   Current domain-independent RL methods struggle with games requiring high-level planning or elaborate behavior for positive rewards (e.g., Montezuma's Revenge, Tennis).\n        *   The feature sets used for RL, while domain-independent, are still relatively simple and may not capture all necessary information.\n    *   **Scope of Applicability:**\n        *   Primarily focused on Atari 2600 games, which are simpler than modern environments but still pose significant challenges.\n        *   While designed for general AI, the immediate goal is \"general competency across the gamut of Atari 2600 games\" \\cite{bellemare2012sge}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:**\n        *   **Standardized Benchmark:** Provides the first large-scale, diverse, and standardized evaluation platform for general AI, addressing a critical need in the field.\n        *   **Enabler for Model-Based AI:** The save/restore state functionality is a crucial innovation that enables rigorous research in planning and model-based reinforcement learning.\n        *   **Methodological Rigor:** Introduces and validates a robust train/test evaluation methodology for general agents, promoting more reliable assessment of generalization capabilities.\n    *   **Potential Impact on Future Research:**\n        *   Has become a de facto standard benchmark for deep reinforcement learning and general AI research (e.g., AlphaGo, DQN).\n        *   Facilitates the development and comparison of novel algorithms for reinforcement learning, model learning, planning, imitation learning, transfer learning, and intrinsic motivation.\n        *   The open-source nature and ease of use have significantly lowered the barrier to entry for researchers working on general AI problems.",
    "intriguing_abstract": "Developing truly general artificial intelligence demands rigorous, domain-independent evaluation, a challenge often hampered by limited, biased benchmarks. We introduce the **Arcade Learning Environment (ALE)**, a groundbreaking platform designed to address this critical need. Built upon the Stella Atari 2600 emulator, ALE provides a standardized interface to over 500 diverse game environments, transforming each into a uniform **reinforcement learning (RL)** problem with pixel or RAM observations and discrete actions.\n\nOur most novel contribution is ALE's unique ability to save and restore emulator states, effectively turning it into a perfect **generative model**. This crucial feature unlocks unprecedented opportunities for research in **planning** and **model-based RL**, allowing for precise exploration of complex decision-making. We propose and validate a robust train/test evaluation methodology, demonstrating its utility by benchmarking several **domain-independent** RL agents and planning algorithms across dozens of games. ALE's scale, diversity, and open-source nature establish it as a foundational **benchmark**, accelerating the development and assessment of next-generation **general AI** algorithms and fostering significant advancements in the field.",
    "keywords": [
      "Arcade Learning Environment (ALE)",
      "General Artificial Intelligence (AI)",
      "domain-independent AI algorithms",
      "standardized evaluation platform",
      "Reinforcement Learning (RL)",
      "model-based reinforcement learning",
      "planning algorithms",
      "Atari 2600 games",
      "generative model (save/restore state)",
      "train/test split methodology",
      "large-scale diverse testbed",
      "open-source platform",
      "generalization capabilities",
      "SARSA(λ)",
      "UCT"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f82e4ff4f003581330338aaae71f60316e58dd26.pdf",
    "citation_key": "bellemare2012sge",
    "metadata": {
      "title": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
      "authors": [
        "Marc G. Bellemare",
        "Yavar Naddaf",
        "J. Veness",
        "Michael Bowling"
      ],
      "published_date": "2012",
      "abstract": "In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f82e4ff4f003581330338aaae71f60316e58dd26.pdf",
      "venue": "Journal of Artificial Intelligence Research",
      "citationCount": 3124,
      "score": 240.30769230769232,
      "summary": "The Arcade Learning Environment (ALE) \\cite{bellemare2012sge} is a foundational platform for research in general artificial intelligence.\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of developing and rigorously evaluating general, domain-independent AI algorithms that can achieve competency across a wide variety of tasks without domain-specific tailoring.\n    *   **Importance & Challenge:**\n        *   Developing general AI is a longstanding goal, but evaluating \"general competency\" is difficult.\n        *   Traditional evaluation on a few parameterized benchmarks is flawed, prone to method overfitting, and underestimates the effort needed to transfer algorithms to new domains.\n        *   An ideal evaluation requires diverse, interesting, and independently created domains to avoid experimenter bias, which is hard to achieve at scale.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   Acknowledges theoretical frameworks for \"big AI\" (e.g., Russell, Hutter, Legg) and lifelong learning (Thrun & Mitchell).\n        *   Relates to the growing interest in general competency competitions like General Game Playing, Reinforcement Learning, and International Planning competitions.\n    *   **Limitations of Previous Solutions:**\n        *   Existing evaluation methods often rely on a small number of parameterized problems, which can lead to overfitting and fail to truly assess generality.\n        *   Lack of a standardized, large-scale, and diverse testbed for general AI research.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:**\n        *   **Arcade Learning Environment (ALE):** A software framework built on the Stella Atari 2600 emulator, providing a standardized interface to hundreds of diverse Atari 2600 game environments.\n        *   **Standardized RL Problem Formulation:** ALE includes a game-handling layer that transforms each game into a standard reinforcement learning problem, identifying accumulated score, game termination, and providing screen pixels (160x210, 128-color palette) or raw RAM as observations, and 18 discrete joystick actions.\n        *   **Evaluation Methodology:** Proposes a train/test split approach, where agents are tuned on a small set of \"training games\" and then evaluated on a larger, unseen set of \"testing games\" to assess true generalization.\n    *   **Novelty/Difference:**\n        *   **Scale and Diversity:** Offers access to over 500 distinct game environments, providing unprecedented diversity for evaluating general agents.\n        *   **Generative Model Capability:** Crucially, ALE provides functionality to save and restore the emulator's state, allowing it to be used as a perfect generative model for studying planning and model-based reinforcement learning, which is a significant enabler for these research areas.\n        *   **Open-Source Platform:** Released as free, open-source software, fostering community development and standardized benchmarking.\n\n*   **4. Key Technical Contributions**\n    *   **System Design/Architectural Innovations:**\n        *   The design of ALE itself as a robust, high-performance (up to 6000 frames/sec emulation) interface to a vast library of games.\n        *   The game-handling layer that abstracts diverse game mechanics into a uniform RL problem interface.\n        *   The save/restore state functionality, transforming the emulator into a powerful tool for model-based AI research.\n    *   **Novel Algorithms/Methods (as part of benchmarks):**\n        *   Development and benchmarking of several domain-independent feature construction methods for SARSA(λ) agents (Basic, BASS, DISCO, LSH, RAM) to demonstrate ALE's utility.\n        *   Application and benchmarking of traditional planning algorithms (Breadth-first Search, UCT) using ALE as a generative model.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:**\n        *   **Reinforcement Learning (RL):** Evaluated SARSA(λ) with linear function approximation using five different feature sets (Basic, BASS, DISCO, LSH, RAM) on 55 Atari 2600 games.\n        *   **Planning:** Evaluated Breadth-first Search and UCT algorithms using ALE's generative model capabilities on a subset of games.\n        *   **Methodology Validation:** Used a distinct training set (5 games) for parameter tuning and a testing set (50 unseen games) for final evaluation, demonstrating the proposed methodology.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Metric:** Average score achieved during 500 evaluation episodes (after 5,000 training episodes for RL agents).\n        *   **Baselines:** Compared against simple agents (Random, Const, Perturb) and non-expert human performance.\n        *   **RL Findings:**\n            *   Learning agents outperformed baselines in 40 out of 55 games.\n            *   BASS generally performed best among the learning methods.\n            *   The DISCO method showed a significant performance drop on unseen test games, validating the train/test methodology for assessing robustness.\n            *   RAM-based agents did not consistently outperform image-based methods, suggesting the screen image contains crucial structural information.\n        *   **Planning Findings:**\n            *   Planning agents (Breadth-first Search, UCT) significantly outperformed RL agents and baselines on some games (e.g., Asterix, Zaxxon).\n            *   UCT generally outperformed Breadth-first Search, especially on games requiring longer-term planning.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   Even with a perfect model, the vast state space and sparse rewards in Atari 2600 games make exhaustive search intractable for planning algorithms.\n        *   Current domain-independent RL methods struggle with games requiring high-level planning or elaborate behavior for positive rewards (e.g., Montezuma's Revenge, Tennis).\n        *   The feature sets used for RL, while domain-independent, are still relatively simple and may not capture all necessary information.\n    *   **Scope of Applicability:**\n        *   Primarily focused on Atari 2600 games, which are simpler than modern environments but still pose significant challenges.\n        *   While designed for general AI, the immediate goal is \"general competency across the gamut of Atari 2600 games\" \\cite{bellemare2012sge}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:**\n        *   **Standardized Benchmark:** Provides the first large-scale, diverse, and standardized evaluation platform for general AI, addressing a critical need in the field.\n        *   **Enabler for Model-Based AI:** The save/restore state functionality is a crucial innovation that enables rigorous research in planning and model-based reinforcement learning.\n        *   **Methodological Rigor:** Introduces and validates a robust train/test evaluation methodology for general agents, promoting more reliable assessment of generalization capabilities.\n    *   **Potential Impact on Future Research:**\n        *   Has become a de facto standard benchmark for deep reinforcement learning and general AI research (e.g., AlphaGo, DQN).\n        *   Facilitates the development and comparison of novel algorithms for reinforcement learning, model learning, planning, imitation learning, transfer learning, and intrinsic motivation.\n        *   The open-source nature and ease of use have significantly lowered the barrier to entry for researchers working on general AI problems.",
      "keywords": [
        "Arcade Learning Environment (ALE)",
        "General Artificial Intelligence (AI)",
        "domain-independent AI algorithms",
        "standardized evaluation platform",
        "Reinforcement Learning (RL)",
        "model-based reinforcement learning",
        "planning algorithms",
        "Atari 2600 games",
        "generative model (save/restore state)",
        "train/test split methodology",
        "large-scale diverse testbed",
        "open-source platform",
        "generalization capabilities",
        "SARSA(λ)",
        "UCT"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we introduce the arcade learning environment (ale): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent ai technology.\" it also mentions \"propose an evaluation methodology\" and \"developing and benchmarking domain-independent agents.\"\n*   the introduction discusses the problem of evaluating general ai competency and implicitly positions ale as a solution.\n*   while it reports \"empirical results,\" these are presented as an illustration and benchmarking of the *new platform and methodology* rather than being the primary focus of a standalone empirical study. the core contribution is the creation and presentation of the ale system and its associated methodology.\n\nthis aligns best with the **technical** classification, which involves presenting new methods, algorithms, or systems.\n\n**classification: technical**"
    },
    "file_name": "f82e4ff4f003581330338aaae71f60316e58dd26.pdf"
  },
  {
    "success": true,
    "doc_id": "01c58d2c3424f575e36b7670bf5cfcae",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** General-purpose deep learning (DL) frameworks (e.g., PyTorch, TensorFlow) lack domain-specific functionality required for healthcare data, which has unique particularities (e.g., geometry, physiology, physics, rich metadata in formats like DICOM). Existing healthcare-specific DL frameworks are fragmented, leading to diluted development efforts, reduced code quality, and slowed research progress \\cite{cardoso2022a89}.\n    *   **Importance & Challenge:** AI holds immense potential to improve healthcare (detection, diagnosis, prognosis, intervention, image reconstruction, data curation, clinical safety, operations). However, for clinical use, AI models must be safe, reproducible, and robust. The underlying software framework must explicitly account for the complexities and specific requirements of medical data, which often involves high-dimensional arrays, coupled processing with physical interpretations, and anatomical analysis \\cite{cardoso2022a89}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper acknowledges the maturity and feature parity of general-purpose DL frameworks like TensorFlow and PyTorch \\cite{cardoso2022a89}. It also notes the existence of academic (e.g., NiftyNet, DLTK, DeepNeuro) and industry-led (e.g., NVIDIA Clara, Microsoft Project InnerEye) healthcare-specific frameworks \\cite{cardoso2022a89}.\n    *   **Limitations of Previous Solutions:** General-purpose frameworks necessitate significant custom development for healthcare applications, increasing R&D risks and timelines. The proliferation of disparate healthcare-specific frameworks has resulted in a fragmented software ecosystem, hindering collaboration and standardization \\cite{cardoso2022a89}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** MONAI (Medical Open Network for AI) Core is a PyTorch-based, open-source, community-supported framework that extends PyTorch with domain-optimized foundational capabilities for deep learning in healthcare, focusing on imaging, video, and structured data \\cite{cardoso2022a89}.\n    *   **Novelty/Difference:**\n        *   **PyTorch-native Design:** Adheres to PyTorch's design principles, ensuring a minimal learning curve and seamless integration with the PyTorch ecosystem \\cite{cardoso2022a89}.\n        *   **Opt-in and Incremental:** Users can gradually adopt MONAI components (transforms, layers, loss functions) into existing PyTorch projects without stringent design enforcement or cumbersome APIs \\cite{cardoso2022a89}.\n        *   **Domain-Specific Components:** Provides purpose-specific AI model architectures, transformations, and utilities tailored for medical data, addressing the limitations of general-purpose frameworks \\cite{cardoso2022a89}.\n        *   **Unification:** Aims to unify the fragmented healthcare AI software field by standardizing best practices and fostering collaboration across research, clinical, and industrial teams \\cite{cardoso2022a89}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   **Comprehensive Medical Image Transforms:** Offers a rich set of medical image-specific transformations for I/O, spatial manipulation, intensity adjustment, cropping/padding, etc., designed for high-dimensional medical data and emphasizing reproducible results (e.g., `LoadImage`, `Spacing`, `Orientation`, `Rand3DElastic`) \\cite{cardoso2022a89}.\n        *   **Physics-Specific Transforms:** Includes transformations grounded in the physics of medical image acquisition, such as `RandKSpaceSpikeNoise` for MR k-space augmentation \\cite{cardoso2022a89}.\n        *   **Invertible Transforms:** Provides the capability to invert spatial transformations, crucial for applications like test-time augmentation (TTA), augmentation-consistency, and preserving original geometry when saving inferred segmented images \\cite{cardoso2022a89}.\n        *   **Array and Dictionary Transforms:** Supports flexible data processing pipelines by allowing transforms to be applied to single tensors/arrays or to data dictionaries, enabling consistent augmentation across paired data (e.g., image and ground truth) \\cite{cardoso2022a89}.\n    *   **System Design or Architectural Innovations:**\n        *   **Modular Architecture:** Organized into core modules (`monai.data`, `monai.losses`, `monai.networks`, `monai.transforms`, `monai.metrics`, `monai.optimizers`, `monai.engines`, `monai.handlers`) for clear separation of concerns and extensibility \\cite{cardoso2022a89}.\n        *   **C++/CUDA Extensions:** Includes `monai.csrc` and `monai.extensions` for performance-critical operations \\cite{cardoso2022a89}.\n        *   **Consortium-Led Development:** A collaborative initiative involving multiple universities and industrial partners, ensuring broad input and adoption \\cite{cardoso2022a89}.\n\n5.  **Experimental Validation**\n    *   The provided paper content primarily focuses on describing the MONAI framework's design, philosophy, and components. It *does not include a dedicated section detailing specific experimental validations*, performance metrics, or comparative results against other frameworks or baselines. While the introduction mentions MONAI \"is being applied to solve a variety of healthcare challenges,\" these applications are not elaborated with empirical data within the provided text \\cite{cardoso2022a89}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper does not explicitly list technical limitations of MONAI itself. Its design principles (PyTorch-like, opt-in, collaborative) are intended to mitigate common challenges in healthcare AI development. It assumes users are familiar with PyTorch and aims to build upon that knowledge \\cite{cardoso2022a89}.\n    *   **Scope of Applicability:** MONAI Core is focused on deep learning model research and development in healthcare, with a particular emphasis on imaging, video, and other structured data (e.g., tabular data, EEG signals). It is part of a broader Project MONAI consortium that includes tools for AI-assisted labeling (MONAI Label), clinical deployment (MONAI Deploy), and federated learning (MONAI FL) \\cite{cardoso2022a89}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** MONAI significantly advances the technical state-of-the-art by providing a unified, robust, and domain-aware open-source framework for healthcare AI. It addresses the critical gap between general-purpose DL frameworks and the specific needs of medical data processing \\cite{cardoso2022a89}.\n    *   **Potential Impact on Future Research:**\n        *   **Accelerated R&D:** Streamlines the development and deployment of medical AI models, allowing researchers to focus on novel contributions rather than re-implementing foundational components \\cite{cardoso2022a89}.\n        *   **Improved Reproducibility:** Standardized pipeline elements and a well-tested framework enhance the reproducibility of algorithmic research \\cite{cardoso2022a89}.\n        *   **Enhanced Collaboration:** Fosters a collaborative ecosystem, bringing together diverse communities and promoting the exchange of best practices, thereby reducing fragmentation in the field \\cite{cardoso2022a89}.\n        *   **Safer and More Robust AI:** By embedding awareness of medical data particularities, MONAI contributes to building safer and more robust AI systems for clinical applications \\cite{cardoso2022a89}.",
    "intriguing_abstract": "The transformative potential of Artificial Intelligence in healthcare is undeniable, yet its full realization is hampered by fragmented development and the inherent limitations of general-purpose deep learning (DL) frameworks when confronted with complex, domain-specific medical data, including rich DICOM metadata. We introduce MONAI Core, an innovative, PyTorch-native, and open-source framework meticulously engineered to bridge this critical gap. MONAI provides a robust foundation for deep learning in medical imaging, video, and structured data, offering unparalleled domain-optimized capabilities.\n\nOur novel contributions include a comprehensive suite of medical image transforms, featuring physics-specific and invertible operations crucial for high-dimensional data processing, test-time augmentation, and ensuring geometric fidelity. Designed for seamless integration and incremental adoption, MONAI unifies a previously disparate software ecosystem, fostering collaboration and standardizing best practices. By accelerating R&D, enhancing reproducibility, and enabling the development of safer, more robust AI models tailored for clinical translation, MONAI empowers researchers and clinicians to unlock the next generation of healthcare AI solutions.",
    "keywords": [
      "MONAI Core",
      "healthcare AI",
      "deep learning frameworks",
      "medical image transforms",
      "PyTorch-based",
      "domain-optimized capabilities",
      "fragmented software ecosystem",
      "invertible transforms",
      "modular architecture",
      "open-source community-supported",
      "reproducibility in AI",
      "clinical AI applications",
      "high-dimensional medical data",
      "unification of healthcare AI",
      "physics-specific transforms"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9b90291103892b9f9665c11461d7bc9ea40ea9ec.pdf",
    "citation_key": "cardoso2022a89",
    "metadata": {
      "title": "MONAI: An open-source framework for deep learning in healthcare",
      "authors": [
        "M. Cardoso",
        "Wenqi Li",
        "Richard Brown",
        "Nic Ma",
        "E. Kerfoot",
        "Yiheng Wang",
        "Benjamin Murrey",
        "A. Myronenko",
        "Can Zhao",
        "Dong Yang",
        "V. Nath",
        "Yufan He",
        "Ziyue Xu",
        "Ali Hatamizadeh",
        "Wenjie Zhu",
        "Yun Liu",
        "Mingxin Zheng",
        "Yucheng Tang",
        "Isaac Yang",
        "Michael Zephyr",
        "Behrooz Hashemian",
        "Sachidanand Alle",
        "Mohammad Zalbagi Darestani",
        "C. Budd",
        "M. Modat",
        "Tom Kamiel Magda Vercauteren",
        "Guotai Wang",
        "Yiwen Li",
        "Yipeng Hu",
        "Yunguan Fu",
        "Benjamin L. Gorman",
        "Hans J. Johnson",
        "Brad W. Genereaux",
        "B. S. Erdal",
        "Vikash Gupta",
        "A. Diaz-Pinto",
        "Andre Dourson",
        "L. Maier-Hein",
        "P. Jaeger",
        "M. Baumgartner",
        "Jayashree Kalpathy-Cramer",
        "Mona G. Flores",
        "J. Kirby",
        "L. Cooper",
        "H. Roth",
        "Daguang Xu",
        "David Bericat",
        "R. Floca",
        "S. K. Zhou",
        "Haris Shuaib",
        "K. Farahani",
        "K. Maier-Hein",
        "S. Aylward",
        "Prerna Dogra",
        "S. Ourselin",
        "Andrew Feng"
      ],
      "published_date": "2022",
      "abstract": "Artificial Intelligence (AI) is having a tremendous impact across most areas of science. Applications of AI in healthcare have the potential to improve our ability to detect, diagnose, prognose, and intervene on human disease. For AI models to be used clinically, they need to be made safe, reproducible and robust, and the underlying software framework must be aware of the particularities (e.g. geometry, physiology, physics) of medical data being processed. This work introduces MONAI, a freely available, community-supported, and consortium-led PyTorch-based framework for deep learning in healthcare. MONAI extends PyTorch to support medical data, with a particular focus on imaging, and provide purpose-specific AI model architectures, transformations and utilities that streamline the development and deployment of medical AI models. MONAI follows best practices for software-development, providing an easy-to-use, robust, well-documented, and well-tested software framework. MONAI preserves the simple, additive, and compositional approach of its underlying PyTorch libraries. MONAI is being used by and receiving contributions from research, clinical and industrial teams from around the world, who are pursuing applications spanning nearly every aspect of healthcare.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9b90291103892b9f9665c11461d7bc9ea40ea9ec.pdf",
      "venue": "arXiv.org",
      "citationCount": 611,
      "score": 203.66666666666666,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** General-purpose deep learning (DL) frameworks (e.g., PyTorch, TensorFlow) lack domain-specific functionality required for healthcare data, which has unique particularities (e.g., geometry, physiology, physics, rich metadata in formats like DICOM). Existing healthcare-specific DL frameworks are fragmented, leading to diluted development efforts, reduced code quality, and slowed research progress \\cite{cardoso2022a89}.\n    *   **Importance & Challenge:** AI holds immense potential to improve healthcare (detection, diagnosis, prognosis, intervention, image reconstruction, data curation, clinical safety, operations). However, for clinical use, AI models must be safe, reproducible, and robust. The underlying software framework must explicitly account for the complexities and specific requirements of medical data, which often involves high-dimensional arrays, coupled processing with physical interpretations, and anatomical analysis \\cite{cardoso2022a89}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper acknowledges the maturity and feature parity of general-purpose DL frameworks like TensorFlow and PyTorch \\cite{cardoso2022a89}. It also notes the existence of academic (e.g., NiftyNet, DLTK, DeepNeuro) and industry-led (e.g., NVIDIA Clara, Microsoft Project InnerEye) healthcare-specific frameworks \\cite{cardoso2022a89}.\n    *   **Limitations of Previous Solutions:** General-purpose frameworks necessitate significant custom development for healthcare applications, increasing R&D risks and timelines. The proliferation of disparate healthcare-specific frameworks has resulted in a fragmented software ecosystem, hindering collaboration and standardization \\cite{cardoso2022a89}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** MONAI (Medical Open Network for AI) Core is a PyTorch-based, open-source, community-supported framework that extends PyTorch with domain-optimized foundational capabilities for deep learning in healthcare, focusing on imaging, video, and structured data \\cite{cardoso2022a89}.\n    *   **Novelty/Difference:**\n        *   **PyTorch-native Design:** Adheres to PyTorch's design principles, ensuring a minimal learning curve and seamless integration with the PyTorch ecosystem \\cite{cardoso2022a89}.\n        *   **Opt-in and Incremental:** Users can gradually adopt MONAI components (transforms, layers, loss functions) into existing PyTorch projects without stringent design enforcement or cumbersome APIs \\cite{cardoso2022a89}.\n        *   **Domain-Specific Components:** Provides purpose-specific AI model architectures, transformations, and utilities tailored for medical data, addressing the limitations of general-purpose frameworks \\cite{cardoso2022a89}.\n        *   **Unification:** Aims to unify the fragmented healthcare AI software field by standardizing best practices and fostering collaboration across research, clinical, and industrial teams \\cite{cardoso2022a89}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   **Comprehensive Medical Image Transforms:** Offers a rich set of medical image-specific transformations for I/O, spatial manipulation, intensity adjustment, cropping/padding, etc., designed for high-dimensional medical data and emphasizing reproducible results (e.g., `LoadImage`, `Spacing`, `Orientation`, `Rand3DElastic`) \\cite{cardoso2022a89}.\n        *   **Physics-Specific Transforms:** Includes transformations grounded in the physics of medical image acquisition, such as `RandKSpaceSpikeNoise` for MR k-space augmentation \\cite{cardoso2022a89}.\n        *   **Invertible Transforms:** Provides the capability to invert spatial transformations, crucial for applications like test-time augmentation (TTA), augmentation-consistency, and preserving original geometry when saving inferred segmented images \\cite{cardoso2022a89}.\n        *   **Array and Dictionary Transforms:** Supports flexible data processing pipelines by allowing transforms to be applied to single tensors/arrays or to data dictionaries, enabling consistent augmentation across paired data (e.g., image and ground truth) \\cite{cardoso2022a89}.\n    *   **System Design or Architectural Innovations:**\n        *   **Modular Architecture:** Organized into core modules (`monai.data`, `monai.losses`, `monai.networks`, `monai.transforms`, `monai.metrics`, `monai.optimizers`, `monai.engines`, `monai.handlers`) for clear separation of concerns and extensibility \\cite{cardoso2022a89}.\n        *   **C++/CUDA Extensions:** Includes `monai.csrc` and `monai.extensions` for performance-critical operations \\cite{cardoso2022a89}.\n        *   **Consortium-Led Development:** A collaborative initiative involving multiple universities and industrial partners, ensuring broad input and adoption \\cite{cardoso2022a89}.\n\n5.  **Experimental Validation**\n    *   The provided paper content primarily focuses on describing the MONAI framework's design, philosophy, and components. It *does not include a dedicated section detailing specific experimental validations*, performance metrics, or comparative results against other frameworks or baselines. While the introduction mentions MONAI \"is being applied to solve a variety of healthcare challenges,\" these applications are not elaborated with empirical data within the provided text \\cite{cardoso2022a89}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper does not explicitly list technical limitations of MONAI itself. Its design principles (PyTorch-like, opt-in, collaborative) are intended to mitigate common challenges in healthcare AI development. It assumes users are familiar with PyTorch and aims to build upon that knowledge \\cite{cardoso2022a89}.\n    *   **Scope of Applicability:** MONAI Core is focused on deep learning model research and development in healthcare, with a particular emphasis on imaging, video, and other structured data (e.g., tabular data, EEG signals). It is part of a broader Project MONAI consortium that includes tools for AI-assisted labeling (MONAI Label), clinical deployment (MONAI Deploy), and federated learning (MONAI FL) \\cite{cardoso2022a89}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** MONAI significantly advances the technical state-of-the-art by providing a unified, robust, and domain-aware open-source framework for healthcare AI. It addresses the critical gap between general-purpose DL frameworks and the specific needs of medical data processing \\cite{cardoso2022a89}.\n    *   **Potential Impact on Future Research:**\n        *   **Accelerated R&D:** Streamlines the development and deployment of medical AI models, allowing researchers to focus on novel contributions rather than re-implementing foundational components \\cite{cardoso2022a89}.\n        *   **Improved Reproducibility:** Standardized pipeline elements and a well-tested framework enhance the reproducibility of algorithmic research \\cite{cardoso2022a89}.\n        *   **Enhanced Collaboration:** Fosters a collaborative ecosystem, bringing together diverse communities and promoting the exchange of best practices, thereby reducing fragmentation in the field \\cite{cardoso2022a89}.\n        *   **Safer and More Robust AI:** By embedding awareness of medical data particularities, MONAI contributes to building safer and more robust AI systems for clinical applications \\cite{cardoso2022a89}.",
      "keywords": [
        "MONAI Core",
        "healthcare AI",
        "deep learning frameworks",
        "medical image transforms",
        "PyTorch-based",
        "domain-optimized capabilities",
        "fragmented software ecosystem",
        "invertible transforms",
        "modular architecture",
        "open-source community-supported",
        "reproducibility in AI",
        "clinical AI applications",
        "high-dimensional medical data",
        "unification of healthcare AI",
        "physics-specific transforms"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"this work introduces monai, a freely available... pytorch-based framework for deep learning in healthcare.\"\n*   it then details what monai \"extends pytorch to support\" and what it \"provide[s]\" (ai model architectures, transformations, utilities).\n*   the introduction highlights the importance of \"underlying software frameworks and tools\" for ai in healthcare.\n\nthese points strongly indicate that the paper is presenting a new system or framework.\n\ntherefore, the paper type is **technical**."
    },
    "file_name": "9b90291103892b9f9665c11461d7bc9ea40ea9ec.pdf"
  },
  {
    "success": true,
    "doc_id": "b415fe91f3a6d3719af5b7b143fd5abf",
    "summary": "Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be \"entangled\" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.",
    "intriguing_abstract": "Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be \"entangled\" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f70b2f20be241f445a61f33c4b8e76e554760340.pdf",
    "citation_key": "amershi20196rm",
    "metadata": {
      "title": "Software Engineering for Machine Learning: A Case Study",
      "authors": [
        "Saleema Amershi",
        "Andrew Begel",
        "C. Bird",
        "R. Deline",
        "H. Gall",
        "Ece Kamar",
        "Nachiappan Nagappan",
        "Besmira Nushi",
        "Thomas Zimmermann"
      ],
      "published_date": "2019",
      "abstract": "Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be \"entangled\" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f70b2f20be241f445a61f33c4b8e76e554760340.pdf",
      "venue": "2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
      "citationCount": 841,
      "score": 140.16666666666666,
      "summary": "Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be \"entangled\" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.",
      "keywords": []
    },
    "file_name": "f70b2f20be241f445a61f33c4b8e76e554760340.pdf"
  },
  {
    "success": true,
    "doc_id": "6c900069711e609d5b302c933ed5f690",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{wu2021t2c}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the rapidly growing and significant environmental impact (carbon footprint) of Artificial Intelligence (AI) computing, which is driven by super-linear growth in AI data, model sizes, and infrastructure capacity \\cite{wu2021t2c}.\n    *   **Importance and Challenge**: This problem is critical because AI's exponential growth, while offering societal benefits, creates a self-accelerating demand on environmental resources. Previous work often focused only on the carbon footprint of training a single large model, which is insufficient for understanding the full impact. The challenge lies in holistically characterizing this impact across the entire AI ecosystem, including both operational and embodied carbon, and optimizing across complex, interconnected ML pipelines and system life cycles \\cite{wu2021t2c}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The paper acknowledges prior work that quantifies the carbon footprint of training individual large ML models (e.g., Meena \\cite{wu2021t2c}).\n    *   **Limitations of Previous Solutions**: It explicitly states that such prior work only captures \"one aspect\" and fails to provide a \"holistic perspective\" needed to understand the \"real environmental impact.\" Previous solutions often overlook the end-to-end ML pipeline (data, experimentation, inference) and the full life cycle of hardware (manufacturing, operational use, embodied carbon) \\cite{wu2021t2c}. This paper positions itself as the first to take such a holistic approach.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a holistic framework to characterize AI's carbon footprint by examining the entire model development cycle (Data Processing, Experimentation, Training, and Inference) and the full life cycle of AI system hardware (Manufacturing, Transport, Product Use, and Recycling, with a focus on manufacturing and product use) \\cite{wu2021t2c}. It integrates both operational (energy consumption during use) and embodied (manufacturing) carbon footprints.\n    *   **Novelty/Difference**: The innovation lies in its comprehensive, end-to-end analysis that spans data, algorithms, and system hardware, considering both operational and embodied carbon across all phases of the ML pipeline and hardware life cycle. It emphasizes the importance of hardware-software co-design and at-scale optimization as key strategies for reduction \\cite{wu2021t2c}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Framework**: Introduction of a holistic framework for analyzing AI's environmental footprint, encompassing the entire ML development cycle and system hardware life cycle, moving beyond single-model training analysis \\cite{wu2021t2c}.\n    *   **End-to-End Carbon Analysis**: Empirical demonstration and quantification of the significant contribution of *embodied carbon footprint* (from hardware manufacturing) to the overall AI carbon footprint, showing it can become the dominating factor when operational emissions are mitigated by carbon-free energy \\cite{wu2021t2c}.\n    *   **Optimization Strategies**: Identification and empirical validation of hardware-software co-design and at-scale optimization as effective strategies for substantial carbon footprint reduction in real-world, industry-scale ML deployments \\cite{wu2021t2c}.\n    *   **Insights into ML Pipeline Impact**: Characterization of how carbon footprint contributions vary across different ML pipeline phases (e.g., training vs. inference) and model types (e.g., recommendation models vs. language models) \\cite{wu2021t2c}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The paper analyzes six representative, large-scale production machine learning models at Facebook (e.g., Transformer-based Universal Language Model, Deep Learning Recommendation Models) and compares their carbon footprints with seven large-scale open-source models (e.g., BERT-NAS, T5, Meena, GPT-3, Switch Transformer) \\cite{wu2021t2c}.\n    *   **Key Performance Metrics and Results**:\n        *   **Operational Carbon Footprint**: Measured in CO2e (kg) for offline training, online training, and inference. It shows that for recommendation models, training and inference contribute roughly equally, while for language models, inference dominates (65% vs. 35%) \\cite{wu2021t2c}.\n        *   **Embodied Carbon Footprint**: Estimated using Life Cycle Analysis (LCA), revealing that manufacturing carbon cost is roughly 50% of the location-based operational carbon footprint for large-scale ML tasks \\cite{wu2021t2c}.\n        *   **Optimization Impact**: Demonstrated an \"over 800% operational carbon footprint reduction achieved through judicious hardware-software co-design for a Transformer-based universal language model\" \\cite{wu2021t2c}.\n        *   **Model Architecture Efficiency**: Showed that models with more parameters do not necessarily lead to higher emissions (e.g., Switch Transformer with 1.5 trillion parameters had significantly less carbon emission than GPT-3 with 750 billion parameters), highlighting the advantage of operationally-efficient architectures \\cite{wu2021t2c}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: Quantifying the exact breakdown between operational and embodied carbon footprint is complex \\cite{wu2021t2c}. The embodied carbon estimation assumes GPU-based AI training systems have similar embodied carbon as servers.\n    *   **Scope of Applicability**: While the analysis is based on industry-scale Facebook data centers, the general insights regarding holistic analysis, embodied carbon, and hardware-software co-design are broadly applicable. However, the specific breakdown of carbon sources and the effectiveness of certain optimizations might vary with different infrastructure scales, energy mixes, and ML workloads \\cite{wu2021t2c}. The paper also notes that shifting to carbon-free energy may not scale to all use cases due to geographical and material limitations, and on-device learning faces limited renewable energy access at the edge \\cite{wu2021t2c}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the technical understanding of AI's environmental impact by providing the first holistic, end-to-end analysis that integrates both operational and embodied carbon across the entire ML pipeline and hardware life cycle \\cite{wu2021t2c}. It shifts the focus from isolated model training costs to a comprehensive system-level perspective.\n    *   **Potential Impact on Future Research**: It highlights critical, often overlooked, areas for future research, particularly the dominant role of embodied carbon and the need for hardware-software co-design for sustainable AI. It inspires the community to develop environmentally-responsible AI by focusing on data efficiency, resource-efficient algorithms, sustainable hardware, and the establishment of standardized metrics and best practices \\cite{wu2021t2c}.",
    "intriguing_abstract": "The escalating environmental cost of Artificial Intelligence (AI) demands a holistic re-evaluation beyond single-model training. This paper introduces the first end-to-end framework to characterize AI's true carbon footprint, integrating both **operational carbon** (energy consumption) and **embodied carbon** (hardware manufacturing) across the entire **Machine Learning (ML) pipeline** and the full **hardware life cycle**.\n\nOur empirical analysis of industry-scale models reveals that **embodied carbon** can be a surprisingly dominant factor, particularly as operational emissions are mitigated by cleaner energy. We demonstrate that judicious **hardware-software co-design** and **at-scale optimization** are critical, achieving over 800% operational carbon footprint reduction for complex models like Transformers. This work fundamentally shifts the discourse on sustainable AI, providing crucial insights into varying carbon contributions across ML phases and model types. It underscores the urgent need for comprehensive **Life Cycle Analysis** and innovative co-design strategies to mitigate AI's rapidly accelerating environmental burden.",
    "keywords": [
      "AI carbon footprint",
      "holistic framework",
      "operational carbon footprint",
      "embodied carbon footprint",
      "ML pipeline",
      "hardware life cycle",
      "hardware-software co-design",
      "at-scale optimization",
      "end-to-end carbon analysis",
      "carbon footprint reduction",
      "industry-scale ML deployments",
      "sustainable AI",
      "Life Cycle Analysis (LCA)",
      "resource-efficient architectures"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0.pdf",
    "citation_key": "wu2021t2c",
    "metadata": {
      "title": "Sustainable AI: Environmental Implications, Challenges and Opportunities",
      "authors": [
        "Carole-Jean Wu",
        "R. Raghavendra",
        "Udit Gupta",
        "Bilge Acun",
        "Newsha Ardalani",
        "Kiwan Maeng",
        "Gloria Chang",
        "Fiona Aga Behram",
        "James Huang",
        "Charles Bai",
        "M. Gschwind",
        "Anurag Gupta",
        "Myle Ott",
        "Anastasia Melnikov",
        "Salvatore Candido",
        "David Brooks",
        "Geeta Chauhan",
        "Benjamin Lee",
        "Hsien-Hsin S. Lee",
        "Bugra Akyildiz",
        "Maximilian Balandat",
        "Joe Spisak",
        "R. Jain",
        "M. Rabbat",
        "K. Hazelwood"
      ],
      "published_date": "2021",
      "abstract": "This paper explores the environmental impact of the super-linear growth trends for AI from a holistic perspective, spanning Data, Algorithms, and System Hardware. We characterize the carbon footprint of AI computing by examining the model development cycle across industry-scale machine learning use cases and, at the same time, considering the life cycle of system hardware. Taking a step further, we capture the operational and manufacturing carbon footprint of AI computing and present an end-to-end analysis for what and how hardware-software design and at-scale optimization can help reduce the overall carbon footprint of AI. Based on the industry experience and lessons learned, we share the key challenges and chart out important development directions across the many dimensions of AI. We hope the key messages and insights presented in this paper can inspire the community to advance the field of AI in an environmentally-responsible manner.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0.pdf",
      "venue": "Conference on Machine Learning and Systems",
      "citationCount": 464,
      "score": 116.0,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{wu2021t2c}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the rapidly growing and significant environmental impact (carbon footprint) of Artificial Intelligence (AI) computing, which is driven by super-linear growth in AI data, model sizes, and infrastructure capacity \\cite{wu2021t2c}.\n    *   **Importance and Challenge**: This problem is critical because AI's exponential growth, while offering societal benefits, creates a self-accelerating demand on environmental resources. Previous work often focused only on the carbon footprint of training a single large model, which is insufficient for understanding the full impact. The challenge lies in holistically characterizing this impact across the entire AI ecosystem, including both operational and embodied carbon, and optimizing across complex, interconnected ML pipelines and system life cycles \\cite{wu2021t2c}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The paper acknowledges prior work that quantifies the carbon footprint of training individual large ML models (e.g., Meena \\cite{wu2021t2c}).\n    *   **Limitations of Previous Solutions**: It explicitly states that such prior work only captures \"one aspect\" and fails to provide a \"holistic perspective\" needed to understand the \"real environmental impact.\" Previous solutions often overlook the end-to-end ML pipeline (data, experimentation, inference) and the full life cycle of hardware (manufacturing, operational use, embodied carbon) \\cite{wu2021t2c}. This paper positions itself as the first to take such a holistic approach.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a holistic framework to characterize AI's carbon footprint by examining the entire model development cycle (Data Processing, Experimentation, Training, and Inference) and the full life cycle of AI system hardware (Manufacturing, Transport, Product Use, and Recycling, with a focus on manufacturing and product use) \\cite{wu2021t2c}. It integrates both operational (energy consumption during use) and embodied (manufacturing) carbon footprints.\n    *   **Novelty/Difference**: The innovation lies in its comprehensive, end-to-end analysis that spans data, algorithms, and system hardware, considering both operational and embodied carbon across all phases of the ML pipeline and hardware life cycle. It emphasizes the importance of hardware-software co-design and at-scale optimization as key strategies for reduction \\cite{wu2021t2c}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Framework**: Introduction of a holistic framework for analyzing AI's environmental footprint, encompassing the entire ML development cycle and system hardware life cycle, moving beyond single-model training analysis \\cite{wu2021t2c}.\n    *   **End-to-End Carbon Analysis**: Empirical demonstration and quantification of the significant contribution of *embodied carbon footprint* (from hardware manufacturing) to the overall AI carbon footprint, showing it can become the dominating factor when operational emissions are mitigated by carbon-free energy \\cite{wu2021t2c}.\n    *   **Optimization Strategies**: Identification and empirical validation of hardware-software co-design and at-scale optimization as effective strategies for substantial carbon footprint reduction in real-world, industry-scale ML deployments \\cite{wu2021t2c}.\n    *   **Insights into ML Pipeline Impact**: Characterization of how carbon footprint contributions vary across different ML pipeline phases (e.g., training vs. inference) and model types (e.g., recommendation models vs. language models) \\cite{wu2021t2c}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The paper analyzes six representative, large-scale production machine learning models at Facebook (e.g., Transformer-based Universal Language Model, Deep Learning Recommendation Models) and compares their carbon footprints with seven large-scale open-source models (e.g., BERT-NAS, T5, Meena, GPT-3, Switch Transformer) \\cite{wu2021t2c}.\n    *   **Key Performance Metrics and Results**:\n        *   **Operational Carbon Footprint**: Measured in CO2e (kg) for offline training, online training, and inference. It shows that for recommendation models, training and inference contribute roughly equally, while for language models, inference dominates (65% vs. 35%) \\cite{wu2021t2c}.\n        *   **Embodied Carbon Footprint**: Estimated using Life Cycle Analysis (LCA), revealing that manufacturing carbon cost is roughly 50% of the location-based operational carbon footprint for large-scale ML tasks \\cite{wu2021t2c}.\n        *   **Optimization Impact**: Demonstrated an \"over 800% operational carbon footprint reduction achieved through judicious hardware-software co-design for a Transformer-based universal language model\" \\cite{wu2021t2c}.\n        *   **Model Architecture Efficiency**: Showed that models with more parameters do not necessarily lead to higher emissions (e.g., Switch Transformer with 1.5 trillion parameters had significantly less carbon emission than GPT-3 with 750 billion parameters), highlighting the advantage of operationally-efficient architectures \\cite{wu2021t2c}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: Quantifying the exact breakdown between operational and embodied carbon footprint is complex \\cite{wu2021t2c}. The embodied carbon estimation assumes GPU-based AI training systems have similar embodied carbon as servers.\n    *   **Scope of Applicability**: While the analysis is based on industry-scale Facebook data centers, the general insights regarding holistic analysis, embodied carbon, and hardware-software co-design are broadly applicable. However, the specific breakdown of carbon sources and the effectiveness of certain optimizations might vary with different infrastructure scales, energy mixes, and ML workloads \\cite{wu2021t2c}. The paper also notes that shifting to carbon-free energy may not scale to all use cases due to geographical and material limitations, and on-device learning faces limited renewable energy access at the edge \\cite{wu2021t2c}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the technical understanding of AI's environmental impact by providing the first holistic, end-to-end analysis that integrates both operational and embodied carbon across the entire ML pipeline and hardware life cycle \\cite{wu2021t2c}. It shifts the focus from isolated model training costs to a comprehensive system-level perspective.\n    *   **Potential Impact on Future Research**: It highlights critical, often overlooked, areas for future research, particularly the dominant role of embodied carbon and the need for hardware-software co-design for sustainable AI. It inspires the community to develop environmentally-responsible AI by focusing on data efficiency, resource-efficient algorithms, sustainable hardware, and the establishment of standardized metrics and best practices \\cite{wu2021t2c}.",
      "keywords": [
        "AI carbon footprint",
        "holistic framework",
        "operational carbon footprint",
        "embodied carbon footprint",
        "ML pipeline",
        "hardware life cycle",
        "hardware-software co-design",
        "at-scale optimization",
        "end-to-end carbon analysis",
        "carbon footprint reduction",
        "industry-scale ML deployments",
        "sustainable AI",
        "Life Cycle Analysis (LCA)",
        "resource-efficient architectures"
      ],
      "paper_type": "based on the abstract and introduction:\n\n1.  **survey**: the paper explores an impact and charts directions, but it doesn't primarily review existing literature comprehensively or discuss classification schemes of prior work.\n2.  **technical**: it discusses hardware-software design and optimization, but its main contribution isn't proposing a *new* method, algorithm, or system. it analyzes existing and potential solutions.\n3.  **theoretical**: there is no mention of mathematical analysis, proofs, or formal models.\n4.  **empirical**: the paper presents data (e.g., growth trends, carbon footprint analysis from facebook's use cases) and characterizes impacts. this is a strong component, but it's used to support a larger argument.\n5.  **case_study**: the paper heavily relies on \"industry-scale machine learning use cases at facebook\" and \"industry experience and lessons learned\" to illustrate its points and provide data. this is a very strong element.\n6.  **position**: the abstract mentions \"share the key challenges and chart out important development directions\" and \"inspire the community to advance the ﬁeld of ai in an environmentally-responsible manner.\" the introduction reinforces this with \"present the challenges and opportunities to designing sustainable ai computing\" and \"chart out opportunities and important development directions.\" sections like \"a sustainability mindset for ai\" and \"call-to-action\" (mentioned in the introduction) are hallmarks of a position paper. the paper argues for a viewpoint (sustainable ai) and outlines future directions.\n7.  **short**: the content provided is substantial, indicating it's not a brief communication.\n\nwhile the paper contains strong **empirical** and **case_study** elements (using facebook's data and experience), these serve to build and support a broader argument. the overarching goal, as stated in the abstract and introduction, is to \"explore,\" \"characterize,\" \"present an end-to-end analysis,\" \"share key challenges,\" and \"chart out important development directions\" to \"inspire the community to advance the ﬁeld of ai in an environmentally-responsible manner.\" this aligns most closely with arguing for a viewpoint and future direction.\n\ntherefore, the best classification is **position**."
    },
    "file_name": "2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0.pdf"
  },
  {
    "success": true,
    "doc_id": "ffb1f14b9f33b0501cc00c965f93ce3d",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a0650855634a156db81a01dcdceff931e9f1ac04.pdf",
    "citation_key": "laird2012r6c",
    "metadata": {
      "title": "The Soar Cognitive Architecture",
      "authors": [
        "J. Laird"
      ],
      "published_date": "2012",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a0650855634a156db81a01dcdceff931e9f1ac04.pdf",
      "venue": "",
      "citationCount": 1038,
      "score": 79.84615384615385,
      "summary": "",
      "keywords": []
    },
    "file_name": "a0650855634a156db81a01dcdceff931e9f1ac04.pdf"
  },
  {
    "success": true,
    "doc_id": "d29f8123a4d8adea3edd1488b066a947",
    "summary": "Here's a focused summary of the paper \"Toward Trustworthy AI Development: Mechanisms for Supporting Veriﬁable Claims\" \\cite{brundage2020dn4} for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical gap between the widespread adoption of AI ethics principles and the actual ability to ensure and demonstrate responsible AI development. Existing norms and principles are often non-binding, difficult to translate into actionable steps, and lack mechanisms for external verification, leading to a deficit of trust and accusations of \"ethics washing\" \\cite{brundage2020dn4}.\n    *   **Importance and Challenge**: Rapid AI progress has led to large-scale impacts, raising concerns about bias, privacy loss, safety, and disinformation. Ensuring trustworthiness is paramount for public acceptance and effective governance. The challenge lies in moving beyond abstract principles to concrete, falsifiable claims about AI systems and development processes, supported by verifiable evidence, across diverse technical and organizational contexts \\cite{brundage2020dn4}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work acknowledges the significant effort in articulating AI ethics principles but positions itself as a necessary evolution *beyond* these principles. It draws parallels with established safety infrastructures in other high-stakes domains (e.g., airline safety) to emphasize the need for robust, verifiable mechanisms in AI \\cite{brundage2020dn4}.\n    *   **Limitations of Previous Solutions**: High-level ethics principles, while important, are often vague, non-binding, and lack mechanisms for independent monitoring or enforcement. This makes it difficult for external stakeholders (users, regulators, civil society) to assess developer claims, fostering skepticism about self-regulation and hindering accountability \\cite{brundage2020dn4}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a comprehensive \"toolbox\" of mechanisms, categorized into Institutional, Software, and Hardware, designed to enable the making and assessment of *verifiable claims* about AI systems and their development processes \\cite{brundage2020dn4}. A verifiable claim is defined as a falsifiable statement for which evidence and arguments can be brought to bear on its likelihood of being true.\n    *   **Novelty**: The innovation lies in systematically articulating and categorizing these diverse mechanisms, emphasizing their role in enabling *falsifiable claims* and *external scrutiny*, rather than just internal adherence to principles. It provides a structured framework for bridging the gap between abstract ethical guidelines and concrete, actionable steps for demonstrating trustworthiness, highlighting the interconnectedness of these sociotechnical mechanisms \\cite{brundage2020dn4}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Methods/Techniques (Software)**:\n        *   **Audit Trails**: Recommends developing requirements for audit trails in safety-critical AI applications to capture crucial information about the development and deployment lifecycle, enabling accountability and post-hoc analysis of incidents \\cite{brundage2020dn4}.\n        *   **Interpretability**: Advocates for research into interpretability methods specifically focused on supporting risk assessment and auditing, moving beyond mere explanation to actionable insights for verification purposes \\cite{brundage2020dn4}.\n        *   **Privacy-Preserving Machine Learning (PPML)**: Calls for the development, sharing, and use of PPML tool suites that include measures of performance against common standards, thereby making privacy commitments more robust and verifiable \\cite{brundage2020dn4}.\n    *   **System Design/Architectural Innovations (Hardware)**:\n        *   **Secure Hardware for ML**: Proposes developing hardware security features for AI accelerators or establishing best practices for using secure enclaves on commodity hardware in ML contexts, to significantly increase the verifiability of privacy and security claims \\cite{brundage2020dn4}.\n        *   **High-Precision Compute Measurement**: Recommends detailed estimation and reporting of computing power involved in AI projects to improve transparency and comparability of claims about resource usage, which can be relevant for assessing environmental impact or strategic capabilities \\cite{brundage2020dn4}.\n        *   **Compute Support for Academia**: Advocates for increased government funding for academic computing resources to empower independent researchers to verify claims made by industry, particularly for large-scale AI systems \\cite{brundage2020dn4}.\n    *   **Institutional Innovations**: Proposes mechanisms like third-party auditing, red teaming exercises, bias and safety bounties, and sharing of AI incidents to create external pressure, incentives, and transparency for verifiable claims \\cite{brundage2020dn4}.\n\n*   **5. Experimental Validation**\n    *   The paper is a conceptual and policy-oriented report, not a traditional research paper presenting novel algorithms or systems with empirical results.\n    *   It *does not present experimental validation* in the typical sense (e.g., benchmarks, performance metrics of a new algorithm or system).\n    *   Instead, its \"validation\" stems from:\n        *   **Problem Identification**: Identifying a critical gap in current AI development practices, supported by references to existing concerns and studies \\cite{brundage2020dn4}.\n        *   **Mechanism Proposal**: Drawing on best practices from other fields (e.g., information security, formal verification) and existing concepts (e.g., red teaming, bounties) to propose actionable steps \\cite{brundage2020dn4}.\n        *   **Expert Consensus**: The report itself is a product of a workshop and collaboration among a large group of experts from diverse institutions, lending weight to the identified problems and proposed solutions \\cite{brundage2020dn4}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The report acknowledges that not all important claims about AI can be fully verified, and that verification alone is insufficient without robust oversight agencies aligning developer incentives with public interest \\cite{brundage2020dn4}. It clarifies that \"verifiable\" is used in a broader sense than \"formal verification\" unless specified. The proposed mechanisms are presented as an \"incremental step.\"\n    *   **Scope of Applicability**: The mechanisms are broadly applicable to various stakeholders (AI developers, users, regulators, civil society, academia) and across different stages of AI development and deployment. The primary focus is on providing evidence about the safety, security, fairness, and privacy protection of AI systems \\cite{brundage2020dn4}.\n\n*   **7. Technical Significance**\n    *   **Advance State-of-the-Art**: The paper significantly advances the discourse on responsible AI by shifting the focus from abstract ethical principles to concrete, actionable, and *verifiable mechanisms* \\cite{brundage2020dn4}. It provides a structured, sociotechnical framework (Institutional, Software, Hardware) for building trust and accountability in AI development.\n    *   **Potential Impact**: It offers a \"robust toolbox\" for AI developers to substantiate their claims and for external stakeholders to scrutinize them, fostering greater transparency and accountability. This framework can inform future policy, industry best practices, and research directions in critical areas like AI safety, security, interpretability, and privacy-preserving machine learning, by highlighting specific technical and organizational gaps that need to be addressed to achieve trustworthy AI \\cite{brundage2020dn4}.",
    "intriguing_abstract": "The rapid proliferation of AI has sparked a critical crisis of trust, as abstract ethical principles often fail to translate into demonstrable, responsible development, leading to accusations of \"ethics washing.\" This paper confronts this challenge head-on, proposing a groundbreaking shift from vague guidelines to a robust framework for *verifiable claims* about AI systems and their development processes. We introduce a comprehensive sociotechnical \"toolbox\" of Institutional, Software, and Hardware mechanisms designed to enable external scrutiny and accountability.\n\nOur novel contributions include advocating for rigorous *audit trails*, interpretability methods tailored for risk assessment, and the deployment of *privacy-preserving machine learning* tools. We also propose innovations like *secure hardware* for ML and high-precision compute measurement, alongside institutional mechanisms such as third-party auditing and red teaming. By systematically articulating these diverse, interconnected mechanisms, this work provides a crucial blueprint for bridging the gap between ethical aspirations and concrete, falsifiable evidence. This framework is essential for fostering transparency, building public trust, and guiding future research and policy in *trustworthy AI*, *AI safety*, *security*, and *fairness*.",
    "keywords": [
      "Trustworthy AI Development",
      "Verifiable Claims",
      "AI Ethics Principles",
      "Sociotechnical Mechanisms",
      "External Scrutiny",
      "Audit Trails",
      "Interpretability for Risk Assessment",
      "Privacy-Preserving Machine Learning (PPML)",
      "Secure Hardware for ML",
      "Third-Party Auditing",
      "Accountability and Transparency",
      "Falsifiable Claims",
      "AI Safety and Security",
      "Structured Framework"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/62c3142956d54db158d190ce691e3c13e7897412.pdf",
    "citation_key": "brundage2020dn4",
    "metadata": {
      "title": "Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims",
      "authors": [
        "Miles Brundage",
        "S. Avin",
        "Jasmine Wang",
        "Haydn Belfield",
        "Gretchen Krueger",
        "Gillian K. Hadfield",
        "Heidy Khlaaf",
        "Jingying Yang",
        "H. Toner",
        "Ruth Fong",
        "Tegan Maharaj",
        "Pang Wei Koh",
        "Sara Hooker",
        "Jade Leung",
        "Andrew Trask",
        "Emma Bluemke",
        "Jonathan Lebensbold",
        "Cullen O'Keefe",
        "Mark Koren",
        "T. Ryffel",
        "JB Rubinovitz",
        "T. Besiroglu",
        "F. Carugati",
        "Jack Clark",
        "P. Eckersley",
        "Sarah de Haas",
        "Maritza L. Johnson",
        "B. Laurie",
        "A. Ingerman",
        "Igor Krawczuk",
        "Amanda Askell",
        "Rosario Cammarota",
        "A. Lohn",
        "David Krueger",
        "C. Stix",
        "Peter Henderson",
        "L. Graham",
        "Carina E. A. Prunkl",
        "Bianca Martin",
        "Elizabeth Seger",
        "Noa Zilberman",
        "Se'an 'O h'Eigeartaigh",
        "F. Kroeger",
        "Girish Sastry",
        "R. Kagan",
        "Adrian Weller",
        "Brian Tse",
        "Elizabeth Barnes",
        "A. Dafoe",
        "P. Scharre",
        "Ariel Herbert-Voss",
        "Martijn Rasser",
        "Shagun Sodhani",
        "Carrick Flynn",
        "T. Gilbert",
        "Lisa Dyer",
        "Saif Khan",
        "Yoshua Bengio",
        "Markus Anderljung"
      ],
      "published_date": "2020",
      "abstract": "With the recent wave of progress in artificial intelligence (AI) has come a growing awareness of the large-scale impacts of AI systems, and recognition that existing regulations and norms in industry and academia are insufficient to ensure responsible AI development. In order for AI developers to earn trust from system users, customers, civil society, governments, and other stakeholders that they are building AI responsibly, they will need to make verifiable claims to which they can be held accountable. Those outside of a given organization also need effective means of scrutinizing such claims. This report suggests various steps that different stakeholders can take to improve the verifiability of claims made about AI systems and their associated development processes, with a focus on providing evidence about the safety, security, fairness, and privacy protection of AI systems. We analyze ten mechanisms for this purpose--spanning institutions, software, and hardware--and make recommendations aimed at implementing, exploring, or improving those mechanisms.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/62c3142956d54db158d190ce691e3c13e7897412.pdf",
      "venue": "arXiv.org",
      "citationCount": 379,
      "score": 75.8,
      "summary": "Here's a focused summary of the paper \"Toward Trustworthy AI Development: Mechanisms for Supporting Veriﬁable Claims\" \\cite{brundage2020dn4} for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical gap between the widespread adoption of AI ethics principles and the actual ability to ensure and demonstrate responsible AI development. Existing norms and principles are often non-binding, difficult to translate into actionable steps, and lack mechanisms for external verification, leading to a deficit of trust and accusations of \"ethics washing\" \\cite{brundage2020dn4}.\n    *   **Importance and Challenge**: Rapid AI progress has led to large-scale impacts, raising concerns about bias, privacy loss, safety, and disinformation. Ensuring trustworthiness is paramount for public acceptance and effective governance. The challenge lies in moving beyond abstract principles to concrete, falsifiable claims about AI systems and development processes, supported by verifiable evidence, across diverse technical and organizational contexts \\cite{brundage2020dn4}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work acknowledges the significant effort in articulating AI ethics principles but positions itself as a necessary evolution *beyond* these principles. It draws parallels with established safety infrastructures in other high-stakes domains (e.g., airline safety) to emphasize the need for robust, verifiable mechanisms in AI \\cite{brundage2020dn4}.\n    *   **Limitations of Previous Solutions**: High-level ethics principles, while important, are often vague, non-binding, and lack mechanisms for independent monitoring or enforcement. This makes it difficult for external stakeholders (users, regulators, civil society) to assess developer claims, fostering skepticism about self-regulation and hindering accountability \\cite{brundage2020dn4}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a comprehensive \"toolbox\" of mechanisms, categorized into Institutional, Software, and Hardware, designed to enable the making and assessment of *verifiable claims* about AI systems and their development processes \\cite{brundage2020dn4}. A verifiable claim is defined as a falsifiable statement for which evidence and arguments can be brought to bear on its likelihood of being true.\n    *   **Novelty**: The innovation lies in systematically articulating and categorizing these diverse mechanisms, emphasizing their role in enabling *falsifiable claims* and *external scrutiny*, rather than just internal adherence to principles. It provides a structured framework for bridging the gap between abstract ethical guidelines and concrete, actionable steps for demonstrating trustworthiness, highlighting the interconnectedness of these sociotechnical mechanisms \\cite{brundage2020dn4}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Methods/Techniques (Software)**:\n        *   **Audit Trails**: Recommends developing requirements for audit trails in safety-critical AI applications to capture crucial information about the development and deployment lifecycle, enabling accountability and post-hoc analysis of incidents \\cite{brundage2020dn4}.\n        *   **Interpretability**: Advocates for research into interpretability methods specifically focused on supporting risk assessment and auditing, moving beyond mere explanation to actionable insights for verification purposes \\cite{brundage2020dn4}.\n        *   **Privacy-Preserving Machine Learning (PPML)**: Calls for the development, sharing, and use of PPML tool suites that include measures of performance against common standards, thereby making privacy commitments more robust and verifiable \\cite{brundage2020dn4}.\n    *   **System Design/Architectural Innovations (Hardware)**:\n        *   **Secure Hardware for ML**: Proposes developing hardware security features for AI accelerators or establishing best practices for using secure enclaves on commodity hardware in ML contexts, to significantly increase the verifiability of privacy and security claims \\cite{brundage2020dn4}.\n        *   **High-Precision Compute Measurement**: Recommends detailed estimation and reporting of computing power involved in AI projects to improve transparency and comparability of claims about resource usage, which can be relevant for assessing environmental impact or strategic capabilities \\cite{brundage2020dn4}.\n        *   **Compute Support for Academia**: Advocates for increased government funding for academic computing resources to empower independent researchers to verify claims made by industry, particularly for large-scale AI systems \\cite{brundage2020dn4}.\n    *   **Institutional Innovations**: Proposes mechanisms like third-party auditing, red teaming exercises, bias and safety bounties, and sharing of AI incidents to create external pressure, incentives, and transparency for verifiable claims \\cite{brundage2020dn4}.\n\n*   **5. Experimental Validation**\n    *   The paper is a conceptual and policy-oriented report, not a traditional research paper presenting novel algorithms or systems with empirical results.\n    *   It *does not present experimental validation* in the typical sense (e.g., benchmarks, performance metrics of a new algorithm or system).\n    *   Instead, its \"validation\" stems from:\n        *   **Problem Identification**: Identifying a critical gap in current AI development practices, supported by references to existing concerns and studies \\cite{brundage2020dn4}.\n        *   **Mechanism Proposal**: Drawing on best practices from other fields (e.g., information security, formal verification) and existing concepts (e.g., red teaming, bounties) to propose actionable steps \\cite{brundage2020dn4}.\n        *   **Expert Consensus**: The report itself is a product of a workshop and collaboration among a large group of experts from diverse institutions, lending weight to the identified problems and proposed solutions \\cite{brundage2020dn4}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The report acknowledges that not all important claims about AI can be fully verified, and that verification alone is insufficient without robust oversight agencies aligning developer incentives with public interest \\cite{brundage2020dn4}. It clarifies that \"verifiable\" is used in a broader sense than \"formal verification\" unless specified. The proposed mechanisms are presented as an \"incremental step.\"\n    *   **Scope of Applicability**: The mechanisms are broadly applicable to various stakeholders (AI developers, users, regulators, civil society, academia) and across different stages of AI development and deployment. The primary focus is on providing evidence about the safety, security, fairness, and privacy protection of AI systems \\cite{brundage2020dn4}.\n\n*   **7. Technical Significance**\n    *   **Advance State-of-the-Art**: The paper significantly advances the discourse on responsible AI by shifting the focus from abstract ethical principles to concrete, actionable, and *verifiable mechanisms* \\cite{brundage2020dn4}. It provides a structured, sociotechnical framework (Institutional, Software, Hardware) for building trust and accountability in AI development.\n    *   **Potential Impact**: It offers a \"robust toolbox\" for AI developers to substantiate their claims and for external stakeholders to scrutinize them, fostering greater transparency and accountability. This framework can inform future policy, industry best practices, and research directions in critical areas like AI safety, security, interpretability, and privacy-preserving machine learning, by highlighting specific technical and organizational gaps that need to be addressed to achieve trustworthy AI \\cite{brundage2020dn4}.",
      "keywords": [
        "Trustworthy AI Development",
        "Verifiable Claims",
        "AI Ethics Principles",
        "Sociotechnical Mechanisms",
        "External Scrutiny",
        "Audit Trails",
        "Interpretability for Risk Assessment",
        "Privacy-Preserving Machine Learning (PPML)",
        "Secure Hardware for ML",
        "Third-Party Auditing",
        "Accountability and Transparency",
        "Falsifiable Claims",
        "AI Safety and Security",
        "Structured Framework"
      ],
      "paper_type": "based on the abstract and introduction provided, this paper is a **survey**.\n\nhere's why:\n\n1.  **reviews existing literature/concepts comprehensively:** the paper systematically introduces and explores various \"mechanisms\" (institutional, software, and hardware) for supporting verifiable claims in ai development. it discusses concepts like third-party auditing, red team exercises, bias bounties, incident sharing, audit trails, interpretability, privacy-preserving machine learning, secure hardware, and compute measurement. for each, it outlines problems, existing approaches (often referencing other works), and then provides recommendations. this comprehensive overview of existing and emerging practices aligns with a survey.\n2.  **introduction discusses literature organization/classification schemes:** the table of contents explicitly categorizes the content into \"institutional mechanisms,\" \"software mechanisms,\" and \"hardware mechanisms,\" with detailed subsections under each. this clear organizational structure is a hallmark of a survey paper that aims to classify and present a broad field of knowledge.\n3.  **focus on analysis and recommendations based on existing knowledge:** while the paper makes \"recommendations\" (which could lean towards a position paper), these recommendations are consistently framed as next steps for adopting, standardizing, or further researching the *already discussed* mechanisms. the paper's primary goal is to \"flesh out\" these mechanisms and inform dialogue, rather than to propose a single, novel argument or technical solution. it synthesizes current challenges and potential solutions.\n\nthe paper does not present new methods or algorithms (technical), mathematical proofs (theoretical), data-driven experiments (empirical), or a detailed analysis of a single application (case study). while it takes a stance on the importance of verifiable claims and suggests future directions, its extensive categorization and discussion of a wide array of existing and proposed mechanisms make \"survey\" the most appropriate classification."
    },
    "file_name": "62c3142956d54db158d190ce691e3c13e7897412.pdf"
  },
  {
    "success": true,
    "doc_id": "90c56e45147544dcdb002da40a96003d",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific technical problem:** The paper addresses the lack of easy and reliable access to measurements of the greenhouse gas impact of AI workloads, particularly when run on cloud instances \\cite{dodge2022uqb}. This prevents data scientists and cloud users from developing actionable strategies to minimize emissions.\n    *   **Importance and challenge:** The rapid growth of AI technologies incurs significant energy costs and a commensurate carbon footprint. Current methods for estimating AI emissions are often coarse or rely on non-public data, and cloud providers typically do not present fine-grained, actionable carbon intensity information to users \\cite{dodge2022uqb}.\n\n*   **Related Work & Positioning**\n    *   **Relation to existing approaches:** This work builds upon prior research quantifying AI emissions (e.g., Strubell et al. \\cite{strubell2019energy}, Patterson et al. \\cite{patterson2021carbon}) and tools for carbon tracking like Code Carbon \\cite{lacoste2019codecarbon} and Carbon Tracker \\cite{anthony2020carbontracker} \\cite{dodge2022uqb}. It also acknowledges efforts by cloud providers to offer tools for choosing regions with smaller carbon footprints \\cite{dodge2022uqb}.\n    *   **Limitations of previous solutions:** Previous work often relies on coarse measures (e.g., average CO2 emissions for a region) or post-hoc analyses. Existing tools may not support fine-grained, real-time carbon tracking on cloud instances. Crucially, many \"carbon-neutral\" claims by cloud providers are based on market-based offsets (e.g., RECs, PPAs) rather than actual grid emissions signals, which does not provide actionable information for *reducing* emissions \\cite{dodge2022uqb}.\n\n*   **Technical Approach & Innovation**\n    *   **Core technical method/algorithm:** The paper proposes a framework for measuring Software Carbon Intensity (SCI) for cloud instances, focusing on operational carbon emissions. The SCI is calculated as `SCI = (E * I + M) per R`, where `E` is energy consumed (kWh), `I` is location-based and *time-specific marginal* carbon emissions (gCO2eq/kWh), `M` is embodied carbon (deferred in this work), and `R` is the functional unit (e.g., one ML training job) \\cite{dodge2022uqb}. The approach specifically focuses on GPU energy consumption (`E`) due to its dominance in AI workloads (empirically shown to be ~74% of total energy in their experiment) and ease of measurement in cloud environments \\cite{dodge2022uqb}. It advocates for a \"consequential\" carbon accounting approach, using marginal emissions data to quantify the change in emissions caused by specific decisions.\n    *   **Novelty:** This work introduces the first tool to estimate the *real-time* CO2 emissions impact of cloud instances using *location-based and time-specific marginal emissions data* \\cite{dodge2022uqb}. It is also the first to systematically explore the impact of *time of day* on operational software carbon intensity for AI workloads, enabling potential temporal shifting of computation to mitigate emissions \\cite{dodge2022uqb}.\n\n*   **Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques:**\n        *   A practical framework for calculating Software Carbon Intensity (SCI) for cloud AI workloads, emphasizing operational emissions (`O = E * I`) using *marginal* carbon intensity data, which provides more actionable insights than average data \\cite{dodge2022uqb}.\n        *   A methodology that prioritizes GPU energy consumption for operational emissions measurement in AI cloud instances, justified by empirical evidence of its dominant energy draw \\cite{dodge2022uqb}.\n    *   **Theoretical insights or analysis:** Advocates for a \"consequential\" carbon accounting approach, arguing that it provides more actionable information for emissions reduction compared to \"attributional\" accounting or market-based carbon offsets \\cite{dodge2022uqb}.\n\n*   **Experimental Validation**\n    *   **Experiments conducted:**\n        *   Measured operational software carbon intensity for a range of modern NLP and computer vision models, including pretraining a 6.1 billion parameter language model, on the Microsoft Azure cloud platform \\cite{dodge2022uqb}.\n        *   Evaluated three strategies for emissions reduction: choosing different geographic regions, running instances at different times of day, and dynamically pausing instances based on carbon intensity thresholds \\cite{dodge2022uqb}.\n        *   Conducted an experiment to confirm the dominance of GPU energy consumption in AI workloads, training a BERT-base model and measuring power draw from GPU, CPU, and DRAM \\cite{dodge2022uqb}.\n    *   **Key performance metrics and comparison results:**\n        *   Confirmed that the geographic region of the data center significantly impacts carbon intensity, with region choice offering the largest operational emissions reduction potential \\cite{dodge2022uqb}.\n        *   Presented novel results demonstrating that the *time of day* also has a meaningful impact on operational software carbon intensity \\cite{dodge2022uqb}.\n        *   The BERT-base experiment showed the GPU accounted for approximately 74% of the total electricity consumption, validating the focus on GPU measurement \\cite{dodge2022uqb}.\n\n*   **Limitations & Scope**\n    *   **Technical limitations or assumptions:** The current tool focuses solely on GPU electricity consumption, acknowledging that this is an underestimate of total data center energy use (e.g., it excludes CPUs, RAM, storage, networking, and HVAC) \\cite{dodge2022uqb}. The measurement and accounting for embodied carbon (`M`) are deferred to future work \\cite{dodge2022uqb}.\n    *   **Scope of applicability:** The framework and tool are primarily applicable to AI workloads running on cloud computing platforms, with experiments conducted specifically on Microsoft Azure \\cite{dodge2022uqb}.\n\n*   **Technical Significance**\n    *   **Advances the technical state-of-the-art:** This paper significantly advances the state-of-the-art by providing a practical, real-time, and fine-grained method for measuring and acting upon the carbon intensity of AI workloads in the cloud. It moves beyond coarse estimates and market-based offsets by leveraging marginal, time- and location-specific grid emissions data \\cite{dodge2022uqb}. The identification of time-of-day as a significant factor for emissions reduction is a novel contribution.\n    *   **Potential impact on future research:** The work empowers ML practitioners and cloud users to make informed, carbon-aware decisions by choosing optimal regions and times for computation. It lays crucial groundwork for the development of automated carbon-aware job scheduling systems in cloud environments and encourages cloud providers to expose SCI information, fostering a more environmentally responsible AI ecosystem \\cite{dodge2022uqb}.",
    "intriguing_abstract": "The escalating energy demands of AI workloads in cloud environments pose a significant, yet often opaque, carbon footprint challenge. Current methods for quantifying these emissions are typically coarse, lacking the real-time, actionable insights needed for effective mitigation. This paper introduces a novel framework and the first tool designed to measure the **Software Carbon Intensity (SCI)** of cloud AI instances by leveraging *location-based and time-specific marginal emissions data*. We move beyond average grid intensity and market-based offsets, advocating for a **consequential carbon accounting** approach that empowers users to make informed decisions.\n\nOur methodology prioritizes **GPU energy consumption**, empirically shown to dominate AI workload power draw, and systematically explores the impact of both geographic region and, critically, *time of day* on **operational emissions**. Through extensive experiments on modern NLP and computer vision models on a major cloud platform, we demonstrate that **temporal shifting** of computation can yield meaningful reductions in carbon intensity. This work provides practitioners with unprecedented visibility into their AI's environmental impact, paving the way for **carbon-aware job scheduling** and fostering a truly sustainable AI ecosystem.",
    "keywords": [
      "AI workloads carbon footprint",
      "Cloud computing emissions",
      "Software Carbon Intensity (SCI)",
      "Operational carbon emissions",
      "Location and time-specific marginal emissions data",
      "Real-time CO2 emissions estimation",
      "GPU energy consumption measurement",
      "Consequential carbon accounting",
      "Temporal shifting of computation",
      "Emissions reduction strategies",
      "Carbon-aware job scheduling"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/00df5cf0d83c48657d453ab8083d8805a67f744f.pdf",
    "citation_key": "dodge2022uqb",
    "metadata": {
      "title": "Measuring the Carbon Intensity of AI in Cloud Instances",
      "authors": [
        "Jesse Dodge",
        "Taylor Prewitt",
        "Rémi Tachet des Combes",
        "Erika Odmark",
        "Roy Schwartz",
        "Emma Strubell",
        "A. Luccioni",
        "Noah A. Smith",
        "Nicole DeCario",
        "Will Buchanan"
      ],
      "published_date": "2022",
      "abstract": "The advent of cloud computing has provided people around the world with unprecedented access to computational power and enabled rapid growth in technologies such as machine learning, the computational demands of which incur a high energy cost and a commensurate carbon footprint. As a result, recent scholarship has called for better estimates of the greenhouse gas impact of AI: data scientists today do not have easy or reliable access to measurements of this information, which precludes development of actionable tactics. We argue that cloud providers presenting information about software carbon intensity to users is a fundamental stepping stone towards minimizing emissions. In this paper, we provide a framework for measuring software carbon intensity, and propose to measure operational carbon emissions by using location-based and time-specific marginal emissions data per energy unit. We provide measurements of operational software carbon intensity for a set of modern models covering natural language processing and computer vision applications, and a wide range of model sizes, including pretraining of a 6.1 billion parameter language model. We then evaluate a suite of approaches for reducing emissions on the Microsoft Azure cloud compute platform: using cloud instances in different geographic regions, using cloud instances at different times of day, and dynamically pausing cloud instances when the marginal carbon intensity is above a certain threshold. We confirm previous results that the geographic region of the data center plays a significant role in the carbon intensity for a given cloud instance, and find that choosing an appropriate region can have the largest operational emissions reduction impact. We also present new results showing that the time of day has meaningful impact on operational software carbon intensity.Finally, we conclude with recommendations for how machine learning practitioners can use software carbon intensity information to reduce environmental impact.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/00df5cf0d83c48657d453ab8083d8805a67f744f.pdf",
      "venue": "Conference on Fairness, Accountability and Transparency",
      "citationCount": 224,
      "score": 74.66666666666666,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific technical problem:** The paper addresses the lack of easy and reliable access to measurements of the greenhouse gas impact of AI workloads, particularly when run on cloud instances \\cite{dodge2022uqb}. This prevents data scientists and cloud users from developing actionable strategies to minimize emissions.\n    *   **Importance and challenge:** The rapid growth of AI technologies incurs significant energy costs and a commensurate carbon footprint. Current methods for estimating AI emissions are often coarse or rely on non-public data, and cloud providers typically do not present fine-grained, actionable carbon intensity information to users \\cite{dodge2022uqb}.\n\n*   **Related Work & Positioning**\n    *   **Relation to existing approaches:** This work builds upon prior research quantifying AI emissions (e.g., Strubell et al. \\cite{strubell2019energy}, Patterson et al. \\cite{patterson2021carbon}) and tools for carbon tracking like Code Carbon \\cite{lacoste2019codecarbon} and Carbon Tracker \\cite{anthony2020carbontracker} \\cite{dodge2022uqb}. It also acknowledges efforts by cloud providers to offer tools for choosing regions with smaller carbon footprints \\cite{dodge2022uqb}.\n    *   **Limitations of previous solutions:** Previous work often relies on coarse measures (e.g., average CO2 emissions for a region) or post-hoc analyses. Existing tools may not support fine-grained, real-time carbon tracking on cloud instances. Crucially, many \"carbon-neutral\" claims by cloud providers are based on market-based offsets (e.g., RECs, PPAs) rather than actual grid emissions signals, which does not provide actionable information for *reducing* emissions \\cite{dodge2022uqb}.\n\n*   **Technical Approach & Innovation**\n    *   **Core technical method/algorithm:** The paper proposes a framework for measuring Software Carbon Intensity (SCI) for cloud instances, focusing on operational carbon emissions. The SCI is calculated as `SCI = (E * I + M) per R`, where `E` is energy consumed (kWh), `I` is location-based and *time-specific marginal* carbon emissions (gCO2eq/kWh), `M` is embodied carbon (deferred in this work), and `R` is the functional unit (e.g., one ML training job) \\cite{dodge2022uqb}. The approach specifically focuses on GPU energy consumption (`E`) due to its dominance in AI workloads (empirically shown to be ~74% of total energy in their experiment) and ease of measurement in cloud environments \\cite{dodge2022uqb}. It advocates for a \"consequential\" carbon accounting approach, using marginal emissions data to quantify the change in emissions caused by specific decisions.\n    *   **Novelty:** This work introduces the first tool to estimate the *real-time* CO2 emissions impact of cloud instances using *location-based and time-specific marginal emissions data* \\cite{dodge2022uqb}. It is also the first to systematically explore the impact of *time of day* on operational software carbon intensity for AI workloads, enabling potential temporal shifting of computation to mitigate emissions \\cite{dodge2022uqb}.\n\n*   **Key Technical Contributions**\n    *   **Novel algorithms, methods, or techniques:**\n        *   A practical framework for calculating Software Carbon Intensity (SCI) for cloud AI workloads, emphasizing operational emissions (`O = E * I`) using *marginal* carbon intensity data, which provides more actionable insights than average data \\cite{dodge2022uqb}.\n        *   A methodology that prioritizes GPU energy consumption for operational emissions measurement in AI cloud instances, justified by empirical evidence of its dominant energy draw \\cite{dodge2022uqb}.\n    *   **Theoretical insights or analysis:** Advocates for a \"consequential\" carbon accounting approach, arguing that it provides more actionable information for emissions reduction compared to \"attributional\" accounting or market-based carbon offsets \\cite{dodge2022uqb}.\n\n*   **Experimental Validation**\n    *   **Experiments conducted:**\n        *   Measured operational software carbon intensity for a range of modern NLP and computer vision models, including pretraining a 6.1 billion parameter language model, on the Microsoft Azure cloud platform \\cite{dodge2022uqb}.\n        *   Evaluated three strategies for emissions reduction: choosing different geographic regions, running instances at different times of day, and dynamically pausing instances based on carbon intensity thresholds \\cite{dodge2022uqb}.\n        *   Conducted an experiment to confirm the dominance of GPU energy consumption in AI workloads, training a BERT-base model and measuring power draw from GPU, CPU, and DRAM \\cite{dodge2022uqb}.\n    *   **Key performance metrics and comparison results:**\n        *   Confirmed that the geographic region of the data center significantly impacts carbon intensity, with region choice offering the largest operational emissions reduction potential \\cite{dodge2022uqb}.\n        *   Presented novel results demonstrating that the *time of day* also has a meaningful impact on operational software carbon intensity \\cite{dodge2022uqb}.\n        *   The BERT-base experiment showed the GPU accounted for approximately 74% of the total electricity consumption, validating the focus on GPU measurement \\cite{dodge2022uqb}.\n\n*   **Limitations & Scope**\n    *   **Technical limitations or assumptions:** The current tool focuses solely on GPU electricity consumption, acknowledging that this is an underestimate of total data center energy use (e.g., it excludes CPUs, RAM, storage, networking, and HVAC) \\cite{dodge2022uqb}. The measurement and accounting for embodied carbon (`M`) are deferred to future work \\cite{dodge2022uqb}.\n    *   **Scope of applicability:** The framework and tool are primarily applicable to AI workloads running on cloud computing platforms, with experiments conducted specifically on Microsoft Azure \\cite{dodge2022uqb}.\n\n*   **Technical Significance**\n    *   **Advances the technical state-of-the-art:** This paper significantly advances the state-of-the-art by providing a practical, real-time, and fine-grained method for measuring and acting upon the carbon intensity of AI workloads in the cloud. It moves beyond coarse estimates and market-based offsets by leveraging marginal, time- and location-specific grid emissions data \\cite{dodge2022uqb}. The identification of time-of-day as a significant factor for emissions reduction is a novel contribution.\n    *   **Potential impact on future research:** The work empowers ML practitioners and cloud users to make informed, carbon-aware decisions by choosing optimal regions and times for computation. It lays crucial groundwork for the development of automated carbon-aware job scheduling systems in cloud environments and encourages cloud providers to expose SCI information, fostering a more environmentally responsible AI ecosystem \\cite{dodge2022uqb}.",
      "keywords": [
        "AI workloads carbon footprint",
        "Cloud computing emissions",
        "Software Carbon Intensity (SCI)",
        "Operational carbon emissions",
        "Location and time-specific marginal emissions data",
        "Real-time CO2 emissions estimation",
        "GPU energy consumption measurement",
        "Consequential carbon accounting",
        "Temporal shifting of computation",
        "Emissions reduction strategies",
        "Carbon-aware job scheduling"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the **title** \"measuring the carbon intensity of ai in cloud instances\" directly indicates the paper's focus on a method or system for measurement.\n*   the **introduction** highlights the problem of ai's carbon footprint and critically discusses the limitations of previous approaches (\"coarse measures,\" \"post-hoc analyses\"). this strongly implies that the paper will propose a new or improved method for this measurement.\n*   the criteria for **technical** papers include \"presents new methods, algorithms, or systems\" and \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'\". while the abstract is cut off, the title and the introduction's critique of existing methods strongly suggest the development of a new measurement method.\n\ntherefore, this paper is best classified as **technical**."
    },
    "file_name": "00df5cf0d83c48657d453ab8083d8805a67f744f.pdf"
  },
  {
    "success": true,
    "doc_id": "44e133f04457defbad73ecda9417510e",
    "summary": "Here's a focused summary of the paper \"Do Users Write More Insecure Code with AI Assistants?\" \\cite{perry2022cq5} for a literature review:\n\n### 1. Research Problem & Motivation\n\n*   **Specific Technical Problem**: The paper investigates how users interact with AI code assistants and how these interactions influence the security of the code they write in practical scenarios. While AI assistants are known to produce insecure code in lab settings, the actual security risks introduced by developer usage patterns remained largely unmeasured \\cite{perry2022cq5}.\n*   **Importance and Challenge**: This problem is critical because AI code assistants, despite their potential for productivity gains, raise significant security concerns. Understanding the practical security challenges and how users inadvertently introduce vulnerabilities through their interaction and prompting strategies is essential for designing safer AI-powered development tools \\cite{perry2022cq5}. The study specifically addresses whether AI access leads to more insecure code, if users trust AI for secure code, and how interaction patterns affect vulnerability levels.\n\n### 2. Related Work & Positioning\n\n*   **Relation to Existing Approaches**:\n    *   Previous evaluations of AI code models (e.g., Codex, InCoder) primarily focused on accuracy using static datasets (e.g., HumanEval, MBPP), offering limited insight into security risks in realistic human-developer settings \\cite{perry2022cq5}.\n    *   Prior work on GitHub Copilot's security risks used synthetic prompts, lacking the context of human interaction \\cite{perry2022cq5}.\n    *   Numerous user studies have examined AI assistants for usability, correctness, and productivity, yielding mixed results, but often without a specific focus on security or the potential for misplaced user trust \\cite{perry2022cq5}.\n*   **Limitations of Previous Solutions**:\n    *   The most closely related controlled user study \\cite{21} used an older, less powerful AI model with fixed parameters and focused solely on C language tasks. \\cite{perry2022cq5} highlights that users *do adjust model parameters* and that studying multiple languages is crucial, as results can vary significantly across languages.\n    *   \\cite{21} found inconclusive results regarding the effect of AI assistance on security vulnerabilities, leaving a gap that \\cite{perry2022cq5} addresses with a more extensive analysis of prompt language and query repair strategies.\n\n### 3. Technical Approach & Innovation\n\n*   **Core Technical Method**:\n    *   **User Study Design**: A comprehensive user study involving 47 participants (33 with AI access, 14 control) solving five security-related programming tasks across Python, JavaScript, and C \\cite{perry2022cq5}.\n    *   **Custom Study Instrument**: Development of a standalone desktop application (UI infrastructure) built on React, Redux, and Electron. This UI provided a sandboxed environment for coding, running code, and (for the experiment group) querying the AI assistant, enabling detailed logging of all interactions \\cite{perry2022cq5}.\n    *   **Task Design**: Tasks covered common security mistakes (cryptography, user-controlled data, web vulnerabilities, memory management) typically taught in introductory security courses \\cite{perry2022cq5}.\n    *   **Data Collection & Analysis**: Automated logging of AI queries, responses, final code, and \"acceptances\" of AI-generated code. Screen and audio recordings were also captured. Two authors manually coded all solutions for correctness and security mistakes (categorized as \"Secure,\" \"Partially Secure,\" \"Insecure\") with strong inter-rater reliability (Cohen-Kappa 0.7-0.96 for correctness, 0.68-0.88 for security). Mistakes were attributed to \"AI,\" \"Internet,\" or \"User\" based on detailed logs and recordings \\cite{perry2022cq5}.\n*   **Novelty or Difference**:\n    *   **Focus on Human-AI Interaction for Security**: This work uniquely focuses on the *dynamics of user interaction* with AI assistants and their *direct impact on code security* in a practical, controlled setting, moving beyond mere model output evaluation \\cite{perry2022cq5}.\n    *   **Multi-language and Diverse Security Contexts**: The study's inclusion of multiple programming languages (Python, JavaScript, C) and a variety of security problem types provides a broader and more representative analysis than prior single-language studies \\cite{perry2022cq5}.\n    *   **In-depth Interaction Analysis**: The custom UI and extensive logging allowed for a granular analysis of user behaviors, including prompt engineering, query refinement strategies, and the adjustment of AI model parameters (e.g., temperature), which was not possible in previous work \\cite{perry2022cq5}.\n    *   **Measurement of User Overconfidence**: Explicitly investigates and quantifies the phenomenon of users developing a false sense of security or overconfidence when using AI assistants \\cite{perry2022cq5}.\n\n### 4. Key Technical Contributions\n\n*   **Novel Algorithms, Methods, or Techniques**:\n    *   A robust methodology for conducting user studies on AI code assistant security, including a structured task design, comprehensive data collection (interaction logs, screen/audio recordings), and a rigorous manual analysis procedure with inter-rater reliability checks \\cite{perry2022cq5}.\n    *   A framework for categorizing and attributing security mistakes to specific sources (AI, Internet, User) based on detailed interaction data \\cite{perry2022cq5}.\n*   **System Design or Architectural Innovations**:\n    *   The development and open-sourcing of a custom, flexible study instrument (UI infrastructure) built on React, Redux, and Electron. This tool is designed for easy modification of questions and detailed logging of user-AI interactions, facilitating future research and replication \\cite{perry2022cq5}.\n*   **Theoretical Insights or Analysis**:\n    *   Empirical evidence demonstrating that access to AI assistants can lead to *significantly less secure code* and *increased user overconfidence* regarding security flaws \\cite{perry2022cq5}.\n    *   Identification of specific user interaction patterns that correlate with more secure code (e.g., clear task instructions, providing function declarations, focusing AI on helper functions) and those that exacerbate security problems (e.g., using previous AI outputs as new prompts) \\cite{perry2022cq5}.\n    *   Observation that users who successfully wrote secure code with AI assistants tended to increase the `temperature` parameter and provide more contextual prompts over time, highlighting the importance of prompt engineering skills \\cite{perry2022cq5}.\n\n### 5. Experimental Validation\n\n*   **Experiments Conducted**: A user study with 47 participants (33 experiment group with AI, 14 control group without AI) solving five security-related programming tasks in Python, JavaScript, and C. Tasks included symmetric encryption/decryption, ECDSA signing, sandboxed file access, SQL injection prevention, and integer to string conversion \\cite{perry2022cq5}.\n*   **Key Performance Metrics and Comparison Results**:\n    *   **Code Security**: Participants with AI access wrote *significantly less secure code* than the control group for four out of five tasks \\cite{perry2022cq5}.\n    *   **User Confidence**: Participants with AI access were *more likely to believe they wrote secure code*, indicating a false sense of security, despite their code being less secure \\cite{perry2022cq5}.\n    *   **Interaction Patterns**: Analysis of prompt language and parameter adjustments revealed that specifying task instructions, providing function declarations, and using the AI for helper functions correlated with *more secure code*. Conversely, using previous AI outputs as new prompts often *magnified or replicated security problems* \\cite{perry2022cq5}.\n    *   **Prompt Engineering**: Participants who achieved secure code with AI tended to increase the `temperature` parameter and provide more context in their prompts over time \\cite{perry2022cq5}.\n    *   **Reliability**: Manual coding of solutions achieved strong inter-rater reliability scores (Cohen-Kappa 0.7-0.96 for correctness, 0.68-0.88 for security) \\cite{perry2022cq5}.\n\n### 6. Limitations & Scope\n\n*   **Technical Limitations or Assumptions**:\n    *   The manual attribution of mistakes to \"AI,\" \"Internet,\" or \"User\" involves some subjectivity, despite efforts to ensure consistency and domain expertise \\cite{perry2022cq5}.\n    *   The study used a specific AI assistant model (implied to be based on OpenAI's Codex); results might vary with different or newer models.\n*   **Scope of Applicability**:\n    *   The participant pool, while diverse in experience, consisted of 47 individuals, primarily students, which is a relatively small sample size. While statistical significance was noted, broader generalization requires further studies \\cite{perry2022cq5}.\n    *   Tasks were designed for relatively short completion times, which may not fully capture the complexities of long-term software development cycles \\cite{perry2022cq5}.\n    *   The study focused on a set of common security vulnerabilities; it may not cover all types of highly complex or niche security scenarios.\n\n### 7. Technical Significance\n\n*   **Advancement of the Technical State-of-the-Art**:\n    *   This paper provides the *first extensive user study* to empirically quantify the practical security risks introduced by AI code assistants in the context of *how developers actually use them*, moving beyond theoretical or synthetic evaluations \\cite{perry2022cq5}.\n    *   It offers critical, data-driven insights into the human element of AI-assisted development, demonstrating that these tools can lead to *less secure code* and *increased user overconfidence*, which is a significant finding for the field of usable security and AI ethics \\cite{perry2022cq5}.\n*   **Potential Impact on Future Research**:\n    *   **Informs AI Assistant Design**: The findings directly inform designers and model builders to prioritize security and user guidance, suggesting a need for \"security-aware\" AI assistants that actively mitigate vulnerabilities and user overconfidence \\cite{perry2022cq5}.\n    *   **Promotes Usable Security Research**: Highlights the crucial role of usable security research in understanding and addressing the human factors in the security implications of AI-powered development tools.\n    *   **Enables Replication and Extension**: The release of the custom UI infrastructure and anonymized data provides a valuable resource for future researchers to replicate, generalize, and extend this work, exploring different AI models, interaction patterns, or security contexts \\cite{perry2022cq5}.\n    *   **Guides Developer Training**: Implies a strong need for educating developers on secure prompt engineering, critical evaluation of AI-generated code, and understanding the limitations of AI assistants in security-critical contexts.",
    "intriguing_abstract": "Are AI code assistants making developers write *less* secure code? While AI models are known to generate vulnerabilities in controlled lab settings, their real-world impact on code security through human-AI interaction remains critically under-explored. This paper presents the first extensive user study, involving 47 participants, to empirically quantify how AI access influences code security across Python, JavaScript, and C. We developed a custom, open-source UI to meticulously log user interactions, prompt engineering strategies, and code acceptance patterns.\n\nOur findings are alarming: participants with AI access produced significantly less secure code in four out of five tasks and exhibited a dangerous overconfidence in their code's security. We uncover specific interaction patterns, such as using previous AI outputs as new prompts, that exacerbate vulnerabilities, alongside strategies like clear task instructions and `temperature` adjustments that can mitigate risks. This research provides crucial insights for designing security-aware AI assistants and emphasizes the urgent need for developer education on secure prompt engineering, fundamentally reshaping our understanding of AI's role in software security.",
    "keywords": [
      "AI code assistants",
      "code security vulnerabilities",
      "user study methodology",
      "human-AI interaction",
      "user overconfidence",
      "prompt engineering",
      "interaction logging",
      "custom study instrument",
      "multi-language programming",
      "less secure code",
      "usable security",
      "security-aware AI design"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ce3f027b68dad014a58aa35f52380932c8d0b209.pdf",
    "citation_key": "perry2022cq5",
    "metadata": {
      "title": "Do Users Write More Insecure Code with AI Assistants?",
      "authors": [
        "Neil Perry",
        "Megha Srivastava",
        "Deepak Kumar",
        "D. Boneh"
      ],
      "published_date": "2022",
      "abstract": "AI code assistants have emerged as powerful tools that can aid in the software development life-cycle and can improve developer productivity. Unfortunately, such assistants have also been found to produce insecure code in lab environments, raising significant concerns about their usage in practice. In this paper, we conduct a user study to examine how users interact with AI code assistants to solve a variety of security related tasks. Overall, we find that participants who had access to an AI assistant wrote significantly less secure code than those without access to an assistant. Participants with access to an AI assistant were also more likely to believe they wrote secure code, suggesting that such tools may lead users to be overconfident about security flaws in their code. To better inform the design of future AI-based code assistants, we release our user-study apparatus to researchers seeking to build on our work.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ce3f027b68dad014a58aa35f52380932c8d0b209.pdf",
      "venue": "Conference on Computer and Communications Security",
      "citationCount": 223,
      "score": 74.33333333333333,
      "summary": "Here's a focused summary of the paper \"Do Users Write More Insecure Code with AI Assistants?\" \\cite{perry2022cq5} for a literature review:\n\n### 1. Research Problem & Motivation\n\n*   **Specific Technical Problem**: The paper investigates how users interact with AI code assistants and how these interactions influence the security of the code they write in practical scenarios. While AI assistants are known to produce insecure code in lab settings, the actual security risks introduced by developer usage patterns remained largely unmeasured \\cite{perry2022cq5}.\n*   **Importance and Challenge**: This problem is critical because AI code assistants, despite their potential for productivity gains, raise significant security concerns. Understanding the practical security challenges and how users inadvertently introduce vulnerabilities through their interaction and prompting strategies is essential for designing safer AI-powered development tools \\cite{perry2022cq5}. The study specifically addresses whether AI access leads to more insecure code, if users trust AI for secure code, and how interaction patterns affect vulnerability levels.\n\n### 2. Related Work & Positioning\n\n*   **Relation to Existing Approaches**:\n    *   Previous evaluations of AI code models (e.g., Codex, InCoder) primarily focused on accuracy using static datasets (e.g., HumanEval, MBPP), offering limited insight into security risks in realistic human-developer settings \\cite{perry2022cq5}.\n    *   Prior work on GitHub Copilot's security risks used synthetic prompts, lacking the context of human interaction \\cite{perry2022cq5}.\n    *   Numerous user studies have examined AI assistants for usability, correctness, and productivity, yielding mixed results, but often without a specific focus on security or the potential for misplaced user trust \\cite{perry2022cq5}.\n*   **Limitations of Previous Solutions**:\n    *   The most closely related controlled user study \\cite{21} used an older, less powerful AI model with fixed parameters and focused solely on C language tasks. \\cite{perry2022cq5} highlights that users *do adjust model parameters* and that studying multiple languages is crucial, as results can vary significantly across languages.\n    *   \\cite{21} found inconclusive results regarding the effect of AI assistance on security vulnerabilities, leaving a gap that \\cite{perry2022cq5} addresses with a more extensive analysis of prompt language and query repair strategies.\n\n### 3. Technical Approach & Innovation\n\n*   **Core Technical Method**:\n    *   **User Study Design**: A comprehensive user study involving 47 participants (33 with AI access, 14 control) solving five security-related programming tasks across Python, JavaScript, and C \\cite{perry2022cq5}.\n    *   **Custom Study Instrument**: Development of a standalone desktop application (UI infrastructure) built on React, Redux, and Electron. This UI provided a sandboxed environment for coding, running code, and (for the experiment group) querying the AI assistant, enabling detailed logging of all interactions \\cite{perry2022cq5}.\n    *   **Task Design**: Tasks covered common security mistakes (cryptography, user-controlled data, web vulnerabilities, memory management) typically taught in introductory security courses \\cite{perry2022cq5}.\n    *   **Data Collection & Analysis**: Automated logging of AI queries, responses, final code, and \"acceptances\" of AI-generated code. Screen and audio recordings were also captured. Two authors manually coded all solutions for correctness and security mistakes (categorized as \"Secure,\" \"Partially Secure,\" \"Insecure\") with strong inter-rater reliability (Cohen-Kappa 0.7-0.96 for correctness, 0.68-0.88 for security). Mistakes were attributed to \"AI,\" \"Internet,\" or \"User\" based on detailed logs and recordings \\cite{perry2022cq5}.\n*   **Novelty or Difference**:\n    *   **Focus on Human-AI Interaction for Security**: This work uniquely focuses on the *dynamics of user interaction* with AI assistants and their *direct impact on code security* in a practical, controlled setting, moving beyond mere model output evaluation \\cite{perry2022cq5}.\n    *   **Multi-language and Diverse Security Contexts**: The study's inclusion of multiple programming languages (Python, JavaScript, C) and a variety of security problem types provides a broader and more representative analysis than prior single-language studies \\cite{perry2022cq5}.\n    *   **In-depth Interaction Analysis**: The custom UI and extensive logging allowed for a granular analysis of user behaviors, including prompt engineering, query refinement strategies, and the adjustment of AI model parameters (e.g., temperature), which was not possible in previous work \\cite{perry2022cq5}.\n    *   **Measurement of User Overconfidence**: Explicitly investigates and quantifies the phenomenon of users developing a false sense of security or overconfidence when using AI assistants \\cite{perry2022cq5}.\n\n### 4. Key Technical Contributions\n\n*   **Novel Algorithms, Methods, or Techniques**:\n    *   A robust methodology for conducting user studies on AI code assistant security, including a structured task design, comprehensive data collection (interaction logs, screen/audio recordings), and a rigorous manual analysis procedure with inter-rater reliability checks \\cite{perry2022cq5}.\n    *   A framework for categorizing and attributing security mistakes to specific sources (AI, Internet, User) based on detailed interaction data \\cite{perry2022cq5}.\n*   **System Design or Architectural Innovations**:\n    *   The development and open-sourcing of a custom, flexible study instrument (UI infrastructure) built on React, Redux, and Electron. This tool is designed for easy modification of questions and detailed logging of user-AI interactions, facilitating future research and replication \\cite{perry2022cq5}.\n*   **Theoretical Insights or Analysis**:\n    *   Empirical evidence demonstrating that access to AI assistants can lead to *significantly less secure code* and *increased user overconfidence* regarding security flaws \\cite{perry2022cq5}.\n    *   Identification of specific user interaction patterns that correlate with more secure code (e.g., clear task instructions, providing function declarations, focusing AI on helper functions) and those that exacerbate security problems (e.g., using previous AI outputs as new prompts) \\cite{perry2022cq5}.\n    *   Observation that users who successfully wrote secure code with AI assistants tended to increase the `temperature` parameter and provide more contextual prompts over time, highlighting the importance of prompt engineering skills \\cite{perry2022cq5}.\n\n### 5. Experimental Validation\n\n*   **Experiments Conducted**: A user study with 47 participants (33 experiment group with AI, 14 control group without AI) solving five security-related programming tasks in Python, JavaScript, and C. Tasks included symmetric encryption/decryption, ECDSA signing, sandboxed file access, SQL injection prevention, and integer to string conversion \\cite{perry2022cq5}.\n*   **Key Performance Metrics and Comparison Results**:\n    *   **Code Security**: Participants with AI access wrote *significantly less secure code* than the control group for four out of five tasks \\cite{perry2022cq5}.\n    *   **User Confidence**: Participants with AI access were *more likely to believe they wrote secure code*, indicating a false sense of security, despite their code being less secure \\cite{perry2022cq5}.\n    *   **Interaction Patterns**: Analysis of prompt language and parameter adjustments revealed that specifying task instructions, providing function declarations, and using the AI for helper functions correlated with *more secure code*. Conversely, using previous AI outputs as new prompts often *magnified or replicated security problems* \\cite{perry2022cq5}.\n    *   **Prompt Engineering**: Participants who achieved secure code with AI tended to increase the `temperature` parameter and provide more context in their prompts over time \\cite{perry2022cq5}.\n    *   **Reliability**: Manual coding of solutions achieved strong inter-rater reliability scores (Cohen-Kappa 0.7-0.96 for correctness, 0.68-0.88 for security) \\cite{perry2022cq5}.\n\n### 6. Limitations & Scope\n\n*   **Technical Limitations or Assumptions**:\n    *   The manual attribution of mistakes to \"AI,\" \"Internet,\" or \"User\" involves some subjectivity, despite efforts to ensure consistency and domain expertise \\cite{perry2022cq5}.\n    *   The study used a specific AI assistant model (implied to be based on OpenAI's Codex); results might vary with different or newer models.\n*   **Scope of Applicability**:\n    *   The participant pool, while diverse in experience, consisted of 47 individuals, primarily students, which is a relatively small sample size. While statistical significance was noted, broader generalization requires further studies \\cite{perry2022cq5}.\n    *   Tasks were designed for relatively short completion times, which may not fully capture the complexities of long-term software development cycles \\cite{perry2022cq5}.\n    *   The study focused on a set of common security vulnerabilities; it may not cover all types of highly complex or niche security scenarios.\n\n### 7. Technical Significance\n\n*   **Advancement of the Technical State-of-the-Art**:\n    *   This paper provides the *first extensive user study* to empirically quantify the practical security risks introduced by AI code assistants in the context of *how developers actually use them*, moving beyond theoretical or synthetic evaluations \\cite{perry2022cq5}.\n    *   It offers critical, data-driven insights into the human element of AI-assisted development, demonstrating that these tools can lead to *less secure code* and *increased user overconfidence*, which is a significant finding for the field of usable security and AI ethics \\cite{perry2022cq5}.\n*   **Potential Impact on Future Research**:\n    *   **Informs AI Assistant Design**: The findings directly inform designers and model builders to prioritize security and user guidance, suggesting a need for \"security-aware\" AI assistants that actively mitigate vulnerabilities and user overconfidence \\cite{perry2022cq5}.\n    *   **Promotes Usable Security Research**: Highlights the crucial role of usable security research in understanding and addressing the human factors in the security implications of AI-powered development tools.\n    *   **Enables Replication and Extension**: The release of the custom UI infrastructure and anonymized data provides a valuable resource for future researchers to replicate, generalize, and extend this work, exploring different AI models, interaction patterns, or security contexts \\cite{perry2022cq5}.\n    *   **Guides Developer Training**: Implies a strong need for educating developers on secure prompt engineering, critical evaluation of AI-generated code, and understanding the limitations of AI assistants in security-critical contexts.",
      "keywords": [
        "AI code assistants",
        "code security vulnerabilities",
        "user study methodology",
        "human-AI interaction",
        "user overconfidence",
        "prompt engineering",
        "interaction logging",
        "custom study instrument",
        "multi-language programming",
        "less secure code",
        "usable security",
        "security-aware AI design"
      ],
      "paper_type": "based on the abstract and introduction, this paper is an **empirical** type.\n\nhere's why:\n\n*   **abstract mentions:** \"we conduct a **user study** to examine how users interact...\", \"we **find** that participants...\", \"participants with access to an ai assistant were also more likely to believe...\", \"we release our user-study apparatus and anonymized **data**\". these are all strong indicators of a data-driven study with findings based on observation and analysis.\n*   **introduction discusses:** \"no **study** has extensively measured the security risks of ai assistants in the context of how developers choose to use them.\" this sets up a research question that the empirical study aims to answer.\n\nthe keywords and themes directly align with the \"empirical\" classification criteria: \"study\", \"experiment\" (implied by user study), \"data\", \"statistical\" (implied by \"significantly less secure code\"), \"findings\", \"research questions\", \"methodology\", \"participants\"."
    },
    "file_name": "ce3f027b68dad014a58aa35f52380932c8d0b209.pdf"
  },
  {
    "success": true,
    "doc_id": "6557c93a48dfb3f9a23b4a4259ed1744",
    "summary": "Here's a focused summary of the paper \"CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks\" by Puri et al. \\cite{puri2021d34} for a literature review:\n\n---\n\n### Analysis of CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks \\cite{puri2021d34}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical need for large-scale, diverse, and richly annotated datasets to accelerate research in \"AI for Code\" – leveraging AI techniques to improve software development efficiency.\n    *   **Importance and Challenge**: Software development productivity and modernization of legacy applications are crucial. While AI has seen breakthroughs in other domains (vision, NLP), its application to code is hampered by the lack of high-quality, extensive datasets comparable to those in other fields (e.g., ImageNet). Existing datasets are often limited in scale, language diversity, or metadata, making it challenging to train robust AI models for complex coding tasks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work relates to existing datasets like POJ-104 \\cite{puri2021d34} and GCJ \\cite{puri2021d34}, which also provide code samples for various tasks (clone detection, vulnerability detection, code completion, etc.).\n    *   **Limitations of Previous Solutions**:\n        *   **POJ-104**: Limited scale (52,000 samples), restricted to C/C++ (often mixed), lacks crucial metadata (judging results, problem statements, execution info), and contains identical problems/near-duplicates without explicit identification.\n        *   **GCJ**: Larger than POJ-104 (2.43 million samples) and more language-diverse, but still lacks comprehensive metadata (e.g., problem statements, test data), and does not provide information on identical problems or near-duplicates.\n        *   **General**: Many existing datasets are task-specific, whereas CodeNet aims for broad applicability.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: CodeNet is constructed by scraping and curating data from two online judge websites (AIZU and AtCoder), unifying their formats, and applying rigorous cleansing and annotation processes.\n    *   **Novelty/Differentiation**:\n        *   **Unprecedented Scale and Diversity**: Over 14 million code samples, 500 million lines of code, in 55 programming languages, making it the largest dataset of its kind.\n        *   **Rich, High-Quality Annotations**: Includes detailed metadata for each submission (status like Accepted, Wrong Answer, TLE, MLE; CPU time, memory usage, code size), problem descriptions, and sample input/output test sets for 98.5% of samples.\n        *   **Data Cleansing and Quality Control**: Employs Jaccard similarity (set and multiset) to identify and flag near-duplicate code samples (thresholds 0.9 and 0.8 respectively) and uses `fdupes` combined with near-duplicate code analysis and clustering to detect identical problems.\n        *   **Usability Features**: Provides pre-processing tools (fast C implementations of tokenizers for C, C++, Java, Python, JavaScript, and parse-tree generators) to transform source code into readily usable representations for ML models.\n        *   **Support for Diverse Tasks**: Designed to support a wide range of tasks including code similarity, classification, translation, and performance improvement (runtime/memory prediction).\n\n4.  **Key Technical Contributions**\n    *   **Novel Dataset**: The CodeNet dataset itself, characterized by its massive scale, linguistic diversity (55 languages), and rich, high-quality metadata (submission status, performance metrics, problem descriptions, I/O test cases).\n    *   **Advanced Data Cleansing**: Introduction and application of a systematic approach for identifying and flagging near-duplicate code samples (using Jaccard similarity on tokenized code) and identical problems (using `fdupes` and code-level near-duplicate analysis), which is crucial for robust ML model training.\n    *   **Pre-processing Toolchain**: Provision of open-source tools for tokenization and parse-tree generation, enabling researchers to easily convert raw code into ML-ready representations.\n    *   **Benchmarking Capabilities**: The dataset's structure and metadata enable the creation of customized benchmark datasets (e.g., C++, Python, Java subsets) for various AI for Code tasks.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The paper mentions conducting baseline experiments for code classification and code similarity using the CodeNet dataset.\n    *   **Key Performance Metrics and Comparison Results**: While specific detailed results or comparative metrics are not provided in the abstract or introduction, the paper states that \"Results of code classiﬁcation and code similarity experiments using the CodeNet dataset are provided as a reference\" and \"Section 8 describes important baseline experiments.\" This indicates that the dataset's utility for these tasks has been demonstrated through initial experiments, serving as a reference for future research.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Code samples may not be extensively commented, and comments can be in multiple languages, posing challenges for AI techniques relying heavily on comments.\n        *   The dataset primarily consists of solutions to high-school and beginning college-level programming problems.\n    *   **Scope of Applicability**:\n        *   Not suitable for tasks requiring code with enterprise APIs or advanced design patterns.\n        *   Primarily focused on pedagogical and competitive programming contexts.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: CodeNet significantly advances the technical state-of-the-art in AI for Code by providing an unprecedentedly large, diverse, and richly annotated dataset. This addresses a major bottleneck in the field, enabling the development and evaluation of more sophisticated deep learning models.\n    *   **Potential Impact on Future Research**:\n        *   **Accelerates Algorithmic Advances**: Expected to accelerate research in AI techniques for a wide variety of critical coding tasks (e.g., code translation, performance prediction, error prediction, code generation).\n        *   **Enables New Research Directions**: The rich metadata (runtime, memory, correctness status, I/O tests) opens up new research avenues, such as reinforcement learning for code quality improvement or fine-grained performance prediction.\n        *   **Standardization**: Aims to become a foundational resource, similar to ImageNet for computer vision, fostering standardized benchmarking and comparison of AI for Code models.",
    "intriguing_abstract": "The transformative potential of AI for Code remains largely untapped due to the scarcity of comprehensive, high-quality datasets. We introduce **CodeNet**, a groundbreaking large-scale dataset meticulously designed to accelerate research in this critical domain. Boasting an unprecedented 14 million code samples, 500 million lines of code across 55 diverse programming languages, CodeNet shatters existing limitations in scale and linguistic breadth.\n\nBeyond sheer volume, CodeNet offers unparalleled richness: each submission is annotated with detailed metadata including execution status (Accepted, TLE, MLE), CPU time, memory usage, problem descriptions, and I/O test cases. We employ rigorous data cleansing, utilizing Jaccard similarity for near-duplicate detection and advanced clustering for identical problem identification, ensuring data integrity crucial for robust deep learning models. CodeNet also provides essential pre-processing tools for tokenization and parse-tree generation. This foundational resource supports a vast array of tasks, from code similarity and classification to translation and performance prediction, poised to become the ImageNet for AI for Code and unlock novel research avenues.",
    "keywords": [
      "AI for Code",
      "CodeNet dataset",
      "large-scale diverse dataset",
      "rich metadata and annotations",
      "data cleansing methodologies",
      "near-duplicate code detection",
      "pre-processing toolchain",
      "code similarity",
      "code classification",
      "code translation",
      "performance prediction",
      "software development efficiency",
      "benchmarking capabilities",
      "deep learning for code",
      "foundational resource"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/7547680408358916e66917d03436fca7540a7528.pdf",
    "citation_key": "puri2021d34",
    "metadata": {
      "title": "CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks",
      "authors": [
        "Ruchi Puri",
        "David S. Kung",
        "G. Janssen",
        "Wei Zhang",
        "Giacomo Domeniconi",
        "Vladmir A. Zolotov",
        "Julian Dolby",
        "Jie Chen",
        "M. Choudhury",
        "Lindsey Decker",
        "Veronika Thost",
        "Luca Buratti",
        "Saurabh Pujar",
        "Ulrich Finkler"
      ],
      "published_date": "2021",
      "abstract": "Over the last several decades, software has been woven into the fabric of every aspect of our society. As software development surges and code infrastructure of enterprise applications ages, it is now more critical than ever to increase software development productivity and modernize legacy applications. Advances in deep learning and machine learning algorithms have enabled numerous breakthroughs, motivating researchers to leverage AI techniques to improve software development efficiency. Thus, the fast-emerging research area of AI for Code has garnered new interest and gathered momentum. In this paper, we present a large-scale dataset CodeNet, consisting of over 14 million code samples and about 500 million lines of code in 55 different programming languages, which is aimed at teaching AI to code. In addition to its large scale, CodeNet has a rich set of high-quality annotations to benchmark and help accelerate research in AI techniques for a variety of critical coding tasks, including code similarity and classification, code translation between a large variety of programming languages, and code performance (runtime and memory) improvement techniques. Additionally, CodeNet provides sample input and output test sets for 98.5% of the code samples, which can be used as an oracle for determining code correctness and potentially guide reinforcement learning for code quality improvements. As a usability feature, we provide several pre-processing tools in CodeNet to transform source code into representations that can be readily used as inputs into machine learning models. Results of code classification and code similarity experiments using the CodeNet dataset are provided as a reference. We hope that the scale, diversity and rich, high-quality annotations of CodeNet will offer unprecedented research opportunities at the intersection of AI and Software Engineering.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/7547680408358916e66917d03436fca7540a7528.pdf",
      "venue": "NeurIPS Datasets and Benchmarks",
      "citationCount": 286,
      "score": 71.5,
      "summary": "Here's a focused summary of the paper \"CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks\" by Puri et al. \\cite{puri2021d34} for a literature review:\n\n---\n\n### Analysis of CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks \\cite{puri2021d34}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical need for large-scale, diverse, and richly annotated datasets to accelerate research in \"AI for Code\" – leveraging AI techniques to improve software development efficiency.\n    *   **Importance and Challenge**: Software development productivity and modernization of legacy applications are crucial. While AI has seen breakthroughs in other domains (vision, NLP), its application to code is hampered by the lack of high-quality, extensive datasets comparable to those in other fields (e.g., ImageNet). Existing datasets are often limited in scale, language diversity, or metadata, making it challenging to train robust AI models for complex coding tasks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work relates to existing datasets like POJ-104 \\cite{puri2021d34} and GCJ \\cite{puri2021d34}, which also provide code samples for various tasks (clone detection, vulnerability detection, code completion, etc.).\n    *   **Limitations of Previous Solutions**:\n        *   **POJ-104**: Limited scale (52,000 samples), restricted to C/C++ (often mixed), lacks crucial metadata (judging results, problem statements, execution info), and contains identical problems/near-duplicates without explicit identification.\n        *   **GCJ**: Larger than POJ-104 (2.43 million samples) and more language-diverse, but still lacks comprehensive metadata (e.g., problem statements, test data), and does not provide information on identical problems or near-duplicates.\n        *   **General**: Many existing datasets are task-specific, whereas CodeNet aims for broad applicability.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: CodeNet is constructed by scraping and curating data from two online judge websites (AIZU and AtCoder), unifying their formats, and applying rigorous cleansing and annotation processes.\n    *   **Novelty/Differentiation**:\n        *   **Unprecedented Scale and Diversity**: Over 14 million code samples, 500 million lines of code, in 55 programming languages, making it the largest dataset of its kind.\n        *   **Rich, High-Quality Annotations**: Includes detailed metadata for each submission (status like Accepted, Wrong Answer, TLE, MLE; CPU time, memory usage, code size), problem descriptions, and sample input/output test sets for 98.5% of samples.\n        *   **Data Cleansing and Quality Control**: Employs Jaccard similarity (set and multiset) to identify and flag near-duplicate code samples (thresholds 0.9 and 0.8 respectively) and uses `fdupes` combined with near-duplicate code analysis and clustering to detect identical problems.\n        *   **Usability Features**: Provides pre-processing tools (fast C implementations of tokenizers for C, C++, Java, Python, JavaScript, and parse-tree generators) to transform source code into readily usable representations for ML models.\n        *   **Support for Diverse Tasks**: Designed to support a wide range of tasks including code similarity, classification, translation, and performance improvement (runtime/memory prediction).\n\n4.  **Key Technical Contributions**\n    *   **Novel Dataset**: The CodeNet dataset itself, characterized by its massive scale, linguistic diversity (55 languages), and rich, high-quality metadata (submission status, performance metrics, problem descriptions, I/O test cases).\n    *   **Advanced Data Cleansing**: Introduction and application of a systematic approach for identifying and flagging near-duplicate code samples (using Jaccard similarity on tokenized code) and identical problems (using `fdupes` and code-level near-duplicate analysis), which is crucial for robust ML model training.\n    *   **Pre-processing Toolchain**: Provision of open-source tools for tokenization and parse-tree generation, enabling researchers to easily convert raw code into ML-ready representations.\n    *   **Benchmarking Capabilities**: The dataset's structure and metadata enable the creation of customized benchmark datasets (e.g., C++, Python, Java subsets) for various AI for Code tasks.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The paper mentions conducting baseline experiments for code classification and code similarity using the CodeNet dataset.\n    *   **Key Performance Metrics and Comparison Results**: While specific detailed results or comparative metrics are not provided in the abstract or introduction, the paper states that \"Results of code classiﬁcation and code similarity experiments using the CodeNet dataset are provided as a reference\" and \"Section 8 describes important baseline experiments.\" This indicates that the dataset's utility for these tasks has been demonstrated through initial experiments, serving as a reference for future research.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   Code samples may not be extensively commented, and comments can be in multiple languages, posing challenges for AI techniques relying heavily on comments.\n        *   The dataset primarily consists of solutions to high-school and beginning college-level programming problems.\n    *   **Scope of Applicability**:\n        *   Not suitable for tasks requiring code with enterprise APIs or advanced design patterns.\n        *   Primarily focused on pedagogical and competitive programming contexts.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: CodeNet significantly advances the technical state-of-the-art in AI for Code by providing an unprecedentedly large, diverse, and richly annotated dataset. This addresses a major bottleneck in the field, enabling the development and evaluation of more sophisticated deep learning models.\n    *   **Potential Impact on Future Research**:\n        *   **Accelerates Algorithmic Advances**: Expected to accelerate research in AI techniques for a wide variety of critical coding tasks (e.g., code translation, performance prediction, error prediction, code generation).\n        *   **Enables New Research Directions**: The rich metadata (runtime, memory, correctness status, I/O tests) opens up new research avenues, such as reinforcement learning for code quality improvement or fine-grained performance prediction.\n        *   **Standardization**: Aims to become a foundational resource, similar to ImageNet for computer vision, fostering standardized benchmarking and comparison of AI for Code models.",
      "keywords": [
        "AI for Code",
        "CodeNet dataset",
        "large-scale diverse dataset",
        "rich metadata and annotations",
        "data cleansing methodologies",
        "near-duplicate code detection",
        "pre-processing toolchain",
        "code similarity",
        "code classification",
        "code translation",
        "performance prediction",
        "software development efficiency",
        "benchmarking capabilities",
        "deep learning for code",
        "foundational resource"
      ],
      "paper_type": "based on the abstract and introduction:\n\n1.  **\"present a large-scale dataset codenet\"**: this is the core contribution. the paper is introducing a new resource.\n2.  **\"consisting of over 14 million code samples... in 55 different programming languages\"**: describes the scale and nature of this new resource.\n3.  **\"aimed at teaching ai to code\"**: states the purpose of the dataset.\n4.  **\"rich set of high-quality annotations to benchmark and help accelerate research\"**: highlights its utility.\n5.  **\"provide several pre-processing tools in codenet\"**: indicates the development of supporting tools.\n6.  **\"results of code classiﬁcation and code similarity experiments using the codenet dataset are provided as a reference.\"**: while experiments are mentioned, they are \"as a reference,\" meaning the primary goal isn't to report new empirical findings from these experiments, but to demonstrate the utility of the *new dataset*.\n\nthis paper is primarily focused on **presenting a new, large-scale dataset and associated tools**, which serves as a foundational resource for future research. this aligns best with the \"technical\" classification, as it involves the development and presentation of a new \"system\" or \"resource\" (the dataset and its tools) designed to enable technical advancements in the field of \"ai for code.\" it's not a survey, a theoretical analysis, or primarily an empirical study of findings, but rather the creation of a significant new artifact.\n\n**classification:** technical"
    },
    "file_name": "7547680408358916e66917d03436fca7540a7528.pdf"
  },
  {
    "success": true,
    "doc_id": "a468d5cabdd0731312de871c9290f328",
    "summary": "Digital twin (DT) and artificial intelligence (AI) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for Industry 4.0. As a digital replica of a physical entity, the basis of DT is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. The grounding of DT and AI in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. This survey comprehensively reviews over 300 manuscripts on AI-driven DT technologies of Industry 4.0 used over the past five years and summarizes their general developments and the current state of AI-integration in the fields of smart manufacturing and advanced robotics. These cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3D printing and human–robot interaction/cooperation. Furthermore, advantages of AI-driven DTs in the context of sustainable development are elaborated. Practical challenges and development prospects of AI-driven DTs are discussed with a respective focus on different levels. A route for AI-integration in multiscale/fidelity DTs with multiscale/fidelity data sources in Industry 4.0 is outlined.",
    "intriguing_abstract": "Digital twin (DT) and artificial intelligence (AI) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for Industry 4.0. As a digital replica of a physical entity, the basis of DT is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. The grounding of DT and AI in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. This survey comprehensively reviews over 300 manuscripts on AI-driven DT technologies of Industry 4.0 used over the past five years and summarizes their general developments and the current state of AI-integration in the fields of smart manufacturing and advanced robotics. These cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3D printing and human–robot interaction/cooperation. Furthermore, advantages of AI-driven DTs in the context of sustainable development are elaborated. Practical challenges and development prospects of AI-driven DTs are discussed with a respective focus on different levels. A route for AI-integration in multiscale/fidelity DTs with multiscale/fidelity data sources in Industry 4.0 is outlined.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8e76c41f4df07fdc512cb13f8e9b14e1692577ed.pdf",
    "citation_key": "huang2021b50",
    "metadata": {
      "title": "A Survey on AI-Driven Digital Twins in Industry 4.0: Smart Manufacturing and Advanced Robotics",
      "authors": [
        "Ziqi Huang",
        "Yang Shen",
        "Jiayi Li",
        "M. Fey",
        "C. Brecher"
      ],
      "published_date": "2021",
      "abstract": "Digital twin (DT) and artificial intelligence (AI) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for Industry 4.0. As a digital replica of a physical entity, the basis of DT is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. The grounding of DT and AI in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. This survey comprehensively reviews over 300 manuscripts on AI-driven DT technologies of Industry 4.0 used over the past five years and summarizes their general developments and the current state of AI-integration in the fields of smart manufacturing and advanced robotics. These cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3D printing and human–robot interaction/cooperation. Furthermore, advantages of AI-driven DTs in the context of sustainable development are elaborated. Practical challenges and development prospects of AI-driven DTs are discussed with a respective focus on different levels. A route for AI-integration in multiscale/fidelity DTs with multiscale/fidelity data sources in Industry 4.0 is outlined.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8e76c41f4df07fdc512cb13f8e9b14e1692577ed.pdf",
      "venue": "Italian National Conference on Sensors",
      "citationCount": 250,
      "score": 62.5,
      "summary": "Digital twin (DT) and artificial intelligence (AI) technologies have grown rapidly in recent years and are considered by both academia and industry to be key enablers for Industry 4.0. As a digital replica of a physical entity, the basis of DT is the infrastructure and data, the core is the algorithm and model, and the application is the software and service. The grounding of DT and AI in industrial sectors is even more dependent on the systematic and in-depth integration of domain-specific expertise. This survey comprehensively reviews over 300 manuscripts on AI-driven DT technologies of Industry 4.0 used over the past five years and summarizes their general developments and the current state of AI-integration in the fields of smart manufacturing and advanced robotics. These cover conventional sophisticated metal machining and industrial automation as well as emerging techniques, such as 3D printing and human–robot interaction/cooperation. Furthermore, advantages of AI-driven DTs in the context of sustainable development are elaborated. Practical challenges and development prospects of AI-driven DTs are discussed with a respective focus on different levels. A route for AI-integration in multiscale/fidelity DTs with multiscale/fidelity data sources in Industry 4.0 is outlined.",
      "keywords": []
    },
    "file_name": "8e76c41f4df07fdc512cb13f8e9b14e1692577ed.pdf"
  },
  {
    "success": true,
    "doc_id": "599026978b52d4cacef47d0e78c670e5",
    "summary": "Sustainable agricultural development is a significant solution with fast population development through the use of information and communication (ICT) in precision agriculture, which produced new methods for making cultivation further productive, proficient, well-regulated while preserving the climate. Big data (machine learning, deep learning, etc.) is amongst the vital technologies of ICT employed in precision agriculture for their huge data analytical capabilities to abstract significant information and to assist agricultural practitioners to comprehend well farming practices and take precise decisions. The main goal of this article is to acquire an awareness of the Big Data latest applications in smart agriculture and be acquainted with related social and financial challenges to be concentrated on. This article features data creation methods, accessibility of technology, accessibility of devices, software tools, and data analytic methods, and appropriate applications of big data in precision agriculture. Besides, there are still a few challenges that come across the widespread implementation of big data technology in agriculture.",
    "intriguing_abstract": "Sustainable agricultural development is a significant solution with fast population development through the use of information and communication (ICT) in precision agriculture, which produced new methods for making cultivation further productive, proficient, well-regulated while preserving the climate. Big data (machine learning, deep learning, etc.) is amongst the vital technologies of ICT employed in precision agriculture for their huge data analytical capabilities to abstract significant information and to assist agricultural practitioners to comprehend well farming practices and take precise decisions. The main goal of this article is to acquire an awareness of the Big Data latest applications in smart agriculture and be acquainted with related social and financial challenges to be concentrated on. This article features data creation methods, accessibility of technology, accessibility of devices, software tools, and data analytic methods, and appropriate applications of big data in precision agriculture. Besides, there are still a few challenges that come across the widespread implementation of big data technology in agriculture.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8b417c2be7a7707f372049fb1193f0d42f799562.pdf",
    "citation_key": "bhat2021gdq",
    "metadata": {
      "title": "Big Data and AI Revolution in Precision Agriculture: Survey and Challenges",
      "authors": [
        "S. Bhat",
        "N. Huang"
      ],
      "published_date": "2021",
      "abstract": "Sustainable agricultural development is a significant solution with fast population development through the use of information and communication (ICT) in precision agriculture, which produced new methods for making cultivation further productive, proficient, well-regulated while preserving the climate. Big data (machine learning, deep learning, etc.) is amongst the vital technologies of ICT employed in precision agriculture for their huge data analytical capabilities to abstract significant information and to assist agricultural practitioners to comprehend well farming practices and take precise decisions. The main goal of this article is to acquire an awareness of the Big Data latest applications in smart agriculture and be acquainted with related social and financial challenges to be concentrated on. This article features data creation methods, accessibility of technology, accessibility of devices, software tools, and data analytic methods, and appropriate applications of big data in precision agriculture. Besides, there are still a few challenges that come across the widespread implementation of big data technology in agriculture.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8b417c2be7a7707f372049fb1193f0d42f799562.pdf",
      "venue": "IEEE Access",
      "citationCount": 211,
      "score": 52.75,
      "summary": "Sustainable agricultural development is a significant solution with fast population development through the use of information and communication (ICT) in precision agriculture, which produced new methods for making cultivation further productive, proficient, well-regulated while preserving the climate. Big data (machine learning, deep learning, etc.) is amongst the vital technologies of ICT employed in precision agriculture for their huge data analytical capabilities to abstract significant information and to assist agricultural practitioners to comprehend well farming practices and take precise decisions. The main goal of this article is to acquire an awareness of the Big Data latest applications in smart agriculture and be acquainted with related social and financial challenges to be concentrated on. This article features data creation methods, accessibility of technology, accessibility of devices, software tools, and data analytic methods, and appropriate applications of big data in precision agriculture. Besides, there are still a few challenges that come across the widespread implementation of big data technology in agriculture.",
      "keywords": []
    },
    "file_name": "8b417c2be7a7707f372049fb1193f0d42f799562.pdf"
  },
  {
    "success": true,
    "doc_id": "0d21326f3a3c12f16de3332309b791e0",
    "summary": "Summary Introduction: Artificial intelligence (AI) technologies continue to attract interest from a broad range of disciplines in recent years, including health. The increase in computer hardware and software applications in medicine, as well as digitization of health-related data together fuel progress in the development and use of AI in medicine. This progress provides new opportunities and challenges, as well as directions for the future of AI in health. Objective: The goals of this survey are to review the current state of AI in health, along with opportunities, challenges, and practical implications. This review highlights recent developments over the past five years and directions for the future. Methods: Publications over the past five years reporting the use of AI in health in clinical and biomedical informatics journals, as well as computer science conferences, were selected according to Google Scholar citations. Publications were then categorized into five different classes, according to the type of data analyzed. Results: The major data types identified were multi-omics, clinical, behavioral, environmental and pharmaceutical research and development (R&D) data. The current state of AI related to each data type is described, followed by associated challenges and practical implications that have emerged over the last several years. Opportunities and future directions based on these advances are discussed. Conclusion: Technologies have enabled the development of AI-assisted approaches to healthcare. However, there remain challenges. Work is currently underway to address multi-modal data integration, balancing quantitative algorithm performance and qualitative model interpretability, protection of model security, federated learning, and model bias.",
    "intriguing_abstract": "Summary Introduction: Artificial intelligence (AI) technologies continue to attract interest from a broad range of disciplines in recent years, including health. The increase in computer hardware and software applications in medicine, as well as digitization of health-related data together fuel progress in the development and use of AI in medicine. This progress provides new opportunities and challenges, as well as directions for the future of AI in health. Objective: The goals of this survey are to review the current state of AI in health, along with opportunities, challenges, and practical implications. This review highlights recent developments over the past five years and directions for the future. Methods: Publications over the past five years reporting the use of AI in health in clinical and biomedical informatics journals, as well as computer science conferences, were selected according to Google Scholar citations. Publications were then categorized into five different classes, according to the type of data analyzed. Results: The major data types identified were multi-omics, clinical, behavioral, environmental and pharmaceutical research and development (R&D) data. The current state of AI related to each data type is described, followed by associated challenges and practical implications that have emerged over the last several years. Opportunities and future directions based on these advances are discussed. Conclusion: Technologies have enabled the development of AI-assisted approaches to healthcare. However, there remain challenges. Work is currently underway to address multi-modal data integration, balancing quantitative algorithm performance and qualitative model interpretability, protection of model security, federated learning, and model bias.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/dfa67fa1b5eafc1e350c4a7357ce6c57aa6b989a.pdf",
    "citation_key": "wang2019i62",
    "metadata": {
      "title": "AI in Health: State of the Art, Challenges, and Future Directions",
      "authors": [
        "Fei Wang",
        "A. Preininger"
      ],
      "published_date": "2019",
      "abstract": "Summary Introduction: Artificial intelligence (AI) technologies continue to attract interest from a broad range of disciplines in recent years, including health. The increase in computer hardware and software applications in medicine, as well as digitization of health-related data together fuel progress in the development and use of AI in medicine. This progress provides new opportunities and challenges, as well as directions for the future of AI in health. Objective: The goals of this survey are to review the current state of AI in health, along with opportunities, challenges, and practical implications. This review highlights recent developments over the past five years and directions for the future. Methods: Publications over the past five years reporting the use of AI in health in clinical and biomedical informatics journals, as well as computer science conferences, were selected according to Google Scholar citations. Publications were then categorized into five different classes, according to the type of data analyzed. Results: The major data types identified were multi-omics, clinical, behavioral, environmental and pharmaceutical research and development (R&D) data. The current state of AI related to each data type is described, followed by associated challenges and practical implications that have emerged over the last several years. Opportunities and future directions based on these advances are discussed. Conclusion: Technologies have enabled the development of AI-assisted approaches to healthcare. However, there remain challenges. Work is currently underway to address multi-modal data integration, balancing quantitative algorithm performance and qualitative model interpretability, protection of model security, federated learning, and model bias.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/dfa67fa1b5eafc1e350c4a7357ce6c57aa6b989a.pdf",
      "venue": "Yearbook of Medical Informatics",
      "citationCount": 270,
      "score": 45.0,
      "summary": "Summary Introduction: Artificial intelligence (AI) technologies continue to attract interest from a broad range of disciplines in recent years, including health. The increase in computer hardware and software applications in medicine, as well as digitization of health-related data together fuel progress in the development and use of AI in medicine. This progress provides new opportunities and challenges, as well as directions for the future of AI in health. Objective: The goals of this survey are to review the current state of AI in health, along with opportunities, challenges, and practical implications. This review highlights recent developments over the past five years and directions for the future. Methods: Publications over the past five years reporting the use of AI in health in clinical and biomedical informatics journals, as well as computer science conferences, were selected according to Google Scholar citations. Publications were then categorized into five different classes, according to the type of data analyzed. Results: The major data types identified were multi-omics, clinical, behavioral, environmental and pharmaceutical research and development (R&D) data. The current state of AI related to each data type is described, followed by associated challenges and practical implications that have emerged over the last several years. Opportunities and future directions based on these advances are discussed. Conclusion: Technologies have enabled the development of AI-assisted approaches to healthcare. However, there remain challenges. Work is currently underway to address multi-modal data integration, balancing quantitative algorithm performance and qualitative model interpretability, protection of model security, federated learning, and model bias.",
      "keywords": []
    },
    "file_name": "dfa67fa1b5eafc1e350c4a7357ce6c57aa6b989a.pdf"
  },
  {
    "success": true,
    "doc_id": "48c4e2421a4c6a7aa62718df3e2bc914",
    "summary": "The presence of ‘Grammarly’ as one of the online grammar checkers as the impact of technology development.  This paper aims to reveal an overview of ‘Grammarly’ as an AI-powered English Writing Assistant for EFL students in Writing English. This research applies descriptive qualitative research. Based on the analysis, using Grammarly software shows the performance increased. Before using Grammarly, the performance of the test score is 34 out of 100. After using Grammarly, the performance text score is 77 out of 100. This score shows the quality of writing in this text increased. The performance can be increased based on Grammarly's suggestions in a Premium account. The researcher recommends the students to use Grammarly. Grammarly is a web tool to perform grammar checks well, starting from the spelling of words, sentence structure to standard grammar. Grammarly is free, so it is recommended for students who want to check various documents or articles in English. Grammarly helps check the grammatical rule, the spelling rule in English structure, also correct errors in writing such as punctuation and capitalization. Grammarly runs on an Artificial Intelligence (AI) system, which is built to analyze English sentences relying on a set of rules. Grammarly takes context when showing corrections or suggestions, and inform the students quickly but still precisely. For accuracy, two service options available both free and paid features. Of course, the Grammarly free version still has limitations and in-service features, unlike the paid version (premium) which has full advantages and benefits, many features, and complete.",
    "intriguing_abstract": "The presence of ‘Grammarly’ as one of the online grammar checkers as the impact of technology development.  This paper aims to reveal an overview of ‘Grammarly’ as an AI-powered English Writing Assistant for EFL students in Writing English. This research applies descriptive qualitative research. Based on the analysis, using Grammarly software shows the performance increased. Before using Grammarly, the performance of the test score is 34 out of 100. After using Grammarly, the performance text score is 77 out of 100. This score shows the quality of writing in this text increased. The performance can be increased based on Grammarly's suggestions in a Premium account. The researcher recommends the students to use Grammarly. Grammarly is a web tool to perform grammar checks well, starting from the spelling of words, sentence structure to standard grammar. Grammarly is free, so it is recommended for students who want to check various documents or articles in English. Grammarly helps check the grammatical rule, the spelling rule in English structure, also correct errors in writing such as punctuation and capitalization. Grammarly runs on an Artificial Intelligence (AI) system, which is built to analyze English sentences relying on a set of rules. Grammarly takes context when showing corrections or suggestions, and inform the students quickly but still precisely. For accuracy, two service options available both free and paid features. Of course, the Grammarly free version still has limitations and in-service features, unlike the paid version (premium) which has full advantages and benefits, many features, and complete.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/0f1de2c79f263e3a02a079768a99bb7db26e5841.pdf",
    "citation_key": "fitria2021h5v",
    "metadata": {
      "title": "Grammarly as AI-powered English Writing Assistant: Students’ Alternative for Writing English",
      "authors": [
        "Tira Nur Fitria"
      ],
      "published_date": "2021",
      "abstract": "The presence of ‘Grammarly’ as one of the online grammar checkers as the impact of technology development.  This paper aims to reveal an overview of ‘Grammarly’ as an AI-powered English Writing Assistant for EFL students in Writing English. This research applies descriptive qualitative research. Based on the analysis, using Grammarly software shows the performance increased. Before using Grammarly, the performance of the test score is 34 out of 100. After using Grammarly, the performance text score is 77 out of 100. This score shows the quality of writing in this text increased. The performance can be increased based on Grammarly's suggestions in a Premium account. The researcher recommends the students to use Grammarly. Grammarly is a web tool to perform grammar checks well, starting from the spelling of words, sentence structure to standard grammar. Grammarly is free, so it is recommended for students who want to check various documents or articles in English. Grammarly helps check the grammatical rule, the spelling rule in English structure, also correct errors in writing such as punctuation and capitalization. Grammarly runs on an Artificial Intelligence (AI) system, which is built to analyze English sentences relying on a set of rules. Grammarly takes context when showing corrections or suggestions, and inform the students quickly but still precisely. For accuracy, two service options available both free and paid features. Of course, the Grammarly free version still has limitations and in-service features, unlike the paid version (premium) which has full advantages and benefits, many features, and complete.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/0f1de2c79f263e3a02a079768a99bb7db26e5841.pdf",
      "venue": "",
      "citationCount": 174,
      "score": 43.5,
      "summary": "The presence of ‘Grammarly’ as one of the online grammar checkers as the impact of technology development.  This paper aims to reveal an overview of ‘Grammarly’ as an AI-powered English Writing Assistant for EFL students in Writing English. This research applies descriptive qualitative research. Based on the analysis, using Grammarly software shows the performance increased. Before using Grammarly, the performance of the test score is 34 out of 100. After using Grammarly, the performance text score is 77 out of 100. This score shows the quality of writing in this text increased. The performance can be increased based on Grammarly's suggestions in a Premium account. The researcher recommends the students to use Grammarly. Grammarly is a web tool to perform grammar checks well, starting from the spelling of words, sentence structure to standard grammar. Grammarly is free, so it is recommended for students who want to check various documents or articles in English. Grammarly helps check the grammatical rule, the spelling rule in English structure, also correct errors in writing such as punctuation and capitalization. Grammarly runs on an Artificial Intelligence (AI) system, which is built to analyze English sentences relying on a set of rules. Grammarly takes context when showing corrections or suggestions, and inform the students quickly but still precisely. For accuracy, two service options available both free and paid features. Of course, the Grammarly free version still has limitations and in-service features, unlike the paid version (premium) which has full advantages and benefits, many features, and complete.",
      "keywords": []
    },
    "file_name": "0f1de2c79f263e3a02a079768a99bb7db26e5841.pdf"
  },
  {
    "success": true,
    "doc_id": "9f4f4c7f99eca7c32473c40dcd6da9de",
    "summary": "One of the biggest challenges of utilizing artificial intelligence (AI) in medicine is that physicians are reluctant to trust and adopt something that they do not fully understand and regarded as a “black box.” Machine Learning (ML) can assist in reading radiological, endoscopic and histological pictures, suggesting diagnosis and predict disease outcome, and even recommending therapy and surgical decisions. However, clinical adoption of these AI tools has been slow because of a lack of trust. Besides clinician's doubt, patients lacking confidence with AI‐powered technologies also hamper development. While they may accept the reality that human errors can occur, little tolerance of machine error is anticipated. In order to implement AI medicine successfully, interpretability of ML algorithm needs to improve. Opening the black box in AI medicine needs to take a stepwise approach. Small steps of biological explanation and clinical experience in ML algorithm can help to build trust and acceptance. AI software developers will have to clearly demonstrate that when the ML technologies are integrated into the clinical decision‐making process, they can actually help to improve clinical outcome. Enhancing interpretability of ML algorithm is a crucial step in adopting AI in medicine.",
    "intriguing_abstract": "One of the biggest challenges of utilizing artificial intelligence (AI) in medicine is that physicians are reluctant to trust and adopt something that they do not fully understand and regarded as a “black box.” Machine Learning (ML) can assist in reading radiological, endoscopic and histological pictures, suggesting diagnosis and predict disease outcome, and even recommending therapy and surgical decisions. However, clinical adoption of these AI tools has been slow because of a lack of trust. Besides clinician's doubt, patients lacking confidence with AI‐powered technologies also hamper development. While they may accept the reality that human errors can occur, little tolerance of machine error is anticipated. In order to implement AI medicine successfully, interpretability of ML algorithm needs to improve. Opening the black box in AI medicine needs to take a stepwise approach. Small steps of biological explanation and clinical experience in ML algorithm can help to build trust and acceptance. AI software developers will have to clearly demonstrate that when the ML technologies are integrated into the clinical decision‐making process, they can actually help to improve clinical outcome. Enhancing interpretability of ML algorithm is a crucial step in adopting AI in medicine.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/5f6b6182810b184293254979646bcfe424f50a18.pdf",
    "citation_key": "poon2021tu1",
    "metadata": {
      "title": "Opening the black box of AI‐Medicine",
      "authors": [
        "Aaron I F Poon",
        "J. Sung"
      ],
      "published_date": "2021",
      "abstract": "One of the biggest challenges of utilizing artificial intelligence (AI) in medicine is that physicians are reluctant to trust and adopt something that they do not fully understand and regarded as a “black box.” Machine Learning (ML) can assist in reading radiological, endoscopic and histological pictures, suggesting diagnosis and predict disease outcome, and even recommending therapy and surgical decisions. However, clinical adoption of these AI tools has been slow because of a lack of trust. Besides clinician's doubt, patients lacking confidence with AI‐powered technologies also hamper development. While they may accept the reality that human errors can occur, little tolerance of machine error is anticipated. In order to implement AI medicine successfully, interpretability of ML algorithm needs to improve. Opening the black box in AI medicine needs to take a stepwise approach. Small steps of biological explanation and clinical experience in ML algorithm can help to build trust and acceptance. AI software developers will have to clearly demonstrate that when the ML technologies are integrated into the clinical decision‐making process, they can actually help to improve clinical outcome. Enhancing interpretability of ML algorithm is a crucial step in adopting AI in medicine.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/5f6b6182810b184293254979646bcfe424f50a18.pdf",
      "venue": "Journal of Gastroenterology and Hepatology",
      "citationCount": 137,
      "score": 34.25,
      "summary": "One of the biggest challenges of utilizing artificial intelligence (AI) in medicine is that physicians are reluctant to trust and adopt something that they do not fully understand and regarded as a “black box.” Machine Learning (ML) can assist in reading radiological, endoscopic and histological pictures, suggesting diagnosis and predict disease outcome, and even recommending therapy and surgical decisions. However, clinical adoption of these AI tools has been slow because of a lack of trust. Besides clinician's doubt, patients lacking confidence with AI‐powered technologies also hamper development. While they may accept the reality that human errors can occur, little tolerance of machine error is anticipated. In order to implement AI medicine successfully, interpretability of ML algorithm needs to improve. Opening the black box in AI medicine needs to take a stepwise approach. Small steps of biological explanation and clinical experience in ML algorithm can help to build trust and acceptance. AI software developers will have to clearly demonstrate that when the ML technologies are integrated into the clinical decision‐making process, they can actually help to improve clinical outcome. Enhancing interpretability of ML algorithm is a crucial step in adopting AI in medicine.",
      "keywords": []
    },
    "file_name": "5f6b6182810b184293254979646bcfe424f50a18.pdf"
  },
  {
    "success": true,
    "doc_id": "a717fcfccc7b68c62cdb133badf585c5",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of identifying and classifying software engineering (SE) challenges encountered by companies developing and deploying software-intensive systems that incorporate machine learning (ML) components in real-world commercial settings \\cite{lwakatare2019i3u}.\n    *   **Importance and Challenge:** AI-enabled systems are pervasive, but their development process significantly deviates from traditional software. There's a critical need to understand how these systems are engineered, deployed, and maintained in industry, and how established SE principles must be adapted or extended. Existing literature often focuses on theoretical ML breakthroughs or ML applied to SE activities, leaving a gap in understanding SE challenges for *operational* ML systems \\cite{lwakatare2019i3u}. Challenges include managing data, experiments, reproducibility, infrastructure, and model maintenance over time.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon existing empirical studies and experience reports that describe end-to-end development processes and challenges of AI-enabled applications \\cite{lwakatare2019i3u}. It specifically focuses on *applied ML* in operational commercial systems, distinguishing itself from ML applications within the software development process itself (e.g., fault prediction) \\cite{lwakatare2019i3u}.\n    *   **Limitations of Previous Solutions:** While prior work identified various challenges (e.g., informal data/artifact management, reproducibility issues, difficulties with complex model provenance, large data volume training, debugging deep learning systems), and proposed solutions like agile methods or versioning ML pipelines, a consolidated and structured overview of these challenges within an evolutionary framework was lacking \\cite{lwakatare2019i3u}. This paper aims to provide such a taxonomy to consolidate and structure these disparate findings.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper employs an **interpretive multiple-case study approach** to empirically investigate SE challenges. This involved conducting semi-structured interviews with practitioners from six diverse companies developing ML-enabled systems \\cite{lwakatare2019i3u}. Qualitative data was collected and analyzed using thematic analysis, with two coding iterations to identify and categorize challenges.\n    *   **Novelty/Difference:** The primary innovation is the **creation of a novel taxonomy** that depicts the evolution of ML component use in industrial software-intensive systems. This taxonomy then serves as a structured framework to classify the identified SE challenges, providing a coherent and organized view of the complex landscape of ML system development in practice \\cite{lwakatare2019i3u}. The empirical focus on *real-world commercial settings* and *operational ML systems* across diverse domains (automotive, web, telecom) provides unique and practical insights.\n\n*   **Key Technical Contributions**\n    *   **Novel Methods/Techniques:** The paper's main contribution is the **empirically-derived taxonomy** for understanding the evolution and associated SE challenges of ML components in industrial software systems \\cite{lwakatare2019i3u}. This taxonomy provides a structured lens through which to view the complexities of MLOps.\n    *   **Theoretical Insights/Analysis:** It offers detailed empirical insights into the development processes of six AI-enabled applications, highlighting specific pain points and challenges across different stages of ML system lifecycle (data management, model creation, training, deployment, organizational issues) \\cite{lwakatare2019i3u}. The classification of challenges within the proposed evolutionary taxonomy provides a new analytical framework for the field.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** The validation is through a rigorous **multiple-case study** involving six companies and seven distinct ML components. Data was collected via 15 semi-structured interviews (12 used for analysis) with experienced practitioners (managers, data scientists, ML engineers) and supplemented by a workshop with 10 practitioners \\cite{lwakatare2019i3u}. The cases covered diverse domains (e.g., automotive perception, web platform for ML, collaborative annotation, telecom failure prediction, e-commerce search) \\cite{lwakatare2019i3u}.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Knowledge Saturation:** The number of interviews (15) was sufficient to reach saturation of knowledge regarding challenges \\cite{lwakatare2019i3u}.\n        *   **Inter-rater Reliability:** A \"good agreement\" (Kappa value = 0.72) was achieved during the thematic analysis coding process, ensuring the robustness of the qualitative data interpretation \\cite{lwakatare2019i3u}.\n        *   **Qualitative Evidence:** The paper presents rich qualitative findings, including direct quotes from practitioners, illustrating challenges such as difficulties in building scalable deep learning infrastructure, managing design trade-offs in ML platforms, handling data drifts, model invalidation due to data source changes, and the need for robust processes for annotation quality \\cite{lwakatare2019i3u}. These findings are then mapped to the proposed taxonomy.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The study is qualitative and interpretive, relying on practitioners' perceptions, which may introduce subjectivity. The number of cases (six companies) is limited, though diverse. The findings reflect the state of industrial practice at the time of the study (2018), and the field of ML engineering is rapidly evolving \\cite{lwakatare2019i3u}.\n    *   **Scope of Applicability:** The findings and taxonomy are primarily applicable to software-intensive companies engaged in developing and operating ML components within their commercial products and services.\n\n*   **Technical Significance**\n    *   **Advance State-of-the-Art:** This paper significantly advances the technical state-of-the-art by providing an empirically-grounded, structured understanding of SE challenges in industrial ML system development. It moves beyond theoretical discussions to offer practical insights into the complexities faced by companies, bridging the gap between academic ML research and real-world software engineering practices \\cite{lwakatare2019i3u}. The proposed taxonomy offers a novel and valuable framework for organizing and discussing these challenges.\n    *   **Potential Impact on Future Research:** The identified challenges and the taxonomy provide a clear roadmap for future research in applied machine learning and MLOps. It highlights critical areas requiring further investigation, such as robust infrastructure design, data management strategies, model monitoring, reproducibility, and organizational structures for ML development, guiding the development of new tools, processes, and methodologies \\cite{lwakatare2019i3u}.",
    "intriguing_abstract": "The pervasive integration of AI into commercial software systems presents unprecedented software engineering challenges, often obscured by the focus on theoretical ML advancements. This paper demystifies the practical complexities of developing and deploying *operational machine learning components* in real-world industrial settings. Through an **interpretive multiple-case study** involving semi-structured interviews with practitioners from six diverse companies, we empirically uncover and classify critical **SE challenges** across the entire **ML system lifecycle**. Our novel contribution is an **empirically-derived taxonomy** that not only structures these challenges but also depicts the evolution of ML component use within software-intensive systems. We highlight pain points in **data management, experiment reproducibility, infrastructure scalability, and continuous model maintenance**, including issues like **data drift** and **annotation quality**. This work provides a crucial, structured understanding of **MLOps** in practice, offering a vital roadmap for future research and guiding practitioners in adapting established SE principles to the unique demands of AI-driven development.",
    "keywords": [
      "Software engineering challenges",
      "machine learning components",
      "AI-enabled systems",
      "operational ML systems",
      "interpretive multiple-case study",
      "thematic analysis",
      "novel taxonomy",
      "empirically-derived taxonomy",
      "ML system evolution",
      "industrial ML system development",
      "MLOps",
      "data management",
      "model maintenance",
      "reproducibility"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/21c6beb2a6df81f424e3d1283fbb9cc3157a3115.pdf",
    "citation_key": "lwakatare2019i3u",
    "metadata": {
      "title": "A Taxonomy of Software Engineering Challenges for Machine Learning Systems: An Empirical Investigation",
      "authors": [
        "Lucy Ellen Lwakatare",
        "Aiswarya Raj",
        "J. Bosch",
        "H. H. Olsson",
        "I. Crnkovic"
      ],
      "published_date": "2019",
      "abstract": "Artificial intelligence enabled systems have been an inevitable part of everyday life. However, efficient software engineering principles and processes need to be considered and extended when developing AI- enabled systems. The objective of this study is to identify and classify software engineering challenges that are faced by different companies when developing software-intensive systems that incorporate machine learning components. Using case study approach, we explored the development of machine learning systems from six different companies across various domains and identified main software engineering challenges. The challenges are mapped into a proposed taxonomy that depicts the evolution of use of ML components in software-intensive system in industrial settings. Our study provides insights to software engineering community and research to guide discussions and future research into applied machine learning.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/21c6beb2a6df81f424e3d1283fbb9cc3157a3115.pdf",
      "venue": "International Conference on Agile Software Development",
      "citationCount": 177,
      "score": 29.5,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of identifying and classifying software engineering (SE) challenges encountered by companies developing and deploying software-intensive systems that incorporate machine learning (ML) components in real-world commercial settings \\cite{lwakatare2019i3u}.\n    *   **Importance and Challenge:** AI-enabled systems are pervasive, but their development process significantly deviates from traditional software. There's a critical need to understand how these systems are engineered, deployed, and maintained in industry, and how established SE principles must be adapted or extended. Existing literature often focuses on theoretical ML breakthroughs or ML applied to SE activities, leaving a gap in understanding SE challenges for *operational* ML systems \\cite{lwakatare2019i3u}. Challenges include managing data, experiments, reproducibility, infrastructure, and model maintenance over time.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon existing empirical studies and experience reports that describe end-to-end development processes and challenges of AI-enabled applications \\cite{lwakatare2019i3u}. It specifically focuses on *applied ML* in operational commercial systems, distinguishing itself from ML applications within the software development process itself (e.g., fault prediction) \\cite{lwakatare2019i3u}.\n    *   **Limitations of Previous Solutions:** While prior work identified various challenges (e.g., informal data/artifact management, reproducibility issues, difficulties with complex model provenance, large data volume training, debugging deep learning systems), and proposed solutions like agile methods or versioning ML pipelines, a consolidated and structured overview of these challenges within an evolutionary framework was lacking \\cite{lwakatare2019i3u}. This paper aims to provide such a taxonomy to consolidate and structure these disparate findings.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper employs an **interpretive multiple-case study approach** to empirically investigate SE challenges. This involved conducting semi-structured interviews with practitioners from six diverse companies developing ML-enabled systems \\cite{lwakatare2019i3u}. Qualitative data was collected and analyzed using thematic analysis, with two coding iterations to identify and categorize challenges.\n    *   **Novelty/Difference:** The primary innovation is the **creation of a novel taxonomy** that depicts the evolution of ML component use in industrial software-intensive systems. This taxonomy then serves as a structured framework to classify the identified SE challenges, providing a coherent and organized view of the complex landscape of ML system development in practice \\cite{lwakatare2019i3u}. The empirical focus on *real-world commercial settings* and *operational ML systems* across diverse domains (automotive, web, telecom) provides unique and practical insights.\n\n*   **Key Technical Contributions**\n    *   **Novel Methods/Techniques:** The paper's main contribution is the **empirically-derived taxonomy** for understanding the evolution and associated SE challenges of ML components in industrial software systems \\cite{lwakatare2019i3u}. This taxonomy provides a structured lens through which to view the complexities of MLOps.\n    *   **Theoretical Insights/Analysis:** It offers detailed empirical insights into the development processes of six AI-enabled applications, highlighting specific pain points and challenges across different stages of ML system lifecycle (data management, model creation, training, deployment, organizational issues) \\cite{lwakatare2019i3u}. The classification of challenges within the proposed evolutionary taxonomy provides a new analytical framework for the field.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** The validation is through a rigorous **multiple-case study** involving six companies and seven distinct ML components. Data was collected via 15 semi-structured interviews (12 used for analysis) with experienced practitioners (managers, data scientists, ML engineers) and supplemented by a workshop with 10 practitioners \\cite{lwakatare2019i3u}. The cases covered diverse domains (e.g., automotive perception, web platform for ML, collaborative annotation, telecom failure prediction, e-commerce search) \\cite{lwakatare2019i3u}.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Knowledge Saturation:** The number of interviews (15) was sufficient to reach saturation of knowledge regarding challenges \\cite{lwakatare2019i3u}.\n        *   **Inter-rater Reliability:** A \"good agreement\" (Kappa value = 0.72) was achieved during the thematic analysis coding process, ensuring the robustness of the qualitative data interpretation \\cite{lwakatare2019i3u}.\n        *   **Qualitative Evidence:** The paper presents rich qualitative findings, including direct quotes from practitioners, illustrating challenges such as difficulties in building scalable deep learning infrastructure, managing design trade-offs in ML platforms, handling data drifts, model invalidation due to data source changes, and the need for robust processes for annotation quality \\cite{lwakatare2019i3u}. These findings are then mapped to the proposed taxonomy.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The study is qualitative and interpretive, relying on practitioners' perceptions, which may introduce subjectivity. The number of cases (six companies) is limited, though diverse. The findings reflect the state of industrial practice at the time of the study (2018), and the field of ML engineering is rapidly evolving \\cite{lwakatare2019i3u}.\n    *   **Scope of Applicability:** The findings and taxonomy are primarily applicable to software-intensive companies engaged in developing and operating ML components within their commercial products and services.\n\n*   **Technical Significance**\n    *   **Advance State-of-the-Art:** This paper significantly advances the technical state-of-the-art by providing an empirically-grounded, structured understanding of SE challenges in industrial ML system development. It moves beyond theoretical discussions to offer practical insights into the complexities faced by companies, bridging the gap between academic ML research and real-world software engineering practices \\cite{lwakatare2019i3u}. The proposed taxonomy offers a novel and valuable framework for organizing and discussing these challenges.\n    *   **Potential Impact on Future Research:** The identified challenges and the taxonomy provide a clear roadmap for future research in applied machine learning and MLOps. It highlights critical areas requiring further investigation, such as robust infrastructure design, data management strategies, model monitoring, reproducibility, and organizational structures for ML development, guiding the development of new tools, processes, and methodologies \\cite{lwakatare2019i3u}.",
      "keywords": [
        "Software engineering challenges",
        "machine learning components",
        "AI-enabled systems",
        "operational ML systems",
        "interpretive multiple-case study",
        "thematic analysis",
        "novel taxonomy",
        "empirically-derived taxonomy",
        "ML system evolution",
        "industrial ML system development",
        "MLOps",
        "data management",
        "model maintenance",
        "reproducibility"
      ],
      "paper_type": "the paper explicitly states its methodology in the abstract: \"using case study approach, we explored the development of machine learning systems from six different companies across various domains and identified main software engineering challenges.\"\n\nthis directly matches the criteria for a **case_study**:\n*   **abstract mentions:** \"case study\", \"application\" (development of ml systems), \"practice\" (in different companies), \"experience\" (implied by exploring development).\n*   **introduction discusses:** \"specific context\" (ai-enabled applications in real-world commercial settings), \"real-world scenario\" (development in six different companies).\n\nwhile the title includes \"an empirical investigation,\" which points to the \"empirical\" category, the abstract then specifies that this investigation was conducted *using a case study approach*. a case study is a specific type of empirical research. given that \"case_study\" is one of the classification options and is explicitly mentioned and detailed as the methodology, it is the most precise classification.\n\n**classification: case_study**"
    },
    "file_name": "21c6beb2a6df81f424e3d1283fbb9cc3157a3115.pdf"
  },
  {
    "success": true,
    "doc_id": "0b39b33ca85a505af9cd30b8f76ff51d",
    "summary": "Big Tech's unregulated roll-out out of experimental AI poses risks to the achievement of the UN Sustainable Development Goals (SDGs), with particular vulnerability for developing countries. The goal of financial inclusion is threatened by the imperfect and ungoverned design and implementation of AI decision-making software making important financial decisions affecting customers. Automated decision-making algorithms have displayed evidence of bias, lack ethical governance, and limit transparency in the basis for their decisions, causing unfair outcomes and amplify unequal access to finance. Poverty reduction and sustainable development targets are risked by Big Tech's potential exploitation of developing countries by using AI to harvest data and profits. Stakeholder progress toward preventing financial crime and corruption is further threatened by potential misuse of AI. In the light of such risks, Big Tech's unscrupulous history means it cannot be trusted to operate without regulatory oversight. The article proposes effective pre-emptive regulatory options to minimize scenarios of AI damaging the SDGs. It explores internationally accepted principles of AI governance, and argues for their implementation as regulatory requirements governing AI developers and coders, with compliance verified through algorithmic auditing. Furthermore, it argues that AI governance frameworks must require a benefit to the SDGs. The article argues that proactively predicting such problems can enable continued AI innovation through well-designed regulations adhering to international principles. It highlights risks of unregulated AI causing harm to human interests, where a public and regulatory backlash may result in over-regulation that could damage the otherwise beneficial development of AI.",
    "intriguing_abstract": "Big Tech's unregulated roll-out out of experimental AI poses risks to the achievement of the UN Sustainable Development Goals (SDGs), with particular vulnerability for developing countries. The goal of financial inclusion is threatened by the imperfect and ungoverned design and implementation of AI decision-making software making important financial decisions affecting customers. Automated decision-making algorithms have displayed evidence of bias, lack ethical governance, and limit transparency in the basis for their decisions, causing unfair outcomes and amplify unequal access to finance. Poverty reduction and sustainable development targets are risked by Big Tech's potential exploitation of developing countries by using AI to harvest data and profits. Stakeholder progress toward preventing financial crime and corruption is further threatened by potential misuse of AI. In the light of such risks, Big Tech's unscrupulous history means it cannot be trusted to operate without regulatory oversight. The article proposes effective pre-emptive regulatory options to minimize scenarios of AI damaging the SDGs. It explores internationally accepted principles of AI governance, and argues for their implementation as regulatory requirements governing AI developers and coders, with compliance verified through algorithmic auditing. Furthermore, it argues that AI governance frameworks must require a benefit to the SDGs. The article argues that proactively predicting such problems can enable continued AI innovation through well-designed regulations adhering to international principles. It highlights risks of unregulated AI causing harm to human interests, where a public and regulatory backlash may result in over-regulation that could damage the otherwise beneficial development of AI.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b238e588683bf20be6ff9d98137be0ff1ca4210a.pdf",
    "citation_key": "truby2020xrk",
    "metadata": {
      "title": "Governing Artificial Intelligence to benefit the UN Sustainable Development Goals",
      "authors": [
        "J. Truby"
      ],
      "published_date": "2020",
      "abstract": "Big Tech's unregulated roll-out out of experimental AI poses risks to the achievement of the UN Sustainable Development Goals (SDGs), with particular vulnerability for developing countries. The goal of financial inclusion is threatened by the imperfect and ungoverned design and implementation of AI decision-making software making important financial decisions affecting customers. Automated decision-making algorithms have displayed evidence of bias, lack ethical governance, and limit transparency in the basis for their decisions, causing unfair outcomes and amplify unequal access to finance. Poverty reduction and sustainable development targets are risked by Big Tech's potential exploitation of developing countries by using AI to harvest data and profits. Stakeholder progress toward preventing financial crime and corruption is further threatened by potential misuse of AI. In the light of such risks, Big Tech's unscrupulous history means it cannot be trusted to operate without regulatory oversight. The article proposes effective pre-emptive regulatory options to minimize scenarios of AI damaging the SDGs. It explores internationally accepted principles of AI governance, and argues for their implementation as regulatory requirements governing AI developers and coders, with compliance verified through algorithmic auditing. Furthermore, it argues that AI governance frameworks must require a benefit to the SDGs. The article argues that proactively predicting such problems can enable continued AI innovation through well-designed regulations adhering to international principles. It highlights risks of unregulated AI causing harm to human interests, where a public and regulatory backlash may result in over-regulation that could damage the otherwise beneficial development of AI.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b238e588683bf20be6ff9d98137be0ff1ca4210a.pdf",
      "venue": "Sustainable Development",
      "citationCount": 137,
      "score": 27.400000000000002,
      "summary": "Big Tech's unregulated roll-out out of experimental AI poses risks to the achievement of the UN Sustainable Development Goals (SDGs), with particular vulnerability for developing countries. The goal of financial inclusion is threatened by the imperfect and ungoverned design and implementation of AI decision-making software making important financial decisions affecting customers. Automated decision-making algorithms have displayed evidence of bias, lack ethical governance, and limit transparency in the basis for their decisions, causing unfair outcomes and amplify unequal access to finance. Poverty reduction and sustainable development targets are risked by Big Tech's potential exploitation of developing countries by using AI to harvest data and profits. Stakeholder progress toward preventing financial crime and corruption is further threatened by potential misuse of AI. In the light of such risks, Big Tech's unscrupulous history means it cannot be trusted to operate without regulatory oversight. The article proposes effective pre-emptive regulatory options to minimize scenarios of AI damaging the SDGs. It explores internationally accepted principles of AI governance, and argues for their implementation as regulatory requirements governing AI developers and coders, with compliance verified through algorithmic auditing. Furthermore, it argues that AI governance frameworks must require a benefit to the SDGs. The article argues that proactively predicting such problems can enable continued AI innovation through well-designed regulations adhering to international principles. It highlights risks of unregulated AI causing harm to human interests, where a public and regulatory backlash may result in over-regulation that could damage the otherwise beneficial development of AI.",
      "keywords": []
    },
    "file_name": "b238e588683bf20be6ff9d98137be0ff1ca4210a.pdf"
  },
  {
    "success": true,
    "doc_id": "e2aea14e0285020c97a7423e68272d36",
    "summary": "Logs have been widely adopted in software system development and maintenance because of the rich runtime information they record. In recent years, the increase of software size and complexity leads to the rapid growth of the volume of logs. To handle these large volumes of logs efficiently and effectively, a line of research focuses on developing intelligent and automated log analysis techniques. However, only a few of these techniques have reached successful deployments in industry due to the lack of public log datasets and open benchmarking upon them. To fill this significant gap and facilitate more research on AI-driven log analytics, we have collected and released loghub, a large collection of system log datasets. In particular, loghub provides 19 real-world log datasets collected from a wide range of software systems, including distributed systems, supercomputers, operating systems, mobile systems, server applications, and standalone software. In this paper, we summarize the statistics of these datasets, introduce some practical usage scenarios of the loghub datasets, and present our benchmarking results on loghub to benefit the researchers and practitioners in this field. Up to the time of this paper writing, the loghub datasets have been downloaded for roughly 90,000 times in total by hundreds of organizations from both industry and academia. The loghub datasets are available at https://github.com/logpai/loghub.",
    "intriguing_abstract": "Logs have been widely adopted in software system development and maintenance because of the rich runtime information they record. In recent years, the increase of software size and complexity leads to the rapid growth of the volume of logs. To handle these large volumes of logs efficiently and effectively, a line of research focuses on developing intelligent and automated log analysis techniques. However, only a few of these techniques have reached successful deployments in industry due to the lack of public log datasets and open benchmarking upon them. To fill this significant gap and facilitate more research on AI-driven log analytics, we have collected and released loghub, a large collection of system log datasets. In particular, loghub provides 19 real-world log datasets collected from a wide range of software systems, including distributed systems, supercomputers, operating systems, mobile systems, server applications, and standalone software. In this paper, we summarize the statistics of these datasets, introduce some practical usage scenarios of the loghub datasets, and present our benchmarking results on loghub to benefit the researchers and practitioners in this field. Up to the time of this paper writing, the loghub datasets have been downloaded for roughly 90,000 times in total by hundreds of organizations from both industry and academia. The loghub datasets are available at https://github.com/logpai/loghub.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/c3bdc6149097fa186a17d07cff6ce210d468bdf3.pdf",
    "citation_key": "zhu20202t6",
    "metadata": {
      "title": "Loghub: A Large Collection of System Log Datasets for AI-driven Log Analytics",
      "authors": [
        "Jieming Zhu",
        "Shilin He",
        "Pinjia He",
        "Jinyang Liu",
        "Michael R. Lyu"
      ],
      "published_date": "2020",
      "abstract": "Logs have been widely adopted in software system development and maintenance because of the rich runtime information they record. In recent years, the increase of software size and complexity leads to the rapid growth of the volume of logs. To handle these large volumes of logs efficiently and effectively, a line of research focuses on developing intelligent and automated log analysis techniques. However, only a few of these techniques have reached successful deployments in industry due to the lack of public log datasets and open benchmarking upon them. To fill this significant gap and facilitate more research on AI-driven log analytics, we have collected and released loghub, a large collection of system log datasets. In particular, loghub provides 19 real-world log datasets collected from a wide range of software systems, including distributed systems, supercomputers, operating systems, mobile systems, server applications, and standalone software. In this paper, we summarize the statistics of these datasets, introduce some practical usage scenarios of the loghub datasets, and present our benchmarking results on loghub to benefit the researchers and practitioners in this field. Up to the time of this paper writing, the loghub datasets have been downloaded for roughly 90,000 times in total by hundreds of organizations from both industry and academia. The loghub datasets are available at https://github.com/logpai/loghub.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/c3bdc6149097fa186a17d07cff6ce210d468bdf3.pdf",
      "venue": "IEEE International Symposium on Software Reliability Engineering",
      "citationCount": 123,
      "score": 24.6,
      "summary": "Logs have been widely adopted in software system development and maintenance because of the rich runtime information they record. In recent years, the increase of software size and complexity leads to the rapid growth of the volume of logs. To handle these large volumes of logs efficiently and effectively, a line of research focuses on developing intelligent and automated log analysis techniques. However, only a few of these techniques have reached successful deployments in industry due to the lack of public log datasets and open benchmarking upon them. To fill this significant gap and facilitate more research on AI-driven log analytics, we have collected and released loghub, a large collection of system log datasets. In particular, loghub provides 19 real-world log datasets collected from a wide range of software systems, including distributed systems, supercomputers, operating systems, mobile systems, server applications, and standalone software. In this paper, we summarize the statistics of these datasets, introduce some practical usage scenarios of the loghub datasets, and present our benchmarking results on loghub to benefit the researchers and practitioners in this field. Up to the time of this paper writing, the loghub datasets have been downloaded for roughly 90,000 times in total by hundreds of organizations from both industry and academia. The loghub datasets are available at https://github.com/logpai/loghub.",
      "keywords": []
    },
    "file_name": "c3bdc6149097fa186a17d07cff6ce210d468bdf3.pdf"
  },
  {
    "success": true,
    "doc_id": "8697f9b1c79ab8e71b375745c055884b",
    "summary": "\nPurpose\nThis study aims to review the progress of research on artificial intelligence (AI) relating to the hospitality and tourism industry, focusing on the content, focal points, key terms and trends of AI research.\n\n\nDesign/methodology/approach\nA total of 491 referred papers are selected from the Web of Science core collection database. These papers, published in the past 30 years (1991–2021), are analyzed by using Gephi and VOSviewer software.\n\n\nFindings\nAI research shows a growing trend since 1991, and the number of publications and citations increased significantly since 2018, indicating that AI became a focus for researchers. AI studies are grouped into four clusters, namely, AI technology, technology acceptance, customers’ perception and future trends. The research focus changed from AI technology in the early stage to customers’ attitudes toward and willingness to accept AI.\n\n\nResearch limitations/implications\nThe findings contribute to advance knowledge development, identify research gaps and shed light on future research. The results offer practical enlightenment for governments, tourism destinations and hospitality organization.\n\n\nPractical implications\nThe results offer practical enlightenment for governments, tourism destinations and hospitality organization.\n\n\nOriginality/value\nThis study is the initial attempt to provide a systematic review of AI research relating to the tourism and hospitality fields.\n",
    "intriguing_abstract": "\nPurpose\nThis study aims to review the progress of research on artificial intelligence (AI) relating to the hospitality and tourism industry, focusing on the content, focal points, key terms and trends of AI research.\n\n\nDesign/methodology/approach\nA total of 491 referred papers are selected from the Web of Science core collection database. These papers, published in the past 30 years (1991–2021), are analyzed by using Gephi and VOSviewer software.\n\n\nFindings\nAI research shows a growing trend since 1991, and the number of publications and citations increased significantly since 2018, indicating that AI became a focus for researchers. AI studies are grouped into four clusters, namely, AI technology, technology acceptance, customers’ perception and future trends. The research focus changed from AI technology in the early stage to customers’ attitudes toward and willingness to accept AI.\n\n\nResearch limitations/implications\nThe findings contribute to advance knowledge development, identify research gaps and shed light on future research. The results offer practical enlightenment for governments, tourism destinations and hospitality organization.\n\n\nPractical implications\nThe results offer practical enlightenment for governments, tourism destinations and hospitality organization.\n\n\nOriginality/value\nThis study is the initial attempt to provide a systematic review of AI research relating to the tourism and hospitality fields.\n",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b5b8115ea9820f6118d8c7ac3f5ce92ae276ca42.pdf",
    "citation_key": "kong2022lv5",
    "metadata": {
      "title": "30 years of artificial intelligence (AI) research relating to the hospitality and tourism industry",
      "authors": [
        "Haiyan Kong",
        "Kang-Ting Wang",
        "Xuejie Qiu",
        "C. Cheung",
        "N. Bu"
      ],
      "published_date": "2022",
      "abstract": "\nPurpose\nThis study aims to review the progress of research on artificial intelligence (AI) relating to the hospitality and tourism industry, focusing on the content, focal points, key terms and trends of AI research.\n\n\nDesign/methodology/approach\nA total of 491 referred papers are selected from the Web of Science core collection database. These papers, published in the past 30 years (1991–2021), are analyzed by using Gephi and VOSviewer software.\n\n\nFindings\nAI research shows a growing trend since 1991, and the number of publications and citations increased significantly since 2018, indicating that AI became a focus for researchers. AI studies are grouped into four clusters, namely, AI technology, technology acceptance, customers’ perception and future trends. The research focus changed from AI technology in the early stage to customers’ attitudes toward and willingness to accept AI.\n\n\nResearch limitations/implications\nThe findings contribute to advance knowledge development, identify research gaps and shed light on future research. The results offer practical enlightenment for governments, tourism destinations and hospitality organization.\n\n\nPractical implications\nThe results offer practical enlightenment for governments, tourism destinations and hospitality organization.\n\n\nOriginality/value\nThis study is the initial attempt to provide a systematic review of AI research relating to the tourism and hospitality fields.\n",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b5b8115ea9820f6118d8c7ac3f5ce92ae276ca42.pdf",
      "venue": "International Journal of Contemporary Hospitality Management",
      "citationCount": 69,
      "score": 23.0,
      "summary": "\nPurpose\nThis study aims to review the progress of research on artificial intelligence (AI) relating to the hospitality and tourism industry, focusing on the content, focal points, key terms and trends of AI research.\n\n\nDesign/methodology/approach\nA total of 491 referred papers are selected from the Web of Science core collection database. These papers, published in the past 30 years (1991–2021), are analyzed by using Gephi and VOSviewer software.\n\n\nFindings\nAI research shows a growing trend since 1991, and the number of publications and citations increased significantly since 2018, indicating that AI became a focus for researchers. AI studies are grouped into four clusters, namely, AI technology, technology acceptance, customers’ perception and future trends. The research focus changed from AI technology in the early stage to customers’ attitudes toward and willingness to accept AI.\n\n\nResearch limitations/implications\nThe findings contribute to advance knowledge development, identify research gaps and shed light on future research. The results offer practical enlightenment for governments, tourism destinations and hospitality organization.\n\n\nPractical implications\nThe results offer practical enlightenment for governments, tourism destinations and hospitality organization.\n\n\nOriginality/value\nThis study is the initial attempt to provide a systematic review of AI research relating to the tourism and hospitality fields.\n",
      "keywords": []
    },
    "file_name": "b5b8115ea9820f6118d8c7ac3f5ce92ae276ca42.pdf"
  },
  {
    "success": true,
    "doc_id": "528f3d200efdee595ae103b2fb5f2c27",
    "summary": "Survey/review study\nFrom Emotion AI to Cognitive AI\n\nGuoying Zhao *, Yante Li , and Qianru Xu\n\n\nUniversity of Oulu, Pentti Kaiteran Katu 1, Linnanmaa 90570, Finland\n* Correspondence: guoying.zhao@oulu.fi\n \n \nReceived: 22 September 2022\nAccepted: 28 November 2022\nPublished: 22 December 2022\n \n\nAbstract: Cognitive computing is recognized as the next era of computing. In order to make hardware and software systems more human-like, emotion artificial intelligence (AI) and cognitive AI which simulate human intelligence are the core of real AI. The current boom of sentiment analysis and affective computing in computer science gives rise to the rapid development of emotion AI. However, the research of cognitive AI has just started in the past few years. In this visionary paper, we briefly review the current development in emotion AI, introduce the concept of cognitive AI, and propose the envisioned future of cognitive AI, which intends to let computers think, reason, and make decisions in similar ways that humans do. The important aspect of cognitive AI in terms of engagement, regulation, decision making, and discovery are further discussed. Finally, we propose important directions for constructing future cognitive AI, including data and knowledge mining, multi-modal AI explainability, hybrid AI, and potential ethical challenges.",
    "intriguing_abstract": "Survey/review study\nFrom Emotion AI to Cognitive AI\n\nGuoying Zhao *, Yante Li , and Qianru Xu\n\n\nUniversity of Oulu, Pentti Kaiteran Katu 1, Linnanmaa 90570, Finland\n* Correspondence: guoying.zhao@oulu.fi\n \n \nReceived: 22 September 2022\nAccepted: 28 November 2022\nPublished: 22 December 2022\n \n\nAbstract: Cognitive computing is recognized as the next era of computing. In order to make hardware and software systems more human-like, emotion artificial intelligence (AI) and cognitive AI which simulate human intelligence are the core of real AI. The current boom of sentiment analysis and affective computing in computer science gives rise to the rapid development of emotion AI. However, the research of cognitive AI has just started in the past few years. In this visionary paper, we briefly review the current development in emotion AI, introduce the concept of cognitive AI, and propose the envisioned future of cognitive AI, which intends to let computers think, reason, and make decisions in similar ways that humans do. The important aspect of cognitive AI in terms of engagement, regulation, decision making, and discovery are further discussed. Finally, we propose important directions for constructing future cognitive AI, including data and knowledge mining, multi-modal AI explainability, hybrid AI, and potential ethical challenges.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/c3c905f5ec787a00e661d10ae86a6b55bb5303ea.pdf",
    "citation_key": "zhao2022m2c",
    "metadata": {
      "title": "From Emotion AI to Cognitive AI",
      "authors": [
        "Guoying Zhao",
        "Yante Li",
        "Qianru Xu"
      ],
      "published_date": "2022",
      "abstract": "Survey/review study\nFrom Emotion AI to Cognitive AI\n\nGuoying Zhao *, Yante Li , and Qianru Xu\n\n\nUniversity of Oulu, Pentti Kaiteran Katu 1, Linnanmaa 90570, Finland\n* Correspondence: guoying.zhao@oulu.fi\n \n \nReceived: 22 September 2022\nAccepted: 28 November 2022\nPublished: 22 December 2022\n \n\nAbstract: Cognitive computing is recognized as the next era of computing. In order to make hardware and software systems more human-like, emotion artificial intelligence (AI) and cognitive AI which simulate human intelligence are the core of real AI. The current boom of sentiment analysis and affective computing in computer science gives rise to the rapid development of emotion AI. However, the research of cognitive AI has just started in the past few years. In this visionary paper, we briefly review the current development in emotion AI, introduce the concept of cognitive AI, and propose the envisioned future of cognitive AI, which intends to let computers think, reason, and make decisions in similar ways that humans do. The important aspect of cognitive AI in terms of engagement, regulation, decision making, and discovery are further discussed. Finally, we propose important directions for constructing future cognitive AI, including data and knowledge mining, multi-modal AI explainability, hybrid AI, and potential ethical challenges.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/c3c905f5ec787a00e661d10ae86a6b55bb5303ea.pdf",
      "venue": "International Journal of Network Dynamics and Intelligence",
      "citationCount": 66,
      "score": 22.0,
      "summary": "Survey/review study\nFrom Emotion AI to Cognitive AI\n\nGuoying Zhao *, Yante Li , and Qianru Xu\n\n\nUniversity of Oulu, Pentti Kaiteran Katu 1, Linnanmaa 90570, Finland\n* Correspondence: guoying.zhao@oulu.fi\n \n \nReceived: 22 September 2022\nAccepted: 28 November 2022\nPublished: 22 December 2022\n \n\nAbstract: Cognitive computing is recognized as the next era of computing. In order to make hardware and software systems more human-like, emotion artificial intelligence (AI) and cognitive AI which simulate human intelligence are the core of real AI. The current boom of sentiment analysis and affective computing in computer science gives rise to the rapid development of emotion AI. However, the research of cognitive AI has just started in the past few years. In this visionary paper, we briefly review the current development in emotion AI, introduce the concept of cognitive AI, and propose the envisioned future of cognitive AI, which intends to let computers think, reason, and make decisions in similar ways that humans do. The important aspect of cognitive AI in terms of engagement, regulation, decision making, and discovery are further discussed. Finally, we propose important directions for constructing future cognitive AI, including data and knowledge mining, multi-modal AI explainability, hybrid AI, and potential ethical challenges.",
      "keywords": []
    },
    "file_name": "c3c905f5ec787a00e661d10ae86a6b55bb5303ea.pdf"
  },
  {
    "success": true,
    "doc_id": "78fa69252d0f2dfa4cfcf777188bfded",
    "summary": "The reconstruction of the trajectories of charged particles, or track reconstruction, is a key computational challenge for particle and nuclear physics experiments. While the tuning of track reconstruction algorithms can depend strongly on details of the detector geometry, the algorithms currently in use by experiments share many common features. At the same time, the intense environment of the High-Luminosity LHC accelerator and other future experiments is expected to put even greater computational stress on track reconstruction software, motivating the development of more performant algorithms. We present here A Common Tracking Software (ACTS) toolkit, which draws on the experience with track reconstruction algorithms in the ATLAS experiment and presents them in an experiment-independent and framework-independent toolkit. It provides a set of high-level track reconstruction tools which are agnostic to the details of the detection technologies and magnetic field configuration and tested for strict thread-safety to support multi-threaded event processing. We discuss the conceptual design and technical implementation of ACTS, selected applications and performance of ACTS, and the lessons learned.",
    "intriguing_abstract": "The reconstruction of the trajectories of charged particles, or track reconstruction, is a key computational challenge for particle and nuclear physics experiments. While the tuning of track reconstruction algorithms can depend strongly on details of the detector geometry, the algorithms currently in use by experiments share many common features. At the same time, the intense environment of the High-Luminosity LHC accelerator and other future experiments is expected to put even greater computational stress on track reconstruction software, motivating the development of more performant algorithms. We present here A Common Tracking Software (ACTS) toolkit, which draws on the experience with track reconstruction algorithms in the ATLAS experiment and presents them in an experiment-independent and framework-independent toolkit. It provides a set of high-level track reconstruction tools which are agnostic to the details of the detection technologies and magnetic field configuration and tested for strict thread-safety to support multi-threaded event processing. We discuss the conceptual design and technical implementation of ACTS, selected applications and performance of ACTS, and the lessons learned.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6ac0bff6e2a2d8eea2a325838dc4c8ecbc608f17.pdf",
    "citation_key": "ai2021it5",
    "metadata": {
      "title": "A Common Tracking Software Project",
      "authors": [
        "X. Ai",
        "C. Allaire",
        "N. Calace",
        "Angéla Czirkos",
        "M. Elsing",
        "I. Ene",
        "R. Farkas",
        "L. Gagnon",
        "R. Garg",
        "Paul Gessinger",
        "H. Grasland",
        "H. Gray",
        "C. Gumpert",
        "J. Hrdinka",
        "Benjamin Huth",
        "M. Kiehn",
        "F. Klimpel",
        "B. Kolbinger",
        "A. Krasznahorkay",
        "R. Langenberg",
        "Charles Leggett",
        "Georgiana Mania",
        "E. Moyse",
        "Joana Niermann",
        "J. Osborn",
        "D. Rousseau",
        "A. Salzburger",
        "B. Schlag",
        "Lauren Tompkins",
        "T. Yamazaki",
        "Beomki Yeo",
        "Jin Zhang"
      ],
      "published_date": "2021",
      "abstract": "The reconstruction of the trajectories of charged particles, or track reconstruction, is a key computational challenge for particle and nuclear physics experiments. While the tuning of track reconstruction algorithms can depend strongly on details of the detector geometry, the algorithms currently in use by experiments share many common features. At the same time, the intense environment of the High-Luminosity LHC accelerator and other future experiments is expected to put even greater computational stress on track reconstruction software, motivating the development of more performant algorithms. We present here A Common Tracking Software (ACTS) toolkit, which draws on the experience with track reconstruction algorithms in the ATLAS experiment and presents them in an experiment-independent and framework-independent toolkit. It provides a set of high-level track reconstruction tools which are agnostic to the details of the detection technologies and magnetic field configuration and tested for strict thread-safety to support multi-threaded event processing. We discuss the conceptual design and technical implementation of ACTS, selected applications and performance of ACTS, and the lessons learned.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6ac0bff6e2a2d8eea2a325838dc4c8ecbc608f17.pdf",
      "venue": "Computing and Software for Big Science",
      "citationCount": 85,
      "score": 21.25,
      "summary": "The reconstruction of the trajectories of charged particles, or track reconstruction, is a key computational challenge for particle and nuclear physics experiments. While the tuning of track reconstruction algorithms can depend strongly on details of the detector geometry, the algorithms currently in use by experiments share many common features. At the same time, the intense environment of the High-Luminosity LHC accelerator and other future experiments is expected to put even greater computational stress on track reconstruction software, motivating the development of more performant algorithms. We present here A Common Tracking Software (ACTS) toolkit, which draws on the experience with track reconstruction algorithms in the ATLAS experiment and presents them in an experiment-independent and framework-independent toolkit. It provides a set of high-level track reconstruction tools which are agnostic to the details of the detection technologies and magnetic field configuration and tested for strict thread-safety to support multi-threaded event processing. We discuss the conceptual design and technical implementation of ACTS, selected applications and performance of ACTS, and the lessons learned.",
      "keywords": []
    },
    "file_name": "6ac0bff6e2a2d8eea2a325838dc4c8ecbc608f17.pdf"
  },
  {
    "success": true,
    "doc_id": "9e17ba329c07ff6c8b6e29e773487bf7",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{lu2022et0}\n\n### 1. Research Problem & Motivation\n\n*   **Specific Technical Problem**: The paper addresses the critical challenge of operationalizing Responsible AI (RAI) in practice. While numerous high-level ethical principles and frameworks for AI exist, they lack concrete, actionable guidance for software engineers to design, implement, and track RAI requirements throughout the entire AI system lifecycle.\n*   **Importance and Challenge**: This problem is important because AI systems are increasingly deployed in sensitive domains, raising serious concerns about their ethical behavior and decision-making. It is challenging because current AI research often focuses on isolated algorithmic solutions (e.g., for fairness or privacy) without integrating them into a holistic software engineering process, and the ethical principles themselves are abstract, making their translation into verifiable technical requirements difficult. The problem crosscuts the entire engineering lifecycle and components of AI systems, requiring a systemic approach beyond just algorithms \\cite{lu2022et0}.\n\n### 2. Related Work & Positioning\n\n*   **Relation to Existing Approaches**: \\cite{lu2022et0} positions its work as a bridge between high-level ethical principles and low-level algorithmic solutions. It acknowledges the existence of many ethical principle frameworks and some algorithm-level mechanisms (e.g., for privacy and fairness).\n*   **Limitations of Previous Solutions**:\n    *   **High-level Principles**: Existing ethical principles are too abstract and do not provide operationalized guidance or software engineering methods for developing responsible AI systems. They leave unanswered questions about how to design for, implement, and track these principles.\n    *   **Algorithmic Focus**: Most AI research on ethics focuses on algorithm-level mechanisms, which often address only a small subset of ethical principles (e.g., privacy, fairness) and rely on theoretical heuristics. These solutions lack linkage to the broader software development processes, including requirements engineering, system design, and operations \\cite{lu2022et0}.\n\n### 3. Technical Approach & Innovation\n\n*   **Core Technical Method**: The paper proposes a research roadmap on software engineering for operationalizing Responsible AI, developed through a Systematic Literature Review (SLR) of 159 primary studies. The roadmap is structured around three key perspectives:\n    1.  **Multi-level Governance**: Establishing governance structures and processes at industry, organization, and team levels to ensure compliance with ethical regulations.\n    2.  **Process-Oriented Practices**: Integrating responsible AI considerations into the entire software development lifecycle (SDLC), including requirements engineering, design, implementation, verification & validation, and operation.\n    3.  **Responsible-AI-by-Design**: Building responsible AI into systems through system-level architectural styles, patterns, and techniques \\cite{lu2022et0}.\n*   **Novelty/Difference**: The novelty lies in its holistic, software engineering-centric approach to Responsible AI. Instead of proposing new algorithms or abstract principles, \\cite{lu2022et0} systematically synthesizes and structures existing and emerging software engineering practices into a comprehensive roadmap. It emphasizes integrating ethical considerations across the entire AI system lifecycle and at multiple organizational levels, moving beyond isolated technical fixes to a systemic engineering discipline \\cite{lu2022et0}.\n\n### 4. Key Technical Contributions\n\n*   **Novel Methods/Techniques**:\n    *   **Multi-level Governance Framework**: Proposes a structured governance framework (industry, organization, team) with concrete mechanisms (e.g., agile regulatory sandboxes, AI capability maturity models, ethical certification, ethics committees, ethical risk assessment checklists, role-level accountability, diverse teams, continuous documentation) \\cite{lu2022et0}.\n    *   **Lifecycle-Integrated Process Practices**: Identifies and organizes specific software engineering practices for each stage of the AI system lifecycle to embed responsible AI:\n        *   **Requirements Engineering**: Ethical user stories, classifying ethical principles into non-functional requirements, verifiable ethical requirements.\n        *   **Design**: Architectural styles/patterns for ethics, value-sensitive design, ethical scenario simulation, XAI UX.\n        *   **Implementation**: Ethical coding standards/checklists, continuous documentation, ethical code review, ethical compliance checking for APIs.\n        *   **Verification & Validation**: Ethical acceptance tests, data tests, formal verification, assurance cases, ethical scoring (AI quotient).\n        *   **Operation**: Phased deployment, continuous monitoring of outcomes, dynamic ethical risk assessment, co-versioning of data/model/code, accountability mechanisms (bill of materials, audit trails) \\cite{lu2022et0}.\n    *   **Responsible-AI-by-Design Principles**: Advocates for embedding ethical considerations directly into the system architecture and design through patterns and techniques.\n*   **System Design/Architectural Innovations**: While not proposing a specific architecture, the roadmap highlights the need for architectural styles and patterns that support responsible AI, such as those enabling transparency, explainability, and human control. It also points to decentralized infrastructure for verifiable ethical credentials \\cite{lu2022et0}.\n*   **Theoretical Insights/Analysis**: The paper's primary theoretical contribution is the systematic synthesis of a comprehensive roadmap, providing a structured way to think about and implement Responsible AI from a software engineering perspective. It identifies the critical gaps between high-level principles and practical implementation, offering a framework to bridge this divide.\n\n### 5. Experimental Validation\n\n*   **Experiments Conducted**: The paper itself does not present experimental validation of a proposed technical solution. Instead, its foundation is a **Systematic Literature Review (SLR)**. The SLR involved:\n    *   Defining two research questions: 1) What responsible AI principles are addressed? 2) What solutions for responsible AI can be identified?\n    *   Searching five major digital libraries (ACM, IEEE, Science Direct, Springer Link, Google Scholar).\n    *   Identifying 159 primary studies that presented concrete solutions for responsible AI (excluding high-level frameworks) \\cite{lu2022et0}.\n*   **Key Performance Metrics/Comparison Results**: As a roadmap paper based on an SLR, it does not report performance metrics or comparative results of a new system. The \"results\" are the synthesized current state, identified challenges, and the proposed roadmap itself, derived from the analysis of the 159 primary studies.\n\n### 6. Limitations & Scope\n\n*   **Technical Limitations/Assumptions**:\n    *   The roadmap is a *proposal* for future research and development, not a fully implemented or validated system. Its effectiveness would need to be empirically tested in real-world AI development contexts.\n    *   The SLR, while systematic, is a snapshot of existing literature up to March 2022 and may not capture all emerging practices.\n    *   The paper focuses on the software engineering perspective, acknowledging that Responsible AI is multidisciplinary but positioning SE as the key driver. This implies that non-SE aspects (e.g., purely legal, philosophical, or sociological) are considered primarily through their implications for engineering.\n*   **Scope of Applicability**: The roadmap is broadly applicable to the development of any AI system where ethical considerations are paramount. It aims to provide guidance for governments, organizations, and development teams involved in the AI lifecycle \\cite{lu2022et0}.\n\n### 7. Technical Significance\n\n*   **Advancement of State-of-the-Art**: \\cite{lu2022et0} significantly advances the technical state-of-the-art by providing the first comprehensive, software engineering-focused roadmap for operationalizing Responsible AI. It moves beyond abstract ethical discussions and isolated algorithmic fixes to offer a structured, lifecycle-oriented approach, making RAI more tangible and actionable for practitioners.\n*   **Potential Impact on Future Research**:\n    *   **Structured Research Agenda**: Provides a clear research agenda by identifying critical challenges in multi-level governance, process integration, and responsible-AI-by-design.\n    *   **Interdisciplinary Collaboration**: Highlights the necessity for improved communication and collaboration between software engineers, machine learning experts, social scientists, and ethicists.\n    *   **Tooling and Method Development**: Will likely spur research into developing specific tools, methods, and architectural patterns that implement the practices outlined in the roadmap (e.g., ethical requirement elicitation tools, ethical risk assessment frameworks, automated ethical code review, and verifiable credential infrastructures) \\cite{lu2022et0}.\n    *   **Education**: Emphasizes the urgent need for responsible AI education, influencing curriculum development in computer science and software engineering.",
    "intriguing_abstract": "The promise of Artificial Intelligence is shadowed by the critical challenge of operationalizing Responsible AI (RAI). While high-level ethical principles abound, software engineers lack concrete, actionable guidance to integrate these into the complex AI system lifecycle, often relying on isolated algorithmic fixes that fail to address systemic ethical concerns. This paper bridges this crucial gap by presenting the first comprehensive *software engineering roadmap* for making RAI actionable.\n\nDerived from a Systematic Literature Review (SLR) of 159 primary studies, our roadmap offers a holistic framework structured around three pillars: multi-level governance, process-oriented practices integrated across the entire AI system lifecycle (from requirements engineering and design to verification & validation and operation), and Responsible-AI-by-Design principles. We detail specific techniques for embedding ethical considerations into every stage, including verifiable ethical requirements, architectural patterns for transparency and explainability, and continuous ethical monitoring. This work transforms abstract ethical discussions into a tangible engineering discipline, providing a vital blueprint for researchers and practitioners to build truly responsible, trustworthy AI systems and shaping the future of ethical AI development.",
    "keywords": [
      "Responsible AI (RAI)",
      "operationalizing Responsible AI",
      "software engineering",
      "AI system lifecycle",
      "Systematic Literature Review",
      "research roadmap",
      "multi-level governance",
      "process-oriented practices",
      "Responsible-AI-by-Design",
      "ethical principles",
      "verifiable ethical requirements",
      "accountability mechanisms",
      "bridging principles and algorithms"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/dccd738bc67c1e4b807b07872ff065fadc4253da.pdf",
    "citation_key": "lu2022et0",
    "metadata": {
      "title": "Towards a Roadmap on Software Engineering for Responsible AI",
      "authors": [
        "Q. Lu",
        "Liming Zhu",
        "Xiwei Xu",
        "J. Whittle",
        "Zhenchang Xing"
      ],
      "published_date": "2022",
      "abstract": "Although AI is transforming the world, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and frameworks for responsible AI have been issued recently. However, they are high level and difficult to put into practice. On the other hand, most AI researchers focus on algorithmic solutions, while the responsible AI challenges actually crosscut the entire engineering lifecycle and components of AI systems. To close the gap in operationalizing responsible AI, this paper aims to develop a roadmap on software engineering for responsible AI. The roadmap focuses on (i) establishing multi-level governance for responsible AI systems, (ii) setting up the development processes incorporating process-oriented practices for responsible AI systems, and (iii) building responsible-AI-by-design into AI systems through system-level architectural style, patterns and techniques. CCS CONCEPTS • Software and its engineering;",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/dccd738bc67c1e4b807b07872ff065fadc4253da.pdf",
      "venue": "2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN)",
      "citationCount": 63,
      "score": 21.0,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{lu2022et0}\n\n### 1. Research Problem & Motivation\n\n*   **Specific Technical Problem**: The paper addresses the critical challenge of operationalizing Responsible AI (RAI) in practice. While numerous high-level ethical principles and frameworks for AI exist, they lack concrete, actionable guidance for software engineers to design, implement, and track RAI requirements throughout the entire AI system lifecycle.\n*   **Importance and Challenge**: This problem is important because AI systems are increasingly deployed in sensitive domains, raising serious concerns about their ethical behavior and decision-making. It is challenging because current AI research often focuses on isolated algorithmic solutions (e.g., for fairness or privacy) without integrating them into a holistic software engineering process, and the ethical principles themselves are abstract, making their translation into verifiable technical requirements difficult. The problem crosscuts the entire engineering lifecycle and components of AI systems, requiring a systemic approach beyond just algorithms \\cite{lu2022et0}.\n\n### 2. Related Work & Positioning\n\n*   **Relation to Existing Approaches**: \\cite{lu2022et0} positions its work as a bridge between high-level ethical principles and low-level algorithmic solutions. It acknowledges the existence of many ethical principle frameworks and some algorithm-level mechanisms (e.g., for privacy and fairness).\n*   **Limitations of Previous Solutions**:\n    *   **High-level Principles**: Existing ethical principles are too abstract and do not provide operationalized guidance or software engineering methods for developing responsible AI systems. They leave unanswered questions about how to design for, implement, and track these principles.\n    *   **Algorithmic Focus**: Most AI research on ethics focuses on algorithm-level mechanisms, which often address only a small subset of ethical principles (e.g., privacy, fairness) and rely on theoretical heuristics. These solutions lack linkage to the broader software development processes, including requirements engineering, system design, and operations \\cite{lu2022et0}.\n\n### 3. Technical Approach & Innovation\n\n*   **Core Technical Method**: The paper proposes a research roadmap on software engineering for operationalizing Responsible AI, developed through a Systematic Literature Review (SLR) of 159 primary studies. The roadmap is structured around three key perspectives:\n    1.  **Multi-level Governance**: Establishing governance structures and processes at industry, organization, and team levels to ensure compliance with ethical regulations.\n    2.  **Process-Oriented Practices**: Integrating responsible AI considerations into the entire software development lifecycle (SDLC), including requirements engineering, design, implementation, verification & validation, and operation.\n    3.  **Responsible-AI-by-Design**: Building responsible AI into systems through system-level architectural styles, patterns, and techniques \\cite{lu2022et0}.\n*   **Novelty/Difference**: The novelty lies in its holistic, software engineering-centric approach to Responsible AI. Instead of proposing new algorithms or abstract principles, \\cite{lu2022et0} systematically synthesizes and structures existing and emerging software engineering practices into a comprehensive roadmap. It emphasizes integrating ethical considerations across the entire AI system lifecycle and at multiple organizational levels, moving beyond isolated technical fixes to a systemic engineering discipline \\cite{lu2022et0}.\n\n### 4. Key Technical Contributions\n\n*   **Novel Methods/Techniques**:\n    *   **Multi-level Governance Framework**: Proposes a structured governance framework (industry, organization, team) with concrete mechanisms (e.g., agile regulatory sandboxes, AI capability maturity models, ethical certification, ethics committees, ethical risk assessment checklists, role-level accountability, diverse teams, continuous documentation) \\cite{lu2022et0}.\n    *   **Lifecycle-Integrated Process Practices**: Identifies and organizes specific software engineering practices for each stage of the AI system lifecycle to embed responsible AI:\n        *   **Requirements Engineering**: Ethical user stories, classifying ethical principles into non-functional requirements, verifiable ethical requirements.\n        *   **Design**: Architectural styles/patterns for ethics, value-sensitive design, ethical scenario simulation, XAI UX.\n        *   **Implementation**: Ethical coding standards/checklists, continuous documentation, ethical code review, ethical compliance checking for APIs.\n        *   **Verification & Validation**: Ethical acceptance tests, data tests, formal verification, assurance cases, ethical scoring (AI quotient).\n        *   **Operation**: Phased deployment, continuous monitoring of outcomes, dynamic ethical risk assessment, co-versioning of data/model/code, accountability mechanisms (bill of materials, audit trails) \\cite{lu2022et0}.\n    *   **Responsible-AI-by-Design Principles**: Advocates for embedding ethical considerations directly into the system architecture and design through patterns and techniques.\n*   **System Design/Architectural Innovations**: While not proposing a specific architecture, the roadmap highlights the need for architectural styles and patterns that support responsible AI, such as those enabling transparency, explainability, and human control. It also points to decentralized infrastructure for verifiable ethical credentials \\cite{lu2022et0}.\n*   **Theoretical Insights/Analysis**: The paper's primary theoretical contribution is the systematic synthesis of a comprehensive roadmap, providing a structured way to think about and implement Responsible AI from a software engineering perspective. It identifies the critical gaps between high-level principles and practical implementation, offering a framework to bridge this divide.\n\n### 5. Experimental Validation\n\n*   **Experiments Conducted**: The paper itself does not present experimental validation of a proposed technical solution. Instead, its foundation is a **Systematic Literature Review (SLR)**. The SLR involved:\n    *   Defining two research questions: 1) What responsible AI principles are addressed? 2) What solutions for responsible AI can be identified?\n    *   Searching five major digital libraries (ACM, IEEE, Science Direct, Springer Link, Google Scholar).\n    *   Identifying 159 primary studies that presented concrete solutions for responsible AI (excluding high-level frameworks) \\cite{lu2022et0}.\n*   **Key Performance Metrics/Comparison Results**: As a roadmap paper based on an SLR, it does not report performance metrics or comparative results of a new system. The \"results\" are the synthesized current state, identified challenges, and the proposed roadmap itself, derived from the analysis of the 159 primary studies.\n\n### 6. Limitations & Scope\n\n*   **Technical Limitations/Assumptions**:\n    *   The roadmap is a *proposal* for future research and development, not a fully implemented or validated system. Its effectiveness would need to be empirically tested in real-world AI development contexts.\n    *   The SLR, while systematic, is a snapshot of existing literature up to March 2022 and may not capture all emerging practices.\n    *   The paper focuses on the software engineering perspective, acknowledging that Responsible AI is multidisciplinary but positioning SE as the key driver. This implies that non-SE aspects (e.g., purely legal, philosophical, or sociological) are considered primarily through their implications for engineering.\n*   **Scope of Applicability**: The roadmap is broadly applicable to the development of any AI system where ethical considerations are paramount. It aims to provide guidance for governments, organizations, and development teams involved in the AI lifecycle \\cite{lu2022et0}.\n\n### 7. Technical Significance\n\n*   **Advancement of State-of-the-Art**: \\cite{lu2022et0} significantly advances the technical state-of-the-art by providing the first comprehensive, software engineering-focused roadmap for operationalizing Responsible AI. It moves beyond abstract ethical discussions and isolated algorithmic fixes to offer a structured, lifecycle-oriented approach, making RAI more tangible and actionable for practitioners.\n*   **Potential Impact on Future Research**:\n    *   **Structured Research Agenda**: Provides a clear research agenda by identifying critical challenges in multi-level governance, process integration, and responsible-AI-by-design.\n    *   **Interdisciplinary Collaboration**: Highlights the necessity for improved communication and collaboration between software engineers, machine learning experts, social scientists, and ethicists.\n    *   **Tooling and Method Development**: Will likely spur research into developing specific tools, methods, and architectural patterns that implement the practices outlined in the roadmap (e.g., ethical requirement elicitation tools, ethical risk assessment frameworks, automated ethical code review, and verifiable credential infrastructures) \\cite{lu2022et0}.\n    *   **Education**: Emphasizes the urgent need for responsible AI education, influencing curriculum development in computer science and software engineering.",
      "keywords": [
        "Responsible AI (RAI)",
        "operationalizing Responsible AI",
        "software engineering",
        "AI system lifecycle",
        "Systematic Literature Review",
        "research roadmap",
        "multi-level governance",
        "process-oriented practices",
        "Responsible-AI-by-Design",
        "ethical principles",
        "verifiable ethical requirements",
        "accountability mechanisms",
        "bridging principles and algorithms"
      ],
      "paper_type": "based on the abstract and introduction, this paper is best classified as a **position** paper.\n\nhere's why:\n\n1.  **identifies a problem and proposes a direction:** the abstract clearly states \"serious concerns about its ability to behave and make decisions responsibly\" and that existing ethical regulations are \"high level and difficult to put into practice.\" it also notes that \"most ai researchers focus on algorithmic solutions, while the responsible ai challenges actually crosscut the entire engineering lifecycle.\" this sets up a problem statement.\n2.  **aims to \"develop a roadmap\":** the core aim is to \"develop a roadmap on software engineering for responsible ai.\" a roadmap is inherently a strategic plan, a vision for future work, and a proposed direction.\n3.  **outlines strategic pillars:** the roadmap focuses on \"(i) establishing multi-level governance,\" \"(ii) setting up the development processes,\" and \"(iii) building responsible-ai-by-design through system-level architectural style, patterns and techniques.\" these are high-level strategic pillars for how to approach the problem, rather than a detailed technical implementation of a specific algorithm or system.\n4.  **keywords alignment:**\n    *   **position criteria:** \"argues for viewpoint or future direction.\" the paper argues for a specific approach (the roadmap) to operationalize responsible ai and outlines the future direction this field should take. \"vision\" and \"future\" are strongly implied by \"roadmap.\"\n    *   **technical criteria:** while it aims to \"develop\" a roadmap, and the roadmap involves \"methods\" (software engineering methods), the paper doesn't present a *new* specific algorithm, system, or detailed technical method in the way a typical technical paper would. it's more about the *strategy* for applying software engineering.\n\nthe paper is arguing for a particular strategic approach and outlining a path forward, which aligns perfectly with the definition of a position paper."
    },
    "file_name": "dccd738bc67c1e4b807b07872ff065fadc4253da.pdf"
  },
  {
    "success": true,
    "doc_id": "abd92c6ea27b049597dcb6697e33010e",
    "summary": "Open source software communities are a significant site of AI development, but “Ethical AI” discourses largely focus on the problems that arise in software produced by private companies. Design, policy and tooling interventions to encourage “Ethical AI” based on studies in private companies risk being ill-suited for an open source context, which operates under radically different organizational structures, cultural norms, and incentives. In this paper, we show that significant and understudied harms and possibilities originate from differing practices of transparency and accountability in the open source community. We conducted an interview study of an AI-enabled open source Deepfake project to understand how members of that community reason about the ethics of their work. We found that notions of the “Freedom 0” to use code without any restriction, alongside beliefs about technology neutrality and technological inevitability, were central to how community members framed their responsibilities, and the actions they believed were and were not available to them. We propose a continuum between harms resulting from how a system is implemented versus how it is used, and show how commitments to radical transparency in open source allow great ethical scrutiny for harms wrought by implementation bugs, but allow harms through (mis)use to proliferate, requiring a deeper toolbox for disincentivizing harmful use. We discuss how an assumption of control over downstream uses is often implicit in discourses of “Ethical AI”, but outline alternative possibilities for action in cases such as open source where this assumption may not hold.",
    "intriguing_abstract": "Open source software communities are a significant site of AI development, but “Ethical AI” discourses largely focus on the problems that arise in software produced by private companies. Design, policy and tooling interventions to encourage “Ethical AI” based on studies in private companies risk being ill-suited for an open source context, which operates under radically different organizational structures, cultural norms, and incentives. In this paper, we show that significant and understudied harms and possibilities originate from differing practices of transparency and accountability in the open source community. We conducted an interview study of an AI-enabled open source Deepfake project to understand how members of that community reason about the ethics of their work. We found that notions of the “Freedom 0” to use code without any restriction, alongside beliefs about technology neutrality and technological inevitability, were central to how community members framed their responsibilities, and the actions they believed were and were not available to them. We propose a continuum between harms resulting from how a system is implemented versus how it is used, and show how commitments to radical transparency in open source allow great ethical scrutiny for harms wrought by implementation bugs, but allow harms through (mis)use to proliferate, requiring a deeper toolbox for disincentivizing harmful use. We discuss how an assumption of control over downstream uses is often implicit in discourses of “Ethical AI”, but outline alternative possibilities for action in cases such as open source where this assumption may not hold.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a4374578c7a7226c159c77d7cd98b8a9d293c184.pdf",
    "citation_key": "widder20222na",
    "metadata": {
      "title": "Limits and Possibilities for “Ethical AI” in Open Source: A Study of Deepfakes",
      "authors": [
        "D. Widder",
        "D. Nafus",
        "Laura A. Dabbish",
        "J. Herbsleb"
      ],
      "published_date": "2022",
      "abstract": "Open source software communities are a significant site of AI development, but “Ethical AI” discourses largely focus on the problems that arise in software produced by private companies. Design, policy and tooling interventions to encourage “Ethical AI” based on studies in private companies risk being ill-suited for an open source context, which operates under radically different organizational structures, cultural norms, and incentives. In this paper, we show that significant and understudied harms and possibilities originate from differing practices of transparency and accountability in the open source community. We conducted an interview study of an AI-enabled open source Deepfake project to understand how members of that community reason about the ethics of their work. We found that notions of the “Freedom 0” to use code without any restriction, alongside beliefs about technology neutrality and technological inevitability, were central to how community members framed their responsibilities, and the actions they believed were and were not available to them. We propose a continuum between harms resulting from how a system is implemented versus how it is used, and show how commitments to radical transparency in open source allow great ethical scrutiny for harms wrought by implementation bugs, but allow harms through (mis)use to proliferate, requiring a deeper toolbox for disincentivizing harmful use. We discuss how an assumption of control over downstream uses is often implicit in discourses of “Ethical AI”, but outline alternative possibilities for action in cases such as open source where this assumption may not hold.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a4374578c7a7226c159c77d7cd98b8a9d293c184.pdf",
      "venue": "Conference on Fairness, Accountability and Transparency",
      "citationCount": 61,
      "score": 20.333333333333332,
      "summary": "Open source software communities are a significant site of AI development, but “Ethical AI” discourses largely focus on the problems that arise in software produced by private companies. Design, policy and tooling interventions to encourage “Ethical AI” based on studies in private companies risk being ill-suited for an open source context, which operates under radically different organizational structures, cultural norms, and incentives. In this paper, we show that significant and understudied harms and possibilities originate from differing practices of transparency and accountability in the open source community. We conducted an interview study of an AI-enabled open source Deepfake project to understand how members of that community reason about the ethics of their work. We found that notions of the “Freedom 0” to use code without any restriction, alongside beliefs about technology neutrality and technological inevitability, were central to how community members framed their responsibilities, and the actions they believed were and were not available to them. We propose a continuum between harms resulting from how a system is implemented versus how it is used, and show how commitments to radical transparency in open source allow great ethical scrutiny for harms wrought by implementation bugs, but allow harms through (mis)use to proliferate, requiring a deeper toolbox for disincentivizing harmful use. We discuss how an assumption of control over downstream uses is often implicit in discourses of “Ethical AI”, but outline alternative possibilities for action in cases such as open source where this assumption may not hold.",
      "keywords": []
    },
    "file_name": "a4374578c7a7226c159c77d7cd98b8a9d293c184.pdf"
  },
  {
    "success": true,
    "doc_id": "c52819ae35631fc075b66fd6bba465e3",
    "summary": "Here is a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{haakman2020xky}\" when referencing this paper.\n\n---\n\n**1. Research Problem & Motivation**\n*   **Problem**: Existing Artificial Intelligence (AI) lifecycle models (e.g., CRISP-DM, TDSP) are inadequate for the current needs of the industry, particularly in heavily-regulated domains like fintech \\cite{haakman2020xky}. As intelligent systems integrate with traditional software, they must comply with the same rigorous software engineering development processes and standards.\n*   **Motivation**: There is a critical need to understand the real-world processes of AI system development and to identify deficiencies in state-of-the-art lifecycle models when applied in complex, regulated environments. The paper argues that the challenges of applying Machine Learning (ML) extend beyond sophisticated algorithms, requiring a holistic focus on the entire lifecycle, especially for organizations undergoing digital transformation to embrace AI \\cite{haakman2020xky}.\n\n**2. Related Work & Positioning**\n*   **Existing Approaches**: The paper reviews prominent ML lifecycle models (CRISP-DM \\cite{chapman2000crisp}, TDSP \\cite{microsoft2017team}, and Microsoft's ML workflow \\cite{amershi2019software}) and discusses related industry case studies (e.g., Microsoft, Booking.com, Twitter) and research on ML-specific software engineering challenges (e.g., technical debt, production readiness, experiment management) \\cite{haakman2020xky}.\n*   **Limitations of Previous Solutions**:\n    *   Existing lifecycle models do not adequately address the unique challenges of AI systems operating under heavy regulations, such as those prevalent in the fintech industry \\cite{haakman2020xky}.\n    *   Previous industry studies often focused on organizations with established ML practices (e.g., Microsoft) or did not define formal lifecycle models (e.g., Booking.com), potentially overlooking the specific challenges faced by organizations *transitioning* to AI or those in highly regulated sectors.\n    *   There was a recognized gap in understanding the post-evaluation stages of the ML lifecycle, such as deployment and monitoring, which this study aims to extend beyond prior work \\cite{haakman2020xky}.\n\n**3. Technical Approach & Innovation**\n*   **Core Technical Method/Algorithm**: This paper does not propose a new technical algorithm. Instead, its core method is an *exploratory single-case study methodology* \\cite{haakman2020xky}. It involved conducting semi-structured interviews with 17 participants from diverse roles and departments within ING, a global bank, and triangulating this data with other organizational resources. The goal was to empirically identify gaps and challenges in existing AI lifecycle models.\n*   **Novelty/Difference**: The approach is novel due to its specific focus on the *fintech domain*, which introduces unique regulatory and compliance challenges not fully addressed by generic ML lifecycle models. By studying an organization undergoing a significant digital transformation to integrate AI at scale, the research provides empirical insights into the practical deficiencies of current practices, leading to the identification of previously overlooked, yet critical, stages in the AI lifecycle \\cite{haakman2020xky}.\n\n**4. Key Technical Contributions**\n*   **Novel Algorithms, Methods, or Techniques**: The study identifies and highlights critical, previously overlooked stages essential for robust AI system development, particularly in regulated environments. These stages are:\n    *   `Data Collection` (emphasizing its complexity beyond simple acquisition).\n    *   `Feasibility Study` (for early assessment of business value and technical viability).\n    *   `Documentation` (for transparency, auditability, and maintenance).\n    *   `Model Monitoring` (for continuous performance and drift detection post-deployment).\n    *   `Model Risk Assessment` (for evaluating regulatory, ethical, and operational risks) \\cite{haakman2020xky}.\n*   **System Design or Architectural Innovations**: The findings implicitly contribute to future system design by underscoring the need for architectural considerations that support these overlooked stages, such as robust data governance, automated documentation generation, and integrated monitoring and risk assessment frameworks for AI systems.\n*   **Theoretical Insights or Analysis**: The paper provides empirical evidence that the real challenges of applying Machine Learning extend significantly beyond sophisticated learning algorithms, necessitating a holistic focus on the entire AI lifecycle. It refines existing lifecycle models (CRISP-DM and TDSP) by integrating these newly identified stages, offering a more comprehensive framework for AI engineering in regulated industries \\cite{haakman2020xky}.\n\n**5. Experimental Validation**\n*   **Experiments Conducted**: An exploratory single-case study was performed at ING, a global bank with a strong focus on fintech and AI professionalization. Data was primarily collected through semi-structured interviews with 17 participants from various roles and departments (e.g., IT Engineers, Product Managers, Data Scientists). This interview data was triangulated with other internal organizational resources \\cite{haakman2020xky}. Data saturation was used as a stopping criterion for interviews.\n*   **Key Performance Metrics and Comparison Results**:\n    *   The study's \"performance\" is measured by its success in *identifying critical gaps* in existing ML lifecycle models and *unveiling specific challenges* in developing ML applications at scale within a fintech context.\n    *   The key finding is that `data collection`, `feasibility study`, `documentation`, `model monitoring`, and `model risk assessment` are consistently overlooked by previous lifecycle models \\cite{haakman2020xky}.\n    *   The research highlighted a significant lack of standards and a strong need for automation in the documentation and governance of ML models.\n    *   These findings implicitly compare observed industry practices against the theoretical stages of CRISP-DM, TDSP, and Amershi et al.'s model, demonstrating their practical deficiencies in a real-world, regulated environment \\cite{haakman2020xky}.\n\n**6. Limitations & Scope**\n*   **Technical Limitations or Assumptions**: As a single-case exploratory study at one organization (ING), the findings, while rich, may not be universally generalizable to all fintech organizations or other industries without further validation \\cite{haakman2020xky}. The reliance on self-reported interview data introduces potential for recall bias or subjective interpretation.\n*   **Scope of Applicability**: The findings are most applicable to large, heavily-regulated organizations in the fintech domain that are undergoing digital transformation to integrate AI at scale. While some insights may extend to other industries, the emphasis on regulatory compliance and risk assessment is highly specific to financial services. The study focuses specifically on Machine Learning as a branch of AI \\cite{haakman2020xky}.\n\n**7. Technical Significance**\n*   **Advance State-of-the-Art**: This paper significantly advances the technical state-of-the-art in AI Engineering by empirically identifying crucial, often neglected, stages in the AI lifecycle that are vital for the successful, compliant, and robust deployment of ML systems in regulated industries \\cite{haakman2020xky}. It shifts the focus from purely algorithmic advancements to the comprehensive engineering, governance, and operational aspects of AI systems.\n*   **Potential Impact on Future Research**:\n    *   It paves the way for future research into developing standardized processes, tools, and automation for the newly identified stages: `data collection`, `feasibility studies`, `documentation`, `model monitoring`, and `model risk assessment` in AI systems \\cite{haakman2020xky}.\n    *   It highlights the need for interdisciplinary research combining software engineering, data science, and regulatory compliance.\n    *   The findings can inform and shape the education of AI practitioners, emphasizing a broader skillset beyond just model development.\n    *   It encourages the development of new lifecycle models or significant revisions to existing ones that explicitly incorporate these identified stages, especially for critical, regulated applications.",
    "intriguing_abstract": "The transformative potential of Artificial Intelligence often collides with the rigorous demands of heavily regulated industries. While established AI lifecycle models like CRISP-DM and TDSP offer foundational guidance, their real-world application in domains such as fintech reveals critical, unaddressed challenges. This paper presents an exploratory single-case study conducted within a global financial institution, empirically uncovering profound deficiencies in current AI development practices when integrating intelligent systems at scale. Through extensive semi-structured interviews with 17 practitioners, we identify five crucial, yet consistently overlooked, stages essential for robust and compliant AI systems: `Data Collection`, `Feasibility Study`, `Documentation`, `Model Monitoring`, and `Model Risk Assessment`. Our findings underscore that successful AI engineering extends far beyond algorithmic sophistication, demanding a holistic lifecycle perspective that prioritizes transparency, auditability, and continuous governance. This research refines the understanding of the AI lifecycle, offering vital empirical insights for organizations undergoing digital transformation and charting a path towards more resilient and trustworthy AI deployments in regulated environments.",
    "keywords": [
      "AI lifecycle models",
      "Machine Learning (ML)",
      "Fintech domain",
      "Regulated environments",
      "Exploratory single-case study",
      "Gaps in AI lifecycle models",
      "Data collection",
      "Feasibility study",
      "Documentation (AI systems)",
      "Model monitoring",
      "Model risk assessment",
      "AI engineering",
      "Digital transformation",
      "Compliance challenges"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8908d069c4cb45ac2dd937e8c48712a766b037f6.pdf",
    "citation_key": "haakman2020xky",
    "metadata": {
      "title": "AI lifecycle models need to be revised",
      "authors": [
        "Mark Haakman",
        "Luís Cruz",
        "Hennie Huijgens",
        "Arie van Deursen"
      ],
      "published_date": "2020",
      "abstract": "Tech-leading organizations are embracing the forthcoming artificial intelligence revolution. Intelligent systems are replacing and cooperating with traditional software components. Thus, the same development processes and standards in software engineering ought to be complied in artificial intelligence systems. This study aims to understand the processes by which artificial intelligence-based systems are developed and how state-of-the-art lifecycle models fit the current needs of the industry. We conducted an exploratory case study at ING, a global bank with a strong European base. We interviewed 17 people with different roles and from different departments within the organization. We have found that the following stages have been overlooked by previous lifecycle models: data collection, feasibility study, documentation, model monitoring, and model risk assessment. Our work shows that the real challenges of applying Machine Learning go much beyond sophisticated learning algorithms – more focus is needed on the entire lifecycle. In particular, regardless of the existing development tools for Machine Learning, we observe that they are still not meeting the particularities of this field.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8908d069c4cb45ac2dd937e8c48712a766b037f6.pdf",
      "venue": "Empirical Software Engineering",
      "citationCount": 97,
      "score": 19.400000000000002,
      "summary": "Here is a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{haakman2020xky}\" when referencing this paper.\n\n---\n\n**1. Research Problem & Motivation**\n*   **Problem**: Existing Artificial Intelligence (AI) lifecycle models (e.g., CRISP-DM, TDSP) are inadequate for the current needs of the industry, particularly in heavily-regulated domains like fintech \\cite{haakman2020xky}. As intelligent systems integrate with traditional software, they must comply with the same rigorous software engineering development processes and standards.\n*   **Motivation**: There is a critical need to understand the real-world processes of AI system development and to identify deficiencies in state-of-the-art lifecycle models when applied in complex, regulated environments. The paper argues that the challenges of applying Machine Learning (ML) extend beyond sophisticated algorithms, requiring a holistic focus on the entire lifecycle, especially for organizations undergoing digital transformation to embrace AI \\cite{haakman2020xky}.\n\n**2. Related Work & Positioning**\n*   **Existing Approaches**: The paper reviews prominent ML lifecycle models (CRISP-DM \\cite{chapman2000crisp}, TDSP \\cite{microsoft2017team}, and Microsoft's ML workflow \\cite{amershi2019software}) and discusses related industry case studies (e.g., Microsoft, Booking.com, Twitter) and research on ML-specific software engineering challenges (e.g., technical debt, production readiness, experiment management) \\cite{haakman2020xky}.\n*   **Limitations of Previous Solutions**:\n    *   Existing lifecycle models do not adequately address the unique challenges of AI systems operating under heavy regulations, such as those prevalent in the fintech industry \\cite{haakman2020xky}.\n    *   Previous industry studies often focused on organizations with established ML practices (e.g., Microsoft) or did not define formal lifecycle models (e.g., Booking.com), potentially overlooking the specific challenges faced by organizations *transitioning* to AI or those in highly regulated sectors.\n    *   There was a recognized gap in understanding the post-evaluation stages of the ML lifecycle, such as deployment and monitoring, which this study aims to extend beyond prior work \\cite{haakman2020xky}.\n\n**3. Technical Approach & Innovation**\n*   **Core Technical Method/Algorithm**: This paper does not propose a new technical algorithm. Instead, its core method is an *exploratory single-case study methodology* \\cite{haakman2020xky}. It involved conducting semi-structured interviews with 17 participants from diverse roles and departments within ING, a global bank, and triangulating this data with other organizational resources. The goal was to empirically identify gaps and challenges in existing AI lifecycle models.\n*   **Novelty/Difference**: The approach is novel due to its specific focus on the *fintech domain*, which introduces unique regulatory and compliance challenges not fully addressed by generic ML lifecycle models. By studying an organization undergoing a significant digital transformation to integrate AI at scale, the research provides empirical insights into the practical deficiencies of current practices, leading to the identification of previously overlooked, yet critical, stages in the AI lifecycle \\cite{haakman2020xky}.\n\n**4. Key Technical Contributions**\n*   **Novel Algorithms, Methods, or Techniques**: The study identifies and highlights critical, previously overlooked stages essential for robust AI system development, particularly in regulated environments. These stages are:\n    *   `Data Collection` (emphasizing its complexity beyond simple acquisition).\n    *   `Feasibility Study` (for early assessment of business value and technical viability).\n    *   `Documentation` (for transparency, auditability, and maintenance).\n    *   `Model Monitoring` (for continuous performance and drift detection post-deployment).\n    *   `Model Risk Assessment` (for evaluating regulatory, ethical, and operational risks) \\cite{haakman2020xky}.\n*   **System Design or Architectural Innovations**: The findings implicitly contribute to future system design by underscoring the need for architectural considerations that support these overlooked stages, such as robust data governance, automated documentation generation, and integrated monitoring and risk assessment frameworks for AI systems.\n*   **Theoretical Insights or Analysis**: The paper provides empirical evidence that the real challenges of applying Machine Learning extend significantly beyond sophisticated learning algorithms, necessitating a holistic focus on the entire AI lifecycle. It refines existing lifecycle models (CRISP-DM and TDSP) by integrating these newly identified stages, offering a more comprehensive framework for AI engineering in regulated industries \\cite{haakman2020xky}.\n\n**5. Experimental Validation**\n*   **Experiments Conducted**: An exploratory single-case study was performed at ING, a global bank with a strong focus on fintech and AI professionalization. Data was primarily collected through semi-structured interviews with 17 participants from various roles and departments (e.g., IT Engineers, Product Managers, Data Scientists). This interview data was triangulated with other internal organizational resources \\cite{haakman2020xky}. Data saturation was used as a stopping criterion for interviews.\n*   **Key Performance Metrics and Comparison Results**:\n    *   The study's \"performance\" is measured by its success in *identifying critical gaps* in existing ML lifecycle models and *unveiling specific challenges* in developing ML applications at scale within a fintech context.\n    *   The key finding is that `data collection`, `feasibility study`, `documentation`, `model monitoring`, and `model risk assessment` are consistently overlooked by previous lifecycle models \\cite{haakman2020xky}.\n    *   The research highlighted a significant lack of standards and a strong need for automation in the documentation and governance of ML models.\n    *   These findings implicitly compare observed industry practices against the theoretical stages of CRISP-DM, TDSP, and Amershi et al.'s model, demonstrating their practical deficiencies in a real-world, regulated environment \\cite{haakman2020xky}.\n\n**6. Limitations & Scope**\n*   **Technical Limitations or Assumptions**: As a single-case exploratory study at one organization (ING), the findings, while rich, may not be universally generalizable to all fintech organizations or other industries without further validation \\cite{haakman2020xky}. The reliance on self-reported interview data introduces potential for recall bias or subjective interpretation.\n*   **Scope of Applicability**: The findings are most applicable to large, heavily-regulated organizations in the fintech domain that are undergoing digital transformation to integrate AI at scale. While some insights may extend to other industries, the emphasis on regulatory compliance and risk assessment is highly specific to financial services. The study focuses specifically on Machine Learning as a branch of AI \\cite{haakman2020xky}.\n\n**7. Technical Significance**\n*   **Advance State-of-the-Art**: This paper significantly advances the technical state-of-the-art in AI Engineering by empirically identifying crucial, often neglected, stages in the AI lifecycle that are vital for the successful, compliant, and robust deployment of ML systems in regulated industries \\cite{haakman2020xky}. It shifts the focus from purely algorithmic advancements to the comprehensive engineering, governance, and operational aspects of AI systems.\n*   **Potential Impact on Future Research**:\n    *   It paves the way for future research into developing standardized processes, tools, and automation for the newly identified stages: `data collection`, `feasibility studies`, `documentation`, `model monitoring`, and `model risk assessment` in AI systems \\cite{haakman2020xky}.\n    *   It highlights the need for interdisciplinary research combining software engineering, data science, and regulatory compliance.\n    *   The findings can inform and shape the education of AI practitioners, emphasizing a broader skillset beyond just model development.\n    *   It encourages the development of new lifecycle models or significant revisions to existing ones that explicitly incorporate these identified stages, especially for critical, regulated applications.",
      "keywords": [
        "AI lifecycle models",
        "Machine Learning (ML)",
        "Fintech domain",
        "Regulated environments",
        "Exploratory single-case study",
        "Gaps in AI lifecycle models",
        "Data collection",
        "Feasibility study",
        "Documentation (AI systems)",
        "Model monitoring",
        "Model risk assessment",
        "AI engineering",
        "Digital transformation",
        "Compliance challenges"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we conducted an exploratory **case study** at ing, a global bank...\" and \"we interviewed 17 people...\"\n*   the abstract also mentions \"we have found that the following stages have been overlooked...\" which are findings from this specific study.\n*   the keywords include \"case study\".\n*   the introduction discusses learning \"lessons to be learned to help other organizations and guide research in a direction that is meaningful to the industry,\" particularly for \"heavily-regulated industries such as fintech,\" indicating a focus on real-world application and specific contexts.\n\nthis directly aligns with the criteria for a **case_study**: \"detailed analysis of specific applications\" and \"abstract mentions: 'case study', 'application', 'practice', 'experience'\". while it is also an empirical study, \"case_study\" is a more specific and accurate classification given the explicit mention of the methodology.\n\n**classification: case_study**"
    },
    "file_name": "8908d069c4cb45ac2dd937e8c48712a766b037f6.pdf"
  },
  {
    "success": true,
    "doc_id": "f75e6683d8724674c68ed3ad7842382b",
    "summary": "As the trajectory of the Internet of Things (IoT) moving at a rapid pace and with the rapid worldwide development and public embracement of wearable sensors, these days, most companies and organizations are awash in massive amounts of data. Determining how to profit from data deluge can give companies an edge in the market because data have the potential to add tremendous value to many aspects of a business. The market has already seen a level of monetization across vertical domains in the form of layering connected devices with a variety of Software-as-a-Service (SaaS) choices, such as subscription plans or smart device insights. Out of this arena is evolving a “machine economy” in which the ability to correctly monetize data rather than simply hoard it, will provide a significant advantage in a competitive digital environment. The recent advent of the technological advances in the fields of big data, analytics, and artificial intelligence (AI) has opened new avenues of competition, where data are utilized strategically and treated as a continuously changing asset able to unleash new revenue opportunities for monetization. Such growth has made room for an onslaught of new tools, architectures, business models, platforms, and marketplaces that enable organizations to successfully monetize data. In fact, emerging business models are striving to alter the power balance between users and companies that harvest information. Start-ups and organizations are offering to sell user data to data analytics companies and other businesses. Monetizing data goes beyond just selling data. It is also possible to include steps that add value to data. Generally, organizations can monetize data by: 1) utilizing it to make better business decisions or improve processes; 2) surrounding flagship services or products with data; or 3) selling information to current or new markets. This article will address all important aspects of IoT data monetization with more focus on the healthcare industry and discuss the corresponding challenges, such as data management, scalability, regulations, interoperability, security, and privacy. In addition, it presents a holistic reference architecture for the healthcare data economy with an in-depth case study on the detection and prediction of cardiac anomalies using multiparty computation (MPC) and privacy-preserving machine learning (PPML) techniques.",
    "intriguing_abstract": "As the trajectory of the Internet of Things (IoT) moving at a rapid pace and with the rapid worldwide development and public embracement of wearable sensors, these days, most companies and organizations are awash in massive amounts of data. Determining how to profit from data deluge can give companies an edge in the market because data have the potential to add tremendous value to many aspects of a business. The market has already seen a level of monetization across vertical domains in the form of layering connected devices with a variety of Software-as-a-Service (SaaS) choices, such as subscription plans or smart device insights. Out of this arena is evolving a “machine economy” in which the ability to correctly monetize data rather than simply hoard it, will provide a significant advantage in a competitive digital environment. The recent advent of the technological advances in the fields of big data, analytics, and artificial intelligence (AI) has opened new avenues of competition, where data are utilized strategically and treated as a continuously changing asset able to unleash new revenue opportunities for monetization. Such growth has made room for an onslaught of new tools, architectures, business models, platforms, and marketplaces that enable organizations to successfully monetize data. In fact, emerging business models are striving to alter the power balance between users and companies that harvest information. Start-ups and organizations are offering to sell user data to data analytics companies and other businesses. Monetizing data goes beyond just selling data. It is also possible to include steps that add value to data. Generally, organizations can monetize data by: 1) utilizing it to make better business decisions or improve processes; 2) surrounding flagship services or products with data; or 3) selling information to current or new markets. This article will address all important aspects of IoT data monetization with more focus on the healthcare industry and discuss the corresponding challenges, such as data management, scalability, regulations, interoperability, security, and privacy. In addition, it presents a holistic reference architecture for the healthcare data economy with an in-depth case study on the detection and prediction of cardiac anomalies using multiparty computation (MPC) and privacy-preserving machine learning (PPML) techniques.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/41953da351150461612e5f72f914e45bdcbba31a.pdf",
    "citation_key": "firouzi20226vl",
    "metadata": {
      "title": "AI-Driven Data Monetization: The Other Face of Data in IoT-Based Smart and Connected Health",
      "authors": [
        "F. Firouzi",
        "Bahar Farahani",
        "Mojtaba Barzegari",
        "M. Daneshmand"
      ],
      "published_date": "2022",
      "abstract": "As the trajectory of the Internet of Things (IoT) moving at a rapid pace and with the rapid worldwide development and public embracement of wearable sensors, these days, most companies and organizations are awash in massive amounts of data. Determining how to profit from data deluge can give companies an edge in the market because data have the potential to add tremendous value to many aspects of a business. The market has already seen a level of monetization across vertical domains in the form of layering connected devices with a variety of Software-as-a-Service (SaaS) choices, such as subscription plans or smart device insights. Out of this arena is evolving a “machine economy” in which the ability to correctly monetize data rather than simply hoard it, will provide a significant advantage in a competitive digital environment. The recent advent of the technological advances in the fields of big data, analytics, and artificial intelligence (AI) has opened new avenues of competition, where data are utilized strategically and treated as a continuously changing asset able to unleash new revenue opportunities for monetization. Such growth has made room for an onslaught of new tools, architectures, business models, platforms, and marketplaces that enable organizations to successfully monetize data. In fact, emerging business models are striving to alter the power balance between users and companies that harvest information. Start-ups and organizations are offering to sell user data to data analytics companies and other businesses. Monetizing data goes beyond just selling data. It is also possible to include steps that add value to data. Generally, organizations can monetize data by: 1) utilizing it to make better business decisions or improve processes; 2) surrounding flagship services or products with data; or 3) selling information to current or new markets. This article will address all important aspects of IoT data monetization with more focus on the healthcare industry and discuss the corresponding challenges, such as data management, scalability, regulations, interoperability, security, and privacy. In addition, it presents a holistic reference architecture for the healthcare data economy with an in-depth case study on the detection and prediction of cardiac anomalies using multiparty computation (MPC) and privacy-preserving machine learning (PPML) techniques.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/41953da351150461612e5f72f914e45bdcbba31a.pdf",
      "venue": "IEEE Internet of Things Journal",
      "citationCount": 57,
      "score": 19.0,
      "summary": "As the trajectory of the Internet of Things (IoT) moving at a rapid pace and with the rapid worldwide development and public embracement of wearable sensors, these days, most companies and organizations are awash in massive amounts of data. Determining how to profit from data deluge can give companies an edge in the market because data have the potential to add tremendous value to many aspects of a business. The market has already seen a level of monetization across vertical domains in the form of layering connected devices with a variety of Software-as-a-Service (SaaS) choices, such as subscription plans or smart device insights. Out of this arena is evolving a “machine economy” in which the ability to correctly monetize data rather than simply hoard it, will provide a significant advantage in a competitive digital environment. The recent advent of the technological advances in the fields of big data, analytics, and artificial intelligence (AI) has opened new avenues of competition, where data are utilized strategically and treated as a continuously changing asset able to unleash new revenue opportunities for monetization. Such growth has made room for an onslaught of new tools, architectures, business models, platforms, and marketplaces that enable organizations to successfully monetize data. In fact, emerging business models are striving to alter the power balance between users and companies that harvest information. Start-ups and organizations are offering to sell user data to data analytics companies and other businesses. Monetizing data goes beyond just selling data. It is also possible to include steps that add value to data. Generally, organizations can monetize data by: 1) utilizing it to make better business decisions or improve processes; 2) surrounding flagship services or products with data; or 3) selling information to current or new markets. This article will address all important aspects of IoT data monetization with more focus on the healthcare industry and discuss the corresponding challenges, such as data management, scalability, regulations, interoperability, security, and privacy. In addition, it presents a holistic reference architecture for the healthcare data economy with an in-depth case study on the detection and prediction of cardiac anomalies using multiparty computation (MPC) and privacy-preserving machine learning (PPML) techniques.",
      "keywords": []
    },
    "file_name": "41953da351150461612e5f72f914e45bdcbba31a.pdf"
  },
  {
    "success": true,
    "doc_id": "521f1f6f259965596b6c850be1432319",
    "summary": "FPGAs provide significant advantages in throughput, latency, and energy efficiency for implementing low-latency, compute-intensive applications when compared to general-purpose CPUs and GPUs. Over the last decade, FPGAs have evolved into highly configurable SoCs with on-chip CPUs, domain-specific programmable accelerators, and flexible connectivity options. Recently, Xilinx introduced a new heterogeneous compute architecture, the Adaptive Compute Acceleration Platform (ACAP), with significantly more flexibility and performance to address an evolving set of new applications such as machine learning. This advancement on the device side is accompanied by similar advances on higher-level programming approaches to make FPGAs and ACAPs significantly easy to use for a wide range of applications. Xilinx Vitis Unified Software Platform is a comprehensive development environment to build and seamlessly deploy accelerated applications on Xilinx platforms including Alveo cards, FPGA-instances in the cloud, and embedded platforms. It addresses the three major industry trends: the need for heterogenous computing, applications that span cloud to edge to end-point, and AI proliferation. Vitis supports application programming using C, C++ and OpenCL, and it enables the development of large-scale data processing and machine learning applications using familiar, higher-level frameworks such as TensorFlow and SPARK. To facilitate communication between the host application and accelerators, Xilinx Runtime library (XRT) provides APIs for accelerator life-cycle management, accelerator execution management, memory allocation, and data communication between the host application and accelerators. In addition, a rich set of performance-optimized, open-source libraries significantly ease the application development. Vitis AI, an integral part of Vitis, enables AI inference acceleration on Xilinx platforms. It supports industry's leading deep learning frameworks like Tensorflow and Caffe, and offers a comprehensive suite of tools and APIs to prune, quantize, optimize, and compile pre-trained models to achieve the highest AI inference performance on Xilinx platforms. This talk provides an overview of Vitis and Vitis AI development environments.",
    "intriguing_abstract": "FPGAs provide significant advantages in throughput, latency, and energy efficiency for implementing low-latency, compute-intensive applications when compared to general-purpose CPUs and GPUs. Over the last decade, FPGAs have evolved into highly configurable SoCs with on-chip CPUs, domain-specific programmable accelerators, and flexible connectivity options. Recently, Xilinx introduced a new heterogeneous compute architecture, the Adaptive Compute Acceleration Platform (ACAP), with significantly more flexibility and performance to address an evolving set of new applications such as machine learning. This advancement on the device side is accompanied by similar advances on higher-level programming approaches to make FPGAs and ACAPs significantly easy to use for a wide range of applications. Xilinx Vitis Unified Software Platform is a comprehensive development environment to build and seamlessly deploy accelerated applications on Xilinx platforms including Alveo cards, FPGA-instances in the cloud, and embedded platforms. It addresses the three major industry trends: the need for heterogenous computing, applications that span cloud to edge to end-point, and AI proliferation. Vitis supports application programming using C, C++ and OpenCL, and it enables the development of large-scale data processing and machine learning applications using familiar, higher-level frameworks such as TensorFlow and SPARK. To facilitate communication between the host application and accelerators, Xilinx Runtime library (XRT) provides APIs for accelerator life-cycle management, accelerator execution management, memory allocation, and data communication between the host application and accelerators. In addition, a rich set of performance-optimized, open-source libraries significantly ease the application development. Vitis AI, an integral part of Vitis, enables AI inference acceleration on Xilinx platforms. It supports industry's leading deep learning frameworks like Tensorflow and Caffe, and offers a comprehensive suite of tools and APIs to prune, quantize, optimize, and compile pre-trained models to achieve the highest AI inference performance on Xilinx platforms. This talk provides an overview of Vitis and Vitis AI development environments.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/275f66ef562a00d01e9eaa10b0363688b7c5e36f.pdf",
    "citation_key": "kathail2020ylx",
    "metadata": {
      "title": "Xilinx Vitis Unified Software Platform",
      "authors": [
        "Vinod Kathail"
      ],
      "published_date": "2020",
      "abstract": "FPGAs provide significant advantages in throughput, latency, and energy efficiency for implementing low-latency, compute-intensive applications when compared to general-purpose CPUs and GPUs. Over the last decade, FPGAs have evolved into highly configurable SoCs with on-chip CPUs, domain-specific programmable accelerators, and flexible connectivity options. Recently, Xilinx introduced a new heterogeneous compute architecture, the Adaptive Compute Acceleration Platform (ACAP), with significantly more flexibility and performance to address an evolving set of new applications such as machine learning. This advancement on the device side is accompanied by similar advances on higher-level programming approaches to make FPGAs and ACAPs significantly easy to use for a wide range of applications. Xilinx Vitis Unified Software Platform is a comprehensive development environment to build and seamlessly deploy accelerated applications on Xilinx platforms including Alveo cards, FPGA-instances in the cloud, and embedded platforms. It addresses the three major industry trends: the need for heterogenous computing, applications that span cloud to edge to end-point, and AI proliferation. Vitis supports application programming using C, C++ and OpenCL, and it enables the development of large-scale data processing and machine learning applications using familiar, higher-level frameworks such as TensorFlow and SPARK. To facilitate communication between the host application and accelerators, Xilinx Runtime library (XRT) provides APIs for accelerator life-cycle management, accelerator execution management, memory allocation, and data communication between the host application and accelerators. In addition, a rich set of performance-optimized, open-source libraries significantly ease the application development. Vitis AI, an integral part of Vitis, enables AI inference acceleration on Xilinx platforms. It supports industry's leading deep learning frameworks like Tensorflow and Caffe, and offers a comprehensive suite of tools and APIs to prune, quantize, optimize, and compile pre-trained models to achieve the highest AI inference performance on Xilinx platforms. This talk provides an overview of Vitis and Vitis AI development environments.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/275f66ef562a00d01e9eaa10b0363688b7c5e36f.pdf",
      "venue": "Symposium on Field Programmable Gate Arrays",
      "citationCount": 90,
      "score": 18.0,
      "summary": "FPGAs provide significant advantages in throughput, latency, and energy efficiency for implementing low-latency, compute-intensive applications when compared to general-purpose CPUs and GPUs. Over the last decade, FPGAs have evolved into highly configurable SoCs with on-chip CPUs, domain-specific programmable accelerators, and flexible connectivity options. Recently, Xilinx introduced a new heterogeneous compute architecture, the Adaptive Compute Acceleration Platform (ACAP), with significantly more flexibility and performance to address an evolving set of new applications such as machine learning. This advancement on the device side is accompanied by similar advances on higher-level programming approaches to make FPGAs and ACAPs significantly easy to use for a wide range of applications. Xilinx Vitis Unified Software Platform is a comprehensive development environment to build and seamlessly deploy accelerated applications on Xilinx platforms including Alveo cards, FPGA-instances in the cloud, and embedded platforms. It addresses the three major industry trends: the need for heterogenous computing, applications that span cloud to edge to end-point, and AI proliferation. Vitis supports application programming using C, C++ and OpenCL, and it enables the development of large-scale data processing and machine learning applications using familiar, higher-level frameworks such as TensorFlow and SPARK. To facilitate communication between the host application and accelerators, Xilinx Runtime library (XRT) provides APIs for accelerator life-cycle management, accelerator execution management, memory allocation, and data communication between the host application and accelerators. In addition, a rich set of performance-optimized, open-source libraries significantly ease the application development. Vitis AI, an integral part of Vitis, enables AI inference acceleration on Xilinx platforms. It supports industry's leading deep learning frameworks like Tensorflow and Caffe, and offers a comprehensive suite of tools and APIs to prune, quantize, optimize, and compile pre-trained models to achieve the highest AI inference performance on Xilinx platforms. This talk provides an overview of Vitis and Vitis AI development environments.",
      "keywords": []
    },
    "file_name": "275f66ef562a00d01e9eaa10b0363688b7c5e36f.pdf"
  },
  {
    "success": true,
    "doc_id": "bf417f5c2bb82ffa3edd0d4a2f18c4be",
    "summary": "The modern trend of moving artificial intelligence computation near to the origin of data sources has increased the demand for new hardware and software suitable for such environments. We carried out a scoping study to find the current resources used when developing Edge AI applications. Due to the nature of the topic, the research combined scientific sources with product information and software project sources. The paper is structured as follows. In the first part, Edge AI applications are briefly discussed followed by hardware options and finally, the software used to develop AI models is described. There are various hardware products available, and we found as many as possible for this research to identify the best-known manufacturers. We describe the devices in the following categories: artificial intelligence accelerators and processors, field-programmable gate arrays, system-on-a-chip devices, system-on-modules, and full computers from development boards to servers. There seem to be three trends in Edge AI software development: neural network optimization, mobile device software and microcontroller software. We discussed these emerging fields and how the special challenges of low power consumption and machine learning computation are being taken into account. Our findings suggest that the Edge AI ecosystem is currently developing, and it has its own challenges to which vendors and developers are responding.",
    "intriguing_abstract": "The modern trend of moving artificial intelligence computation near to the origin of data sources has increased the demand for new hardware and software suitable for such environments. We carried out a scoping study to find the current resources used when developing Edge AI applications. Due to the nature of the topic, the research combined scientific sources with product information and software project sources. The paper is structured as follows. In the first part, Edge AI applications are briefly discussed followed by hardware options and finally, the software used to develop AI models is described. There are various hardware products available, and we found as many as possible for this research to identify the best-known manufacturers. We describe the devices in the following categories: artificial intelligence accelerators and processors, field-programmable gate arrays, system-on-a-chip devices, system-on-modules, and full computers from development boards to servers. There seem to be three trends in Edge AI software development: neural network optimization, mobile device software and microcontroller software. We discussed these emerging fields and how the special challenges of low power consumption and machine learning computation are being taken into account. Our findings suggest that the Edge AI ecosystem is currently developing, and it has its own challenges to which vendors and developers are responding.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a9da29b69c029087d45cb098acc83df942c8762f.pdf",
    "citation_key": "sipola2022owi",
    "metadata": {
      "title": "Artificial Intelligence in the IoT Era: A Review of Edge AI Hardware and Software",
      "authors": [
        "T. Sipola",
        "Janne Alatalo",
        "T. Kokkonen",
        "M. Rantonen"
      ],
      "published_date": "2022",
      "abstract": "The modern trend of moving artificial intelligence computation near to the origin of data sources has increased the demand for new hardware and software suitable for such environments. We carried out a scoping study to find the current resources used when developing Edge AI applications. Due to the nature of the topic, the research combined scientific sources with product information and software project sources. The paper is structured as follows. In the first part, Edge AI applications are briefly discussed followed by hardware options and finally, the software used to develop AI models is described. There are various hardware products available, and we found as many as possible for this research to identify the best-known manufacturers. We describe the devices in the following categories: artificial intelligence accelerators and processors, field-programmable gate arrays, system-on-a-chip devices, system-on-modules, and full computers from development boards to servers. There seem to be three trends in Edge AI software development: neural network optimization, mobile device software and microcontroller software. We discussed these emerging fields and how the special challenges of low power consumption and machine learning computation are being taken into account. Our findings suggest that the Edge AI ecosystem is currently developing, and it has its own challenges to which vendors and developers are responding.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a9da29b69c029087d45cb098acc83df942c8762f.pdf",
      "venue": "Conference of the Open Innovations Association",
      "citationCount": 52,
      "score": 17.333333333333332,
      "summary": "The modern trend of moving artificial intelligence computation near to the origin of data sources has increased the demand for new hardware and software suitable for such environments. We carried out a scoping study to find the current resources used when developing Edge AI applications. Due to the nature of the topic, the research combined scientific sources with product information and software project sources. The paper is structured as follows. In the first part, Edge AI applications are briefly discussed followed by hardware options and finally, the software used to develop AI models is described. There are various hardware products available, and we found as many as possible for this research to identify the best-known manufacturers. We describe the devices in the following categories: artificial intelligence accelerators and processors, field-programmable gate arrays, system-on-a-chip devices, system-on-modules, and full computers from development boards to servers. There seem to be three trends in Edge AI software development: neural network optimization, mobile device software and microcontroller software. We discussed these emerging fields and how the special challenges of low power consumption and machine learning computation are being taken into account. Our findings suggest that the Edge AI ecosystem is currently developing, and it has its own challenges to which vendors and developers are responding.",
      "keywords": []
    },
    "file_name": "a9da29b69c029087d45cb098acc83df942c8762f.pdf"
  },
  {
    "success": true,
    "doc_id": "973f9d0bb5454b96f84d4379b598ba13",
    "summary": "From a socio-psychological standpoint, improving the morphology of the facial soft-tissues is regarded as an important therapeutic goal in modern orthodontic treatment. Currently, many of the algorithms used in commercially available software programs that are said to provide the function of performing profile prediction are based on the false assumption that the amount of movement of hard-tissue and soft-tissue has a proportional relationship. The specification of the proportionality constant value depends on the operator, and there is little evidence to support the validity of the prediction result. Thus, the present study attempted to develop artificial intelligence (AI) systems that predict the three-dimensional (3-D) facial morphology after orthognathic surgery and orthodontic treatment based on the results of previous treatment. This was a retrospective study in a secondary adult care setting. A total of 137 patients who underwent orthognathic surgery (n = 72) and orthodontic treatment with four premolar extraction (n = 65) were enrolled. Lateral cephalograms and 3-D facial images were obtained before and after treatment. We have developed two AI systems to predict facial morphology after orthognathic surgery (System S) and orthodontic treatment (System E) using landmark-based geometric morphometric methods together with deep learning methods; where cephalometric changes during treatment and the coordinate values of the faces before treatment were employed as predictive variables. Eleven-fold cross-validation showed that the average system errors were 0.94 mm and 0.69 mm for systems S and E, respectively. The total success rates, when success was defined by a system error of < 1 mm, were 54% and 98% for systems S and E, respectively. The total success rates when success was defined by a system error of < 2 mm were both 100%. AI systems to predict facial morphology after treatment were therefore confirmed to be clinically acceptable.",
    "intriguing_abstract": "From a socio-psychological standpoint, improving the morphology of the facial soft-tissues is regarded as an important therapeutic goal in modern orthodontic treatment. Currently, many of the algorithms used in commercially available software programs that are said to provide the function of performing profile prediction are based on the false assumption that the amount of movement of hard-tissue and soft-tissue has a proportional relationship. The specification of the proportionality constant value depends on the operator, and there is little evidence to support the validity of the prediction result. Thus, the present study attempted to develop artificial intelligence (AI) systems that predict the three-dimensional (3-D) facial morphology after orthognathic surgery and orthodontic treatment based on the results of previous treatment. This was a retrospective study in a secondary adult care setting. A total of 137 patients who underwent orthognathic surgery (n = 72) and orthodontic treatment with four premolar extraction (n = 65) were enrolled. Lateral cephalograms and 3-D facial images were obtained before and after treatment. We have developed two AI systems to predict facial morphology after orthognathic surgery (System S) and orthodontic treatment (System E) using landmark-based geometric morphometric methods together with deep learning methods; where cephalometric changes during treatment and the coordinate values of the faces before treatment were employed as predictive variables. Eleven-fold cross-validation showed that the average system errors were 0.94 mm and 0.69 mm for systems S and E, respectively. The total success rates, when success was defined by a system error of < 1 mm, were 54% and 98% for systems S and E, respectively. The total success rates when success was defined by a system error of < 2 mm were both 100%. AI systems to predict facial morphology after treatment were therefore confirmed to be clinically acceptable.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2be4b7ded038427fb096449c2a286dffbef8fbe5.pdf",
    "citation_key": "tanikawa2021q7b",
    "metadata": {
      "title": "Development of novel artificial intelligence systems to predict facial morphology after orthognathic surgery and orthodontic treatment in Japanese patients",
      "authors": [
        "C. Tanikawa",
        "T. Yamashiro"
      ],
      "published_date": "2021",
      "abstract": "From a socio-psychological standpoint, improving the morphology of the facial soft-tissues is regarded as an important therapeutic goal in modern orthodontic treatment. Currently, many of the algorithms used in commercially available software programs that are said to provide the function of performing profile prediction are based on the false assumption that the amount of movement of hard-tissue and soft-tissue has a proportional relationship. The specification of the proportionality constant value depends on the operator, and there is little evidence to support the validity of the prediction result. Thus, the present study attempted to develop artificial intelligence (AI) systems that predict the three-dimensional (3-D) facial morphology after orthognathic surgery and orthodontic treatment based on the results of previous treatment. This was a retrospective study in a secondary adult care setting. A total of 137 patients who underwent orthognathic surgery (n = 72) and orthodontic treatment with four premolar extraction (n = 65) were enrolled. Lateral cephalograms and 3-D facial images were obtained before and after treatment. We have developed two AI systems to predict facial morphology after orthognathic surgery (System S) and orthodontic treatment (System E) using landmark-based geometric morphometric methods together with deep learning methods; where cephalometric changes during treatment and the coordinate values of the faces before treatment were employed as predictive variables. Eleven-fold cross-validation showed that the average system errors were 0.94 mm and 0.69 mm for systems S and E, respectively. The total success rates, when success was defined by a system error of < 1 mm, were 54% and 98% for systems S and E, respectively. The total success rates when success was defined by a system error of < 2 mm were both 100%. AI systems to predict facial morphology after treatment were therefore confirmed to be clinically acceptable.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2be4b7ded038427fb096449c2a286dffbef8fbe5.pdf",
      "venue": "Scientific Reports",
      "citationCount": 69,
      "score": 17.25,
      "summary": "From a socio-psychological standpoint, improving the morphology of the facial soft-tissues is regarded as an important therapeutic goal in modern orthodontic treatment. Currently, many of the algorithms used in commercially available software programs that are said to provide the function of performing profile prediction are based on the false assumption that the amount of movement of hard-tissue and soft-tissue has a proportional relationship. The specification of the proportionality constant value depends on the operator, and there is little evidence to support the validity of the prediction result. Thus, the present study attempted to develop artificial intelligence (AI) systems that predict the three-dimensional (3-D) facial morphology after orthognathic surgery and orthodontic treatment based on the results of previous treatment. This was a retrospective study in a secondary adult care setting. A total of 137 patients who underwent orthognathic surgery (n = 72) and orthodontic treatment with four premolar extraction (n = 65) were enrolled. Lateral cephalograms and 3-D facial images were obtained before and after treatment. We have developed two AI systems to predict facial morphology after orthognathic surgery (System S) and orthodontic treatment (System E) using landmark-based geometric morphometric methods together with deep learning methods; where cephalometric changes during treatment and the coordinate values of the faces before treatment were employed as predictive variables. Eleven-fold cross-validation showed that the average system errors were 0.94 mm and 0.69 mm for systems S and E, respectively. The total success rates, when success was defined by a system error of < 1 mm, were 54% and 98% for systems S and E, respectively. The total success rates when success was defined by a system error of < 2 mm were both 100%. AI systems to predict facial morphology after treatment were therefore confirmed to be clinically acceptable.",
      "keywords": []
    },
    "file_name": "2be4b7ded038427fb096449c2a286dffbef8fbe5.pdf"
  },
  {
    "success": true,
    "doc_id": "4b2325100a2f3377ee6a99251e944772",
    "summary": "In conventional software development, user experience (UX) designers and engineers collaborate through separation of concerns (SoC): designers create human interface specifications, and engineers build to those specifications. However, we argue that Human-AI systems thwart SoC because human needs must shape the design of the AI interface, the underlying AI sub-components, and training data. How do designers and engineers currently collaborate on AI and UX design? To find out, we interviewed 21 industry professionals (UX researchers, AI engineers, data scientists, and managers) across 14 organizations about their collaborative work practices and associated challenges. We find that hidden information encapsulated by SoC challenges collaboration across design and engineering concerns. Practitioners describe inventing ad-hoc representations exposing low-level design and implementation details (which we characterize as leaky abstractions) to “puncture” SoC and share information across expertise boundaries. We identify how leaky abstractions are employed to collaborate at the AI-UX boundary and formalize a process of creating and using leaky abstractions.",
    "intriguing_abstract": "In conventional software development, user experience (UX) designers and engineers collaborate through separation of concerns (SoC): designers create human interface specifications, and engineers build to those specifications. However, we argue that Human-AI systems thwart SoC because human needs must shape the design of the AI interface, the underlying AI sub-components, and training data. How do designers and engineers currently collaborate on AI and UX design? To find out, we interviewed 21 industry professionals (UX researchers, AI engineers, data scientists, and managers) across 14 organizations about their collaborative work practices and associated challenges. We find that hidden information encapsulated by SoC challenges collaboration across design and engineering concerns. Practitioners describe inventing ad-hoc representations exposing low-level design and implementation details (which we characterize as leaky abstractions) to “puncture” SoC and share information across expertise boundaries. We identify how leaky abstractions are employed to collaborate at the AI-UX boundary and formalize a process of creating and using leaky abstractions.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ad44a987fd8828c2ba93ccca6d20c80994b3b9cf.pdf",
    "citation_key": "subramonyam20225qh",
    "metadata": {
      "title": "Solving Separation-of-Concerns Problems in Collaborative Design of Human-AI Systems through Leaky Abstractions",
      "authors": [
        "Hariharan Subramonyam",
        "Jane Im",
        "C. Seifert",
        "Eytan Adar"
      ],
      "published_date": "2022",
      "abstract": "In conventional software development, user experience (UX) designers and engineers collaborate through separation of concerns (SoC): designers create human interface specifications, and engineers build to those specifications. However, we argue that Human-AI systems thwart SoC because human needs must shape the design of the AI interface, the underlying AI sub-components, and training data. How do designers and engineers currently collaborate on AI and UX design? To find out, we interviewed 21 industry professionals (UX researchers, AI engineers, data scientists, and managers) across 14 organizations about their collaborative work practices and associated challenges. We find that hidden information encapsulated by SoC challenges collaboration across design and engineering concerns. Practitioners describe inventing ad-hoc representations exposing low-level design and implementation details (which we characterize as leaky abstractions) to “puncture” SoC and share information across expertise boundaries. We identify how leaky abstractions are employed to collaborate at the AI-UX boundary and formalize a process of creating and using leaky abstractions.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ad44a987fd8828c2ba93ccca6d20c80994b3b9cf.pdf",
      "venue": "International Conference on Human Factors in Computing Systems",
      "citationCount": 50,
      "score": 16.666666666666664,
      "summary": "In conventional software development, user experience (UX) designers and engineers collaborate through separation of concerns (SoC): designers create human interface specifications, and engineers build to those specifications. However, we argue that Human-AI systems thwart SoC because human needs must shape the design of the AI interface, the underlying AI sub-components, and training data. How do designers and engineers currently collaborate on AI and UX design? To find out, we interviewed 21 industry professionals (UX researchers, AI engineers, data scientists, and managers) across 14 organizations about their collaborative work practices and associated challenges. We find that hidden information encapsulated by SoC challenges collaboration across design and engineering concerns. Practitioners describe inventing ad-hoc representations exposing low-level design and implementation details (which we characterize as leaky abstractions) to “puncture” SoC and share information across expertise boundaries. We identify how leaky abstractions are employed to collaborate at the AI-UX boundary and formalize a process of creating and using leaky abstractions.",
      "keywords": []
    },
    "file_name": "ad44a987fd8828c2ba93ccca6d20c80994b3b9cf.pdf"
  },
  {
    "success": true,
    "doc_id": "256f2937b122af4a94baad6a90d622ca",
    "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n---\n\n**Analysis of \"Applications of AI in classical software engineering\" \\cite{barenkamp2020w3b}**\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem:** Despite Artificial Intelligence (AI) being a prominent buzzword, its systematic relevance, specific applications, and comprehensive impact on the various stages of classical Software Engineering (SE) have been insufficiently analyzed.\n    *   **Importance and Challenge:** The problem is important because AI holds significant potential to transform SE processes, but its actual status, future potentials, and inherent risks across the entire Software Development Life Cycle (SDLC) remain largely unexplored in a structured and balanced manner. Previous studies often focused solely on potentials or used incomplete classification frameworks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches:** The paper builds upon earlier process-related classifications of AI in SE, specifically those by Sorte et al. \\cite{sorte2017applications} and Padmanaban et al. \\cite{padmanaban2017applications}, which categorized AI applications by SDLC stages.\n    *   **Limitations of previous solutions:**\n        *   Earlier process-related reviews were criticized for lacking topical sources, systematic data research, and being incomplete or merely explorative regarding opportunities and limitations.\n        *   Object-related classifications struggled to differentiate interacting AI functionalities.\n        *   Function-related classifications risked neglecting undiscovered AI domains or overlooking limitations due to their empirical focus.\n        *   Many prior studies predominantly focused on the *potentials* of AI, often neglecting a critical discussion of its *limitations* and development requirements.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method (of the paper's analysis):** The paper employs a mixed-method research approach to systematically analyze AI applications in classical software engineering. This involves:\n        *   A systematic literature review of over 60 peer-reviewed publications (2010-2020) to identify existing AI applications and their impacts across the Software Development Life Cycle (SDLC).\n        *   Five qualitative, semi-structured expert interviews with experienced software engineers to gather practical insights, validate review findings, and critically assess the status, potentials, and risks of AI in daily work routines.\n    *   **Novelty of the Approach (of the paper's analysis):**\n        *   It provides a more differentiated and comprehensive discussion of AI's impact across a six-stage SDLC model, addressing the incompleteness of prior process-related reviews.\n        *   It explicitly discusses both the potentials and the limitations/risks of AI, offering a balanced perspective often missing in earlier, more positivistic studies.\n        *   The integration of systematic review with expert interviews offers a robust, empirically-founded, yet critically reflective perspective on AI in SE.\n    *   **AI techniques analyzed:** The paper analyzes the application of various AI technologies in SE, including big data analytics, machine learning, artificial neural networks (deep learning, backpropagation, gradient descent), natural language processing, and computer vision. For project planning, it specifically discusses Search-Based Software Engineering (SBSE), ant colony optimization \\cite{mahadik2016ant, han2017ant}, Bayesian networks \\cite{fenton2008bayesian}, expert systems \\cite{peischl2008expert}, and multi-objective solver algorithms \\cite{chicano2018adaptive}.\n\n4.  **Key Technical Contributions**\n    *   **Structured Analysis Framework:** The paper's primary contribution is a systematic classification and analysis of AI applications within a comprehensive six-stage Software Development Life Cycle (SDLC) model (project planning, problem analysis, software design, implementation, software testing and integration, software support and maintenance).\n    *   **Identified AI Potentials:** It highlights that AI's major achievements and future potentials in SE include:\n        *   Automation of lengthy routine jobs (e.g., debugging, documentation) using algorithms.\n        *   Structured analysis of large data pools to discover patterns and novel information clusters.\n        *   Systematic evaluation of these data using neural networks.\n    *   **Impact on SE Processes:** AI contributes to speeding up development processes, realizing development cost reductions, and achieving efficiency gains.\n    *   **Human-AI Synergy:** The paper posits that while AI currently depends on man-made structures and is mainly reproductive, its effective use can multiply human developers' creative potential.\n    *   **Detailed Insights for Project Planning:** Provides specific examples of AI techniques applicable to project planning, such as SBSE for optimizing cost, duration, and quality; non-linear, self-optimizing algorithms like ant colony optimization for task assignment and resource allocation \\cite{mahadik2016ant, han2017ant}; Bayesian network algorithms for multi-objective optimization under uncertainty \\cite{fenton2008bayesian}; and expert systems for selecting optimal planning routines \\cite{peischl2008expert}.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted (by the paper):**\n        *   A systematic review of over 60 peer-reviewed publications (2010-2020) was conducted to gather existing evidence on AI applications in SE.\n        *   Five qualitative expert interviews were conducted with experienced software engineers to provide practical perspectives, validate review findings, and identify limitations and future potentials.\n    *   **Key performance metrics and comparison results (reported by the paper):**\n        *   The paper's methodology aims for *comprehensiveness* and *critical reflection* rather than quantitative performance metrics for its own findings.\n        *   It reports that AI-based algorithms have been found superior to conventional linear planning in multi-objective task optimization in diverse case studies \\cite{stylianou2001multi}.\n        *   It notes that \"practice performance proofs in a real-life team context are outstanding\" for models predicting human interactions for team performance optimization \\cite{athavale2017predicting}, implying such validation is still needed or not yet widely available.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations or assumptions (of the paper's analysis):**\n        *   The qualitative nature of the expert interviews means findings are based on a small sample (5 experts) and their subjective experiences.\n        *   The systematic review is limited to publications between 2010 and 2020.\n        *   The paper's analysis of AI applications is based on existing literature and expert opinions, not on developing or testing new AI systems.\n        *   The paper acknowledges that AI \"to date depends on man-made structures and is mainly reproductive.\"\n    *   **Scope of applicability:** The analysis is focused on \"classical software engineering\" and its various stages within the SDLC. It provides a high-level overview and classification of AI applications, rather than deep technical dives into specific AI algorithms. The provided content only details AI applications up to the \"Problem Analysis\" stage of the SDLC.\n\n7.  **Technical Significance**\n    *   **Advance the technical state-of-the-art:** The paper significantly advances the understanding of AI in SE by providing the first systematic and comprehensive analysis across a full six-stage SDLC, addressing gaps in previous process-related reviews. It offers a balanced perspective by discussing both the potentials and the limitations/risks of AI in SE, which was often lacking in prior work. The mixed-method approach (systematic review + expert interviews) sets a new standard for analyzing the complex interplay of AI and SE.\n    *   **Potential impact on future research:** This study serves as a foundational reference for researchers and practitioners seeking to understand the current state and future directions of AI in SE, structured by SDLC stages. It highlights specific areas within the SDLC where AI shows promise (e.g., automation of routine tasks, big data analysis, pattern recognition) and where further research and practical validation are needed (e.g., practical application of AI in *new* project planning, real-life validation of team optimization models). It encourages a more critical and comprehensive evaluation of AI technologies in SE, moving beyond mere hype.\n\n---",
    "intriguing_abstract": "Despite the pervasive buzz, the systematic relevance and comprehensive impact of Artificial Intelligence (AI) across the classical Software Development Life Cycle (SDLC) remain critically underexplored. This paper presents the first systematic and balanced analysis of AI's role in Software Engineering (SE), moving beyond mere hype. Employing a rigorous mixed-method approach, combining a systematic literature review of over 60 publications with five qualitative expert interviews, we provide a differentiated discussion of AI applications across a comprehensive six-stage SDLC model.\n\nOur novel framework meticulously classifies AI potentials, from automating routine tasks and leveraging big data analytics with machine learning and deep learning, to enhancing efficiency and fostering human-AI synergy. We highlight specific AI techniques like Search-Based Software Engineering (SBSE), ant colony optimization, and Bayesian networks for project planning. Crucially, we also critically assess the inherent limitations and risks, a perspective often missing in prior studies. This foundational work offers a robust, empirically-grounded reference for researchers and practitioners, guiding future research and practical validation while encouraging a more critical and comprehensive evaluation of AI technologies in SE.",
    "keywords": [
      "Artificial Intelligence (AI) in Software Engineering",
      "Software Development Life Cycle (SDLC)",
      "Systematic Literature Review",
      "Expert Interviews",
      "Mixed-method research",
      "AI Potentials and Limitations",
      "Automation of Software Engineering tasks",
      "Machine Learning",
      "Big Data Analytics",
      "Search-Based Software Engineering (SBSE)",
      "Efficiency and Cost Reduction",
      "Human-AI Synergy",
      "Structured Analysis Framework",
      "Project Planning Optimization"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f2a621a360a13211a877923b68af3c147155c9a6.pdf",
    "citation_key": "barenkamp2020w3b",
    "metadata": {
      "title": "Applications of AI in classical software engineering",
      "authors": [
        "Marco Barenkamp",
        "Jonas Rebstadt",
        "Oliver Thomas"
      ],
      "published_date": "2020",
      "abstract": "Although Artificial Intelligence (AI) has become a buzzword for self-organizing IT applications, its relevance to software engineering has hardly been analyzed systematically. This study combines a systematic review of previous research in the field and five qualitative interviews with software developers who use or want to use AI tools in their daily work routines, to assess the status of development, future development potentials and equally the risks of AI application to software engineering. The study classifies the insights in the software development life cycle. The analysis results that major achievements and future potentials of AI are a) the automation of lengthy routine jobs in software development and testing using algorithms, e.g. for debugging and documentation, b) the structured analysis of big data pools to discover patterns and novel information clusters and c) the systematic evaluation of these data in neural networks. AI thus contributes to speed up development processes, realize development cost reductions and efficiency gains. AI to date depends on man-made structures and is mainly reproductive, but the automation of software engineering routines entails a major advantage: Human developers multiply their creative potential when using AI tools effectively.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f2a621a360a13211a877923b68af3c147155c9a6.pdf",
      "venue": "AI Perspectives",
      "citationCount": 83,
      "score": 16.6,
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n---\n\n**Analysis of \"Applications of AI in classical software engineering\" \\cite{barenkamp2020w3b}**\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem:** Despite Artificial Intelligence (AI) being a prominent buzzword, its systematic relevance, specific applications, and comprehensive impact on the various stages of classical Software Engineering (SE) have been insufficiently analyzed.\n    *   **Importance and Challenge:** The problem is important because AI holds significant potential to transform SE processes, but its actual status, future potentials, and inherent risks across the entire Software Development Life Cycle (SDLC) remain largely unexplored in a structured and balanced manner. Previous studies often focused solely on potentials or used incomplete classification frameworks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches:** The paper builds upon earlier process-related classifications of AI in SE, specifically those by Sorte et al. \\cite{sorte2017applications} and Padmanaban et al. \\cite{padmanaban2017applications}, which categorized AI applications by SDLC stages.\n    *   **Limitations of previous solutions:**\n        *   Earlier process-related reviews were criticized for lacking topical sources, systematic data research, and being incomplete or merely explorative regarding opportunities and limitations.\n        *   Object-related classifications struggled to differentiate interacting AI functionalities.\n        *   Function-related classifications risked neglecting undiscovered AI domains or overlooking limitations due to their empirical focus.\n        *   Many prior studies predominantly focused on the *potentials* of AI, often neglecting a critical discussion of its *limitations* and development requirements.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method (of the paper's analysis):** The paper employs a mixed-method research approach to systematically analyze AI applications in classical software engineering. This involves:\n        *   A systematic literature review of over 60 peer-reviewed publications (2010-2020) to identify existing AI applications and their impacts across the Software Development Life Cycle (SDLC).\n        *   Five qualitative, semi-structured expert interviews with experienced software engineers to gather practical insights, validate review findings, and critically assess the status, potentials, and risks of AI in daily work routines.\n    *   **Novelty of the Approach (of the paper's analysis):**\n        *   It provides a more differentiated and comprehensive discussion of AI's impact across a six-stage SDLC model, addressing the incompleteness of prior process-related reviews.\n        *   It explicitly discusses both the potentials and the limitations/risks of AI, offering a balanced perspective often missing in earlier, more positivistic studies.\n        *   The integration of systematic review with expert interviews offers a robust, empirically-founded, yet critically reflective perspective on AI in SE.\n    *   **AI techniques analyzed:** The paper analyzes the application of various AI technologies in SE, including big data analytics, machine learning, artificial neural networks (deep learning, backpropagation, gradient descent), natural language processing, and computer vision. For project planning, it specifically discusses Search-Based Software Engineering (SBSE), ant colony optimization \\cite{mahadik2016ant, han2017ant}, Bayesian networks \\cite{fenton2008bayesian}, expert systems \\cite{peischl2008expert}, and multi-objective solver algorithms \\cite{chicano2018adaptive}.\n\n4.  **Key Technical Contributions**\n    *   **Structured Analysis Framework:** The paper's primary contribution is a systematic classification and analysis of AI applications within a comprehensive six-stage Software Development Life Cycle (SDLC) model (project planning, problem analysis, software design, implementation, software testing and integration, software support and maintenance).\n    *   **Identified AI Potentials:** It highlights that AI's major achievements and future potentials in SE include:\n        *   Automation of lengthy routine jobs (e.g., debugging, documentation) using algorithms.\n        *   Structured analysis of large data pools to discover patterns and novel information clusters.\n        *   Systematic evaluation of these data using neural networks.\n    *   **Impact on SE Processes:** AI contributes to speeding up development processes, realizing development cost reductions, and achieving efficiency gains.\n    *   **Human-AI Synergy:** The paper posits that while AI currently depends on man-made structures and is mainly reproductive, its effective use can multiply human developers' creative potential.\n    *   **Detailed Insights for Project Planning:** Provides specific examples of AI techniques applicable to project planning, such as SBSE for optimizing cost, duration, and quality; non-linear, self-optimizing algorithms like ant colony optimization for task assignment and resource allocation \\cite{mahadik2016ant, han2017ant}; Bayesian network algorithms for multi-objective optimization under uncertainty \\cite{fenton2008bayesian}; and expert systems for selecting optimal planning routines \\cite{peischl2008expert}.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted (by the paper):**\n        *   A systematic review of over 60 peer-reviewed publications (2010-2020) was conducted to gather existing evidence on AI applications in SE.\n        *   Five qualitative expert interviews were conducted with experienced software engineers to provide practical perspectives, validate review findings, and identify limitations and future potentials.\n    *   **Key performance metrics and comparison results (reported by the paper):**\n        *   The paper's methodology aims for *comprehensiveness* and *critical reflection* rather than quantitative performance metrics for its own findings.\n        *   It reports that AI-based algorithms have been found superior to conventional linear planning in multi-objective task optimization in diverse case studies \\cite{stylianou2001multi}.\n        *   It notes that \"practice performance proofs in a real-life team context are outstanding\" for models predicting human interactions for team performance optimization \\cite{athavale2017predicting}, implying such validation is still needed or not yet widely available.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations or assumptions (of the paper's analysis):**\n        *   The qualitative nature of the expert interviews means findings are based on a small sample (5 experts) and their subjective experiences.\n        *   The systematic review is limited to publications between 2010 and 2020.\n        *   The paper's analysis of AI applications is based on existing literature and expert opinions, not on developing or testing new AI systems.\n        *   The paper acknowledges that AI \"to date depends on man-made structures and is mainly reproductive.\"\n    *   **Scope of applicability:** The analysis is focused on \"classical software engineering\" and its various stages within the SDLC. It provides a high-level overview and classification of AI applications, rather than deep technical dives into specific AI algorithms. The provided content only details AI applications up to the \"Problem Analysis\" stage of the SDLC.\n\n7.  **Technical Significance**\n    *   **Advance the technical state-of-the-art:** The paper significantly advances the understanding of AI in SE by providing the first systematic and comprehensive analysis across a full six-stage SDLC, addressing gaps in previous process-related reviews. It offers a balanced perspective by discussing both the potentials and the limitations/risks of AI in SE, which was often lacking in prior work. The mixed-method approach (systematic review + expert interviews) sets a new standard for analyzing the complex interplay of AI and SE.\n    *   **Potential impact on future research:** This study serves as a foundational reference for researchers and practitioners seeking to understand the current state and future directions of AI in SE, structured by SDLC stages. It highlights specific areas within the SDLC where AI shows promise (e.g., automation of routine tasks, big data analysis, pattern recognition) and where further research and practical validation are needed (e.g., practical application of AI in *new* project planning, real-life validation of team optimization models). It encourages a more critical and comprehensive evaluation of AI technologies in SE, moving beyond mere hype.\n\n---",
      "keywords": [
        "Artificial Intelligence (AI) in Software Engineering",
        "Software Development Life Cycle (SDLC)",
        "Systematic Literature Review",
        "Expert Interviews",
        "Mixed-method research",
        "AI Potentials and Limitations",
        "Automation of Software Engineering tasks",
        "Machine Learning",
        "Big Data Analytics",
        "Search-Based Software Engineering (SBSE)",
        "Efficiency and Cost Reduction",
        "Human-AI Synergy",
        "Structured Analysis Framework",
        "Project Planning Optimization"
      ],
      "paper_type": "based on the abstract and introduction:\n\n1.  **abstract analysis:**\n    *   \"this study combines a **systematic review of previous research** in the field and five qualitative interviews...\" - the explicit mention of \"systematic review\" is a strong indicator for a survey paper.\n    *   \"...to **assess the status of development**, future development potentials and equally the risks of ai application to software engineering.\" - assessing the status of development is a key characteristic of a survey, which often aims to provide a comprehensive overview or state-of-the-art.\n    *   \"the study **classifies the insights** in the software development life cycle.\" - classification schemes are often used in survey papers to organize and present the reviewed literature.\n    *   the \"analysis results\" describe major achievements and future potentials, which are typical outcomes of a comprehensive review.\n\n2.  **introduction analysis:**\n    *   the introduction discusses existing \"prophecies and futuristic legends\" and references multiple existing works ([1], [2], [3], [4–6], [7]). this indicates a focus on synthesizing and discussing existing literature and ideas.\n    *   it contrasts \"future visions\" with the current state, which is common in survey papers that aim to contextualize the current landscape.\n\n3.  **matching to criteria:**\n    *   **survey**: the abstract explicitly mentions \"systematic review\" and aims to \"assess the status of development\" and \"classifies the insights.\" the introduction discusses existing literature and ideas. this aligns perfectly with the criteria for a survey paper.\n    *   **empirical**: while there is an empirical component (\"five qualitative interviews\"), the abstract frames the study as primarily a \"systematic review\" *combined with* interviews. the interviews seem to complement the review rather than being the sole or primary focus of the paper's classification. the overall goal is to assess the *status* and *potentials*, which is broader than just reporting interview findings.\n\ngiven the strong emphasis on \"systematic review\" and \"assessing the status of development\" by synthesizing existing knowledge, the paper's primary classification is a survey.\n\n**classification:** survey"
    },
    "file_name": "f2a621a360a13211a877923b68af3c147155c9a6.pdf"
  },
  {
    "success": true,
    "doc_id": "711eecf029db71816467979354b2e868",
    "summary": "In the last few years, artificial intelligence (AI) and machine learning (ML) have become ubiquitous terms. These powerful techniques have escaped obscurity in academic communities with the recent onslaught of AI & ML tools, frameworks, and libraries that make these techniques accessible to a wider audience of developers. As a result, applying AI & ML to solve existing and emergent problems is an increasingly popular practice. However, little is known about this domain from the software engineering perspective. Many AI & ML tools and applications are open source, hosted on platforms such as GitHub that provide rich tools for large-scale distributed software development. Despite widespread use and popularity, these repositories have never been examined as a community to identify unique properties, development patterns, and trends. In this paper, we conducted a large-scale empirical study of AI & ML Tool (700) and Application (4,524) repositories hosted on GitHub to develop such a characterization. While not the only platform hosting AI & ML development, GitHub facilitates collecting a rich data set for each repository with high traceability between issues, commits, pull requests and users. To compare the AI & ML community to the wider population of repositories, we also analyzed a set of 4,101 unrelated repositories. We enhance this characterization with an elaborate study of developer workflow that measures collaboration and autonomy within a repository. We've captured key insights of this community's 10 year history such as it's primary language (Python) and most popular repositories (Tensorflow, Tesseract). Our findings show the AI & ML community has unique characteristics that should be accounted for in future research.",
    "intriguing_abstract": "In the last few years, artificial intelligence (AI) and machine learning (ML) have become ubiquitous terms. These powerful techniques have escaped obscurity in academic communities with the recent onslaught of AI & ML tools, frameworks, and libraries that make these techniques accessible to a wider audience of developers. As a result, applying AI & ML to solve existing and emergent problems is an increasingly popular practice. However, little is known about this domain from the software engineering perspective. Many AI & ML tools and applications are open source, hosted on platforms such as GitHub that provide rich tools for large-scale distributed software development. Despite widespread use and popularity, these repositories have never been examined as a community to identify unique properties, development patterns, and trends. In this paper, we conducted a large-scale empirical study of AI & ML Tool (700) and Application (4,524) repositories hosted on GitHub to develop such a characterization. While not the only platform hosting AI & ML development, GitHub facilitates collecting a rich data set for each repository with high traceability between issues, commits, pull requests and users. To compare the AI & ML community to the wider population of repositories, we also analyzed a set of 4,101 unrelated repositories. We enhance this characterization with an elaborate study of developer workflow that measures collaboration and autonomy within a repository. We've captured key insights of this community's 10 year history such as it's primary language (Python) and most popular repositories (Tensorflow, Tesseract). Our findings show the AI & ML community has unique characteristics that should be accounted for in future research.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/14b42a095728221f9ea1698c9749634574c9980e.pdf",
    "citation_key": "gonzalez20200oi",
    "metadata": {
      "title": "The State of the ML-universe: 10 Years of Artificial Intelligence & Machine Learning Software Development on GitHub",
      "authors": [
        "Danielle Gonzalez",
        "Thomas Zimmermann",
        "Nachiappan Nagappan"
      ],
      "published_date": "2020",
      "abstract": "In the last few years, artificial intelligence (AI) and machine learning (ML) have become ubiquitous terms. These powerful techniques have escaped obscurity in academic communities with the recent onslaught of AI & ML tools, frameworks, and libraries that make these techniques accessible to a wider audience of developers. As a result, applying AI & ML to solve existing and emergent problems is an increasingly popular practice. However, little is known about this domain from the software engineering perspective. Many AI & ML tools and applications are open source, hosted on platforms such as GitHub that provide rich tools for large-scale distributed software development. Despite widespread use and popularity, these repositories have never been examined as a community to identify unique properties, development patterns, and trends. In this paper, we conducted a large-scale empirical study of AI & ML Tool (700) and Application (4,524) repositories hosted on GitHub to develop such a characterization. While not the only platform hosting AI & ML development, GitHub facilitates collecting a rich data set for each repository with high traceability between issues, commits, pull requests and users. To compare the AI & ML community to the wider population of repositories, we also analyzed a set of 4,101 unrelated repositories. We enhance this characterization with an elaborate study of developer workflow that measures collaboration and autonomy within a repository. We've captured key insights of this community's 10 year history such as it's primary language (Python) and most popular repositories (Tensorflow, Tesseract). Our findings show the AI & ML community has unique characteristics that should be accounted for in future research.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/14b42a095728221f9ea1698c9749634574c9980e.pdf",
      "venue": "IEEE Working Conference on Mining Software Repositories",
      "citationCount": 82,
      "score": 16.400000000000002,
      "summary": "In the last few years, artificial intelligence (AI) and machine learning (ML) have become ubiquitous terms. These powerful techniques have escaped obscurity in academic communities with the recent onslaught of AI & ML tools, frameworks, and libraries that make these techniques accessible to a wider audience of developers. As a result, applying AI & ML to solve existing and emergent problems is an increasingly popular practice. However, little is known about this domain from the software engineering perspective. Many AI & ML tools and applications are open source, hosted on platforms such as GitHub that provide rich tools for large-scale distributed software development. Despite widespread use and popularity, these repositories have never been examined as a community to identify unique properties, development patterns, and trends. In this paper, we conducted a large-scale empirical study of AI & ML Tool (700) and Application (4,524) repositories hosted on GitHub to develop such a characterization. While not the only platform hosting AI & ML development, GitHub facilitates collecting a rich data set for each repository with high traceability between issues, commits, pull requests and users. To compare the AI & ML community to the wider population of repositories, we also analyzed a set of 4,101 unrelated repositories. We enhance this characterization with an elaborate study of developer workflow that measures collaboration and autonomy within a repository. We've captured key insights of this community's 10 year history such as it's primary language (Python) and most popular repositories (Tensorflow, Tesseract). Our findings show the AI & ML community has unique characteristics that should be accounted for in future research.",
      "keywords": []
    },
    "file_name": "14b42a095728221f9ea1698c9749634574c9980e.pdf"
  },
  {
    "success": true,
    "doc_id": "03ccffe6f070a2c03e8be22402ef7341",
    "summary": "Abstract Artificial intelligence (AI) can transform health care by delivering medical services to underserved areas, while also filling gaps in health care provider availability. However, AI may also lead to patient harm due to fatal glitches in robotic surgery, bias in diagnosis, or dangerous recommendations. Despite concerns ethicists have identified in the use of AI in health care, the most significant consideration ought not be vulnerabilities in the software, but the environmental impact of AI. Health care emits a significant amount of carbon in many countries. As AI becomes an essential part of health care, ethical reflection must include the potential to negatively impact the environment. As such, this article will first overview the carbon emissions in health care. It will, second, offer five reasons why carbon calculations are insufficient to address sustainability in health care. Third, the article will derive normative concepts from the goals of medicine, the principles of biomedical ethics, and green bioethics—the very locus in which AI in health care sits—to propose health, justice, and resource conservation as criteria for sustainable AI in health care. In the fourth and final part of the article, examples of sustainable and unsustainable development and use of AI in health care will be evaluated through the three‐fold lens of health, justice, and resource conservation. With various ethical approaches to AI in health care, the imperative for environmental sustainability must be underscored, lest carbon emissions continue to increase, harming people and planet alike.",
    "intriguing_abstract": "Abstract Artificial intelligence (AI) can transform health care by delivering medical services to underserved areas, while also filling gaps in health care provider availability. However, AI may also lead to patient harm due to fatal glitches in robotic surgery, bias in diagnosis, or dangerous recommendations. Despite concerns ethicists have identified in the use of AI in health care, the most significant consideration ought not be vulnerabilities in the software, but the environmental impact of AI. Health care emits a significant amount of carbon in many countries. As AI becomes an essential part of health care, ethical reflection must include the potential to negatively impact the environment. As such, this article will first overview the carbon emissions in health care. It will, second, offer five reasons why carbon calculations are insufficient to address sustainability in health care. Third, the article will derive normative concepts from the goals of medicine, the principles of biomedical ethics, and green bioethics—the very locus in which AI in health care sits—to propose health, justice, and resource conservation as criteria for sustainable AI in health care. In the fourth and final part of the article, examples of sustainable and unsustainable development and use of AI in health care will be evaluated through the three‐fold lens of health, justice, and resource conservation. With various ethical approaches to AI in health care, the imperative for environmental sustainability must be underscored, lest carbon emissions continue to increase, harming people and planet alike.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/baee16e76433605cdd093b939e5915a0e902bcef.pdf",
    "citation_key": "richie2022jm4",
    "metadata": {
      "title": "Environmentally sustainable development and use of artificial intelligence in health care",
      "authors": [
        "C. Richie"
      ],
      "published_date": "2022",
      "abstract": "Abstract Artificial intelligence (AI) can transform health care by delivering medical services to underserved areas, while also filling gaps in health care provider availability. However, AI may also lead to patient harm due to fatal glitches in robotic surgery, bias in diagnosis, or dangerous recommendations. Despite concerns ethicists have identified in the use of AI in health care, the most significant consideration ought not be vulnerabilities in the software, but the environmental impact of AI. Health care emits a significant amount of carbon in many countries. As AI becomes an essential part of health care, ethical reflection must include the potential to negatively impact the environment. As such, this article will first overview the carbon emissions in health care. It will, second, offer five reasons why carbon calculations are insufficient to address sustainability in health care. Third, the article will derive normative concepts from the goals of medicine, the principles of biomedical ethics, and green bioethics—the very locus in which AI in health care sits—to propose health, justice, and resource conservation as criteria for sustainable AI in health care. In the fourth and final part of the article, examples of sustainable and unsustainable development and use of AI in health care will be evaluated through the three‐fold lens of health, justice, and resource conservation. With various ethical approaches to AI in health care, the imperative for environmental sustainability must be underscored, lest carbon emissions continue to increase, harming people and planet alike.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/baee16e76433605cdd093b939e5915a0e902bcef.pdf",
      "venue": "Bioethics",
      "citationCount": 49,
      "score": 16.333333333333332,
      "summary": "Abstract Artificial intelligence (AI) can transform health care by delivering medical services to underserved areas, while also filling gaps in health care provider availability. However, AI may also lead to patient harm due to fatal glitches in robotic surgery, bias in diagnosis, or dangerous recommendations. Despite concerns ethicists have identified in the use of AI in health care, the most significant consideration ought not be vulnerabilities in the software, but the environmental impact of AI. Health care emits a significant amount of carbon in many countries. As AI becomes an essential part of health care, ethical reflection must include the potential to negatively impact the environment. As such, this article will first overview the carbon emissions in health care. It will, second, offer five reasons why carbon calculations are insufficient to address sustainability in health care. Third, the article will derive normative concepts from the goals of medicine, the principles of biomedical ethics, and green bioethics—the very locus in which AI in health care sits—to propose health, justice, and resource conservation as criteria for sustainable AI in health care. In the fourth and final part of the article, examples of sustainable and unsustainable development and use of AI in health care will be evaluated through the three‐fold lens of health, justice, and resource conservation. With various ethical approaches to AI in health care, the imperative for environmental sustainability must be underscored, lest carbon emissions continue to increase, harming people and planet alike.",
      "keywords": []
    },
    "file_name": "baee16e76433605cdd093b939e5915a0e902bcef.pdf"
  },
  {
    "success": true,
    "doc_id": "b554e0cb1cb6fac1c05c93abbc39f630",
    "summary": "Advances in machine learning (ML) algorithms and increasing availability of computational power have resulted in huge investments in systems that aspire to exploit artificial intelligence (AI), in particular ML. AIenabled systems, software-reliant systems that include data and components that implement algorithms mimicking learning and problem solving, have inherently different characteristics than software systems alone.1 However, the development and sustainment of such systems also have many parallels with building, deploying, and sustaining software systems. A common observation is that although software systems are deterministic and you can build and test to a specification, AI-enabled systems, in particular those that include ML components, are generally probabilistic. Systems with ML components can have a high margin of error due to the uncertainty that often follows predictive algorithms. The margin of error can be related to the inability to predict the result in advance or the same result cannot be reproduced. This characteristic makes AI-enabled systems hard to test and verify.2 Consequently, it is easy to assume that what we know about designing and reasoning about software systems does not immediately apply in AI engineering. AI-enabled systems are software systems. The sneaky part about engineering AI systems is they are \"just like\" conventional software systems we can design and reason about until they?re not.",
    "intriguing_abstract": "Advances in machine learning (ML) algorithms and increasing availability of computational power have resulted in huge investments in systems that aspire to exploit artificial intelligence (AI), in particular ML. AIenabled systems, software-reliant systems that include data and components that implement algorithms mimicking learning and problem solving, have inherently different characteristics than software systems alone.1 However, the development and sustainment of such systems also have many parallels with building, deploying, and sustaining software systems. A common observation is that although software systems are deterministic and you can build and test to a specification, AI-enabled systems, in particular those that include ML components, are generally probabilistic. Systems with ML components can have a high margin of error due to the uncertainty that often follows predictive algorithms. The margin of error can be related to the inability to predict the result in advance or the same result cannot be reproduced. This characteristic makes AI-enabled systems hard to test and verify.2 Consequently, it is easy to assume that what we know about designing and reasoning about software systems does not immediately apply in AI engineering. AI-enabled systems are software systems. The sneaky part about engineering AI systems is they are \"just like\" conventional software systems we can design and reason about until they?re not.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/05086329135fdb15049a5ac8edd7f980762f2097.pdf",
    "citation_key": "ozkaya2020go5",
    "metadata": {
      "title": "What Is Really Different in Engineering AI-Enabled Systems?",
      "authors": [
        "Ipek Ozkaya"
      ],
      "published_date": "2020",
      "abstract": "Advances in machine learning (ML) algorithms and increasing availability of computational power have resulted in huge investments in systems that aspire to exploit artificial intelligence (AI), in particular ML. AIenabled systems, software-reliant systems that include data and components that implement algorithms mimicking learning and problem solving, have inherently different characteristics than software systems alone.1 However, the development and sustainment of such systems also have many parallels with building, deploying, and sustaining software systems. A common observation is that although software systems are deterministic and you can build and test to a specification, AI-enabled systems, in particular those that include ML components, are generally probabilistic. Systems with ML components can have a high margin of error due to the uncertainty that often follows predictive algorithms. The margin of error can be related to the inability to predict the result in advance or the same result cannot be reproduced. This characteristic makes AI-enabled systems hard to test and verify.2 Consequently, it is easy to assume that what we know about designing and reasoning about software systems does not immediately apply in AI engineering. AI-enabled systems are software systems. The sneaky part about engineering AI systems is they are \"just like\" conventional software systems we can design and reason about until they?re not.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/05086329135fdb15049a5ac8edd7f980762f2097.pdf",
      "venue": "IEEE Software",
      "citationCount": 75,
      "score": 15.0,
      "summary": "Advances in machine learning (ML) algorithms and increasing availability of computational power have resulted in huge investments in systems that aspire to exploit artificial intelligence (AI), in particular ML. AIenabled systems, software-reliant systems that include data and components that implement algorithms mimicking learning and problem solving, have inherently different characteristics than software systems alone.1 However, the development and sustainment of such systems also have many parallels with building, deploying, and sustaining software systems. A common observation is that although software systems are deterministic and you can build and test to a specification, AI-enabled systems, in particular those that include ML components, are generally probabilistic. Systems with ML components can have a high margin of error due to the uncertainty that often follows predictive algorithms. The margin of error can be related to the inability to predict the result in advance or the same result cannot be reproduced. This characteristic makes AI-enabled systems hard to test and verify.2 Consequently, it is easy to assume that what we know about designing and reasoning about software systems does not immediately apply in AI engineering. AI-enabled systems are software systems. The sneaky part about engineering AI systems is they are \"just like\" conventional software systems we can design and reason about until they?re not.",
      "keywords": []
    },
    "file_name": "05086329135fdb15049a5ac8edd7f980762f2097.pdf"
  },
  {
    "success": true,
    "doc_id": "93bab1d404cc3ce66d78879387bb04d4",
    "summary": "Artificial intelligence (AI) in healthcare holds great potential to expand access to high‐quality medical care, while reducing systemic costs. Despite hitting headlines regularly and many publications of proofs‐of‐concept, certified products are failing to break through to the clinic. AI in healthcare is a multiparty process with deep knowledge required in multiple individual domains. A lack of understanding of the specific challenges in the domain is the major contributor to the failure to deliver on the big promises. Herein, a “decision perspective” framework for the development of AI‐driven biomedical products from conception to market launch is presented. The framework highlights the risks, objectives, and key results which are typically required to navigate a three‐phase process to market‐launch of a validated medical AI product. Clinical validation, regulatory affairs, data strategy, and algorithmic development are addressed. The development process proposed for AI in healthcare software strongly diverges from modern consumer software development processes. Key time points to guide founders, investors, and key stakeholders throughout the process are highlighted. This framework should be seen as a template for innovation frameworks, which can be used to coordinate team communications and responsibilities toward a viable product development roadmap, thus unlocking the potential of AI in medicine.",
    "intriguing_abstract": "Artificial intelligence (AI) in healthcare holds great potential to expand access to high‐quality medical care, while reducing systemic costs. Despite hitting headlines regularly and many publications of proofs‐of‐concept, certified products are failing to break through to the clinic. AI in healthcare is a multiparty process with deep knowledge required in multiple individual domains. A lack of understanding of the specific challenges in the domain is the major contributor to the failure to deliver on the big promises. Herein, a “decision perspective” framework for the development of AI‐driven biomedical products from conception to market launch is presented. The framework highlights the risks, objectives, and key results which are typically required to navigate a three‐phase process to market‐launch of a validated medical AI product. Clinical validation, regulatory affairs, data strategy, and algorithmic development are addressed. The development process proposed for AI in healthcare software strongly diverges from modern consumer software development processes. Key time points to guide founders, investors, and key stakeholders throughout the process are highlighted. This framework should be seen as a template for innovation frameworks, which can be used to coordinate team communications and responsibilities toward a viable product development roadmap, thus unlocking the potential of AI in medicine.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/7616f919c632de874d6ef9f5f9a73a1076bfd6d4.pdf",
    "citation_key": "higgins2020u9l",
    "metadata": {
      "title": "From Bit to Bedside: A Practical Framework for Artificial Intelligence Product Development in Healthcare",
      "authors": [
        "David C. Higgins",
        "V. Madai"
      ],
      "published_date": "2020",
      "abstract": "Artificial intelligence (AI) in healthcare holds great potential to expand access to high‐quality medical care, while reducing systemic costs. Despite hitting headlines regularly and many publications of proofs‐of‐concept, certified products are failing to break through to the clinic. AI in healthcare is a multiparty process with deep knowledge required in multiple individual domains. A lack of understanding of the specific challenges in the domain is the major contributor to the failure to deliver on the big promises. Herein, a “decision perspective” framework for the development of AI‐driven biomedical products from conception to market launch is presented. The framework highlights the risks, objectives, and key results which are typically required to navigate a three‐phase process to market‐launch of a validated medical AI product. Clinical validation, regulatory affairs, data strategy, and algorithmic development are addressed. The development process proposed for AI in healthcare software strongly diverges from modern consumer software development processes. Key time points to guide founders, investors, and key stakeholders throughout the process are highlighted. This framework should be seen as a template for innovation frameworks, which can be used to coordinate team communications and responsibilities toward a viable product development roadmap, thus unlocking the potential of AI in medicine.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/7616f919c632de874d6ef9f5f9a73a1076bfd6d4.pdf",
      "venue": "Advanced Intelligent Systems",
      "citationCount": 75,
      "score": 15.0,
      "summary": "Artificial intelligence (AI) in healthcare holds great potential to expand access to high‐quality medical care, while reducing systemic costs. Despite hitting headlines regularly and many publications of proofs‐of‐concept, certified products are failing to break through to the clinic. AI in healthcare is a multiparty process with deep knowledge required in multiple individual domains. A lack of understanding of the specific challenges in the domain is the major contributor to the failure to deliver on the big promises. Herein, a “decision perspective” framework for the development of AI‐driven biomedical products from conception to market launch is presented. The framework highlights the risks, objectives, and key results which are typically required to navigate a three‐phase process to market‐launch of a validated medical AI product. Clinical validation, regulatory affairs, data strategy, and algorithmic development are addressed. The development process proposed for AI in healthcare software strongly diverges from modern consumer software development processes. Key time points to guide founders, investors, and key stakeholders throughout the process are highlighted. This framework should be seen as a template for innovation frameworks, which can be used to coordinate team communications and responsibilities toward a viable product development roadmap, thus unlocking the potential of AI in medicine.",
      "keywords": []
    },
    "file_name": "7616f919c632de874d6ef9f5f9a73a1076bfd6d4.pdf"
  },
  {
    "success": true,
    "doc_id": "3a3af82bc62f73bdc1f4c011697e0059",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/1e4c6d47c34d64aa5883d16a64df82603f7e9706.pdf",
    "citation_key": "khandelwal20178mq",
    "metadata": {
      "title": "BWIBots: A platform for bridging the gap between AI and human–robot interaction research",
      "authors": [
        "Piyush Khandelwal",
        "Shiqi Zhang",
        "Jivko Sinapov",
        "M. Leonetti",
        "Jesse Thomason",
        "Fangkai Yang",
        "I. Gori",
        "Maxwell Svetlik",
        "Priyanka Khante",
        "V. Lifschitz",
        "J. Aggarwal",
        "R. Mooney",
        "P. Stone"
      ],
      "published_date": "2017",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/1e4c6d47c34d64aa5883d16a64df82603f7e9706.pdf",
      "venue": "Int. J. Robotics Res.",
      "citationCount": 119,
      "score": 14.875,
      "summary": "",
      "keywords": []
    },
    "file_name": "1e4c6d47c34d64aa5883d16a64df82603f7e9706.pdf"
  },
  {
    "success": true,
    "doc_id": "0ef15e7a68e73c8f226d61de9fa1b8b4",
    "summary": "This paper proposes a cloud-based framework and platform for end-to-end development and lifecycle management of artificial intelligence (AI) applications. We build on our previous work on platform-level support for cloud-managed deep learning services, and show how the principles of software lifecycle management can be leveraged and extended to enable automation, trust, reliability, traceability, quality control, and reproducibility of AI pipelines. Based on a discussion of use cases and current challenges, we describe a framework for managingAI application lifecycles and its key components. We also show concrete examples that illustrate how this framework enables managing and executing model training and continuous learning pipelines while infusing trusted AI principles.",
    "intriguing_abstract": "This paper proposes a cloud-based framework and platform for end-to-end development and lifecycle management of artificial intelligence (AI) applications. We build on our previous work on platform-level support for cloud-managed deep learning services, and show how the principles of software lifecycle management can be leveraged and extended to enable automation, trust, reliability, traceability, quality control, and reproducibility of AI pipelines. Based on a discussion of use cases and current challenges, we describe a framework for managingAI application lifecycles and its key components. We also show concrete examples that illustrate how this framework enables managing and executing model training and continuous learning pipelines while infusing trusted AI principles.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/14e50dab3238b6824a9100d88893eb4582842d3b.pdf",
    "citation_key": "hummer2019lah",
    "metadata": {
      "title": "ModelOps: Cloud-Based Lifecycle Management for Reliable and Trusted AI",
      "authors": [
        "W. Hummer",
        "Vinod Muthusamy",
        "T. Rausch",
        "Parijat Dube",
        "K. E. Maghraoui",
        "Anupama Murthi",
        "Punleuk Oum"
      ],
      "published_date": "2019",
      "abstract": "This paper proposes a cloud-based framework and platform for end-to-end development and lifecycle management of artificial intelligence (AI) applications. We build on our previous work on platform-level support for cloud-managed deep learning services, and show how the principles of software lifecycle management can be leveraged and extended to enable automation, trust, reliability, traceability, quality control, and reproducibility of AI pipelines. Based on a discussion of use cases and current challenges, we describe a framework for managingAI application lifecycles and its key components. We also show concrete examples that illustrate how this framework enables managing and executing model training and continuous learning pipelines while infusing trusted AI principles.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/14e50dab3238b6824a9100d88893eb4582842d3b.pdf",
      "venue": "2019 IEEE International Conference on Cloud Engineering (IC2E)",
      "citationCount": 88,
      "score": 14.666666666666666,
      "summary": "This paper proposes a cloud-based framework and platform for end-to-end development and lifecycle management of artificial intelligence (AI) applications. We build on our previous work on platform-level support for cloud-managed deep learning services, and show how the principles of software lifecycle management can be leveraged and extended to enable automation, trust, reliability, traceability, quality control, and reproducibility of AI pipelines. Based on a discussion of use cases and current challenges, we describe a framework for managingAI application lifecycles and its key components. We also show concrete examples that illustrate how this framework enables managing and executing model training and continuous learning pipelines while infusing trusted AI principles.",
      "keywords": []
    },
    "file_name": "14e50dab3238b6824a9100d88893eb4582842d3b.pdf"
  },
  {
    "success": true,
    "doc_id": "57835a275ce0e78eb184571417c81c1d",
    "summary": "Software game is a kind of application that is used not only for entertainment, but also for serious purposes that can be applicable to different domains such as education, business, and health care. Multidisciplinary nature of the game development processes that combine sound, art, control systems, artificial intelligence (AI), and human factors, makes the software game development practice different from traditional software development. However, the underline software engineering techniques help game development to achieve maintainability, flexibility, lower effort and cost, and better design. The purpose of this study is to assesses the state of the art research on the game development software engineering process and highlight areas that need further consideration by researchers. In the study, we used a systematic literature review methodology based on well-known digital libraries. The largest number of studies have been reported in the production phase of the game development software engineering process life cycle, followed by the pre-production phase. By contrast, the post-production phase has received much less research activity than the pre-production and production phases. The results of this study suggest that the game development software engineering process has many aspects that need further attention from researchers; that especially includes the postproduction phase.",
    "intriguing_abstract": "Software game is a kind of application that is used not only for entertainment, but also for serious purposes that can be applicable to different domains such as education, business, and health care. Multidisciplinary nature of the game development processes that combine sound, art, control systems, artificial intelligence (AI), and human factors, makes the software game development practice different from traditional software development. However, the underline software engineering techniques help game development to achieve maintainability, flexibility, lower effort and cost, and better design. The purpose of this study is to assesses the state of the art research on the game development software engineering process and highlight areas that need further consideration by researchers. In the study, we used a systematic literature review methodology based on well-known digital libraries. The largest number of studies have been reported in the production phase of the game development software engineering process life cycle, followed by the pre-production phase. By contrast, the post-production phase has received much less research activity than the pre-production and production phases. The results of this study suggest that the game development software engineering process has many aspects that need further attention from researchers; that especially includes the postproduction phase.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/768b444c84340d2210bd2782ce3aa39b723bd0b9.pdf",
    "citation_key": "aleem2016hm6",
    "metadata": {
      "title": "Game development software engineering process life cycle: a systematic review",
      "authors": [
        "Saiqa Aleem",
        "Luiz Fernando Capretz",
        "F. Ahmed"
      ],
      "published_date": "2016",
      "abstract": "Software game is a kind of application that is used not only for entertainment, but also for serious purposes that can be applicable to different domains such as education, business, and health care. Multidisciplinary nature of the game development processes that combine sound, art, control systems, artificial intelligence (AI), and human factors, makes the software game development practice different from traditional software development. However, the underline software engineering techniques help game development to achieve maintainability, flexibility, lower effort and cost, and better design. The purpose of this study is to assesses the state of the art research on the game development software engineering process and highlight areas that need further consideration by researchers. In the study, we used a systematic literature review methodology based on well-known digital libraries. The largest number of studies have been reported in the production phase of the game development software engineering process life cycle, followed by the pre-production phase. By contrast, the post-production phase has received much less research activity than the pre-production and production phases. The results of this study suggest that the game development software engineering process has many aspects that need further attention from researchers; that especially includes the postproduction phase.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/768b444c84340d2210bd2782ce3aa39b723bd0b9.pdf",
      "venue": "Journal of Software Engineering Research and Development",
      "citationCount": 128,
      "score": 14.222222222222221,
      "summary": "Software game is a kind of application that is used not only for entertainment, but also for serious purposes that can be applicable to different domains such as education, business, and health care. Multidisciplinary nature of the game development processes that combine sound, art, control systems, artificial intelligence (AI), and human factors, makes the software game development practice different from traditional software development. However, the underline software engineering techniques help game development to achieve maintainability, flexibility, lower effort and cost, and better design. The purpose of this study is to assesses the state of the art research on the game development software engineering process and highlight areas that need further consideration by researchers. In the study, we used a systematic literature review methodology based on well-known digital libraries. The largest number of studies have been reported in the production phase of the game development software engineering process life cycle, followed by the pre-production phase. By contrast, the post-production phase has received much less research activity than the pre-production and production phases. The results of this study suggest that the game development software engineering process has many aspects that need further attention from researchers; that especially includes the postproduction phase.",
      "keywords": []
    },
    "file_name": "768b444c84340d2210bd2782ce3aa39b723bd0b9.pdf"
  },
  {
    "success": true,
    "doc_id": "fd4c2f5e366180653402fa457dd821b8",
    "summary": "Artificial intelligence can be used to realise new types of protective devices and assistance systems, so their importance for occupational safety and health is continuously increasing. However, established risk mitigation measures in software development are only partially suitable for applications in AI systems, which only create new sources of risk. Risk management for systems that for systems using AI must therefore be adapted to the new problems. This work objects to contribute hereto by identifying relevant sources of risk for AI systems. For this purpose, the differences between AI systems, especially those based on modern machine learning methods, and classical software were analysed, and the current research fields of trustworthy AI were evaluated. On this basis, a taxonomy could be created that provides an overview of various AI-specific sources of risk. These new sources of risk should be taken into account in the overall risk assessment of a system based on AI technologies, examined for their criticality and managed accordingly at an early stage to prevent a later system failure.",
    "intriguing_abstract": "Artificial intelligence can be used to realise new types of protective devices and assistance systems, so their importance for occupational safety and health is continuously increasing. However, established risk mitigation measures in software development are only partially suitable for applications in AI systems, which only create new sources of risk. Risk management for systems that for systems using AI must therefore be adapted to the new problems. This work objects to contribute hereto by identifying relevant sources of risk for AI systems. For this purpose, the differences between AI systems, especially those based on modern machine learning methods, and classical software were analysed, and the current research fields of trustworthy AI were evaluated. On this basis, a taxonomy could be created that provides an overview of various AI-specific sources of risk. These new sources of risk should be taken into account in the overall risk assessment of a system based on AI technologies, examined for their criticality and managed accordingly at an early stage to prevent a later system failure.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8afc1513982784c5a6d649390dbb41cbce30268a.pdf",
    "citation_key": "steimers20220y3",
    "metadata": {
      "title": "Sources of Risk of AI Systems",
      "authors": [
        "André Steimers",
        "Moritz Schneider"
      ],
      "published_date": "2022",
      "abstract": "Artificial intelligence can be used to realise new types of protective devices and assistance systems, so their importance for occupational safety and health is continuously increasing. However, established risk mitigation measures in software development are only partially suitable for applications in AI systems, which only create new sources of risk. Risk management for systems that for systems using AI must therefore be adapted to the new problems. This work objects to contribute hereto by identifying relevant sources of risk for AI systems. For this purpose, the differences between AI systems, especially those based on modern machine learning methods, and classical software were analysed, and the current research fields of trustworthy AI were evaluated. On this basis, a taxonomy could be created that provides an overview of various AI-specific sources of risk. These new sources of risk should be taken into account in the overall risk assessment of a system based on AI technologies, examined for their criticality and managed accordingly at an early stage to prevent a later system failure.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8afc1513982784c5a6d649390dbb41cbce30268a.pdf",
      "venue": "International Journal of Environmental Research and Public Health",
      "citationCount": 42,
      "score": 14.0,
      "summary": "Artificial intelligence can be used to realise new types of protective devices and assistance systems, so their importance for occupational safety and health is continuously increasing. However, established risk mitigation measures in software development are only partially suitable for applications in AI systems, which only create new sources of risk. Risk management for systems that for systems using AI must therefore be adapted to the new problems. This work objects to contribute hereto by identifying relevant sources of risk for AI systems. For this purpose, the differences between AI systems, especially those based on modern machine learning methods, and classical software were analysed, and the current research fields of trustworthy AI were evaluated. On this basis, a taxonomy could be created that provides an overview of various AI-specific sources of risk. These new sources of risk should be taken into account in the overall risk assessment of a system based on AI technologies, examined for their criticality and managed accordingly at an early stage to prevent a later system failure.",
      "keywords": []
    },
    "file_name": "8afc1513982784c5a6d649390dbb41cbce30268a.pdf"
  },
  {
    "success": true,
    "doc_id": "415d04f85ca725e69eecff24f9d90dac",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9ebcda8a313d09de0ae6e40b1449c68c3f1a8a78.pdf",
    "citation_key": "balasubramaniam2022zp2",
    "metadata": {
      "title": "Transparency and Explainability of AI Systems: Ethical Guidelines in Practice",
      "authors": [
        "Nagadivya Balasubramaniam",
        "Marjo Kauppinen",
        "Kari Hiekkanen",
        "Sari Kujala"
      ],
      "published_date": "2022",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9ebcda8a313d09de0ae6e40b1449c68c3f1a8a78.pdf",
      "venue": "Requirements Engineering: Foundation for Software Quality",
      "citationCount": 40,
      "score": 13.333333333333332,
      "summary": "",
      "keywords": []
    },
    "file_name": "9ebcda8a313d09de0ae6e40b1449c68c3f1a8a78.pdf"
  },
  {
    "success": true,
    "doc_id": "0fd375060ff36f44a05869c449600f93",
    "summary": "Proponents of artificial intelligence (\"AI\") technology have suggested that in the near future, AI software may replace human radiologists. While AI's assimilation into the specialty has occurred more slowly than predicted, developments in machine learning, deep learning, and neural networks suggest that technological hurdles and costs will eventually be overcome. However, beyond these technological hurdles, formidable legal hurdles threaten AI's impact on the specialty. Legal liability for errors committed by AI will influence AI's ultimate role within radiology and whether AI remains a simple decision support tool or develops into an autonomous member of the healthcare team. Additional areas of uncertainty include the potential application of products liability law to AI, and the approach taken by the U.S. FDA in potentially classifying autonomous AI as a medical device. The current ambiguity of the legal treatment of AI will profoundly impact autonomous AI development given that vendors, radiologists, and hospitals will be unable to reliably assess their liability from implementing such tools. Advocates of AI in radiology and health care in general should lobby for legislative action to better clarify the liability risks of AI in a way that does not deter technological development.",
    "intriguing_abstract": "Proponents of artificial intelligence (\"AI\") technology have suggested that in the near future, AI software may replace human radiologists. While AI's assimilation into the specialty has occurred more slowly than predicted, developments in machine learning, deep learning, and neural networks suggest that technological hurdles and costs will eventually be overcome. However, beyond these technological hurdles, formidable legal hurdles threaten AI's impact on the specialty. Legal liability for errors committed by AI will influence AI's ultimate role within radiology and whether AI remains a simple decision support tool or develops into an autonomous member of the healthcare team. Additional areas of uncertainty include the potential application of products liability law to AI, and the approach taken by the U.S. FDA in potentially classifying autonomous AI as a medical device. The current ambiguity of the legal treatment of AI will profoundly impact autonomous AI development given that vendors, radiologists, and hospitals will be unable to reliably assess their liability from implementing such tools. Advocates of AI in radiology and health care in general should lobby for legislative action to better clarify the liability risks of AI in a way that does not deter technological development.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/5232908fdfd6c4bc92ed1ab40cb8bddbeea91b22.pdf",
    "citation_key": "mezrich202243j",
    "metadata": {
      "title": "Is Artificial Intelligence (AI) a Pipe Dream? Why Legal Issues Present Significant Hurdles to AI Autonomy.",
      "authors": [
        "J. Mezrich"
      ],
      "published_date": "2022",
      "abstract": "Proponents of artificial intelligence (\"AI\") technology have suggested that in the near future, AI software may replace human radiologists. While AI's assimilation into the specialty has occurred more slowly than predicted, developments in machine learning, deep learning, and neural networks suggest that technological hurdles and costs will eventually be overcome. However, beyond these technological hurdles, formidable legal hurdles threaten AI's impact on the specialty. Legal liability for errors committed by AI will influence AI's ultimate role within radiology and whether AI remains a simple decision support tool or develops into an autonomous member of the healthcare team. Additional areas of uncertainty include the potential application of products liability law to AI, and the approach taken by the U.S. FDA in potentially classifying autonomous AI as a medical device. The current ambiguity of the legal treatment of AI will profoundly impact autonomous AI development given that vendors, radiologists, and hospitals will be unable to reliably assess their liability from implementing such tools. Advocates of AI in radiology and health care in general should lobby for legislative action to better clarify the liability risks of AI in a way that does not deter technological development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/5232908fdfd6c4bc92ed1ab40cb8bddbeea91b22.pdf",
      "venue": "AJR. American journal of roentgenology",
      "citationCount": 39,
      "score": 13.0,
      "summary": "Proponents of artificial intelligence (\"AI\") technology have suggested that in the near future, AI software may replace human radiologists. While AI's assimilation into the specialty has occurred more slowly than predicted, developments in machine learning, deep learning, and neural networks suggest that technological hurdles and costs will eventually be overcome. However, beyond these technological hurdles, formidable legal hurdles threaten AI's impact on the specialty. Legal liability for errors committed by AI will influence AI's ultimate role within radiology and whether AI remains a simple decision support tool or develops into an autonomous member of the healthcare team. Additional areas of uncertainty include the potential application of products liability law to AI, and the approach taken by the U.S. FDA in potentially classifying autonomous AI as a medical device. The current ambiguity of the legal treatment of AI will profoundly impact autonomous AI development given that vendors, radiologists, and hospitals will be unable to reliably assess their liability from implementing such tools. Advocates of AI in radiology and health care in general should lobby for legislative action to better clarify the liability risks of AI in a way that does not deter technological development.",
      "keywords": []
    },
    "file_name": "5232908fdfd6c4bc92ed1ab40cb8bddbeea91b22.pdf"
  },
  {
    "success": true,
    "doc_id": "48cac3ba892daba888de76dbfa545758",
    "summary": "The wide use of machine learning is fundamentally changing the software development paradigm (a.k.a. Software 2.0) where data becomes a first-class citizen, on par with code. As machine learning is used in sensitive applications, it becomes imperative that the trained model is accurate, fair, and robust to attacks. While many techniques have been proposed to improve the model training process (in-processing approach) or the trained model itself (post-processing), we argue that the most effective method is to clean the root cause of error: the data the model is trained on (pre-processing). Historically, there are at least three research communities that have been separately studying this problem: data management, machine learning (model fairness), and security. Although a significant amount of research has been done by each community, ultimately the same datasets must be preprocessed, and there is little understanding how the techniques relate to each other and can possibly be integrated. We contend that it is time to extend the notion of data cleaning for modern machine learning needs. We identify dependencies among the data preprocessing techniques and propose MLClean, a unified data cleaning framework that integrates the techniques and helps train accurate and fair models. This work is part of a broader trend of Big data -- Artificial Intelligence (AI) integration.",
    "intriguing_abstract": "The wide use of machine learning is fundamentally changing the software development paradigm (a.k.a. Software 2.0) where data becomes a first-class citizen, on par with code. As machine learning is used in sensitive applications, it becomes imperative that the trained model is accurate, fair, and robust to attacks. While many techniques have been proposed to improve the model training process (in-processing approach) or the trained model itself (post-processing), we argue that the most effective method is to clean the root cause of error: the data the model is trained on (pre-processing). Historically, there are at least three research communities that have been separately studying this problem: data management, machine learning (model fairness), and security. Although a significant amount of research has been done by each community, ultimately the same datasets must be preprocessed, and there is little understanding how the techniques relate to each other and can possibly be integrated. We contend that it is time to extend the notion of data cleaning for modern machine learning needs. We identify dependencies among the data preprocessing techniques and propose MLClean, a unified data cleaning framework that integrates the techniques and helps train accurate and fair models. This work is part of a broader trend of Big data -- Artificial Intelligence (AI) integration.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/772b82843613eb1ac87ed2546b84dbf5efbd7d98.pdf",
    "citation_key": "tae2019xwg",
    "metadata": {
      "title": "Data Cleaning for Accurate, Fair, and Robust Models: A Big Data - AI Integration Approach",
      "authors": [
        "Ki Hyun Tae",
        "Yuji Roh",
        "Young Hun Oh",
        "Hyunsub Kim",
        "Steven Euijong Whang"
      ],
      "published_date": "2019",
      "abstract": "The wide use of machine learning is fundamentally changing the software development paradigm (a.k.a. Software 2.0) where data becomes a first-class citizen, on par with code. As machine learning is used in sensitive applications, it becomes imperative that the trained model is accurate, fair, and robust to attacks. While many techniques have been proposed to improve the model training process (in-processing approach) or the trained model itself (post-processing), we argue that the most effective method is to clean the root cause of error: the data the model is trained on (pre-processing). Historically, there are at least three research communities that have been separately studying this problem: data management, machine learning (model fairness), and security. Although a significant amount of research has been done by each community, ultimately the same datasets must be preprocessed, and there is little understanding how the techniques relate to each other and can possibly be integrated. We contend that it is time to extend the notion of data cleaning for modern machine learning needs. We identify dependencies among the data preprocessing techniques and propose MLClean, a unified data cleaning framework that integrates the techniques and helps train accurate and fair models. This work is part of a broader trend of Big data -- Artificial Intelligence (AI) integration.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/772b82843613eb1ac87ed2546b84dbf5efbd7d98.pdf",
      "venue": "DEEM@SIGMOD",
      "citationCount": 74,
      "score": 12.333333333333332,
      "summary": "The wide use of machine learning is fundamentally changing the software development paradigm (a.k.a. Software 2.0) where data becomes a first-class citizen, on par with code. As machine learning is used in sensitive applications, it becomes imperative that the trained model is accurate, fair, and robust to attacks. While many techniques have been proposed to improve the model training process (in-processing approach) or the trained model itself (post-processing), we argue that the most effective method is to clean the root cause of error: the data the model is trained on (pre-processing). Historically, there are at least three research communities that have been separately studying this problem: data management, machine learning (model fairness), and security. Although a significant amount of research has been done by each community, ultimately the same datasets must be preprocessed, and there is little understanding how the techniques relate to each other and can possibly be integrated. We contend that it is time to extend the notion of data cleaning for modern machine learning needs. We identify dependencies among the data preprocessing techniques and propose MLClean, a unified data cleaning framework that integrates the techniques and helps train accurate and fair models. This work is part of a broader trend of Big data -- Artificial Intelligence (AI) integration.",
      "keywords": []
    },
    "file_name": "772b82843613eb1ac87ed2546b84dbf5efbd7d98.pdf"
  },
  {
    "success": true,
    "doc_id": "0d1dffad803336b55227f997034ac580",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the significant challenges in applying Requirements Engineering (RE) principles and practices to the development of AI-based complex systems, particularly those leveraging machine learning (ML) and deep learning (DL) \\cite{belani20194yc}. There is a lack of a widely used and specifically tailored development process to effectively manage requirements for such systems.\n    *   **Importance and Challenge:** AI is rapidly growing, but its widespread adoption in complex and dependable systems is hindered by enormous, often underestimated, challenges. The inherent complex behavior of AI systems necessitates a specialized development process, as traditional RE approaches struggle with aspects like the \"black-box\" nature of ML models, data dependencies, and the dynamic evolution of AI components \\cite{belani20194yc}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work analyzes existing literature from software engineering (SE) and artificial intelligence (AI) fields, identifying potential contributions from agent-based software engineering (ABSE) and goal-oriented requirements engineering (GORE) \\cite{belani20194yc}. It also draws insights from the AI development practices of large product companies, categorizing AI development into requirement-driven, outcome/data-driven, and AI-driven approaches \\cite{belani20194yc}.\n    *   **Limitations of Previous Solutions:** Existing software development paradigms often lack explicit mechanisms for autonomous systems \\cite{belani20194yc}. Traditional SE processes struggle to maintain traceability and perform impact analysis when ML subsystems are treated as \"black-box\" elements. There's a recognized gap in expertise between AI and SE practitioners, and a lack of goal modeling approaches specifically tailored for AI systems that view ML subsystems as goal-seeking entities \\cite{belani20194yc}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper's core approach is the conceptualization and outlining of the **RE4AI taxonomy** \\cite{belani20194yc}. This taxonomy provides a structured framework that maps AI-related entities (data, model, system) to typical RE activities (elicitation, analysis, specification, validation, management, documentation).\n    *   **Novelty/Difference:** The RE4AI taxonomy is novel in its explicit alignment of AI-specific challenges with traditional RE activities and AI system components \\cite{belani20194yc}. It offers a systematic way to identify *when* and *how* to tackle these challenges throughout the software product lifecycle, aiming to inform the tailoring of AI development processes. The paper also highlights the potential of GORE to address the goal-seeking nature of AI components \\cite{belani20194yc}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:** The primary contribution is the **RE4AI taxonomy outline** itself, which serves as a conceptual tool for organizing and addressing RE challenges in AI development \\cite{belani20194yc}. It's a structured classification rather than a new algorithm.\n    *   **System Design or Architectural Innovations:** The paper identifies and discusses critical system-level design anti-patterns prevalent in AI systems, such as \"glue code,\" \"pipeline jungles,\" \"dead experimental code paths,\" and \"configuration debt,\" which contribute to technical debt \\cite{belani20194yc}.\n    *   **Theoretical Insights or Analysis:** It provides a detailed analysis of ML-specific risk factors, including \"entanglement\" (the CACE – Changing Anything Changes Everything – principle), \"undeclared consumers,\" and various \"data dependencies\" (unstable, underutilized, difficult to track, causing correction cascades) \\cite{belani20194yc}. This analysis frames these issues within the context of technical debt, offering a valuable perspective for managing AI system complexity.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** The paper does *not* present new experimental validation. It is a conceptual and analytical paper that synthesizes findings from existing literature, industry observations, and informal analysis of related work \\cite{belani20194yc}.\n    *   **Key Performance Metrics and Comparison Results:** Not applicable, as no original experiments were conducted or reported. The paper references studies that performed interviews and surveys to identify challenges, but it does not perform its own empirical validation.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations or Assumptions:** The RE4AI taxonomy is presented as an \"outline\" and requires further refinement and validation \\cite{belani20194yc}. The applicability of existing GORE frameworks and methods to AI systems needs deeper analysis. The paper's analysis of related work is described as \"informally looked into\" \\cite{belani20194yc}.\n    *   **Scope of Applicability:** The work primarily focuses on AI-based complex systems, specifically those incorporating machine learning and deep learning components \\cite{belani20194yc}. It highlights potential applicability to domains like healthcare, where challenges such as imbalanced datasets and unsafe failure modes are critical \\cite{belani20194yc}.\n\n*   **7. Technical Significance**\n    *   **Advance State-of-the-Art:** The paper significantly advances the technical state-of-the-art by providing a structured, comprehensive framework (RE4AI taxonomy) for understanding and categorizing the unique requirements engineering challenges in AI-based complex systems \\cite{belani20194yc}. It bridges the gap between traditional RE and the specific demands of AI development, offering a roadmap for practitioners and researchers.\n    *   **Potential Impact on Future Research:** The RE4AI taxonomy can inform the tailoring of AI development processes and guide future research into specific RE activities for AI \\cite{belani20194yc}. It explicitly suggests GORE as a promising area for further investigation to model ML subsystems as goal-seeking entities. The paper also calls for detailed exploration of new system design paradigms (e.g., Data-driven and Model-based Design - DMD) in conjunction with the RE4AI taxonomy, and highlights critical \"skill,\" \"data,\" and \"engineering\" gaps that require future attention \\cite{belani20194yc}.",
    "intriguing_abstract": "The transformative potential of Artificial Intelligence (AI), particularly Machine Learning (ML) and Deep Learning (DL), is undeniable, yet its reliable integration into complex, dependable systems remains severely challenged by inadequate Requirements Engineering (RE) practices. Traditional RE struggles with the inherent 'black-box' nature of ML models, intricate data dependencies, and the dynamic evolution of AI components, leading to significant technical debt and unpredictable system behavior.\n\nThis paper introduces the novel **RE4AI taxonomy**, a structured framework designed to bridge this critical gap. RE4AI systematically maps AI-specific entities (data, model, system) to core RE activities (elicitation, analysis, specification, validation, management, documentation). By explicitly addressing unique AI challenges like 'entanglement,' 'pipeline jungles,' and complex data dependencies, our taxonomy provides a systematic approach to identify and manage risks throughout the AI software lifecycle. We also highlight the promising role of Goal-Oriented Requirements Engineering (GORE) in modeling ML subsystems as goal-seeking entities. This work offers a crucial conceptual tool for tailoring AI development processes, fostering greater dependability, and guiding future research in AI system engineering.",
    "keywords": [
      "RE4AI taxonomy",
      "Requirements Engineering for AI",
      "AI-based complex systems",
      "Machine Learning",
      "Deep Learning",
      "Goal-Oriented Requirements Engineering",
      "Technical debt in AI systems",
      "ML-specific risk factors",
      "\"Black-box\" AI models",
      "AI development processes",
      "System design anti-patterns",
      "Data dependencies",
      "Traceability and impact analysis"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/58090cdbb7526f4e22c09387814ee060dab1de54.pdf",
    "citation_key": "belani20194yc",
    "metadata": {
      "title": "Requirements Engineering Challenges in Building AI-Based Complex Systems",
      "authors": [
        "H. Belani",
        "M. Vuković",
        "Z. Car"
      ],
      "published_date": "2019",
      "abstract": "This paper identifies and tackles the challenges of the requirements engineering discipline when applied to development of AI-based complex systems. Due to their complex behaviour, there is an immanent need for a tailored development process for such systems. However, there is still no widely used and specifically tailored process in place to effectively and efficiently deal with requirements suitable for specifying a software solution that uses machine learning. By analysing the related work from software engineering and artificial intelligence fields, potential contributions have been recognized from agent-based software engineering and goal-oriented requirements engineering research, as well as examples from large product development companies. The challenges have been discussed, with proposals given how and when to tackle them. RE4AI taxonomy has also been outlined, to inform the tailoring of development process.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/58090cdbb7526f4e22c09387814ee060dab1de54.pdf",
      "venue": "2019 IEEE 27th International Requirements Engineering Conference Workshops (REW)",
      "citationCount": 74,
      "score": 12.333333333333332,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the significant challenges in applying Requirements Engineering (RE) principles and practices to the development of AI-based complex systems, particularly those leveraging machine learning (ML) and deep learning (DL) \\cite{belani20194yc}. There is a lack of a widely used and specifically tailored development process to effectively manage requirements for such systems.\n    *   **Importance and Challenge:** AI is rapidly growing, but its widespread adoption in complex and dependable systems is hindered by enormous, often underestimated, challenges. The inherent complex behavior of AI systems necessitates a specialized development process, as traditional RE approaches struggle with aspects like the \"black-box\" nature of ML models, data dependencies, and the dynamic evolution of AI components \\cite{belani20194yc}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work analyzes existing literature from software engineering (SE) and artificial intelligence (AI) fields, identifying potential contributions from agent-based software engineering (ABSE) and goal-oriented requirements engineering (GORE) \\cite{belani20194yc}. It also draws insights from the AI development practices of large product companies, categorizing AI development into requirement-driven, outcome/data-driven, and AI-driven approaches \\cite{belani20194yc}.\n    *   **Limitations of Previous Solutions:** Existing software development paradigms often lack explicit mechanisms for autonomous systems \\cite{belani20194yc}. Traditional SE processes struggle to maintain traceability and perform impact analysis when ML subsystems are treated as \"black-box\" elements. There's a recognized gap in expertise between AI and SE practitioners, and a lack of goal modeling approaches specifically tailored for AI systems that view ML subsystems as goal-seeking entities \\cite{belani20194yc}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper's core approach is the conceptualization and outlining of the **RE4AI taxonomy** \\cite{belani20194yc}. This taxonomy provides a structured framework that maps AI-related entities (data, model, system) to typical RE activities (elicitation, analysis, specification, validation, management, documentation).\n    *   **Novelty/Difference:** The RE4AI taxonomy is novel in its explicit alignment of AI-specific challenges with traditional RE activities and AI system components \\cite{belani20194yc}. It offers a systematic way to identify *when* and *how* to tackle these challenges throughout the software product lifecycle, aiming to inform the tailoring of AI development processes. The paper also highlights the potential of GORE to address the goal-seeking nature of AI components \\cite{belani20194yc}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:** The primary contribution is the **RE4AI taxonomy outline** itself, which serves as a conceptual tool for organizing and addressing RE challenges in AI development \\cite{belani20194yc}. It's a structured classification rather than a new algorithm.\n    *   **System Design or Architectural Innovations:** The paper identifies and discusses critical system-level design anti-patterns prevalent in AI systems, such as \"glue code,\" \"pipeline jungles,\" \"dead experimental code paths,\" and \"configuration debt,\" which contribute to technical debt \\cite{belani20194yc}.\n    *   **Theoretical Insights or Analysis:** It provides a detailed analysis of ML-specific risk factors, including \"entanglement\" (the CACE – Changing Anything Changes Everything – principle), \"undeclared consumers,\" and various \"data dependencies\" (unstable, underutilized, difficult to track, causing correction cascades) \\cite{belani20194yc}. This analysis frames these issues within the context of technical debt, offering a valuable perspective for managing AI system complexity.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** The paper does *not* present new experimental validation. It is a conceptual and analytical paper that synthesizes findings from existing literature, industry observations, and informal analysis of related work \\cite{belani20194yc}.\n    *   **Key Performance Metrics and Comparison Results:** Not applicable, as no original experiments were conducted or reported. The paper references studies that performed interviews and surveys to identify challenges, but it does not perform its own empirical validation.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations or Assumptions:** The RE4AI taxonomy is presented as an \"outline\" and requires further refinement and validation \\cite{belani20194yc}. The applicability of existing GORE frameworks and methods to AI systems needs deeper analysis. The paper's analysis of related work is described as \"informally looked into\" \\cite{belani20194yc}.\n    *   **Scope of Applicability:** The work primarily focuses on AI-based complex systems, specifically those incorporating machine learning and deep learning components \\cite{belani20194yc}. It highlights potential applicability to domains like healthcare, where challenges such as imbalanced datasets and unsafe failure modes are critical \\cite{belani20194yc}.\n\n*   **7. Technical Significance**\n    *   **Advance State-of-the-Art:** The paper significantly advances the technical state-of-the-art by providing a structured, comprehensive framework (RE4AI taxonomy) for understanding and categorizing the unique requirements engineering challenges in AI-based complex systems \\cite{belani20194yc}. It bridges the gap between traditional RE and the specific demands of AI development, offering a roadmap for practitioners and researchers.\n    *   **Potential Impact on Future Research:** The RE4AI taxonomy can inform the tailoring of AI development processes and guide future research into specific RE activities for AI \\cite{belani20194yc}. It explicitly suggests GORE as a promising area for further investigation to model ML subsystems as goal-seeking entities. The paper also calls for detailed exploration of new system design paradigms (e.g., Data-driven and Model-based Design - DMD) in conjunction with the RE4AI taxonomy, and highlights critical \"skill,\" \"data,\" and \"engineering\" gaps that require future attention \\cite{belani20194yc}.",
      "keywords": [
        "RE4AI taxonomy",
        "Requirements Engineering for AI",
        "AI-based complex systems",
        "Machine Learning",
        "Deep Learning",
        "Goal-Oriented Requirements Engineering",
        "Technical debt in AI systems",
        "ML-specific risk factors",
        "\"Black-box\" AI models",
        "AI development processes",
        "System design anti-patterns",
        "Data dependencies",
        "Traceability and impact analysis"
      ],
      "paper_type": "based on the abstract and introduction:\n\n1.  **identifies challenges:** \"identifies and tackles the challenges of the requirements engineering discipline when applied to development of ai-based complex systems.\"\n2.  **highlights a gap/problem:** \"there is still no widely used and specifically tailored process in place to effectively and efficiently deal with requirements suitable for specifying a software solution that uses machine learning.\"\n3.  **proposes solutions/directions:** \"the challenges have been discussed, with proposals given how and when to tackle them. re4ai taxonomy has also been outlined, to inform the tailoring of development process.\"\n4.  **focus on current problems and proposed direction:** the introduction reinforces the scope as targeting \"challenges that arise in re as a disciplined approach to develop ai-based complex systems.\"\n\nthese points strongly align with the criteria for a **position** paper, which argues for a viewpoint or future direction by discussing current problems and proposing a way forward. while it outlines a taxonomy, it's presented as informing a process tailoring, rather than a fully developed technical system or algorithm.\n\n**classification:** position"
    },
    "file_name": "58090cdbb7526f4e22c09387814ee060dab1de54.pdf"
  },
  {
    "success": true,
    "doc_id": "01cd4fb45add622315780404e4e7c87e",
    "summary": "In recent years, the use of more and more technology in education has been a trend. The shift of traditional learning procedures into more online and tech-ish approaches has contributed to a context that can favor integrating Artificial-Intelligence-based or algorithm-based assessment of learning. Even more, with the current acceleration because of the COVID-19 pandemic, more and more learning processes are becoming online and are incorporating technologies related to automatize assessment or help instructors in the process. While we are in an initial stage of that integration, it is the moment to reflect on the students' perceptions of being assessed by a non-conscious software entity like a machine learning model or any other artificial intelligence application. As a result of the paper, we present a TAM-based model and a ready-to-use instrument based on five aspects concerning understanding technology adoption like the AI-based assessment on education. These aspects are perceived usefulness, perceived ease of use, attitude towards use, behavioral intention, and actual use. The paper's outcomes can be relevant to the research community since there is a lack of this kind of proposal in the literature.",
    "intriguing_abstract": "In recent years, the use of more and more technology in education has been a trend. The shift of traditional learning procedures into more online and tech-ish approaches has contributed to a context that can favor integrating Artificial-Intelligence-based or algorithm-based assessment of learning. Even more, with the current acceleration because of the COVID-19 pandemic, more and more learning processes are becoming online and are incorporating technologies related to automatize assessment or help instructors in the process. While we are in an initial stage of that integration, it is the moment to reflect on the students' perceptions of being assessed by a non-conscious software entity like a machine learning model or any other artificial intelligence application. As a result of the paper, we present a TAM-based model and a ready-to-use instrument based on five aspects concerning understanding technology adoption like the AI-based assessment on education. These aspects are perceived usefulness, perceived ease of use, attitude towards use, behavioral intention, and actual use. The paper's outcomes can be relevant to the research community since there is a lack of this kind of proposal in the literature.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/abedd93d38a56e6652aa04627b11cfa55c2af651.pdf",
    "citation_key": "prieto2020w0l",
    "metadata": {
      "title": "Assessed by Machines: Development of a TAM-Based Tool to Measure AI-based Assessment Acceptance Among Students",
      "authors": [
        "José Carlos Sánchez Prieto",
        "Juan Cruz-Benito",
        "Roberto Therón",
        "F. García-Peñalvo"
      ],
      "published_date": "2020",
      "abstract": "In recent years, the use of more and more technology in education has been a trend. The shift of traditional learning procedures into more online and tech-ish approaches has contributed to a context that can favor integrating Artificial-Intelligence-based or algorithm-based assessment of learning. Even more, with the current acceleration because of the COVID-19 pandemic, more and more learning processes are becoming online and are incorporating technologies related to automatize assessment or help instructors in the process. While we are in an initial stage of that integration, it is the moment to reflect on the students' perceptions of being assessed by a non-conscious software entity like a machine learning model or any other artificial intelligence application. As a result of the paper, we present a TAM-based model and a ready-to-use instrument based on five aspects concerning understanding technology adoption like the AI-based assessment on education. These aspects are perceived usefulness, perceived ease of use, attitude towards use, behavioral intention, and actual use. The paper's outcomes can be relevant to the research community since there is a lack of this kind of proposal in the literature.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/abedd93d38a56e6652aa04627b11cfa55c2af651.pdf",
      "venue": "Int. J. Interact. Multim. Artif. Intell.",
      "citationCount": 58,
      "score": 11.600000000000001,
      "summary": "In recent years, the use of more and more technology in education has been a trend. The shift of traditional learning procedures into more online and tech-ish approaches has contributed to a context that can favor integrating Artificial-Intelligence-based or algorithm-based assessment of learning. Even more, with the current acceleration because of the COVID-19 pandemic, more and more learning processes are becoming online and are incorporating technologies related to automatize assessment or help instructors in the process. While we are in an initial stage of that integration, it is the moment to reflect on the students' perceptions of being assessed by a non-conscious software entity like a machine learning model or any other artificial intelligence application. As a result of the paper, we present a TAM-based model and a ready-to-use instrument based on five aspects concerning understanding technology adoption like the AI-based assessment on education. These aspects are perceived usefulness, perceived ease of use, attitude towards use, behavioral intention, and actual use. The paper's outcomes can be relevant to the research community since there is a lack of this kind of proposal in the literature.",
      "keywords": []
    },
    "file_name": "abedd93d38a56e6652aa04627b11cfa55c2af651.pdf"
  },
  {
    "success": true,
    "doc_id": "b15f7e3321703edbaa0bbc0ce70c7e05",
    "summary": "When developing software systems that contain Machine Learning (ML) based components, the development process become significantly more complex. The central part of the ML process is training iterations to find the best possible prediction model. Modern software development processes, such as DevOps, have widely been adopted and typically emphasise frequent development iterations and continuous delivery of software changes. Despite the ability of modern approaches in solving some of the problems faced when building ML-based software systems, there are no established procedures on how to combine them with processes in ML workflow in practice today. This paper points out the challenges in development of complex systems that include ML components, and discuss possible solutions driven by the combination of DevOps and ML workflow processes. Industrial cases are presented to illustrate these challenges and the possible solutions.",
    "intriguing_abstract": "When developing software systems that contain Machine Learning (ML) based components, the development process become significantly more complex. The central part of the ML process is training iterations to find the best possible prediction model. Modern software development processes, such as DevOps, have widely been adopted and typically emphasise frequent development iterations and continuous delivery of software changes. Despite the ability of modern approaches in solving some of the problems faced when building ML-based software systems, there are no established procedures on how to combine them with processes in ML workflow in practice today. This paper points out the challenges in development of complex systems that include ML components, and discuss possible solutions driven by the combination of DevOps and ML workflow processes. Industrial cases are presented to illustrate these challenges and the possible solutions.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/877ae5a0bc9eb975d23467a13459a028f2ac8774.pdf",
    "citation_key": "lwakatare2020cgl",
    "metadata": {
      "title": "DevOps for AI – Challenges in Development of AI-enabled Applications",
      "authors": [
        "Lucy Ellen Lwakatare",
        "I. Crnkovic",
        "J. Bosch"
      ],
      "published_date": "2020",
      "abstract": "When developing software systems that contain Machine Learning (ML) based components, the development process become significantly more complex. The central part of the ML process is training iterations to find the best possible prediction model. Modern software development processes, such as DevOps, have widely been adopted and typically emphasise frequent development iterations and continuous delivery of software changes. Despite the ability of modern approaches in solving some of the problems faced when building ML-based software systems, there are no established procedures on how to combine them with processes in ML workflow in practice today. This paper points out the challenges in development of complex systems that include ML components, and discuss possible solutions driven by the combination of DevOps and ML workflow processes. Industrial cases are presented to illustrate these challenges and the possible solutions.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/877ae5a0bc9eb975d23467a13459a028f2ac8774.pdf",
      "venue": "International Conference on Software, Telecommunications and Computer Networks",
      "citationCount": 54,
      "score": 10.8,
      "summary": "When developing software systems that contain Machine Learning (ML) based components, the development process become significantly more complex. The central part of the ML process is training iterations to find the best possible prediction model. Modern software development processes, such as DevOps, have widely been adopted and typically emphasise frequent development iterations and continuous delivery of software changes. Despite the ability of modern approaches in solving some of the problems faced when building ML-based software systems, there are no established procedures on how to combine them with processes in ML workflow in practice today. This paper points out the challenges in development of complex systems that include ML components, and discuss possible solutions driven by the combination of DevOps and ML workflow processes. Industrial cases are presented to illustrate these challenges and the possible solutions.",
      "keywords": []
    },
    "file_name": "877ae5a0bc9eb975d23467a13459a028f2ac8774.pdf"
  },
  {
    "success": true,
    "doc_id": "fab3de231fcff855ff9215813f8f7bbe",
    "summary": "With the emergence of Cyber-Physical Systems (CPS), the increasing complexity in development and operation demands for an efficient engineering process. In the recent years DevOps promotes closer continuous integration of system development and its operational deployment perspectives. In this context, the use of Artificial Intelligence (AI) is beneficial to improve the system design and integration activities, however, it is still limited despite its high potential. AIDOaRT is a 3 years long H2020-ECSEL European project involving 32 organizations, grouped in clusters from 7 different countries, focusing on AI-augmented automation supporting modelling, coding, testing, monitoring and continuous development of Cyber-Physical Systems (CPS). The project proposes to apply Model-Driven Engineering (MDE) principles and techniques to provide a framework offering proper AI-enhanced methods and related tooling for building trustable CPSs. The framework is intended to work within the DevOps practices combining software development and information technology (IT) operations. In this regard, the project points at enabling AI for IT operations (AIOps) to auto-mate decision making process and complete system development tasks. This paper presents an overview of the project with the aim to discuss context, objectives and the proposed approach.",
    "intriguing_abstract": "With the emergence of Cyber-Physical Systems (CPS), the increasing complexity in development and operation demands for an efficient engineering process. In the recent years DevOps promotes closer continuous integration of system development and its operational deployment perspectives. In this context, the use of Artificial Intelligence (AI) is beneficial to improve the system design and integration activities, however, it is still limited despite its high potential. AIDOaRT is a 3 years long H2020-ECSEL European project involving 32 organizations, grouped in clusters from 7 different countries, focusing on AI-augmented automation supporting modelling, coding, testing, monitoring and continuous development of Cyber-Physical Systems (CPS). The project proposes to apply Model-Driven Engineering (MDE) principles and techniques to provide a framework offering proper AI-enhanced methods and related tooling for building trustable CPSs. The framework is intended to work within the DevOps practices combining software development and information technology (IT) operations. In this regard, the project points at enabling AI for IT operations (AIOps) to auto-mate decision making process and complete system development tasks. This paper presents an overview of the project with the aim to discuss context, objectives and the proposed approach.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/27bed49eb06b15f29260a217a3329d36c111801e.pdf",
    "citation_key": "eramo2021l4k",
    "metadata": {
      "title": "AIDOaRt: AI-augmented Automation for DevOps, a Model-based Framework for Continuous Development in Cyber-Physical Systems",
      "authors": [
        "Romina Eramo",
        "V. Muttillo",
        "Luca Berardinelli",
        "H. Brunelière",
        "A. Gómez",
        "A. Bagnato",
        "Andrey Sadovykh",
        "A. Cicchetti"
      ],
      "published_date": "2021",
      "abstract": "With the emergence of Cyber-Physical Systems (CPS), the increasing complexity in development and operation demands for an efficient engineering process. In the recent years DevOps promotes closer continuous integration of system development and its operational deployment perspectives. In this context, the use of Artificial Intelligence (AI) is beneficial to improve the system design and integration activities, however, it is still limited despite its high potential. AIDOaRT is a 3 years long H2020-ECSEL European project involving 32 organizations, grouped in clusters from 7 different countries, focusing on AI-augmented automation supporting modelling, coding, testing, monitoring and continuous development of Cyber-Physical Systems (CPS). The project proposes to apply Model-Driven Engineering (MDE) principles and techniques to provide a framework offering proper AI-enhanced methods and related tooling for building trustable CPSs. The framework is intended to work within the DevOps practices combining software development and information technology (IT) operations. In this regard, the project points at enabling AI for IT operations (AIOps) to auto-mate decision making process and complete system development tasks. This paper presents an overview of the project with the aim to discuss context, objectives and the proposed approach.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/27bed49eb06b15f29260a217a3329d36c111801e.pdf",
      "venue": "Euromicro Symposium on Digital Systems Design",
      "citationCount": 43,
      "score": 10.75,
      "summary": "With the emergence of Cyber-Physical Systems (CPS), the increasing complexity in development and operation demands for an efficient engineering process. In the recent years DevOps promotes closer continuous integration of system development and its operational deployment perspectives. In this context, the use of Artificial Intelligence (AI) is beneficial to improve the system design and integration activities, however, it is still limited despite its high potential. AIDOaRT is a 3 years long H2020-ECSEL European project involving 32 organizations, grouped in clusters from 7 different countries, focusing on AI-augmented automation supporting modelling, coding, testing, monitoring and continuous development of Cyber-Physical Systems (CPS). The project proposes to apply Model-Driven Engineering (MDE) principles and techniques to provide a framework offering proper AI-enhanced methods and related tooling for building trustable CPSs. The framework is intended to work within the DevOps practices combining software development and information technology (IT) operations. In this regard, the project points at enabling AI for IT operations (AIOps) to auto-mate decision making process and complete system development tasks. This paper presents an overview of the project with the aim to discuss context, objectives and the proposed approach.",
      "keywords": []
    },
    "file_name": "27bed49eb06b15f29260a217a3329d36c111801e.pdf"
  },
  {
    "success": true,
    "doc_id": "055f1635718bde530eab31f17272bf40",
    "summary": "Artificial intelligence (AI) software in radiology is becoming increasingly prevalent and performance is improving rapidly with new applications for given use cases being developed continuously, oftentimes with development and validation occurring in parallel. Several guidelines have provided reporting standards for publications of AI-based research in medicine and radiology. Yet, there is an unmet need for recommendations on the assessment of AI software before adoption and after commercialization. As the radiology AI ecosystem continues to grow and mature, a formalization of system assessment and evaluation is paramount to ensure patient safety, relevance and support to clinical workflows, and optimal allocation of limited AI development and validation resources before broader implementation into clinical practice. To fulfil these needs, we provide a glossary for AI software types, use cases and roles within the clinical workflow; list healthcare needs, key performance indicators and required information about software prior to assessment; and lay out examples of software performance metrics per software category. This conceptual framework is intended to streamline communication with the AI software industry and provide healthcare decision makers and radiologists with tools to assess the potential use of these software. The proposed software evaluation framework lays the foundation for a radiologist-led prospective validation network of radiology AI software. Learning Points: The rapid expansion of AI applications in radiology requires standardization of AI software specification, classification, and evaluation. The Canadian Association of Radiologists' AI Tech & Apps Working Group Proposes an AI Specification document format and supports the implementation of a clinical expert evaluation process for Radiology AI software.",
    "intriguing_abstract": "Artificial intelligence (AI) software in radiology is becoming increasingly prevalent and performance is improving rapidly with new applications for given use cases being developed continuously, oftentimes with development and validation occurring in parallel. Several guidelines have provided reporting standards for publications of AI-based research in medicine and radiology. Yet, there is an unmet need for recommendations on the assessment of AI software before adoption and after commercialization. As the radiology AI ecosystem continues to grow and mature, a formalization of system assessment and evaluation is paramount to ensure patient safety, relevance and support to clinical workflows, and optimal allocation of limited AI development and validation resources before broader implementation into clinical practice. To fulfil these needs, we provide a glossary for AI software types, use cases and roles within the clinical workflow; list healthcare needs, key performance indicators and required information about software prior to assessment; and lay out examples of software performance metrics per software category. This conceptual framework is intended to streamline communication with the AI software industry and provide healthcare decision makers and radiologists with tools to assess the potential use of these software. The proposed software evaluation framework lays the foundation for a radiologist-led prospective validation network of radiology AI software. Learning Points: The rapid expansion of AI applications in radiology requires standardization of AI software specification, classification, and evaluation. The Canadian Association of Radiologists' AI Tech & Apps Working Group Proposes an AI Specification document format and supports the implementation of a clinical expert evaluation process for Radiology AI software.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b6764d461c477c3c42a0ecee2fd9dd9ecaa0f7fc.pdf",
    "citation_key": "tanguay2022btj",
    "metadata": {
      "title": "Assessment of Radiology Artificial Intelligence Software: A Validation and Evaluation Framework",
      "authors": [
        "William Tanguay",
        "Philippe Acar",
        "Benjamin Fine",
        "M. Abdolell",
        "B. Gong",
        "A. Cadrin-Chênevert",
        "C. Chartrand-Lefebvre",
        "J. Chalaoui",
        "A. Gorgos",
        "Anne Shu-Lei Chin",
        "J. Prénovault",
        "F. Guilbert",
        "L. Létourneau-Guillon",
        "Jaron J. R. Chong",
        "A. Tang"
      ],
      "published_date": "2022",
      "abstract": "Artificial intelligence (AI) software in radiology is becoming increasingly prevalent and performance is improving rapidly with new applications for given use cases being developed continuously, oftentimes with development and validation occurring in parallel. Several guidelines have provided reporting standards for publications of AI-based research in medicine and radiology. Yet, there is an unmet need for recommendations on the assessment of AI software before adoption and after commercialization. As the radiology AI ecosystem continues to grow and mature, a formalization of system assessment and evaluation is paramount to ensure patient safety, relevance and support to clinical workflows, and optimal allocation of limited AI development and validation resources before broader implementation into clinical practice. To fulfil these needs, we provide a glossary for AI software types, use cases and roles within the clinical workflow; list healthcare needs, key performance indicators and required information about software prior to assessment; and lay out examples of software performance metrics per software category. This conceptual framework is intended to streamline communication with the AI software industry and provide healthcare decision makers and radiologists with tools to assess the potential use of these software. The proposed software evaluation framework lays the foundation for a radiologist-led prospective validation network of radiology AI software. Learning Points: The rapid expansion of AI applications in radiology requires standardization of AI software specification, classification, and evaluation. The Canadian Association of Radiologists' AI Tech & Apps Working Group Proposes an AI Specification document format and supports the implementation of a clinical expert evaluation process for Radiology AI software.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b6764d461c477c3c42a0ecee2fd9dd9ecaa0f7fc.pdf",
      "venue": "Canadian Association of Radiologists journal = Journal l'Association canadienne des radiologistes",
      "citationCount": 31,
      "score": 10.333333333333332,
      "summary": "Artificial intelligence (AI) software in radiology is becoming increasingly prevalent and performance is improving rapidly with new applications for given use cases being developed continuously, oftentimes with development and validation occurring in parallel. Several guidelines have provided reporting standards for publications of AI-based research in medicine and radiology. Yet, there is an unmet need for recommendations on the assessment of AI software before adoption and after commercialization. As the radiology AI ecosystem continues to grow and mature, a formalization of system assessment and evaluation is paramount to ensure patient safety, relevance and support to clinical workflows, and optimal allocation of limited AI development and validation resources before broader implementation into clinical practice. To fulfil these needs, we provide a glossary for AI software types, use cases and roles within the clinical workflow; list healthcare needs, key performance indicators and required information about software prior to assessment; and lay out examples of software performance metrics per software category. This conceptual framework is intended to streamline communication with the AI software industry and provide healthcare decision makers and radiologists with tools to assess the potential use of these software. The proposed software evaluation framework lays the foundation for a radiologist-led prospective validation network of radiology AI software. Learning Points: The rapid expansion of AI applications in radiology requires standardization of AI software specification, classification, and evaluation. The Canadian Association of Radiologists' AI Tech & Apps Working Group Proposes an AI Specification document format and supports the implementation of a clinical expert evaluation process for Radiology AI software.",
      "keywords": []
    },
    "file_name": "b6764d461c477c3c42a0ecee2fd9dd9ecaa0f7fc.pdf"
  },
  {
    "success": true,
    "doc_id": "a81d9cd55a968ac6c1cbda0c74989ea8",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   The paper addresses the critical technical problem that existing high-level AI ethics principles and guidelines lack concrete, operationalized guidance for designing and developing responsible AI systems \\cite{lu2021m0b}.\n    *   This problem is important because while AI is transforming industries, there are serious concerns about its ability to behave responsibly. It is challenging because AI systems are often highly uncertain, involve continual learning, and require system-level ethical consideration beyond just the AI model \\cite{lu2021m0b}. Developers currently face difficulties in integrating ethical considerations throughout the AI lifecycle.\n\n*   **2. Related Work & Positioning**\n    *   This work positions itself as a bridge between abstract AI ethics principles (e.g., from governments and organizations) and practical software engineering implementation \\cite{lu2021m0b}.\n    *   Limitations of previous solutions highlighted include:\n        *   Current ethical risk assessments are often \"done-once-and-forget,\" insufficient for dynamic, continual learning AI systems \\cite{lu2021m0b}.\n        *   Responsible AI requirements are frequently stated as high-level objectives rather than verifiable specifications \\cite{lu2021m0b}.\n        *   System-level architecture and design for responsible AI are under-explored, with a focus often limited to the AI model itself \\cite{lu2021m0b}.\n        *   Existing MLOps/AIOps practices provide limited guidance for continuous monitoring and validation of responsible AI requirements post-deployment \\cite{lu2021m0b}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:**\n        *   An empirical study was conducted, interviewing 21 AI scientists and engineers to understand their perceptions and challenges in implementing AI ethics principles \\cite{lu2021m0b}.\n        *   Based on these findings and literature review, the authors propose a novel template for operationalizing AI ethics principles into concrete, actionable \"patterns\" \\cite{lu2021m0b}.\n        *   They then suggest a list of process and design patterns using this template, covering the entire AI system lifecycle (from requirement engineering to deployment and operation) \\cite{lu2021m0b}.\n    *   **Novelty/Difference:**\n        *   This is presented as the first in-depth empirical study exploring practitioners' perceptions on AI ethics principles and their implementation \\cite{lu2021m0b}.\n        *   The innovation lies in moving beyond abstract guidelines to provide concrete, operationalized software engineering patterns, offering practical guidance for developers \\cite{lu2021m0b}.\n        *   It emphasizes integrating responsible AI considerations throughout the entire AI system development and operation (AIOps/MLOps) process, including both AI and non-AI components, addressing system-level emergent behaviors \\cite{lu2021m0b}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   A novel pattern template designed to operationalize abstract AI ethics principles into concrete, verifiable, and actionable software engineering patterns \\cite{lu2021m0b}.\n        *   A suggested list of ethical assurance patterns (process and design patterns) derived from empirical data and existing software engineering practices, providing specific guidance for responsible AI development across the lifecycle \\cite{lu2021m0b}.\n    *   **System Design or Architectural Innovations:**\n        *   Identification and integration of responsible AI considerations into an end-to-end AI system development and operation (AIOps/MLOps) process, encompassing data engineering, feature engineering, model training, evaluation, and continuous updates \\cite{lu2021m0b}.\n        *   Emphasis on system-level ethical consideration, recognizing that combining AI and non-AI components can create new emergent behaviors and dynamics requiring holistic design \\cite{lu2021m0b}.\n    *   **Theoretical Insights or Analysis:**\n        *   Empirical findings highlighting the inadequacy of \"done-once-and-forget\" risk assessments and the strong desire for continuous monitoring and validation of responsible AI post-deployment \\cite{lu2021m0b}.\n        *   Distinction between system trustworthiness (inherent ability to meet principles) and human trust (subjective estimation), and the need for process/product evidence to drive trust \\cite{lu2021m0b}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** An empirical study was performed involving semi-structured interviews with 21 AI scientists and engineers from various backgrounds (computer science, health & biosecurity, land & water) and roles (research scientist, team leader, etc.) \\cite{lu2021m0b}. The interviews explored ethical issues considered in their AI projects and how they were addressed.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Interview Findings (RQ1):** The study revealed that \"Reliability & Safety\" (90%), \"Transparency & Explainability\" (86%), and \"Privacy Protection & Security\" (81%) were the most frequently discussed AI ethics principles among practitioners \\cite{lu2021m0b}.\n        *   **Identified Challenges:** The study empirically validated that current practices suffer from \"done-once-and-forget\" risk assessments, high-level and unverifiable responsible AI requirements, under-explored system-level ethical design, and a lack of continuous monitoring guidance in MLOps/AIOps \\cite{lu2021m0b}. It also found that implementation heavily relies on manual operations due to a lack of end-to-end tools \\cite{lu2021m0b}.\n        *   These empirical findings directly informed the design of the pattern template and the proposed list of operationalized patterns (RQ2), demonstrating that the proposed solution is grounded in real-world practitioner needs and challenges \\cite{lu2021m0b}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations or Assumptions:** The empirical study's interviewees were primarily from a single research institute, which may limit the generalizability of findings to a broader industry context \\cite{lu2021m0b}. The proposed list of patterns is an initial suggestion and requires further validation, refinement, and extension in diverse real-world AI projects \\cite{lu2021m0b}.\n    *   **Scope of Applicability:** The work focuses on providing software engineering guidance for operationalizing AI ethics principles across the entire lifecycle of AI systems, from requirements to deployment and operation \\cite{lu2021m0b}. It aims to guide AI developers in building responsible AI systems.\n\n*   **7. Technical Significance**\n    *   **Advances the Technical State-of-the-Art:** This paper significantly advances the state-of-the-art by translating abstract AI ethics principles into concrete, actionable software engineering patterns, thereby bridging a critical gap between ethical theory and practical development \\cite{lu2021m0b}. It integrates responsible AI considerations directly into the AI system development and MLOps/AIOps lifecycle, promoting continuous assurance rather than isolated checks \\cite{lu2021m0b}.\n    *   **Potential Impact on Future Research:** The proposed pattern template and initial list of patterns provide a foundational framework for future research in developing standardized tools, architectural patterns, and automated solutions for continuous monitoring and assurance of AI ethics \\cite{lu2021m0b}. It encourages a shift towards a more systematic, engineering-driven approach to responsible AI development, fostering the creation of more trustworthy and ethically sound AI systems.",
    "intriguing_abstract": "The proliferation of AI systems demands robust ethical integration, yet developers grapple with abstract principles lacking actionable guidance. This paper addresses this critical gap by presenting the first in-depth empirical study, interviewing 21 AI scientists and engineers, to uncover real-world challenges in operationalizing AI ethics. We reveal that current \"done-once-and-forget\" risk assessments and model-centric approaches are insufficient for dynamic, continually learning AI. To overcome this, we introduce a novel pattern template designed to translate high-level AI ethics principles into concrete, verifiable **software engineering patterns**. Our contribution includes a suggested list of these **ethical assurance patterns**, spanning the entire **AI system lifecycle** from requirements to **MLOps/AIOps**. This work emphasizes **system-level ethical design**, ensuring continuous monitoring and validation of **responsible AI** beyond isolated checks. By bridging the chasm between ethical theory and practical development, we provide a foundational framework for building truly trustworthy and ethically sound AI systems, paving the way for systematic, engineering-driven responsible AI.",
    "keywords": [
      "AI ethics principles",
      "operationalized AI ethics",
      "responsible AI systems",
      "software engineering patterns",
      "AI system lifecycle",
      "empirical study",
      "MLOps/AIOps integration",
      "system-level ethical consideration",
      "ethical assurance patterns",
      "continuous monitoring and validation",
      "novel pattern template",
      "practitioner challenges",
      "trustworthy AI"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6a03b02e61b447ce1456624853d7accfd24a2711.pdf",
    "citation_key": "lu2021m0b",
    "metadata": {
      "title": "Software engineering for Responsible AI: An empirical study and operationalised patterns",
      "authors": [
        "Q. Lu",
        "Liming Zhu",
        "Xiwei Xu",
        "J. Whittle",
        "David M. Douglas",
        "Conrad Sanderson"
      ],
      "published_date": "2021",
      "abstract": "AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to develop responsible AI systems. To address this shortcoming, we perform an empirical study involving interviews with 21 scientists and engineers to understand the practitioners' views on AI ethics principles and their implementation. Our major findings are: (1) the current practice is often a done-once-and-forget type of ethical risk assessment at a particular development step, which is not sufficient for highly uncertain and continual learning AI systems; (2) ethical requirements are either omitted or mostly stated as high-level objectives, and not specified explicitly in verifiable way as system outputs or outcomes; (3) although ethical requirements have the characteristics of cross-cutting quality and non-functional requirements amenable to architecture and design analysis, system-level architecture and design are under-explored; (4) there is a strong desire for continuously monitoring and validating AI systems post deployment for ethical requirements but current operation practices provide limited guidance. To address these findings, we suggest a preliminary list of patterns to provide operationalised guidance for developing responsible AI systems.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6a03b02e61b447ce1456624853d7accfd24a2711.pdf",
      "venue": "2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
      "citationCount": 40,
      "score": 10.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   The paper addresses the critical technical problem that existing high-level AI ethics principles and guidelines lack concrete, operationalized guidance for designing and developing responsible AI systems \\cite{lu2021m0b}.\n    *   This problem is important because while AI is transforming industries, there are serious concerns about its ability to behave responsibly. It is challenging because AI systems are often highly uncertain, involve continual learning, and require system-level ethical consideration beyond just the AI model \\cite{lu2021m0b}. Developers currently face difficulties in integrating ethical considerations throughout the AI lifecycle.\n\n*   **2. Related Work & Positioning**\n    *   This work positions itself as a bridge between abstract AI ethics principles (e.g., from governments and organizations) and practical software engineering implementation \\cite{lu2021m0b}.\n    *   Limitations of previous solutions highlighted include:\n        *   Current ethical risk assessments are often \"done-once-and-forget,\" insufficient for dynamic, continual learning AI systems \\cite{lu2021m0b}.\n        *   Responsible AI requirements are frequently stated as high-level objectives rather than verifiable specifications \\cite{lu2021m0b}.\n        *   System-level architecture and design for responsible AI are under-explored, with a focus often limited to the AI model itself \\cite{lu2021m0b}.\n        *   Existing MLOps/AIOps practices provide limited guidance for continuous monitoring and validation of responsible AI requirements post-deployment \\cite{lu2021m0b}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:**\n        *   An empirical study was conducted, interviewing 21 AI scientists and engineers to understand their perceptions and challenges in implementing AI ethics principles \\cite{lu2021m0b}.\n        *   Based on these findings and literature review, the authors propose a novel template for operationalizing AI ethics principles into concrete, actionable \"patterns\" \\cite{lu2021m0b}.\n        *   They then suggest a list of process and design patterns using this template, covering the entire AI system lifecycle (from requirement engineering to deployment and operation) \\cite{lu2021m0b}.\n    *   **Novelty/Difference:**\n        *   This is presented as the first in-depth empirical study exploring practitioners' perceptions on AI ethics principles and their implementation \\cite{lu2021m0b}.\n        *   The innovation lies in moving beyond abstract guidelines to provide concrete, operationalized software engineering patterns, offering practical guidance for developers \\cite{lu2021m0b}.\n        *   It emphasizes integrating responsible AI considerations throughout the entire AI system development and operation (AIOps/MLOps) process, including both AI and non-AI components, addressing system-level emergent behaviors \\cite{lu2021m0b}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   A novel pattern template designed to operationalize abstract AI ethics principles into concrete, verifiable, and actionable software engineering patterns \\cite{lu2021m0b}.\n        *   A suggested list of ethical assurance patterns (process and design patterns) derived from empirical data and existing software engineering practices, providing specific guidance for responsible AI development across the lifecycle \\cite{lu2021m0b}.\n    *   **System Design or Architectural Innovations:**\n        *   Identification and integration of responsible AI considerations into an end-to-end AI system development and operation (AIOps/MLOps) process, encompassing data engineering, feature engineering, model training, evaluation, and continuous updates \\cite{lu2021m0b}.\n        *   Emphasis on system-level ethical consideration, recognizing that combining AI and non-AI components can create new emergent behaviors and dynamics requiring holistic design \\cite{lu2021m0b}.\n    *   **Theoretical Insights or Analysis:**\n        *   Empirical findings highlighting the inadequacy of \"done-once-and-forget\" risk assessments and the strong desire for continuous monitoring and validation of responsible AI post-deployment \\cite{lu2021m0b}.\n        *   Distinction between system trustworthiness (inherent ability to meet principles) and human trust (subjective estimation), and the need for process/product evidence to drive trust \\cite{lu2021m0b}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** An empirical study was performed involving semi-structured interviews with 21 AI scientists and engineers from various backgrounds (computer science, health & biosecurity, land & water) and roles (research scientist, team leader, etc.) \\cite{lu2021m0b}. The interviews explored ethical issues considered in their AI projects and how they were addressed.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Interview Findings (RQ1):** The study revealed that \"Reliability & Safety\" (90%), \"Transparency & Explainability\" (86%), and \"Privacy Protection & Security\" (81%) were the most frequently discussed AI ethics principles among practitioners \\cite{lu2021m0b}.\n        *   **Identified Challenges:** The study empirically validated that current practices suffer from \"done-once-and-forget\" risk assessments, high-level and unverifiable responsible AI requirements, under-explored system-level ethical design, and a lack of continuous monitoring guidance in MLOps/AIOps \\cite{lu2021m0b}. It also found that implementation heavily relies on manual operations due to a lack of end-to-end tools \\cite{lu2021m0b}.\n        *   These empirical findings directly informed the design of the pattern template and the proposed list of operationalized patterns (RQ2), demonstrating that the proposed solution is grounded in real-world practitioner needs and challenges \\cite{lu2021m0b}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations or Assumptions:** The empirical study's interviewees were primarily from a single research institute, which may limit the generalizability of findings to a broader industry context \\cite{lu2021m0b}. The proposed list of patterns is an initial suggestion and requires further validation, refinement, and extension in diverse real-world AI projects \\cite{lu2021m0b}.\n    *   **Scope of Applicability:** The work focuses on providing software engineering guidance for operationalizing AI ethics principles across the entire lifecycle of AI systems, from requirements to deployment and operation \\cite{lu2021m0b}. It aims to guide AI developers in building responsible AI systems.\n\n*   **7. Technical Significance**\n    *   **Advances the Technical State-of-the-Art:** This paper significantly advances the state-of-the-art by translating abstract AI ethics principles into concrete, actionable software engineering patterns, thereby bridging a critical gap between ethical theory and practical development \\cite{lu2021m0b}. It integrates responsible AI considerations directly into the AI system development and MLOps/AIOps lifecycle, promoting continuous assurance rather than isolated checks \\cite{lu2021m0b}.\n    *   **Potential Impact on Future Research:** The proposed pattern template and initial list of patterns provide a foundational framework for future research in developing standardized tools, architectural patterns, and automated solutions for continuous monitoring and assurance of AI ethics \\cite{lu2021m0b}. It encourages a shift towards a more systematic, engineering-driven approach to responsible AI development, fostering the creation of more trustworthy and ethically sound AI systems.",
      "keywords": [
        "AI ethics principles",
        "operationalized AI ethics",
        "responsible AI systems",
        "software engineering patterns",
        "AI system lifecycle",
        "empirical study",
        "MLOps/AIOps integration",
        "system-level ethical consideration",
        "ethical assurance patterns",
        "continuous monitoring and validation",
        "novel pattern template",
        "practitioner challenges",
        "trustworthy AI"
      ],
      "paper_type": "based on the abstract and introduction:\n\n1.  **empirical indicators:**\n    *   \"we first present an **empirical study** where we **interviewed 21 scientists and engineers** to understand the practitioners’ perceptions on ai ethics principles and their implementation.\"\n    *   the introduction explicitly states: \"to address this, we pose the research questions listed below. rq1: what are the current states and potential challenges developers are facing in dealing with responsible ai issues during the development of ai systems? we perform an **empirical study** where we **interviewed 21 ai scientists and engineers**...\"\n    *   this directly aligns with the \"empirical\" criteria: \"data-driven studies with statistical analysis,\" \"study,\" \"data,\" \"findings,\" \"research questions,\" \"methodology,\" \"participants.\"\n\n2.  **technical indicators:**\n    *   \"we then **propose a template** that enables ai ethics principles to be operationalised in the form of concrete patterns and suggest a list of patterns using the newly created template.\"\n    *   this aligns with the \"technical\" criteria: \"propose,\" \"develop,\" \"present,\" \"method.\"\n\n**conclusion:**\nthe paper clearly has both empirical and technical components. however, the abstract explicitly states that the **empirical study is presented first** to understand the problem and practitioners' perceptions, which then informs the proposed template and patterns. the empirical study is foundational to the work presented. given the strong and explicit description of the empirical methodology (interviews, participants, research questions), the paper's primary classification leans towards **empirical**. the \"operationalised patterns\" are a solution derived from or informed by this empirical understanding.\n\ntherefore, the most fitting classification is **empirical**."
    },
    "file_name": "6a03b02e61b447ce1456624853d7accfd24a2711.pdf"
  },
  {
    "success": true,
    "doc_id": "f0fcfc2021f70c8a7667493fc4d95f08",
    "summary": "AI provides tremendous opportunities for improving patient care, but at present there is little evidence of real-world uptake. An important barrier is the lack of well-designed, vendor-neutral and future-proof infrastructures for deployment. Because current AI algorithms are very narrow in scope, it is expected that a typical hospital will deploy many algorithms concurrently. Managing stand-alone point solutions for all of these algorithms will be unmanageable. A solution to this problem is a dedicated platform for deployment of AI. Here we describe a blueprint for such a platform and the high-level design and implementation considerations of such a system that can be used clinically as well as for research and development. Close collaboration between radiologists, data scientists, software developers and experts in hospital IT as well as involvement of patients is crucial in order to successfully bring AI to the clinic.",
    "intriguing_abstract": "AI provides tremendous opportunities for improving patient care, but at present there is little evidence of real-world uptake. An important barrier is the lack of well-designed, vendor-neutral and future-proof infrastructures for deployment. Because current AI algorithms are very narrow in scope, it is expected that a typical hospital will deploy many algorithms concurrently. Managing stand-alone point solutions for all of these algorithms will be unmanageable. A solution to this problem is a dedicated platform for deployment of AI. Here we describe a blueprint for such a platform and the high-level design and implementation considerations of such a system that can be used clinically as well as for research and development. Close collaboration between radiologists, data scientists, software developers and experts in hospital IT as well as involvement of patients is crucial in order to successfully bring AI to the clinic.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/1359b5cc1fb832d70c115d3e14b55cb9dc3fb8dd.pdf",
    "citation_key": "leiner20219sd",
    "metadata": {
      "title": "Bringing AI to the clinic: blueprint for a vendor-neutral AI deployment infrastructure",
      "authors": [
        "T. Leiner",
        "E. Bennink",
        "Christian P. Mol",
        "Hugo J. Kuijf",
        "W. Veldhuis"
      ],
      "published_date": "2021",
      "abstract": "AI provides tremendous opportunities for improving patient care, but at present there is little evidence of real-world uptake. An important barrier is the lack of well-designed, vendor-neutral and future-proof infrastructures for deployment. Because current AI algorithms are very narrow in scope, it is expected that a typical hospital will deploy many algorithms concurrently. Managing stand-alone point solutions for all of these algorithms will be unmanageable. A solution to this problem is a dedicated platform for deployment of AI. Here we describe a blueprint for such a platform and the high-level design and implementation considerations of such a system that can be used clinically as well as for research and development. Close collaboration between radiologists, data scientists, software developers and experts in hospital IT as well as involvement of patients is crucial in order to successfully bring AI to the clinic.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/1359b5cc1fb832d70c115d3e14b55cb9dc3fb8dd.pdf",
      "venue": "Insights into Imaging",
      "citationCount": 39,
      "score": 9.75,
      "summary": "AI provides tremendous opportunities for improving patient care, but at present there is little evidence of real-world uptake. An important barrier is the lack of well-designed, vendor-neutral and future-proof infrastructures for deployment. Because current AI algorithms are very narrow in scope, it is expected that a typical hospital will deploy many algorithms concurrently. Managing stand-alone point solutions for all of these algorithms will be unmanageable. A solution to this problem is a dedicated platform for deployment of AI. Here we describe a blueprint for such a platform and the high-level design and implementation considerations of such a system that can be used clinically as well as for research and development. Close collaboration between radiologists, data scientists, software developers and experts in hospital IT as well as involvement of patients is crucial in order to successfully bring AI to the clinic.",
      "keywords": []
    },
    "file_name": "1359b5cc1fb832d70c115d3e14b55cb9dc3fb8dd.pdf"
  },
  {
    "success": true,
    "doc_id": "71bbc040e608accab47c834f4eb2d3ef",
    "summary": "In this study we explore the incorporation of artificial intelligence (AI) governance to system development life cycle (SDLC) models. We conducted expert interviews among AI and SDLC professionals and analyzed the interview data using qualitative coding and clustering to extract AI governance concepts. Subsequently, we mapped these concepts onto three stages in the machine learning (ML) system development process: (1) design, (2) development, and (3) operation. We discovered 20 governance concepts, some of which are relevant to more than one of the three stages. Our analysis highlights AI governance as a complex process that involves multiple activities and stakeholders. As development projects are unique, the governance requirements and processes also vary. This study is a step towards understanding how AI governance is conceptually connected to ML systems’ management processes through the project life cycle. CCS CONCEPTS • Software and its engineering $^{\\rightarrow}$ Software creation and management.",
    "intriguing_abstract": "In this study we explore the incorporation of artificial intelligence (AI) governance to system development life cycle (SDLC) models. We conducted expert interviews among AI and SDLC professionals and analyzed the interview data using qualitative coding and clustering to extract AI governance concepts. Subsequently, we mapped these concepts onto three stages in the machine learning (ML) system development process: (1) design, (2) development, and (3) operation. We discovered 20 governance concepts, some of which are relevant to more than one of the three stages. Our analysis highlights AI governance as a complex process that involves multiple activities and stakeholders. As development projects are unique, the governance requirements and processes also vary. This study is a step towards understanding how AI governance is conceptually connected to ML systems’ management processes through the project life cycle. CCS CONCEPTS • Software and its engineering $^{\\rightarrow}$ Software creation and management.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/bfa3cb3fae2d4fcc66b18dba752467f4f5861073.pdf",
    "citation_key": "laato2022t93",
    "metadata": {
      "title": "AI Governance in the System Development Life Cycle: Insights on Responsible Machine Learning Engineering",
      "authors": [
        "Samuli Laato",
        "Teemu Birkstedt",
        "Matti Mäntymäki",
        "Matti Minkkinen",
        "T. Mikkonen"
      ],
      "published_date": "2022",
      "abstract": "In this study we explore the incorporation of artificial intelligence (AI) governance to system development life cycle (SDLC) models. We conducted expert interviews among AI and SDLC professionals and analyzed the interview data using qualitative coding and clustering to extract AI governance concepts. Subsequently, we mapped these concepts onto three stages in the machine learning (ML) system development process: (1) design, (2) development, and (3) operation. We discovered 20 governance concepts, some of which are relevant to more than one of the three stages. Our analysis highlights AI governance as a complex process that involves multiple activities and stakeholders. As development projects are unique, the governance requirements and processes also vary. This study is a step towards understanding how AI governance is conceptually connected to ML systems’ management processes through the project life cycle. CCS CONCEPTS • Software and its engineering $^{\\rightarrow}$ Software creation and management.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/bfa3cb3fae2d4fcc66b18dba752467f4f5861073.pdf",
      "venue": "2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN)",
      "citationCount": 29,
      "score": 9.666666666666666,
      "summary": "In this study we explore the incorporation of artificial intelligence (AI) governance to system development life cycle (SDLC) models. We conducted expert interviews among AI and SDLC professionals and analyzed the interview data using qualitative coding and clustering to extract AI governance concepts. Subsequently, we mapped these concepts onto three stages in the machine learning (ML) system development process: (1) design, (2) development, and (3) operation. We discovered 20 governance concepts, some of which are relevant to more than one of the three stages. Our analysis highlights AI governance as a complex process that involves multiple activities and stakeholders. As development projects are unique, the governance requirements and processes also vary. This study is a step towards understanding how AI governance is conceptually connected to ML systems’ management processes through the project life cycle. CCS CONCEPTS • Software and its engineering $^{\\rightarrow}$ Software creation and management.",
      "keywords": []
    },
    "file_name": "bfa3cb3fae2d4fcc66b18dba752467f4f5861073.pdf"
  },
  {
    "success": true,
    "doc_id": "343e62ae425b88d41f9b7353b5527b9b",
    "summary": "Availability of powerful computation and communication technology as well as advances in artificial intelligence enable a new generation of complex, AI-intense systems and applications. Such systems and applications promise exciting improvements on a societal level, yet they also bring with them new challenges for their development. In this paper we argue that significant challenges relate to defining and ensuring behaviour and quality attributes of such systems and applications. We specifically derive four challenge areas from relevant use cases of complex, AI-intense systems and applications related to industry, transportation, and home automation: understanding, determining, and specifying (i) contextual definitions and requirements, (ii) data attributes and requirements, (iii) performance definition and monitoring, and (iv) the impact of human factors on system acceptance and success. Solving these challenges will imply process support that integrates new requirements engineering methods into development approaches for complex, AI-intense systems and applications. We present these challenges in detail and propose a research roadmap.",
    "intriguing_abstract": "Availability of powerful computation and communication technology as well as advances in artificial intelligence enable a new generation of complex, AI-intense systems and applications. Such systems and applications promise exciting improvements on a societal level, yet they also bring with them new challenges for their development. In this paper we argue that significant challenges relate to defining and ensuring behaviour and quality attributes of such systems and applications. We specifically derive four challenge areas from relevant use cases of complex, AI-intense systems and applications related to industry, transportation, and home automation: understanding, determining, and specifying (i) contextual definitions and requirements, (ii) data attributes and requirements, (iii) performance definition and monitoring, and (iv) the impact of human factors on system acceptance and success. Solving these challenges will imply process support that integrates new requirements engineering methods into development approaches for complex, AI-intense systems and applications. We present these challenges in detail and propose a research roadmap.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/e4189dca82737cbaf9b56d1e6f58e9e1dddd8151.pdf",
    "citation_key": "heyn202126v",
    "metadata": {
      "title": "Requirement Engineering Challenges for AI-intense Systems Development",
      "authors": [
        "Hans-Martin Heyn",
        "E. Knauss",
        "Amna Pir Muhammad",
        "O. Eriksson",
        "Jennifer Linder",
        "P. Subbiah",
        "S. K. Pradhan",
        "Sagar Tungal"
      ],
      "published_date": "2021",
      "abstract": "Availability of powerful computation and communication technology as well as advances in artificial intelligence enable a new generation of complex, AI-intense systems and applications. Such systems and applications promise exciting improvements on a societal level, yet they also bring with them new challenges for their development. In this paper we argue that significant challenges relate to defining and ensuring behaviour and quality attributes of such systems and applications. We specifically derive four challenge areas from relevant use cases of complex, AI-intense systems and applications related to industry, transportation, and home automation: understanding, determining, and specifying (i) contextual definitions and requirements, (ii) data attributes and requirements, (iii) performance definition and monitoring, and (iv) the impact of human factors on system acceptance and success. Solving these challenges will imply process support that integrates new requirements engineering methods into development approaches for complex, AI-intense systems and applications. We present these challenges in detail and propose a research roadmap.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/e4189dca82737cbaf9b56d1e6f58e9e1dddd8151.pdf",
      "venue": "Workshop on AI Engineering - Software Engineering for AI",
      "citationCount": 38,
      "score": 9.5,
      "summary": "Availability of powerful computation and communication technology as well as advances in artificial intelligence enable a new generation of complex, AI-intense systems and applications. Such systems and applications promise exciting improvements on a societal level, yet they also bring with them new challenges for their development. In this paper we argue that significant challenges relate to defining and ensuring behaviour and quality attributes of such systems and applications. We specifically derive four challenge areas from relevant use cases of complex, AI-intense systems and applications related to industry, transportation, and home automation: understanding, determining, and specifying (i) contextual definitions and requirements, (ii) data attributes and requirements, (iii) performance definition and monitoring, and (iv) the impact of human factors on system acceptance and success. Solving these challenges will imply process support that integrates new requirements engineering methods into development approaches for complex, AI-intense systems and applications. We present these challenges in detail and propose a research roadmap.",
      "keywords": []
    },
    "file_name": "e4189dca82737cbaf9b56d1e6f58e9e1dddd8151.pdf"
  },
  {
    "success": true,
    "doc_id": "5c3b817b30dc419f50e4dafcaf00e262",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b74c2221fc9a85dc79c6dc7e78e100b171bdc125.pdf",
    "citation_key": "cho2021kl7",
    "metadata": {
      "title": "Rising to the challenge of bias in health care AI",
      "authors": [
        "Mildred K. Cho"
      ],
      "published_date": "2021",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b74c2221fc9a85dc79c6dc7e78e100b171bdc125.pdf",
      "venue": "Nature Network Boston",
      "citationCount": 38,
      "score": 9.5,
      "summary": "",
      "keywords": []
    },
    "file_name": "b74c2221fc9a85dc79c6dc7e78e100b171bdc125.pdf"
  },
  {
    "success": true,
    "doc_id": "e13cb84fda8079ddc0734c9ee6fc7aed",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **CITATION**: \\cite{vakkuri2020co9}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Problem**: The paper addresses the critical lack of ethical consideration and implementation in Artificial Intelligence (AI) software development, particularly within agile, startup-like environments.\n    *   **Importance & Challenge**: AI systems are increasingly common, exert significant societal influence, and have demonstrated potential for harmful failures (e.g., biased algorithms). Despite this, there is limited research on practical methods and tools for integrating AI ethics into software development, and the actual state of practice is largely unknown. AI ethics is a new non-functional requirement, but existing theoretical guidelines often fail to translate into practical action.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work acknowledges a history of ethics in software design (e.g., Value Sensitive Design) but highlights that AI introduces unique ethical requirements. It references theoretical discussions on AI ethics values (transparency, accountability, responsibility, fairness) and the proliferation of guidelines from governments, standardization bodies (e.g., ISO), and major tech companies (e.g., IEEE EAD, Google, Microsoft).\n    *   **Limitations of Previous Solutions**: Existing AI ethics research is predominantly philosophical and theoretical, with a scarcity of empirical studies on practical implementation \\cite{vakkuri2020co9}. There are no project-level methods for AI ethics, only narrow technical tools for specific machine learning elements. Crucially, the paper positions itself by noting that prior empirical studies have shown ethical guidelines (like ACM's or IEEE EAD) to be largely ineffective in changing developer practices, as developers lack the norms and methods to translate principles into practice \\cite{vakkuri2020co9}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper does not propose a technical method or algorithm. Instead, its core approach is an *empirical, qualitative multiple case study* to understand the *state of practice* regarding AI ethics in software development \\cite{vakkuri2020co9}.\n    *   **Novelty/Difference**: The innovation lies in its empirical investigation into a largely unexplored area: how AI ethics are *actually* handled (or ignored) in real-world, startup-like development projects, especially when not formally mandated. It employs a structured research framework combining Dignum's ART principles (Accountability, Responsibility, Transparency), Dignum's AI ethics categories (Ethics by/in/for Design), and Abrahamsson's commitment net model (concerns and actions) to systematically analyze developer perspectives and practices \\cite{vakkuri2020co9}.\n\n4.  **Key Technical Contributions**\n    *   **Theoretical Insights/Analysis**: The primary contribution is empirical evidence revealing the *complete ignorance* of ethical considerations in AI development within the studied startup-like environments \\cite{vakkuri2020co9}. It empirically demonstrates the significant gap between theoretical AI ethics discussions and practical software engineering. The study also identifies existing \"good practices\" (e.g., documentation, error handling) that, while not explicitly for ethics, *could* potentially support ethical implementation if consciously applied \\cite{vakkuri2020co9}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: A multiple case study was conducted involving three \"startup-like\" AI software development projects in the healthcare sector in Finland \\cite{vakkuri2020co9}. Data was collected through semi-structured interviews with eight developers and managers across these projects. The cases involved developing a statistical tool for social marginalization, a speech recognition/NLP tool for diagnostics, and an NLP tool for indoor navigation. The healthcare sector was chosen due to its inherent ethical sensitivities and regulatory environment.\n    *   **Key Performance Metrics & Comparison Results**: As a qualitative study, it does not use quantitative performance metrics. Key findings (Primary Empirical Conclusions - PECs) include:\n        *   **Responsibility**: Developers' concerns were primarily practical (project schedule, quality) and detached from broader AI ethical responsibility \\cite{vakkuri2020co9}.\n        *   **Accountability**: Accountability was narrowly perceived as legal liability for data handling, with no formal processes for ethical accountability in AI system decisions \\cite{vakkuri2020co9}.\n        *   **Transparency**: Transparency focused on technical documentation and error handling, not on explaining AI decision-making or data provenance for ethical purposes \\cite{vakkuri2020co9}.\n        *   **Overall**: A pervasive \"prototype\" mindset often served as an excuse to defer ethical considerations, assuming they would be addressed later. Ethical concerns were present but rarely translated into concrete actions, highlighting a lack of commitment.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study's qualitative nature and small sample size (3 cases, 8 respondents) limit the generalizability of findings. It focuses specifically on \"startup-like\" environments, which may have different pressures than larger organizations. The analysis relies on interview data, which reflects perceptions and reported practices.\n    *   **Scope of Applicability**: The findings are most applicable to understanding the challenges of integrating AI ethics into agile, resource-constrained, and prototype-focused software development contexts, particularly within sensitive domains like healthcare.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art**: While not introducing new technical algorithms, the paper significantly advances the *empirical understanding* of the socio-technical gap in AI ethics implementation. It provides concrete evidence for the ineffectiveness of current guideline-centric approaches and the practical challenges faced by developers \\cite{vakkuri2020co9}.\n    *   **Potential Impact on Future Research**: The study highlights the urgent need for future research to focus on developing *practical, project-level methods and tools* that can seamlessly integrate AI ethics into existing software engineering processes (e.g., agile methodologies). It calls for a shift from theoretical guidelines to actionable engineering practices and informs the design of more effective AI ethics education and training for practitioners.",
    "intriguing_abstract": "As Artificial Intelligence permeates critical societal functions, the imperative for ethical AI development intensifies. Yet, despite a proliferation of theoretical guidelines, a profound gap persists in their practical integration into software engineering. This paper presents a groundbreaking empirical investigation, a qualitative multiple case study of three startup-like AI development projects in the sensitive healthcare sector. We uncover an alarming reality: a pervasive 'prototype mindset' often defers ethical considerations, leading to a near-complete ignorance of AI ethics as a non-functional requirement.\n\nOur findings reveal that developers narrowly interpret principles like Accountability, Responsibility, and Transparency, focusing on technical or legalistic aspects rather than broader ethical implications. This study provides crucial empirical evidence of the socio-technical disconnect between theoretical AI ethics and real-world agile development practices. It underscores an urgent need for actionable, project-level methods and tools to bridge this divide, fundamentally reshaping how AI ethics are integrated from conception to deployment and ensuring responsible innovation.",
    "keywords": [
      "AI ethics",
      "software development",
      "agile environments",
      "empirical qualitative case study",
      "state of practice",
      "ethical considerations (ignorance of)",
      "Accountability Responsibility Transparency (ART)",
      "socio-technical gap",
      "practical implementation challenges",
      "biased algorithms",
      "healthcare sector",
      "prototype mindset",
      "project-level methods"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/38819caf3755331f512e25c4fd2adf20077f33d1.pdf",
    "citation_key": "vakkuri2020co9",
    "metadata": {
      "title": "“This is Just a Prototype”: How Ethics Are Ignored in Software Startup-Like Environments",
      "authors": [
        "Ville Vakkuri",
        "Kai-Kristian Kemell",
        "Marianna Jantunen",
        "P. Abrahamsson"
      ],
      "published_date": "2020",
      "abstract": "Artificial Intelligence (AI) solutions are becoming increasingly common in software development endeavors, and consequently exert a growing societal influence as well. Due to their unique nature, AI based systems influence a wide range of stakeholders with or without their consent, and thus the development of these systems necessitates a higher degree of ethical consideration than is currently carried out in most cases. Various practical examples of AI failures have also highlighted this need. However, there is only limited research on methods and tools for implementing AI ethics in software development, and we currently have little knowledge of the state of practice. In this study, we explore the state of the art in startup-like environments where majority of the AI software today gets developed. Based on a multiple case study, we discuss the current state of practice and highlight issues. The cases underline the complete ignorance of ethical consideration in AI endeavors. We also outline existing good practices that can already support the implementation of AI ethics, such as documentation and error handling.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/38819caf3755331f512e25c4fd2adf20077f33d1.pdf",
      "venue": "International Conference on Agile Software Development",
      "citationCount": 46,
      "score": 9.200000000000001,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **CITATION**: \\cite{vakkuri2020co9}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Problem**: The paper addresses the critical lack of ethical consideration and implementation in Artificial Intelligence (AI) software development, particularly within agile, startup-like environments.\n    *   **Importance & Challenge**: AI systems are increasingly common, exert significant societal influence, and have demonstrated potential for harmful failures (e.g., biased algorithms). Despite this, there is limited research on practical methods and tools for integrating AI ethics into software development, and the actual state of practice is largely unknown. AI ethics is a new non-functional requirement, but existing theoretical guidelines often fail to translate into practical action.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work acknowledges a history of ethics in software design (e.g., Value Sensitive Design) but highlights that AI introduces unique ethical requirements. It references theoretical discussions on AI ethics values (transparency, accountability, responsibility, fairness) and the proliferation of guidelines from governments, standardization bodies (e.g., ISO), and major tech companies (e.g., IEEE EAD, Google, Microsoft).\n    *   **Limitations of Previous Solutions**: Existing AI ethics research is predominantly philosophical and theoretical, with a scarcity of empirical studies on practical implementation \\cite{vakkuri2020co9}. There are no project-level methods for AI ethics, only narrow technical tools for specific machine learning elements. Crucially, the paper positions itself by noting that prior empirical studies have shown ethical guidelines (like ACM's or IEEE EAD) to be largely ineffective in changing developer practices, as developers lack the norms and methods to translate principles into practice \\cite{vakkuri2020co9}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper does not propose a technical method or algorithm. Instead, its core approach is an *empirical, qualitative multiple case study* to understand the *state of practice* regarding AI ethics in software development \\cite{vakkuri2020co9}.\n    *   **Novelty/Difference**: The innovation lies in its empirical investigation into a largely unexplored area: how AI ethics are *actually* handled (or ignored) in real-world, startup-like development projects, especially when not formally mandated. It employs a structured research framework combining Dignum's ART principles (Accountability, Responsibility, Transparency), Dignum's AI ethics categories (Ethics by/in/for Design), and Abrahamsson's commitment net model (concerns and actions) to systematically analyze developer perspectives and practices \\cite{vakkuri2020co9}.\n\n4.  **Key Technical Contributions**\n    *   **Theoretical Insights/Analysis**: The primary contribution is empirical evidence revealing the *complete ignorance* of ethical considerations in AI development within the studied startup-like environments \\cite{vakkuri2020co9}. It empirically demonstrates the significant gap between theoretical AI ethics discussions and practical software engineering. The study also identifies existing \"good practices\" (e.g., documentation, error handling) that, while not explicitly for ethics, *could* potentially support ethical implementation if consciously applied \\cite{vakkuri2020co9}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: A multiple case study was conducted involving three \"startup-like\" AI software development projects in the healthcare sector in Finland \\cite{vakkuri2020co9}. Data was collected through semi-structured interviews with eight developers and managers across these projects. The cases involved developing a statistical tool for social marginalization, a speech recognition/NLP tool for diagnostics, and an NLP tool for indoor navigation. The healthcare sector was chosen due to its inherent ethical sensitivities and regulatory environment.\n    *   **Key Performance Metrics & Comparison Results**: As a qualitative study, it does not use quantitative performance metrics. Key findings (Primary Empirical Conclusions - PECs) include:\n        *   **Responsibility**: Developers' concerns were primarily practical (project schedule, quality) and detached from broader AI ethical responsibility \\cite{vakkuri2020co9}.\n        *   **Accountability**: Accountability was narrowly perceived as legal liability for data handling, with no formal processes for ethical accountability in AI system decisions \\cite{vakkuri2020co9}.\n        *   **Transparency**: Transparency focused on technical documentation and error handling, not on explaining AI decision-making or data provenance for ethical purposes \\cite{vakkuri2020co9}.\n        *   **Overall**: A pervasive \"prototype\" mindset often served as an excuse to defer ethical considerations, assuming they would be addressed later. Ethical concerns were present but rarely translated into concrete actions, highlighting a lack of commitment.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study's qualitative nature and small sample size (3 cases, 8 respondents) limit the generalizability of findings. It focuses specifically on \"startup-like\" environments, which may have different pressures than larger organizations. The analysis relies on interview data, which reflects perceptions and reported practices.\n    *   **Scope of Applicability**: The findings are most applicable to understanding the challenges of integrating AI ethics into agile, resource-constrained, and prototype-focused software development contexts, particularly within sensitive domains like healthcare.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art**: While not introducing new technical algorithms, the paper significantly advances the *empirical understanding* of the socio-technical gap in AI ethics implementation. It provides concrete evidence for the ineffectiveness of current guideline-centric approaches and the practical challenges faced by developers \\cite{vakkuri2020co9}.\n    *   **Potential Impact on Future Research**: The study highlights the urgent need for future research to focus on developing *practical, project-level methods and tools* that can seamlessly integrate AI ethics into existing software engineering processes (e.g., agile methodologies). It calls for a shift from theoretical guidelines to actionable engineering practices and informs the design of more effective AI ethics education and training for practitioners.",
      "keywords": [
        "AI ethics",
        "software development",
        "agile environments",
        "empirical qualitative case study",
        "state of practice",
        "ethical considerations (ignorance of)",
        "Accountability Responsibility Transparency (ART)",
        "socio-technical gap",
        "practical implementation challenges",
        "biased algorithms",
        "healthcare sector",
        "prototype mindset",
        "project-level methods"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"based on a **multiple case study**, we discuss the current state of practice and highlight issues.\"\n*   the keywords include: \"case study\".\n*   the paper explores \"the state of the art in startup-like environments\" and discusses \"the current state of practice,\" which involves analyzing specific applications and real-world scenarios.\n\nthis aligns perfectly with the definition of a **case_study** paper.\n\n**classification: case_study**"
    },
    "file_name": "38819caf3755331f512e25c4fd2adf20077f33d1.pdf"
  },
  {
    "success": true,
    "doc_id": "e63a3e3579fd1a7937a4a5a8dab61ae2",
    "summary": "© Annals of Translational Medicine. All rights reserved. Ann Transl Med 2022 | https://dx.doi.org/10.21037/atm-22-4203 The goal of precision medicine is to provide tailored therapy to each patient with considering therapeutic benefits and risks. Strides toward this goal have been made by harnessing the benefits of big data, the development of mathematical and data-based computational models, and the use of artificial intelligence (AI) and machine learning (ML) algorithms (1-3). The currently available mathematical models lack fidelity, are unable to represent changes in realtime, and are far from being the optimal tools to provide robust predictive enrichment that can be of use in clinical medicine. In their article, Liu et al. (4) performed an exhaustive bibliometric analysis of the currently available applications, specifically in the arena of individualized diagnosis and treatment of the critically ill patients. There has been an increasing number of articles published over the past decade, however, the clinical relevance and real-world application remains debatable. To circumvent these issues, the construction of digital twin models based on research data and physiological properties has been proposed.",
    "intriguing_abstract": "© Annals of Translational Medicine. All rights reserved. Ann Transl Med 2022 | https://dx.doi.org/10.21037/atm-22-4203 The goal of precision medicine is to provide tailored therapy to each patient with considering therapeutic benefits and risks. Strides toward this goal have been made by harnessing the benefits of big data, the development of mathematical and data-based computational models, and the use of artificial intelligence (AI) and machine learning (ML) algorithms (1-3). The currently available mathematical models lack fidelity, are unable to represent changes in realtime, and are far from being the optimal tools to provide robust predictive enrichment that can be of use in clinical medicine. In their article, Liu et al. (4) performed an exhaustive bibliometric analysis of the currently available applications, specifically in the arena of individualized diagnosis and treatment of the critically ill patients. There has been an increasing number of articles published over the past decade, however, the clinical relevance and real-world application remains debatable. To circumvent these issues, the construction of digital twin models based on research data and physiological properties has been proposed.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b4f96bddb1bf45ab2fbc271ecaace0c50235f1e3.pdf",
    "citation_key": "lal2022o1u",
    "metadata": {
      "title": "Regulatory oversight and ethical concerns surrounding software as medical device (SaMD) and digital twin technology in healthcare",
      "authors": [
        "Amos Lal",
        "Johnny Dang",
        "C. Nabzdyk",
        "O. Gajic",
        "V. Herasevich"
      ],
      "published_date": "2022",
      "abstract": "© Annals of Translational Medicine. All rights reserved. Ann Transl Med 2022 | https://dx.doi.org/10.21037/atm-22-4203 The goal of precision medicine is to provide tailored therapy to each patient with considering therapeutic benefits and risks. Strides toward this goal have been made by harnessing the benefits of big data, the development of mathematical and data-based computational models, and the use of artificial intelligence (AI) and machine learning (ML) algorithms (1-3). The currently available mathematical models lack fidelity, are unable to represent changes in realtime, and are far from being the optimal tools to provide robust predictive enrichment that can be of use in clinical medicine. In their article, Liu et al. (4) performed an exhaustive bibliometric analysis of the currently available applications, specifically in the arena of individualized diagnosis and treatment of the critically ill patients. There has been an increasing number of articles published over the past decade, however, the clinical relevance and real-world application remains debatable. To circumvent these issues, the construction of digital twin models based on research data and physiological properties has been proposed.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b4f96bddb1bf45ab2fbc271ecaace0c50235f1e3.pdf",
      "venue": "Annals of Translational Medicine",
      "citationCount": 27,
      "score": 9.0,
      "summary": "© Annals of Translational Medicine. All rights reserved. Ann Transl Med 2022 | https://dx.doi.org/10.21037/atm-22-4203 The goal of precision medicine is to provide tailored therapy to each patient with considering therapeutic benefits and risks. Strides toward this goal have been made by harnessing the benefits of big data, the development of mathematical and data-based computational models, and the use of artificial intelligence (AI) and machine learning (ML) algorithms (1-3). The currently available mathematical models lack fidelity, are unable to represent changes in realtime, and are far from being the optimal tools to provide robust predictive enrichment that can be of use in clinical medicine. In their article, Liu et al. (4) performed an exhaustive bibliometric analysis of the currently available applications, specifically in the arena of individualized diagnosis and treatment of the critically ill patients. There has been an increasing number of articles published over the past decade, however, the clinical relevance and real-world application remains debatable. To circumvent these issues, the construction of digital twin models based on research data and physiological properties has been proposed.",
      "keywords": []
    },
    "file_name": "b4f96bddb1bf45ab2fbc271ecaace0c50235f1e3.pdf"
  },
  {
    "success": true,
    "doc_id": "c3e7b093203fb533e8c9f4428735c477",
    "summary": "Several factors are motivating the development of preventive, personalized, connected, virtual, and ubiquitous healthcare services. These factors include declining public health, increase in chronic diseases, an ageing population, rising healthcare costs, the need to bring intelligence near the user for privacy, security, performance, and costs reasons, as well as COVID-19. Motivated by these drivers, this paper proposes, implements, and evaluates a reference architecture called Imtidad that provides Distributed Artificial Intelligence (AI) as a Service (DAIaaS) over cloud, fog, and edge using a service catalog case study containing 22 AI skin disease diagnosis services. These services belong to four service classes that are distinguished based on software platforms (containerized gRPC, gRPC, Android, and Android Nearby) and are executed on a range of hardware platforms (Google Cloud, HP Pavilion Laptop, NVIDIA Jetson nano, Raspberry Pi Model B, Samsung Galaxy S9, and Samsung Galaxy Note 4) and four network types (Fiber, Cellular, Wi-Fi, and Bluetooth). The AI models for the diagnosis include two standard Deep Neural Networks and two Tiny AI deep models to enable their execution at the edge, trained and tested using 10,015 real-life dermatoscopic images. The services are evaluated using several benchmarks including model service value, response time, energy consumption, and network transfer time. A DL service on a local smartphone provides the best service in terms of both energy and speed, followed by a Raspberry Pi edge device and a laptop in fog. The services are designed to enable different use cases, such as patient diagnosis at home or sending diagnosis requests to travelling medical professionals through a fog device or cloud. This is the pioneering work that provides a reference architecture and such a detailed implementation and treatment of DAIaaS services, and is also expected to have an extensive impact on developing smart distributed service infrastructures for healthcare and other sectors.",
    "intriguing_abstract": "Several factors are motivating the development of preventive, personalized, connected, virtual, and ubiquitous healthcare services. These factors include declining public health, increase in chronic diseases, an ageing population, rising healthcare costs, the need to bring intelligence near the user for privacy, security, performance, and costs reasons, as well as COVID-19. Motivated by these drivers, this paper proposes, implements, and evaluates a reference architecture called Imtidad that provides Distributed Artificial Intelligence (AI) as a Service (DAIaaS) over cloud, fog, and edge using a service catalog case study containing 22 AI skin disease diagnosis services. These services belong to four service classes that are distinguished based on software platforms (containerized gRPC, gRPC, Android, and Android Nearby) and are executed on a range of hardware platforms (Google Cloud, HP Pavilion Laptop, NVIDIA Jetson nano, Raspberry Pi Model B, Samsung Galaxy S9, and Samsung Galaxy Note 4) and four network types (Fiber, Cellular, Wi-Fi, and Bluetooth). The AI models for the diagnosis include two standard Deep Neural Networks and two Tiny AI deep models to enable their execution at the edge, trained and tested using 10,015 real-life dermatoscopic images. The services are evaluated using several benchmarks including model service value, response time, energy consumption, and network transfer time. A DL service on a local smartphone provides the best service in terms of both energy and speed, followed by a Raspberry Pi edge device and a laptop in fog. The services are designed to enable different use cases, such as patient diagnosis at home or sending diagnosis requests to travelling medical professionals through a fog device or cloud. This is the pioneering work that provides a reference architecture and such a detailed implementation and treatment of DAIaaS services, and is also expected to have an extensive impact on developing smart distributed service infrastructures for healthcare and other sectors.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/157600e0348b99bbc4187b95fd0c438a2189a841.pdf",
    "citation_key": "janbi2022e2i",
    "metadata": {
      "title": "Imtidad: A Reference Architecture and a Case Study on Developing Distributed AI Services for Skin Disease Diagnosis over Cloud, Fog and Edge",
      "authors": [
        "N. Janbi",
        "Rashid Mehmood",
        "Iyad A. Katib",
        "A. Albeshri",
        "J. Corchado",
        "Tan Yigitcanlar"
      ],
      "published_date": "2022",
      "abstract": "Several factors are motivating the development of preventive, personalized, connected, virtual, and ubiquitous healthcare services. These factors include declining public health, increase in chronic diseases, an ageing population, rising healthcare costs, the need to bring intelligence near the user for privacy, security, performance, and costs reasons, as well as COVID-19. Motivated by these drivers, this paper proposes, implements, and evaluates a reference architecture called Imtidad that provides Distributed Artificial Intelligence (AI) as a Service (DAIaaS) over cloud, fog, and edge using a service catalog case study containing 22 AI skin disease diagnosis services. These services belong to four service classes that are distinguished based on software platforms (containerized gRPC, gRPC, Android, and Android Nearby) and are executed on a range of hardware platforms (Google Cloud, HP Pavilion Laptop, NVIDIA Jetson nano, Raspberry Pi Model B, Samsung Galaxy S9, and Samsung Galaxy Note 4) and four network types (Fiber, Cellular, Wi-Fi, and Bluetooth). The AI models for the diagnosis include two standard Deep Neural Networks and two Tiny AI deep models to enable their execution at the edge, trained and tested using 10,015 real-life dermatoscopic images. The services are evaluated using several benchmarks including model service value, response time, energy consumption, and network transfer time. A DL service on a local smartphone provides the best service in terms of both energy and speed, followed by a Raspberry Pi edge device and a laptop in fog. The services are designed to enable different use cases, such as patient diagnosis at home or sending diagnosis requests to travelling medical professionals through a fog device or cloud. This is the pioneering work that provides a reference architecture and such a detailed implementation and treatment of DAIaaS services, and is also expected to have an extensive impact on developing smart distributed service infrastructures for healthcare and other sectors.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/157600e0348b99bbc4187b95fd0c438a2189a841.pdf",
      "venue": "Italian National Conference on Sensors",
      "citationCount": 27,
      "score": 9.0,
      "summary": "Several factors are motivating the development of preventive, personalized, connected, virtual, and ubiquitous healthcare services. These factors include declining public health, increase in chronic diseases, an ageing population, rising healthcare costs, the need to bring intelligence near the user for privacy, security, performance, and costs reasons, as well as COVID-19. Motivated by these drivers, this paper proposes, implements, and evaluates a reference architecture called Imtidad that provides Distributed Artificial Intelligence (AI) as a Service (DAIaaS) over cloud, fog, and edge using a service catalog case study containing 22 AI skin disease diagnosis services. These services belong to four service classes that are distinguished based on software platforms (containerized gRPC, gRPC, Android, and Android Nearby) and are executed on a range of hardware platforms (Google Cloud, HP Pavilion Laptop, NVIDIA Jetson nano, Raspberry Pi Model B, Samsung Galaxy S9, and Samsung Galaxy Note 4) and four network types (Fiber, Cellular, Wi-Fi, and Bluetooth). The AI models for the diagnosis include two standard Deep Neural Networks and two Tiny AI deep models to enable their execution at the edge, trained and tested using 10,015 real-life dermatoscopic images. The services are evaluated using several benchmarks including model service value, response time, energy consumption, and network transfer time. A DL service on a local smartphone provides the best service in terms of both energy and speed, followed by a Raspberry Pi edge device and a laptop in fog. The services are designed to enable different use cases, such as patient diagnosis at home or sending diagnosis requests to travelling medical professionals through a fog device or cloud. This is the pioneering work that provides a reference architecture and such a detailed implementation and treatment of DAIaaS services, and is also expected to have an extensive impact on developing smart distributed service infrastructures for healthcare and other sectors.",
      "keywords": []
    },
    "file_name": "157600e0348b99bbc4187b95fd0c438a2189a841.pdf"
  },
  {
    "success": true,
    "doc_id": "bd5bad2d26da7d9e82a4ac8c72d7a370",
    "summary": "The recent advances and availability of computer hardware, software tools, and massive digital data archives have enabled the rapid development of artificial intelligence (AI) applications. Concerns over whether AI tools can \"communicate\" decisions to radiologists and primary care physicians is of particular importance because automated clinical decisions can substantially impact patient outcome. A challenge facing the clinical implementation of AI stems from the potential lack of trust clinicians have in these predictive models. This review will expand on the existing literature on interpretability methods for deep learning and review the state-of-the-art methods for predictive uncertainty estimation for computer-assisted segmentation tasks. Last, we discuss how uncertainty can improve predictive performance and model interpretability and can act as a tool to help foster trust. Keywords: Segmentation, Quantification, Ethics, Bayesian Network (BN) © RSNA, 2021.",
    "intriguing_abstract": "The recent advances and availability of computer hardware, software tools, and massive digital data archives have enabled the rapid development of artificial intelligence (AI) applications. Concerns over whether AI tools can \"communicate\" decisions to radiologists and primary care physicians is of particular importance because automated clinical decisions can substantially impact patient outcome. A challenge facing the clinical implementation of AI stems from the potential lack of trust clinicians have in these predictive models. This review will expand on the existing literature on interpretability methods for deep learning and review the state-of-the-art methods for predictive uncertainty estimation for computer-assisted segmentation tasks. Last, we discuss how uncertainty can improve predictive performance and model interpretability and can act as a tool to help foster trust. Keywords: Segmentation, Quantification, Ethics, Bayesian Network (BN) © RSNA, 2021.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/4ce525f658f281a9a1d196b4a8e1faf02796bf58.pdf",
    "citation_key": "mccrindle2021ie2",
    "metadata": {
      "title": "A Radiology-focused Review of Predictive Uncertainty for AI Interpretability in Computer-assisted Segmentation.",
      "authors": [
        "B. McCrindle",
        "K. Zukotynski",
        "Thomas E. Doyle",
        "M. Noseworthy"
      ],
      "published_date": "2021",
      "abstract": "The recent advances and availability of computer hardware, software tools, and massive digital data archives have enabled the rapid development of artificial intelligence (AI) applications. Concerns over whether AI tools can \"communicate\" decisions to radiologists and primary care physicians is of particular importance because automated clinical decisions can substantially impact patient outcome. A challenge facing the clinical implementation of AI stems from the potential lack of trust clinicians have in these predictive models. This review will expand on the existing literature on interpretability methods for deep learning and review the state-of-the-art methods for predictive uncertainty estimation for computer-assisted segmentation tasks. Last, we discuss how uncertainty can improve predictive performance and model interpretability and can act as a tool to help foster trust. Keywords: Segmentation, Quantification, Ethics, Bayesian Network (BN) © RSNA, 2021.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/4ce525f658f281a9a1d196b4a8e1faf02796bf58.pdf",
      "venue": "Radiology: Artificial Intelligence",
      "citationCount": 36,
      "score": 9.0,
      "summary": "The recent advances and availability of computer hardware, software tools, and massive digital data archives have enabled the rapid development of artificial intelligence (AI) applications. Concerns over whether AI tools can \"communicate\" decisions to radiologists and primary care physicians is of particular importance because automated clinical decisions can substantially impact patient outcome. A challenge facing the clinical implementation of AI stems from the potential lack of trust clinicians have in these predictive models. This review will expand on the existing literature on interpretability methods for deep learning and review the state-of-the-art methods for predictive uncertainty estimation for computer-assisted segmentation tasks. Last, we discuss how uncertainty can improve predictive performance and model interpretability and can act as a tool to help foster trust. Keywords: Segmentation, Quantification, Ethics, Bayesian Network (BN) © RSNA, 2021.",
      "keywords": []
    },
    "file_name": "4ce525f658f281a9a1d196b4a8e1faf02796bf58.pdf"
  },
  {
    "success": true,
    "doc_id": "dae2f9e0436e6cd0a7b4caa0166eedac",
    "summary": "Artificial intelligence (AI) and the use of machine learning (ML) and deep learning (DL) technologies are becoming increasingly popular in companies. These technologies enable companies to leverage big quantities of data to improve system performance and accelerate business development. However, despite the appeal of ML/DL, there is a lack of systematic and structured methods and processes to help data scientists and other company roles and functions to develop, deploy and evolve models. In this paper, based on multi‐case study research in six companies, we explore practices and challenges practitioners experience in developing ML/DL models as part of large software‐intensive embedded systems. Based on our empirical findings, we derive a conceptual framework in which we identify three high‐level activities that companies perform in parallel with the development, deployment and evolution of models. Within this framework, we outline activities, iterations and triggers that optimize model design as well as roles and company functions. In this way, we provide practitioners with a blueprint for effectively integrating ML/DL model development into the business to achieve better results than other (algorithmic) approaches. In addition, we show how this framework helps companies solve the challenges we have identified and discuss checkpoints for terminating the business case.",
    "intriguing_abstract": "Artificial intelligence (AI) and the use of machine learning (ML) and deep learning (DL) technologies are becoming increasingly popular in companies. These technologies enable companies to leverage big quantities of data to improve system performance and accelerate business development. However, despite the appeal of ML/DL, there is a lack of systematic and structured methods and processes to help data scientists and other company roles and functions to develop, deploy and evolve models. In this paper, based on multi‐case study research in six companies, we explore practices and challenges practitioners experience in developing ML/DL models as part of large software‐intensive embedded systems. Based on our empirical findings, we derive a conceptual framework in which we identify three high‐level activities that companies perform in parallel with the development, deployment and evolution of models. Within this framework, we outline activities, iterations and triggers that optimize model design as well as roles and company functions. In this way, we provide practitioners with a blueprint for effectively integrating ML/DL model development into the business to achieve better results than other (algorithmic) approaches. In addition, we show how this framework helps companies solve the challenges we have identified and discuss checkpoints for terminating the business case.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d16ed45e038674d1597e6a3e9b7fa1e9f57c8457.pdf",
    "citation_key": "john2022i2y",
    "metadata": {
      "title": "Towards an AI‐driven business development framework: A multi‐case study",
      "authors": [
        "Meenu Mary John",
        "H. H. Olsson",
        "Jan Bosch"
      ],
      "published_date": "2022",
      "abstract": "Artificial intelligence (AI) and the use of machine learning (ML) and deep learning (DL) technologies are becoming increasingly popular in companies. These technologies enable companies to leverage big quantities of data to improve system performance and accelerate business development. However, despite the appeal of ML/DL, there is a lack of systematic and structured methods and processes to help data scientists and other company roles and functions to develop, deploy and evolve models. In this paper, based on multi‐case study research in six companies, we explore practices and challenges practitioners experience in developing ML/DL models as part of large software‐intensive embedded systems. Based on our empirical findings, we derive a conceptual framework in which we identify three high‐level activities that companies perform in parallel with the development, deployment and evolution of models. Within this framework, we outline activities, iterations and triggers that optimize model design as well as roles and company functions. In this way, we provide practitioners with a blueprint for effectively integrating ML/DL model development into the business to achieve better results than other (algorithmic) approaches. In addition, we show how this framework helps companies solve the challenges we have identified and discuss checkpoints for terminating the business case.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d16ed45e038674d1597e6a3e9b7fa1e9f57c8457.pdf",
      "venue": "J. Softw. Evol. Process.",
      "citationCount": 26,
      "score": 8.666666666666666,
      "summary": "Artificial intelligence (AI) and the use of machine learning (ML) and deep learning (DL) technologies are becoming increasingly popular in companies. These technologies enable companies to leverage big quantities of data to improve system performance and accelerate business development. However, despite the appeal of ML/DL, there is a lack of systematic and structured methods and processes to help data scientists and other company roles and functions to develop, deploy and evolve models. In this paper, based on multi‐case study research in six companies, we explore practices and challenges practitioners experience in developing ML/DL models as part of large software‐intensive embedded systems. Based on our empirical findings, we derive a conceptual framework in which we identify three high‐level activities that companies perform in parallel with the development, deployment and evolution of models. Within this framework, we outline activities, iterations and triggers that optimize model design as well as roles and company functions. In this way, we provide practitioners with a blueprint for effectively integrating ML/DL model development into the business to achieve better results than other (algorithmic) approaches. In addition, we show how this framework helps companies solve the challenges we have identified and discuss checkpoints for terminating the business case.",
      "keywords": []
    },
    "file_name": "d16ed45e038674d1597e6a3e9b7fa1e9f57c8457.pdf"
  },
  {
    "success": true,
    "doc_id": "a161e34d819fe72e30d976a5fa7d1649",
    "summary": "Mammographic breast density (BD) is commonly visually assessed using the Breast Imaging Reporting and Data System (BI-RADS) four-category scale. To overcome inter- and intraobserver variability of visual assessment, the authors retrospectively developed and externally validated a software for BD classification based on convolutional neural networks from mammograms obtained between 2017 and 2020. The tool was trained using the majority BD category determined by seven board-certified radiologists who independently visually assessed 760 mediolateral oblique (MLO) images in 380 women (mean age, 57 years ± 6 [SD]) from center 1; this process mimicked training from a consensus of several human readers. External validation of the model was performed by the three radiologists whose BD assessment was closest to the majority (consensus) of the initial seven on a dataset of 384 MLO images in 197 women (mean age, 56 years ± 13) obtained from center 2. The model achieved an accuracy of 89.3% in distinguishing BI-RADS a or b (nondense breasts) versus c or d (dense breasts) categories, with an agreement of 90.4% (178 of 197 mammograms) and a reliability of 0.807 (Cohen κ) compared with the mode of the three readers. This study demonstrates accuracy and reliability of a fully automated software for BD classification. Keywords: Mammography, Breast, Convolutional Neural Network (CNN), Deep Learning Algorithms, Machine Learning Algorithms Supplemental material is available for this article. © RSNA, 2022.",
    "intriguing_abstract": "Mammographic breast density (BD) is commonly visually assessed using the Breast Imaging Reporting and Data System (BI-RADS) four-category scale. To overcome inter- and intraobserver variability of visual assessment, the authors retrospectively developed and externally validated a software for BD classification based on convolutional neural networks from mammograms obtained between 2017 and 2020. The tool was trained using the majority BD category determined by seven board-certified radiologists who independently visually assessed 760 mediolateral oblique (MLO) images in 380 women (mean age, 57 years ± 6 [SD]) from center 1; this process mimicked training from a consensus of several human readers. External validation of the model was performed by the three radiologists whose BD assessment was closest to the majority (consensus) of the initial seven on a dataset of 384 MLO images in 197 women (mean age, 56 years ± 13) obtained from center 2. The model achieved an accuracy of 89.3% in distinguishing BI-RADS a or b (nondense breasts) versus c or d (dense breasts) categories, with an agreement of 90.4% (178 of 197 mammograms) and a reliability of 0.807 (Cohen κ) compared with the mode of the three readers. This study demonstrates accuracy and reliability of a fully automated software for BD classification. Keywords: Mammography, Breast, Convolutional Neural Network (CNN), Deep Learning Algorithms, Machine Learning Algorithms Supplemental material is available for this article. © RSNA, 2022.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b94d8ca82a99e0effc7895ec100f6b9d011d4937.pdf",
    "citation_key": "magni2022a4o",
    "metadata": {
      "title": "Development and Validation of an AI-driven Mammographic Breast Density Classification Tool Based on Radiologist Consensus.",
      "authors": [
        "Veronica Magni",
        "M. Interlenghi",
        "A. Cozzi",
        "Marco Alì",
        "C. Salvatore",
        "Alcide A Azzena",
        "D. Capra",
        "S. Carriero",
        "G. Della Pepa",
        "Deborah Fazzini",
        "Giuseppe Granata",
        "C. Monti",
        "Giulia Muscogiuri",
        "Giuseppe Pellegrino",
        "S. Schiaffino",
        "I. Castiglioni",
        "S. Papa",
        "F. Sardanelli"
      ],
      "published_date": "2022",
      "abstract": "Mammographic breast density (BD) is commonly visually assessed using the Breast Imaging Reporting and Data System (BI-RADS) four-category scale. To overcome inter- and intraobserver variability of visual assessment, the authors retrospectively developed and externally validated a software for BD classification based on convolutional neural networks from mammograms obtained between 2017 and 2020. The tool was trained using the majority BD category determined by seven board-certified radiologists who independently visually assessed 760 mediolateral oblique (MLO) images in 380 women (mean age, 57 years ± 6 [SD]) from center 1; this process mimicked training from a consensus of several human readers. External validation of the model was performed by the three radiologists whose BD assessment was closest to the majority (consensus) of the initial seven on a dataset of 384 MLO images in 197 women (mean age, 56 years ± 13) obtained from center 2. The model achieved an accuracy of 89.3% in distinguishing BI-RADS a or b (nondense breasts) versus c or d (dense breasts) categories, with an agreement of 90.4% (178 of 197 mammograms) and a reliability of 0.807 (Cohen κ) compared with the mode of the three readers. This study demonstrates accuracy and reliability of a fully automated software for BD classification. Keywords: Mammography, Breast, Convolutional Neural Network (CNN), Deep Learning Algorithms, Machine Learning Algorithms Supplemental material is available for this article. © RSNA, 2022.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b94d8ca82a99e0effc7895ec100f6b9d011d4937.pdf",
      "venue": "Radiology: Artificial Intelligence",
      "citationCount": 25,
      "score": 8.333333333333332,
      "summary": "Mammographic breast density (BD) is commonly visually assessed using the Breast Imaging Reporting and Data System (BI-RADS) four-category scale. To overcome inter- and intraobserver variability of visual assessment, the authors retrospectively developed and externally validated a software for BD classification based on convolutional neural networks from mammograms obtained between 2017 and 2020. The tool was trained using the majority BD category determined by seven board-certified radiologists who independently visually assessed 760 mediolateral oblique (MLO) images in 380 women (mean age, 57 years ± 6 [SD]) from center 1; this process mimicked training from a consensus of several human readers. External validation of the model was performed by the three radiologists whose BD assessment was closest to the majority (consensus) of the initial seven on a dataset of 384 MLO images in 197 women (mean age, 56 years ± 13) obtained from center 2. The model achieved an accuracy of 89.3% in distinguishing BI-RADS a or b (nondense breasts) versus c or d (dense breasts) categories, with an agreement of 90.4% (178 of 197 mammograms) and a reliability of 0.807 (Cohen κ) compared with the mode of the three readers. This study demonstrates accuracy and reliability of a fully automated software for BD classification. Keywords: Mammography, Breast, Convolutional Neural Network (CNN), Deep Learning Algorithms, Machine Learning Algorithms Supplemental material is available for this article. © RSNA, 2022.",
      "keywords": []
    },
    "file_name": "b94d8ca82a99e0effc7895ec100f6b9d011d4937.pdf"
  },
  {
    "success": true,
    "doc_id": "536d9884551a6ee2e4594e056ced1f1c",
    "summary": "We aimed to develop a new artificial intelligence (AI)-based method for evaluating endoscopic ultrasound-guided fine-needle biopsy (EUS-FNB) specimens in pancreatic diseases using deep learning and contrastive learning. We analysed a total of 173 specimens from 96 patients who underwent EUS-FNB with a 22 G Franseen needle for pancreatic diseases. In the initial study, the deep learning method based on stereomicroscopic images of 98 EUS-FNB specimens from 63 patients showed an accuracy of 71.8% for predicting the histological diagnosis, which was lower than that of macroscopic on-site evaluation (MOSE) performed by EUS experts (81.6%). Then, we used image analysis software to mark the core tissues in the photomicrographs of EUS-FNB specimens after haematoxylin and eosin staining and verified whether the diagnostic performance could be improved by applying contrastive learning for the features of the stereomicroscopic images and stained images. The sensitivity, specificity, and accuracy of MOSE were 88.97%, 53.5%, and 83.24%, respectively, while those of the AI-based diagnostic method using contrastive learning were 90.34%, 53.5%, and 84.39%, respectively. The AI-based evaluation method using contrastive learning was comparable to MOSE performed by EUS experts and can be a novel objective evaluation method for EUS-FNB.",
    "intriguing_abstract": "We aimed to develop a new artificial intelligence (AI)-based method for evaluating endoscopic ultrasound-guided fine-needle biopsy (EUS-FNB) specimens in pancreatic diseases using deep learning and contrastive learning. We analysed a total of 173 specimens from 96 patients who underwent EUS-FNB with a 22 G Franseen needle for pancreatic diseases. In the initial study, the deep learning method based on stereomicroscopic images of 98 EUS-FNB specimens from 63 patients showed an accuracy of 71.8% for predicting the histological diagnosis, which was lower than that of macroscopic on-site evaluation (MOSE) performed by EUS experts (81.6%). Then, we used image analysis software to mark the core tissues in the photomicrographs of EUS-FNB specimens after haematoxylin and eosin staining and verified whether the diagnostic performance could be improved by applying contrastive learning for the features of the stereomicroscopic images and stained images. The sensitivity, specificity, and accuracy of MOSE were 88.97%, 53.5%, and 83.24%, respectively, while those of the AI-based diagnostic method using contrastive learning were 90.34%, 53.5%, and 84.39%, respectively. The AI-based evaluation method using contrastive learning was comparable to MOSE performed by EUS experts and can be a novel objective evaluation method for EUS-FNB.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/db8c10f46f8a7022663d70f725e7502ce239573a.pdf",
    "citation_key": "ishikawa2022gn3",
    "metadata": {
      "title": "Development of a Novel Evaluation Method for Endoscopic Ultrasound-Guided Fine-Needle Biopsy in Pancreatic Diseases Using Artificial Intelligence",
      "authors": [
        "T. Ishikawa",
        "Masato Hayakawa",
        "Hirotaka Suzuki",
        "E. Ohno",
        "Yasuyuki Mizutani",
        "T. Iida",
        "M. Fujishiro",
        "H. Kawashima",
        "K. Hotta"
      ],
      "published_date": "2022",
      "abstract": "We aimed to develop a new artificial intelligence (AI)-based method for evaluating endoscopic ultrasound-guided fine-needle biopsy (EUS-FNB) specimens in pancreatic diseases using deep learning and contrastive learning. We analysed a total of 173 specimens from 96 patients who underwent EUS-FNB with a 22 G Franseen needle for pancreatic diseases. In the initial study, the deep learning method based on stereomicroscopic images of 98 EUS-FNB specimens from 63 patients showed an accuracy of 71.8% for predicting the histological diagnosis, which was lower than that of macroscopic on-site evaluation (MOSE) performed by EUS experts (81.6%). Then, we used image analysis software to mark the core tissues in the photomicrographs of EUS-FNB specimens after haematoxylin and eosin staining and verified whether the diagnostic performance could be improved by applying contrastive learning for the features of the stereomicroscopic images and stained images. The sensitivity, specificity, and accuracy of MOSE were 88.97%, 53.5%, and 83.24%, respectively, while those of the AI-based diagnostic method using contrastive learning were 90.34%, 53.5%, and 84.39%, respectively. The AI-based evaluation method using contrastive learning was comparable to MOSE performed by EUS experts and can be a novel objective evaluation method for EUS-FNB.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/db8c10f46f8a7022663d70f725e7502ce239573a.pdf",
      "venue": "Diagnostics",
      "citationCount": 25,
      "score": 8.333333333333332,
      "summary": "We aimed to develop a new artificial intelligence (AI)-based method for evaluating endoscopic ultrasound-guided fine-needle biopsy (EUS-FNB) specimens in pancreatic diseases using deep learning and contrastive learning. We analysed a total of 173 specimens from 96 patients who underwent EUS-FNB with a 22 G Franseen needle for pancreatic diseases. In the initial study, the deep learning method based on stereomicroscopic images of 98 EUS-FNB specimens from 63 patients showed an accuracy of 71.8% for predicting the histological diagnosis, which was lower than that of macroscopic on-site evaluation (MOSE) performed by EUS experts (81.6%). Then, we used image analysis software to mark the core tissues in the photomicrographs of EUS-FNB specimens after haematoxylin and eosin staining and verified whether the diagnostic performance could be improved by applying contrastive learning for the features of the stereomicroscopic images and stained images. The sensitivity, specificity, and accuracy of MOSE were 88.97%, 53.5%, and 83.24%, respectively, while those of the AI-based diagnostic method using contrastive learning were 90.34%, 53.5%, and 84.39%, respectively. The AI-based evaluation method using contrastive learning was comparable to MOSE performed by EUS experts and can be a novel objective evaluation method for EUS-FNB.",
      "keywords": []
    },
    "file_name": "db8c10f46f8a7022663d70f725e7502ce239573a.pdf"
  },
  {
    "success": true,
    "doc_id": "2c4f388b479fc2b4dcdc4085916fbe3c",
    "summary": "Field Programmable Gate Array (FPGA) accelerators have been widely adopted for artificial intelligence (AI) applications on edge devices (Edge-AI) utilizing Deep Neural Networks (DNN) architectures. FPGAs have gained their reputation due to the greater energy efficiency and high parallelism than microcontrollers (MCU) and graphical processing units (GPU), while they are easier to develop and more reconfigurable than the Application Specific Integrated Circuit (ASIC). The development and building of AI applications on resource constraint devices such as FPGAs remains a challenge, however, due to the co-design approach, which requires a valuable expertise in low-level hardware design and in software development. This paper explores the efficacy and the dynamic deployment of hardware accelerated applications on the Kria KV260 development platform based on the Xilinx Kria K26 system-on-module (SoM), which includes a Zynq multiprocessor system-on-chip (MPSoC). The platform supports the Python-based PYNQ framework and maintains a high level of versatility with the support of custom bitstreams (overlays). The demonstration proved the reconfigurabibilty and the overall ease of implementation with low-footprint machine learning (ML) algorithms.",
    "intriguing_abstract": "Field Programmable Gate Array (FPGA) accelerators have been widely adopted for artificial intelligence (AI) applications on edge devices (Edge-AI) utilizing Deep Neural Networks (DNN) architectures. FPGAs have gained their reputation due to the greater energy efficiency and high parallelism than microcontrollers (MCU) and graphical processing units (GPU), while they are easier to develop and more reconfigurable than the Application Specific Integrated Circuit (ASIC). The development and building of AI applications on resource constraint devices such as FPGAs remains a challenge, however, due to the co-design approach, which requires a valuable expertise in low-level hardware design and in software development. This paper explores the efficacy and the dynamic deployment of hardware accelerated applications on the Kria KV260 development platform based on the Xilinx Kria K26 system-on-module (SoM), which includes a Zynq multiprocessor system-on-chip (MPSoC). The platform supports the Python-based PYNQ framework and maintains a high level of versatility with the support of custom bitstreams (overlays). The demonstration proved the reconfigurabibilty and the overall ease of implementation with low-footprint machine learning (ML) algorithms.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/550101e2b41ffadf2990402861758c9234646126.pdf",
    "citation_key": "kalapothas2022nd7",
    "metadata": {
      "title": "Efficient Edge-AI Application Deployment for FPGAs",
      "authors": [
        "Stavros Kalapothas",
        "Georgios Flamis",
        "P. Kitsos"
      ],
      "published_date": "2022",
      "abstract": "Field Programmable Gate Array (FPGA) accelerators have been widely adopted for artificial intelligence (AI) applications on edge devices (Edge-AI) utilizing Deep Neural Networks (DNN) architectures. FPGAs have gained their reputation due to the greater energy efficiency and high parallelism than microcontrollers (MCU) and graphical processing units (GPU), while they are easier to develop and more reconfigurable than the Application Specific Integrated Circuit (ASIC). The development and building of AI applications on resource constraint devices such as FPGAs remains a challenge, however, due to the co-design approach, which requires a valuable expertise in low-level hardware design and in software development. This paper explores the efficacy and the dynamic deployment of hardware accelerated applications on the Kria KV260 development platform based on the Xilinx Kria K26 system-on-module (SoM), which includes a Zynq multiprocessor system-on-chip (MPSoC). The platform supports the Python-based PYNQ framework and maintains a high level of versatility with the support of custom bitstreams (overlays). The demonstration proved the reconfigurabibilty and the overall ease of implementation with low-footprint machine learning (ML) algorithms.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/550101e2b41ffadf2990402861758c9234646126.pdf",
      "venue": "Inf.",
      "citationCount": 24,
      "score": 8.0,
      "summary": "Field Programmable Gate Array (FPGA) accelerators have been widely adopted for artificial intelligence (AI) applications on edge devices (Edge-AI) utilizing Deep Neural Networks (DNN) architectures. FPGAs have gained their reputation due to the greater energy efficiency and high parallelism than microcontrollers (MCU) and graphical processing units (GPU), while they are easier to develop and more reconfigurable than the Application Specific Integrated Circuit (ASIC). The development and building of AI applications on resource constraint devices such as FPGAs remains a challenge, however, due to the co-design approach, which requires a valuable expertise in low-level hardware design and in software development. This paper explores the efficacy and the dynamic deployment of hardware accelerated applications on the Kria KV260 development platform based on the Xilinx Kria K26 system-on-module (SoM), which includes a Zynq multiprocessor system-on-chip (MPSoC). The platform supports the Python-based PYNQ framework and maintains a high level of versatility with the support of custom bitstreams (overlays). The demonstration proved the reconfigurabibilty and the overall ease of implementation with low-footprint machine learning (ML) algorithms.",
      "keywords": []
    },
    "file_name": "550101e2b41ffadf2990402861758c9234646126.pdf"
  },
  {
    "success": true,
    "doc_id": "1bb76d6bc350473e90de48782ab57259",
    "summary": "Artificial Intelligence is the ability to make machines intelligent. The development in AI made machines capable to initiate the simulation of natural intelligence and are able to take decisions where humans do better. Natural Language Processing, Machine Learning are some of the major branches of AI. A Chatbot is an AI software uses Natural Language Processing Techniques to simulate a chat between a system and a user. Natural Language Processing help Chatbots to understand natural language more clearly and generate an intelligent response. Since the introduction of first Chatbot ELIZA in 1966, different versions with variety of technology and approach have been developed. In this paper, we describe the generic work flow of Chatbots and represents their comparison on the basis of technology/approach used with some significant parameters. To make natural language conversation more efficient, a Chatbot must analyze and understand the user input correctly for a relevant response. They are currently being used in various important domains like science, education, health care etc. Chatbots have a potential to improve human interaction with machines.",
    "intriguing_abstract": "Artificial Intelligence is the ability to make machines intelligent. The development in AI made machines capable to initiate the simulation of natural intelligence and are able to take decisions where humans do better. Natural Language Processing, Machine Learning are some of the major branches of AI. A Chatbot is an AI software uses Natural Language Processing Techniques to simulate a chat between a system and a user. Natural Language Processing help Chatbots to understand natural language more clearly and generate an intelligent response. Since the introduction of first Chatbot ELIZA in 1966, different versions with variety of technology and approach have been developed. In this paper, we describe the generic work flow of Chatbots and represents their comparison on the basis of technology/approach used with some significant parameters. To make natural language conversation more efficient, a Chatbot must analyze and understand the user input correctly for a relevant response. They are currently being used in various important domains like science, education, health care etc. Chatbots have a potential to improve human interaction with machines.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/1de6841d9c858a30a3dc4cab8b8b8dec6aa830c9.pdf",
    "citation_key": "singh20206e5",
    "metadata": {
      "title": "Survey of Various AI Chatbots Based on Technology Used",
      "authors": [
        "Siddhant Singh",
        "H. Thakur"
      ],
      "published_date": "2020",
      "abstract": "Artificial Intelligence is the ability to make machines intelligent. The development in AI made machines capable to initiate the simulation of natural intelligence and are able to take decisions where humans do better. Natural Language Processing, Machine Learning are some of the major branches of AI. A Chatbot is an AI software uses Natural Language Processing Techniques to simulate a chat between a system and a user. Natural Language Processing help Chatbots to understand natural language more clearly and generate an intelligent response. Since the introduction of first Chatbot ELIZA in 1966, different versions with variety of technology and approach have been developed. In this paper, we describe the generic work flow of Chatbots and represents their comparison on the basis of technology/approach used with some significant parameters. To make natural language conversation more efficient, a Chatbot must analyze and understand the user input correctly for a relevant response. They are currently being used in various important domains like science, education, health care etc. Chatbots have a potential to improve human interaction with machines.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/1de6841d9c858a30a3dc4cab8b8b8dec6aa830c9.pdf",
      "venue": "2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",
      "citationCount": 40,
      "score": 8.0,
      "summary": "Artificial Intelligence is the ability to make machines intelligent. The development in AI made machines capable to initiate the simulation of natural intelligence and are able to take decisions where humans do better. Natural Language Processing, Machine Learning are some of the major branches of AI. A Chatbot is an AI software uses Natural Language Processing Techniques to simulate a chat between a system and a user. Natural Language Processing help Chatbots to understand natural language more clearly and generate an intelligent response. Since the introduction of first Chatbot ELIZA in 1966, different versions with variety of technology and approach have been developed. In this paper, we describe the generic work flow of Chatbots and represents their comparison on the basis of technology/approach used with some significant parameters. To make natural language conversation more efficient, a Chatbot must analyze and understand the user input correctly for a relevant response. They are currently being used in various important domains like science, education, health care etc. Chatbots have a potential to improve human interaction with machines.",
      "keywords": []
    },
    "file_name": "1de6841d9c858a30a3dc4cab8b8b8dec6aa830c9.pdf"
  },
  {
    "success": true,
    "doc_id": "fc22abbba75b3d7448738f0827f17758",
    "summary": "Technological and material issues in 3D printing technologies should take into account sustainable development, use of materials, energy, emitted particles, and waste. The aim of this paper is to investigate whether the sustainability of 3D printing processes can be supported by computational intelligence (CI) and artificial intelligence (AI) based solutions. We present a new AI-based software to evaluate the amount of pollution generated by 3D printing systems. We input the values: printing technology, material, print weight, etc., and the expected results (risk assessment) and determine if and what precautions should be taken. The study uses a self-learning program that will improve as more data are entered. This program does not replace but complements previously used 3D printing metrics and software.",
    "intriguing_abstract": "Technological and material issues in 3D printing technologies should take into account sustainable development, use of materials, energy, emitted particles, and waste. The aim of this paper is to investigate whether the sustainability of 3D printing processes can be supported by computational intelligence (CI) and artificial intelligence (AI) based solutions. We present a new AI-based software to evaluate the amount of pollution generated by 3D printing systems. We input the values: printing technology, material, print weight, etc., and the expected results (risk assessment) and determine if and what precautions should be taken. The study uses a self-learning program that will improve as more data are entered. This program does not replace but complements previously used 3D printing metrics and software.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/90f243510274d7ce58e7b34f39b14d29f6d2573f.pdf",
    "citation_key": "rojek2021nwg",
    "metadata": {
      "title": "Optimization of Extrusion-Based 3D Printing Process Using Neural Networks for Sustainable Development",
      "authors": [
        "Izabela Rojek",
        "D. Mikołajewski",
        "M. Macko",
        "Z. Szczepański",
        "E. Dostatni"
      ],
      "published_date": "2021",
      "abstract": "Technological and material issues in 3D printing technologies should take into account sustainable development, use of materials, energy, emitted particles, and waste. The aim of this paper is to investigate whether the sustainability of 3D printing processes can be supported by computational intelligence (CI) and artificial intelligence (AI) based solutions. We present a new AI-based software to evaluate the amount of pollution generated by 3D printing systems. We input the values: printing technology, material, print weight, etc., and the expected results (risk assessment) and determine if and what precautions should be taken. The study uses a self-learning program that will improve as more data are entered. This program does not replace but complements previously used 3D printing metrics and software.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/90f243510274d7ce58e7b34f39b14d29f6d2573f.pdf",
      "venue": "Materials",
      "citationCount": 31,
      "score": 7.75,
      "summary": "Technological and material issues in 3D printing technologies should take into account sustainable development, use of materials, energy, emitted particles, and waste. The aim of this paper is to investigate whether the sustainability of 3D printing processes can be supported by computational intelligence (CI) and artificial intelligence (AI) based solutions. We present a new AI-based software to evaluate the amount of pollution generated by 3D printing systems. We input the values: printing technology, material, print weight, etc., and the expected results (risk assessment) and determine if and what precautions should be taken. The study uses a self-learning program that will improve as more data are entered. This program does not replace but complements previously used 3D printing metrics and software.",
      "keywords": []
    },
    "file_name": "90f243510274d7ce58e7b34f39b14d29f6d2573f.pdf"
  },
  {
    "success": true,
    "doc_id": "2a8cefffbb768655066d53ef1b374fc7",
    "summary": "DevOps practices are the de facto sandard when developing software. The increased adoption of machine learning (ML) to solve problems urges us to adapt all the current approaches to developing a new standard that can take full benefit from the new solution. In this work we propose a graphical representation for DevOps for ML-based applications, namely MLOps, and also outline open research challenges. The pipeline aims to get the best of both worlds by maintaining the simple and iconic pipeline of DevOps, yet improving it by adding new circular steps for ML incorporation. This aims to create an ML-based development subsystem that can be self-maintained, and is capable of evolving side-by-side with the software development.",
    "intriguing_abstract": "DevOps practices are the de facto sandard when developing software. The increased adoption of machine learning (ML) to solve problems urges us to adapt all the current approaches to developing a new standard that can take full benefit from the new solution. In this work we propose a graphical representation for DevOps for ML-based applications, namely MLOps, and also outline open research challenges. The pipeline aims to get the best of both worlds by maintaining the simple and iconic pipeline of DevOps, yet improving it by adding new circular steps for ML incorporation. This aims to create an ML-based development subsystem that can be self-maintained, and is capable of evolving side-by-side with the software development.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/85738378330fe837282190f76edcda164ffdd2f7.pdf",
    "citation_key": "moreschini20228ag",
    "metadata": {
      "title": "MLOps for evolvable AI intensive software systems",
      "authors": [
        "Sergio Moreschini",
        "Francesco Lomio",
        "David Hästbacka",
        "D. Taibi"
      ],
      "published_date": "2022",
      "abstract": "DevOps practices are the de facto sandard when developing software. The increased adoption of machine learning (ML) to solve problems urges us to adapt all the current approaches to developing a new standard that can take full benefit from the new solution. In this work we propose a graphical representation for DevOps for ML-based applications, namely MLOps, and also outline open research challenges. The pipeline aims to get the best of both worlds by maintaining the simple and iconic pipeline of DevOps, yet improving it by adding new circular steps for ML incorporation. This aims to create an ML-based development subsystem that can be self-maintained, and is capable of evolving side-by-side with the software development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/85738378330fe837282190f76edcda164ffdd2f7.pdf",
      "venue": "IEEE International Conference on Software Analysis, Evolution, and Reengineering",
      "citationCount": 23,
      "score": 7.666666666666666,
      "summary": "DevOps practices are the de facto sandard when developing software. The increased adoption of machine learning (ML) to solve problems urges us to adapt all the current approaches to developing a new standard that can take full benefit from the new solution. In this work we propose a graphical representation for DevOps for ML-based applications, namely MLOps, and also outline open research challenges. The pipeline aims to get the best of both worlds by maintaining the simple and iconic pipeline of DevOps, yet improving it by adding new circular steps for ML incorporation. This aims to create an ML-based development subsystem that can be self-maintained, and is capable of evolving side-by-side with the software development.",
      "keywords": []
    },
    "file_name": "85738378330fe837282190f76edcda164ffdd2f7.pdf"
  },
  {
    "success": true,
    "doc_id": "b92fcd754f2143e8411b1789a9bb8773",
    "summary": "In optical transport networks, the urgent demand for control efficiency and intelligence has become one of the most significant challenges for telecom operators. With the development in control technology, more attention has been paid to performance enhancement of the centralized controller of software-defined optical networks (SDONs). Meanwhile, machine learning (ML) is emerging as a promising technology to facilitate the intelligence of control planes in SDONs. Some research works have been conducted to use ML to solve problems in optical transport networks. However, it is still a challenge to deploy and use computing resources. On the one hand, computing resources can be deployed inside the centralized controller of an SDON to enable control layer artificial intelligence (AI). On the other hand, computing resources can also be deployed on the hardware board to enable on-board AI. The two-layer AI functions are able to meet different intelligent requirements in data and control layers in different scenarios. Therefore, coordination between them is an important issue. In this paper, a novel control architecture based on an SDON is proposed, and it can support control layer AI and on-board AI simultaneously. Particularly, on-board AI is proposed based on edge computing to support various ML applications. To evaluate the proposed architecture, we develop an experimental testbed and demonstrate a typical use case, i.e., alarm information prediction. Experimental results show that coordination and cross-layer optimization between control layer AI and on-board AI can be achieved. However, there is much space for research in this area, and we envision some open issues.",
    "intriguing_abstract": "In optical transport networks, the urgent demand for control efficiency and intelligence has become one of the most significant challenges for telecom operators. With the development in control technology, more attention has been paid to performance enhancement of the centralized controller of software-defined optical networks (SDONs). Meanwhile, machine learning (ML) is emerging as a promising technology to facilitate the intelligence of control planes in SDONs. Some research works have been conducted to use ML to solve problems in optical transport networks. However, it is still a challenge to deploy and use computing resources. On the one hand, computing resources can be deployed inside the centralized controller of an SDON to enable control layer artificial intelligence (AI). On the other hand, computing resources can also be deployed on the hardware board to enable on-board AI. The two-layer AI functions are able to meet different intelligent requirements in data and control layers in different scenarios. Therefore, coordination between them is an important issue. In this paper, a novel control architecture based on an SDON is proposed, and it can support control layer AI and on-board AI simultaneously. Particularly, on-board AI is proposed based on edge computing to support various ML applications. To evaluate the proposed architecture, we develop an experimental testbed and demonstrate a typical use case, i.e., alarm information prediction. Experimental results show that coordination and cross-layer optimization between control layer AI and on-board AI can be achieved. However, there is much space for research in this area, and we envision some open issues.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ba8e762ce6697becdb150c3c141331e989850699.pdf",
    "citation_key": "zhao2019bwa",
    "metadata": {
      "title": "Coordination between control layer AI and on-board AI in optical transport networks [Invited]",
      "authors": [
        "Yongli Zhao",
        "Boyuan Yan",
        "Zhuotong Li",
        "Wei Wang",
        "Ying Wang",
        "Jie Zhang"
      ],
      "published_date": "2019",
      "abstract": "In optical transport networks, the urgent demand for control efficiency and intelligence has become one of the most significant challenges for telecom operators. With the development in control technology, more attention has been paid to performance enhancement of the centralized controller of software-defined optical networks (SDONs). Meanwhile, machine learning (ML) is emerging as a promising technology to facilitate the intelligence of control planes in SDONs. Some research works have been conducted to use ML to solve problems in optical transport networks. However, it is still a challenge to deploy and use computing resources. On the one hand, computing resources can be deployed inside the centralized controller of an SDON to enable control layer artificial intelligence (AI). On the other hand, computing resources can also be deployed on the hardware board to enable on-board AI. The two-layer AI functions are able to meet different intelligent requirements in data and control layers in different scenarios. Therefore, coordination between them is an important issue. In this paper, a novel control architecture based on an SDON is proposed, and it can support control layer AI and on-board AI simultaneously. Particularly, on-board AI is proposed based on edge computing to support various ML applications. To evaluate the proposed architecture, we develop an experimental testbed and demonstrate a typical use case, i.e., alarm information prediction. Experimental results show that coordination and cross-layer optimization between control layer AI and on-board AI can be achieved. However, there is much space for research in this area, and we envision some open issues.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ba8e762ce6697becdb150c3c141331e989850699.pdf",
      "venue": "IEEE\\/OSA Journal of Optical Communications and Networking",
      "citationCount": 45,
      "score": 7.5,
      "summary": "In optical transport networks, the urgent demand for control efficiency and intelligence has become one of the most significant challenges for telecom operators. With the development in control technology, more attention has been paid to performance enhancement of the centralized controller of software-defined optical networks (SDONs). Meanwhile, machine learning (ML) is emerging as a promising technology to facilitate the intelligence of control planes in SDONs. Some research works have been conducted to use ML to solve problems in optical transport networks. However, it is still a challenge to deploy and use computing resources. On the one hand, computing resources can be deployed inside the centralized controller of an SDON to enable control layer artificial intelligence (AI). On the other hand, computing resources can also be deployed on the hardware board to enable on-board AI. The two-layer AI functions are able to meet different intelligent requirements in data and control layers in different scenarios. Therefore, coordination between them is an important issue. In this paper, a novel control architecture based on an SDON is proposed, and it can support control layer AI and on-board AI simultaneously. Particularly, on-board AI is proposed based on edge computing to support various ML applications. To evaluate the proposed architecture, we develop an experimental testbed and demonstrate a typical use case, i.e., alarm information prediction. Experimental results show that coordination and cross-layer optimization between control layer AI and on-board AI can be achieved. However, there is much space for research in this area, and we envision some open issues.",
      "keywords": []
    },
    "file_name": "ba8e762ce6697becdb150c3c141331e989850699.pdf"
  },
  {
    "success": true,
    "doc_id": "0e20a23ee67650ec4b5c0998ffbb60be",
    "summary": "The main challenges are discussed together with the lessons learned from past and ongoing research along the development cycle of machine learning systems. This will be done by taking into account intrinsic conditions of nowadays deep learning models, data and software quality issues and human-centered artificial intelligence (AI) postulates, including confidentiality and ethical aspects. The analysis outlines a fundamental theory-practice gap which superimposes the challenges of AI system engineering at the level of data quality assurance, model building, software engineering and deployment. The aim of this paper is to pinpoint research topics to explore approaches to address these challenges.",
    "intriguing_abstract": "The main challenges are discussed together with the lessons learned from past and ongoing research along the development cycle of machine learning systems. This will be done by taking into account intrinsic conditions of nowadays deep learning models, data and software quality issues and human-centered artificial intelligence (AI) postulates, including confidentiality and ethical aspects. The analysis outlines a fundamental theory-practice gap which superimposes the challenges of AI system engineering at the level of data quality assurance, model building, software engineering and deployment. The aim of this paper is to pinpoint research topics to explore approaches to address these challenges.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/75d16719ec5378cfe433143232d02029ad9dadbe.pdf",
    "citation_key": "fischer2020gef",
    "metadata": {
      "title": "AI System Engineering - Key Challenges and Lessons Learned",
      "authors": [
        "Lukas Fischer",
        "Lisa Ehrlinger",
        "V. Geist",
        "Rudolf Ramler",
        "F. Sobieczky",
        "W. Zellinger",
        "David Brunner",
        "Mohit Kumar",
        "B. Moser"
      ],
      "published_date": "2020",
      "abstract": "The main challenges are discussed together with the lessons learned from past and ongoing research along the development cycle of machine learning systems. This will be done by taking into account intrinsic conditions of nowadays deep learning models, data and software quality issues and human-centered artificial intelligence (AI) postulates, including confidentiality and ethical aspects. The analysis outlines a fundamental theory-practice gap which superimposes the challenges of AI system engineering at the level of data quality assurance, model building, software engineering and deployment. The aim of this paper is to pinpoint research topics to explore approaches to address these challenges.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/75d16719ec5378cfe433143232d02029ad9dadbe.pdf",
      "venue": "Machine Learning and Knowledge Extraction",
      "citationCount": 37,
      "score": 7.4,
      "summary": "The main challenges are discussed together with the lessons learned from past and ongoing research along the development cycle of machine learning systems. This will be done by taking into account intrinsic conditions of nowadays deep learning models, data and software quality issues and human-centered artificial intelligence (AI) postulates, including confidentiality and ethical aspects. The analysis outlines a fundamental theory-practice gap which superimposes the challenges of AI system engineering at the level of data quality assurance, model building, software engineering and deployment. The aim of this paper is to pinpoint research topics to explore approaches to address these challenges.",
      "keywords": []
    },
    "file_name": "75d16719ec5378cfe433143232d02029ad9dadbe.pdf"
  },
  {
    "success": true,
    "doc_id": "aa6234a65a35c49cebbaacadf554d729",
    "summary": "Automated hiring systems are among the fastest-developing of all high-stakes AI systems. Among these are algorithmic personality tests that use insights from psychometric testing, and promise to surface personality traits indicative of future success based on job seekers’ resumes or social media profiles. We interrogate the validity of such systems using stability of the outputs they produce, noting that reliability is a necessary, but not a sufficient, condition for validity. Crucially, rather than challenging or affirming the assumptions made in psychometric testing — that personality is a meaningful and measurable construct, and that personality traits are indicative of future success on the job — we frame our audit methodology around testing the underlying assumptions made by the vendors of the algorithmic personality tests themselves. Our main contribution is the development of a socio-technical framework for auditing the stability of algorithmic systems. This contribution is supplemented with an open-source software library that implements the technical components of the audit, and can be used to conduct similar stability audits of algorithmic systems. We instantiate our framework with the audit of two real-world personality prediction systems, namely, Humantic AI and Crystal. The application of our audit framework demonstrates that both these systems show substantial instability with respect to key facets of measurement, and hence cannot be considered valid testing instruments.",
    "intriguing_abstract": "Automated hiring systems are among the fastest-developing of all high-stakes AI systems. Among these are algorithmic personality tests that use insights from psychometric testing, and promise to surface personality traits indicative of future success based on job seekers’ resumes or social media profiles. We interrogate the validity of such systems using stability of the outputs they produce, noting that reliability is a necessary, but not a sufficient, condition for validity. Crucially, rather than challenging or affirming the assumptions made in psychometric testing — that personality is a meaningful and measurable construct, and that personality traits are indicative of future success on the job — we frame our audit methodology around testing the underlying assumptions made by the vendors of the algorithmic personality tests themselves. Our main contribution is the development of a socio-technical framework for auditing the stability of algorithmic systems. This contribution is supplemented with an open-source software library that implements the technical components of the audit, and can be used to conduct similar stability audits of algorithmic systems. We instantiate our framework with the audit of two real-world personality prediction systems, namely, Humantic AI and Crystal. The application of our audit framework demonstrates that both these systems show substantial instability with respect to key facets of measurement, and hence cannot be considered valid testing instruments.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/3b9a171115014839028d3bea68578f9d4dab8cbf.pdf",
    "citation_key": "rhea2022kiz",
    "metadata": {
      "title": "An external stability audit framework to test the validity of personality prediction in AI hiring",
      "authors": [
        "Alene K. Rhea",
        "K. Markey",
        "L. D’Arinzo",
        "Hilke Schellmann",
        "Mona Sloane",
        "Paul Squires",
        "Falaah Arif Khan",
        "J. Stoyanovich"
      ],
      "published_date": "2022",
      "abstract": "Automated hiring systems are among the fastest-developing of all high-stakes AI systems. Among these are algorithmic personality tests that use insights from psychometric testing, and promise to surface personality traits indicative of future success based on job seekers’ resumes or social media profiles. We interrogate the validity of such systems using stability of the outputs they produce, noting that reliability is a necessary, but not a sufficient, condition for validity. Crucially, rather than challenging or affirming the assumptions made in psychometric testing — that personality is a meaningful and measurable construct, and that personality traits are indicative of future success on the job — we frame our audit methodology around testing the underlying assumptions made by the vendors of the algorithmic personality tests themselves. Our main contribution is the development of a socio-technical framework for auditing the stability of algorithmic systems. This contribution is supplemented with an open-source software library that implements the technical components of the audit, and can be used to conduct similar stability audits of algorithmic systems. We instantiate our framework with the audit of two real-world personality prediction systems, namely, Humantic AI and Crystal. The application of our audit framework demonstrates that both these systems show substantial instability with respect to key facets of measurement, and hence cannot be considered valid testing instruments.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/3b9a171115014839028d3bea68578f9d4dab8cbf.pdf",
      "venue": "Data mining and knowledge discovery",
      "citationCount": 22,
      "score": 7.333333333333333,
      "summary": "Automated hiring systems are among the fastest-developing of all high-stakes AI systems. Among these are algorithmic personality tests that use insights from psychometric testing, and promise to surface personality traits indicative of future success based on job seekers’ resumes or social media profiles. We interrogate the validity of such systems using stability of the outputs they produce, noting that reliability is a necessary, but not a sufficient, condition for validity. Crucially, rather than challenging or affirming the assumptions made in psychometric testing — that personality is a meaningful and measurable construct, and that personality traits are indicative of future success on the job — we frame our audit methodology around testing the underlying assumptions made by the vendors of the algorithmic personality tests themselves. Our main contribution is the development of a socio-technical framework for auditing the stability of algorithmic systems. This contribution is supplemented with an open-source software library that implements the technical components of the audit, and can be used to conduct similar stability audits of algorithmic systems. We instantiate our framework with the audit of two real-world personality prediction systems, namely, Humantic AI and Crystal. The application of our audit framework demonstrates that both these systems show substantial instability with respect to key facets of measurement, and hence cannot be considered valid testing instruments.",
      "keywords": []
    },
    "file_name": "3b9a171115014839028d3bea68578f9d4dab8cbf.pdf"
  },
  {
    "success": true,
    "doc_id": "89ec061143405d7e48342248e6710291",
    "summary": "PurposeAlthough many universities have begun to provide artificial intelligence (AI)-related courses for students, the influence of the course on students' intention to participate in the development of AI-related products/services needs to be verified. In order to explore the factors that influence students' participation in AI services and system development, this study uses self-efficacy, AI literacy, and the theory of planned behaviour (TPB) to investigate students' intention to engage in AI software development.Design/methodology/approachThe questionnaire was distributed online to collect university students' responses in central Taiwan. The research model and eleven hypotheses are tested using 151 responses. The testing process adopted SmartPLS 3.3 and SPSS 26 software.FindingsAI programming self-efficacy, AI literacy, and course satisfaction directly affected the intention to participate in AI software development. Moreover, course playfulness significantly affected course satisfaction and AI literacy. However, course usefulness positively affected course satisfaction but did not significantly affect AI literacy and AI programming self-efficacy.Originality/valueThe model improves our comprehension of the influence of AI literacy and AI programming self-efficacy on the intention. Moreover, the effects of AI course usefulness and playfulness on literacy and self-efficacy were verified. The findings and insights can help design the AI-related course and encourage university students to participate in AI software development. The study concludes with suggestions for course design for AI course instructors or related educators.",
    "intriguing_abstract": "PurposeAlthough many universities have begun to provide artificial intelligence (AI)-related courses for students, the influence of the course on students' intention to participate in the development of AI-related products/services needs to be verified. In order to explore the factors that influence students' participation in AI services and system development, this study uses self-efficacy, AI literacy, and the theory of planned behaviour (TPB) to investigate students' intention to engage in AI software development.Design/methodology/approachThe questionnaire was distributed online to collect university students' responses in central Taiwan. The research model and eleven hypotheses are tested using 151 responses. The testing process adopted SmartPLS 3.3 and SPSS 26 software.FindingsAI programming self-efficacy, AI literacy, and course satisfaction directly affected the intention to participate in AI software development. Moreover, course playfulness significantly affected course satisfaction and AI literacy. However, course usefulness positively affected course satisfaction but did not significantly affect AI literacy and AI programming self-efficacy.Originality/valueThe model improves our comprehension of the influence of AI literacy and AI programming self-efficacy on the intention. Moreover, the effects of AI course usefulness and playfulness on literacy and self-efficacy were verified. The findings and insights can help design the AI-related course and encourage university students to participate in AI software development. The study concludes with suggestions for course design for AI course instructors or related educators.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/3d328e4ed66b9f5d4b4f95a1f6e5fbe8f470544e.pdf",
    "citation_key": "chen2022tt5",
    "metadata": {
      "title": "Exploring the factors of students' intention to participate in AI software development",
      "authors": [
        "Shih-Yeh Chen",
        "Yu-Sheng Su",
        "Yaochia Ku",
        "Chin-Feng Lai",
        "Kuo-Lun Hsiao"
      ],
      "published_date": "2022",
      "abstract": "PurposeAlthough many universities have begun to provide artificial intelligence (AI)-related courses for students, the influence of the course on students' intention to participate in the development of AI-related products/services needs to be verified. In order to explore the factors that influence students' participation in AI services and system development, this study uses self-efficacy, AI literacy, and the theory of planned behaviour (TPB) to investigate students' intention to engage in AI software development.Design/methodology/approachThe questionnaire was distributed online to collect university students' responses in central Taiwan. The research model and eleven hypotheses are tested using 151 responses. The testing process adopted SmartPLS 3.3 and SPSS 26 software.FindingsAI programming self-efficacy, AI literacy, and course satisfaction directly affected the intention to participate in AI software development. Moreover, course playfulness significantly affected course satisfaction and AI literacy. However, course usefulness positively affected course satisfaction but did not significantly affect AI literacy and AI programming self-efficacy.Originality/valueThe model improves our comprehension of the influence of AI literacy and AI programming self-efficacy on the intention. Moreover, the effects of AI course usefulness and playfulness on literacy and self-efficacy were verified. The findings and insights can help design the AI-related course and encourage university students to participate in AI software development. The study concludes with suggestions for course design for AI course instructors or related educators.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/3d328e4ed66b9f5d4b4f95a1f6e5fbe8f470544e.pdf",
      "venue": "Library hi tech",
      "citationCount": 21,
      "score": 7.0,
      "summary": "PurposeAlthough many universities have begun to provide artificial intelligence (AI)-related courses for students, the influence of the course on students' intention to participate in the development of AI-related products/services needs to be verified. In order to explore the factors that influence students' participation in AI services and system development, this study uses self-efficacy, AI literacy, and the theory of planned behaviour (TPB) to investigate students' intention to engage in AI software development.Design/methodology/approachThe questionnaire was distributed online to collect university students' responses in central Taiwan. The research model and eleven hypotheses are tested using 151 responses. The testing process adopted SmartPLS 3.3 and SPSS 26 software.FindingsAI programming self-efficacy, AI literacy, and course satisfaction directly affected the intention to participate in AI software development. Moreover, course playfulness significantly affected course satisfaction and AI literacy. However, course usefulness positively affected course satisfaction but did not significantly affect AI literacy and AI programming self-efficacy.Originality/valueThe model improves our comprehension of the influence of AI literacy and AI programming self-efficacy on the intention. Moreover, the effects of AI course usefulness and playfulness on literacy and self-efficacy were verified. The findings and insights can help design the AI-related course and encourage university students to participate in AI software development. The study concludes with suggestions for course design for AI course instructors or related educators.",
      "keywords": []
    },
    "file_name": "3d328e4ed66b9f5d4b4f95a1f6e5fbe8f470544e.pdf"
  },
  {
    "success": true,
    "doc_id": "48be29766a3dc643d91dd11e2f94be93",
    "summary": "DevOps practices have increasingly been applied to software development as well as the machine learning lifecycle, in a process known as MLOps. Currently, many professionals have written about this topic, but still few results can be found in the academic and scientific literature on MLOps and how to to implement it effectively. Considering aspects of responsible AI, this number is even lower, opening up a field of research with many possibilities. This article presents five steps to guide the understanding and adoption of MLOps in the context of responsible AI. The study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement MLOps practices to develop their systems, following responsible AI principles.CCS CONCEPTS• Software and its engineering → Software creation and management; • Computing methodologies → Machine learning.",
    "intriguing_abstract": "DevOps practices have increasingly been applied to software development as well as the machine learning lifecycle, in a process known as MLOps. Currently, many professionals have written about this topic, but still few results can be found in the academic and scientific literature on MLOps and how to to implement it effectively. Considering aspects of responsible AI, this number is even lower, opening up a field of research with many possibilities. This article presents five steps to guide the understanding and adoption of MLOps in the context of responsible AI. The study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement MLOps practices to develop their systems, following responsible AI principles.CCS CONCEPTS• Software and its engineering → Software creation and management; • Computing methodologies → Machine learning.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/267e19842ee07b786572629d464cca56a0e1c6b3.pdf",
    "citation_key": "matsui20223jp",
    "metadata": {
      "title": "MLOps: A Guide to its Adoption in the Context of Responsible AI",
      "authors": [
        "B. M. A. Matsui",
        "Denise H. Goya"
      ],
      "published_date": "2022",
      "abstract": "DevOps practices have increasingly been applied to software development as well as the machine learning lifecycle, in a process known as MLOps. Currently, many professionals have written about this topic, but still few results can be found in the academic and scientific literature on MLOps and how to to implement it effectively. Considering aspects of responsible AI, this number is even lower, opening up a field of research with many possibilities. This article presents five steps to guide the understanding and adoption of MLOps in the context of responsible AI. The study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement MLOps practices to develop their systems, following responsible AI principles.CCS CONCEPTS• Software and its engineering → Software creation and management; • Computing methodologies → Machine learning.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/267e19842ee07b786572629d464cca56a0e1c6b3.pdf",
      "venue": "2022 IEEE/ACM 1st International Workshop on Software Engineering for Responsible Artificial Intelligence (SE4RAI)",
      "citationCount": 21,
      "score": 7.0,
      "summary": "DevOps practices have increasingly been applied to software development as well as the machine learning lifecycle, in a process known as MLOps. Currently, many professionals have written about this topic, but still few results can be found in the academic and scientific literature on MLOps and how to to implement it effectively. Considering aspects of responsible AI, this number is even lower, opening up a field of research with many possibilities. This article presents five steps to guide the understanding and adoption of MLOps in the context of responsible AI. The study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement MLOps practices to develop their systems, following responsible AI principles.CCS CONCEPTS• Software and its engineering → Software creation and management; • Computing methodologies → Machine learning.",
      "keywords": []
    },
    "file_name": "267e19842ee07b786572629d464cca56a0e1c6b3.pdf"
  },
  {
    "success": true,
    "doc_id": "d2f21c7241c4a736ad541148cea150ae",
    "summary": "Background Margin reflex distance 1 (MRD1), margin reflex distance 2 (MRD2), and levator muscle function (LF) are crucial metrics for ptosis evaluation and management. However, manual measurements of MRD1, MRD2, and LF are time-consuming, subjective, and prone to human error. Smartphone-based artificial intelligence (AI) image processing is a potential solution to overcome these limitations. Objective We propose the first smartphone-based AI-assisted image processing algorithm for MRD1, MRD2, and LF measurements. Methods This observational study included 822 eyes of 411 volunteers aged over 18 years from August 1, 2020, to April 30, 2021. Six orbital photographs (bilateral primary gaze, up-gaze, and down-gaze) were taken using a smartphone (iPhone 11 Pro Max). The gold-standard measurements and normalized eye photographs were obtained from these orbital photographs and compiled using AI-assisted software to create MRD1, MRD2, and LF models. Results The Pearson correlation coefficients between the gold-standard measurements and the predicted values obtained with the MRD1 and MRD2 models were excellent (r=0.91 and 0.88, respectively) and that obtained with the LF model was good (r=0.73). The intraclass correlation coefficient demonstrated excellent agreement between the gold-standard measurements and the values predicted by the MRD1 and MRD2 models (0.90 and 0.84, respectively), and substantial agreement with the LF model (0.69). The mean absolute errors were 0.35 mm, 0.37 mm, and 1.06 mm for the MRD1, MRD2, and LF models, respectively. The 95% limits of agreement were –0.94 to 0.94 mm for the MRD1 model, –0.92 to 1.03 mm for the MRD2 model, and –0.63 to 2.53 mm for the LF model. Conclusions We developed the first smartphone-based AI-assisted image processing algorithm for eyelid measurements. MRD1, MRD2, and LF measures can be taken in a quick, objective, and convenient manner. Furthermore, by using a smartphone, the examiner can check these measurements anywhere and at any time, which facilitates data collection.",
    "intriguing_abstract": "Background Margin reflex distance 1 (MRD1), margin reflex distance 2 (MRD2), and levator muscle function (LF) are crucial metrics for ptosis evaluation and management. However, manual measurements of MRD1, MRD2, and LF are time-consuming, subjective, and prone to human error. Smartphone-based artificial intelligence (AI) image processing is a potential solution to overcome these limitations. Objective We propose the first smartphone-based AI-assisted image processing algorithm for MRD1, MRD2, and LF measurements. Methods This observational study included 822 eyes of 411 volunteers aged over 18 years from August 1, 2020, to April 30, 2021. Six orbital photographs (bilateral primary gaze, up-gaze, and down-gaze) were taken using a smartphone (iPhone 11 Pro Max). The gold-standard measurements and normalized eye photographs were obtained from these orbital photographs and compiled using AI-assisted software to create MRD1, MRD2, and LF models. Results The Pearson correlation coefficients between the gold-standard measurements and the predicted values obtained with the MRD1 and MRD2 models were excellent (r=0.91 and 0.88, respectively) and that obtained with the LF model was good (r=0.73). The intraclass correlation coefficient demonstrated excellent agreement between the gold-standard measurements and the values predicted by the MRD1 and MRD2 models (0.90 and 0.84, respectively), and substantial agreement with the LF model (0.69). The mean absolute errors were 0.35 mm, 0.37 mm, and 1.06 mm for the MRD1, MRD2, and LF models, respectively. The 95% limits of agreement were –0.94 to 0.94 mm for the MRD1 model, –0.92 to 1.03 mm for the MRD2 model, and –0.63 to 2.53 mm for the LF model. Conclusions We developed the first smartphone-based AI-assisted image processing algorithm for eyelid measurements. MRD1, MRD2, and LF measures can be taken in a quick, objective, and convenient manner. Furthermore, by using a smartphone, the examiner can check these measurements anywhere and at any time, which facilitates data collection.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b5dce2e833015ca4b1530f513d89b6b8732073c0.pdf",
    "citation_key": "chen2021o3n",
    "metadata": {
      "title": "Smartphone-Based Artificial Intelligence–Assisted Prediction for Eyelid Measurements: Algorithm Development and Observational Validation Study",
      "authors": [
        "Hung-Chang Chen",
        "Shin-Shi Tzeng",
        "Yen-Chang Hsiao",
        "Ruei-Feng Chen",
        "Erh-Chien Hung",
        "O. K. Lee"
      ],
      "published_date": "2021",
      "abstract": "Background Margin reflex distance 1 (MRD1), margin reflex distance 2 (MRD2), and levator muscle function (LF) are crucial metrics for ptosis evaluation and management. However, manual measurements of MRD1, MRD2, and LF are time-consuming, subjective, and prone to human error. Smartphone-based artificial intelligence (AI) image processing is a potential solution to overcome these limitations. Objective We propose the first smartphone-based AI-assisted image processing algorithm for MRD1, MRD2, and LF measurements. Methods This observational study included 822 eyes of 411 volunteers aged over 18 years from August 1, 2020, to April 30, 2021. Six orbital photographs (bilateral primary gaze, up-gaze, and down-gaze) were taken using a smartphone (iPhone 11 Pro Max). The gold-standard measurements and normalized eye photographs were obtained from these orbital photographs and compiled using AI-assisted software to create MRD1, MRD2, and LF models. Results The Pearson correlation coefficients between the gold-standard measurements and the predicted values obtained with the MRD1 and MRD2 models were excellent (r=0.91 and 0.88, respectively) and that obtained with the LF model was good (r=0.73). The intraclass correlation coefficient demonstrated excellent agreement between the gold-standard measurements and the values predicted by the MRD1 and MRD2 models (0.90 and 0.84, respectively), and substantial agreement with the LF model (0.69). The mean absolute errors were 0.35 mm, 0.37 mm, and 1.06 mm for the MRD1, MRD2, and LF models, respectively. The 95% limits of agreement were –0.94 to 0.94 mm for the MRD1 model, –0.92 to 1.03 mm for the MRD2 model, and –0.63 to 2.53 mm for the LF model. Conclusions We developed the first smartphone-based AI-assisted image processing algorithm for eyelid measurements. MRD1, MRD2, and LF measures can be taken in a quick, objective, and convenient manner. Furthermore, by using a smartphone, the examiner can check these measurements anywhere and at any time, which facilitates data collection.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b5dce2e833015ca4b1530f513d89b6b8732073c0.pdf",
      "venue": "JMIR mHealth and uHealth",
      "citationCount": 28,
      "score": 7.0,
      "summary": "Background Margin reflex distance 1 (MRD1), margin reflex distance 2 (MRD2), and levator muscle function (LF) are crucial metrics for ptosis evaluation and management. However, manual measurements of MRD1, MRD2, and LF are time-consuming, subjective, and prone to human error. Smartphone-based artificial intelligence (AI) image processing is a potential solution to overcome these limitations. Objective We propose the first smartphone-based AI-assisted image processing algorithm for MRD1, MRD2, and LF measurements. Methods This observational study included 822 eyes of 411 volunteers aged over 18 years from August 1, 2020, to April 30, 2021. Six orbital photographs (bilateral primary gaze, up-gaze, and down-gaze) were taken using a smartphone (iPhone 11 Pro Max). The gold-standard measurements and normalized eye photographs were obtained from these orbital photographs and compiled using AI-assisted software to create MRD1, MRD2, and LF models. Results The Pearson correlation coefficients between the gold-standard measurements and the predicted values obtained with the MRD1 and MRD2 models were excellent (r=0.91 and 0.88, respectively) and that obtained with the LF model was good (r=0.73). The intraclass correlation coefficient demonstrated excellent agreement between the gold-standard measurements and the values predicted by the MRD1 and MRD2 models (0.90 and 0.84, respectively), and substantial agreement with the LF model (0.69). The mean absolute errors were 0.35 mm, 0.37 mm, and 1.06 mm for the MRD1, MRD2, and LF models, respectively. The 95% limits of agreement were –0.94 to 0.94 mm for the MRD1 model, –0.92 to 1.03 mm for the MRD2 model, and –0.63 to 2.53 mm for the LF model. Conclusions We developed the first smartphone-based AI-assisted image processing algorithm for eyelid measurements. MRD1, MRD2, and LF measures can be taken in a quick, objective, and convenient manner. Furthermore, by using a smartphone, the examiner can check these measurements anywhere and at any time, which facilitates data collection.",
      "keywords": []
    },
    "file_name": "b5dce2e833015ca4b1530f513d89b6b8732073c0.pdf"
  },
  {
    "success": true,
    "doc_id": "1e1375e09f9595e644e93d64cf402008",
    "summary": "The integration of Artificial Intelligence (AI) into mobile applications has significantly advanced the capabilities of modern software, enhancing user experiences through personalized, intelligent interactions. The effective use of AI-driven third-party frameworks has emerged as a pivotal strategy for developers aiming to leverage AI's potential without the need for extensive in-house expertise. This paper explores the impact and benefits of incorporating AI-driven third-party frameworks into mobile app development, focusing on their role in optimizing performance, enhancing user engagement, and accelerating development cycles. \nAI-driven third-party frameworks offer a range of pre-built functionalities, including natural language processing (NLP), image recognition, and predictive analytics, which can be seamlessly integrated into mobile applications. These frameworks provide developers with powerful tools to implement advanced features with reduced time and resource investment. By utilizing these frameworks, developers can focus on core application functionalities while benefiting from sophisticated AI capabilities that would otherwise require significant development effort.",
    "intriguing_abstract": "The integration of Artificial Intelligence (AI) into mobile applications has significantly advanced the capabilities of modern software, enhancing user experiences through personalized, intelligent interactions. The effective use of AI-driven third-party frameworks has emerged as a pivotal strategy for developers aiming to leverage AI's potential without the need for extensive in-house expertise. This paper explores the impact and benefits of incorporating AI-driven third-party frameworks into mobile app development, focusing on their role in optimizing performance, enhancing user engagement, and accelerating development cycles. \nAI-driven third-party frameworks offer a range of pre-built functionalities, including natural language processing (NLP), image recognition, and predictive analytics, which can be seamlessly integrated into mobile applications. These frameworks provide developers with powerful tools to implement advanced features with reduced time and resource investment. By utilizing these frameworks, developers can focus on core application functionalities while benefiting from sophisticated AI capabilities that would otherwise require significant development effort.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8f4d78fc1f6a52f28a1d7abf3bfd0b89d1fca737.pdf",
    "citation_key": "bhasker2021iq2",
    "metadata": {
      "title": "Effective Use of AI-Driven Third-Party Frameworks in Mobile Apps",
      "authors": [
        "Vijay Bhasker",
        "Reddy Bhimanapati",
        "Dr. Punit Goel",
        "A. Renuka"
      ],
      "published_date": "2021",
      "abstract": "The integration of Artificial Intelligence (AI) into mobile applications has significantly advanced the capabilities of modern software, enhancing user experiences through personalized, intelligent interactions. The effective use of AI-driven third-party frameworks has emerged as a pivotal strategy for developers aiming to leverage AI's potential without the need for extensive in-house expertise. This paper explores the impact and benefits of incorporating AI-driven third-party frameworks into mobile app development, focusing on their role in optimizing performance, enhancing user engagement, and accelerating development cycles. \nAI-driven third-party frameworks offer a range of pre-built functionalities, including natural language processing (NLP), image recognition, and predictive analytics, which can be seamlessly integrated into mobile applications. These frameworks provide developers with powerful tools to implement advanced features with reduced time and resource investment. By utilizing these frameworks, developers can focus on core application functionalities while benefiting from sophisticated AI capabilities that would otherwise require significant development effort.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8f4d78fc1f6a52f28a1d7abf3bfd0b89d1fca737.pdf",
      "venue": "Innovative Research Thoughts",
      "citationCount": 27,
      "score": 6.75,
      "summary": "The integration of Artificial Intelligence (AI) into mobile applications has significantly advanced the capabilities of modern software, enhancing user experiences through personalized, intelligent interactions. The effective use of AI-driven third-party frameworks has emerged as a pivotal strategy for developers aiming to leverage AI's potential without the need for extensive in-house expertise. This paper explores the impact and benefits of incorporating AI-driven third-party frameworks into mobile app development, focusing on their role in optimizing performance, enhancing user engagement, and accelerating development cycles. \nAI-driven third-party frameworks offer a range of pre-built functionalities, including natural language processing (NLP), image recognition, and predictive analytics, which can be seamlessly integrated into mobile applications. These frameworks provide developers with powerful tools to implement advanced features with reduced time and resource investment. By utilizing these frameworks, developers can focus on core application functionalities while benefiting from sophisticated AI capabilities that would otherwise require significant development effort.",
      "keywords": []
    },
    "file_name": "8f4d78fc1f6a52f28a1d7abf3bfd0b89d1fca737.pdf"
  },
  {
    "success": true,
    "doc_id": "429c2bb8a878f5c4a2a9fc76efbc8a99",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8ec04edd745b964fb7ea31d07b6cefb4cbf91876.pdf",
    "citation_key": "correa20221nw",
    "metadata": {
      "title": "A Systematic Review of ‘Fair’ AI Model Development for Image Classification and Prediction",
      "authors": [
        "Ramon Correa",
        "M. Shaan",
        "H. Trivedi",
        "B. Patel",
        "L. Celi",
        "J. Gichoya",
        "I. Banerjee"
      ],
      "published_date": "2022",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8ec04edd745b964fb7ea31d07b6cefb4cbf91876.pdf",
      "venue": "Journal of Medical and Biological Engineering",
      "citationCount": 20,
      "score": 6.666666666666666,
      "summary": "",
      "keywords": []
    },
    "file_name": "8ec04edd745b964fb7ea31d07b6cefb4cbf91876.pdf"
  },
  {
    "success": true,
    "doc_id": "2db7cf2fafd00a9a6a2337b5a568e7b4",
    "summary": "Autonomous systems are gaining momentum in various application domains, such as autonomous vehicles, autonomous transport robotics and self-adaptation in smart homes. Product liability regulations impose high standards on manufacturers of such systems with respect to dependability (safety, security and privacy). Today’s conventional engineering methods are not adequate for providing guarantees with respect to dependability requirements in a costefficient manner, e.g. road tests in the automotive industry sum up millions of miles before a system can be considered sufficiently safe. System engineers will no longer be able to test and respectively formally verify autonomous systems during development time in order to guarantee the dependability requirements in advance. In this vision paper, we introduce a new holistic software systems engineering approach for autonomous systems, which integrates development time methods as well as operation time techniques. With this approach, we aim to give the users a transparent view of the confidence level of the autonomous system under use with respect to the dependability requirements. We present already obtained results and point out research goals to be addressed in the future.",
    "intriguing_abstract": "Autonomous systems are gaining momentum in various application domains, such as autonomous vehicles, autonomous transport robotics and self-adaptation in smart homes. Product liability regulations impose high standards on manufacturers of such systems with respect to dependability (safety, security and privacy). Today’s conventional engineering methods are not adequate for providing guarantees with respect to dependability requirements in a costefficient manner, e.g. road tests in the automotive industry sum up millions of miles before a system can be considered sufficiently safe. System engineers will no longer be able to test and respectively formally verify autonomous systems during development time in order to guarantee the dependability requirements in advance. In this vision paper, we introduce a new holistic software systems engineering approach for autonomous systems, which integrates development time methods as well as operation time techniques. With this approach, we aim to give the users a transparent view of the confidence level of the autonomous system under use with respect to the dependability requirements. We present already obtained results and point out research goals to be addressed in the future.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9fa595746be376abd0a63a4b8dd9c8d9fba4bd2f.pdf",
    "citation_key": "aniculaesei2018tuz",
    "metadata": {
      "title": "Toward a Holistic Software Systems Engineering Approach for Dependable Autonomous Systems",
      "authors": [
        "Adina Aniculaesei",
        "Jörg Grieser",
        "A. Rausch",
        "Karina Rehfeldt",
        "Tim Warnecke"
      ],
      "published_date": "2018",
      "abstract": "Autonomous systems are gaining momentum in various application domains, such as autonomous vehicles, autonomous transport robotics and self-adaptation in smart homes. Product liability regulations impose high standards on manufacturers of such systems with respect to dependability (safety, security and privacy). Today’s conventional engineering methods are not adequate for providing guarantees with respect to dependability requirements in a costefficient manner, e.g. road tests in the automotive industry sum up millions of miles before a system can be considered sufficiently safe. System engineers will no longer be able to test and respectively formally verify autonomous systems during development time in order to guarantee the dependability requirements in advance. In this vision paper, we introduce a new holistic software systems engineering approach for autonomous systems, which integrates development time methods as well as operation time techniques. With this approach, we aim to give the users a transparent view of the confidence level of the autonomous system under use with respect to the dependability requirements. We present already obtained results and point out research goals to be addressed in the future.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9fa595746be376abd0a63a4b8dd9c8d9fba4bd2f.pdf",
      "venue": "2018 IEEE/ACM 1st International Workshop on Software Engineering for AI in Autonomous Systems (SEFAIAS)",
      "citationCount": 45,
      "score": 6.428571428571428,
      "summary": "Autonomous systems are gaining momentum in various application domains, such as autonomous vehicles, autonomous transport robotics and self-adaptation in smart homes. Product liability regulations impose high standards on manufacturers of such systems with respect to dependability (safety, security and privacy). Today’s conventional engineering methods are not adequate for providing guarantees with respect to dependability requirements in a costefficient manner, e.g. road tests in the automotive industry sum up millions of miles before a system can be considered sufficiently safe. System engineers will no longer be able to test and respectively formally verify autonomous systems during development time in order to guarantee the dependability requirements in advance. In this vision paper, we introduce a new holistic software systems engineering approach for autonomous systems, which integrates development time methods as well as operation time techniques. With this approach, we aim to give the users a transparent view of the confidence level of the autonomous system under use with respect to the dependability requirements. We present already obtained results and point out research goals to be addressed in the future.",
      "keywords": []
    },
    "file_name": "9fa595746be376abd0a63a4b8dd9c8d9fba4bd2f.pdf"
  },
  {
    "success": true,
    "doc_id": "2c52b7c0a80aea3b4ab51ca2b77f9e79",
    "summary": "The dynamic nature of AI technologies makes testing human-AI interaction and collaboration challenging – especially before such features are deployed in the wild. This presents a challenge for designers and AI practitioners as early feedback for iteration is often unavailable in the development phase. In this paper, we take inspiration from integration testing concepts in software development and present HINT (Human-AI INtegration Testing), a crowd-based framework for testing AI-based experiences integrated with a humans-in-the-loop workflow. HINT supports early testing of AI-based features within the context of realistic user tasks and makes use of successive sessions to simulate AI experiences that evolve over-time. Finally, it provides practitioners with reports to evaluate and compare aspects of these experiences. Through a crowd-based study, we demonstrate the need for over-time testing where user behaviors evolve as they interact with an AI system. We also show that HINT is able to capture and reveal these distinct user behavior patterns across a variety of common AI performance modalities using two AI-based feature prototypes. We further evaluated HINT’s potential to support practitioners’ evaluation of human-AI interaction experiences pre-deployment through semi-structured interviews with 13 practitioners.",
    "intriguing_abstract": "The dynamic nature of AI technologies makes testing human-AI interaction and collaboration challenging – especially before such features are deployed in the wild. This presents a challenge for designers and AI practitioners as early feedback for iteration is often unavailable in the development phase. In this paper, we take inspiration from integration testing concepts in software development and present HINT (Human-AI INtegration Testing), a crowd-based framework for testing AI-based experiences integrated with a humans-in-the-loop workflow. HINT supports early testing of AI-based features within the context of realistic user tasks and makes use of successive sessions to simulate AI experiences that evolve over-time. Finally, it provides practitioners with reports to evaluate and compare aspects of these experiences. Through a crowd-based study, we demonstrate the need for over-time testing where user behaviors evolve as they interact with an AI system. We also show that HINT is able to capture and reveal these distinct user behavior patterns across a variety of common AI performance modalities using two AI-based feature prototypes. We further evaluated HINT’s potential to support practitioners’ evaluation of human-AI interaction experiences pre-deployment through semi-structured interviews with 13 practitioners.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2ff388eb4516519660eb9b4a006f90ed4d67c40b.pdf",
    "citation_key": "chen2022j8e",
    "metadata": {
      "title": "HINT: Integration Testing for AI-based features with Humans in the Loop",
      "authors": [
        "Quan Ze Chen",
        "Tobias Schnabel",
        "Besmira Nushi",
        "Saleema Amershi"
      ],
      "published_date": "2022",
      "abstract": "The dynamic nature of AI technologies makes testing human-AI interaction and collaboration challenging – especially before such features are deployed in the wild. This presents a challenge for designers and AI practitioners as early feedback for iteration is often unavailable in the development phase. In this paper, we take inspiration from integration testing concepts in software development and present HINT (Human-AI INtegration Testing), a crowd-based framework for testing AI-based experiences integrated with a humans-in-the-loop workflow. HINT supports early testing of AI-based features within the context of realistic user tasks and makes use of successive sessions to simulate AI experiences that evolve over-time. Finally, it provides practitioners with reports to evaluate and compare aspects of these experiences. Through a crowd-based study, we demonstrate the need for over-time testing where user behaviors evolve as they interact with an AI system. We also show that HINT is able to capture and reveal these distinct user behavior patterns across a variety of common AI performance modalities using two AI-based feature prototypes. We further evaluated HINT’s potential to support practitioners’ evaluation of human-AI interaction experiences pre-deployment through semi-structured interviews with 13 practitioners.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2ff388eb4516519660eb9b4a006f90ed4d67c40b.pdf",
      "venue": "International Conference on Intelligent User Interfaces",
      "citationCount": 19,
      "score": 6.333333333333333,
      "summary": "The dynamic nature of AI technologies makes testing human-AI interaction and collaboration challenging – especially before such features are deployed in the wild. This presents a challenge for designers and AI practitioners as early feedback for iteration is often unavailable in the development phase. In this paper, we take inspiration from integration testing concepts in software development and present HINT (Human-AI INtegration Testing), a crowd-based framework for testing AI-based experiences integrated with a humans-in-the-loop workflow. HINT supports early testing of AI-based features within the context of realistic user tasks and makes use of successive sessions to simulate AI experiences that evolve over-time. Finally, it provides practitioners with reports to evaluate and compare aspects of these experiences. Through a crowd-based study, we demonstrate the need for over-time testing where user behaviors evolve as they interact with an AI system. We also show that HINT is able to capture and reveal these distinct user behavior patterns across a variety of common AI performance modalities using two AI-based feature prototypes. We further evaluated HINT’s potential to support practitioners’ evaluation of human-AI interaction experiences pre-deployment through semi-structured interviews with 13 practitioners.",
      "keywords": []
    },
    "file_name": "2ff388eb4516519660eb9b4a006f90ed4d67c40b.pdf"
  },
  {
    "success": true,
    "doc_id": "315eb46f06d00b1e966d929b47c88abe",
    "summary": "Recently, the job market for Artificial Intelligence (AI) engineers has exploded. Since the role of AI engineer is relatively new, limited research has been done on the requirements as set by the industry. Moreover, the definition of an AI engineer is less established than for a data scientist or a software engineer. In this study we explore, based on job ads, the requirements from the job market for the position of AI engineer in The Netherlands. We retrieved job ad data between April 2018 and April 2021 from a large job ad database, Jobfeed from TextKernel. The job ads were selected with a process similar to the selection of primary studies in a literature review. We characterize the 367 resulting job ads based on meta-data such as publication date, industry/sector, educational background and job titles. To answer our research questions we have further coded 125 job ads manually. The job tasks of AI engineers are concentrated in five categories: business understanding, data engineering, modeling, software development and operations engineering. Companies ask for AI engineers with different profiles: 1) data science engineer with focus on modeling, 2) AI software engineer with focus on software development, 3) generalist AI engineer with focus on both models and software. Furthermore, we present the tools and technologies mentioned in the selected job ads, and the soft skills. Our research helps to understand the expectations companies have for professionals building AI-enabled systems. Understanding these expectations is crucial both for prospective AI engineers and educational institutions in charge of training those prospective engineers. Our research also helps to better define the profession of AI engineering. We do this by proposing an extended AI engineering life-cycle that includes a business understanding phase.",
    "intriguing_abstract": "Recently, the job market for Artificial Intelligence (AI) engineers has exploded. Since the role of AI engineer is relatively new, limited research has been done on the requirements as set by the industry. Moreover, the definition of an AI engineer is less established than for a data scientist or a software engineer. In this study we explore, based on job ads, the requirements from the job market for the position of AI engineer in The Netherlands. We retrieved job ad data between April 2018 and April 2021 from a large job ad database, Jobfeed from TextKernel. The job ads were selected with a process similar to the selection of primary studies in a literature review. We characterize the 367 resulting job ads based on meta-data such as publication date, industry/sector, educational background and job titles. To answer our research questions we have further coded 125 job ads manually. The job tasks of AI engineers are concentrated in five categories: business understanding, data engineering, modeling, software development and operations engineering. Companies ask for AI engineers with different profiles: 1) data science engineer with focus on modeling, 2) AI software engineer with focus on software development, 3) generalist AI engineer with focus on both models and software. Furthermore, we present the tools and technologies mentioned in the selected job ads, and the soft skills. Our research helps to understand the expectations companies have for professionals building AI-enabled systems. Understanding these expectations is crucial both for prospective AI engineers and educational institutions in charge of training those prospective engineers. Our research also helps to better define the profession of AI engineering. We do this by proposing an extended AI engineering life-cycle that includes a business understanding phase.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/848b49ca819d30943d36ac803f9275969f33f413.pdf",
    "citation_key": "meesters20225ep",
    "metadata": {
      "title": "What Is an AI Engineer? An Empirical Analysis of Job Ads in The Netherlands",
      "authors": [
        "M. Meesters",
        "P. Heck",
        "A. Serebrenik"
      ],
      "published_date": "2022",
      "abstract": "Recently, the job market for Artificial Intelligence (AI) engineers has exploded. Since the role of AI engineer is relatively new, limited research has been done on the requirements as set by the industry. Moreover, the definition of an AI engineer is less established than for a data scientist or a software engineer. In this study we explore, based on job ads, the requirements from the job market for the position of AI engineer in The Netherlands. We retrieved job ad data between April 2018 and April 2021 from a large job ad database, Jobfeed from TextKernel. The job ads were selected with a process similar to the selection of primary studies in a literature review. We characterize the 367 resulting job ads based on meta-data such as publication date, industry/sector, educational background and job titles. To answer our research questions we have further coded 125 job ads manually. The job tasks of AI engineers are concentrated in five categories: business understanding, data engineering, modeling, software development and operations engineering. Companies ask for AI engineers with different profiles: 1) data science engineer with focus on modeling, 2) AI software engineer with focus on software development, 3) generalist AI engineer with focus on both models and software. Furthermore, we present the tools and technologies mentioned in the selected job ads, and the soft skills. Our research helps to understand the expectations companies have for professionals building AI-enabled systems. Understanding these expectations is crucial both for prospective AI engineers and educational institutions in charge of training those prospective engineers. Our research also helps to better define the profession of AI engineering. We do this by proposing an extended AI engineering life-cycle that includes a business understanding phase.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/848b49ca819d30943d36ac803f9275969f33f413.pdf",
      "venue": "2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN)",
      "citationCount": 19,
      "score": 6.333333333333333,
      "summary": "Recently, the job market for Artificial Intelligence (AI) engineers has exploded. Since the role of AI engineer is relatively new, limited research has been done on the requirements as set by the industry. Moreover, the definition of an AI engineer is less established than for a data scientist or a software engineer. In this study we explore, based on job ads, the requirements from the job market for the position of AI engineer in The Netherlands. We retrieved job ad data between April 2018 and April 2021 from a large job ad database, Jobfeed from TextKernel. The job ads were selected with a process similar to the selection of primary studies in a literature review. We characterize the 367 resulting job ads based on meta-data such as publication date, industry/sector, educational background and job titles. To answer our research questions we have further coded 125 job ads manually. The job tasks of AI engineers are concentrated in five categories: business understanding, data engineering, modeling, software development and operations engineering. Companies ask for AI engineers with different profiles: 1) data science engineer with focus on modeling, 2) AI software engineer with focus on software development, 3) generalist AI engineer with focus on both models and software. Furthermore, we present the tools and technologies mentioned in the selected job ads, and the soft skills. Our research helps to understand the expectations companies have for professionals building AI-enabled systems. Understanding these expectations is crucial both for prospective AI engineers and educational institutions in charge of training those prospective engineers. Our research also helps to better define the profession of AI engineering. We do this by proposing an extended AI engineering life-cycle that includes a business understanding phase.",
      "keywords": []
    },
    "file_name": "848b49ca819d30943d36ac803f9275969f33f413.pdf"
  },
  {
    "success": true,
    "doc_id": "ff4ea223681d571131c82315ba902054",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a38d746fe37963c43c0a560cc3d13fcefd515ff0.pdf",
    "citation_key": "bosch20185z7",
    "metadata": {
      "title": "It takes three to tango: Requirement, outcome/data, and AI driven development",
      "authors": [
        "J. Bosch",
        "H. H. Olsson",
        "I. Crnkovic"
      ],
      "published_date": "2018",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a38d746fe37963c43c0a560cc3d13fcefd515ff0.pdf",
      "venue": "Workshop on Software-intensive Business",
      "citationCount": 44,
      "score": 6.285714285714286,
      "summary": "",
      "keywords": []
    },
    "file_name": "a38d746fe37963c43c0a560cc3d13fcefd515ff0.pdf"
  },
  {
    "success": true,
    "doc_id": "d94814f6d8a96bea5cd2e111c94fa19d",
    "summary": "Self-Driving cars is a fast-growing area of study both in academia and industry. It is part of a broader domain which involves the development of software for Highly Automated Vehicles (HAV) and notions extracted from Artificial Intelligence/Autonomous Systems (AI/AS). There are many challenges that must be overcome to deliver self-driving cars in a manner that is readily accepted by consumers and society. Studies have shown that although many people are comfortable with the idea of AI helping them to operate their houses or schedule appointments, not many people are comfortable with the idea of cars being driven by AI algorithms. At the same time, insurance companies are concerned about vehicle liability issues and how to demonstrate who/what caused an accident. We believe that self-driving cars that demonstrate transparency in their operations will increase consumer trust which is pivotal to its acceptance and will pave the way for its commercialization and daily use. In this work, we investigate how to pursue the elicitation and modeling of transparency as a Non-Functional Requirement (NFR) to produce self-driving cars that are more robust.",
    "intriguing_abstract": "Self-Driving cars is a fast-growing area of study both in academia and industry. It is part of a broader domain which involves the development of software for Highly Automated Vehicles (HAV) and notions extracted from Artificial Intelligence/Autonomous Systems (AI/AS). There are many challenges that must be overcome to deliver self-driving cars in a manner that is readily accepted by consumers and society. Studies have shown that although many people are comfortable with the idea of AI helping them to operate their houses or schedule appointments, not many people are comfortable with the idea of cars being driven by AI algorithms. At the same time, insurance companies are concerned about vehicle liability issues and how to demonstrate who/what caused an accident. We believe that self-driving cars that demonstrate transparency in their operations will increase consumer trust which is pivotal to its acceptance and will pave the way for its commercialization and daily use. In this work, we investigate how to pursue the elicitation and modeling of transparency as a Non-Functional Requirement (NFR) to produce self-driving cars that are more robust.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d36c958ee9615f3f28f09e2f17e71dbd663793af.pdf",
    "citation_key": "cysneiros2018rsq",
    "metadata": {
      "title": "Software Transparency as a Key Requirement for Self-Driving Cars",
      "authors": [
        "L. M. Cysneiros",
        "Majid Raffi",
        "Julio Cesar Sampaio do Prado Leite"
      ],
      "published_date": "2018",
      "abstract": "Self-Driving cars is a fast-growing area of study both in academia and industry. It is part of a broader domain which involves the development of software for Highly Automated Vehicles (HAV) and notions extracted from Artificial Intelligence/Autonomous Systems (AI/AS). There are many challenges that must be overcome to deliver self-driving cars in a manner that is readily accepted by consumers and society. Studies have shown that although many people are comfortable with the idea of AI helping them to operate their houses or schedule appointments, not many people are comfortable with the idea of cars being driven by AI algorithms. At the same time, insurance companies are concerned about vehicle liability issues and how to demonstrate who/what caused an accident. We believe that self-driving cars that demonstrate transparency in their operations will increase consumer trust which is pivotal to its acceptance and will pave the way for its commercialization and daily use. In this work, we investigate how to pursue the elicitation and modeling of transparency as a Non-Functional Requirement (NFR) to produce self-driving cars that are more robust.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d36c958ee9615f3f28f09e2f17e71dbd663793af.pdf",
      "venue": "IEEE International Requirements Engineering Conference",
      "citationCount": 43,
      "score": 6.142857142857142,
      "summary": "Self-Driving cars is a fast-growing area of study both in academia and industry. It is part of a broader domain which involves the development of software for Highly Automated Vehicles (HAV) and notions extracted from Artificial Intelligence/Autonomous Systems (AI/AS). There are many challenges that must be overcome to deliver self-driving cars in a manner that is readily accepted by consumers and society. Studies have shown that although many people are comfortable with the idea of AI helping them to operate their houses or schedule appointments, not many people are comfortable with the idea of cars being driven by AI algorithms. At the same time, insurance companies are concerned about vehicle liability issues and how to demonstrate who/what caused an accident. We believe that self-driving cars that demonstrate transparency in their operations will increase consumer trust which is pivotal to its acceptance and will pave the way for its commercialization and daily use. In this work, we investigate how to pursue the elicitation and modeling of transparency as a Non-Functional Requirement (NFR) to produce self-driving cars that are more robust.",
      "keywords": []
    },
    "file_name": "d36c958ee9615f3f28f09e2f17e71dbd663793af.pdf"
  },
  {
    "success": true,
    "doc_id": "de70e097331b6bf5c9bc24a218cffe3e",
    "summary": "Using artificial intelligence (AI) based software defect prediction (SDP) techniques in the software development process helps isolate defective software modules, count the number of software defects, and identify risky code changes. However, software development teams are unaware of SDP and do not have easy access to relevant models and techniques. The major reason for this problem seems to be the fragmentation of SDP research and SDP practice. To unify SDP research and practice this article introduces a cloud-based, global, unified AI framework for SDP called DePaaS—Defects Prediction as a Service. The article describes the usage context, use cases and detailed architecture of DePaaS and presents the first response of the industry practitioners to DePaaS. In a first of its kind survey, the article captures practitioner’s belief into SDP and ability of DePaaS to solve some of the known challenges of the field of software defect prediction. This article also provides a novel process for SDP, detailed description of the structure and behaviour of DePaaS architecture components, six best SDP models offered by DePaaS, a description of algorithms that recommend SDP models, feature sets and tunable parameters, and a rich set of challenges to build, use and sustain DePaaS. With the contributions of this article, SDP research and practice could be unified enabling building and using more pragmatic defect prediction models leading to increase in the efficiency of software testing.",
    "intriguing_abstract": "Using artificial intelligence (AI) based software defect prediction (SDP) techniques in the software development process helps isolate defective software modules, count the number of software defects, and identify risky code changes. However, software development teams are unaware of SDP and do not have easy access to relevant models and techniques. The major reason for this problem seems to be the fragmentation of SDP research and SDP practice. To unify SDP research and practice this article introduces a cloud-based, global, unified AI framework for SDP called DePaaS—Defects Prediction as a Service. The article describes the usage context, use cases and detailed architecture of DePaaS and presents the first response of the industry practitioners to DePaaS. In a first of its kind survey, the article captures practitioner’s belief into SDP and ability of DePaaS to solve some of the known challenges of the field of software defect prediction. This article also provides a novel process for SDP, detailed description of the structure and behaviour of DePaaS architecture components, six best SDP models offered by DePaaS, a description of algorithms that recommend SDP models, feature sets and tunable parameters, and a rich set of challenges to build, use and sustain DePaaS. With the contributions of this article, SDP research and practice could be unified enabling building and using more pragmatic defect prediction models leading to increase in the efficiency of software testing.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a65b105907ce91721355968da494b4ddb1347751.pdf",
    "citation_key": "pandit2022w11",
    "metadata": {
      "title": "Towards Design and Feasibility Analysis of DePaaS: AI Based Global Unified Software Defect Prediction Framework",
      "authors": [
        "Mahesha Pandit",
        "Deepali Gupta",
        "Divya Anand",
        "Nitin Goyal",
        "H. Aljahdali",
        "A. Mansilla",
        "Seifedien Kadry",
        "Arun Kumar"
      ],
      "published_date": "2022",
      "abstract": "Using artificial intelligence (AI) based software defect prediction (SDP) techniques in the software development process helps isolate defective software modules, count the number of software defects, and identify risky code changes. However, software development teams are unaware of SDP and do not have easy access to relevant models and techniques. The major reason for this problem seems to be the fragmentation of SDP research and SDP practice. To unify SDP research and practice this article introduces a cloud-based, global, unified AI framework for SDP called DePaaS—Defects Prediction as a Service. The article describes the usage context, use cases and detailed architecture of DePaaS and presents the first response of the industry practitioners to DePaaS. In a first of its kind survey, the article captures practitioner’s belief into SDP and ability of DePaaS to solve some of the known challenges of the field of software defect prediction. This article also provides a novel process for SDP, detailed description of the structure and behaviour of DePaaS architecture components, six best SDP models offered by DePaaS, a description of algorithms that recommend SDP models, feature sets and tunable parameters, and a rich set of challenges to build, use and sustain DePaaS. With the contributions of this article, SDP research and practice could be unified enabling building and using more pragmatic defect prediction models leading to increase in the efficiency of software testing.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a65b105907ce91721355968da494b4ddb1347751.pdf",
      "venue": "Applied Sciences",
      "citationCount": 18,
      "score": 6.0,
      "summary": "Using artificial intelligence (AI) based software defect prediction (SDP) techniques in the software development process helps isolate defective software modules, count the number of software defects, and identify risky code changes. However, software development teams are unaware of SDP and do not have easy access to relevant models and techniques. The major reason for this problem seems to be the fragmentation of SDP research and SDP practice. To unify SDP research and practice this article introduces a cloud-based, global, unified AI framework for SDP called DePaaS—Defects Prediction as a Service. The article describes the usage context, use cases and detailed architecture of DePaaS and presents the first response of the industry practitioners to DePaaS. In a first of its kind survey, the article captures practitioner’s belief into SDP and ability of DePaaS to solve some of the known challenges of the field of software defect prediction. This article also provides a novel process for SDP, detailed description of the structure and behaviour of DePaaS architecture components, six best SDP models offered by DePaaS, a description of algorithms that recommend SDP models, feature sets and tunable parameters, and a rich set of challenges to build, use and sustain DePaaS. With the contributions of this article, SDP research and practice could be unified enabling building and using more pragmatic defect prediction models leading to increase in the efficiency of software testing.",
      "keywords": []
    },
    "file_name": "a65b105907ce91721355968da494b4ddb1347751.pdf"
  },
  {
    "success": true,
    "doc_id": "ee3fc3a37c12d8afc07ed569fb070278",
    "summary": "Requirements Engineering (RE) is a very important activity in the software development life cycle. Poorly executed RE steps can result in poor quality software and expensive maintenance cost. Although researchers have previously related and applied artificial intelligence (AI) to RE, little is known about the specific role of AI in RE process. In particular, there are insufficient understandings about how AI should be incorporated in the RE process to produce high quality, clear and detailed requirements. In this paper, we present the current state-of-the-art of AI in RE. We reviewed the literature published between January 2015 to December 2021 in order to understand how the state of the art of AI branches such as machine learning, classification, and natural language processing (NLP) has advanced the field of RE. Each recent study is summarized and the advancement to the RE field is presented. There is an apparent direction of applying NLP techniques and supervised learning techniques such as classification to requirements documents. This study provides a summary and direction of the AI applications in the field of RE.",
    "intriguing_abstract": "Requirements Engineering (RE) is a very important activity in the software development life cycle. Poorly executed RE steps can result in poor quality software and expensive maintenance cost. Although researchers have previously related and applied artificial intelligence (AI) to RE, little is known about the specific role of AI in RE process. In particular, there are insufficient understandings about how AI should be incorporated in the RE process to produce high quality, clear and detailed requirements. In this paper, we present the current state-of-the-art of AI in RE. We reviewed the literature published between January 2015 to December 2021 in order to understand how the state of the art of AI branches such as machine learning, classification, and natural language processing (NLP) has advanced the field of RE. Each recent study is summarized and the advancement to the RE field is presented. There is an apparent direction of applying NLP techniques and supervised learning techniques such as classification to requirements documents. This study provides a summary and direction of the AI applications in the field of RE.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9644a2716a1be2562f1bb8f4d7929871050dd8cd.pdf",
    "citation_key": "liu2022g3w",
    "metadata": {
      "title": "Artificial Intelligence in Software Requirements Engineering: State-of-the-Art",
      "authors": [
        "Kaihua Liu",
        "S. Reddivari",
        "Kalyan Reddivari"
      ],
      "published_date": "2022",
      "abstract": "Requirements Engineering (RE) is a very important activity in the software development life cycle. Poorly executed RE steps can result in poor quality software and expensive maintenance cost. Although researchers have previously related and applied artificial intelligence (AI) to RE, little is known about the specific role of AI in RE process. In particular, there are insufficient understandings about how AI should be incorporated in the RE process to produce high quality, clear and detailed requirements. In this paper, we present the current state-of-the-art of AI in RE. We reviewed the literature published between January 2015 to December 2021 in order to understand how the state of the art of AI branches such as machine learning, classification, and natural language processing (NLP) has advanced the field of RE. Each recent study is summarized and the advancement to the RE field is presented. There is an apparent direction of applying NLP techniques and supervised learning techniques such as classification to requirements documents. This study provides a summary and direction of the AI applications in the field of RE.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9644a2716a1be2562f1bb8f4d7929871050dd8cd.pdf",
      "venue": "IEEE International Conference on Information Reuse and Integration",
      "citationCount": 18,
      "score": 6.0,
      "summary": "Requirements Engineering (RE) is a very important activity in the software development life cycle. Poorly executed RE steps can result in poor quality software and expensive maintenance cost. Although researchers have previously related and applied artificial intelligence (AI) to RE, little is known about the specific role of AI in RE process. In particular, there are insufficient understandings about how AI should be incorporated in the RE process to produce high quality, clear and detailed requirements. In this paper, we present the current state-of-the-art of AI in RE. We reviewed the literature published between January 2015 to December 2021 in order to understand how the state of the art of AI branches such as machine learning, classification, and natural language processing (NLP) has advanced the field of RE. Each recent study is summarized and the advancement to the RE field is presented. There is an apparent direction of applying NLP techniques and supervised learning techniques such as classification to requirements documents. This study provides a summary and direction of the AI applications in the field of RE.",
      "keywords": []
    },
    "file_name": "9644a2716a1be2562f1bb8f4d7929871050dd8cd.pdf"
  },
  {
    "success": true,
    "doc_id": "db4eb983f3bcd61cfa5b2e8e5d05e414",
    "summary": "ABSTRACT An essential attribute of software quality is software reliability. To achieve higher reliability, the testing phase with detected and corrected flaws is incorporated in the software development. The fault correction process (FCP) includes the fault detection process (FDP) to develop the software reliability growth model (SRGM). This is difficult to integrate because due to several reasons, including the effects of staffing levels and the interdependence of faults. It limits the applicability of the analytical model. Because of the adoption of data-driven methodologies such as Artificial Intelligence (AI) technology, no precise FCP and FDP assumptions are necessary. In this article, we proposed a hybrid long short-term memory (LSTM) with BrainStorm Optimization and Late Acceptance Hill Climbing (BSO-LAHC) algorithm of a stepwise prediction model for software fault detection and correction. The fault detection and correction procedure has great influence by considering the testing effort. While compared to the existing methods, the proposed hybrid with the BSO-LAHC algorithm demonstrated superior results by using Firefox and bug tracking system Bugzilla datasets. The proposed model’s effectiveness is confirmed via empirical study. Based on the Bugzilla and firefox datasets, the proposed mean square error performance is 1.92 and 21.44 respectively. Additionally, the proposed method is less expensive and takes less time to execute. In Bugzilla version 5.0.4, releases 2 and 3 had a determination coefficient of 99.2% and 98.9%, respectively. The FCP is 27% more effective than previous approaches, and the FDP is 32% more effective.",
    "intriguing_abstract": "ABSTRACT An essential attribute of software quality is software reliability. To achieve higher reliability, the testing phase with detected and corrected flaws is incorporated in the software development. The fault correction process (FCP) includes the fault detection process (FDP) to develop the software reliability growth model (SRGM). This is difficult to integrate because due to several reasons, including the effects of staffing levels and the interdependence of faults. It limits the applicability of the analytical model. Because of the adoption of data-driven methodologies such as Artificial Intelligence (AI) technology, no precise FCP and FDP assumptions are necessary. In this article, we proposed a hybrid long short-term memory (LSTM) with BrainStorm Optimization and Late Acceptance Hill Climbing (BSO-LAHC) algorithm of a stepwise prediction model for software fault detection and correction. The fault detection and correction procedure has great influence by considering the testing effort. While compared to the existing methods, the proposed hybrid with the BSO-LAHC algorithm demonstrated superior results by using Firefox and bug tracking system Bugzilla datasets. The proposed model’s effectiveness is confirmed via empirical study. Based on the Bugzilla and firefox datasets, the proposed mean square error performance is 1.92 and 21.44 respectively. Additionally, the proposed method is less expensive and takes less time to execute. In Bugzilla version 5.0.4, releases 2 and 3 had a determination coefficient of 99.2% and 98.9%, respectively. The FCP is 27% more effective than previous approaches, and the FDP is 32% more effective.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/bd8c8339448f4413b4e580ad7810d501512c69bb.pdf",
    "citation_key": "raamesh2022qhp",
    "metadata": {
      "title": "Enhancing Software Reliability and Fault Detection Using Hybrid Brainstorm Optimization-Based LSTM Model",
      "authors": [
        "L. Raamesh",
        "S. Jothi",
        "S. Radhika"
      ],
      "published_date": "2022",
      "abstract": "ABSTRACT An essential attribute of software quality is software reliability. To achieve higher reliability, the testing phase with detected and corrected flaws is incorporated in the software development. The fault correction process (FCP) includes the fault detection process (FDP) to develop the software reliability growth model (SRGM). This is difficult to integrate because due to several reasons, including the effects of staffing levels and the interdependence of faults. It limits the applicability of the analytical model. Because of the adoption of data-driven methodologies such as Artificial Intelligence (AI) technology, no precise FCP and FDP assumptions are necessary. In this article, we proposed a hybrid long short-term memory (LSTM) with BrainStorm Optimization and Late Acceptance Hill Climbing (BSO-LAHC) algorithm of a stepwise prediction model for software fault detection and correction. The fault detection and correction procedure has great influence by considering the testing effort. While compared to the existing methods, the proposed hybrid with the BSO-LAHC algorithm demonstrated superior results by using Firefox and bug tracking system Bugzilla datasets. The proposed model’s effectiveness is confirmed via empirical study. Based on the Bugzilla and firefox datasets, the proposed mean square error performance is 1.92 and 21.44 respectively. Additionally, the proposed method is less expensive and takes less time to execute. In Bugzilla version 5.0.4, releases 2 and 3 had a determination coefficient of 99.2% and 98.9%, respectively. The FCP is 27% more effective than previous approaches, and the FDP is 32% more effective.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/bd8c8339448f4413b4e580ad7810d501512c69bb.pdf",
      "venue": "Journal of the Institution of Electronics and Telecommunication Engineers",
      "citationCount": 18,
      "score": 6.0,
      "summary": "ABSTRACT An essential attribute of software quality is software reliability. To achieve higher reliability, the testing phase with detected and corrected flaws is incorporated in the software development. The fault correction process (FCP) includes the fault detection process (FDP) to develop the software reliability growth model (SRGM). This is difficult to integrate because due to several reasons, including the effects of staffing levels and the interdependence of faults. It limits the applicability of the analytical model. Because of the adoption of data-driven methodologies such as Artificial Intelligence (AI) technology, no precise FCP and FDP assumptions are necessary. In this article, we proposed a hybrid long short-term memory (LSTM) with BrainStorm Optimization and Late Acceptance Hill Climbing (BSO-LAHC) algorithm of a stepwise prediction model for software fault detection and correction. The fault detection and correction procedure has great influence by considering the testing effort. While compared to the existing methods, the proposed hybrid with the BSO-LAHC algorithm demonstrated superior results by using Firefox and bug tracking system Bugzilla datasets. The proposed model’s effectiveness is confirmed via empirical study. Based on the Bugzilla and firefox datasets, the proposed mean square error performance is 1.92 and 21.44 respectively. Additionally, the proposed method is less expensive and takes less time to execute. In Bugzilla version 5.0.4, releases 2 and 3 had a determination coefficient of 99.2% and 98.9%, respectively. The FCP is 27% more effective than previous approaches, and the FDP is 32% more effective.",
      "keywords": []
    },
    "file_name": "bd8c8339448f4413b4e580ad7810d501512c69bb.pdf"
  },
  {
    "success": true,
    "doc_id": "403a4f9deb89b271cd4d1dec87784233",
    "summary": "The public and academic discussion on Artificial Intelligence (AI) ethics is accelerating and the general public is becoming more aware AI ethics issues such as data privacy in these systems. To guide ethical development of AI systems, governmental and institutional actors, as well as companies, have drafted various guidelines for ethical AI. Though these guidelines are becoming increasingly common, they have been criticized for a lack of impact on industrial practice. There seems to be a gap between research and practice in the area, though its exact nature remains unknown. In this paper, we present a gap analysis of the current state of the art by comparing practices of 39 companies that work with AI systems to the seven key requirements for trustworthy AI presented in the “The Ethics Guidelines for Trustworthy Artificial Intelligence”. The key finding of this paper is that there is indeed notable gap between AI ethics guidelines and practice. Especially practices considering the novel requirements for software development, requirements of societal and environmental well-being and diversity, nondiscrimination and fairness were not tackled by companies.",
    "intriguing_abstract": "The public and academic discussion on Artificial Intelligence (AI) ethics is accelerating and the general public is becoming more aware AI ethics issues such as data privacy in these systems. To guide ethical development of AI systems, governmental and institutional actors, as well as companies, have drafted various guidelines for ethical AI. Though these guidelines are becoming increasingly common, they have been criticized for a lack of impact on industrial practice. There seems to be a gap between research and practice in the area, though its exact nature remains unknown. In this paper, we present a gap analysis of the current state of the art by comparing practices of 39 companies that work with AI systems to the seven key requirements for trustworthy AI presented in the “The Ethics Guidelines for Trustworthy Artificial Intelligence”. The key finding of this paper is that there is indeed notable gap between AI ethics guidelines and practice. Especially practices considering the novel requirements for software development, requirements of societal and environmental well-being and diversity, nondiscrimination and fairness were not tackled by companies.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/13e1ea3c8cfd18b652e547ffc0ef8c7ad30403ae.pdf",
    "citation_key": "vakkuri2022wjr",
    "metadata": {
      "title": "How Do Software Companies Deal with Artificial Intelligence Ethics? A Gap Analysis",
      "authors": [
        "Ville Vakkuri",
        "Kai-Kristian Kemell",
        "Joel Tolvanen",
        "Marianna Jantunen",
        "Erika Halme",
        "P. Abrahamsson"
      ],
      "published_date": "2022",
      "abstract": "The public and academic discussion on Artificial Intelligence (AI) ethics is accelerating and the general public is becoming more aware AI ethics issues such as data privacy in these systems. To guide ethical development of AI systems, governmental and institutional actors, as well as companies, have drafted various guidelines for ethical AI. Though these guidelines are becoming increasingly common, they have been criticized for a lack of impact on industrial practice. There seems to be a gap between research and practice in the area, though its exact nature remains unknown. In this paper, we present a gap analysis of the current state of the art by comparing practices of 39 companies that work with AI systems to the seven key requirements for trustworthy AI presented in the “The Ethics Guidelines for Trustworthy Artificial Intelligence”. The key finding of this paper is that there is indeed notable gap between AI ethics guidelines and practice. Especially practices considering the novel requirements for software development, requirements of societal and environmental well-being and diversity, nondiscrimination and fairness were not tackled by companies.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/13e1ea3c8cfd18b652e547ffc0ef8c7ad30403ae.pdf",
      "venue": "International Conference on Evaluation & Assessment in Software Engineering",
      "citationCount": 18,
      "score": 6.0,
      "summary": "The public and academic discussion on Artificial Intelligence (AI) ethics is accelerating and the general public is becoming more aware AI ethics issues such as data privacy in these systems. To guide ethical development of AI systems, governmental and institutional actors, as well as companies, have drafted various guidelines for ethical AI. Though these guidelines are becoming increasingly common, they have been criticized for a lack of impact on industrial practice. There seems to be a gap between research and practice in the area, though its exact nature remains unknown. In this paper, we present a gap analysis of the current state of the art by comparing practices of 39 companies that work with AI systems to the seven key requirements for trustworthy AI presented in the “The Ethics Guidelines for Trustworthy Artificial Intelligence”. The key finding of this paper is that there is indeed notable gap between AI ethics guidelines and practice. Especially practices considering the novel requirements for software development, requirements of societal and environmental well-being and diversity, nondiscrimination and fairness were not tackled by companies.",
      "keywords": []
    },
    "file_name": "13e1ea3c8cfd18b652e547ffc0ef8c7ad30403ae.pdf"
  },
  {
    "success": true,
    "doc_id": "dd6dfca45c59dca8289af24af6c5f0a4",
    "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the growing complexity and challenges in developing **multiexperience User Interfaces (UIs)**, particularly those incorporating **AI-based Conversational User Interfaces (CUIs)** (e.g., chatbots, voicebots) alongside traditional Graphical User Interfaces (GUIs) \\cite{planas2021k3v}.\n    *   This problem is important because multiexperience UIs are becoming prevalent, offering integrated user experiences across various modalities (touch, voice, gesture) and devices \\cite{planas2021k3v}.\n    *   It is challenging because CUIs are often built as standalone, platform-dependent components using fragmented ecosystems of proprietary languages, libraries, and APIs \\cite{planas2021k3v}. This leads to significant integration, evolution, and maintenance issues, as their development is typically separated from the rest of the system \\cite{planas2021k3v}.\n\n*   **Related Work & Positioning**\n    *   The paper positions its work as a **model-driven approach** to address the limitations of current ad-hoc, fragmented, and platform-dependent methods for building multiexperience UIs \\cite{planas2021k3v}.\n    *   It acknowledges that while model-based philosophies are common for GUIs, dedicated methods for multiexperience UIs, especially CUIs, are missing \\cite{planas2021k3v}.\n    *   (Note: The specific content of Section 5, \"Related Work,\" was not provided in the input text, so a detailed comparison to existing model-driven approaches for UIs or CUI development tools cannot be extracted.)\n\n*   **Technical Approach & Innovation**\n    *   The core technical approach is the application of **Model-Driven Development (MDD)** techniques to raise the abstraction level for defining multiexperience UIs \\cite{planas2021k3v}.\n    *   The paper proposes a **new Domain Specific Language (DSL)** for specifying various types of CUIs \\cite{planas2021k3v}. This DSL is designed to be part of an integrated modeling environment that can describe interactions between CUIs, GUIs, and other software components.\n    *   The DSL's abstract syntax is defined through three metamodels:\n        *   **Intent Package Metamodel**: Describes concepts for modeling user intentions, including events, intents, training sentences, parameters, and entity types, generalizing primitives from major intent recognition platforms \\cite{planas2021k3v}.\n        *   **Behavioral Package Metamodel**: Reuses the **UML state-machine formalism** to define the execution logic and interaction flows of the bot, including states, transitions (automatic and guarded), actions, and fallback behaviors \\cite{planas2021k3v}.\n        *   **Runtime Package Metamodel**: Defines classes for the runtime execution of the bot, illustrating how user inputs (spoken, textual, gestural) are processed, translated to text, matched to intents, and parameters extracted \\cite{planas2021k3v}.\n    *   The approach also includes an **extension of the standard Interaction Flow Modeling Language (IFML)** to link multiexperience UIs with other software components \\cite{planas2021k3v}.\n\n*   **Key Technical Contributions**\n    *   A novel **Domain Specific Language (DSL)**, defined by comprehensive metamodels (Intent, Behavioral, Runtime packages), for abstractly specifying diverse CUIs, generalizing existing platform primitives \\cite{planas2021k3v}.\n    *   The adoption of **UML state-machine semantics** within the Behavioral Package Metamodel to facilitate the definition of complex conversational flows and bot behaviors \\cite{planas2021k3v}.\n    *   A conceptual framework for integrating CUI models with GUI models and other system components through an **extension of IFML**, enabling a holistic model-driven approach for multiexperience applications \\cite{planas2021k3v}.\n    *   A model-driven strategy to address the challenges of **integration, evolution, and maintenance** in multiexperience UI development by raising the abstraction level \\cite{planas2021k3v}.\n\n*   **Experimental Validation**\n    *   The paper illustrates its concepts using a **running case study: a weather forecast chatbot** \\cite{planas2021k3v}.\n    *   It provides examples of the **textual concrete syntax** for defining intents and state-machine transitions, based on the Xatkit platform \\cite{planas2021k3v}.\n    *   This validation serves as a **proof-of-concept and illustrative example** of how the proposed DSL and MDD approach can be applied, rather than a rigorous empirical evaluation with performance metrics or comparative studies. The authors provide a GitHub link for the complete syntax and instantiation of this example \\cite{planas2021k3v}.\n\n*   **Limitations & Scope**\n    *   The paper is an \"Expert Voice\" contribution, outlining a **\"towards\" approach**, indicating a conceptual proposal rather than a fully implemented and extensively validated system \\cite{planas2021k3v}.\n    *   It simplifies certain aspects, such as not explicitly modeling external AI libraries for speech/video-to-text translation, assuming these are handled internally to provide text for homogeneous CUI treatment \\cite{planas2021k3v}.\n    *   The scope primarily focuses on the **modeling aspects** of multiexperience UIs and their integration, rather than the underlying AI algorithms or the automated generation of production code from these models.\n    *   (Note: The content of Section 6, \"Further Work,\" which might detail explicit limitations, was not provided.)\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by proposing a **structured, model-driven methodology** for developing complex multiexperience AI-based UIs, moving beyond fragmented and ad-hoc development practices \\cite{planas2021k3v}.\n    *   It offers a foundational **DSL and metamodels** that can serve as a blueprint for future Multiexperience Development Platforms (MXDPs) and tools, addressing a critical gap in software engineering for emerging UI paradigms \\cite{planas2021k3v}.\n    *   By enabling the integrated specification of GUIs and CUIs, it facilitates the creation of **consistent and collaborative user experiences** across diverse interaction modalities, which is crucial for modern software systems \\cite{planas2021k3v}.\n    *   The approach has the potential to **reduce development time and costs**, improve maintainability, and enhance the integration capabilities of multiexperience applications by providing a higher level of abstraction \\cite{planas2021k3v}.",
    "intriguing_abstract": "Developing sophisticated multiexperience User Interfaces (UIs) that seamlessly integrate traditional Graphical UIs (GUIs) with AI-based Conversational UIs (CUIs) presents significant challenges in integration, evolution, and maintenance due to fragmented, platform-dependent development ecosystems. This paper introduces a novel Model-Driven Development (MDD) approach to elevate the abstraction level for designing such complex systems. We propose a new Domain Specific Language (DSL) specifically tailored for specifying diverse CUIs, defined through comprehensive metamodels: an Intent Package Metamodel for user intentions, a Behavioral Package Metamodel leveraging UML state-machine formalism for conversational flows, and a Runtime Package Metamodel for execution logic. Furthermore, we extend the Interaction Flow Modeling Language (IFML) to enable holistic integration of CUI models with GUI models and other software components. This structured methodology offers a foundational framework for future Multiexperience Development Platforms (MXDPs), promising to enhance consistency, reduce development overhead, and significantly improve the maintainability and evolution of integrated multiexperience applications.",
    "keywords": [
      "Multiexperience User Interfaces",
      "AI-based Conversational UIs",
      "Model-Driven Development (MDD)",
      "Domain Specific Language (DSL)",
      "CUI Metamodels",
      "UML state-machine semantics",
      "IFML extension",
      "Integrated modeling environment",
      "CUI/GUI integration",
      "Abstraction level",
      "Development challenges",
      "Structured methodology",
      "Multiexperience Development Platforms (MXDPs)"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d8f32d89af6284893c30611f51f1b01798849b26.pdf",
    "citation_key": "planas2021k3v",
    "metadata": {
      "title": "Towards a model-driven approach for multiexperience AI-based user interfaces",
      "authors": [
        "Elena Planas",
        "Gwendal Daniel",
        "Marco Brambilla",
        "Jordi Cabot"
      ],
      "published_date": "2021",
      "abstract": "Software systems start to include other types of interfaces beyond the “traditional” Graphical-User Interfaces (GUIs). In particular, Conversational User Interfaces (CUIs) such as chat and voice are becoming more and more popular. These new types of interfaces embed smart natural language processing components to understand user requests and respond to them. To provide an integrated user experience all the user interfaces in the system should be aware of each other and be able to collaborate. This is what is known as a multiexperience User Interface. Despite their many benefits, multiexperience UIs are challenging to build. So far CUIs are created as standalone components using a platform-dependent set of libraries and technologies. This raises significant integration, evolution and maintenance issues. This paper explores the application of model-driven techniques to the development of software applications embedding a multiexperience User Interface. We will discuss how raising the abstraction level at which these interfaces are defined enables a faster development and a better deployment and integration of each interface with the rest of the software system and the other interfaces with whom it may need to collaborate. In particular, we propose a new Domain Specific Language (DSL) for specifying several types of CUIs and show how this DSL can be part of an integrated modeling environment able to describe the interactions between the modeled CUIs and the other models of the system (including the models of the GUI). We will use the standard Interaction Flow Modeling Language (IFML) as an example “host” language.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d8f32d89af6284893c30611f51f1b01798849b26.pdf",
      "venue": "Journal of Software and Systems Modeling",
      "citationCount": 24,
      "score": 6.0,
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the growing complexity and challenges in developing **multiexperience User Interfaces (UIs)**, particularly those incorporating **AI-based Conversational User Interfaces (CUIs)** (e.g., chatbots, voicebots) alongside traditional Graphical User Interfaces (GUIs) \\cite{planas2021k3v}.\n    *   This problem is important because multiexperience UIs are becoming prevalent, offering integrated user experiences across various modalities (touch, voice, gesture) and devices \\cite{planas2021k3v}.\n    *   It is challenging because CUIs are often built as standalone, platform-dependent components using fragmented ecosystems of proprietary languages, libraries, and APIs \\cite{planas2021k3v}. This leads to significant integration, evolution, and maintenance issues, as their development is typically separated from the rest of the system \\cite{planas2021k3v}.\n\n*   **Related Work & Positioning**\n    *   The paper positions its work as a **model-driven approach** to address the limitations of current ad-hoc, fragmented, and platform-dependent methods for building multiexperience UIs \\cite{planas2021k3v}.\n    *   It acknowledges that while model-based philosophies are common for GUIs, dedicated methods for multiexperience UIs, especially CUIs, are missing \\cite{planas2021k3v}.\n    *   (Note: The specific content of Section 5, \"Related Work,\" was not provided in the input text, so a detailed comparison to existing model-driven approaches for UIs or CUI development tools cannot be extracted.)\n\n*   **Technical Approach & Innovation**\n    *   The core technical approach is the application of **Model-Driven Development (MDD)** techniques to raise the abstraction level for defining multiexperience UIs \\cite{planas2021k3v}.\n    *   The paper proposes a **new Domain Specific Language (DSL)** for specifying various types of CUIs \\cite{planas2021k3v}. This DSL is designed to be part of an integrated modeling environment that can describe interactions between CUIs, GUIs, and other software components.\n    *   The DSL's abstract syntax is defined through three metamodels:\n        *   **Intent Package Metamodel**: Describes concepts for modeling user intentions, including events, intents, training sentences, parameters, and entity types, generalizing primitives from major intent recognition platforms \\cite{planas2021k3v}.\n        *   **Behavioral Package Metamodel**: Reuses the **UML state-machine formalism** to define the execution logic and interaction flows of the bot, including states, transitions (automatic and guarded), actions, and fallback behaviors \\cite{planas2021k3v}.\n        *   **Runtime Package Metamodel**: Defines classes for the runtime execution of the bot, illustrating how user inputs (spoken, textual, gestural) are processed, translated to text, matched to intents, and parameters extracted \\cite{planas2021k3v}.\n    *   The approach also includes an **extension of the standard Interaction Flow Modeling Language (IFML)** to link multiexperience UIs with other software components \\cite{planas2021k3v}.\n\n*   **Key Technical Contributions**\n    *   A novel **Domain Specific Language (DSL)**, defined by comprehensive metamodels (Intent, Behavioral, Runtime packages), for abstractly specifying diverse CUIs, generalizing existing platform primitives \\cite{planas2021k3v}.\n    *   The adoption of **UML state-machine semantics** within the Behavioral Package Metamodel to facilitate the definition of complex conversational flows and bot behaviors \\cite{planas2021k3v}.\n    *   A conceptual framework for integrating CUI models with GUI models and other system components through an **extension of IFML**, enabling a holistic model-driven approach for multiexperience applications \\cite{planas2021k3v}.\n    *   A model-driven strategy to address the challenges of **integration, evolution, and maintenance** in multiexperience UI development by raising the abstraction level \\cite{planas2021k3v}.\n\n*   **Experimental Validation**\n    *   The paper illustrates its concepts using a **running case study: a weather forecast chatbot** \\cite{planas2021k3v}.\n    *   It provides examples of the **textual concrete syntax** for defining intents and state-machine transitions, based on the Xatkit platform \\cite{planas2021k3v}.\n    *   This validation serves as a **proof-of-concept and illustrative example** of how the proposed DSL and MDD approach can be applied, rather than a rigorous empirical evaluation with performance metrics or comparative studies. The authors provide a GitHub link for the complete syntax and instantiation of this example \\cite{planas2021k3v}.\n\n*   **Limitations & Scope**\n    *   The paper is an \"Expert Voice\" contribution, outlining a **\"towards\" approach**, indicating a conceptual proposal rather than a fully implemented and extensively validated system \\cite{planas2021k3v}.\n    *   It simplifies certain aspects, such as not explicitly modeling external AI libraries for speech/video-to-text translation, assuming these are handled internally to provide text for homogeneous CUI treatment \\cite{planas2021k3v}.\n    *   The scope primarily focuses on the **modeling aspects** of multiexperience UIs and their integration, rather than the underlying AI algorithms or the automated generation of production code from these models.\n    *   (Note: The content of Section 6, \"Further Work,\" which might detail explicit limitations, was not provided.)\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by proposing a **structured, model-driven methodology** for developing complex multiexperience AI-based UIs, moving beyond fragmented and ad-hoc development practices \\cite{planas2021k3v}.\n    *   It offers a foundational **DSL and metamodels** that can serve as a blueprint for future Multiexperience Development Platforms (MXDPs) and tools, addressing a critical gap in software engineering for emerging UI paradigms \\cite{planas2021k3v}.\n    *   By enabling the integrated specification of GUIs and CUIs, it facilitates the creation of **consistent and collaborative user experiences** across diverse interaction modalities, which is crucial for modern software systems \\cite{planas2021k3v}.\n    *   The approach has the potential to **reduce development time and costs**, improve maintainability, and enhance the integration capabilities of multiexperience applications by providing a higher level of abstraction \\cite{planas2021k3v}.",
      "keywords": [
        "Multiexperience User Interfaces",
        "AI-based Conversational UIs",
        "Model-Driven Development (MDD)",
        "Domain Specific Language (DSL)",
        "CUI Metamodels",
        "UML state-machine semantics",
        "IFML extension",
        "Integrated modeling environment",
        "CUI/GUI integration",
        "Abstraction level",
        "Development challenges",
        "Structured methodology",
        "Multiexperience Development Platforms (MXDPs)"
      ],
      "paper_type": "based on the abstract and introduction:\n\nthe abstract explicitly states: \"in particular, we **propose a new domain speciﬁc language (dsl)** for specifying several types of cuis and show how this dsl can be part of an integrated modeling environment...\" it also discusses applying \"model-driven techniques\" to address \"integration, evolution and maintenance issues\" in building multiexperience uis.\n\nthis aligns perfectly with the criteria for a **technical** paper:\n*   abstract mentions: \"propose\", \"develop\", \"present\", \"algorithm\", \"method\" (specifically \"propose a new domain specific language\").\n*   introduction discusses: technical problem (challenges of building multiexperience uis, integration issues), proposed solution (model-driven techniques, new dsl).\n\ntherefore, the paper type is: **technical**"
    },
    "file_name": "d8f32d89af6284893c30611f51f1b01798849b26.pdf"
  },
  {
    "success": true,
    "doc_id": "43847122896b282127e61715c9d52d87",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation, using the required citation format:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical problem that Software Quality Assurance (SQA) is often overlooked in AI-enabled systems, despite their inherent nature as software systems \\cite{golendukhina2022kqe}.\n    *   This problem is important and challenging because AI is increasingly prevalent, yet AI engineers frequently lack proper training in software quality practices, leading to low code quality, inadequate testing, and poor long-term maintainability of AI/ML components \\cite{golendukhina2022kqe}. The dynamic nature of AI development, especially in agile contexts, makes it difficult to anticipate quality issues early on \\cite{golendukhina2022kqe}.\n\n*   **Related Work & Positioning**\n    *   Existing research has explored the role of AI in software engineering, challenges, and best practices, with some work highlighting quality issues in AI-enabled software \\cite{golendukhina2022kqe}. Previous studies have proposed ML testing frameworks (e.g., regression testing, metamorphic testing) \\cite{golendukhina2022kqe} and analyzed bug patterns and technical debt in ML code through code analysis (e.g., on GitHub projects, StackOverflow, Jupyter notebooks) \\cite{golendukhina2022kqe}. Other empirical studies have surveyed challenges in ML system engineering, including broad views from large corporations or taxonomies of lifecycle challenges \\cite{golendukhina2022kqe}.\n    *   This work distinguishes itself by conducting an empirical study from the *developers' perspective* to gather their direct experience and expertise, unlike studies that primarily rely on code analysis \\cite{golendukhina2022kqe}. Furthermore, it focuses on *Small and Medium-sized Enterprises (SMEs)* in Austria, offering insights that may differ from large multinational corporations with more mature processes \\cite{golendukhina2022kqe}. Unlike some prior work that identified challenges, this study aims to identify *clear issues and possible solutions* \\cite{golendukhina2022kqe}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is an **exploratory qualitative empirical study** utilizing **semi-structured interviews** \\cite{golendukhina2022kqe}. This approach allows for in-depth understanding of real-world experiences and perceptions regarding SQA in AI/ML development.\n    *   The innovation lies in its specific focus and methodology:\n        *   **Direct Developer Perspective**: Gathering qualitative data directly from industry practitioners involved in AI/ML component development, integration, and maintenance \\cite{golendukhina2022kqe}.\n        *   **SME Context**: Investigating SQA strategies within Austrian SMEs, a segment of the industry often underrepresented in large-scale studies but crucial for understanding diverse development practices \\cite{golendukhina2022kqe}.\n        *   **Comprehensive Inquiry**: The interview design covers demographic information, development processes, specific quality issues experienced, methods of discovery, phases of occurrence, and applied quality practices, aiming to provide a holistic view \\cite{golendukhina2022kqe}.\n\n*   **Key Technical Contributions**\n    *   **Identification of 12 Quality Issues**: Through qualitative analysis of interview data, the study identified 12 distinct categories of internal quality issues experienced by industry in AI-enabled systems \\cite{golendukhina2022kqe}. (Note: The provided paper content cuts off before listing all 12 issues, but highlights \"data handling\" as the most frequently recalled issue by 8 out of 10 companies \\cite{golendukhina2022kqe}).\n    *   **Insights into Issue Detection and Timing**: The research provides insights into *when* quality issues arise in AI/ML components (development, integration, maintenance phases) and *how* they are detected \\cite{golendukhina2022kqe}.\n    *   **Characterization of Development Process Challenges**: The study revealed that 60% of interviewed companies face planning-related issues in agile AI/ML development due to the impossibility of identifying hard deadlines, especially in early stages \\cite{golendukhina2022kqe}.\n    *   **Practical Workarounds**: Companies adopt workarounds such as shortening sprints in early development or introducing \"spikes\" for time-ambiguous research activities to manage these planning challenges \\cite{golendukhina2022kqe}.\n\n*   **Experimental Validation**\n    *   **Study Design**: An exploratory survey was conducted using semi-structured interviews with representatives from ten Austrian SMEs that develop AI-enabled systems \\cite{golendukhina2022kqe}.\n    *   **Participant Selection**: Companies were selected from the Austrian AI Landscape, targeting industry practitioners closely involved in AI/ML component development \\cite{golendukhina2022kqe}.\n    *   **Data Collection**: Interviews were conducted online, recorded, and transcribed, lasting 30-50 minutes each \\cite{golendukhina2022kqe}.\n    *   **Data Analysis**: A qualitative analysis was performed using open and axial coding methodologies by two authors to identify and group similar answers into hierarchical sets of codes \\cite{golendukhina2022kqe}.\n    *   **Key Findings (Partial)**:\n        *   **Organizational Context**: 90% of respondents reported separated data science and software engineering departments, with 50% having AI teams of less than 10 employees \\cite{golendukhina2022kqe}.\n        *   **Development Practices**: All companies used agile or agile-like processes with 1-2 week sprints \\cite{golendukhina2022kqe}.\n        *   **Tooling**: Python was the most common programming language (80%), with mentions of R, Julia, MATLAB, and deep learning frameworks like PyTorch, TensorFlow, and Onnx \\cite{golendukhina2022kqe}.\n        *   **Primary Issue**: \"Data handling\" was identified as the most frequent issue in AI/ML code development, reported by 8 companies \\cite{golendukhina2022kqe}.\n\n*   **Limitations & Scope**\n    *   **Generalizability**: The study's findings are based on interviews with ten Austrian SMEs, which may limit the generalizability of the results to larger organizations or companies in different geographical or cultural contexts \\cite{golendukhina2022kqe}.\n    *   **Scope of Issues**: While the study aimed to focus on AI/ML *code* quality, respondents often found it difficult to distinguish between code quality and the quality of data and models, indicating a broader perception of \"quality issues\" in AI systems \\cite{golendukhina2022kqe}.\n    *   **Incomplete Results (from provided text)**: The provided paper content ends before fully detailing all 12 identified issues and the quality practices applied by companies (RQ2), which limits a complete understanding of the study's findings.\n\n*   **Technical Significance**\n    *   This paper significantly advances the technical state-of-the-art by providing **empirical, qualitative evidence** from industry practitioners on the specific SQA challenges faced in AI/ML development \\cite{golendukhina2022kqe}.\n    *   By identifying concrete issues and the context in which they arise, it \"thins the fog\" around AI/ML quality, offering a **grounded understanding** that can guide future research \\cite{golendukhina2022kqe}.\n    *   The insights into planning difficulties and practical workarounds in agile AI development are valuable for refining software engineering processes for AI \\cite{golendukhina2022kqe}.\n    *   The findings lay the groundwork for developing more targeted SQA processes, techniques, and training programs specifically tailored for AI/ML components, potentially improving the long-term quality and maintainability of AI-enabled systems \\cite{golendukhina2022kqe}.",
    "intriguing_abstract": "Despite the rapid proliferation of AI-enabled systems, Software Quality Assurance (SQA) remains a critically neglected aspect. AI/ML components face unique quality challenges, exacerbated by limited SQA training for AI engineers and the dynamic nature of agile AI development. This paper presents a novel qualitative empirical study, delving into developers' direct experiences within ten Austrian Small and Medium-sized Enterprises (SMEs).\n\nThrough semi-structured interviews, we uncover 12 distinct internal quality issues, with \"data handling\" identified as the most pervasive. Our findings illuminate *when* and *how* these issues manifest across development, integration, and maintenance. We characterize significant planning challenges in agile AI/ML development, where 60% of companies struggle with hard deadlines, and detail practical workarounds like \"spikes.\" This research provides crucial, practitioner-grounded insights, \"thinning the fog\" around AI/ML quality. It offers a vital foundation for developing targeted SQA processes, techniques, and training, ultimately enhancing the quality and maintainability of AI-enabled systems.",
    "keywords": [
      "Software Quality Assurance (SQA)",
      "AI-enabled systems",
      "Machine Learning (ML) components",
      "exploratory qualitative empirical study",
      "semi-structured interviews",
      "developer perspective",
      "Small and Medium-sized Enterprises (SMEs)",
      "AI/ML quality issues",
      "data handling issues",
      "agile AI/ML development",
      "planning challenges",
      "practical workarounds",
      "open and axial coding"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2874c1b39e848bd32848de7a40a7b52fbab2c58a.pdf",
    "citation_key": "golendukhina2022kqe",
    "metadata": {
      "title": "What is Software Quality for AI Engineers? Towards a Thinning of the Fog",
      "authors": [
        "Valentina Golendukhina",
        "Valentina Lenarduzzi",
        "M. Felderer"
      ],
      "published_date": "2022",
      "abstract": "It is often overseen that AI-enabled systems are also software systems and therefore rely on software quality assurance (SQA). Thus, the goal of this study is to investigate the software quality assurance strategies adopted during the development, integration, and maintenance of AI/ML components and code. We conducted semi-structured interviews with representatives of ten Austrian SMEs that develop AI-enabled systems. A qualitative analysis of the interview data identified 12 issues in the development of AI/ML components. Furthermore, we identified when quality issues arise in AI/ML components and how they are detected. The results of this study should guide future work on software quality assurance processes and techniques for AI/ML components.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2874c1b39e848bd32848de7a40a7b52fbab2c58a.pdf",
      "venue": "2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN)",
      "citationCount": 17,
      "score": 5.666666666666666,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation, using the required citation format:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical problem that Software Quality Assurance (SQA) is often overlooked in AI-enabled systems, despite their inherent nature as software systems \\cite{golendukhina2022kqe}.\n    *   This problem is important and challenging because AI is increasingly prevalent, yet AI engineers frequently lack proper training in software quality practices, leading to low code quality, inadequate testing, and poor long-term maintainability of AI/ML components \\cite{golendukhina2022kqe}. The dynamic nature of AI development, especially in agile contexts, makes it difficult to anticipate quality issues early on \\cite{golendukhina2022kqe}.\n\n*   **Related Work & Positioning**\n    *   Existing research has explored the role of AI in software engineering, challenges, and best practices, with some work highlighting quality issues in AI-enabled software \\cite{golendukhina2022kqe}. Previous studies have proposed ML testing frameworks (e.g., regression testing, metamorphic testing) \\cite{golendukhina2022kqe} and analyzed bug patterns and technical debt in ML code through code analysis (e.g., on GitHub projects, StackOverflow, Jupyter notebooks) \\cite{golendukhina2022kqe}. Other empirical studies have surveyed challenges in ML system engineering, including broad views from large corporations or taxonomies of lifecycle challenges \\cite{golendukhina2022kqe}.\n    *   This work distinguishes itself by conducting an empirical study from the *developers' perspective* to gather their direct experience and expertise, unlike studies that primarily rely on code analysis \\cite{golendukhina2022kqe}. Furthermore, it focuses on *Small and Medium-sized Enterprises (SMEs)* in Austria, offering insights that may differ from large multinational corporations with more mature processes \\cite{golendukhina2022kqe}. Unlike some prior work that identified challenges, this study aims to identify *clear issues and possible solutions* \\cite{golendukhina2022kqe}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is an **exploratory qualitative empirical study** utilizing **semi-structured interviews** \\cite{golendukhina2022kqe}. This approach allows for in-depth understanding of real-world experiences and perceptions regarding SQA in AI/ML development.\n    *   The innovation lies in its specific focus and methodology:\n        *   **Direct Developer Perspective**: Gathering qualitative data directly from industry practitioners involved in AI/ML component development, integration, and maintenance \\cite{golendukhina2022kqe}.\n        *   **SME Context**: Investigating SQA strategies within Austrian SMEs, a segment of the industry often underrepresented in large-scale studies but crucial for understanding diverse development practices \\cite{golendukhina2022kqe}.\n        *   **Comprehensive Inquiry**: The interview design covers demographic information, development processes, specific quality issues experienced, methods of discovery, phases of occurrence, and applied quality practices, aiming to provide a holistic view \\cite{golendukhina2022kqe}.\n\n*   **Key Technical Contributions**\n    *   **Identification of 12 Quality Issues**: Through qualitative analysis of interview data, the study identified 12 distinct categories of internal quality issues experienced by industry in AI-enabled systems \\cite{golendukhina2022kqe}. (Note: The provided paper content cuts off before listing all 12 issues, but highlights \"data handling\" as the most frequently recalled issue by 8 out of 10 companies \\cite{golendukhina2022kqe}).\n    *   **Insights into Issue Detection and Timing**: The research provides insights into *when* quality issues arise in AI/ML components (development, integration, maintenance phases) and *how* they are detected \\cite{golendukhina2022kqe}.\n    *   **Characterization of Development Process Challenges**: The study revealed that 60% of interviewed companies face planning-related issues in agile AI/ML development due to the impossibility of identifying hard deadlines, especially in early stages \\cite{golendukhina2022kqe}.\n    *   **Practical Workarounds**: Companies adopt workarounds such as shortening sprints in early development or introducing \"spikes\" for time-ambiguous research activities to manage these planning challenges \\cite{golendukhina2022kqe}.\n\n*   **Experimental Validation**\n    *   **Study Design**: An exploratory survey was conducted using semi-structured interviews with representatives from ten Austrian SMEs that develop AI-enabled systems \\cite{golendukhina2022kqe}.\n    *   **Participant Selection**: Companies were selected from the Austrian AI Landscape, targeting industry practitioners closely involved in AI/ML component development \\cite{golendukhina2022kqe}.\n    *   **Data Collection**: Interviews were conducted online, recorded, and transcribed, lasting 30-50 minutes each \\cite{golendukhina2022kqe}.\n    *   **Data Analysis**: A qualitative analysis was performed using open and axial coding methodologies by two authors to identify and group similar answers into hierarchical sets of codes \\cite{golendukhina2022kqe}.\n    *   **Key Findings (Partial)**:\n        *   **Organizational Context**: 90% of respondents reported separated data science and software engineering departments, with 50% having AI teams of less than 10 employees \\cite{golendukhina2022kqe}.\n        *   **Development Practices**: All companies used agile or agile-like processes with 1-2 week sprints \\cite{golendukhina2022kqe}.\n        *   **Tooling**: Python was the most common programming language (80%), with mentions of R, Julia, MATLAB, and deep learning frameworks like PyTorch, TensorFlow, and Onnx \\cite{golendukhina2022kqe}.\n        *   **Primary Issue**: \"Data handling\" was identified as the most frequent issue in AI/ML code development, reported by 8 companies \\cite{golendukhina2022kqe}.\n\n*   **Limitations & Scope**\n    *   **Generalizability**: The study's findings are based on interviews with ten Austrian SMEs, which may limit the generalizability of the results to larger organizations or companies in different geographical or cultural contexts \\cite{golendukhina2022kqe}.\n    *   **Scope of Issues**: While the study aimed to focus on AI/ML *code* quality, respondents often found it difficult to distinguish between code quality and the quality of data and models, indicating a broader perception of \"quality issues\" in AI systems \\cite{golendukhina2022kqe}.\n    *   **Incomplete Results (from provided text)**: The provided paper content ends before fully detailing all 12 identified issues and the quality practices applied by companies (RQ2), which limits a complete understanding of the study's findings.\n\n*   **Technical Significance**\n    *   This paper significantly advances the technical state-of-the-art by providing **empirical, qualitative evidence** from industry practitioners on the specific SQA challenges faced in AI/ML development \\cite{golendukhina2022kqe}.\n    *   By identifying concrete issues and the context in which they arise, it \"thins the fog\" around AI/ML quality, offering a **grounded understanding** that can guide future research \\cite{golendukhina2022kqe}.\n    *   The insights into planning difficulties and practical workarounds in agile AI development are valuable for refining software engineering processes for AI \\cite{golendukhina2022kqe}.\n    *   The findings lay the groundwork for developing more targeted SQA processes, techniques, and training programs specifically tailored for AI/ML components, potentially improving the long-term quality and maintainability of AI-enabled systems \\cite{golendukhina2022kqe}.",
      "keywords": [
        "Software Quality Assurance (SQA)",
        "AI-enabled systems",
        "Machine Learning (ML) components",
        "exploratory qualitative empirical study",
        "semi-structured interviews",
        "developer perspective",
        "Small and Medium-sized Enterprises (SMEs)",
        "AI/ML quality issues",
        "data handling issues",
        "agile AI/ML development",
        "planning challenges",
        "practical workarounds",
        "open and axial coding"
      ],
      "paper_type": "**empirical**\n\n**reasoning:**\n\n1.  **abstract keywords:** the abstract explicitly lists \"empirical study\" as a keyword.\n2.  **methodology:** the abstract states, \"we conducted semi-structured interviews with representatives of ten austrian smes...\" and \"a qualitative analysis of the interview data identified 12 issues...\" this clearly describes a data-driven study involving data collection (interviews) and analysis to derive findings.\n3.  **goal:** the goal \"to investigate the software quality assurance strategies adopted...\" is a typical objective for an empirical study.\n4.  **findings:** the identification of \"12 issues\" and how/when \"quality issues arise\" are direct findings from the data analysis.\n\nthese elements align perfectly with the criteria for an **empirical** paper: \"data-driven studies with statistical analysis\" (qualitative analysis is a form of data analysis), \"study\", \"experiment\" (implied by conducting interviews), \"data\", \"findings\", \"research questions\" (implied by \"goal of this study\"), \"methodology\", \"participants\"."
    },
    "file_name": "2874c1b39e848bd32848de7a40a7b52fbab2c58a.pdf"
  },
  {
    "success": true,
    "doc_id": "e519e32acde4e878712c832218e0db9b",
    "summary": "With the rapid development of the Internet of Things (IoT) network, the IoT devices need to perform the artificial intelligence (AI) model to make decisions according to the specific service requirement under a dynamic environment. However, the generation and usage of AI model typically requires a huge amount of communication, computing, and caching resource. Thus, the construction of the network and the scheduling of the limited network resources to realize the rapid generation and propagation of AI models are critical. Therefore, we propose a software-defined Information Centric-Internet of Things (IC-IoT) architecture to bring caching and computing capabilities to the IoT network. Based on the proposed IC-IoT architecture, we design a joint resource scheduling scheme to uniformly manage the computing and caching resources. The objective is to maximize the reward which consists not only short-term reward but also long-term reward brought by caching popular AI models. The resource scheduling problem is formulated into a multi-dimensional optimization problem. A new deep Q-learning method is proposed due to the complexity and high dimension of this problem. The simulation results verify the effectiveness of the software-defined IC-IoT architecture and the joint resource allocation strategy.",
    "intriguing_abstract": "With the rapid development of the Internet of Things (IoT) network, the IoT devices need to perform the artificial intelligence (AI) model to make decisions according to the specific service requirement under a dynamic environment. However, the generation and usage of AI model typically requires a huge amount of communication, computing, and caching resource. Thus, the construction of the network and the scheduling of the limited network resources to realize the rapid generation and propagation of AI models are critical. Therefore, we propose a software-defined Information Centric-Internet of Things (IC-IoT) architecture to bring caching and computing capabilities to the IoT network. Based on the proposed IC-IoT architecture, we design a joint resource scheduling scheme to uniformly manage the computing and caching resources. The objective is to maximize the reward which consists not only short-term reward but also long-term reward brought by caching popular AI models. The resource scheduling problem is formulated into a multi-dimensional optimization problem. A new deep Q-learning method is proposed due to the complexity and high dimension of this problem. The simulation results verify the effectiveness of the software-defined IC-IoT architecture and the joint resource allocation strategy.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/1ff198eba8c09c8fb960e416c3365e7d84e330f8.pdf",
    "citation_key": "xu2019hml",
    "metadata": {
      "title": "DQN Inspired Joint Computing and Caching Resource Allocation Approach for Software Defined Information-Centric Internet of Things Network",
      "authors": [
        "Fangmin Xu",
        "Fan Yang",
        "Shijian Bao",
        "Cheng-lin Zhao"
      ],
      "published_date": "2019",
      "abstract": "With the rapid development of the Internet of Things (IoT) network, the IoT devices need to perform the artificial intelligence (AI) model to make decisions according to the specific service requirement under a dynamic environment. However, the generation and usage of AI model typically requires a huge amount of communication, computing, and caching resource. Thus, the construction of the network and the scheduling of the limited network resources to realize the rapid generation and propagation of AI models are critical. Therefore, we propose a software-defined Information Centric-Internet of Things (IC-IoT) architecture to bring caching and computing capabilities to the IoT network. Based on the proposed IC-IoT architecture, we design a joint resource scheduling scheme to uniformly manage the computing and caching resources. The objective is to maximize the reward which consists not only short-term reward but also long-term reward brought by caching popular AI models. The resource scheduling problem is formulated into a multi-dimensional optimization problem. A new deep Q-learning method is proposed due to the complexity and high dimension of this problem. The simulation results verify the effectiveness of the software-defined IC-IoT architecture and the joint resource allocation strategy.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/1ff198eba8c09c8fb960e416c3365e7d84e330f8.pdf",
      "venue": "IEEE Access",
      "citationCount": 33,
      "score": 5.5,
      "summary": "With the rapid development of the Internet of Things (IoT) network, the IoT devices need to perform the artificial intelligence (AI) model to make decisions according to the specific service requirement under a dynamic environment. However, the generation and usage of AI model typically requires a huge amount of communication, computing, and caching resource. Thus, the construction of the network and the scheduling of the limited network resources to realize the rapid generation and propagation of AI models are critical. Therefore, we propose a software-defined Information Centric-Internet of Things (IC-IoT) architecture to bring caching and computing capabilities to the IoT network. Based on the proposed IC-IoT architecture, we design a joint resource scheduling scheme to uniformly manage the computing and caching resources. The objective is to maximize the reward which consists not only short-term reward but also long-term reward brought by caching popular AI models. The resource scheduling problem is formulated into a multi-dimensional optimization problem. A new deep Q-learning method is proposed due to the complexity and high dimension of this problem. The simulation results verify the effectiveness of the software-defined IC-IoT architecture and the joint resource allocation strategy.",
      "keywords": []
    },
    "file_name": "1ff198eba8c09c8fb960e416c3365e7d84e330f8.pdf"
  },
  {
    "success": true,
    "doc_id": "5d18fe2c96e9570eb59d7747298cf957",
    "summary": "In response to the trend that artificial intelligence (AI) is becoming the main driver for social and economic development, enhancing the readiness of learners in AI is significant and important. The state council and the ministry of education of China put AI education for K-12 schools on a high priority in order to foster local AI talents and reduce educational disparities. However, the AI knowledge and technical skills are still limited for not only students but also the school teachers. Furthermore, many local schools in China, especially in the rural areas, are lack of the necessary software and hardware for teaching AI. Hence, we designed and implemented a structured series of AI courses, built on an online block-based visual programming platform. The AI courses are free and easily accessible for all. We have conducted the experimental classes in a local school and collected the results. The results show that the learners in general gained significant learning progress on AI knowledge comprehension, aroused strong interests in AI, and increased the degree of satisfaction towards the course. Especially, our practices significantly increased computational thinking of the students who were initially staying at a lower level.",
    "intriguing_abstract": "In response to the trend that artificial intelligence (AI) is becoming the main driver for social and economic development, enhancing the readiness of learners in AI is significant and important. The state council and the ministry of education of China put AI education for K-12 schools on a high priority in order to foster local AI talents and reduce educational disparities. However, the AI knowledge and technical skills are still limited for not only students but also the school teachers. Furthermore, many local schools in China, especially in the rural areas, are lack of the necessary software and hardware for teaching AI. Hence, we designed and implemented a structured series of AI courses, built on an online block-based visual programming platform. The AI courses are free and easily accessible for all. We have conducted the experimental classes in a local school and collected the results. The results show that the learners in general gained significant learning progress on AI knowledge comprehension, aroused strong interests in AI, and increased the degree of satisfaction towards the course. Especially, our practices significantly increased computational thinking of the students who were initially staying at a lower level.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/76e8d699c24149999321eb5ffd186e1c86038cf5.pdf",
    "citation_key": "song20225if",
    "metadata": {
      "title": "Paving the Way for Novices: How to Teach AI for K-12 Education in China",
      "authors": [
        "Jiachen Song",
        "Linan Zhang",
        "Jinglei Yu",
        "Yan Peng",
        "Anyao Ma",
        "Yu Lu"
      ],
      "published_date": "2022",
      "abstract": "In response to the trend that artificial intelligence (AI) is becoming the main driver for social and economic development, enhancing the readiness of learners in AI is significant and important. The state council and the ministry of education of China put AI education for K-12 schools on a high priority in order to foster local AI talents and reduce educational disparities. However, the AI knowledge and technical skills are still limited for not only students but also the school teachers. Furthermore, many local schools in China, especially in the rural areas, are lack of the necessary software and hardware for teaching AI. Hence, we designed and implemented a structured series of AI courses, built on an online block-based visual programming platform. The AI courses are free and easily accessible for all. We have conducted the experimental classes in a local school and collected the results. The results show that the learners in general gained significant learning progress on AI knowledge comprehension, aroused strong interests in AI, and increased the degree of satisfaction towards the course. Especially, our practices significantly increased computational thinking of the students who were initially staying at a lower level.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/76e8d699c24149999321eb5ffd186e1c86038cf5.pdf",
      "venue": "AAAI Conference on Artificial Intelligence",
      "citationCount": 16,
      "score": 5.333333333333333,
      "summary": "In response to the trend that artificial intelligence (AI) is becoming the main driver for social and economic development, enhancing the readiness of learners in AI is significant and important. The state council and the ministry of education of China put AI education for K-12 schools on a high priority in order to foster local AI talents and reduce educational disparities. However, the AI knowledge and technical skills are still limited for not only students but also the school teachers. Furthermore, many local schools in China, especially in the rural areas, are lack of the necessary software and hardware for teaching AI. Hence, we designed and implemented a structured series of AI courses, built on an online block-based visual programming platform. The AI courses are free and easily accessible for all. We have conducted the experimental classes in a local school and collected the results. The results show that the learners in general gained significant learning progress on AI knowledge comprehension, aroused strong interests in AI, and increased the degree of satisfaction towards the course. Especially, our practices significantly increased computational thinking of the students who were initially staying at a lower level.",
      "keywords": []
    },
    "file_name": "76e8d699c24149999321eb5ffd186e1c86038cf5.pdf"
  },
  {
    "success": true,
    "doc_id": "729bd4286237ee0eb2129124519e57fd",
    "summary": "Artificial Intelligence finds application at all stages of Software Engineering, and uses the Neural Networks, Machine Learning, Natural Language Processing concepts. This paper attempts to review the instance of such approach - neural network programmer’s assistant Copilot, based on Codex, the AI system developed by OpenAI. The differences between Codex language model’s versions and analogous systems were analyzed. The main problems and gaps of this innovation, such as correct commands formulation, copyrighting, safety issues, inefficient code, good practice examples and restrictions are also considered. Additionally, the opportunities for Copilot’s growth, development and possible features’ proposed recommendations were suggested.",
    "intriguing_abstract": "Artificial Intelligence finds application at all stages of Software Engineering, and uses the Neural Networks, Machine Learning, Natural Language Processing concepts. This paper attempts to review the instance of such approach - neural network programmer’s assistant Copilot, based on Codex, the AI system developed by OpenAI. The differences between Codex language model’s versions and analogous systems were analyzed. The main problems and gaps of this innovation, such as correct commands formulation, copyrighting, safety issues, inefficient code, good practice examples and restrictions are also considered. Additionally, the opportunities for Copilot’s growth, development and possible features’ proposed recommendations were suggested.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/443f16b95edec746a5259644540c44204f2d91c3.pdf",
    "citation_key": "moroz20223e8",
    "metadata": {
      "title": "The Potential of Artificial Intelligence as a Method of Software Developer's Productivity Improvement",
      "authors": [
        "Ekaterina A. Moroz",
        "Vladimir O. Grizkevich",
        "I. M. Novozhilov"
      ],
      "published_date": "2022",
      "abstract": "Artificial Intelligence finds application at all stages of Software Engineering, and uses the Neural Networks, Machine Learning, Natural Language Processing concepts. This paper attempts to review the instance of such approach - neural network programmer’s assistant Copilot, based on Codex, the AI system developed by OpenAI. The differences between Codex language model’s versions and analogous systems were analyzed. The main problems and gaps of this innovation, such as correct commands formulation, copyrighting, safety issues, inefficient code, good practice examples and restrictions are also considered. Additionally, the opportunities for Copilot’s growth, development and possible features’ proposed recommendations were suggested.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/443f16b95edec746a5259644540c44204f2d91c3.pdf",
      "venue": "2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus)",
      "citationCount": 16,
      "score": 5.333333333333333,
      "summary": "Artificial Intelligence finds application at all stages of Software Engineering, and uses the Neural Networks, Machine Learning, Natural Language Processing concepts. This paper attempts to review the instance of such approach - neural network programmer’s assistant Copilot, based on Codex, the AI system developed by OpenAI. The differences between Codex language model’s versions and analogous systems were analyzed. The main problems and gaps of this innovation, such as correct commands formulation, copyrighting, safety issues, inefficient code, good practice examples and restrictions are also considered. Additionally, the opportunities for Copilot’s growth, development and possible features’ proposed recommendations were suggested.",
      "keywords": []
    },
    "file_name": "443f16b95edec746a5259644540c44204f2d91c3.pdf"
  },
  {
    "success": true,
    "doc_id": "73b8edfd5bf1613174f5357328c08590",
    "summary": "Recently, there has been a significant increase in the number of Artificial Intelligence (AI) systems, software, and components. As a result, it is crucial to evaluate their quality. Quality models for AI have in fact been proposed, but there is a lack of Systematic Mapping Studies (SMS) for quality models in AI systems, software, and components. The goal of this paper is to understand, classify, and critically evaluate existing quality models for AI systems, software, and components. This study conducts an SMS to investigate quality models proposed by various authors in the past. The study only found quality models for AI systems and software. So far, the SMS has revealed no work on AI software component quality models. Finally, the limitations of the quality models and the implications for future research and development efforts are discussed.",
    "intriguing_abstract": "Recently, there has been a significant increase in the number of Artificial Intelligence (AI) systems, software, and components. As a result, it is crucial to evaluate their quality. Quality models for AI have in fact been proposed, but there is a lack of Systematic Mapping Studies (SMS) for quality models in AI systems, software, and components. The goal of this paper is to understand, classify, and critically evaluate existing quality models for AI systems, software, and components. This study conducts an SMS to investigate quality models proposed by various authors in the past. The study only found quality models for AI systems and software. So far, the SMS has revealed no work on AI software component quality models. Finally, the limitations of the quality models and the implications for future research and development efforts are discussed.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/3713a35e2b5ecb2ffeaaeb8966d88bf948901a08.pdf",
    "citation_key": "ali2022fc4",
    "metadata": {
      "title": "A Systematic Mapping of Quality Models for AI Systems, Software and Components",
      "authors": [
        "Mohamed Abdullahi Ali",
        "Ng Keng Yap",
        "A. Ghani",
        "H. Zulzalil",
        "N. Admodisastro",
        "Amin Arab Najafabadi"
      ],
      "published_date": "2022",
      "abstract": "Recently, there has been a significant increase in the number of Artificial Intelligence (AI) systems, software, and components. As a result, it is crucial to evaluate their quality. Quality models for AI have in fact been proposed, but there is a lack of Systematic Mapping Studies (SMS) for quality models in AI systems, software, and components. The goal of this paper is to understand, classify, and critically evaluate existing quality models for AI systems, software, and components. This study conducts an SMS to investigate quality models proposed by various authors in the past. The study only found quality models for AI systems and software. So far, the SMS has revealed no work on AI software component quality models. Finally, the limitations of the quality models and the implications for future research and development efforts are discussed.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/3713a35e2b5ecb2ffeaaeb8966d88bf948901a08.pdf",
      "venue": "Applied Sciences",
      "citationCount": 15,
      "score": 5.0,
      "summary": "Recently, there has been a significant increase in the number of Artificial Intelligence (AI) systems, software, and components. As a result, it is crucial to evaluate their quality. Quality models for AI have in fact been proposed, but there is a lack of Systematic Mapping Studies (SMS) for quality models in AI systems, software, and components. The goal of this paper is to understand, classify, and critically evaluate existing quality models for AI systems, software, and components. This study conducts an SMS to investigate quality models proposed by various authors in the past. The study only found quality models for AI systems and software. So far, the SMS has revealed no work on AI software component quality models. Finally, the limitations of the quality models and the implications for future research and development efforts are discussed.",
      "keywords": []
    },
    "file_name": "3713a35e2b5ecb2ffeaaeb8966d88bf948901a08.pdf"
  },
  {
    "success": true,
    "doc_id": "a570d5aaa34cd7d5e5b258a4b6d0cc51",
    "summary": "ABSTRACT Fighter jets are a critical national asset. Because of the high cost of their manufacture and that of their related equipment, both pilots and maintenance personnel must complete intensive training before coming into contact with a jet. Due to gradual military downsizing, one-on-one training is often impracticable, and the level of familiarization with procedures among personnel is difficult to measure. The US military introduced a chatbot as part of its digital training material to enhance training effectiveness and avoid equipment damage. In this study, the contribution of an artificial intelligence (AI) chatbot in training is explored. To evaluate the necessity of an AI chatbot, research samples were divided into two groups, namely an experimental and a control group, with 20 people in each group. A paired t test was employed for differentiation analysis of pretest and posttest average scores, revealing that the two groups exhibited a statistically significant improvement in their learning performance. In addition, the blend of analysis of variance results indicated significant differences between the two groups. The chatbot training was more effective than traditional instructor teaching in terms of trainee performance improvement.",
    "intriguing_abstract": "ABSTRACT Fighter jets are a critical national asset. Because of the high cost of their manufacture and that of their related equipment, both pilots and maintenance personnel must complete intensive training before coming into contact with a jet. Due to gradual military downsizing, one-on-one training is often impracticable, and the level of familiarization with procedures among personnel is difficult to measure. The US military introduced a chatbot as part of its digital training material to enhance training effectiveness and avoid equipment damage. In this study, the contribution of an artificial intelligence (AI) chatbot in training is explored. To evaluate the necessity of an AI chatbot, research samples were divided into two groups, namely an experimental and a control group, with 20 people in each group. A paired t test was employed for differentiation analysis of pretest and posttest average scores, revealing that the two groups exhibited a statistically significant improvement in their learning performance. In addition, the blend of analysis of variance results indicated significant differences between the two groups. The chatbot training was more effective than traditional instructor teaching in terms of trainee performance improvement.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a5fda6083251562ecf64ca0c6826447688921ebb.pdf",
    "citation_key": "yuan20217tj",
    "metadata": {
      "title": "Development of mobile interactive courses based on an artificial intelligence chatbot on the communication software LINE",
      "authors": [
        "Chia-Ching Yuan",
        "Cheng-Hsuan Li",
        "Chin-Cheng Peng"
      ],
      "published_date": "2021",
      "abstract": "ABSTRACT Fighter jets are a critical national asset. Because of the high cost of their manufacture and that of their related equipment, both pilots and maintenance personnel must complete intensive training before coming into contact with a jet. Due to gradual military downsizing, one-on-one training is often impracticable, and the level of familiarization with procedures among personnel is difficult to measure. The US military introduced a chatbot as part of its digital training material to enhance training effectiveness and avoid equipment damage. In this study, the contribution of an artificial intelligence (AI) chatbot in training is explored. To evaluate the necessity of an AI chatbot, research samples were divided into two groups, namely an experimental and a control group, with 20 people in each group. A paired t test was employed for differentiation analysis of pretest and posttest average scores, revealing that the two groups exhibited a statistically significant improvement in their learning performance. In addition, the blend of analysis of variance results indicated significant differences between the two groups. The chatbot training was more effective than traditional instructor teaching in terms of trainee performance improvement.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a5fda6083251562ecf64ca0c6826447688921ebb.pdf",
      "venue": "Interactive Learning Environments",
      "citationCount": 20,
      "score": 5.0,
      "summary": "ABSTRACT Fighter jets are a critical national asset. Because of the high cost of their manufacture and that of their related equipment, both pilots and maintenance personnel must complete intensive training before coming into contact with a jet. Due to gradual military downsizing, one-on-one training is often impracticable, and the level of familiarization with procedures among personnel is difficult to measure. The US military introduced a chatbot as part of its digital training material to enhance training effectiveness and avoid equipment damage. In this study, the contribution of an artificial intelligence (AI) chatbot in training is explored. To evaluate the necessity of an AI chatbot, research samples were divided into two groups, namely an experimental and a control group, with 20 people in each group. A paired t test was employed for differentiation analysis of pretest and posttest average scores, revealing that the two groups exhibited a statistically significant improvement in their learning performance. In addition, the blend of analysis of variance results indicated significant differences between the two groups. The chatbot training was more effective than traditional instructor teaching in terms of trainee performance improvement.",
      "keywords": []
    },
    "file_name": "a5fda6083251562ecf64ca0c6826447688921ebb.pdf"
  },
  {
    "success": true,
    "doc_id": "96802b07434480db01774332cee47c7f",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/44283301f2eecce448c0ba85444e35b172b9d0d3.pdf",
    "citation_key": "kulkarni2017dv5",
    "metadata": {
      "title": "Integration of artificial intelligence activities in software development processes and measuring effectiveness of integration",
      "authors": [
        "Rajesh Kulkarni",
        "P. Padmanabham"
      ],
      "published_date": "2017",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/44283301f2eecce448c0ba85444e35b172b9d0d3.pdf",
      "venue": "IET Software",
      "citationCount": 39,
      "score": 4.875,
      "summary": "",
      "keywords": []
    },
    "file_name": "44283301f2eecce448c0ba85444e35b172b9d0d3.pdf"
  },
  {
    "success": true,
    "doc_id": "c235c95d913ce1f70f9a819d36f1f2b4",
    "summary": "In this paper we introduce the Mozart Processor, which implements a new processing paradigm called Reuse Exposed Dataflow (RED). RED is a counterpart to existing execution models of Von-Neumann, SIMT, Dataflow, and FPGA. Dataflow and data reuse are the fundamental architecture primitives in RED, implemented with mechanisms for inter-worker communication and synchronization. The paper defines the processor architecture, the details of the microarchitecture, chip implementation, software stack development, and performance results. The architecture's goal is to achieve near-CPU like flexibility while having ASIC-like efficiency for a large-class of data-intensive workloads. An additional goal was software maturity --- have large coverage of applications immediately, avoiding the need for a long-drawn hand-tuning software development phase. The architecture was defined with this software-maturity/compiler friendliness in mind. In short, the goal was to do to GPUs, what GPUs did to CPUs --- i.e. be a better solution for a large range of workloads, while preserving flexibility and programmability. The chip was implemented with HBM and PCIe interfaces and taken to production on a 16nm TSMC FFC process. For ML inference tasks with batch-size=4, Mozart is integer factors better than state-of-the-art GPUs even while being nearly 2 technology nodes behind. We conclude with a set of lessons learned, the unique challenges of a clean-slate architecture in a commercial setting, and pointers for uncovered research problems.",
    "intriguing_abstract": "In this paper we introduce the Mozart Processor, which implements a new processing paradigm called Reuse Exposed Dataflow (RED). RED is a counterpart to existing execution models of Von-Neumann, SIMT, Dataflow, and FPGA. Dataflow and data reuse are the fundamental architecture primitives in RED, implemented with mechanisms for inter-worker communication and synchronization. The paper defines the processor architecture, the details of the microarchitecture, chip implementation, software stack development, and performance results. The architecture's goal is to achieve near-CPU like flexibility while having ASIC-like efficiency for a large-class of data-intensive workloads. An additional goal was software maturity --- have large coverage of applications immediately, avoiding the need for a long-drawn hand-tuning software development phase. The architecture was defined with this software-maturity/compiler friendliness in mind. In short, the goal was to do to GPUs, what GPUs did to CPUs --- i.e. be a better solution for a large range of workloads, while preserving flexibility and programmability. The chip was implemented with HBM and PCIe interfaces and taken to production on a 16nm TSMC FFC process. For ML inference tasks with batch-size=4, Mozart is integer factors better than state-of-the-art GPUs even while being nearly 2 technology nodes behind. We conclude with a set of lessons learned, the unique challenges of a clean-slate architecture in a commercial setting, and pointers for uncovered research problems.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/18bd983094d5f8f9a7bba922ad74fd120e17dd35.pdf",
    "citation_key": "sankaralingam2022uw6",
    "metadata": {
      "title": "The Mozart reuse exposed dataflow processor for AI and beyond: industrial product",
      "authors": [
        "Karthikeyan Sankaralingam",
        "Tony Nowatzki",
        "Vinay Gangadhar",
        "Preyas Shah",
        "Michael Davies",
        "Will Galliher",
        "Ziliang Guo",
        "Jitu Khare",
        "Deepa Vijay",
        "Poly Palamuttam",
        "Maghawan Punde",
        "A. Tan",
        "Vijayraghavan Thiruvengadam",
        "Rongyi Wang",
        "Shunmiao Xu"
      ],
      "published_date": "2022",
      "abstract": "In this paper we introduce the Mozart Processor, which implements a new processing paradigm called Reuse Exposed Dataflow (RED). RED is a counterpart to existing execution models of Von-Neumann, SIMT, Dataflow, and FPGA. Dataflow and data reuse are the fundamental architecture primitives in RED, implemented with mechanisms for inter-worker communication and synchronization. The paper defines the processor architecture, the details of the microarchitecture, chip implementation, software stack development, and performance results. The architecture's goal is to achieve near-CPU like flexibility while having ASIC-like efficiency for a large-class of data-intensive workloads. An additional goal was software maturity --- have large coverage of applications immediately, avoiding the need for a long-drawn hand-tuning software development phase. The architecture was defined with this software-maturity/compiler friendliness in mind. In short, the goal was to do to GPUs, what GPUs did to CPUs --- i.e. be a better solution for a large range of workloads, while preserving flexibility and programmability. The chip was implemented with HBM and PCIe interfaces and taken to production on a 16nm TSMC FFC process. For ML inference tasks with batch-size=4, Mozart is integer factors better than state-of-the-art GPUs even while being nearly 2 technology nodes behind. We conclude with a set of lessons learned, the unique challenges of a clean-slate architecture in a commercial setting, and pointers for uncovered research problems.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/18bd983094d5f8f9a7bba922ad74fd120e17dd35.pdf",
      "venue": "International Symposium on Computer Architecture",
      "citationCount": 14,
      "score": 4.666666666666666,
      "summary": "In this paper we introduce the Mozart Processor, which implements a new processing paradigm called Reuse Exposed Dataflow (RED). RED is a counterpart to existing execution models of Von-Neumann, SIMT, Dataflow, and FPGA. Dataflow and data reuse are the fundamental architecture primitives in RED, implemented with mechanisms for inter-worker communication and synchronization. The paper defines the processor architecture, the details of the microarchitecture, chip implementation, software stack development, and performance results. The architecture's goal is to achieve near-CPU like flexibility while having ASIC-like efficiency for a large-class of data-intensive workloads. An additional goal was software maturity --- have large coverage of applications immediately, avoiding the need for a long-drawn hand-tuning software development phase. The architecture was defined with this software-maturity/compiler friendliness in mind. In short, the goal was to do to GPUs, what GPUs did to CPUs --- i.e. be a better solution for a large range of workloads, while preserving flexibility and programmability. The chip was implemented with HBM and PCIe interfaces and taken to production on a 16nm TSMC FFC process. For ML inference tasks with batch-size=4, Mozart is integer factors better than state-of-the-art GPUs even while being nearly 2 technology nodes behind. We conclude with a set of lessons learned, the unique challenges of a clean-slate architecture in a commercial setting, and pointers for uncovered research problems.",
      "keywords": []
    },
    "file_name": "18bd983094d5f8f9a7bba922ad74fd120e17dd35.pdf"
  },
  {
    "success": true,
    "doc_id": "45521857fbc69fac774f267c9f6021c6",
    "summary": "The development of computer-aided detection (CAD) using artificial intelligence (AI) and machine learning (ML) is rapidly evolving. Submission of AI/ML-based CAD devices for regulatory approval requires information about clinical trial design and performance criteria, but the requirements vary between countries. This study compares the requirements for AI/ML-based CAD devices approved by the US Food and Drug Administration (FDA) and the Pharmaceuticals and Medical Devices Agency (PMDA) in Japan. A list of 45 FDA-approved and 12 PMDA-approved AI/ML-based CAD devices was compiled. In the USA, devices classified as computer-aided simple triage were approved based on standalone software testing, whereas devices classified as computer-aided detection/diagnosis were approved based on reader study testing. In Japan, however, there was no clear distinction between evaluation methods according to the category. In the USA, a prospective randomized controlled trial was conducted for AI/ML-based CAD devices used for the detection of colorectal polyps, whereas in Japan, such devices were approved based on standalone software testing. This study indicated that the different viewpoints of AI/ML-based CAD in the two countries influenced the selection of different evaluation methods. This study’s findings may be useful for defining a unified global development and approval standard for AI/ML-based CAD.",
    "intriguing_abstract": "The development of computer-aided detection (CAD) using artificial intelligence (AI) and machine learning (ML) is rapidly evolving. Submission of AI/ML-based CAD devices for regulatory approval requires information about clinical trial design and performance criteria, but the requirements vary between countries. This study compares the requirements for AI/ML-based CAD devices approved by the US Food and Drug Administration (FDA) and the Pharmaceuticals and Medical Devices Agency (PMDA) in Japan. A list of 45 FDA-approved and 12 PMDA-approved AI/ML-based CAD devices was compiled. In the USA, devices classified as computer-aided simple triage were approved based on standalone software testing, whereas devices classified as computer-aided detection/diagnosis were approved based on reader study testing. In Japan, however, there was no clear distinction between evaluation methods according to the category. In the USA, a prospective randomized controlled trial was conducted for AI/ML-based CAD devices used for the detection of colorectal polyps, whereas in Japan, such devices were approved based on standalone software testing. This study indicated that the different viewpoints of AI/ML-based CAD in the two countries influenced the selection of different evaluation methods. This study’s findings may be useful for defining a unified global development and approval standard for AI/ML-based CAD.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/20783f1e6b07389840e7c797aad81378d832e8af.pdf",
    "citation_key": "yuba2022yhb",
    "metadata": {
      "title": "Systematic analysis of the test design and performance of AI/ML-based medical devices approved for triage/detection/diagnosis in the USA and Japan",
      "authors": [
        "Mitsuru Yuba",
        "Kiyotaka Iwasaki"
      ],
      "published_date": "2022",
      "abstract": "The development of computer-aided detection (CAD) using artificial intelligence (AI) and machine learning (ML) is rapidly evolving. Submission of AI/ML-based CAD devices for regulatory approval requires information about clinical trial design and performance criteria, but the requirements vary between countries. This study compares the requirements for AI/ML-based CAD devices approved by the US Food and Drug Administration (FDA) and the Pharmaceuticals and Medical Devices Agency (PMDA) in Japan. A list of 45 FDA-approved and 12 PMDA-approved AI/ML-based CAD devices was compiled. In the USA, devices classified as computer-aided simple triage were approved based on standalone software testing, whereas devices classified as computer-aided detection/diagnosis were approved based on reader study testing. In Japan, however, there was no clear distinction between evaluation methods according to the category. In the USA, a prospective randomized controlled trial was conducted for AI/ML-based CAD devices used for the detection of colorectal polyps, whereas in Japan, such devices were approved based on standalone software testing. This study indicated that the different viewpoints of AI/ML-based CAD in the two countries influenced the selection of different evaluation methods. This study’s findings may be useful for defining a unified global development and approval standard for AI/ML-based CAD.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/20783f1e6b07389840e7c797aad81378d832e8af.pdf",
      "venue": "Scientific Reports",
      "citationCount": 14,
      "score": 4.666666666666666,
      "summary": "The development of computer-aided detection (CAD) using artificial intelligence (AI) and machine learning (ML) is rapidly evolving. Submission of AI/ML-based CAD devices for regulatory approval requires information about clinical trial design and performance criteria, but the requirements vary between countries. This study compares the requirements for AI/ML-based CAD devices approved by the US Food and Drug Administration (FDA) and the Pharmaceuticals and Medical Devices Agency (PMDA) in Japan. A list of 45 FDA-approved and 12 PMDA-approved AI/ML-based CAD devices was compiled. In the USA, devices classified as computer-aided simple triage were approved based on standalone software testing, whereas devices classified as computer-aided detection/diagnosis were approved based on reader study testing. In Japan, however, there was no clear distinction between evaluation methods according to the category. In the USA, a prospective randomized controlled trial was conducted for AI/ML-based CAD devices used for the detection of colorectal polyps, whereas in Japan, such devices were approved based on standalone software testing. This study indicated that the different viewpoints of AI/ML-based CAD in the two countries influenced the selection of different evaluation methods. This study’s findings may be useful for defining a unified global development and approval standard for AI/ML-based CAD.",
      "keywords": []
    },
    "file_name": "20783f1e6b07389840e7c797aad81378d832e8af.pdf"
  },
  {
    "success": true,
    "doc_id": "7f212aaf909bc54afe0a32308cc11b54",
    "summary": "The history of Artificial Intelligence and Machine Learning dates back to 1950’s. In recent years, there has been an increase in popularity for applications that implement AI and ML technology. As with traditional development, software testing is a critical component of an efficient AI/ML application. However, the approach to development methodology used in AI/ML varies significantly from traditional development. Owing to these variations, numerous software testing challenges occur. This paper aims to recognize and to explain some of the biggest challenges that software testers face in dealing with AI/ML applications. For future research, this study has key implications. Each of the challenges outlined in this paper is ideal for further investigation and has great potential to shed light on the way to more productive software testing strategies and methodologies that can be applied to AI/ML applications.",
    "intriguing_abstract": "The history of Artificial Intelligence and Machine Learning dates back to 1950’s. In recent years, there has been an increase in popularity for applications that implement AI and ML technology. As with traditional development, software testing is a critical component of an efficient AI/ML application. However, the approach to development methodology used in AI/ML varies significantly from traditional development. Owing to these variations, numerous software testing challenges occur. This paper aims to recognize and to explain some of the biggest challenges that software testers face in dealing with AI/ML applications. For future research, this study has key implications. Each of the challenges outlined in this paper is ideal for further investigation and has great potential to shed light on the way to more productive software testing strategies and methodologies that can be applied to AI/ML applications.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/c5e13acf97e1709c0ffc4f77125c36ea51bf2000.pdf",
    "citation_key": "sugali20213rg",
    "metadata": {
      "title": "Software Testing: Issues and Challenges of Artificial Intelligence & Machine Learning",
      "authors": [
        "Kishore Sugali",
        "Chris Sprunger",
        "Venkata N. Inukollu"
      ],
      "published_date": "2021",
      "abstract": "The history of Artificial Intelligence and Machine Learning dates back to 1950’s. In recent years, there has been an increase in popularity for applications that implement AI and ML technology. As with traditional development, software testing is a critical component of an efficient AI/ML application. However, the approach to development methodology used in AI/ML varies significantly from traditional development. Owing to these variations, numerous software testing challenges occur. This paper aims to recognize and to explain some of the biggest challenges that software testers face in dealing with AI/ML applications. For future research, this study has key implications. Each of the challenges outlined in this paper is ideal for further investigation and has great potential to shed light on the way to more productive software testing strategies and methodologies that can be applied to AI/ML applications.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/c5e13acf97e1709c0ffc4f77125c36ea51bf2000.pdf",
      "venue": "International Journal of Artificial Intelligence & Applications",
      "citationCount": 18,
      "score": 4.5,
      "summary": "The history of Artificial Intelligence and Machine Learning dates back to 1950’s. In recent years, there has been an increase in popularity for applications that implement AI and ML technology. As with traditional development, software testing is a critical component of an efficient AI/ML application. However, the approach to development methodology used in AI/ML varies significantly from traditional development. Owing to these variations, numerous software testing challenges occur. This paper aims to recognize and to explain some of the biggest challenges that software testers face in dealing with AI/ML applications. For future research, this study has key implications. Each of the challenges outlined in this paper is ideal for further investigation and has great potential to shed light on the way to more productive software testing strategies and methodologies that can be applied to AI/ML applications.",
      "keywords": []
    },
    "file_name": "c5e13acf97e1709c0ffc4f77125c36ea51bf2000.pdf"
  },
  {
    "success": true,
    "doc_id": "52edaeae5b4b8937c419e24b4f7c0e75",
    "summary": "This document, DARPA-BAA-16-41, is a Broad Agency Announcement (BAA) for the \"Dispersed Computing\" program, not a research paper presenting specific solutions. Therefore, the analysis below reflects the problems identified, the innovations sought, and the validation requirements outlined by DARPA for prospective researchers \\cite{zhao2021nv3}.\n\n---\n\n### Focused Summary for Literature Review: Dispersed Computing Program (DARPA-BAA-16-41)\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The program addresses the challenge of efficiently performing mission-aware computation and communication across broad-scale, physically dispersed, and heterogeneous computing infrastructure \\cite{zhao2021nv3}.\n    *   **Importance and Challenge**:\n        *   Current reliance on large, centralized data centers for significant computing tasks leads to problematic backhaul costs and latency, especially in scenarios with limited network throughput or near real-time response requirements \\cite{zhao2021nv3}.\n        *   The existing \"end-to-end\" Internet architecture confines application and transport-layer protocol logic primarily to endpoints, failing to leverage modern programmable, secure, high-speed information processing capabilities *within* the network \\cite{zhao2021nv3}.\n        *   The need for scalable, robust decision systems that can securely and collectively task diverse computing assets in a mission-aware fashion, even under highly variable and degraded network connectivity, is critical for military and broader applications \\cite{zhao2021nv3}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The BAA positions itself as seeking \"truly innovative, revolutionary approaches\" that represent a \"major advance over existing techniques,\" explicitly excluding \"evolutionary improvements\" \\cite{zhao2021nv3}. It calls for a \"fundamental reconsideration\" of how programmable execution environments within the network path can be leveraged \\cite{zhao2021nv3}.\n    *   **Limitations of Previous Solutions (as identified by the BAA)**:\n        *   Centralized computing models (e.g., large data centers) are inefficient and high-latency for many operational scenarios due to data backhaul requirements \\cite{zhao2021nv3}.\n        *   The traditional \"end-to-end\" design principle of the Internet prevents dynamic modification of protocol logic or localized in-path analytics, missing opportunities to boost performance through in-network computation \\cite{zhao2021nv3}.\n        *   Existing systems lack robust mechanisms for secure, collective, mission-aware tasking across a vast number of heterogeneous, physically dispersed computing platforms (Networked Computation Points or NCPs) \\cite{zhao2021nv3}.\n\n3.  **Technical Approach & Innovation (Desired from Proposers)**\n    *   **Core Technical Method/Algorithm**: The program seeks algorithms and protocols that enable \"strategic, opportunistic movement of code to data, and data to code\" \\cite{zhao2021nv3}. This includes:\n        *   Algorithms for efficient use of networked, geographically dispersed, heterogeneous computing capabilities, considering user, application, and mission requirements \\cite{zhao2021nv3}.\n        *   Novel network protocols that leverage programmable execution environments (NCPs) along the path between endpoints for dynamic protocol logic modification and in-path analytics \\cite{zhao2021nv3}.\n    *   **Novelty/Differentiation (Desired)**:\n        *   Addressing multi-dimensional optimization (processing latency, network latency, throughput) under dynamic and uncertain conditions \\cite{zhao2021nv3}.\n        *   Developing distributed control mechanisms for physically dispersed computing environments, contrasting with typical centralized controllers for parallel execution within data centers \\cite{zhao2021nv3}.\n        *   Incorporating capabilities to sense and recover from platform failures (e.g., physical damage, network connectivity loss, power outage) and integrate failure risk into job/data placement and replication decisions \\cite{zhao2021nv3}.\n        *   Prioritizing resource allocation among competing tasks and users in a mission-aware fashion, including meeting deadlines for mission-critical tasks \\cite{zhao2021nv3}.\n\n4.  **Key Technical Contributions (Desired from Proposers)**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   Algorithms for \"Dispersed Mission-Aware Computation\" (TA1) that manage code/data movement and task apportionment across heterogeneous, dispersed platforms \\cite{zhao2021nv3}.\n        *   Techniques for distributed control of computing resources across thousands of simultaneous users and locations \\cite{zhao2021nv3}.\n        *   New network protocols and programmable node functionalities (TA2) that enable in-network computation, dynamic protocol modification, and localized analytics \\cite{zhao2021nv3}.\n    *   **System Design or Architectural Innovations**:\n        *   Software instantiations for Networked Computation Points (NCPs) that can execute user applications, network protocol stacks, or both \\cite{zhao2021nv3}.\n        *   Architectures that facilitate robust operation in environments with highly variable and degraded network connectivity \\cite{zhao2021nv3}.\n    *   **Theoretical Insights or Analysis**: Implicitly, solutions are sought for the complex multi-dimensional optimization problems inherent in managing dispersed, mission-aware computing under uncertainty \\cite{zhao2021nv3}.\n\n5.  **Experimental Validation (Required from Proposers)**\n    *   **Experiments Conducted**: Proposers are required to devise and implement their own project-specific experimentation and demonstration capabilities, including plans for periodic demonstrations and potential field exercises \\cite{zhao2021nv3}. This may involve developing novel applications to showcase the unique value of dispersed computing architectures \\cite{zhao2021nv3}.\n    *   **Key Performance Metrics and Comparison Results**: Proposers must define metrics to assess system performance, along with a timetable and methodology for such assessments \\cite{zhao2021nv3}. These metrics should demonstrate advances in computation and/or networking capabilities relevant to the chosen contexts, implicitly focusing on improvements in latency, throughput, resilience, mission-aware resource allocation, and scalability \\cite{zhao2021nv3}.\n\n6.  **Limitations & Scope (Defined by the BAA)**\n    *   **Technical Limitations/Assumptions**: The program explicitly states that the design and production of hardware for computing platforms is *not* in scope \\cite{zhao2021nv3}. While cyber security aspects (authentication, authorization, secure code/data transfer, etc.) are not a primary research focus, proposals should account for them \\cite{zhao2021nv3}.\n    *   **Scope of Applicability**: Solutions should have broad applicability to various military and broader community scenarios, operating across diverse platforms (e.g., network elements, radios, smartphones, sensors, portable micro-clouds) and in environments with highly variable/degraded network connectivity \\cite{zhao2021nv3}.\n\n7.  **Technical Significance (Envisioned by the BAA)**\n    *   **Advancement of State-of-the-Art**: The program aims to produce \"revolutionary advances\" that boost application and network performance by \"orders of magnitude\" through the effective utilization of pervasive, physically dispersed computing infrastructure \\cite{zhao2021nv3}. It seeks to fundamentally change how computing and communication are managed in distributed environments \\cite{zhao2021nv3}.\n    *   **Potential Impact on Future Research**: The Dispersed Computing program is expected to drive research into scalable, robust decision systems for secure, collective, mission-aware tasking of heterogeneous computing assets, and new paradigms for dynamic code and data movement, paving the way for more resilient and efficient computing in challenging operational environments \\cite{zhao2021nv3}.",
    "intriguing_abstract": "The pervasive reliance on centralized data centers and the traditional \"end-to-end\" Internet architecture critically hobble modern computing in scenarios demanding low-latency, high-resilience, and mission-aware operations across vast, heterogeneous infrastructures. This paper introduces the revolutionary vision of **Dispersed Computing**, a paradigm shift addressing the fundamental challenge of efficiently performing computation and communication across physically dispersed, diverse computing assets. We explore the urgent need for strategic, opportunistic movement of **code to data and data to code**, leveraging novel **Networked Computation Points (NCPs)** for **in-network computation** and dynamic protocol modification. This approach promises to overcome limitations of current systems by enabling robust, distributed control and multi-dimensional optimization (processing latency, network latency, throughput) under highly variable connectivity. By fundamentally reconsidering how programmable execution environments within the network path can be utilized, Dispersed Computing offers orders-of-magnitude performance improvements, paving the way for scalable, secure, and mission-critical decision systems in the most challenging operational environments. Researchers are invited to delve into this transformative framework for the future of distributed intelligence.",
    "keywords": [
      "Dispersed Computing",
      "Mission-aware computation",
      "In-network computation",
      "Networked Computation Points (NCPs)",
      "Code to data movement",
      "Heterogeneous computing infrastructure",
      "Distributed control mechanisms",
      "Dynamic protocol modification",
      "Multi-dimensional optimization",
      "Degraded network connectivity",
      "Scalable robust decision systems",
      "Revolutionary computing architectures"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/06e5d18d333bd7cbf10072d52abdda3309ae9a50.pdf",
    "citation_key": "zhao2021nv3",
    "metadata": {
      "title": "A secure and flexible edge computing scheme for AI-driven industrial IoT",
      "authors": [
        "Yan Zhao",
        "Ning Hu",
        "Yue Zhao",
        "Zhihan Zhu"
      ],
      "published_date": "2021",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/06e5d18d333bd7cbf10072d52abdda3309ae9a50.pdf",
      "venue": "Cluster Computing",
      "citationCount": 18,
      "score": 4.5,
      "summary": "This document, DARPA-BAA-16-41, is a Broad Agency Announcement (BAA) for the \"Dispersed Computing\" program, not a research paper presenting specific solutions. Therefore, the analysis below reflects the problems identified, the innovations sought, and the validation requirements outlined by DARPA for prospective researchers \\cite{zhao2021nv3}.\n\n---\n\n### Focused Summary for Literature Review: Dispersed Computing Program (DARPA-BAA-16-41)\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The program addresses the challenge of efficiently performing mission-aware computation and communication across broad-scale, physically dispersed, and heterogeneous computing infrastructure \\cite{zhao2021nv3}.\n    *   **Importance and Challenge**:\n        *   Current reliance on large, centralized data centers for significant computing tasks leads to problematic backhaul costs and latency, especially in scenarios with limited network throughput or near real-time response requirements \\cite{zhao2021nv3}.\n        *   The existing \"end-to-end\" Internet architecture confines application and transport-layer protocol logic primarily to endpoints, failing to leverage modern programmable, secure, high-speed information processing capabilities *within* the network \\cite{zhao2021nv3}.\n        *   The need for scalable, robust decision systems that can securely and collectively task diverse computing assets in a mission-aware fashion, even under highly variable and degraded network connectivity, is critical for military and broader applications \\cite{zhao2021nv3}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The BAA positions itself as seeking \"truly innovative, revolutionary approaches\" that represent a \"major advance over existing techniques,\" explicitly excluding \"evolutionary improvements\" \\cite{zhao2021nv3}. It calls for a \"fundamental reconsideration\" of how programmable execution environments within the network path can be leveraged \\cite{zhao2021nv3}.\n    *   **Limitations of Previous Solutions (as identified by the BAA)**:\n        *   Centralized computing models (e.g., large data centers) are inefficient and high-latency for many operational scenarios due to data backhaul requirements \\cite{zhao2021nv3}.\n        *   The traditional \"end-to-end\" design principle of the Internet prevents dynamic modification of protocol logic or localized in-path analytics, missing opportunities to boost performance through in-network computation \\cite{zhao2021nv3}.\n        *   Existing systems lack robust mechanisms for secure, collective, mission-aware tasking across a vast number of heterogeneous, physically dispersed computing platforms (Networked Computation Points or NCPs) \\cite{zhao2021nv3}.\n\n3.  **Technical Approach & Innovation (Desired from Proposers)**\n    *   **Core Technical Method/Algorithm**: The program seeks algorithms and protocols that enable \"strategic, opportunistic movement of code to data, and data to code\" \\cite{zhao2021nv3}. This includes:\n        *   Algorithms for efficient use of networked, geographically dispersed, heterogeneous computing capabilities, considering user, application, and mission requirements \\cite{zhao2021nv3}.\n        *   Novel network protocols that leverage programmable execution environments (NCPs) along the path between endpoints for dynamic protocol logic modification and in-path analytics \\cite{zhao2021nv3}.\n    *   **Novelty/Differentiation (Desired)**:\n        *   Addressing multi-dimensional optimization (processing latency, network latency, throughput) under dynamic and uncertain conditions \\cite{zhao2021nv3}.\n        *   Developing distributed control mechanisms for physically dispersed computing environments, contrasting with typical centralized controllers for parallel execution within data centers \\cite{zhao2021nv3}.\n        *   Incorporating capabilities to sense and recover from platform failures (e.g., physical damage, network connectivity loss, power outage) and integrate failure risk into job/data placement and replication decisions \\cite{zhao2021nv3}.\n        *   Prioritizing resource allocation among competing tasks and users in a mission-aware fashion, including meeting deadlines for mission-critical tasks \\cite{zhao2021nv3}.\n\n4.  **Key Technical Contributions (Desired from Proposers)**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   Algorithms for \"Dispersed Mission-Aware Computation\" (TA1) that manage code/data movement and task apportionment across heterogeneous, dispersed platforms \\cite{zhao2021nv3}.\n        *   Techniques for distributed control of computing resources across thousands of simultaneous users and locations \\cite{zhao2021nv3}.\n        *   New network protocols and programmable node functionalities (TA2) that enable in-network computation, dynamic protocol modification, and localized analytics \\cite{zhao2021nv3}.\n    *   **System Design or Architectural Innovations**:\n        *   Software instantiations for Networked Computation Points (NCPs) that can execute user applications, network protocol stacks, or both \\cite{zhao2021nv3}.\n        *   Architectures that facilitate robust operation in environments with highly variable and degraded network connectivity \\cite{zhao2021nv3}.\n    *   **Theoretical Insights or Analysis**: Implicitly, solutions are sought for the complex multi-dimensional optimization problems inherent in managing dispersed, mission-aware computing under uncertainty \\cite{zhao2021nv3}.\n\n5.  **Experimental Validation (Required from Proposers)**\n    *   **Experiments Conducted**: Proposers are required to devise and implement their own project-specific experimentation and demonstration capabilities, including plans for periodic demonstrations and potential field exercises \\cite{zhao2021nv3}. This may involve developing novel applications to showcase the unique value of dispersed computing architectures \\cite{zhao2021nv3}.\n    *   **Key Performance Metrics and Comparison Results**: Proposers must define metrics to assess system performance, along with a timetable and methodology for such assessments \\cite{zhao2021nv3}. These metrics should demonstrate advances in computation and/or networking capabilities relevant to the chosen contexts, implicitly focusing on improvements in latency, throughput, resilience, mission-aware resource allocation, and scalability \\cite{zhao2021nv3}.\n\n6.  **Limitations & Scope (Defined by the BAA)**\n    *   **Technical Limitations/Assumptions**: The program explicitly states that the design and production of hardware for computing platforms is *not* in scope \\cite{zhao2021nv3}. While cyber security aspects (authentication, authorization, secure code/data transfer, etc.) are not a primary research focus, proposals should account for them \\cite{zhao2021nv3}.\n    *   **Scope of Applicability**: Solutions should have broad applicability to various military and broader community scenarios, operating across diverse platforms (e.g., network elements, radios, smartphones, sensors, portable micro-clouds) and in environments with highly variable/degraded network connectivity \\cite{zhao2021nv3}.\n\n7.  **Technical Significance (Envisioned by the BAA)**\n    *   **Advancement of State-of-the-Art**: The program aims to produce \"revolutionary advances\" that boost application and network performance by \"orders of magnitude\" through the effective utilization of pervasive, physically dispersed computing infrastructure \\cite{zhao2021nv3}. It seeks to fundamentally change how computing and communication are managed in distributed environments \\cite{zhao2021nv3}.\n    *   **Potential Impact on Future Research**: The Dispersed Computing program is expected to drive research into scalable, robust decision systems for secure, collective, mission-aware tasking of heterogeneous computing assets, and new paradigms for dynamic code and data movement, paving the way for more resilient and efficient computing in challenging operational environments \\cite{zhao2021nv3}.",
      "keywords": [
        "Dispersed Computing",
        "Mission-aware computation",
        "In-network computation",
        "Networked Computation Points (NCPs)",
        "Code to data movement",
        "Heterogeneous computing infrastructure",
        "Distributed control mechanisms",
        "Dynamic protocol modification",
        "Multi-dimensional optimization",
        "Degraded network connectivity",
        "Scalable robust decision systems",
        "Revolutionary computing architectures"
      ],
      "paper_type": "the provided \"abstract\" and \"introduction\" content does not appear to be from a research paper. instead, it looks like administrative text related to a darpa program (baa-16-41), discussing public release processes, eligibility information, and document structure.\n\ntherefore, it is impossible to classify the paper \"a secure and flexible edge computing scheme for ai-driven industrial iot\" based on the content provided, as the content does not reflect the paper's actual abstract or introduction."
    },
    "file_name": "06e5d18d333bd7cbf10072d52abdda3309ae9a50.pdf"
  },
  {
    "success": true,
    "doc_id": "dc2d15a72725ff87b003f6c1bd6b0378",
    "summary": "The purpose of this paper is to explore the advances in artificial intelligence (AI) chatbots as part of public services, mainly when applied to mental health in today’s post-pandemic world. The adoption of AI chatbots to keep up with basic customer support business activities is based on extensive knowledge, both from the hard (software development) and the soft side (increasing the added value to the service/product). However, using chatbots as extenders of public services to support mental health in pandemic times is an emerging research topic. Hence, the paper identifies niche and under-explored research gaps in state-of-the-art literature, thus contributing to the body of academic knowledge. The paper adopts a design science approach to formulate the problem statement, articulate the objectives of target solutions, and propose a design and development framework for future mental health chatbots by employing an extensive literature review. Findings from this paper emphasize considerations of ethical issues and governance, purposeful and goal-oriented design, and AI-based technology as critical enablers for designing new mental health chatbots. The paper contributes to the knowledge by providing clear and structured future research priorities and offers a framework for designing more effective and intelligent mental health chatbots that public organizations and managers may find useful.",
    "intriguing_abstract": "The purpose of this paper is to explore the advances in artificial intelligence (AI) chatbots as part of public services, mainly when applied to mental health in today’s post-pandemic world. The adoption of AI chatbots to keep up with basic customer support business activities is based on extensive knowledge, both from the hard (software development) and the soft side (increasing the added value to the service/product). However, using chatbots as extenders of public services to support mental health in pandemic times is an emerging research topic. Hence, the paper identifies niche and under-explored research gaps in state-of-the-art literature, thus contributing to the body of academic knowledge. The paper adopts a design science approach to formulate the problem statement, articulate the objectives of target solutions, and propose a design and development framework for future mental health chatbots by employing an extensive literature review. Findings from this paper emphasize considerations of ethical issues and governance, purposeful and goal-oriented design, and AI-based technology as critical enablers for designing new mental health chatbots. The paper contributes to the knowledge by providing clear and structured future research priorities and offers a framework for designing more effective and intelligent mental health chatbots that public organizations and managers may find useful.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a5e35909886f08faf55542ec4db6acfad9782eac.pdf",
    "citation_key": "damij2022kbt",
    "metadata": {
      "title": "The Role of AI Chatbots in Mental Health Related Public Services in a (Post)Pandemic World: A Review and Future Research Agenda",
      "authors": [
        "Nadja Damij",
        "S. Bhattacharya"
      ],
      "published_date": "2022",
      "abstract": "The purpose of this paper is to explore the advances in artificial intelligence (AI) chatbots as part of public services, mainly when applied to mental health in today’s post-pandemic world. The adoption of AI chatbots to keep up with basic customer support business activities is based on extensive knowledge, both from the hard (software development) and the soft side (increasing the added value to the service/product). However, using chatbots as extenders of public services to support mental health in pandemic times is an emerging research topic. Hence, the paper identifies niche and under-explored research gaps in state-of-the-art literature, thus contributing to the body of academic knowledge. The paper adopts a design science approach to formulate the problem statement, articulate the objectives of target solutions, and propose a design and development framework for future mental health chatbots by employing an extensive literature review. Findings from this paper emphasize considerations of ethical issues and governance, purposeful and goal-oriented design, and AI-based technology as critical enablers for designing new mental health chatbots. The paper contributes to the knowledge by providing clear and structured future research priorities and offers a framework for designing more effective and intelligent mental health chatbots that public organizations and managers may find useful.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a5e35909886f08faf55542ec4db6acfad9782eac.pdf",
      "venue": "2022 IEEE Technology and Engineering Management Conference (TEMSCON EUROPE)",
      "citationCount": 13,
      "score": 4.333333333333333,
      "summary": "The purpose of this paper is to explore the advances in artificial intelligence (AI) chatbots as part of public services, mainly when applied to mental health in today’s post-pandemic world. The adoption of AI chatbots to keep up with basic customer support business activities is based on extensive knowledge, both from the hard (software development) and the soft side (increasing the added value to the service/product). However, using chatbots as extenders of public services to support mental health in pandemic times is an emerging research topic. Hence, the paper identifies niche and under-explored research gaps in state-of-the-art literature, thus contributing to the body of academic knowledge. The paper adopts a design science approach to formulate the problem statement, articulate the objectives of target solutions, and propose a design and development framework for future mental health chatbots by employing an extensive literature review. Findings from this paper emphasize considerations of ethical issues and governance, purposeful and goal-oriented design, and AI-based technology as critical enablers for designing new mental health chatbots. The paper contributes to the knowledge by providing clear and structured future research priorities and offers a framework for designing more effective and intelligent mental health chatbots that public organizations and managers may find useful.",
      "keywords": []
    },
    "file_name": "a5e35909886f08faf55542ec4db6acfad9782eac.pdf"
  },
  {
    "success": true,
    "doc_id": "c9a17ba940f059b98ed113b965f6bb67",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the specific technical problem of understanding the views and experiences of AI practitioners regarding ethics in AI development and implementation \\cite{pant2022dlh}.\n    *   This problem is critical due to numerous incidents highlighting ethical failures in AI systems (e.g., bias in facial recognition, gender bias in recruitment tools, lack of transparency in algorithms) and public concerns about AI proliferation \\cite{pant2022dlh}.\n    *   Despite the existence of ethical principles and guidelines, their practical implementation ultimately rests with AI practitioners, making their perspective crucial yet underexplored in a consolidated manner \\cite{pant2022dlh}.\n    *   The lack of a universal definition for AI ethics and diverse ethical principles across organizations further complicates practical application.\n\n*   **Related Work & Positioning**\n    *   The work acknowledges a long history of ethics research in ICT and Software Engineering, including the development of professional codes of ethics and studies on their influence on professional conduct \\cite{pant2022dlh}.\n    *   It positions itself against existing secondary studies on AI ethics, which have primarily focused on identifying ethical principles, analyzing their normative consequences, exploring ethical concerns in specific domains, or reviewing general methods for ethical AI development \\cite{pant2022dlh}.\n    *   The key limitation of previous solutions is a gap in systematically synthesizing empirical research to understand the *direct perspectives, challenges, and approaches of AI practitioners* concerning ethics, which this paper aims to fill \\cite{pant2022dlh}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a **Grounded Theory Literature Review (GTLR)**, adapted from Wolfswinkel et al.'s (2013) framework \\cite{pant2022dlh}.\n    *   For data analysis, it innovatively applies procedures from **socio-technical grounded theory (STGT)** (Hoda, 2021), including open coding, targeted coding, constant comparison, and memoing, to synthesize findings from empirical literature \\cite{pant2022dlh}.\n    *   The novelty lies in applying this rigorous qualitative research methodology to systematically analyze *published empirical studies* focusing on AI practitioners' views, thereby building a theory (taxonomy) directly from existing evidence rather than conducting new primary data collection \\cite{pant2022dlh}.\n\n*   **Key Technical Contributions**\n    *   **Novel Method Application:** Demonstrates an example of applying GTLR, specifically STGT procedures, for in-depth analysis and theory development from literature as a data source within software engineering \\cite{pant2022dlh}.\n    *   **Systematic Taxonomy:** Develops a **taxonomy of ethics in AI from practitioners’ viewpoints**, structured into five categories: (i) practitioner awareness, (ii) practitioner perception, (iii) practitioner need, (iv) practitioner challenge, and (v) practitioner approach \\cite{pant2022dlh}. This taxonomy provides a structured, empirically-grounded landscape view of practitioners' concerns.\n    *   **Empirical Insights:** Provides a consolidated source of information on AI practitioners' real-world experiences and challenges with AI ethics, underpinned by evidence from 38 primary empirical studies \\cite{pant2022dlh}.\n\n*   **Experimental Validation**\n    *   The validation is conducted through the systematic process of the GTLR itself, which involved:\n        *   A defined research question guiding the review: \"What do we know from the literature about the AI practitioners’ views and experiences of ethics in AI?\" \\cite{pant2022dlh}.\n        *   Systematic search and selection of 38 primary empirical studies that directly captured AI practitioners' perspectives \\cite{pant2022dlh}.\n        *   Rigorous qualitative data analysis using STGT procedures (coding, constant comparison) to derive categories, codes, and concepts, ensuring the taxonomy is grounded in the analyzed literature \\cite{pant2022dlh}.\n    *   The \"results\" are the derived taxonomy and the detailed explanation of its categories, codes, and concepts, supported by evidence from the included studies, demonstrating the synthesis of empirical findings \\cite{pant2022dlh}.\n\n*   **Limitations & Scope**\n    *   The study's findings are inherently limited by the scope and quality of the *existing empirical literature* on AI practitioners' views, meaning it reflects what has been published rather than a comprehensive, real-time snapshot of all practitioners \\cite{pant2022dlh}.\n    *   The adopted definitions of AI ethics and principles, while necessary, acknowledge the lack of universal consensus, which might influence the framing of the derived taxonomy \\cite{pant2022dlh}.\n    *   The scope is focused specifically on **AI practitioners** (developers, engineers, specialists, experts) and their direct engagement with ethics in AI development \\cite{pant2022dlh}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing an **empirically grounded and structured understanding** of AI ethics from the perspective of those who build these systems, moving beyond theoretical or principle-centric discussions \\cite{pant2022dlh}.\n    *   The derived taxonomy offers a practical framework for identifying and understanding the multifaceted aspects of AI ethics relevant to practitioners \\cite{pant2022dlh}.\n    *   It provides concrete guidance for practitioners, managers, and organizations seeking to better consider and implement ethics in AI, and offers a clear agenda for future research in this critical area \\cite{pant2022dlh}.",
    "intriguing_abstract": "As AI proliferates, ethical failures continue to plague systems, underscoring a critical gap: understanding the perspectives of AI practitioners themselves. Despite numerous ethical guidelines, their practical implementation remains elusive, largely due to an underexplored understanding of the challenges and approaches faced by those on the front lines of AI development. This paper addresses this crucial void through a novel **Grounded Theory Literature Review (GTLR)**, innovatively applying **socio-technical grounded theory (STGT)** procedures to systematically synthesize empirical research on AI practitioners' views. From 38 primary studies, we unveil a comprehensive, empirically-grounded **taxonomy of ethics in AI from practitioners’ viewpoints**, categorizing their awareness, perceptions, needs, challenges, and approaches. This taxonomy moves beyond theoretical discourse, offering a structured framework and consolidated insights vital for guiding ethical AI development, informing organizational strategies, and charting future research. It provides a practical roadmap for embedding ethics into the very fabric of AI systems.",
    "keywords": [
      "AI ethics",
      "AI practitioners' perspectives",
      "Grounded Theory Literature Review (GTLR)",
      "Socio-technical Grounded Theory (STGT)",
      "Empirical literature synthesis",
      "Taxonomy of ethics in AI from practitioners' viewpoints",
      "Ethical failures in AI systems",
      "Bias in AI",
      "Transparency in algorithms",
      "Qualitative data analysis",
      "AI development and implementation",
      "Empirically grounded understanding",
      "Practitioner-centric AI ethics framework"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/752e1ee49aeb941cbd7616b8c901237a0a5d2a83.pdf",
    "citation_key": "pant2022dlh",
    "metadata": {
      "title": "Ethics in AI through the practitioner's view: a grounded theory literature review",
      "authors": [
        "Aastha Pant",
        "Rashina Hoda",
        "C. Tantithamthavorn",
        "Burak Turhan"
      ],
      "published_date": "2022",
      "abstract": "The term ethics is widely used, explored, and debated in the context of developing Artificial Intelligence (AI) based software systems. In recent years, numerous incidents have raised the profile of ethical issues in AI development and led to public concerns about the proliferation of AI technology in our everyday lives. But what do we know about the views and experiences of those who develop these systems – the AI practitioners? We conducted a grounded theory literature review (GTLR) of 38 primary empirical studies that included AI practitioners’ views on ethics in AI and analysed them to derive five categories: practitioner awareness, perception, need, challenge, and approach. These are underpinned by multiple codes and concepts that we explain with evidence from the included studies. We present a taxonomy of ethics in AI from practitioners’ viewpoints to assist AI practitioners in identifying and understanding the different aspects of AI ethics. The taxonomy provides a landscape view of the key aspects that concern AI practitioners when it comes to ethics in AI. We also share an agenda for future research studies and recommendations for practitioners, managers, and organisations to help in their efforts to better consider and implement ethics in AI.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/752e1ee49aeb941cbd7616b8c901237a0a5d2a83.pdf",
      "venue": "Empirical Software Engineering",
      "citationCount": 13,
      "score": 4.333333333333333,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the specific technical problem of understanding the views and experiences of AI practitioners regarding ethics in AI development and implementation \\cite{pant2022dlh}.\n    *   This problem is critical due to numerous incidents highlighting ethical failures in AI systems (e.g., bias in facial recognition, gender bias in recruitment tools, lack of transparency in algorithms) and public concerns about AI proliferation \\cite{pant2022dlh}.\n    *   Despite the existence of ethical principles and guidelines, their practical implementation ultimately rests with AI practitioners, making their perspective crucial yet underexplored in a consolidated manner \\cite{pant2022dlh}.\n    *   The lack of a universal definition for AI ethics and diverse ethical principles across organizations further complicates practical application.\n\n*   **Related Work & Positioning**\n    *   The work acknowledges a long history of ethics research in ICT and Software Engineering, including the development of professional codes of ethics and studies on their influence on professional conduct \\cite{pant2022dlh}.\n    *   It positions itself against existing secondary studies on AI ethics, which have primarily focused on identifying ethical principles, analyzing their normative consequences, exploring ethical concerns in specific domains, or reviewing general methods for ethical AI development \\cite{pant2022dlh}.\n    *   The key limitation of previous solutions is a gap in systematically synthesizing empirical research to understand the *direct perspectives, challenges, and approaches of AI practitioners* concerning ethics, which this paper aims to fill \\cite{pant2022dlh}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a **Grounded Theory Literature Review (GTLR)**, adapted from Wolfswinkel et al.'s (2013) framework \\cite{pant2022dlh}.\n    *   For data analysis, it innovatively applies procedures from **socio-technical grounded theory (STGT)** (Hoda, 2021), including open coding, targeted coding, constant comparison, and memoing, to synthesize findings from empirical literature \\cite{pant2022dlh}.\n    *   The novelty lies in applying this rigorous qualitative research methodology to systematically analyze *published empirical studies* focusing on AI practitioners' views, thereby building a theory (taxonomy) directly from existing evidence rather than conducting new primary data collection \\cite{pant2022dlh}.\n\n*   **Key Technical Contributions**\n    *   **Novel Method Application:** Demonstrates an example of applying GTLR, specifically STGT procedures, for in-depth analysis and theory development from literature as a data source within software engineering \\cite{pant2022dlh}.\n    *   **Systematic Taxonomy:** Develops a **taxonomy of ethics in AI from practitioners’ viewpoints**, structured into five categories: (i) practitioner awareness, (ii) practitioner perception, (iii) practitioner need, (iv) practitioner challenge, and (v) practitioner approach \\cite{pant2022dlh}. This taxonomy provides a structured, empirically-grounded landscape view of practitioners' concerns.\n    *   **Empirical Insights:** Provides a consolidated source of information on AI practitioners' real-world experiences and challenges with AI ethics, underpinned by evidence from 38 primary empirical studies \\cite{pant2022dlh}.\n\n*   **Experimental Validation**\n    *   The validation is conducted through the systematic process of the GTLR itself, which involved:\n        *   A defined research question guiding the review: \"What do we know from the literature about the AI practitioners’ views and experiences of ethics in AI?\" \\cite{pant2022dlh}.\n        *   Systematic search and selection of 38 primary empirical studies that directly captured AI practitioners' perspectives \\cite{pant2022dlh}.\n        *   Rigorous qualitative data analysis using STGT procedures (coding, constant comparison) to derive categories, codes, and concepts, ensuring the taxonomy is grounded in the analyzed literature \\cite{pant2022dlh}.\n    *   The \"results\" are the derived taxonomy and the detailed explanation of its categories, codes, and concepts, supported by evidence from the included studies, demonstrating the synthesis of empirical findings \\cite{pant2022dlh}.\n\n*   **Limitations & Scope**\n    *   The study's findings are inherently limited by the scope and quality of the *existing empirical literature* on AI practitioners' views, meaning it reflects what has been published rather than a comprehensive, real-time snapshot of all practitioners \\cite{pant2022dlh}.\n    *   The adopted definitions of AI ethics and principles, while necessary, acknowledge the lack of universal consensus, which might influence the framing of the derived taxonomy \\cite{pant2022dlh}.\n    *   The scope is focused specifically on **AI practitioners** (developers, engineers, specialists, experts) and their direct engagement with ethics in AI development \\cite{pant2022dlh}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing an **empirically grounded and structured understanding** of AI ethics from the perspective of those who build these systems, moving beyond theoretical or principle-centric discussions \\cite{pant2022dlh}.\n    *   The derived taxonomy offers a practical framework for identifying and understanding the multifaceted aspects of AI ethics relevant to practitioners \\cite{pant2022dlh}.\n    *   It provides concrete guidance for practitioners, managers, and organizations seeking to better consider and implement ethics in AI, and offers a clear agenda for future research in this critical area \\cite{pant2022dlh}.",
      "keywords": [
        "AI ethics",
        "AI practitioners' perspectives",
        "Grounded Theory Literature Review (GTLR)",
        "Socio-technical Grounded Theory (STGT)",
        "Empirical literature synthesis",
        "Taxonomy of ethics in AI from practitioners' viewpoints",
        "Ethical failures in AI systems",
        "Bias in AI",
        "Transparency in algorithms",
        "Qualitative data analysis",
        "AI development and implementation",
        "Empirically grounded understanding",
        "Practitioner-centric AI ethics framework"
      ],
      "paper_type": "based on the abstract and introduction, this paper is a **survey**.\n\nhere's why:\n\n*   **abstract explicitly states:** \"we conducted a grounded theory literature review (gtlr) of 38 primary empirical studies...\"\n*   **abstract mentions:** \"...analysed them to derive five categories...\", \"we present a taxonomy of ethics in ai from practitioners’ viewpoints...\", \"the taxonomy provides a landscape view of the key aspects...\" these phrases align with reviewing existing literature, organizing it, and presenting classification schemes.\n*   **introduction discusses:** the lack of a universal definition of ai ethics and the adoption of definitions and principles from other sources (siau and wang, australia's ai ethics principles, european commission, us department of defense), which is characteristic of a paper reviewing and synthesizing existing knowledge.\n\nthese points directly match the criteria for a **survey** paper: \"reviews existing literature comprehensively\" and \"introduction discusses: literature organization, classification schemes.\""
    },
    "file_name": "752e1ee49aeb941cbd7616b8c901237a0a5d2a83.pdf"
  },
  {
    "success": true,
    "doc_id": "362e20e9529c259fcab9b4ecfc99b027",
    "summary": "With the development of software-defined network (SDN), there will be a large number of devices to access network, which may cause an incalculable burden to the communication network. In addition, due to the high bandwidth in the fifth-generation (5G) era, innovation will occur in different fields. There are not only strict requirements on the communication capability of SDN for these application scenarios but also a lot of computing resources. For massive access devices, it is difficult for the traditional service resource scheduling and the allocation system to meet user demand growth. To address the above-stated problems, an artificial intelligence agent (AI Agent) system is put forth in this article. AI Agents can be deployed in different layers of the SDN, thus realizing functions like network service prediction and resource scheduling. A brand new AI Agent framework is designed, and an AI algorithm is adopted to replace the traditional service prediction and resource scheduling strategies. In the meantime, a relevant agent deployment scheme is put forward. Finally, an AI Agent-based simulation experiment for resource scheduling is designed, and the accuracy in network service prediction and rationality in resource allocation based on this framework are tested. The experimental result showed that the operation efficiency of the SDN can be effectively improved, and the resource hit ratio and user service quality may be improved with AI-agent-based traffic prediction and resource allocation model.",
    "intriguing_abstract": "With the development of software-defined network (SDN), there will be a large number of devices to access network, which may cause an incalculable burden to the communication network. In addition, due to the high bandwidth in the fifth-generation (5G) era, innovation will occur in different fields. There are not only strict requirements on the communication capability of SDN for these application scenarios but also a lot of computing resources. For massive access devices, it is difficult for the traditional service resource scheduling and the allocation system to meet user demand growth. To address the above-stated problems, an artificial intelligence agent (AI Agent) system is put forth in this article. AI Agents can be deployed in different layers of the SDN, thus realizing functions like network service prediction and resource scheduling. A brand new AI Agent framework is designed, and an AI algorithm is adopted to replace the traditional service prediction and resource scheduling strategies. In the meantime, a relevant agent deployment scheme is put forward. Finally, an AI Agent-based simulation experiment for resource scheduling is designed, and the accuracy in network service prediction and rationality in resource allocation based on this framework are tested. The experimental result showed that the operation efficiency of the SDN can be effectively improved, and the resource hit ratio and user service quality may be improved with AI-agent-based traffic prediction and resource allocation model.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9495148c32432ce89dd34d3d164fab0855b4caf2.pdf",
    "citation_key": "cao2020ojh",
    "metadata": {
      "title": "AI Agent in Software-Defined Network: Agent-Based Network Service Prediction and Wireless Resource Scheduling Optimization",
      "authors": [
        "Yong Cao",
        "Rui Wang",
        "Min Chen",
        "A. Barnawi"
      ],
      "published_date": "2020",
      "abstract": "With the development of software-defined network (SDN), there will be a large number of devices to access network, which may cause an incalculable burden to the communication network. In addition, due to the high bandwidth in the fifth-generation (5G) era, innovation will occur in different fields. There are not only strict requirements on the communication capability of SDN for these application scenarios but also a lot of computing resources. For massive access devices, it is difficult for the traditional service resource scheduling and the allocation system to meet user demand growth. To address the above-stated problems, an artificial intelligence agent (AI Agent) system is put forth in this article. AI Agents can be deployed in different layers of the SDN, thus realizing functions like network service prediction and resource scheduling. A brand new AI Agent framework is designed, and an AI algorithm is adopted to replace the traditional service prediction and resource scheduling strategies. In the meantime, a relevant agent deployment scheme is put forward. Finally, an AI Agent-based simulation experiment for resource scheduling is designed, and the accuracy in network service prediction and rationality in resource allocation based on this framework are tested. The experimental result showed that the operation efficiency of the SDN can be effectively improved, and the resource hit ratio and user service quality may be improved with AI-agent-based traffic prediction and resource allocation model.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9495148c32432ce89dd34d3d164fab0855b4caf2.pdf",
      "venue": "IEEE Internet of Things Journal",
      "citationCount": 21,
      "score": 4.2,
      "summary": "With the development of software-defined network (SDN), there will be a large number of devices to access network, which may cause an incalculable burden to the communication network. In addition, due to the high bandwidth in the fifth-generation (5G) era, innovation will occur in different fields. There are not only strict requirements on the communication capability of SDN for these application scenarios but also a lot of computing resources. For massive access devices, it is difficult for the traditional service resource scheduling and the allocation system to meet user demand growth. To address the above-stated problems, an artificial intelligence agent (AI Agent) system is put forth in this article. AI Agents can be deployed in different layers of the SDN, thus realizing functions like network service prediction and resource scheduling. A brand new AI Agent framework is designed, and an AI algorithm is adopted to replace the traditional service prediction and resource scheduling strategies. In the meantime, a relevant agent deployment scheme is put forward. Finally, an AI Agent-based simulation experiment for resource scheduling is designed, and the accuracy in network service prediction and rationality in resource allocation based on this framework are tested. The experimental result showed that the operation efficiency of the SDN can be effectively improved, and the resource hit ratio and user service quality may be improved with AI-agent-based traffic prediction and resource allocation model.",
      "keywords": []
    },
    "file_name": "9495148c32432ce89dd34d3d164fab0855b4caf2.pdf"
  },
  {
    "success": true,
    "doc_id": "b9f4784bc5887e01a5ffaa3d9ed064c3",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of \"safe model compression\" for deep learning models \\cite{zhu2022oq6}. While model compression is crucial for deploying large AI models on resource-restricted devices (e.g., smartphones), compressed models often inherit or even exacerbate vulnerabilities (e.g., privacy leakage) from their larger counterparts.\n    *   **Importance & Challenge**: The problem is critical because compressed models are widely deployed, increasing their exposure to attackers. Existing approaches that sequentially apply compression and then protection often lead to suboptimal performance and safety due to a lack of interaction between the two processes. The core challenge is to co-optimize both model performance and safety during the compression process.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds upon traditional AI model compression techniques (e.g., pruning, knowledge distillation) and model protection methods (e.g., differential privacy, defenses against membership inference attacks) \\cite{zhu2022oq6}.\n    *   **Limitations of Previous Solutions**: Previous model compression primarily focuses on reducing size while maintaining task performance. Model protection techniques are typically applied *after* compression. The paper highlights that a \"two-step solution\" (compress then protect) suffers from poor model performance and low safety because it fails to consider the intricate interactions between compression and protection mechanisms \\cite{zhu2022oq6}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes `SafeCompress`, a test-driven sparse training framework for safe model compression \\cite{zhu2022oq6}. It is inspired by test-driven development (TDD) and dynamic sparse training (DST).\n    *   **Novelty**: `SafeCompress` introduces an iterative, co-optimization approach where attack mechanisms are simulated as \"safety tests\" during the compression process. This allows for simultaneous optimization of both model performance and safety. A concrete instance, `MIA-SafeCompress`, is developed to defend against Membership Inference Attacks (MIAs), incorporating an entropy-based regularizer to increase model output uncertainty and enhance safety \\cite{zhu2022oq6}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   `SafeCompress`: A general, test-driven, iterative framework for safe model compression that co-optimizes performance and safety by simulating attacks as tests \\cite{zhu2022oq6}.\n        *   `MIA-SafeCompress`: A concrete instantiation of `SafeCompress` specifically designed to defend against Membership Inference Attacks, enhanced with an entropy-based regularizer \\cite{zhu2022oq6}.\n    *   **System Design/Architectural Innovations**: The `SafeCompress` framework is structured into three stages: Sparsity-Aware Model Initialization, Candidate Sparse Model and Simulated Attacker Generation, and Safety Test-driven Model Selection \\cite{zhu2022oq6}.\n    *   **Theoretical Insights/Analysis**: The problem is formulated as a bi-objective optimization problem, aiming to minimize both task performance loss and attack gain under sparsity constraints \\cite{zhu2022oq6}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were conducted using `MIA-SafeCompress` as a showcase for the `SafeCompress` framework \\cite{zhu2022oq6}.\n    *   **Key Performance Metrics & Comparison Results**: The method was evaluated on five datasets covering both computer vision and natural language processing tasks. Results demonstrated that `MIA-SafeCompress` significantly outperforms baseline solutions that combine state-of-the-art compression and MIA defense techniques, verifying its effectiveness and generalization \\cite{zhu2022oq6}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: While `SafeCompress` is general, its concrete implementation (`MIA-SafeCompress`) is tailored to Membership Inference Attacks. Adapting it to other attack types requires configuring the simulated attack mechanism \\cite{zhu2022oq6}. The iterative process relies on predefined stopping criteria.\n    *   **Scope of Applicability**: The framework is designed for DNN model compression and is adaptable to heterogeneous AI tasks (e.g., CV, NLP) and various pre-specified attack mechanisms \\cite{zhu2022oq6}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper represents a pioneering effort in safe model compression, moving beyond sequential compression and protection to a co-optimization paradigm \\cite{zhu2022oq6}. It addresses a critical gap in ensuring the security and privacy of AI software deployed on edge devices.\n    *   **Potential Impact on Future Research**: `SafeCompress` provides a generalizable framework that can inspire future research into co-optimizing other non-functional requirements (e.g., robustness, fairness) alongside performance during model compression. It paves the way for more secure and efficient large-scale AI software deployment \\cite{zhu2022oq6}.",
    "intriguing_abstract": "Deploying powerful deep learning models on resource-constrained devices necessitates aggressive model compression, yet this often inadvertently amplifies critical vulnerabilities like privacy leakage. Current sequential approaches, which first compress and then protect, are fundamentally flawed, leading to suboptimal performance and compromised safety. We introduce `SafeCompress`, a pioneering test-driven sparse training framework designed for truly safe model compression. Inspired by test-driven development (TDD) and dynamic sparse training (DST), `SafeCompress` innovatively co-optimizes model performance and safety by simulating attack mechanisms as \"safety tests\" directly within the iterative compression process. We present `MIA-SafeCompress`, a concrete instantiation specifically engineered to defend against Membership Inference Attacks (MIAs), incorporating a novel entropy-based regularizer to enhance privacy. Extensive experiments across diverse datasets demonstrate that `MIA-SafeCompress` significantly outperforms state-of-the-art baselines, validating its effectiveness and generalization. `SafeCompress` marks a crucial advancement, enabling the secure and efficient deployment of AI software by ensuring privacy and robustness from the ground up, paving the way for trustworthy AI on the edge.",
    "keywords": [
      "Safe model compression",
      "deep learning models",
      "resource-constrained devices",
      "AI model privacy",
      "Membership Inference Attacks (MIAs)",
      "co-optimization (performance and safety)",
      "SafeCompress framework",
      "test-driven sparse training",
      "MIA-SafeCompress",
      "entropy-based regularizer",
      "bi-objective optimization",
      "simulated attack mechanisms",
      "dynamic sparse training",
      "computer vision and NLP"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ded0f3ac4c904f0f91bb937bb2bfd5fcb591c777.pdf",
    "citation_key": "zhu2022oq6",
    "metadata": {
      "title": "Safety and Performance, Why not Both? Bi-Objective Optimized Model Compression toward AI Software Deployment",
      "authors": [
        "Jie Zhu",
        "Leye Wang",
        "Xiao Han"
      ],
      "published_date": "2022",
      "abstract": "The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, which hinders the large-scale deployment on resource-restricted devices (e.g., smartphones). To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in the big model may be inherited by the compressed one. Such defects may be easily leveraged by attackers, since the compressed models are usually deployed in a large number of devices without adequate protection. In this paper, we try to address the safe model compression problem from a safety-performance co-optimization perspective. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as the safety test, SafeCompress can automatically compress a big model to a small one following the dynamic sparse training paradigm. Further, considering a representative attack, i.e., membership inference attack (MIA), we develop a concrete safe model compression mechanism, called MIA-SafeCompress. Extensive experiments are conducted to evaluate MIA-SafeCompress on five datasets for both computer vision and natural language processing tasks. The results verify the effectiveness and generalization of our method. We also discuss how to adapt SafeCompress to other attacks besides MIA, demonstrating the flexibility of SafeCompress.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ded0f3ac4c904f0f91bb937bb2bfd5fcb591c777.pdf",
      "venue": "International Conference on Automated Software Engineering",
      "citationCount": 12,
      "score": 4.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of \"safe model compression\" for deep learning models \\cite{zhu2022oq6}. While model compression is crucial for deploying large AI models on resource-restricted devices (e.g., smartphones), compressed models often inherit or even exacerbate vulnerabilities (e.g., privacy leakage) from their larger counterparts.\n    *   **Importance & Challenge**: The problem is critical because compressed models are widely deployed, increasing their exposure to attackers. Existing approaches that sequentially apply compression and then protection often lead to suboptimal performance and safety due to a lack of interaction between the two processes. The core challenge is to co-optimize both model performance and safety during the compression process.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work builds upon traditional AI model compression techniques (e.g., pruning, knowledge distillation) and model protection methods (e.g., differential privacy, defenses against membership inference attacks) \\cite{zhu2022oq6}.\n    *   **Limitations of Previous Solutions**: Previous model compression primarily focuses on reducing size while maintaining task performance. Model protection techniques are typically applied *after* compression. The paper highlights that a \"two-step solution\" (compress then protect) suffers from poor model performance and low safety because it fails to consider the intricate interactions between compression and protection mechanisms \\cite{zhu2022oq6}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes `SafeCompress`, a test-driven sparse training framework for safe model compression \\cite{zhu2022oq6}. It is inspired by test-driven development (TDD) and dynamic sparse training (DST).\n    *   **Novelty**: `SafeCompress` introduces an iterative, co-optimization approach where attack mechanisms are simulated as \"safety tests\" during the compression process. This allows for simultaneous optimization of both model performance and safety. A concrete instance, `MIA-SafeCompress`, is developed to defend against Membership Inference Attacks (MIAs), incorporating an entropy-based regularizer to increase model output uncertainty and enhance safety \\cite{zhu2022oq6}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms/Methods**:\n        *   `SafeCompress`: A general, test-driven, iterative framework for safe model compression that co-optimizes performance and safety by simulating attacks as tests \\cite{zhu2022oq6}.\n        *   `MIA-SafeCompress`: A concrete instantiation of `SafeCompress` specifically designed to defend against Membership Inference Attacks, enhanced with an entropy-based regularizer \\cite{zhu2022oq6}.\n    *   **System Design/Architectural Innovations**: The `SafeCompress` framework is structured into three stages: Sparsity-Aware Model Initialization, Candidate Sparse Model and Simulated Attacker Generation, and Safety Test-driven Model Selection \\cite{zhu2022oq6}.\n    *   **Theoretical Insights/Analysis**: The problem is formulated as a bi-objective optimization problem, aiming to minimize both task performance loss and attack gain under sparsity constraints \\cite{zhu2022oq6}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were conducted using `MIA-SafeCompress` as a showcase for the `SafeCompress` framework \\cite{zhu2022oq6}.\n    *   **Key Performance Metrics & Comparison Results**: The method was evaluated on five datasets covering both computer vision and natural language processing tasks. Results demonstrated that `MIA-SafeCompress` significantly outperforms baseline solutions that combine state-of-the-art compression and MIA defense techniques, verifying its effectiveness and generalization \\cite{zhu2022oq6}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: While `SafeCompress` is general, its concrete implementation (`MIA-SafeCompress`) is tailored to Membership Inference Attacks. Adapting it to other attack types requires configuring the simulated attack mechanism \\cite{zhu2022oq6}. The iterative process relies on predefined stopping criteria.\n    *   **Scope of Applicability**: The framework is designed for DNN model compression and is adaptable to heterogeneous AI tasks (e.g., CV, NLP) and various pre-specified attack mechanisms \\cite{zhu2022oq6}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper represents a pioneering effort in safe model compression, moving beyond sequential compression and protection to a co-optimization paradigm \\cite{zhu2022oq6}. It addresses a critical gap in ensuring the security and privacy of AI software deployed on edge devices.\n    *   **Potential Impact on Future Research**: `SafeCompress` provides a generalizable framework that can inspire future research into co-optimizing other non-functional requirements (e.g., robustness, fairness) alongside performance during model compression. It paves the way for more secure and efficient large-scale AI software deployment \\cite{zhu2022oq6}.",
      "keywords": [
        "Safe model compression",
        "deep learning models",
        "resource-constrained devices",
        "AI model privacy",
        "Membership Inference Attacks (MIAs)",
        "co-optimization (performance and safety)",
        "SafeCompress framework",
        "test-driven sparse training",
        "MIA-SafeCompress",
        "entropy-based regularizer",
        "bi-objective optimization",
        "simulated attack mechanisms",
        "dynamic sparse training",
        "computer vision and NLP"
      ],
      "paper_type": "this paper is best classified as **technical**.\n\nhere's why:\n\n*   **abstract:** it explicitly states \"we propose a test-driven sparse training framework called safecompress\" and \"we develop a concrete safe model compression mechanism, called mia-safecompress.\" these phrases directly align with the \"technical\" criteria of presenting new methods, algorithms, or systems.\n*   **introduction (first part):** it sets up a technical problem (large ai models hindering deployment) and the need for a solution (ai software compression).\n*   **empirical component:** while the abstract mentions \"extensive experiments are conducted to evaluate mia-safecompress on five datasets\" and \"the results verify the effectiveness and generalization of our method,\" this empirical work serves to validate the *new method* being proposed and developed. the primary contribution is the creation of the safecompress framework and mia-safecompress mechanism, with the experiments demonstrating their efficacy. many technical papers include empirical evaluation to support their proposed solutions."
    },
    "file_name": "ded0f3ac4c904f0f91bb937bb2bfd5fcb591c777.pdf"
  },
  {
    "success": true,
    "doc_id": "9bb683a32f251f2711332db06f2f84d1",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the growing lack of consumer trust in ubiquitous software, particularly those incorporating Artificial Intelligence (AI), Internet of Things (IoT), cloud services, and mobile technologies \\cite{cysneiros2020bew}. This trust deficit is exacerbated in mission-critical applications where concerns about safety, privacy, and ethics are paramount.\n    *   This problem is important because software's pervasive nature and increasing autonomy mean its decisions have significant social and legal implications. Building consumer trust is crucial for market acceptance, fostering loyalty, and avoiding negative societal impacts and potential legal disputes. Existing approaches to trust often lack a comprehensive social perspective \\cite{cysneiros2020bew}.\n\n*   **Related Work & Positioning**\n    *   The work relates to existing research on trust in machine learning and decision support systems but positions itself by arguing that these often view trust in a \"single dimension\" and fail to capture its social consequences \\cite{cysneiros2020bew}.\n    *   It leverages insights from Corporate Social Responsibility (CSR) literature, which demonstrates CSR's role in promoting loyalty, transparency, and reducing information asymmetry, adapting these principles to the software domain \\cite{cysneiros2020bew}.\n    *   The paper builds upon the Non-Functional Requirements (NFR) framework and Softgoal Interdependencies Goals (SIG) catalogues for modeling and operationalizing requirements \\cite{cysneiros2020bew}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes an NFR-oriented approach to guide software development towards trustworthiness and social responsibility. It identifies a core set of NFRs (Trust, Ethics, Transparency, Privacy, Safety, Security) derived from CSR principles and existing NFR knowledge. These NFRs and their interdependencies are then modeled using a Softgoal Interdependencies Goals (SIG) diagram \\cite{cysneiros2020bew}.\n    *   **Novelty/Difference**:\n        *   The primary innovation lies in adapting principles from Corporate Social Responsibility (CSR), traditionally a business domain concept, to explicitly orient software development processes through the lens of Non-Functional Requirements \\cite{cysneiros2020bew}.\n        *   It introduces a multi-dimensional view of trust in software, integrating social concerns (ethics, privacy, safety, security) and emphasizing transparency as a crucial enabler for trust and mitigation of legal risks \\cite{cysneiros2020bew}.\n        *   The use of SIG catalogues is proposed as a structured way to operationalize these complex, often conflicting, NFRs in software design, moving beyond single-dimensional trust considerations \\cite{cysneiros2020bew}.\n\n*   **Key Technical Contributions**\n    *   **Novel Methodological Framework**: A systematic approach to derive and integrate socially-oriented NFRs (Ethics, Safety, Security, Privacy, Transparency) into software development, anchored by the overarching goal of Trust, using insights from Corporate Social Responsibility \\cite{cysneiros2020bew}.\n    *   **Conceptual Model**: Identification and conceptualization of a core set of NFRs crucial for socially responsible software, and their interdependencies, visualized in a Softgoal Interdependencies Goals (SIG) diagram (Fig. 1) \\cite{cysneiros2020bew}. This model illustrates how Ethics, Safety, Privacy, and Security *Help* Trust, and how Transparency *Helps* these contributions and *Mitigates* Legal Disputes \\cite{cysneiros2020bew}.\n    *   **NFR Framework Extension**: The paper extends the NFR Framework by proposing specific NFRs and their relationships to address the emerging challenges of trust and social responsibility in AI, IoT, and other advanced software systems \\cite{cysneiros2020bew}.\n    *   **Future Work Direction**: It lays the groundwork for developing detailed SIG catalogues for operationalizing these NFRs, which would provide concrete solutions and guide software reuse processes \\cite{cysneiros2020bew}.\n\n*   **Experimental Validation**\n    *   The paper's validation primarily consists of a **brief literature review** rather than empirical experiments on software systems \\cite{cysneiros2020bew}.\n    *   A literature review was conducted in the CSR domain (2015-2019) using keywords like \"(csr AND trust)\" and \"(corporate social responsibility AND Trust)\". From 112 initial publications, 22 were reviewed after filtering for relevance to CSR and Trust \\cite{cysneiros2020bew}.\n    *   Knowledge was elicited from these references to identify frequently mentioned properties expected in companies adopting CSR. These properties were then analyzed from an NFR perspective to identify Trust, Ethics, and Transparency, with Privacy, Safety, and Security identified as interacting NFRs based on existing knowledge \\cite{cysneiros2020bew}.\n    *   **No quantitative performance metrics or comparative results from software implementations are presented**, as this is an \"idea paper\" focused on establishing foundational NFRs and their conceptual model \\cite{cysneiros2020bew}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: As an \"idea paper,\" it presents a foundational argument and conceptual model but does not provide concrete operationalizations, algorithms, or detailed architectural solutions for the identified NFRs \\cite{cysneiros2020bew}. The complexity of operationalizing concepts like \"Ethics\" is acknowledged \\cite{cysneiros2020bew}.\n    *   **Scope of Applicability**: The proposed NFRs are considered \"basic\" and \"anchor\" NFRs, primarily applicable to software aiming for social responsibility and trustworthiness, especially in domains involving AI, IoT, cloud services, and mission-critical applications \\cite{cysneiros2020bew}. It acknowledges that other NFRs (e.g., Reliability) are also relevant but are not the core focus \\cite{cysneiros2020bew}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The paper advances the state-of-the-art by bridging corporate social responsibility principles with software engineering practices through the NFR framework \\cite{cysneiros2020bew}. It provides a structured, multi-dimensional conceptualization of trust in software, moving beyond purely technical reliability to encompass crucial social and ethical dimensions \\cite{cysneiros2020bew}.\n    *   **Potential Impact**:\n        *   It offers a foundational set of NFRs to guide software developers in building trustworthy and socially responsible systems from the outset, which is particularly critical for emerging technologies like AI and IoT \\cite{cysneiros2020bew}.\n        *   It highlights the importance of transparency and the identified NFRs in mitigating legal disputes and fostering consumer acceptance, which is vital for the software industry \\cite{cysneiros2020bew}.\n        *   It inspires future research into operationalizing these complex NFRs through detailed SIG catalogues, systematic solution searching, and integration into software reuse processes, thereby contributing to more ethical and trusted software ecosystems \\cite{cysneiros2020bew}.",
    "intriguing_abstract": "The pervasive integration of Artificial Intelligence (AI), Internet of Things (IoT), and cloud services into mission-critical applications has severely eroded consumer trust, posing significant social, ethical, and legal challenges. This paper introduces a novel Non-Functional Requirements (NFR)-oriented approach to systematically embed social responsibility into software development, directly addressing this critical trust deficit. We uniquely adapt principles from Corporate Social Responsibility (CSR) to define a core set of NFRs: Trust, Ethics, Transparency, Privacy, Safety, and Security.\n\nOur key contribution is a multi-dimensional conceptualization of trust, modeled through a Softgoal Interdependencies Goals (SIG) diagram, which illustrates how these crucial NFRs interact to foster trustworthiness. This framework moves beyond single-dimensional trust considerations, emphasizing transparency as a vital enabler for mitigating legal risks and building genuine consumer loyalty. By bridging CSR with software engineering, this work provides a foundational methodology for designing socially responsible software, crucial for market acceptance and ethical development in the era of autonomous systems. It lays the groundwork for operationalizing complex NFRs, guiding developers towards building a more trusted digital future.",
    "keywords": [
      "Consumer trust",
      "Ubiquitous software",
      "Non-Functional Requirements (NFR)",
      "Softgoal Interdependencies Goals (SIG)",
      "Corporate Social Responsibility (CSR) adaptation",
      "NFR-oriented approach",
      "Trustworthiness",
      "Socially-oriented NFRs",
      "Transparency",
      "Multi-dimensional trust",
      "Socially responsible software development",
      "Conceptual model",
      "Legal disputes mitigation"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/91aae70e76aa43426b6ee2d8ce8f6213377bf475.pdf",
    "citation_key": "cysneiros2020bew",
    "metadata": {
      "title": "Non-Functional Requirements Orienting the Development of Socially Responsible Software",
      "authors": [
        "L. M. Cysneiros",
        "Julio Cesar Sampaio do Prado Leite"
      ],
      "published_date": "2020",
      "abstract": "Nowadays, software is ubiquitous and present in almost everything we buy and use. Artificial intelligence (AI) is becoming prevalent in software products. The use of AI entices consumer inquisitiveness, promising software products that can make our lives easier, productive, and in some mission-critical applications safer. Similar reasoning can be applied to systems exploring Internet of Things, cloud services, and mobile technologies. However, there is a trust deficit when it comes to accepting AI as well as the other above-mentioned features, as a reliable technology platform. This paper argues that the more critical the domain is, the less consumers seem to trust software to make decisions on their behalf or even to be used. Aspects such as safety, privacy, and ethics challenges the perception of trustworthy computing. In the past two decades, several works have suggested that Corporate Social Responsibility (CSR) may play an essential role in creating a trust paradigm between customers and businesses promoting loyalty, customer retention and thus enhancing customer trust and increasing corporate profit. We believe that the software industry will need soon rather than later to encourage trust in their embedded software. A promising approach lies in adapting principles associated with CSR to guide the software development processes. Such an approach could help to achieve two goals: Deliver trustworthy software and, if desired, deliver socially responsible software. We believe that Non-Functional Requirements (NFR) will play a crucial role in this endeavor. This paper highlights a first approach to establishing a basic set of NFRs that should always be carefully considered when developing software, as to aim socially responsible software.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/91aae70e76aa43426b6ee2d8ce8f6213377bf475.pdf",
      "venue": "BPMDS/EMMSAD@CAiSE",
      "citationCount": 20,
      "score": 4.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the growing lack of consumer trust in ubiquitous software, particularly those incorporating Artificial Intelligence (AI), Internet of Things (IoT), cloud services, and mobile technologies \\cite{cysneiros2020bew}. This trust deficit is exacerbated in mission-critical applications where concerns about safety, privacy, and ethics are paramount.\n    *   This problem is important because software's pervasive nature and increasing autonomy mean its decisions have significant social and legal implications. Building consumer trust is crucial for market acceptance, fostering loyalty, and avoiding negative societal impacts and potential legal disputes. Existing approaches to trust often lack a comprehensive social perspective \\cite{cysneiros2020bew}.\n\n*   **Related Work & Positioning**\n    *   The work relates to existing research on trust in machine learning and decision support systems but positions itself by arguing that these often view trust in a \"single dimension\" and fail to capture its social consequences \\cite{cysneiros2020bew}.\n    *   It leverages insights from Corporate Social Responsibility (CSR) literature, which demonstrates CSR's role in promoting loyalty, transparency, and reducing information asymmetry, adapting these principles to the software domain \\cite{cysneiros2020bew}.\n    *   The paper builds upon the Non-Functional Requirements (NFR) framework and Softgoal Interdependencies Goals (SIG) catalogues for modeling and operationalizing requirements \\cite{cysneiros2020bew}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes an NFR-oriented approach to guide software development towards trustworthiness and social responsibility. It identifies a core set of NFRs (Trust, Ethics, Transparency, Privacy, Safety, Security) derived from CSR principles and existing NFR knowledge. These NFRs and their interdependencies are then modeled using a Softgoal Interdependencies Goals (SIG) diagram \\cite{cysneiros2020bew}.\n    *   **Novelty/Difference**:\n        *   The primary innovation lies in adapting principles from Corporate Social Responsibility (CSR), traditionally a business domain concept, to explicitly orient software development processes through the lens of Non-Functional Requirements \\cite{cysneiros2020bew}.\n        *   It introduces a multi-dimensional view of trust in software, integrating social concerns (ethics, privacy, safety, security) and emphasizing transparency as a crucial enabler for trust and mitigation of legal risks \\cite{cysneiros2020bew}.\n        *   The use of SIG catalogues is proposed as a structured way to operationalize these complex, often conflicting, NFRs in software design, moving beyond single-dimensional trust considerations \\cite{cysneiros2020bew}.\n\n*   **Key Technical Contributions**\n    *   **Novel Methodological Framework**: A systematic approach to derive and integrate socially-oriented NFRs (Ethics, Safety, Security, Privacy, Transparency) into software development, anchored by the overarching goal of Trust, using insights from Corporate Social Responsibility \\cite{cysneiros2020bew}.\n    *   **Conceptual Model**: Identification and conceptualization of a core set of NFRs crucial for socially responsible software, and their interdependencies, visualized in a Softgoal Interdependencies Goals (SIG) diagram (Fig. 1) \\cite{cysneiros2020bew}. This model illustrates how Ethics, Safety, Privacy, and Security *Help* Trust, and how Transparency *Helps* these contributions and *Mitigates* Legal Disputes \\cite{cysneiros2020bew}.\n    *   **NFR Framework Extension**: The paper extends the NFR Framework by proposing specific NFRs and their relationships to address the emerging challenges of trust and social responsibility in AI, IoT, and other advanced software systems \\cite{cysneiros2020bew}.\n    *   **Future Work Direction**: It lays the groundwork for developing detailed SIG catalogues for operationalizing these NFRs, which would provide concrete solutions and guide software reuse processes \\cite{cysneiros2020bew}.\n\n*   **Experimental Validation**\n    *   The paper's validation primarily consists of a **brief literature review** rather than empirical experiments on software systems \\cite{cysneiros2020bew}.\n    *   A literature review was conducted in the CSR domain (2015-2019) using keywords like \"(csr AND trust)\" and \"(corporate social responsibility AND Trust)\". From 112 initial publications, 22 were reviewed after filtering for relevance to CSR and Trust \\cite{cysneiros2020bew}.\n    *   Knowledge was elicited from these references to identify frequently mentioned properties expected in companies adopting CSR. These properties were then analyzed from an NFR perspective to identify Trust, Ethics, and Transparency, with Privacy, Safety, and Security identified as interacting NFRs based on existing knowledge \\cite{cysneiros2020bew}.\n    *   **No quantitative performance metrics or comparative results from software implementations are presented**, as this is an \"idea paper\" focused on establishing foundational NFRs and their conceptual model \\cite{cysneiros2020bew}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: As an \"idea paper,\" it presents a foundational argument and conceptual model but does not provide concrete operationalizations, algorithms, or detailed architectural solutions for the identified NFRs \\cite{cysneiros2020bew}. The complexity of operationalizing concepts like \"Ethics\" is acknowledged \\cite{cysneiros2020bew}.\n    *   **Scope of Applicability**: The proposed NFRs are considered \"basic\" and \"anchor\" NFRs, primarily applicable to software aiming for social responsibility and trustworthiness, especially in domains involving AI, IoT, cloud services, and mission-critical applications \\cite{cysneiros2020bew}. It acknowledges that other NFRs (e.g., Reliability) are also relevant but are not the core focus \\cite{cysneiros2020bew}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The paper advances the state-of-the-art by bridging corporate social responsibility principles with software engineering practices through the NFR framework \\cite{cysneiros2020bew}. It provides a structured, multi-dimensional conceptualization of trust in software, moving beyond purely technical reliability to encompass crucial social and ethical dimensions \\cite{cysneiros2020bew}.\n    *   **Potential Impact**:\n        *   It offers a foundational set of NFRs to guide software developers in building trustworthy and socially responsible systems from the outset, which is particularly critical for emerging technologies like AI and IoT \\cite{cysneiros2020bew}.\n        *   It highlights the importance of transparency and the identified NFRs in mitigating legal disputes and fostering consumer acceptance, which is vital for the software industry \\cite{cysneiros2020bew}.\n        *   It inspires future research into operationalizing these complex NFRs through detailed SIG catalogues, systematic solution searching, and integration into software reuse processes, thereby contributing to more ethical and trusted software ecosystems \\cite{cysneiros2020bew}.",
      "keywords": [
        "Consumer trust",
        "Ubiquitous software",
        "Non-Functional Requirements (NFR)",
        "Softgoal Interdependencies Goals (SIG)",
        "Corporate Social Responsibility (CSR) adaptation",
        "NFR-oriented approach",
        "Trustworthiness",
        "Socially-oriented NFRs",
        "Transparency",
        "Multi-dimensional trust",
        "Socially responsible software development",
        "Conceptual model",
        "Legal disputes mitigation"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"this paper argues that...\", \"we believe that the software industry will need soon rather than later to encourage trust...\", \"a promising approach lies in adapting principles associated with csr...\", \"this paper highlights a first approach to establishing a basic set of nfrs that should always be carefully considered...\".\n*   the introduction reinforces this with: \"therefore, we believe that the software development process needs to address ways to assure consumers they can trust the software...\".\n*   the paper identifies a problem (trust deficit in ai/software), argues for its importance, and proposes a conceptual direction or viewpoint (adapting csr principles through nfrs) to address it. it's advocating for a particular way of thinking and a future direction for software development.\n\nthis aligns perfectly with the criteria for a **position** paper.\n\n**classification:** position"
    },
    "file_name": "91aae70e76aa43426b6ee2d8ce8f6213377bf475.pdf"
  },
  {
    "success": true,
    "doc_id": "5714b0773143fcedeb1e1154a075758b",
    "summary": "Here's a focused summary of the technical/research paper for a literature review, adhering to your requirements:\n\n---\n\n**Analysis of the Urgent Response Fund for Wildlife Conservation \\cite{nandutu2021umv}**\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the escalating crisis of illegal poaching and wildlife trafficking that is causing severe population declines in Africa's iconic species (elephants, rhinos, large carnivores, and African apes).\n    *   **Importance & Challenge:** This problem is critical due to the rapid decimation of wildlife populations (e.g., 20,000-35,000 elephants killed annually, 9,200% increase in rhino poaching between 2007-2014). Elephant mortality currently exceeds natural birth rates, and rhino populations are projected to have negative growth rates if poaching continues. The challenge lies in combating a complex, multi-faceted criminal enterprise that spans from on-the-ground killing to international trafficking and consumer demand.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds upon and expands AWF's previous \"Species Protection Grants (SPG)\" program, which provided funding (US$50,000-$100,000) for practical anti-poaching equipment (e.g., GPS units, motorbikes) and direct support to partners on the ground.\n    *   **Limitations of Previous Solutions:** While SPG showed success in reducing poaching in specific areas (e.g., Manyara Ranch Conservancy, Lower Zambezi National Park), it was not a comprehensive, full-scale response addressing all components of the illegal wildlife trade supply chain. The crisis persisted, indicating a need for a more robust and integrated strategy. The Urgent Response Fund is positioned as an \"upgraded version\" of SPG, committing significantly more resources and broadening its scope.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper outlines a comprehensive, multi-pronged strategy through the \"Urgent Response Fund,\" committing US$10 million over three years. This approach targets three interconnected areas of the illegal wildlife trade supply chain: \"Stop the Killing,\" \"Stop the Trafficking,\" and \"Stop the Demand.\"\n    *   **Novelty/Difference:** The innovation lies in its holistic and integrated approach.\n        *   **\"Stop the Killing\":** Expands direct anti-poaching efforts, including funding for rangers, equipment, aerial patrols (helicopters), and deployment of canine detection units in conservation areas. It also incorporates community engagement models (e.g., \"Wolf Ambassadors,\" camera trap incentive programs).\n        *   **\"Stop the Trafficking\":** Introduces targeted interventions to disrupt the criminal trade route, specifically strengthening detection capabilities at key African ports (e.g., through trained sniffer dogs) and enhancing prosecutorial efforts via specialized training for magistrates and prosecutors.\n        *   **\"Stop the Demand\":** Addresses the root cause by implementing public awareness campaigns in Asia (leveraging celebrities like Jackie Chan), facilitating high-level China–Africa policy dialogues on natural resource management, and conducting awareness campaigns within Africa to foster local ownership of conservation.\n\n4.  **Key Technical Contributions**\n    *   **System Design/Architectural Innovations:** The \"Urgent Response Fund\" itself represents a novel programmatic architecture for conservation, integrating diverse interventions across the entire illegal wildlife trade value chain (source, transit, demand).\n    *   **Novel Algorithms/Methods/Techniques (within conservation context):**\n        *   Strategic deployment of canine detection units at critical trafficking hotspots.\n        *   Development and implementation of specialized prosecutorial training programs for wildlife crime.\n        *   Leveraging celebrity endorsements and targeted public awareness campaigns for demand reduction in key consumer markets.\n        *   Facilitation of \"Track II dialogs\" for policy influence between African and Chinese stakeholders.\n        *   Integration of advanced monitoring technologies (e.g., CyberTracker handheld devices for rangers, camera traps for community-based monitoring) with incentive programs.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The paper presents observational results and case studies from projects funded by the precursor SPG program and initial activities under the Urgent Response Fund, rather than formal controlled experiments.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Manyara Ranch Conservancy:** Reported zero elephants poached since the deployment of tracker dogs and Honeyguide Foundation patrols, compared to 15 poached in 2012.\n        *   **Lower Zambezi National Park:** Elephant poaching decreased from 24 in 2011 (pre-AWF support) to 5 in 2013 (after one year of SPG funding).\n        *   **Overall SPG:** Disbursed over US$1.5 million, protecting approximately 20 distinct populations of target species across Africa.\n        *   **Demand Reduction:** A public awareness campaign in China and Vietnam (started 2012) is described as \"successful,\" though specific quantitative metrics for its success are not provided in this document.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper assumes a direct causal link between increased funding, equipment, training, and awareness efforts, and a reduction in poaching and trafficking. Quantitative evidence for the effectiveness of some interventions, particularly demand reduction campaigns, is stated but not detailed. The long-term sustainability of the fund's impact beyond its three-year commitment is not explicitly addressed.\n    *   **Scope of Applicability:** The fund's activities are primarily focused on Africa's most threatened iconic species (elephants, rhinos, large carnivores, African apes) and specific geographic hotspots for poaching and trafficking within Africa, as well as key demand markets in Asia.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art:** The paper signifies a strategic evolution in conservation efforts by advocating for and implementing a truly integrated, supply-chain-oriented approach to combating wildlife crime. It moves beyond traditional on-the-ground protection to systematically address law enforcement and demand reduction, representing a more sophisticated and comprehensive conservation model.\n    *   **Potential Impact on Future Research:** This work highlights the critical need for multi-faceted, collaborative strategies in conservation. It suggests avenues for future research into the quantitative effectiveness of demand reduction campaigns, the impact of specialized prosecutorial training, and the optimal integration of technology (e.g., canine units, aerial surveillance, digital monitoring) across the entire wildlife crime supply chain. The fund's structured approach could serve as a valuable case study or model for designing and evaluating large-scale conservation interventions.",
    "intriguing_abstract": "Africa's iconic wildlife faces an unprecedented crisis, with illegal poaching and wildlife trafficking driving species like elephants and rhinos towards extinction. This paper introduces the Urgent Response Fund, a novel, US$10 million initiative designed to combat this complex criminal enterprise through a comprehensive, integrated strategy. Moving beyond traditional anti-poaching efforts, our approach targets the entire illegal wildlife trade supply chain: 'Stop the Killing' through enhanced ranger support and advanced detection technologies like canine units; 'Stop the Trafficking' by strengthening interdiction at critical ports and implementing specialized prosecutorial training; and 'Stop the Demand' via targeted public awareness campaigns and high-level policy dialogues. This programmatic architecture represents a significant evolution in conservation, offering a holistic model that integrates on-the-ground protection with sophisticated law enforcement and demand reduction strategies. We present initial successes from precursor programs and outline how this fund aims to reverse devastating population declines, setting a new standard for effective, large-scale wildlife conservation interventions.",
    "keywords": [
      "Urgent Response Fund",
      "illegal wildlife trade supply chain",
      "holistic integrated conservation",
      "anti-poaching strategies",
      "wildlife trafficking disruption",
      "demand reduction campaigns",
      "canine detection units",
      "specialized prosecutorial training",
      "community engagement in conservation",
      "advanced monitoring technologies",
      "elephant and rhino conservation",
      "novel programmatic architecture",
      "China-Africa policy dialogues",
      "wildlife crime mitigation"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/bab98e802060ae6cac5325d9da7b4cc61811e8ef.pdf",
    "citation_key": "nandutu2021umv",
    "metadata": {
      "title": "Integrating AI ethics in wildlife conservation AI systems in South Africa: a review, challenges, and future research agenda",
      "authors": [
        "Irene Nandutu",
        "M. Atemkeng",
        "Patrice Okouma"
      ],
      "published_date": "2021",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/bab98e802060ae6cac5325d9da7b4cc61811e8ef.pdf",
      "venue": "Ai & Society",
      "citationCount": 16,
      "score": 4.0,
      "summary": "Here's a focused summary of the technical/research paper for a literature review, adhering to your requirements:\n\n---\n\n**Analysis of the Urgent Response Fund for Wildlife Conservation \\cite{nandutu2021umv}**\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the escalating crisis of illegal poaching and wildlife trafficking that is causing severe population declines in Africa's iconic species (elephants, rhinos, large carnivores, and African apes).\n    *   **Importance & Challenge:** This problem is critical due to the rapid decimation of wildlife populations (e.g., 20,000-35,000 elephants killed annually, 9,200% increase in rhino poaching between 2007-2014). Elephant mortality currently exceeds natural birth rates, and rhino populations are projected to have negative growth rates if poaching continues. The challenge lies in combating a complex, multi-faceted criminal enterprise that spans from on-the-ground killing to international trafficking and consumer demand.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds upon and expands AWF's previous \"Species Protection Grants (SPG)\" program, which provided funding (US$50,000-$100,000) for practical anti-poaching equipment (e.g., GPS units, motorbikes) and direct support to partners on the ground.\n    *   **Limitations of Previous Solutions:** While SPG showed success in reducing poaching in specific areas (e.g., Manyara Ranch Conservancy, Lower Zambezi National Park), it was not a comprehensive, full-scale response addressing all components of the illegal wildlife trade supply chain. The crisis persisted, indicating a need for a more robust and integrated strategy. The Urgent Response Fund is positioned as an \"upgraded version\" of SPG, committing significantly more resources and broadening its scope.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper outlines a comprehensive, multi-pronged strategy through the \"Urgent Response Fund,\" committing US$10 million over three years. This approach targets three interconnected areas of the illegal wildlife trade supply chain: \"Stop the Killing,\" \"Stop the Trafficking,\" and \"Stop the Demand.\"\n    *   **Novelty/Difference:** The innovation lies in its holistic and integrated approach.\n        *   **\"Stop the Killing\":** Expands direct anti-poaching efforts, including funding for rangers, equipment, aerial patrols (helicopters), and deployment of canine detection units in conservation areas. It also incorporates community engagement models (e.g., \"Wolf Ambassadors,\" camera trap incentive programs).\n        *   **\"Stop the Trafficking\":** Introduces targeted interventions to disrupt the criminal trade route, specifically strengthening detection capabilities at key African ports (e.g., through trained sniffer dogs) and enhancing prosecutorial efforts via specialized training for magistrates and prosecutors.\n        *   **\"Stop the Demand\":** Addresses the root cause by implementing public awareness campaigns in Asia (leveraging celebrities like Jackie Chan), facilitating high-level China–Africa policy dialogues on natural resource management, and conducting awareness campaigns within Africa to foster local ownership of conservation.\n\n4.  **Key Technical Contributions**\n    *   **System Design/Architectural Innovations:** The \"Urgent Response Fund\" itself represents a novel programmatic architecture for conservation, integrating diverse interventions across the entire illegal wildlife trade value chain (source, transit, demand).\n    *   **Novel Algorithms/Methods/Techniques (within conservation context):**\n        *   Strategic deployment of canine detection units at critical trafficking hotspots.\n        *   Development and implementation of specialized prosecutorial training programs for wildlife crime.\n        *   Leveraging celebrity endorsements and targeted public awareness campaigns for demand reduction in key consumer markets.\n        *   Facilitation of \"Track II dialogs\" for policy influence between African and Chinese stakeholders.\n        *   Integration of advanced monitoring technologies (e.g., CyberTracker handheld devices for rangers, camera traps for community-based monitoring) with incentive programs.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The paper presents observational results and case studies from projects funded by the precursor SPG program and initial activities under the Urgent Response Fund, rather than formal controlled experiments.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Manyara Ranch Conservancy:** Reported zero elephants poached since the deployment of tracker dogs and Honeyguide Foundation patrols, compared to 15 poached in 2012.\n        *   **Lower Zambezi National Park:** Elephant poaching decreased from 24 in 2011 (pre-AWF support) to 5 in 2013 (after one year of SPG funding).\n        *   **Overall SPG:** Disbursed over US$1.5 million, protecting approximately 20 distinct populations of target species across Africa.\n        *   **Demand Reduction:** A public awareness campaign in China and Vietnam (started 2012) is described as \"successful,\" though specific quantitative metrics for its success are not provided in this document.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper assumes a direct causal link between increased funding, equipment, training, and awareness efforts, and a reduction in poaching and trafficking. Quantitative evidence for the effectiveness of some interventions, particularly demand reduction campaigns, is stated but not detailed. The long-term sustainability of the fund's impact beyond its three-year commitment is not explicitly addressed.\n    *   **Scope of Applicability:** The fund's activities are primarily focused on Africa's most threatened iconic species (elephants, rhinos, large carnivores, African apes) and specific geographic hotspots for poaching and trafficking within Africa, as well as key demand markets in Asia.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art:** The paper signifies a strategic evolution in conservation efforts by advocating for and implementing a truly integrated, supply-chain-oriented approach to combating wildlife crime. It moves beyond traditional on-the-ground protection to systematically address law enforcement and demand reduction, representing a more sophisticated and comprehensive conservation model.\n    *   **Potential Impact on Future Research:** This work highlights the critical need for multi-faceted, collaborative strategies in conservation. It suggests avenues for future research into the quantitative effectiveness of demand reduction campaigns, the impact of specialized prosecutorial training, and the optimal integration of technology (e.g., canine units, aerial surveillance, digital monitoring) across the entire wildlife crime supply chain. The fund's structured approach could serve as a valuable case study or model for designing and evaluating large-scale conservation interventions.",
      "keywords": [
        "Urgent Response Fund",
        "illegal wildlife trade supply chain",
        "holistic integrated conservation",
        "anti-poaching strategies",
        "wildlife trafficking disruption",
        "demand reduction campaigns",
        "canine detection units",
        "specialized prosecutorial training",
        "community engagement in conservation",
        "advanced monitoring technologies",
        "elephant and rhino conservation",
        "novel programmatic architecture",
        "China-Africa policy dialogues",
        "wildlife crime mitigation"
      ],
      "paper_type": "the provided \"abstract\" and \"introduction\" content does not match the paper's title. the content describes an \"urgent response fund\" and conservation efforts, while the title is about \"integrating ai ethics in wildlife conservation ai systems... a review, challenges, and future research agenda.\"\n\ntherefore, i will classify the paper based solely on its **title**: \"integrating ai ethics in wildlife conservation ai systems in south africa: a **review**, **challenges**, and **future research agenda**\".\n\nlet's analyze the title against the classification criteria:\n\n1.  **survey**: reviews existing literature comprehensively\n    *   the title explicitly states \"a **review**\".\n    *   \"challenges, and future research agenda\" are common components of a comprehensive survey paper that identifies gaps and proposes future directions.\n\n2.  **technical**: presents new methods, algorithms, or systems\n    *   the title does not mention proposing new methods, algorithms, or systems.\n\n3.  **theoretical**: mathematical analysis, proofs, formal models\n    *   the title does not suggest mathematical analysis or formal models.\n\n4.  **empirical**: data-driven studies with statistical analysis\n    *   the title does not indicate an experiment, data analysis, or statistical findings.\n\n5.  **case_study**: detailed analysis of specific applications\n    *   while \"in south africa\" provides a specific context, the primary descriptor is \"a review,\" not \"a case study.\"\n\n6.  **position**: argues for viewpoint or future direction\n    *   \"future research agenda\" strongly aligns with arguing for a future direction. \"challenges\" also fits with identifying problems and proposing solutions/directions. a survey often forms the basis for a position on future work.\n\n7.  **short**: brief communication or work-in-progress\n    *   the title suggests a comprehensive paper (\"a review\"), and the venue \"ai & society\" is a journal, not typically for short communications.\n\n**conclusion:**\n\nthe most prominent keyword in the title is \"**review**,\" which directly matches the definition of a **survey** paper. while \"challenges, and future research agenda\" also align with a **position** paper, these elements are very common and often integral parts of a comprehensive survey paper that aims to synthesize current knowledge, identify gaps, and guide future research. a survey paper often concludes by taking a \"position\" on what future work is needed. given the explicit mention of \"a review,\" **survey** is the most direct and fitting classification.\n\n**classification:** survey"
    },
    "file_name": "bab98e802060ae6cac5325d9da7b4cc61811e8ef.pdf"
  },
  {
    "success": true,
    "doc_id": "fc2a3714956a66b6aa66879c3a47bf34",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/4765f23ebb071e0beb6c85d7cad64ff35d9fa91e.pdf",
    "citation_key": "tosun2020g0g",
    "metadata": {
      "title": "HistoMapr™: An Explainable AI (xAI) Platform for Computational Pathology Solutions",
      "authors": [
        "A. B. Tosun",
        "F. Pullara",
        "M. Becich",
        "D. L. Taylor",
        "S. Chennubhotla",
        "J. Fine"
      ],
      "published_date": "2020",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/4765f23ebb071e0beb6c85d7cad64ff35d9fa91e.pdf",
      "venue": "AI and ML for Digital Pathology",
      "citationCount": 20,
      "score": 4.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "4765f23ebb071e0beb6c85d7cad64ff35d9fa91e.pdf"
  },
  {
    "success": true,
    "doc_id": "8514b00e141421bdd6b5a7036d9590fb",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f0dfcb4b85d9d5a827b8e244aa64721ad8c7550e.pdf",
    "citation_key": "maleki20149js",
    "metadata": {
      "title": "A New Approach for Software Cost Estimation with Hybrid Genetic Algorithm and Ant Colony Optimization",
      "authors": [
        "Isa Maleki",
        "A. Ghaffari",
        "Mohammad Masdari"
      ],
      "published_date": "2014",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f0dfcb4b85d9d5a827b8e244aa64721ad8c7550e.pdf",
      "venue": "",
      "citationCount": 42,
      "score": 3.8181818181818183,
      "summary": "",
      "keywords": []
    },
    "file_name": "f0dfcb4b85d9d5a827b8e244aa64721ad8c7550e.pdf"
  },
  {
    "success": true,
    "doc_id": "efb42e16e75b979329fdd1cf6c83615a",
    "summary": "Artificial Intelligence (AI) is experiencing a \"diversity crisis.\"1 Several reports1-3 have shown how the breakthrough of modern AI has not yet been able to improve on existing diversity challenges regarding gender, race, geography, and other factors, neither for the end users of those products nor the companies and organizations building them. Plenty of examples have surfaced in which biased data engineering practices or existing data sets led to incorrect, painful, or sometimes even harmful consequences for unassuming end users.4 The problem is that ruling out such biases is not straightforward due to the sheer number of different bias types.5 To have a chance to eliminate as many biases as possible, most of the experts agree that the teams and organizations building AI products should be made more diverse.1-3 This harkens back to Linus' law6 for open source development (\"given enough eyeballs, all bugs are shallow\") but applied to the development process of AI products.",
    "intriguing_abstract": "Artificial Intelligence (AI) is experiencing a \"diversity crisis.\"1 Several reports1-3 have shown how the breakthrough of modern AI has not yet been able to improve on existing diversity challenges regarding gender, race, geography, and other factors, neither for the end users of those products nor the companies and organizations building them. Plenty of examples have surfaced in which biased data engineering practices or existing data sets led to incorrect, painful, or sometimes even harmful consequences for unassuming end users.4 The problem is that ruling out such biases is not straightforward due to the sheer number of different bias types.5 To have a chance to eliminate as many biases as possible, most of the experts agree that the teams and organizations building AI products should be made more diverse.1-3 This harkens back to Linus' law6 for open source development (\"given enough eyeballs, all bugs are shallow\") but applied to the development process of AI products.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/52ad599144f4f42bab61a8c132698296fa9758b7.pdf",
    "citation_key": "adams2020kb6",
    "metadata": {
      "title": "The Diversity Crisis of Software Engineering for Artificial Intelligence",
      "authors": [
        "Bram Adams",
        "Foutse Khomh"
      ],
      "published_date": "2020",
      "abstract": "Artificial Intelligence (AI) is experiencing a \"diversity crisis.\"1 Several reports1-3 have shown how the breakthrough of modern AI has not yet been able to improve on existing diversity challenges regarding gender, race, geography, and other factors, neither for the end users of those products nor the companies and organizations building them. Plenty of examples have surfaced in which biased data engineering practices or existing data sets led to incorrect, painful, or sometimes even harmful consequences for unassuming end users.4 The problem is that ruling out such biases is not straightforward due to the sheer number of different bias types.5 To have a chance to eliminate as many biases as possible, most of the experts agree that the teams and organizations building AI products should be made more diverse.1-3 This harkens back to Linus' law6 for open source development (\"given enough eyeballs, all bugs are shallow\") but applied to the development process of AI products.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/52ad599144f4f42bab61a8c132698296fa9758b7.pdf",
      "venue": "IEEE Software",
      "citationCount": 19,
      "score": 3.8000000000000003,
      "summary": "Artificial Intelligence (AI) is experiencing a \"diversity crisis.\"1 Several reports1-3 have shown how the breakthrough of modern AI has not yet been able to improve on existing diversity challenges regarding gender, race, geography, and other factors, neither for the end users of those products nor the companies and organizations building them. Plenty of examples have surfaced in which biased data engineering practices or existing data sets led to incorrect, painful, or sometimes even harmful consequences for unassuming end users.4 The problem is that ruling out such biases is not straightforward due to the sheer number of different bias types.5 To have a chance to eliminate as many biases as possible, most of the experts agree that the teams and organizations building AI products should be made more diverse.1-3 This harkens back to Linus' law6 for open source development (\"given enough eyeballs, all bugs are shallow\") but applied to the development process of AI products.",
      "keywords": []
    },
    "file_name": "52ad599144f4f42bab61a8c132698296fa9758b7.pdf"
  },
  {
    "success": true,
    "doc_id": "3c65bcdaefcc5d48bb3c908a613d340d",
    "summary": "This chapter argues that international human rights standards offer the most promising basis for developing a coherent and universally recognized set of standards that can be applied to meet any of the normative concerns currently falling under the rubric of AI (artificial intelligence) ethics. It then outlines the core elements of a human rights–centered design, deliberation, and oversight approach to the governance of AI. This approach requires that human rights norms are systemically considered at every stage of system design, development, and deployment, drawing upon and adapting technical methods and techniques for safe software and system design, verification, testing, and auditing in order to ensure compliance with human rights norms. The regime must be mandated by law and relies critically on external oversight by independent, competent, and properly resourced regulatory authorities with appropriate powers of investigation and enforcement. However, this approach will not ensure the protection of all ethical values adversely implicated by AI, given that human rights norms do not comprehensively cover all values of societal concern. As such, a great deal more work needs to be done to develop techniques and methodologies that are robust—reliable yet practically implementable across a wide and diverse range of organizations involved in developing, building, and operating AI systems.",
    "intriguing_abstract": "This chapter argues that international human rights standards offer the most promising basis for developing a coherent and universally recognized set of standards that can be applied to meet any of the normative concerns currently falling under the rubric of AI (artificial intelligence) ethics. It then outlines the core elements of a human rights–centered design, deliberation, and oversight approach to the governance of AI. This approach requires that human rights norms are systemically considered at every stage of system design, development, and deployment, drawing upon and adapting technical methods and techniques for safe software and system design, verification, testing, and auditing in order to ensure compliance with human rights norms. The regime must be mandated by law and relies critically on external oversight by independent, competent, and properly resourced regulatory authorities with appropriate powers of investigation and enforcement. However, this approach will not ensure the protection of all ethical values adversely implicated by AI, given that human rights norms do not comprehensively cover all values of societal concern. As such, a great deal more work needs to be done to develop techniques and methodologies that are robust—reliable yet practically implementable across a wide and diverse range of organizations involved in developing, building, and operating AI systems.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/c2a288ca7bdae6f029e9f663ef33530e010882dd.pdf",
    "citation_key": "yeung20205sw",
    "metadata": {
      "title": "AI Governance by Human Rights–Centered Design, Deliberation, and Oversight",
      "authors": [
        "K. Yeung",
        "A. Howes",
        "Ganna Pogrebna"
      ],
      "published_date": "2020",
      "abstract": "This chapter argues that international human rights standards offer the most promising basis for developing a coherent and universally recognized set of standards that can be applied to meet any of the normative concerns currently falling under the rubric of AI (artificial intelligence) ethics. It then outlines the core elements of a human rights–centered design, deliberation, and oversight approach to the governance of AI. This approach requires that human rights norms are systemically considered at every stage of system design, development, and deployment, drawing upon and adapting technical methods and techniques for safe software and system design, verification, testing, and auditing in order to ensure compliance with human rights norms. The regime must be mandated by law and relies critically on external oversight by independent, competent, and properly resourced regulatory authorities with appropriate powers of investigation and enforcement. However, this approach will not ensure the protection of all ethical values adversely implicated by AI, given that human rights norms do not comprehensively cover all values of societal concern. As such, a great deal more work needs to be done to develop techniques and methodologies that are robust—reliable yet practically implementable across a wide and diverse range of organizations involved in developing, building, and operating AI systems.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/c2a288ca7bdae6f029e9f663ef33530e010882dd.pdf",
      "venue": "",
      "citationCount": 19,
      "score": 3.8000000000000003,
      "summary": "This chapter argues that international human rights standards offer the most promising basis for developing a coherent and universally recognized set of standards that can be applied to meet any of the normative concerns currently falling under the rubric of AI (artificial intelligence) ethics. It then outlines the core elements of a human rights–centered design, deliberation, and oversight approach to the governance of AI. This approach requires that human rights norms are systemically considered at every stage of system design, development, and deployment, drawing upon and adapting technical methods and techniques for safe software and system design, verification, testing, and auditing in order to ensure compliance with human rights norms. The regime must be mandated by law and relies critically on external oversight by independent, competent, and properly resourced regulatory authorities with appropriate powers of investigation and enforcement. However, this approach will not ensure the protection of all ethical values adversely implicated by AI, given that human rights norms do not comprehensively cover all values of societal concern. As such, a great deal more work needs to be done to develop techniques and methodologies that are robust—reliable yet practically implementable across a wide and diverse range of organizations involved in developing, building, and operating AI systems.",
      "keywords": []
    },
    "file_name": "c2a288ca7bdae6f029e9f663ef33530e010882dd.pdf"
  },
  {
    "success": true,
    "doc_id": "df7617c929e0e1bc6d96684887152ff5",
    "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: High-level AI ethics principles and guidelines, despite their proliferation, fail to translate into actionable advice for practitioners, leading to a significant gap between ethical aspirations and practical AI software development \\cite{vakkuri2021n6l}. Existing guidelines lack standardization, suffer from low industry adoption, and do not provide concrete \"how-to\" guidance.\n    *   **Motivation**: With AI systems becoming pervasive and impacting critical decision-making (e.g., healthcare, transportation), there is an urgent need for systematic guidance to ensure the development of ethically sound AI. The authors argue that AI software, being software, can benefit from the structured improvement approach of maturity models, which have proven effective in traditional software engineering \\cite{vakkuri2021n6l}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Numerous organizations have published AI ethics principles and guidelines (e.g., IEEE, EU Commission). Some AI-specific process models exist (e.g., Microsoft nine-step pipeline, \"stairway to heaven\" AI model). Traditional software engineering maturity models (e.g., CMMI, SAFe) are widely used.\n    *   **Limitations of Previous Solutions**:\n        *   AI ethics guidelines are abstract, provide \"what\" but not \"how,\" and have shown limited impact on industry practices \\cite{vakkuri2021n6l}. A survey by the authors found that these guidelines had not notably affected industry practices \\cite{vakkuri2021n6l}.\n        *   Existing AI-specific models are not primarily focused on the *quality or ethical aspects* of AI systems and lack generality for diverse organizational contexts, including SMEs and startups \\cite{vakkuri2021n6l}.\n        *   Traditional software maturity models are insufficient because AI systems possess unique characteristics: they are probabilistic (not deterministic), learn from data, have quality attributes that change during experimentation, and ethical requirements (fairness, trustworthiness, transparency, explainability) have distinct meanings in the AI context that are not adequately addressed by existing models \\cite{vakkuri2021n6l}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper *proposes* and advocates for the development of a **maturity model** specifically designed for AI software development, which could focus either on AI ethics (AI Ethics Maturity Model) or broader AI system quality (AI Maturity Model) \\cite{vakkuri2021n6l}. This is a conceptual proposal for a new framework type.\n    *   **Novelty**: The innovation lies in identifying the critical need for such a specialized maturity model, explicitly detailing why existing SE and AI-specific models are inadequate for integrating ethical considerations and unique AI quality attributes. It positions a maturity model as a structured, actionable roadmap to bridge the research-practice gap in ethical AI development \\cite{vakkuri2021n6l}.\n\n*   **Key Technical Contributions**\n    *   **Conceptual Framework**: Articulation of the foundational argument for a process-oriented maturity model to systematically integrate ethical requirements and quality attributes throughout the AI system development lifecycle \\cite{vakkuri2021n6l}.\n    *   **Identification of Unique AI Challenges**: Detailed analysis highlighting the specific technical and ethical characteristics of AI systems (e.g., probabilistic nature, data-centricity, evolving quality attributes, unique interpretations of fairness and transparency) that necessitate a distinct maturity model, differentiating it from traditional software engineering \\cite{vakkuri2021n6l}.\n    *   **Call to Action**: A clear proposal for the research and industry communities to collaborate on devising a generic AI (ethics) maturity model to benchmark, standardize, and disseminate best practices for ethical AI engineering \\cite{vakkuri2021n6l}.\n\n*   **Experimental Validation**\n    *   This paper *does not present new experimental validation* of a proposed maturity model.\n    *   It *references prior empirical work* by the authors to motivate the problem: a survey of 211 companies (106 developing AI products) revealed mixed levels of maturity in implementing AI ethics and confirmed that existing AI ethics guidelines had not significantly impacted industry practices \\cite{vakkuri2021n6l}. This serves as empirical evidence for the problem statement rather than validation of a solution.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The paper is a conceptual proposal and a call to action; it does not present a fully developed maturity model, its specific stages, key process areas, or implementation details.\n    *   **Scope of Applicability**: The envisioned maturity model is intended to be generic and applicable across various organizations, including SMEs and startups, to standardize and promote proper engineering practices for integrating ethical requirements into AI development \\cite{vakkuri2021n6l}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: By rigorously outlining the shortcomings of current approaches and articulating the unique technical and ethical demands of AI, the paper significantly advances the discourse towards a more structured, engineering-centric paradigm for ethical AI development \\cite{vakkuri2021n6l}.\n    *   **Potential Impact**: It provides a strong conceptual foundation and a clear direction for future research and development of practical, actionable frameworks (maturity models) that can bridge the gap between abstract ethical principles and concrete AI development practices. This could lead to more consistent, trustworthy, and ethically sound AI systems across diverse industries \\cite{vakkuri2021n6l}.",
    "intriguing_abstract": "Despite the proliferation of AI ethics principles, a critical chasm persists between abstract guidelines and actionable practices for AI software developers. This paper confronts the urgent challenge of operationalizing ethical AI, revealing why existing frameworks—from high-level principles to traditional software engineering maturity models—fall short. We argue that AI's unique characteristics, including its probabilistic nature, data-centricity, and evolving quality attributes, demand a fundamentally new approach.\n\nWe propose a novel conceptual framework: a specialized **AI (Ethics) Maturity Model**. This model offers a structured, process-oriented roadmap to systematically integrate crucial ethical requirements like **fairness, trustworthiness, transparency, and explainability** throughout the entire **AI system development lifecycle**. By detailing the shortcomings of current solutions and providing empirical evidence for their limited industry impact, this work serves as a pivotal call to action. It aims to bridge the persistent **research-practice gap**, fostering the development of standardized, ethically sound, and truly responsible AI systems, thereby advancing the state-of-the-art in **ethical AI engineering**.",
    "keywords": [
      "AI ethics principles",
      "Research-practice gap",
      "AI software development",
      "Maturity models",
      "AI Ethics Maturity Model",
      "Conceptual framework",
      "Unique AI characteristics",
      "Fairness",
      "trustworthiness",
      "transparency",
      "explainability",
      "Ethical AI engineering",
      "Systematic guidance",
      "Industry adoption",
      "Standardization of best practices"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/439ee9451908eef05f3937e67ce5816f2b90d2a5.pdf",
    "citation_key": "vakkuri2021n6l",
    "metadata": {
      "title": "Time for AI (Ethics) Maturity Model Is Now",
      "authors": [
        "Ville Vakkuri",
        "Marianna Jantunen",
        "Erika Halme",
        "Kai-Kristian Kemell",
        "Anh Nguyen-Duc",
        "T. Mikkonen",
        "P. Abrahamsson"
      ],
      "published_date": "2021",
      "abstract": "There appears to be a common agreement that ethical concerns are of high importance when it comes to systems equipped with some sort of Artificial Intelligence (AI). Demands for ethical AI are declared from all directions. As a response, in recent years, public bodies, governments, and universities have rushed in to provide a set of principles to be considered when AI based systems are designed and used. We have learned, however, that high-level principles do not turn easily into actionable advice for practitioners. Hence, also companies are publishing their own ethical guidelines to guide their AI development. This paper argues that AI software is still software and needs to be approached from the software development perspective. The software engineering paradigm has introduced maturity model thinking, which provides a roadmap for companies to improve their performance from the selected viewpoints known as the key capabilities. We want to voice out a call for action for the development of a maturity model for AI software. We wish to discuss whether the focus should be on AI ethics or, more broadly, the quality of an AI system, called a maturity model for the development of AI systems.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/439ee9451908eef05f3937e67ce5816f2b90d2a5.pdf",
      "venue": "SafeAI@AAAI",
      "citationCount": 15,
      "score": 3.75,
      "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: High-level AI ethics principles and guidelines, despite their proliferation, fail to translate into actionable advice for practitioners, leading to a significant gap between ethical aspirations and practical AI software development \\cite{vakkuri2021n6l}. Existing guidelines lack standardization, suffer from low industry adoption, and do not provide concrete \"how-to\" guidance.\n    *   **Motivation**: With AI systems becoming pervasive and impacting critical decision-making (e.g., healthcare, transportation), there is an urgent need for systematic guidance to ensure the development of ethically sound AI. The authors argue that AI software, being software, can benefit from the structured improvement approach of maturity models, which have proven effective in traditional software engineering \\cite{vakkuri2021n6l}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Numerous organizations have published AI ethics principles and guidelines (e.g., IEEE, EU Commission). Some AI-specific process models exist (e.g., Microsoft nine-step pipeline, \"stairway to heaven\" AI model). Traditional software engineering maturity models (e.g., CMMI, SAFe) are widely used.\n    *   **Limitations of Previous Solutions**:\n        *   AI ethics guidelines are abstract, provide \"what\" but not \"how,\" and have shown limited impact on industry practices \\cite{vakkuri2021n6l}. A survey by the authors found that these guidelines had not notably affected industry practices \\cite{vakkuri2021n6l}.\n        *   Existing AI-specific models are not primarily focused on the *quality or ethical aspects* of AI systems and lack generality for diverse organizational contexts, including SMEs and startups \\cite{vakkuri2021n6l}.\n        *   Traditional software maturity models are insufficient because AI systems possess unique characteristics: they are probabilistic (not deterministic), learn from data, have quality attributes that change during experimentation, and ethical requirements (fairness, trustworthiness, transparency, explainability) have distinct meanings in the AI context that are not adequately addressed by existing models \\cite{vakkuri2021n6l}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper *proposes* and advocates for the development of a **maturity model** specifically designed for AI software development, which could focus either on AI ethics (AI Ethics Maturity Model) or broader AI system quality (AI Maturity Model) \\cite{vakkuri2021n6l}. This is a conceptual proposal for a new framework type.\n    *   **Novelty**: The innovation lies in identifying the critical need for such a specialized maturity model, explicitly detailing why existing SE and AI-specific models are inadequate for integrating ethical considerations and unique AI quality attributes. It positions a maturity model as a structured, actionable roadmap to bridge the research-practice gap in ethical AI development \\cite{vakkuri2021n6l}.\n\n*   **Key Technical Contributions**\n    *   **Conceptual Framework**: Articulation of the foundational argument for a process-oriented maturity model to systematically integrate ethical requirements and quality attributes throughout the AI system development lifecycle \\cite{vakkuri2021n6l}.\n    *   **Identification of Unique AI Challenges**: Detailed analysis highlighting the specific technical and ethical characteristics of AI systems (e.g., probabilistic nature, data-centricity, evolving quality attributes, unique interpretations of fairness and transparency) that necessitate a distinct maturity model, differentiating it from traditional software engineering \\cite{vakkuri2021n6l}.\n    *   **Call to Action**: A clear proposal for the research and industry communities to collaborate on devising a generic AI (ethics) maturity model to benchmark, standardize, and disseminate best practices for ethical AI engineering \\cite{vakkuri2021n6l}.\n\n*   **Experimental Validation**\n    *   This paper *does not present new experimental validation* of a proposed maturity model.\n    *   It *references prior empirical work* by the authors to motivate the problem: a survey of 211 companies (106 developing AI products) revealed mixed levels of maturity in implementing AI ethics and confirmed that existing AI ethics guidelines had not significantly impacted industry practices \\cite{vakkuri2021n6l}. This serves as empirical evidence for the problem statement rather than validation of a solution.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: The paper is a conceptual proposal and a call to action; it does not present a fully developed maturity model, its specific stages, key process areas, or implementation details.\n    *   **Scope of Applicability**: The envisioned maturity model is intended to be generic and applicable across various organizations, including SMEs and startups, to standardize and promote proper engineering practices for integrating ethical requirements into AI development \\cite{vakkuri2021n6l}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: By rigorously outlining the shortcomings of current approaches and articulating the unique technical and ethical demands of AI, the paper significantly advances the discourse towards a more structured, engineering-centric paradigm for ethical AI development \\cite{vakkuri2021n6l}.\n    *   **Potential Impact**: It provides a strong conceptual foundation and a clear direction for future research and development of practical, actionable frameworks (maturity models) that can bridge the gap between abstract ethical principles and concrete AI development practices. This could lead to more consistent, trustworthy, and ethically sound AI systems across diverse industries \\cite{vakkuri2021n6l}.",
      "keywords": [
        "AI ethics principles",
        "Research-practice gap",
        "AI software development",
        "Maturity models",
        "AI Ethics Maturity Model",
        "Conceptual framework",
        "Unique AI characteristics",
        "Fairness",
        "trustworthiness",
        "transparency",
        "explainability",
        "Ethical AI engineering",
        "Systematic guidance",
        "Industry adoption",
        "Standardization of best practices"
      ],
      "paper_type": "based on the abstract and introduction, this paper is a **position** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"this paper argues that...\", \"we want to voice out a call for action for the development of a maturity model...\", \"we wish to discuss whether the focus should be...\" these phrases directly align with the \"position\" criteria of \"argue\", \"position\", \"vision\", \"future\", \"should\".\n*   **introduction discusses:** it highlights current problems (\"high-level principles do not turn easily into actionable advice\", \"details of what 'ethical ai' constitutes... is up for debate\") and proposes a direction/solution (\"increasing need for guidance\", \"call for action for the development of a maturity model\")."
    },
    "file_name": "439ee9451908eef05f3937e67ce5816f2b90d2a5.pdf"
  },
  {
    "success": true,
    "doc_id": "049721f23fdb749dc3ed40de9be81170",
    "summary": "Software or web application security is the main objective in the era of Information Technology (IT) and Artificial Intelligence (AI). Distinguishing proof of security at the initial stage produces significant results to comprehend the administration of security relics for best potential outcomes. A security alternative gives several methods and algorithms to ensure the software security. Security estimation is the vital factor in assessing, administrating, controlling security to improve the nature of security. It is to be realized that assessment of security at early stage of development helps in identifying distinctive worms, dangers, weaknesses and threats. This paper will talk about the definition and characterization of quantum computing in software security. For software security, we use different cryptography (methods or algorithms to secure our financial organizations, medical devices, military weapons, planes, ships, automobiles, navigators, etc. However, many cryptosystems are likely to collapse when the large quantum computer is developed. Recently, Google developed the Sycamore Processor 53 qubits. Such innovations indicate the advent of large quantum computer in future. Since cryptographic algorithm can be solved by the quantum computers, the present cryptosystem would be rendered obsolete. Hence, it is imperative to focus more on intensive research in the context of the present quantum cyber security. The main challenges in quantum era would be cryptography methods that fulfill the demands of security usability and flexibility without sacrificing the users’ confidence. This research study, in particular, focuses on ‘Software durability’ which is a quality of security that alludes to the capacity to execution of an item on schedule. In the context of software and web application, a thorough assessment of security factors will significantly influence the software’s durability in the era of quantum computing.",
    "intriguing_abstract": "Software or web application security is the main objective in the era of Information Technology (IT) and Artificial Intelligence (AI). Distinguishing proof of security at the initial stage produces significant results to comprehend the administration of security relics for best potential outcomes. A security alternative gives several methods and algorithms to ensure the software security. Security estimation is the vital factor in assessing, administrating, controlling security to improve the nature of security. It is to be realized that assessment of security at early stage of development helps in identifying distinctive worms, dangers, weaknesses and threats. This paper will talk about the definition and characterization of quantum computing in software security. For software security, we use different cryptography (methods or algorithms to secure our financial organizations, medical devices, military weapons, planes, ships, automobiles, navigators, etc. However, many cryptosystems are likely to collapse when the large quantum computer is developed. Recently, Google developed the Sycamore Processor 53 qubits. Such innovations indicate the advent of large quantum computer in future. Since cryptographic algorithm can be solved by the quantum computers, the present cryptosystem would be rendered obsolete. Hence, it is imperative to focus more on intensive research in the context of the present quantum cyber security. The main challenges in quantum era would be cryptography methods that fulfill the demands of security usability and flexibility without sacrificing the users’ confidence. This research study, in particular, focuses on ‘Software durability’ which is a quality of security that alludes to the capacity to execution of an item on schedule. In the context of software and web application, a thorough assessment of security factors will significantly influence the software’s durability in the era of quantum computing.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d85680bf1847e5b4909bb7ad9d8581437302da8c.pdf",
    "citation_key": "alyami2022e86",
    "metadata": {
      "title": "Analyzing the Data of Software Security Life-Span: Quantum Computing Era",
      "authors": [
        "Hashem Alyami",
        "M. Nadeem",
        "Wael Alosaimi",
        "A. Alharbi",
        "Rajeev Kumar",
        "Bineet Kumar Gupta",
        "A. Agrawal",
        "Raees Ahmad Khan"
      ],
      "published_date": "2022",
      "abstract": "Software or web application security is the main objective in the era of Information Technology (IT) and Artificial Intelligence (AI). Distinguishing proof of security at the initial stage produces significant results to comprehend the administration of security relics for best potential outcomes. A security alternative gives several methods and algorithms to ensure the software security. Security estimation is the vital factor in assessing, administrating, controlling security to improve the nature of security. It is to be realized that assessment of security at early stage of development helps in identifying distinctive worms, dangers, weaknesses and threats. This paper will talk about the definition and characterization of quantum computing in software security. For software security, we use different cryptography (methods or algorithms to secure our financial organizations, medical devices, military weapons, planes, ships, automobiles, navigators, etc. However, many cryptosystems are likely to collapse when the large quantum computer is developed. Recently, Google developed the Sycamore Processor 53 qubits. Such innovations indicate the advent of large quantum computer in future. Since cryptographic algorithm can be solved by the quantum computers, the present cryptosystem would be rendered obsolete. Hence, it is imperative to focus more on intensive research in the context of the present quantum cyber security. The main challenges in quantum era would be cryptography methods that fulfill the demands of security usability and flexibility without sacrificing the users’ confidence. This research study, in particular, focuses on ‘Software durability’ which is a quality of security that alludes to the capacity to execution of an item on schedule. In the context of software and web application, a thorough assessment of security factors will significantly influence the software’s durability in the era of quantum computing.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d85680bf1847e5b4909bb7ad9d8581437302da8c.pdf",
      "venue": "Intelligent Automation and Soft Computing",
      "citationCount": 11,
      "score": 3.6666666666666665,
      "summary": "Software or web application security is the main objective in the era of Information Technology (IT) and Artificial Intelligence (AI). Distinguishing proof of security at the initial stage produces significant results to comprehend the administration of security relics for best potential outcomes. A security alternative gives several methods and algorithms to ensure the software security. Security estimation is the vital factor in assessing, administrating, controlling security to improve the nature of security. It is to be realized that assessment of security at early stage of development helps in identifying distinctive worms, dangers, weaknesses and threats. This paper will talk about the definition and characterization of quantum computing in software security. For software security, we use different cryptography (methods or algorithms to secure our financial organizations, medical devices, military weapons, planes, ships, automobiles, navigators, etc. However, many cryptosystems are likely to collapse when the large quantum computer is developed. Recently, Google developed the Sycamore Processor 53 qubits. Such innovations indicate the advent of large quantum computer in future. Since cryptographic algorithm can be solved by the quantum computers, the present cryptosystem would be rendered obsolete. Hence, it is imperative to focus more on intensive research in the context of the present quantum cyber security. The main challenges in quantum era would be cryptography methods that fulfill the demands of security usability and flexibility without sacrificing the users’ confidence. This research study, in particular, focuses on ‘Software durability’ which is a quality of security that alludes to the capacity to execution of an item on schedule. In the context of software and web application, a thorough assessment of security factors will significantly influence the software’s durability in the era of quantum computing.",
      "keywords": []
    },
    "file_name": "d85680bf1847e5b4909bb7ad9d8581437302da8c.pdf"
  },
  {
    "success": true,
    "doc_id": "4b858c7ba7461551b6da402d2c115c0b",
    "summary": "RISC-V is an emergent architecture that is gaining strength in low-power IoT applications. The stabilization of the architectural extensions and the start of commercialization of RISC-V based SOCs, like the Kendryte K210, raises the question of whether this open standard will facilitate the development of applications in specific markets or not.In this paper we evaluate the development environments, the toolchain, the debugging processes related to the Sipeed MAIX Go development board, as well as the standalone SDK and the Micropython port for the Kendryte K210. The training pipeline for the built-in convolutional neural network accelerator, with support for Tiny YOLO v2, has also been studied. In order to evaluate all the above aspects in depth, two low-cost, low-power, IoT edge applications based on AI have been developed. The first one is capable of recognizing movement in a house and autonomously identify whether it was caused by a human or by a house pet, like for example a dog or a cat. In the context of the current COVID-19 pandemic, the second application is capable of labeling whether a pedestrian is wearing a face mask or not, doing real-time object recognition at a mean rate of 13 FPS. Throughout the process, we can conclude that, despite the potential of the hardware and its excellent performance/cost ratio, the documentation for developers is scarce, the development environments are in low maturity levels, and the debugging processes are sometimes nonexistent.",
    "intriguing_abstract": "RISC-V is an emergent architecture that is gaining strength in low-power IoT applications. The stabilization of the architectural extensions and the start of commercialization of RISC-V based SOCs, like the Kendryte K210, raises the question of whether this open standard will facilitate the development of applications in specific markets or not.In this paper we evaluate the development environments, the toolchain, the debugging processes related to the Sipeed MAIX Go development board, as well as the standalone SDK and the Micropython port for the Kendryte K210. The training pipeline for the built-in convolutional neural network accelerator, with support for Tiny YOLO v2, has also been studied. In order to evaluate all the above aspects in depth, two low-cost, low-power, IoT edge applications based on AI have been developed. The first one is capable of recognizing movement in a house and autonomously identify whether it was caused by a human or by a house pet, like for example a dog or a cat. In the context of the current COVID-19 pandemic, the second application is capable of labeling whether a pedestrian is wearing a face mask or not, doing real-time object recognition at a mean rate of 13 FPS. Throughout the process, we can conclude that, despite the potential of the hardware and its excellent performance/cost ratio, the documentation for developers is scarce, the development environments are in low maturity levels, and the debugging processes are sometimes nonexistent.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/44707cda0191190cb040824ac202ed94b77cd831.pdf",
    "citation_key": "torressnchez2020u4r",
    "metadata": {
      "title": "Developing an AI IoT application with open software on a RISC-V SoC",
      "authors": [
        "Enrique Torres-Sánchez",
        "Jesús Alastruey-Benedé",
        "Enrique F. Torres Moreno"
      ],
      "published_date": "2020",
      "abstract": "RISC-V is an emergent architecture that is gaining strength in low-power IoT applications. The stabilization of the architectural extensions and the start of commercialization of RISC-V based SOCs, like the Kendryte K210, raises the question of whether this open standard will facilitate the development of applications in specific markets or not.In this paper we evaluate the development environments, the toolchain, the debugging processes related to the Sipeed MAIX Go development board, as well as the standalone SDK and the Micropython port for the Kendryte K210. The training pipeline for the built-in convolutional neural network accelerator, with support for Tiny YOLO v2, has also been studied. In order to evaluate all the above aspects in depth, two low-cost, low-power, IoT edge applications based on AI have been developed. The first one is capable of recognizing movement in a house and autonomously identify whether it was caused by a human or by a house pet, like for example a dog or a cat. In the context of the current COVID-19 pandemic, the second application is capable of labeling whether a pedestrian is wearing a face mask or not, doing real-time object recognition at a mean rate of 13 FPS. Throughout the process, we can conclude that, despite the potential of the hardware and its excellent performance/cost ratio, the documentation for developers is scarce, the development environments are in low maturity levels, and the debugging processes are sometimes nonexistent.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/44707cda0191190cb040824ac202ed94b77cd831.pdf",
      "venue": "Conference on Design of Circuits and Integrated Systems",
      "citationCount": 18,
      "score": 3.6,
      "summary": "RISC-V is an emergent architecture that is gaining strength in low-power IoT applications. The stabilization of the architectural extensions and the start of commercialization of RISC-V based SOCs, like the Kendryte K210, raises the question of whether this open standard will facilitate the development of applications in specific markets or not.In this paper we evaluate the development environments, the toolchain, the debugging processes related to the Sipeed MAIX Go development board, as well as the standalone SDK and the Micropython port for the Kendryte K210. The training pipeline for the built-in convolutional neural network accelerator, with support for Tiny YOLO v2, has also been studied. In order to evaluate all the above aspects in depth, two low-cost, low-power, IoT edge applications based on AI have been developed. The first one is capable of recognizing movement in a house and autonomously identify whether it was caused by a human or by a house pet, like for example a dog or a cat. In the context of the current COVID-19 pandemic, the second application is capable of labeling whether a pedestrian is wearing a face mask or not, doing real-time object recognition at a mean rate of 13 FPS. Throughout the process, we can conclude that, despite the potential of the hardware and its excellent performance/cost ratio, the documentation for developers is scarce, the development environments are in low maturity levels, and the debugging processes are sometimes nonexistent.",
      "keywords": []
    },
    "file_name": "44707cda0191190cb040824ac202ed94b77cd831.pdf"
  },
  {
    "success": true,
    "doc_id": "6fe486381b2e20582fa326d642a98480",
    "summary": "Artificial intelligence has already proven to be a powerful tool to automate and improve how we deal with software development processes. The application of artificial intelligence to model-driven engineering projects is becoming more and more popular; however, within the model repair field, the use of this technique remains mostly an open challenge. In this paper, we explore some existing approaches in the field of AI-powered model repair. From the existing approaches in this field, we identify a series of challenges which the community needs to overcome. In addition, we present a number of research opportunities by taking inspiration from other fields which have successfully used artificial intelligence, such as code repair. Moreover, we discuss the connection between the existing approaches and the opportunities with the identified challenges. Finally, we present the outcomes of our experience of applying artificial intelligence to model repair.",
    "intriguing_abstract": "Artificial intelligence has already proven to be a powerful tool to automate and improve how we deal with software development processes. The application of artificial intelligence to model-driven engineering projects is becoming more and more popular; however, within the model repair field, the use of this technique remains mostly an open challenge. In this paper, we explore some existing approaches in the field of AI-powered model repair. From the existing approaches in this field, we identify a series of challenges which the community needs to overcome. In addition, we present a number of research opportunities by taking inspiration from other fields which have successfully used artificial intelligence, such as code repair. Moreover, we discuss the connection between the existing approaches and the opportunities with the identified challenges. Finally, we present the outcomes of our experience of applying artificial intelligence to model repair.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ee32116c9f9944be1f492764f22451affd9c1713.pdf",
    "citation_key": "barriga2022ay7",
    "metadata": {
      "title": "AI-powered model repair: an experience report—lessons learned, challenges, and opportunities",
      "authors": [
        "Angela Barriga",
        "Adrian Rutle",
        "Rogardt Heldal"
      ],
      "published_date": "2022",
      "abstract": "Artificial intelligence has already proven to be a powerful tool to automate and improve how we deal with software development processes. The application of artificial intelligence to model-driven engineering projects is becoming more and more popular; however, within the model repair field, the use of this technique remains mostly an open challenge. In this paper, we explore some existing approaches in the field of AI-powered model repair. From the existing approaches in this field, we identify a series of challenges which the community needs to overcome. In addition, we present a number of research opportunities by taking inspiration from other fields which have successfully used artificial intelligence, such as code repair. Moreover, we discuss the connection between the existing approaches and the opportunities with the identified challenges. Finally, we present the outcomes of our experience of applying artificial intelligence to model repair.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ee32116c9f9944be1f492764f22451affd9c1713.pdf",
      "venue": "Journal of Software and Systems Modeling",
      "citationCount": 10,
      "score": 3.333333333333333,
      "summary": "Artificial intelligence has already proven to be a powerful tool to automate and improve how we deal with software development processes. The application of artificial intelligence to model-driven engineering projects is becoming more and more popular; however, within the model repair field, the use of this technique remains mostly an open challenge. In this paper, we explore some existing approaches in the field of AI-powered model repair. From the existing approaches in this field, we identify a series of challenges which the community needs to overcome. In addition, we present a number of research opportunities by taking inspiration from other fields which have successfully used artificial intelligence, such as code repair. Moreover, we discuss the connection between the existing approaches and the opportunities with the identified challenges. Finally, we present the outcomes of our experience of applying artificial intelligence to model repair.",
      "keywords": []
    },
    "file_name": "ee32116c9f9944be1f492764f22451affd9c1713.pdf"
  },
  {
    "success": true,
    "doc_id": "a991a20fab7f1aad3e3fc5c29ff8942b",
    "summary": "As the deployment of artificial intelligence (AI) is changing many fields and industries, there are concerns about AI systems making decisions and recommendations without adequately considering various ethical aspects, such as accountability, reliability, transparency, explainability, contestability, privacy, and fairness. While many sets of AI ethics principles have been recently proposed that acknowledge these concerns, such principles are high-level and do not provide tangible advice on how to develop ethical and responsible AI systems. To gain insight on the possible implementation of the principles, we conducted an empirical investigation involving semi-structured interviews with a cohort of AI practitioners. The salient findings cover four aspects of AI system design and development, adapting processes used in software engineering: (i) high-level view, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation.",
    "intriguing_abstract": "As the deployment of artificial intelligence (AI) is changing many fields and industries, there are concerns about AI systems making decisions and recommendations without adequately considering various ethical aspects, such as accountability, reliability, transparency, explainability, contestability, privacy, and fairness. While many sets of AI ethics principles have been recently proposed that acknowledge these concerns, such principles are high-level and do not provide tangible advice on how to develop ethical and responsible AI systems. To gain insight on the possible implementation of the principles, we conducted an empirical investigation involving semi-structured interviews with a cohort of AI practitioners. The salient findings cover four aspects of AI system design and development, adapting processes used in software engineering: (i) high-level view, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6035386cbdadfd80ccae0b103bda9d04f65b44fb.pdf",
    "citation_key": "sanderson2022zra",
    "metadata": {
      "title": "Towards Implementing Responsible AI",
      "authors": [
        "Conrad Sanderson",
        "Qinghua Lu",
        "David M. Douglas",
        "Xiwei Xu",
        "Liming Zhu",
        "Jon Whittle"
      ],
      "published_date": "2022",
      "abstract": "As the deployment of artificial intelligence (AI) is changing many fields and industries, there are concerns about AI systems making decisions and recommendations without adequately considering various ethical aspects, such as accountability, reliability, transparency, explainability, contestability, privacy, and fairness. While many sets of AI ethics principles have been recently proposed that acknowledge these concerns, such principles are high-level and do not provide tangible advice on how to develop ethical and responsible AI systems. To gain insight on the possible implementation of the principles, we conducted an empirical investigation involving semi-structured interviews with a cohort of AI practitioners. The salient findings cover four aspects of AI system design and development, adapting processes used in software engineering: (i) high-level view, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6035386cbdadfd80ccae0b103bda9d04f65b44fb.pdf",
      "venue": "2022 IEEE International Conference on Big Data (Big Data)",
      "citationCount": 10,
      "score": 3.333333333333333,
      "summary": "As the deployment of artificial intelligence (AI) is changing many fields and industries, there are concerns about AI systems making decisions and recommendations without adequately considering various ethical aspects, such as accountability, reliability, transparency, explainability, contestability, privacy, and fairness. While many sets of AI ethics principles have been recently proposed that acknowledge these concerns, such principles are high-level and do not provide tangible advice on how to develop ethical and responsible AI systems. To gain insight on the possible implementation of the principles, we conducted an empirical investigation involving semi-structured interviews with a cohort of AI practitioners. The salient findings cover four aspects of AI system design and development, adapting processes used in software engineering: (i) high-level view, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation.",
      "keywords": []
    },
    "file_name": "6035386cbdadfd80ccae0b103bda9d04f65b44fb.pdf"
  },
  {
    "success": true,
    "doc_id": "8c2ad521eb8bbda293742f653d117f63",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/44d42efed710570e16d724421eeb821cc904135a.pdf",
    "citation_key": "dinverno20155zo",
    "metadata": {
      "title": "Heroic versus Collaborative AI for the Arts",
      "authors": [
        "M. d'Inverno",
        "J. Mccormack"
      ],
      "published_date": "2015",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/44d42efed710570e16d724421eeb821cc904135a.pdf",
      "venue": "International Joint Conference on Artificial Intelligence",
      "citationCount": 33,
      "score": 3.3000000000000003,
      "summary": "",
      "keywords": []
    },
    "file_name": "44d42efed710570e16d724421eeb821cc904135a.pdf"
  },
  {
    "success": true,
    "doc_id": "7e5abc665dc67bdf72b11d627b698e62",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: Agility in Software 2.0 { Notebook Interfaces and MLOps with Buttresses and Rebars \\cite{borg20214da}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenges of achieving agility and ensuring quality in Machine Learning (ML) development, often referred to as \"Software 2.0.\" Specifically, it targets two key issues:\n        *   The intrinsic weaknesses of cloud-based notebook interfaces for developing production-grade ML solutions, particularly the difficulty in transitioning from rapid prototyping to robust software engineering practices (e.g., version control, refactoring, deployment).\n        *   The need for robust, continuous engineering and operationalization of ML systems (MLOps) to ensure trustworthiness and maintainability, especially given the \"Changing Anything Changes Everything\" (CACE) principle in ML.\n    *   **Importance and Challenge:** This problem is critical because ML is increasingly central to digital society, yet data scientists often lack traditional software engineering training. The experimental, iterative nature of ML development (data collection, feature engineering, model selection, etc.) demands extreme agility but often compromises qualities like reproducibility, testability, and traceability, which are essential for trustworthy and maintainable AI systems in production.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   The work positions ML development as requiring \"agility on steroids\" compared to conventional agile software development and DevOps.\n        *   It acknowledges the widespread use and benefits of notebook interfaces (e.g., Jupyter, Databricks) for rapid experimentation and literate computing, building on Knuth's literate programming paradigm.\n        *   It draws parallels between MLOps and DevOps, extending the concept of continuous engineering to the unique challenges of ML systems.\n    *   **Limitations of Previous Solutions:**\n        *   **Notebook Interfaces:** Current notebook interfaces, while agile, suffer from pain points like limited support for code refactoring, difficult deployment to production, poor history exploration, and challenges with long-running tasks \\cite{borg20214da}. They often lack the robust tooling (version control, static analysis, linting) available in Integrated Development Environments (IDEs).\n        *   **ML Development Lifecycle:** Many organizations struggle to transition ML proofs-of-concept into production-quality AI systems due to a lack of focus on the holistic lifecycle, continuous monitoring, and adaptation to phenomena like distributional shifts \\cite{borg20214da}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm:** The paper presents two main technical thrusts:\n        *   **Bridging Notebooks and IDEs:** It introduces a solution (developed by Jakobsson and Henriksson) that enables seamless movement between cloud-based notebook interfaces and local IDEs. This is achieved through a custom **networked file system implemented using File System in Userspace (FUSE)**, which is exposed to Kubernetes clusters as a **Container Storage Interface (CSI) driver** \\cite{borg20214da}. This allows remote notebook environments (specifically, Cowait Notebooks running JupyterLab in a Cowait task) to access local files on a data scientist's machine.\n        *   **Reinforced MLOps (\"Buttresses and Rebars\"):** It proposes a conceptual framework for \"reinforced continuous engineering\" of AI systems. This involves adopting MLOps as an engineering discipline that combines ML, DevOps, and Data Engineering practices to standardize and streamline the entire ML lifecycle. The metaphors of \"buttresses\" (external support) and \"rebars\" (internal reinforcement) emphasize the need for robust, continuous processes and infrastructure to build trustworthy and resilient AI systems.\n    *   **Novelty/Difference:**\n        *   The FUSE-based CSI driver for local-remote file sharing in ML environments is a novel technical approach to address the notebook-IDE gap, contrasting with solutions where both code and data are local (Jupyter) or where remote execution lacks local data access (Databricks) \\cite{borg20214da}.\n        *   The \"buttresses and rebars\" metaphor provides a fresh perspective on MLOps, highlighting the structural integrity and continuous reinforcement required for AI systems, especially in the context of regulatory demands for trustworthy AI.\n        *   The use of **Cowait**, an open-source framework for simplified container orchestration on Kubernetes, as the underlying platform for running notebook interfaces and distributed ML workflows, is also a key enabler for the proposed solution.\n\n4.  **Key Technical Contributions**\n    *   **System Design/Architectural Innovations:**\n        *   A novel architecture for integrating local IDEs with remote, cloud-based notebook environments via a custom networked file system (FUSE) exposed through a Kubernetes CSI driver \\cite{borg20214da}.\n        *   Leveraging the Cowait framework to containerize and orchestrate JupyterLab as \"Cowait Notebooks,\" enabling distributed execution of ML tasks directly from notebook cells.\n    *   **Theoretical Insights/Analysis:**\n        *   The conceptualization of \"reinforced continuous engineering\" for AI systems, using the \"buttresses and rebars\" metaphor, to address the inherent dynamism and CACE principle of ML development and operations \\cite{borg20214da}.\n        *   An emphasis on MLOps as a holistic discipline for achieving trustworthy AI, extending beyond mere automation to encompass continuous monitoring, evolution, and quality assurance throughout the ML lifecycle.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted (for the notebook-IDE bridging solution):** Jakobsson and Henriksson conducted two studies:\n        *   **Quantitative Performance Study:** Evaluated the solution's file access performance under varying numbers of files, file sizes, and network conditions \\cite{borg20214da}.\n        *   **Qualitative Utility Study:** Recruited data scientists and ML-experienced software developers to perform a programming task using a think-aloud protocol to gather feedback on the solution's utility and user experience \\cite{borg20214da}.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Quantitative:** The solution satisfied the requirement of file access within 1 second for reasonable file sizes and realistic network latency, aligning with human response time expectations \\cite{borg20214da}.\n        *   **Qualitative:** Feedback was mixed. Data scientists comfortable with managed cloud solutions expressed hesitation due to perceived reduced ease-of-use and potential collaboration issues. Developers with a software engineering background were more positive, appreciating the ability to use familiar local IDE tooling \\cite{borg20214da}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The FUSE-based file sharing solution is a proof-of-concept, and while performance was acceptable, user feedback indicated a need for further refinement to address ease-of-use and collaboration concerns for some user groups \\cite{borg20214da}.\n        *   The MLOps \"buttresses and rebars\" concept is primarily a high-level framework and vision, with the paper not detailing specific novel algorithms or implementations for this part beyond advocating for existing MLOps practices.\n    *   **Scope of Applicability:** The notebook-IDE bridging solution is specifically designed for environments leveraging Kubernetes for container orchestration and Python-based ML workflows (via Cowait and JupyterLab). The MLOps framework is broadly applicable to any organization developing and deploying ML systems.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:**\n        *   Provides a concrete, technically innovative solution (FUSE-based CSI driver) to a long-standing pain point in ML development workflows: the disconnect between rapid prototyping in notebooks and robust engineering in IDEs \\cite{borg20214da}. This directly enhances developer agility and productivity in distributed ML environments.\n        *   Elevates the discussion around MLOps from a set of tools or practices to a strategic imperative for \"reinforced continuous engineering\" of trustworthy AI, linking it to critical aspects like regulatory compliance (e.g., EU AI Act) and the inherent challenges of ML system evolution \\cite{borg20214da}.\n    *   **Potential Impact on Future Research:**\n        *   The FUSE/CSI solution opens avenues for further research into seamless local-remote development environments for ML, exploring alternative file sharing mechanisms, user experience improvements, and integration with diverse ML frameworks.\n        *   The \"buttresses and rebars\" concept can inspire research into novel architectural patterns, automated quality assurance mechanisms, and governance frameworks that explicitly address the continuous reinforcement and trustworthiness of AI systems throughout their lifecycle.\n        *   It highlights the need for interdisciplinary research bridging software engineering, data science, and operations to build more resilient and accountable AI solutions.",
    "intriguing_abstract": "Unleashing the full potential of Machine Learning (Software 2.0) demands extreme agility without compromising trustworthiness. Yet, the chasm between rapid **notebook interface** prototyping and robust production-grade systems, often developed in **IDEs**, remains a significant hurdle. This paper presents a dual-pronged approach to bridge this gap and fortify **MLOps** practices. We introduce a novel **FUSE-based Container Storage Interface (CSI) driver** that seamlessly integrates local IDEs with remote **Cowait Notebooks** running on **Kubernetes**, enabling data scientists to leverage powerful local tooling while executing distributed ML workflows in the cloud. Complementing this, we propose \"Buttresses and Rebars,\" a conceptual framework for \"reinforced continuous engineering\" in **MLOps**. This framework emphasizes the structural integrity and continuous reinforcement needed to build resilient and **trustworthy AI** systems, addressing the \"Changing Anything Changes Everything\" (CACE) principle inherent in ML. Our approach directly enhances reproducibility, testability, and traceability, crucial for regulatory compliance and long-term maintainability. This work offers a significant advancement towards building agile, high-quality, and **trustworthy AI** solutions.",
    "keywords": [
      "Agility in Software 2.0",
      "Reinforced MLOps",
      "Notebook-IDE bridging",
      "FUSE-based CSI driver",
      "Kubernetes orchestration",
      "Cowait framework",
      "Trustworthy AI systems",
      "Continuous engineering",
      "CACE principle",
      "Production-grade ML solutions",
      "Local-remote development environments",
      "Performance and utility studies"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/4d3e1d7aebf1bbfe7191e45f844d61f93617b569.pdf",
    "citation_key": "borg20214da",
    "metadata": {
      "title": "Agility in Software 2.0 - Notebook Interfaces and MLOps with Buttresses and Rebars",
      "authors": [
        "Markus Borg"
      ],
      "published_date": "2021",
      "abstract": "Artificial intelligence through machine learning is increasingly used in the digital society. Solutions based on machine learning bring both great opportunities, thus coined\"Software 2.0,\"but also great challenges for the engineering community to tackle. Due to the experimental approach used by data scientists when developing machine learning models, agility is an essential characteristic. In this keynote address, we discuss two contemporary development phenomena that are fundamental in machine learning development, i.e., notebook interfaces and MLOps. First, we present a solution that can remedy some of the intrinsic weaknesses of working in notebooks by supporting easy transitions to integrated development environments. Second, we propose reinforced engineering of AI systems by introducing metaphorical buttresses and rebars in the MLOps context. Machine learning-based solutions are dynamic in nature, and we argue that reinforced continuous engineering is required to quality assure the trustworthy AI systems of tomorrow.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/4d3e1d7aebf1bbfe7191e45f844d61f93617b569.pdf",
      "venue": "International Conference on Lean and Agile Software Development",
      "citationCount": 13,
      "score": 3.25,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: Agility in Software 2.0 { Notebook Interfaces and MLOps with Buttresses and Rebars \\cite{borg20214da}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenges of achieving agility and ensuring quality in Machine Learning (ML) development, often referred to as \"Software 2.0.\" Specifically, it targets two key issues:\n        *   The intrinsic weaknesses of cloud-based notebook interfaces for developing production-grade ML solutions, particularly the difficulty in transitioning from rapid prototyping to robust software engineering practices (e.g., version control, refactoring, deployment).\n        *   The need for robust, continuous engineering and operationalization of ML systems (MLOps) to ensure trustworthiness and maintainability, especially given the \"Changing Anything Changes Everything\" (CACE) principle in ML.\n    *   **Importance and Challenge:** This problem is critical because ML is increasingly central to digital society, yet data scientists often lack traditional software engineering training. The experimental, iterative nature of ML development (data collection, feature engineering, model selection, etc.) demands extreme agility but often compromises qualities like reproducibility, testability, and traceability, which are essential for trustworthy and maintainable AI systems in production.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   The work positions ML development as requiring \"agility on steroids\" compared to conventional agile software development and DevOps.\n        *   It acknowledges the widespread use and benefits of notebook interfaces (e.g., Jupyter, Databricks) for rapid experimentation and literate computing, building on Knuth's literate programming paradigm.\n        *   It draws parallels between MLOps and DevOps, extending the concept of continuous engineering to the unique challenges of ML systems.\n    *   **Limitations of Previous Solutions:**\n        *   **Notebook Interfaces:** Current notebook interfaces, while agile, suffer from pain points like limited support for code refactoring, difficult deployment to production, poor history exploration, and challenges with long-running tasks \\cite{borg20214da}. They often lack the robust tooling (version control, static analysis, linting) available in Integrated Development Environments (IDEs).\n        *   **ML Development Lifecycle:** Many organizations struggle to transition ML proofs-of-concept into production-quality AI systems due to a lack of focus on the holistic lifecycle, continuous monitoring, and adaptation to phenomena like distributional shifts \\cite{borg20214da}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm:** The paper presents two main technical thrusts:\n        *   **Bridging Notebooks and IDEs:** It introduces a solution (developed by Jakobsson and Henriksson) that enables seamless movement between cloud-based notebook interfaces and local IDEs. This is achieved through a custom **networked file system implemented using File System in Userspace (FUSE)**, which is exposed to Kubernetes clusters as a **Container Storage Interface (CSI) driver** \\cite{borg20214da}. This allows remote notebook environments (specifically, Cowait Notebooks running JupyterLab in a Cowait task) to access local files on a data scientist's machine.\n        *   **Reinforced MLOps (\"Buttresses and Rebars\"):** It proposes a conceptual framework for \"reinforced continuous engineering\" of AI systems. This involves adopting MLOps as an engineering discipline that combines ML, DevOps, and Data Engineering practices to standardize and streamline the entire ML lifecycle. The metaphors of \"buttresses\" (external support) and \"rebars\" (internal reinforcement) emphasize the need for robust, continuous processes and infrastructure to build trustworthy and resilient AI systems.\n    *   **Novelty/Difference:**\n        *   The FUSE-based CSI driver for local-remote file sharing in ML environments is a novel technical approach to address the notebook-IDE gap, contrasting with solutions where both code and data are local (Jupyter) or where remote execution lacks local data access (Databricks) \\cite{borg20214da}.\n        *   The \"buttresses and rebars\" metaphor provides a fresh perspective on MLOps, highlighting the structural integrity and continuous reinforcement required for AI systems, especially in the context of regulatory demands for trustworthy AI.\n        *   The use of **Cowait**, an open-source framework for simplified container orchestration on Kubernetes, as the underlying platform for running notebook interfaces and distributed ML workflows, is also a key enabler for the proposed solution.\n\n4.  **Key Technical Contributions**\n    *   **System Design/Architectural Innovations:**\n        *   A novel architecture for integrating local IDEs with remote, cloud-based notebook environments via a custom networked file system (FUSE) exposed through a Kubernetes CSI driver \\cite{borg20214da}.\n        *   Leveraging the Cowait framework to containerize and orchestrate JupyterLab as \"Cowait Notebooks,\" enabling distributed execution of ML tasks directly from notebook cells.\n    *   **Theoretical Insights/Analysis:**\n        *   The conceptualization of \"reinforced continuous engineering\" for AI systems, using the \"buttresses and rebars\" metaphor, to address the inherent dynamism and CACE principle of ML development and operations \\cite{borg20214da}.\n        *   An emphasis on MLOps as a holistic discipline for achieving trustworthy AI, extending beyond mere automation to encompass continuous monitoring, evolution, and quality assurance throughout the ML lifecycle.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted (for the notebook-IDE bridging solution):** Jakobsson and Henriksson conducted two studies:\n        *   **Quantitative Performance Study:** Evaluated the solution's file access performance under varying numbers of files, file sizes, and network conditions \\cite{borg20214da}.\n        *   **Qualitative Utility Study:** Recruited data scientists and ML-experienced software developers to perform a programming task using a think-aloud protocol to gather feedback on the solution's utility and user experience \\cite{borg20214da}.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Quantitative:** The solution satisfied the requirement of file access within 1 second for reasonable file sizes and realistic network latency, aligning with human response time expectations \\cite{borg20214da}.\n        *   **Qualitative:** Feedback was mixed. Data scientists comfortable with managed cloud solutions expressed hesitation due to perceived reduced ease-of-use and potential collaboration issues. Developers with a software engineering background were more positive, appreciating the ability to use familiar local IDE tooling \\cite{borg20214da}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The FUSE-based file sharing solution is a proof-of-concept, and while performance was acceptable, user feedback indicated a need for further refinement to address ease-of-use and collaboration concerns for some user groups \\cite{borg20214da}.\n        *   The MLOps \"buttresses and rebars\" concept is primarily a high-level framework and vision, with the paper not detailing specific novel algorithms or implementations for this part beyond advocating for existing MLOps practices.\n    *   **Scope of Applicability:** The notebook-IDE bridging solution is specifically designed for environments leveraging Kubernetes for container orchestration and Python-based ML workflows (via Cowait and JupyterLab). The MLOps framework is broadly applicable to any organization developing and deploying ML systems.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:**\n        *   Provides a concrete, technically innovative solution (FUSE-based CSI driver) to a long-standing pain point in ML development workflows: the disconnect between rapid prototyping in notebooks and robust engineering in IDEs \\cite{borg20214da}. This directly enhances developer agility and productivity in distributed ML environments.\n        *   Elevates the discussion around MLOps from a set of tools or practices to a strategic imperative for \"reinforced continuous engineering\" of trustworthy AI, linking it to critical aspects like regulatory compliance (e.g., EU AI Act) and the inherent challenges of ML system evolution \\cite{borg20214da}.\n    *   **Potential Impact on Future Research:**\n        *   The FUSE/CSI solution opens avenues for further research into seamless local-remote development environments for ML, exploring alternative file sharing mechanisms, user experience improvements, and integration with diverse ML frameworks.\n        *   The \"buttresses and rebars\" concept can inspire research into novel architectural patterns, automated quality assurance mechanisms, and governance frameworks that explicitly address the continuous reinforcement and trustworthiness of AI systems throughout their lifecycle.\n        *   It highlights the need for interdisciplinary research bridging software engineering, data science, and operations to build more resilient and accountable AI solutions.",
      "keywords": [
        "Agility in Software 2.0",
        "Reinforced MLOps",
        "Notebook-IDE bridging",
        "FUSE-based CSI driver",
        "Kubernetes orchestration",
        "Cowait framework",
        "Trustworthy AI systems",
        "Continuous engineering",
        "CACE principle",
        "Production-grade ML solutions",
        "Local-remote development environments",
        "Performance and utility studies"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the **abstract** explicitly introduces and describes a system/tool called \"cowait.\" it states that \"backtick technologies designed cowait\" and details its \"four key features\" and how it \"helps developers leverage the power of containerization\" and \"simplifies dependency management.\" this is a direct presentation of a new system.\n*   the **introduction** sets the context for the problem that a tool like cowait would address (ai surge, ml applications, software 2.0, agile development, devops).\n\nthis content strongly aligns with the \"technical\" classification criteria: \"presents new methods, algorithms, or systems\" and \"abstract mentions: 'propose', 'develop', 'present', 'algorithm', 'method'.\" the paper is presenting cowait as a developed system.\n\n**classification: technical**"
    },
    "file_name": "4d3e1d7aebf1bbfe7191e45f844d61f93617b569.pdf"
  },
  {
    "success": true,
    "doc_id": "3e6c36913a180f783eecae605fe716a8",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/3dcf4c3e9161819f0aa1cf315fe1db20b6602da4.pdf",
    "citation_key": "surya2021b86",
    "metadata": {
      "title": "An exploratory study of AI and Big Data, and it's future in the United States",
      "authors": [
        "L. Surya"
      ],
      "published_date": "2021",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/3dcf4c3e9161819f0aa1cf315fe1db20b6602da4.pdf",
      "venue": "",
      "citationCount": 13,
      "score": 3.25,
      "summary": "",
      "keywords": []
    },
    "file_name": "3dcf4c3e9161819f0aa1cf315fe1db20b6602da4.pdf"
  },
  {
    "success": true,
    "doc_id": "95d727f1f347436f588231c2d9893a51",
    "summary": "This paper proposes the project-based learning (PBL) education system which uses Artificial Intelligence (AI) instead of teachers’ direct instruction. Kanazawa Institute of Technology (KIT) applies PBL to its design and engineering programme as Project Design (PD) Programme. Students form small groups to discuss real-life problems and sometimes collaborate with local communities. However, in order to prevent COVID-19 infection, students cannot go to school. Instead, e-Syllabus and the web meeting Zoom (videoconferencing software) are used to take lectures at home. Adding to the PBL class implementation experience under the impact of COVID-19 and to the review results of the progress of digital technology, the outline, and the feature of the on-line PBL education system using chatbot and AI is proposed. Although the system is still under development, some of the components are introduced. © PDE 2021.",
    "intriguing_abstract": "This paper proposes the project-based learning (PBL) education system which uses Artificial Intelligence (AI) instead of teachers’ direct instruction. Kanazawa Institute of Technology (KIT) applies PBL to its design and engineering programme as Project Design (PD) Programme. Students form small groups to discuss real-life problems and sometimes collaborate with local communities. However, in order to prevent COVID-19 infection, students cannot go to school. Instead, e-Syllabus and the web meeting Zoom (videoconferencing software) are used to take lectures at home. Adding to the PBL class implementation experience under the impact of COVID-19 and to the review results of the progress of digital technology, the outline, and the feature of the on-line PBL education system using chatbot and AI is proposed. Although the system is still under development, some of the components are introduced. © PDE 2021.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b83b390d0f991b844d3f4f3885dc753ee3f24aa6.pdf",
    "citation_key": "ito2021loj",
    "metadata": {
      "title": "THE ONLINE PBL (PROJECT-BASED LEARNING) EDUCATION SYSTEM USING AI (ARTIFICIAL INTELLIGENCE)",
      "authors": [
        "Takao Ito",
        "M. Tanaka",
        "Masako Shin",
        "K. Miyazaki"
      ],
      "published_date": "2021",
      "abstract": "This paper proposes the project-based learning (PBL) education system which uses Artificial Intelligence (AI) instead of teachers’ direct instruction. Kanazawa Institute of Technology (KIT) applies PBL to its design and engineering programme as Project Design (PD) Programme. Students form small groups to discuss real-life problems and sometimes collaborate with local communities. However, in order to prevent COVID-19 infection, students cannot go to school. Instead, e-Syllabus and the web meeting Zoom (videoconferencing software) are used to take lectures at home. Adding to the PBL class implementation experience under the impact of COVID-19 and to the review results of the progress of digital technology, the outline, and the feature of the on-line PBL education system using chatbot and AI is proposed. Although the system is still under development, some of the components are introduced. © PDE 2021.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b83b390d0f991b844d3f4f3885dc753ee3f24aa6.pdf",
      "venue": "DS 110: Proceedings of the 23rd International Conference on Engineering and Product Design Education (EPDE 2021)",
      "citationCount": 12,
      "score": 3.0,
      "summary": "This paper proposes the project-based learning (PBL) education system which uses Artificial Intelligence (AI) instead of teachers’ direct instruction. Kanazawa Institute of Technology (KIT) applies PBL to its design and engineering programme as Project Design (PD) Programme. Students form small groups to discuss real-life problems and sometimes collaborate with local communities. However, in order to prevent COVID-19 infection, students cannot go to school. Instead, e-Syllabus and the web meeting Zoom (videoconferencing software) are used to take lectures at home. Adding to the PBL class implementation experience under the impact of COVID-19 and to the review results of the progress of digital technology, the outline, and the feature of the on-line PBL education system using chatbot and AI is proposed. Although the system is still under development, some of the components are introduced. © PDE 2021.",
      "keywords": []
    },
    "file_name": "b83b390d0f991b844d3f4f3885dc753ee3f24aa6.pdf"
  },
  {
    "success": true,
    "doc_id": "65a90d804df8dd1712685810f40c1c82",
    "summary": "The chapter summarizes the concepts and challenges of DevOps in IoT, DevSecOps in IoT, integrating security into IoT, machine learning and AI in IoT of software engineering practices. DevOps is a software engineering culture and practice that aims at unifying software development (Dev) and software operation (Ops). The main characteristic of DevOps is the automation and monitoring at all steps of software construction, from integration, testing, releasing to deployment and infrastructure management. DevSecOps is a practice of integrating security into every aspect of an application lifecycle from design to development.",
    "intriguing_abstract": "The chapter summarizes the concepts and challenges of DevOps in IoT, DevSecOps in IoT, integrating security into IoT, machine learning and AI in IoT of software engineering practices. DevOps is a software engineering culture and practice that aims at unifying software development (Dev) and software operation (Ops). The main characteristic of DevOps is the automation and monitoring at all steps of software construction, from integration, testing, releasing to deployment and infrastructure management. DevSecOps is a practice of integrating security into every aspect of an application lifecycle from design to development.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8ed3ec67eff4b3e4ac9df97df331356d74fead64.pdf",
    "citation_key": "kavitha2021jvg",
    "metadata": {
      "title": "Current Trends in Integrating the Internet of Things Into Software Engineering Practices",
      "authors": [
        "S. Kavitha",
        "J. V. Anchitaalagammai",
        "S. Nirmala",
        "S. Murali"
      ],
      "published_date": "2021",
      "abstract": "The chapter summarizes the concepts and challenges of DevOps in IoT, DevSecOps in IoT, integrating security into IoT, machine learning and AI in IoT of software engineering practices. DevOps is a software engineering culture and practice that aims at unifying software development (Dev) and software operation (Ops). The main characteristic of DevOps is the automation and monitoring at all steps of software construction, from integration, testing, releasing to deployment and infrastructure management. DevSecOps is a practice of integrating security into every aspect of an application lifecycle from design to development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8ed3ec67eff4b3e4ac9df97df331356d74fead64.pdf",
      "venue": "Research Anthology on Artificial Intelligence Applications in Security",
      "citationCount": 12,
      "score": 3.0,
      "summary": "The chapter summarizes the concepts and challenges of DevOps in IoT, DevSecOps in IoT, integrating security into IoT, machine learning and AI in IoT of software engineering practices. DevOps is a software engineering culture and practice that aims at unifying software development (Dev) and software operation (Ops). The main characteristic of DevOps is the automation and monitoring at all steps of software construction, from integration, testing, releasing to deployment and infrastructure management. DevSecOps is a practice of integrating security into every aspect of an application lifecycle from design to development.",
      "keywords": []
    },
    "file_name": "8ed3ec67eff4b3e4ac9df97df331356d74fead64.pdf"
  },
  {
    "success": true,
    "doc_id": "c8db53abba3304a029f567331e133257",
    "summary": "Purpose To evaluate the performance of trained technologists vis-à-vis radiologists for volumetric pancreas segmentation and to assess the impact of supplementary training on their performance. Methods In this IRB-approved study, 22 technologists were trained in pancreas segmentation on portal venous phase CT through radiologist-led interactive videoconferencing sessions based on an image-rich curriculum. Technologists segmented pancreas in 188 CTs using freehand tools on custom image-viewing software. Subsequent supplementary training included multimedia videos focused on common errors, which were followed by second batch of 159 segmentations. Two radiologists reviewed all cases and corrected inaccurate segmentations. Technologists’ segmentations were compared against radiologists’ segmentations using Dice-Sorenson coefficient (DSC), Jaccard coefficient (JC), and Bland–Altman analysis. Results Corrections were made in 71 (38%) cases from first batch [26 (37%) oversegmentations and 45 (63%) undersegmentations] and in 77 (48%) cases from second batch [12 (16%) oversegmentations and 65 (84%) undersegmentations]. DSC, JC, false positive (FP), and false negative (FN) [mean (SD)] in first versus second batches were 0.63 (0.15) versus 0.63 (0.16), 0.48 (0.15) versus 0.48 (0.15), 0.29 (0.21) versus 0.21 (0.10), and 0.36 (0.20) versus 0.43 (0.19), respectively. Differences were not significant ( p  > 0.05). However, range of mean pancreatic volume difference reduced in the second batch [− 2.74 cc (min − 92.96 cc, max 87.47 cc) versus − 23.57 cc (min − 77.32, max 30.19)]. Conclusion Trained technologists could perform volumetric pancreas segmentation with reasonable accuracy despite its complexity. Supplementary training further reduced range of volume difference in segmentations. Investment into training technologists could augment and accelerate development of body imaging datasets for AI applications.",
    "intriguing_abstract": "Purpose To evaluate the performance of trained technologists vis-à-vis radiologists for volumetric pancreas segmentation and to assess the impact of supplementary training on their performance. Methods In this IRB-approved study, 22 technologists were trained in pancreas segmentation on portal venous phase CT through radiologist-led interactive videoconferencing sessions based on an image-rich curriculum. Technologists segmented pancreas in 188 CTs using freehand tools on custom image-viewing software. Subsequent supplementary training included multimedia videos focused on common errors, which were followed by second batch of 159 segmentations. Two radiologists reviewed all cases and corrected inaccurate segmentations. Technologists’ segmentations were compared against radiologists’ segmentations using Dice-Sorenson coefficient (DSC), Jaccard coefficient (JC), and Bland–Altman analysis. Results Corrections were made in 71 (38%) cases from first batch [26 (37%) oversegmentations and 45 (63%) undersegmentations] and in 77 (48%) cases from second batch [12 (16%) oversegmentations and 65 (84%) undersegmentations]. DSC, JC, false positive (FP), and false negative (FN) [mean (SD)] in first versus second batches were 0.63 (0.15) versus 0.63 (0.16), 0.48 (0.15) versus 0.48 (0.15), 0.29 (0.21) versus 0.21 (0.10), and 0.36 (0.20) versus 0.43 (0.19), respectively. Differences were not significant ( p  > 0.05). However, range of mean pancreatic volume difference reduced in the second batch [− 2.74 cc (min − 92.96 cc, max 87.47 cc) versus − 23.57 cc (min − 77.32, max 30.19)]. Conclusion Trained technologists could perform volumetric pancreas segmentation with reasonable accuracy despite its complexity. Supplementary training further reduced range of volume difference in segmentations. Investment into training technologists could augment and accelerate development of body imaging datasets for AI applications.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/e295175ad6020d391d62cc6ca694df5da1ab9f31.pdf",
    "citation_key": "suman2020zxw",
    "metadata": {
      "title": "Development of a volumetric pancreas segmentation CT dataset for AI applications through trained technologists: a study during the COVID 19 containment phase",
      "authors": [
        "Garima Suman",
        "A. Panda",
        "P. Korfiatis",
        "Marie E. Edwards",
        "Sushil Garg",
        "D. Blezek",
        "S. Chari",
        "A. Goenka"
      ],
      "published_date": "2020",
      "abstract": "Purpose To evaluate the performance of trained technologists vis-à-vis radiologists for volumetric pancreas segmentation and to assess the impact of supplementary training on their performance. Methods In this IRB-approved study, 22 technologists were trained in pancreas segmentation on portal venous phase CT through radiologist-led interactive videoconferencing sessions based on an image-rich curriculum. Technologists segmented pancreas in 188 CTs using freehand tools on custom image-viewing software. Subsequent supplementary training included multimedia videos focused on common errors, which were followed by second batch of 159 segmentations. Two radiologists reviewed all cases and corrected inaccurate segmentations. Technologists’ segmentations were compared against radiologists’ segmentations using Dice-Sorenson coefficient (DSC), Jaccard coefficient (JC), and Bland–Altman analysis. Results Corrections were made in 71 (38%) cases from first batch [26 (37%) oversegmentations and 45 (63%) undersegmentations] and in 77 (48%) cases from second batch [12 (16%) oversegmentations and 65 (84%) undersegmentations]. DSC, JC, false positive (FP), and false negative (FN) [mean (SD)] in first versus second batches were 0.63 (0.15) versus 0.63 (0.16), 0.48 (0.15) versus 0.48 (0.15), 0.29 (0.21) versus 0.21 (0.10), and 0.36 (0.20) versus 0.43 (0.19), respectively. Differences were not significant ( p  > 0.05). However, range of mean pancreatic volume difference reduced in the second batch [− 2.74 cc (min − 92.96 cc, max 87.47 cc) versus − 23.57 cc (min − 77.32, max 30.19)]. Conclusion Trained technologists could perform volumetric pancreas segmentation with reasonable accuracy despite its complexity. Supplementary training further reduced range of volume difference in segmentations. Investment into training technologists could augment and accelerate development of body imaging datasets for AI applications.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/e295175ad6020d391d62cc6ca694df5da1ab9f31.pdf",
      "venue": "Abdominal Radiology",
      "citationCount": 14,
      "score": 2.8000000000000003,
      "summary": "Purpose To evaluate the performance of trained technologists vis-à-vis radiologists for volumetric pancreas segmentation and to assess the impact of supplementary training on their performance. Methods In this IRB-approved study, 22 technologists were trained in pancreas segmentation on portal venous phase CT through radiologist-led interactive videoconferencing sessions based on an image-rich curriculum. Technologists segmented pancreas in 188 CTs using freehand tools on custom image-viewing software. Subsequent supplementary training included multimedia videos focused on common errors, which were followed by second batch of 159 segmentations. Two radiologists reviewed all cases and corrected inaccurate segmentations. Technologists’ segmentations were compared against radiologists’ segmentations using Dice-Sorenson coefficient (DSC), Jaccard coefficient (JC), and Bland–Altman analysis. Results Corrections were made in 71 (38%) cases from first batch [26 (37%) oversegmentations and 45 (63%) undersegmentations] and in 77 (48%) cases from second batch [12 (16%) oversegmentations and 65 (84%) undersegmentations]. DSC, JC, false positive (FP), and false negative (FN) [mean (SD)] in first versus second batches were 0.63 (0.15) versus 0.63 (0.16), 0.48 (0.15) versus 0.48 (0.15), 0.29 (0.21) versus 0.21 (0.10), and 0.36 (0.20) versus 0.43 (0.19), respectively. Differences were not significant ( p  > 0.05). However, range of mean pancreatic volume difference reduced in the second batch [− 2.74 cc (min − 92.96 cc, max 87.47 cc) versus − 23.57 cc (min − 77.32, max 30.19)]. Conclusion Trained technologists could perform volumetric pancreas segmentation with reasonable accuracy despite its complexity. Supplementary training further reduced range of volume difference in segmentations. Investment into training technologists could augment and accelerate development of body imaging datasets for AI applications.",
      "keywords": []
    },
    "file_name": "e295175ad6020d391d62cc6ca694df5da1ab9f31.pdf"
  },
  {
    "success": true,
    "doc_id": "90c2d743acf363613f1f2249008c885b",
    "summary": "Energy conservation has become a crucial issue for today’s sustainable development. However, converting the energy system to renewable ones and improving the energy efficiency are enormous challenges for current energy sectors. To overcome such challenges, we propose in this work a smart software-hardware (SW-HW) platform and design for a smart energy management system. The platform combines the advantages of SW (refers to user interface) and HW (i.e., AI chip) in terms of high speed and low power. Electric vehicles (EVs) then intelligently and autonomously charge or discharge their batteries. Therefore, the VPP can efficiently manage all the distributed EV batteries as a huge smart power-storage facility. In this way, EV batteries are able to store the extra electricity produced by renewable energy resources, such as solar installations, wind farms, etc. This will bring about greater flexibility and scalability to the power grid and the green vehicle networks.",
    "intriguing_abstract": "Energy conservation has become a crucial issue for today’s sustainable development. However, converting the energy system to renewable ones and improving the energy efficiency are enormous challenges for current energy sectors. To overcome such challenges, we propose in this work a smart software-hardware (SW-HW) platform and design for a smart energy management system. The platform combines the advantages of SW (refers to user interface) and HW (i.e., AI chip) in terms of high speed and low power. Electric vehicles (EVs) then intelligently and autonomously charge or discharge their batteries. Therefore, the VPP can efficiently manage all the distributed EV batteries as a huge smart power-storage facility. In this way, EV batteries are able to store the extra electricity produced by renewable energy resources, such as solar installations, wind farms, etc. This will bring about greater flexibility and scalability to the power grid and the green vehicle networks.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/02a8df1c16ae5d085be35d4418baad35f1f74764.pdf",
    "citation_key": "huang2021xwb",
    "metadata": {
      "title": "Smart Energy Management System based on Reconfigurable AI Chip and Electrical Vehicles",
      "authors": [
        "Huakun Huang",
        "M. Ogbodo",
        "Zhishang Wang",
        "Chen Qiu",
        "Masayuki Hisada",
        "Abderazek Ben Abdallah"
      ],
      "published_date": "2021",
      "abstract": "Energy conservation has become a crucial issue for today’s sustainable development. However, converting the energy system to renewable ones and improving the energy efficiency are enormous challenges for current energy sectors. To overcome such challenges, we propose in this work a smart software-hardware (SW-HW) platform and design for a smart energy management system. The platform combines the advantages of SW (refers to user interface) and HW (i.e., AI chip) in terms of high speed and low power. Electric vehicles (EVs) then intelligently and autonomously charge or discharge their batteries. Therefore, the VPP can efficiently manage all the distributed EV batteries as a huge smart power-storage facility. In this way, EV batteries are able to store the extra electricity produced by renewable energy resources, such as solar installations, wind farms, etc. This will bring about greater flexibility and scalability to the power grid and the green vehicle networks.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/02a8df1c16ae5d085be35d4418baad35f1f74764.pdf",
      "venue": "International Conference on Big Data and Smart Computing",
      "citationCount": 11,
      "score": 2.75,
      "summary": "Energy conservation has become a crucial issue for today’s sustainable development. However, converting the energy system to renewable ones and improving the energy efficiency are enormous challenges for current energy sectors. To overcome such challenges, we propose in this work a smart software-hardware (SW-HW) platform and design for a smart energy management system. The platform combines the advantages of SW (refers to user interface) and HW (i.e., AI chip) in terms of high speed and low power. Electric vehicles (EVs) then intelligently and autonomously charge or discharge their batteries. Therefore, the VPP can efficiently manage all the distributed EV batteries as a huge smart power-storage facility. In this way, EV batteries are able to store the extra electricity produced by renewable energy resources, such as solar installations, wind farms, etc. This will bring about greater flexibility and scalability to the power grid and the green vehicle networks.",
      "keywords": []
    },
    "file_name": "02a8df1c16ae5d085be35d4418baad35f1f74764.pdf"
  },
  {
    "success": true,
    "doc_id": "a660aa6d4a1579f9dc6833fc8701fb7f",
    "summary": "Mining of software engineering data have proved successful for reusability of components in software development. Artificial Intelligence improves a large application domain of software engineering activities. Intelligent knowledge discovery integrates Artificial Intelligence with Data Mining for intelligent computing of software engineering tasks. The integration of artificial intelligence with data mining for supporting software engineering applications leads to Software Intelligence. This paper analyzes three artificial intelligence techniques that uses data mining, business intelligence, machine learning for promoting automated software reuse for software construction and overall software development. The business intelligence tools are used for intelligent knowledge discovery of code that will be used for reusability of applications and components. An analysis of several AI techniques in software reuse domain of software engineering is discussed for automated software reuse and identification of potential research prospects in the field.",
    "intriguing_abstract": "Mining of software engineering data have proved successful for reusability of components in software development. Artificial Intelligence improves a large application domain of software engineering activities. Intelligent knowledge discovery integrates Artificial Intelligence with Data Mining for intelligent computing of software engineering tasks. The integration of artificial intelligence with data mining for supporting software engineering applications leads to Software Intelligence. This paper analyzes three artificial intelligence techniques that uses data mining, business intelligence, machine learning for promoting automated software reuse for software construction and overall software development. The business intelligence tools are used for intelligent knowledge discovery of code that will be used for reusability of applications and components. An analysis of several AI techniques in software reuse domain of software engineering is discussed for automated software reuse and identification of potential research prospects in the field.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/098c0218483681b2034f84418f1f1876c4953d89.pdf",
    "citation_key": "wangoo2018dc5",
    "metadata": {
      "title": "Artificial Intelligence Techniques in Software Engineering for Automated Software Reuse and Design",
      "authors": [
        "Divanshi Priyadarshni Wangoo"
      ],
      "published_date": "2018",
      "abstract": "Mining of software engineering data have proved successful for reusability of components in software development. Artificial Intelligence improves a large application domain of software engineering activities. Intelligent knowledge discovery integrates Artificial Intelligence with Data Mining for intelligent computing of software engineering tasks. The integration of artificial intelligence with data mining for supporting software engineering applications leads to Software Intelligence. This paper analyzes three artificial intelligence techniques that uses data mining, business intelligence, machine learning for promoting automated software reuse for software construction and overall software development. The business intelligence tools are used for intelligent knowledge discovery of code that will be used for reusability of applications and components. An analysis of several AI techniques in software reuse domain of software engineering is discussed for automated software reuse and identification of potential research prospects in the field.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/098c0218483681b2034f84418f1f1876c4953d89.pdf",
      "venue": "International Conference on Computing, Communication and Automation",
      "citationCount": 18,
      "score": 2.571428571428571,
      "summary": "Mining of software engineering data have proved successful for reusability of components in software development. Artificial Intelligence improves a large application domain of software engineering activities. Intelligent knowledge discovery integrates Artificial Intelligence with Data Mining for intelligent computing of software engineering tasks. The integration of artificial intelligence with data mining for supporting software engineering applications leads to Software Intelligence. This paper analyzes three artificial intelligence techniques that uses data mining, business intelligence, machine learning for promoting automated software reuse for software construction and overall software development. The business intelligence tools are used for intelligent knowledge discovery of code that will be used for reusability of applications and components. An analysis of several AI techniques in software reuse domain of software engineering is discussed for automated software reuse and identification of potential research prospects in the field.",
      "keywords": []
    },
    "file_name": "098c0218483681b2034f84418f1f1876c4953d89.pdf"
  },
  {
    "success": true,
    "doc_id": "1fd56563197570876d28cfa0b215856b",
    "summary": "Artificial intelligence (AI) technologies are being actively developed in modern healthcare. Despite the extensive data on the prospects for AI, promises of the developers of such products are inflated sometimes. As a result, overestimated expectations of AI can occur in practical healthcare. There are many obstacles for the widespread adoption of AI in practical healthcare. In this regard, a balance between creating the conditions for accelerated introduction of AI and ensuring the reasonable control of potential risks of harm to patients’ health is an urgent task of modern regulation of software as medical devices (SaMD) in Russia. The Russian Federation has recently conducted a consistent improvement of the current legislation to ensure state control over safety and effectiveness of SaMD. Decree of the President of Russia dated by October 10, 2019 No. 490 approved the Russian national strategy for the development of AI up to 2030 and identified healthcare as one of the key areas for the development",
    "intriguing_abstract": "Artificial intelligence (AI) technologies are being actively developed in modern healthcare. Despite the extensive data on the prospects for AI, promises of the developers of such products are inflated sometimes. As a result, overestimated expectations of AI can occur in practical healthcare. There are many obstacles for the widespread adoption of AI in practical healthcare. In this regard, a balance between creating the conditions for accelerated introduction of AI and ensuring the reasonable control of potential risks of harm to patients’ health is an urgent task of modern regulation of software as medical devices (SaMD) in Russia. The Russian Federation has recently conducted a consistent improvement of the current legislation to ensure state control over safety and effectiveness of SaMD. Decree of the President of Russia dated by October 10, 2019 No. 490 approved the Russian national strategy for the development of AI up to 2030 and identified healthcare as one of the key areas for the development",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d01a4cfe9de3f3b30691a4cc3f6a719206900da3.pdf",
    "citation_key": "gusev2021upg",
    "metadata": {
      "title": "Legal regulation of artificial intelligence software in healthcare in the Russian Federation",
      "authors": [
        "A. Gusev",
        "S. Morozov",
        "V. A. Kutichev",
        "R. Novitsky"
      ],
      "published_date": "2021",
      "abstract": "Artificial intelligence (AI) technologies are being actively developed in modern healthcare. Despite the extensive data on the prospects for AI, promises of the developers of such products are inflated sometimes. As a result, overestimated expectations of AI can occur in practical healthcare. There are many obstacles for the widespread adoption of AI in practical healthcare. In this regard, a balance between creating the conditions for accelerated introduction of AI and ensuring the reasonable control of potential risks of harm to patients’ health is an urgent task of modern regulation of software as medical devices (SaMD) in Russia. The Russian Federation has recently conducted a consistent improvement of the current legislation to ensure state control over safety and effectiveness of SaMD. Decree of the President of Russia dated by October 10, 2019 No. 490 approved the Russian national strategy for the development of AI up to 2030 and identified healthcare as one of the key areas for the development",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d01a4cfe9de3f3b30691a4cc3f6a719206900da3.pdf",
      "venue": "Medical Technologies. Assessment and Choice",
      "citationCount": 10,
      "score": 2.5,
      "summary": "Artificial intelligence (AI) technologies are being actively developed in modern healthcare. Despite the extensive data on the prospects for AI, promises of the developers of such products are inflated sometimes. As a result, overestimated expectations of AI can occur in practical healthcare. There are many obstacles for the widespread adoption of AI in practical healthcare. In this regard, a balance between creating the conditions for accelerated introduction of AI and ensuring the reasonable control of potential risks of harm to patients’ health is an urgent task of modern regulation of software as medical devices (SaMD) in Russia. The Russian Federation has recently conducted a consistent improvement of the current legislation to ensure state control over safety and effectiveness of SaMD. Decree of the President of Russia dated by October 10, 2019 No. 490 approved the Russian national strategy for the development of AI up to 2030 and identified healthcare as one of the key areas for the development",
      "keywords": []
    },
    "file_name": "d01a4cfe9de3f3b30691a4cc3f6a719206900da3.pdf"
  },
  {
    "success": true,
    "doc_id": "dd0c81e0fac56cbe71be4e42d5d0e943",
    "summary": "Conversational Artificial Intelligence (AI) systems have recently sky-rocketed in popularity and are now used in many applications, from car assistants to customer support. The development of conversational AI systems is supported by a large variety of software platforms, all with similar goals, but different focus points and functionalities. A systematic foundation for classifying conversational AI platforms is currently lacking. We propose a framework for assessing the maturity level of conversational AI development platforms. Our framework is based on a systematic literature review, in which we extracted common and distinguishing features of various open-source and commercial (or in-house) platforms. Inspired by language reference frameworks, we identify different maturity levels that a conversational AI development platform may exhibit in understanding and responding to user inputs. Our framework can guide organizations in selecting a conversational AI development platform according to their needs, as well as helping researchers and platform developers improving the maturity of their platforms.",
    "intriguing_abstract": "Conversational Artificial Intelligence (AI) systems have recently sky-rocketed in popularity and are now used in many applications, from car assistants to customer support. The development of conversational AI systems is supported by a large variety of software platforms, all with similar goals, but different focus points and functionalities. A systematic foundation for classifying conversational AI platforms is currently lacking. We propose a framework for assessing the maturity level of conversational AI development platforms. Our framework is based on a systematic literature review, in which we extracted common and distinguishing features of various open-source and commercial (or in-house) platforms. Inspired by language reference frameworks, we identify different maturity levels that a conversational AI development platform may exhibit in understanding and responding to user inputs. Our framework can guide organizations in selecting a conversational AI development platform according to their needs, as well as helping researchers and platform developers improving the maturity of their platforms.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/4827fe6cb92acf1ce4b157fe5e52a05537965454.pdf",
    "citation_key": "aronsson2020w1s",
    "metadata": {
      "title": "A maturity assessment framework for conversational AI development platforms",
      "authors": [
        "Johan Aronsson",
        "Philip Lu",
        "D. Strüber",
        "T. Berger"
      ],
      "published_date": "2020",
      "abstract": "Conversational Artificial Intelligence (AI) systems have recently sky-rocketed in popularity and are now used in many applications, from car assistants to customer support. The development of conversational AI systems is supported by a large variety of software platforms, all with similar goals, but different focus points and functionalities. A systematic foundation for classifying conversational AI platforms is currently lacking. We propose a framework for assessing the maturity level of conversational AI development platforms. Our framework is based on a systematic literature review, in which we extracted common and distinguishing features of various open-source and commercial (or in-house) platforms. Inspired by language reference frameworks, we identify different maturity levels that a conversational AI development platform may exhibit in understanding and responding to user inputs. Our framework can guide organizations in selecting a conversational AI development platform according to their needs, as well as helping researchers and platform developers improving the maturity of their platforms.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/4827fe6cb92acf1ce4b157fe5e52a05537965454.pdf",
      "venue": "ACM Symposium on Applied Computing",
      "citationCount": 12,
      "score": 2.4000000000000004,
      "summary": "Conversational Artificial Intelligence (AI) systems have recently sky-rocketed in popularity and are now used in many applications, from car assistants to customer support. The development of conversational AI systems is supported by a large variety of software platforms, all with similar goals, but different focus points and functionalities. A systematic foundation for classifying conversational AI platforms is currently lacking. We propose a framework for assessing the maturity level of conversational AI development platforms. Our framework is based on a systematic literature review, in which we extracted common and distinguishing features of various open-source and commercial (or in-house) platforms. Inspired by language reference frameworks, we identify different maturity levels that a conversational AI development platform may exhibit in understanding and responding to user inputs. Our framework can guide organizations in selecting a conversational AI development platform according to their needs, as well as helping researchers and platform developers improving the maturity of their platforms.",
      "keywords": []
    },
    "file_name": "4827fe6cb92acf1ce4b157fe5e52a05537965454.pdf"
  },
  {
    "success": true,
    "doc_id": "74f3af08bf9856e4db82e67902e7cc7a",
    "summary": "Here's a focused summary of the paper \"Ethically Aligned Design: An empirical evaluation of the RESOLVEDD -strategy in Software and Systems development context\" by Vakkuri, Kemell, and Abrahamsson \\cite{vakkuri20190xd} for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of integrating ethical considerations into the practical design and development of Artificial Intelligence and Autonomous Systems (AI/AS). Despite the growing societal impact of AI/AS, there is a significant lack of useful and tangible tools to help software developers and designers implement ethical considerations effectively \\cite{vakkuri20190xd}. Developers often lack awareness of ethical issues and the practical means to address them during the development lifecycle.\n    *   **Importance and Challenge:** This problem is critical because AI/AS systems are becoming ubiquitous and influential, with potential for significant damage due to their cyber-physical nature. Developers' values are inherently built into systems, yet they are often not well-informed about ethics and tend to neglect ethical issues, leading to problems being discovered only after deployment. The challenge lies in finding simple, practical, and non-resource-intensive methods that developers will actually adopt to tackle complex ethical dilemmas \\cite{vakkuri20190xd}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work acknowledges a history of integrating human values into design, citing Value Sensitive Design (VSD) and its various adaptations (e.g., Care Centered VSD, Value Dams and Flows) as foundational. It also references AI-specific values like transparency, accountability, responsibility (ART principles), fairness, and freedom from bias, as well as the IEEE's Ethically Aligned Design (EAD) initiative \\cite{vakkuri20190xd}.\n    *   **Limitations of Previous Solutions:** While these existing frameworks define ethical principles and values, the paper highlights a gap in practical knowledge regarding *how* to introduce these ethics to developers and *how* proposed methods function in real-world development contexts. Many existing approaches may not be sufficiently simple or practical for developers, who prefer methods that are not resource-intensive. This paper positions itself by empirically evaluating a concrete, step-by-step decision-making tool (RESOLVEDD) to bridge this practical implementation gap \\cite{vakkuri20190xd}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm:** The paper evaluates the **RESOLVEDD-strategy**, a nine-step, step-by-step decision-making tool originally from business ethics. This strategy is designed to guide individuals without prior ethics or philosophy knowledge through a rational ethical decision-making process. It is flexible, not tied to a specific ethical theory, and allows users to apply their own values or chosen ethical framework to justify and explain their decisions \\cite{vakkuri20190xd}.\n    *   **Novelty/Difference:** The innovation lies in the *application and empirical evaluation* of the RESOLVEDD-strategy within the specific technical domain of AI/AS software and systems development. Unlike more abstract ethical guidelines, RESOLVEDD provides a concrete, process-oriented method for developers to identify, analyze, and address ethical issues. The paper also introduces a conceptual research framework (Figure 2) that links the use of such an ethical tool to developer commitment, and the \"ART\" principles (Accountability, Responsibility, Transparency), hypothesizing that tool adoption can foster a more ethical development culture \\cite{vakkuri20190xd}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:** The primary contribution is the empirical assessment of the RESOLVEDD-strategy as a practical, actionable ethical tool for AI/AS development. While RESOLVEDD itself is an existing method, its validation in this technical context, particularly for software developers, is a novel contribution to \"Ethically Aligned Design\" practices \\cite{vakkuri20190xd}.\n    *   **Theoretical Insights or Analysis:** The paper proposes a conceptual framework (Figure 2) illustrating the interplay between developer commitment, transparency, accountability, and responsibility (ART principles) in achieving ethically aligned design. This framework provides a theoretical basis for understanding how practical ethical tools can influence developer behavior and, consequently, the ethical outcomes of AI/AS systems \\cite{vakkuri20190xd}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The RESOLVEDD-strategy was empirically evaluated through a multiple case study involving five student projects focused on developing AI/AS prototypes \\cite{vakkuri20190xd}. In these projects, the use of an ethical tool (specifically RESOLVEDD) was explicitly mandated as a design requirement for the development teams.\n    *   **Key Performance Metrics and Comparison Results:** Although detailed results are not fully provided in the excerpt, the abstract highlights a key finding: \"simply the presence of an ethical tool has an effect on ethical consideration, creating more responsibility even in instances where the use of the tool is not intrinsically motivated\" \\cite{vakkuri20190xd}. This indicates that the mere requirement to engage with a structured ethical tool can positively influence developers' ethical awareness and sense of responsibility during the design process. The study aimed to understand the *impact* of the tool on ethical consideration and its *practical functioning* within the given context.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The study's reliance on student projects for empirical validation may limit the generalizability of findings to professional development environments, which often involve different pressures, motivations, and project complexities \\cite{vakkuri20190xd}. The RESOLVEDD-strategy, while flexible, is a structured process, and its effectiveness might vary depending on developers' receptiveness to such structured approaches.\n    *   **Scope of Applicability:** The evaluation is specifically within the context of AI/AS design. While RESOLVEDD is adaptable, its direct applicability and effectiveness in other software domains or organizational cultures would require further validation \\cite{vakkuri20190xd}. The study focuses on the *introduction* and *effect* of one specific ethical tool rather than a comprehensive comparison across all ethical design methodologies.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This paper significantly advances the technical state-of-the-art by providing empirical evidence for the practical utility of a structured ethical decision-making tool in AI/AS development \\cite{vakkuri20190xd}. It moves beyond theoretical discussions of ethical principles to evaluate a concrete method for their implementation, addressing a critical gap in \"Ethically Aligned Design.\" The finding that the *presence* of such a tool can foster responsibility, even without intrinsic motivation, is a crucial insight for promoting ethical practices in software engineering.\n    *   **Potential Impact on Future Research:** The work establishes a foundation for future research into practical ethical tools and their integration into software engineering processes. It underscores the importance of developer commitment and the ART principles as key factors in achieving ethical AI/AS. Future research can build upon this by exploring the long-term impact of RESOLVEDD, comparing its effectiveness with other ethical design methods, investigating its scalability, and examining its application in diverse professional settings to further refine \"Ethically Aligned Design\" methodologies \\cite{vakkuri20190xd}.",
    "intriguing_abstract": "The rapid proliferation of Artificial Intelligence and Autonomous Systems (AI/AS) demands robust ethical integration, yet developers often lack practical tools to embed these critical considerations into design. This paper addresses this pressing challenge by empirically evaluating the **RESOLVEDD-strategy**, a nine-step ethical decision-making tool, within the specific context of AI/AS software development. Moving beyond abstract principles, we demonstrate RESOLVEDD's efficacy in providing a tangible, process-oriented method for developers to identify and address complex ethical dilemmas.\n\nOur multiple case study reveals a pivotal insight: the mere presence of a structured ethical tool significantly enhances ethical consideration and fosters a sense of **responsibility** among developers, even when intrinsic motivation is initially low. This work introduces a novel conceptual framework linking tool adoption to developer commitment and the crucial **ART principles** (**Accountability, Responsibility, Transparency**). By offering a concrete pathway for **Ethically Aligned Design**, this research advances the state-of-the-art, providing actionable strategies to cultivate a more ethical **software engineering** culture and ensure responsible AI/AS innovation.",
    "keywords": [
      "Ethically Aligned Design",
      "Artificial Intelligence and Autonomous Systems (AI/AS)",
      "Ethical considerations",
      "RESOLVEDD-strategy",
      "Empirical evaluation",
      "Software and systems development",
      "Practical ethical tools",
      "Accountability",
      "Responsibility",
      "Transparency (ART principles)",
      "Ethical decision-making process",
      "Integrating ethics into design",
      "Developer commitment",
      "Conceptual research framework",
      "Impact of ethical tools"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/41e2d221f01ecbf0fa76124c9fb2fdcc5f890112.pdf",
    "citation_key": "vakkuri20190xd",
    "metadata": {
      "title": "Ethically Aligned Design: An Empirical Evaluation of the RESOLVEDD-Strategy in Software and Systems Development Context",
      "authors": [
        "Ville Vakkuri",
        "Kai-Kristian Kemell",
        "P. Abrahamsson"
      ],
      "published_date": "2019",
      "abstract": "Use of artificial intelligence (AI) in human contexts calls for ethical considerations for the design and development of AI-based systems. However, little knowledge currently exists on how to provide useful and tangible tools that could help software developers and designers implement ethical considerations into practice. In this paper, we empirically evaluate a method that enables ethically aligned design in a decision-making process. Though this method, titled the RESOLVEDD strategy, originates from the field of business ethics, it is being applied in other fields as well. We tested the RESOLVEDD strategy in a multiple case study of five student projects where the use of ethical tools was given as one of the design requirements. A key finding from the study indicates that simply the presence of an ethical tool has an effect on ethical consideration, creating more responsibility even in instances where the use of the tool is not intrinsically motivated.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/41e2d221f01ecbf0fa76124c9fb2fdcc5f890112.pdf",
      "venue": "EUROMICRO Conference on Software Engineering and Advanced Applications",
      "citationCount": 14,
      "score": 2.333333333333333,
      "summary": "Here's a focused summary of the paper \"Ethically Aligned Design: An empirical evaluation of the RESOLVEDD -strategy in Software and Systems development context\" by Vakkuri, Kemell, and Abrahamsson \\cite{vakkuri20190xd} for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of integrating ethical considerations into the practical design and development of Artificial Intelligence and Autonomous Systems (AI/AS). Despite the growing societal impact of AI/AS, there is a significant lack of useful and tangible tools to help software developers and designers implement ethical considerations effectively \\cite{vakkuri20190xd}. Developers often lack awareness of ethical issues and the practical means to address them during the development lifecycle.\n    *   **Importance and Challenge:** This problem is critical because AI/AS systems are becoming ubiquitous and influential, with potential for significant damage due to their cyber-physical nature. Developers' values are inherently built into systems, yet they are often not well-informed about ethics and tend to neglect ethical issues, leading to problems being discovered only after deployment. The challenge lies in finding simple, practical, and non-resource-intensive methods that developers will actually adopt to tackle complex ethical dilemmas \\cite{vakkuri20190xd}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work acknowledges a history of integrating human values into design, citing Value Sensitive Design (VSD) and its various adaptations (e.g., Care Centered VSD, Value Dams and Flows) as foundational. It also references AI-specific values like transparency, accountability, responsibility (ART principles), fairness, and freedom from bias, as well as the IEEE's Ethically Aligned Design (EAD) initiative \\cite{vakkuri20190xd}.\n    *   **Limitations of Previous Solutions:** While these existing frameworks define ethical principles and values, the paper highlights a gap in practical knowledge regarding *how* to introduce these ethics to developers and *how* proposed methods function in real-world development contexts. Many existing approaches may not be sufficiently simple or practical for developers, who prefer methods that are not resource-intensive. This paper positions itself by empirically evaluating a concrete, step-by-step decision-making tool (RESOLVEDD) to bridge this practical implementation gap \\cite{vakkuri20190xd}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm:** The paper evaluates the **RESOLVEDD-strategy**, a nine-step, step-by-step decision-making tool originally from business ethics. This strategy is designed to guide individuals without prior ethics or philosophy knowledge through a rational ethical decision-making process. It is flexible, not tied to a specific ethical theory, and allows users to apply their own values or chosen ethical framework to justify and explain their decisions \\cite{vakkuri20190xd}.\n    *   **Novelty/Difference:** The innovation lies in the *application and empirical evaluation* of the RESOLVEDD-strategy within the specific technical domain of AI/AS software and systems development. Unlike more abstract ethical guidelines, RESOLVEDD provides a concrete, process-oriented method for developers to identify, analyze, and address ethical issues. The paper also introduces a conceptual research framework (Figure 2) that links the use of such an ethical tool to developer commitment, and the \"ART\" principles (Accountability, Responsibility, Transparency), hypothesizing that tool adoption can foster a more ethical development culture \\cite{vakkuri20190xd}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:** The primary contribution is the empirical assessment of the RESOLVEDD-strategy as a practical, actionable ethical tool for AI/AS development. While RESOLVEDD itself is an existing method, its validation in this technical context, particularly for software developers, is a novel contribution to \"Ethically Aligned Design\" practices \\cite{vakkuri20190xd}.\n    *   **Theoretical Insights or Analysis:** The paper proposes a conceptual framework (Figure 2) illustrating the interplay between developer commitment, transparency, accountability, and responsibility (ART principles) in achieving ethically aligned design. This framework provides a theoretical basis for understanding how practical ethical tools can influence developer behavior and, consequently, the ethical outcomes of AI/AS systems \\cite{vakkuri20190xd}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The RESOLVEDD-strategy was empirically evaluated through a multiple case study involving five student projects focused on developing AI/AS prototypes \\cite{vakkuri20190xd}. In these projects, the use of an ethical tool (specifically RESOLVEDD) was explicitly mandated as a design requirement for the development teams.\n    *   **Key Performance Metrics and Comparison Results:** Although detailed results are not fully provided in the excerpt, the abstract highlights a key finding: \"simply the presence of an ethical tool has an effect on ethical consideration, creating more responsibility even in instances where the use of the tool is not intrinsically motivated\" \\cite{vakkuri20190xd}. This indicates that the mere requirement to engage with a structured ethical tool can positively influence developers' ethical awareness and sense of responsibility during the design process. The study aimed to understand the *impact* of the tool on ethical consideration and its *practical functioning* within the given context.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The study's reliance on student projects for empirical validation may limit the generalizability of findings to professional development environments, which often involve different pressures, motivations, and project complexities \\cite{vakkuri20190xd}. The RESOLVEDD-strategy, while flexible, is a structured process, and its effectiveness might vary depending on developers' receptiveness to such structured approaches.\n    *   **Scope of Applicability:** The evaluation is specifically within the context of AI/AS design. While RESOLVEDD is adaptable, its direct applicability and effectiveness in other software domains or organizational cultures would require further validation \\cite{vakkuri20190xd}. The study focuses on the *introduction* and *effect* of one specific ethical tool rather than a comprehensive comparison across all ethical design methodologies.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This paper significantly advances the technical state-of-the-art by providing empirical evidence for the practical utility of a structured ethical decision-making tool in AI/AS development \\cite{vakkuri20190xd}. It moves beyond theoretical discussions of ethical principles to evaluate a concrete method for their implementation, addressing a critical gap in \"Ethically Aligned Design.\" The finding that the *presence* of such a tool can foster responsibility, even without intrinsic motivation, is a crucial insight for promoting ethical practices in software engineering.\n    *   **Potential Impact on Future Research:** The work establishes a foundation for future research into practical ethical tools and their integration into software engineering processes. It underscores the importance of developer commitment and the ART principles as key factors in achieving ethical AI/AS. Future research can build upon this by exploring the long-term impact of RESOLVEDD, comparing its effectiveness with other ethical design methods, investigating its scalability, and examining its application in diverse professional settings to further refine \"Ethically Aligned Design\" methodologies \\cite{vakkuri20190xd}.",
      "keywords": [
        "Ethically Aligned Design",
        "Artificial Intelligence and Autonomous Systems (AI/AS)",
        "Ethical considerations",
        "RESOLVEDD-strategy",
        "Empirical evaluation",
        "Software and systems development",
        "Practical ethical tools",
        "Accountability",
        "Responsibility",
        "Transparency (ART principles)",
        "Ethical decision-making process",
        "Integrating ethics into design",
        "Developer commitment",
        "Conceptual research framework",
        "Impact of ethical tools"
      ],
      "paper_type": "the paper should be classified as **empirical**.\n\nhere's why:\n\n1.  **explicit mention:** the title itself is \"an **empirical evaluation**...\" and the abstract states \"we **empirically evaluate** a method.\"\n2.  **methodology:** the abstract describes the methodology: \"we **tested** the resolvedd strategy in a multiple case study of five student projects.\" testing a strategy and collecting data from projects is characteristic of empirical research.\n3.  **findings:** the abstract highlights \"a key **finding from the study indicates** that simply the presence of an ethical tool has an effect...\" this focus on findings derived from observation/experimentation is central to empirical papers.\n4.  **keywords:** the classification criteria for \"empirical\" include \"study,\" \"experiment,\" \"data,\" and \"findings,\" all of which are strongly present in the abstract. while \"case_study\" is also mentioned, it describes the *methodology* used within the broader empirical evaluation, rather than the overarching paper type. the primary goal is the empirical evaluation and its findings."
    },
    "file_name": "41e2d221f01ecbf0fa76124c9fb2fdcc5f890112.pdf"
  },
  {
    "success": true,
    "doc_id": "17c17ec3d0cdf560a78aabff642fb6d8",
    "summary": "Software Engineering is the fundamental methodology used in the process of developing the software. Software Development Life Cycle (SDLC) is the backbone of software engineering. SDLC is emerging in several forms to support software development at different phases. SDLC plays as a\n role of guide for engineers that are involved from traditional desktop application development to much trending development. The new emerging technologies accelerate the process of software engineering, resulting in saving time and resources and enhance the quality of software systems. This\n paper focuses on technologies used to accelerate the process of software engineering in solving problems associated with its phases. The first section of this paper contains an introduction to Software Engineering (SE) and Artificial Intelligence (AI). The next section describes the aspects\n of emerging technologies in software engineering. After this, the role of AI in SE is discussed followed by a conclusion in the last section.",
    "intriguing_abstract": "Software Engineering is the fundamental methodology used in the process of developing the software. Software Development Life Cycle (SDLC) is the backbone of software engineering. SDLC is emerging in several forms to support software development at different phases. SDLC plays as a\n role of guide for engineers that are involved from traditional desktop application development to much trending development. The new emerging technologies accelerate the process of software engineering, resulting in saving time and resources and enhance the quality of software systems. This\n paper focuses on technologies used to accelerate the process of software engineering in solving problems associated with its phases. The first section of this paper contains an introduction to Software Engineering (SE) and Artificial Intelligence (AI). The next section describes the aspects\n of emerging technologies in software engineering. After this, the role of AI in SE is discussed followed by a conclusion in the last section.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/e1107b3fe589b7853c2e6a5a1711c8c4843f96dc.pdf",
    "citation_key": "mudita2020uuo",
    "metadata": {
      "title": "The Aspects of Artificial Intelligence in Software Engineering",
      "authors": [
        "Mudita",
        "D. Gupta"
      ],
      "published_date": "2020",
      "abstract": "Software Engineering is the fundamental methodology used in the process of developing the software. Software Development Life Cycle (SDLC) is the backbone of software engineering. SDLC is emerging in several forms to support software development at different phases. SDLC plays as a\n role of guide for engineers that are involved from traditional desktop application development to much trending development. The new emerging technologies accelerate the process of software engineering, resulting in saving time and resources and enhance the quality of software systems. This\n paper focuses on technologies used to accelerate the process of software engineering in solving problems associated with its phases. The first section of this paper contains an introduction to Software Engineering (SE) and Artificial Intelligence (AI). The next section describes the aspects\n of emerging technologies in software engineering. After this, the role of AI in SE is discussed followed by a conclusion in the last section.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/e1107b3fe589b7853c2e6a5a1711c8c4843f96dc.pdf",
      "venue": "",
      "citationCount": 11,
      "score": 2.2,
      "summary": "Software Engineering is the fundamental methodology used in the process of developing the software. Software Development Life Cycle (SDLC) is the backbone of software engineering. SDLC is emerging in several forms to support software development at different phases. SDLC plays as a\n role of guide for engineers that are involved from traditional desktop application development to much trending development. The new emerging technologies accelerate the process of software engineering, resulting in saving time and resources and enhance the quality of software systems. This\n paper focuses on technologies used to accelerate the process of software engineering in solving problems associated with its phases. The first section of this paper contains an introduction to Software Engineering (SE) and Artificial Intelligence (AI). The next section describes the aspects\n of emerging technologies in software engineering. After this, the role of AI in SE is discussed followed by a conclusion in the last section.",
      "keywords": []
    },
    "file_name": "e1107b3fe589b7853c2e6a5a1711c8c4843f96dc.pdf"
  },
  {
    "success": true,
    "doc_id": "5403ae6635a5bfb41e85571d2a378128",
    "summary": "As the software industry transitions to software-as-a-service (SAAS) model, there has been tremendous competitive pressure on companies to improve software quality at a much faster rate than before. The software defect prediction (SDP) plays an important role in this effort by enabling predictive quality management during the entire software development lifecycle (SDLC). The SDP has traditionally used defect density and other parametric models. However, recent advances in machine learning and artificial intelligence (ML/AI) have created a renewed interest in ML-based defect prediction among academic researchers and industry practitioners. Published studies on this subject have focused on two areas, i.e. model attributes and ML algorithms, to develop SDP models for small to medium sized software (mostly opensource). However, as we present in this paper, ML-based SDP for large scale software with hundreds of millions of lines of code (LOC) needs to address challenges in additional areas called \"Data Definition\" and \"SDP Lifecycle.\" We have proposed solutions for these challenges and used the example of a large-scale software (IOS-XE) developed by Cisco Systems to show the validity of our solutions.",
    "intriguing_abstract": "As the software industry transitions to software-as-a-service (SAAS) model, there has been tremendous competitive pressure on companies to improve software quality at a much faster rate than before. The software defect prediction (SDP) plays an important role in this effort by enabling predictive quality management during the entire software development lifecycle (SDLC). The SDP has traditionally used defect density and other parametric models. However, recent advances in machine learning and artificial intelligence (ML/AI) have created a renewed interest in ML-based defect prediction among academic researchers and industry practitioners. Published studies on this subject have focused on two areas, i.e. model attributes and ML algorithms, to develop SDP models for small to medium sized software (mostly opensource). However, as we present in this paper, ML-based SDP for large scale software with hundreds of millions of lines of code (LOC) needs to address challenges in additional areas called \"Data Definition\" and \"SDP Lifecycle.\" We have proposed solutions for these challenges and used the example of a large-scale software (IOS-XE) developed by Cisco Systems to show the validity of our solutions.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b0aa13e9b0d68d2a55f8b7323869865a310fe596.pdf",
    "citation_key": "pradhan2020jc1",
    "metadata": {
      "title": "On the Defect Prediction for Large Scale Software Systems – From Defect Density to Machine Learning",
      "authors": [
        "Satyabrata Pradhan",
        "Venky Nanniyur",
        "Pavan K. Vissapragada"
      ],
      "published_date": "2020",
      "abstract": "As the software industry transitions to software-as-a-service (SAAS) model, there has been tremendous competitive pressure on companies to improve software quality at a much faster rate than before. The software defect prediction (SDP) plays an important role in this effort by enabling predictive quality management during the entire software development lifecycle (SDLC). The SDP has traditionally used defect density and other parametric models. However, recent advances in machine learning and artificial intelligence (ML/AI) have created a renewed interest in ML-based defect prediction among academic researchers and industry practitioners. Published studies on this subject have focused on two areas, i.e. model attributes and ML algorithms, to develop SDP models for small to medium sized software (mostly opensource). However, as we present in this paper, ML-based SDP for large scale software with hundreds of millions of lines of code (LOC) needs to address challenges in additional areas called \"Data Definition\" and \"SDP Lifecycle.\" We have proposed solutions for these challenges and used the example of a large-scale software (IOS-XE) developed by Cisco Systems to show the validity of our solutions.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b0aa13e9b0d68d2a55f8b7323869865a310fe596.pdf",
      "venue": "International Conference on Software Quality, Reliability and Security",
      "citationCount": 11,
      "score": 2.2,
      "summary": "As the software industry transitions to software-as-a-service (SAAS) model, there has been tremendous competitive pressure on companies to improve software quality at a much faster rate than before. The software defect prediction (SDP) plays an important role in this effort by enabling predictive quality management during the entire software development lifecycle (SDLC). The SDP has traditionally used defect density and other parametric models. However, recent advances in machine learning and artificial intelligence (ML/AI) have created a renewed interest in ML-based defect prediction among academic researchers and industry practitioners. Published studies on this subject have focused on two areas, i.e. model attributes and ML algorithms, to develop SDP models for small to medium sized software (mostly opensource). However, as we present in this paper, ML-based SDP for large scale software with hundreds of millions of lines of code (LOC) needs to address challenges in additional areas called \"Data Definition\" and \"SDP Lifecycle.\" We have proposed solutions for these challenges and used the example of a large-scale software (IOS-XE) developed by Cisco Systems to show the validity of our solutions.",
      "keywords": []
    },
    "file_name": "b0aa13e9b0d68d2a55f8b7323869865a310fe596.pdf"
  },
  {
    "success": true,
    "doc_id": "b257e2ad2cccf4797a217533865acddc",
    "summary": "Internet of Things (IoT) and Artificial Intelligence (AI) are one of the most promising and disruptive areas of current research and development. However, these areas require deep knowledge in multiple disciplines such as sensors, protocols, embedded programming, distributed systems, statistics and algorithms. This broad knowledge is not easy to acquire and the software used to design these systems is becoming increasingly complex. Small and medium-sized enterprises therefore have problems in developing new business ideas. However, node- and block-based software tools have also been released and are freely available as open source toolboxes. In this paper, we present an overview of multiple node- and block-based software tools to develop IoT- and AI-based business ideas. We arrange these tools according their capabilities and further propose extension and combinations of tools to design a useful open-source library for small and medium-sized enterprises, that is easy to use and helps with rapid prototyping, enabling new business ideas to be developed using distributed computing.",
    "intriguing_abstract": "Internet of Things (IoT) and Artificial Intelligence (AI) are one of the most promising and disruptive areas of current research and development. However, these areas require deep knowledge in multiple disciplines such as sensors, protocols, embedded programming, distributed systems, statistics and algorithms. This broad knowledge is not easy to acquire and the software used to design these systems is becoming increasingly complex. Small and medium-sized enterprises therefore have problems in developing new business ideas. However, node- and block-based software tools have also been released and are freely available as open source toolboxes. In this paper, we present an overview of multiple node- and block-based software tools to develop IoT- and AI-based business ideas. We arrange these tools according their capabilities and further propose extension and combinations of tools to design a useful open-source library for small and medium-sized enterprises, that is easy to use and helps with rapid prototyping, enabling new business ideas to be developed using distributed computing.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2708c87891071e69c1a098b961c4c6fc2c26f7a5.pdf",
    "citation_key": "hauck2019lub",
    "metadata": {
      "title": "Node and Block-Based Development Tools for Distributed Systems With AI Applications",
      "authors": [
        "Marcel Hauck",
        "Rüdiger Machhamer",
        "Levin Czenkusch",
        "K. Gollmer",
        "Guido Dartmann"
      ],
      "published_date": "2019",
      "abstract": "Internet of Things (IoT) and Artificial Intelligence (AI) are one of the most promising and disruptive areas of current research and development. However, these areas require deep knowledge in multiple disciplines such as sensors, protocols, embedded programming, distributed systems, statistics and algorithms. This broad knowledge is not easy to acquire and the software used to design these systems is becoming increasingly complex. Small and medium-sized enterprises therefore have problems in developing new business ideas. However, node- and block-based software tools have also been released and are freely available as open source toolboxes. In this paper, we present an overview of multiple node- and block-based software tools to develop IoT- and AI-based business ideas. We arrange these tools according their capabilities and further propose extension and combinations of tools to design a useful open-source library for small and medium-sized enterprises, that is easy to use and helps with rapid prototyping, enabling new business ideas to be developed using distributed computing.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2708c87891071e69c1a098b961c4c6fc2c26f7a5.pdf",
      "venue": "IEEE Access",
      "citationCount": 13,
      "score": 2.1666666666666665,
      "summary": "Internet of Things (IoT) and Artificial Intelligence (AI) are one of the most promising and disruptive areas of current research and development. However, these areas require deep knowledge in multiple disciplines such as sensors, protocols, embedded programming, distributed systems, statistics and algorithms. This broad knowledge is not easy to acquire and the software used to design these systems is becoming increasingly complex. Small and medium-sized enterprises therefore have problems in developing new business ideas. However, node- and block-based software tools have also been released and are freely available as open source toolboxes. In this paper, we present an overview of multiple node- and block-based software tools to develop IoT- and AI-based business ideas. We arrange these tools according their capabilities and further propose extension and combinations of tools to design a useful open-source library for small and medium-sized enterprises, that is easy to use and helps with rapid prototyping, enabling new business ideas to be developed using distributed computing.",
      "keywords": []
    },
    "file_name": "2708c87891071e69c1a098b961c4c6fc2c26f7a5.pdf"
  },
  {
    "success": true,
    "doc_id": "6026f3352d2d70cc8f2c790794a32037",
    "summary": "Intelligent Vision Systems (IVS) are omnipresent in our daily life from social media apps to m-health services, from street surveillance cameras to airport e-gates, from drones to companion robots. Hence, IVS encompass any software which has a visual input processed by means of algorithm(s) involving Artificial Intelligence (AI) methods. The design and development of these IVS softwares has become an increasingly complex task, since vision-based systems have evolved into (semi-)autonomous AI systems, usually requiring effective and ethical data processing along with efficient signal processing and real-time hardware/software integration as well as User Experience (UX) and (cyber)security features. Consequently, IVS system development necessitates an adapted software development life-cycle (SDLC) addressing these multi-domain needs, whilst being developer friendly. Hence, we propose in this paper a new SDLC we called D7-R4 which allows developers to produce quality, new-generation IVS to be deployed in real-time and in real-world, unstructured environments.",
    "intriguing_abstract": "Intelligent Vision Systems (IVS) are omnipresent in our daily life from social media apps to m-health services, from street surveillance cameras to airport e-gates, from drones to companion robots. Hence, IVS encompass any software which has a visual input processed by means of algorithm(s) involving Artificial Intelligence (AI) methods. The design and development of these IVS softwares has become an increasingly complex task, since vision-based systems have evolved into (semi-)autonomous AI systems, usually requiring effective and ethical data processing along with efficient signal processing and real-time hardware/software integration as well as User Experience (UX) and (cyber)security features. Consequently, IVS system development necessitates an adapted software development life-cycle (SDLC) addressing these multi-domain needs, whilst being developer friendly. Hence, we propose in this paper a new SDLC we called D7-R4 which allows developers to produce quality, new-generation IVS to be deployed in real-time and in real-world, unstructured environments.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/896bf0e70d8896e21cf57674f77dcf8b3abf27ec.pdf",
    "citation_key": "olszewska2019bh5",
    "metadata": {
      "title": "D7-R4: Software Development Life-Cycle for Intelligent Vision Systems",
      "authors": [
        "J. Olszewska"
      ],
      "published_date": "2019",
      "abstract": "Intelligent Vision Systems (IVS) are omnipresent in our daily life from social media apps to m-health services, from street surveillance cameras to airport e-gates, from drones to companion robots. Hence, IVS encompass any software which has a visual input processed by means of algorithm(s) involving Artificial Intelligence (AI) methods. The design and development of these IVS softwares has become an increasingly complex task, since vision-based systems have evolved into (semi-)autonomous AI systems, usually requiring effective and ethical data processing along with efficient signal processing and real-time hardware/software integration as well as User Experience (UX) and (cyber)security features. Consequently, IVS system development necessitates an adapted software development life-cycle (SDLC) addressing these multi-domain needs, whilst being developer friendly. Hence, we propose in this paper a new SDLC we called D7-R4 which allows developers to produce quality, new-generation IVS to be deployed in real-time and in real-world, unstructured environments.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/896bf0e70d8896e21cf57674f77dcf8b3abf27ec.pdf",
      "venue": "International Conference on Knowledge Engineering and Ontology Development",
      "citationCount": 12,
      "score": 2.0,
      "summary": "Intelligent Vision Systems (IVS) are omnipresent in our daily life from social media apps to m-health services, from street surveillance cameras to airport e-gates, from drones to companion robots. Hence, IVS encompass any software which has a visual input processed by means of algorithm(s) involving Artificial Intelligence (AI) methods. The design and development of these IVS softwares has become an increasingly complex task, since vision-based systems have evolved into (semi-)autonomous AI systems, usually requiring effective and ethical data processing along with efficient signal processing and real-time hardware/software integration as well as User Experience (UX) and (cyber)security features. Consequently, IVS system development necessitates an adapted software development life-cycle (SDLC) addressing these multi-domain needs, whilst being developer friendly. Hence, we propose in this paper a new SDLC we called D7-R4 which allows developers to produce quality, new-generation IVS to be deployed in real-time and in real-world, unstructured environments.",
      "keywords": []
    },
    "file_name": "896bf0e70d8896e21cf57674f77dcf8b3abf27ec.pdf"
  },
  {
    "success": true,
    "doc_id": "fe46a2cb85b243c8b446e45eb7b331fb",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ea086904188987e3813b23b9496ed0806759d835.pdf",
    "citation_key": "paper2019yd1",
    "metadata": {
      "title": "Artificial Intelligence in Software Engineering: Current Developments and Future Prospects",
      "authors": [],
      "published_date": "2019",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ea086904188987e3813b23b9496ed0806759d835.pdf",
      "venue": "",
      "citationCount": 12,
      "score": 2.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "ea086904188987e3813b23b9496ed0806759d835.pdf"
  },
  {
    "success": true,
    "doc_id": "909910144081a6b536af453fd3b6d221",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/602ce7181d29f90e490864f97f584a3884dc4929.pdf",
    "citation_key": "zahid2018zjz",
    "metadata": {
      "title": "Crowdsourcing Software Development: Task Assignment Using PDDL Artificial Intelligence Planning",
      "authors": [
        "Tunio Muhammad Zahid",
        "Haiyong Luo",
        "Cong Wang",
        "Fang Zhao"
      ],
      "published_date": "2018",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/602ce7181d29f90e490864f97f584a3884dc4929.pdf",
      "venue": "Journal of Information Processing Systems",
      "citationCount": 13,
      "score": 1.857142857142857,
      "summary": "",
      "keywords": []
    },
    "file_name": "602ce7181d29f90e490864f97f584a3884dc4929.pdf"
  },
  {
    "success": true,
    "doc_id": "621ac6752dc04b61ed89c364f23e0c78",
    "summary": "This paper investigates a paradigm for offering artificial intelligence as a service (AI-aaS) on software-defined infrastructures (SDIs). The increasing complexity of networking and computing infrastructures is already driving the introduction of automation in networking and cloud computing management systems. Here we consider how these automation mechanisms can be leveraged to offer AI-aaS. Use cases for AI-aaS are easily found in addressing smart applications in sectors such as transportation, manufacturing, energy, water, air quality, and emissions. We propose an architectural scheme based on SDIs where each AI-aaS application is comprised of a monitoring, analysis, policy, execution plus knowledge (MAPE-K) loop (MKL). Each application is composed as one or more specific service chains embedded in SDI, some of which will include a Machine Learning (ML) pipeline. Our model includes a new training plane and an AI-aaS plane to deal with the model-development and operational phases of AI applications. We also consider the role of an ML/MKL sandbox in ensuring coherency and consistency in the operation of multiple parallel MKL loops.",
    "intriguing_abstract": "This paper investigates a paradigm for offering artificial intelligence as a service (AI-aaS) on software-defined infrastructures (SDIs). The increasing complexity of networking and computing infrastructures is already driving the introduction of automation in networking and cloud computing management systems. Here we consider how these automation mechanisms can be leveraged to offer AI-aaS. Use cases for AI-aaS are easily found in addressing smart applications in sectors such as transportation, manufacturing, energy, water, air quality, and emissions. We propose an architectural scheme based on SDIs where each AI-aaS application is comprised of a monitoring, analysis, policy, execution plus knowledge (MAPE-K) loop (MKL). Each application is composed as one or more specific service chains embedded in SDI, some of which will include a Machine Learning (ML) pipeline. Our model includes a new training plane and an AI-aaS plane to deal with the model-development and operational phases of AI applications. We also consider the role of an ML/MKL sandbox in ensuring coherency and consistency in the operation of multiple parallel MKL loops.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f46f50938206b3537b348afda5873a74970872cb.pdf",
    "citation_key": "parsaeefard20199v6",
    "metadata": {
      "title": "Artificial Intelligence as a Service (AI-aaS) on Software-Defined Infrastructure",
      "authors": [
        "S. Parsaeefard",
        "Iman Tabrizian",
        "Alberto Leon-Garcia"
      ],
      "published_date": "2019",
      "abstract": "This paper investigates a paradigm for offering artificial intelligence as a service (AI-aaS) on software-defined infrastructures (SDIs). The increasing complexity of networking and computing infrastructures is already driving the introduction of automation in networking and cloud computing management systems. Here we consider how these automation mechanisms can be leveraged to offer AI-aaS. Use cases for AI-aaS are easily found in addressing smart applications in sectors such as transportation, manufacturing, energy, water, air quality, and emissions. We propose an architectural scheme based on SDIs where each AI-aaS application is comprised of a monitoring, analysis, policy, execution plus knowledge (MAPE-K) loop (MKL). Each application is composed as one or more specific service chains embedded in SDI, some of which will include a Machine Learning (ML) pipeline. Our model includes a new training plane and an AI-aaS plane to deal with the model-development and operational phases of AI applications. We also consider the role of an ML/MKL sandbox in ensuring coherency and consistency in the operation of multiple parallel MKL loops.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f46f50938206b3537b348afda5873a74970872cb.pdf",
      "venue": "IEEE Conference on Standards for Communications and Networking",
      "citationCount": 10,
      "score": 1.6666666666666665,
      "summary": "This paper investigates a paradigm for offering artificial intelligence as a service (AI-aaS) on software-defined infrastructures (SDIs). The increasing complexity of networking and computing infrastructures is already driving the introduction of automation in networking and cloud computing management systems. Here we consider how these automation mechanisms can be leveraged to offer AI-aaS. Use cases for AI-aaS are easily found in addressing smart applications in sectors such as transportation, manufacturing, energy, water, air quality, and emissions. We propose an architectural scheme based on SDIs where each AI-aaS application is comprised of a monitoring, analysis, policy, execution plus knowledge (MAPE-K) loop (MKL). Each application is composed as one or more specific service chains embedded in SDI, some of which will include a Machine Learning (ML) pipeline. Our model includes a new training plane and an AI-aaS plane to deal with the model-development and operational phases of AI applications. We also consider the role of an ML/MKL sandbox in ensuring coherency and consistency in the operation of multiple parallel MKL loops.",
      "keywords": []
    },
    "file_name": "f46f50938206b3537b348afda5873a74970872cb.pdf"
  },
  {
    "success": true,
    "doc_id": "8ca49f583513f6b46467c9241668334c",
    "summary": "This research paper aims an analytical study on the software development organization insight into trending automation technologies and their implementation Software Engineering Management (SEM) processes. Software Project Management (SPM) is a scientific art for planning, controlling execution and monitoring. SPM approaches are more focusing towards the essential requirement for the success of software project development. It has been very challenging to manage software development using existing project management procedures driven by software development organizations and this is one of the areas of problem statement for this research. This paper discusses an analytical study for the requirements and consideration of BPR in SPM, explores to spot and emphasizes the important success factors for the execution of a BPR using benefits of Artificial Intelligence (AI) in software development organization. BPR is organizational mechanism that improves ability to respond to challenges of qualitative result by change and improvement in software engineering processes, productivity, product quality and competitive advantages. AI will be the best approach and scope of automation SEM processes for software development organizations. This paper also represents a conceptual view of software engineering model shift for improvements in capability of project managers to handle agile thinking and problem solving for betterment of SPM using Artificial Intelligence.",
    "intriguing_abstract": "This research paper aims an analytical study on the software development organization insight into trending automation technologies and their implementation Software Engineering Management (SEM) processes. Software Project Management (SPM) is a scientific art for planning, controlling execution and monitoring. SPM approaches are more focusing towards the essential requirement for the success of software project development. It has been very challenging to manage software development using existing project management procedures driven by software development organizations and this is one of the areas of problem statement for this research. This paper discusses an analytical study for the requirements and consideration of BPR in SPM, explores to spot and emphasizes the important success factors for the execution of a BPR using benefits of Artificial Intelligence (AI) in software development organization. BPR is organizational mechanism that improves ability to respond to challenges of qualitative result by change and improvement in software engineering processes, productivity, product quality and competitive advantages. AI will be the best approach and scope of automation SEM processes for software development organizations. This paper also represents a conceptual view of software engineering model shift for improvements in capability of project managers to handle agile thinking and problem solving for betterment of SPM using Artificial Intelligence.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8453a57446e28871aefd519e02f2a9a8235265f4.pdf",
    "citation_key": "paper20196x5",
    "metadata": {
      "title": "Business Process Reengineering: A Scope of Automation in Software Project Management using Artificial Intelligence",
      "authors": [],
      "published_date": "2019",
      "abstract": "This research paper aims an analytical study on the software development organization insight into trending automation technologies and their implementation Software Engineering Management (SEM) processes. Software Project Management (SPM) is a scientific art for planning, controlling execution and monitoring. SPM approaches are more focusing towards the essential requirement for the success of software project development. It has been very challenging to manage software development using existing project management procedures driven by software development organizations and this is one of the areas of problem statement for this research. This paper discusses an analytical study for the requirements and consideration of BPR in SPM, explores to spot and emphasizes the important success factors for the execution of a BPR using benefits of Artificial Intelligence (AI) in software development organization. BPR is organizational mechanism that improves ability to respond to challenges of qualitative result by change and improvement in software engineering processes, productivity, product quality and competitive advantages. AI will be the best approach and scope of automation SEM processes for software development organizations. This paper also represents a conceptual view of software engineering model shift for improvements in capability of project managers to handle agile thinking and problem solving for betterment of SPM using Artificial Intelligence.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8453a57446e28871aefd519e02f2a9a8235265f4.pdf",
      "venue": "International Journal of Engineering and Advanced Technology",
      "citationCount": 10,
      "score": 1.6666666666666665,
      "summary": "This research paper aims an analytical study on the software development organization insight into trending automation technologies and their implementation Software Engineering Management (SEM) processes. Software Project Management (SPM) is a scientific art for planning, controlling execution and monitoring. SPM approaches are more focusing towards the essential requirement for the success of software project development. It has been very challenging to manage software development using existing project management procedures driven by software development organizations and this is one of the areas of problem statement for this research. This paper discusses an analytical study for the requirements and consideration of BPR in SPM, explores to spot and emphasizes the important success factors for the execution of a BPR using benefits of Artificial Intelligence (AI) in software development organization. BPR is organizational mechanism that improves ability to respond to challenges of qualitative result by change and improvement in software engineering processes, productivity, product quality and competitive advantages. AI will be the best approach and scope of automation SEM processes for software development organizations. This paper also represents a conceptual view of software engineering model shift for improvements in capability of project managers to handle agile thinking and problem solving for betterment of SPM using Artificial Intelligence.",
      "keywords": []
    },
    "file_name": "8453a57446e28871aefd519e02f2a9a8235265f4.pdf"
  },
  {
    "success": true,
    "doc_id": "c8ac65c4181f30b6bb596b0c18450cf9",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/66497c851d4f2df81b68eac6681d5deb0ac32458.pdf",
    "citation_key": "sorte20153ip",
    "metadata": {
      "title": "Use of Artificial Intelligence in Software Development Life Cycle: A state of the Art Review",
      "authors": [
        "Bhagyashree W. Sorte",
        "P. P. Joshi",
        "V. Jagtap"
      ],
      "published_date": "2015",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/66497c851d4f2df81b68eac6681d5deb0ac32458.pdf",
      "venue": "",
      "citationCount": 16,
      "score": 1.6,
      "summary": "",
      "keywords": []
    },
    "file_name": "66497c851d4f2df81b68eac6681d5deb0ac32458.pdf"
  },
  {
    "success": true,
    "doc_id": "30acdf277073e640b31d17d3456233bb",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/506aeaaa7eb01b95957ea2618e00232263f2b1fc.pdf",
    "citation_key": "kocaguneli2010ejx",
    "metadata": {
      "title": "AI-Based Models for Software Effort Estimation",
      "authors": [
        "Ekrem Kocaguneli",
        "Ayse Tosun Misirli",
        "A. Bener"
      ],
      "published_date": "2010",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/506aeaaa7eb01b95957ea2618e00232263f2b1fc.pdf",
      "venue": "EUROMICRO Conference on Software Engineering and Advanced Applications",
      "citationCount": 22,
      "score": 1.4666666666666666,
      "summary": "",
      "keywords": []
    },
    "file_name": "506aeaaa7eb01b95957ea2618e00232263f2b1fc.pdf"
  },
  {
    "success": true,
    "doc_id": "1b5286089a527889d323e05cab400a1b",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2f219d083bb79ae02498246e042bb99234cc5dd3.pdf",
    "citation_key": "ricci2011dr6",
    "metadata": {
      "title": "Agent-Oriented Computing : Agents as a Paradigm for Computer Programming and Software Development",
      "authors": [
        "A. Ricci"
      ],
      "published_date": "2011",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2f219d083bb79ae02498246e042bb99234cc5dd3.pdf",
      "venue": "",
      "citationCount": 20,
      "score": 1.4285714285714284,
      "summary": "",
      "keywords": []
    },
    "file_name": "2f219d083bb79ae02498246e042bb99234cc5dd3.pdf"
  },
  {
    "success": true,
    "doc_id": "dafa8bb9ddca06cd0486baea8bbce33b",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8a05b758eb3590f535eafb00e1506221cd448010.pdf",
    "citation_key": "gharehchopogh20148p6",
    "metadata": {
      "title": "Artificial bee colony based constructive cost model for software cost estimation",
      "authors": [
        "F. S. Gharehchopogh",
        "Isa Maleki",
        "Amin Kamalinia",
        "Habibeh Mohammad Zadeh"
      ],
      "published_date": "2014",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8a05b758eb3590f535eafb00e1506221cd448010.pdf",
      "venue": "",
      "citationCount": 13,
      "score": 1.1818181818181819,
      "summary": "",
      "keywords": []
    },
    "file_name": "8a05b758eb3590f535eafb00e1506221cd448010.pdf"
  },
  {
    "success": true,
    "doc_id": "54f7877c25a82c74c2b21e73d5dded24",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/549f495d7695056052f6c60fe6e02fbd40dd5bfe.pdf",
    "citation_key": "shankari20146qb",
    "metadata": {
      "title": "A Survey on Using Artificial Intelligence Techniques in the Software Development Process",
      "authors": [
        "K. Shankari",
        "Dr.R. Thirumalaiselvi"
      ],
      "published_date": "2014",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/549f495d7695056052f6c60fe6e02fbd40dd5bfe.pdf",
      "venue": "",
      "citationCount": 10,
      "score": 0.9090909090909092,
      "summary": "",
      "keywords": []
    },
    "file_name": "549f495d7695056052f6c60fe6e02fbd40dd5bfe.pdf"
  },
  {
    "success": true,
    "doc_id": "9fe7b2a68b3ec0a3b21dc034eefcee5a",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/78f5d77499893c6bac0275e1219643f3074a5e23.pdf",
    "citation_key": "jayavel201365z",
    "metadata": {
      "title": "USE OF ARTIFICIAL INTELLIGENCE IN AUTOMATION OF SEQUENTIAL STEPS OF SOFTWARE DEVELOPMENT / PRODUCTION",
      "authors": [
        "S. Jayavel",
        "S. Arumugam",
        "B. Singh",
        "P. Pandey",
        "Akash Giri",
        "Akshay Sharma"
      ],
      "published_date": "2013",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/78f5d77499893c6bac0275e1219643f3074a5e23.pdf",
      "venue": "",
      "citationCount": 10,
      "score": 0.8333333333333333,
      "summary": "",
      "keywords": []
    },
    "file_name": "78f5d77499893c6bac0275e1219643f3074a5e23.pdf"
  },
  {
    "success": true,
    "doc_id": "08a847b15fed84915048771bc0cc85d2",
    "summary": "Here's a focused summary of the paper \"OPENHANDS : AN OPEN PLATFORM FOR AI SOFTWARE DEVELOPERS AS GENERALIST AGENTS\" by Wang et al. \\cite{wang20241va} for a literature review:\n\n### 1. Research Problem & Motivation\n*   **Specific Technical Problem**: The paper addresses the increasing complexity in developing and evaluating AI agents, particularly those designed to interact with the world through software development, command-line interfaces, and web browsing.\n*   **Importance and Challenge**: As AI agents become capable of tackling complex problems (e.g., software development, web navigation, scientific research), their creation, testing, and deployment become challenging. Existing frameworks streamline parts of this process but often lack a comprehensive, flexible, and safe environment for generalist agents that mimic human developer interactions. Key challenges include enabling agents to effectively create/modify complex software, gather information on-the-fly for debugging, and ensuring safe execution to prevent negative side effects on user systems.\n\n### 2. Related Work & Positioning\n*   **Relation to Existing Approaches**: The work builds upon the rapid development in LLM-powered AI agents and existing open-source frameworks for agent development (e.g., Hong et al., 2023; Chen et al., 2024; Wu et al., 2023). It is inspired by architectures like CodeAct (Wang et al., 2024a) and tools like BrowserGym (Drouin et al., 2024) and SWE-Agent (Yang et al., 2024).\n*   **Limitations of Previous Solutions (Implicit)**: While not explicitly detailing limitations of *other* frameworks, \\cite{wang20241va} positions OpenHands as a more comprehensive and flexible platform that integrates a broad action space (code, bash, web browsing), a secure sandboxed environment, multi-agent coordination, and an extensible evaluation framework, addressing the general challenges in agent development and evaluation that existing efforts may not fully cover in a unified manner. It aims to provide an \"ideal interface for AI agents to interact with the world in complex ways\" through software.\n\n### 3. Technical Approach & Innovation\n*   **Core Technical Method**: OpenHands is a community-driven platform for developing generalist and specialist AI agents. Its architecture comprises three main components:\n    *   **Agent Abstraction**: A simple yet powerful interface where agents perceive the environment state (event stream) and produce actions.\n    *   **Event Stream**: A chronological collection of past actions and observations, including user interactions, forming the agent's state.\n    *   **Agent Runtime**: A general environment for executing agent actions and generating observations.\n*   **Novelty/Differentiation**:\n    *   **Comprehensive Action Space**: Agents interact via a core set of general actions: `IPythonRunCellAction` (arbitrary Python code), `CmdRunAction` (bash commands), and `BrowserInteractiveAction` (web browsing using a domain-specific language). This PL-based action space is highly flexible and powerful.\n    *   **Secure Docker Sandbox**: Each task session runs in a securely isolated Docker container, preventing side effects on the host system. It supports arbitrary Docker images, allowing agents to operate in diverse software environments.\n    *   **OpenHands Action Execution API**: An API server within the sandbox manages bash, IPython, and a Playwright-based Chromium browser, providing rich observations (HTML, DOM, screenshots).\n    *   **AgentSkills Library**: An extensible Python package for specialized tools (e.g., `edit_file`, `parse_image`, `parse_pdf`) that are not easily achievable by LLMs directly or involve external models, automatically imported into the IPython environment.\n    *   **Multi-Agent Delegation**: A special `AgentDelegateAction` allows agents to delegate subtasks to other specialized agents, fostering cooperative problem-solving.\n\n### 4. Key Technical Contributions\n*   **Novel Algorithms/Methods**:\n    *   A unified event stream architecture for managing agent state and interactions.\n    *   A flexible, programming language-based action space (Python, Bash, Browser DSL) designed for generalist agents.\n    *   The AgentSkills library, providing an extensible and maintainable mechanism for agents to access specialized tools and external models.\n    *   A multi-agent delegation mechanism (`AgentDelegateAction`) for cooperative task execution.\n*   **System Design/Architectural Innovations**:\n    *   A robust and secure Docker-sandboxed runtime environment that supports arbitrary user-provided Docker images, ensuring isolation and configurability.\n    *   The OpenHands Action Execution API, which standardizes interaction with the sandboxed OS, IPython server, and web browser.\n    *   A community-driven \"Agent Hub\" for contributing and evaluating diverse agent implementations.\n*   **Theoretical Insights/Analysis**: The paper emphasizes the power and flexibility of a PL-based action space for generalist agents, arguing it's sufficient for most tasks and allows agents to create their own tools.\n\n### 5. Experimental Validation\n*   **Experiments Conducted**: OpenHands includes an evaluation framework that facilitates agent assessment across a wide range of tasks. The paper reports an evaluation of agents over 15 challenging tasks.\n*   **Key Performance Metrics and Comparison Results**:\n    *   The evaluation covers domains such as software engineering (e.g., SWE-BENCH) and web browsing (e.g., WEBARENA).\n    *   The platform currently includes an agent hub with over 10 implemented agents, including a strong generalist agent based on the CodeAct architecture with additions for web browsing and code editing specialists.\n    *   While specific performance metrics and detailed comparison results are not provided in the abstract or introduction, the paper states that evaluations were performed on these benchmarks, demonstrating the platform's utility for assessing agent capabilities.\n\n### 6. Limitations & Scope\n*   **Technical Limitations/Assumptions**: The platform's effectiveness relies on the capabilities of the underlying LLMs used by the agents. While it provides the environment and tools, the agent's \"intelligence\" (e.g., reasoning, planning) is external. The paper does not explicitly detail technical limitations of the OpenHands platform itself, but rather focuses on its broad applicability.\n*   **Scope of Applicability**: OpenHands is designed for the development of generalist and specialist AI agents that interact with the world through software. Its primary applications include complex software development workflows, data analysis projects, and web-based tasks (e.g., information seeking, navigation). It supports a wide array of research and real-world applications across academia and industry.\n\n### 7. Technical Significance\n*   **Advancement of State-of-the-Art**: OpenHands \\cite{wang20241va} significantly advances the state-of-the-art by providing a comprehensive, open-source, and community-driven platform that unifies a secure sandboxed runtime, a flexible programming language-based action space, an extensible tool library, and multi-agent coordination for developing and evaluating generalist AI agents. Its design addresses key challenges in agent development by mimicking human developer interactions with software.\n*   **Potential Impact on Future Research**: As an open platform (MIT license) with significant community traction (32K GitHub stars, 2.1K+ contributions), OpenHands is poised to be a catalyst for future research. It provides a standardized environment and a rich set of tools for researchers to:\n    *   Develop and benchmark novel agent architectures.\n    *   Explore multi-agent collaboration strategies.\n    *   Investigate advanced human-agent interaction paradigms.\n    *   Push the boundaries of AI agents in complex software engineering and web-based tasks.",
    "intriguing_abstract": "The quest for truly generalist AI agents capable of complex software development, command-line operations, and web browsing is hampered by the lack of comprehensive, secure, and flexible development platforms. We introduce **OpenHands**, an open-source, community-driven platform designed to empower the development of AI agents as generalist software developers. OpenHands features a novel architecture centered on a unified event stream and a powerful, programming language-based action space, enabling agents to execute arbitrary Python code, Bash commands, and interactive web browsing through a Playwright-based DSL. Crucially, all agent actions are performed within a secure, isolated Docker sandbox, supporting diverse software environments and preventing unintended host system modifications. Further innovations include an extensible `AgentSkills` library for specialized tools and a `Multi-Agent Delegation` mechanism for cooperative problem-solving. By providing a robust evaluation framework and fostering an \"Agent Hub,\" OpenHands significantly advances the state-of-the-art, offering an unparalleled environment for developing, benchmarking, and pushing the boundaries of autonomous AI agents in real-world software engineering and web-based tasks.",
    "keywords": [
      "OpenHands platform",
      "Generalist AI agents",
      "Programming language-based action space",
      "Secure Docker sandbox",
      "Multi-agent delegation",
      "Software development automation",
      "Web browsing automation",
      "Unified event stream architecture",
      "AgentSkills library",
      "Evaluation framework",
      "Community-driven platform",
      "LLM-powered agents",
      "Complex problem-solving"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/1d07e5b6f978cf69c0186f3d5f434fa92d471e46.pdf",
    "citation_key": "wang20241va",
    "metadata": {
      "title": "OpenHands: An Open Platform for AI Software Developers as Generalist Agents",
      "authors": [
        "Xingyao Wang",
        "Boxuan Li",
        "Yufan Song",
        "Frank F. Xu",
        "Xiangru Tang",
        "Mingchen Zhuge",
        "Jiayi Pan",
        "Yueqi Song",
        "Bowen Li",
        "Jaskirat Singh",
        "Hoang H. Tran",
        "Fuqiang Li",
        "Ren Ma",
        "Mingzhang Zheng",
        "Bill Qian",
        "Yanjun Shao",
        "Niklas Muennighoff",
        "Yizhe Zhang",
        "Binyuan Hui",
        "Junyang Lin",
        "Robert Brennan",
        "Hao Peng",
        "Heng Ji",
        "Graham Neubig"
      ],
      "published_date": "2024",
      "abstract": "Software is one of the most powerful tools that we humans have at our disposal; it allows a skilled programmer to interact with the world in complex and profound ways. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and affect change in their surrounding environments. In this paper, we introduce OpenHands (f.k.a. OpenDevin), a platform for the development of powerful and flexible AI agents that interact with the world in similar ways to those of a human developer: by writing code, interacting with a command line, and browsing the web. We describe how the platform allows for the implementation of new agents, safe interaction with sandboxed environments for code execution, coordination between multiple agents, and incorporation of evaluation benchmarks. Based on our currently incorporated benchmarks, we perform an evaluation of agents over 15 challenging tasks, including software engineering (e.g., SWE-BENCH) and web browsing (e.g., WEBARENA), among others. Released under the permissive MIT license, OpenHands is a community project spanning academia and industry with more than 2.1K contributions from over 188 contributors.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/1d07e5b6f978cf69c0186f3d5f434fa92d471e46.pdf",
      "venue": "International Conference on Learning Representations",
      "citationCount": 223,
      "score": 223.0,
      "summary": "Here's a focused summary of the paper \"OPENHANDS : AN OPEN PLATFORM FOR AI SOFTWARE DEVELOPERS AS GENERALIST AGENTS\" by Wang et al. \\cite{wang20241va} for a literature review:\n\n### 1. Research Problem & Motivation\n*   **Specific Technical Problem**: The paper addresses the increasing complexity in developing and evaluating AI agents, particularly those designed to interact with the world through software development, command-line interfaces, and web browsing.\n*   **Importance and Challenge**: As AI agents become capable of tackling complex problems (e.g., software development, web navigation, scientific research), their creation, testing, and deployment become challenging. Existing frameworks streamline parts of this process but often lack a comprehensive, flexible, and safe environment for generalist agents that mimic human developer interactions. Key challenges include enabling agents to effectively create/modify complex software, gather information on-the-fly for debugging, and ensuring safe execution to prevent negative side effects on user systems.\n\n### 2. Related Work & Positioning\n*   **Relation to Existing Approaches**: The work builds upon the rapid development in LLM-powered AI agents and existing open-source frameworks for agent development (e.g., Hong et al., 2023; Chen et al., 2024; Wu et al., 2023). It is inspired by architectures like CodeAct (Wang et al., 2024a) and tools like BrowserGym (Drouin et al., 2024) and SWE-Agent (Yang et al., 2024).\n*   **Limitations of Previous Solutions (Implicit)**: While not explicitly detailing limitations of *other* frameworks, \\cite{wang20241va} positions OpenHands as a more comprehensive and flexible platform that integrates a broad action space (code, bash, web browsing), a secure sandboxed environment, multi-agent coordination, and an extensible evaluation framework, addressing the general challenges in agent development and evaluation that existing efforts may not fully cover in a unified manner. It aims to provide an \"ideal interface for AI agents to interact with the world in complex ways\" through software.\n\n### 3. Technical Approach & Innovation\n*   **Core Technical Method**: OpenHands is a community-driven platform for developing generalist and specialist AI agents. Its architecture comprises three main components:\n    *   **Agent Abstraction**: A simple yet powerful interface where agents perceive the environment state (event stream) and produce actions.\n    *   **Event Stream**: A chronological collection of past actions and observations, including user interactions, forming the agent's state.\n    *   **Agent Runtime**: A general environment for executing agent actions and generating observations.\n*   **Novelty/Differentiation**:\n    *   **Comprehensive Action Space**: Agents interact via a core set of general actions: `IPythonRunCellAction` (arbitrary Python code), `CmdRunAction` (bash commands), and `BrowserInteractiveAction` (web browsing using a domain-specific language). This PL-based action space is highly flexible and powerful.\n    *   **Secure Docker Sandbox**: Each task session runs in a securely isolated Docker container, preventing side effects on the host system. It supports arbitrary Docker images, allowing agents to operate in diverse software environments.\n    *   **OpenHands Action Execution API**: An API server within the sandbox manages bash, IPython, and a Playwright-based Chromium browser, providing rich observations (HTML, DOM, screenshots).\n    *   **AgentSkills Library**: An extensible Python package for specialized tools (e.g., `edit_file`, `parse_image`, `parse_pdf`) that are not easily achievable by LLMs directly or involve external models, automatically imported into the IPython environment.\n    *   **Multi-Agent Delegation**: A special `AgentDelegateAction` allows agents to delegate subtasks to other specialized agents, fostering cooperative problem-solving.\n\n### 4. Key Technical Contributions\n*   **Novel Algorithms/Methods**:\n    *   A unified event stream architecture for managing agent state and interactions.\n    *   A flexible, programming language-based action space (Python, Bash, Browser DSL) designed for generalist agents.\n    *   The AgentSkills library, providing an extensible and maintainable mechanism for agents to access specialized tools and external models.\n    *   A multi-agent delegation mechanism (`AgentDelegateAction`) for cooperative task execution.\n*   **System Design/Architectural Innovations**:\n    *   A robust and secure Docker-sandboxed runtime environment that supports arbitrary user-provided Docker images, ensuring isolation and configurability.\n    *   The OpenHands Action Execution API, which standardizes interaction with the sandboxed OS, IPython server, and web browser.\n    *   A community-driven \"Agent Hub\" for contributing and evaluating diverse agent implementations.\n*   **Theoretical Insights/Analysis**: The paper emphasizes the power and flexibility of a PL-based action space for generalist agents, arguing it's sufficient for most tasks and allows agents to create their own tools.\n\n### 5. Experimental Validation\n*   **Experiments Conducted**: OpenHands includes an evaluation framework that facilitates agent assessment across a wide range of tasks. The paper reports an evaluation of agents over 15 challenging tasks.\n*   **Key Performance Metrics and Comparison Results**:\n    *   The evaluation covers domains such as software engineering (e.g., SWE-BENCH) and web browsing (e.g., WEBARENA).\n    *   The platform currently includes an agent hub with over 10 implemented agents, including a strong generalist agent based on the CodeAct architecture with additions for web browsing and code editing specialists.\n    *   While specific performance metrics and detailed comparison results are not provided in the abstract or introduction, the paper states that evaluations were performed on these benchmarks, demonstrating the platform's utility for assessing agent capabilities.\n\n### 6. Limitations & Scope\n*   **Technical Limitations/Assumptions**: The platform's effectiveness relies on the capabilities of the underlying LLMs used by the agents. While it provides the environment and tools, the agent's \"intelligence\" (e.g., reasoning, planning) is external. The paper does not explicitly detail technical limitations of the OpenHands platform itself, but rather focuses on its broad applicability.\n*   **Scope of Applicability**: OpenHands is designed for the development of generalist and specialist AI agents that interact with the world through software. Its primary applications include complex software development workflows, data analysis projects, and web-based tasks (e.g., information seeking, navigation). It supports a wide array of research and real-world applications across academia and industry.\n\n### 7. Technical Significance\n*   **Advancement of State-of-the-Art**: OpenHands \\cite{wang20241va} significantly advances the state-of-the-art by providing a comprehensive, open-source, and community-driven platform that unifies a secure sandboxed runtime, a flexible programming language-based action space, an extensible tool library, and multi-agent coordination for developing and evaluating generalist AI agents. Its design addresses key challenges in agent development by mimicking human developer interactions with software.\n*   **Potential Impact on Future Research**: As an open platform (MIT license) with significant community traction (32K GitHub stars, 2.1K+ contributions), OpenHands is poised to be a catalyst for future research. It provides a standardized environment and a rich set of tools for researchers to:\n    *   Develop and benchmark novel agent architectures.\n    *   Explore multi-agent collaboration strategies.\n    *   Investigate advanced human-agent interaction paradigms.\n    *   Push the boundaries of AI agents in complex software engineering and web-based tasks.",
      "keywords": [
        "OpenHands platform",
        "Generalist AI agents",
        "Programming language-based action space",
        "Secure Docker sandbox",
        "Multi-agent delegation",
        "Software development automation",
        "Web browsing automation",
        "Unified event stream architecture",
        "AgentSkills library",
        "Evaluation framework",
        "Community-driven platform",
        "LLM-powered agents",
        "Complex problem-solving"
      ],
      "paper_type": "based on the abstract and introduction:\n\n1.  **\"we introduce openhands (f.k.a. opendevin), a platform for the development of powerful and flexible ai agents\"** - this is a clear indicator of presenting a new system or platform.\n2.  **\"we describe how the platform allows for the implementation of new agents, safe interaction with sandboxed environments for code execution, coordination between multiple agents, and incorporation of evaluation benchmarks.\"** - this details the functionalities and architecture of the proposed system.\n3.  the introduction further elaborates on the platform's features: **\"an interaction mechanism,\" \"a runtime environment,\" \"an interface,\" \"multi-agent delegation,\"** and an **\"evaluation framework.\"** these are all components of a newly developed system.\n4.  while the paper does include an **\"evaluation of agents over 15 challenging tasks\"** (empirical aspect), this evaluation is presented as a demonstration of the platform's capabilities and the agents built upon it, rather than the primary research question of a standalone empirical study. the core contribution is the platform itself.\n\nthe paper's primary focus is on presenting a novel platform, its architecture, and its components. the empirical evaluation serves to validate the utility and effectiveness of this new system.\n\ntherefore, the most fitting classification is **technical**."
    },
    "file_name": "1d07e5b6f978cf69c0186f3d5f434fa92d471e46.pdf"
  },
  {
    "success": true,
    "doc_id": "4beb51652a6b670c7df32ced5b164ab0",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the specific technical problem of empirically quantifying the impact of generative AI tools on human productivity in professional software development \\cite{peng2023uj3}.\n    *   This problem is important because AI applications hold significant promise for increasing productivity, with major implications for labor markets, skills, and firm organization. It is challenging due to the difficulty in precisely measuring software developer productivity and the lack of controlled experimental evidence on AI's real-world impact in professional contexts.\n\n*   **Related Work & Positioning**\n    *   Existing literature primarily studies perceptions of AI tools, how people use them, and their implications for security and education \\cite{peng2023uj3}.\n    *   Previous solutions or studies often lack rigorous, controlled experimental designs to measure direct productivity impacts in professional settings, focusing instead on qualitative aspects or specific use cases without a control group for comparison. This work positions itself as the \"first controlled experiment to measure the productivity of AI tools in professional software development\" \\cite{peng2023uj3}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a **controlled experiment (randomized control trial)** designed to measure the productivity impact of GitHub Copilot, an AI pair programmer powered by OpenAI's Codex model \\cite{peng2023uj3}.\n    *   The approach is novel due to its rigorous experimental design:\n        *   **Standardized Task**: Participants were tasked with implementing an HTTP server in JavaScript, allowing for precise and comparable performance metrics.\n        *   **Objective Measurement**: Task completion time and success rate were objectively measured using GitHub Classroom, which tracked repository creation timestamps and the first commit passing a comprehensive test suite.\n        *   **Randomized Assignment**: Professional programmers were randomly assigned to a treatment group (with Copilot access) and a control group (without Copilot).\n        *   **Heterogeneous Effects Analysis**: The study investigated how productivity gains varied across developer characteristics (experience, age, daily coding hours).\n\n*   **Key Technical Contributions**\n    *   **Empirical Methodology**: Development and execution of a robust controlled experimental design for quantifying AI's productivity impact in a professional software development context \\cite{peng2023uj3}.\n    *   **Quantified Productivity Gain**: Providing statistically and practically significant evidence that an AI pair programmer (GitHub Copilot) substantially increases developer speed.\n    *   **Identification of Heterogeneous Effects**: Discovering that less experienced programmers, older programmers (25-44), and those who program more hours per day benefit more from AI assistance.\n    *   **Measurement of Willingness to Pay**: An indirect method to gauge the perceived value of the AI tool by asking about \"irrelevant price\" for notification of release.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: A controlled experiment involving 95 professional programmers recruited via Upwork. Participants were randomly split into a treatment group (45 with Copilot) and a control group (50 without Copilot). The task was to implement an HTTP server in JavaScript as quickly as possible \\cite{peng2023uj3}.\n    *   **Key Performance Metrics**:\n        *   **Task Completion Time**: Measured from repository creation to the first commit passing all 12 tests.\n        *   **Task Success Rate**: Percentage of participants adequately completing the task.\n        *   **Self-reported Productivity Gain**: Surveyed after task completion.\n        *   **Willingness to Pay**: Surveyed via \"irrelevant price\" for Copilot.\n    *   **Comparison Results**:\n        *   The **treatment group completed the task 55.8% faster** than the control group (average 71.17 minutes vs. 160.89 minutes). This difference was statistically significant (p-value = 0.0017, 95% CI: [21%, 89%]) \\cite{peng2023uj3}.\n        *   The treated group's success rate was 7 percentage points higher, though not statistically significant.\n        *   Heterogeneous effects analysis showed that **less experienced developers, developers with heavy coding loads, and older developers (25-44 age group) benefited more** from Copilot \\cite{peng2023uj3}.\n        *   Self-reported productivity gain averaged 35% (an underestimation compared to the observed 55.8%).\n        *   The treated group showed a significantly higher average willingness to pay for Copilot ($27.25/month) compared to the control group ($16.91/month).\n\n*   **Limitations & Scope**\n    *   **Task Specificity**: The study used a standardized programming task (HTTP server) which may not generalize to all types of software development tasks, especially complex, collaborative projects, or tasks requiring high creativity or debugging \\cite{peng2023uj3}.\n    *   **Code Quality**: The study did not examine the effects of AI on code quality (e.g., performance, security, maintainability), which could significantly alter the real-world impact of AI assistance \\cite{peng2023uj3}.\n    *   **Single Tool Focus**: The findings are specific to GitHub Copilot and may not directly apply to other AI-powered developer tools.\n    *   **Demographic Scope**: The participant pool, while professional, was predominantly from specific age groups and geographical locations (e.g., India and Pakistan), which might limit the generalizability of heterogeneous effects.\n\n*   **Technical Significance**\n    *   This paper provides **pioneering empirical evidence** through a controlled experiment, establishing a baseline for understanding the direct productivity impact of generative AI in professional software development \\cite{peng2023uj3}.\n    *   It significantly advances the technical state-of-the-art by moving beyond anecdotal evidence or qualitative studies to offer **quantifiable productivity gains**.\n    *   The identification of heterogeneous effects suggests a potential for AI tools to **democratize access to software development careers** by significantly aiding less experienced or older programmers.\n    *   It lays the groundwork for future research into the broader economic impacts of AI, including changes in job tasks, skill requirements, and the distribution of productivity gains, while also highlighting the critical need to investigate code quality implications \\cite{peng2023uj3}.",
    "intriguing_abstract": "The advent of generative AI promises to redefine human-computer collaboration, yet its empirical impact on professional software development productivity remains largely unquantified. This paper presents the *first controlled experiment* (a randomized control trial) to rigorously measure the effects of an AI pair programmer, GitHub Copilot, on professional developers. We tasked 95 professional programmers with implementing a standardized HTTP server in JavaScript, objectively measuring task completion time and success rates.\n\nOur findings reveal a dramatic and statistically significant productivity boost: developers using GitHub Copilot completed the task **55.8% faster** than the control group. Intriguingly, we uncover significant *heterogeneous effects*, demonstrating that less experienced developers, older programmers (25-44), and those with heavier coding loads experienced even greater gains. This pioneering empirical evidence not only quantifies the substantial immediate benefits of AI assistance but also suggests profound implications for skill acquisition, labor market dynamics, and the democratization of software development careers. This work establishes a critical baseline, urging further research into AI's long-term impacts on code quality and the evolving landscape of human-AI collaboration.",
    "keywords": [
      "Generative AI tools",
      "professional software development",
      "software developer productivity",
      "controlled experiment",
      "randomized control trial",
      "GitHub Copilot",
      "AI pair programmer",
      "quantifiable productivity gain",
      "task completion time",
      "heterogeneous effects",
      "less experienced programmers",
      "older programmers",
      "empirical evidence"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/15abedb29536d50afeeec739a25358255cbda3e8.pdf",
    "citation_key": "peng2023uj3",
    "metadata": {
      "title": "The Impact of AI on Developer Productivity: Evidence from GitHub Copilot",
      "authors": [
        "Sida Peng",
        "Eirini Kalliamvakou",
        "Peter Cihon",
        "Mert Demirer"
      ],
      "published_date": "2023",
      "abstract": "Generative AI tools hold promise to increase human productivity. This paper presents results from a controlled experiment with GitHub Copilot, an AI pair programmer. Recruited software developers were asked to implement an HTTP server in JavaScript as quickly as possible. The treatment group, with access to the AI pair programmer, completed the task 55.8% faster than the control group. Observed heterogenous effects show promise for AI pair programmers to help people transition into software development careers.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/15abedb29536d50afeeec739a25358255cbda3e8.pdf",
      "venue": "arXiv.org",
      "citationCount": 360,
      "score": 180.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the specific technical problem of empirically quantifying the impact of generative AI tools on human productivity in professional software development \\cite{peng2023uj3}.\n    *   This problem is important because AI applications hold significant promise for increasing productivity, with major implications for labor markets, skills, and firm organization. It is challenging due to the difficulty in precisely measuring software developer productivity and the lack of controlled experimental evidence on AI's real-world impact in professional contexts.\n\n*   **Related Work & Positioning**\n    *   Existing literature primarily studies perceptions of AI tools, how people use them, and their implications for security and education \\cite{peng2023uj3}.\n    *   Previous solutions or studies often lack rigorous, controlled experimental designs to measure direct productivity impacts in professional settings, focusing instead on qualitative aspects or specific use cases without a control group for comparison. This work positions itself as the \"first controlled experiment to measure the productivity of AI tools in professional software development\" \\cite{peng2023uj3}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a **controlled experiment (randomized control trial)** designed to measure the productivity impact of GitHub Copilot, an AI pair programmer powered by OpenAI's Codex model \\cite{peng2023uj3}.\n    *   The approach is novel due to its rigorous experimental design:\n        *   **Standardized Task**: Participants were tasked with implementing an HTTP server in JavaScript, allowing for precise and comparable performance metrics.\n        *   **Objective Measurement**: Task completion time and success rate were objectively measured using GitHub Classroom, which tracked repository creation timestamps and the first commit passing a comprehensive test suite.\n        *   **Randomized Assignment**: Professional programmers were randomly assigned to a treatment group (with Copilot access) and a control group (without Copilot).\n        *   **Heterogeneous Effects Analysis**: The study investigated how productivity gains varied across developer characteristics (experience, age, daily coding hours).\n\n*   **Key Technical Contributions**\n    *   **Empirical Methodology**: Development and execution of a robust controlled experimental design for quantifying AI's productivity impact in a professional software development context \\cite{peng2023uj3}.\n    *   **Quantified Productivity Gain**: Providing statistically and practically significant evidence that an AI pair programmer (GitHub Copilot) substantially increases developer speed.\n    *   **Identification of Heterogeneous Effects**: Discovering that less experienced programmers, older programmers (25-44), and those who program more hours per day benefit more from AI assistance.\n    *   **Measurement of Willingness to Pay**: An indirect method to gauge the perceived value of the AI tool by asking about \"irrelevant price\" for notification of release.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: A controlled experiment involving 95 professional programmers recruited via Upwork. Participants were randomly split into a treatment group (45 with Copilot) and a control group (50 without Copilot). The task was to implement an HTTP server in JavaScript as quickly as possible \\cite{peng2023uj3}.\n    *   **Key Performance Metrics**:\n        *   **Task Completion Time**: Measured from repository creation to the first commit passing all 12 tests.\n        *   **Task Success Rate**: Percentage of participants adequately completing the task.\n        *   **Self-reported Productivity Gain**: Surveyed after task completion.\n        *   **Willingness to Pay**: Surveyed via \"irrelevant price\" for Copilot.\n    *   **Comparison Results**:\n        *   The **treatment group completed the task 55.8% faster** than the control group (average 71.17 minutes vs. 160.89 minutes). This difference was statistically significant (p-value = 0.0017, 95% CI: [21%, 89%]) \\cite{peng2023uj3}.\n        *   The treated group's success rate was 7 percentage points higher, though not statistically significant.\n        *   Heterogeneous effects analysis showed that **less experienced developers, developers with heavy coding loads, and older developers (25-44 age group) benefited more** from Copilot \\cite{peng2023uj3}.\n        *   Self-reported productivity gain averaged 35% (an underestimation compared to the observed 55.8%).\n        *   The treated group showed a significantly higher average willingness to pay for Copilot ($27.25/month) compared to the control group ($16.91/month).\n\n*   **Limitations & Scope**\n    *   **Task Specificity**: The study used a standardized programming task (HTTP server) which may not generalize to all types of software development tasks, especially complex, collaborative projects, or tasks requiring high creativity or debugging \\cite{peng2023uj3}.\n    *   **Code Quality**: The study did not examine the effects of AI on code quality (e.g., performance, security, maintainability), which could significantly alter the real-world impact of AI assistance \\cite{peng2023uj3}.\n    *   **Single Tool Focus**: The findings are specific to GitHub Copilot and may not directly apply to other AI-powered developer tools.\n    *   **Demographic Scope**: The participant pool, while professional, was predominantly from specific age groups and geographical locations (e.g., India and Pakistan), which might limit the generalizability of heterogeneous effects.\n\n*   **Technical Significance**\n    *   This paper provides **pioneering empirical evidence** through a controlled experiment, establishing a baseline for understanding the direct productivity impact of generative AI in professional software development \\cite{peng2023uj3}.\n    *   It significantly advances the technical state-of-the-art by moving beyond anecdotal evidence or qualitative studies to offer **quantifiable productivity gains**.\n    *   The identification of heterogeneous effects suggests a potential for AI tools to **democratize access to software development careers** by significantly aiding less experienced or older programmers.\n    *   It lays the groundwork for future research into the broader economic impacts of AI, including changes in job tasks, skill requirements, and the distribution of productivity gains, while also highlighting the critical need to investigate code quality implications \\cite{peng2023uj3}.",
      "keywords": [
        "Generative AI tools",
        "professional software development",
        "software developer productivity",
        "controlled experiment",
        "randomized control trial",
        "GitHub Copilot",
        "AI pair programmer",
        "quantifiable productivity gain",
        "task completion time",
        "heterogeneous effects",
        "less experienced programmers",
        "older programmers",
        "empirical evidence"
      ],
      "paper_type": "**empirical**\n\n**reasoning:**\n\nthe abstract and introduction explicitly state that the paper:\n*   \"presents results from a **controlled experiment**\"\n*   involves \"recruited software developers\" (participants)\n*   describes a specific methodology (\"were asked to implement an http server... as quickly as possible. the treatment group... completed the task 55.8% faster than the control group.\")\n*   presents quantitative \"findings\" (\"55.8% faster,\" \"observed heterogenous effects\")\n*   \"studies the productivity effects of ai tools on software development\" (research question/objective)\n*   \"present a **controlled trial** of github copilot\" (methodology)\n\nthese elements directly align with the criteria for an **empirical** paper, which focuses on data-driven studies with statistical analysis, experiments, and findings."
    },
    "file_name": "15abedb29536d50afeeec739a25358255cbda3e8.pdf"
  },
  {
    "success": true,
    "doc_id": "c44de892a169591076583a49f315df1b",
    "summary": "An Artificial Intelligence (AI) agent is a software entity that autonomously performs tasks or makes decisions based on pre-defined objectives and data inputs. AI agents, capable of perceiving user inputs, reasoning and planning tasks, and executing actions, have seen remarkable advancements in algorithm development and task performance. However, the security challenges they pose remain under-explored and unresolved. This survey delves into the emerging security threats faced by AI agents, categorizing them into four critical knowledge gaps: unpredictability of multi-step user inputs, complexity in internal executions, variability of operational environments, and interactions with untrusted external entities. By systematically reviewing these threats, this article highlights both the progress made and the existing limitations in safeguarding AI agents. The insights provided aim to inspire further research into addressing the security threats associated with AI agents, thereby fostering the development of more robust and secure AI agent applications.",
    "intriguing_abstract": "An Artificial Intelligence (AI) agent is a software entity that autonomously performs tasks or makes decisions based on pre-defined objectives and data inputs. AI agents, capable of perceiving user inputs, reasoning and planning tasks, and executing actions, have seen remarkable advancements in algorithm development and task performance. However, the security challenges they pose remain under-explored and unresolved. This survey delves into the emerging security threats faced by AI agents, categorizing them into four critical knowledge gaps: unpredictability of multi-step user inputs, complexity in internal executions, variability of operational environments, and interactions with untrusted external entities. By systematically reviewing these threats, this article highlights both the progress made and the existing limitations in safeguarding AI agents. The insights provided aim to inspire further research into addressing the security threats associated with AI agents, thereby fostering the development of more robust and secure AI agent applications.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/5aacf780ec16a29bdbe283a14f5a9e6b7e1f292d.pdf",
    "citation_key": "deng2024mdx",
    "metadata": {
      "title": "AI Agents Under Threat: A Survey of Key Security Challenges and Future Pathways",
      "authors": [
        "Zehang Deng",
        "Yongjian Guo",
        "Changzhou Han",
        "Wanlun Ma",
        "Junwu Xiong",
        "Sheng Wen",
        "Yang Xiang"
      ],
      "published_date": "2024",
      "abstract": "An Artificial Intelligence (AI) agent is a software entity that autonomously performs tasks or makes decisions based on pre-defined objectives and data inputs. AI agents, capable of perceiving user inputs, reasoning and planning tasks, and executing actions, have seen remarkable advancements in algorithm development and task performance. However, the security challenges they pose remain under-explored and unresolved. This survey delves into the emerging security threats faced by AI agents, categorizing them into four critical knowledge gaps: unpredictability of multi-step user inputs, complexity in internal executions, variability of operational environments, and interactions with untrusted external entities. By systematically reviewing these threats, this article highlights both the progress made and the existing limitations in safeguarding AI agents. The insights provided aim to inspire further research into addressing the security threats associated with AI agents, thereby fostering the development of more robust and secure AI agent applications.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/5aacf780ec16a29bdbe283a14f5a9e6b7e1f292d.pdf",
      "venue": "ACM Computing Surveys",
      "citationCount": 85,
      "score": 85.0,
      "summary": "An Artificial Intelligence (AI) agent is a software entity that autonomously performs tasks or makes decisions based on pre-defined objectives and data inputs. AI agents, capable of perceiving user inputs, reasoning and planning tasks, and executing actions, have seen remarkable advancements in algorithm development and task performance. However, the security challenges they pose remain under-explored and unresolved. This survey delves into the emerging security threats faced by AI agents, categorizing them into four critical knowledge gaps: unpredictability of multi-step user inputs, complexity in internal executions, variability of operational environments, and interactions with untrusted external entities. By systematically reviewing these threats, this article highlights both the progress made and the existing limitations in safeguarding AI agents. The insights provided aim to inspire further research into addressing the security threats associated with AI agents, thereby fostering the development of more robust and secure AI agent applications.",
      "keywords": []
    },
    "file_name": "5aacf780ec16a29bdbe283a14f5a9e6b7e1f292d.pdf"
  },
  {
    "success": true,
    "doc_id": "eec524a879f8e59b0deaef6e1fee763a",
    "summary": "Here's a focused summary of the paper \"LARGE LANGUAGE MODELS AS TOOL MAKERS\" \\cite{sauvola2024zw7} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** While Large Language Models (LLMs) benefit from external tools, their problem-solving capabilities are limited by the availability of suitable tools. The challenge is to enable LLMs to autonomously create these tools.\n    *   **Importance & Challenge:** This problem is crucial for advancing LLM autonomy and efficiency. It's challenging because it requires LLMs to not just *use* but *design, implement, and verify* reusable programmatic solutions, mimicking a key evolutionary milestone in human intelligence. Furthermore, it aims to reduce the high inference costs associated with powerful LLMs for repetitive complex tasks.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds upon research in Chain-of-Thought (CoT) prompting and augmenting LLMs with external tools (e.g., calculators, search engines, APIs). It also shares a spirit with adaptive generation and language model cascades that aim for efficiency.\n    *   **Limitations of Previous Solutions:** Existing tool-using methods are contingent on pre-existing tools. While some works use Python executors for sub-steps (e.g., Chameleon), they don't focus on LLMs *creating reusable tools* for broader task instances. Concurrent early attempts at tool-making exist, but \\cite{sauvola2024zw7} uniquely emphasizes tool reusability and cost-effectiveness through a strategic division of labor.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper introduces LLMs AsToolMakers (LATM) \\cite{sauvola2024zw7}, a closed-loop framework where LLMs create their own reusable tools (implemented as Python utility functions) for problem-solving.\n    *   **Novelty/Difference:**\n        *   **Two-Phase Framework:**\n            1.  **Tool Making:** A powerful, resource-intensive LLM (the \"tool maker,\" e.g., GPT-4) crafts generic, reusable Python functions from a few demonstrations. This phase includes \"Tool Proposing\" (generating code, retrying on errors), \"Tool Verification\" (generating and running unit tests, fixing unit test calls), and \"Tool Wrapping\" (preparing the function and usage demonstrations).\n            2.  **Tool Using:** A lightweight, cost-effective LLM (the \"tool user,\" e.g., GPT-3.5 Turbo) applies the verified tool by translating natural language queries into function calls using in-context learning.\n        *   **Strategic Division of Labor:** Assigns the complex, once-off tool-making task to a powerful LLM and the simpler, repetitive tool-using task to a lightweight LLM, significantly reducing average inference costs.\n        *   **Functional Cache:** Introduces a novel caching mechanism for LLM serving that stores *functionality* (reusable tools) for classes of requests, rather than just natural language responses, extending the applicability of conventional caches.\n        *   **Dispatcher LLM:** A lightweight \"dispatcher\" LLM manages the functional cache, deciding whether to use an existing tool or trigger the tool maker for novel tasks.\n\n*   **Key Technical Contributions**\n    *   A novel closed-loop framework, LATM \\cite{sauvola2024zw7}, enabling LLMs to generate and reuse their own Python-based tools.\n    *   A detailed, automated three-sub-stage process for tool making: Tool Proposing, Tool Verification (including self-correction of unit test calls), and Tool Wrapping.\n    *   An innovative architectural design that separates tool creation (powerful LLM) from tool application (lightweight LLM) to optimize cost and performance.\n    *   The concept and implementation of a \"functional cache\" for LLM serving, which stores reusable programmatic solutions for task categories.\n    *   The introduction of a dispatcher LLM to intelligently manage tool selection and new tool generation within a streaming request environment.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** The approach was evaluated on a range of complex reasoning tasks.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Datasets:** Six datasets, including five from Big-Bench (Logical Deduction (5), Tracking Shuffled Objects (5), Dyck Language, Word Sorting, Chinese Remainder Theorem) and a custom \"Scheduling Meeting\" task. Each dataset used 3 training, 3 validation, and 240 test instances.\n        *   **Model Configuration:** GPT-4 was used as the tool maker, and GPT-3.5 Turbo as the tool user.\n        *   **Results:** LATM \\cite{sauvola2024zw7} demonstrated performance *equivalent to using GPT-4 for both tool making and tool using*, but with a *significantly reduced inference cost*. The tool-making stage, though initially costly, is amortized over many tool-using instances.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The tool-making process, particularly tool proposing and verification, has a preset retry limit, implying potential failure for highly complex or ambiguous tasks. The tool verification stage specifically corrects *function calls* in unit tests, not the core function logic itself (though the tool maker can fix the function in the proposing stage).\n    *   **Scope of Applicability:** Primarily demonstrated on complex reasoning tasks and recurring workflows that can be encapsulated into Python functions (e.g., algorithmic reasoning, data parsing, scheduling). The functional cache is particularly beneficial in streaming LLM serving scenarios.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This work represents a significant step beyond LLMs merely *using* tools, enabling them to *create* and *manage* their own reusable programmatic tools \\cite{sauvola2024zw7}.\n    *   **Potential Impact on Future Research:** It opens new avenues for research into autonomous LLM agents, cost-efficient LLM deployment, and novel caching strategies. The framework's ability to generate and reuse functional code could enhance LLMs' capabilities in algorithmic reasoning and complex problem-solving, fostering a community around LLM-generated tools.",
    "intriguing_abstract": "Large Language Models (LLMs) are powerful tool-users, yet their problem-solving autonomy is fundamentally limited by the availability of pre-existing utilities and the high inference costs of repetitive complex tasks. We introduce LLMs AsToolMakers (LATM) \\cite{sauvola2024zw7}, a groundbreaking closed-loop framework that empowers LLMs to autonomously *create, verify, and reuse* their own Python utility functions. This novel architecture strategically divides labor: a powerful \"tool maker\" LLM (e.g., GPT-4) crafts generic, reusable programmatic solutions through a robust three-stage process, including self-correction and unit test generation. Subsequently, a lightweight \"tool user\" LLM (e.g., GPT-3.5 Turbo) efficiently applies these verified tools by translating natural language queries into function calls. A key innovation is the \"functional cache,\" which stores these reusable tools, managed by a dispatcher LLM, dramatically reducing average inference costs. Our experiments demonstrate that LATM achieves GPT-4 level performance on complex reasoning tasks with significantly lower operational expenses. This work marks a pivotal step towards truly autonomous LLM agents, offering a paradigm shift in cost-efficient LLM deployment and opening new frontiers for algorithmic reasoning and dynamic tool ecosystems.",
    "keywords": [
      "LLMs AsToolMakers (LATM)",
      "autonomous tool creation",
      "reusable programmatic solutions",
      "closed-loop framework",
      "strategic division of labor",
      "functional cache",
      "dispatcher LLM",
      "automated tool making process",
      "reduced inference costs",
      "complex reasoning tasks",
      "LLM autonomy",
      "Python utility functions"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8b910aaa410dd1a5b3c0be5134394af23bc6b848.pdf",
    "citation_key": "sauvola2024zw7",
    "metadata": {
      "title": "Future of software development with generative AI",
      "authors": [
        "Jaakko Sauvola",
        "Sasu Tarkoma",
        "Mika Klemettinen",
        "J. Riekki",
        "David S. Doermann"
      ],
      "published_date": "2024",
      "abstract": "Generative AI is regarded as a major disruption to software development. Platforms, repositories, clouds, and the automation of tools and processes have been proven to improve productivity, cost, and quality. Generative AI, with its rapidly expanding capabilities, is a major step forward in this field. As a new key enabling technology, it can be used for many purposes, from creative dimensions to replacing repetitive and manual tasks. The number of opportunities increases with the capabilities of large-language models (LLMs). This has raised concerns about ethics, education, regulation, intellectual property, and even criminal activities. We analyzed the potential of generative AI and LLM technologies for future software development paths. We propose four primary scenarios, model trajectories for transitions between them, and reflect against relevant software development operations. The motivation for this research is clear: the software development industry needs new tools to understand the potential, limitations, and risks of generative AI, as well as guidelines for using it.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8b910aaa410dd1a5b3c0be5134394af23bc6b848.pdf",
      "venue": "International Conference on Automated Software Engineering",
      "citationCount": 73,
      "score": 73.0,
      "summary": "Here's a focused summary of the paper \"LARGE LANGUAGE MODELS AS TOOL MAKERS\" \\cite{sauvola2024zw7} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** While Large Language Models (LLMs) benefit from external tools, their problem-solving capabilities are limited by the availability of suitable tools. The challenge is to enable LLMs to autonomously create these tools.\n    *   **Importance & Challenge:** This problem is crucial for advancing LLM autonomy and efficiency. It's challenging because it requires LLMs to not just *use* but *design, implement, and verify* reusable programmatic solutions, mimicking a key evolutionary milestone in human intelligence. Furthermore, it aims to reduce the high inference costs associated with powerful LLMs for repetitive complex tasks.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds upon research in Chain-of-Thought (CoT) prompting and augmenting LLMs with external tools (e.g., calculators, search engines, APIs). It also shares a spirit with adaptive generation and language model cascades that aim for efficiency.\n    *   **Limitations of Previous Solutions:** Existing tool-using methods are contingent on pre-existing tools. While some works use Python executors for sub-steps (e.g., Chameleon), they don't focus on LLMs *creating reusable tools* for broader task instances. Concurrent early attempts at tool-making exist, but \\cite{sauvola2024zw7} uniquely emphasizes tool reusability and cost-effectiveness through a strategic division of labor.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper introduces LLMs AsToolMakers (LATM) \\cite{sauvola2024zw7}, a closed-loop framework where LLMs create their own reusable tools (implemented as Python utility functions) for problem-solving.\n    *   **Novelty/Difference:**\n        *   **Two-Phase Framework:**\n            1.  **Tool Making:** A powerful, resource-intensive LLM (the \"tool maker,\" e.g., GPT-4) crafts generic, reusable Python functions from a few demonstrations. This phase includes \"Tool Proposing\" (generating code, retrying on errors), \"Tool Verification\" (generating and running unit tests, fixing unit test calls), and \"Tool Wrapping\" (preparing the function and usage demonstrations).\n            2.  **Tool Using:** A lightweight, cost-effective LLM (the \"tool user,\" e.g., GPT-3.5 Turbo) applies the verified tool by translating natural language queries into function calls using in-context learning.\n        *   **Strategic Division of Labor:** Assigns the complex, once-off tool-making task to a powerful LLM and the simpler, repetitive tool-using task to a lightweight LLM, significantly reducing average inference costs.\n        *   **Functional Cache:** Introduces a novel caching mechanism for LLM serving that stores *functionality* (reusable tools) for classes of requests, rather than just natural language responses, extending the applicability of conventional caches.\n        *   **Dispatcher LLM:** A lightweight \"dispatcher\" LLM manages the functional cache, deciding whether to use an existing tool or trigger the tool maker for novel tasks.\n\n*   **Key Technical Contributions**\n    *   A novel closed-loop framework, LATM \\cite{sauvola2024zw7}, enabling LLMs to generate and reuse their own Python-based tools.\n    *   A detailed, automated three-sub-stage process for tool making: Tool Proposing, Tool Verification (including self-correction of unit test calls), and Tool Wrapping.\n    *   An innovative architectural design that separates tool creation (powerful LLM) from tool application (lightweight LLM) to optimize cost and performance.\n    *   The concept and implementation of a \"functional cache\" for LLM serving, which stores reusable programmatic solutions for task categories.\n    *   The introduction of a dispatcher LLM to intelligently manage tool selection and new tool generation within a streaming request environment.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** The approach was evaluated on a range of complex reasoning tasks.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Datasets:** Six datasets, including five from Big-Bench (Logical Deduction (5), Tracking Shuffled Objects (5), Dyck Language, Word Sorting, Chinese Remainder Theorem) and a custom \"Scheduling Meeting\" task. Each dataset used 3 training, 3 validation, and 240 test instances.\n        *   **Model Configuration:** GPT-4 was used as the tool maker, and GPT-3.5 Turbo as the tool user.\n        *   **Results:** LATM \\cite{sauvola2024zw7} demonstrated performance *equivalent to using GPT-4 for both tool making and tool using*, but with a *significantly reduced inference cost*. The tool-making stage, though initially costly, is amortized over many tool-using instances.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The tool-making process, particularly tool proposing and verification, has a preset retry limit, implying potential failure for highly complex or ambiguous tasks. The tool verification stage specifically corrects *function calls* in unit tests, not the core function logic itself (though the tool maker can fix the function in the proposing stage).\n    *   **Scope of Applicability:** Primarily demonstrated on complex reasoning tasks and recurring workflows that can be encapsulated into Python functions (e.g., algorithmic reasoning, data parsing, scheduling). The functional cache is particularly beneficial in streaming LLM serving scenarios.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This work represents a significant step beyond LLMs merely *using* tools, enabling them to *create* and *manage* their own reusable programmatic tools \\cite{sauvola2024zw7}.\n    *   **Potential Impact on Future Research:** It opens new avenues for research into autonomous LLM agents, cost-efficient LLM deployment, and novel caching strategies. The framework's ability to generate and reuse functional code could enhance LLMs' capabilities in algorithmic reasoning and complex problem-solving, fostering a community around LLM-generated tools.",
      "keywords": [
        "LLMs AsToolMakers (LATM)",
        "autonomous tool creation",
        "reusable programmatic solutions",
        "closed-loop framework",
        "strategic division of labor",
        "functional cache",
        "dispatcher LLM",
        "automated tool making process",
        "reduced inference costs",
        "complex reasoning tasks",
        "LLM autonomy",
        "Python utility functions"
      ],
      "paper_type": "based on the abstract and introduction:\n\nthe paper introduces a **new closed-loop framework** called llms astoolmakers (latm). it describes the **approach** consisting of two phases (tool making and tool using), details the **methodology** (assigning tasks to different llms, functional cache), and mentions the **implementation** (python utility function, codebase available). it then discusses the **evaluation** of this new approach.\n\nthis aligns perfectly with the criteria for a **technical** paper:\n*   abstract mentions: \"introducing a closed-loop framework\", \"our approach consists of two phases\", \"tool is implemented as a python utility function\".\n*   introduction discusses: \"our framework also uncovers intriguing opportunities\", \"our method offers a functional cache\".\n\ntherefore, the paper type is: **technical**"
    },
    "file_name": "8b910aaa410dd1a5b3c0be5134394af23bc6b848.pdf"
  },
  {
    "success": true,
    "doc_id": "05430314d15b1f668975637b3c3675dd",
    "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n### Focused Summary for Literature Review: SWE-BENCH MULTIMODAL\n\n1.  **Research Problem & Motivation**\n    *   Existing benchmarks for autonomous software engineering systems, such as SWE-bench `\\cite{yang20244xg}`, are predominantly limited to Python repositories and text-based problem statements.\n    *   This narrow scope fails to represent a significant portion of real-world software development, particularly user-facing domains like front-end web development, game development, and data visualization, which heavily rely on visual assets and diverse programming languages (e.g., JavaScript).\n    *   The problem is important because AI systems need to generalize beyond Python and text-only issues to be truly effective across the broader software landscape. It is challenging due to the requirements for multimodal reasoning (interpreting images/videos) and cross-language generalization, which current systems are not designed to handle.\n\n2.  **Related Work & Positioning**\n    *   This work extends the paradigm of repository-level coding benchmarks established by SWE-bench `\\cite{yang20244xg}` by introducing a new dimension: multimodal and multi-language challenges.\n    *   Previous solutions, including SWE-bench `\\cite{yang20244xg}`, are limited by their exclusive focus on Python and text-only problem descriptions; only 5.6% of SWE-bench tasks contain images, and their necessity for problem-solving is often unclear.\n    *   Existing systems often rely on language-specific tools (e.g., Python `ast` parsers for fault localization), making them rigid and unable to generalize to other programming languages like JavaScript or to problems requiring visual comprehension.\n    *   `\\cite{yang20244xg}` positions itself as the first benchmark to specifically address the generalization of AI systems to visual software domains, particularly in JavaScript, by explicitly incorporating visual elements and diverse development practices.\n\n3.  **Technical Approach & Innovation**\n    *   The core innovation is the introduction of **SWE-bench Multimodal (SWE-bench M)** `\\cite{yang20244xg}`, a new benchmark dataset designed to evaluate AI systems on visual, user-facing JavaScript software issues.\n    *   **Data Collection**: `\\cite{yang20244xg}` collected 619 task instances from 17 open-source JavaScript libraries (e.g., for UI design, diagramming, data visualization, interactive mapping, syntax highlighting) by scraping real-world GitHub issues and pull requests.\n    *   **Multimodal Filtering**: A key step involved filtering for task instances that explicitly contain images or videos in their problem statements or unit tests, ensuring the necessity of visual comprehension. Human validation confirmed that for 83.5% of tasks, images were crucial for resolution.\n    *   **Environment Setup**: `\\cite{yang20244xg}` developed tailored Docker environments for each JavaScript repository, including foundational infrastructure like Node.js and Chrome, to support JavaScript execution, visual testing, and in-browser webpage rendering.\n    *   **System Adaptation**: `\\cite{yang20244xg}` adapted existing top-performing SWE-bench systems, notably SWE-agent, to handle JavaScript and multimodal inputs. For SWE-agent, this involved developing `SWE-agent JS` (integrating JavaScript edit error detection/linting) and `SWE-agent M` (extending `SWE-agent JS` with a simple web browser, screenshot, and image viewing capabilities for visual reproduction and verification).\n\n4.  **Key Technical Contributions**\n    *   **Novel Benchmark Dataset**: SWE-bench Multimodal `\\cite{yang20244xg}`, the first benchmark to specifically evaluate AI systems on visual, user-facing JavaScript software issues, comprising 619 real-world GitHub tasks.\n    *   **Multimodal Problem Formulation**: Explicitly incorporates images and videos into problem statements and unit tests, with human validation confirming their necessity for task resolution, thereby pushing the frontier of multimodal reasoning in software engineering.\n    *   **Cross-Language Generalization Focus**: Shifts evaluation from Python to JavaScript, highlighting challenges related to diverse programming paradigms (OO, functional, procedural), asynchronous programming, and DOM/state manipulation inherent in web development.\n    *   **Enhanced Agent Capabilities**: Demonstrates the need for and provides a framework for adapting agent systems (e.g., SWE-agent `\\cite{yang20244xg}`) with flexible, language-agnostic features and multimodal perception tools (e.g., browser interaction, screenshot analysis) to tackle these new domains.\n    *   **Detailed Dataset Characterization**: Provides an in-depth analysis of image diversity (e.g., website screenshots, code snippets, diagrams, maps, data visualizations), video usage, the necessity of visual information, and difficulty curve estimations.\n\n5.  **Experimental Validation**\n    *   **Experiment Design**: `\\cite{yang20244xg}` evaluated top-performing open-source systems from the SWE-bench leaderboard on SWE-bench M to assess their generalization capabilities.\n    *   **System Adaptation**: Attempts were made to adapt these systems, with a focus on SWE-agent `\\cite{yang20244xg}` due to its flexible architecture. Three configurations of SWE-agent were tested: `SWE-agent Base` (original), `SWE-agent JS` (with JavaScript linting), and `SWE-agent M` (with browser, screenshot, and image viewing capabilities).\n    *   **Key Performance Metrics**: The primary metric is the percentage of task instances successfully resolved, where a solution passes all fail-to-pass and pass-to-pass unit tests.\n    *   **Comparison Results**:\n        *   Existing top-performing SWE-bench systems struggled significantly on SWE-bench M, revealing severe limitations in visual problem-solving and cross-language generalization.\n        *   `SWE-agent M` `\\cite{yang20244xg}` substantially outperformed alternatives, resolving 12% of task instances.\n        *   The next best system achieved only 6% resolution, highlighting the significant performance gap and the challenges posed by SWE-bench M.\n        *   Performance varied based on the type of visual elements and the diverse development practices within JavaScript.\n\n6.  **Limitations & Scope**\n    *   **System Generalizability**: Many existing SWE-bench systems were found to be too heavily tailored to Python and the original SWE-bench `\\cite{yang20244xg}` to be directly usable or easily adaptable for JavaScript and multimodal tasks.\n    *   **Manual Effort**: The creation of SWE-bench M required significant manual effort, particularly in setting up tailored Docker environments for each JavaScript repository (averaging ten hours per repository) and human validation of task instances.\n    *   **Scope of Applicability**: While SWE-bench M expands to visual JavaScript domains, it still represents a specific subset of software engineering. Other unrepresented domains (e.g., game development, DevOps in other languages) remain for future exploration.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art in AI for Software Engineering**: `\\cite{yang20244xg}` significantly pushes the boundaries of autonomous software engineering by introducing the critical dimensions of multimodal reasoning and cross-language generalization, which are essential for real-world applicability.\n    *   **New Research Direction**: The benchmark and its findings highlight generalizability as a crucial, yet overlooked, property for future LM-based software engineering systems, encouraging research into more flexible and language-agnostic agent architectures.\n    *   **Catalyst for Multimodal Agents**: The poor performance of existing systems on SWE-bench M `\\cite{yang20244xg}` underscores the urgent need for developing AI agents capable of effectively interpreting and acting upon visual information in software development contexts.\n    *   **Impact on Future Research**: SWE-bench M `\\cite{yang20244xg}` provides a challenging new evaluation standard and a rich dataset for developing and testing next-generation AI systems that can understand and fix bugs in complex, visually-driven, and multi-language software environments. It also offers concrete suggestions for building agents that operate efficiently across numerous programming languages and visual content.",
    "intriguing_abstract": "The promise of truly autonomous software engineering agents remains elusive, largely due to benchmarks that fail to capture the visual and multi-language complexity of real-world software development. We introduce **SWE-bench Multimodal (SWE-bench M)**, the first benchmark explicitly designed to evaluate AI systems on visual, user-facing JavaScript software issues. Comprising 619 meticulously curated tasks from real-world GitHub issues across 17 diverse JavaScript libraries, SWE-bench M uniquely integrates images and videos, with human validation confirming their necessity for problem resolution. This dataset challenges AI agents to perform sophisticated multimodal reasoning and cross-language generalization, pushing beyond the limitations of current text-only, Python-centric systems. Our experiments reveal that even top-performing SWE-bench agents struggle significantly on SWE-bench M, with an adapted `SWE-agent M` (equipped with browser interaction and screenshot capabilities) achieving a modest 12% resolution rate. This stark performance gap underscores the urgent need for developing next-generation AI agents capable of effectively interpreting visual information and operating across diverse programming paradigms. SWE-bench M provides a critical new standard and a rich dataset to accelerate research into truly generalizable and robust AI for software engineering, paving the way for agents that can tackle the full complexity of modern software development.",
    "keywords": [
      "SWE-bench Multimodal",
      "Multimodal reasoning",
      "Cross-language generalization",
      "Autonomous software engineering",
      "JavaScript software issues",
      "Visual problem-solving",
      "Benchmark dataset",
      "Agent systems adaptation",
      "SWE-agent M",
      "Front-end web development",
      "Docker environments",
      "Multimodal problem formulation",
      "Language-agnostic agents",
      "Real-world software development"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/1d59c7a29723aa56271ff0252b79fb378655cf21.pdf",
    "citation_key": "yang20244xg",
    "metadata": {
      "title": "SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?",
      "authors": [
        "John Yang",
        "Carlos E. Jimenez",
        "Alex L. Zhang",
        "Kilian Adriano Lieret",
        "Joyce Yang",
        "Xindi Wu",
        "Ori Press",
        "Niklas Muennighoff",
        "Gabriele Synnaeve",
        "Karthik R. Narasimhan",
        "Diyi Yang",
        "Sida Wang",
        "Ofir Press"
      ],
      "published_date": "2024",
      "abstract": "Autonomous systems for software engineering are now capable of fixing bugs and developing features. These systems are commonly evaluated on SWE-bench (Jimenez et al., 2024a), which assesses their ability to solve software issues from GitHub repositories. However, SWE-bench uses only Python repositories, with problem statements presented predominantly as text and lacking visual elements such as images. This limited coverage motivates our inquiry into how existing systems might perform on unrepresented software engineering domains (e.g., front-end, game development, DevOps), which use different programming languages and paradigms. Therefore, we propose SWE-bench Multimodal (SWE-bench M), to evaluate systems on their ability to fix bugs in visual, user-facing JavaScript software. SWE-bench M features 617 task instances collected from 17 JavaScript libraries used for web interface design, diagramming, data visualization, syntax highlighting, and interactive mapping. Each SWE-bench M task instance contains at least one image in its problem statement or unit tests. Our analysis finds that top-performing SWE-bench systems struggle with SWE-bench M, revealing limitations in visual problem-solving and cross-language generalization. Lastly, we show that SWE-agent's flexible language-agnostic features enable it to substantially outperform alternatives on SWE-bench M, resolving 12% of task instances compared to 6% for the next best system.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/1d59c7a29723aa56271ff0252b79fb378655cf21.pdf",
      "venue": "arXiv.org",
      "citationCount": 60,
      "score": 60.0,
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n### Focused Summary for Literature Review: SWE-BENCH MULTIMODAL\n\n1.  **Research Problem & Motivation**\n    *   Existing benchmarks for autonomous software engineering systems, such as SWE-bench `\\cite{yang20244xg}`, are predominantly limited to Python repositories and text-based problem statements.\n    *   This narrow scope fails to represent a significant portion of real-world software development, particularly user-facing domains like front-end web development, game development, and data visualization, which heavily rely on visual assets and diverse programming languages (e.g., JavaScript).\n    *   The problem is important because AI systems need to generalize beyond Python and text-only issues to be truly effective across the broader software landscape. It is challenging due to the requirements for multimodal reasoning (interpreting images/videos) and cross-language generalization, which current systems are not designed to handle.\n\n2.  **Related Work & Positioning**\n    *   This work extends the paradigm of repository-level coding benchmarks established by SWE-bench `\\cite{yang20244xg}` by introducing a new dimension: multimodal and multi-language challenges.\n    *   Previous solutions, including SWE-bench `\\cite{yang20244xg}`, are limited by their exclusive focus on Python and text-only problem descriptions; only 5.6% of SWE-bench tasks contain images, and their necessity for problem-solving is often unclear.\n    *   Existing systems often rely on language-specific tools (e.g., Python `ast` parsers for fault localization), making them rigid and unable to generalize to other programming languages like JavaScript or to problems requiring visual comprehension.\n    *   `\\cite{yang20244xg}` positions itself as the first benchmark to specifically address the generalization of AI systems to visual software domains, particularly in JavaScript, by explicitly incorporating visual elements and diverse development practices.\n\n3.  **Technical Approach & Innovation**\n    *   The core innovation is the introduction of **SWE-bench Multimodal (SWE-bench M)** `\\cite{yang20244xg}`, a new benchmark dataset designed to evaluate AI systems on visual, user-facing JavaScript software issues.\n    *   **Data Collection**: `\\cite{yang20244xg}` collected 619 task instances from 17 open-source JavaScript libraries (e.g., for UI design, diagramming, data visualization, interactive mapping, syntax highlighting) by scraping real-world GitHub issues and pull requests.\n    *   **Multimodal Filtering**: A key step involved filtering for task instances that explicitly contain images or videos in their problem statements or unit tests, ensuring the necessity of visual comprehension. Human validation confirmed that for 83.5% of tasks, images were crucial for resolution.\n    *   **Environment Setup**: `\\cite{yang20244xg}` developed tailored Docker environments for each JavaScript repository, including foundational infrastructure like Node.js and Chrome, to support JavaScript execution, visual testing, and in-browser webpage rendering.\n    *   **System Adaptation**: `\\cite{yang20244xg}` adapted existing top-performing SWE-bench systems, notably SWE-agent, to handle JavaScript and multimodal inputs. For SWE-agent, this involved developing `SWE-agent JS` (integrating JavaScript edit error detection/linting) and `SWE-agent M` (extending `SWE-agent JS` with a simple web browser, screenshot, and image viewing capabilities for visual reproduction and verification).\n\n4.  **Key Technical Contributions**\n    *   **Novel Benchmark Dataset**: SWE-bench Multimodal `\\cite{yang20244xg}`, the first benchmark to specifically evaluate AI systems on visual, user-facing JavaScript software issues, comprising 619 real-world GitHub tasks.\n    *   **Multimodal Problem Formulation**: Explicitly incorporates images and videos into problem statements and unit tests, with human validation confirming their necessity for task resolution, thereby pushing the frontier of multimodal reasoning in software engineering.\n    *   **Cross-Language Generalization Focus**: Shifts evaluation from Python to JavaScript, highlighting challenges related to diverse programming paradigms (OO, functional, procedural), asynchronous programming, and DOM/state manipulation inherent in web development.\n    *   **Enhanced Agent Capabilities**: Demonstrates the need for and provides a framework for adapting agent systems (e.g., SWE-agent `\\cite{yang20244xg}`) with flexible, language-agnostic features and multimodal perception tools (e.g., browser interaction, screenshot analysis) to tackle these new domains.\n    *   **Detailed Dataset Characterization**: Provides an in-depth analysis of image diversity (e.g., website screenshots, code snippets, diagrams, maps, data visualizations), video usage, the necessity of visual information, and difficulty curve estimations.\n\n5.  **Experimental Validation**\n    *   **Experiment Design**: `\\cite{yang20244xg}` evaluated top-performing open-source systems from the SWE-bench leaderboard on SWE-bench M to assess their generalization capabilities.\n    *   **System Adaptation**: Attempts were made to adapt these systems, with a focus on SWE-agent `\\cite{yang20244xg}` due to its flexible architecture. Three configurations of SWE-agent were tested: `SWE-agent Base` (original), `SWE-agent JS` (with JavaScript linting), and `SWE-agent M` (with browser, screenshot, and image viewing capabilities).\n    *   **Key Performance Metrics**: The primary metric is the percentage of task instances successfully resolved, where a solution passes all fail-to-pass and pass-to-pass unit tests.\n    *   **Comparison Results**:\n        *   Existing top-performing SWE-bench systems struggled significantly on SWE-bench M, revealing severe limitations in visual problem-solving and cross-language generalization.\n        *   `SWE-agent M` `\\cite{yang20244xg}` substantially outperformed alternatives, resolving 12% of task instances.\n        *   The next best system achieved only 6% resolution, highlighting the significant performance gap and the challenges posed by SWE-bench M.\n        *   Performance varied based on the type of visual elements and the diverse development practices within JavaScript.\n\n6.  **Limitations & Scope**\n    *   **System Generalizability**: Many existing SWE-bench systems were found to be too heavily tailored to Python and the original SWE-bench `\\cite{yang20244xg}` to be directly usable or easily adaptable for JavaScript and multimodal tasks.\n    *   **Manual Effort**: The creation of SWE-bench M required significant manual effort, particularly in setting up tailored Docker environments for each JavaScript repository (averaging ten hours per repository) and human validation of task instances.\n    *   **Scope of Applicability**: While SWE-bench M expands to visual JavaScript domains, it still represents a specific subset of software engineering. Other unrepresented domains (e.g., game development, DevOps in other languages) remain for future exploration.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art in AI for Software Engineering**: `\\cite{yang20244xg}` significantly pushes the boundaries of autonomous software engineering by introducing the critical dimensions of multimodal reasoning and cross-language generalization, which are essential for real-world applicability.\n    *   **New Research Direction**: The benchmark and its findings highlight generalizability as a crucial, yet overlooked, property for future LM-based software engineering systems, encouraging research into more flexible and language-agnostic agent architectures.\n    *   **Catalyst for Multimodal Agents**: The poor performance of existing systems on SWE-bench M `\\cite{yang20244xg}` underscores the urgent need for developing AI agents capable of effectively interpreting and acting upon visual information in software development contexts.\n    *   **Impact on Future Research**: SWE-bench M `\\cite{yang20244xg}` provides a challenging new evaluation standard and a rich dataset for developing and testing next-generation AI systems that can understand and fix bugs in complex, visually-driven, and multi-language software environments. It also offers concrete suggestions for building agents that operate efficiently across numerous programming languages and visual content.",
      "keywords": [
        "SWE-bench Multimodal",
        "Multimodal reasoning",
        "Cross-language generalization",
        "Autonomous software engineering",
        "JavaScript software issues",
        "Visual problem-solving",
        "Benchmark dataset",
        "Agent systems adaptation",
        "SWE-agent M",
        "Front-end web development",
        "Docker environments",
        "Multimodal problem formulation",
        "Language-agnostic agents",
        "Real-world software development"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"therefore, we **propose swe-bench multimodal (swe-bench m)**, to evaluate systems on their ability to fix bugs in visual, user-facing javascript software.\"\n*   it then describes the features of this proposed benchmark: \"swe-bench m features 617 task instances collected from 17 javascript libraries...\" and \"each swe-bench m task instance contains at least one image...\"\n*   the paper then uses this newly proposed benchmark to conduct an analysis: \"our analysis finds that top-performing swe-bench systems struggle with swe-bench m...\" and \"we show that swe-agent’s flexible language-agnostic features enable it to substantially outperform alternatives on swe-bench m...\"\n\nthis structure indicates that the paper's primary contribution is the **development and presentation of a new system/benchmark (swe-bench m)**, followed by an empirical evaluation using this new system. the act of \"proposing\" and detailing a new benchmark falls under the \"technical\" classification. while there is an empirical component (the analysis of system performance), it is conducted *with* the newly proposed technical artifact, making the creation of the artifact the central theme.\n\ntherefore, the paper best fits the **technical** type."
    },
    "file_name": "1d59c7a29723aa56271ff0252b79fb378655cf21.pdf"
  },
  {
    "success": true,
    "doc_id": "be0c0a81adaff5991717b46e8b6d1cd9",
    "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n**1. Research Problem & Motivation**\n\n*   **Specific Technical Problem**: The paper addresses the problem of understanding the factors that influence the adoption of Generative Artificial Intelligence (AI) tools, particularly Large Language Models (LLMs), by software engineers within their development workflows \\cite{russo2023kua}.\n*   **Importance & Challenge**:\n    *   Generative AI promises significant productivity gains (20-45%) across the software development lifecycle, from ideation and coding to testing and maintenance \\cite{russo2023kua}.\n    *   Despite this potential, the integration of LLMs is complex and challenging, with evidence suggesting a decline in usage due to tools not meeting end-user requirements \\cite{russo2023kua}.\n    *   There is a critical need for empirical research to identify the core determinants of Generative AI adoption, as existing studies often lack a comprehensive understanding of individual, technological, and social influencing factors \\cite{russo2023kua}.\n\n**2. Related Work & Positioning**\n\n*   **Relation to Existing Approaches**:\n    *   The work acknowledges existing research on Generative AI in software engineering, which largely focuses on technical aspects such as assessing code correctness, evaluating productivity gains, comparing different AI code generators, and discussing pedagogical or security concerns \\cite{russo2023kua}.\n    *   It positions itself by drawing upon established technology acceptance theories—the Technology Acceptance Model (TAM), the Diffusion of Innovation Theory (DOI), and the Social Cognitive Theory (SCT)—to frame its investigation into adoption dynamics \\cite{russo2023kua}.\n*   **Limitations of Previous Solutions**:\n    *   A significant gap identified is the \"glaring lack of empirical research evaluating\" the *adoption* of Generative AI tools, especially beyond specific tools like GitHub Copilot \\cite{russo2023kua}.\n    *   Previous work often overlooks the multifaceted individual, technological, and social factors that drive or hinder engineers' decisions to integrate these tools into their daily work \\cite{russo2023kua}.\n    *   The paper implicitly critiques the direct applicability of conventional technology acceptance theories, as its findings later challenge some of their core tenets regarding primary adoption drivers \\cite{russo2023kua}.\n\n**3. Technical Approach & Innovation**\n\n*   **Core Technical Method/Algorithm**:\n    *   The paper employs a **convergent mixed-methods approach**, integrating qualitative and quantitative research \\cite{russo2023kua}.\n    *   **Qualitative Phase**: An initial questionnaire survey with 100 software engineers was conducted. The data was then analyzed using the **Gioia Methodology** for inductive theory building, leading to the development of a preliminary theoretical model \\cite{russo2023kua}.\n    *   **Quantitative Phase**: This preliminary model was rigorously validated using **Partial Least Squares – Structural Equation Modeling (PLS-SEM)**, based on data collected from a larger sample of 183 software engineers \\cite{russo2023kua}.\n*   **Novelty/Difference**:\n    *   The primary innovation is the **inductive derivation and empirical validation of the Human-AI Collaboration and Adaptation Framework (HACAF)**, a novel theoretical model specifically designed to explain Generative AI adoption in software engineering \\cite{russo2023kua}.\n    *   Unlike studies that solely apply existing acceptance models, this work uses the Gioia Methodology to build a context-specific framework from empirical data, offering a more nuanced understanding of this disruptive technology's adoption \\cite{russo2023kua}.\n    *   The approach is novel in its finding that, at early stages, **compatibility with existing workflows** is a more dominant adoption driver than factors like perceived usefulness, which often take precedence in traditional technology acceptance models \\cite{russo2023kua}.\n\n**4. Key Technical Contributions**\n\n*   **Novel Algorithms, Methods, or Techniques**:\n    *   The application of the **Gioia Methodology** for inductive theory generation from qualitative data in the context of Generative AI adoption \\cite{russo2023kua}.\n    *   The use of **PLS-SEM** for robust statistical validation of the complex relationships within the newly proposed theoretical model \\cite{russo2023kua}.\n*   **System Design or Architectural Innovations**:\n    *   The paper's core contribution is the **Human-AI Collaboration and Adaptation Framework (HACAF)**, a theoretical architecture that maps the influencing factors and their relationships governing Generative AI adoption in software engineering \\cite{russo2023kua}.\n*   **Theoretical Insights or Analysis**:\n    *   The development of HACAF provides a comprehensive, empirically grounded theoretical lens for understanding Generative AI adoption dynamics \\cite{russo2023kua}.\n    *   A significant theoretical insight is the empirical demonstration that **workflow compatibility** is the predominant driver for Generative AI adoption in software engineering at its early stages, challenging the conventional hierarchy of factors in established technology acceptance theories \\cite{russo2023kua}.\n    *   It highlights that perceived usefulness, social factors, and personal innovativeness have a less pronounced impact than typically expected in this specific context \\cite{russo2023kua}.\n\n**5. Experimental Validation**\n\n*   **Experiments Conducted**:\n    *   **Phase 1**: An initial questionnaire survey was administered to 100 software engineers to gather qualitative insights into their experiences with Generative AI tools \\cite{russo2023kua}.\n    *   **Phase 2**: A subsequent survey collected quantitative data from 183 software engineers to validate the theoretical model derived from Phase 1 \\cite{russo2023kua}.\n*   **Key Performance Metrics and Comparison Results**:\n    *   The validation employed **Partial Least Squares – Structural Equation Modeling (PLS-SEM)** to assess the strength and significance of relationships between the constructs in the HACAF model \\cite{russo2023kua}.\n    *   **Key Finding**: The PLS-SEM results indicated that the **compatibility of AI tools within existing development workflows predominantly drives their adoption** \\cite{russo2023kua}.\n    *   **Comparison Result**: This finding directly challenges conventional technology acceptance theories, which often posit perceived usefulness as the primary driver. The study found that the impact of perceived usefulness, social factors, and personal innovativeness was less significant than anticipated in this early adoption phase \\cite{russo2023kua}.\n\n**6. Limitations & Scope**\n\n*   **Technical Limitations or Assumptions**:\n    *   The study focuses on the *early stage* of Generative AI integration, and adoption dynamics may evolve as the technology matures and becomes more deeply embedded \\cite{russo2023kua}.\n    *   The findings are based on self-reported data from surveys, which inherently carry potential for response bias \\cite{russo2023kua}.\n    *   The sample sizes, while substantial for empirical software engineering, may not fully capture the diversity of the global software engineering population \\cite{russo2023kua}.\n*   **Scope of Applicability**:\n    *   The derived HACAF and its insights are specifically applicable to the **adoption of Generative AI tools (LLMs)** within the **software engineering domain** \\cite{russo2023kua}.\n    *   The framework provides crucial insights for the design of future AI tools and the development of effective organizational implementation strategies within software development contexts \\cite{russo2023kua}.\n\n**7. Technical Significance**\n\n*   **Advancement of State-of-the-Art**:\n    *   The paper significantly advances the technical state-of-the-art by providing the first comprehensive, empirically validated theoretical framework (HACAF) for understanding Generative AI adoption in software engineering \\cite{russo2023kua}.\n    *   It moves beyond mere technical evaluation of AI outputs to address the critical human and organizational factors influencing successful integration \\cite{russo2023kua}.\n    *   By empirically demonstrating the primacy of **workflow compatibility** over perceived usefulness in early adoption, it refines and challenges existing technology acceptance theories, offering a more accurate model for disruptive AI technologies \\cite{russo2023kua}.\n*   **Potential Impact on Future Research**:\n    *   The HACAF provides a robust foundation for future research into human-AI collaboration, the evolution of AI adoption factors over time, and the design principles for user-centric Generative AI tools in software engineering \\cite{russo2023kua}.\n    *   It encourages researchers and tool developers to prioritize seamless integration and minimal disruption to existing workflows as a key design principle for new AI-powered development tools \\cite{russo2023kua}.\n    *   The findings open avenues for investigating how different organizational contexts or levels of AI maturity might alter the relative importance of adoption factors \\cite{russo2023kua}.",
    "intriguing_abstract": "Generative AI promises transformative productivity in software engineering, yet its widespread adoption is hindered by a critical lack of empirical understanding of what truly drives engineers to integrate these powerful tools. This paper addresses this gap, employing a rigorous convergent **mixed-methods approach**—combining inductive theory building via the **Gioia Methodology** with robust **Partial Least Squares – Structural Equation Modeling (PLS-SEM)** validation from 283 software engineers.\n\nOur novel contribution is the **Human-AI Collaboration and Adaptation Framework (HACAF)**, an empirically validated theoretical model for **Generative AI adoption**. HACAF reveals a profound insight: **workflow compatibility** is the predominant driver for early adoption of **Large Language Models (LLMs)** in software engineering, significantly challenging conventional **technology acceptance theories** that often prioritize perceived usefulness. This work offers crucial guidance for designing user-centric AI tools and strategies, emphasizing seamless integration to unlock AI's full potential in software development.",
    "keywords": [
      "Generative AI adoption",
      "Large Language Models (LLMs)",
      "Software engineering workflows",
      "Human-AI Collaboration and Adaptation Framework (HACAF)",
      "Convergent mixed-methods approach",
      "Gioia Methodology",
      "Partial Least Squares – Structural Equation Modeling (PLS-SEM)",
      "Workflow compatibility (adoption driver)",
      "Challenging technology acceptance theories",
      "Empirical validation",
      "Inductive theory building",
      "Perceived usefulness (less significant)"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/0e41ae9360a962430650d5bb174de223aa8deea5.pdf",
    "citation_key": "russo2023kua",
    "metadata": {
      "title": "Navigating the Complexity of Generative AI Adoption in Software Engineering",
      "authors": [
        "Daniel Russo"
      ],
      "published_date": "2023",
      "abstract": "This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares–Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/0e41ae9360a962430650d5bb174de223aa8deea5.pdf",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "citationCount": 119,
      "score": 59.5,
      "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n**1. Research Problem & Motivation**\n\n*   **Specific Technical Problem**: The paper addresses the problem of understanding the factors that influence the adoption of Generative Artificial Intelligence (AI) tools, particularly Large Language Models (LLMs), by software engineers within their development workflows \\cite{russo2023kua}.\n*   **Importance & Challenge**:\n    *   Generative AI promises significant productivity gains (20-45%) across the software development lifecycle, from ideation and coding to testing and maintenance \\cite{russo2023kua}.\n    *   Despite this potential, the integration of LLMs is complex and challenging, with evidence suggesting a decline in usage due to tools not meeting end-user requirements \\cite{russo2023kua}.\n    *   There is a critical need for empirical research to identify the core determinants of Generative AI adoption, as existing studies often lack a comprehensive understanding of individual, technological, and social influencing factors \\cite{russo2023kua}.\n\n**2. Related Work & Positioning**\n\n*   **Relation to Existing Approaches**:\n    *   The work acknowledges existing research on Generative AI in software engineering, which largely focuses on technical aspects such as assessing code correctness, evaluating productivity gains, comparing different AI code generators, and discussing pedagogical or security concerns \\cite{russo2023kua}.\n    *   It positions itself by drawing upon established technology acceptance theories—the Technology Acceptance Model (TAM), the Diffusion of Innovation Theory (DOI), and the Social Cognitive Theory (SCT)—to frame its investigation into adoption dynamics \\cite{russo2023kua}.\n*   **Limitations of Previous Solutions**:\n    *   A significant gap identified is the \"glaring lack of empirical research evaluating\" the *adoption* of Generative AI tools, especially beyond specific tools like GitHub Copilot \\cite{russo2023kua}.\n    *   Previous work often overlooks the multifaceted individual, technological, and social factors that drive or hinder engineers' decisions to integrate these tools into their daily work \\cite{russo2023kua}.\n    *   The paper implicitly critiques the direct applicability of conventional technology acceptance theories, as its findings later challenge some of their core tenets regarding primary adoption drivers \\cite{russo2023kua}.\n\n**3. Technical Approach & Innovation**\n\n*   **Core Technical Method/Algorithm**:\n    *   The paper employs a **convergent mixed-methods approach**, integrating qualitative and quantitative research \\cite{russo2023kua}.\n    *   **Qualitative Phase**: An initial questionnaire survey with 100 software engineers was conducted. The data was then analyzed using the **Gioia Methodology** for inductive theory building, leading to the development of a preliminary theoretical model \\cite{russo2023kua}.\n    *   **Quantitative Phase**: This preliminary model was rigorously validated using **Partial Least Squares – Structural Equation Modeling (PLS-SEM)**, based on data collected from a larger sample of 183 software engineers \\cite{russo2023kua}.\n*   **Novelty/Difference**:\n    *   The primary innovation is the **inductive derivation and empirical validation of the Human-AI Collaboration and Adaptation Framework (HACAF)**, a novel theoretical model specifically designed to explain Generative AI adoption in software engineering \\cite{russo2023kua}.\n    *   Unlike studies that solely apply existing acceptance models, this work uses the Gioia Methodology to build a context-specific framework from empirical data, offering a more nuanced understanding of this disruptive technology's adoption \\cite{russo2023kua}.\n    *   The approach is novel in its finding that, at early stages, **compatibility with existing workflows** is a more dominant adoption driver than factors like perceived usefulness, which often take precedence in traditional technology acceptance models \\cite{russo2023kua}.\n\n**4. Key Technical Contributions**\n\n*   **Novel Algorithms, Methods, or Techniques**:\n    *   The application of the **Gioia Methodology** for inductive theory generation from qualitative data in the context of Generative AI adoption \\cite{russo2023kua}.\n    *   The use of **PLS-SEM** for robust statistical validation of the complex relationships within the newly proposed theoretical model \\cite{russo2023kua}.\n*   **System Design or Architectural Innovations**:\n    *   The paper's core contribution is the **Human-AI Collaboration and Adaptation Framework (HACAF)**, a theoretical architecture that maps the influencing factors and their relationships governing Generative AI adoption in software engineering \\cite{russo2023kua}.\n*   **Theoretical Insights or Analysis**:\n    *   The development of HACAF provides a comprehensive, empirically grounded theoretical lens for understanding Generative AI adoption dynamics \\cite{russo2023kua}.\n    *   A significant theoretical insight is the empirical demonstration that **workflow compatibility** is the predominant driver for Generative AI adoption in software engineering at its early stages, challenging the conventional hierarchy of factors in established technology acceptance theories \\cite{russo2023kua}.\n    *   It highlights that perceived usefulness, social factors, and personal innovativeness have a less pronounced impact than typically expected in this specific context \\cite{russo2023kua}.\n\n**5. Experimental Validation**\n\n*   **Experiments Conducted**:\n    *   **Phase 1**: An initial questionnaire survey was administered to 100 software engineers to gather qualitative insights into their experiences with Generative AI tools \\cite{russo2023kua}.\n    *   **Phase 2**: A subsequent survey collected quantitative data from 183 software engineers to validate the theoretical model derived from Phase 1 \\cite{russo2023kua}.\n*   **Key Performance Metrics and Comparison Results**:\n    *   The validation employed **Partial Least Squares – Structural Equation Modeling (PLS-SEM)** to assess the strength and significance of relationships between the constructs in the HACAF model \\cite{russo2023kua}.\n    *   **Key Finding**: The PLS-SEM results indicated that the **compatibility of AI tools within existing development workflows predominantly drives their adoption** \\cite{russo2023kua}.\n    *   **Comparison Result**: This finding directly challenges conventional technology acceptance theories, which often posit perceived usefulness as the primary driver. The study found that the impact of perceived usefulness, social factors, and personal innovativeness was less significant than anticipated in this early adoption phase \\cite{russo2023kua}.\n\n**6. Limitations & Scope**\n\n*   **Technical Limitations or Assumptions**:\n    *   The study focuses on the *early stage* of Generative AI integration, and adoption dynamics may evolve as the technology matures and becomes more deeply embedded \\cite{russo2023kua}.\n    *   The findings are based on self-reported data from surveys, which inherently carry potential for response bias \\cite{russo2023kua}.\n    *   The sample sizes, while substantial for empirical software engineering, may not fully capture the diversity of the global software engineering population \\cite{russo2023kua}.\n*   **Scope of Applicability**:\n    *   The derived HACAF and its insights are specifically applicable to the **adoption of Generative AI tools (LLMs)** within the **software engineering domain** \\cite{russo2023kua}.\n    *   The framework provides crucial insights for the design of future AI tools and the development of effective organizational implementation strategies within software development contexts \\cite{russo2023kua}.\n\n**7. Technical Significance**\n\n*   **Advancement of State-of-the-Art**:\n    *   The paper significantly advances the technical state-of-the-art by providing the first comprehensive, empirically validated theoretical framework (HACAF) for understanding Generative AI adoption in software engineering \\cite{russo2023kua}.\n    *   It moves beyond mere technical evaluation of AI outputs to address the critical human and organizational factors influencing successful integration \\cite{russo2023kua}.\n    *   By empirically demonstrating the primacy of **workflow compatibility** over perceived usefulness in early adoption, it refines and challenges existing technology acceptance theories, offering a more accurate model for disruptive AI technologies \\cite{russo2023kua}.\n*   **Potential Impact on Future Research**:\n    *   The HACAF provides a robust foundation for future research into human-AI collaboration, the evolution of AI adoption factors over time, and the design principles for user-centric Generative AI tools in software engineering \\cite{russo2023kua}.\n    *   It encourages researchers and tool developers to prioritize seamless integration and minimal disruption to existing workflows as a key design principle for new AI-powered development tools \\cite{russo2023kua}.\n    *   The findings open avenues for investigating how different organizational contexts or levels of AI maturity might alter the relative importance of adoption factors \\cite{russo2023kua}.",
      "keywords": [
        "Generative AI adoption",
        "Large Language Models (LLMs)",
        "Software engineering workflows",
        "Human-AI Collaboration and Adaptation Framework (HACAF)",
        "Convergent mixed-methods approach",
        "Gioia Methodology",
        "Partial Least Squares – Structural Equation Modeling (PLS-SEM)",
        "Workflow compatibility (adoption driver)",
        "Challenging technology acceptance theories",
        "Empirical validation",
        "Inductive theory building",
        "Perceived usefulness (less significant)"
      ],
      "paper_type": "based on the abstract and introduction, this paper is best classified as **empirical**.\n\nhere's why:\n\n*   **research question:** the abstract explicitly states a research question: \"what influences the adoption of generative ai tools in software engineering?\" this is a common characteristic of empirical studies.\n*   **methodology:** it details a \"convergent mixed-methods approach,\" including a \"questionnaire survey with a cohort of 100 software engineers\" and later \"data collected from 183 software engineers.\"\n*   **data analysis:** it mentions specific data analysis techniques: \"gioia methodology\" and \"partial least squares – structural equation modeling (pls-sem).\"\n*   **theoretical frameworks:** while it references theoretical frameworks (tam, doi, sct), it uses them to *frame its understanding* and *investigate* adoption, rather than solely developing new theory or proving theorems. the focus is on applying and validating these theories with real-world data.\n*   **findings/model validation:** the paper aims to develop a \"preliminary theoretical model\" and then validate it using collected data and statistical methods.\n\nthese elements strongly align with the criteria for an **empirical** paper, which focuses on data-driven studies with statistical analysis to answer research questions."
    },
    "file_name": "0e41ae9360a962430650d5bb174de223aa8deea5.pdf"
  },
  {
    "success": true,
    "doc_id": "f2b7284fd320f1a0952d72aabce6e9b5",
    "summary": "Generative artificial intelligence (AI) tools, such as Bard, ChatGPT, and CoPilot, have rapidly gained widespread usage. They also have the potential to boost software engineering productivity. In this article, we elaborate technologies and usage of generative AI in the software industry. We address questions, such as: How does generative AI improve software productivity? How to connect generative AI to software development, and what are the risks? Which technologies have what sorts of benefits? Practitioner guidance and case studies are shared from our industry context. I look forward to hearing from you about this column and the technologies that matter most for your work.—Christof Ebert",
    "intriguing_abstract": "Generative artificial intelligence (AI) tools, such as Bard, ChatGPT, and CoPilot, have rapidly gained widespread usage. They also have the potential to boost software engineering productivity. In this article, we elaborate technologies and usage of generative AI in the software industry. We address questions, such as: How does generative AI improve software productivity? How to connect generative AI to software development, and what are the risks? Which technologies have what sorts of benefits? Practitioner guidance and case studies are shared from our industry context. I look forward to hearing from you about this column and the technologies that matter most for your work.—Christof Ebert",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/eb22629ba7dd88761c39173f8abc69b589acc5cd.pdf",
    "citation_key": "ebert2023w0c",
    "metadata": {
      "title": "Generative AI for Software Practitioners",
      "authors": [
        "C. Ebert",
        "Panos Louridas",
        "C. Ebert"
      ],
      "published_date": "2023",
      "abstract": "Generative artificial intelligence (AI) tools, such as Bard, ChatGPT, and CoPilot, have rapidly gained widespread usage. They also have the potential to boost software engineering productivity. In this article, we elaborate technologies and usage of generative AI in the software industry. We address questions, such as: How does generative AI improve software productivity? How to connect generative AI to software development, and what are the risks? Which technologies have what sorts of benefits? Practitioner guidance and case studies are shared from our industry context. I look forward to hearing from you about this column and the technologies that matter most for your work.—Christof Ebert",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/eb22629ba7dd88761c39173f8abc69b589acc5cd.pdf",
      "venue": "IEEE Software",
      "citationCount": 109,
      "score": 54.5,
      "summary": "Generative artificial intelligence (AI) tools, such as Bard, ChatGPT, and CoPilot, have rapidly gained widespread usage. They also have the potential to boost software engineering productivity. In this article, we elaborate technologies and usage of generative AI in the software industry. We address questions, such as: How does generative AI improve software productivity? How to connect generative AI to software development, and what are the risks? Which technologies have what sorts of benefits? Practitioner guidance and case studies are shared from our industry context. I look forward to hearing from you about this column and the technologies that matter most for your work.—Christof Ebert",
      "keywords": []
    },
    "file_name": "eb22629ba7dd88761c39173f8abc69b589acc5cd.pdf"
  },
  {
    "success": true,
    "doc_id": "3774e56229319a0dca77d5e6f3732ad2",
    "summary": "Here is a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the underexplored usefulness of Large Language Models (LLMs) in academic software engineering projects, particularly in team-based settings \\cite{rasnayaka2024xtw}.\n    *   This problem is important because LLMs show significant promise in code generation, bug detection, and documentation, potentially bridging the gap between natural language and executable code. Understanding their practical utility, integration effort, and impact on student learning and productivity within a structured software development lifecycle is crucial for both education and industry \\cite{rasnayaka2024xtw}.\n\n*   **Related Work & Positioning**\n    *   This work is positioned as the *first empirical study* to investigate LLM usage in a team-based academic software engineering project \\cite{rasnayaka2024xtw}.\n    *   A key limitation of previous academic approaches is that most courses explicitly prohibit LLM use, preventing systematic observation and analysis of their integration into development workflows \\cite{rasnayaka2024xtw}. Existing literature lacks comprehensive insights into LLM usefulness within a full software development lifecycle in an educational context.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method**: An empirical study involving 214 undergraduate students across 37 teams in a semester-long C++ software engineering project (developing a Static Program Analyser), where LLM usage was *actively encouraged* \\cite{rasnayaka2024xtw}.\n    *   **Data Collection**:\n        *   **Code Analysis**: Automatic extraction of AI-generated code snippets, associated prompts, and a novel \"human intervention level\" metric (0: no changes, 1: minor ≤10% changes, 2: major >10% changes) from student code repositories \\cite{rasnayaka2024xtw}.\n        *   **Perception Study**: An online survey based on the Unified Theory of Acceptance and Use of Technology (UTAUT) model, augmented with personal influence factors (internship experience, workload, coding ability), and open-ended questions analyzed with VADER sentiment analysis \\cite{rasnayaka2024xtw}.\n    *   **Novelty**: The primary innovation lies in the *active encouragement* of LLM use in a structured academic project, coupled with a systematic approach to collect both quantitative (code artifacts, intervention levels) and qualitative (perceptions via UTAUT) data. The definition and measurement of \"human intervention\" for integrating AI-generated code is a practical technical contribution \\cite{rasnayaka2024xtw}.\n\n*   **Key Technical Contributions**\n    *   **Empirical Framework**: Establishment of a methodology for studying LLM integration in a realistic, team-based software engineering project, including artifact collection and perception analysis \\cite{rasnayaka2024xtw}.\n    *   **Human Intervention Metric**: Introduction of a quantifiable metric (Level 0, 1, 2) to assess the effort required to integrate AI-generated code, providing practical insights into the usability and quality of LLM outputs \\cite{rasnayaka2024xtw}.\n    *   **Dataset**: Provision of a publicly available dataset comprising AI-generated code, prompts, and survey results for further analysis by the research community \\cite{rasnayaka2024xtw}.\n\n*   **Experimental Validation**\n    *   **Participants & Context**: The study involved 214 undergraduate computer science students (37 teams) developing a C++ Static Program Analyser over 13 weeks, mimicking agile development practices \\cite{rasnayaka2024xtw}.\n    *   **LLM Usage**: 15 out of 37 teams (40.5%) used AI-generated code. ChatGPT-3.5 was the most prevalent (82.5% of snippets), followed by GitHub Copilot (9.5%) and ChatGPT-4 (8%) \\cite{rasnayaka2024xtw}.\n    *   **Usage Patterns**: LLMs were most utilized in the *early stages* of the project (Milestone 1 accounted for 53 out of 63 total snippets), primarily for generating foundational code structures, basic algorithms (e.g., DFS), data structures, and C++ syntax help \\cite{rasnayaka2024xtw}. The average lines per AI-generated snippet *increased* from MS1 (33.6 lines) to MS3 (73.29 lines), suggesting students improved their prompting skills over time \\cite{rasnayaka2024xtw}.\n    *   **Human Intervention Results**: ChatGPT-4 outputs generally required *minimal to no major changes* (Level 0 or 1 intervention) for integration. In contrast, GitHub Copilot outputs consistently required *more human intervention* (often Level 2) and tended to generate simpler code snippets \\cite{rasnayaka2024xtw}.\n    *   **Perception Study Results**: Students perceived LLMs as useful for routine tasks and improving productivity, though concerns were raised regarding potential deprivation of coding skills and impact on the software engineering job market \\cite{rasnayaka2024xtw}. The UTAUT model constructs showed robust reliability (Cronbach's Alpha > 0.7) \\cite{rasnayaka2024xtw}.\n\n*   **Limitations & Scope**\n    *   **Context Specificity**: The study was conducted in a specific academic setting (NUS, C++ SPA project) with undergraduate students, which might limit generalizability to professional environments or other programming languages/project types \\cite{rasnayaka2024xtw}.\n    *   **Self-Reported Data**: Human intervention levels and prompt usage relied on student annotations, which could introduce bias or inconsistencies \\cite{rasnayaka2024xtw}.\n    *   **LLM Versions**: The study used specific LLM versions available at the time, and performance may vary with newer models \\cite{rasnayaka2024xtw}.\n\n*   **Technical Significance**\n    *   **Advancing State-of-the-Art**: Provides crucial empirical evidence on the practical utility, integration challenges, and specific use cases of LLMs in a team-based software engineering context, moving beyond anecdotal observations \\cite{rasnayaka2024xtw}.\n    *   **Educational Implications**: Offers a data-driven framework for educators on how to effectively integrate LLMs into software engineering curricula, highlighting the necessity of preparing students for human-AI collaboration \\cite{rasnayaka2024xtw}.\n    *   **Future Research & Tool Development**: The findings on differential intervention levels for various LLMs (e.g., ChatGPT-4 requiring less intervention than Copilot) can guide future research into improving LLM output quality and prompt engineering strategies. Insights into common use cases (foundational code, syntax, debugging) can inform the development of more specialized and effective AI coding assistants \\cite{rasnayaka2024xtw}.",
    "intriguing_abstract": "The integration of Large Language Models (LLMs) into software engineering education remains largely unexplored, with most academic settings prohibiting their use. This paper presents the *first large-scale empirical study* to actively encourage and systematically analyze LLM adoption within team-based academic software projects. We investigated 214 undergraduate students across 37 teams developing a C++ Static Program Analyser over a semester. Our novel methodology automatically extracted AI-generated code snippets and introduced a quantifiable \"human intervention level\" metric (0-2) to assess integration effort, complemented by a UTAUT-based perception study.\n\nFindings reveal that 40.5% of teams leveraged LLMs, primarily ChatGPT-3.5, for foundational code and syntax help, particularly in early project stages. Crucially, ChatGPT-4 outputs consistently required minimal human intervention, contrasting with GitHub Copilot's need for more significant modifications. Students perceived LLMs as productivity enhancers for routine tasks, though concerns about skill development emerged. This work provides an empirical framework, a publicly available dataset, and critical insights for educators and researchers on fostering effective human-AI collaboration in software development, guiding future prompt engineering and AI assistant design.",
    "keywords": [
      "Large Language Models (LLMs)",
      "Academic Software Engineering Projects",
      "Empirical Study",
      "Human Intervention Level Metric",
      "AI-generated Code Integration",
      "Team-based Software Development",
      "Unified Theory of Acceptance and Use of Technology (UTAUT)",
      "LLM Usage Patterns",
      "Prompt Engineering",
      "ChatGPT-4 vs. GitHub Copilot",
      "Student Perceptions of LLMs",
      "Static Program Analyser",
      "Human-AI Collaboration"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/403cc4091b9843d475268f88c0b99081d6a397f1.pdf",
    "citation_key": "rasnayaka2024xtw",
    "metadata": {
      "title": "An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project",
      "authors": [
        "Sanka Rasnayaka",
        "Guanlin Wang",
        "Ridwan Shariffdeen",
        "Ganesh Neelakanta Iyer"
      ],
      "published_date": "2024",
      "abstract": "Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student’s perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.CCS CONCEPTS• Software and its engineering → Software development techniques; • Applied computing → Education.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/403cc4091b9843d475268f88c0b99081d6a397f1.pdf",
      "venue": "2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)",
      "citationCount": 53,
      "score": 53.0,
      "summary": "Here is a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the underexplored usefulness of Large Language Models (LLMs) in academic software engineering projects, particularly in team-based settings \\cite{rasnayaka2024xtw}.\n    *   This problem is important because LLMs show significant promise in code generation, bug detection, and documentation, potentially bridging the gap between natural language and executable code. Understanding their practical utility, integration effort, and impact on student learning and productivity within a structured software development lifecycle is crucial for both education and industry \\cite{rasnayaka2024xtw}.\n\n*   **Related Work & Positioning**\n    *   This work is positioned as the *first empirical study* to investigate LLM usage in a team-based academic software engineering project \\cite{rasnayaka2024xtw}.\n    *   A key limitation of previous academic approaches is that most courses explicitly prohibit LLM use, preventing systematic observation and analysis of their integration into development workflows \\cite{rasnayaka2024xtw}. Existing literature lacks comprehensive insights into LLM usefulness within a full software development lifecycle in an educational context.\n\n*   **Technical Approach & Innovation**\n    *   **Core Method**: An empirical study involving 214 undergraduate students across 37 teams in a semester-long C++ software engineering project (developing a Static Program Analyser), where LLM usage was *actively encouraged* \\cite{rasnayaka2024xtw}.\n    *   **Data Collection**:\n        *   **Code Analysis**: Automatic extraction of AI-generated code snippets, associated prompts, and a novel \"human intervention level\" metric (0: no changes, 1: minor ≤10% changes, 2: major >10% changes) from student code repositories \\cite{rasnayaka2024xtw}.\n        *   **Perception Study**: An online survey based on the Unified Theory of Acceptance and Use of Technology (UTAUT) model, augmented with personal influence factors (internship experience, workload, coding ability), and open-ended questions analyzed with VADER sentiment analysis \\cite{rasnayaka2024xtw}.\n    *   **Novelty**: The primary innovation lies in the *active encouragement* of LLM use in a structured academic project, coupled with a systematic approach to collect both quantitative (code artifacts, intervention levels) and qualitative (perceptions via UTAUT) data. The definition and measurement of \"human intervention\" for integrating AI-generated code is a practical technical contribution \\cite{rasnayaka2024xtw}.\n\n*   **Key Technical Contributions**\n    *   **Empirical Framework**: Establishment of a methodology for studying LLM integration in a realistic, team-based software engineering project, including artifact collection and perception analysis \\cite{rasnayaka2024xtw}.\n    *   **Human Intervention Metric**: Introduction of a quantifiable metric (Level 0, 1, 2) to assess the effort required to integrate AI-generated code, providing practical insights into the usability and quality of LLM outputs \\cite{rasnayaka2024xtw}.\n    *   **Dataset**: Provision of a publicly available dataset comprising AI-generated code, prompts, and survey results for further analysis by the research community \\cite{rasnayaka2024xtw}.\n\n*   **Experimental Validation**\n    *   **Participants & Context**: The study involved 214 undergraduate computer science students (37 teams) developing a C++ Static Program Analyser over 13 weeks, mimicking agile development practices \\cite{rasnayaka2024xtw}.\n    *   **LLM Usage**: 15 out of 37 teams (40.5%) used AI-generated code. ChatGPT-3.5 was the most prevalent (82.5% of snippets), followed by GitHub Copilot (9.5%) and ChatGPT-4 (8%) \\cite{rasnayaka2024xtw}.\n    *   **Usage Patterns**: LLMs were most utilized in the *early stages* of the project (Milestone 1 accounted for 53 out of 63 total snippets), primarily for generating foundational code structures, basic algorithms (e.g., DFS), data structures, and C++ syntax help \\cite{rasnayaka2024xtw}. The average lines per AI-generated snippet *increased* from MS1 (33.6 lines) to MS3 (73.29 lines), suggesting students improved their prompting skills over time \\cite{rasnayaka2024xtw}.\n    *   **Human Intervention Results**: ChatGPT-4 outputs generally required *minimal to no major changes* (Level 0 or 1 intervention) for integration. In contrast, GitHub Copilot outputs consistently required *more human intervention* (often Level 2) and tended to generate simpler code snippets \\cite{rasnayaka2024xtw}.\n    *   **Perception Study Results**: Students perceived LLMs as useful for routine tasks and improving productivity, though concerns were raised regarding potential deprivation of coding skills and impact on the software engineering job market \\cite{rasnayaka2024xtw}. The UTAUT model constructs showed robust reliability (Cronbach's Alpha > 0.7) \\cite{rasnayaka2024xtw}.\n\n*   **Limitations & Scope**\n    *   **Context Specificity**: The study was conducted in a specific academic setting (NUS, C++ SPA project) with undergraduate students, which might limit generalizability to professional environments or other programming languages/project types \\cite{rasnayaka2024xtw}.\n    *   **Self-Reported Data**: Human intervention levels and prompt usage relied on student annotations, which could introduce bias or inconsistencies \\cite{rasnayaka2024xtw}.\n    *   **LLM Versions**: The study used specific LLM versions available at the time, and performance may vary with newer models \\cite{rasnayaka2024xtw}.\n\n*   **Technical Significance**\n    *   **Advancing State-of-the-Art**: Provides crucial empirical evidence on the practical utility, integration challenges, and specific use cases of LLMs in a team-based software engineering context, moving beyond anecdotal observations \\cite{rasnayaka2024xtw}.\n    *   **Educational Implications**: Offers a data-driven framework for educators on how to effectively integrate LLMs into software engineering curricula, highlighting the necessity of preparing students for human-AI collaboration \\cite{rasnayaka2024xtw}.\n    *   **Future Research & Tool Development**: The findings on differential intervention levels for various LLMs (e.g., ChatGPT-4 requiring less intervention than Copilot) can guide future research into improving LLM output quality and prompt engineering strategies. Insights into common use cases (foundational code, syntax, debugging) can inform the development of more specialized and effective AI coding assistants \\cite{rasnayaka2024xtw}.",
      "keywords": [
        "Large Language Models (LLMs)",
        "Academic Software Engineering Projects",
        "Empirical Study",
        "Human Intervention Level Metric",
        "AI-generated Code Integration",
        "Team-based Software Development",
        "Unified Theory of Acceptance and Use of Technology (UTAUT)",
        "LLM Usage Patterns",
        "Prompt Engineering",
        "ChatGPT-4 vs. GitHub Copilot",
        "Student Perceptions of LLMs",
        "Static Program Analyser",
        "Human-AI Collaboration"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the **title** explicitly states: \"an **empirical study** on usage and perceptions of llms in a software engineering project\".\n*   the **abstract** mentions: \"in this **study**, we explore the usefulness of llms for 214 students...\", \"we **analyze** the ai-generated code, prompts used...\", \"we also conduct a **perception study** to gain insights...\", \"our **findings** suggest...\".\n*   the **introduction** discusses: \"we explore the possible uses of llms for software development projects in a controlled academic setting.\", \"for this purpose, we use a software engineering course with an enrolment of more than 200 students...\", \"we capture ai-generated code, the prompts used for code...\".\n\nthese elements directly align with the criteria for an **empirical** paper, which involves data-driven studies with analysis, research questions, methodology, and participants.\n\n**classification:** empirical"
    },
    "file_name": "403cc4091b9843d475268f88c0b99081d6a397f1.pdf"
  },
  {
    "success": true,
    "doc_id": "8ab912329a217e758952be56f24c0fc1",
    "summary": "Here's a focused summary of the paper \"MarsCode Agent: AI-native Automated Bug Fixing\" \\cite{liu2024uqj} for a literature review:\n\n### Technical Paper Analysis: MarsCode Agent: AI-native Automated Bug Fixing \\cite{liu2024uqj}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Automating bug fixing in real-world software systems using Large Language Models (LLMs).\n    *   **Importance & Challenge**: Bug fixing is a critical and complex aspect of software maintenance. Traditional automated program repair (APR) methods are limited in scope and adaptability. Applying LLMs is challenging due to the need for deep understanding of complex codebases, interdependencies among files, and context-specific issues, unlike simpler, self-contained coding tasks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon advancements in LLMs for software engineering tasks (code generation, program repair, fault localization) and LLM-based agent frameworks (e.g., Devin, OpenDevin, SWE-agent).\n    *   **Limitations of Previous Solutions**:\n        *   Traditional APR relies on manually crafted rules, limiting adaptability.\n        *   Existing LLM-based approaches often struggle with the complexity and scale of real-world software projects, as evidenced by low success rates on benchmarks like SWE-bench (e.g., Claude 2 achieving only 1.96%).\n        *   LLMs generally have weak code modification capabilities, struggling with precise line number calculations and context for generating unified diffs or exact replacement snippets.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: MarsCode Agent employs a novel multi-agent collaborative framework that combines LLMs with advanced code analysis techniques. It follows a systematic process of planning, bug reproduction, fault localization, candidate patch generation, and validation.\n    *   **Novelty/Differentiation**:\n        *   **Adaptive Multi-Agent Collaboration**: Unlike fixed approaches, it uses a multi-agent framework (Searcher, Planner, Reproducer, Programmer, Tester, Editor) with static or dynamic solving pipelines to adapt to diverse bug fixing scenarios (e.g., test failures, logic errors, feature extensions).\n        *   **Comprehensive Code Understanding**: Integrates Code Knowledge Graphs (CKG) and Language Server Protocols (LSP) to provide agents with human-like capabilities for code entity retrieval, relationship navigation, and definition/reference lookup across large codebases and external libraries.\n        *   **Robust Dynamic Debugging**: Leverages a containerized sandbox environment (Docker) for dynamic debugging, enabling agents to reproduce defects, add logs, and execute test frameworks.\n        *   **Accurate Code Editing**: Addresses LLM limitations in code modification by using conflict-based code edit descriptions and static syntax checking to generate well-formatted and accurate code patches.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   A multi-agent collaboration framework that dynamically allocates solving pipelines based on problem nature, enhancing flexibility and stability.\n        *   A hybrid code retrieval system combining Code Knowledge Graphs (CKG) for repository-level semantic understanding and Language Server Protocols (LSP) with fuzzy positioning for precise, global code navigation (including external libraries).\n        *   A robust dynamic debugging mechanism utilizing a containerized sandbox for defect reproduction, logging, and test execution.\n        *   A code editing strategy based on conflict-based descriptions and static syntax checking to overcome LLM limitations in generating accurate and well-formatted patches.\n    *   **System Design or Architectural Innovations**: The multi-agent architecture with specialized roles and toolsets, and the integration of a Docker-based sandbox for dynamic execution.\n    *   **Theoretical Insights or Analysis**: The paper implicitly demonstrates that by structuring the bug-fixing process into distinct agent roles and equipping them with specialized tools, LLMs can overcome their inherent limitations in handling complex, real-world software engineering tasks. The approach of generating multiple candidate solutions and voting (similar to Agentless \\cite{liu2024uqj}) for static repair scenarios highlights a strategy for improving patch quality.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: MarsCode Agent was evaluated on SWE-bench, a comprehensive benchmark of real-world software projects sourced from GitHub issues and pull requests across 12 popular Python repositories.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   Achieved a \"high success rate\" in bug fixing.\n        *   Outperformed \"most of the existing automated approaches\" and \"most of existing automated bug fixing tools\" in terms of both accuracy and efficiency. (Specific numerical results are not provided in the excerpt, but the claim of outperforming existing tools on SWE-bench, where previous models had very low success rates, is significant).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper highlights that current LLMs generally have weak code modification capabilities, which MarsCode Agent aims to mitigate through its specific code editing approach. The effectiveness relies on the quality of the LLM used within the agent framework.\n    *   **Scope of Applicability**: Primarily demonstrated on real-world software projects, specifically Python repositories as per the SWE-bench benchmark. The CKG supports 12 programming languages, suggesting broader applicability for code understanding, but the primary validation is in Python.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: MarsCode Agent represents a significant step forward in automating complex software maintenance tasks by systematically leveraging LLMs. It addresses key challenges in real-world bug fixing that previous LLM-based agents and traditional APR methods struggled with.\n    *   **Potential Impact on Future Research**: The framework's success in integrating multi-agent collaboration, advanced code analysis (CKG, LSP), robust debugging environments, and refined code editing strategies provides a strong foundation. It is expected to inspire further research and innovation in fully autonomous software maintenance, feature development, and more robust/reliable software systems.",
    "intriguing_abstract": "Automating bug fixing in complex, real-world software systems remains a formidable challenge for Large Language Models (LLMs), which often struggle with deep codebase understanding and precise code modification. We introduce MarsCode Agent, an AI-native automated bug fixing system that overcomes these limitations through a novel multi-agent collaborative framework. MarsCode Agent integrates specialized agents (e.g., Searcher, Planner, Programmer, Tester) with adaptive solving pipelines, enabling it to tackle diverse bug scenarios. Its core innovation lies in comprehensive code understanding, leveraging Code Knowledge Graphs (CKG) and Language Server Protocols (LSP) for global, semantic navigation across vast codebases and external libraries. Furthermore, it employs robust dynamic debugging within a containerized sandbox for accurate defect reproduction and validation. To address LLMs' weak code modification capabilities, MarsCode Agent utilizes conflict-based code edit descriptions and static syntax checking, ensuring precise and well-formatted patches. Evaluated on the challenging SWE-bench, MarsCode Agent achieves a high success rate, significantly outperforming existing automated program repair (APR) tools. This work marks a significant leap towards fully autonomous software engineering, paving the way for more reliable and self-maintaining software systems.",
    "keywords": [
      "AI-native Automated Bug Fixing",
      "MarsCode Agent",
      "Large Language Models (LLMs)",
      "Multi-agent collaborative framework",
      "Code Knowledge Graphs (CKG)",
      "Language Server Protocols (LSP)",
      "Robust dynamic debugging",
      "Containerized sandbox",
      "Conflict-based code edit descriptions",
      "Static syntax checking",
      "SWE-bench benchmark",
      "Real-world software systems",
      "Automated Program Repair (APR)",
      "Fault localization"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/59071b1d99b6fa15dffc45de782f634d274a2c45.pdf",
    "citation_key": "liu2024uqj",
    "metadata": {
      "title": "MarsCode Agent: AI-native Automated Bug Fixing",
      "authors": [
        "Yizhou Liu",
        "Pengfei Gao",
        "Xinchen Wang",
        "Jie Liu",
        "Yexuan Shi",
        "Zhao Zhang",
        "Chao Peng"
      ],
      "published_date": "2024",
      "abstract": "Recent advances in large language models (LLMs) have shown significant potential to automate various software development tasks, including code completion, test generation, and bug fixing. However, the application of LLMs for automated bug fixing remains challenging due to the complexity and diversity of real-world software systems. In this paper, we introduce MarsCode Agent, a novel framework that leverages LLMs to automatically identify and repair bugs in software code. MarsCode Agent combines the power of LLMs with advanced code analysis techniques to accurately localize faults and generate patches. Our approach follows a systematic process of planning, bug reproduction, fault localization, candidate patch generation, and validation to ensure high-quality bug fixes. We evaluated MarsCode Agent on SWE-bench, a comprehensive benchmark of real-world software projects, and our results show that MarsCode Agent achieves a high success rate in bug fixing compared to most of the existing automated approaches.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/59071b1d99b6fa15dffc45de782f634d274a2c45.pdf",
      "venue": "arXiv.org",
      "citationCount": 49,
      "score": 49.0,
      "summary": "Here's a focused summary of the paper \"MarsCode Agent: AI-native Automated Bug Fixing\" \\cite{liu2024uqj} for a literature review:\n\n### Technical Paper Analysis: MarsCode Agent: AI-native Automated Bug Fixing \\cite{liu2024uqj}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: Automating bug fixing in real-world software systems using Large Language Models (LLMs).\n    *   **Importance & Challenge**: Bug fixing is a critical and complex aspect of software maintenance. Traditional automated program repair (APR) methods are limited in scope and adaptability. Applying LLMs is challenging due to the need for deep understanding of complex codebases, interdependencies among files, and context-specific issues, unlike simpler, self-contained coding tasks.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon advancements in LLMs for software engineering tasks (code generation, program repair, fault localization) and LLM-based agent frameworks (e.g., Devin, OpenDevin, SWE-agent).\n    *   **Limitations of Previous Solutions**:\n        *   Traditional APR relies on manually crafted rules, limiting adaptability.\n        *   Existing LLM-based approaches often struggle with the complexity and scale of real-world software projects, as evidenced by low success rates on benchmarks like SWE-bench (e.g., Claude 2 achieving only 1.96%).\n        *   LLMs generally have weak code modification capabilities, struggling with precise line number calculations and context for generating unified diffs or exact replacement snippets.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: MarsCode Agent employs a novel multi-agent collaborative framework that combines LLMs with advanced code analysis techniques. It follows a systematic process of planning, bug reproduction, fault localization, candidate patch generation, and validation.\n    *   **Novelty/Differentiation**:\n        *   **Adaptive Multi-Agent Collaboration**: Unlike fixed approaches, it uses a multi-agent framework (Searcher, Planner, Reproducer, Programmer, Tester, Editor) with static or dynamic solving pipelines to adapt to diverse bug fixing scenarios (e.g., test failures, logic errors, feature extensions).\n        *   **Comprehensive Code Understanding**: Integrates Code Knowledge Graphs (CKG) and Language Server Protocols (LSP) to provide agents with human-like capabilities for code entity retrieval, relationship navigation, and definition/reference lookup across large codebases and external libraries.\n        *   **Robust Dynamic Debugging**: Leverages a containerized sandbox environment (Docker) for dynamic debugging, enabling agents to reproduce defects, add logs, and execute test frameworks.\n        *   **Accurate Code Editing**: Addresses LLM limitations in code modification by using conflict-based code edit descriptions and static syntax checking to generate well-formatted and accurate code patches.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   A multi-agent collaboration framework that dynamically allocates solving pipelines based on problem nature, enhancing flexibility and stability.\n        *   A hybrid code retrieval system combining Code Knowledge Graphs (CKG) for repository-level semantic understanding and Language Server Protocols (LSP) with fuzzy positioning for precise, global code navigation (including external libraries).\n        *   A robust dynamic debugging mechanism utilizing a containerized sandbox for defect reproduction, logging, and test execution.\n        *   A code editing strategy based on conflict-based descriptions and static syntax checking to overcome LLM limitations in generating accurate and well-formatted patches.\n    *   **System Design or Architectural Innovations**: The multi-agent architecture with specialized roles and toolsets, and the integration of a Docker-based sandbox for dynamic execution.\n    *   **Theoretical Insights or Analysis**: The paper implicitly demonstrates that by structuring the bug-fixing process into distinct agent roles and equipping them with specialized tools, LLMs can overcome their inherent limitations in handling complex, real-world software engineering tasks. The approach of generating multiple candidate solutions and voting (similar to Agentless \\cite{liu2024uqj}) for static repair scenarios highlights a strategy for improving patch quality.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: MarsCode Agent was evaluated on SWE-bench, a comprehensive benchmark of real-world software projects sourced from GitHub issues and pull requests across 12 popular Python repositories.\n    *   **Key Performance Metrics & Comparison Results**:\n        *   Achieved a \"high success rate\" in bug fixing.\n        *   Outperformed \"most of the existing automated approaches\" and \"most of existing automated bug fixing tools\" in terms of both accuracy and efficiency. (Specific numerical results are not provided in the excerpt, but the claim of outperforming existing tools on SWE-bench, where previous models had very low success rates, is significant).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper highlights that current LLMs generally have weak code modification capabilities, which MarsCode Agent aims to mitigate through its specific code editing approach. The effectiveness relies on the quality of the LLM used within the agent framework.\n    *   **Scope of Applicability**: Primarily demonstrated on real-world software projects, specifically Python repositories as per the SWE-bench benchmark. The CKG supports 12 programming languages, suggesting broader applicability for code understanding, but the primary validation is in Python.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: MarsCode Agent represents a significant step forward in automating complex software maintenance tasks by systematically leveraging LLMs. It addresses key challenges in real-world bug fixing that previous LLM-based agents and traditional APR methods struggled with.\n    *   **Potential Impact on Future Research**: The framework's success in integrating multi-agent collaboration, advanced code analysis (CKG, LSP), robust debugging environments, and refined code editing strategies provides a strong foundation. It is expected to inspire further research and innovation in fully autonomous software maintenance, feature development, and more robust/reliable software systems.",
      "keywords": [
        "AI-native Automated Bug Fixing",
        "MarsCode Agent",
        "Large Language Models (LLMs)",
        "Multi-agent collaborative framework",
        "Code Knowledge Graphs (CKG)",
        "Language Server Protocols (LSP)",
        "Robust dynamic debugging",
        "Containerized sandbox",
        "Conflict-based code edit descriptions",
        "Static syntax checking",
        "SWE-bench benchmark",
        "Real-world software systems",
        "Automated Program Repair (APR)",
        "Fault localization"
      ],
      "paper_type": "this paper is **technical**.\n\nhere's why:\n\n*   **abstract:** explicitly states \"we introduce marscode agent, a novel framework that leverages llms to automatically identify and repair bugs in software code.\" it then describes the \"approach\" and \"systematic process\" of this framework. the evaluation (\"we evaluated marscode agent... and our results show...\") is presented as a validation of this newly introduced framework.\n*   **introduction:** discusses the \"automation of software engineering tasks,\" the \"progress in large language models,\" and the \"challenges\" in applying llms to bug fixing. it then states, \"in this report, we introduce ma...\" (referring to marscode agent). this sets up a technical problem and proposes a new solution.\n*   **keywords from criteria:** the abstract uses \"introduce,\" \"novel framework,\" \"combines... techniques,\" \"our approach follows a systematic process.\" these align directly with the \"technical\" criteria of \"propose,\" \"develop,\" \"present,\" \"algorithm,\" \"method.\" while it also includes an empirical evaluation, the core contribution is the *creation and description* of the new system/method."
    },
    "file_name": "59071b1d99b6fa15dffc45de782f634d274a2c45.pdf"
  },
  {
    "success": true,
    "doc_id": "8cf0bf32e67f321724a79410cc8e4c86",
    "summary": "The Software Development Life Cycle (SDLC) comprises multiple phases, each requiring Subject Matter Experts (SMEs) with phase-specific skills. The efficacy and quality of deliverables of each phase are skill dependent. In recent times, Generative AI techniques, including Large-scale Language Models (LLMs) like GPT, have become significant players in software engineering. These models, trained on extensive text data, can offer valuable contributions to software development. Interacting with LLMs involves feeding prompts with the context information and guiding the generation of textual responses. The quality of the response is dependent on the quality of the prompt given. This paper proposes a systematic prompting approach based on meta-model concepts for SDLC phases. The approach is validated using ChatGPT for small but complex business application development. We share the approach and our experience, learnings, benefits obtained, and the challenges encountered while applying the approach using ChatGPT. Our experience indicates that Generative AI techniques, such as ChatGPT, have the potential to reduce the skills barrier and accelerate software development substantially.",
    "intriguing_abstract": "The Software Development Life Cycle (SDLC) comprises multiple phases, each requiring Subject Matter Experts (SMEs) with phase-specific skills. The efficacy and quality of deliverables of each phase are skill dependent. In recent times, Generative AI techniques, including Large-scale Language Models (LLMs) like GPT, have become significant players in software engineering. These models, trained on extensive text data, can offer valuable contributions to software development. Interacting with LLMs involves feeding prompts with the context information and guiding the generation of textual responses. The quality of the response is dependent on the quality of the prompt given. This paper proposes a systematic prompting approach based on meta-model concepts for SDLC phases. The approach is validated using ChatGPT for small but complex business application development. We share the approach and our experience, learnings, benefits obtained, and the challenges encountered while applying the approach using ChatGPT. Our experience indicates that Generative AI techniques, such as ChatGPT, have the potential to reduce the skills barrier and accelerate software development substantially.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/65bb41fd0575d025e2d4fcb50b7fa8c5a7e3c10e.pdf",
    "citation_key": "rajbhoj202473y",
    "metadata": {
      "title": "Accelerating Software Development Using Generative AI: ChatGPT Case Study",
      "authors": [
        "Asha Rajbhoj",
        "Akanksha Somase",
        "Piyush Kulkarni",
        "Vinay Kulkarni"
      ],
      "published_date": "2024",
      "abstract": "The Software Development Life Cycle (SDLC) comprises multiple phases, each requiring Subject Matter Experts (SMEs) with phase-specific skills. The efficacy and quality of deliverables of each phase are skill dependent. In recent times, Generative AI techniques, including Large-scale Language Models (LLMs) like GPT, have become significant players in software engineering. These models, trained on extensive text data, can offer valuable contributions to software development. Interacting with LLMs involves feeding prompts with the context information and guiding the generation of textual responses. The quality of the response is dependent on the quality of the prompt given. This paper proposes a systematic prompting approach based on meta-model concepts for SDLC phases. The approach is validated using ChatGPT for small but complex business application development. We share the approach and our experience, learnings, benefits obtained, and the challenges encountered while applying the approach using ChatGPT. Our experience indicates that Generative AI techniques, such as ChatGPT, have the potential to reduce the skills barrier and accelerate software development substantially.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/65bb41fd0575d025e2d4fcb50b7fa8c5a7e3c10e.pdf",
      "venue": "International Symposium on Electronic Commerce",
      "citationCount": 42,
      "score": 42.0,
      "summary": "The Software Development Life Cycle (SDLC) comprises multiple phases, each requiring Subject Matter Experts (SMEs) with phase-specific skills. The efficacy and quality of deliverables of each phase are skill dependent. In recent times, Generative AI techniques, including Large-scale Language Models (LLMs) like GPT, have become significant players in software engineering. These models, trained on extensive text data, can offer valuable contributions to software development. Interacting with LLMs involves feeding prompts with the context information and guiding the generation of textual responses. The quality of the response is dependent on the quality of the prompt given. This paper proposes a systematic prompting approach based on meta-model concepts for SDLC phases. The approach is validated using ChatGPT for small but complex business application development. We share the approach and our experience, learnings, benefits obtained, and the challenges encountered while applying the approach using ChatGPT. Our experience indicates that Generative AI techniques, such as ChatGPT, have the potential to reduce the skills barrier and accelerate software development substantially.",
      "keywords": []
    },
    "file_name": "65bb41fd0575d025e2d4fcb50b7fa8c5a7e3c10e.pdf"
  },
  {
    "success": true,
    "doc_id": "87346366d257fb708936f380be0cad4b",
    "summary": "The integration of artificial intelligence (AI) in developing software solutions marks a pivotal advancement in enhancing accessibility for individuals with disabilities. This paper explores the transformative potential of AI-driven technologies designed to empower those with physical, sensory, and cognitive impairments. AI's capability to learn and adapt to diverse user needs enables the creation of personalized and intuitive applications, offering unprecedented levels of independence and inclusion. AI-driven accessibility solutions encompass various innovations, including speech recognition, natural language processing (NLP), and computer vision. Speech recognition technologies facilitate communication for individuals with speech and hearing impairments by converting spoken language into text and vice versa. NLP advancements have enabled the development of sophisticated text-to-speech systems, which can read aloud text content for visually impaired users, and text prediction tools that assist users with motor impairments in typing efficiently. Furthermore, computer vision technology provides real-time image and video recognition, aiding visually impaired users in navigating their environment and identifying objects. These AI-driven tools are integrated into everyday devices and platforms, significantly enhancing their utility and accessibility. For instance, AI-powered screen readers and voice assistants are now embedded in smartphones and computers, providing seamless access to information and digital services. Educational software leveraging AI ensures that learning materials are accessible to all students, regardless of their disabilities, by providing tailored content and support. The impact of AI-driven accessibility solutions extends beyond personal empowerment to societal inclusion. By enabling greater participation in education, employment, and social activities, these technologies help bridge the gap between individuals with disabilities and their peers. Companies and organizations benefit from the diverse talents and perspectives of a more inclusive workforce, driving innovation and economic growth. However, the development and implementation of AI-driven accessibility solutions also present challenges. Ensuring data privacy and security, avoiding bias in AI algorithms, and maintaining affordability and user-friendliness are critical considerations. Ongoing research, collaboration among stakeholders, and inclusive design practices are essential to address these challenges and maximize the benefits of AI for accessibility. In conclusion, AI-driven accessibility solutions are revolutionizing the way individuals with disabilities interact with the world. By harnessing the power of AI, these technologies offer transformative opportunities for independence, inclusion, and empowerment, ultimately contributing to a more equitable and accessible society. \nKeywords: Al-Driven, Accessibility, Transformative, Disabilities, Empowering.",
    "intriguing_abstract": "The integration of artificial intelligence (AI) in developing software solutions marks a pivotal advancement in enhancing accessibility for individuals with disabilities. This paper explores the transformative potential of AI-driven technologies designed to empower those with physical, sensory, and cognitive impairments. AI's capability to learn and adapt to diverse user needs enables the creation of personalized and intuitive applications, offering unprecedented levels of independence and inclusion. AI-driven accessibility solutions encompass various innovations, including speech recognition, natural language processing (NLP), and computer vision. Speech recognition technologies facilitate communication for individuals with speech and hearing impairments by converting spoken language into text and vice versa. NLP advancements have enabled the development of sophisticated text-to-speech systems, which can read aloud text content for visually impaired users, and text prediction tools that assist users with motor impairments in typing efficiently. Furthermore, computer vision technology provides real-time image and video recognition, aiding visually impaired users in navigating their environment and identifying objects. These AI-driven tools are integrated into everyday devices and platforms, significantly enhancing their utility and accessibility. For instance, AI-powered screen readers and voice assistants are now embedded in smartphones and computers, providing seamless access to information and digital services. Educational software leveraging AI ensures that learning materials are accessible to all students, regardless of their disabilities, by providing tailored content and support. The impact of AI-driven accessibility solutions extends beyond personal empowerment to societal inclusion. By enabling greater participation in education, employment, and social activities, these technologies help bridge the gap between individuals with disabilities and their peers. Companies and organizations benefit from the diverse talents and perspectives of a more inclusive workforce, driving innovation and economic growth. However, the development and implementation of AI-driven accessibility solutions also present challenges. Ensuring data privacy and security, avoiding bias in AI algorithms, and maintaining affordability and user-friendliness are critical considerations. Ongoing research, collaboration among stakeholders, and inclusive design practices are essential to address these challenges and maximize the benefits of AI for accessibility. In conclusion, AI-driven accessibility solutions are revolutionizing the way individuals with disabilities interact with the world. By harnessing the power of AI, these technologies offer transformative opportunities for independence, inclusion, and empowerment, ultimately contributing to a more equitable and accessible society. \nKeywords: Al-Driven, Accessibility, Transformative, Disabilities, Empowering.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9471912f9e788a4b2ac1ba4e73098c04517ee9e8.pdf",
    "citation_key": "eziamaka2024zaq",
    "metadata": {
      "title": "AI-Driven accessibility: Transformative software solutions for empowering individuals with disabilities",
      "authors": [
        "Nnaemeka Valentine Eziamaka",
        "Theodore Narku Odonkor",
        "Adetola Adewale Akinsulire"
      ],
      "published_date": "2024",
      "abstract": "The integration of artificial intelligence (AI) in developing software solutions marks a pivotal advancement in enhancing accessibility for individuals with disabilities. This paper explores the transformative potential of AI-driven technologies designed to empower those with physical, sensory, and cognitive impairments. AI's capability to learn and adapt to diverse user needs enables the creation of personalized and intuitive applications, offering unprecedented levels of independence and inclusion. AI-driven accessibility solutions encompass various innovations, including speech recognition, natural language processing (NLP), and computer vision. Speech recognition technologies facilitate communication for individuals with speech and hearing impairments by converting spoken language into text and vice versa. NLP advancements have enabled the development of sophisticated text-to-speech systems, which can read aloud text content for visually impaired users, and text prediction tools that assist users with motor impairments in typing efficiently. Furthermore, computer vision technology provides real-time image and video recognition, aiding visually impaired users in navigating their environment and identifying objects. These AI-driven tools are integrated into everyday devices and platforms, significantly enhancing their utility and accessibility. For instance, AI-powered screen readers and voice assistants are now embedded in smartphones and computers, providing seamless access to information and digital services. Educational software leveraging AI ensures that learning materials are accessible to all students, regardless of their disabilities, by providing tailored content and support. The impact of AI-driven accessibility solutions extends beyond personal empowerment to societal inclusion. By enabling greater participation in education, employment, and social activities, these technologies help bridge the gap between individuals with disabilities and their peers. Companies and organizations benefit from the diverse talents and perspectives of a more inclusive workforce, driving innovation and economic growth. However, the development and implementation of AI-driven accessibility solutions also present challenges. Ensuring data privacy and security, avoiding bias in AI algorithms, and maintaining affordability and user-friendliness are critical considerations. Ongoing research, collaboration among stakeholders, and inclusive design practices are essential to address these challenges and maximize the benefits of AI for accessibility. In conclusion, AI-driven accessibility solutions are revolutionizing the way individuals with disabilities interact with the world. By harnessing the power of AI, these technologies offer transformative opportunities for independence, inclusion, and empowerment, ultimately contributing to a more equitable and accessible society. \nKeywords: Al-Driven, Accessibility, Transformative, Disabilities, Empowering.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9471912f9e788a4b2ac1ba4e73098c04517ee9e8.pdf",
      "venue": "International journal of applied research in social sciences",
      "citationCount": 36,
      "score": 36.0,
      "summary": "The integration of artificial intelligence (AI) in developing software solutions marks a pivotal advancement in enhancing accessibility for individuals with disabilities. This paper explores the transformative potential of AI-driven technologies designed to empower those with physical, sensory, and cognitive impairments. AI's capability to learn and adapt to diverse user needs enables the creation of personalized and intuitive applications, offering unprecedented levels of independence and inclusion. AI-driven accessibility solutions encompass various innovations, including speech recognition, natural language processing (NLP), and computer vision. Speech recognition technologies facilitate communication for individuals with speech and hearing impairments by converting spoken language into text and vice versa. NLP advancements have enabled the development of sophisticated text-to-speech systems, which can read aloud text content for visually impaired users, and text prediction tools that assist users with motor impairments in typing efficiently. Furthermore, computer vision technology provides real-time image and video recognition, aiding visually impaired users in navigating their environment and identifying objects. These AI-driven tools are integrated into everyday devices and platforms, significantly enhancing their utility and accessibility. For instance, AI-powered screen readers and voice assistants are now embedded in smartphones and computers, providing seamless access to information and digital services. Educational software leveraging AI ensures that learning materials are accessible to all students, regardless of their disabilities, by providing tailored content and support. The impact of AI-driven accessibility solutions extends beyond personal empowerment to societal inclusion. By enabling greater participation in education, employment, and social activities, these technologies help bridge the gap between individuals with disabilities and their peers. Companies and organizations benefit from the diverse talents and perspectives of a more inclusive workforce, driving innovation and economic growth. However, the development and implementation of AI-driven accessibility solutions also present challenges. Ensuring data privacy and security, avoiding bias in AI algorithms, and maintaining affordability and user-friendliness are critical considerations. Ongoing research, collaboration among stakeholders, and inclusive design practices are essential to address these challenges and maximize the benefits of AI for accessibility. In conclusion, AI-driven accessibility solutions are revolutionizing the way individuals with disabilities interact with the world. By harnessing the power of AI, these technologies offer transformative opportunities for independence, inclusion, and empowerment, ultimately contributing to a more equitable and accessible society. \nKeywords: Al-Driven, Accessibility, Transformative, Disabilities, Empowering.",
      "keywords": []
    },
    "file_name": "9471912f9e788a4b2ac1ba4e73098c04517ee9e8.pdf"
  },
  {
    "success": true,
    "doc_id": "dd26f1768e06b9220828258c44b05c7e",
    "summary": "This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.",
    "intriguing_abstract": "This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f51489c94d71271a98512c8b214aaa599cc0c059.pdf",
    "citation_key": "petrovska2024sf8",
    "metadata": {
      "title": "Incorporating Generative AI into Software Development Education",
      "authors": [
        "Olga Petrovska",
        "Lee Clift",
        "Faron Moller",
        "Rebecca Pearsall"
      ],
      "published_date": "2024",
      "abstract": "This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f51489c94d71271a98512c8b214aaa599cc0c059.pdf",
      "venue": "Conference on Computing Education Practice",
      "citationCount": 35,
      "score": 35.0,
      "summary": "This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.",
      "keywords": []
    },
    "file_name": "f51489c94d71271a98512c8b214aaa599cc0c059.pdf"
  },
  {
    "success": true,
    "doc_id": "ec7b207d8c448206046323e6c4a08af6",
    "summary": "Currently, explainability represents a major barrier that Artificial Intelligence (AI) is facing in regard to its practical implementation in various application domains. To combat the lack of understanding of AI-based systems, Explainable AI (XAI) aims to make black-box AI models more transparent and comprehensible for humans. Fortunately, plenty of XAI methods have been introduced to tackle the explainability problem from different perspectives. However, due to the vast search space, it is challenging for ML practitioners and data scientists to start with the development of XAI software and to optimally select the most suitable XAI methods. To tackle this challenge, we introduce XAIR, a novel systematic metareview of the most promising XAI methods and tools. XAIR differentiates itself from existing reviews by aligning its results to the five steps of the software development process, including requirement analysis, design, implementation, evaluation, and deployment. Through this mapping, we aim to create a better understanding of the individual steps of developing XAI software and to foster the creation of real-world AI applications that incorporate explainability. Finally, we conclude with highlighting new directions for future research.",
    "intriguing_abstract": "Currently, explainability represents a major barrier that Artificial Intelligence (AI) is facing in regard to its practical implementation in various application domains. To combat the lack of understanding of AI-based systems, Explainable AI (XAI) aims to make black-box AI models more transparent and comprehensible for humans. Fortunately, plenty of XAI methods have been introduced to tackle the explainability problem from different perspectives. However, due to the vast search space, it is challenging for ML practitioners and data scientists to start with the development of XAI software and to optimally select the most suitable XAI methods. To tackle this challenge, we introduce XAIR, a novel systematic metareview of the most promising XAI methods and tools. XAIR differentiates itself from existing reviews by aligning its results to the five steps of the software development process, including requirement analysis, design, implementation, evaluation, and deployment. Through this mapping, we aim to create a better understanding of the individual steps of developing XAI software and to foster the creation of real-world AI applications that incorporate explainability. Finally, we conclude with highlighting new directions for future research.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d0b6c5820ae12bb42a82f5f56de37a70c8b3b98a.pdf",
    "citation_key": "clement2023hy3",
    "metadata": {
      "title": "XAIR: A Systematic Metareview of Explainable AI (XAI) Aligned to the Software Development Process",
      "authors": [
        "Tobias Clement",
        "Nils Kemmerzell",
        "Mohamed Abdelaal",
        "M. Amberg"
      ],
      "published_date": "2023",
      "abstract": "Currently, explainability represents a major barrier that Artificial Intelligence (AI) is facing in regard to its practical implementation in various application domains. To combat the lack of understanding of AI-based systems, Explainable AI (XAI) aims to make black-box AI models more transparent and comprehensible for humans. Fortunately, plenty of XAI methods have been introduced to tackle the explainability problem from different perspectives. However, due to the vast search space, it is challenging for ML practitioners and data scientists to start with the development of XAI software and to optimally select the most suitable XAI methods. To tackle this challenge, we introduce XAIR, a novel systematic metareview of the most promising XAI methods and tools. XAIR differentiates itself from existing reviews by aligning its results to the five steps of the software development process, including requirement analysis, design, implementation, evaluation, and deployment. Through this mapping, we aim to create a better understanding of the individual steps of developing XAI software and to foster the creation of real-world AI applications that incorporate explainability. Finally, we conclude with highlighting new directions for future research.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d0b6c5820ae12bb42a82f5f56de37a70c8b3b98a.pdf",
      "venue": "Machine Learning and Knowledge Extraction",
      "citationCount": 70,
      "score": 35.0,
      "summary": "Currently, explainability represents a major barrier that Artificial Intelligence (AI) is facing in regard to its practical implementation in various application domains. To combat the lack of understanding of AI-based systems, Explainable AI (XAI) aims to make black-box AI models more transparent and comprehensible for humans. Fortunately, plenty of XAI methods have been introduced to tackle the explainability problem from different perspectives. However, due to the vast search space, it is challenging for ML practitioners and data scientists to start with the development of XAI software and to optimally select the most suitable XAI methods. To tackle this challenge, we introduce XAIR, a novel systematic metareview of the most promising XAI methods and tools. XAIR differentiates itself from existing reviews by aligning its results to the five steps of the software development process, including requirement analysis, design, implementation, evaluation, and deployment. Through this mapping, we aim to create a better understanding of the individual steps of developing XAI software and to foster the creation of real-world AI applications that incorporate explainability. Finally, we conclude with highlighting new directions for future research.",
      "keywords": []
    },
    "file_name": "d0b6c5820ae12bb42a82f5f56de37a70c8b3b98a.pdf"
  },
  {
    "success": true,
    "doc_id": "d0e6ce1252e7122868622d04fa883ac9",
    "summary": "Artificial Intelligence (AI) is revolutionizing software development practices in high-tech companies, providing transformative insights and tools that enhance productivity, quality, and efficiency. This review explores the integration of AI into software development processes, highlighting its impact on key areas such as code generation, bug detection, project management, and testing. AI-driven tools are enabling developers to automate repetitive tasks, optimize code, and identify potential issues before they become critical, thus reducing development time and improving software reliability. Machine learning algorithms analyze vast amounts of data from past projects to provide predictive analytics, guiding teams in decision-making and resource allocation. Natural language processing (NLP) facilitates more intuitive interactions with development tools, streamlining communication and collaboration among team members. Furthermore, AI enhances continuous integration and continuous deployment (CI/CD) pipelines by automating the testing and deployment stages, ensuring that code changes are seamlessly integrated and deployed with minimal human intervention. By leveraging AI, high-tech companies can adopt more agile methodologies, respond swiftly to market changes, and deliver high-quality software products. The review also discusses the challenges of integrating AI into software development, including the need for substantial initial investment, the complexity of AI models, and the importance of ensuring data privacy and security. Solutions such as fostering a culture of continuous learning, investing in AI-specific training for developers, and establishing robust data governance frameworks are essential for overcoming these barriers. In conclusion, AI-driven insights and tools offer significant advantages for high-tech companies, enabling them to enhance their software development practices, achieve greater efficiency, and maintain a competitive edge in a rapidly evolving technological landscape. Embracing these advancements requires a strategic approach, including investment in AI technologies and training, to fully harness the potential of AI and drive innovation in software development. \nKeywords: AI, Software Development, High-Tech, Practices, Companies.",
    "intriguing_abstract": "Artificial Intelligence (AI) is revolutionizing software development practices in high-tech companies, providing transformative insights and tools that enhance productivity, quality, and efficiency. This review explores the integration of AI into software development processes, highlighting its impact on key areas such as code generation, bug detection, project management, and testing. AI-driven tools are enabling developers to automate repetitive tasks, optimize code, and identify potential issues before they become critical, thus reducing development time and improving software reliability. Machine learning algorithms analyze vast amounts of data from past projects to provide predictive analytics, guiding teams in decision-making and resource allocation. Natural language processing (NLP) facilitates more intuitive interactions with development tools, streamlining communication and collaboration among team members. Furthermore, AI enhances continuous integration and continuous deployment (CI/CD) pipelines by automating the testing and deployment stages, ensuring that code changes are seamlessly integrated and deployed with minimal human intervention. By leveraging AI, high-tech companies can adopt more agile methodologies, respond swiftly to market changes, and deliver high-quality software products. The review also discusses the challenges of integrating AI into software development, including the need for substantial initial investment, the complexity of AI models, and the importance of ensuring data privacy and security. Solutions such as fostering a culture of continuous learning, investing in AI-specific training for developers, and establishing robust data governance frameworks are essential for overcoming these barriers. In conclusion, AI-driven insights and tools offer significant advantages for high-tech companies, enabling them to enhance their software development practices, achieve greater efficiency, and maintain a competitive edge in a rapidly evolving technological landscape. Embracing these advancements requires a strategic approach, including investment in AI technologies and training, to fully harness the potential of AI and drive innovation in software development. \nKeywords: AI, Software Development, High-Tech, Practices, Companies.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9866e05e0bedf3e7900901b10c588df1895f7215.pdf",
    "citation_key": "ajiga20244cu",
    "metadata": {
      "title": "Enhancing software development practices with AI insights in high-tech companies",
      "authors": [
        "Daniel Ajiga",
        "Patrick Azuka Okeleke",
        "Samuel Olaoluwa Folorunsho",
        "Chinedu Ezeigweneme"
      ],
      "published_date": "2024",
      "abstract": "Artificial Intelligence (AI) is revolutionizing software development practices in high-tech companies, providing transformative insights and tools that enhance productivity, quality, and efficiency. This review explores the integration of AI into software development processes, highlighting its impact on key areas such as code generation, bug detection, project management, and testing. AI-driven tools are enabling developers to automate repetitive tasks, optimize code, and identify potential issues before they become critical, thus reducing development time and improving software reliability. Machine learning algorithms analyze vast amounts of data from past projects to provide predictive analytics, guiding teams in decision-making and resource allocation. Natural language processing (NLP) facilitates more intuitive interactions with development tools, streamlining communication and collaboration among team members. Furthermore, AI enhances continuous integration and continuous deployment (CI/CD) pipelines by automating the testing and deployment stages, ensuring that code changes are seamlessly integrated and deployed with minimal human intervention. By leveraging AI, high-tech companies can adopt more agile methodologies, respond swiftly to market changes, and deliver high-quality software products. The review also discusses the challenges of integrating AI into software development, including the need for substantial initial investment, the complexity of AI models, and the importance of ensuring data privacy and security. Solutions such as fostering a culture of continuous learning, investing in AI-specific training for developers, and establishing robust data governance frameworks are essential for overcoming these barriers. In conclusion, AI-driven insights and tools offer significant advantages for high-tech companies, enabling them to enhance their software development practices, achieve greater efficiency, and maintain a competitive edge in a rapidly evolving technological landscape. Embracing these advancements requires a strategic approach, including investment in AI technologies and training, to fully harness the potential of AI and drive innovation in software development. \nKeywords: AI, Software Development, High-Tech, Practices, Companies.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9866e05e0bedf3e7900901b10c588df1895f7215.pdf",
      "venue": "Computer Science &amp; IT Research Journal",
      "citationCount": 34,
      "score": 34.0,
      "summary": "Artificial Intelligence (AI) is revolutionizing software development practices in high-tech companies, providing transformative insights and tools that enhance productivity, quality, and efficiency. This review explores the integration of AI into software development processes, highlighting its impact on key areas such as code generation, bug detection, project management, and testing. AI-driven tools are enabling developers to automate repetitive tasks, optimize code, and identify potential issues before they become critical, thus reducing development time and improving software reliability. Machine learning algorithms analyze vast amounts of data from past projects to provide predictive analytics, guiding teams in decision-making and resource allocation. Natural language processing (NLP) facilitates more intuitive interactions with development tools, streamlining communication and collaboration among team members. Furthermore, AI enhances continuous integration and continuous deployment (CI/CD) pipelines by automating the testing and deployment stages, ensuring that code changes are seamlessly integrated and deployed with minimal human intervention. By leveraging AI, high-tech companies can adopt more agile methodologies, respond swiftly to market changes, and deliver high-quality software products. The review also discusses the challenges of integrating AI into software development, including the need for substantial initial investment, the complexity of AI models, and the importance of ensuring data privacy and security. Solutions such as fostering a culture of continuous learning, investing in AI-specific training for developers, and establishing robust data governance frameworks are essential for overcoming these barriers. In conclusion, AI-driven insights and tools offer significant advantages for high-tech companies, enabling them to enhance their software development practices, achieve greater efficiency, and maintain a competitive edge in a rapidly evolving technological landscape. Embracing these advancements requires a strategic approach, including investment in AI technologies and training, to fully harness the potential of AI and drive innovation in software development. \nKeywords: AI, Software Development, High-Tech, Practices, Companies.",
      "keywords": []
    },
    "file_name": "9866e05e0bedf3e7900901b10c588df1895f7215.pdf"
  },
  {
    "success": true,
    "doc_id": "e4514f609dcb4a496d2cdb40f57aa99d",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8d10846e0fdc84c13bb09bea1097449b15da741d.pdf",
    "citation_key": "kuhail20243am",
    "metadata": {
      "title": "\"Will I be replaced?\" Assessing ChatGPT's effect on software development and programmer perceptions of AI tools",
      "authors": [
        "M. Kuhail",
        "S. Mathew",
        "Ashraf Khalil",
        "Jose Berengueres",
        "Syed Jawad Hussain Shah"
      ],
      "published_date": "2024",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8d10846e0fdc84c13bb09bea1097449b15da741d.pdf",
      "venue": "Science of Computer Programming",
      "citationCount": 32,
      "score": 32.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "8d10846e0fdc84c13bb09bea1097449b15da741d.pdf"
  },
  {
    "success": true,
    "doc_id": "25f71d86e5e6695bb2e8e7fa37d92da5",
    "summary": "The increasing demand for energy efficiency and sustainability in the industrial sector has spurred the development of innovative software solutions for effective energy management systems (EMS). This review explores the key advancements and applications of these solutions in enhancing energy management practices. Modern EMS software leverages cutting-edge technologies such as artificial intelligence (AI), machine learning, and the Internet of Things (IoT) to optimize energy consumption, reduce operational costs, and minimize environmental impact. By integrating real-time data from various sensors and devices, these systems provide comprehensive insights into energy usage patterns, enabling industries to identify inefficiencies and implement corrective measures promptly. AI-driven predictive analytics play a crucial role in forecasting energy demand and optimizing energy distribution across industrial processes. Machine learning algorithms analyze historical and real-time data to predict peak usage periods, allowing for proactive energy load management and reducing the risk of energy wastage. Additionally, IoT-enabled devices facilitate seamless communication between different components of the energy management infrastructure, ensuring accurate data collection and real-time monitoring. One significant innovation in EMS software is the development of user-friendly interfaces and dashboards that present complex energy data in an accessible format. These interfaces enable facility managers and operators to make informed decisions quickly, enhancing their ability to manage energy consumption efficiently. Moreover, advanced EMS solutions offer automated control features that adjust energy usage dynamically based on predefined parameters and real-time conditions, further streamlining energy management processes. Case studies from various industries, such as manufacturing, logistics, and data centers, demonstrate the tangible benefits of implementing innovative EMS software. These benefits include significant reductions in energy costs, improved regulatory compliance, and enhanced sustainability performance. For instance, a manufacturing plant utilizing AI-powered EMS software reported a 15% decrease in energy consumption within the first year of implementation, highlighting the potential for substantial energy savings. In conclusion, developing innovative software solutions for effective energy management systems is crucial for industries aiming to achieve energy efficiency and sustainability goals. By harnessing the power of AI, machine learning, and IoT, these solutions provide actionable insights, automate energy control, and promote sustainable practices. Continued research and development in this field will further enhance the capabilities of EMS software, driving progress toward a more energy-efficient industrial sector. \nKeywords: Industry, Software Solutions, Innovative, Effective, Energy Management System.",
    "intriguing_abstract": "The increasing demand for energy efficiency and sustainability in the industrial sector has spurred the development of innovative software solutions for effective energy management systems (EMS). This review explores the key advancements and applications of these solutions in enhancing energy management practices. Modern EMS software leverages cutting-edge technologies such as artificial intelligence (AI), machine learning, and the Internet of Things (IoT) to optimize energy consumption, reduce operational costs, and minimize environmental impact. By integrating real-time data from various sensors and devices, these systems provide comprehensive insights into energy usage patterns, enabling industries to identify inefficiencies and implement corrective measures promptly. AI-driven predictive analytics play a crucial role in forecasting energy demand and optimizing energy distribution across industrial processes. Machine learning algorithms analyze historical and real-time data to predict peak usage periods, allowing for proactive energy load management and reducing the risk of energy wastage. Additionally, IoT-enabled devices facilitate seamless communication between different components of the energy management infrastructure, ensuring accurate data collection and real-time monitoring. One significant innovation in EMS software is the development of user-friendly interfaces and dashboards that present complex energy data in an accessible format. These interfaces enable facility managers and operators to make informed decisions quickly, enhancing their ability to manage energy consumption efficiently. Moreover, advanced EMS solutions offer automated control features that adjust energy usage dynamically based on predefined parameters and real-time conditions, further streamlining energy management processes. Case studies from various industries, such as manufacturing, logistics, and data centers, demonstrate the tangible benefits of implementing innovative EMS software. These benefits include significant reductions in energy costs, improved regulatory compliance, and enhanced sustainability performance. For instance, a manufacturing plant utilizing AI-powered EMS software reported a 15% decrease in energy consumption within the first year of implementation, highlighting the potential for substantial energy savings. In conclusion, developing innovative software solutions for effective energy management systems is crucial for industries aiming to achieve energy efficiency and sustainability goals. By harnessing the power of AI, machine learning, and IoT, these solutions provide actionable insights, automate energy control, and promote sustainable practices. Continued research and development in this field will further enhance the capabilities of EMS software, driving progress toward a more energy-efficient industrial sector. \nKeywords: Industry, Software Solutions, Innovative, Effective, Energy Management System.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d889ca54563c3ddb7ca184895107c7eb1f3fe312.pdf",
    "citation_key": "segunfalade2024ygj",
    "metadata": {
      "title": "Developing innovative software solutions for effective energy management systems in industry",
      "authors": [
        "Osinachi Deborah Segun-Falade",
        "Olajide Soji Osundare",
        "Wagobera Edgar Kedi",
        "Patrick Azuka Okeleke",
        "Tochukwu Ignatius Ijomah",
        "Oluwatosin Yetunde Abdul-Azeez"
      ],
      "published_date": "2024",
      "abstract": "The increasing demand for energy efficiency and sustainability in the industrial sector has spurred the development of innovative software solutions for effective energy management systems (EMS). This review explores the key advancements and applications of these solutions in enhancing energy management practices. Modern EMS software leverages cutting-edge technologies such as artificial intelligence (AI), machine learning, and the Internet of Things (IoT) to optimize energy consumption, reduce operational costs, and minimize environmental impact. By integrating real-time data from various sensors and devices, these systems provide comprehensive insights into energy usage patterns, enabling industries to identify inefficiencies and implement corrective measures promptly. AI-driven predictive analytics play a crucial role in forecasting energy demand and optimizing energy distribution across industrial processes. Machine learning algorithms analyze historical and real-time data to predict peak usage periods, allowing for proactive energy load management and reducing the risk of energy wastage. Additionally, IoT-enabled devices facilitate seamless communication between different components of the energy management infrastructure, ensuring accurate data collection and real-time monitoring. One significant innovation in EMS software is the development of user-friendly interfaces and dashboards that present complex energy data in an accessible format. These interfaces enable facility managers and operators to make informed decisions quickly, enhancing their ability to manage energy consumption efficiently. Moreover, advanced EMS solutions offer automated control features that adjust energy usage dynamically based on predefined parameters and real-time conditions, further streamlining energy management processes. Case studies from various industries, such as manufacturing, logistics, and data centers, demonstrate the tangible benefits of implementing innovative EMS software. These benefits include significant reductions in energy costs, improved regulatory compliance, and enhanced sustainability performance. For instance, a manufacturing plant utilizing AI-powered EMS software reported a 15% decrease in energy consumption within the first year of implementation, highlighting the potential for substantial energy savings. In conclusion, developing innovative software solutions for effective energy management systems is crucial for industries aiming to achieve energy efficiency and sustainability goals. By harnessing the power of AI, machine learning, and IoT, these solutions provide actionable insights, automate energy control, and promote sustainable practices. Continued research and development in this field will further enhance the capabilities of EMS software, driving progress toward a more energy-efficient industrial sector. \nKeywords: Industry, Software Solutions, Innovative, Effective, Energy Management System.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d889ca54563c3ddb7ca184895107c7eb1f3fe312.pdf",
      "venue": "Engineering Science &amp; Technology Journal",
      "citationCount": 32,
      "score": 32.0,
      "summary": "The increasing demand for energy efficiency and sustainability in the industrial sector has spurred the development of innovative software solutions for effective energy management systems (EMS). This review explores the key advancements and applications of these solutions in enhancing energy management practices. Modern EMS software leverages cutting-edge technologies such as artificial intelligence (AI), machine learning, and the Internet of Things (IoT) to optimize energy consumption, reduce operational costs, and minimize environmental impact. By integrating real-time data from various sensors and devices, these systems provide comprehensive insights into energy usage patterns, enabling industries to identify inefficiencies and implement corrective measures promptly. AI-driven predictive analytics play a crucial role in forecasting energy demand and optimizing energy distribution across industrial processes. Machine learning algorithms analyze historical and real-time data to predict peak usage periods, allowing for proactive energy load management and reducing the risk of energy wastage. Additionally, IoT-enabled devices facilitate seamless communication between different components of the energy management infrastructure, ensuring accurate data collection and real-time monitoring. One significant innovation in EMS software is the development of user-friendly interfaces and dashboards that present complex energy data in an accessible format. These interfaces enable facility managers and operators to make informed decisions quickly, enhancing their ability to manage energy consumption efficiently. Moreover, advanced EMS solutions offer automated control features that adjust energy usage dynamically based on predefined parameters and real-time conditions, further streamlining energy management processes. Case studies from various industries, such as manufacturing, logistics, and data centers, demonstrate the tangible benefits of implementing innovative EMS software. These benefits include significant reductions in energy costs, improved regulatory compliance, and enhanced sustainability performance. For instance, a manufacturing plant utilizing AI-powered EMS software reported a 15% decrease in energy consumption within the first year of implementation, highlighting the potential for substantial energy savings. In conclusion, developing innovative software solutions for effective energy management systems is crucial for industries aiming to achieve energy efficiency and sustainability goals. By harnessing the power of AI, machine learning, and IoT, these solutions provide actionable insights, automate energy control, and promote sustainable practices. Continued research and development in this field will further enhance the capabilities of EMS software, driving progress toward a more energy-efficient industrial sector. \nKeywords: Industry, Software Solutions, Innovative, Effective, Energy Management System.",
      "keywords": []
    },
    "file_name": "d889ca54563c3ddb7ca184895107c7eb1f3fe312.pdf"
  },
  {
    "success": true,
    "doc_id": "eb01640276bafee47c52e4856f283fb9",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{klemmer20246zk}\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem**: The paper investigates how software professionals balance the use of AI assistants (like ChatGPT, GitHub Copilot) with security considerations in software development.\n    *   **Importance and challenge**: While AI-generated code is known to contain security vulnerabilities, it is unclear how developers perceive these risks, integrate AI assistants into secure development practices, and scrutinize AI suggestions. Understanding these human factors is crucial to prevent AI assistants from weakening software security.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches**: Prior research has demonstrated that AI assistants can generate vulnerable code (e.g., 40% in some cases) and introduce security bugs, with some studies showing developers produce less secure code when using them. Other work highlights issues like AI package hallucinations.\n    *   **Limitations of previous solutions**: Existing studies primarily focus on the *shortcomings* of AI assistants in generating secure code or their impact on code quality. They do not explore the *considerations, perceptions, and human factors* of software professionals when using these tools, nor do they extensively cover general-purpose AI assistants beyond code generation. This paper aims to fill this gap by qualitatively exploring user behavior and scrutiny. The paper also positions AI assistants as a new source of advice, similar to Stack Overflow, which is known to contain insecure suggestions.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method/algorithm**: The paper employs a qualitative research methodology.\n        *   **Semi-structured interviews**: Conducted 27 interviews with software professionals (software engineers, team leads, security testers) to gather in-depth insights into their experiences, usage patterns, security concerns, and future expectations regarding AI assistants.\n        *   **Reddit discourse analysis**: Reviewed 190 relevant Reddit posts and comments, qualitatively analyzing 68 threads and 122 comments to complement interview findings with broader community discourse.\n    *   **Novelty/difference**: This approach is novel in providing the *first qualitative insights* into how software professionals *consider security* when using AI assistants, moving beyond quantitative assessments of AI-generated code vulnerabilities. It also covers general-purpose AI assistants, not just code-specific ones.\n\n4.  **Key Technical Contributions**\n    *   **Qualitative Insights**: Presents the first qualitative insights into software professionals' security practices and concerns when using AI assistants.\n        *   Participants generally mistrust the security of AI suggestions due to overall quality concerns.\n        *   Despite mistrust, AI assistants are widely used for security-critical tasks (e.g., code generation, threat modeling, vulnerability detection), often replacing traditional advice sources like Google and Stack Overflow.\n        *   Participants critically review AI suggestions, similar to how they would review human-written code.\n        *   There is an expectation for heavier future adoption of AI assistants for security tasks if their quality improves.\n    *   **Recommendations**: Provides actionable recommendations for various stakeholders:\n        *   **Software professionals**: Maintain skepticism and critically check all AI suggestions (e.g., through peer reviewing, testing).\n        *   **AI creators**: Improve the security of AI suggestions and ensure reasonable ethical safeguards for security-related tasks.\n        *   **Academic researchers**: Broaden research focus beyond AI code assistants to include general-purpose AI assistants and their use in software development.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted**:\n        *   27 semi-structured interviews with a diverse sample of software professionals (average 14.6 years experience, high self-efficacy in secure software development).\n        *   Qualitative analysis of 190 Reddit posts/comments, focusing on 68 threads and 122 comments related to AI in software development and security.\n    *   **Key performance metrics and comparison results**:\n        *   The qualitative analysis revealed a consistent theme of mistrust in AI security but widespread usage for security-critical tasks.\n        *   Participants' scrutiny of AI suggestions mirrors that of human-generated code.\n        *   The Reddit analysis largely confirmed the findings from the interviews, indicating a broader community sentiment.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations/assumptions**: As a qualitative study, the findings are based on self-reported experiences and perceptions, which may not always align with actual behavior. The sample size of 27 interviews, while substantial for qualitative research, may not be fully representative of the entire software development industry.\n    *   **Scope of applicability**: The study focuses on software professionals' experiences with AI assistants in the context of security. It covers both code-specific and general-purpose AI assistants. The findings are applicable to understanding human-AI interaction in secure software development.\n\n7.  **Technical Significance**\n    *   **Advancement of state-of-the-art**: This paper significantly advances the understanding of the human element in the adoption and secure use of AI assistants in software development. It shifts the focus from merely identifying AI-generated vulnerabilities to understanding how developers *interact* with and *mitigate* these risks.\n    *   **Potential impact on future research**: The study highlights critical areas for future research, including improving AI suggestion security, developing ethical guidelines for AI in security tasks, and expanding research to general-purpose AI assistants. It also underscores the need for tools and training that help developers effectively scrutinize AI-generated content for security flaws.",
    "intriguing_abstract": "AI assistants are rapidly transforming software development, yet their propensity to generate vulnerable code poses a significant security challenge. While prior research quantifies AI-introduced vulnerabilities, the critical human element—how software professionals *actually* integrate these tools into secure practices and scrutinize AI suggestions—remains largely unexplored. This paper addresses this crucial gap, presenting the first qualitative investigation into developers' security considerations when leveraging AI assistants like ChatGPT and GitHub Copilot.\n\nThrough 27 semi-structured interviews with software professionals and an extensive analysis of 190 Reddit discussions, we unveil a compelling paradox: despite widespread mistrust in AI's security capabilities, these tools are extensively adopted for security-critical tasks, including code generation, threat modeling, and vulnerability detection, often replacing traditional advice sources. Our findings illuminate that developers apply rigorous scrutiny to AI-generated content, mirroring their review of human-written code. We provide actionable recommendations for professionals, AI creators, and researchers, emphasizing the imperative for enhanced AI security, ethical safeguards, and continued critical engagement. This work is pivotal for safeguarding software security in the AI era, guiding future research and development towards more secure human-AI collaboration.",
    "keywords": [
      "AI assistants",
      "software security",
      "security vulnerabilities",
      "qualitative research methodology",
      "semi-structured interviews",
      "Reddit discourse analysis",
      "human factors in AI security",
      "developer perceptions",
      "AI-generated code",
      "security-critical tasks",
      "mistrust in AI suggestions",
      "critical review of AI suggestions",
      "general-purpose AI assistants",
      "secure development practices"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a78b0eb79ddc4b17ac16b4b599e7ee8aca12036d.pdf",
    "citation_key": "klemmer20246zk",
    "metadata": {
      "title": "Using AI Assistants in Software Development: A Qualitative Study on Security Practices and Concerns",
      "authors": [
        "J. Klemmer",
        "Stefan Albert Horstmann",
        "Nikhil Patnaik",
        "Cordelia Ludden",
        "Cordell Burton",
        "Carson Powers",
        "Fabio Massacci",
        "Akond Rahman",
        "Daniel Votipka",
        "H. Lipford",
        "Awais Rashid",
        "Alena Naiakshina",
        "Sascha Fahl Cispa Helmholtz Center for Information Security",
        "R. Bochum",
        "U. Bristol",
        "Tufts University",
        "V. U. Amsterdam",
        "U. Trento",
        "Auburn University",
        "University of North Carolina at Charlotte"
      ],
      "published_date": "2024",
      "abstract": "Following the recent release of AI assistants, such as OpenAI's ChatGPT and GitHub Copilot, the software industry quickly utilized these tools for software development tasks, e.g., generating code or consulting AI for advice. While recent research has demonstrated that AI-generated code can contain security issues, how software professionals balance AI assistant usage and security remains unclear. This paper investigates how software professionals use AI assistants in secure software development, what security implications and considerations arise, and what impact they foresee on security in software development. We conducted 27 semi-structured interviews with software professionals, including software engineers, team leads, and security testers. We also reviewed 190 relevant Reddit posts and comments to gain insights into the current discourse surrounding AI assistants for software development. Our analysis of the interviews and Reddit posts finds that, despite many security and quality concerns, participants widely use AI assistants for security-critical tasks, e.g., code generation, threat modeling, and vulnerability detection. Participants' overall mistrust leads to checking AI suggestions in similar ways to human code. However, they expect improvements and, therefore, a heavier use of AI for security tasks in the future. We conclude with recommendations for software professionals to critically check AI suggestions, for AI creators to improve suggestion security and capabilities for ethical security tasks, and for academic researchers to consider general-purpose AI in software development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a78b0eb79ddc4b17ac16b4b599e7ee8aca12036d.pdf",
      "venue": "Conference on Computer and Communications Security",
      "citationCount": 28,
      "score": 28.0,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **CITATION**: \\cite{klemmer20246zk}\n\n1.  **Research Problem & Motivation**\n    *   **Specific technical problem**: The paper investigates how software professionals balance the use of AI assistants (like ChatGPT, GitHub Copilot) with security considerations in software development.\n    *   **Importance and challenge**: While AI-generated code is known to contain security vulnerabilities, it is unclear how developers perceive these risks, integrate AI assistants into secure development practices, and scrutinize AI suggestions. Understanding these human factors is crucial to prevent AI assistants from weakening software security.\n\n2.  **Related Work & Positioning**\n    *   **Relation to existing approaches**: Prior research has demonstrated that AI assistants can generate vulnerable code (e.g., 40% in some cases) and introduce security bugs, with some studies showing developers produce less secure code when using them. Other work highlights issues like AI package hallucinations.\n    *   **Limitations of previous solutions**: Existing studies primarily focus on the *shortcomings* of AI assistants in generating secure code or their impact on code quality. They do not explore the *considerations, perceptions, and human factors* of software professionals when using these tools, nor do they extensively cover general-purpose AI assistants beyond code generation. This paper aims to fill this gap by qualitatively exploring user behavior and scrutiny. The paper also positions AI assistants as a new source of advice, similar to Stack Overflow, which is known to contain insecure suggestions.\n\n3.  **Technical Approach & Innovation**\n    *   **Core technical method/algorithm**: The paper employs a qualitative research methodology.\n        *   **Semi-structured interviews**: Conducted 27 interviews with software professionals (software engineers, team leads, security testers) to gather in-depth insights into their experiences, usage patterns, security concerns, and future expectations regarding AI assistants.\n        *   **Reddit discourse analysis**: Reviewed 190 relevant Reddit posts and comments, qualitatively analyzing 68 threads and 122 comments to complement interview findings with broader community discourse.\n    *   **Novelty/difference**: This approach is novel in providing the *first qualitative insights* into how software professionals *consider security* when using AI assistants, moving beyond quantitative assessments of AI-generated code vulnerabilities. It also covers general-purpose AI assistants, not just code-specific ones.\n\n4.  **Key Technical Contributions**\n    *   **Qualitative Insights**: Presents the first qualitative insights into software professionals' security practices and concerns when using AI assistants.\n        *   Participants generally mistrust the security of AI suggestions due to overall quality concerns.\n        *   Despite mistrust, AI assistants are widely used for security-critical tasks (e.g., code generation, threat modeling, vulnerability detection), often replacing traditional advice sources like Google and Stack Overflow.\n        *   Participants critically review AI suggestions, similar to how they would review human-written code.\n        *   There is an expectation for heavier future adoption of AI assistants for security tasks if their quality improves.\n    *   **Recommendations**: Provides actionable recommendations for various stakeholders:\n        *   **Software professionals**: Maintain skepticism and critically check all AI suggestions (e.g., through peer reviewing, testing).\n        *   **AI creators**: Improve the security of AI suggestions and ensure reasonable ethical safeguards for security-related tasks.\n        *   **Academic researchers**: Broaden research focus beyond AI code assistants to include general-purpose AI assistants and their use in software development.\n\n5.  **Experimental Validation**\n    *   **Experiments conducted**:\n        *   27 semi-structured interviews with a diverse sample of software professionals (average 14.6 years experience, high self-efficacy in secure software development).\n        *   Qualitative analysis of 190 Reddit posts/comments, focusing on 68 threads and 122 comments related to AI in software development and security.\n    *   **Key performance metrics and comparison results**:\n        *   The qualitative analysis revealed a consistent theme of mistrust in AI security but widespread usage for security-critical tasks.\n        *   Participants' scrutiny of AI suggestions mirrors that of human-generated code.\n        *   The Reddit analysis largely confirmed the findings from the interviews, indicating a broader community sentiment.\n\n6.  **Limitations & Scope**\n    *   **Technical limitations/assumptions**: As a qualitative study, the findings are based on self-reported experiences and perceptions, which may not always align with actual behavior. The sample size of 27 interviews, while substantial for qualitative research, may not be fully representative of the entire software development industry.\n    *   **Scope of applicability**: The study focuses on software professionals' experiences with AI assistants in the context of security. It covers both code-specific and general-purpose AI assistants. The findings are applicable to understanding human-AI interaction in secure software development.\n\n7.  **Technical Significance**\n    *   **Advancement of state-of-the-art**: This paper significantly advances the understanding of the human element in the adoption and secure use of AI assistants in software development. It shifts the focus from merely identifying AI-generated vulnerabilities to understanding how developers *interact* with and *mitigate* these risks.\n    *   **Potential impact on future research**: The study highlights critical areas for future research, including improving AI suggestion security, developing ethical guidelines for AI in security tasks, and expanding research to general-purpose AI assistants. It also underscores the need for tools and training that help developers effectively scrutinize AI-generated content for security flaws.",
      "keywords": [
        "AI assistants",
        "software security",
        "security vulnerabilities",
        "qualitative research methodology",
        "semi-structured interviews",
        "Reddit discourse analysis",
        "human factors in AI security",
        "developer perceptions",
        "AI-generated code",
        "security-critical tasks",
        "mistrust in AI suggestions",
        "critical review of AI suggestions",
        "general-purpose AI assistants",
        "secure development practices"
      ],
      "paper_type": "based on the abstract and introduction, this paper is an **empirical** study.\n\nhere's why:\n\n*   **abstract mentions:**\n    *   \"this paper investigates how software professionals use ai assistants...\" (indicates a study)\n    *   \"we conducted 27 semi-structured interviews with software professionals...\" (describes data collection methodology)\n    *   \"we also reviewed 190 relevant reddit posts and comments...\" (describes additional data collection)\n    *   \"our analysis of the interviews and reddit posts finds that...\" (mentions data analysis and findings)\n    *   \"qualitative study\" is explicitly mentioned in the keywords.\n*   **introduction discusses:**\n    *   the context and problem (security implications of ai assistants in software development).\n    *   the widespread adoption of ai tools, setting the stage for a data-driven investigation into current practices.\n    *   the abstract clearly outlines research questions, methodology, and findings, which are hallmarks of an empirical paper."
    },
    "file_name": "a78b0eb79ddc4b17ac16b4b599e7ee8aca12036d.pdf"
  },
  {
    "success": true,
    "doc_id": "5397dbf079efdade901ae4b1ca5406fd",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Problem**: The paper addresses the lack of empirical evidence regarding the impact of generative AI tools on software development productivity, especially in complex, real-world industrial settings \\cite{coutinho20245vb}.\n    *   **Importance & Challenge**: Understanding productivity in software development is inherently challenging due to its multifaceted nature, influenced by technical, social, and psychological factors, and the absence of universally accepted metrics \\cite{coutinho20245vb}. While there's a general belief in generative AI's potential benefits, empirical validation beyond simple task completion times is scarce, particularly in diverse roles and complex projects \\cite{coutinho20245vb}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous studies have explored teamwork, collaboration, and tool adoption in software engineering, and more recently, the potential of generative AI for automated code generation and task automation \\cite{coutinho20245vb}.\n    *   **Limitations of Previous Solutions**: Existing research often focuses on task completion time as the primary productivity metric, which inadequately captures the complex factors influencing software development productivity \\cite{coutinho20245vb}. There's a gap in comprehensive investigations that detail the application of generative AI across the entire software creation process in real-world industrial contexts, considering broader productivity dimensions like satisfaction, performance, activity, communication, collaboration, efficiency, and flow \\cite{coutinho20245vb}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper employs a pilot case study methodology to investigate the integration of existing generative AI tools (ChatGPT Plus, OpenAI API, Midjourney, GitHub Copilot) into the daily work routines of software professionals \\cite{coutinho20245vb}. It focuses on gathering qualitative insights into their uses, benefits, and challenges, particularly concerning perceived productivity.\n    *   **Novelty/Difference**: The innovation lies in its empirical, qualitative approach within a large, diverse software company, aiming to understand the nuanced characteristics of productivity in a real-world industrial context, rather than proposing a new AI model or algorithm. This moves beyond laboratory settings and simple coding tasks to encompass various roles and activities across the software development lifecycle \\cite{coutinho20245vb}.\n\n4.  **Key Technical Contributions**\n    *   **Empirical Study Design**: Development and execution of a pilot case study framework for assessing the real-world impact of generative AI tools on software development productivity across diverse professional roles (engineers, designers, data scientists, QA, agile coaches) in an industrial setting \\cite{coutinho20245vb}.\n    *   **Qualitative Data Collection & Analysis**: Utilization of a structured questionnaire with open-ended questions and observations to gather rich, descriptive data on perceived productivity, benefits, and challenges, enabling a more nuanced understanding than purely quantitative metrics \\cite{coutinho20245vb}.\n    *   **Initial Empirical Insights**: Provision of preliminary findings on how generative AI tools are being integrated and perceived by professionals in a complex organizational environment, setting the groundwork for more extensive investigations into productivity facets \\cite{coutinho20245vb}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: A pilot case study was conducted over four weeks involving 13 software professionals from a large software company specializing in on-demand solutions across various sectors \\cite{coutinho20245vb}. Participants were provided licenses for generative AI tools (ChatGPT Plus, OpenAI API, Midjourney, GitHub Copilot) and asked to integrate them into their work.\n    *   **Key Performance Metrics & Comparison Results**: Validation was primarily qualitative. Data was collected through questionnaires with open-ended questions focusing on:\n        *   Summary of activities performed with AI tools.\n        *   Details of working experience with the tools.\n        *   Main benefits encountered.\n        *   Observed impact on productivity.\n        *   Contribution to enhancing activity value.\n        *   Satisfaction with results.\n        *   Willingness to continue using AI.\n        *   Other important aspects of experience \\cite{coutinho20245vb}.\n        *   **Results (Preliminary)**: Findings revealed a generally positive perception of these tools in individual productivity, while also highlighting identified limitations. Specific detailed results are not fully elaborated in the provided abstract/introduction/methodology sections but are stated to be discussed in Section 5 of the full paper \\cite{coutinho20245vb}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study is a *pilot* case study, meaning its findings are preliminary and intended to guide future, broader investigations \\cite{coutinho20245vb}. The use of tools was voluntary and not consistently integrated into daily work for all participants, potentially affecting the depth of experience captured \\cite{coutinho20245vb}. The reliance on questionnaires rather than interviews might limit the richness of qualitative data compared to more interactive methods \\cite{coutinho20245vb}.\n    *   **Scope of Applicability**: The study focuses on a single large software company and a relatively small sample size (13 participants), which may limit the generalizability of the findings to other organizational contexts or smaller teams \\cite{coutinho20245vb}. It primarily captures *perceived* productivity and initial experiences.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper contributes by providing much-needed initial empirical evidence from a real-world industrial setting on the integration and impact of generative AI tools on software development productivity \\cite{coutinho20245vb}. It addresses a critical gap in the literature by moving beyond theoretical discussions and laboratory experiments to explore the practical implications across diverse roles and complex tasks.\n    *   **Potential Impact on Future Research**: The research sets the stage for further, more comprehensive, and longitudinal explorations into the evolving landscape of software development practices with generative AI \\cite{coutinho20245vb}. It highlights the need for broader productivity metrics and provides a methodological foundation for future studies to investigate the nuanced characteristics of productivity in this context.",
    "intriguing_abstract": "The advent of generative AI promises to revolutionize software development, yet robust empirical evidence on its real-world impact on productivity remains critically scarce, particularly beyond isolated tasks and laboratory settings. This paper addresses this significant gap by presenting a pioneering **qualitative pilot case study** investigating the integration of leading **generative AI tools** (e.g., **ChatGPT Plus, GitHub Copilot**) into the daily routines of diverse **software professionals** within a large industrial company.\n\nMoving beyond simplistic metrics, we explore *perceived productivity*, benefits, and challenges across various roles, from engineers to designers and data scientists. Our novel approach provides initial, much-needed **empirical insights** into how these tools are genuinely transforming the complex **software development lifecycle**. The findings reveal generally positive perceptions regarding individual productivity, alongside identified limitations, offering a nuanced understanding of **human-AI collaboration**. This study not only bridges a crucial empirical void in **software engineering** research but also establishes a foundational framework for future comprehensive investigations into the multifaceted nature of **generative AI's impact on productivity** in real-world industrial contexts.",
    "keywords": [
      "Generative AI tools",
      "software development productivity",
      "real-world industrial settings",
      "pilot case study",
      "qualitative research methodology",
      "perceived productivity",
      "diverse professional roles",
      "empirical evidence",
      "software development lifecycle",
      "nuanced productivity metrics",
      "AI integration challenges",
      "code generation",
      "task automation"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/5e16600a03b824911557e78f7d5521d5c3339cd9.pdf",
    "citation_key": "coutinho20245vb",
    "metadata": {
      "title": "The Role of Generative AI in Software Development Productivity: A Pilot Case Study",
      "authors": [
        "Mariana Coutinho",
        "Lorena Marques",
        "Anderson Santos",
        "Marcio Dahia",
        "César França",
        "Ronnie de Souza Santos"
      ],
      "published_date": "2024",
      "abstract": "With software development increasingly reliant on innovative technologies, there is a growing interest in exploring the potential of generative AI tools to streamline processes and enhance productivity. In this scenario, this paper investigates the integration of generative AI tools within software development, focusing on understanding their uses, benefits, and challenges to software professionals, in particular, looking at aspects of productivity. Through a pilot case study involving software practitioners working in different roles, we gathered valuable experiences on the integration of generative AI tools into their daily work routines. Our findings reveal a generally positive perception of these tools in individual productivity while also highlighting the need to address identified limitations. Overall, our research sets the stage for further exploration into the evolving landscape of software development practices with the integration of generative AI tools.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/5e16600a03b824911557e78f7d5521d5c3339cd9.pdf",
      "venue": "AIware",
      "citationCount": 28,
      "score": 28.0,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Problem**: The paper addresses the lack of empirical evidence regarding the impact of generative AI tools on software development productivity, especially in complex, real-world industrial settings \\cite{coutinho20245vb}.\n    *   **Importance & Challenge**: Understanding productivity in software development is inherently challenging due to its multifaceted nature, influenced by technical, social, and psychological factors, and the absence of universally accepted metrics \\cite{coutinho20245vb}. While there's a general belief in generative AI's potential benefits, empirical validation beyond simple task completion times is scarce, particularly in diverse roles and complex projects \\cite{coutinho20245vb}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous studies have explored teamwork, collaboration, and tool adoption in software engineering, and more recently, the potential of generative AI for automated code generation and task automation \\cite{coutinho20245vb}.\n    *   **Limitations of Previous Solutions**: Existing research often focuses on task completion time as the primary productivity metric, which inadequately captures the complex factors influencing software development productivity \\cite{coutinho20245vb}. There's a gap in comprehensive investigations that detail the application of generative AI across the entire software creation process in real-world industrial contexts, considering broader productivity dimensions like satisfaction, performance, activity, communication, collaboration, efficiency, and flow \\cite{coutinho20245vb}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper employs a pilot case study methodology to investigate the integration of existing generative AI tools (ChatGPT Plus, OpenAI API, Midjourney, GitHub Copilot) into the daily work routines of software professionals \\cite{coutinho20245vb}. It focuses on gathering qualitative insights into their uses, benefits, and challenges, particularly concerning perceived productivity.\n    *   **Novelty/Difference**: The innovation lies in its empirical, qualitative approach within a large, diverse software company, aiming to understand the nuanced characteristics of productivity in a real-world industrial context, rather than proposing a new AI model or algorithm. This moves beyond laboratory settings and simple coding tasks to encompass various roles and activities across the software development lifecycle \\cite{coutinho20245vb}.\n\n4.  **Key Technical Contributions**\n    *   **Empirical Study Design**: Development and execution of a pilot case study framework for assessing the real-world impact of generative AI tools on software development productivity across diverse professional roles (engineers, designers, data scientists, QA, agile coaches) in an industrial setting \\cite{coutinho20245vb}.\n    *   **Qualitative Data Collection & Analysis**: Utilization of a structured questionnaire with open-ended questions and observations to gather rich, descriptive data on perceived productivity, benefits, and challenges, enabling a more nuanced understanding than purely quantitative metrics \\cite{coutinho20245vb}.\n    *   **Initial Empirical Insights**: Provision of preliminary findings on how generative AI tools are being integrated and perceived by professionals in a complex organizational environment, setting the groundwork for more extensive investigations into productivity facets \\cite{coutinho20245vb}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: A pilot case study was conducted over four weeks involving 13 software professionals from a large software company specializing in on-demand solutions across various sectors \\cite{coutinho20245vb}. Participants were provided licenses for generative AI tools (ChatGPT Plus, OpenAI API, Midjourney, GitHub Copilot) and asked to integrate them into their work.\n    *   **Key Performance Metrics & Comparison Results**: Validation was primarily qualitative. Data was collected through questionnaires with open-ended questions focusing on:\n        *   Summary of activities performed with AI tools.\n        *   Details of working experience with the tools.\n        *   Main benefits encountered.\n        *   Observed impact on productivity.\n        *   Contribution to enhancing activity value.\n        *   Satisfaction with results.\n        *   Willingness to continue using AI.\n        *   Other important aspects of experience \\cite{coutinho20245vb}.\n        *   **Results (Preliminary)**: Findings revealed a generally positive perception of these tools in individual productivity, while also highlighting identified limitations. Specific detailed results are not fully elaborated in the provided abstract/introduction/methodology sections but are stated to be discussed in Section 5 of the full paper \\cite{coutinho20245vb}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study is a *pilot* case study, meaning its findings are preliminary and intended to guide future, broader investigations \\cite{coutinho20245vb}. The use of tools was voluntary and not consistently integrated into daily work for all participants, potentially affecting the depth of experience captured \\cite{coutinho20245vb}. The reliance on questionnaires rather than interviews might limit the richness of qualitative data compared to more interactive methods \\cite{coutinho20245vb}.\n    *   **Scope of Applicability**: The study focuses on a single large software company and a relatively small sample size (13 participants), which may limit the generalizability of the findings to other organizational contexts or smaller teams \\cite{coutinho20245vb}. It primarily captures *perceived* productivity and initial experiences.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper contributes by providing much-needed initial empirical evidence from a real-world industrial setting on the integration and impact of generative AI tools on software development productivity \\cite{coutinho20245vb}. It addresses a critical gap in the literature by moving beyond theoretical discussions and laboratory experiments to explore the practical implications across diverse roles and complex tasks.\n    *   **Potential Impact on Future Research**: The research sets the stage for further, more comprehensive, and longitudinal explorations into the evolving landscape of software development practices with generative AI \\cite{coutinho20245vb}. It highlights the need for broader productivity metrics and provides a methodological foundation for future studies to investigate the nuanced characteristics of productivity in this context.",
      "keywords": [
        "Generative AI tools",
        "software development productivity",
        "real-world industrial settings",
        "pilot case study",
        "qualitative research methodology",
        "perceived productivity",
        "diverse professional roles",
        "empirical evidence",
        "software development lifecycle",
        "nuanced productivity metrics",
        "AI integration challenges",
        "code generation",
        "task automation"
      ],
      "paper_type": "the paper explicitly states in its title and abstract that it is \"a pilot case study\". the abstract describes the methodology as \"through a pilot case study involving software practitioners... we gathered valuable experiences\" and discusses \"findings\" from this specific investigation. this directly matches the criteria for a **case_study**:\n\n*   **abstract mentions:** \"case study\", \"application\", \"practice\", \"experience\"\n*   **introduction discusses:** specific context, real-world scenario (implied by investigating generative ai tools with software practitioners)\n\ntherefore, the most appropriate classification is **case_study**."
    },
    "file_name": "5e16600a03b824911557e78f7d5521d5c3339cd9.pdf"
  },
  {
    "success": true,
    "doc_id": "373f6992a72741e22ff875a68dac4031",
    "summary": "The emergence of AI tools such as ChatGPT is being used to assist with software development, but little is known of how developers utilize these tools as well as the capabilities of these tools in software engineering tasks. Using the DevGPT dataset, we conduct quantitative analyses of the tasks developers seek assistance from ChatGPT and how effectively ChatGPT addresses them. We also examine the impact of initial prompt quality on conversation length. The findings reveal where ChatGPT is most and least suited to assist in the identified 12 software development tasks. The insights from this research would guide the software developers, researchers, and AI tool providers in optimizing these tools for more effective programming aid.",
    "intriguing_abstract": "The emergence of AI tools such as ChatGPT is being used to assist with software development, but little is known of how developers utilize these tools as well as the capabilities of these tools in software engineering tasks. Using the DevGPT dataset, we conduct quantitative analyses of the tasks developers seek assistance from ChatGPT and how effectively ChatGPT addresses them. We also examine the impact of initial prompt quality on conversation length. The findings reveal where ChatGPT is most and least suited to assist in the identified 12 software development tasks. The insights from this research would guide the software developers, researchers, and AI tool providers in optimizing these tools for more effective programming aid.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6f8f35aea416b2542d55a638ad20497f38181384.pdf",
    "citation_key": "champa2024ps0",
    "metadata": {
      "title": "ChatGPT in Action: Analyzing Its Use in Software Development",
      "authors": [
        "A. I. Champa",
        "Md. Fazle Rabbi",
        "Costain Nachuma",
        "M. Zibran"
      ],
      "published_date": "2024",
      "abstract": "The emergence of AI tools such as ChatGPT is being used to assist with software development, but little is known of how developers utilize these tools as well as the capabilities of these tools in software engineering tasks. Using the DevGPT dataset, we conduct quantitative analyses of the tasks developers seek assistance from ChatGPT and how effectively ChatGPT addresses them. We also examine the impact of initial prompt quality on conversation length. The findings reveal where ChatGPT is most and least suited to assist in the identified 12 software development tasks. The insights from this research would guide the software developers, researchers, and AI tool providers in optimizing these tools for more effective programming aid.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6f8f35aea416b2542d55a638ad20497f38181384.pdf",
      "venue": "IEEE Working Conference on Mining Software Repositories",
      "citationCount": 27,
      "score": 27.0,
      "summary": "The emergence of AI tools such as ChatGPT is being used to assist with software development, but little is known of how developers utilize these tools as well as the capabilities of these tools in software engineering tasks. Using the DevGPT dataset, we conduct quantitative analyses of the tasks developers seek assistance from ChatGPT and how effectively ChatGPT addresses them. We also examine the impact of initial prompt quality on conversation length. The findings reveal where ChatGPT is most and least suited to assist in the identified 12 software development tasks. The insights from this research would guide the software developers, researchers, and AI tool providers in optimizing these tools for more effective programming aid.",
      "keywords": []
    },
    "file_name": "6f8f35aea416b2542d55a638ad20497f38181384.pdf"
  },
  {
    "success": true,
    "doc_id": "f3744c5d05980cc456106103a0f1cb06",
    "summary": "The development of robust circuit structures remains a pivotal milestone in electronic device research. This article proposes an integrated hardware–software system designed for the acquisition, processing, and analysis of surface electromyographic (sEMG) signals. The system analyzes sEMG signals to understand muscle function and neuromuscular control, employing convolutional neural networks (CNNs) for pattern recognition. The electrical signals analyzed on healthy and unhealthy subjects are acquired using a meticulously developed integrated circuit system featuring biopotential acquisition electrodes. The signals captured in the database are extracted, classified, and interpreted by the application of CNNs with the aim of identifying patterns indicative of neuromuscular problems. By leveraging advanced learning techniques, the proposed method addresses the non-stationary nature of sEMG recordings and mitigates cross-talk effects commonly observed in electrical interference patterns captured by surface sensors. The integration of an AI algorithm with the signal acquisition device enhances the qualitative outcomes by eliminating redundant information. CNNs reveals their effectiveness in accurately deciphering complex data patterns from sEMG signals, identifying subjects with neuromuscular problems with high precision. This paper contributes to the landscape of biomedical research, advocating for the integration of advanced computational techniques to unravel complex physiological phenomena and enhance the utility of sEMG signal analysis.",
    "intriguing_abstract": "The development of robust circuit structures remains a pivotal milestone in electronic device research. This article proposes an integrated hardware–software system designed for the acquisition, processing, and analysis of surface electromyographic (sEMG) signals. The system analyzes sEMG signals to understand muscle function and neuromuscular control, employing convolutional neural networks (CNNs) for pattern recognition. The electrical signals analyzed on healthy and unhealthy subjects are acquired using a meticulously developed integrated circuit system featuring biopotential acquisition electrodes. The signals captured in the database are extracted, classified, and interpreted by the application of CNNs with the aim of identifying patterns indicative of neuromuscular problems. By leveraging advanced learning techniques, the proposed method addresses the non-stationary nature of sEMG recordings and mitigates cross-talk effects commonly observed in electrical interference patterns captured by surface sensors. The integration of an AI algorithm with the signal acquisition device enhances the qualitative outcomes by eliminating redundant information. CNNs reveals their effectiveness in accurately deciphering complex data patterns from sEMG signals, identifying subjects with neuromuscular problems with high precision. This paper contributes to the landscape of biomedical research, advocating for the integration of advanced computational techniques to unravel complex physiological phenomena and enhance the utility of sEMG signal analysis.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d7a2bb980d56f7db43f168f084ee923758d872ab.pdf",
    "citation_key": "lagan2024ifb",
    "metadata": {
      "title": "Development of an Integrated System of sEMG Signal Acquisition, Processing, and Analysis with AI Techniques",
      "authors": [
        "F. Laganá",
        "Danilo Pratticò",
        "G. Angiulli",
        "G. Oliva",
        "S. Pullano",
        "M. Versaci",
        "Fabio La Foresta"
      ],
      "published_date": "2024",
      "abstract": "The development of robust circuit structures remains a pivotal milestone in electronic device research. This article proposes an integrated hardware–software system designed for the acquisition, processing, and analysis of surface electromyographic (sEMG) signals. The system analyzes sEMG signals to understand muscle function and neuromuscular control, employing convolutional neural networks (CNNs) for pattern recognition. The electrical signals analyzed on healthy and unhealthy subjects are acquired using a meticulously developed integrated circuit system featuring biopotential acquisition electrodes. The signals captured in the database are extracted, classified, and interpreted by the application of CNNs with the aim of identifying patterns indicative of neuromuscular problems. By leveraging advanced learning techniques, the proposed method addresses the non-stationary nature of sEMG recordings and mitigates cross-talk effects commonly observed in electrical interference patterns captured by surface sensors. The integration of an AI algorithm with the signal acquisition device enhances the qualitative outcomes by eliminating redundant information. CNNs reveals their effectiveness in accurately deciphering complex data patterns from sEMG signals, identifying subjects with neuromuscular problems with high precision. This paper contributes to the landscape of biomedical research, advocating for the integration of advanced computational techniques to unravel complex physiological phenomena and enhance the utility of sEMG signal analysis.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d7a2bb980d56f7db43f168f084ee923758d872ab.pdf",
      "venue": "Signals",
      "citationCount": 27,
      "score": 27.0,
      "summary": "The development of robust circuit structures remains a pivotal milestone in electronic device research. This article proposes an integrated hardware–software system designed for the acquisition, processing, and analysis of surface electromyographic (sEMG) signals. The system analyzes sEMG signals to understand muscle function and neuromuscular control, employing convolutional neural networks (CNNs) for pattern recognition. The electrical signals analyzed on healthy and unhealthy subjects are acquired using a meticulously developed integrated circuit system featuring biopotential acquisition electrodes. The signals captured in the database are extracted, classified, and interpreted by the application of CNNs with the aim of identifying patterns indicative of neuromuscular problems. By leveraging advanced learning techniques, the proposed method addresses the non-stationary nature of sEMG recordings and mitigates cross-talk effects commonly observed in electrical interference patterns captured by surface sensors. The integration of an AI algorithm with the signal acquisition device enhances the qualitative outcomes by eliminating redundant information. CNNs reveals their effectiveness in accurately deciphering complex data patterns from sEMG signals, identifying subjects with neuromuscular problems with high precision. This paper contributes to the landscape of biomedical research, advocating for the integration of advanced computational techniques to unravel complex physiological phenomena and enhance the utility of sEMG signal analysis.",
      "keywords": []
    },
    "file_name": "d7a2bb980d56f7db43f168f084ee923758d872ab.pdf"
  },
  {
    "success": true,
    "doc_id": "d37ff91ad471fd2d21db0d06ebadc48b",
    "summary": "ABSTRACT The rapid advancement of generative AI technology offers new opportunities for the innovation and transformation of education. However, this also brings forth risks and challenges, including the potential to exacerbate educational inequality and integrity. This study aims to address the extensive controversies surrounding the application of generative AI technology in education by providing an objective and comprehensive understanding of its current state, development in educational contexts. Using the CiteSpace and VOSviewer software, we conducted visual analyses of relevant literature from the Web of Science core collection pertaining to the application of generative AI in education.Subsequently, we identified productive journals, productive articles, collaboration patterns, article hotspots, and prevalent topics in this field.This study will facilitate the promotion of in-depth research and practical implementation of AI in education.",
    "intriguing_abstract": "ABSTRACT The rapid advancement of generative AI technology offers new opportunities for the innovation and transformation of education. However, this also brings forth risks and challenges, including the potential to exacerbate educational inequality and integrity. This study aims to address the extensive controversies surrounding the application of generative AI technology in education by providing an objective and comprehensive understanding of its current state, development in educational contexts. Using the CiteSpace and VOSviewer software, we conducted visual analyses of relevant literature from the Web of Science core collection pertaining to the application of generative AI in education.Subsequently, we identified productive journals, productive articles, collaboration patterns, article hotspots, and prevalent topics in this field.This study will facilitate the promotion of in-depth research and practical implementation of AI in education.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/de3c9e140af2be93b61d0203a1d182e343e52cb1.pdf",
    "citation_key": "liu20245xy",
    "metadata": {
      "title": "A bibliometric analysis of generative AI in education: current status and development",
      "authors": [
        "Jun Liu",
        "Cong Wang",
        "Zile Liu",
        "Minghui Gao",
        "Yanhua Xu",
        "Jiayu Chen",
        "Yichun Cheng"
      ],
      "published_date": "2024",
      "abstract": "ABSTRACT The rapid advancement of generative AI technology offers new opportunities for the innovation and transformation of education. However, this also brings forth risks and challenges, including the potential to exacerbate educational inequality and integrity. This study aims to address the extensive controversies surrounding the application of generative AI technology in education by providing an objective and comprehensive understanding of its current state, development in educational contexts. Using the CiteSpace and VOSviewer software, we conducted visual analyses of relevant literature from the Web of Science core collection pertaining to the application of generative AI in education.Subsequently, we identified productive journals, productive articles, collaboration patterns, article hotspots, and prevalent topics in this field.This study will facilitate the promotion of in-depth research and practical implementation of AI in education.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/de3c9e140af2be93b61d0203a1d182e343e52cb1.pdf",
      "venue": "Asia Pacific Journal of Education",
      "citationCount": 26,
      "score": 26.0,
      "summary": "ABSTRACT The rapid advancement of generative AI technology offers new opportunities for the innovation and transformation of education. However, this also brings forth risks and challenges, including the potential to exacerbate educational inequality and integrity. This study aims to address the extensive controversies surrounding the application of generative AI technology in education by providing an objective and comprehensive understanding of its current state, development in educational contexts. Using the CiteSpace and VOSviewer software, we conducted visual analyses of relevant literature from the Web of Science core collection pertaining to the application of generative AI in education.Subsequently, we identified productive journals, productive articles, collaboration patterns, article hotspots, and prevalent topics in this field.This study will facilitate the promotion of in-depth research and practical implementation of AI in education.",
      "keywords": []
    },
    "file_name": "de3c9e140af2be93b61d0203a1d182e343e52cb1.pdf"
  },
  {
    "success": true,
    "doc_id": "90a98dd8d048d2c95ae137bbdf2bfcb4",
    "summary": "The landscape of software development has witnessed a paradigm shift with the advent of AI-powered assistants, exemplified by GitHub Copilot. However, existing solutions are not leveraging all the potential capabilities available in an IDE such as building, testing, executing code, git operations, etc. Therefore, they are constrained by their limited capabilities, primarily focusing on suggesting code snippets and file manipulation within a chat-based interface. To fill this gap, we present AutoDev, a fully automated AI-driven software development framework, designed for autonomous planning and execution of intricate software engineering tasks. AutoDev enables users to define complex software engineering objectives, which are assigned to AutoDev's autonomous AI Agents to achieve. These AI agents can perform diverse operations on a codebase, including file editing, retrieval, build processes, execution, testing, and git operations. They also have access to files, compiler output, build and testing logs, static analysis tools, and more. This enables the AI Agents to execute tasks in a fully automated manner with a comprehensive understanding of the contextual information required. Furthermore, AutoDev establishes a secure development environment by confining all operations within Docker containers. This framework incorporates guardrails to ensure user privacy and file security, allowing users to define specific permitted or restricted commands and operations within AutoDev. In our evaluation, we tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.",
    "intriguing_abstract": "The landscape of software development has witnessed a paradigm shift with the advent of AI-powered assistants, exemplified by GitHub Copilot. However, existing solutions are not leveraging all the potential capabilities available in an IDE such as building, testing, executing code, git operations, etc. Therefore, they are constrained by their limited capabilities, primarily focusing on suggesting code snippets and file manipulation within a chat-based interface. To fill this gap, we present AutoDev, a fully automated AI-driven software development framework, designed for autonomous planning and execution of intricate software engineering tasks. AutoDev enables users to define complex software engineering objectives, which are assigned to AutoDev's autonomous AI Agents to achieve. These AI agents can perform diverse operations on a codebase, including file editing, retrieval, build processes, execution, testing, and git operations. They also have access to files, compiler output, build and testing logs, static analysis tools, and more. This enables the AI Agents to execute tasks in a fully automated manner with a comprehensive understanding of the contextual information required. Furthermore, AutoDev establishes a secure development environment by confining all operations within Docker containers. This framework incorporates guardrails to ensure user privacy and file security, allowing users to define specific permitted or restricted commands and operations within AutoDev. In our evaluation, we tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/215cf45522610045741238f7689a10f6bc5a1f8b.pdf",
    "citation_key": "tufano2024tqr",
    "metadata": {
      "title": "AutoDev: Automated AI-Driven Development",
      "authors": [
        "Michele Tufano",
        "Anisha Agarwal",
        "Jinu Jang",
        "Roshanak Zilouchian Moghaddam",
        "Neel Sundaresan"
      ],
      "published_date": "2024",
      "abstract": "The landscape of software development has witnessed a paradigm shift with the advent of AI-powered assistants, exemplified by GitHub Copilot. However, existing solutions are not leveraging all the potential capabilities available in an IDE such as building, testing, executing code, git operations, etc. Therefore, they are constrained by their limited capabilities, primarily focusing on suggesting code snippets and file manipulation within a chat-based interface. To fill this gap, we present AutoDev, a fully automated AI-driven software development framework, designed for autonomous planning and execution of intricate software engineering tasks. AutoDev enables users to define complex software engineering objectives, which are assigned to AutoDev's autonomous AI Agents to achieve. These AI agents can perform diverse operations on a codebase, including file editing, retrieval, build processes, execution, testing, and git operations. They also have access to files, compiler output, build and testing logs, static analysis tools, and more. This enables the AI Agents to execute tasks in a fully automated manner with a comprehensive understanding of the contextual information required. Furthermore, AutoDev establishes a secure development environment by confining all operations within Docker containers. This framework incorporates guardrails to ensure user privacy and file security, allowing users to define specific permitted or restricted commands and operations within AutoDev. In our evaluation, we tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/215cf45522610045741238f7689a10f6bc5a1f8b.pdf",
      "venue": "arXiv.org",
      "citationCount": 25,
      "score": 25.0,
      "summary": "The landscape of software development has witnessed a paradigm shift with the advent of AI-powered assistants, exemplified by GitHub Copilot. However, existing solutions are not leveraging all the potential capabilities available in an IDE such as building, testing, executing code, git operations, etc. Therefore, they are constrained by their limited capabilities, primarily focusing on suggesting code snippets and file manipulation within a chat-based interface. To fill this gap, we present AutoDev, a fully automated AI-driven software development framework, designed for autonomous planning and execution of intricate software engineering tasks. AutoDev enables users to define complex software engineering objectives, which are assigned to AutoDev's autonomous AI Agents to achieve. These AI agents can perform diverse operations on a codebase, including file editing, retrieval, build processes, execution, testing, and git operations. They also have access to files, compiler output, build and testing logs, static analysis tools, and more. This enables the AI Agents to execute tasks in a fully automated manner with a comprehensive understanding of the contextual information required. Furthermore, AutoDev establishes a secure development environment by confining all operations within Docker containers. This framework incorporates guardrails to ensure user privacy and file security, allowing users to define specific permitted or restricted commands and operations within AutoDev. In our evaluation, we tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.",
      "keywords": []
    },
    "file_name": "215cf45522610045741238f7689a10f6bc5a1f8b.pdf"
  },
  {
    "success": true,
    "doc_id": "aa03c9d53039fbf99459881bcb5e394e",
    "summary": "The software engineering landscape is undergoing a significant transformation with the advent of artificial intelligence (AI). AI technologies are poised to redefine traditional software development practices, offering innovative solutions to long-standing challenges. This paper explores the integration of AI into software engineering processes, aiming to identify its impacts, benefits, and the challenges that accompany this paradigm shift. A comprehensive analysis of current AI applications in software engineering is conducted, supported by case studies and theoretical models. The study examines various phases of software development to assess where AI contributes most effectively. The integration of AI enhances productivity, improves code quality, and accelerates development cycles. Key areas of impact include automated code generation, intelligent debugging, predictive maintenance, and enhanced decision-making processes. AI is revolutionizing software engineering by introducing automation and intelligence into the development lifecycle. Embracing AI-driven tools and methodologies is essential for staying competitive in the evolving technological landscape.",
    "intriguing_abstract": "The software engineering landscape is undergoing a significant transformation with the advent of artificial intelligence (AI). AI technologies are poised to redefine traditional software development practices, offering innovative solutions to long-standing challenges. This paper explores the integration of AI into software engineering processes, aiming to identify its impacts, benefits, and the challenges that accompany this paradigm shift. A comprehensive analysis of current AI applications in software engineering is conducted, supported by case studies and theoretical models. The study examines various phases of software development to assess where AI contributes most effectively. The integration of AI enhances productivity, improves code quality, and accelerates development cycles. Key areas of impact include automated code generation, intelligent debugging, predictive maintenance, and enhanced decision-making processes. AI is revolutionizing software engineering by introducing automation and intelligence into the development lifecycle. Embracing AI-driven tools and methodologies is essential for staying competitive in the evolving technological landscape.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ff8c9fdd9d5a1d63a10abfd114c9f47b1a9d6160.pdf",
    "citation_key": "alenezi2025syg",
    "metadata": {
      "title": "AI-Driven Innovations in Software Engineering: A Review of Current Practices and Future Directions",
      "authors": [
        "M. Alenezi",
        "Mohammed Akour"
      ],
      "published_date": "2025",
      "abstract": "The software engineering landscape is undergoing a significant transformation with the advent of artificial intelligence (AI). AI technologies are poised to redefine traditional software development practices, offering innovative solutions to long-standing challenges. This paper explores the integration of AI into software engineering processes, aiming to identify its impacts, benefits, and the challenges that accompany this paradigm shift. A comprehensive analysis of current AI applications in software engineering is conducted, supported by case studies and theoretical models. The study examines various phases of software development to assess where AI contributes most effectively. The integration of AI enhances productivity, improves code quality, and accelerates development cycles. Key areas of impact include automated code generation, intelligent debugging, predictive maintenance, and enhanced decision-making processes. AI is revolutionizing software engineering by introducing automation and intelligence into the development lifecycle. Embracing AI-driven tools and methodologies is essential for staying competitive in the evolving technological landscape.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ff8c9fdd9d5a1d63a10abfd114c9f47b1a9d6160.pdf",
      "venue": "Applied Sciences",
      "citationCount": 22,
      "score": 22.0,
      "summary": "The software engineering landscape is undergoing a significant transformation with the advent of artificial intelligence (AI). AI technologies are poised to redefine traditional software development practices, offering innovative solutions to long-standing challenges. This paper explores the integration of AI into software engineering processes, aiming to identify its impacts, benefits, and the challenges that accompany this paradigm shift. A comprehensive analysis of current AI applications in software engineering is conducted, supported by case studies and theoretical models. The study examines various phases of software development to assess where AI contributes most effectively. The integration of AI enhances productivity, improves code quality, and accelerates development cycles. Key areas of impact include automated code generation, intelligent debugging, predictive maintenance, and enhanced decision-making processes. AI is revolutionizing software engineering by introducing automation and intelligence into the development lifecycle. Embracing AI-driven tools and methodologies is essential for staying competitive in the evolving technological landscape.",
      "keywords": []
    },
    "file_name": "ff8c9fdd9d5a1d63a10abfd114c9f47b1a9d6160.pdf"
  },
  {
    "success": true,
    "doc_id": "a6a06afef125f4003fcea71804c1189d",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper investigates how Generative AI (GenAI) fundamentally transforms software development, focusing on its impact on individual work practices and team collaboration \\cite{ulfsnes2024pib}.\n    *   **Importance and Challenge**: GenAI tools like ChatGPT and Copilot are rapidly changing how software developers work, offering opportunities for automation and efficiency. However, there is a significant lack of empirical research on how these tools affect individual workflows, and critically, the dynamics of team collaboration and knowledge sharing within software development teams, which are inherently social activities \\cite{ulfsnes2024pib}. Understanding these socio-technical impacts is crucial for successful GenAI adoption.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work acknowledges prior research on developer assistance tools (IDEs, autocompletion) and AI in software engineering. It builds upon existing frameworks for developer productivity, work satisfaction, and established models of agile teamwork and knowledge sharing \\cite{ulfsnes2024pib}.\n    *   **Limitations of Previous Solutions**: While previous studies explored GenAI's capabilities for automating tasks (e.g., code generation, test writing), they largely overlooked the broader empirical impact on human-AI interaction, individual developer workflows, and the subsequent effects on team dynamics and collaboration. The paper explicitly states that research on team dynamics in the context of GenAI is lacking \\cite{ulfsnes2024pib}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: This paper is an empirical, qualitative study, not proposing a technical method or algorithm. Its core approach is:\n        *   **Methodology**: An exploratory multi-case study using semi-structured interviews \\cite{ulfsnes2024pib}.\n        *   **Data Collection**: Interviews with 13 diverse roles (data scientists, managers, developers, designers, frontend developers) from companies actively integrating GenAI into their product development processes \\cite{ulfsnes2024pib}.\n        *   **Tools Investigated**: Primarily ChatGPT and GitHub Copilot, with some mention of Midjourney and DALL-E 2 \\cite{ulfsnes2024pib}.\n    *   **Novelty/Difference**: The innovation lies in its empirical focus on the *socio-technical transformation* brought by GenAI. It provides early, real-world insights into how developers *actually use* GenAI, the perceived benefits and challenges, and its direct and indirect effects on individual productivity, learning, and, crucially, team collaboration and knowledge exchange \\cite{ulfsnes2024pib}.\n\n4.  **Key Technical Contributions**\n    *   **Empirical Evidence of Workflow Transformation**: Provides qualitative evidence that GenAI (especially ChatGPT) signifies a \"paradigm shift\" in software developer workflows \\cite{ulfsnes2024pib}.\n    *   **Categorization of GenAI Use Cases**: Identifies and describes a range of practical GenAI activities in software development, including:\n        *   Asking for assistance when stuck (e.g., \"rubber-ducking\") \\cite{ulfsnes2024pib}.\n        *   Interactive learning and skill acquisition \\cite{ulfsnes2024pib}.\n        *   Creating virtual environments for product testing and domain understanding \\cite{ulfsnes2024pib}.\n        *   Copywriting for non-technical tasks (e.g., emails, presentations) \\cite{ulfsnes2024pib}.\n        *   Generating boilerplate code and text \\cite{ulfsnes2024pib}.\n        *   Working with existing code (refactoring, debugging, testing, translation, explanation) \\cite{ulfsnes2024pib}.\n    *   **Insights into Individual Impact**: Demonstrates that GenAI empowers developers by increasing efficiency, accelerating learning, and boosting motivation through the reduction of tedious and repetitive tasks \\cite{ulfsnes2024pib}.\n    *   **Identification of Collaboration Impact**: Reveals a change in teamwork dynamics, where developers increasingly use GenAI for help instead of asking co-workers, potentially impacting the learning loop and knowledge sharing in agile teams \\cite{ulfsnes2024pib}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The validation is based on an empirical, qualitative study:\n        *   **Study Design**: An exploratory multi-case study involving 13 participants from various roles in software-intensive organizations \\cite{ulfsnes2024pib}.\n        *   **Data Collection**: Semi-structured interviews were conducted to gather insights on GenAI usage and its perceived effects \\cite{ulfsnes2024pib}.\n        *   **Data Analysis**: A two-cycle coding process (descriptive, initial, and focused coding) followed by thematic analysis and discussions among the authors was used to extract themes and categories \\cite{ulfsnes2024pib}.\n    *   **Key Performance Metrics and Comparison Results**: As a qualitative study, it does not present quantitative performance metrics. Instead, it provides rich qualitative findings:\n        *   **Benefits**: Participants reported increased productivity, faster learning, reduced time on menial tasks, increased motivation, improved focus, and the ability to generate more comprehensive test cases \\cite{ulfsnes2024pib}.\n        *   **Challenges**: Identified potential reduction in inter-team interactions, overhead in prompt engineering for quality output, and the need for double-checking GenAI-generated content \\cite{ulfsnes2024pib}.\n        *   **Impact on Teams**: The study empirically highlights that developers are substituting human interaction with GenAI for problem-solving, which has implications for team learning and collaboration \\cite{ulfsnes2024pib}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   **Qualitative Nature**: Findings are based on self-reported perceptions and experiences, not objective quantitative measurements \\cite{ulfsnes2024pib}.\n        *   **Sample Size**: The study involved 13 informants, which, while diverse, is a relatively small sample for broad generalization \\cite{ulfsnes2024pib}.\n        *   **Exploratory**: As an early exploratory study, the findings may be preliminary and require further validation through larger-scale or quantitative research \\cite{ulfsnes2024pib}.\n    *   **Scope of Applicability**: The insights are primarily applicable to software-intensive organizations adopting GenAI tools like ChatGPT and GitHub Copilot, particularly within agile development contexts. It focuses on the initial impacts on individual workflows and perceived changes in team dynamics \\cite{ulfsnes2024pib}.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art**: This paper significantly advances the understanding of GenAI's impact by providing early, empirical evidence of its transformative effects on software development workflows and individual productivity \\cite{ulfsnes2024pib}. Crucially, it highlights the often-overlooked socio-technical implications, particularly the potential disruption to team collaboration, knowledge sharing, and learning loops in agile environments \\cite{ulfsnes2024pib}.\n    *   **Potential Impact on Future Research**: It lays the groundwork for future research by identifying critical areas for investigation, such as the long-term effects of GenAI on team cohesion, collective learning, and the development of strategies to balance individual GenAI-driven productivity with maintaining effective human-to-human interactions and knowledge transfer within teams \\cite{ulfsnes2024pib}. It also calls for more quantitative studies to measure the observed effects.",
    "intriguing_abstract": "The advent of Generative AI (GenAI) tools like ChatGPT and GitHub Copilot is fundamentally reshaping the landscape of software development, promising unprecedented automation and efficiency. However, empirical understanding of its profound socio-technical impact on individual workflows and, critically, on team collaboration and knowledge sharing remains nascent. This exploratory multi-case study, based on semi-structured interviews with 13 diverse software professionals, provides early, real-world insights into GenAI adoption. We reveal a paradigm shift in developer workflows, identifying a rich spectrum of GenAI use cases from 'rubber-ducking' and interactive learning to code generation and debugging. While GenAI demonstrably boosts individual productivity, accelerates learning, and reduces tedious tasks, our most striking finding highlights a potential disruption: developers are increasingly substituting human interaction with GenAI for problem-solving. This shift risks eroding vital team collaboration, knowledge sharing, and collective learning loops inherent in agile environments. This paper offers crucial empirical evidence of GenAI's transformative power and its double-edged socio-technical implications. It underscores the urgent need for strategies to balance individual GenAI-driven efficiency with maintaining robust human-to-human interaction, paving the way for future research on sustainable GenAI integration in software teams.",
    "keywords": [
      "Generative AI (GenAI)",
      "software development",
      "socio-technical transformation",
      "developer workflows",
      "team collaboration",
      "knowledge sharing",
      "individual productivity",
      "learning acceleration",
      "empirical qualitative study",
      "ChatGPT",
      "GitHub Copilot",
      "reduced inter-team interactions",
      "agile teams"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b5187ab65ad87597e880505a66b048497a8c4a8d.pdf",
    "citation_key": "ulfsnes2024pib",
    "metadata": {
      "title": "Transforming Software Development with Generative AI: Empirical Insights on Collaboration and Workflow",
      "authors": [
        "Rasmus Ulfsnes",
        "N. B. Moe",
        "V. Stray",
        "Marianne Skarpen"
      ],
      "published_date": "2024",
      "abstract": "Generative AI (GenAI) has fundamentally changed how knowledge workers, such as software developers, solve tasks and collaborate to build software products. Introducing innovative tools like ChatGPT and Copilot has created new opportunities to assist and augment software developers across various problems. We conducted an empirical study involving interviews with 13 data scientists, managers, developers, designers, and frontend developers to investigate the usage of GenAI. Our study reveals that ChatGPT signifies a paradigm shift in the workflow of software developers. The technology empowers developers by enabling them to work more efficiently, speed up the learning process, and increase motivation by reducing tedious and repetitive tasks. Moreover, our results indicate a change in teamwork collaboration due to software engineers using GenAI for help instead of asking co-workers which impacts the learning loop in agile teams.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b5187ab65ad87597e880505a66b048497a8c4a8d.pdf",
      "venue": "arXiv.org",
      "citationCount": 21,
      "score": 21.0,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper investigates how Generative AI (GenAI) fundamentally transforms software development, focusing on its impact on individual work practices and team collaboration \\cite{ulfsnes2024pib}.\n    *   **Importance and Challenge**: GenAI tools like ChatGPT and Copilot are rapidly changing how software developers work, offering opportunities for automation and efficiency. However, there is a significant lack of empirical research on how these tools affect individual workflows, and critically, the dynamics of team collaboration and knowledge sharing within software development teams, which are inherently social activities \\cite{ulfsnes2024pib}. Understanding these socio-technical impacts is crucial for successful GenAI adoption.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work acknowledges prior research on developer assistance tools (IDEs, autocompletion) and AI in software engineering. It builds upon existing frameworks for developer productivity, work satisfaction, and established models of agile teamwork and knowledge sharing \\cite{ulfsnes2024pib}.\n    *   **Limitations of Previous Solutions**: While previous studies explored GenAI's capabilities for automating tasks (e.g., code generation, test writing), they largely overlooked the broader empirical impact on human-AI interaction, individual developer workflows, and the subsequent effects on team dynamics and collaboration. The paper explicitly states that research on team dynamics in the context of GenAI is lacking \\cite{ulfsnes2024pib}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: This paper is an empirical, qualitative study, not proposing a technical method or algorithm. Its core approach is:\n        *   **Methodology**: An exploratory multi-case study using semi-structured interviews \\cite{ulfsnes2024pib}.\n        *   **Data Collection**: Interviews with 13 diverse roles (data scientists, managers, developers, designers, frontend developers) from companies actively integrating GenAI into their product development processes \\cite{ulfsnes2024pib}.\n        *   **Tools Investigated**: Primarily ChatGPT and GitHub Copilot, with some mention of Midjourney and DALL-E 2 \\cite{ulfsnes2024pib}.\n    *   **Novelty/Difference**: The innovation lies in its empirical focus on the *socio-technical transformation* brought by GenAI. It provides early, real-world insights into how developers *actually use* GenAI, the perceived benefits and challenges, and its direct and indirect effects on individual productivity, learning, and, crucially, team collaboration and knowledge exchange \\cite{ulfsnes2024pib}.\n\n4.  **Key Technical Contributions**\n    *   **Empirical Evidence of Workflow Transformation**: Provides qualitative evidence that GenAI (especially ChatGPT) signifies a \"paradigm shift\" in software developer workflows \\cite{ulfsnes2024pib}.\n    *   **Categorization of GenAI Use Cases**: Identifies and describes a range of practical GenAI activities in software development, including:\n        *   Asking for assistance when stuck (e.g., \"rubber-ducking\") \\cite{ulfsnes2024pib}.\n        *   Interactive learning and skill acquisition \\cite{ulfsnes2024pib}.\n        *   Creating virtual environments for product testing and domain understanding \\cite{ulfsnes2024pib}.\n        *   Copywriting for non-technical tasks (e.g., emails, presentations) \\cite{ulfsnes2024pib}.\n        *   Generating boilerplate code and text \\cite{ulfsnes2024pib}.\n        *   Working with existing code (refactoring, debugging, testing, translation, explanation) \\cite{ulfsnes2024pib}.\n    *   **Insights into Individual Impact**: Demonstrates that GenAI empowers developers by increasing efficiency, accelerating learning, and boosting motivation through the reduction of tedious and repetitive tasks \\cite{ulfsnes2024pib}.\n    *   **Identification of Collaboration Impact**: Reveals a change in teamwork dynamics, where developers increasingly use GenAI for help instead of asking co-workers, potentially impacting the learning loop and knowledge sharing in agile teams \\cite{ulfsnes2024pib}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The validation is based on an empirical, qualitative study:\n        *   **Study Design**: An exploratory multi-case study involving 13 participants from various roles in software-intensive organizations \\cite{ulfsnes2024pib}.\n        *   **Data Collection**: Semi-structured interviews were conducted to gather insights on GenAI usage and its perceived effects \\cite{ulfsnes2024pib}.\n        *   **Data Analysis**: A two-cycle coding process (descriptive, initial, and focused coding) followed by thematic analysis and discussions among the authors was used to extract themes and categories \\cite{ulfsnes2024pib}.\n    *   **Key Performance Metrics and Comparison Results**: As a qualitative study, it does not present quantitative performance metrics. Instead, it provides rich qualitative findings:\n        *   **Benefits**: Participants reported increased productivity, faster learning, reduced time on menial tasks, increased motivation, improved focus, and the ability to generate more comprehensive test cases \\cite{ulfsnes2024pib}.\n        *   **Challenges**: Identified potential reduction in inter-team interactions, overhead in prompt engineering for quality output, and the need for double-checking GenAI-generated content \\cite{ulfsnes2024pib}.\n        *   **Impact on Teams**: The study empirically highlights that developers are substituting human interaction with GenAI for problem-solving, which has implications for team learning and collaboration \\cite{ulfsnes2024pib}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   **Qualitative Nature**: Findings are based on self-reported perceptions and experiences, not objective quantitative measurements \\cite{ulfsnes2024pib}.\n        *   **Sample Size**: The study involved 13 informants, which, while diverse, is a relatively small sample for broad generalization \\cite{ulfsnes2024pib}.\n        *   **Exploratory**: As an early exploratory study, the findings may be preliminary and require further validation through larger-scale or quantitative research \\cite{ulfsnes2024pib}.\n    *   **Scope of Applicability**: The insights are primarily applicable to software-intensive organizations adopting GenAI tools like ChatGPT and GitHub Copilot, particularly within agile development contexts. It focuses on the initial impacts on individual workflows and perceived changes in team dynamics \\cite{ulfsnes2024pib}.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art**: This paper significantly advances the understanding of GenAI's impact by providing early, empirical evidence of its transformative effects on software development workflows and individual productivity \\cite{ulfsnes2024pib}. Crucially, it highlights the often-overlooked socio-technical implications, particularly the potential disruption to team collaboration, knowledge sharing, and learning loops in agile environments \\cite{ulfsnes2024pib}.\n    *   **Potential Impact on Future Research**: It lays the groundwork for future research by identifying critical areas for investigation, such as the long-term effects of GenAI on team cohesion, collective learning, and the development of strategies to balance individual GenAI-driven productivity with maintaining effective human-to-human interactions and knowledge transfer within teams \\cite{ulfsnes2024pib}. It also calls for more quantitative studies to measure the observed effects.",
      "keywords": [
        "Generative AI (GenAI)",
        "software development",
        "socio-technical transformation",
        "developer workflows",
        "team collaboration",
        "knowledge sharing",
        "individual productivity",
        "learning acceleration",
        "empirical qualitative study",
        "ChatGPT",
        "GitHub Copilot",
        "reduced inter-team interactions",
        "agile teams"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we conducted an **empirical study** involving **interviews** with 13 data scientists, managers, developers, designers, and frontend developers to investigate the usage of genai. our **study reveals**... moreover, our **results indicate**...\"\n*   this directly aligns with the criteria for **empirical**: \"data-driven studies with statistical analysis\" (interviews are a form of data collection), \"abstract mentions: 'study', 'experiment', 'data', 'statistical', 'findings'\", and \"introduction discusses: research questions, methodology, participants\". the interviews with 13 individuals across various roles represent the methodology and participants for a data-driven study.\n\ntherefore, the paper is a **empirical** type."
    },
    "file_name": "b5187ab65ad87597e880505a66b048497a8c4a8d.pdf"
  },
  {
    "success": true,
    "doc_id": "13ec4e3efc9e13f017117f92abd16b43",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Problem**: The software development industry is undergoing a disruptive paradigm shift with the widespread adoption of Generative AI (GAI) assistants (e.g., GitHub Copilot, ChatGPT) for programming. Educational institutions often react defensively, focusing on preventing GAI use rather than strategically integrating it into curricula \\cite{bull20230ks}.\n    *   **Importance & Challenge**: This reactive stance risks graduating students unprepared for an industry where GAI tools are becoming indispensable. The challenge is to develop pedagogical strategies that leverage GAI's potential to enhance learning and productivity while ensuring students develop foundational programming skills and critical evaluation abilities \\cite{bull20230ks}.\n\n*   **2. Related Work & Positioning**\n    *   **Existing Approaches**: Current educational responses primarily involve detecting GAI-assisted cheating or adapting assessments to make GAI tools less effective \\cite{bull20230ks}.\n    *   **Limitations of Previous Solutions**: This reactionary approach is deemed counterproductive, as it deviates from the principle of industry-informed computing education and misses opportunities to prepare students for future professional practice. The paper draws parallels to past technological shifts (e.g., intelligent code completion, search engines) which, despite initial concerns, became integral tools \\cite{bull20230ks}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a proactive vision for integrating GAI software development tools and practices directly into programming education. This involves teaching students *how and when* to effectively use these tools, treating them as essential components of a developer's toolkit \\cite{bull20230ks}.\n    *   **Novelty**: The approach is novel in its integration-focused stance, contrasting with prevailing defensive strategies. It emphasizes adapting education to future industry needs, including skills like prompt engineering, evaluating AI outputs, and integrating GAI into larger systems and workflows. The application of \"scaffolding and fading\" pedagogical principles to GAI tool usage represents a key innovation in educational methodology \\cite{bull20230ks}.\n\n*   **4. Key Technical Contributions**\n    *   **Visionary Framework**: A comprehensive vision for integrating GAI into software development education, advocating for a shift from a defensive posture to one of strategic utilization \\cite{bull20230ks}.\n    *   **Industry Insights**: Qualitative insights derived from interviews with professional developers regarding current GAI tool usage, perceived benefits (e.g., for repetitive tasks, brainstorming, system design), identified limitations (e.g., \"hallucinations,\" outdated data, lack of project context), and desired features \\cite{bull20230ks}.\n    *   **Pedagogical Recommendations**:\n        *   **Scaffolding and Fading**: Proposing GAI tools as mechanisms to provide adaptive scaffolding and fading support in learning, grounded in Vygotsky's Zone of Proximal Development and Sweller's cognitive load theory (worked examples). This includes a speculative concept of an adjustable \"dial or slider\" within an IDE to control GAI assistance levels \\cite{bull20230ks}.\n        *   **Assessment Redesign**: Recommending a shift towards more contextualized and applied programming problems for assessment, which are less amenable to direct GAI solutions, thereby encouraging deeper student engagement and critical thinking \\cite{bull20230ks}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: The paper conducted exploratory, semi-structured interviews with five professional software developers (P1-P5) who were familiar with GAI tools (GitHub Copilot, ChatGPT) during Q1 2023 \\cite{bull20230ks}. This qualitative study aimed to understand current professional practices, challenges, and perspectives on GAI integration.\n    *   **Key Performance Metrics and Comparison Results**: As a qualitative study informing a vision, traditional quantitative performance metrics are not applicable. Key findings (qualitative) include:\n        *   **Tool Usage**: Professionals leverage GAI for \"boring\" or repetitive code, brainstorming, and system design. ChatGPT is favored for its conversational interface, contextual awareness, and code explanations, while Copilot assists with simpler function generation \\cite{bull20230ks}.\n        *   **Training Needs**: Participants agreed that foundational programming knowledge is more crucial than specific GAI tool training for effective use and output evaluation \\cite{bull20230ks}.\n        *   **Limitations**: Universal concerns included GAI's potential for incorrect but confidently presented responses (\"hallucinations\"), reliance on potentially outdated training data, and Copilot's limited understanding of broader project context \\cite{bull20230ks}.\n        *   **Code Quality**: GAI can assist with unit tests and refactoring, but human oversight and code review remain essential for quality assurance \\cite{bull20230ks}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The proposed pedagogical recommendations, particularly the \"scaffolding/fading dial,\" are speculative and require further technical development and empirical validation. The vision assumes continued evolution and integration of GAI tools into professional workflows \\cite{bull20230ks}.\n    *   **Scope of Applicability**: The vision and recommendations are primarily focused on software development education. The qualitative study's small sample size (5 professionals) is acknowledged as a limitation for broad generalizability \\cite{bull20230ks}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the discourse on GAI in education by proposing a proactive, integration-focused framework, moving beyond defensive strategies. It provides a foundational vision for how educational institutions can adapt to the GAI paradigm shift \\cite{bull20230ks}.\n    *   **Potential Impact on Future Research**: The paper opens critical avenues for future research, including:\n        *   The development and empirical evaluation of GAI-integrated IDEs with adaptive scaffolding features \\cite{bull20230ks}.\n        *   The design and assessment of novel curricula and pedagogical methods that effectively leverage GAI while fostering critical thinking and core programming competencies \\cite{bull20230ks}.\n        *   Long-term studies on the impact of GAI integration on student learning outcomes, productivity, and skill acquisition \\cite{bull20230ks}.\n        *   Research into methods for fine-tuning GAI models for specific educational contexts to ensure pedagogical alignment and output quality \\cite{bull20230ks}.",
    "intriguing_abstract": "The advent of Generative AI (GAI) tools like GitHub Copilot and ChatGPT is fundamentally reshaping software development, yet educational institutions often adopt a defensive, prohibitive stance. This paper challenges this reactive paradigm, proposing a visionary framework for *proactively integrating* GAI into programming education to equip students for an AI-augmented industry. We present novel pedagogical strategies, grounded in **scaffolding and fading** principles, that leverage GAI as an adaptive learning tool, fostering essential skills like **prompt engineering** and critical evaluation of AI outputs.\n\nDrawing on qualitative insights from professional developers, we illuminate current GAI usage, benefits, and critical limitations, informing practical recommendations for curriculum and **assessment redesign**. Our work advocates for a shift from preventing GAI use to teaching its strategic application, ensuring students develop foundational programming competencies alongside proficiency with these indispensable tools. This research offers a crucial roadmap for transforming **software development education**, preparing a new generation of developers and catalyzing future research into GAI-integrated learning environments and adaptive **IDEs**.",
    "keywords": [
      "Generative AI (GAI)",
      "software development education",
      "GAI integration strategies",
      "pedagogical scaffolding and fading",
      "prompt engineering",
      "AI output evaluation",
      "assessment redesign",
      "professional developer insights",
      "GAI limitations",
      "foundational programming skills",
      "adaptive scaffolding",
      "visionary framework"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6564470d2722c273725b219f90cc9f90428eb95a.pdf",
    "citation_key": "bull20230ks",
    "metadata": {
      "title": "Generative Artificial Intelligence Assistants in Software Development Education: A Vision for Integrating Generative Artificial Intelligence Into Educational Practice, Not Instinctively Defending Against It",
      "authors": [
        "Christopher Bull",
        "Ahmed Kharrufa"
      ],
      "published_date": "2023",
      "abstract": "The use of Generative AI in software development is gaining traction. But what are the potentials and implications on software development education? We gathered insights on the use of Generative AI from professional software developers and make some pedagogical recommendations.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6564470d2722c273725b219f90cc9f90428eb95a.pdf",
      "venue": "IEEE Software",
      "citationCount": 42,
      "score": 21.0,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Problem**: The software development industry is undergoing a disruptive paradigm shift with the widespread adoption of Generative AI (GAI) assistants (e.g., GitHub Copilot, ChatGPT) for programming. Educational institutions often react defensively, focusing on preventing GAI use rather than strategically integrating it into curricula \\cite{bull20230ks}.\n    *   **Importance & Challenge**: This reactive stance risks graduating students unprepared for an industry where GAI tools are becoming indispensable. The challenge is to develop pedagogical strategies that leverage GAI's potential to enhance learning and productivity while ensuring students develop foundational programming skills and critical evaluation abilities \\cite{bull20230ks}.\n\n*   **2. Related Work & Positioning**\n    *   **Existing Approaches**: Current educational responses primarily involve detecting GAI-assisted cheating or adapting assessments to make GAI tools less effective \\cite{bull20230ks}.\n    *   **Limitations of Previous Solutions**: This reactionary approach is deemed counterproductive, as it deviates from the principle of industry-informed computing education and misses opportunities to prepare students for future professional practice. The paper draws parallels to past technological shifts (e.g., intelligent code completion, search engines) which, despite initial concerns, became integral tools \\cite{bull20230ks}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes a proactive vision for integrating GAI software development tools and practices directly into programming education. This involves teaching students *how and when* to effectively use these tools, treating them as essential components of a developer's toolkit \\cite{bull20230ks}.\n    *   **Novelty**: The approach is novel in its integration-focused stance, contrasting with prevailing defensive strategies. It emphasizes adapting education to future industry needs, including skills like prompt engineering, evaluating AI outputs, and integrating GAI into larger systems and workflows. The application of \"scaffolding and fading\" pedagogical principles to GAI tool usage represents a key innovation in educational methodology \\cite{bull20230ks}.\n\n*   **4. Key Technical Contributions**\n    *   **Visionary Framework**: A comprehensive vision for integrating GAI into software development education, advocating for a shift from a defensive posture to one of strategic utilization \\cite{bull20230ks}.\n    *   **Industry Insights**: Qualitative insights derived from interviews with professional developers regarding current GAI tool usage, perceived benefits (e.g., for repetitive tasks, brainstorming, system design), identified limitations (e.g., \"hallucinations,\" outdated data, lack of project context), and desired features \\cite{bull20230ks}.\n    *   **Pedagogical Recommendations**:\n        *   **Scaffolding and Fading**: Proposing GAI tools as mechanisms to provide adaptive scaffolding and fading support in learning, grounded in Vygotsky's Zone of Proximal Development and Sweller's cognitive load theory (worked examples). This includes a speculative concept of an adjustable \"dial or slider\" within an IDE to control GAI assistance levels \\cite{bull20230ks}.\n        *   **Assessment Redesign**: Recommending a shift towards more contextualized and applied programming problems for assessment, which are less amenable to direct GAI solutions, thereby encouraging deeper student engagement and critical thinking \\cite{bull20230ks}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: The paper conducted exploratory, semi-structured interviews with five professional software developers (P1-P5) who were familiar with GAI tools (GitHub Copilot, ChatGPT) during Q1 2023 \\cite{bull20230ks}. This qualitative study aimed to understand current professional practices, challenges, and perspectives on GAI integration.\n    *   **Key Performance Metrics and Comparison Results**: As a qualitative study informing a vision, traditional quantitative performance metrics are not applicable. Key findings (qualitative) include:\n        *   **Tool Usage**: Professionals leverage GAI for \"boring\" or repetitive code, brainstorming, and system design. ChatGPT is favored for its conversational interface, contextual awareness, and code explanations, while Copilot assists with simpler function generation \\cite{bull20230ks}.\n        *   **Training Needs**: Participants agreed that foundational programming knowledge is more crucial than specific GAI tool training for effective use and output evaluation \\cite{bull20230ks}.\n        *   **Limitations**: Universal concerns included GAI's potential for incorrect but confidently presented responses (\"hallucinations\"), reliance on potentially outdated training data, and Copilot's limited understanding of broader project context \\cite{bull20230ks}.\n        *   **Code Quality**: GAI can assist with unit tests and refactoring, but human oversight and code review remain essential for quality assurance \\cite{bull20230ks}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The proposed pedagogical recommendations, particularly the \"scaffolding/fading dial,\" are speculative and require further technical development and empirical validation. The vision assumes continued evolution and integration of GAI tools into professional workflows \\cite{bull20230ks}.\n    *   **Scope of Applicability**: The vision and recommendations are primarily focused on software development education. The qualitative study's small sample size (5 professionals) is acknowledged as a limitation for broad generalizability \\cite{bull20230ks}.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the discourse on GAI in education by proposing a proactive, integration-focused framework, moving beyond defensive strategies. It provides a foundational vision for how educational institutions can adapt to the GAI paradigm shift \\cite{bull20230ks}.\n    *   **Potential Impact on Future Research**: The paper opens critical avenues for future research, including:\n        *   The development and empirical evaluation of GAI-integrated IDEs with adaptive scaffolding features \\cite{bull20230ks}.\n        *   The design and assessment of novel curricula and pedagogical methods that effectively leverage GAI while fostering critical thinking and core programming competencies \\cite{bull20230ks}.\n        *   Long-term studies on the impact of GAI integration on student learning outcomes, productivity, and skill acquisition \\cite{bull20230ks}.\n        *   Research into methods for fine-tuning GAI models for specific educational contexts to ensure pedagogical alignment and output quality \\cite{bull20230ks}.",
      "keywords": [
        "Generative AI (GAI)",
        "software development education",
        "GAI integration strategies",
        "pedagogical scaffolding and fading",
        "prompt engineering",
        "AI output evaluation",
        "assessment redesign",
        "professional developer insights",
        "GAI limitations",
        "foundational programming skills",
        "adaptive scaffolding",
        "visionary framework"
      ],
      "paper_type": "the paper type is **position**.\n\nhere's why:\n\n*   **title:** \"generative artificial intelligence assistants in software development education: a vision for integrating generative artificial intelligence into educational practice, not instinctively defending against it\" explicitly states a \"vision\" and argues for a specific approach (\"integrating... not instinctively defending against it\"). this is a strong indicator of a position paper.\n*   **abstract:** discusses benefits, surprising preferences, and participant agreement on how people \"should\" use these tools and what is needed for training. this includes prescriptive elements and observations that support a viewpoint.\n*   **introduction:** clearly states the goal to \"incorporate into our vision of a future of software development education and make some pedagogical recommendations.\" it also argues for the potential benefits of gai (\"may lower the barrier of entry... allow for developers to shift focus\"). these elements directly align with arguing for a viewpoint and proposing a future direction."
    },
    "file_name": "6564470d2722c273725b219f90cc9f90428eb95a.pdf"
  },
  {
    "success": true,
    "doc_id": "d3e485160ce94bdc3bf77c93849eb779",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the limitations of current AI-powered copilots (e.g., GitHub Copilot) in software engineering \\cite{hassan2024hq8}.\n    *   This problem is important because existing copilots are primarily \"task-driven\" (focused on localized code changes/completion) and fall short in addressing the broader, higher-level \"goals\" and complexities inherent in real-world software development \\cite{hassan2024hq8}.\n    *   Challenges include copilots being additive-only, lacking deep SE context (e.g., architectural styles, project conventions), generating potentially buggy or inefficient code, and offering poor communication/control mechanisms for developers \\cite{hassan2024hq8}.\n\n*   **Related Work & Positioning**\n    *   This work positions itself as a paradigm shift away from current \"task-driven\" copilots and \"AI-first\" autonomous agents (like Devin AI, ChatDev, MetaGPT) \\cite{hassan2024hq8}.\n    *   Limitations of previous solutions:\n        *   **Task-driven copilots**: They are additive, lack system-wide context, produce code with quality issues, and are difficult to control, leading to low automation and trustworthiness concerns \\cite{hassan2024hq8}.\n        *   **AI-first autonomous agents**: While impressive, they can generate code too quickly for human review/maintenance, delegate critical architecture/design trade-offs without human oversight, and may not adequately focus on goal alignment, making them potentially unsuitable for enterprise contexts \\cite{hassan2024hq8}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical approach proposes \"goal-driven AI-powered pair programmers\" that collaborate with human developers in a holistic and context-aware manner \\cite{hassan2024hq8}.\n    *   This approach is novel due to its emphasis on four key attributes for AI pair programmers:\n        *   **Goal-driven**: Focuses on high-level objectives (e.g., GitHub issues) rather than isolated tasks, leveraging FM planning capabilities \\cite{hassan2024hq8}.\n        *   **Human partner**: AI acts as a collaborator, not a replacement, with humans maintaining control and engaging in iterative, conversation-driven development \\cite{hassan2024hq8}.\n        *   **SE-aware**: Possesses deep understanding of software engineering principles, design patterns, architectural trade-offs, and can perform complex non-additive changes like refactoring \\cite{hassan2024hq8}.\n        *   **Self-learner**: Learns from feedback, recurrent contextual information (e.g., project constraints), and human preferences (e.g., coding style) \\cite{hassan2024hq8}.\n    *   The vision is envisioned to be implemented using a multi-agent system, including specialized agents for Goal Alignment, Architecture & Design, Code, and Goal-Delivery \\cite{hassan2024hq8}.\n    *   Introduces \"Evaluation-Driven Delivery (EDD)\" as the iterative development process, where the AI tracks and evaluates progress towards goals, inspired by Test-Driven Development (TDD) \\cite{hassan2024hq8}.\n\n*   **Key Technical Contributions**\n    *   **Novel Paradigm**: Proposes a fundamental shift from \"AI-augmented SE\" (code completion) to \"AI-transformed SE\" (collaborative partnership) \\cite{hassan2024hq8}.\n    *   **Conceptual Framework**: Defines the desired attributes and a high-level architecture (multi-agent system with specific roles) for AI pair programmers \\cite{hassan2024hq8}.\n    *   **Theoretical Underpinnings**: Grounds the vision in established theories: Bloom's Sigma Learning Problem (for AI mentoring), Theory of Mind (for human-AI alignment and personalized interaction), and the power of human-AI conversations (for improved task resolution) \\cite{hassan2024hq8}.\n    *   **Identified Challenges**: Articulates critical technical challenges for realizing the vision, including speeding up human-AI alignment, transitioning from prompt engineering to natural inquiries, and developing cheaper and smarter code models \\cite{hassan2024hq8}.\n\n*   **Experimental Validation**\n    *   This paper is a vision paper and does not present empirical experimental validation of an implemented system \\cite{hassan2024hq8}.\n    *   The challenges and vision are informed by surveys, discussions with industry/academic leaders, customer feedback, and the authors' practical experience with R&D in multi-agent frameworks and cognitive architectures \\cite{hassan2024hq8}.\n\n*   **Limitations & Scope**\n    *   The paper presents a conceptual vision and a set of challenges, rather than a fully realized or empirically tested solution \\cite{hassan2024hq8}.\n    *   It acknowledges significant technical hurdles, such as designing effective mechanisms for AI to develop a \"theory of mind,\" creating prompt transpiler technologies for natural inquiries, and developing more efficient and capable code-specific FMs \\cite{hassan2024hq8}.\n    *   The scope is focused on transforming software engineering practices, particularly in enterprise contexts, by fostering a deeper, more collaborative human-AI partnership \\cite{hassan2024hq8}.\n\n*   **Technical Significance**\n    *   This work advances the technical state-of-the-art by advocating for a more sophisticated and integrated role for AI in software development, moving beyond mere code generation to intelligent, goal-oriented collaboration \\cite{hassan2024hq8}.\n    *   Potential impact on future research includes:\n        *   Driving research into multi-agent systems for complex SE tasks \\cite{hassan2024hq8}.\n        *   Innovations in human-AI interaction, particularly in goal alignment and natural language understanding for SE contexts \\cite{hassan2024hq8}.\n        *   Development of AI models with enhanced SE-awareness, reasoning capabilities, and self-learning mechanisms \\cite{hassan2024hq8}.\n        *   Potentially accelerating the skill development of junior developers through AI-powered one-on-one mentoring \\cite{hassan2024hq8}.\n        *   Ultimately, it aims to enhance both developer productivity and the quality of software produced \\cite{hassan2024hq8}.",
    "intriguing_abstract": "Current AI-powered copilots in software engineering remain largely task-driven, struggling with the high-level goals and complex architectural nuances inherent in real-world development. This paper introduces a transformative vision: **goal-driven AI-powered pair programmers**. We propose a paradigm shift from \"AI-augmented SE\" to \"AI-transformed SE,\" where AI acts as a deeply collaborative human partner, not just a code generator.\n\nOur novel framework defines AI pair programmers as inherently **goal-driven**, focusing on high-level objectives like GitHub issues, and profoundly **SE-aware**, understanding architectural styles, design patterns, and performing complex non-additive changes like **refactoring**. These agents are also **self-learning**, adapting to feedback and human preferences, operating within a **multi-agent system** that employs an **Evaluation-Driven Delivery (EDD)** process. This vision fosters iterative, conversation-driven development, ensuring human control while significantly enhancing developer productivity, software quality, and accelerating skill development. We outline a conceptual framework, theoretical underpinnings, and critical challenges for realizing this future of profound **human-AI collaboration** in software engineering.",
    "keywords": [
      "Goal-driven AI-powered pair programmers",
      "AI-transformed Software Engineering",
      "multi-agent systems",
      "Evaluation-Driven Delivery (EDD)",
      "SE-aware AI",
      "human-AI collaboration",
      "Theory of Mind",
      "human-AI alignment",
      "code models",
      "context-aware AI",
      "self-learning AI",
      "developer productivity",
      "enterprise software development",
      "task-driven vs. goal-driven AI"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/bbab45f57c7c0be7371d7139cf2aafb5772eaa9f.pdf",
    "citation_key": "hassan2024hq8",
    "metadata": {
      "title": "Rethinking Software Engineering in the Foundation Model Era: From Task-Driven AI Copilots to Goal-Driven AI Pair Programmers",
      "authors": [
        "Ahmed E. Hassan",
        "G. Oliva",
        "Dayi Lin",
        "Boyuan Chen",
        "Zhen Ming Jiang"
      ],
      "published_date": "2024",
      "abstract": "The advent of Foundation Models (FMs) and AI-powered copilots has transformed the landscape of software development, offering unprecedented code completion capabilities and enhancing developer productivity. However, the current task-driven nature of these copilots falls short in addressing the broader goals and complexities inherent in software engineering (SE). In this paper, we propose a paradigm shift towards goal-driven AI-powered pair programmers that collaborate with human developers in a more holistic and context-aware manner. We envision AI pair programmers that are goal-driven, human partners, SE-aware, and self-learning. These AI partners engage in iterative, conversation-driven development processes, aligning closely with human goals and facilitating informed decision-making. We discuss the desired attributes of such AI pair programmers and outline key challenges that must be addressed to realize this vision. Ultimately, our work represents a shift from AI-augmented SE to AI-transformed SE by replacing code completion with a collaborative partnership between humans and AI that enhances both productivity and software quality.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/bbab45f57c7c0be7371d7139cf2aafb5772eaa9f.pdf",
      "venue": "arXiv.org",
      "citationCount": 20,
      "score": 20.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the limitations of current AI-powered copilots (e.g., GitHub Copilot) in software engineering \\cite{hassan2024hq8}.\n    *   This problem is important because existing copilots are primarily \"task-driven\" (focused on localized code changes/completion) and fall short in addressing the broader, higher-level \"goals\" and complexities inherent in real-world software development \\cite{hassan2024hq8}.\n    *   Challenges include copilots being additive-only, lacking deep SE context (e.g., architectural styles, project conventions), generating potentially buggy or inefficient code, and offering poor communication/control mechanisms for developers \\cite{hassan2024hq8}.\n\n*   **Related Work & Positioning**\n    *   This work positions itself as a paradigm shift away from current \"task-driven\" copilots and \"AI-first\" autonomous agents (like Devin AI, ChatDev, MetaGPT) \\cite{hassan2024hq8}.\n    *   Limitations of previous solutions:\n        *   **Task-driven copilots**: They are additive, lack system-wide context, produce code with quality issues, and are difficult to control, leading to low automation and trustworthiness concerns \\cite{hassan2024hq8}.\n        *   **AI-first autonomous agents**: While impressive, they can generate code too quickly for human review/maintenance, delegate critical architecture/design trade-offs without human oversight, and may not adequately focus on goal alignment, making them potentially unsuitable for enterprise contexts \\cite{hassan2024hq8}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical approach proposes \"goal-driven AI-powered pair programmers\" that collaborate with human developers in a holistic and context-aware manner \\cite{hassan2024hq8}.\n    *   This approach is novel due to its emphasis on four key attributes for AI pair programmers:\n        *   **Goal-driven**: Focuses on high-level objectives (e.g., GitHub issues) rather than isolated tasks, leveraging FM planning capabilities \\cite{hassan2024hq8}.\n        *   **Human partner**: AI acts as a collaborator, not a replacement, with humans maintaining control and engaging in iterative, conversation-driven development \\cite{hassan2024hq8}.\n        *   **SE-aware**: Possesses deep understanding of software engineering principles, design patterns, architectural trade-offs, and can perform complex non-additive changes like refactoring \\cite{hassan2024hq8}.\n        *   **Self-learner**: Learns from feedback, recurrent contextual information (e.g., project constraints), and human preferences (e.g., coding style) \\cite{hassan2024hq8}.\n    *   The vision is envisioned to be implemented using a multi-agent system, including specialized agents for Goal Alignment, Architecture & Design, Code, and Goal-Delivery \\cite{hassan2024hq8}.\n    *   Introduces \"Evaluation-Driven Delivery (EDD)\" as the iterative development process, where the AI tracks and evaluates progress towards goals, inspired by Test-Driven Development (TDD) \\cite{hassan2024hq8}.\n\n*   **Key Technical Contributions**\n    *   **Novel Paradigm**: Proposes a fundamental shift from \"AI-augmented SE\" (code completion) to \"AI-transformed SE\" (collaborative partnership) \\cite{hassan2024hq8}.\n    *   **Conceptual Framework**: Defines the desired attributes and a high-level architecture (multi-agent system with specific roles) for AI pair programmers \\cite{hassan2024hq8}.\n    *   **Theoretical Underpinnings**: Grounds the vision in established theories: Bloom's Sigma Learning Problem (for AI mentoring), Theory of Mind (for human-AI alignment and personalized interaction), and the power of human-AI conversations (for improved task resolution) \\cite{hassan2024hq8}.\n    *   **Identified Challenges**: Articulates critical technical challenges for realizing the vision, including speeding up human-AI alignment, transitioning from prompt engineering to natural inquiries, and developing cheaper and smarter code models \\cite{hassan2024hq8}.\n\n*   **Experimental Validation**\n    *   This paper is a vision paper and does not present empirical experimental validation of an implemented system \\cite{hassan2024hq8}.\n    *   The challenges and vision are informed by surveys, discussions with industry/academic leaders, customer feedback, and the authors' practical experience with R&D in multi-agent frameworks and cognitive architectures \\cite{hassan2024hq8}.\n\n*   **Limitations & Scope**\n    *   The paper presents a conceptual vision and a set of challenges, rather than a fully realized or empirically tested solution \\cite{hassan2024hq8}.\n    *   It acknowledges significant technical hurdles, such as designing effective mechanisms for AI to develop a \"theory of mind,\" creating prompt transpiler technologies for natural inquiries, and developing more efficient and capable code-specific FMs \\cite{hassan2024hq8}.\n    *   The scope is focused on transforming software engineering practices, particularly in enterprise contexts, by fostering a deeper, more collaborative human-AI partnership \\cite{hassan2024hq8}.\n\n*   **Technical Significance**\n    *   This work advances the technical state-of-the-art by advocating for a more sophisticated and integrated role for AI in software development, moving beyond mere code generation to intelligent, goal-oriented collaboration \\cite{hassan2024hq8}.\n    *   Potential impact on future research includes:\n        *   Driving research into multi-agent systems for complex SE tasks \\cite{hassan2024hq8}.\n        *   Innovations in human-AI interaction, particularly in goal alignment and natural language understanding for SE contexts \\cite{hassan2024hq8}.\n        *   Development of AI models with enhanced SE-awareness, reasoning capabilities, and self-learning mechanisms \\cite{hassan2024hq8}.\n        *   Potentially accelerating the skill development of junior developers through AI-powered one-on-one mentoring \\cite{hassan2024hq8}.\n        *   Ultimately, it aims to enhance both developer productivity and the quality of software produced \\cite{hassan2024hq8}.",
      "keywords": [
        "Goal-driven AI-powered pair programmers",
        "AI-transformed Software Engineering",
        "multi-agent systems",
        "Evaluation-Driven Delivery (EDD)",
        "SE-aware AI",
        "human-AI collaboration",
        "Theory of Mind",
        "human-AI alignment",
        "code models",
        "context-aware AI",
        "self-learning AI",
        "developer productivity",
        "enterprise software development",
        "task-driven vs. goal-driven AI"
      ],
      "paper_type": "based on the abstract and introduction:\n\nthis paper best fits the **position** type.\n\nhere's why:\n*   **abstract mentions:** \"propose a paradigm shift,\" \"envision ai pair programmers,\" \"discuss the desired attributes,\" \"outline key challenges,\" \"represents a shift from ai-augmented se to ai-transformed se.\" these phrases strongly indicate the paper is arguing for a new viewpoint and future direction.\n*   **introduction discusses:** it identifies current problems with existing copilots (\"falls short,\" \"limitations\") and sets the stage for the proposed new direction. the title \"rethinking software engineering...\" also supports this.\n\nit's not primarily a technical paper presenting a new algorithm or system, nor is it a survey, theoretical analysis, empirical study, or case study. it's advocating for a new way of thinking and a future vision."
    },
    "file_name": "bbab45f57c7c0be7371d7139cf2aafb5772eaa9f.pdf"
  },
  {
    "success": true,
    "doc_id": "40f31ac1d591a307a1f7680c042d1f67",
    "summary": "The provided text is an excerpt from **Regulation (EU) 2016/679, commonly known as the General Data Protection Regulation (GDPR)** \\cite{amugongo2023vwb}. It is a legal instrument, not a technical or research paper describing a specific technical solution or empirical validation. Therefore, the analysis below interprets the \"technical\" aspects as the *implications and requirements for technology and data processing practices* rather than describing an inherent technical system within the document itself.\n\n---\n\n### Analysis of Regulation (EU) 2016/679 (GDPR) for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Problem**: The paper (regulation) addresses the fragmentation and inconsistencies in data protection laws across the European Union, leading to legal uncertainty and a widespread public perception of significant risks to personal data, particularly in online activities \\cite{amugongo2023vwb} (Recital 9). Rapid technological developments and globalization have led to an unprecedented scale of personal data collection and sharing, posing new challenges to individual privacy \\cite{amugongo2023vwb} (Recital 6).\n    *   **Importance and Challenge**: Protecting personal data is a fundamental right \\cite{amugongo2023vwb} (Recital 1). The challenge lies in establishing a strong, coherent, and enforceable data protection framework that ensures a consistent high level of protection for natural persons across all Member States, removes obstacles to the free flow of personal data within the Union, and fosters trust for the digital economy to develop \\cite{amugongo2023vwb} (Recital 7, 10, 13).\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**: The GDPR builds upon and repeals Directive 95/46/EC \\cite{amugongo2023vwb} (Recital 3).\n    *   **Limitations of Previous Solutions**: Directive 95/46/EC, while sound in its objectives, failed to prevent fragmentation in data protection implementation, resulting in legal uncertainty and public concern over data protection risks, especially online \\cite{amugongo2023vwb} (Recital 9). Differences in protection levels hindered the free flow of personal data and economic activities across the Union \\cite{amugongo2023vwb} (Recital 9).\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: The GDPR does not propose a technical method or algorithm. Instead, its core \"approach\" is a **unified, directly applicable legal framework** that mandates principles and rules for data processing.\n    *   **Novelty/Difference (in a regulatory context with technical implications)**:\n        *   **Direct Applicability**: As a Regulation, it ensures consistent and homogeneous application across all Member States, unlike a Directive which required national transposition and led to variations \\cite{amugongo2023vwb} (Recital 10, 13).\n        *   **Technological Neutrality**: The protection afforded is designed to be technologically neutral, applying to both automated and manual processing of personal data, ensuring its relevance regardless of the techniques used \\cite{amugongo2023vwb} (Recital 15).\n        *   **Extraterritorial Scope**: It extends its reach to controllers and processors not established in the EU if they offer goods or services to, or monitor the behavior of, data subjects within the Union \\cite{amugongo2023vwb} (Recital 23, 24). This significantly impacts global data handling practices.\n        *   **Enhanced Rights and Obligations**: It strengthens the rights of data subjects and imposes more stringent obligations on data controllers and processors, requiring them to implement appropriate technical and organizational measures to ensure compliance.\n\n4.  **Key Technical Contributions (Interpreted as Regulatory Contributions with Technical Impact)**\n    *   **Novel Legal Framework**: Establishes a comprehensive and harmonized legal standard for personal data protection across the EU, serving as a global benchmark \\cite{amugongo2023vwb} (Recital 7, 10).\n    *   **System Design/Architectural Implications**: Mandates principles like data minimization, privacy by design and by default (though not explicitly detailed in this excerpt, it's a core GDPR principle), and security of processing, which necessitate specific technical and architectural considerations in data systems \\cite{amugongo2023vwb} (implied by Recital 7, 11).\n    *   **Enhanced Enforcement**: Provides for equivalent powers for monitoring compliance and significant sanctions for infringements, driving organizations to invest in robust technical compliance solutions \\cite{amugongo2023vwb} (Recital 11, 13).\n    *   **Definition of Personal Data**: Clarifies that pseudonymized data, which can be attributed to a natural person using additional information, is still considered personal data, impacting how data anonymization and de-identification techniques are viewed and implemented \\cite{amugongo2023vwb} (Recital 26).\n\n5.  **Experimental Validation**\n    *   This document is a legal regulation and, as such, does not present experimental validation, performance metrics, or comparison results of a technical system or algorithm. Its effectiveness is measured through its implementation, enforcement, and impact on data protection practices and legal outcomes.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The regulation itself does not have technical limitations in the sense of a system. Its effectiveness relies on the ability of organizations to implement the required technical and organizational measures.\n    *   **Scope of Applicability**: Applies to the processing of personal data of natural persons, regardless of nationality or residence, within the context of an EU establishment or when targeting EU data subjects \\cite{amugongo2023vwb} (Recital 14, 22, 23, 24). It covers both automated and manual processing within a filing system \\cite{amugongo2023vwb} (Recital 15).\n    *   **Exclusions**: Does not apply to legal persons \\cite{amugongo2023vwb} (Recital 14), activities outside the scope of Union law (e.g., national security, common foreign and security policy) \\cite{amugongo2023vwb} (Recital 16), purely personal or household activities \\cite{amugongo2023vwb} (Recital 18), or processing for criminal justice purposes (which falls under Directive (EU) 2016/680) \\cite{amugongo2023vwb} (Recital 19). Courts acting in their judicial capacity are also outside the supervisory authorities' competence \\cite{amugongo2023vwb} (Recital 20).\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: While not a technical paper, the GDPR significantly advances the *regulatory state-of-the-art* in data protection, setting a global standard that influences legislation worldwide. It compels organizations to adopt and innovate in privacy-enhancing technologies (PETs), secure data architectures, and robust data governance frameworks.\n    *   **Potential Impact on Future Research**: The GDPR has profoundly impacted and continues to drive research in areas such as:\n        *   **Privacy-by-Design and Privacy-by-Default**: Encouraging the integration of privacy considerations into the entire lifecycle of data processing systems.\n        *   **Secure Multi-Party Computation, Homomorphic Encryption, Differential Privacy**: Technologies that can help achieve data minimization and enhanced security requirements.\n        *   **Automated Compliance Tools**: Development of tools for data mapping, consent management, data subject rights fulfillment, and breach notification.\n        *   **Ethical AI and Explainable AI**: Addressing concerns around automated decision-making and profiling.\n        *   **Data Governance and Accountability Frameworks**: Research into effective organizational and technical measures for demonstrating compliance.\n        The regulation's emphasis on accountability and data subject rights necessitates continuous technical innovation to meet its stringent requirements.",
    "intriguing_abstract": "The escalating crisis of fragmented data protection and pervasive privacy risks in our digital world demands a unified, robust response. This paper examines Regulation (EU) 2016/679, the General Data Protection Regulation (GDPR), a transformative legal framework that has fundamentally reshaped global data handling practices. Moving beyond previous directives, GDPR introduces a directly applicable, technologically neutral standard with unprecedented extraterritorial scope. It compels organizations worldwide to embed stringent privacy-by-design and data minimization principles into their systems and processes. We highlight how GDPR's enhanced data subject rights and robust accountability mechanisms are driving critical innovation in secure data architectures, advanced pseudonymization techniques, and privacy-enhancing technologies (PETs). As a global benchmark, GDPR not only safeguards the fundamental right to personal data protection but also profoundly influences future research in areas such as ethical AI, automated compliance, and cutting-edge cryptographic solutions, charting a course for a more secure and privacy-aware digital future.",
    "keywords": [
      "General Data Protection Regulation (GDPR)",
      "personal data protection",
      "unified legal framework",
      "technological neutrality",
      "extraterritorial scope",
      "data controllers and processors",
      "technical and organizational measures",
      "privacy by design and by default",
      "pseudonymized data",
      "privacy-enhancing technologies (PETs)",
      "secure data architectures",
      "data governance frameworks",
      "automated decision-making",
      "global data protection standard"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/3f063ccf18e0c9d42f6ecff72dc516ceeac9d4b0.pdf",
    "citation_key": "amugongo2023vwb",
    "metadata": {
      "title": "Operationalising AI ethics through the agile software development lifecycle: a case study of AI-enabled mobile health applications",
      "authors": [
        "L. M. Amugongo",
        "Alexander Kriebitz",
        "Auxane Boch",
        "C. Lütge"
      ],
      "published_date": "2023",
      "abstract": "Although numerous ethical principles and guidelines have been proposed to guide the development of artificial intelligence (AI) systems, it has proven difficult to translate these principles into actionable practices beyond mere adherence to ethical ideas. This is particularly challenging in the context of AI systems for healthcare, which requires balancing the potential benefits of the solution against the risks to patients and the wider community, including minorities and underserved populations. To address this challenge, we propose a shift from one-size-fits-all ethical principles to contextualized case-based ethical frameworks. This study uses an AI-enabled mHealth application as a case study. Our framework is built on existing ethical guidelines and principles, including the AI4People framework, the EU High-Level Expert Group on trustworthy AI, and wider human rights considerations. Additionally, we incorporate relational perspectives to address human value concerns and moral tensions between individual rights and public health. Our approach is based on ”ethics by design,” where ethical principles are integrated throughout the entire AI development pipeline, ensuring that ethical considerations are not an afterthought but implemented from the beginning. For our case study, we identified 7 ethical principles: fairness, agility, precision, safeguarding humanity, respect for others, trust and accountability, and robustness and reproducibility. We believe that the best way to mitigate and address ethical consequences is by implementing ethical principles in the software development processes that developers commonly use. Finally, we provide examples of how our case-based framework can be applied in practice, using examples of AI-driven mobile applications in healthcare.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/3f063ccf18e0c9d42f6ecff72dc516ceeac9d4b0.pdf",
      "venue": "AI and Ethics",
      "citationCount": 39,
      "score": 19.5,
      "summary": "The provided text is an excerpt from **Regulation (EU) 2016/679, commonly known as the General Data Protection Regulation (GDPR)** \\cite{amugongo2023vwb}. It is a legal instrument, not a technical or research paper describing a specific technical solution or empirical validation. Therefore, the analysis below interprets the \"technical\" aspects as the *implications and requirements for technology and data processing practices* rather than describing an inherent technical system within the document itself.\n\n---\n\n### Analysis of Regulation (EU) 2016/679 (GDPR) for Literature Review\n\n1.  **Research Problem & Motivation**\n    *   **Specific Problem**: The paper (regulation) addresses the fragmentation and inconsistencies in data protection laws across the European Union, leading to legal uncertainty and a widespread public perception of significant risks to personal data, particularly in online activities \\cite{amugongo2023vwb} (Recital 9). Rapid technological developments and globalization have led to an unprecedented scale of personal data collection and sharing, posing new challenges to individual privacy \\cite{amugongo2023vwb} (Recital 6).\n    *   **Importance and Challenge**: Protecting personal data is a fundamental right \\cite{amugongo2023vwb} (Recital 1). The challenge lies in establishing a strong, coherent, and enforceable data protection framework that ensures a consistent high level of protection for natural persons across all Member States, removes obstacles to the free flow of personal data within the Union, and fosters trust for the digital economy to develop \\cite{amugongo2023vwb} (Recital 7, 10, 13).\n\n2.  **Related Work & Positioning**\n    *   **Existing Approaches**: The GDPR builds upon and repeals Directive 95/46/EC \\cite{amugongo2023vwb} (Recital 3).\n    *   **Limitations of Previous Solutions**: Directive 95/46/EC, while sound in its objectives, failed to prevent fragmentation in data protection implementation, resulting in legal uncertainty and public concern over data protection risks, especially online \\cite{amugongo2023vwb} (Recital 9). Differences in protection levels hindered the free flow of personal data and economic activities across the Union \\cite{amugongo2023vwb} (Recital 9).\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: The GDPR does not propose a technical method or algorithm. Instead, its core \"approach\" is a **unified, directly applicable legal framework** that mandates principles and rules for data processing.\n    *   **Novelty/Difference (in a regulatory context with technical implications)**:\n        *   **Direct Applicability**: As a Regulation, it ensures consistent and homogeneous application across all Member States, unlike a Directive which required national transposition and led to variations \\cite{amugongo2023vwb} (Recital 10, 13).\n        *   **Technological Neutrality**: The protection afforded is designed to be technologically neutral, applying to both automated and manual processing of personal data, ensuring its relevance regardless of the techniques used \\cite{amugongo2023vwb} (Recital 15).\n        *   **Extraterritorial Scope**: It extends its reach to controllers and processors not established in the EU if they offer goods or services to, or monitor the behavior of, data subjects within the Union \\cite{amugongo2023vwb} (Recital 23, 24). This significantly impacts global data handling practices.\n        *   **Enhanced Rights and Obligations**: It strengthens the rights of data subjects and imposes more stringent obligations on data controllers and processors, requiring them to implement appropriate technical and organizational measures to ensure compliance.\n\n4.  **Key Technical Contributions (Interpreted as Regulatory Contributions with Technical Impact)**\n    *   **Novel Legal Framework**: Establishes a comprehensive and harmonized legal standard for personal data protection across the EU, serving as a global benchmark \\cite{amugongo2023vwb} (Recital 7, 10).\n    *   **System Design/Architectural Implications**: Mandates principles like data minimization, privacy by design and by default (though not explicitly detailed in this excerpt, it's a core GDPR principle), and security of processing, which necessitate specific technical and architectural considerations in data systems \\cite{amugongo2023vwb} (implied by Recital 7, 11).\n    *   **Enhanced Enforcement**: Provides for equivalent powers for monitoring compliance and significant sanctions for infringements, driving organizations to invest in robust technical compliance solutions \\cite{amugongo2023vwb} (Recital 11, 13).\n    *   **Definition of Personal Data**: Clarifies that pseudonymized data, which can be attributed to a natural person using additional information, is still considered personal data, impacting how data anonymization and de-identification techniques are viewed and implemented \\cite{amugongo2023vwb} (Recital 26).\n\n5.  **Experimental Validation**\n    *   This document is a legal regulation and, as such, does not present experimental validation, performance metrics, or comparison results of a technical system or algorithm. Its effectiveness is measured through its implementation, enforcement, and impact on data protection practices and legal outcomes.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The regulation itself does not have technical limitations in the sense of a system. Its effectiveness relies on the ability of organizations to implement the required technical and organizational measures.\n    *   **Scope of Applicability**: Applies to the processing of personal data of natural persons, regardless of nationality or residence, within the context of an EU establishment or when targeting EU data subjects \\cite{amugongo2023vwb} (Recital 14, 22, 23, 24). It covers both automated and manual processing within a filing system \\cite{amugongo2023vwb} (Recital 15).\n    *   **Exclusions**: Does not apply to legal persons \\cite{amugongo2023vwb} (Recital 14), activities outside the scope of Union law (e.g., national security, common foreign and security policy) \\cite{amugongo2023vwb} (Recital 16), purely personal or household activities \\cite{amugongo2023vwb} (Recital 18), or processing for criminal justice purposes (which falls under Directive (EU) 2016/680) \\cite{amugongo2023vwb} (Recital 19). Courts acting in their judicial capacity are also outside the supervisory authorities' competence \\cite{amugongo2023vwb} (Recital 20).\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: While not a technical paper, the GDPR significantly advances the *regulatory state-of-the-art* in data protection, setting a global standard that influences legislation worldwide. It compels organizations to adopt and innovate in privacy-enhancing technologies (PETs), secure data architectures, and robust data governance frameworks.\n    *   **Potential Impact on Future Research**: The GDPR has profoundly impacted and continues to drive research in areas such as:\n        *   **Privacy-by-Design and Privacy-by-Default**: Encouraging the integration of privacy considerations into the entire lifecycle of data processing systems.\n        *   **Secure Multi-Party Computation, Homomorphic Encryption, Differential Privacy**: Technologies that can help achieve data minimization and enhanced security requirements.\n        *   **Automated Compliance Tools**: Development of tools for data mapping, consent management, data subject rights fulfillment, and breach notification.\n        *   **Ethical AI and Explainable AI**: Addressing concerns around automated decision-making and profiling.\n        *   **Data Governance and Accountability Frameworks**: Research into effective organizational and technical measures for demonstrating compliance.\n        The regulation's emphasis on accountability and data subject rights necessitates continuous technical innovation to meet its stringent requirements.",
      "keywords": [
        "General Data Protection Regulation (GDPR)",
        "personal data protection",
        "unified legal framework",
        "technological neutrality",
        "extraterritorial scope",
        "data controllers and processors",
        "technical and organizational measures",
        "privacy by design and by default",
        "pseudonymized data",
        "privacy-enhancing technologies (PETs)",
        "secure data architectures",
        "data governance frameworks",
        "automated decision-making",
        "global data protection standard"
      ],
      "paper_type": "the provided \"abstract\" and \"introduction\" content appears to be an excerpt from a legal regulation (specifically, the general data protection regulation - gdpr) and not an abstract or introduction of a research paper.\n\ntherefore, it does not contain the typical elements, keywords, or structure required to classify a research paper according to the given criteria. it is impossible to classify \"this paper\" based on the provided text into one of the specified research paper types."
    },
    "file_name": "3f063ccf18e0c9d42f6ecff72dc516ceeac9d4b0.pdf"
  },
  {
    "success": true,
    "doc_id": "ddd0b76f46088d365846ef242e928b8f",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of integrating Generative Artificial Intelligence (GenAI) into Agile software development processes to overcome common project management difficulties and enhance efficiency \\cite{bahi2024m17}.\n    *   **Importance and Challenge**: Agile methodologies, while emphasizing adaptability and rapid delivery, still face significant \"pain points\" such as issues with requirement management, managerial and stakeholder support, role clarity, team member overlap, understanding of agile processes, resistance to change, effort prediction, and sufficient technical expertise. The integration of GenAI offers a promising avenue to automate tasks and improve decision-making, but research on its explicit integration within Agile frameworks, particularly with real-world case studies, is still in its early stages \\cite{bahi2024m17}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon established Agile methodologies (e.g., Scrum, XP, Kanban, SAFe) and their associated ceremonies and artifacts. It acknowledges the historical use of search engines and Q&A sites by developers for problem-solving \\cite{bahi2024m17}.\n    *   **Limitations of Previous Solutions**: Traditional Agile approaches, despite their benefits, struggle with persistent challenges like resistance to adopting new practices, lack of upper management participation, technical support issues, and difficulties in scaling to large projects. Existing GenAI tools (e.g., CoPilot, GPT, Bard) have shown productivity gains but their systematic integration into Agile to address specific pain points is underexplored, with a noted absence of significant case studies in the literature \\cite{bahi2024m17}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper explores the potential benefits of GenAI in Agile and proposes an \"adapted framework\" for its explicit integration into a commonly used Agile methodology. The approach leverages GenAI for tasks such as code generation, automated testing, predictive analytics, documentation, ideation, and providing insights into project metrics and risks \\cite{bahi2024m17}.\n    *   **Novelty**: The innovation lies in conceptualizing \"intelligent project management\" through the application of GenAI to automate and enhance various aspects of the Agile process. The paper's novelty is in presenting a structured framework for this integration, aiming to provide a practical perspective on how GenAI can address specific Agile pain points, which is an area lacking significant academic attention and case studies \\cite{bahi2024m17}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**: The primary contribution is the *proposal of an adapted framework* for integrating Generative AI into Agile software development practices. This framework aims to map GenAI capabilities to specific Agile pain points, offering solutions for areas like requirement management, effort prediction, and team collaboration \\cite{bahi2024m17}.\n    *   **Theoretical Insights or Analysis**: The paper provides an in-depth analysis of common Agile pain points, categorizing them (e.g., project, personnel, methods, persistence, estimated effort) and visualizing them using a fishbone diagram. It then theoretically links GenAI's capabilities (e.g., content generation, data analysis, decision support) to mitigate these identified challenges \\cite{bahi2024m17}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The provided paper content *does not describe any experimental validation, case studies, or empirical results*. It states the *goal* is to \"give a real case study of how this can be achieved,\" implying this is a future or ongoing effort not presented in this publication \\cite{bahi2024m17}.\n    *   **Key Performance Metrics and Comparison Results**: No performance metrics or comparative results are presented, as the paper focuses on the theoretical integration and framework proposal.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper acknowledges that GenAI introduces new risks, such as Intellectual Property Rights (IPR) and cybersecurity concerns, due to its non-deterministic and less explicable nature. It also highlights that research on GenAI integration into Agile is nascent, with a lack of significant case studies \\cite{bahi2024m17}.\n    *   **Scope of Applicability**: The proposed framework and analysis are applicable to Agile software development projects, particularly those seeking to enhance efficiency and mitigate common project management challenges through AI integration. The framework is intended for \"one of the most commonly used agile methodology by developers\" \\cite{bahi2024m17}.\n\n*   **Technical Significance**\n    *   **Advance the Technical State-of-the-Art**: This paper advances the state-of-the-art by providing a structured conceptual framework for systematically integrating Generative AI into Agile methodologies. It moves beyond general discussions of AI in software engineering to specifically address how GenAI can tackle identified Agile pain points, filling a gap in current literature \\cite{bahi2024m17}.\n    *   **Potential Impact on Future Research**: The work is crucial for guiding academics and practitioners by highlighting current applications and shaping future studies on GenAI in Agile. It lays the groundwork for future empirical research and case studies on the practical implementation, benefits, and challenges of GenAI-enhanced Agile development, potentially leading to accelerated development cycles, improved collaboration, and enhanced product quality \\cite{bahi2024m17}.",
    "intriguing_abstract": "Despite its widespread adoption, Agile software development continues to grapple with persistent 'pain points'—from complex requirements management and effort prediction to stakeholder misalignment and resistance to change. While Generative Artificial Intelligence (GenAI) promises unprecedented automation and enhanced decision-making, its systematic integration into Agile methodologies remains largely unexplored, lacking a structured approach to tackle these critical challenges.\n\nThis paper introduces a novel, adapted framework designed for the explicit integration of GenAI into mainstream Agile practices. Moving beyond general discussions, we conceptualize 'intelligent project management' by meticulously mapping GenAI capabilities—including automated code generation, predictive analytics, documentation, and ideation—to directly mitigate identified Agile pain points. Through an in-depth analysis, we demonstrate how this framework can transform areas like requirements engineering, team collaboration, and project forecasting within Agile frameworks such as Scrum, XP, Kanban, and SAFe.\n\nOur contribution offers a crucial theoretical foundation, guiding practitioners and researchers toward a new paradigm of GenAI-enhanced Agile. This framework paves the way for accelerated development cycles, improved product quality, and more resilient project outcomes, setting the stage for future empirical studies and unlocking the full potential of intelligent automation in software engineering.",
    "keywords": [
      "Generative AI (GenAI)",
      "Agile software development",
      "Agile pain points",
      "GenAI integration framework",
      "Intelligent project management",
      "Requirement management",
      "Effort prediction",
      "Automated testing",
      "Code generation",
      "Predictive analytics",
      "Theoretical framework proposal",
      "Software engineering",
      "Cybersecurity risks",
      "Lack of empirical validation"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9eb9cf56cc8b616c121c0c90c2419480e9747765.pdf",
    "citation_key": "bahi2024m17",
    "metadata": {
      "title": "Integrating Generative AI for Advancing Agile Software Development and Mitigating Project Management Challenges",
      "authors": [
        "A. Bahi",
        "Jihane Gharib",
        "Youssef Gahi"
      ],
      "published_date": "2024",
      "abstract": "— Agile software development emphasizes iterative progress, adaptability, and stakeholder collaboration. It champions flexible planning, continuous improvement, and rapid delivery, aiming to respond swiftly to change and deliver value efficiently. Integrating Generative Artificial Intelligence (AI) into Agile software development processes presents a promising avenue for overcoming project management challenges and enhancing the efficiency and effectiveness of software development endeavors. This paper explores the potential benefits of leveraging Generative AI in Agile methodologies, aiming to streamline development workflows, foster innovation, and mitigate common project management challenges. By harnessing the capabilities of Generative AI for tasks such as code generation, automated testing, and predictive analytics, Agile teams can augment their productivity, accelerate delivery cycles, and improve the quality of software products. Additionally, Generative AI offers opportunities for enhancing collaboration, facilitating decision-making, and addressing uncertainties inherent in Agile project management. Through an in-depth analysis of the integration of Generative AI within Agile frameworks, this paper provides insights into how organizations can harness the transformative potential of AI to advance Agile software development practices and navigate the complexities of modern software projects more effectively.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9eb9cf56cc8b616c121c0c90c2419480e9747765.pdf",
      "venue": "International Journal of Advanced Computer Science and Applications",
      "citationCount": 19,
      "score": 19.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of integrating Generative Artificial Intelligence (GenAI) into Agile software development processes to overcome common project management difficulties and enhance efficiency \\cite{bahi2024m17}.\n    *   **Importance and Challenge**: Agile methodologies, while emphasizing adaptability and rapid delivery, still face significant \"pain points\" such as issues with requirement management, managerial and stakeholder support, role clarity, team member overlap, understanding of agile processes, resistance to change, effort prediction, and sufficient technical expertise. The integration of GenAI offers a promising avenue to automate tasks and improve decision-making, but research on its explicit integration within Agile frameworks, particularly with real-world case studies, is still in its early stages \\cite{bahi2024m17}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon established Agile methodologies (e.g., Scrum, XP, Kanban, SAFe) and their associated ceremonies and artifacts. It acknowledges the historical use of search engines and Q&A sites by developers for problem-solving \\cite{bahi2024m17}.\n    *   **Limitations of Previous Solutions**: Traditional Agile approaches, despite their benefits, struggle with persistent challenges like resistance to adopting new practices, lack of upper management participation, technical support issues, and difficulties in scaling to large projects. Existing GenAI tools (e.g., CoPilot, GPT, Bard) have shown productivity gains but their systematic integration into Agile to address specific pain points is underexplored, with a noted absence of significant case studies in the literature \\cite{bahi2024m17}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper explores the potential benefits of GenAI in Agile and proposes an \"adapted framework\" for its explicit integration into a commonly used Agile methodology. The approach leverages GenAI for tasks such as code generation, automated testing, predictive analytics, documentation, ideation, and providing insights into project metrics and risks \\cite{bahi2024m17}.\n    *   **Novelty**: The innovation lies in conceptualizing \"intelligent project management\" through the application of GenAI to automate and enhance various aspects of the Agile process. The paper's novelty is in presenting a structured framework for this integration, aiming to provide a practical perspective on how GenAI can address specific Agile pain points, which is an area lacking significant academic attention and case studies \\cite{bahi2024m17}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**: The primary contribution is the *proposal of an adapted framework* for integrating Generative AI into Agile software development practices. This framework aims to map GenAI capabilities to specific Agile pain points, offering solutions for areas like requirement management, effort prediction, and team collaboration \\cite{bahi2024m17}.\n    *   **Theoretical Insights or Analysis**: The paper provides an in-depth analysis of common Agile pain points, categorizing them (e.g., project, personnel, methods, persistence, estimated effort) and visualizing them using a fishbone diagram. It then theoretically links GenAI's capabilities (e.g., content generation, data analysis, decision support) to mitigate these identified challenges \\cite{bahi2024m17}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The provided paper content *does not describe any experimental validation, case studies, or empirical results*. It states the *goal* is to \"give a real case study of how this can be achieved,\" implying this is a future or ongoing effort not presented in this publication \\cite{bahi2024m17}.\n    *   **Key Performance Metrics and Comparison Results**: No performance metrics or comparative results are presented, as the paper focuses on the theoretical integration and framework proposal.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper acknowledges that GenAI introduces new risks, such as Intellectual Property Rights (IPR) and cybersecurity concerns, due to its non-deterministic and less explicable nature. It also highlights that research on GenAI integration into Agile is nascent, with a lack of significant case studies \\cite{bahi2024m17}.\n    *   **Scope of Applicability**: The proposed framework and analysis are applicable to Agile software development projects, particularly those seeking to enhance efficiency and mitigate common project management challenges through AI integration. The framework is intended for \"one of the most commonly used agile methodology by developers\" \\cite{bahi2024m17}.\n\n*   **Technical Significance**\n    *   **Advance the Technical State-of-the-Art**: This paper advances the state-of-the-art by providing a structured conceptual framework for systematically integrating Generative AI into Agile methodologies. It moves beyond general discussions of AI in software engineering to specifically address how GenAI can tackle identified Agile pain points, filling a gap in current literature \\cite{bahi2024m17}.\n    *   **Potential Impact on Future Research**: The work is crucial for guiding academics and practitioners by highlighting current applications and shaping future studies on GenAI in Agile. It lays the groundwork for future empirical research and case studies on the practical implementation, benefits, and challenges of GenAI-enhanced Agile development, potentially leading to accelerated development cycles, improved collaboration, and enhanced product quality \\cite{bahi2024m17}.",
      "keywords": [
        "Generative AI (GenAI)",
        "Agile software development",
        "Agile pain points",
        "GenAI integration framework",
        "Intelligent project management",
        "Requirement management",
        "Effort prediction",
        "Automated testing",
        "Code generation",
        "Predictive analytics",
        "Theoretical framework proposal",
        "Software engineering",
        "Cybersecurity risks",
        "Lack of empirical validation"
      ],
      "paper_type": "based on the abstract and introduction:\n\n1.  **abstract analysis:**\n    *   \"integrating generative artificial intelligence (ai) into agile software development processes presents a promising avenue for overcoming project management challenges...\" - highlights a new direction/solution.\n    *   \"this paper explores the potential benefits of leveraging generative ai in agile methodologies, aiming to streamline development workflows, foster innovation, and mitigate common project management challenges.\" - focuses on potential, aims, and benefits, suggesting an advocacy for a particular approach.\n    *   \"by harnessing the capabilities of generative ai... agile teams can augment their productivity, accelerate delivery cycles, and improve the quality...\" - describes the positive impact of this integration.\n    *   \"through an in-depth analysis of the integration of generative ai within agile frameworks, this paper provides insights into how organizations can harness the transformative potential of ai to advance agile software development practices...\" - offers guidance and a vision for the future.\n\n2.  **introduction analysis:**\n    *   \"as agile project management demands meticulous discipline for successful software development, exploring ai to enhance this process presents a novel and compelling research domain.\" - emphasizes the novelty and importance of this exploration.\n    *   \"with ai's growing capabilities, there is curiosity about whether certain aspects of project management today may be automated or if some activities are delegated to ai...\" - poses a question about future possibilities and the role of ai.\n\n**classification rationale:**\n\n*   the paper **does not** explicitly state it's a \"survey\" or \"review\" of existing literature, nor does it discuss literature organization or classification schemes. while it performs an \"in-depth analysis,\" the primary goal seems to be advocating for a new approach rather than summarizing the current state of a well-established field.\n*   it **does not** present a new \"method,\" \"algorithm,\" or \"system\" in a technical sense, but rather discusses the *integration* and *potential benefits* of existing generative ai capabilities.\n*   it **does not** involve mathematical analysis, proofs, or formal models, ruling out \"theoretical.\"\n*   it **does not** describe an experiment, data collection, or statistical analysis, ruling out \"empirical.\"\n*   it **does not** focus on a specific real-world application or company, ruling out \"case_study.\"\n*   it **does not** provide indicators of being a \"short\" communication or work-in-progress.\n\nthe paper strongly aligns with the \"position\" type. it identifies current challenges in agile project management and argues for a specific viewpoint: that integrating generative ai is a \"promising avenue\" and a \"novel and compelling research domain\" that can \"advance agile software development practices.\" it presents a vision for the future, discusses potential benefits, and provides insights into how organizations \"can harness\" this transformative potential. this is a clear argument for a particular direction and approach.\n\n**conclusion:** the paper is best classified as a **position** paper."
    },
    "file_name": "9eb9cf56cc8b616c121c0c90c2419480e9747765.pdf"
  },
  {
    "success": true,
    "doc_id": "f0a1426fd18bf6502b9b73af3875d0db",
    "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Problem:** The paper addresses the challenge and opportunity of integrating Artificial Intelligence (AI) and Machine Learning (ML) into front-end development \\cite{ekpobimi2024ryu}.\n    *   **Motivation:** This integration is crucial for transforming software development by automating routine tasks, enhancing predictive capabilities, and improving user engagement. The goal is to revolutionize how digital applications are created and experienced, moving beyond traditional static designs to more intelligent, adaptive, and personalized user interfaces \\cite{ekpobimi2024ryu}. The U.S. tech sector's competitive edge also depends on innovation in this rapidly evolving field.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper positions itself as a comprehensive overview of the shift from traditional front-end technologies (HTML, CSS, JavaScript) and frameworks (React, Angular, Vue.js) towards more intelligent and adaptive systems powered by AI and ML \\cite{ekpobimi2024ryu}. It synthesizes current applications and emerging trends.\n    *   **Limitations of Previous Solutions:** Implicitly, the paper highlights the limitations of non-AI/ML approaches in terms of efficiency (manual coding, testing), personalization (static interfaces), and responsiveness (lack of real-time adaptation), which AI/ML integration aims to overcome \\cite{ekpobimi2024ryu}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper discusses the application of AI and ML techniques across various aspects of front-end development, rather than proposing a single novel method. Key areas include:\n        *   **Automation:** Leveraging AI for code generation (e.g., code suggestion engines, auto-completion) and automated testing/debugging (AI-powered frameworks that learn and adapt) \\cite{ekpobimi2024ryu}.\n        *   **Predictive Analytics:** Utilizing ML algorithms to analyze user data, identify patterns, and make predictions for personalization (e.g., content/product recommendations) and real-time decision-making (e.g., adaptive UIs, CDN content pre-loading) \\cite{ekpobimi2024ryu}.\n        *   **Natural Language Processing (NLP):** Employing NLP for conversational interfaces (chatbots, virtual assistants) and sentiment analysis to enhance user interaction \\cite{ekpobimi2024ryu}.\n        *   **Adaptive Interfaces:** Designing UIs that dynamically adjust layout, content, and functionality based on real-time user behavior and preferences \\cite{ekpobimi2024ryu}.\n    *   **Novelty/Difference:** The paper's novelty lies in its comprehensive synthesis of how these diverse AI/ML techniques are converging to redefine front-end development, offering a roadmap for future integration and addressing associated challenges \\cite{ekpobimi2024ryu}.\n\n*   **Key Technical Contributions**\n    *   **Synthesis of Innovations:** The paper's primary contribution is a structured overview of how AI and ML are technically applied to:\n        *   Automate routine tasks like code generation (e.g., GitHub Copilot) and testing/debugging, improving efficiency and reducing errors \\cite{ekpobimi2024ryu}.\n        *   Enhance predictive capabilities for deep personalization (e.g., e-commerce recommendations) and real-time adaptive UI/UX optimization \\cite{ekpobimi2024ryu}.\n        *   Improve user engagement through intelligent, adaptive interfaces, NLP-driven chatbots, and immersive AR/VR experiences \\cite{ekpobimi2024ryu}.\n    *   **Categorization of Trends:** It identifies and categorizes existing integrations (e.g., content recommendations, virtual assistants, AI in design tools like Adobe Sensei, AI-driven testing frameworks like Testim) and emerging trends (e.g., AI-powered design generation, voice user interfaces, truly adaptive UIs) \\cite{ekpobimi2024ryu}.\n\n*   **Experimental Validation**\n    *   The paper is a review and does not present novel experimental data or empirical validation from the authors' own research.\n    *   **Discussion of Observed Benefits:** Instead, it references the observed benefits and performance improvements from existing, widely adopted applications and tools that have integrated AI/ML. Examples include:\n        *   The effectiveness of AI-driven recommendation systems on platforms like Netflix and Amazon in driving user engagement and satisfaction \\cite{ekpobimi2024ryu}.\n        *   The efficiency gains from AI-powered code suggestion tools like GitHub Copilot in accelerating coding and reducing errors \\cite{ekpobimi2024ryu}.\n        *   The improved user experience and efficiency offered by AI-driven virtual assistants (Siri, Alexa) and chatbots \\cite{ekpobimi2024ryu}.\n        *   The enhanced quality and consistency in design workflows using AI-powered features in tools like Adobe Sensei and Figma \\cite{ekpobimi2024ryu}.\n        *   The robustness and reliability achieved through AI-driven testing frameworks like Testim and Applitools \\cite{ekpobimi2024ryu}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The paper acknowledges significant technical challenges inherent in AI/ML integration, including the complexity of AI systems, performance concerns (e.g., latency, computational overhead), and the need for specialized skills \\cite{ekpobimi2024ryu}.\n    *   **Ethical Considerations:** It highlights critical ethical issues such as data privacy, algorithmic bias, and the responsible use of AI in user-facing applications \\cite{ekpobimi2024ryu}.\n    *   **Scope of Applicability:** The paper's scope is focused specifically on front-end development, discussing its impact across various digital applications, from web and mobile to AR/VR interfaces \\cite{ekpobimi2024ryu}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** The paper significantly advances the technical state-of-the-art by providing a comprehensive, forward-looking analysis of how AI and ML are fundamentally reshaping front-end development. It moves beyond theoretical discussions to detail practical applications and emerging paradigms \\cite{ekpobimi2024ryu}.\n    *   **Potential Impact on Future Research:** It serves as a roadmap, identifying key areas for future research and innovation, particularly in addressing the technical and ethical challenges of AI/ML integration. It underscores the importance of continued investment in R&D to maintain competitiveness and ensure positive contributions to software development \\cite{ekpobimi2024ryu}.",
    "intriguing_abstract": "The landscape of front-end development is undergoing a profound transformation, driven by the strategic integration of Artificial Intelligence (AI) and Machine Learning (ML). This paper offers a comprehensive synthesis, charting the convergence of diverse AI/ML techniques that are revolutionizing how digital applications are built and experienced. We explore how AI/ML empowers unprecedented **automation** in code generation and testing, enhances **predictive analytics** for deep **personalization** and real-time decision-making, and leverages **Natural Language Processing (NLP)** for intuitive conversational interfaces.\n\nMoving beyond static designs, this work highlights the emergence of truly **adaptive user interfaces (UIs)** that dynamically respond to user behavior, significantly improving **user experience (UX)** and engagement. By providing a structured overview of current applications and emerging trends, this paper serves as a critical roadmap for researchers and developers navigating this evolving domain. It underscores the immense potential for efficiency gains, innovative interaction paradigms, and maintaining a competitive edge in the tech sector, while also acknowledging inherent technical and ethical challenges. This forward-looking analysis positions AI/ML as indispensable for the future of intelligent, adaptive front-end systems.",
    "keywords": [
      "AI/ML integration",
      "front-end development",
      "automated code generation",
      "predictive analytics",
      "adaptive user interfaces",
      "Natural Language Processing (NLP)",
      "user engagement",
      "comprehensive synthesis",
      "real-time UI/UX optimization",
      "algorithmic bias",
      "data privacy",
      "software development automation",
      "AR/VR interfaces"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f0953d67eed1d0da53a321a3731c086e754e775e.pdf",
    "citation_key": "ekpobimi2024ryu",
    "metadata": {
      "title": "The future of software development: integrating AI and machine learning into front-end technologies",
      "authors": [
        "Harrison Oke Ekpobimi",
        "Regina Coelis Kandekere",
        "Adebamigbe Fasanmade"
      ],
      "published_date": "2024",
      "abstract": "This paper explores the integration of artificial intelligence (AI) and machine learning into front-end development, highlighting the transformative potential these technologies hold for the future of software development. By automating routine tasks, enhancing predictive capabilities, and improving user engagement, AI and machine learning are set to revolutionize how digital applications are created and experienced. However, this integration is accompanied by significant technical challenges, including the complexity of AI systems, performance concerns, and ethical issues such as data privacy and bias. The paper also discusses current applications and emerging trends in AI-powered front-end technologies, providing a comprehensive overview of the benefits and obstacles. It emphasizes the importance of ongoing research, innovation, and ethical considerations in maintaining the U.S. tech sector's competitive edge in this rapidly evolving field. The findings suggest that while AI and machine learning offer substantial opportunities for innovation, careful implementation is essential to ensure these technologies contribute positively to the future of software development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f0953d67eed1d0da53a321a3731c086e754e775e.pdf",
      "venue": "Global Journal of Advanced Research and Reviews",
      "citationCount": 19,
      "score": 19.0,
      "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Problem:** The paper addresses the challenge and opportunity of integrating Artificial Intelligence (AI) and Machine Learning (ML) into front-end development \\cite{ekpobimi2024ryu}.\n    *   **Motivation:** This integration is crucial for transforming software development by automating routine tasks, enhancing predictive capabilities, and improving user engagement. The goal is to revolutionize how digital applications are created and experienced, moving beyond traditional static designs to more intelligent, adaptive, and personalized user interfaces \\cite{ekpobimi2024ryu}. The U.S. tech sector's competitive edge also depends on innovation in this rapidly evolving field.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper positions itself as a comprehensive overview of the shift from traditional front-end technologies (HTML, CSS, JavaScript) and frameworks (React, Angular, Vue.js) towards more intelligent and adaptive systems powered by AI and ML \\cite{ekpobimi2024ryu}. It synthesizes current applications and emerging trends.\n    *   **Limitations of Previous Solutions:** Implicitly, the paper highlights the limitations of non-AI/ML approaches in terms of efficiency (manual coding, testing), personalization (static interfaces), and responsiveness (lack of real-time adaptation), which AI/ML integration aims to overcome \\cite{ekpobimi2024ryu}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper discusses the application of AI and ML techniques across various aspects of front-end development, rather than proposing a single novel method. Key areas include:\n        *   **Automation:** Leveraging AI for code generation (e.g., code suggestion engines, auto-completion) and automated testing/debugging (AI-powered frameworks that learn and adapt) \\cite{ekpobimi2024ryu}.\n        *   **Predictive Analytics:** Utilizing ML algorithms to analyze user data, identify patterns, and make predictions for personalization (e.g., content/product recommendations) and real-time decision-making (e.g., adaptive UIs, CDN content pre-loading) \\cite{ekpobimi2024ryu}.\n        *   **Natural Language Processing (NLP):** Employing NLP for conversational interfaces (chatbots, virtual assistants) and sentiment analysis to enhance user interaction \\cite{ekpobimi2024ryu}.\n        *   **Adaptive Interfaces:** Designing UIs that dynamically adjust layout, content, and functionality based on real-time user behavior and preferences \\cite{ekpobimi2024ryu}.\n    *   **Novelty/Difference:** The paper's novelty lies in its comprehensive synthesis of how these diverse AI/ML techniques are converging to redefine front-end development, offering a roadmap for future integration and addressing associated challenges \\cite{ekpobimi2024ryu}.\n\n*   **Key Technical Contributions**\n    *   **Synthesis of Innovations:** The paper's primary contribution is a structured overview of how AI and ML are technically applied to:\n        *   Automate routine tasks like code generation (e.g., GitHub Copilot) and testing/debugging, improving efficiency and reducing errors \\cite{ekpobimi2024ryu}.\n        *   Enhance predictive capabilities for deep personalization (e.g., e-commerce recommendations) and real-time adaptive UI/UX optimization \\cite{ekpobimi2024ryu}.\n        *   Improve user engagement through intelligent, adaptive interfaces, NLP-driven chatbots, and immersive AR/VR experiences \\cite{ekpobimi2024ryu}.\n    *   **Categorization of Trends:** It identifies and categorizes existing integrations (e.g., content recommendations, virtual assistants, AI in design tools like Adobe Sensei, AI-driven testing frameworks like Testim) and emerging trends (e.g., AI-powered design generation, voice user interfaces, truly adaptive UIs) \\cite{ekpobimi2024ryu}.\n\n*   **Experimental Validation**\n    *   The paper is a review and does not present novel experimental data or empirical validation from the authors' own research.\n    *   **Discussion of Observed Benefits:** Instead, it references the observed benefits and performance improvements from existing, widely adopted applications and tools that have integrated AI/ML. Examples include:\n        *   The effectiveness of AI-driven recommendation systems on platforms like Netflix and Amazon in driving user engagement and satisfaction \\cite{ekpobimi2024ryu}.\n        *   The efficiency gains from AI-powered code suggestion tools like GitHub Copilot in accelerating coding and reducing errors \\cite{ekpobimi2024ryu}.\n        *   The improved user experience and efficiency offered by AI-driven virtual assistants (Siri, Alexa) and chatbots \\cite{ekpobimi2024ryu}.\n        *   The enhanced quality and consistency in design workflows using AI-powered features in tools like Adobe Sensei and Figma \\cite{ekpobimi2024ryu}.\n        *   The robustness and reliability achieved through AI-driven testing frameworks like Testim and Applitools \\cite{ekpobimi2024ryu}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations:** The paper acknowledges significant technical challenges inherent in AI/ML integration, including the complexity of AI systems, performance concerns (e.g., latency, computational overhead), and the need for specialized skills \\cite{ekpobimi2024ryu}.\n    *   **Ethical Considerations:** It highlights critical ethical issues such as data privacy, algorithmic bias, and the responsible use of AI in user-facing applications \\cite{ekpobimi2024ryu}.\n    *   **Scope of Applicability:** The paper's scope is focused specifically on front-end development, discussing its impact across various digital applications, from web and mobile to AR/VR interfaces \\cite{ekpobimi2024ryu}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** The paper significantly advances the technical state-of-the-art by providing a comprehensive, forward-looking analysis of how AI and ML are fundamentally reshaping front-end development. It moves beyond theoretical discussions to detail practical applications and emerging paradigms \\cite{ekpobimi2024ryu}.\n    *   **Potential Impact on Future Research:** It serves as a roadmap, identifying key areas for future research and innovation, particularly in addressing the technical and ethical challenges of AI/ML integration. It underscores the importance of continued investment in R&D to maintain competitiveness and ensure positive contributions to software development \\cite{ekpobimi2024ryu}.",
      "keywords": [
        "AI/ML integration",
        "front-end development",
        "automated code generation",
        "predictive analytics",
        "adaptive user interfaces",
        "Natural Language Processing (NLP)",
        "user engagement",
        "comprehensive synthesis",
        "real-time UI/UX optimization",
        "algorithmic bias",
        "data privacy",
        "software development automation",
        "AR/VR interfaces"
      ],
      "paper_type": "based on the abstract and introduction, this paper best fits the **position** type.\n\nhere's why:\n\n*   **abstract mentions:**\n    *   \"highlighting the transformative potential these technologies hold for the **future** of software development.\" (vision, future)\n    *   \"it **emphasizes the importance** of ongoing research, innovation, and ethical considerations...\" (argues for a viewpoint, \"should\")\n    *   \"the findings **suggest that while ai and machine learning offer substantial opportunities for innovation, careful implementation is essential** to ensure these technologies contribute positively to the future of software development.\" (argues for a viewpoint, \"should\")\n*   **introduction discusses:**\n    *   the evolution of front-end development and the **need** for more intelligent and adaptive systems, leading to interest in ai/ml integration. this sets up the current problems and the proposed direction the paper will advocate for.\n\nwhile it does provide an \"overview of the benefits and obstacles\" (which has some overlap with a survey), its primary thrust is to argue for a specific viewpoint regarding the future integration of ai/ml into front-end development, emphasizing challenges, ethical considerations, and the importance of careful implementation. it's not primarily reviewing existing literature comprehensively with classification schemes, nor is it presenting new technical methods, empirical data, or theoretical proofs."
    },
    "file_name": "f0953d67eed1d0da53a321a3731c086e754e775e.pdf"
  },
  {
    "success": true,
    "doc_id": "45c0ee4194d09cf5b443eaf0f511e267",
    "summary": "Cervical cancer, the fourth most common cancer among women worldwide, often proves fatal and stems from precursor lesions caused by high-risk human papillomavirus (HR-HPV) infection. Accurate and early diagnosis is crucial for effective treatment. Current screening methods, such as the Pap test, liquid-based cytology (LBC), visual inspection with acetic acid (VIA), and HPV DNA testing, have limitations, requiring confirmation through colposcopy. This study introduces CerviCARE AI, an artificial intelligence (AI) analysis software, to address colposcopy challenges. It automatically analyzes Tele-cervicography images, distinguishing between low-grade and high-grade lesions. In a multicenter retrospective study, CerviCARE AI achieved a remarkable sensitivity of 98% for high-risk groups (P2, P3, HSIL or higher, CIN2 or higher) and a specificity of 95.5%. These findings underscore CerviCARE AI's potential as a valuable diagnostic tool for highly accurate identification of cervical precancerous lesions. While further prospective research is needed to validate its clinical utility, this AI system holds promise for improving cervical cancer screening and lessening the burden of this deadly disease.",
    "intriguing_abstract": "Cervical cancer, the fourth most common cancer among women worldwide, often proves fatal and stems from precursor lesions caused by high-risk human papillomavirus (HR-HPV) infection. Accurate and early diagnosis is crucial for effective treatment. Current screening methods, such as the Pap test, liquid-based cytology (LBC), visual inspection with acetic acid (VIA), and HPV DNA testing, have limitations, requiring confirmation through colposcopy. This study introduces CerviCARE AI, an artificial intelligence (AI) analysis software, to address colposcopy challenges. It automatically analyzes Tele-cervicography images, distinguishing between low-grade and high-grade lesions. In a multicenter retrospective study, CerviCARE AI achieved a remarkable sensitivity of 98% for high-risk groups (P2, P3, HSIL or higher, CIN2 or higher) and a specificity of 95.5%. These findings underscore CerviCARE AI's potential as a valuable diagnostic tool for highly accurate identification of cervical precancerous lesions. While further prospective research is needed to validate its clinical utility, this AI system holds promise for improving cervical cancer screening and lessening the burden of this deadly disease.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/0ce7fea8000be3e43c581057734d01aaa4b240d8.pdf",
    "citation_key": "ouh2024bgk",
    "metadata": {
      "title": "Development and validation of artificial intelligence-based analysis software to support screening system of cervical intraepithelial neoplasia",
      "authors": [
        "Y. Ouh",
        "Tae Jin Kim",
        "Woong Ju",
        "Sang Wun Kim",
        "S. Jeon",
        "Soonyung Kim",
        "Kwang Gi Kim",
        "Jae-Kwan Lee"
      ],
      "published_date": "2024",
      "abstract": "Cervical cancer, the fourth most common cancer among women worldwide, often proves fatal and stems from precursor lesions caused by high-risk human papillomavirus (HR-HPV) infection. Accurate and early diagnosis is crucial for effective treatment. Current screening methods, such as the Pap test, liquid-based cytology (LBC), visual inspection with acetic acid (VIA), and HPV DNA testing, have limitations, requiring confirmation through colposcopy. This study introduces CerviCARE AI, an artificial intelligence (AI) analysis software, to address colposcopy challenges. It automatically analyzes Tele-cervicography images, distinguishing between low-grade and high-grade lesions. In a multicenter retrospective study, CerviCARE AI achieved a remarkable sensitivity of 98% for high-risk groups (P2, P3, HSIL or higher, CIN2 or higher) and a specificity of 95.5%. These findings underscore CerviCARE AI's potential as a valuable diagnostic tool for highly accurate identification of cervical precancerous lesions. While further prospective research is needed to validate its clinical utility, this AI system holds promise for improving cervical cancer screening and lessening the burden of this deadly disease.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/0ce7fea8000be3e43c581057734d01aaa4b240d8.pdf",
      "venue": "Scientific Reports",
      "citationCount": 19,
      "score": 19.0,
      "summary": "Cervical cancer, the fourth most common cancer among women worldwide, often proves fatal and stems from precursor lesions caused by high-risk human papillomavirus (HR-HPV) infection. Accurate and early diagnosis is crucial for effective treatment. Current screening methods, such as the Pap test, liquid-based cytology (LBC), visual inspection with acetic acid (VIA), and HPV DNA testing, have limitations, requiring confirmation through colposcopy. This study introduces CerviCARE AI, an artificial intelligence (AI) analysis software, to address colposcopy challenges. It automatically analyzes Tele-cervicography images, distinguishing between low-grade and high-grade lesions. In a multicenter retrospective study, CerviCARE AI achieved a remarkable sensitivity of 98% for high-risk groups (P2, P3, HSIL or higher, CIN2 or higher) and a specificity of 95.5%. These findings underscore CerviCARE AI's potential as a valuable diagnostic tool for highly accurate identification of cervical precancerous lesions. While further prospective research is needed to validate its clinical utility, this AI system holds promise for improving cervical cancer screening and lessening the burden of this deadly disease.",
      "keywords": []
    },
    "file_name": "0ce7fea8000be3e43c581057734d01aaa4b240d8.pdf"
  },
  {
    "success": true,
    "doc_id": "653fc2ed4bb587bf5d2c6eecffe65a3b",
    "summary": "Here's a focused summary of the paper \\cite{pandey2024dcu} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   This paper addresses the specific technical problem of systematically evaluating the efficiency gains, identifying areas for improvement, and understanding emerging challenges associated with using GitHub Copilot, an AI-powered coding assistant, in real-world software development projects.\n    *   This problem is important and challenging because generative AI technologies are rapidly transforming software development, necessitating a robust, empirical understanding of their practical benefits and pitfalls beyond synthetic benchmarks, especially within large, proprietary codebases and diverse enterprise contexts.\n\n*   **Related Work & Positioning**\n    *   Previous studies have evaluated Copilot's output for correctness, understandability (e.g., on LeetCode), program synthesis capabilities, usability, algorithmic problem-solving, programmer interaction modes, perceived productivity, and security vulnerabilities (e.g., 40% insecure code generation).\n    *   The limitations of previous solutions, as implied by \\cite{pandey2024dcu}, often stem from their reliance on synthetic coding problems. This work positions itself as novel by conducting its evaluation on \"real-world software projects, utilizing large existing codebases\" and assessing 15 distinct software development tasks, aiming for greater relevance to practical enterprise software engineering contexts.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method involved a structured empirical evaluation with a study group of 26 engineers (ranging from junior to senior) who used GitHub Copilot as part of their everyday coding tasks within a full-stack cloud software development environment. GitHub Copilot was *not* finetuned or trained on the internal codebases.\n    *   This approach is novel due to its focus on:\n        *   **Real-world, proprietary contexts**: Evaluation on large, existing proprietary codebases at Cisco Systems Inc., rather than synthetic problems.\n        *   **Comprehensive task coverage**: Identified and assessed Copilot's benefits across 15 distinct software development tasks (e.g., new code development, refactoring, documentation, unit test generation, debugging, CI/CD development).\n        *   **Task complexity analysis**: Tasks were categorized by type and complexity (repetitive, boilerplate, small function/context, complex multi-file) to understand performance variations.\n        *   **Multi-language evaluation**: Covered a wide range of programming languages (C/C++, Golang, Python, JavaScript/PHP, scripting languages, config formats).\n        *   **Empirical data collection**: Developers maintained detailed logs of interactions, efficiency changes, and challenges, with a baseline comparison to work without Copilot.\n\n*   **Key Technical Contributions**\n    *   **Quantified Productivity Gains**: Provided specific, empirically validated time savings for various software development tasks, projecting a 33-36% overall time reduction for coding-related tasks in a cloud-first SDLC.\n    *   **Identified Performance Scenarios**: Clearly delineated specific tasks and complexities where Copilot excels (e.g., documentation, autocompletion, repetitive tasks, fixing linter errors) and where it struggles significantly (e.g., complex multi-file tasks, large proprietary contexts, C/C++ code, generating optimized code, mocking for unit tests).\n    *   **Language-Specific Efficacy**: Demonstrated significant variance in Copilot's effectiveness across programming languages, highlighting strong performance in JavaScript/Java and notable weaknesses in C/C++.\n    *   **Practical Integration Insights**: Discussed emerging challenges related to code quality (variability, need for review, impact of context quality), security (implied by the need for review), and developer experience in an enterprise setting.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: A structured evaluation involving 26 engineers using GitHub Copilot for their daily tasks on large proprietary codebases in a full-stack cloud environment. The study compared efficiency with and without Copilot.\n    *   **Key Performance Metrics & Results**:\n        *   **Overall Time Savings**: Average 35% reduction in coding time.\n        *   **Task-Specific Savings**:\n            *   Highest (over 50%): Code documentation, Doxygen generation, CI/CD-related tasks (deployment scripts, log analysis, Docker optimization).\n            *   Significant (30-40%): Repetitive coding, unit test generation, debugging, pair programming, fixing compiler/linter errors, autocompletion.\n            *   Lowest utility/acceptance: Complex custom algorithms, code not following existing patterns, un-optimized code, mocking objects for unit tests.\n        *   **Language Performance**:\n            *   Best: JavaScript (~50% time savings), Java (~45%).\n            *   Moderate: Golang, Python, scripting/config languages (33-37%).\n            *   Struggled: C/C++ (often failed to generate useful code, lacked basic quality practices like null checking, basic explanations).\n        *   **Complexity Performance**:\n            *   Highest (up to 60%): Repetitive tasks.\n            *   Good: Boilerplate code, small function/context code.\n            *   Poor (around 26%): Complex multi-file tasks or those requiring understanding large local context.\n        *   **Code Quality**: Variable; improved with detailed/few-shot prompting and more context (open files, descriptive names). Thorough review was always necessary.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations of Copilot**: Struggles with complex tasks, large functions, multiple files, and proprietary contexts. It often fails to generate useful code for C/C++, can produce un-optimized code, struggles with mocking objects for unit tests, and requires manual input for complex CI/CD setups. It also showed limitations in understanding OS-specific variations in low-level code.\n    *   **Scope of Applicability**: The study was conducted within a specific enterprise context (Cisco Systems Inc., Security Business Group) on large proprietary codebases in a cloud-first software development lifecycle. While the findings are highly relevant to enterprise software development, they might not generalize perfectly to all development environments or project types.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing one of the most comprehensive empirical evaluations of GitHub Copilot in a real-world, enterprise setting. It moves beyond theoretical discussions and synthetic benchmarks to quantify actual productivity gains and pinpoint specific technical limitations across a diverse set of tasks, languages, and complexities.\n    *   The potential impact on future research includes guiding the development of next-generation AI coding assistants to address identified weaknesses (e.g., better handling of complex proprietary contexts, multi-file changes, C/C++ support, code optimization, advanced unit test generation). It also provides a robust framework for organizations to strategically integrate AI tools into their SDLC, informing decisions on where AI can provide maximum benefit and where human expertise remains indispensable for code quality, security, and performance.",
    "intriguing_abstract": "The rapid evolution of generative AI is reshaping software development, yet a robust empirical understanding of its real-world impact, especially within large enterprise contexts, remains elusive. This paper presents a groundbreaking, large-scale empirical evaluation of **GitHub Copilot's** efficacy, moving beyond synthetic benchmarks to analyze its performance across 15 distinct **software development tasks** within **proprietary codebases** at Cisco Systems Inc. Our study involved 26 engineers in a full-stack cloud environment, revealing a significant 33-36% overall time reduction in coding-related tasks.\n\nWe precisely quantify **productivity gains**, identifying scenarios where this **AI-powered coding assistant** excels (e.g., documentation, repetitive tasks, **JavaScript/Java**, **CI/CD** scripting) and where it struggles (e.g., complex multi-file changes, **C/C++**, optimized code, **unit test** mocking). This research provides critical insights into **language-specific performance**, the nuanced challenges of **code quality**, and developer experience in an **enterprise SDLC**. Our findings offer an essential framework for strategically integrating AI tools, guiding future **AI assistant** development to address identified limitations, and optimizing human-AI collaboration for enhanced software engineering productivity and quality.",
    "keywords": [
      "GitHub Copilot empirical evaluation",
      "real-world enterprise software development",
      "proprietary codebases",
      "quantified productivity gains",
      "software development task analysis",
      "multi-language performance evaluation",
      "AI coding assistant limitations",
      "code quality and developer experience",
      "cloud-first SDLC",
      "C/C++ code generation challenges",
      "repetitive task automation",
      "complex multi-file task support"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/0f34a8d56ce65c62d5ac1e51e9b7e34b3ac96813.pdf",
    "citation_key": "pandey2024dcu",
    "metadata": {
      "title": "Transforming Software Development: Evaluating the Efficiency and Challenges of GitHub Copilot in Real-World Projects",
      "authors": [
        "Ruchika Pandey",
        "Prabhat Singh",
        "Raymond Wei",
        "Shaila Shankar"
      ],
      "published_date": "2024",
      "abstract": "Generative AI technologies promise to transform the product development lifecycle. This study evaluates the efficiency gains, areas for improvement, and emerging challenges of using GitHub Copilot, an AI-powered coding assistant. We identified 15 software development tasks and assessed Copilot's benefits through real-world projects on large proprietary code bases. Our findings indicate significant reductions in developer toil, with up to 50% time saved in code documentation and autocompletion, and 30-40% in repetitive coding tasks, unit test generation, debugging, and pair programming. However, Copilot struggles with complex tasks, large functions, multiple files, and proprietary contexts, particularly with C/C++ code. We project a 33-36% time reduction for coding-related tasks in a cloud-first software development lifecycle. This study aims to quantify productivity improvements, identify underperforming scenarios, examine practical benefits and challenges, investigate performance variations across programming languages, and discuss emerging issues related to code quality, security, and developer experience.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/0f34a8d56ce65c62d5ac1e51e9b7e34b3ac96813.pdf",
      "venue": "arXiv.org",
      "citationCount": 17,
      "score": 17.0,
      "summary": "Here's a focused summary of the paper \\cite{pandey2024dcu} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   This paper addresses the specific technical problem of systematically evaluating the efficiency gains, identifying areas for improvement, and understanding emerging challenges associated with using GitHub Copilot, an AI-powered coding assistant, in real-world software development projects.\n    *   This problem is important and challenging because generative AI technologies are rapidly transforming software development, necessitating a robust, empirical understanding of their practical benefits and pitfalls beyond synthetic benchmarks, especially within large, proprietary codebases and diverse enterprise contexts.\n\n*   **Related Work & Positioning**\n    *   Previous studies have evaluated Copilot's output for correctness, understandability (e.g., on LeetCode), program synthesis capabilities, usability, algorithmic problem-solving, programmer interaction modes, perceived productivity, and security vulnerabilities (e.g., 40% insecure code generation).\n    *   The limitations of previous solutions, as implied by \\cite{pandey2024dcu}, often stem from their reliance on synthetic coding problems. This work positions itself as novel by conducting its evaluation on \"real-world software projects, utilizing large existing codebases\" and assessing 15 distinct software development tasks, aiming for greater relevance to practical enterprise software engineering contexts.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method involved a structured empirical evaluation with a study group of 26 engineers (ranging from junior to senior) who used GitHub Copilot as part of their everyday coding tasks within a full-stack cloud software development environment. GitHub Copilot was *not* finetuned or trained on the internal codebases.\n    *   This approach is novel due to its focus on:\n        *   **Real-world, proprietary contexts**: Evaluation on large, existing proprietary codebases at Cisco Systems Inc., rather than synthetic problems.\n        *   **Comprehensive task coverage**: Identified and assessed Copilot's benefits across 15 distinct software development tasks (e.g., new code development, refactoring, documentation, unit test generation, debugging, CI/CD development).\n        *   **Task complexity analysis**: Tasks were categorized by type and complexity (repetitive, boilerplate, small function/context, complex multi-file) to understand performance variations.\n        *   **Multi-language evaluation**: Covered a wide range of programming languages (C/C++, Golang, Python, JavaScript/PHP, scripting languages, config formats).\n        *   **Empirical data collection**: Developers maintained detailed logs of interactions, efficiency changes, and challenges, with a baseline comparison to work without Copilot.\n\n*   **Key Technical Contributions**\n    *   **Quantified Productivity Gains**: Provided specific, empirically validated time savings for various software development tasks, projecting a 33-36% overall time reduction for coding-related tasks in a cloud-first SDLC.\n    *   **Identified Performance Scenarios**: Clearly delineated specific tasks and complexities where Copilot excels (e.g., documentation, autocompletion, repetitive tasks, fixing linter errors) and where it struggles significantly (e.g., complex multi-file tasks, large proprietary contexts, C/C++ code, generating optimized code, mocking for unit tests).\n    *   **Language-Specific Efficacy**: Demonstrated significant variance in Copilot's effectiveness across programming languages, highlighting strong performance in JavaScript/Java and notable weaknesses in C/C++.\n    *   **Practical Integration Insights**: Discussed emerging challenges related to code quality (variability, need for review, impact of context quality), security (implied by the need for review), and developer experience in an enterprise setting.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: A structured evaluation involving 26 engineers using GitHub Copilot for their daily tasks on large proprietary codebases in a full-stack cloud environment. The study compared efficiency with and without Copilot.\n    *   **Key Performance Metrics & Results**:\n        *   **Overall Time Savings**: Average 35% reduction in coding time.\n        *   **Task-Specific Savings**:\n            *   Highest (over 50%): Code documentation, Doxygen generation, CI/CD-related tasks (deployment scripts, log analysis, Docker optimization).\n            *   Significant (30-40%): Repetitive coding, unit test generation, debugging, pair programming, fixing compiler/linter errors, autocompletion.\n            *   Lowest utility/acceptance: Complex custom algorithms, code not following existing patterns, un-optimized code, mocking objects for unit tests.\n        *   **Language Performance**:\n            *   Best: JavaScript (~50% time savings), Java (~45%).\n            *   Moderate: Golang, Python, scripting/config languages (33-37%).\n            *   Struggled: C/C++ (often failed to generate useful code, lacked basic quality practices like null checking, basic explanations).\n        *   **Complexity Performance**:\n            *   Highest (up to 60%): Repetitive tasks.\n            *   Good: Boilerplate code, small function/context code.\n            *   Poor (around 26%): Complex multi-file tasks or those requiring understanding large local context.\n        *   **Code Quality**: Variable; improved with detailed/few-shot prompting and more context (open files, descriptive names). Thorough review was always necessary.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations of Copilot**: Struggles with complex tasks, large functions, multiple files, and proprietary contexts. It often fails to generate useful code for C/C++, can produce un-optimized code, struggles with mocking objects for unit tests, and requires manual input for complex CI/CD setups. It also showed limitations in understanding OS-specific variations in low-level code.\n    *   **Scope of Applicability**: The study was conducted within a specific enterprise context (Cisco Systems Inc., Security Business Group) on large proprietary codebases in a cloud-first software development lifecycle. While the findings are highly relevant to enterprise software development, they might not generalize perfectly to all development environments or project types.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing one of the most comprehensive empirical evaluations of GitHub Copilot in a real-world, enterprise setting. It moves beyond theoretical discussions and synthetic benchmarks to quantify actual productivity gains and pinpoint specific technical limitations across a diverse set of tasks, languages, and complexities.\n    *   The potential impact on future research includes guiding the development of next-generation AI coding assistants to address identified weaknesses (e.g., better handling of complex proprietary contexts, multi-file changes, C/C++ support, code optimization, advanced unit test generation). It also provides a robust framework for organizations to strategically integrate AI tools into their SDLC, informing decisions on where AI can provide maximum benefit and where human expertise remains indispensable for code quality, security, and performance.",
      "keywords": [
        "GitHub Copilot empirical evaluation",
        "real-world enterprise software development",
        "proprietary codebases",
        "quantified productivity gains",
        "software development task analysis",
        "multi-language performance evaluation",
        "AI coding assistant limitations",
        "code quality and developer experience",
        "cloud-first SDLC",
        "C/C++ code generation challenges",
        "repetitive task automation",
        "complex multi-file task support"
      ],
      "paper_type": "based on the abstract and introduction, this paper is best classified as **empirical**.\n\nhere's why:\n\n*   **abstract mentions:**\n    *   \"this **study evaluates** the efficiency gains...\"\n    *   \"we identified 15 software development tasks and **assessed** copilot's benefits through **real-world projects**...\"\n    *   \"our **findings indicate significant reductions** in developer toil...\"\n    *   \"this **study aims to quantify** productivity improvements, **identify** underperforming scenarios, **examine** practical benefits and challenges, **investigate** performance variations...\"\n*   **introduction discusses:**\n    *   \"necessitates a **systematic study** to understand their potential gains and pitfalls.\"\n    *   \"in this **study, we aim to quantify** the time savings and productivity improvements...\"\n    *   \"we also seek to **determine specific scenarios** and types of tasks where github copilot currently struggles...\"\n    *   \"additionally, we **examine the practical benefits and challenges** of integrating github copilot into **real-world software engineering practices**...\"\n    *   \"our **investigation also focuses on how copilot's performance varies** across different programming languages...\"\n\nthese elements strongly align with the criteria for an **empirical** paper, which involves data-driven studies, experiments, observations, and statistical analysis to present findings and answer research questions."
    },
    "file_name": "0f34a8d56ce65c62d5ac1e51e9b7e34b3ac96813.pdf"
  },
  {
    "success": true,
    "doc_id": "c97271dace8a280c79127148089c7cff",
    "summary": "In various research domains, artificial intelligence (AI) has gained significant prominence, leading to the development of numerous learning-based models in research laboratories, which are evaluated using benchmark datasets. While the models proposed in previous studies may demonstrate satisfactory performance on benchmark datasets, translating academic findings into practical applications for industry practitioners presents challenges. This can entail either the direct adoption of trained academic models into industrial applications, leading to a performance decrease, or retraining models with industrial data, a task often hindered by insufficient data instances or skewed data distributions. Real-world industrial data is typically significantly more intricate than benchmark datasets, frequently exhibiting data-skewing issues, such as label distribution skews and quantity skews. Furthermore, accessing industrial data, particularly source code, can prove challenging for Software Engineering (SE) researchers due to privacy policies. This limitation hinders SE researchers’ ability to gain insights into industry developers’ concerns and subsequently enhance their proposed models. To bridge the divide between academic models and industrial applications, we introduce a federated learning (FL)-based framework called Almity. Our aim is to simplify the process of implementing research findings into practical use for both SE researchers and industry developers. Almity enhances model performance on sensitive skewed data distributions while ensuring data privacy and security. It introduces an innovative aggregation strategy that takes into account three key attributes: data scale, data balance, and minority class learnability. This strategy is employed to refine model parameters, thereby enhancing model performance on sensitive skewed datasets. In our evaluation, we employ two well-established SE tasks, i.e., code clone detection and defect prediction, as evaluation tasks. We compare the performance of Almity on both machine learning (ML) and deep learning (DL) models against two mainstream training methods, specifically the Centralized Training Method (CTM) and Vanilla Federated Learning (VFL), to validate the effectiveness and generalizability of Almity. Our experimental results demonstrate that our framework is not only feasible but also practical in real-world scenarios. Almity consistently enhances the performance of learning-based models, outperforming baseline training methods across all types of data distributions.",
    "intriguing_abstract": "In various research domains, artificial intelligence (AI) has gained significant prominence, leading to the development of numerous learning-based models in research laboratories, which are evaluated using benchmark datasets. While the models proposed in previous studies may demonstrate satisfactory performance on benchmark datasets, translating academic findings into practical applications for industry practitioners presents challenges. This can entail either the direct adoption of trained academic models into industrial applications, leading to a performance decrease, or retraining models with industrial data, a task often hindered by insufficient data instances or skewed data distributions. Real-world industrial data is typically significantly more intricate than benchmark datasets, frequently exhibiting data-skewing issues, such as label distribution skews and quantity skews. Furthermore, accessing industrial data, particularly source code, can prove challenging for Software Engineering (SE) researchers due to privacy policies. This limitation hinders SE researchers’ ability to gain insights into industry developers’ concerns and subsequently enhance their proposed models. To bridge the divide between academic models and industrial applications, we introduce a federated learning (FL)-based framework called Almity. Our aim is to simplify the process of implementing research findings into practical use for both SE researchers and industry developers. Almity enhances model performance on sensitive skewed data distributions while ensuring data privacy and security. It introduces an innovative aggregation strategy that takes into account three key attributes: data scale, data balance, and minority class learnability. This strategy is employed to refine model parameters, thereby enhancing model performance on sensitive skewed datasets. In our evaluation, we employ two well-established SE tasks, i.e., code clone detection and defect prediction, as evaluation tasks. We compare the performance of Almity on both machine learning (ML) and deep learning (DL) models against two mainstream training methods, specifically the Centralized Training Method (CTM) and Vanilla Federated Learning (VFL), to validate the effectiveness and generalizability of Almity. Our experimental results demonstrate that our framework is not only feasible but also practical in real-world scenarios. Almity consistently enhances the performance of learning-based models, outperforming baseline training methods across all types of data distributions.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a9b3d3313e8918541c4c348fb2a95020a5242ac4.pdf",
    "citation_key": "yang2024mj7",
    "metadata": {
      "title": "Federated Learning for Software Engineering: A Case Study of Code Clone Detection and Defect Prediction",
      "authors": [
        "Yanming Yang",
        "Xing Hu",
        "Zhipeng Gao",
        "Jinfu Chen",
        "Chao Ni",
        "Xin Xia",
        "David Lo"
      ],
      "published_date": "2024",
      "abstract": "In various research domains, artificial intelligence (AI) has gained significant prominence, leading to the development of numerous learning-based models in research laboratories, which are evaluated using benchmark datasets. While the models proposed in previous studies may demonstrate satisfactory performance on benchmark datasets, translating academic findings into practical applications for industry practitioners presents challenges. This can entail either the direct adoption of trained academic models into industrial applications, leading to a performance decrease, or retraining models with industrial data, a task often hindered by insufficient data instances or skewed data distributions. Real-world industrial data is typically significantly more intricate than benchmark datasets, frequently exhibiting data-skewing issues, such as label distribution skews and quantity skews. Furthermore, accessing industrial data, particularly source code, can prove challenging for Software Engineering (SE) researchers due to privacy policies. This limitation hinders SE researchers’ ability to gain insights into industry developers’ concerns and subsequently enhance their proposed models. To bridge the divide between academic models and industrial applications, we introduce a federated learning (FL)-based framework called Almity. Our aim is to simplify the process of implementing research findings into practical use for both SE researchers and industry developers. Almity enhances model performance on sensitive skewed data distributions while ensuring data privacy and security. It introduces an innovative aggregation strategy that takes into account three key attributes: data scale, data balance, and minority class learnability. This strategy is employed to refine model parameters, thereby enhancing model performance on sensitive skewed datasets. In our evaluation, we employ two well-established SE tasks, i.e., code clone detection and defect prediction, as evaluation tasks. We compare the performance of Almity on both machine learning (ML) and deep learning (DL) models against two mainstream training methods, specifically the Centralized Training Method (CTM) and Vanilla Federated Learning (VFL), to validate the effectiveness and generalizability of Almity. Our experimental results demonstrate that our framework is not only feasible but also practical in real-world scenarios. Almity consistently enhances the performance of learning-based models, outperforming baseline training methods across all types of data distributions.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a9b3d3313e8918541c4c348fb2a95020a5242ac4.pdf",
      "venue": "IEEE Transactions on Software Engineering",
      "citationCount": 15,
      "score": 15.0,
      "summary": "In various research domains, artificial intelligence (AI) has gained significant prominence, leading to the development of numerous learning-based models in research laboratories, which are evaluated using benchmark datasets. While the models proposed in previous studies may demonstrate satisfactory performance on benchmark datasets, translating academic findings into practical applications for industry practitioners presents challenges. This can entail either the direct adoption of trained academic models into industrial applications, leading to a performance decrease, or retraining models with industrial data, a task often hindered by insufficient data instances or skewed data distributions. Real-world industrial data is typically significantly more intricate than benchmark datasets, frequently exhibiting data-skewing issues, such as label distribution skews and quantity skews. Furthermore, accessing industrial data, particularly source code, can prove challenging for Software Engineering (SE) researchers due to privacy policies. This limitation hinders SE researchers’ ability to gain insights into industry developers’ concerns and subsequently enhance their proposed models. To bridge the divide between academic models and industrial applications, we introduce a federated learning (FL)-based framework called Almity. Our aim is to simplify the process of implementing research findings into practical use for both SE researchers and industry developers. Almity enhances model performance on sensitive skewed data distributions while ensuring data privacy and security. It introduces an innovative aggregation strategy that takes into account three key attributes: data scale, data balance, and minority class learnability. This strategy is employed to refine model parameters, thereby enhancing model performance on sensitive skewed datasets. In our evaluation, we employ two well-established SE tasks, i.e., code clone detection and defect prediction, as evaluation tasks. We compare the performance of Almity on both machine learning (ML) and deep learning (DL) models against two mainstream training methods, specifically the Centralized Training Method (CTM) and Vanilla Federated Learning (VFL), to validate the effectiveness and generalizability of Almity. Our experimental results demonstrate that our framework is not only feasible but also practical in real-world scenarios. Almity consistently enhances the performance of learning-based models, outperforming baseline training methods across all types of data distributions.",
      "keywords": []
    },
    "file_name": "a9b3d3313e8918541c4c348fb2a95020a5242ac4.pdf"
  },
  {
    "success": true,
    "doc_id": "a5b6b73bca9ed6a2c3defcb2515ebb1a",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures \\cite{eisenreich20243sq}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the significant challenge of designing domain models and software architectures, particularly in deriving models that fit functional and non-functional requirements for complex or unknown domains. Architects often design only one architecture due to time pressure and limited understanding, leading to sub-optimal solutions and high maintenance costs.\n    *   **Importance and Challenge:** Software architecture is crucial for system quality. Current semi-automatic approaches for generating domain models from requirements (e.g., Kof \\cite{eisenreich20243sq}) still demand extensive manual effort. The process is time-consuming, requires deep domain knowledge, and new architects lack experience, while experienced ones may stick to familiar concepts, hindering innovation and thorough evaluation of alternatives.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   Acknowledges reviews of architecture derivation from requirements (Souza et al. \\cite{eisenreich20243sq}) that highlight heavy reliance on architect experience.\n        *   Builds upon semi-automatic domain model generation (Kof \\cite{eisenreich20243sq}) but aims to significantly reduce manual effort using modern AI.\n        *   Relates to existing work on automated architecture evaluation (Bashroush et al. \\cite{eisenreich20243sq} with ATAM, Krüger et al. \\cite{eisenreich20243sq} with prototypes, Scheerer et al. \\cite{eisenreich20243sq} with quantitative analysis, Mo et al. \\cite{eisenreich20243sq} with metrics), but seeks a more comprehensive and fully automated approach.\n    *   **Limitations of Previous Solutions:**\n        *   Existing methods for architecture derivation heavily depend on the architect's experience and knowledge.\n        *   Prior semi-automatic domain model generation required extensive manual preparation of requirements documents.\n        *   To the authors' knowledge, there is no existing automatic and comprehensive architecture evaluation method that fully considers all requirements.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a semi-automatic, iterative process and tool framework for generating and evaluating software architecture candidates based on requirements, primarily leveraging Artificial Intelligence (AI) techniques, specifically Large Language Models (LLMs).\n    *   **Process Steps:**\n        1.  **AI-based Generation:** Automatically generates initial domain models and use-case scenarios from textual requirements using LLMs.\n        2.  **Manual Refinement:** Architects manually refine the generated models and scenarios, primarily through additional prompts to the LLM.\n        3.  **Architecture Candidate Generation:** Automatically derives multiple software architecture candidates and their Architectural Design Decision Records (ADRs) using the refined domain model, scenarios, and non-functional requirements. This step combines LLMs for conceptual tasks (e.g., component cutting) and classic algorithms for structured, technical tasks (e.g., process views).\n        4.  **Automated Evaluation:** Automatically evaluates and compares architecture candidates using established methods like ATAM \\cite{eisenreich20243sq}, quality metrics, and quantitative analyses, potentially enhanced by LLMs.\n        5.  **Manual Refinement & Selection:** Architects manually refine candidates (via prompts) and select the best-fitting architecture, considering implicit requirements and trade-offs presented by the tooling.\n        6.  **Iterative Support:** The process supports further iterations by considering the current architecture and aiming to minimize changes while balancing quality implications against change expenses.\n    *   **Novelty/Difference:**\n        *   **LLM-driven Automation:** Significantly reduces manual effort in domain modeling and architecture generation by integrating state-of-the-art LLMs, moving beyond previous semi-automatic approaches that still required extensive manual work.\n        *   **Multi-Candidate Generation & Evaluation:** Focuses on generating *multiple* architecture candidates and providing automated, comprehensive evaluation and trade-off analysis, addressing the common practice of designing only a single architecture.\n        *   **Hybrid AI Approach:** Combines the deep understanding capabilities of LLMs for high-level conceptual tasks with the precision of classic algorithms for well-structured, technical architectural aspects.\n        *   **Automated ADRs:** Automatically extracts and models architectural design decisions as ADRs, providing transparency and documentation for each candidate.\n        *   **Comprehensive Evaluation Vision:** Envisions automating established architecture evaluation techniques (like ATAM) and quantitative analyses, potentially using LLMs to interpret requirements for evaluation.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   A novel, iterative, semi-automatic process for generating and evaluating software architectures from natural language requirements, integrating modern AI.\n        *   A hybrid approach for architecture generation, leveraging LLMs for conceptual understanding and classic algorithms for structured architectural views.\n        *   The concept of automatically generating multiple architecture candidates along with their Architectural Design Decision Records (ADRs).\n        *   A vision for automating comprehensive architecture evaluation and trade-off analysis by combining LLMs with established methods (e.g., ATAM) and quantitative metrics.\n    *   **System Design or Architectural Innovations:**\n        *   A proposed tool framework that orchestrates LLM interactions, classic algorithms, and user feedback for architecture creation and refinement.\n        *   Support for various architecture models (e.g., \"4+1 Model,\" Palladio Component Model) and the potential for conversion between them.\n    *   **Theoretical Insights or Analysis:**\n        *   An exploratory analysis demonstrating the general capability of LLMs (LLaMA2, GPT-3.5) to understand application domains and generate structured output (e.g., PlantUML) from requirements, albeit with the need for prompt engineering and output translation. This suggests the feasibility of using general-purpose LLMs for architectural tasks without specialized training.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted (Exploratory Analysis):**\n        *   An exploratory analysis was performed using chat versions of LLaMA2 70-B and GPT-3.5.\n        *   The LLMs were tasked with generating PlantUML domain models from 91 requirements sourced from the MobSTr-dataset \\cite{eisenreich20243sq}.\n    *   **Key Performance Metrics and Comparison Results (Exploratory):**\n        *   Both LLMs successfully identified concepts from the requirements and generated valid PlantUML syntax.\n        *   GPT-3.5 performed better in creating relations between concepts compared to LLaMA2, which failed to do so despite claiming it.\n        *   Initial attempts showed LLMs sometimes misunderstood the prompt, modeling the system instead of the domain.\n        *   Basic prompt engineering significantly improved the results for both models.\n        *   **Conclusion:** The exploratory analysis indicated that general, unmodified LLMs are capable of understanding application domains, but require investment in prompt engineering and translation of their output into the desired format.\n    *   **Planned Evaluation (Future Work):**\n        *   **Evaluation Based on Reference Architectures:** Apply the process to re-engineered requirements from well-established reference architectures (e.g., T2-Project, TeaStore, SockShop \\cite{eisenreich20243sq}). Manually compare generated architectures to reference and expert-created architectures, checking for LLM reproduction vs. novel ideas.\n        *   **Industrial Field Study:** Conduct a real-world study by applying the process to a project's requirements, interviewing project members on architecture quality, process challenges, advantages, and using the Technology Acceptance Model (TAM \\cite{eisenreich20243sq}) to evaluate adoption.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The current state-of-the-art LLMs may not perform well in a *fully automated* solution without specific training data, necessitating a semi-automatic approach.\n        *   Requires careful prompt engineering and translation of LLM output into chosen architectural formats.\n        *   The feasibility of achieving accurate and comprehensive *fully automatic* architecture evaluation is an open research question.\n        *   There's a risk that LLMs might simply reproduce architectures they were trained on, requiring careful validation.\n    *   **Scope of Applicability:**\n        *   Primarily focuses on textual requirements as input.\n        *   Aims to support both the initial creation of new architectures and the adaptation of existing architectures to evolving requirements, making it suitable for agile development environments.\n\n7.  **Technical Significance**\n    *   **Advance the Technical State-of-the-Art:**\n        *   Represents a significant step towards reducing the manual burden and improving the efficiency of software architecture design by integrating advanced AI capabilities.\n        *   Advances the state-of-the-art by proposing a comprehensive, iterative framework for generating and systematically evaluating *multiple* architecture candidates, which is currently lacking.\n        *   Addresses the gap in fully automated and comprehensive architecture evaluation by envisioning a hybrid approach combining LLMs with established methods.\n    *   **Potential Impact on Future Research:**\n        *   Could lead to higher quality, more reproducible, and better-fitting software architectures in industrial settings.\n        *   Reduces the time and cost associated with architectural design, making it more accessible and efficient.\n        *   Opens new research avenues in AI-driven software engineering, particularly in bridging natural language requirements with formal architectural models and automating complex design decisions.\n        *   Provides a foundation for further research into fine-tuning LLMs for architectural tasks and developing robust evaluation mechanisms.",
    "intriguing_abstract": "The journey from complex requirements to robust software architecture is a critical yet often sub-optimal process, heavily reliant on individual architect experience and prone to time constraints. This paper unveils a groundbreaking, semi-automatic framework that harnesses the power of Artificial Intelligence, specifically Large Language Models (LLMs), to transform software architecture design.\n\nOur novel approach integrates LLMs for conceptual understanding and classic algorithms for structured architectural views, enabling the automatic generation of *multiple* diverse architecture candidates. Each candidate is meticulously documented with automatically derived Architectural Design Decision Records (ADRs). Crucially, the framework provides comprehensive, automated evaluation and trade-off analysis, leveraging established methods like ATAM and quality metrics. An exploratory analysis demonstrates the feasibility of LLMs in generating structured domain models from natural language requirements. This iterative, hybrid AI solution promises to significantly reduce manual effort, foster innovation by exploring a wider design space, and ultimately lead to higher quality, more reproducible, and better-fitting software architectures, advancing the state-of-the-art in requirements engineering and architectural design.",
    "keywords": [
      "Software architecture generation",
      "AI-based software architecture",
      "Large Language Models (LLMs)",
      "semi-automatic architecture design",
      "requirements engineering",
      "domain model generation",
      "multi-candidate architecture generation",
      "automated architecture evaluation",
      "Architectural Design Decision Records (ADRs)",
      "hybrid AI approach",
      "prompt engineering",
      "non-functional requirements",
      "iterative software design",
      "software quality"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/07358d921b00ccfad1ea2fdbe8eb5f73d4ed5f12.pdf",
    "citation_key": "eisenreich20243sq",
    "metadata": {
      "title": "From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures",
      "authors": [
        "Tobias Eisenreich",
        "Sandro Speth",
        "Stefan Wagner"
      ],
      "published_date": "2024",
      "abstract": "Designing domain models and software architectures represents a significant challenge in software development, as the resulting architectures play a vital role in fulfilling the system’s quality of service. Due to time pressure, architects often model only one architecture based on their known limited domain understanding, patterns, and experience instead of thoroughly analyzing the domain and evaluating multiple candidates, selecting the best fitting. Existing approaches try to generate domain models based on requirements, but still require time-consuming manual effort to achieve good results. Therefore, in this vision paper, we propose a method to generate software architecture candidates semi-automatically based on requirements using artificial intelligence techniques. We further envision an automatic evaluation and trade-off analysis of the generated architecture candidates using, e.g., the architecture trade-off analysis method combined with large language models and quantitative analyses. To evaluate this approach, we aim to analyze the quality of the generated architecture models and the efficiency and effectiveness of our proposed process by conducting qualitative studies.CCS CONCEPTS • Software and its engineering → Designing software; Software architectures; System description languages; • Computing methodologies → Artificial intelligence.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/07358d921b00ccfad1ea2fdbe8eb5f73d4ed5f12.pdf",
      "venue": "2024 IEEE/ACM International Workshop on Designing Software (Designing)",
      "citationCount": 15,
      "score": 15.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n### Technical Paper Analysis: From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures \\cite{eisenreich20243sq}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the significant challenge of designing domain models and software architectures, particularly in deriving models that fit functional and non-functional requirements for complex or unknown domains. Architects often design only one architecture due to time pressure and limited understanding, leading to sub-optimal solutions and high maintenance costs.\n    *   **Importance and Challenge:** Software architecture is crucial for system quality. Current semi-automatic approaches for generating domain models from requirements (e.g., Kof \\cite{eisenreich20243sq}) still demand extensive manual effort. The process is time-consuming, requires deep domain knowledge, and new architects lack experience, while experienced ones may stick to familiar concepts, hindering innovation and thorough evaluation of alternatives.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:**\n        *   Acknowledges reviews of architecture derivation from requirements (Souza et al. \\cite{eisenreich20243sq}) that highlight heavy reliance on architect experience.\n        *   Builds upon semi-automatic domain model generation (Kof \\cite{eisenreich20243sq}) but aims to significantly reduce manual effort using modern AI.\n        *   Relates to existing work on automated architecture evaluation (Bashroush et al. \\cite{eisenreich20243sq} with ATAM, Krüger et al. \\cite{eisenreich20243sq} with prototypes, Scheerer et al. \\cite{eisenreich20243sq} with quantitative analysis, Mo et al. \\cite{eisenreich20243sq} with metrics), but seeks a more comprehensive and fully automated approach.\n    *   **Limitations of Previous Solutions:**\n        *   Existing methods for architecture derivation heavily depend on the architect's experience and knowledge.\n        *   Prior semi-automatic domain model generation required extensive manual preparation of requirements documents.\n        *   To the authors' knowledge, there is no existing automatic and comprehensive architecture evaluation method that fully considers all requirements.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a semi-automatic, iterative process and tool framework for generating and evaluating software architecture candidates based on requirements, primarily leveraging Artificial Intelligence (AI) techniques, specifically Large Language Models (LLMs).\n    *   **Process Steps:**\n        1.  **AI-based Generation:** Automatically generates initial domain models and use-case scenarios from textual requirements using LLMs.\n        2.  **Manual Refinement:** Architects manually refine the generated models and scenarios, primarily through additional prompts to the LLM.\n        3.  **Architecture Candidate Generation:** Automatically derives multiple software architecture candidates and their Architectural Design Decision Records (ADRs) using the refined domain model, scenarios, and non-functional requirements. This step combines LLMs for conceptual tasks (e.g., component cutting) and classic algorithms for structured, technical tasks (e.g., process views).\n        4.  **Automated Evaluation:** Automatically evaluates and compares architecture candidates using established methods like ATAM \\cite{eisenreich20243sq}, quality metrics, and quantitative analyses, potentially enhanced by LLMs.\n        5.  **Manual Refinement & Selection:** Architects manually refine candidates (via prompts) and select the best-fitting architecture, considering implicit requirements and trade-offs presented by the tooling.\n        6.  **Iterative Support:** The process supports further iterations by considering the current architecture and aiming to minimize changes while balancing quality implications against change expenses.\n    *   **Novelty/Difference:**\n        *   **LLM-driven Automation:** Significantly reduces manual effort in domain modeling and architecture generation by integrating state-of-the-art LLMs, moving beyond previous semi-automatic approaches that still required extensive manual work.\n        *   **Multi-Candidate Generation & Evaluation:** Focuses on generating *multiple* architecture candidates and providing automated, comprehensive evaluation and trade-off analysis, addressing the common practice of designing only a single architecture.\n        *   **Hybrid AI Approach:** Combines the deep understanding capabilities of LLMs for high-level conceptual tasks with the precision of classic algorithms for well-structured, technical architectural aspects.\n        *   **Automated ADRs:** Automatically extracts and models architectural design decisions as ADRs, providing transparency and documentation for each candidate.\n        *   **Comprehensive Evaluation Vision:** Envisions automating established architecture evaluation techniques (like ATAM) and quantitative analyses, potentially using LLMs to interpret requirements for evaluation.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   A novel, iterative, semi-automatic process for generating and evaluating software architectures from natural language requirements, integrating modern AI.\n        *   A hybrid approach for architecture generation, leveraging LLMs for conceptual understanding and classic algorithms for structured architectural views.\n        *   The concept of automatically generating multiple architecture candidates along with their Architectural Design Decision Records (ADRs).\n        *   A vision for automating comprehensive architecture evaluation and trade-off analysis by combining LLMs with established methods (e.g., ATAM) and quantitative metrics.\n    *   **System Design or Architectural Innovations:**\n        *   A proposed tool framework that orchestrates LLM interactions, classic algorithms, and user feedback for architecture creation and refinement.\n        *   Support for various architecture models (e.g., \"4+1 Model,\" Palladio Component Model) and the potential for conversion between them.\n    *   **Theoretical Insights or Analysis:**\n        *   An exploratory analysis demonstrating the general capability of LLMs (LLaMA2, GPT-3.5) to understand application domains and generate structured output (e.g., PlantUML) from requirements, albeit with the need for prompt engineering and output translation. This suggests the feasibility of using general-purpose LLMs for architectural tasks without specialized training.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted (Exploratory Analysis):**\n        *   An exploratory analysis was performed using chat versions of LLaMA2 70-B and GPT-3.5.\n        *   The LLMs were tasked with generating PlantUML domain models from 91 requirements sourced from the MobSTr-dataset \\cite{eisenreich20243sq}.\n    *   **Key Performance Metrics and Comparison Results (Exploratory):**\n        *   Both LLMs successfully identified concepts from the requirements and generated valid PlantUML syntax.\n        *   GPT-3.5 performed better in creating relations between concepts compared to LLaMA2, which failed to do so despite claiming it.\n        *   Initial attempts showed LLMs sometimes misunderstood the prompt, modeling the system instead of the domain.\n        *   Basic prompt engineering significantly improved the results for both models.\n        *   **Conclusion:** The exploratory analysis indicated that general, unmodified LLMs are capable of understanding application domains, but require investment in prompt engineering and translation of their output into the desired format.\n    *   **Planned Evaluation (Future Work):**\n        *   **Evaluation Based on Reference Architectures:** Apply the process to re-engineered requirements from well-established reference architectures (e.g., T2-Project, TeaStore, SockShop \\cite{eisenreich20243sq}). Manually compare generated architectures to reference and expert-created architectures, checking for LLM reproduction vs. novel ideas.\n        *   **Industrial Field Study:** Conduct a real-world study by applying the process to a project's requirements, interviewing project members on architecture quality, process challenges, advantages, and using the Technology Acceptance Model (TAM \\cite{eisenreich20243sq}) to evaluate adoption.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The current state-of-the-art LLMs may not perform well in a *fully automated* solution without specific training data, necessitating a semi-automatic approach.\n        *   Requires careful prompt engineering and translation of LLM output into chosen architectural formats.\n        *   The feasibility of achieving accurate and comprehensive *fully automatic* architecture evaluation is an open research question.\n        *   There's a risk that LLMs might simply reproduce architectures they were trained on, requiring careful validation.\n    *   **Scope of Applicability:**\n        *   Primarily focuses on textual requirements as input.\n        *   Aims to support both the initial creation of new architectures and the adaptation of existing architectures to evolving requirements, making it suitable for agile development environments.\n\n7.  **Technical Significance**\n    *   **Advance the Technical State-of-the-Art:**\n        *   Represents a significant step towards reducing the manual burden and improving the efficiency of software architecture design by integrating advanced AI capabilities.\n        *   Advances the state-of-the-art by proposing a comprehensive, iterative framework for generating and systematically evaluating *multiple* architecture candidates, which is currently lacking.\n        *   Addresses the gap in fully automated and comprehensive architecture evaluation by envisioning a hybrid approach combining LLMs with established methods.\n    *   **Potential Impact on Future Research:**\n        *   Could lead to higher quality, more reproducible, and better-fitting software architectures in industrial settings.\n        *   Reduces the time and cost associated with architectural design, making it more accessible and efficient.\n        *   Opens new research avenues in AI-driven software engineering, particularly in bridging natural language requirements with formal architectural models and automating complex design decisions.\n        *   Provides a foundation for further research into fine-tuning LLMs for architectural tasks and developing robust evaluation mechanisms.",
      "keywords": [
        "Software architecture generation",
        "AI-based software architecture",
        "Large Language Models (LLMs)",
        "semi-automatic architecture design",
        "requirements engineering",
        "domain model generation",
        "multi-candidate architecture generation",
        "automated architecture evaluation",
        "Architectural Design Decision Records (ADRs)",
        "hybrid AI approach",
        "prompt engineering",
        "non-functional requirements",
        "iterative software design",
        "software quality"
      ],
      "paper_type": "the paper should be classified as **position**.\n\nhere's why:\n\n1.  **\"vision paper\"**: the abstract explicitly states, \"therefore, in this **vision paper**, we propose a method...\" this is a direct indicator for a position paper, which often outlines a new vision, direction, or argument for future work.\n2.  **\"propose a method\" & \"envision an automatic evaluation\"**: while it proposes a method (which could lean technical), the language \"envision\" and \"aim to evaluate\" suggests that the full technical implementation and empirical results are not yet present. instead, it's arguing for the *validity and potential* of this proposed direction.\n3.  **introduction's focus**: the introduction highlights current problems in software architecture design and argues for the *need* for semi-automation and ai support, setting the stage for their proposed direction.\n4.  **criteria match**:\n    *   abstract mentions: \"vision paper\", \"propose\", \"envision\", \"aim to analyze\" (future evaluation).\n    *   introduction discusses: \"current problems\", \"require means to support\" (proposed direction).\n\nthis aligns perfectly with the \"position\" criteria: \"argues for viewpoint or future direction.\""
    },
    "file_name": "07358d921b00ccfad1ea2fdbe8eb5f73d4ed5f12.pdf"
  },
  {
    "success": true,
    "doc_id": "4557ac63708911fb3597380a3d358b71",
    "summary": "Depression and anxiety are prevalent mental disorders that have impacted a substantial number of individuals worldwide, exceeding 300 million cases. The repercussions of the COVID-19 pandemic are expected to further escalate these figures due to the economic, social, and societal challenges faced by individuals. Extensive research has revealed distinctive asymmetry in frontal brain-wave activity among individuals with depression and anxiety compared to those without these disorders. Considering this, our research proposes a non-invasive method utilizing a wearable EEG device for the detection of depression and anxiety. The study encompasses essential components such as EEG device interfacing, data collection, preprocessing, feature extraction, data analysis, machine learning model training and evaluation, and the development of a mobile application enabling on-device inference and integration with a cloud database. EEG signals were collected from 30 individuals in a resting state using a single-electrode EEG sensor. Time and frequency domain analyses were conducted on the collected signals. Our machine learning model achieved a remarkable 93% accuracy in detecting depression and anxiety. Thus, the completed study comprises both hardware and software elements. The hardware component features the NeuroSky Mindwave wearable EEG sensor, while the software component includes machine learning models, an Android mobile application, and a data processing pipeline. This integrated system aims to provide a comprehensive solution for the detection and management of depression and anxiety, ultimately enhancing the well-being of individuals afflicted by these conditions.",
    "intriguing_abstract": "Depression and anxiety are prevalent mental disorders that have impacted a substantial number of individuals worldwide, exceeding 300 million cases. The repercussions of the COVID-19 pandemic are expected to further escalate these figures due to the economic, social, and societal challenges faced by individuals. Extensive research has revealed distinctive asymmetry in frontal brain-wave activity among individuals with depression and anxiety compared to those without these disorders. Considering this, our research proposes a non-invasive method utilizing a wearable EEG device for the detection of depression and anxiety. The study encompasses essential components such as EEG device interfacing, data collection, preprocessing, feature extraction, data analysis, machine learning model training and evaluation, and the development of a mobile application enabling on-device inference and integration with a cloud database. EEG signals were collected from 30 individuals in a resting state using a single-electrode EEG sensor. Time and frequency domain analyses were conducted on the collected signals. Our machine learning model achieved a remarkable 93% accuracy in detecting depression and anxiety. Thus, the completed study comprises both hardware and software elements. The hardware component features the NeuroSky Mindwave wearable EEG sensor, while the software component includes machine learning models, an Android mobile application, and a data processing pipeline. This integrated system aims to provide a comprehensive solution for the detection and management of depression and anxiety, ultimately enhancing the well-being of individuals afflicted by these conditions.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/5ee1801f4b294ff9f35297f817e1631c75b5dcf9.pdf",
    "citation_key": "husnain2024y6e",
    "metadata": {
      "title": "Ai-driven Integrated Hardware and Software Solution for EEG-based Detection of Depression and Anxiety",
      "authors": [
        "Ali Husnain",
        "Ghaith Alomari",
        "Ayesha Saeed"
      ],
      "published_date": "2024",
      "abstract": "Depression and anxiety are prevalent mental disorders that have impacted a substantial number of individuals worldwide, exceeding 300 million cases. The repercussions of the COVID-19 pandemic are expected to further escalate these figures due to the economic, social, and societal challenges faced by individuals. Extensive research has revealed distinctive asymmetry in frontal brain-wave activity among individuals with depression and anxiety compared to those without these disorders. Considering this, our research proposes a non-invasive method utilizing a wearable EEG device for the detection of depression and anxiety. The study encompasses essential components such as EEG device interfacing, data collection, preprocessing, feature extraction, data analysis, machine learning model training and evaluation, and the development of a mobile application enabling on-device inference and integration with a cloud database. EEG signals were collected from 30 individuals in a resting state using a single-electrode EEG sensor. Time and frequency domain analyses were conducted on the collected signals. Our machine learning model achieved a remarkable 93% accuracy in detecting depression and anxiety. Thus, the completed study comprises both hardware and software elements. The hardware component features the NeuroSky Mindwave wearable EEG sensor, while the software component includes machine learning models, an Android mobile application, and a data processing pipeline. This integrated system aims to provide a comprehensive solution for the detection and management of depression and anxiety, ultimately enhancing the well-being of individuals afflicted by these conditions.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/5ee1801f4b294ff9f35297f817e1631c75b5dcf9.pdf",
      "venue": "International Journal For Multidisciplinary Research",
      "citationCount": 15,
      "score": 15.0,
      "summary": "Depression and anxiety are prevalent mental disorders that have impacted a substantial number of individuals worldwide, exceeding 300 million cases. The repercussions of the COVID-19 pandemic are expected to further escalate these figures due to the economic, social, and societal challenges faced by individuals. Extensive research has revealed distinctive asymmetry in frontal brain-wave activity among individuals with depression and anxiety compared to those without these disorders. Considering this, our research proposes a non-invasive method utilizing a wearable EEG device for the detection of depression and anxiety. The study encompasses essential components such as EEG device interfacing, data collection, preprocessing, feature extraction, data analysis, machine learning model training and evaluation, and the development of a mobile application enabling on-device inference and integration with a cloud database. EEG signals were collected from 30 individuals in a resting state using a single-electrode EEG sensor. Time and frequency domain analyses were conducted on the collected signals. Our machine learning model achieved a remarkable 93% accuracy in detecting depression and anxiety. Thus, the completed study comprises both hardware and software elements. The hardware component features the NeuroSky Mindwave wearable EEG sensor, while the software component includes machine learning models, an Android mobile application, and a data processing pipeline. This integrated system aims to provide a comprehensive solution for the detection and management of depression and anxiety, ultimately enhancing the well-being of individuals afflicted by these conditions.",
      "keywords": []
    },
    "file_name": "5ee1801f4b294ff9f35297f817e1631c75b5dcf9.pdf"
  },
  {
    "success": true,
    "doc_id": "765b83a09754eebe94d78f4ae8a4ec59",
    "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the significant effort and time developers expend during the software development life cycle's implementation phase, specifically in translating software requirements and design into executable code.\n    *   **Importance and Challenge**: Automating code generation (ACG) is crucial for increasing productivity, reducing development costs, and addressing various software development challenges. The problem is important because manual coding is often repetitive and time-consuming. The challenge lies in effectively leveraging diverse Artificial Intelligence (AI) techniques to generate high-quality, correct, efficient, and maintainable code from various inputs (e.g., natural language, sketches, high-level specifications).\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself as a comprehensive comparative review, analyzing both traditional (Rule-Based, Template-Based, Domain-Specific Languages) and modern AI-based ACG methods. It synthesizes findings from numerous studies on Machine Learning (ML), Natural Language Processing (NLP), Deep Learning (DL), and Evolutionary Algorithms (EAs) in ACG.\n    *   **Limitations of Previous Solutions**: Traditional methods often require extensive manual effort in defining rules or templates and struggle with complex or evolving code generation tasks. Early ML approaches can struggle with rare or unseen coding scenarios and demand substantial training data. DL models, while powerful, typically require large labeled datasets, significant computational resources, and often suffer from a lack of interpretability.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The core technical method of \\cite{odeh2024b0w} is a systematic comparative review. It identifies and categorizes various AI techniques applied to ACG, extracting common evaluation metrics and criteria (e.g., Accuracy, Efficiency, Scalability, Correctness, Generalization). It then uses these criteria to analyze the applications, strengths, weaknesses, and performance of different AI methods.\n    *   **Novelty/Difference**: As a review paper, its innovation lies in providing a structured, comprehensive synthesis of the current state-of-the-art in AI-driven ACG. It offers a comparative framework that highlights advancements, identifies persistent challenges, and outlines future research directions across a broad spectrum of AI methodologies, thereby facilitating informed decision-making for researchers and practitioners.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**: While not introducing new algorithms, the paper systematically details and categorizes the technical underpinnings of prominent AI techniques for ACG, including:\n        *   **ML-based**: Statistical language models, Recurrent Neural Networks (RNNs), and Transformers (e.g., Amazon CodeWhisperer).\n        *   **NLP-based**: Parsing, neural language models, sequence-to-sequence models, and semantic analysis for natural language to code generation.\n        *   **DL-based**: CodeGRU, deep transfer learning, RNNs, Transformers (GPT, BERT), and Graph Neural Networks (GNNs), exemplified by models like AlphaCode and GitHub Copilot.\n        *   **Evolutionary Algorithms (EAs)**: Genetic programming for iterative code optimization and generation.\n    *   **System Design or Architectural Innovations**: The paper highlights architectural innovations within the reviewed techniques, such as transformer-based models for improved context awareness and tree-structured architectures for enhancing the structural coherence of generated code.\n    *   **Theoretical Insights or Analysis**: It provides a comparative analysis of the theoretical strengths (e.g., complex pattern capture by DL, interpretability of RB systems) and weaknesses (e.g., data requirements for ML/DL, rule engineering for RB) of each AI paradigm, offering a foundational understanding for selecting appropriate techniques.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: As a review paper, \\cite{odeh2024b0w} does not conduct new experiments. Instead, it synthesizes and discusses the experimental findings and performance metrics reported in a selection of related studies.\n    *   **Key Performance Metrics and Comparison Results**: The paper identifies and utilizes a set of common evaluation metrics and criteria from the reviewed literature, including Accuracy, Efficiency, Scalability, Correctness, Generalization, Readability, and Maintainability. It discusses how various AI applications (e.g., CodeGRU, Amazon CodeWhisperer, GPT-3, AlphaCode) demonstrate benefits such as improved coding efficiency, reduced manual efforts, enhanced code quality, and the ability to generate code from diverse inputs (natural language, sketches).\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper implicitly highlights the technical limitations inherent in the reviewed AI techniques, such as the substantial data and computational resource requirements for advanced DL models, the challenges in ensuring the interpretability of complex neural networks, and the difficulties traditional methods face in handling ambiguity or evolving requirements.\n    *   **Scope of Applicability**: The review covers ACG across various domains, including web development, mobile applications, and industrial automation. Its scope is focused on the application of AI techniques within the software development life cycle, particularly the code implementation phase.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{odeh2024b0w} significantly advances the technical state-of-the-art by providing a structured, comprehensive, and comparative overview of the rapidly evolving field of AI-driven ACG. It consolidates knowledge on diverse techniques, their applications, and their comparative performance, which is invaluable for researchers and practitioners navigating this complex domain.\n    *   **Potential Impact on Future Research**: The paper identifies critical gaps in existing approaches and proposes future research directions, particularly in addressing challenges related to robust performance evaluation, ensuring the quality and correctness of generated code, and improving the interpretability and resource efficiency of AI-based code generators. It serves as a guide for fostering informed decision-making and promoting the adoption of effective AI-based practices in software development.",
    "intriguing_abstract": "The relentless demand for software often burdens developers with repetitive, time-consuming manual coding, hindering productivity and escalating costs. Automated Code Generation (ACG) promises a transformative solution, yet effectively leveraging diverse Artificial Intelligence (AI) techniques remains a significant challenge. This paper presents a systematic, comprehensive comparative review of the state-of-the-art in AI-driven ACG, synthesizing advancements across Machine Learning (ML), Natural Language Processing (NLP), Deep Learning (DL), and Evolutionary Algorithms (EAs). We meticulously analyze the applications, technical underpinnings (including Transformer-based models and Graph Neural Networks), strengths, and weaknesses of prominent methods, using a structured framework based on critical evaluation metrics like Accuracy, Efficiency, Correctness, and Generalization. By identifying persistent challenges and charting future research directions, this work provides invaluable insights for researchers and practitioners. It aims to foster informed decision-making, accelerate the adoption of robust AI-based practices, and ultimately revolutionize the software development life cycle by enhancing code quality and reducing development efforts.",
    "keywords": [
      "Automating Code Generation (ACG)",
      "Artificial Intelligence (AI)",
      "Machine Learning (ML)",
      "Deep Learning (DL)",
      "Natural Language Processing (NLP)",
      "Evolutionary Algorithms (EAs)",
      "Systematic Comparative Review",
      "Code Quality and Correctness",
      "Software Development Life Cycle",
      "Transformer-based Models",
      "Performance Evaluation Metrics",
      "State-of-the-Art Synthesis",
      "Future Research Directions",
      "Interpretability Challenges",
      "Computational Resource Requirements"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8281b1dcf71dac90a5c95a36f5c4b988ff1ec259.pdf",
    "citation_key": "odeh2024b0w",
    "metadata": {
      "title": "A Comparative Review of AI Techniques for Automated Code Generation in Software Development: Advancements, Challenges, and Future Directions",
      "authors": [
        "A. Odeh",
        "Nada Odeh",
        "Abdul Salam Mohammed"
      ],
      "published_date": "2024",
      "abstract": "Artificial Intelligence (AI), as one of the most important fields of computer science, plays a significant role in the software development life cycle process, especially in the implementation phase, where developers require considerable effort to convert software requirements and design into code. Automated Code Generation (ACG) using AI can help in this phase. Automating the code generation process is becoming increasingly popular as a solution to address various software development challenges and increase productivity. In this work, we provide a comprehensive review and discussion of traditional and AI techniques used for ACG, their challenges, and limitations. By analysing a selection of related studies, we will identify all AI methods and algorithms used for ACG, extracting the evaluation metrics and criteria such as Accuracy, Efficiency, Scalability, Correctness, Generalization, and more. These criteria will be used to perform a comparative result for AI methods used for ACG, exploring their applications, strengths, weaknesses, performance, and future applications.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8281b1dcf71dac90a5c95a36f5c4b988ff1ec259.pdf",
      "venue": "TEM Journal",
      "citationCount": 14,
      "score": 14.0,
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the significant effort and time developers expend during the software development life cycle's implementation phase, specifically in translating software requirements and design into executable code.\n    *   **Importance and Challenge**: Automating code generation (ACG) is crucial for increasing productivity, reducing development costs, and addressing various software development challenges. The problem is important because manual coding is often repetitive and time-consuming. The challenge lies in effectively leveraging diverse Artificial Intelligence (AI) techniques to generate high-quality, correct, efficient, and maintainable code from various inputs (e.g., natural language, sketches, high-level specifications).\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work positions itself as a comprehensive comparative review, analyzing both traditional (Rule-Based, Template-Based, Domain-Specific Languages) and modern AI-based ACG methods. It synthesizes findings from numerous studies on Machine Learning (ML), Natural Language Processing (NLP), Deep Learning (DL), and Evolutionary Algorithms (EAs) in ACG.\n    *   **Limitations of Previous Solutions**: Traditional methods often require extensive manual effort in defining rules or templates and struggle with complex or evolving code generation tasks. Early ML approaches can struggle with rare or unseen coding scenarios and demand substantial training data. DL models, while powerful, typically require large labeled datasets, significant computational resources, and often suffer from a lack of interpretability.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The core technical method of \\cite{odeh2024b0w} is a systematic comparative review. It identifies and categorizes various AI techniques applied to ACG, extracting common evaluation metrics and criteria (e.g., Accuracy, Efficiency, Scalability, Correctness, Generalization). It then uses these criteria to analyze the applications, strengths, weaknesses, and performance of different AI methods.\n    *   **Novelty/Difference**: As a review paper, its innovation lies in providing a structured, comprehensive synthesis of the current state-of-the-art in AI-driven ACG. It offers a comparative framework that highlights advancements, identifies persistent challenges, and outlines future research directions across a broad spectrum of AI methodologies, thereby facilitating informed decision-making for researchers and practitioners.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**: While not introducing new algorithms, the paper systematically details and categorizes the technical underpinnings of prominent AI techniques for ACG, including:\n        *   **ML-based**: Statistical language models, Recurrent Neural Networks (RNNs), and Transformers (e.g., Amazon CodeWhisperer).\n        *   **NLP-based**: Parsing, neural language models, sequence-to-sequence models, and semantic analysis for natural language to code generation.\n        *   **DL-based**: CodeGRU, deep transfer learning, RNNs, Transformers (GPT, BERT), and Graph Neural Networks (GNNs), exemplified by models like AlphaCode and GitHub Copilot.\n        *   **Evolutionary Algorithms (EAs)**: Genetic programming for iterative code optimization and generation.\n    *   **System Design or Architectural Innovations**: The paper highlights architectural innovations within the reviewed techniques, such as transformer-based models for improved context awareness and tree-structured architectures for enhancing the structural coherence of generated code.\n    *   **Theoretical Insights or Analysis**: It provides a comparative analysis of the theoretical strengths (e.g., complex pattern capture by DL, interpretability of RB systems) and weaknesses (e.g., data requirements for ML/DL, rule engineering for RB) of each AI paradigm, offering a foundational understanding for selecting appropriate techniques.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: As a review paper, \\cite{odeh2024b0w} does not conduct new experiments. Instead, it synthesizes and discusses the experimental findings and performance metrics reported in a selection of related studies.\n    *   **Key Performance Metrics and Comparison Results**: The paper identifies and utilizes a set of common evaluation metrics and criteria from the reviewed literature, including Accuracy, Efficiency, Scalability, Correctness, Generalization, Readability, and Maintainability. It discusses how various AI applications (e.g., CodeGRU, Amazon CodeWhisperer, GPT-3, AlphaCode) demonstrate benefits such as improved coding efficiency, reduced manual efforts, enhanced code quality, and the ability to generate code from diverse inputs (natural language, sketches).\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper implicitly highlights the technical limitations inherent in the reviewed AI techniques, such as the substantial data and computational resource requirements for advanced DL models, the challenges in ensuring the interpretability of complex neural networks, and the difficulties traditional methods face in handling ambiguity or evolving requirements.\n    *   **Scope of Applicability**: The review covers ACG across various domains, including web development, mobile applications, and industrial automation. Its scope is focused on the application of AI techniques within the software development life cycle, particularly the code implementation phase.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art**: \\cite{odeh2024b0w} significantly advances the technical state-of-the-art by providing a structured, comprehensive, and comparative overview of the rapidly evolving field of AI-driven ACG. It consolidates knowledge on diverse techniques, their applications, and their comparative performance, which is invaluable for researchers and practitioners navigating this complex domain.\n    *   **Potential Impact on Future Research**: The paper identifies critical gaps in existing approaches and proposes future research directions, particularly in addressing challenges related to robust performance evaluation, ensuring the quality and correctness of generated code, and improving the interpretability and resource efficiency of AI-based code generators. It serves as a guide for fostering informed decision-making and promoting the adoption of effective AI-based practices in software development.",
      "keywords": [
        "Automating Code Generation (ACG)",
        "Artificial Intelligence (AI)",
        "Machine Learning (ML)",
        "Deep Learning (DL)",
        "Natural Language Processing (NLP)",
        "Evolutionary Algorithms (EAs)",
        "Systematic Comparative Review",
        "Code Quality and Correctness",
        "Software Development Life Cycle",
        "Transformer-based Models",
        "Performance Evaluation Metrics",
        "State-of-the-Art Synthesis",
        "Future Research Directions",
        "Interpretability Challenges",
        "Computational Resource Requirements"
      ],
      "paper_type": "based on the abstract and introduction, this paper is a **survey**.\n\nhere's why:\n\n*   **abstract:** explicitly states, \"we provide a **comprehensive review and discussion** of traditional and ai techniques used for acg, their challenges, and limitations. by **analysing a selection of related studies**, we will identify all ai methods and algorithms us ed for acg, extracting the evaluation metrics and criteria... these criteria will be used to perform a **comparative result** for ai methods used for acg, exploring their applications, strengths, weaknesses, performance, and future applications.\" these phrases directly align with the criteria for a survey paper.\n*   **title:** \"a comparative **review** of ai techniques for automated code generation...\" the word \"review\" is a strong indicator.\n*   **introduction:** sets the context by discussing the existing landscape of ai in software development and acg, mentioning that \"researchers have conducted surveys and systematic reviews to investigate the effectiveness of different approaches,\" which further contextualizes this paper as contributing to that body of review literature."
    },
    "file_name": "8281b1dcf71dac90a5c95a36f5c4b988ff1ec259.pdf"
  },
  {
    "success": true,
    "doc_id": "3cc551027cae6c6f1b9b89f9f4f7d3c4",
    "summary": "Quantum software engineering is advancing in the domain of quantum computing research and application, yet the documentation is scattered. The slow transition from Von-Neumann based computation systems to quantum systems, and conserving the fundamental computing principles in software development and software engineering helps in enrichment of quantum software development. The evolution of quantum computing over the past years shows a shift in the domain of classical computation to quantum computation in the years to come. Future applications such as, quantum AI and quantum machine learning will benefit from quantum software engineering. This survey collects and explores the various documentations in the domain of quantum systems and quantum software engineering. The survey provides an in-depth exploration of quantum programming languages, which is combined with explanations of quantum computing’s fundamentals. The review also goes in-depth about quantum software engineering and quantum software life cycle development, outlining the quantum software reuse methodology that is introduced in the quantum software lifecycle development domain.",
    "intriguing_abstract": "Quantum software engineering is advancing in the domain of quantum computing research and application, yet the documentation is scattered. The slow transition from Von-Neumann based computation systems to quantum systems, and conserving the fundamental computing principles in software development and software engineering helps in enrichment of quantum software development. The evolution of quantum computing over the past years shows a shift in the domain of classical computation to quantum computation in the years to come. Future applications such as, quantum AI and quantum machine learning will benefit from quantum software engineering. This survey collects and explores the various documentations in the domain of quantum systems and quantum software engineering. The survey provides an in-depth exploration of quantum programming languages, which is combined with explanations of quantum computing’s fundamentals. The review also goes in-depth about quantum software engineering and quantum software life cycle development, outlining the quantum software reuse methodology that is introduced in the quantum software lifecycle development domain.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/bc641d646456c4ee69b4630ddd3b047a2ca39b1d.pdf",
    "citation_key": "dwivedi2024har",
    "metadata": {
      "title": "Quantum software engineering and quantum software development lifecycle: a survey",
      "authors": [
        "Kanishk Dwivedi",
        "Majid Haghparast",
        "T. Mikkonen"
      ],
      "published_date": "2024",
      "abstract": "Quantum software engineering is advancing in the domain of quantum computing research and application, yet the documentation is scattered. The slow transition from Von-Neumann based computation systems to quantum systems, and conserving the fundamental computing principles in software development and software engineering helps in enrichment of quantum software development. The evolution of quantum computing over the past years shows a shift in the domain of classical computation to quantum computation in the years to come. Future applications such as, quantum AI and quantum machine learning will benefit from quantum software engineering. This survey collects and explores the various documentations in the domain of quantum systems and quantum software engineering. The survey provides an in-depth exploration of quantum programming languages, which is combined with explanations of quantum computing’s fundamentals. The review also goes in-depth about quantum software engineering and quantum software life cycle development, outlining the quantum software reuse methodology that is introduced in the quantum software lifecycle development domain.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/bc641d646456c4ee69b4630ddd3b047a2ca39b1d.pdf",
      "venue": "Cluster Computing",
      "citationCount": 14,
      "score": 14.0,
      "summary": "Quantum software engineering is advancing in the domain of quantum computing research and application, yet the documentation is scattered. The slow transition from Von-Neumann based computation systems to quantum systems, and conserving the fundamental computing principles in software development and software engineering helps in enrichment of quantum software development. The evolution of quantum computing over the past years shows a shift in the domain of classical computation to quantum computation in the years to come. Future applications such as, quantum AI and quantum machine learning will benefit from quantum software engineering. This survey collects and explores the various documentations in the domain of quantum systems and quantum software engineering. The survey provides an in-depth exploration of quantum programming languages, which is combined with explanations of quantum computing’s fundamentals. The review also goes in-depth about quantum software engineering and quantum software life cycle development, outlining the quantum software reuse methodology that is introduced in the quantum software lifecycle development domain.",
      "keywords": []
    },
    "file_name": "bc641d646456c4ee69b4630ddd3b047a2ca39b1d.pdf"
  },
  {
    "success": true,
    "doc_id": "17f4a61967ff3668b1e3852eb3fd89ee",
    "summary": "DevOps has emerged as one of the most rapidly evolving software development paradigms. With the growing concerns surrounding security in software systems, the DevSecOps paradigm has gained prominence, urging practitioners to incorporate security practices seamlessly into the DevOps workflow. However, integrating security into the DevOps workflow can impact agility and impede delivery speed. Recently, the advancement of artificial intelligence (AI) has revolutionized automation in various software domains, including software security. AI-driven security approaches, particularly those leveraging machine learning or deep learning, hold promise in automating security workflows. They have the potential to reduce manual efforts and can be incorporated into DevOps practices to support consistent delivery speed while aligning with the principles of the DevSecOps paradigm. This article seeks to contribute to the critical intersection of AI and DevSecOps by presenting a comprehensive landscape of AI-driven security techniques applicable to DevOps and identifying avenues for enhancing security, trust, and efficiency in software development processes. We analyzed 99 research papers spanning from 2017 to 2023. Specifically, we address two key research questions (RQs). In RQ1, we identified 12 security tasks associated with the DevSecOps process and reviewed existing AI-driven security approaches, the problems they addressed, and the 65 benchmarks used to evaluate those approaches. Drawing insights from our findings, in RQ2, we discussed state-of-the-art AI-driven security approaches, highlighted 15 challenges in existing research, and proposed 15 corresponding avenues for future opportunities.",
    "intriguing_abstract": "DevOps has emerged as one of the most rapidly evolving software development paradigms. With the growing concerns surrounding security in software systems, the DevSecOps paradigm has gained prominence, urging practitioners to incorporate security practices seamlessly into the DevOps workflow. However, integrating security into the DevOps workflow can impact agility and impede delivery speed. Recently, the advancement of artificial intelligence (AI) has revolutionized automation in various software domains, including software security. AI-driven security approaches, particularly those leveraging machine learning or deep learning, hold promise in automating security workflows. They have the potential to reduce manual efforts and can be incorporated into DevOps practices to support consistent delivery speed while aligning with the principles of the DevSecOps paradigm. This article seeks to contribute to the critical intersection of AI and DevSecOps by presenting a comprehensive landscape of AI-driven security techniques applicable to DevOps and identifying avenues for enhancing security, trust, and efficiency in software development processes. We analyzed 99 research papers spanning from 2017 to 2023. Specifically, we address two key research questions (RQs). In RQ1, we identified 12 security tasks associated with the DevSecOps process and reviewed existing AI-driven security approaches, the problems they addressed, and the 65 benchmarks used to evaluate those approaches. Drawing insights from our findings, in RQ2, we discussed state-of-the-art AI-driven security approaches, highlighted 15 challenges in existing research, and proposed 15 corresponding avenues for future opportunities.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ac90276ee7894c7b92ea62e4d3e5680a99c59599.pdf",
    "citation_key": "fu20246t0",
    "metadata": {
      "title": "AI for DevSecOps: A Landscape and Future Opportunities",
      "authors": [
        "Michael Fu",
        "Jirat Pasuksmit",
        "C. Tantithamthavorn"
      ],
      "published_date": "2024",
      "abstract": "DevOps has emerged as one of the most rapidly evolving software development paradigms. With the growing concerns surrounding security in software systems, the DevSecOps paradigm has gained prominence, urging practitioners to incorporate security practices seamlessly into the DevOps workflow. However, integrating security into the DevOps workflow can impact agility and impede delivery speed. Recently, the advancement of artificial intelligence (AI) has revolutionized automation in various software domains, including software security. AI-driven security approaches, particularly those leveraging machine learning or deep learning, hold promise in automating security workflows. They have the potential to reduce manual efforts and can be incorporated into DevOps practices to support consistent delivery speed while aligning with the principles of the DevSecOps paradigm. This article seeks to contribute to the critical intersection of AI and DevSecOps by presenting a comprehensive landscape of AI-driven security techniques applicable to DevOps and identifying avenues for enhancing security, trust, and efficiency in software development processes. We analyzed 99 research papers spanning from 2017 to 2023. Specifically, we address two key research questions (RQs). In RQ1, we identified 12 security tasks associated with the DevSecOps process and reviewed existing AI-driven security approaches, the problems they addressed, and the 65 benchmarks used to evaluate those approaches. Drawing insights from our findings, in RQ2, we discussed state-of-the-art AI-driven security approaches, highlighted 15 challenges in existing research, and proposed 15 corresponding avenues for future opportunities.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ac90276ee7894c7b92ea62e4d3e5680a99c59599.pdf",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "citationCount": 14,
      "score": 14.0,
      "summary": "DevOps has emerged as one of the most rapidly evolving software development paradigms. With the growing concerns surrounding security in software systems, the DevSecOps paradigm has gained prominence, urging practitioners to incorporate security practices seamlessly into the DevOps workflow. However, integrating security into the DevOps workflow can impact agility and impede delivery speed. Recently, the advancement of artificial intelligence (AI) has revolutionized automation in various software domains, including software security. AI-driven security approaches, particularly those leveraging machine learning or deep learning, hold promise in automating security workflows. They have the potential to reduce manual efforts and can be incorporated into DevOps practices to support consistent delivery speed while aligning with the principles of the DevSecOps paradigm. This article seeks to contribute to the critical intersection of AI and DevSecOps by presenting a comprehensive landscape of AI-driven security techniques applicable to DevOps and identifying avenues for enhancing security, trust, and efficiency in software development processes. We analyzed 99 research papers spanning from 2017 to 2023. Specifically, we address two key research questions (RQs). In RQ1, we identified 12 security tasks associated with the DevSecOps process and reviewed existing AI-driven security approaches, the problems they addressed, and the 65 benchmarks used to evaluate those approaches. Drawing insights from our findings, in RQ2, we discussed state-of-the-art AI-driven security approaches, highlighted 15 challenges in existing research, and proposed 15 corresponding avenues for future opportunities.",
      "keywords": []
    },
    "file_name": "ac90276ee7894c7b92ea62e4d3e5680a99c59599.pdf"
  },
  {
    "success": true,
    "doc_id": "c313034fd96efba3f817bbe91f2a5b4b",
    "summary": "Here's a focused summary of the paper \"Towards AI-Native Software Engineering (SE 3.0): A Vision and a Challenge Roadmap\" \\cite{hassan2024pqx} for a literature review:\n\n### Technical Paper Analysis: Towards AI-Native Software Engineering (SE 3.0) \\cite{hassan2024pqx}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the inherent limitations and inefficiencies of current AI-assisted Software Engineering (SE 2.0), which relies on Foundation Models (FMs) and AI copilots.\n    *   **Importance and Challenge**:\n        *   **High Cognitive Overload on Developers**: SE 2.0 forces human developers to micromanage the coding process, leading to inefficiency and errors, despite AI assistance \\cite{hassan2024pqx}. The human drives the code creation loop, limiting solution exploration.\n        *   **Inefficient and Ineffective Model Training**: Current FMs (e.g., GPT-4o) rely on vast amounts of unstructured data, leading to high computational costs, energy consumption, data redundancy, and often a shallow understanding of specialized knowledge critical for advanced reasoning \\cite{hassan2024pqpqx}.\n        *   **Suboptimal Code Quality and Vicious Cycle**: Copilot-generated code can be buggy \\cite{hassan2024pqx} and have performance issues \\cite{hassan2024pqx}. Copilots primarily add code, leading to bloated, harder-to-maintain codebases rather than promoting refactoring or abstraction. The proliferation of such code risks contaminating future FM training data, perpetuating a decline in code quality \\cite{hassan2024pqx}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **SE 1.0 (Code-first)**: Traditional SE, human-driven, tools powered by program analysis.\n        *   **SE 2.0 (AI-assisted SE)**: Builds on SE 1.0, incorporating AI models (FMs, LLMs) to enhance traditional activities (AI4SE), primarily through copilots \\cite{hassan2024pqx}.\n        *   **Autonomous Software Engineers (e.g., Devin AI, SWE-agent)**: While impressive, these systems are critiqued for lacking focus on human-AI alignment of intents, potentially failing to meet true requirements. They still rely on \"off-the-shelf\" FMs with limited deep SE knowledge and efficiency, and their real-world performance is unclear due to benchmark limitations \\cite{hassan2024pqx}.\n    *   **Limitations of Previous Solutions**:\n        *   SE 2.0 copilots are task-driven, impersonal, static, and contribute to cognitive overload \\cite{hassan2024pqx}. Their training is inefficient, and their output can be problematic.\n        *   Autonomous agents, while aiming for full automation, may miss human intent and still suffer from underlying FM limitations \\cite{hassan2024pqx}.\n    *   **Positioning**: SE 3.0 proposes a paradigm shift beyond both SE 2.0's assistance model and autonomous agents, advocating for a symbiotic human-AI partnership where AI acts as an intelligent teammate, deeply understanding and reasoning about SE principles and intents \\cite{hassan2024pqx}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: SE 3.0 is an \"AI-native\" approach characterized by:\n        *   **Intent-first, Conversation-oriented Development**: Development is driven by intents expressed through iterative, conversational interactions between human developers and AI teammates, rather than being code-first \\cite{hassan2024pqx}. The AI drives the code creation loop by synthesizing intents into runnable software.\n        *   **Symbiotic Human-AI Collaboration**: Maximizes complementary strengths, with humans focusing on business needs and AI on hyper-speed solution search and implementation \\cite{hassan2024pqx}.\n        *   **Knowledge-driven Models**: Employs more efficient, knowledge-driven AI models trained using \"curriculum engineering\" to enhance reasoning capabilities and flexibility, contrasting with the data-driven inefficiency of SE 2.0 models \\cite{hassan2024pqx}.\n    *   **Novelty/Difference**:\n        *   **AI as Teammate, not Copilot**: AI evolves from a task-driven code completion system to an intelligent collaborator with deep SE knowledge, expert coding skills, and advanced reasoning \\cite{hassan2024pqx}.\n        *   **Intent-Centric IDEs**: A shift from code-centric to intent-centric development environments.\n        *   **Holistic Technology Stack**: Proposes a new stack designed for this AI-native paradigm.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   **Intent-first, Conversation-oriented Development**: A new development paradigm where AI teammates clarify and synthesize human intents into software \\cite{hassan2024pqx}.\n        *   **Knowledge-driven Model Training with Curriculum Engineering**: A more efficient approach to training AI models with deep SE knowledge and reasoning capabilities \\cite{hassan2024pqx}.\n    *   **System Design or Architectural Innovations**:\n        *   **SE 3.0 Technology Stack**: A conceptual architecture comprising:\n            *   **Teammate.next**: Self-evolving, personalized AI partners with conversational and social intelligence, capable of learning from feedback and self-reflection, and acting as one-on-one programming mentors \\cite{hassan2024pqx}.\n            *   **IDE.next**: An intent-centric, conversational AI-native IDE for developing, debugging, and maintaining software \\cite{hassan2024pqx}.\n            *   **Compiler.next**: For multi-objective code synthesis and search-space exploration.\n            *   **Runtime.next**: SLA-aware Uni-Cluster Runtime with Edge Extension for serving compound applications (AIware).\n            *   **FM.next**: Efficient, knowledge-driven FMs.\n    *   **Theoretical Insights or Analysis**:\n        *   A critical analysis of SE 2.0's limitations, including cognitive overload, model training inefficiencies, and the risk of a vicious cycle of degrading code quality \\cite{hassan2024pqx}.\n        *   A vision for a symbiotic human-AI relationship that leverages complementary strengths.\n\n5.  **Experimental Validation**\n    *   This paper is a \"vision and a challenge roadmap\" \\cite{hassan2024pqx}. As such, it **does not present empirical validation** of the proposed SE 3.0 solutions or technology stack.\n    *   The vision and challenges are informed by surveys, discussions with industry/academic leaders, customer feedback, and practical experience with related research and development (e.g., FMware, OPEA alliance) \\cite{hassan2024pqx}, which validates the *problem statement* and *need* for the vision, but not the *effectiveness* of the proposed solutions.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper outlines a future vision and does not delve into the concrete implementation details of the proposed technology stack components (e.g., how \"curriculum engineering\" for FMs would work in practice, or the specific algorithms for intent synthesis). It assumes significant advancements in AI capabilities, particularly in reasoning, deep SE knowledge, and efficient model training.\n    *   **Scope of Applicability**: The vision is broad, aiming to redefine the entire software engineering process. It is applicable to a wide range of software development scenarios where human-AI collaboration can be optimized.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The paper proposes a significant paradigm shift from AI-assisted (SE 2.0) to AI-native (SE 3.0) software engineering, moving beyond mere code completion to deep, conversational, intent-driven collaboration \\cite{hassan2024pqx}. It challenges the current reliance on inefficient data-driven FMs and highlights the need for knowledge-driven, efficient models.\n    *   **Potential Impact on Future Research**:\n        *   Lays a foundational roadmap for future research in human-AI collaboration in SE, AI-native IDEs, multi-objective code synthesis, and SLA-aware runtimes \\cite{hassan2024pqx}.\n        *   Encourages research into more efficient, knowledge-driven AI model training specifically tailored for software engineering tasks.\n        *   Promotes the development of AI systems with advanced social and conversational intelligence for seamless human-AI teaming.\n        *   Stimulates discussion on redefining the role of AI in software development, shifting focus from code generation to intent realization.",
    "intriguing_abstract": "The current paradigm of AI-assisted Software Engineering (SE 2.0), heavily reliant on Foundation Models (FMs) and AI copilots, is reaching its limits, burdening developers with cognitive overload and perpetuating a vicious cycle of suboptimal code quality. This paper unveils a transformative vision: **AI-Native Software Engineering (SE 3.0)**, a radical paradigm shift beyond mere assistance or autonomous agents. We propose an \"intent-first, conversation-oriented\" development model where AI evolves into an intelligent, symbiotic teammate, deeply understanding and reasoning about software engineering principles.\n\nSE 3.0 champions efficient, knowledge-driven AI models, trained through \"curriculum engineering,\" to overcome the inefficiencies of current data-hungry FMs and enable hyper-speed solution exploration. We introduce a conceptual SE 3.0 Technology Stack, featuring **Teammate.next**, **IDE.next**, and **Compiler.next**, designed to synthesize human intents into runnable software. This vision promises to alleviate developer burden, enhance software quality, and fundamentally redefine human-AI collaboration, offering a crucial roadmap for future research in AI-native development environments and reasoning-capable AI for SE.",
    "keywords": [
      "AI-Native Software Engineering (SE 3.0)",
      "Intent-first Development",
      "Symbiotic Human-AI Collaboration",
      "Knowledge-driven AI Models",
      "Curriculum Engineering",
      "Cognitive Overload (SE 2.0)",
      "Inefficient Foundation Model Training",
      "AI Copilots",
      "Intent-centric IDEs",
      "Multi-objective Code Synthesis",
      "Teammate.next",
      "Vision and Challenge Roadmap",
      "Software Engineering Paradigm Shift"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a80cb0325b78c303916cb66d6d33fe0aed8c8311.pdf",
    "citation_key": "hassan2024pqx",
    "metadata": {
      "title": "Towards AI-Native Software Engineering (SE 3.0): A Vision and a Challenge Roadmap",
      "authors": [
        "Ahmed E. Hassan",
        "G. Oliva",
        "Dayi Lin",
        "Boyuan Chen",
        "Zhen Ming Jiang"
      ],
      "published_date": "2024",
      "abstract": "The rise of AI-assisted software engineering (SE 2.0), powered by Foundation Models (FMs) and FM-powered copilots, has shown promise in improving developer productivity. However, it has also exposed inherent limitations, such as cognitive overload on developers and inefficiencies. We propose a shift towards Software Engineering 3.0 (SE 3.0), an AI-native approach characterized by intent-first, conversation-oriented development between human developers and AI teammates. SE 3.0 envisions AI systems evolving beyond task-driven copilots into intelligent collaborators, capable of deeply understanding and reasoning about software engineering principles and intents. We outline the key components of the SE 3.0 technology stack, which includes Teammate.next for adaptive and personalized AI partnership, IDE.next for intent-first conversation-oriented development, Compiler.next for multi-objective code synthesis, and Runtime.next for SLA-aware execution with edge-computing support. Our vision addresses the inefficiencies and cognitive strain of SE 2.0 by fostering a symbiotic relationship between human developers and AI, maximizing their complementary strengths. We also present a roadmap of challenges that must be overcome to realize our vision of SE 3.0. This paper lays the foundation for future discussions on the role of AI in the next era of software engineering.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a80cb0325b78c303916cb66d6d33fe0aed8c8311.pdf",
      "venue": "arXiv.org",
      "citationCount": 14,
      "score": 14.0,
      "summary": "Here's a focused summary of the paper \"Towards AI-Native Software Engineering (SE 3.0): A Vision and a Challenge Roadmap\" \\cite{hassan2024pqx} for a literature review:\n\n### Technical Paper Analysis: Towards AI-Native Software Engineering (SE 3.0) \\cite{hassan2024pqx}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the inherent limitations and inefficiencies of current AI-assisted Software Engineering (SE 2.0), which relies on Foundation Models (FMs) and AI copilots.\n    *   **Importance and Challenge**:\n        *   **High Cognitive Overload on Developers**: SE 2.0 forces human developers to micromanage the coding process, leading to inefficiency and errors, despite AI assistance \\cite{hassan2024pqx}. The human drives the code creation loop, limiting solution exploration.\n        *   **Inefficient and Ineffective Model Training**: Current FMs (e.g., GPT-4o) rely on vast amounts of unstructured data, leading to high computational costs, energy consumption, data redundancy, and often a shallow understanding of specialized knowledge critical for advanced reasoning \\cite{hassan2024pqpqx}.\n        *   **Suboptimal Code Quality and Vicious Cycle**: Copilot-generated code can be buggy \\cite{hassan2024pqx} and have performance issues \\cite{hassan2024pqx}. Copilots primarily add code, leading to bloated, harder-to-maintain codebases rather than promoting refactoring or abstraction. The proliferation of such code risks contaminating future FM training data, perpetuating a decline in code quality \\cite{hassan2024pqx}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**:\n        *   **SE 1.0 (Code-first)**: Traditional SE, human-driven, tools powered by program analysis.\n        *   **SE 2.0 (AI-assisted SE)**: Builds on SE 1.0, incorporating AI models (FMs, LLMs) to enhance traditional activities (AI4SE), primarily through copilots \\cite{hassan2024pqx}.\n        *   **Autonomous Software Engineers (e.g., Devin AI, SWE-agent)**: While impressive, these systems are critiqued for lacking focus on human-AI alignment of intents, potentially failing to meet true requirements. They still rely on \"off-the-shelf\" FMs with limited deep SE knowledge and efficiency, and their real-world performance is unclear due to benchmark limitations \\cite{hassan2024pqx}.\n    *   **Limitations of Previous Solutions**:\n        *   SE 2.0 copilots are task-driven, impersonal, static, and contribute to cognitive overload \\cite{hassan2024pqx}. Their training is inefficient, and their output can be problematic.\n        *   Autonomous agents, while aiming for full automation, may miss human intent and still suffer from underlying FM limitations \\cite{hassan2024pqx}.\n    *   **Positioning**: SE 3.0 proposes a paradigm shift beyond both SE 2.0's assistance model and autonomous agents, advocating for a symbiotic human-AI partnership where AI acts as an intelligent teammate, deeply understanding and reasoning about SE principles and intents \\cite{hassan2024pqx}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: SE 3.0 is an \"AI-native\" approach characterized by:\n        *   **Intent-first, Conversation-oriented Development**: Development is driven by intents expressed through iterative, conversational interactions between human developers and AI teammates, rather than being code-first \\cite{hassan2024pqx}. The AI drives the code creation loop by synthesizing intents into runnable software.\n        *   **Symbiotic Human-AI Collaboration**: Maximizes complementary strengths, with humans focusing on business needs and AI on hyper-speed solution search and implementation \\cite{hassan2024pqx}.\n        *   **Knowledge-driven Models**: Employs more efficient, knowledge-driven AI models trained using \"curriculum engineering\" to enhance reasoning capabilities and flexibility, contrasting with the data-driven inefficiency of SE 2.0 models \\cite{hassan2024pqx}.\n    *   **Novelty/Difference**:\n        *   **AI as Teammate, not Copilot**: AI evolves from a task-driven code completion system to an intelligent collaborator with deep SE knowledge, expert coding skills, and advanced reasoning \\cite{hassan2024pqx}.\n        *   **Intent-Centric IDEs**: A shift from code-centric to intent-centric development environments.\n        *   **Holistic Technology Stack**: Proposes a new stack designed for this AI-native paradigm.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   **Intent-first, Conversation-oriented Development**: A new development paradigm where AI teammates clarify and synthesize human intents into software \\cite{hassan2024pqx}.\n        *   **Knowledge-driven Model Training with Curriculum Engineering**: A more efficient approach to training AI models with deep SE knowledge and reasoning capabilities \\cite{hassan2024pqx}.\n    *   **System Design or Architectural Innovations**:\n        *   **SE 3.0 Technology Stack**: A conceptual architecture comprising:\n            *   **Teammate.next**: Self-evolving, personalized AI partners with conversational and social intelligence, capable of learning from feedback and self-reflection, and acting as one-on-one programming mentors \\cite{hassan2024pqx}.\n            *   **IDE.next**: An intent-centric, conversational AI-native IDE for developing, debugging, and maintaining software \\cite{hassan2024pqx}.\n            *   **Compiler.next**: For multi-objective code synthesis and search-space exploration.\n            *   **Runtime.next**: SLA-aware Uni-Cluster Runtime with Edge Extension for serving compound applications (AIware).\n            *   **FM.next**: Efficient, knowledge-driven FMs.\n    *   **Theoretical Insights or Analysis**:\n        *   A critical analysis of SE 2.0's limitations, including cognitive overload, model training inefficiencies, and the risk of a vicious cycle of degrading code quality \\cite{hassan2024pqx}.\n        *   A vision for a symbiotic human-AI relationship that leverages complementary strengths.\n\n5.  **Experimental Validation**\n    *   This paper is a \"vision and a challenge roadmap\" \\cite{hassan2024pqx}. As such, it **does not present empirical validation** of the proposed SE 3.0 solutions or technology stack.\n    *   The vision and challenges are informed by surveys, discussions with industry/academic leaders, customer feedback, and practical experience with related research and development (e.g., FMware, OPEA alliance) \\cite{hassan2024pqx}, which validates the *problem statement* and *need* for the vision, but not the *effectiveness* of the proposed solutions.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The paper outlines a future vision and does not delve into the concrete implementation details of the proposed technology stack components (e.g., how \"curriculum engineering\" for FMs would work in practice, or the specific algorithms for intent synthesis). It assumes significant advancements in AI capabilities, particularly in reasoning, deep SE knowledge, and efficient model training.\n    *   **Scope of Applicability**: The vision is broad, aiming to redefine the entire software engineering process. It is applicable to a wide range of software development scenarios where human-AI collaboration can be optimized.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: The paper proposes a significant paradigm shift from AI-assisted (SE 2.0) to AI-native (SE 3.0) software engineering, moving beyond mere code completion to deep, conversational, intent-driven collaboration \\cite{hassan2024pqx}. It challenges the current reliance on inefficient data-driven FMs and highlights the need for knowledge-driven, efficient models.\n    *   **Potential Impact on Future Research**:\n        *   Lays a foundational roadmap for future research in human-AI collaboration in SE, AI-native IDEs, multi-objective code synthesis, and SLA-aware runtimes \\cite{hassan2024pqx}.\n        *   Encourages research into more efficient, knowledge-driven AI model training specifically tailored for software engineering tasks.\n        *   Promotes the development of AI systems with advanced social and conversational intelligence for seamless human-AI teaming.\n        *   Stimulates discussion on redefining the role of AI in software development, shifting focus from code generation to intent realization.",
      "keywords": [
        "AI-Native Software Engineering (SE 3.0)",
        "Intent-first Development",
        "Symbiotic Human-AI Collaboration",
        "Knowledge-driven AI Models",
        "Curriculum Engineering",
        "Cognitive Overload (SE 2.0)",
        "Inefficient Foundation Model Training",
        "AI Copilots",
        "Intent-centric IDEs",
        "Multi-objective Code Synthesis",
        "Teammate.next",
        "Vision and Challenge Roadmap",
        "Software Engineering Paradigm Shift"
      ],
      "paper_type": "based on the provided abstract, introduction, and title:\n\n*   **title:** \"towards ai-native software engineering (se 3.0): a vision and a challenge roadmap\"\n    *   the phrases \"a vision\" and \"challenge roadmap\" are strong indicators of a paper that argues for a future direction and outlines the path to get there.\n*   **abstract:**\n    *   discusses current problems with ai-generated code (buggy, performance issues, acceptance by senior programmers).\n    *   identifies a \"threat to the quality of the training data used by current fms.\"\n*   **introduction:**\n    *   describes the current era (\"software engineering 2.0\") and its characteristics (ai-assisted se, copilots).\n    *   explicitly states: \"se 2.0 faces several critical issues, starting with the high cognitive load on human developers...\" and details these problems (inefficiency, errors, training issues).\n\nthe paper clearly identifies current problems, critiques the existing paradigm (se 2.0), and, as indicated by its title, proposes a new vision (se 3.0) and a roadmap for future work. this aligns perfectly with the criteria for a **position** paper.\n\n**classification: position**"
    },
    "file_name": "a80cb0325b78c303916cb66d6d33fe0aed8c8311.pdf"
  },
  {
    "success": true,
    "doc_id": "28fa890e5d7982719f1fb73ca9ed1158",
    "summary": "Here's a focused summary of the paper for a literature review, adhering to your requirements:\n\n---\n\n### Analysis of \"Sea Change in Software Development: Economic and Productivity Analysis of the AI-Powered Developer Lifecycle\" \\cite{dohmke2023tpd}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of quantifying the real-world, large-scale impact of generative AI tools, specifically GitHub Copilot, on developer productivity and understanding its broader economic and ecosystem implications.\n    *   **Importance and Challenge:** Generative AI is a rapidly evolving technology, and understanding its long-term effects on software development workflows, different developer segments, and the global economy is crucial. Previous studies were often smaller-scale or experimental; this work aims to provide a comprehensive, large-scale analysis using in-field telemetry data.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon prior research that established the efficacy of GitHub Copilot.\n        *   Previous controlled experiments (e.g., Peng et al., 2023) showed developers using GitHub Copilot completed tasks significantly faster (55.8% faster for an HTTP server).\n        *   Earlier surveys (e.g., Ziegler et al., 2022; Kalliamvakou, 2023) found a strong correlation between the acceptance rate of Copilot suggestions and reported developer productivity and satisfaction.\n    *   **Limitations of Previous Solutions:** Prior studies, while foundational, were often limited to controlled experimental settings or self-reported survey data. They lacked the ability to analyze the long-term, in-field impact across a massive user base, or to differentiate effects based on developer experience over time.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper employs a large-scale empirical analysis of telemetry data from a vast user base of GitHub Copilot.\n        *   It analyzed data from `n = 934,533` GitHub Copilot users.\n        *   The \"acceptance rate\" of code suggestions was used as a key quantitative indicator of productivity and impact, a metric validated by prior survey research.\n        *   The analysis tracked these metrics over time and across different segments of developers, categorized by their prior experience (measured by repository activity).\n        *   This was complemented by an extensive analysis of GitHub repository data (stars, forks, commits, contributors, topics) to map the growth and drivers of the generative AI open-source ecosystem.\n    *   **Novelty:**\n        *   **Unprecedented Scale:** The analysis of nearly a million users provides a robust, real-world perspective on generative AI's impact on developer productivity \\cite{dohmke2023tpd}.\n        *   **Dynamic Productivity Gains:** It uniquely demonstrates that productivity benefits from GitHub Copilot *increase over time* as developers become more accustomed to the tool, a \"novel, breakthrough finding\" \\cite{dohmke2023tpd}.\n        *   **Democratizing Effect:** The study reveals that *less experienced developers achieve greater relative productivity benefits* from the tool \\cite{dohmke2023tpd}.\n        *   **Ecosystem Mapping:** It provides a detailed, data-driven view of the exponential growth and key drivers (especially individuals and open source) within the generative AI software development ecosystem.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   Development and application of a large-scale telemetry analysis framework for AI-powered developer tools, using acceptance rate as a validated proxy for productivity.\n        *   A methodology for segmenting developer experience based on quantifiable prior platform activity to study differential impacts.\n        *   A comprehensive approach to analyzing open-source ecosystem trends through GitHub repository metadata (topics, commits, forks, stars) to track the evolution of generative AI innovation.\n    *   **Theoretical Insights or Analysis:**\n        *   Empirical validation of a \"learning curve\" for AI tool adoption, showing increasing returns to usage over time.\n        *   Demonstration of the \"democratizing\" potential of AI tools, where they disproportionately empower less experienced individuals.\n        *   Quantification of the significant economic potential of generative AI in software development, projecting a global GDP boost of over $1.5 trillion USD by 2030 \\cite{dohmke2023tpd}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Analysis of GitHub Copilot telemetry data from `n = 934,533` users to measure code suggestion acceptance rates.\n        *   Longitudinal tracking of acceptance rates over several months (up to six months) to observe trends over time.\n        *   Cross-sectional analysis comparing acceptance rates across developer experience quintiles, defined by prior GitHub repository activity.\n        *   Extensive analysis of GitHub repository data (creation, forks, commits, contributors, topics) related to generative AI to illustrate ecosystem growth and innovation drivers.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Average Acceptance Rate:** Users accept an average of ~30% of code suggestions \\cite{dohmke2023tpd}.\n        *   **Time-Dependent Productivity:** Acceptance rates increase over time, demonstrating a growing impact and user comfort, with no diminishing returns observed after six months \\cite{dohmke2023tpd}.\n        *   **Experience-Dependent Productivity:** Less experienced developers (bottom quintile) exhibited a higher acceptance rate (31.9%) compared to more experienced developers (top quintile, 26.2%) \\cite{dohmke2023tpd}.\n        *   **Ecosystem Growth:** Exponential increases were observed in the number of generative AI repositories, forks, commits, and contributors on GitHub, with individuals leading the majority of such repositories.\n        *   **Economic Impact:** The productivity benefits are estimated to boost global GDP by over $1.5 trillion USD by 2030 \\cite{dohmke2023tpd}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions:**\n        *   The primary metric, \"acceptance rate,\" is used as a proxy for productivity, although its correlation with perceived productivity is supported by prior survey research \\cite{dohmke2023tpd}. The paper acknowledges ongoing research into potential overreliance.\n        *   Developer experience is inferred from prior repository activity, which may not fully capture all facets of a developer's skill or expertise.\n        *   The precise productivity effects are noted to vary by use case, suggesting a need for further granular experimental research in diverse field settings \\cite{dohmke2023tpd}.\n        *   Economic projections are conservative and \"moment-in-time,\" not fully accounting for potential increased demand for software or further digital transformation driven by AI.\n    *   **Scope of Applicability:** The analysis is primarily focused on GitHub Copilot and the GitHub ecosystem. While the insights are broadly applicable to AI-powered code generation, specific quantitative results are tied to this platform.\n\n7.  **Technical Significance**\n    *   **Advancement of Technical State-of-the-Art:**\n        *   Provides the most extensive empirical evidence to date on the real-world productivity impact of generative AI in software development, moving beyond controlled experiments to large-scale, in-field observations \\cite{dohmke2023tpd}.\n        *   Offers novel insights into the dynamic nature of AI tool adoption, demonstrating that productivity gains *increase with user familiarity* and are *disproportionately beneficial for less experienced developers* \\cite{dohmke2023tpd}.\n        *   Delivers a robust, data-driven analysis of the generative AI open-source ecosystem, highlighting its rapid growth and the pivotal role of individual contributors.\n    *   **Potential Impact on Future Research:**\n        *   Encourages deeper investigation into the long-term learning curves, adaptation strategies, and cognitive impacts of AI-powered development tools.\n        *   Informs the design of future AI tools and educational programs, particularly those aimed at democratizing software development and empowering novice programmers.\n        *   Provides empirical data for economic models studying the impact of general-purpose technologies like AI on labor markets, productivity, and economic growth.\n        *   Underscores the critical role of open-source communities in driving and disseminating AI innovation.",
    "intriguing_abstract": "The advent of generative AI is fundamentally reshaping software development, yet its real-world, large-scale impact on developer productivity and the broader ecosystem remains largely unquantified. This paper presents an unprecedented empirical analysis of nearly one million GitHub Copilot users, leveraging extensive telemetry data to illuminate the transformative effects of AI-powered coding. We reveal two groundbreaking insights: first, developer productivity gains, measured by code suggestion acceptance rates, *increase significantly over time* as users adapt to the tool, demonstrating a powerful learning curve. Second, less experienced developers exhibit *disproportionately higher relative productivity benefits*, suggesting a profound democratizing effect on software creation. Furthermore, our study meticulously maps the explosive growth of the generative AI open-source ecosystem, highlighting individual contributions as key drivers. These findings not only advance the state-of-the-art in understanding human-AI collaboration but also project a staggering $1.5 trillion boost to global GDP by 2030, underscoring AI's pivotal role in the future of software engineering.",
    "keywords": [
      "Generative AI",
      "GitHub Copilot",
      "developer productivity",
      "large-scale telemetry analysis",
      "code suggestion acceptance rate",
      "dynamic productivity gains",
      "AI tool learning curve",
      "democratizing effect on developers",
      "generative AI open-source ecosystem",
      "economic impact of AI",
      "software development lifecycle",
      "empirical validation"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/e5bafaae57503b59a59386d0b74fc6eb40225ba8.pdf",
    "citation_key": "dohmke2023tpd",
    "metadata": {
      "title": "Sea Change in Software Development: Economic and Productivity Analysis of the AI-Powered Developer Lifecycle",
      "authors": [
        "Thomas Dohmke",
        "M. Iansiti",
        "Gregory L. Richards"
      ],
      "published_date": "2023",
      "abstract": "This study examines the impact of GitHub Copilot on a large sample of Copilot users (n=934,533). The analysis shows that users on average accept nearly 30% of the suggested code, leading to increased productivity. Furthermore, our research demonstrates that the acceptance rate rises over time and is particularly high among less experienced developers, providing them with substantial benefits. Additionally, our estimations indicate that the adoption of generative AI productivity tools could potentially contribute to a $1.5 trillion increase in global GDP by 2030. Moreover, our investigation sheds light on the diverse contributors in the generative AI landscape, including major technology companies, startups, academia, and individual developers. The findings suggest that the driving force behind generative AI software innovation lies within the open-source ecosystem, particularly in the United States. Remarkably, a majority of repositories on GitHub are led by individual developers. As more developers embrace these tools and acquire proficiency in the art of prompting with generative AI, it becomes evident that this novel approach to software development has forged a unique inextricable link between humans and artificial intelligence. This symbiotic relationship has the potential to shape the construction of the world's software for future generations.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/e5bafaae57503b59a59386d0b74fc6eb40225ba8.pdf",
      "venue": "",
      "citationCount": 27,
      "score": 13.5,
      "summary": "Here's a focused summary of the paper for a literature review, adhering to your requirements:\n\n---\n\n### Analysis of \"Sea Change in Software Development: Economic and Productivity Analysis of the AI-Powered Developer Lifecycle\" \\cite{dohmke2023tpd}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of quantifying the real-world, large-scale impact of generative AI tools, specifically GitHub Copilot, on developer productivity and understanding its broader economic and ecosystem implications.\n    *   **Importance and Challenge:** Generative AI is a rapidly evolving technology, and understanding its long-term effects on software development workflows, different developer segments, and the global economy is crucial. Previous studies were often smaller-scale or experimental; this work aims to provide a comprehensive, large-scale analysis using in-field telemetry data.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work builds upon prior research that established the efficacy of GitHub Copilot.\n        *   Previous controlled experiments (e.g., Peng et al., 2023) showed developers using GitHub Copilot completed tasks significantly faster (55.8% faster for an HTTP server).\n        *   Earlier surveys (e.g., Ziegler et al., 2022; Kalliamvakou, 2023) found a strong correlation between the acceptance rate of Copilot suggestions and reported developer productivity and satisfaction.\n    *   **Limitations of Previous Solutions:** Prior studies, while foundational, were often limited to controlled experimental settings or self-reported survey data. They lacked the ability to analyze the long-term, in-field impact across a massive user base, or to differentiate effects based on developer experience over time.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper employs a large-scale empirical analysis of telemetry data from a vast user base of GitHub Copilot.\n        *   It analyzed data from `n = 934,533` GitHub Copilot users.\n        *   The \"acceptance rate\" of code suggestions was used as a key quantitative indicator of productivity and impact, a metric validated by prior survey research.\n        *   The analysis tracked these metrics over time and across different segments of developers, categorized by their prior experience (measured by repository activity).\n        *   This was complemented by an extensive analysis of GitHub repository data (stars, forks, commits, contributors, topics) to map the growth and drivers of the generative AI open-source ecosystem.\n    *   **Novelty:**\n        *   **Unprecedented Scale:** The analysis of nearly a million users provides a robust, real-world perspective on generative AI's impact on developer productivity \\cite{dohmke2023tpd}.\n        *   **Dynamic Productivity Gains:** It uniquely demonstrates that productivity benefits from GitHub Copilot *increase over time* as developers become more accustomed to the tool, a \"novel, breakthrough finding\" \\cite{dohmke2023tpd}.\n        *   **Democratizing Effect:** The study reveals that *less experienced developers achieve greater relative productivity benefits* from the tool \\cite{dohmke2023tpd}.\n        *   **Ecosystem Mapping:** It provides a detailed, data-driven view of the exponential growth and key drivers (especially individuals and open source) within the generative AI software development ecosystem.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   Development and application of a large-scale telemetry analysis framework for AI-powered developer tools, using acceptance rate as a validated proxy for productivity.\n        *   A methodology for segmenting developer experience based on quantifiable prior platform activity to study differential impacts.\n        *   A comprehensive approach to analyzing open-source ecosystem trends through GitHub repository metadata (topics, commits, forks, stars) to track the evolution of generative AI innovation.\n    *   **Theoretical Insights or Analysis:**\n        *   Empirical validation of a \"learning curve\" for AI tool adoption, showing increasing returns to usage over time.\n        *   Demonstration of the \"democratizing\" potential of AI tools, where they disproportionately empower less experienced individuals.\n        *   Quantification of the significant economic potential of generative AI in software development, projecting a global GDP boost of over $1.5 trillion USD by 2030 \\cite{dohmke2023tpd}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:**\n        *   Analysis of GitHub Copilot telemetry data from `n = 934,533` users to measure code suggestion acceptance rates.\n        *   Longitudinal tracking of acceptance rates over several months (up to six months) to observe trends over time.\n        *   Cross-sectional analysis comparing acceptance rates across developer experience quintiles, defined by prior GitHub repository activity.\n        *   Extensive analysis of GitHub repository data (creation, forks, commits, contributors, topics) related to generative AI to illustrate ecosystem growth and innovation drivers.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Average Acceptance Rate:** Users accept an average of ~30% of code suggestions \\cite{dohmke2023tpd}.\n        *   **Time-Dependent Productivity:** Acceptance rates increase over time, demonstrating a growing impact and user comfort, with no diminishing returns observed after six months \\cite{dohmke2023tpd}.\n        *   **Experience-Dependent Productivity:** Less experienced developers (bottom quintile) exhibited a higher acceptance rate (31.9%) compared to more experienced developers (top quintile, 26.2%) \\cite{dohmke2023tpd}.\n        *   **Ecosystem Growth:** Exponential increases were observed in the number of generative AI repositories, forks, commits, and contributors on GitHub, with individuals leading the majority of such repositories.\n        *   **Economic Impact:** The productivity benefits are estimated to boost global GDP by over $1.5 trillion USD by 2030 \\cite{dohmke2023tpd}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions:**\n        *   The primary metric, \"acceptance rate,\" is used as a proxy for productivity, although its correlation with perceived productivity is supported by prior survey research \\cite{dohmke2023tpd}. The paper acknowledges ongoing research into potential overreliance.\n        *   Developer experience is inferred from prior repository activity, which may not fully capture all facets of a developer's skill or expertise.\n        *   The precise productivity effects are noted to vary by use case, suggesting a need for further granular experimental research in diverse field settings \\cite{dohmke2023tpd}.\n        *   Economic projections are conservative and \"moment-in-time,\" not fully accounting for potential increased demand for software or further digital transformation driven by AI.\n    *   **Scope of Applicability:** The analysis is primarily focused on GitHub Copilot and the GitHub ecosystem. While the insights are broadly applicable to AI-powered code generation, specific quantitative results are tied to this platform.\n\n7.  **Technical Significance**\n    *   **Advancement of Technical State-of-the-Art:**\n        *   Provides the most extensive empirical evidence to date on the real-world productivity impact of generative AI in software development, moving beyond controlled experiments to large-scale, in-field observations \\cite{dohmke2023tpd}.\n        *   Offers novel insights into the dynamic nature of AI tool adoption, demonstrating that productivity gains *increase with user familiarity* and are *disproportionately beneficial for less experienced developers* \\cite{dohmke2023tpd}.\n        *   Delivers a robust, data-driven analysis of the generative AI open-source ecosystem, highlighting its rapid growth and the pivotal role of individual contributors.\n    *   **Potential Impact on Future Research:**\n        *   Encourages deeper investigation into the long-term learning curves, adaptation strategies, and cognitive impacts of AI-powered development tools.\n        *   Informs the design of future AI tools and educational programs, particularly those aimed at democratizing software development and empowering novice programmers.\n        *   Provides empirical data for economic models studying the impact of general-purpose technologies like AI on labor markets, productivity, and economic growth.\n        *   Underscores the critical role of open-source communities in driving and disseminating AI innovation.",
      "keywords": [
        "Generative AI",
        "GitHub Copilot",
        "developer productivity",
        "large-scale telemetry analysis",
        "code suggestion acceptance rate",
        "dynamic productivity gains",
        "AI tool learning curve",
        "democratizing effect on developers",
        "generative AI open-source ecosystem",
        "economic impact of AI",
        "software development lifecycle",
        "empirical validation"
      ],
      "paper_type": "the paper type is **empirical**.\n\n**reasoning:**\n\n*   the abstract mentions \"our analysis of github data illustrates...\" which indicates a data-driven approach.\n*   the introduction explicitly describes an \"analysis\" that \"examines innovation, specifically measuring generative ai’s impact on developer productivity and learning\".\n*   it details a \"controlled experiment\" where \"developers were randomly assigned to a control group or a treatment group\" and \"revealed an important finding: developers using github copilot implemented the server 55.8% faster\". this is a classic experimental design.\n*   it also mentions \"a survey of users further investigated the effect of code generation on key productivity measures... this revealed a strong correlation...\". this indicates data collection through surveys and statistical analysis (correlation).\n\nthese elements (data analysis, controlled experiments, surveys, measurement of impact, findings, statistical relationships) are all key characteristics of an empirical study."
    },
    "file_name": "e5bafaae57503b59a59386d0b74fc6eb40225ba8.pdf"
  },
  {
    "success": true,
    "doc_id": "6b4ed3fe1618940dc9f394537beee1fd",
    "summary": "This retrospective study is aimed at developing a web‐based artificial intelligence (AI) software (DiagnoCat) for periodontal bone loss detection on panoramic radiographs and evaluating the model's performance by comparing it with clinicians' results. Separate models are trained for tooth and periodontal bone loss detection. The first model's objective was to detect teeth, segmenting their masks, and to define their numbering and developed with Mask R‐CNN using pretrained ResNet‐101 as a backbone. The second model was based on Cascade R‐CNN architecture and used for bone loss prediction. Around 100 radiographs are evaluated by three clinicians regarding tooth identification and periodontal bone loss, separately. Ground truth is determined by the consensus and model's performance is evaluated with kappa, precision, recall, and F‐score statistics. For tooth conditions, the overall F‐score, accuracy, and Cohen's kappa coefficients were found to be 0.948, 0.977, and 0.933 for the binary, and 0.992, 0.988, and 0.961 for the multiclass results. For bone loss detection, the overall F‐score, accuracy, and Cohen's kappa coefficients were found to be 0.985, 0.980, and 0.956 for the binary, and 0.996, 0.993, and 0.974 for the multiclass results. The results of this study suggest that the use of a web‐based AI software (DiagnoCat) can be beneficial in detecting periodontal bone loss on panoramic radiographs.",
    "intriguing_abstract": "This retrospective study is aimed at developing a web‐based artificial intelligence (AI) software (DiagnoCat) for periodontal bone loss detection on panoramic radiographs and evaluating the model's performance by comparing it with clinicians' results. Separate models are trained for tooth and periodontal bone loss detection. The first model's objective was to detect teeth, segmenting their masks, and to define their numbering and developed with Mask R‐CNN using pretrained ResNet‐101 as a backbone. The second model was based on Cascade R‐CNN architecture and used for bone loss prediction. Around 100 radiographs are evaluated by three clinicians regarding tooth identification and periodontal bone loss, separately. Ground truth is determined by the consensus and model's performance is evaluated with kappa, precision, recall, and F‐score statistics. For tooth conditions, the overall F‐score, accuracy, and Cohen's kappa coefficients were found to be 0.948, 0.977, and 0.933 for the binary, and 0.992, 0.988, and 0.961 for the multiclass results. For bone loss detection, the overall F‐score, accuracy, and Cohen's kappa coefficients were found to be 0.985, 0.980, and 0.956 for the binary, and 0.996, 0.993, and 0.974 for the multiclass results. The results of this study suggest that the use of a web‐based AI software (DiagnoCat) can be beneficial in detecting periodontal bone loss on panoramic radiographs.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/cb52342707b90f8e0ed38780d2e305f74becf306.pdf",
    "citation_key": "amasya20239sn",
    "metadata": {
      "title": "Development and validation of an artificial intelligence software for periodontal bone loss in panoramic imaging",
      "authors": [
        "Hakan Amasya",
        "P. Jaju",
        "M. Ezhov",
        "Maxim Gusarev",
        "Cemal Atakan",
        "A. Sanders",
        "David Manulius",
        "Maria Golitskya",
        "K. Shrivastava",
        "Ajita Singh",
        "Anuja Gupta",
        "Merve Önder",
        "K. Orhan"
      ],
      "published_date": "2023",
      "abstract": "This retrospective study is aimed at developing a web‐based artificial intelligence (AI) software (DiagnoCat) for periodontal bone loss detection on panoramic radiographs and evaluating the model's performance by comparing it with clinicians' results. Separate models are trained for tooth and periodontal bone loss detection. The first model's objective was to detect teeth, segmenting their masks, and to define their numbering and developed with Mask R‐CNN using pretrained ResNet‐101 as a backbone. The second model was based on Cascade R‐CNN architecture and used for bone loss prediction. Around 100 radiographs are evaluated by three clinicians regarding tooth identification and periodontal bone loss, separately. Ground truth is determined by the consensus and model's performance is evaluated with kappa, precision, recall, and F‐score statistics. For tooth conditions, the overall F‐score, accuracy, and Cohen's kappa coefficients were found to be 0.948, 0.977, and 0.933 for the binary, and 0.992, 0.988, and 0.961 for the multiclass results. For bone loss detection, the overall F‐score, accuracy, and Cohen's kappa coefficients were found to be 0.985, 0.980, and 0.956 for the binary, and 0.996, 0.993, and 0.974 for the multiclass results. The results of this study suggest that the use of a web‐based AI software (DiagnoCat) can be beneficial in detecting periodontal bone loss on panoramic radiographs.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/cb52342707b90f8e0ed38780d2e305f74becf306.pdf",
      "venue": "International journal of imaging systems and technology (Print)",
      "citationCount": 27,
      "score": 13.5,
      "summary": "This retrospective study is aimed at developing a web‐based artificial intelligence (AI) software (DiagnoCat) for periodontal bone loss detection on panoramic radiographs and evaluating the model's performance by comparing it with clinicians' results. Separate models are trained for tooth and periodontal bone loss detection. The first model's objective was to detect teeth, segmenting their masks, and to define their numbering and developed with Mask R‐CNN using pretrained ResNet‐101 as a backbone. The second model was based on Cascade R‐CNN architecture and used for bone loss prediction. Around 100 radiographs are evaluated by three clinicians regarding tooth identification and periodontal bone loss, separately. Ground truth is determined by the consensus and model's performance is evaluated with kappa, precision, recall, and F‐score statistics. For tooth conditions, the overall F‐score, accuracy, and Cohen's kappa coefficients were found to be 0.948, 0.977, and 0.933 for the binary, and 0.992, 0.988, and 0.961 for the multiclass results. For bone loss detection, the overall F‐score, accuracy, and Cohen's kappa coefficients were found to be 0.985, 0.980, and 0.956 for the binary, and 0.996, 0.993, and 0.974 for the multiclass results. The results of this study suggest that the use of a web‐based AI software (DiagnoCat) can be beneficial in detecting periodontal bone loss on panoramic radiographs.",
      "keywords": []
    },
    "file_name": "cb52342707b90f8e0ed38780d2e305f74becf306.pdf"
  },
  {
    "success": true,
    "doc_id": "cae385ca802d26efd4d1669c233072c2",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6e42005a5a4ba185540b01e9d2dc6e8c772e26ff.pdf",
    "citation_key": "ozkaya2023lfe",
    "metadata": {
      "title": "The Next Frontier in Software Development: AI-Augmented Software Development Processes",
      "authors": [
        "Ipek Ozkaya"
      ],
      "published_date": "2023",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6e42005a5a4ba185540b01e9d2dc6e8c772e26ff.pdf",
      "venue": "IEEE Software",
      "citationCount": 26,
      "score": 13.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "6e42005a5a4ba185540b01e9d2dc6e8c772e26ff.pdf"
  },
  {
    "success": true,
    "doc_id": "7256ab587a44f77450947a65e9f00941",
    "summary": "As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create \"black box\" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.",
    "intriguing_abstract": "As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create \"black box\" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/35be040f55ef240ca94dc1c5c0b002a1d70fbfe8.pdf",
    "citation_key": "fernandez20241ee",
    "metadata": {
      "title": "CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI",
      "authors": [
        "Amanda Fernandez",
        "Kimberly A. Cornell"
      ],
      "published_date": "2024",
      "abstract": "As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create \"black box\" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/35be040f55ef240ca94dc1c5c0b002a1d70fbfe8.pdf",
      "venue": "Technical Symposium on Computer Science Education",
      "citationCount": 13,
      "score": 13.0,
      "summary": "As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create \"black box\" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.",
      "keywords": []
    },
    "file_name": "35be040f55ef240ca94dc1c5c0b002a1d70fbfe8.pdf"
  },
  {
    "success": true,
    "doc_id": "dc5c7a955917931e0bbdba0bf4f4f986",
    "summary": "The synergy between software engineering (SE) and artificial intelligence (AI) catalyzes software development, as numerous recent studies illustrate an intensified intersection between these domains. This systematic literature review examines the integration of AI techniques or methodologies across SE phases and related activities spanning from 2013 to 2023, resulting in the selection of 110 research papers. Investigating the profound influence of AI techniques, including machine learning, deep learning, natural language processing, optimization algorithms, and expert systems, across various SE phases—such as planning, requirement engineering, design, development, testing, deployment, and maintenance—is the focal point of this study. Notably, the extensive adoption of machine learning and deep learning algorithms in the development and testing phases has enhanced software quality through defect prediction, code recommendation, and vulnerability detection initiatives. Furthermore, natural language processing’s role in automating requirements classification and sentiment analysis has streamlined SE practices. Optimization algorithms have also demonstrated efficacy in refining SE activities such as feature location and software repair action predictions, augmenting precision and efficiency in maintenance endeavors. Prospective research emphasizes the imperative of interpretable AI models and the exploration of novel AI paradigms, including explainable AI and reinforcement learning, to promote ethical and efficient software development practices. This paper fills the gap identified in AI techniques dedicated to improving SE phases. The review concludes that AI in SE is revolutionizing the discipline, enhancing software quality, efficiency, and innovation, with ongoing efforts targeting the mitigation of identified limitations and the augmentation of AI capabilities for intelligent and dependable SE.",
    "intriguing_abstract": "The synergy between software engineering (SE) and artificial intelligence (AI) catalyzes software development, as numerous recent studies illustrate an intensified intersection between these domains. This systematic literature review examines the integration of AI techniques or methodologies across SE phases and related activities spanning from 2013 to 2023, resulting in the selection of 110 research papers. Investigating the profound influence of AI techniques, including machine learning, deep learning, natural language processing, optimization algorithms, and expert systems, across various SE phases—such as planning, requirement engineering, design, development, testing, deployment, and maintenance—is the focal point of this study. Notably, the extensive adoption of machine learning and deep learning algorithms in the development and testing phases has enhanced software quality through defect prediction, code recommendation, and vulnerability detection initiatives. Furthermore, natural language processing’s role in automating requirements classification and sentiment analysis has streamlined SE practices. Optimization algorithms have also demonstrated efficacy in refining SE activities such as feature location and software repair action predictions, augmenting precision and efficiency in maintenance endeavors. Prospective research emphasizes the imperative of interpretable AI models and the exploration of novel AI paradigms, including explainable AI and reinforcement learning, to promote ethical and efficient software development practices. This paper fills the gap identified in AI techniques dedicated to improving SE phases. The review concludes that AI in SE is revolutionizing the discipline, enhancing software quality, efficiency, and innovation, with ongoing efforts targeting the mitigation of identified limitations and the augmentation of AI capabilities for intelligent and dependable SE.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/3ec861b28e230f4622d9e6950cabce00244baa26.pdf",
    "citation_key": "durrani2024qoz",
    "metadata": {
      "title": "A Decade of Progress: A Systematic Literature Review on the Integration of AI in Software Engineering Phases and Activities (2013-2023)",
      "authors": [
        "U. Durrani",
        "Mustafa Akpinar",
        "M. Fatih Adak",
        "Abdullah Talha Kabakus",
        "Muhammed Maruf Öztürk",
        "Mohammed Saleh"
      ],
      "published_date": "2024",
      "abstract": "The synergy between software engineering (SE) and artificial intelligence (AI) catalyzes software development, as numerous recent studies illustrate an intensified intersection between these domains. This systematic literature review examines the integration of AI techniques or methodologies across SE phases and related activities spanning from 2013 to 2023, resulting in the selection of 110 research papers. Investigating the profound influence of AI techniques, including machine learning, deep learning, natural language processing, optimization algorithms, and expert systems, across various SE phases—such as planning, requirement engineering, design, development, testing, deployment, and maintenance—is the focal point of this study. Notably, the extensive adoption of machine learning and deep learning algorithms in the development and testing phases has enhanced software quality through defect prediction, code recommendation, and vulnerability detection initiatives. Furthermore, natural language processing’s role in automating requirements classification and sentiment analysis has streamlined SE practices. Optimization algorithms have also demonstrated efficacy in refining SE activities such as feature location and software repair action predictions, augmenting precision and efficiency in maintenance endeavors. Prospective research emphasizes the imperative of interpretable AI models and the exploration of novel AI paradigms, including explainable AI and reinforcement learning, to promote ethical and efficient software development practices. This paper fills the gap identified in AI techniques dedicated to improving SE phases. The review concludes that AI in SE is revolutionizing the discipline, enhancing software quality, efficiency, and innovation, with ongoing efforts targeting the mitigation of identified limitations and the augmentation of AI capabilities for intelligent and dependable SE.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/3ec861b28e230f4622d9e6950cabce00244baa26.pdf",
      "venue": "IEEE Access",
      "citationCount": 13,
      "score": 13.0,
      "summary": "The synergy between software engineering (SE) and artificial intelligence (AI) catalyzes software development, as numerous recent studies illustrate an intensified intersection between these domains. This systematic literature review examines the integration of AI techniques or methodologies across SE phases and related activities spanning from 2013 to 2023, resulting in the selection of 110 research papers. Investigating the profound influence of AI techniques, including machine learning, deep learning, natural language processing, optimization algorithms, and expert systems, across various SE phases—such as planning, requirement engineering, design, development, testing, deployment, and maintenance—is the focal point of this study. Notably, the extensive adoption of machine learning and deep learning algorithms in the development and testing phases has enhanced software quality through defect prediction, code recommendation, and vulnerability detection initiatives. Furthermore, natural language processing’s role in automating requirements classification and sentiment analysis has streamlined SE practices. Optimization algorithms have also demonstrated efficacy in refining SE activities such as feature location and software repair action predictions, augmenting precision and efficiency in maintenance endeavors. Prospective research emphasizes the imperative of interpretable AI models and the exploration of novel AI paradigms, including explainable AI and reinforcement learning, to promote ethical and efficient software development practices. This paper fills the gap identified in AI techniques dedicated to improving SE phases. The review concludes that AI in SE is revolutionizing the discipline, enhancing software quality, efficiency, and innovation, with ongoing efforts targeting the mitigation of identified limitations and the augmentation of AI capabilities for intelligent and dependable SE.",
      "keywords": []
    },
    "file_name": "3ec861b28e230f4622d9e6950cabce00244baa26.pdf"
  },
  {
    "success": true,
    "doc_id": "d230abb4a8ba9416ba42c7bdd5c35155",
    "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n---\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical gap between the abstract ethical principles for Artificial Intelligence (AI) and their practical implementation throughout the Software Development Life Cycle (SDLC). While numerous Responsible AI (RAI) frameworks exist, their comprehensiveness, practical utility, and coverage across different development phases are unclear.\n    *   **Importance and Challenge**: The pervasive use of AI necessitates adherence to ethical principles (e.g., fairness, transparency, safety, privacy) to build trustworthy systems. The challenge lies in the \"principle proliferation\" (divergent definitions of ethical principles) and the difficulty for practitioners to translate high-level guidelines into concrete actions and tools across all stages of AI development and deployment \\cite{barletta202346k}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work positions itself as a systematic analysis of existing RAI frameworks, rather than proposing a new one. It builds upon previous efforts to define and categorize AI ethics principles (e.g., Jobin et al. \\cite{barletta202346k}) by empirically investigating how these principles are addressed in practical frameworks.\n    *   **Limitations of Previous Solutions (as identified by this paper)**:\n        *   Existing frameworks often suffer from \"principle proliferation,\" leading to inconsistent definitions and interpretations of ethical guidelines \\cite{barletta202346k}.\n        *   Most frameworks are abstract, providing principles or guidelines but lacking concrete, actionable tools for implementation and auditing \\cite{barletta202346k}.\n        *   There is a significant imbalance in SDLC coverage, with most frameworks focusing heavily on the early \"Requirements Elicitation\" phase, leaving later, crucial phases (Design, Development, Testing, Deployment) largely unaddressed \\cite{barletta202346k}.\n        *   No single \"catching-all\" framework exists that comprehensively covers all key RAI principles, spans the entire SDLC, and caters to both technical and non-technical stakeholders \\cite{barletta202346k}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper employs a Rapid Review (RR) methodology, adapted from established protocols \\cite{barletta202346k}, to systematically collect, organize, and analyze RAI frameworks. This involved defining clear research questions, a structured search strategy across white and grey literature (Scopus, Google Scholar, Algorithm Watch, OECD DB, Google Search), rigorous eligibility criteria, and a multi-stage, blind-view data extraction and synthesis process \\cite{barletta202346k}.\n    *   **Novelty/Difference**: The innovation lies in the systematic and quantitative mapping of existing RAI frameworks against specific ethical principles (Transparency, Diversity & Non-discrimination & Fairness, Technical Robustness & Safety, Privacy & Data Governance) and the entire SDLC. Crucially, it specifically investigates the availability and source of *supporting tools*, providing empirical evidence for the practical implementation gap in RAI, which was previously largely qualitative or anecdotal \\cite{barletta202346k}.\n\n*   **4. Key Technical Contributions**\n    *   **Systematic Mapping and Gap Identification**: The primary contribution is a quantified, systematic mapping of 148 RAI frameworks, empirically revealing critical gaps:\n        *   Only 10.1% of reviewed frameworks offer practical tools to support RAI implementation \\cite{barletta202346k}.\n        *   A stark imbalance in SDLC coverage, with 89.9% of frameworks addressing Requirements Elicitation, but significantly fewer covering Design (31.1%), Development (18.2%), Testing (16.9%), or Deployment (14.2%) \\cite{barletta202346k}.\n        *   Identification that most available tools (60%) are provided by private companies, potentially limiting accessibility for smaller entities \\cite{barletta202346k}.\n    *   **Consolidated Principle Definitions**: For consistent analysis, the paper adopts authoritative definitions for four key RAI principles from the European Commission's HLEG, providing a standardized lens to evaluate frameworks amidst \"principle proliferation\" \\cite{barletta202346k}.\n    *   **Curated Dataset**: The review implicitly contributes a valuable, categorized dataset of 148 RAI frameworks, serving as a foundational resource for future research and development in this area \\cite{barletta202346k}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: As a literature review, the \"experiment\" is the rigorous application of the rapid review methodology itself. This involved:\n        *   Executing a comprehensive search strategy across multiple academic and grey literature databases \\cite{barletta202346k}.\n        *   Applying a 3-stage information classification process (title/keywords, abstract, full article) to 148 unique resources \\cite{barletta202346k}.\n        *   Ensuring inter-rater reliability through blind-view analysis by two authors and conflict resolution by a third \\cite{barletta202346k}.\n        *   Systematically extracting data on principle coverage, SDLC phase coverage, and tool availability for each framework \\cite{barletta202346k}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Tool Availability**: Only 15 out of 148 frameworks (10.1%) offered supporting tools \\cite{barletta202346k}.\n        *   **SDLC Coverage**: 89.9% of frameworks addressed Requirements Elicitation, but coverage dropped sharply for Design (31.1%), Development (18.2%), Testing (16.9%), and Deployment (14.2%) \\cite{barletta202346k}.\n        *   **Principle Coverage**: Most frameworks (over 83%) addressed all four selected RAI principles (Transparency, Diversity & Non-discrimination & Fairness, Technical Robustness & Safety, Privacy & Data Governance) \\cite{barletta202346k}.\n        *   **Tool Provider Distribution**: Companies provided 60% of the frameworks that included tools, followed by NPG/COMM/PE (33.3%) and Universities (6.7%) \\cite{barletta202346k}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The rapid review nature, while efficient, inherently involves a streamlined search strategy and time constraints, potentially missing some relevant studies compared to a full systematic review \\cite{barletta202346k}.\n        *   The review was limited to resources in English or Italian \\cite{barletta202346k}.\n        *   The analysis focused on *whether* principles and SDLC phases were addressed, not the *depth, quality, or effectiveness* of their coverage or the tools provided \\cite{barletta202346k}.\n        *   The selection of four specific RAI principles, while justified, means other ethical considerations were not explicitly mapped \\cite{barletta202346k}.\n    *   **Scope of Applicability**: The findings are applicable to the landscape of RAI frameworks as of late 2022. They highlight critical gaps for AI practitioners, particularly those in Small and Medium Enterprises (SMEs) or non-profit organizations, who require practical, comprehensive guidance and tools to implement RAI throughout the entire SDLC \\cite{barletta202346k}.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art**: This paper significantly advances the technical state-of-the-art by providing the first quantified, systematic overview of the practical utility and SDLC coverage of Responsible AI frameworks. It moves beyond qualitative observations to empirically demonstrate the severe lack of actionable tools and comprehensive guidance for later stages of AI development, offering concrete data to inform future research and development \\cite{barletta202346k}.\n    *   **Potential Impact on Future Research**:\n        *   **Directs Framework Development**: Provides a clear roadmap for future research to focus on developing \"catching-all\" RAI frameworks that integrate practical tools and cover all SDLC phases, addressing the identified gaps \\cite{barletta202346k}.\n        *   **Catalyzes Tool Creation**: Emphasizes the urgent need for the creation of more open-source, accessible tools to support the implementation and auditing of RAI principles, especially for the Design, Development, Testing, and Deployment phases \\cite{barletta202346k}.\n        *   **Promotes Integration with Software Engineering**: Encourages future work to explore how to seamlessly integrate RAI principles and tools into existing software engineering methodologies, making ethical AI development a standard practice \\cite{barletta202346k}.\n        *   **Informs Policy and Practice**: The findings can inform policymakers and organizations about the current limitations, guiding investments and initiatives towards more practical and comprehensive RAI solutions \\cite{barletta202346k}.\n\n---",
    "intriguing_abstract": "The promise of Responsible AI (RAI) hinges on its practical implementation, yet a critical chasm persists between abstract ethical principles and their actionable integration throughout the Software Development Life Cycle (SDLC). This paper bridges this gap with the first comprehensive, *quantified* systematic review of 148 existing RAI frameworks. Moving beyond qualitative assessments, we empirically reveal a profound scarcity of practical tools (only 10.1% of frameworks) and a severe imbalance in SDLC coverage, with nearly 90% focusing solely on early requirements while crucial Design, Development, Testing, and Deployment phases remain largely unaddressed. By mapping frameworks against core ethical principles—Transparency, Fairness, Robustness, and Privacy—our findings provide concrete evidence of the \"implementation gap.\" This work is a clarion call for researchers and practitioners to develop \"catching-all\" frameworks and accessible tools, essential for embedding trustworthy AI into every stage of development and ensuring ethical principles move from aspiration to reality.",
    "keywords": [
      "Responsible AI (RAI) frameworks",
      "AI ethics principles",
      "Software Development Life Cycle (SDLC)",
      "practical implementation gap",
      "Rapid Review methodology",
      "systematic mapping",
      "quantified analysis",
      "tool availability",
      "SDLC coverage imbalance",
      "principle proliferation",
      "actionable tools",
      "empirical validation",
      "AI development and deployment"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/7438adc120459c8743411ffb9e4ed71443d66840.pdf",
    "citation_key": "barletta202346k",
    "metadata": {
      "title": "A Rapid Review of Responsible AI frameworks: How to guide the development of ethical AI",
      "authors": [
        "Vita Santa Barletta",
        "D. Caivano",
        "Domenico Gigante",
        "Azzurra Ragone"
      ],
      "published_date": "2023",
      "abstract": "In the last years, the raise of Artificial Intelligence (AI), and its pervasiveness in our lives, has sparked a flourishing debate about the ethical principles that should lead its implementation and use in society. Driven by these concerns, we conduct a rapid review of several frameworks providing principles, guidelines, and/or tools to help practitioners in the development and deployment of Responsible AI (RAI) applications. We map each framework w.r.t. the different Software Development Life Cycle (SDLC) phases discovering that most of these frameworks fall just in the Requirements Elicitation phase, leaving the other phases uncovered. Very few of these frameworks offer supporting tools for practitioners, and they are mainly provided by private companies. Our results reveal that there is not a \"catching-all\" framework supporting both technical and non-technical stakeholders in the implementation of real-world projects. Our findings highlight the lack of a comprehensive framework encompassing all RAI principles and all (SDLC) phases that could be navigated by users with different skill sets and with different goals.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/7438adc120459c8743411ffb9e4ed71443d66840.pdf",
      "venue": "International Conference on Evaluation & Assessment in Software Engineering",
      "citationCount": 26,
      "score": 13.0,
      "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n---\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the critical gap between the abstract ethical principles for Artificial Intelligence (AI) and their practical implementation throughout the Software Development Life Cycle (SDLC). While numerous Responsible AI (RAI) frameworks exist, their comprehensiveness, practical utility, and coverage across different development phases are unclear.\n    *   **Importance and Challenge**: The pervasive use of AI necessitates adherence to ethical principles (e.g., fairness, transparency, safety, privacy) to build trustworthy systems. The challenge lies in the \"principle proliferation\" (divergent definitions of ethical principles) and the difficulty for practitioners to translate high-level guidelines into concrete actions and tools across all stages of AI development and deployment \\cite{barletta202346k}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work positions itself as a systematic analysis of existing RAI frameworks, rather than proposing a new one. It builds upon previous efforts to define and categorize AI ethics principles (e.g., Jobin et al. \\cite{barletta202346k}) by empirically investigating how these principles are addressed in practical frameworks.\n    *   **Limitations of Previous Solutions (as identified by this paper)**:\n        *   Existing frameworks often suffer from \"principle proliferation,\" leading to inconsistent definitions and interpretations of ethical guidelines \\cite{barletta202346k}.\n        *   Most frameworks are abstract, providing principles or guidelines but lacking concrete, actionable tools for implementation and auditing \\cite{barletta202346k}.\n        *   There is a significant imbalance in SDLC coverage, with most frameworks focusing heavily on the early \"Requirements Elicitation\" phase, leaving later, crucial phases (Design, Development, Testing, Deployment) largely unaddressed \\cite{barletta202346k}.\n        *   No single \"catching-all\" framework exists that comprehensively covers all key RAI principles, spans the entire SDLC, and caters to both technical and non-technical stakeholders \\cite{barletta202346k}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper employs a Rapid Review (RR) methodology, adapted from established protocols \\cite{barletta202346k}, to systematically collect, organize, and analyze RAI frameworks. This involved defining clear research questions, a structured search strategy across white and grey literature (Scopus, Google Scholar, Algorithm Watch, OECD DB, Google Search), rigorous eligibility criteria, and a multi-stage, blind-view data extraction and synthesis process \\cite{barletta202346k}.\n    *   **Novelty/Difference**: The innovation lies in the systematic and quantitative mapping of existing RAI frameworks against specific ethical principles (Transparency, Diversity & Non-discrimination & Fairness, Technical Robustness & Safety, Privacy & Data Governance) and the entire SDLC. Crucially, it specifically investigates the availability and source of *supporting tools*, providing empirical evidence for the practical implementation gap in RAI, which was previously largely qualitative or anecdotal \\cite{barletta202346k}.\n\n*   **4. Key Technical Contributions**\n    *   **Systematic Mapping and Gap Identification**: The primary contribution is a quantified, systematic mapping of 148 RAI frameworks, empirically revealing critical gaps:\n        *   Only 10.1% of reviewed frameworks offer practical tools to support RAI implementation \\cite{barletta202346k}.\n        *   A stark imbalance in SDLC coverage, with 89.9% of frameworks addressing Requirements Elicitation, but significantly fewer covering Design (31.1%), Development (18.2%), Testing (16.9%), or Deployment (14.2%) \\cite{barletta202346k}.\n        *   Identification that most available tools (60%) are provided by private companies, potentially limiting accessibility for smaller entities \\cite{barletta202346k}.\n    *   **Consolidated Principle Definitions**: For consistent analysis, the paper adopts authoritative definitions for four key RAI principles from the European Commission's HLEG, providing a standardized lens to evaluate frameworks amidst \"principle proliferation\" \\cite{barletta202346k}.\n    *   **Curated Dataset**: The review implicitly contributes a valuable, categorized dataset of 148 RAI frameworks, serving as a foundational resource for future research and development in this area \\cite{barletta202346k}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: As a literature review, the \"experiment\" is the rigorous application of the rapid review methodology itself. This involved:\n        *   Executing a comprehensive search strategy across multiple academic and grey literature databases \\cite{barletta202346k}.\n        *   Applying a 3-stage information classification process (title/keywords, abstract, full article) to 148 unique resources \\cite{barletta202346k}.\n        *   Ensuring inter-rater reliability through blind-view analysis by two authors and conflict resolution by a third \\cite{barletta202346k}.\n        *   Systematically extracting data on principle coverage, SDLC phase coverage, and tool availability for each framework \\cite{barletta202346k}.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Tool Availability**: Only 15 out of 148 frameworks (10.1%) offered supporting tools \\cite{barletta202346k}.\n        *   **SDLC Coverage**: 89.9% of frameworks addressed Requirements Elicitation, but coverage dropped sharply for Design (31.1%), Development (18.2%), Testing (16.9%), and Deployment (14.2%) \\cite{barletta202346k}.\n        *   **Principle Coverage**: Most frameworks (over 83%) addressed all four selected RAI principles (Transparency, Diversity & Non-discrimination & Fairness, Technical Robustness & Safety, Privacy & Data Governance) \\cite{barletta202346k}.\n        *   **Tool Provider Distribution**: Companies provided 60% of the frameworks that included tools, followed by NPG/COMM/PE (33.3%) and Universities (6.7%) \\cite{barletta202346k}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   The rapid review nature, while efficient, inherently involves a streamlined search strategy and time constraints, potentially missing some relevant studies compared to a full systematic review \\cite{barletta202346k}.\n        *   The review was limited to resources in English or Italian \\cite{barletta202346k}.\n        *   The analysis focused on *whether* principles and SDLC phases were addressed, not the *depth, quality, or effectiveness* of their coverage or the tools provided \\cite{barletta202346k}.\n        *   The selection of four specific RAI principles, while justified, means other ethical considerations were not explicitly mapped \\cite{barletta202346k}.\n    *   **Scope of Applicability**: The findings are applicable to the landscape of RAI frameworks as of late 2022. They highlight critical gaps for AI practitioners, particularly those in Small and Medium Enterprises (SMEs) or non-profit organizations, who require practical, comprehensive guidance and tools to implement RAI throughout the entire SDLC \\cite{barletta202346k}.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art**: This paper significantly advances the technical state-of-the-art by providing the first quantified, systematic overview of the practical utility and SDLC coverage of Responsible AI frameworks. It moves beyond qualitative observations to empirically demonstrate the severe lack of actionable tools and comprehensive guidance for later stages of AI development, offering concrete data to inform future research and development \\cite{barletta202346k}.\n    *   **Potential Impact on Future Research**:\n        *   **Directs Framework Development**: Provides a clear roadmap for future research to focus on developing \"catching-all\" RAI frameworks that integrate practical tools and cover all SDLC phases, addressing the identified gaps \\cite{barletta202346k}.\n        *   **Catalyzes Tool Creation**: Emphasizes the urgent need for the creation of more open-source, accessible tools to support the implementation and auditing of RAI principles, especially for the Design, Development, Testing, and Deployment phases \\cite{barletta202346k}.\n        *   **Promotes Integration with Software Engineering**: Encourages future work to explore how to seamlessly integrate RAI principles and tools into existing software engineering methodologies, making ethical AI development a standard practice \\cite{barletta202346k}.\n        *   **Informs Policy and Practice**: The findings can inform policymakers and organizations about the current limitations, guiding investments and initiatives towards more practical and comprehensive RAI solutions \\cite{barletta202346k}.\n\n---",
      "keywords": [
        "Responsible AI (RAI) frameworks",
        "AI ethics principles",
        "Software Development Life Cycle (SDLC)",
        "practical implementation gap",
        "Rapid Review methodology",
        "systematic mapping",
        "quantified analysis",
        "tool availability",
        "SDLC coverage imbalance",
        "principle proliferation",
        "actionable tools",
        "empirical validation",
        "AI development and deployment"
      ],
      "paper_type": "the paper type is **survey**.\n\n**reasoning:**\n\n*   the **abstract** explicitly states: \"we conduct a rapid review of several frameworks providing principles, guidelines, and/or tools...\" and \"we map each framework w.r.t. the different software development life cycle (sdlc) phases\". it then discusses findings derived from this review, such as the lack of comprehensive frameworks. the keywords also include \"literature review\".\n*   the **introduction** sets the context for the need for such a review, discussing the rise of ai and the ethical principles that should guide its development.\n*   these elements directly align with the criteria for a **survey** paper: \"reviews existing literature comprehensively\" and \"abstract mentions: 'survey', 'review', 'comprehensive analysis', 'state-of-the-art'\"."
    },
    "file_name": "7438adc120459c8743411ffb9e4ed71443d66840.pdf"
  },
  {
    "success": true,
    "doc_id": "2400762a77a7436e632f36c70bc2a1a0",
    "summary": "A paradigm shift is underway in Software Engineering, with AI systems such as LLMs playing an increasingly important role in boosting software development productivity. This trend is anticipated to persist. In the next years, we expect a growing symbiotic partnership between human software developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this article, we present our vision of the future of software development in an AI-driven world and explore the key challenges that our research community should address to realize this vision.",
    "intriguing_abstract": "A paradigm shift is underway in Software Engineering, with AI systems such as LLMs playing an increasingly important role in boosting software development productivity. This trend is anticipated to persist. In the next years, we expect a growing symbiotic partnership between human software developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this article, we present our vision of the future of software development in an AI-driven world and explore the key challenges that our research community should address to realize this vision.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8fbfc75459634ab4941aafce7b23962b054b5014.pdf",
    "citation_key": "terragni2025ltf",
    "metadata": {
      "title": "The Future of AI-Driven Software Engineering",
      "authors": [
        "Valerio Terragni",
        "Annie Vella",
        "Partha S. Roop",
        "Kelly Blincoe"
      ],
      "published_date": "2025",
      "abstract": "A paradigm shift is underway in Software Engineering, with AI systems such as LLMs playing an increasingly important role in boosting software development productivity. This trend is anticipated to persist. In the next years, we expect a growing symbiotic partnership between human software developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this article, we present our vision of the future of software development in an AI-driven world and explore the key challenges that our research community should address to realize this vision.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8fbfc75459634ab4941aafce7b23962b054b5014.pdf",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "citationCount": 13,
      "score": 13.0,
      "summary": "A paradigm shift is underway in Software Engineering, with AI systems such as LLMs playing an increasingly important role in boosting software development productivity. This trend is anticipated to persist. In the next years, we expect a growing symbiotic partnership between human software developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this article, we present our vision of the future of software development in an AI-driven world and explore the key challenges that our research community should address to realize this vision.",
      "keywords": []
    },
    "file_name": "8fbfc75459634ab4941aafce7b23962b054b5014.pdf"
  },
  {
    "success": true,
    "doc_id": "7db88e247b6e5d5a71d4b225ebe29a4d",
    "summary": "Here is a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n### Focused Summary for Literature Review: Empowering Agile-Based Generative Software Development through Human-AI Teamwork \\cite{zhang2024gcy}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of generating complete and accurate software from often incomplete and informal user requirements, particularly when users lack the domain knowledge to articulate detailed specifications or acceptance criteria \\cite{zhang2024gcy}. This leads to software that fails to meet implicit user needs and discrepancies between requirements and generated code \\cite{zhang2024gcy}.\n    *   **Importance and Challenge:** This problem is crucial because current generative software development agents (passive, auto-thinking, multi-agent, questioning) struggle with:\n        *   The propagation and accumulation of errors (e.g., LLM hallucinations) in sequential waterfall models \\cite{zhang2024gcy}.\n        *   The inability to effectively capture user acceptance criteria, leading to functional deviations \\cite{zhang2024gcy}.\n        *   Requiring users to possess substantial domain knowledge to interact effectively or debug, which is often not the case for end-users \\cite{zhang2024gcy}.\n        *   Ensuring semantic consistency between abstract user requirements and the concrete code generated by AI agents \\cite{zhang2024gcy}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work positions itself against four categories of existing generative software development agents:\n        *   **Passive Agents (e.g., ChatGPT, Copilot Chat):** Act as copilots, requiring extensive step-by-step user guidance and lacking analytical capabilities \\cite{zhang2024gcy}.\n        *   **Auto-Thinking Agents (e.g., AutoGPT, DemoGPT):** Offer closed autonomy, making debugging difficult and susceptible to internal process freezing \\cite{zhang2024gcy}. They often follow a waterfall model, accumulating errors \\cite{zhang2024gcy}.\n        *   **Multi-Agent Collaboration Agents (e.g., MetaGPT, ChatDev):** Involve complex intermediate steps, prioritize documentation, and often fail to maintain user control \\cite{zhang2024gcy}. They also follow a waterfall model, leading to error accumulation \\cite{zhang2024gcy}.\n        *   **Questioning Agents (e.g., GPT-Engineer, GPT-pilot):** Attempt to expand requirements by asking users questions, but these often demand substantial programming-oriented domain knowledge from users \\cite{zhang2024gcy}.\n    *   **Limitations of Previous Solutions:**\n        *   A universal limitation is the lack of effective acceptance criteria during requirement completion, leading to software that misses implicit user needs \\cite{zhang2024gcy}.\n        *   Reliance on the waterfall model in many approaches leads to cumulative errors and discrepancies between generated code and user requirements due to the propagation of biases and LLM hallucinations \\cite{zhang2024gcy}.\n        *   Existing methods struggle to bridge the semantic gap between informal user requirements and precise code, and to effectively integrate users who lack technical domain knowledge into the development process \\cite{zhang2024gcy}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** AgileGen proposes an agile-based generative software development framework leveraging human-AI teamwork \\cite{zhang2024gcy}. It adopts a lightweight iterative feedback loop and strategically involves users in decision-making processes where they excel \\cite{zhang2024gcy}.\n    *   **Novelty/Differentiation:**\n        *   **End-User Perspective for Acceptance Criteria:** Unlike questioning agents, AgileGen initiates an end-user perspective to complete acceptance criteria, breaking free from domain knowledge constraints \\cite{zhang2024gcy}.\n        *   **Gherkin Language as a Semantic Bridge:** It introduces the Gherkin language (a formal Behavior Driven Development language) for the first time in this context to define testable requirement descriptions (user scenarios with acceptance criteria), ensuring semantic consistency between requirements and code \\cite{zhang2024gcy}.\n        *   **Innovative Human-AI Teamwork Model:** Users participate in key decision-making processes (requirement proposal, clarification, iterative acceptance with recommendations), while the AI agent handles execution and code generation \\cite{zhang2024gcy}. This is facilitated by an \"interaction bridge\" that translates Gherkin-based requirements into natural language scenarios for user input \\cite{zhang2024gcy}.\n        *   **Consistency Factors:** Derived from Gherkin scenarios, these factors guide subsequent visual design and code generation, ensuring alignment with user needs \\cite{zhang2024gcy}.\n        *   **Memory Pool Mechanism:** Collects and recommends past user decision-making scenarios to new users with similar requirements, enhancing reliability and efficiency \\cite{zhang2024gcy}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Integration of agile methodologies with human-AI teamwork for generative software development, specifically addressing implicit user needs through Gherkin-based acceptance criteria \\cite{zhang2024gcy}.\n        *   An innovative interaction bridge and decision-making method that translates Gherkin-based requirements into natural language scenarios, reducing user knowledge barriers \\cite{zhang2024gcy}.\n        *   A novel approach to derive and utilize \"consistency factors\" from Gherkin to drive code generation and ensure alignment with user requirements \\cite{zhang2024gcy}.\n        *   A lightweight iterative process for rapid prototyping and user feedback, mitigating cumulative errors common in waterfall models \\cite{zhang2024gcy}.\n    *   **System Design/Architectural Innovations:**\n        *   The design of a human-AI teamwork model that strategically places end-users at the requirement clarification and iterative acceptance stages, leveraging their decision-making skills \\cite{zhang2024gcy}.\n        *   Introduction of a memory pool mechanism to store and recommend user decision-making results, improving the efficiency and reliability of requirement refinement \\cite{zhang2024gcy}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** AgileGen was evaluated on 40 diverse web projects and the \"SRDD\" software task dataset \\cite{zhang2024gcy}. User satisfaction was also assessed through participant evaluations \\cite{zhang2024gcy}.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   AgileGen significantly outperformed existing best methods by 16.4% in generative software development efficiency \\cite{zhang2024gcy}.\n        *   It garnered higher user satisfaction scores, as measured by the User Experience Questionnaire (UEQ) and Likert scale assessments \\cite{zhang2024gcy}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper does not explicitly list technical limitations of AgileGen itself within the provided text, but rather the problems it aims to solve in existing systems.\n    *   **Scope of Applicability:** While demonstrated using web development for convenience, the design principles of AgileGen are stated to be \"not limited to web application development\" \\cite{zhang2024gcy}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** AgileGen significantly advances the state-of-the-art in generative software development by being the first to integrate agile methodologies with human-AI teamwork \\cite{zhang2024gcy}. It provides a robust solution for addressing implicit user needs and ensuring semantic consistency between requirements and generated code, a critical gap in previous LLM-based approaches \\cite{zhang2024gcy}.\n    *   **Potential Impact on Future Research:** This work opens avenues for future research in:\n        *   More sophisticated human-AI collaboration models that leverage human strengths in decision-making and AI strengths in execution \\cite{zhang2024gcy}.\n        *   The application of formal, testable requirement description languages (like Gherkin) as effective bridges in generative AI pipelines \\cite{zhang2024gcy}.\n        *   Developing adaptive systems that learn from user interactions and feedback (e.g., through memory pools) to improve requirement refinement and code generation reliability \\cite{zhang2024gcy}.\n        *   Reducing the domain knowledge barrier for end-users in software development, making AI-driven development more accessible \\cite{zhang2024gcy}.",
    "intriguing_abstract": "Generative software development, powered by Large Language Models (LLMs), frequently falters when translating informal user requirements into functional software, leading to error propagation, LLM hallucinations, and a critical inability to capture implicit user needs and acceptance criteria. Existing agents struggle with semantic consistency and demand extensive domain knowledge from users. We introduce **AgileGen**, a novel agile-based framework that revolutionizes generative software development through strategic **human-AI teamwork**. AgileGen leverages a lightweight **iterative feedback loop**, empowering end-users to define precise **acceptance criteria** using the **Gherkin language**, which acts as a robust **semantic bridge** between abstract requirements and concrete code. Our innovative interaction model places users at key decision points, while an AI agent handles execution, guided by Gherkin-derived **consistency factors** and a **memory pool** for enhanced reliability. Experimental validation across diverse projects shows AgileGen significantly outperforms state-of-the-art methods by 16.4% in efficiency and achieves superior user satisfaction. AgileGen paves the way for more accessible, reliable, and user-centric AI-driven software creation, mitigating cumulative errors and bridging the semantic gap in **requirement engineering**.",
    "keywords": [
      "AgileGen",
      "human-AI teamwork",
      "generative software development",
      "user acceptance criteria",
      "Gherkin language",
      "Behavior Driven Development (BDD)",
      "iterative feedback loop",
      "semantic consistency",
      "consistency factors",
      "memory pool mechanism",
      "LLM hallucinations",
      "end-user perspective",
      "domain knowledge barrier",
      "software development efficiency",
      "user satisfaction"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/bdb97f6f85eba3a9786216fa4de033cf82385b60.pdf",
    "citation_key": "zhang2024gcy",
    "metadata": {
      "title": "Empowering Agile-Based Generative Software Development through Human-AI Teamwork",
      "authors": [
        "Sai Zhang",
        "Zhenchang Xing",
        "Ronghui Guo",
        "Fangzhou Xu",
        "Lei Chen",
        "Zhaoyuan Zhang",
        "Xiaowang Zhang",
        "Zhiyong Feng",
        "Zhiqiang Zhuang"
      ],
      "published_date": "2024",
      "abstract": "In software development, the raw requirements proposed by users are frequently incomplete, which impedes the complete implementation of software functionalities. With the emergence of large language models, the exploration of generating software through user requirements has attracted attention. Recent methods with the top-down waterfall model employ a questioning approach for requirement completion, attempting to explore further user requirements. However, users, constrained by their domain knowledge, result in a lack of effective acceptance criteria during the requirement completion, failing to fully capture the implicit needs of the user. Moreover, the cumulative errors of the waterfall model can lead to discrepancies between the generated code and user requirements. The Agile methodologies reduce cumulative errors of the waterfall model through lightweight iteration and collaboration with users, but the challenge lies in ensuring semantic consistency between user requirements and the code generated by the agent. To address these challenges, we propose AgileGen, an agile-based generative software development through human-AI teamwork. Unlike existing questioning agents, AgileGen adopts a novel collaborative approach that breaks free from the constraints of domain knowledge by initiating the end-user perspective to complete the acceptance criteria. By introducing the Gherkin language, AgileGen attempts for the first time to use testable requirement descriptions as a bridge for semantic consistency between requirements and code, aiming to ensure that software products meet actual user requirements by defining user scenarios that include acceptance criteria. Additionally, we innovate in the human-AI teamwork model, allowing users to participate in decision-making processes they do well and significantly enhancing the completeness of software functionality. To ensure semantic consistency between requirements and generated code, we derive consistency factors from Gherkin to drive the subsequent software code generation. Finally, to improve the reliability of user scenarios, we also introduce a memory pool mechanism, collecting user decision-making scenarios and recommending them to new users with similar requirements. AgileGen, as a user-friendly interactive system, significantly outperformed existing best methods by 16.4% and garnered higher user satisfaction.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/bdb97f6f85eba3a9786216fa4de033cf82385b60.pdf",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "citationCount": 12,
      "score": 12.0,
      "summary": "Here is a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n### Focused Summary for Literature Review: Empowering Agile-Based Generative Software Development through Human-AI Teamwork \\cite{zhang2024gcy}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of generating complete and accurate software from often incomplete and informal user requirements, particularly when users lack the domain knowledge to articulate detailed specifications or acceptance criteria \\cite{zhang2024gcy}. This leads to software that fails to meet implicit user needs and discrepancies between requirements and generated code \\cite{zhang2024gcy}.\n    *   **Importance and Challenge:** This problem is crucial because current generative software development agents (passive, auto-thinking, multi-agent, questioning) struggle with:\n        *   The propagation and accumulation of errors (e.g., LLM hallucinations) in sequential waterfall models \\cite{zhang2024gcy}.\n        *   The inability to effectively capture user acceptance criteria, leading to functional deviations \\cite{zhang2024gcy}.\n        *   Requiring users to possess substantial domain knowledge to interact effectively or debug, which is often not the case for end-users \\cite{zhang2024gcy}.\n        *   Ensuring semantic consistency between abstract user requirements and the concrete code generated by AI agents \\cite{zhang2024gcy}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work positions itself against four categories of existing generative software development agents:\n        *   **Passive Agents (e.g., ChatGPT, Copilot Chat):** Act as copilots, requiring extensive step-by-step user guidance and lacking analytical capabilities \\cite{zhang2024gcy}.\n        *   **Auto-Thinking Agents (e.g., AutoGPT, DemoGPT):** Offer closed autonomy, making debugging difficult and susceptible to internal process freezing \\cite{zhang2024gcy}. They often follow a waterfall model, accumulating errors \\cite{zhang2024gcy}.\n        *   **Multi-Agent Collaboration Agents (e.g., MetaGPT, ChatDev):** Involve complex intermediate steps, prioritize documentation, and often fail to maintain user control \\cite{zhang2024gcy}. They also follow a waterfall model, leading to error accumulation \\cite{zhang2024gcy}.\n        *   **Questioning Agents (e.g., GPT-Engineer, GPT-pilot):** Attempt to expand requirements by asking users questions, but these often demand substantial programming-oriented domain knowledge from users \\cite{zhang2024gcy}.\n    *   **Limitations of Previous Solutions:**\n        *   A universal limitation is the lack of effective acceptance criteria during requirement completion, leading to software that misses implicit user needs \\cite{zhang2024gcy}.\n        *   Reliance on the waterfall model in many approaches leads to cumulative errors and discrepancies between generated code and user requirements due to the propagation of biases and LLM hallucinations \\cite{zhang2024gcy}.\n        *   Existing methods struggle to bridge the semantic gap between informal user requirements and precise code, and to effectively integrate users who lack technical domain knowledge into the development process \\cite{zhang2024gcy}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** AgileGen proposes an agile-based generative software development framework leveraging human-AI teamwork \\cite{zhang2024gcy}. It adopts a lightweight iterative feedback loop and strategically involves users in decision-making processes where they excel \\cite{zhang2024gcy}.\n    *   **Novelty/Differentiation:**\n        *   **End-User Perspective for Acceptance Criteria:** Unlike questioning agents, AgileGen initiates an end-user perspective to complete acceptance criteria, breaking free from domain knowledge constraints \\cite{zhang2024gcy}.\n        *   **Gherkin Language as a Semantic Bridge:** It introduces the Gherkin language (a formal Behavior Driven Development language) for the first time in this context to define testable requirement descriptions (user scenarios with acceptance criteria), ensuring semantic consistency between requirements and code \\cite{zhang2024gcy}.\n        *   **Innovative Human-AI Teamwork Model:** Users participate in key decision-making processes (requirement proposal, clarification, iterative acceptance with recommendations), while the AI agent handles execution and code generation \\cite{zhang2024gcy}. This is facilitated by an \"interaction bridge\" that translates Gherkin-based requirements into natural language scenarios for user input \\cite{zhang2024gcy}.\n        *   **Consistency Factors:** Derived from Gherkin scenarios, these factors guide subsequent visual design and code generation, ensuring alignment with user needs \\cite{zhang2024gcy}.\n        *   **Memory Pool Mechanism:** Collects and recommends past user decision-making scenarios to new users with similar requirements, enhancing reliability and efficiency \\cite{zhang2024gcy}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms/Methods:**\n        *   Integration of agile methodologies with human-AI teamwork for generative software development, specifically addressing implicit user needs through Gherkin-based acceptance criteria \\cite{zhang2024gcy}.\n        *   An innovative interaction bridge and decision-making method that translates Gherkin-based requirements into natural language scenarios, reducing user knowledge barriers \\cite{zhang2024gcy}.\n        *   A novel approach to derive and utilize \"consistency factors\" from Gherkin to drive code generation and ensure alignment with user requirements \\cite{zhang2024gcy}.\n        *   A lightweight iterative process for rapid prototyping and user feedback, mitigating cumulative errors common in waterfall models \\cite{zhang2024gcy}.\n    *   **System Design/Architectural Innovations:**\n        *   The design of a human-AI teamwork model that strategically places end-users at the requirement clarification and iterative acceptance stages, leveraging their decision-making skills \\cite{zhang2024gcy}.\n        *   Introduction of a memory pool mechanism to store and recommend user decision-making results, improving the efficiency and reliability of requirement refinement \\cite{zhang2024gcy}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** AgileGen was evaluated on 40 diverse web projects and the \"SRDD\" software task dataset \\cite{zhang2024gcy}. User satisfaction was also assessed through participant evaluations \\cite{zhang2024gcy}.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   AgileGen significantly outperformed existing best methods by 16.4% in generative software development efficiency \\cite{zhang2024gcy}.\n        *   It garnered higher user satisfaction scores, as measured by the User Experience Questionnaire (UEQ) and Likert scale assessments \\cite{zhang2024gcy}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper does not explicitly list technical limitations of AgileGen itself within the provided text, but rather the problems it aims to solve in existing systems.\n    *   **Scope of Applicability:** While demonstrated using web development for convenience, the design principles of AgileGen are stated to be \"not limited to web application development\" \\cite{zhang2024gcy}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** AgileGen significantly advances the state-of-the-art in generative software development by being the first to integrate agile methodologies with human-AI teamwork \\cite{zhang2024gcy}. It provides a robust solution for addressing implicit user needs and ensuring semantic consistency between requirements and generated code, a critical gap in previous LLM-based approaches \\cite{zhang2024gcy}.\n    *   **Potential Impact on Future Research:** This work opens avenues for future research in:\n        *   More sophisticated human-AI collaboration models that leverage human strengths in decision-making and AI strengths in execution \\cite{zhang2024gcy}.\n        *   The application of formal, testable requirement description languages (like Gherkin) as effective bridges in generative AI pipelines \\cite{zhang2024gcy}.\n        *   Developing adaptive systems that learn from user interactions and feedback (e.g., through memory pools) to improve requirement refinement and code generation reliability \\cite{zhang2024gcy}.\n        *   Reducing the domain knowledge barrier for end-users in software development, making AI-driven development more accessible \\cite{zhang2024gcy}.",
      "keywords": [
        "AgileGen",
        "human-AI teamwork",
        "generative software development",
        "user acceptance criteria",
        "Gherkin language",
        "Behavior Driven Development (BDD)",
        "iterative feedback loop",
        "semantic consistency",
        "consistency factors",
        "memory pool mechanism",
        "LLM hallucinations",
        "end-user perspective",
        "domain knowledge barrier",
        "software development efficiency",
        "user satisfaction"
      ],
      "paper_type": "based on the provided content:\n\nthe abstract is incomplete and primarily contains metadata. therefore, the classification relies heavily on the introduction.\n\nthe introduction states:\n*   \"it is widely recognized that realizing generative software development requires overcoming two major challenges: requirement analysis and software design...\" - identifies a technical problem.\n*   \"fig. 1. problem statement diagram. users are unsure how to drive the agent to generate desired software, and the agent does not know how to fulfill user requirements. **we have built a bridge between users and the agent, facilitating collaboration between human decision-making skills and the agent’s coding capabilities. this collaboration has created a generative software development agent with lightweight iterative feedback.**\" - this is a strong indicator. the phrases \"we have built a bridge\" and \"created a generative software development agent\" explicitly describe the development and presentation of a new system or method to address the identified problem.\n\nthis aligns directly with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and \"introduction discusses: technical problem, proposed solution.\"\n\nthe final classification is: **technical**"
    },
    "file_name": "bdb97f6f85eba3a9786216fa4de033cf82385b60.pdf"
  },
  {
    "success": true,
    "doc_id": "47e4af28b86fa44adbc8cd35b1086047",
    "summary": "Software assistants have significantly impacted software development for both practitioners and students, particularly in capstone projects. The effectiveness of these tools varies based on their knowledge sources; assistants with localized domain-specific knowledge may have limitations, while tools, such as ChatGPT, using broad datasets, might offer recommendations that do not always match the specific objectives of a capstone course. Addressing a gap in current educational technology, this article introduces an AI Knowledge Assistant specifically designed to overcome the limitations of the existing tools by enhancing the quality and relevance of large language models (LLMs). It achieves this through the innovative integration of contextual knowledge from a local “lessons learned” database tailored to the capstone course. We conducted a study with 150 students using the assistant during their capstone course. Integrated into the Kanban project tracking system, the assistant offered recommendations using different strategies: direct searches in the lessons learned database, direct queries to a generative pretrained transformers (GPT) model, query enrichment with lessons learned before submission to GPT and large language model meta AI (LLaMa) models, and query enhancement with Stack Overflow data before GPT processing. Survey results underscored a strong preference among students for direct LLM queries and those enriched with local repository insights, highlighting the assistant's practical value. Furthermore, our linguistic analysis conclusively demonstrated that texts generated by the LLM closely mirrored the linguistic standards and topical relevance of university course requirements. This alignment not only fosters a deeper understanding of course content but also significantly enhances the material's applicability to real-world scenarios.",
    "intriguing_abstract": "Software assistants have significantly impacted software development for both practitioners and students, particularly in capstone projects. The effectiveness of these tools varies based on their knowledge sources; assistants with localized domain-specific knowledge may have limitations, while tools, such as ChatGPT, using broad datasets, might offer recommendations that do not always match the specific objectives of a capstone course. Addressing a gap in current educational technology, this article introduces an AI Knowledge Assistant specifically designed to overcome the limitations of the existing tools by enhancing the quality and relevance of large language models (LLMs). It achieves this through the innovative integration of contextual knowledge from a local “lessons learned” database tailored to the capstone course. We conducted a study with 150 students using the assistant during their capstone course. Integrated into the Kanban project tracking system, the assistant offered recommendations using different strategies: direct searches in the lessons learned database, direct queries to a generative pretrained transformers (GPT) model, query enrichment with lessons learned before submission to GPT and large language model meta AI (LLaMa) models, and query enhancement with Stack Overflow data before GPT processing. Survey results underscored a strong preference among students for direct LLM queries and those enriched with local repository insights, highlighting the assistant's practical value. Furthermore, our linguistic analysis conclusively demonstrated that texts generated by the LLM closely mirrored the linguistic standards and topical relevance of university course requirements. This alignment not only fosters a deeper understanding of course content but also significantly enhances the material's applicability to real-world scenarios.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/5ed9c52576538a98804493f067c333ab5673d4f0.pdf",
    "citation_key": "neyem20249v2",
    "metadata": {
      "title": "Toward an AI Knowledge Assistant for Context-Aware Learning Experiences in Software Capstone Project Development",
      "authors": [
        "Andrés Neyem",
        "Luis A. González",
        "M. Mendoza",
        "Juan Pablo Sandoval Alcocer",
        "Leonardo Centellas",
        "Carlos Paredes"
      ],
      "published_date": "2024",
      "abstract": "Software assistants have significantly impacted software development for both practitioners and students, particularly in capstone projects. The effectiveness of these tools varies based on their knowledge sources; assistants with localized domain-specific knowledge may have limitations, while tools, such as ChatGPT, using broad datasets, might offer recommendations that do not always match the specific objectives of a capstone course. Addressing a gap in current educational technology, this article introduces an AI Knowledge Assistant specifically designed to overcome the limitations of the existing tools by enhancing the quality and relevance of large language models (LLMs). It achieves this through the innovative integration of contextual knowledge from a local “lessons learned” database tailored to the capstone course. We conducted a study with 150 students using the assistant during their capstone course. Integrated into the Kanban project tracking system, the assistant offered recommendations using different strategies: direct searches in the lessons learned database, direct queries to a generative pretrained transformers (GPT) model, query enrichment with lessons learned before submission to GPT and large language model meta AI (LLaMa) models, and query enhancement with Stack Overflow data before GPT processing. Survey results underscored a strong preference among students for direct LLM queries and those enriched with local repository insights, highlighting the assistant's practical value. Furthermore, our linguistic analysis conclusively demonstrated that texts generated by the LLM closely mirrored the linguistic standards and topical relevance of university course requirements. This alignment not only fosters a deeper understanding of course content but also significantly enhances the material's applicability to real-world scenarios.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/5ed9c52576538a98804493f067c333ab5673d4f0.pdf",
      "venue": "IEEE Transactions on Learning Technologies",
      "citationCount": 12,
      "score": 12.0,
      "summary": "Software assistants have significantly impacted software development for both practitioners and students, particularly in capstone projects. The effectiveness of these tools varies based on their knowledge sources; assistants with localized domain-specific knowledge may have limitations, while tools, such as ChatGPT, using broad datasets, might offer recommendations that do not always match the specific objectives of a capstone course. Addressing a gap in current educational technology, this article introduces an AI Knowledge Assistant specifically designed to overcome the limitations of the existing tools by enhancing the quality and relevance of large language models (LLMs). It achieves this through the innovative integration of contextual knowledge from a local “lessons learned” database tailored to the capstone course. We conducted a study with 150 students using the assistant during their capstone course. Integrated into the Kanban project tracking system, the assistant offered recommendations using different strategies: direct searches in the lessons learned database, direct queries to a generative pretrained transformers (GPT) model, query enrichment with lessons learned before submission to GPT and large language model meta AI (LLaMa) models, and query enhancement with Stack Overflow data before GPT processing. Survey results underscored a strong preference among students for direct LLM queries and those enriched with local repository insights, highlighting the assistant's practical value. Furthermore, our linguistic analysis conclusively demonstrated that texts generated by the LLM closely mirrored the linguistic standards and topical relevance of university course requirements. This alignment not only fosters a deeper understanding of course content but also significantly enhances the material's applicability to real-world scenarios.",
      "keywords": []
    },
    "file_name": "5ed9c52576538a98804493f067c333ab5673d4f0.pdf"
  },
  {
    "success": true,
    "doc_id": "b322bf48a5a10ca9e5760765bb1e45d3",
    "summary": "The concept and methodology known as Usercentred Design (UCD) puts the user at the center and concentrates on cognitive aspects as they relate to how people interact with objects. In order to overcome biassed decisionmaking, automated AI-based decision support systems need to be able to be used, trusted, and accepted. Design criteria for AI-based decision support systems in traditional craftsmanship are therefore required. In this contribution, we examined the relationships between user acceptance and a user-centred design by evaluating three distinct applications in a mixedmethod user research ($\\mathbf{N} \\mathbf{D}=20$) that included both qualitative (think aloud) and quantitative (survey) components. Starting with research-related planning agreements, the context is established by interviewing the parties who agreed in the first stage, the needs are ascertained through user assessments, the System Usability Scale (SUS) method is used to determine the results, a prototype is designed based on the findings of the third step, and UI evaluation is conducted using the same method when evaluating the UI AI running in the third stage to demonstrate whether or not there has been a significant improvement. It took into account technological adoption, usability, and planning objectivity and efficiency. The findings imply that while AI-based decision support systems improve speed and objectivity, usability, acceptance, and confidence depend on user-centred design. Given that automated options were not as often questioned, it makes sense to give the decision maker the last say. It produces practical recommendations for the development of AI-based manufacturing support systems.",
    "intriguing_abstract": "The concept and methodology known as Usercentred Design (UCD) puts the user at the center and concentrates on cognitive aspects as they relate to how people interact with objects. In order to overcome biassed decisionmaking, automated AI-based decision support systems need to be able to be used, trusted, and accepted. Design criteria for AI-based decision support systems in traditional craftsmanship are therefore required. In this contribution, we examined the relationships between user acceptance and a user-centred design by evaluating three distinct applications in a mixedmethod user research ($\\mathbf{N} \\mathbf{D}=20$) that included both qualitative (think aloud) and quantitative (survey) components. Starting with research-related planning agreements, the context is established by interviewing the parties who agreed in the first stage, the needs are ascertained through user assessments, the System Usability Scale (SUS) method is used to determine the results, a prototype is designed based on the findings of the third step, and UI evaluation is conducted using the same method when evaluating the UI AI running in the third stage to demonstrate whether or not there has been a significant improvement. It took into account technological adoption, usability, and planning objectivity and efficiency. The findings imply that while AI-based decision support systems improve speed and objectivity, usability, acceptance, and confidence depend on user-centred design. Given that automated options were not as often questioned, it makes sense to give the decision maker the last say. It produces practical recommendations for the development of AI-based manufacturing support systems.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/0f4f61e2cac9cf1768f44d7981165df28a41b86b.pdf",
    "citation_key": "chilluri20257ca",
    "metadata": {
      "title": "Design and Implementation of a User Centered Design Framework for Software Development",
      "authors": [
        "Venkata Suresh Babu Chilluri",
        "Sanjay Oli",
        "Chandani Sharma",
        "Ankit Kumar"
      ],
      "published_date": "2025",
      "abstract": "The concept and methodology known as Usercentred Design (UCD) puts the user at the center and concentrates on cognitive aspects as they relate to how people interact with objects. In order to overcome biassed decisionmaking, automated AI-based decision support systems need to be able to be used, trusted, and accepted. Design criteria for AI-based decision support systems in traditional craftsmanship are therefore required. In this contribution, we examined the relationships between user acceptance and a user-centred design by evaluating three distinct applications in a mixedmethod user research ($\\mathbf{N} \\mathbf{D}=20$) that included both qualitative (think aloud) and quantitative (survey) components. Starting with research-related planning agreements, the context is established by interviewing the parties who agreed in the first stage, the needs are ascertained through user assessments, the System Usability Scale (SUS) method is used to determine the results, a prototype is designed based on the findings of the third step, and UI evaluation is conducted using the same method when evaluating the UI AI running in the third stage to demonstrate whether or not there has been a significant improvement. It took into account technological adoption, usability, and planning objectivity and efficiency. The findings imply that while AI-based decision support systems improve speed and objectivity, usability, acceptance, and confidence depend on user-centred design. Given that automated options were not as often questioned, it makes sense to give the decision maker the last say. It produces practical recommendations for the development of AI-based manufacturing support systems.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/0f4f61e2cac9cf1768f44d7981165df28a41b86b.pdf",
      "venue": "2025 First International Conference on Advances in Computer Science, Electrical, Electronics, and Communication Technologies (CE2CT)",
      "citationCount": 12,
      "score": 12.0,
      "summary": "The concept and methodology known as Usercentred Design (UCD) puts the user at the center and concentrates on cognitive aspects as they relate to how people interact with objects. In order to overcome biassed decisionmaking, automated AI-based decision support systems need to be able to be used, trusted, and accepted. Design criteria for AI-based decision support systems in traditional craftsmanship are therefore required. In this contribution, we examined the relationships between user acceptance and a user-centred design by evaluating three distinct applications in a mixedmethod user research ($\\mathbf{N} \\mathbf{D}=20$) that included both qualitative (think aloud) and quantitative (survey) components. Starting with research-related planning agreements, the context is established by interviewing the parties who agreed in the first stage, the needs are ascertained through user assessments, the System Usability Scale (SUS) method is used to determine the results, a prototype is designed based on the findings of the third step, and UI evaluation is conducted using the same method when evaluating the UI AI running in the third stage to demonstrate whether or not there has been a significant improvement. It took into account technological adoption, usability, and planning objectivity and efficiency. The findings imply that while AI-based decision support systems improve speed and objectivity, usability, acceptance, and confidence depend on user-centred design. Given that automated options were not as often questioned, it makes sense to give the decision maker the last say. It produces practical recommendations for the development of AI-based manufacturing support systems.",
      "keywords": []
    },
    "file_name": "0f4f61e2cac9cf1768f44d7981165df28a41b86b.pdf"
  },
  {
    "success": true,
    "doc_id": "dd3c46eaddc087c7ab6e1a8821aa27b7",
    "summary": "Here's a focused summary of the paper for a literature review, adhering to your requirements:\n\n---\n\n### Analysis of \"The Future of Software Engineering in an AI-Driven World\" \\cite{terragni20245xq}\n\n1.  **Research Problem & Motivation**\n    *   **Problem:** The software engineering (SE) field is undergoing a paradigm shift due to the increasing integration of AI systems, particularly Large Language Models (LLMs), which are significantly impacting software development productivity \\cite{terragni20245xq}.\n    *   **Motivation:** This trend towards a symbiotic partnership between human developers and AI is anticipated to persist and grow. The SE research community must proactively address the key research challenges and opportunities arising from this integration to realize an AI-driven future for software development \\cite{terragni20245xq}. Concerns exist regarding the quality, security, and privacy of AI-generated code, necessitating focused research.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper positions LLMs as the latest step in a continuous pursuit of higher abstraction in programming, following machine code, assembly, high-level languages, and the widespread use of APIs and libraries \\cite{terragni20245xq}. It notes that LLMs are rapidly overshadowing traditional developer Q&A platforms like StackOverflow by directly generating code from natural language queries.\n    *   **Limitations of Previous Solutions/Current LLM Use:** While LLMs offer unprecedented productivity, current implementations face limitations regarding the quality, security, and privacy of generated code \\cite{terragni20245xq}. Traditional automated test generators often produce regression oracles, which are insufficient for verifying newly AI-generated code, highlighting a gap in current testing methodologies for this new paradigm.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a vision for an AI-driven software development framework where AI systems (e.g., LLMs) are deeply integrated across the entire Software Development Life Cycle (SDLC): Requirements Engineering, Software Design, Implementation, Testing, and Maintenance \\cite{terragni20245xq}. This framework envisions a bi-directional, conversational interaction between human software engineers and AI, with humans remaining in the loop for oversight, refinement, and validation.\n    *   **Novelty/Differentiation:**\n        *   **AI Orchestration:** A key innovation is the concept of an \"orchestrator of AIs\" – a single unified human-AI interface that manages interactions with various dedicated AI subsystems, each fine-tuned for specific development tasks (e.g., requirements analysis, code generation, testing). This orchestrator monitors artifact changes and invokes relevant AI subsystems for consistency and integrity checks \\cite{terragni20245xq}.\n        *   **Prompt-Friendly Requirement Language:** The vision includes defining a new language for requirements that is \"prompt-friendly,\" enabling seamless understanding by LLMs for subsequent code generation, potentially by unambiguously separating functional and non-functional requirements \\cite{terragni20245xq}.\n        *   **Explainable AI in Design:** AI systems are expected to provide explanations for their design suggestions, detailing trade-offs to aid human decision-making and build trust \\cite{terragni20245xq}.\n        *   **\"APIzation\" of AI-Generated Code:** The paper suggests sharing AI-generated low-level implementations as stateless, immutable APIs within the open-source community, allowing AI systems to reuse verified components rather than generating code from scratch \\cite{terragni20245xq}.\n        *   **Hybrid Test Generation:** It proposes combining LLMs with traditional automated test generators (e.g., Randoop, EvoSuite) to improve the quality and fault detection effectiveness of generated tests, leveraging feedback from compilation and execution \\cite{terragni20245xq}.\n        *   **Metamorphic Testing for Oracles:** To address the oracle problem for AI-generated code, Metamorphic Testing (MT) is highlighted as a crucial technique. MT uses Metamorphic Relations (MRs) – relations among expected outputs of related inputs – as effective oracles, especially for exposing faults in new code \\cite{terragni20245xq}.\n\n4.  **Key Technical Contributions**\n    *   **System Design/Architectural Innovation:** Proposal of an \"orchestrator of AIs\" to manage diverse, specialized AI subsystems through a unified interface, ensuring seamless integration and consistency checks across the SDLC \\cite{terragni20245xq}.\n    *   **Novel Methods/Techniques:**\n        *   Introduction of a \"prompt-friendly\" requirement language to enhance human-AI collaboration and facilitate LLM-based code generation \\cite{terragni20245xq}.\n        *   Emphasis on Explainable AI for design suggestions to foster trust and understanding in human-AI co-creation \\cite{terragni20245xq}.\n        *   Concept of \"APIzation\" for AI-generated low-level code, promoting reuse and verified components \\cite{terragni20245xq}.\n        *   Advocacy for a hybrid approach to test generation, combining LLMs with traditional automated test generators, and leveraging execution feedback \\cite{terragni20245xq}.\n        *   Identification of Metamorphic Testing as a critical solution for the oracle problem in verifying AI-generated code, highlighting the need for further research into automated MR generation \\cite{terragni20245xq}.\n\n5.  **Experimental Validation**\n    *   This paper is a vision paper and does not present new empirical validation or experimental results conducted by the authors \\cite{terragni20245xq}.\n    *   It references existing research demonstrating the effectiveness of LLMs in various software engineering tasks, such as documentation generation \\cite{16,33}, testing \\cite{43,59}, and program repair \\cite{26,55}. It also notes that initial attempts at combining LLMs with traditional test generators have shown promising results \\cite{29}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The vision acknowledges that some aspects may appear \"overly optimistic\" regarding future AI capabilities \\cite{terragni20245xq}. A significant technical challenge is the automated generation or discovery of Metamorphic Relations (MRs), which is largely understudied but crucial for effective Metamorphic Testing \\cite{terragni20245xq}. The effectiveness of prompt engineering for guiding complex code generation and decomposing high-level requirements remains a challenge.\n    *   **Scope of Applicability:** The proposed framework assumes humans will remain \"in the loop\" for understanding, reviewing, improving, validating, and maintaining AI-generated artifacts, positioning AI as a productivity enhancement tool rather than a complete replacement for software engineers \\cite{terragni20245xq}. The vision also highlights ethical considerations in maintenance, such as ensuring fairness in decision-making and addressing needs of minority groups, which are beyond purely technical scope.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** The paper provides a comprehensive vision for the future of software engineering in an AI-driven world, outlining a symbiotic human-AI partnership across the entire SDLC \\cite{terragni20245xq}. It identifies critical research challenges and proposes specific technical directions, such as AI orchestration, prompt-friendly languages, explainable AI in design, and the strategic use of Metamorphic Testing for AI-generated code verification.\n    *   **Potential Impact on Future Research:** This work serves as a roadmap for future research in software engineering, particularly in areas like human-AI collaboration, AI system integration and orchestration, novel requirement specification languages, explainable AI for design decisions, and advanced automated testing techniques (especially Metamorphic Testing) tailored for AI-generated artifacts \\cite{terragni20245xq}. It emphasizes the need for research to ensure the quality, security, and ethical implications of AI-driven software development.",
    "intriguing_abstract": "The advent of Large Language Models (LLMs) is fundamentally reshaping software engineering, promising unprecedented productivity but introducing critical challenges in code quality, security, and verification. This paper envisions a transformative future where AI systems are deeply integrated across the entire Software Development Life Cycle (SDLC), fostering a symbiotic partnership between human engineers and intelligent agents.\n\nWe propose a novel framework centered on an \"orchestrator of AIs,\" a unified interface managing specialized AI subsystems for requirements, design, implementation, testing, and maintenance, ensuring consistency and integrity. Key innovations include a \"prompt-friendly\" requirement language for seamless LLM interaction, the \"APIzation\" of AI-generated code for reuse, and the crucial role of Explainable AI in design. To address the formidable oracle problem for AI-generated code, we advocate for Metamorphic Testing, leveraging Metamorphic Relations to rigorously verify system behavior. This work serves as a vital roadmap, identifying pressing research challenges and charting a course for robust, secure, and high-quality software development in an AI-driven world, ensuring humans remain empowered in the loop.",
    "keywords": [
      "AI-driven Software Engineering",
      "Large Language Models (LLMs)",
      "Software Development Life Cycle (SDLC)",
      "AI Orchestration",
      "Human-AI Collaboration",
      "AI-generated Code Quality",
      "Metamorphic Testing",
      "Oracle Problem",
      "Prompt-Friendly Requirement Language",
      "Explainable AI (XAI)",
      "APIzation of AI-Generated Code",
      "Hybrid Test Generation",
      "Automated Metamorphic Relation Generation"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/7133df341c91fc262c1d2757d0e13a29dcbb6e3c.pdf",
    "citation_key": "terragni20245xq",
    "metadata": {
      "title": "The Future of Software Engineering in an AI-Driven World",
      "authors": [
        "Valerio Terragni",
        "Partha S. Roop",
        "Kelly Blincoe"
      ],
      "published_date": "2024",
      "abstract": "A paradigm shift is underway in Software Engineering, with AI systems such as LLMs gaining increasing importance for improving software development productivity. This trend is anticipated to persist. In the next five years, we will likely see an increasing symbiotic partnership between human developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this paper, we present our vision of the future of software development in an AI-Driven world and explore the key challenges that our research community should address to realize this vision.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/7133df341c91fc262c1d2757d0e13a29dcbb6e3c.pdf",
      "venue": "arXiv.org",
      "citationCount": 12,
      "score": 12.0,
      "summary": "Here's a focused summary of the paper for a literature review, adhering to your requirements:\n\n---\n\n### Analysis of \"The Future of Software Engineering in an AI-Driven World\" \\cite{terragni20245xq}\n\n1.  **Research Problem & Motivation**\n    *   **Problem:** The software engineering (SE) field is undergoing a paradigm shift due to the increasing integration of AI systems, particularly Large Language Models (LLMs), which are significantly impacting software development productivity \\cite{terragni20245xq}.\n    *   **Motivation:** This trend towards a symbiotic partnership between human developers and AI is anticipated to persist and grow. The SE research community must proactively address the key research challenges and opportunities arising from this integration to realize an AI-driven future for software development \\cite{terragni20245xq}. Concerns exist regarding the quality, security, and privacy of AI-generated code, necessitating focused research.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The paper positions LLMs as the latest step in a continuous pursuit of higher abstraction in programming, following machine code, assembly, high-level languages, and the widespread use of APIs and libraries \\cite{terragni20245xq}. It notes that LLMs are rapidly overshadowing traditional developer Q&A platforms like StackOverflow by directly generating code from natural language queries.\n    *   **Limitations of Previous Solutions/Current LLM Use:** While LLMs offer unprecedented productivity, current implementations face limitations regarding the quality, security, and privacy of generated code \\cite{terragni20245xq}. Traditional automated test generators often produce regression oracles, which are insufficient for verifying newly AI-generated code, highlighting a gap in current testing methodologies for this new paradigm.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a vision for an AI-driven software development framework where AI systems (e.g., LLMs) are deeply integrated across the entire Software Development Life Cycle (SDLC): Requirements Engineering, Software Design, Implementation, Testing, and Maintenance \\cite{terragni20245xq}. This framework envisions a bi-directional, conversational interaction between human software engineers and AI, with humans remaining in the loop for oversight, refinement, and validation.\n    *   **Novelty/Differentiation:**\n        *   **AI Orchestration:** A key innovation is the concept of an \"orchestrator of AIs\" – a single unified human-AI interface that manages interactions with various dedicated AI subsystems, each fine-tuned for specific development tasks (e.g., requirements analysis, code generation, testing). This orchestrator monitors artifact changes and invokes relevant AI subsystems for consistency and integrity checks \\cite{terragni20245xq}.\n        *   **Prompt-Friendly Requirement Language:** The vision includes defining a new language for requirements that is \"prompt-friendly,\" enabling seamless understanding by LLMs for subsequent code generation, potentially by unambiguously separating functional and non-functional requirements \\cite{terragni20245xq}.\n        *   **Explainable AI in Design:** AI systems are expected to provide explanations for their design suggestions, detailing trade-offs to aid human decision-making and build trust \\cite{terragni20245xq}.\n        *   **\"APIzation\" of AI-Generated Code:** The paper suggests sharing AI-generated low-level implementations as stateless, immutable APIs within the open-source community, allowing AI systems to reuse verified components rather than generating code from scratch \\cite{terragni20245xq}.\n        *   **Hybrid Test Generation:** It proposes combining LLMs with traditional automated test generators (e.g., Randoop, EvoSuite) to improve the quality and fault detection effectiveness of generated tests, leveraging feedback from compilation and execution \\cite{terragni20245xq}.\n        *   **Metamorphic Testing for Oracles:** To address the oracle problem for AI-generated code, Metamorphic Testing (MT) is highlighted as a crucial technique. MT uses Metamorphic Relations (MRs) – relations among expected outputs of related inputs – as effective oracles, especially for exposing faults in new code \\cite{terragni20245xq}.\n\n4.  **Key Technical Contributions**\n    *   **System Design/Architectural Innovation:** Proposal of an \"orchestrator of AIs\" to manage diverse, specialized AI subsystems through a unified interface, ensuring seamless integration and consistency checks across the SDLC \\cite{terragni20245xq}.\n    *   **Novel Methods/Techniques:**\n        *   Introduction of a \"prompt-friendly\" requirement language to enhance human-AI collaboration and facilitate LLM-based code generation \\cite{terragni20245xq}.\n        *   Emphasis on Explainable AI for design suggestions to foster trust and understanding in human-AI co-creation \\cite{terragni20245xq}.\n        *   Concept of \"APIzation\" for AI-generated low-level code, promoting reuse and verified components \\cite{terragni20245xq}.\n        *   Advocacy for a hybrid approach to test generation, combining LLMs with traditional automated test generators, and leveraging execution feedback \\cite{terragni20245xq}.\n        *   Identification of Metamorphic Testing as a critical solution for the oracle problem in verifying AI-generated code, highlighting the need for further research into automated MR generation \\cite{terragni20245xq}.\n\n5.  **Experimental Validation**\n    *   This paper is a vision paper and does not present new empirical validation or experimental results conducted by the authors \\cite{terragni20245xq}.\n    *   It references existing research demonstrating the effectiveness of LLMs in various software engineering tasks, such as documentation generation \\cite{16,33}, testing \\cite{43,59}, and program repair \\cite{26,55}. It also notes that initial attempts at combining LLMs with traditional test generators have shown promising results \\cite{29}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The vision acknowledges that some aspects may appear \"overly optimistic\" regarding future AI capabilities \\cite{terragni20245xq}. A significant technical challenge is the automated generation or discovery of Metamorphic Relations (MRs), which is largely understudied but crucial for effective Metamorphic Testing \\cite{terragni20245xq}. The effectiveness of prompt engineering for guiding complex code generation and decomposing high-level requirements remains a challenge.\n    *   **Scope of Applicability:** The proposed framework assumes humans will remain \"in the loop\" for understanding, reviewing, improving, validating, and maintaining AI-generated artifacts, positioning AI as a productivity enhancement tool rather than a complete replacement for software engineers \\cite{terragni20245xq}. The vision also highlights ethical considerations in maintenance, such as ensuring fairness in decision-making and addressing needs of minority groups, which are beyond purely technical scope.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** The paper provides a comprehensive vision for the future of software engineering in an AI-driven world, outlining a symbiotic human-AI partnership across the entire SDLC \\cite{terragni20245xq}. It identifies critical research challenges and proposes specific technical directions, such as AI orchestration, prompt-friendly languages, explainable AI in design, and the strategic use of Metamorphic Testing for AI-generated code verification.\n    *   **Potential Impact on Future Research:** This work serves as a roadmap for future research in software engineering, particularly in areas like human-AI collaboration, AI system integration and orchestration, novel requirement specification languages, explainable AI for design decisions, and advanced automated testing techniques (especially Metamorphic Testing) tailored for AI-generated artifacts \\cite{terragni20245xq}. It emphasizes the need for research to ensure the quality, security, and ethical implications of AI-driven software development.",
      "keywords": [
        "AI-driven Software Engineering",
        "Large Language Models (LLMs)",
        "Software Development Life Cycle (SDLC)",
        "AI Orchestration",
        "Human-AI Collaboration",
        "AI-generated Code Quality",
        "Metamorphic Testing",
        "Oracle Problem",
        "Prompt-Friendly Requirement Language",
        "Explainable AI (XAI)",
        "APIzation of AI-Generated Code",
        "Hybrid Test Generation",
        "Automated Metamorphic Relation Generation"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we present our vision of the future of software development in an ai-driven world and explore the key challenges that our research community should address to realize this vision.\"\n*   keywords like \"vision,\" \"future,\" and the call for what the community \"should address\" strongly align with the criteria for a **position** paper.\n*   the introduction sets the historical context for this future vision.\n*   the venue (international workshop on software engineering in 2030) and length (6 pages) also suggest a forward-looking, possibly speculative or visionary, discussion often found in position papers or short communications. while it is a \"short\" paper, \"position\" describes the *nature* of its content more accurately than just its length.\n\ntherefore, the most appropriate classification is **position**."
    },
    "file_name": "7133df341c91fc262c1d2757d0e13a29dcbb6e3c.pdf"
  },
  {
    "success": true,
    "doc_id": "bc490d0508616687f1785ec7f545b121",
    "summary": "AI driven Continuous Integration and Continuous Deployment is a new way of managing and continually updating a software project. This process, powered by Artificial Intelligence, automates the entire software delivery and deployment process - from code submission to monitoring and bug fixing. It eliminates manual errors and allows for multiple versions to be tested in parallel, saving time and effort. By increasing agility, it allows organizations to launch new features to production faster than ever. Continuous Integration and Continuous Deployment leverages artificial intelligence in implementation and execution. It automates the process of integration, testing, packaging and deployment. Furthermore, AI is used to detect and fix bugs which can prevent delays and costly production bugs. AI driven Continuous Integration and Continuous Deployment has become an increasingly popular development strategy. It helps reduce the overall cost and accelerate the software's production cycles, making it easier for developers to quickly get their features and services in the hands of the market.",
    "intriguing_abstract": "AI driven Continuous Integration and Continuous Deployment is a new way of managing and continually updating a software project. This process, powered by Artificial Intelligence, automates the entire software delivery and deployment process - from code submission to monitoring and bug fixing. It eliminates manual errors and allows for multiple versions to be tested in parallel, saving time and effort. By increasing agility, it allows organizations to launch new features to production faster than ever. Continuous Integration and Continuous Deployment leverages artificial intelligence in implementation and execution. It automates the process of integration, testing, packaging and deployment. Furthermore, AI is used to detect and fix bugs which can prevent delays and costly production bugs. AI driven Continuous Integration and Continuous Deployment has become an increasingly popular development strategy. It helps reduce the overall cost and accelerate the software's production cycles, making it easier for developers to quickly get their features and services in the hands of the market.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/c4817cb447db4254d7829215fb85207585eb9064.pdf",
    "citation_key": "mohammed2024s4f",
    "metadata": {
      "title": "AI-Driven Continuous Integration and Continuous Deployment in Software Engineering",
      "authors": [
        "Abdul Sajid Mohammed",
        "Venkata Ramana Saddi",
        "Santhosh Kumar Gopal",
        "S. Dhanasekaran",
        "Mahaveer Singh Naruka"
      ],
      "published_date": "2024",
      "abstract": "AI driven Continuous Integration and Continuous Deployment is a new way of managing and continually updating a software project. This process, powered by Artificial Intelligence, automates the entire software delivery and deployment process - from code submission to monitoring and bug fixing. It eliminates manual errors and allows for multiple versions to be tested in parallel, saving time and effort. By increasing agility, it allows organizations to launch new features to production faster than ever. Continuous Integration and Continuous Deployment leverages artificial intelligence in implementation and execution. It automates the process of integration, testing, packaging and deployment. Furthermore, AI is used to detect and fix bugs which can prevent delays and costly production bugs. AI driven Continuous Integration and Continuous Deployment has become an increasingly popular development strategy. It helps reduce the overall cost and accelerate the software's production cycles, making it easier for developers to quickly get their features and services in the hands of the market.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/c4817cb447db4254d7829215fb85207585eb9064.pdf",
      "venue": "International Conference on Database Theory",
      "citationCount": 12,
      "score": 12.0,
      "summary": "AI driven Continuous Integration and Continuous Deployment is a new way of managing and continually updating a software project. This process, powered by Artificial Intelligence, automates the entire software delivery and deployment process - from code submission to monitoring and bug fixing. It eliminates manual errors and allows for multiple versions to be tested in parallel, saving time and effort. By increasing agility, it allows organizations to launch new features to production faster than ever. Continuous Integration and Continuous Deployment leverages artificial intelligence in implementation and execution. It automates the process of integration, testing, packaging and deployment. Furthermore, AI is used to detect and fix bugs which can prevent delays and costly production bugs. AI driven Continuous Integration and Continuous Deployment has become an increasingly popular development strategy. It helps reduce the overall cost and accelerate the software's production cycles, making it easier for developers to quickly get their features and services in the hands of the market.",
      "keywords": []
    },
    "file_name": "c4817cb447db4254d7829215fb85207585eb9064.pdf"
  },
  {
    "success": true,
    "doc_id": "cfa4fbfbaaba39050d3939b2b9892c77",
    "summary": "The rise of generative AI has led many companies to hire freelanc-ers to harness its potential. However, this technology presents unique challenges to developers who have not previously engaged with it. Freelancers may find these challenges daunting due to the absence of organizational support and their reliance on positive client feedback. In a study involving 52 freelance developers, we identified multiple challenges associated with developing solutions based on generative AI. Freelancers often struggle with as-pects they perceive as unique to generative AI such as unpredict-ability of its output, the occurrence of hallucinations, and the in-consistent effort required due to trial-and-error prompting cycles. Further, the limitations of specific frameworks, such as token lim-its and long response times, add to the complexity. Hype-related issues, such as inflated client expectations and a rapidly evolving technological ecosystem, further exacerbate the difficulties. To address these issues, we propose Software Engineering for Generative AI (SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the software engineering community can provide effective guidance. This support is essential for freelancers working with generative AI and other emerging technologies.",
    "intriguing_abstract": "The rise of generative AI has led many companies to hire freelanc-ers to harness its potential. However, this technology presents unique challenges to developers who have not previously engaged with it. Freelancers may find these challenges daunting due to the absence of organizational support and their reliance on positive client feedback. In a study involving 52 freelance developers, we identified multiple challenges associated with developing solutions based on generative AI. Freelancers often struggle with as-pects they perceive as unique to generative AI such as unpredict-ability of its output, the occurrence of hallucinations, and the in-consistent effort required due to trial-and-error prompting cycles. Further, the limitations of specific frameworks, such as token lim-its and long response times, add to the complexity. Hype-related issues, such as inflated client expectations and a rapidly evolving technological ecosystem, further exacerbate the difficulties. To address these issues, we propose Software Engineering for Generative AI (SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the software engineering community can provide effective guidance. This support is essential for freelancers working with generative AI and other emerging technologies.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/dccf36005393f6a238a080c86e881742af213729.pdf",
    "citation_key": "dolata20249im",
    "metadata": {
      "title": "Development in Times of Hype: How Freelancers Explore Generative AI?",
      "authors": [
        "Mateusz Dolata",
        "Norbert Lange",
        "Gerhard Schwabe"
      ],
      "published_date": "2024",
      "abstract": "The rise of generative AI has led many companies to hire freelanc-ers to harness its potential. However, this technology presents unique challenges to developers who have not previously engaged with it. Freelancers may find these challenges daunting due to the absence of organizational support and their reliance on positive client feedback. In a study involving 52 freelance developers, we identified multiple challenges associated with developing solutions based on generative AI. Freelancers often struggle with as-pects they perceive as unique to generative AI such as unpredict-ability of its output, the occurrence of hallucinations, and the in-consistent effort required due to trial-and-error prompting cycles. Further, the limitations of specific frameworks, such as token lim-its and long response times, add to the complexity. Hype-related issues, such as inflated client expectations and a rapidly evolving technological ecosystem, further exacerbate the difficulties. To address these issues, we propose Software Engineering for Generative AI (SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the software engineering community can provide effective guidance. This support is essential for freelancers working with generative AI and other emerging technologies.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/dccf36005393f6a238a080c86e881742af213729.pdf",
      "venue": "International Conference on Software Engineering",
      "citationCount": 12,
      "score": 12.0,
      "summary": "The rise of generative AI has led many companies to hire freelanc-ers to harness its potential. However, this technology presents unique challenges to developers who have not previously engaged with it. Freelancers may find these challenges daunting due to the absence of organizational support and their reliance on positive client feedback. In a study involving 52 freelance developers, we identified multiple challenges associated with developing solutions based on generative AI. Freelancers often struggle with as-pects they perceive as unique to generative AI such as unpredict-ability of its output, the occurrence of hallucinations, and the in-consistent effort required due to trial-and-error prompting cycles. Further, the limitations of specific frameworks, such as token lim-its and long response times, add to the complexity. Hype-related issues, such as inflated client expectations and a rapidly evolving technological ecosystem, further exacerbate the difficulties. To address these issues, we propose Software Engineering for Generative AI (SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the software engineering community can provide effective guidance. This support is essential for freelancers working with generative AI and other emerging technologies.",
      "keywords": []
    },
    "file_name": "dccf36005393f6a238a080c86e881742af213729.pdf"
  },
  {
    "success": true,
    "doc_id": "8a79ee7d47be99da13df1e34b371a2f8",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the technical problem that while AI-supported programming tools like Copilot excel at basic code completion and solving programming challenges, they often fall short in supporting higher-level software engineering tasks. These tasks include adhering to language idioms, avoiding code smells, and eventually proposing rational software designs \\cite{pudari2023oep}.\n    *   This problem is important and challenging because software development involves more than just writing functional code; it requires producing high-quality, maintainable, and idiomatic code. The rules for identifying and applying best practices are often complex and harder to specify than basic syntax or compilation errors, making it difficult for AI to learn and apply them effectively \\cite{pudari2023oep}. Developers need to understand the limitations of these tools to know when human intervention is critical.\n\n*   **Related Work & Positioning**\n    *   This work relates to existing approaches like GitHub Copilot/OpenAI Codex and DeepMind's AlphaCode, which leverage large language models (LLMs) to achieve impressive performance in code generation and programming contest problems \\cite{pudari2023oep}.\n    *   Limitations of previous solutions include:\n        *   Training data issues: LLMs are trained on existing code, which can lead to suggestions containing security vulnerabilities, license compliance issues, or simple coding mistakes present in the public training data \\cite{pudari2023oep}.\n        *   Lack of higher-level understanding: Existing tools struggle with \"problems that are harder to fix because straightforward corrections may not exist, and rules for finding problems are more challenging to specify than those in smell detectors or linters\" \\cite{pudari2023oep}, such as understanding and applying language idioms or avoiding code smells.\n        *   Focus on code completion: Most research effort is concentrated on code completion, with less attention paid to evaluating the quality of suggestions against software engineering best practices \\cite{pudari2023oep}.\n        *   Inability to customize: Current tools like Copilot do not offer features to customize suggestions based on project-specific coding styles or preferences \\cite{pudari2023oep}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is an *exploratory empirical study* to evaluate the current boundaries of AI-supported code completion tools, using GitHub Copilot as a representative \\cite{pudari2023oep}.\n    *   The approach involves:\n        *   **Sampling**: Selecting 25 popular Pythonic idioms and 25 JavaScript best practices (from the AirBNB style guide, focusing on design-level rather than purely stylistic rules) \\cite{pudari2023oep}.\n        *   **Input Generation**: Providing minimal, unbiased human input (a natural language comment, function name, and parameters) to Copilot to trigger code suggestions without forcing a specific outcome \\cite{pudari2023oep}.\n        *   **Evaluation Methodology**: Comparing Copilot's *first* code suggestion against the desired idiomatic approach or best practice. The study also notes if the desired approach appears within Copilot's top 10 viewable suggestions \\cite{pudari2023oep}.\n    *   The approach is novel in its systematic empirical evaluation of a prominent AI code completion tool against higher-level software quality attributes (idioms, code smells) and its conceptual framing using a *taxonomy of software abstraction hierarchies* (from basic functionality to architectural design) to delineate current AI capabilities and future challenges \\cite{pudari2023oep}.\n\n*   **Key Technical Contributions**\n    *   **Empirical Evaluation Framework**: A structured methodology for assessing AI code completion tools' adherence to language idioms and coding best practices, using controlled input and a clear pass/fail criterion based on suggestion ranking \\cite{pudari2023oep}.\n    *   **Insights into Copilot's Limitations**: Provides concrete evidence that Copilot largely fails to suggest idiomatic code (Python) or adhere to best practices (JavaScript) as its primary suggestion, even for frequently occurring patterns \\cite{pudari2023oep}.\n    *   **Conceptual Taxonomy**: Introduces a taxonomy of software abstraction hierarchies to categorize the capabilities of AI-supported tools, from basic programming functionality to software architecture analysis and design, providing a roadmap for future AI development \\cite{pudari2023oep}.\n    *   **Identification of Future Challenges**: Highlights critical areas for improvement, such as the need for AI to prioritize optimal/idiomatic code over merely frequent patterns, adapt to project-specific coding styles, and advance towards higher levels of software design abstraction \\cite{pudari2023oep}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   **Pythonic Idioms**: Copilot was tested against 25 popular Pythonic idioms.\n        *   **JavaScript Code Smells/Best Practices**: Copilot was tested against 25 best practices from the AirBNB JavaScript coding style guide, focusing on design-level practices.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Pythonic Idioms**: Copilot suggested the idiomatic approach as the *first suggestion* in only 2 out of 25 cases (8%). The idiomatic way appeared in the *top 10 suggestions* for an additional 8 cases. Copilot *failed* (idiom not in top 10) for 15 out of 25 idioms (60%) \\cite{pudari2023oep}. For example, for list comprehension, Copilot suggested a `for` loop instead of the more concise and often faster Pythonic list comprehension (Figure 1) \\cite{pudari2023oep}.\n        *   **JavaScript Code Smells**: Copilot suggested the best practice as the *first suggestion* in only 3 out of 25 cases (12%). The best practice appeared in the *top 10 suggestions* for an additional 5 cases. Copilot *failed* (best practice not in top 10) for 17 out of 25 scenarios (68%) \\cite{pudari2023oep}.\n        *   **Overall**: The results indicate that Copilot did not suggest the optimal/idiomatic/best practice as its first suggestion in the majority of cases (92% for Python idioms, 88% for JavaScript best practices) \\cite{pudari2023oep}. The study suggests Copilot's ranking is heavily influenced by the frequency of approaches in its training data rather than their optimality or idiomaticity \\cite{pudari2023oep}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: Copilot is a closed-source model, preventing direct investigation into the underlying reasons for its suggestion behavior (e.g., specific training data biases or ranking algorithms) \\cite{pudari2023oep}. The evaluation assumes users prioritize productivity and will primarily consider the first suggestion, not scrolling through all ten \\cite{pudari2023oep}. Copilot's inability to override or update input restricted certain testing scenarios \\cite{pudari2023oep}.\n    *   **Scope of Applicability**: The study focuses on Copilot as a representative tool and specifically evaluates Python idioms and JavaScript best practices. It did not test project-specific coding styles due to Copilot's lack of customization features \\cite{pudari2023oep}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a rigorous empirical assessment of current AI code completion tools beyond basic functionality. It shifts the focus from merely generating functional code to evaluating the *quality* and *adherence to best practices* of AI-generated code \\cite{pudari2023oep}.\n    *   **Potential Impact**:\n        *   **Informs Developers**: Provides crucial insights for developers on when to trust AI suggestions and when to apply critical human oversight, especially for higher-level software quality attributes \\cite{pudari2023oep}.\n        *   **Guides Future Research**: Establishes a clear research agenda for developing next-generation AI-supported software engineering tools. This includes the need for AI models that can:\n            *   Understand and prioritize idiomatic and best-practice code over mere frequency.\n            *   Adapt to project-specific coding styles and design patterns.\n            *   Move up the proposed software abstraction hierarchy to assist with architectural design \\cite{pudari2023oep}.\n            *   Learn and apply complex, non-trivial rules for identifying and correcting code quality issues \\cite{pudari2023oep}.",
    "intriguing_abstract": "While large language models (LLMs) like GitHub Copilot have revolutionized code generation, their ability to support higher-level software engineering tasks—such as adhering to language idioms or avoiding code smells—remains largely unexplored. This paper presents a rigorous *exploratory empirical study* evaluating Copilot's performance against 25 popular Pythonic idioms and 25 JavaScript best practices. Our novel methodology uses minimal, unbiased input to assess the quality of Copilot's *first* code suggestions, revealing a critical limitation: Copilot failed to suggest the idiomatic or best-practice approach in the vast majority of cases (92% for Python, 88% for JavaScript).\n\nThese findings highlight that current AI tools prioritize code frequency over optimality, posing significant challenges for generating high-quality, maintainable software. We introduce a *taxonomy of software abstraction hierarchies* to frame these limitations and chart a path forward. This work provides crucial insights for developers on when to critically evaluate AI-generated code and establishes a vital research agenda for developing next-generation AI-supported tools capable of understanding and applying complex software design principles, ultimately advancing the state-of-the-art in *code quality* and *software engineering automation*.",
    "keywords": [
      "AI code completion tools",
      "higher-level software engineering tasks",
      "language idioms",
      "code smells",
      "GitHub Copilot",
      "Large Language Models (LLMs)",
      "exploratory empirical study",
      "empirical evaluation framework",
      "Pythonic idioms",
      "JavaScript best practices",
      "software abstraction hierarchies taxonomy",
      "Copilot's limitations",
      "quality of AI-generated code",
      "frequency bias in suggestions",
      "next-generation AI software engineering tools"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/35afb57a646592c3a471a4f010d00e1b13dd3c43.pdf",
    "citation_key": "pudari2023oep",
    "metadata": {
      "title": "From Copilot to Pilot: Towards AI Supported Software Development",
      "authors": [
        "Rohith Pudari",
        "Neil A. Ernst"
      ],
      "published_date": "2023",
      "abstract": "AI-supported programming has arrived, as shown by the introduction and successes of large language models for code, such as Copilot/Codex (Github/OpenAI) and AlphaCode (DeepMind). Above human average performance on programming challenges is now possible. However, software engineering is much more than solving programming contests. Moving beyond code completion to AI-supported software engineering will require an AI system that can, among other things, understand how to avoid code smells, to follow language idioms, and eventually (maybe!) propose rational software designs. In this study, we explore the current limitations of AI-supported code completion tools like Copilot and offer a simple taxonomy for understanding the classification of AI-supported code completion tools in this space. We first perform an exploratory study on Copilot's code suggestions for language idioms and code smells. Copilot does not follow language idioms and avoid code smells in most of our test scenarios. We then conduct additional investigation to determine the current boundaries of AI-supported code completion tools like Copilot by introducing a taxonomy of software abstraction hierarchies where 'basic programming functionality' such as code compilation and syntax checking is at the least abstract level, software architecture analysis and design are at the most abstract level. We conclude by providing a discussion on challenges for future development of AI-supported code completion tools to reach the design level of abstraction in our taxonomy.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/35afb57a646592c3a471a4f010d00e1b13dd3c43.pdf",
      "venue": "arXiv.org",
      "citationCount": 23,
      "score": 11.5,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the technical problem that while AI-supported programming tools like Copilot excel at basic code completion and solving programming challenges, they often fall short in supporting higher-level software engineering tasks. These tasks include adhering to language idioms, avoiding code smells, and eventually proposing rational software designs \\cite{pudari2023oep}.\n    *   This problem is important and challenging because software development involves more than just writing functional code; it requires producing high-quality, maintainable, and idiomatic code. The rules for identifying and applying best practices are often complex and harder to specify than basic syntax or compilation errors, making it difficult for AI to learn and apply them effectively \\cite{pudari2023oep}. Developers need to understand the limitations of these tools to know when human intervention is critical.\n\n*   **Related Work & Positioning**\n    *   This work relates to existing approaches like GitHub Copilot/OpenAI Codex and DeepMind's AlphaCode, which leverage large language models (LLMs) to achieve impressive performance in code generation and programming contest problems \\cite{pudari2023oep}.\n    *   Limitations of previous solutions include:\n        *   Training data issues: LLMs are trained on existing code, which can lead to suggestions containing security vulnerabilities, license compliance issues, or simple coding mistakes present in the public training data \\cite{pudari2023oep}.\n        *   Lack of higher-level understanding: Existing tools struggle with \"problems that are harder to fix because straightforward corrections may not exist, and rules for finding problems are more challenging to specify than those in smell detectors or linters\" \\cite{pudari2023oep}, such as understanding and applying language idioms or avoiding code smells.\n        *   Focus on code completion: Most research effort is concentrated on code completion, with less attention paid to evaluating the quality of suggestions against software engineering best practices \\cite{pudari2023oep}.\n        *   Inability to customize: Current tools like Copilot do not offer features to customize suggestions based on project-specific coding styles or preferences \\cite{pudari2023oep}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is an *exploratory empirical study* to evaluate the current boundaries of AI-supported code completion tools, using GitHub Copilot as a representative \\cite{pudari2023oep}.\n    *   The approach involves:\n        *   **Sampling**: Selecting 25 popular Pythonic idioms and 25 JavaScript best practices (from the AirBNB style guide, focusing on design-level rather than purely stylistic rules) \\cite{pudari2023oep}.\n        *   **Input Generation**: Providing minimal, unbiased human input (a natural language comment, function name, and parameters) to Copilot to trigger code suggestions without forcing a specific outcome \\cite{pudari2023oep}.\n        *   **Evaluation Methodology**: Comparing Copilot's *first* code suggestion against the desired idiomatic approach or best practice. The study also notes if the desired approach appears within Copilot's top 10 viewable suggestions \\cite{pudari2023oep}.\n    *   The approach is novel in its systematic empirical evaluation of a prominent AI code completion tool against higher-level software quality attributes (idioms, code smells) and its conceptual framing using a *taxonomy of software abstraction hierarchies* (from basic functionality to architectural design) to delineate current AI capabilities and future challenges \\cite{pudari2023oep}.\n\n*   **Key Technical Contributions**\n    *   **Empirical Evaluation Framework**: A structured methodology for assessing AI code completion tools' adherence to language idioms and coding best practices, using controlled input and a clear pass/fail criterion based on suggestion ranking \\cite{pudari2023oep}.\n    *   **Insights into Copilot's Limitations**: Provides concrete evidence that Copilot largely fails to suggest idiomatic code (Python) or adhere to best practices (JavaScript) as its primary suggestion, even for frequently occurring patterns \\cite{pudari2023oep}.\n    *   **Conceptual Taxonomy**: Introduces a taxonomy of software abstraction hierarchies to categorize the capabilities of AI-supported tools, from basic programming functionality to software architecture analysis and design, providing a roadmap for future AI development \\cite{pudari2023oep}.\n    *   **Identification of Future Challenges**: Highlights critical areas for improvement, such as the need for AI to prioritize optimal/idiomatic code over merely frequent patterns, adapt to project-specific coding styles, and advance towards higher levels of software design abstraction \\cite{pudari2023oep}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   **Pythonic Idioms**: Copilot was tested against 25 popular Pythonic idioms.\n        *   **JavaScript Code Smells/Best Practices**: Copilot was tested against 25 best practices from the AirBNB JavaScript coding style guide, focusing on design-level practices.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Pythonic Idioms**: Copilot suggested the idiomatic approach as the *first suggestion* in only 2 out of 25 cases (8%). The idiomatic way appeared in the *top 10 suggestions* for an additional 8 cases. Copilot *failed* (idiom not in top 10) for 15 out of 25 idioms (60%) \\cite{pudari2023oep}. For example, for list comprehension, Copilot suggested a `for` loop instead of the more concise and often faster Pythonic list comprehension (Figure 1) \\cite{pudari2023oep}.\n        *   **JavaScript Code Smells**: Copilot suggested the best practice as the *first suggestion* in only 3 out of 25 cases (12%). The best practice appeared in the *top 10 suggestions* for an additional 5 cases. Copilot *failed* (best practice not in top 10) for 17 out of 25 scenarios (68%) \\cite{pudari2023oep}.\n        *   **Overall**: The results indicate that Copilot did not suggest the optimal/idiomatic/best practice as its first suggestion in the majority of cases (92% for Python idioms, 88% for JavaScript best practices) \\cite{pudari2023oep}. The study suggests Copilot's ranking is heavily influenced by the frequency of approaches in its training data rather than their optimality or idiomaticity \\cite{pudari2023oep}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: Copilot is a closed-source model, preventing direct investigation into the underlying reasons for its suggestion behavior (e.g., specific training data biases or ranking algorithms) \\cite{pudari2023oep}. The evaluation assumes users prioritize productivity and will primarily consider the first suggestion, not scrolling through all ten \\cite{pudari2023oep}. Copilot's inability to override or update input restricted certain testing scenarios \\cite{pudari2023oep}.\n    *   **Scope of Applicability**: The study focuses on Copilot as a representative tool and specifically evaluates Python idioms and JavaScript best practices. It did not test project-specific coding styles due to Copilot's lack of customization features \\cite{pudari2023oep}.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a rigorous empirical assessment of current AI code completion tools beyond basic functionality. It shifts the focus from merely generating functional code to evaluating the *quality* and *adherence to best practices* of AI-generated code \\cite{pudari2023oep}.\n    *   **Potential Impact**:\n        *   **Informs Developers**: Provides crucial insights for developers on when to trust AI suggestions and when to apply critical human oversight, especially for higher-level software quality attributes \\cite{pudari2023oep}.\n        *   **Guides Future Research**: Establishes a clear research agenda for developing next-generation AI-supported software engineering tools. This includes the need for AI models that can:\n            *   Understand and prioritize idiomatic and best-practice code over mere frequency.\n            *   Adapt to project-specific coding styles and design patterns.\n            *   Move up the proposed software abstraction hierarchy to assist with architectural design \\cite{pudari2023oep}.\n            *   Learn and apply complex, non-trivial rules for identifying and correcting code quality issues \\cite{pudari2023oep}.",
      "keywords": [
        "AI code completion tools",
        "higher-level software engineering tasks",
        "language idioms",
        "code smells",
        "GitHub Copilot",
        "Large Language Models (LLMs)",
        "exploratory empirical study",
        "empirical evaluation framework",
        "Pythonic idioms",
        "JavaScript best practices",
        "software abstraction hierarchies taxonomy",
        "Copilot's limitations",
        "quality of AI-generated code",
        "frequency bias in suggestions",
        "next-generation AI software engineering tools"
      ],
      "paper_type": "based on the abstract and introduction, this paper is an **empirical** study.\n\nhere's why:\n\n*   **\"in this study, we explore the current limitations...\"**: directly indicates a study.\n*   **\"we first perform an exploratory study on copilot’s code suggestions for language idioms and code smells.\"**: explicitly states an \"exploratory study\" and focuses on evaluating a specific tool's (copilot's) performance.\n*   **\"copilot does not follow language idioms and avoid code smells in most of our test scenarios.\"**: presents a clear finding/result from the study, based on \"test scenarios.\"\n*   **\"we then conduct additional investigation to determine the current boundaries...\"**: reinforces the investigative, data-driven nature.\n*   the paper is focused on observing and analyzing the behavior of an existing system (copilot) under specific conditions, which is characteristic of empirical research."
    },
    "file_name": "35afb57a646592c3a471a4f010d00e1b13dd3c43.pdf"
  },
  {
    "success": true,
    "doc_id": "d8a4f010eed7e773824ebc528b371c4a",
    "summary": "Data engineering is ever-evolving and is now increasingly more complex and large-scale in modern applications of software. The paper presents an all-encompassing study about the evolution, core components, technological development, and emerging trends in data engineering largely associated with developing software. Thorough research would also help to know how AI might be integrated into cloud-native architectures, processing frameworks and in data engineering, which should take all real-time data. This discussion summarizes the challenges implicated, including scale and security, outlines strategies for workflow optimization, and elaborates on some findings using data tables and practical code snippets. This brings actionable insights for both practitioners and researchers.",
    "intriguing_abstract": "Data engineering is ever-evolving and is now increasingly more complex and large-scale in modern applications of software. The paper presents an all-encompassing study about the evolution, core components, technological development, and emerging trends in data engineering largely associated with developing software. Thorough research would also help to know how AI might be integrated into cloud-native architectures, processing frameworks and in data engineering, which should take all real-time data. This discussion summarizes the challenges implicated, including scale and security, outlines strategies for workflow optimization, and elaborates on some findings using data tables and practical code snippets. This brings actionable insights for both practitioners and researchers.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b41c6f421de3127d5d419e5b8439c02ab12e6253.pdf",
    "citation_key": "bussa2024kee",
    "metadata": {
      "title": "Evolution of Data Engineering in Modern Software Development",
      "authors": [
        "Santhosh Bussa"
      ],
      "published_date": "2024",
      "abstract": "Data engineering is ever-evolving and is now increasingly more complex and large-scale in modern applications of software. The paper presents an all-encompassing study about the evolution, core components, technological development, and emerging trends in data engineering largely associated with developing software. Thorough research would also help to know how AI might be integrated into cloud-native architectures, processing frameworks and in data engineering, which should take all real-time data. This discussion summarizes the challenges implicated, including scale and security, outlines strategies for workflow optimization, and elaborates on some findings using data tables and practical code snippets. This brings actionable insights for both practitioners and researchers.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b41c6f421de3127d5d419e5b8439c02ab12e6253.pdf",
      "venue": "Journal of Sustainable Solutions",
      "citationCount": 11,
      "score": 11.0,
      "summary": "Data engineering is ever-evolving and is now increasingly more complex and large-scale in modern applications of software. The paper presents an all-encompassing study about the evolution, core components, technological development, and emerging trends in data engineering largely associated with developing software. Thorough research would also help to know how AI might be integrated into cloud-native architectures, processing frameworks and in data engineering, which should take all real-time data. This discussion summarizes the challenges implicated, including scale and security, outlines strategies for workflow optimization, and elaborates on some findings using data tables and practical code snippets. This brings actionable insights for both practitioners and researchers.",
      "keywords": []
    },
    "file_name": "b41c6f421de3127d5d419e5b8439c02ab12e6253.pdf"
  },
  {
    "success": true,
    "doc_id": "d85b4e1eebc77988e9d3f9f22e1130f0",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper investigates the real-world adoption, impact, and developer interventions concerning generative AI, specifically GitHub's Copilot for Pull Requests (PRs), in the software development process.\n    *   **Importance & Challenge:** As generative AI rapidly integrates into software development, understanding its practical effects on code review efficiency, PR merge likelihood, and how developers interact with and adapt AI-generated content is crucial. This knowledge is vital for guiding the evolution of AI tools in SE and ensuring software quality in human-AI collaborative environments.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Prior research on Large Language Models (LLMs) in Software Engineering (SE) primarily focuses on developing and evaluating AI models for tasks like code generation, completion, and summarization (e.g., PRSummarizer, PRHAN, AUTOPRTITLE for PR summarization).\n    *   **Limitations of Previous Solutions:** Existing work largely concentrates on the *development and evaluation* of LLMs in controlled or theoretical settings. It lacks empirical investigation into the *real-world applicability, adoption, and practical impact* of these models within actual software development workflows, particularly regarding human-AI collaboration and developer interventions on AI-generated content \\cite{xiao20246s5}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper employs a mixed-methods empirical study, combining quantitative analysis of large-scale PR data with qualitative analysis of developer edits. It analyzes the adoption and impact of an existing generative AI tool (GitHub Copilot for PRs, powered by GPT-4) rather than proposing a new AI model.\n    *   **Novelty:** The approach is novel due to its large-scale, real-world empirical investigation of an early-stage generative AI tool in active open-source software (OSS) development. It uniquely focuses on human-AI collaboration by meticulously analyzing how developers adapt and complement AI-generated PR descriptions, providing insights into the practical dynamics of AI integration.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Methods/Techniques:**\n        *   A robust data collection methodology to identify and filter 18,256 Copilot-generated PRs and 54,188 non-Copilot PRs from 146 GitHub projects, including strategies for handling GitHub API limitations, obsolete uses, and bot-submitted PRs.\n        *   Application of `git diff` (Myers algorithm) to precisely trace and categorize developer modifications to AI-generated content across 1,437 revisions.\n        *   A method for identifying and segregating PR templates to accurately analyze developer-added supplementary information.\n    *   **Theoretical Insights/Analysis:** Provides empirical insights into the patterns of human-AI collaboration, identifying 13 categories of supplementary information developers add and 7 types of editorial actions they perform on AI-generated content.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:**\n        *   **Quantitative Analysis (RQ1 & RQ2):** Examined 18,256 Copilot-generated PRs and 54,188 non-Copilot PRs to assess adoption rates, review time, and merge likelihood.\n        *   **Qualitative Analysis (RQ3):** Analyzed 1,437 revisions from 311 PRs to understand how developers adapt AI-generated content.\n    *   **Key Performance Metrics & Results:**\n        *   **Adoption:** Observed a \"burgeoning adoption\" of Copilot for PRs, with `copilot:summary` being the most popular marker tag (13,231 instances).\n        *   **Review Time:** Copilot-assisted PRs showed a \"substantial reduction of review time by an average of 19.3 hours.\"\n        *   **Merge Likelihood:** PRs assisted by Copilot for PRs had a \"1.57 times higher likelihood of being merged\" (84% acceptance rate vs. 71% for non-Copilot PRs).\n        *   **Developer Interventions:** Identified 13 categories of supplementary information (e.g., integrating templates (22.8%), adding relevant links (22.7%)) and 7 editorial actions (e.g., partially removing content (22.9%)).\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The study is exploratory, focusing on early adoption during a limited release phase of Copilot for PRs. The comparison is quasi-experimental, controlling for temporal variations but not a true randomized controlled trial. Data collection relies on specific phrases and bot identification, which might have minor limitations.\n    *   **Scope of Applicability:** Findings are primarily applicable to open-source GitHub projects using Copilot for PRs. Generalizability to closed-source, enterprise environments, or future, more mature versions of the tool may require further investigation.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:** This paper provides the first large-scale empirical evidence of the real-world impact and adoption of generative AI in software development, moving beyond theoretical evaluations. It quantifies tangible benefits like reduced review time and increased merge likelihood, offering strong justification for AI integration.\n    *   **Potential Impact on Future Research:** The findings inform the design of more effective human-AI interfaces and generative AI tools for SE by highlighting where AI excels and where human input remains critical. It encourages further research into human-AI interaction, developer trust, and the evolving landscape of software development practices with increasing AI integration.",
    "intriguing_abstract": "The rapid integration of generative AI into software engineering demands a deep understanding of its real-world impact. While Large Language Models (LLMs) show immense promise, empirical evidence of their practical adoption and effects on developer workflows is scarce. This paper presents the first large-scale, mixed-methods empirical study investigating GitHub Copilot for Pull Requests (PRs), powered by GPT-4, within active open-source software (OSS) development.\n\nAnalyzing 18,256 Copilot-generated PRs and 54,188 non-Copilot PRs, we reveal a burgeoning adoption and significant benefits: Copilot-assisted PRs reduce code review time by an average of 19.3 hours and boast a 1.57 times higher merge likelihood. Our novel qualitative analysis, using `git diff` on 1,437 revisions, meticulously uncovers how developers engage in human-AI collaboration, identifying 13 categories of supplementary information added and 7 types of editorial actions performed on AI-generated content. These insights illuminate critical areas where human expertise complements AI, offering crucial guidance for designing more effective generative AI tools and interfaces that enhance software quality and developer productivity.",
    "keywords": [
      "Generative AI",
      "GitHub Copilot for Pull Requests",
      "human-AI collaboration",
      "software development process",
      "empirical study",
      "real-world adoption",
      "developer interventions",
      "code review efficiency",
      "PR merge likelihood",
      "mixed-methods research",
      "`git diff` analysis",
      "reduced review time",
      "increased merge likelihood",
      "supplementary information categories",
      "editorial actions"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/e9a4ad74859cda6ad9d50cdd53722d3ce76d0ae1.pdf",
    "citation_key": "xiao20246s5",
    "metadata": {
      "title": "Generative AI for Pull Request Descriptions: Adoption, Impact, and Developer Interventions",
      "authors": [
        "Tao Xiao",
        "Hideaki Hata",
        "Christoph Treude",
        "Kenichi Matsumoto"
      ],
      "published_date": "2024",
      "abstract": "GitHub's Copilot for Pull Requests (PRs) is a promising service aiming to automate various developer tasks related to PRs, such as generating summaries of changes or providing complete walkthroughs with links to the relevant code. As this innovative technology gains traction in the Open Source Software (OSS) community, it is crucial to examine its early adoption and its impact on the development process. Additionally, it offers a unique opportunity to observe how developers respond when they disagree with the generated content. In our study, we employ a mixed-methods approach, blending quantitative analysis with qualitative insights, to examine 18,256 PRs in which parts of the descriptions were crafted by generative AI. Our findings indicate that: (1) Copilot for PRs, though in its infancy, is seeing a marked uptick in adoption. (2) PRs enhanced by Copilot for PRs require less review time and have a higher likelihood of being merged. (3) Developers using Copilot for PRs often complement the automated descriptions with their manual input. These results offer valuable insights into the growing integration of generative AI in software development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/e9a4ad74859cda6ad9d50cdd53722d3ce76d0ae1.pdf",
      "venue": "Proc. ACM Softw. Eng.",
      "citationCount": 11,
      "score": 11.0,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper investigates the real-world adoption, impact, and developer interventions concerning generative AI, specifically GitHub's Copilot for Pull Requests (PRs), in the software development process.\n    *   **Importance & Challenge:** As generative AI rapidly integrates into software development, understanding its practical effects on code review efficiency, PR merge likelihood, and how developers interact with and adapt AI-generated content is crucial. This knowledge is vital for guiding the evolution of AI tools in SE and ensuring software quality in human-AI collaborative environments.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Prior research on Large Language Models (LLMs) in Software Engineering (SE) primarily focuses on developing and evaluating AI models for tasks like code generation, completion, and summarization (e.g., PRSummarizer, PRHAN, AUTOPRTITLE for PR summarization).\n    *   **Limitations of Previous Solutions:** Existing work largely concentrates on the *development and evaluation* of LLMs in controlled or theoretical settings. It lacks empirical investigation into the *real-world applicability, adoption, and practical impact* of these models within actual software development workflows, particularly regarding human-AI collaboration and developer interventions on AI-generated content \\cite{xiao20246s5}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper employs a mixed-methods empirical study, combining quantitative analysis of large-scale PR data with qualitative analysis of developer edits. It analyzes the adoption and impact of an existing generative AI tool (GitHub Copilot for PRs, powered by GPT-4) rather than proposing a new AI model.\n    *   **Novelty:** The approach is novel due to its large-scale, real-world empirical investigation of an early-stage generative AI tool in active open-source software (OSS) development. It uniquely focuses on human-AI collaboration by meticulously analyzing how developers adapt and complement AI-generated PR descriptions, providing insights into the practical dynamics of AI integration.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Methods/Techniques:**\n        *   A robust data collection methodology to identify and filter 18,256 Copilot-generated PRs and 54,188 non-Copilot PRs from 146 GitHub projects, including strategies for handling GitHub API limitations, obsolete uses, and bot-submitted PRs.\n        *   Application of `git diff` (Myers algorithm) to precisely trace and categorize developer modifications to AI-generated content across 1,437 revisions.\n        *   A method for identifying and segregating PR templates to accurately analyze developer-added supplementary information.\n    *   **Theoretical Insights/Analysis:** Provides empirical insights into the patterns of human-AI collaboration, identifying 13 categories of supplementary information developers add and 7 types of editorial actions they perform on AI-generated content.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:**\n        *   **Quantitative Analysis (RQ1 & RQ2):** Examined 18,256 Copilot-generated PRs and 54,188 non-Copilot PRs to assess adoption rates, review time, and merge likelihood.\n        *   **Qualitative Analysis (RQ3):** Analyzed 1,437 revisions from 311 PRs to understand how developers adapt AI-generated content.\n    *   **Key Performance Metrics & Results:**\n        *   **Adoption:** Observed a \"burgeoning adoption\" of Copilot for PRs, with `copilot:summary` being the most popular marker tag (13,231 instances).\n        *   **Review Time:** Copilot-assisted PRs showed a \"substantial reduction of review time by an average of 19.3 hours.\"\n        *   **Merge Likelihood:** PRs assisted by Copilot for PRs had a \"1.57 times higher likelihood of being merged\" (84% acceptance rate vs. 71% for non-Copilot PRs).\n        *   **Developer Interventions:** Identified 13 categories of supplementary information (e.g., integrating templates (22.8%), adding relevant links (22.7%)) and 7 editorial actions (e.g., partially removing content (22.9%)).\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The study is exploratory, focusing on early adoption during a limited release phase of Copilot for PRs. The comparison is quasi-experimental, controlling for temporal variations but not a true randomized controlled trial. Data collection relies on specific phrases and bot identification, which might have minor limitations.\n    *   **Scope of Applicability:** Findings are primarily applicable to open-source GitHub projects using Copilot for PRs. Generalizability to closed-source, enterprise environments, or future, more mature versions of the tool may require further investigation.\n\n*   **7. Technical Significance**\n    *   **Advancement of State-of-the-Art:** This paper provides the first large-scale empirical evidence of the real-world impact and adoption of generative AI in software development, moving beyond theoretical evaluations. It quantifies tangible benefits like reduced review time and increased merge likelihood, offering strong justification for AI integration.\n    *   **Potential Impact on Future Research:** The findings inform the design of more effective human-AI interfaces and generative AI tools for SE by highlighting where AI excels and where human input remains critical. It encourages further research into human-AI interaction, developer trust, and the evolving landscape of software development practices with increasing AI integration.",
      "keywords": [
        "Generative AI",
        "GitHub Copilot for Pull Requests",
        "human-AI collaboration",
        "software development process",
        "empirical study",
        "real-world adoption",
        "developer interventions",
        "code review efficiency",
        "PR merge likelihood",
        "mixed-methods research",
        "`git diff` analysis",
        "reduced review time",
        "increased merge likelihood",
        "supplementary information categories",
        "editorial actions"
      ],
      "paper_type": "the provided \"abstract\" is actually a list of references, so the classification must rely on the title and the introduction.\n\n**title:** generative ai for pull request descriptions: adoption, impact, and developer interventions\n\n**introduction analysis:**\n*   sets the context of generative ai in software development.\n*   states a clear research motivation: \"it is crucial to understand these interactions to gain insights into the evolution of ai in software development and how developers maintain the quality of software projects despite the ai’s involvement.\" this indicates a study aimed at understanding real-world phenomena.\n*   mentions \"github’s copilot for pull requests (prs)\" as a \"prime example,\" suggesting a focus on a specific application or context.\n*   the terms \"adoption,\" \"impact,\" and \"developer interventions\" in the title are all empirical questions that require data collection and analysis from real users or systems.\n\n**classification criteria check:**\n\n1.  **survey**: no indication of reviewing existing literature comprehensively or organizing classification schemes.\n2.  **technical**: the paper is not proposing a new method, algorithm, or system. it discusses understanding the use of an existing one.\n3.  **theoretical**: no mention of mathematical analysis, proofs, or formal models.\n4.  **empirical**:\n    *   the title's keywords (\"adoption,\" \"impact,\" \"developer interventions\") strongly suggest a study that collects and analyzes data to understand real-world phenomena.\n    *   the introduction's motivation (\"crucial to understand these interactions,\" \"how developers maintain the quality\") points to research questions that would be answered through data-driven investigation. this aligns with \"data-driven studies with statistical analysis\" and discussing \"research questions, methodology, participants.\"\n5.  **case_study**: while the paper might involve a case study (e.g., of github copilot), \"empirical\" is a broader category that encompasses such studies. the title's scope (\"adoption, impact, and developer interventions\") suggests a broader investigation into these aspects, which could involve various empirical methods beyond a single, detailed case study. however, it's a strong contender.\n6.  **position**: the paper is not arguing for a specific viewpoint or future direction; it aims to understand current phenomena.\n7.  **short**: the venue \"proc. acm softw. eng.\" typically publishes full papers, not brief communications, unless explicitly stated.\n\n**conclusion:**\nthe paper's title and introduction clearly indicate an investigation into how generative ai is used in practice, its effects, and how developers interact with it. this involves collecting and analyzing data to answer specific research questions about real-world phenomena, which is the definition of **empirical** research. while it might employ a case study methodology, \"empirical\" is the most fitting overarching classification given the broad scope implied by \"adoption, impact, and developer interventions.\"\n\nthe final classification is **empirical**."
    },
    "file_name": "e9a4ad74859cda6ad9d50cdd53722d3ce76d0ae1.pdf"
  },
  {
    "success": true,
    "doc_id": "8e6db3b1d3ec8afabd8e71ad73fdaa3c",
    "summary": "The integration of Artificial Intelligence (AI) into the space of software engineering marks a transformative period that reshapes traditional development processes and propels the industry into a new era of innovation. This exploration delves into the multifaceted impact of AI, from its roots in early symbolic AI to the contemporary dominance of machine learning and deep learning. AI’s applications span various domains, but its significance in software engineering lies in its ability to enhance efficiency, improve software quality, and introduce novel approaches to problem-solving. From automating routine tasks to streamlining complex development workflows, AI acts as a virtual collaborator, allowing human developers to focus on higher-order thinking and creativity. This study introduces the application of AI in software engineering. reverse-engineering, and development environments. Moreover, ethical considerations, challenges, and future trends, including explainable AI, reinforcement learning, and human-AI collaboration, are presented.",
    "intriguing_abstract": "The integration of Artificial Intelligence (AI) into the space of software engineering marks a transformative period that reshapes traditional development processes and propels the industry into a new era of innovation. This exploration delves into the multifaceted impact of AI, from its roots in early symbolic AI to the contemporary dominance of machine learning and deep learning. AI’s applications span various domains, but its significance in software engineering lies in its ability to enhance efficiency, improve software quality, and introduce novel approaches to problem-solving. From automating routine tasks to streamlining complex development workflows, AI acts as a virtual collaborator, allowing human developers to focus on higher-order thinking and creativity. This study introduces the application of AI in software engineering. reverse-engineering, and development environments. Moreover, ethical considerations, challenges, and future trends, including explainable AI, reinforcement learning, and human-AI collaboration, are presented.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/7944923a8865d978ef92bfef0a19d97b71fe5b3d.pdf",
    "citation_key": "marar2024cky",
    "metadata": {
      "title": "Advancements in software engineering using AI",
      "authors": [
        "Hazem W. Marar"
      ],
      "published_date": "2024",
      "abstract": "The integration of Artificial Intelligence (AI) into the space of software engineering marks a transformative period that reshapes traditional development processes and propels the industry into a new era of innovation. This exploration delves into the multifaceted impact of AI, from its roots in early symbolic AI to the contemporary dominance of machine learning and deep learning. AI’s applications span various domains, but its significance in software engineering lies in its ability to enhance efficiency, improve software quality, and introduce novel approaches to problem-solving. From automating routine tasks to streamlining complex development workflows, AI acts as a virtual collaborator, allowing human developers to focus on higher-order thinking and creativity. This study introduces the application of AI in software engineering. reverse-engineering, and development environments. Moreover, ethical considerations, challenges, and future trends, including explainable AI, reinforcement learning, and human-AI collaboration, are presented.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/7944923a8865d978ef92bfef0a19d97b71fe5b3d.pdf",
      "venue": "Computer Software and Media Applications",
      "citationCount": 11,
      "score": 11.0,
      "summary": "The integration of Artificial Intelligence (AI) into the space of software engineering marks a transformative period that reshapes traditional development processes and propels the industry into a new era of innovation. This exploration delves into the multifaceted impact of AI, from its roots in early symbolic AI to the contemporary dominance of machine learning and deep learning. AI’s applications span various domains, but its significance in software engineering lies in its ability to enhance efficiency, improve software quality, and introduce novel approaches to problem-solving. From automating routine tasks to streamlining complex development workflows, AI acts as a virtual collaborator, allowing human developers to focus on higher-order thinking and creativity. This study introduces the application of AI in software engineering. reverse-engineering, and development environments. Moreover, ethical considerations, challenges, and future trends, including explainable AI, reinforcement learning, and human-AI collaboration, are presented.",
      "keywords": []
    },
    "file_name": "7944923a8865d978ef92bfef0a19d97b71fe5b3d.pdf"
  },
  {
    "success": true,
    "doc_id": "48ae8336c54b4da9dec01ddbec7eec6a",
    "summary": "This study investigated the utilization of Artificial Intelligence (AI) in the Recruitment and Selection Process and its effect on the Efficiency of Human Resource Management (HRM) and on the Effectiveness of Organizational Development (OD) in Jordanian commercial banks. The research aimed to provide solutions to reduce the cost, time, and effort spent in the process of HRM and to increase OD Effectiveness. The research model was developed based on comprehensive review of existing literature on the subject. The population of this study comprised HR Managers and Employees across all commercial banks in Jordan, and a census method was employed to gather 177 responses. Data analysis was conducted using Amos and SPSS software packages. The findings show a statistically significant positive impact of AI adoption in the Recruitment and Selection Process on HR Efficiency, which in turn positively impacted OD Effectiveness. Additionally, the study indicated that the ease-of-use of AI technologies played a positive moderating role in the relationship between the Recruitment and Selection Process through AI and HR Efficiency. This study concludes that implementing AI tools in Recruitment is vital through improving HR Efficiency and Organization Effectiveness.",
    "intriguing_abstract": "This study investigated the utilization of Artificial Intelligence (AI) in the Recruitment and Selection Process and its effect on the Efficiency of Human Resource Management (HRM) and on the Effectiveness of Organizational Development (OD) in Jordanian commercial banks. The research aimed to provide solutions to reduce the cost, time, and effort spent in the process of HRM and to increase OD Effectiveness. The research model was developed based on comprehensive review of existing literature on the subject. The population of this study comprised HR Managers and Employees across all commercial banks in Jordan, and a census method was employed to gather 177 responses. Data analysis was conducted using Amos and SPSS software packages. The findings show a statistically significant positive impact of AI adoption in the Recruitment and Selection Process on HR Efficiency, which in turn positively impacted OD Effectiveness. Additionally, the study indicated that the ease-of-use of AI technologies played a positive moderating role in the relationship between the Recruitment and Selection Process through AI and HR Efficiency. This study concludes that implementing AI tools in Recruitment is vital through improving HR Efficiency and Organization Effectiveness.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9d9f4b0d91670d7a1b42d12bab9ad6718acc03fc.pdf",
    "citation_key": "alnsour202438r",
    "metadata": {
      "title": "The impact of implementing AI in recruitment on human resource management efficiency and organizational development effectiveness",
      "authors": [
        "Ahmad Suliman Alnsour",
        "O. Kanaan",
        "Maimar Salah",
        "Leen Alfayyad",
        "Yara Hijazi",
        "Dana Alsharif"
      ],
      "published_date": "2024",
      "abstract": "This study investigated the utilization of Artificial Intelligence (AI) in the Recruitment and Selection Process and its effect on the Efficiency of Human Resource Management (HRM) and on the Effectiveness of Organizational Development (OD) in Jordanian commercial banks. The research aimed to provide solutions to reduce the cost, time, and effort spent in the process of HRM and to increase OD Effectiveness. The research model was developed based on comprehensive review of existing literature on the subject. The population of this study comprised HR Managers and Employees across all commercial banks in Jordan, and a census method was employed to gather 177 responses. Data analysis was conducted using Amos and SPSS software packages. The findings show a statistically significant positive impact of AI adoption in the Recruitment and Selection Process on HR Efficiency, which in turn positively impacted OD Effectiveness. Additionally, the study indicated that the ease-of-use of AI technologies played a positive moderating role in the relationship between the Recruitment and Selection Process through AI and HR Efficiency. This study concludes that implementing AI tools in Recruitment is vital through improving HR Efficiency and Organization Effectiveness.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9d9f4b0d91670d7a1b42d12bab9ad6718acc03fc.pdf",
      "venue": "Journal of Infrastructure Policy and Development",
      "citationCount": 11,
      "score": 11.0,
      "summary": "This study investigated the utilization of Artificial Intelligence (AI) in the Recruitment and Selection Process and its effect on the Efficiency of Human Resource Management (HRM) and on the Effectiveness of Organizational Development (OD) in Jordanian commercial banks. The research aimed to provide solutions to reduce the cost, time, and effort spent in the process of HRM and to increase OD Effectiveness. The research model was developed based on comprehensive review of existing literature on the subject. The population of this study comprised HR Managers and Employees across all commercial banks in Jordan, and a census method was employed to gather 177 responses. Data analysis was conducted using Amos and SPSS software packages. The findings show a statistically significant positive impact of AI adoption in the Recruitment and Selection Process on HR Efficiency, which in turn positively impacted OD Effectiveness. Additionally, the study indicated that the ease-of-use of AI technologies played a positive moderating role in the relationship between the Recruitment and Selection Process through AI and HR Efficiency. This study concludes that implementing AI tools in Recruitment is vital through improving HR Efficiency and Organization Effectiveness.",
      "keywords": []
    },
    "file_name": "9d9f4b0d91670d7a1b42d12bab9ad6718acc03fc.pdf"
  },
  {
    "success": true,
    "doc_id": "2bc9cd80c2a02bc288a385dff6398de2",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2d27d508cfd678bcd1b60fccddb2fe48d9ea62dd.pdf",
    "citation_key": "paper2024o19",
    "metadata": {
      "title": "Generative AI for Effective Software Development",
      "authors": [],
      "published_date": "2024",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2d27d508cfd678bcd1b60fccddb2fe48d9ea62dd.pdf",
      "venue": "",
      "citationCount": 10,
      "score": 10.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "2d27d508cfd678bcd1b60fccddb2fe48d9ea62dd.pdf"
  },
  {
    "success": true,
    "doc_id": "27bc0b741c2c1d908c3c54723ddb393e",
    "summary": "Artificial intelligence (AI) is a very powerful technology and can be a potential disrupter and essential enabler. As AI expands into almost every aspect of our lives, people raise serious concerns about AI misbehaving and misuse. To address this concern, international organizations have put forward ethics guidelines for constructing trustworthy AI (TAI), including privacy, transparency, fairness, robustness, accountability, and so on. However, because of the black-box characteristics and complex models of AI systems, it is challenging to translate these guiding principles and aspirations into AI systems. Blockchain, an important decentralized technology, can provide the capabilities of transparency, traceability, immutability, and secure sharing and hence can be used to make AI trustworthy. In this paper, we survey studies on blockchain-based TAI (BTAI) from a software development lifecycle view. We classify the lifecycle of BTAI into four stages: Planning, data collection, model development, and system deployment/use. Particularly, we investigate and summarize the trustworthy issues that blockchain can achieve in the latter three stages, including (1) data transparency, privacy, and accountability; (2) model transparency, privacy, robustness, and fairness; and (3) robustness, privacy, transparency, and fairness of system deployment/use. Finally, we present essential open research issues and future work on developing BTAI systems.",
    "intriguing_abstract": "Artificial intelligence (AI) is a very powerful technology and can be a potential disrupter and essential enabler. As AI expands into almost every aspect of our lives, people raise serious concerns about AI misbehaving and misuse. To address this concern, international organizations have put forward ethics guidelines for constructing trustworthy AI (TAI), including privacy, transparency, fairness, robustness, accountability, and so on. However, because of the black-box characteristics and complex models of AI systems, it is challenging to translate these guiding principles and aspirations into AI systems. Blockchain, an important decentralized technology, can provide the capabilities of transparency, traceability, immutability, and secure sharing and hence can be used to make AI trustworthy. In this paper, we survey studies on blockchain-based TAI (BTAI) from a software development lifecycle view. We classify the lifecycle of BTAI into four stages: Planning, data collection, model development, and system deployment/use. Particularly, we investigate and summarize the trustworthy issues that blockchain can achieve in the latter three stages, including (1) data transparency, privacy, and accountability; (2) model transparency, privacy, robustness, and fairness; and (3) robustness, privacy, transparency, and fairness of system deployment/use. Finally, we present essential open research issues and future work on developing BTAI systems.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/4bd0aaa2b52bcc5001ef90d390ccbdc8347909d5.pdf",
    "citation_key": "zhang20232xp",
    "metadata": {
      "title": "Exploiting Blockchain to Make AI Trustworthy: A Software Development Lifecycle View",
      "authors": [
        "Peiyun Zhang",
        "Song Ding",
        "Qianchuan Zhao"
      ],
      "published_date": "2023",
      "abstract": "Artificial intelligence (AI) is a very powerful technology and can be a potential disrupter and essential enabler. As AI expands into almost every aspect of our lives, people raise serious concerns about AI misbehaving and misuse. To address this concern, international organizations have put forward ethics guidelines for constructing trustworthy AI (TAI), including privacy, transparency, fairness, robustness, accountability, and so on. However, because of the black-box characteristics and complex models of AI systems, it is challenging to translate these guiding principles and aspirations into AI systems. Blockchain, an important decentralized technology, can provide the capabilities of transparency, traceability, immutability, and secure sharing and hence can be used to make AI trustworthy. In this paper, we survey studies on blockchain-based TAI (BTAI) from a software development lifecycle view. We classify the lifecycle of BTAI into four stages: Planning, data collection, model development, and system deployment/use. Particularly, we investigate and summarize the trustworthy issues that blockchain can achieve in the latter three stages, including (1) data transparency, privacy, and accountability; (2) model transparency, privacy, robustness, and fairness; and (3) robustness, privacy, transparency, and fairness of system deployment/use. Finally, we present essential open research issues and future work on developing BTAI systems.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/4bd0aaa2b52bcc5001ef90d390ccbdc8347909d5.pdf",
      "venue": "ACM Computing Surveys",
      "citationCount": 20,
      "score": 10.0,
      "summary": "Artificial intelligence (AI) is a very powerful technology and can be a potential disrupter and essential enabler. As AI expands into almost every aspect of our lives, people raise serious concerns about AI misbehaving and misuse. To address this concern, international organizations have put forward ethics guidelines for constructing trustworthy AI (TAI), including privacy, transparency, fairness, robustness, accountability, and so on. However, because of the black-box characteristics and complex models of AI systems, it is challenging to translate these guiding principles and aspirations into AI systems. Blockchain, an important decentralized technology, can provide the capabilities of transparency, traceability, immutability, and secure sharing and hence can be used to make AI trustworthy. In this paper, we survey studies on blockchain-based TAI (BTAI) from a software development lifecycle view. We classify the lifecycle of BTAI into four stages: Planning, data collection, model development, and system deployment/use. Particularly, we investigate and summarize the trustworthy issues that blockchain can achieve in the latter three stages, including (1) data transparency, privacy, and accountability; (2) model transparency, privacy, robustness, and fairness; and (3) robustness, privacy, transparency, and fairness of system deployment/use. Finally, we present essential open research issues and future work on developing BTAI systems.",
      "keywords": []
    },
    "file_name": "4bd0aaa2b52bcc5001ef90d390ccbdc8347909d5.pdf"
  },
  {
    "success": true,
    "doc_id": "eebc67b65111a0dc6e7404bcca313db4",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the limited empirical understanding of how Large Language Models (LLMs), specifically ChatGPT, impact undergraduate students' software development experiences across the entire Software Development Life Cycle (SDLC).\n    *   **Importance and Challenge**: Undergraduate students consistently face challenges in fundamental architectural concepts, subsystem integration, debugging, program design, error identification, code quality, and proficiency with professional tools (e.g., version control, testing). Integrating AI tools like ChatGPT could potentially bridge these skill gaps, enhance productivity, and improve learning outcomes, but its effectiveness and limitations in this specific educational context require empirical validation.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous research has explored ChatGPT's capabilities in specific software engineering tasks such as generating requirements \\cite{waseem202369s}, architectural collaboration \\cite{waseem202369s}, code generation \\cite{waseem202369s}, and automated documentation \\cite{waseem202369s}.\n    *   **Limitations of Previous Solutions**: The paper highlights a notable gap: \"empirical reports specifically detailing the application of GPTs, including GPT-3 and the more recent ChatGPT, in the training of undergraduate students across various software development phases remain notably limited\" \\cite{waseem202369s}. This study aims to fill this gap by providing a comprehensive, project-based empirical investigation.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The study employs an empirical, project-based methodology where seven undergraduate students utilized ChatGPT (versions GPT-3.5 and GPT-4) as a support tool throughout a three-month software development project. The investigation covered all phases of the SDLC: requirements analysis, design, architecture, development, testing, and deployment.\n    *   **Novelty/Difference**: The innovation lies not in a new AI algorithm, but in the *empirical and holistic evaluation* of an existing generative AI tool (ChatGPT) within a *real-world, project-based educational setting* for *novice software developers* (undergraduate students) across the *entire software development lifecycle*. This provides unique insights into human-AI collaboration in an educational context.\n\n*   **Key Technical Contributions**\n    *   **Empirical Assessment of AI Impact**: Provides concrete empirical evidence on ChatGPT’s impact on students’ software development lifecycle, detailing its advantages and limitations across different phases.\n    *   **Educational Value and Challenges**: Identifies specific challenges faced by students when using ChatGPT and evaluates its educational value in fostering skill development and improving proficiency in software engineering concepts.\n    *   **Evidence for Human-AI Collaboration**: Presents a case study demonstrating the practical integration and effectiveness of ChatGPT in software development, contributing to the broader discourse on human-AI collaboration in engineering domains.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   **Participants**: Seven undergraduate students with limited prior software development experience were recruited.\n        *   **Projects**: Students worked on three real-world, publicly announced software projects (e.g., AI Procurement Assistant for Solita Ltd, AI-based Teacher-Tech Forum for Jyväskylä University of Applied Sciences, AI-based Skills Assessment SaaS for city governments).\n        *   **Methodology**: A cross-sectional survey design was used, involving an entry survey (53 questions) to assess background and initial proficiency, and an exit survey (114 questions) to evaluate ChatGPT's impact. Data analysis involved descriptive statistics for quantitative data and open coding for qualitative (open-ended) responses.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Effectiveness**: Results showed that ChatGPT \"significantly addresses skill gaps in software development education, enhancing efficiency, accuracy, and collaboration\" \\cite{waseem202369s}.\n        *   **Learning Outcomes**: It \"improved participants’ fundamental understanding and soft skills\" \\cite{waseem202369s}.\n        *   **Skill Gaps Addressed**: Particularly noted improvements in areas where students initially had low proficiency, such as deployment and release management.\n        *   **Perceived Benefits**: Students appreciated ChatGPT's quick code generation, efficiency in finding tools/algorithms, and reduction of manual search time.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study involved a small sample size (seven students), which may limit the generalizability of the findings. The specific versions of ChatGPT (GPT-3.5 and GPT-4) used are subject to continuous updates, potentially affecting long-term applicability. The study also implicitly assumes a certain level of prompt engineering capability from the students.\n    *   **Scope of Applicability**: The findings are most directly applicable to undergraduate software engineering education and early-career developer training, particularly in project-based learning environments where generative AI tools are integrated as support.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper advances the technical state-of-the-art by providing crucial empirical data on the practical utility and educational impact of generative AI in a comprehensive software development context for novice learners, an area previously lacking in detailed studies.\n    *   **Potential Impact on Future Research**: It highlights the importance of incorporating AI tools in education to bridge skill gaps and increase productivity. It also sets the stage for future research on optimizing ChatGPT’s application in various development contexts, exploring balanced approaches to technology use, and further investigating human-AI collaboration dynamics in software engineering.",
    "intriguing_abstract": "The burgeoning role of Large Language Models (LLMs) like ChatGPT promises to revolutionize software development, yet their comprehensive empirical impact on undergraduate students across the entire Software Development Life Cycle (SDLC) remains critically underexplored. Novice developers consistently grapple with fundamental architectural concepts, debugging, and deployment. This paper presents a novel empirical investigation into how ChatGPT (GPT-3.5 and GPT-4) influences undergraduate students' software development experiences from requirements analysis to deployment. Seven students utilized ChatGPT as a support tool throughout a three-month real-world project, providing unique insights into human-AI collaboration. Our findings reveal that ChatGPT significantly addresses critical skill gaps, enhancing efficiency, accuracy, and collaboration, while improving fundamental understanding and soft skills, particularly in complex areas like deployment. This study offers crucial empirical evidence on the practical utility and educational value of generative AI in software engineering training, advancing the state-of-the-art and paving the way for optimized human-AI integration to cultivate future-ready developers.",
    "keywords": [
      "ChatGPT",
      "Large Language Models (LLMs)",
      "Software Development Life Cycle (SDLC)",
      "Undergraduate software engineering education",
      "Empirical project-based methodology",
      "Human-AI collaboration",
      "Software development skill gaps",
      "Learning outcomes",
      "Novice software developers",
      "Generative AI",
      "Educational impact",
      "Deployment and release management",
      "Cross-sectional survey design"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/93a751ed488a22a266a360517fe32b8a6e98f7e7.pdf",
    "citation_key": "waseem202369s",
    "metadata": {
      "title": "ChatGPT as a Software Development Bot: A Project-Based Study",
      "authors": [
        "Muhammad Waseem",
        "Teerath Das",
        "Aakash Ahmad",
        "Peng Liang",
        "Mahdi Fahmideh",
        "T. Mikkonen"
      ],
      "published_date": "2023",
      "abstract": "Artificial Intelligence has demonstrated its significance in software engineering through notable improvements in productivity, accuracy, collaboration, and learning outcomes. This study examines the impact of generative AI tools, specifically ChatGPT, on the software development experiences of undergraduate students. Over a three-month project with seven students, ChatGPT was used as a support tool. The research focused on assessing ChatGPT's effectiveness, benefits, limitations, and its influence on learning. Results showed that ChatGPT significantly addresses skill gaps in software development education, enhancing efficiency, accuracy, and collaboration. It also improved participants' fundamental understanding and soft skills. The study highlights the importance of incorporating AI tools like ChatGPT in education to bridge skill gaps and increase productivity, but stresses the need for a balanced approach to technology use. Future research should focus on optimizing ChatGPT's application in various development contexts to maximize learning and address specific challenges.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/93a751ed488a22a266a360517fe32b8a6e98f7e7.pdf",
      "venue": "International Conference on Evaluation of Novel Approaches to Software Engineering",
      "citationCount": 20,
      "score": 10.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the limited empirical understanding of how Large Language Models (LLMs), specifically ChatGPT, impact undergraduate students' software development experiences across the entire Software Development Life Cycle (SDLC).\n    *   **Importance and Challenge**: Undergraduate students consistently face challenges in fundamental architectural concepts, subsystem integration, debugging, program design, error identification, code quality, and proficiency with professional tools (e.g., version control, testing). Integrating AI tools like ChatGPT could potentially bridge these skill gaps, enhance productivity, and improve learning outcomes, but its effectiveness and limitations in this specific educational context require empirical validation.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous research has explored ChatGPT's capabilities in specific software engineering tasks such as generating requirements \\cite{waseem202369s}, architectural collaboration \\cite{waseem202369s}, code generation \\cite{waseem202369s}, and automated documentation \\cite{waseem202369s}.\n    *   **Limitations of Previous Solutions**: The paper highlights a notable gap: \"empirical reports specifically detailing the application of GPTs, including GPT-3 and the more recent ChatGPT, in the training of undergraduate students across various software development phases remain notably limited\" \\cite{waseem202369s}. This study aims to fill this gap by providing a comprehensive, project-based empirical investigation.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The study employs an empirical, project-based methodology where seven undergraduate students utilized ChatGPT (versions GPT-3.5 and GPT-4) as a support tool throughout a three-month software development project. The investigation covered all phases of the SDLC: requirements analysis, design, architecture, development, testing, and deployment.\n    *   **Novelty/Difference**: The innovation lies not in a new AI algorithm, but in the *empirical and holistic evaluation* of an existing generative AI tool (ChatGPT) within a *real-world, project-based educational setting* for *novice software developers* (undergraduate students) across the *entire software development lifecycle*. This provides unique insights into human-AI collaboration in an educational context.\n\n*   **Key Technical Contributions**\n    *   **Empirical Assessment of AI Impact**: Provides concrete empirical evidence on ChatGPT’s impact on students’ software development lifecycle, detailing its advantages and limitations across different phases.\n    *   **Educational Value and Challenges**: Identifies specific challenges faced by students when using ChatGPT and evaluates its educational value in fostering skill development and improving proficiency in software engineering concepts.\n    *   **Evidence for Human-AI Collaboration**: Presents a case study demonstrating the practical integration and effectiveness of ChatGPT in software development, contributing to the broader discourse on human-AI collaboration in engineering domains.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**:\n        *   **Participants**: Seven undergraduate students with limited prior software development experience were recruited.\n        *   **Projects**: Students worked on three real-world, publicly announced software projects (e.g., AI Procurement Assistant for Solita Ltd, AI-based Teacher-Tech Forum for Jyväskylä University of Applied Sciences, AI-based Skills Assessment SaaS for city governments).\n        *   **Methodology**: A cross-sectional survey design was used, involving an entry survey (53 questions) to assess background and initial proficiency, and an exit survey (114 questions) to evaluate ChatGPT's impact. Data analysis involved descriptive statistics for quantitative data and open coding for qualitative (open-ended) responses.\n    *   **Key Performance Metrics and Comparison Results**:\n        *   **Effectiveness**: Results showed that ChatGPT \"significantly addresses skill gaps in software development education, enhancing efficiency, accuracy, and collaboration\" \\cite{waseem202369s}.\n        *   **Learning Outcomes**: It \"improved participants’ fundamental understanding and soft skills\" \\cite{waseem202369s}.\n        *   **Skill Gaps Addressed**: Particularly noted improvements in areas where students initially had low proficiency, such as deployment and release management.\n        *   **Perceived Benefits**: Students appreciated ChatGPT's quick code generation, efficiency in finding tools/algorithms, and reduction of manual search time.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study involved a small sample size (seven students), which may limit the generalizability of the findings. The specific versions of ChatGPT (GPT-3.5 and GPT-4) used are subject to continuous updates, potentially affecting long-term applicability. The study also implicitly assumes a certain level of prompt engineering capability from the students.\n    *   **Scope of Applicability**: The findings are most directly applicable to undergraduate software engineering education and early-career developer training, particularly in project-based learning environments where generative AI tools are integrated as support.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper advances the technical state-of-the-art by providing crucial empirical data on the practical utility and educational impact of generative AI in a comprehensive software development context for novice learners, an area previously lacking in detailed studies.\n    *   **Potential Impact on Future Research**: It highlights the importance of incorporating AI tools in education to bridge skill gaps and increase productivity. It also sets the stage for future research on optimizing ChatGPT’s application in various development contexts, exploring balanced approaches to technology use, and further investigating human-AI collaboration dynamics in software engineering.",
      "keywords": [
        "ChatGPT",
        "Large Language Models (LLMs)",
        "Software Development Life Cycle (SDLC)",
        "Undergraduate software engineering education",
        "Empirical project-based methodology",
        "Human-AI collaboration",
        "Software development skill gaps",
        "Learning outcomes",
        "Novice software developers",
        "Generative AI",
        "Educational impact",
        "Deployment and release management",
        "Cross-sectional survey design"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the **abstract** explicitly states: \"this **study examines** the impact...\", \"over a three-month **project with seven students**...\", \"the **research focused on assessing** chatgpt’s effectiveness...\", \"**results showed** that chatgpt significantly addresses skill gaps...\", \"the **study highlights** the importance...\". it clearly describes a data-driven investigation with findings.\n*   the **introduction** discusses the \"context and motivation\" for the study, highlighting a gap in \"empirical reports\" and setting up their own investigation. it mentions \"undergraduate students\" as participants.\n*   the **title** \"chatgpt as a software development bot: a project-based study\" further reinforces the nature of an investigation.\n\nthese elements align perfectly with the criteria for an **empirical** paper:\n*   abstract mentions: \"study\", \"experiment\" (implied by \"project-based study\" and \"examines the impact\"), \"data\" (implied by \"results showed\"), \"findings\" (explicitly \"results showed\").\n*   introduction discusses: \"research questions\" (implied by \"assessing chatgpt’s effectiveness...\"), \"methodology\" (implied by \"over a three-month project with seven students...\"), \"participants\" (explicitly \"undergraduate students\", \"seven students\").\n\nwhile it could be considered a small-scale empirical study or even a multiple-case study (if each student was a case), the overarching classification is that it is an **empirical** paper, as it involves collecting and analyzing data from a specific group of participants to answer research questions.\n\n**classification: empirical**"
    },
    "file_name": "93a751ed488a22a266a360517fe32b8a6e98f7e7.pdf"
  },
  {
    "success": true,
    "doc_id": "0244ea6e8683a1accf85d9cccc11f5d2",
    "summary": "Artificial intelligence (AI) has witnessed an exponential increase in use in various applications. Recently, the academic community started to research and inject new AI-based approaches to provide solutions to traditional software-engineering problems. However, a comprehensive and holistic understanding of the current status needs to be included. To close the above gap, synthetic knowledge synthesis was used to induce the research landscape of the contemporary research literature on the use of AI in software engineering. The synthesis resulted in 15 research categories and 5 themes—namely, natural language processing in software engineering, use of artificial intelligence in the management of the software development life cycle, use of machine learning in fault/defect prediction and effort estimation, employment of deep learning in intelligent software engineering and code management, and mining software repositories to improve software quality. The most productive country was China (n = 2042), followed by the United States (n = 1193), India (n = 934), Germany (n = 445), and Canada (n = 381). A high percentage (n = 47.4%) of papers were funded, showing the strong interest in this research topic. The convergence of AI and software engineering can significantly reduce the required resources, improve the quality, enhance the user experience, and improve the well-being of software developers.",
    "intriguing_abstract": "Artificial intelligence (AI) has witnessed an exponential increase in use in various applications. Recently, the academic community started to research and inject new AI-based approaches to provide solutions to traditional software-engineering problems. However, a comprehensive and holistic understanding of the current status needs to be included. To close the above gap, synthetic knowledge synthesis was used to induce the research landscape of the contemporary research literature on the use of AI in software engineering. The synthesis resulted in 15 research categories and 5 themes—namely, natural language processing in software engineering, use of artificial intelligence in the management of the software development life cycle, use of machine learning in fault/defect prediction and effort estimation, employment of deep learning in intelligent software engineering and code management, and mining software repositories to improve software quality. The most productive country was China (n = 2042), followed by the United States (n = 1193), India (n = 934), Germany (n = 445), and Canada (n = 381). A high percentage (n = 47.4%) of papers were funded, showing the strong interest in this research topic. The convergence of AI and software engineering can significantly reduce the required resources, improve the quality, enhance the user experience, and improve the well-being of software developers.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/bcd82c396a9076e485300fc2a5207e9cfa77fdce.pdf",
    "citation_key": "kokol2024w8w",
    "metadata": {
      "title": "The Use of AI in Software Engineering: A Synthetic Knowledge Synthesis of the Recent Research Literature",
      "authors": [
        "Peter Kokol"
      ],
      "published_date": "2024",
      "abstract": "Artificial intelligence (AI) has witnessed an exponential increase in use in various applications. Recently, the academic community started to research and inject new AI-based approaches to provide solutions to traditional software-engineering problems. However, a comprehensive and holistic understanding of the current status needs to be included. To close the above gap, synthetic knowledge synthesis was used to induce the research landscape of the contemporary research literature on the use of AI in software engineering. The synthesis resulted in 15 research categories and 5 themes—namely, natural language processing in software engineering, use of artificial intelligence in the management of the software development life cycle, use of machine learning in fault/defect prediction and effort estimation, employment of deep learning in intelligent software engineering and code management, and mining software repositories to improve software quality. The most productive country was China (n = 2042), followed by the United States (n = 1193), India (n = 934), Germany (n = 445), and Canada (n = 381). A high percentage (n = 47.4%) of papers were funded, showing the strong interest in this research topic. The convergence of AI and software engineering can significantly reduce the required resources, improve the quality, enhance the user experience, and improve the well-being of software developers.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/bcd82c396a9076e485300fc2a5207e9cfa77fdce.pdf",
      "venue": "Inf.",
      "citationCount": 10,
      "score": 10.0,
      "summary": "Artificial intelligence (AI) has witnessed an exponential increase in use in various applications. Recently, the academic community started to research and inject new AI-based approaches to provide solutions to traditional software-engineering problems. However, a comprehensive and holistic understanding of the current status needs to be included. To close the above gap, synthetic knowledge synthesis was used to induce the research landscape of the contemporary research literature on the use of AI in software engineering. The synthesis resulted in 15 research categories and 5 themes—namely, natural language processing in software engineering, use of artificial intelligence in the management of the software development life cycle, use of machine learning in fault/defect prediction and effort estimation, employment of deep learning in intelligent software engineering and code management, and mining software repositories to improve software quality. The most productive country was China (n = 2042), followed by the United States (n = 1193), India (n = 934), Germany (n = 445), and Canada (n = 381). A high percentage (n = 47.4%) of papers were funded, showing the strong interest in this research topic. The convergence of AI and software engineering can significantly reduce the required resources, improve the quality, enhance the user experience, and improve the well-being of software developers.",
      "keywords": []
    },
    "file_name": "bcd82c396a9076e485300fc2a5207e9cfa77fdce.pdf"
  },
  {
    "success": true,
    "doc_id": "f09e3ff25eef54ad3fe5523cb2942b73",
    "summary": "Background Generative artificial intelligence has the potential to revolutionize health technology product development by improving coding quality, efficiency, documentation, quality assessment and review, and troubleshooting. Objective This paper explores the application of a commercially available generative artificial intelligence tool (ChatGPT) to the development of a digital health behavior change intervention designed to support patient engagement in a commercial digital diabetes prevention program. Methods We examined the capacity, advantages, and limitations of ChatGPT to support digital product idea conceptualization, intervention content development, and the software engineering process, including software requirement generation, software design, and code production. In total, 11 evaluators, each with at least 10 years of experience in fields of study ranging from medicine and implementation science to computer science, participated in the output review process (ChatGPT vs human-generated output). All had familiarity or prior exposure to the original personalized automatic messaging system intervention. The evaluators rated the ChatGPT-produced outputs in terms of understandability, usability, novelty, relevance, completeness, and efficiency. Results Most metrics received positive scores. We identified that ChatGPT can (1) support developers to achieve high-quality products faster and (2) facilitate nontechnical communication and system understanding between technical and nontechnical team members around the development goal of rapid and easy-to-build computational solutions for medical technologies. Conclusions ChatGPT can serve as a usable facilitator for researchers engaging in the software development life cycle, from product conceptualization to feature identification and user story development to code generation. Trial Registration ClinicalTrials.gov NCT04049500; https://clinicaltrials.gov/ct2/show/NCT04049500",
    "intriguing_abstract": "Background Generative artificial intelligence has the potential to revolutionize health technology product development by improving coding quality, efficiency, documentation, quality assessment and review, and troubleshooting. Objective This paper explores the application of a commercially available generative artificial intelligence tool (ChatGPT) to the development of a digital health behavior change intervention designed to support patient engagement in a commercial digital diabetes prevention program. Methods We examined the capacity, advantages, and limitations of ChatGPT to support digital product idea conceptualization, intervention content development, and the software engineering process, including software requirement generation, software design, and code production. In total, 11 evaluators, each with at least 10 years of experience in fields of study ranging from medicine and implementation science to computer science, participated in the output review process (ChatGPT vs human-generated output). All had familiarity or prior exposure to the original personalized automatic messaging system intervention. The evaluators rated the ChatGPT-produced outputs in terms of understandability, usability, novelty, relevance, completeness, and efficiency. Results Most metrics received positive scores. We identified that ChatGPT can (1) support developers to achieve high-quality products faster and (2) facilitate nontechnical communication and system understanding between technical and nontechnical team members around the development goal of rapid and easy-to-build computational solutions for medical technologies. Conclusions ChatGPT can serve as a usable facilitator for researchers engaging in the software development life cycle, from product conceptualization to feature identification and user story development to code generation. Trial Registration ClinicalTrials.gov NCT04049500; https://clinicaltrials.gov/ct2/show/NCT04049500",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/beb36f10d16106ebbb0ecf68d0b5806067d9acc9.pdf",
    "citation_key": "rodriguez2023cm2",
    "metadata": {
      "title": "Leveraging Generative AI Tools to Support the Development of Digital Solutions in Health Care Research: Case Study",
      "authors": [
        "Danissa V. Rodriguez",
        "K. Lawrence",
        "Javier González",
        "Beatrix Brandfield-Harvey",
        "Lynn Xu",
        "Sumaiya Tasneem",
        "Defne L Levine",
        "Devin M. Mann"
      ],
      "published_date": "2023",
      "abstract": "Background Generative artificial intelligence has the potential to revolutionize health technology product development by improving coding quality, efficiency, documentation, quality assessment and review, and troubleshooting. Objective This paper explores the application of a commercially available generative artificial intelligence tool (ChatGPT) to the development of a digital health behavior change intervention designed to support patient engagement in a commercial digital diabetes prevention program. Methods We examined the capacity, advantages, and limitations of ChatGPT to support digital product idea conceptualization, intervention content development, and the software engineering process, including software requirement generation, software design, and code production. In total, 11 evaluators, each with at least 10 years of experience in fields of study ranging from medicine and implementation science to computer science, participated in the output review process (ChatGPT vs human-generated output). All had familiarity or prior exposure to the original personalized automatic messaging system intervention. The evaluators rated the ChatGPT-produced outputs in terms of understandability, usability, novelty, relevance, completeness, and efficiency. Results Most metrics received positive scores. We identified that ChatGPT can (1) support developers to achieve high-quality products faster and (2) facilitate nontechnical communication and system understanding between technical and nontechnical team members around the development goal of rapid and easy-to-build computational solutions for medical technologies. Conclusions ChatGPT can serve as a usable facilitator for researchers engaging in the software development life cycle, from product conceptualization to feature identification and user story development to code generation. Trial Registration ClinicalTrials.gov NCT04049500; https://clinicaltrials.gov/ct2/show/NCT04049500",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/beb36f10d16106ebbb0ecf68d0b5806067d9acc9.pdf",
      "venue": "JMIR Human Factors",
      "citationCount": 20,
      "score": 10.0,
      "summary": "Background Generative artificial intelligence has the potential to revolutionize health technology product development by improving coding quality, efficiency, documentation, quality assessment and review, and troubleshooting. Objective This paper explores the application of a commercially available generative artificial intelligence tool (ChatGPT) to the development of a digital health behavior change intervention designed to support patient engagement in a commercial digital diabetes prevention program. Methods We examined the capacity, advantages, and limitations of ChatGPT to support digital product idea conceptualization, intervention content development, and the software engineering process, including software requirement generation, software design, and code production. In total, 11 evaluators, each with at least 10 years of experience in fields of study ranging from medicine and implementation science to computer science, participated in the output review process (ChatGPT vs human-generated output). All had familiarity or prior exposure to the original personalized automatic messaging system intervention. The evaluators rated the ChatGPT-produced outputs in terms of understandability, usability, novelty, relevance, completeness, and efficiency. Results Most metrics received positive scores. We identified that ChatGPT can (1) support developers to achieve high-quality products faster and (2) facilitate nontechnical communication and system understanding between technical and nontechnical team members around the development goal of rapid and easy-to-build computational solutions for medical technologies. Conclusions ChatGPT can serve as a usable facilitator for researchers engaging in the software development life cycle, from product conceptualization to feature identification and user story development to code generation. Trial Registration ClinicalTrials.gov NCT04049500; https://clinicaltrials.gov/ct2/show/NCT04049500",
      "keywords": []
    },
    "file_name": "beb36f10d16106ebbb0ecf68d0b5806067d9acc9.pdf"
  },
  {
    "success": true,
    "doc_id": "ddc9aa10b5ad2cac1fff58f6a492965a",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the bottlenecks in efficiency, accuracy, and coverage of traditional software testing methodologies, particularly in the context of rapid, large-scale software development. It frames \"bug detection\" and \"coding with fewer bugs\" as interconnected problems.\n    *   **Importance & Challenge:** The increasing complexity of systems and the industry's shift towards continuous integration and deployment demand more sophisticated and efficient testing tools. Traditional methods, often manual or semi-automated, struggle to effectively identify bugs and minimize defect rates, leading to inadequate test coverage and impeding the development process \\cite{wang2025vty}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work extends previous AI-assisted programming tools (like Copilot for Xcode) that support code auto-completion and Q&A, applying these innovations to software testing. It builds upon advancements in AI-assisted programming, automated software testing (e.g., ML for test case generation), Search-Based Software Engineering (SBSE), and Retrieval Augmented Generation (RAG) \\cite{wang2025vty}.\n    *   **Limitations of Previous Solutions:** Traditional testing methods often fall short in addressing the dual challenges of effective bug identification and minimizing bug rates. Existing automated testing solutions still face issues like flaky tests and maintenance challenges, highlighting the need for more robust and intelligent strategies \\cite{wang2025vty}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper introduces \"Copilot for Testing,\" an AI-assisted testing system that synchronizes bug detection, fix suggestions, and automated test case generation with codebase updates directly within the development environment. Its core is a **context-based Retrieval Augmented Generation (RAG) module** that enhances Large Language Models (LLMs) \\cite{wang2025vty}.\n    *   **Novelty:** The approach models the codebase as a **graph-based representation**, where nodes represent code context embeddings. These embeddings are dynamically updated based on real-time code changes, error patterns, and LLM-generated insights. Factors influencing embeddings include file path, cursor position, file content, bug logs, and graph connectivity. This dynamic, context-aware RAG mechanism allows the system to adapt and refine testing strategies in real-time, providing highly relevant contextual information to the LLMs for prompt construction \\cite{wang2025vty}.\n\n*   **Key Technical Contributions**\n    *   **Novel Methodology:** A software testing methodology powered by a context-based RAG module that dynamically learns and adapts code context embeddings for enhanced LLM performance \\cite{wang2025vty}.\n    *   **System Design:** Development of \"Copilot for Testing,\" an automated software testing system seamlessly integrated into the development environment, providing real-time bug detection, fix suggestions, and test case generation synchronized with codebase updates \\cite{wang2025vty}.\n    *   **Architectural Innovation:** A graph-based representation of the codebase where nodes are dynamically updated code context embeddings, incorporating multiple factors (e.g., bug logs, graph connectivity) to provide insightful context for LLM prompt generation \\cite{wang2025vty}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Both objective (quantitative) and subjective (user studies with software engineers) experiments were conducted. Objective evaluations used a curated database of Swift and C++ projects from the Software-artifact Infrastructure Repository (SIR), containing known bugs (\"mutants\") \\cite{wang2025vty}.\n    *   **Key Performance Metrics & Results:**\n        *   **Accuracy:** Achieved a **31.2% improvement in bug detection accuracy** compared to a baseline model without the context-based RAG module \\cite{wang2025vty}.\n        *   **Coverage:** Demonstrated a **12.6% increase in critical test coverage**, prioritizing high-impact code areas \\cite{wang2025vty}.\n        *   **Efficiency/User Acceptance:** Showed a **10.5% higher user acceptance rate** for code suggestions in user studies, indicating saved engineering efforts \\cite{wang2025vty}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper notes that information propagation in the codebase graph focuses updates on a localized neighborhood with diminishing weight to manage computational overhead. While the initial implementation was in Xcode (a restrictive environment), the framework's design is described as platform-agnostic, relying on modular components adaptable to other IDEs \\cite{wang2025vty}.\n    *   **Scope of Applicability:** The system is designed for AI-assisted testing within development environments, focusing on bug detection, fix suggestions, and test case generation synchronized with real-time codebase updates. Its robustness was demonstrated by overcoming challenges in Xcode, suggesting broad applicability to other IDEs \\cite{wang2025vty}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This work significantly advances AI-driven software testing by offering a unified solution that connects bug detection with code generation, leveraging dynamic context-based RAG to enhance LLM capabilities. It moves beyond traditional AI-assisted programming to provide real-time, intelligent testing support \\cite{wang2025vty}.\n    *   **Potential Impact:** Copilot for Testing has the potential to transform modern software development practices by streamlining the testing process, reducing manual effort, and improving overall software quality through higher accuracy, coverage, and efficiency in bug detection and code generation \\cite{wang2025vty}. Its platform-agnostic design suggests wide applicability across various development environments.",
    "intriguing_abstract": "Traditional software testing struggles to keep pace with the complexity and rapid iteration of modern development, leading to persistent bottlenecks in efficiency, accuracy, and coverage. We introduce **Copilot for Testing**, an innovative AI-assisted system designed to transform the software development lifecycle by unifying **bug detection**, fix suggestions, and **automated test case generation**.\n\nAt its core, Copilot for Testing leverages a novel **context-based Retrieval Augmented Generation (RAG) module** that dynamically enhances **Large Language Models (LLMs)**. This is achieved through a unique **graph-based representation** of the codebase, where **code context embeddings** are continuously updated in real-time based on code changes, error patterns, and LLM insights. This dynamic, context-aware mechanism provides highly relevant information for LLM prompt construction, enabling seamless, real-time synchronization directly within the development environment.\n\nExperimental validation demonstrates significant advancements: a **31.2% improvement in bug detection accuracy**, a **12.6% increase in critical test coverage**, and a **10.5% higher user acceptance rate** for generated suggestions, substantially reducing engineering effort. Copilot for Testing represents a paradigm shift, offering a unified, intelligent solution to streamline testing, elevate software quality, and accelerate development in the era of continuous integration and deployment.",
    "keywords": [
      "Copilot for Testing",
      "AI-assisted software testing",
      "context-based Retrieval Augmented Generation (RAG)",
      "Large Language Models (LLMs)",
      "graph-based codebase representation",
      "dynamic code context embeddings",
      "real-time bug detection",
      "automated test case generation",
      "fix suggestions",
      "bug detection accuracy",
      "critical test coverage",
      "user acceptance rate",
      "software development environments",
      "continuous integration and deployment"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/73e2f9db60f2bc5590f3b926b7801d66c5e69448.pdf",
    "citation_key": "wang2025vty",
    "metadata": {
      "title": "From Code Generation to Software Testing: AI Copilot With Context-Based Retrieval-Augmented Generation",
      "authors": [
        "Yuchen Wang",
        "Shangxin Guo",
        "Chee Wei Tan"
      ],
      "published_date": "2025",
      "abstract": "The rapid pace of large-scale software development places increasing demands on traditional testing methodologies. We propose a novel perspective on software testing, highlighting the transformative potential of AI-driven technologies in modern software development practices.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/73e2f9db60f2bc5590f3b926b7801d66c5e69448.pdf",
      "venue": "IEEE Software",
      "citationCount": 10,
      "score": 10.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the bottlenecks in efficiency, accuracy, and coverage of traditional software testing methodologies, particularly in the context of rapid, large-scale software development. It frames \"bug detection\" and \"coding with fewer bugs\" as interconnected problems.\n    *   **Importance & Challenge:** The increasing complexity of systems and the industry's shift towards continuous integration and deployment demand more sophisticated and efficient testing tools. Traditional methods, often manual or semi-automated, struggle to effectively identify bugs and minimize defect rates, leading to inadequate test coverage and impeding the development process \\cite{wang2025vty}.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work extends previous AI-assisted programming tools (like Copilot for Xcode) that support code auto-completion and Q&A, applying these innovations to software testing. It builds upon advancements in AI-assisted programming, automated software testing (e.g., ML for test case generation), Search-Based Software Engineering (SBSE), and Retrieval Augmented Generation (RAG) \\cite{wang2025vty}.\n    *   **Limitations of Previous Solutions:** Traditional testing methods often fall short in addressing the dual challenges of effective bug identification and minimizing bug rates. Existing automated testing solutions still face issues like flaky tests and maintenance challenges, highlighting the need for more robust and intelligent strategies \\cite{wang2025vty}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper introduces \"Copilot for Testing,\" an AI-assisted testing system that synchronizes bug detection, fix suggestions, and automated test case generation with codebase updates directly within the development environment. Its core is a **context-based Retrieval Augmented Generation (RAG) module** that enhances Large Language Models (LLMs) \\cite{wang2025vty}.\n    *   **Novelty:** The approach models the codebase as a **graph-based representation**, where nodes represent code context embeddings. These embeddings are dynamically updated based on real-time code changes, error patterns, and LLM-generated insights. Factors influencing embeddings include file path, cursor position, file content, bug logs, and graph connectivity. This dynamic, context-aware RAG mechanism allows the system to adapt and refine testing strategies in real-time, providing highly relevant contextual information to the LLMs for prompt construction \\cite{wang2025vty}.\n\n*   **Key Technical Contributions**\n    *   **Novel Methodology:** A software testing methodology powered by a context-based RAG module that dynamically learns and adapts code context embeddings for enhanced LLM performance \\cite{wang2025vty}.\n    *   **System Design:** Development of \"Copilot for Testing,\" an automated software testing system seamlessly integrated into the development environment, providing real-time bug detection, fix suggestions, and test case generation synchronized with codebase updates \\cite{wang2025vty}.\n    *   **Architectural Innovation:** A graph-based representation of the codebase where nodes are dynamically updated code context embeddings, incorporating multiple factors (e.g., bug logs, graph connectivity) to provide insightful context for LLM prompt generation \\cite{wang2025vty}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** Both objective (quantitative) and subjective (user studies with software engineers) experiments were conducted. Objective evaluations used a curated database of Swift and C++ projects from the Software-artifact Infrastructure Repository (SIR), containing known bugs (\"mutants\") \\cite{wang2025vty}.\n    *   **Key Performance Metrics & Results:**\n        *   **Accuracy:** Achieved a **31.2% improvement in bug detection accuracy** compared to a baseline model without the context-based RAG module \\cite{wang2025vty}.\n        *   **Coverage:** Demonstrated a **12.6% increase in critical test coverage**, prioritizing high-impact code areas \\cite{wang2025vty}.\n        *   **Efficiency/User Acceptance:** Showed a **10.5% higher user acceptance rate** for code suggestions in user studies, indicating saved engineering efforts \\cite{wang2025vty}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The paper notes that information propagation in the codebase graph focuses updates on a localized neighborhood with diminishing weight to manage computational overhead. While the initial implementation was in Xcode (a restrictive environment), the framework's design is described as platform-agnostic, relying on modular components adaptable to other IDEs \\cite{wang2025vty}.\n    *   **Scope of Applicability:** The system is designed for AI-assisted testing within development environments, focusing on bug detection, fix suggestions, and test case generation synchronized with real-time codebase updates. Its robustness was demonstrated by overcoming challenges in Xcode, suggesting broad applicability to other IDEs \\cite{wang2025vty}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This work significantly advances AI-driven software testing by offering a unified solution that connects bug detection with code generation, leveraging dynamic context-based RAG to enhance LLM capabilities. It moves beyond traditional AI-assisted programming to provide real-time, intelligent testing support \\cite{wang2025vty}.\n    *   **Potential Impact:** Copilot for Testing has the potential to transform modern software development practices by streamlining the testing process, reducing manual effort, and improving overall software quality through higher accuracy, coverage, and efficiency in bug detection and code generation \\cite{wang2025vty}. Its platform-agnostic design suggests wide applicability across various development environments.",
      "keywords": [
        "Copilot for Testing",
        "AI-assisted software testing",
        "context-based Retrieval Augmented Generation (RAG)",
        "Large Language Models (LLMs)",
        "graph-based codebase representation",
        "dynamic code context embeddings",
        "real-time bug detection",
        "automated test case generation",
        "fix suggestions",
        "bug detection accuracy",
        "critical test coverage",
        "user acceptance rate",
        "software development environments",
        "continuous integration and deployment"
      ],
      "paper_type": "based on the abstract and introduction, this paper should be classified as **technical**.\n\nhere's why:\n\n*   **abstract keywords:** \"we propose a novel perspective,\" \"we introduce 'copilot for testing,' an automated testing system,\" \"leveraging context-based retrieval augmented generation (rag) to enhance the capabilities of large language models (llms).\" these phrases directly indicate the presentation of a new system and method.\n*   **introduction focus:** the introduction identifies a technical problem (shortcomings of traditional testing) and immediately points to a proposed solution involving ai, llms, and rag.\n*   **empirical elements:** while the abstract does mention \"our evaluation demonstrates a 31.2% improvement...\" and other quantitative results, these are the *results of evaluating the proposed new system*. the primary contribution is the system itself and the method it employs, making the paper fundamentally technical, with an empirical validation component. many technical papers include such evaluations to demonstrate the efficacy of their proposed solutions."
    },
    "file_name": "73e2f9db60f2bc5590f3b926b7801d66c5e69448.pdf"
  },
  {
    "success": true,
    "doc_id": "f2b307d7a3705faf1482f067308aefa4",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/439035b6431c1f81beec71d2fc19845298fd003d.pdf",
    "citation_key": "pothukuchi2023ok8",
    "metadata": {
      "title": "IMPACT OF GENERATIVE AI ON THE SOFTWARE DEVELOPMENT LIFE CYCLE (SDLC)",
      "authors": [
        "Ameya Shastri Pothukuchi",
        "Lakshmi Vasuda Kota",
        "Vinay Mallikarjunaradhya"
      ],
      "published_date": "2023",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/439035b6431c1f81beec71d2fc19845298fd003d.pdf",
      "venue": "",
      "citationCount": 19,
      "score": 9.5,
      "summary": "",
      "keywords": []
    },
    "file_name": "439035b6431c1f81beec71d2fc19845298fd003d.pdf"
  },
  {
    "success": true,
    "doc_id": "c8d1ef8d9fe21fa868bf6bd96e3c0bda",
    "summary": "Scaled agile development approaches are now used widely in modern software engineering, allowing businesses to improve teamwork, productivity, and product quality. The incorporation of artificial intelligence (AI) into scaled agile development methods (SADMs) has emerged as a potential strategy in response to the ongoing demand for simplified procedures and the increasing complexity of software projects. This paper explores the intersection of AI-driven assistants within the context of the scaled agile framework (SAFe) for large-scale software development, as it stands out as the most widely adopted framework. Our paper pursues three principal objectives: (1) an evaluation of the challenges and impediments encountered by organizations during the implementation of SADMs, (2) an assessment of the potential advantages stemming from the incorporation of AI in large-scale contexts, and (3) the compilation of aspects of SADMs that AI-driven assistants enhance. Through a comprehensive systematic literature review, we identified and described 18 distinct challenges that organizations confront. In the course of our research, we pinpointed seven benefits and five challenges associated with the implementation of AI in SADMs. These findings were systematically categorized based on their occurrence either within the development phase or the phases encompassing planning and control. Furthermore, we compiled a list of 15 different AI-driven assistants and tools, subjecting them to a more detailed examination, and employing them to address the challenges we uncovered during our research. One of the key takeaways from this paper is the exceptional versatility and effectiveness of AI-driven assistants, demonstrating their capability to tackle a broader spectrum of problems. In conclusion, this paper not only sheds light on the transformative potential of AI, but also provides invaluable insights for organizations aiming to enhance their agility and management capabilities.",
    "intriguing_abstract": "Scaled agile development approaches are now used widely in modern software engineering, allowing businesses to improve teamwork, productivity, and product quality. The incorporation of artificial intelligence (AI) into scaled agile development methods (SADMs) has emerged as a potential strategy in response to the ongoing demand for simplified procedures and the increasing complexity of software projects. This paper explores the intersection of AI-driven assistants within the context of the scaled agile framework (SAFe) for large-scale software development, as it stands out as the most widely adopted framework. Our paper pursues three principal objectives: (1) an evaluation of the challenges and impediments encountered by organizations during the implementation of SADMs, (2) an assessment of the potential advantages stemming from the incorporation of AI in large-scale contexts, and (3) the compilation of aspects of SADMs that AI-driven assistants enhance. Through a comprehensive systematic literature review, we identified and described 18 distinct challenges that organizations confront. In the course of our research, we pinpointed seven benefits and five challenges associated with the implementation of AI in SADMs. These findings were systematically categorized based on their occurrence either within the development phase or the phases encompassing planning and control. Furthermore, we compiled a list of 15 different AI-driven assistants and tools, subjecting them to a more detailed examination, and employing them to address the challenges we uncovered during our research. One of the key takeaways from this paper is the exceptional versatility and effectiveness of AI-driven assistants, demonstrating their capability to tackle a broader spectrum of problems. In conclusion, this paper not only sheds light on the transformative potential of AI, but also provides invaluable insights for organizations aiming to enhance their agility and management capabilities.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/36821fc3c2202c6d9517484e891ed96df77e260c.pdf",
    "citation_key": "saklamaeva20230ek",
    "metadata": {
      "title": "The Potential of AI-Driven Assistants in Scaled Agile Software Development",
      "authors": [
        "Vasilka Saklamaeva",
        "Luka Pavlič"
      ],
      "published_date": "2023",
      "abstract": "Scaled agile development approaches are now used widely in modern software engineering, allowing businesses to improve teamwork, productivity, and product quality. The incorporation of artificial intelligence (AI) into scaled agile development methods (SADMs) has emerged as a potential strategy in response to the ongoing demand for simplified procedures and the increasing complexity of software projects. This paper explores the intersection of AI-driven assistants within the context of the scaled agile framework (SAFe) for large-scale software development, as it stands out as the most widely adopted framework. Our paper pursues three principal objectives: (1) an evaluation of the challenges and impediments encountered by organizations during the implementation of SADMs, (2) an assessment of the potential advantages stemming from the incorporation of AI in large-scale contexts, and (3) the compilation of aspects of SADMs that AI-driven assistants enhance. Through a comprehensive systematic literature review, we identified and described 18 distinct challenges that organizations confront. In the course of our research, we pinpointed seven benefits and five challenges associated with the implementation of AI in SADMs. These findings were systematically categorized based on their occurrence either within the development phase or the phases encompassing planning and control. Furthermore, we compiled a list of 15 different AI-driven assistants and tools, subjecting them to a more detailed examination, and employing them to address the challenges we uncovered during our research. One of the key takeaways from this paper is the exceptional versatility and effectiveness of AI-driven assistants, demonstrating their capability to tackle a broader spectrum of problems. In conclusion, this paper not only sheds light on the transformative potential of AI, but also provides invaluable insights for organizations aiming to enhance their agility and management capabilities.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/36821fc3c2202c6d9517484e891ed96df77e260c.pdf",
      "venue": "Applied Sciences",
      "citationCount": 18,
      "score": 9.0,
      "summary": "Scaled agile development approaches are now used widely in modern software engineering, allowing businesses to improve teamwork, productivity, and product quality. The incorporation of artificial intelligence (AI) into scaled agile development methods (SADMs) has emerged as a potential strategy in response to the ongoing demand for simplified procedures and the increasing complexity of software projects. This paper explores the intersection of AI-driven assistants within the context of the scaled agile framework (SAFe) for large-scale software development, as it stands out as the most widely adopted framework. Our paper pursues three principal objectives: (1) an evaluation of the challenges and impediments encountered by organizations during the implementation of SADMs, (2) an assessment of the potential advantages stemming from the incorporation of AI in large-scale contexts, and (3) the compilation of aspects of SADMs that AI-driven assistants enhance. Through a comprehensive systematic literature review, we identified and described 18 distinct challenges that organizations confront. In the course of our research, we pinpointed seven benefits and five challenges associated with the implementation of AI in SADMs. These findings were systematically categorized based on their occurrence either within the development phase or the phases encompassing planning and control. Furthermore, we compiled a list of 15 different AI-driven assistants and tools, subjecting them to a more detailed examination, and employing them to address the challenges we uncovered during our research. One of the key takeaways from this paper is the exceptional versatility and effectiveness of AI-driven assistants, demonstrating their capability to tackle a broader spectrum of problems. In conclusion, this paper not only sheds light on the transformative potential of AI, but also provides invaluable insights for organizations aiming to enhance their agility and management capabilities.",
      "keywords": []
    },
    "file_name": "36821fc3c2202c6d9517484e891ed96df77e260c.pdf"
  },
  {
    "success": true,
    "doc_id": "267a186dfba80ede10dcb8ad18a9311d",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/adc9bd141f74a9568596cd618617c2248b83ef68.pdf",
    "citation_key": "nath2023ffu",
    "metadata": {
      "title": "AI and Blockchain-based source code vulnerability detection and prevention system for multiparty software development",
      "authors": [
        "Panchanan Nath",
        "Jaya Rani Mushahary",
        "Ujjal Roy",
        "Maharaj Brahma",
        "P. Singh"
      ],
      "published_date": "2023",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/adc9bd141f74a9568596cd618617c2248b83ef68.pdf",
      "venue": "Computers & electrical engineering",
      "citationCount": 18,
      "score": 9.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "adc9bd141f74a9568596cd618617c2248b83ef68.pdf"
  },
  {
    "success": true,
    "doc_id": "82e4973deb9c49de9d46a20ab037dd40",
    "summary": "Here's a focused summary of the paper \"AI Tool Use and Adoption in Software Development by Individuals and Organizations: A Grounded Theory Study\" \\cite{li2024voc} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the lack of concrete details regarding the issues organizations and practitioners face when exploring or increasing the adoption and use of AI assistance tools (e.g., ChatGPT, Copilot, Gemini) in software development.\n    *   **Importance & Challenge:** While AI tools have significantly impacted software development and numerous studies highlight their benefits and usability aspects, there is a critical gap in understanding the underlying motives and challenges that influence AI tool adoption at both individual and organizational levels. This lack of clarity hinders organizations from effectively increasing AI tool usage and fully realizing their potential benefits.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Previous research has primarily focused on the usability of AI tools, their impact on developer productivity, code quality, trust, and ethical considerations \\cite{li2024voc}. Some studies explored how developers perceive and use tools like GitHub Copilot, identifying benefits (e.g., reducing search time) and limitations (e.g., debugging difficulty, code quality issues).\n    *   **Limitations of Previous Solutions:** A recent study by Russo \\cite{li2024voc} attempted to model generative AI adoption using established theories (TAM, DOI, SCT) but found several hypotheses unsupported and lacked detailed insights into *how* factors influenced adoption. Overall, existing literature lacked a comprehensive understanding of the roles practitioners and organizations play in adoption, and what specific actions organizations could take to increase AI tool usage. This paper aims to fill this gap by providing deeper, theory-driven insights.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The study employs a mixed-methods approach, primarily utilizing Socio-Technical Grounded Theory (STGT) \\cite{li2024voc}. This iterative research method is well-suited for developing deep understandings from qualitative data in technology-intensive domains like software engineering. The STGT process involved basic data collection and analysis, followed by an advanced stage of theory development, and finally a validation stage.\n    *   **Novelty/Difference:** The innovation lies in applying a full STGT methodology, combined with a large-scale validation survey, to develop a novel, empirically grounded theory of AI Tool Adoption. Unlike prior work that often relied on preliminary models or focused on specific aspects (e.g., usability), this study systematically identifies and analyzes a comprehensive set of individual and organizational motives and challenges, and crucially, the interleaved \"push-pull\" relationships between them. It also significantly expands on previous adoption studies by involving a much larger number of participants for validation.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:** The primary contribution is the development of a \"Theory of AI Tool Adoption\" grounded in empirical data.\n    *   **System Design or Architectural Innovations:** Not applicable in the traditional sense, as this is a qualitative/mixed-methods study in software engineering research. The innovation is in the *theoretical model* and its empirical derivation.\n    *   **Theoretical Insights or Analysis:**\n        *   Identification and analysis of **2 individual motive factors** that increase AI tool use and adoption.\n        *   Identification and analysis of **4 individual challenge factors** that limit AI tool use and adoption.\n        *   Identification and analysis of **3 organizational motive factors** that increase AI tool use and adoption.\n        *   Identification and analysis of **3 organizational challenge factors** that limit AI tool use and adoption.\n        *   Identification and analysis of **3 interleaved push-pull relationships** between these motives and challenges, explaining how they interact to influence adoption.\n        *   Provision of recommendations for practitioners to navigate these challenges.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** A mixed-methods study was conducted in two main phases:\n        *   **Qualitative Phase:** 26 semi-structured interviews were conducted with diverse software practitioners (e.g., software engineers, DevOps, tech leads) from various organizational sizes and geographic locations, across three iterative rounds of data collection and analysis.\n        *   **Quantitative Validation Phase:** A survey was administered to 395 respondents to validate the theoretical categories and relationships derived from the qualitative phase.\n    *   **Key Performance Metrics & Comparison Results:** The validation focused on confirming the identified motives, challenges, and their relationships. The paper states that the theory was developed and validated, offering deeper insights into how organizations can support usage and adoption, improving upon previous preliminary models. Specific quantitative results from the survey validating each factor or relationship are not detailed in the provided excerpt but are implied by the validation stage.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations or Assumptions:** The provided excerpt does not explicitly detail specific technical limitations or assumptions of *this* study. However, as a grounded theory study, its findings are context-dependent and may require further validation in different organizational or cultural settings.\n    *   **Scope of Applicability:** The study focuses on AI tool use and adoption in software development by individuals and organizations. The developed theory is applicable to understanding and guiding strategies for increasing AI tool adoption within this domain.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This study significantly advances the technical state-of-the-art in software engineering research by providing a novel, empirically grounded theory of AI tool adoption. It moves beyond descriptive studies of usability or productivity to offer a comprehensive, actionable framework of interacting factors influencing adoption.\n    *   **Potential Impact on Future Research:** The identified motives, challenges, and their push-pull relationships provide a robust foundation for future research. It can inform the design of interventions, training programs, and organizational policies aimed at fostering AI tool adoption. It also opens avenues for quantitative studies to further test and refine the proposed theoretical model across different contexts and populations.",
    "intriguing_abstract": "The rapid integration of AI tools like Copilot and ChatGPT is reshaping software development, yet organizations struggle to effectively foster their widespread adoption. While benefits are evident, a critical gap persists in understanding the intricate individual and organizational dynamics driving or hindering this transformation. This paper addresses this by presenting a novel, empirically grounded **Theory of AI Tool Adoption** in software development.\n\nEmploying a rigorous **Socio-Technical Grounded Theory** (STGT) approach, validated through 26 qualitative interviews and a large-scale survey of 395 practitioners, we uncover a comprehensive set of **individual and organizational motive and challenge factors**. Crucially, we identify and analyze three **interleaved 'push-pull' relationships** that explain how these factors interact to influence adoption. Our findings move beyond superficial observations, providing deep, actionable insights into the complex interplay of human and organizational elements. This theory offers a robust framework for practitioners and organizations to strategically navigate adoption hurdles, maximize AI tool utilization, and significantly advance the state-of-the-art in software engineering research and practice.",
    "keywords": [
      "AI tool adoption",
      "software development",
      "Socio-Technical Grounded Theory (STGT)",
      "mixed-methods approach",
      "Theory of AI Tool Adoption",
      "empirically grounded theory",
      "individual motive factors",
      "individual challenge factors",
      "organizational motive factors",
      "organizational challenge factors",
      "push-pull relationships",
      "AI assistance tools",
      "software practitioners",
      "actionable framework"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/28c67bda234f006fc174e8ded3490c21b57bc79b.pdf",
    "citation_key": "li2024voc",
    "metadata": {
      "title": "AI Tool Use and Adoption in Software Development by Individuals and Organizations: A Grounded Theory Study",
      "authors": [
        "Ze Shi Li",
        "Nowshin Nawar Arony",
        "Ahmed Musa Awon",
        "Daniela E. Damian",
        "Bowen Xu"
      ],
      "published_date": "2024",
      "abstract": "AI assistance tools such as ChatGPT, Copilot, and Gemini have dramatically impacted the nature of software development in recent years. Numerous studies have studied the positive benefits that practitioners have achieved from using these tools in their work. While there is a growing body of knowledge regarding the usability aspects of leveraging AI tools, we still lack concrete details on the issues that organizations and practitioners need to consider should they want to explore increasing adoption or use of AI tools. In this study, we conducted a mixed methods study involving interviews with 26 industry practitioners and 395 survey respondents. We found that there are several motives and challenges that impact individuals and organizations and developed a theory of AI Tool Adoption. For example, we found creating a culture of sharing of AI best practices and tips as a key motive for practitioners' adopting and using AI tools. In total, we identified 2 individual motives, 4 individual challenges, 3 organizational motives, and 3 organizational challenges, and 3 interleaved relationships. The 3 interleaved relationships act in a push-pull manner where motives pull practitioners to increase the use of AI tools and challenges push practitioners away from using AI tools.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/28c67bda234f006fc174e8ded3490c21b57bc79b.pdf",
      "venue": "arXiv.org",
      "citationCount": 8,
      "score": 8.0,
      "summary": "Here's a focused summary of the paper \"AI Tool Use and Adoption in Software Development by Individuals and Organizations: A Grounded Theory Study\" \\cite{li2024voc} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the lack of concrete details regarding the issues organizations and practitioners face when exploring or increasing the adoption and use of AI assistance tools (e.g., ChatGPT, Copilot, Gemini) in software development.\n    *   **Importance & Challenge:** While AI tools have significantly impacted software development and numerous studies highlight their benefits and usability aspects, there is a critical gap in understanding the underlying motives and challenges that influence AI tool adoption at both individual and organizational levels. This lack of clarity hinders organizations from effectively increasing AI tool usage and fully realizing their potential benefits.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** Previous research has primarily focused on the usability of AI tools, their impact on developer productivity, code quality, trust, and ethical considerations \\cite{li2024voc}. Some studies explored how developers perceive and use tools like GitHub Copilot, identifying benefits (e.g., reducing search time) and limitations (e.g., debugging difficulty, code quality issues).\n    *   **Limitations of Previous Solutions:** A recent study by Russo \\cite{li2024voc} attempted to model generative AI adoption using established theories (TAM, DOI, SCT) but found several hypotheses unsupported and lacked detailed insights into *how* factors influenced adoption. Overall, existing literature lacked a comprehensive understanding of the roles practitioners and organizations play in adoption, and what specific actions organizations could take to increase AI tool usage. This paper aims to fill this gap by providing deeper, theory-driven insights.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method:** The study employs a mixed-methods approach, primarily utilizing Socio-Technical Grounded Theory (STGT) \\cite{li2024voc}. This iterative research method is well-suited for developing deep understandings from qualitative data in technology-intensive domains like software engineering. The STGT process involved basic data collection and analysis, followed by an advanced stage of theory development, and finally a validation stage.\n    *   **Novelty/Difference:** The innovation lies in applying a full STGT methodology, combined with a large-scale validation survey, to develop a novel, empirically grounded theory of AI Tool Adoption. Unlike prior work that often relied on preliminary models or focused on specific aspects (e.g., usability), this study systematically identifies and analyzes a comprehensive set of individual and organizational motives and challenges, and crucially, the interleaved \"push-pull\" relationships between them. It also significantly expands on previous adoption studies by involving a much larger number of participants for validation.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:** The primary contribution is the development of a \"Theory of AI Tool Adoption\" grounded in empirical data.\n    *   **System Design or Architectural Innovations:** Not applicable in the traditional sense, as this is a qualitative/mixed-methods study in software engineering research. The innovation is in the *theoretical model* and its empirical derivation.\n    *   **Theoretical Insights or Analysis:**\n        *   Identification and analysis of **2 individual motive factors** that increase AI tool use and adoption.\n        *   Identification and analysis of **4 individual challenge factors** that limit AI tool use and adoption.\n        *   Identification and analysis of **3 organizational motive factors** that increase AI tool use and adoption.\n        *   Identification and analysis of **3 organizational challenge factors** that limit AI tool use and adoption.\n        *   Identification and analysis of **3 interleaved push-pull relationships** between these motives and challenges, explaining how they interact to influence adoption.\n        *   Provision of recommendations for practitioners to navigate these challenges.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted:** A mixed-methods study was conducted in two main phases:\n        *   **Qualitative Phase:** 26 semi-structured interviews were conducted with diverse software practitioners (e.g., software engineers, DevOps, tech leads) from various organizational sizes and geographic locations, across three iterative rounds of data collection and analysis.\n        *   **Quantitative Validation Phase:** A survey was administered to 395 respondents to validate the theoretical categories and relationships derived from the qualitative phase.\n    *   **Key Performance Metrics & Comparison Results:** The validation focused on confirming the identified motives, challenges, and their relationships. The paper states that the theory was developed and validated, offering deeper insights into how organizations can support usage and adoption, improving upon previous preliminary models. Specific quantitative results from the survey validating each factor or relationship are not detailed in the provided excerpt but are implied by the validation stage.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations or Assumptions:** The provided excerpt does not explicitly detail specific technical limitations or assumptions of *this* study. However, as a grounded theory study, its findings are context-dependent and may require further validation in different organizational or cultural settings.\n    *   **Scope of Applicability:** The study focuses on AI tool use and adoption in software development by individuals and organizations. The developed theory is applicable to understanding and guiding strategies for increasing AI tool adoption within this domain.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This study significantly advances the technical state-of-the-art in software engineering research by providing a novel, empirically grounded theory of AI tool adoption. It moves beyond descriptive studies of usability or productivity to offer a comprehensive, actionable framework of interacting factors influencing adoption.\n    *   **Potential Impact on Future Research:** The identified motives, challenges, and their push-pull relationships provide a robust foundation for future research. It can inform the design of interventions, training programs, and organizational policies aimed at fostering AI tool adoption. It also opens avenues for quantitative studies to further test and refine the proposed theoretical model across different contexts and populations.",
      "keywords": [
        "AI tool adoption",
        "software development",
        "Socio-Technical Grounded Theory (STGT)",
        "mixed-methods approach",
        "Theory of AI Tool Adoption",
        "empirically grounded theory",
        "individual motive factors",
        "individual challenge factors",
        "organizational motive factors",
        "organizational challenge factors",
        "push-pull relationships",
        "AI assistance tools",
        "software practitioners",
        "actionable framework"
      ],
      "paper_type": "**empirical**\n\n**reasoning:**\n\nthe abstract and introduction clearly indicate that this paper presents a data-driven study. key phrases and elements supporting this classification include:\n\n*   **\"we conducted a study following socio-technical grounded theory (stgt)\"**: this explicitly states the research methodology, which is a qualitative empirical approach focused on generating theory from data.\n*   **\"we conducted 26 interviews with diverse software practitioners\"**: details the primary data collection method and the number of participants.\n*   **\"we also conducted a round of theoretical category and relationship validation through a survey with 395 respondents\"**: mentions a second data collection method (survey) with a significant number of participants for validation.\n*   **\"our work improves on russo’s preliminary work by surveying a significantly higher number of participants and developing our theory from semi-structured interviews, offering deeper insights...\"**: highlights the empirical nature and the scale of their data collection.\n*   **\"we also developed a theory of motives and challenges for adopting and using ai tool(s) from both an individual and organizational level.\"**: the outcome is a theory, but it is *derived from empirical data*, not purely theoretical derivation.\n*   **contributions listed**: \"identification and analysis of motivation,\" \"identification and analysis of challenges,\" \"identification and analysis of relationships and recommendations to practitioners\" – these are all findings resulting from the conducted study.\n*   **methodology section (section 3)**: explicitly details the stgt method, including data collection (interviews, surveys), analysis steps (coding, memoing, constant comparison), and validation.\n*   **related work (section 2)**: while it reviews other studies, it does so to establish a research gap for *its own* empirical investigation, not as its primary purpose of being a survey paper itself.\n\nthe paper focuses on collecting and analyzing data (interviews, surveys) to understand a phenomenon (ai tool adoption) and generate a theory based on these observations, which is the hallmark of an empirical study."
    },
    "file_name": "28c67bda234f006fc174e8ded3490c21b57bc79b.pdf"
  },
  {
    "success": true,
    "doc_id": "14d5d98e39b9135d718a8e931c2e86a2",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper investigates the impact of generative AI (specifically AI pair programmers like GitHub Copilot) on collaborative open-source software (OSS) development, focusing on project-level code contributions and coordination time for code integration \\cite{song20241ql}.\n    *   **Importance and Challenge**: This problem is crucial because generative AI is transforming content production, including coding, but its role in complex, team-based, and voluntarily collaborative environments like OSS is poorly understood. Challenges include:\n        *   Translating individual productivity gains to project-level outcomes, which involve both individual contribution intensity and developer participation.\n        *   Understanding how AI affects coordination efficiency in decentralized OSS settings, where coordination is informal and fluid.\n        *   Identifying differential impacts on distinct developer roles (core vs. peripheral) given their varying project familiarity, which differs from skill-based heterogeneity studied previously.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Prior work primarily focused on generative AI's impact on individual developer productivity for discrete tasks (e.g., faster coding, fewer errors) \\cite{song20241ql}. Some studies explored AI's effect on participation in Q&A communities (often showing a reduction) or coordination in fixed-size teams with formal processes.\n    *   **Limitations of Previous Solutions**:\n        *   Limited understanding of generative AI's influence on *project-level* outcomes in complex, collaborative tasks involving multiple developers.\n        *   Lack of clarity on how AI affects *voluntary participation* in OSS, which differs from information exchange communities.\n        *   Insufficient research on how AI shapes *coordination time* in fluid, decentralized OSS teams, especially regarding the integration of heterogeneous contributions.\n        *   Previous heterogeneity studies focused on skill levels; they did not address the distinction between core and peripheral developers based on *project familiarity* in OSS.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The study employs a quasi-experimental design using the Generalized Synthetic Control Method (GSCM) to estimate the causal impact of GitHub Copilot adoption on OSS projects \\cite{song20241ql}. This method constructs a synthetic control group from untreated repositories to mimic the pre-treatment trends of treated repositories, allowing for robust causal inference in an observational setting.\n    *   **Novelty/Difference**:\n        *   **Empirical Scope**: It's among the first to analyze the impact of generative AI on *project-level* outcomes (contributions and coordination) in *collaborative OSS development*, moving beyond individual task performance.\n        *   **Data Integration**: Leverages a unique combination of proprietary GitHub Copilot usage data and public GitHub OSS repository data, providing a rich, real-world dataset for analysis.\n        *   **Focus on Coordination**: Explicitly investigates coordination time for code integration, an understudied aspect of AI's impact in collaborative environments.\n        *   **Developer Role Heterogeneity**: Examines the differential effects on core versus peripheral developers, introducing \"project familiarity\" as a key moderating factor, contrasting with prior skill-based analyses.\n\n*   **Key Technical Contributions**\n    *   **Novel Methods/Techniques**: Application of the Generalized Synthetic Control Method (GSCM) to a complex, large-scale observational dataset of OSS projects to infer causal effects of generative AI adoption.\n    *   **Empirical Insights**:\n        *   Demonstrates a dual effect of AI pair programmers: increasing project-level code contributions while simultaneously increasing coordination time for integration \\cite{song20241ql}.\n        *   Uncovers that AI encourages *more participation* in OSS development (both coding and non-coding discussions), contrasting with findings from Q&A communities.\n        *   Reveals that the increase in coordination time is driven by a higher volume, broader participation, and greater intensity of code discussions.\n        *   Identifies a significant heterogeneity: peripheral developers experience smaller gains in contributions and a larger increase in coordination time compared to core developers, attributed to differences in project familiarity.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: A quasi-experimental study analyzing GitHub Copilot adoption in OSS repositories over a sample period from January 2021 to December 2022 \\cite{song20241ql}.\n    *   **Data**: Proprietary GitHub Copilot usage data combined with publicly available OSS repository data from GitHub. The unit of analysis is repository-month.\n    *   **Key Performance Metrics**:\n        *   Project-level code contributions (e.g., number of commits, lines of code).\n        *   Individual code contributions and developer coding participation.\n        *   Coordination time for code integration (time to merge pull requests).\n        *   Metrics related to code discussions (volume, breadth of participants, intensity).\n    *   **Comparison Results**:\n        *   Copilot use is associated with a **5.9% increase** in project-level code contributions.\n        *   This gain is driven by a **2.1% increase** in individual code contributions and a **3.4% rise** in developer coding participation.\n        *   However, coordination time for code integration increases by **8%**.\n        *   The net effect on overall project-level productivity (contributions with timely integration) remains positive.\n        *   Peripheral developers show relatively smaller gains in project-level code contributions and face a higher increase in coordination time than core developers.\n    *   **Robustness**: Results are validated through alternative matching techniques and a comprehensive set of robustness checks.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: While GSCM is robust for causal inference in observational studies, it relies on the assumption that the synthetic control adequately represents the counterfactual. The study focuses on GitHub Copilot, and findings may not directly generalize to all generative AI tools or other development platforms.\n    *   **Scope of Applicability**: The findings are specific to collaborative open-source software development on GitHub. Generalizability to proprietary software development or other forms of online collaboration might require further investigation. The paper also notes that generative AI tools have \"limited ability... to learn the project’s full context,\" which influences their effectiveness for peripheral developers \\cite{song20241ql}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**:\n        *   Provides novel empirical evidence that generative AI can *increase* voluntary participation in OSS (both coding and non-coding activities), challenging prior findings from Q&A communities \\cite{song20241ql}.\n        *   Uncovers an unexpected impact: AI tools, by encouraging more discussion, can *increase coordination time* in team-based collaboration, extending the understanding of AI's role beyond simple convergence.\n        *   Offers a new perspective on heterogeneity, demonstrating that in complex tasks requiring contextual knowledge, peripheral developers (with lower project familiarity) may gain *less* productivity from AI pair programmers than core developers, contrasting with skill-based findings.\n    *   **Potential Impact on Future Research**: The study highlights the dual nature of AI in collaborative development, prompting further research into optimizing the balance between contribution gains and coordination overhead. It also opens avenues for exploring how AI tools could be designed to better support developers with varying levels of project familiarity and contextual knowledge, potentially influencing the long-term structure and dynamics of OSS communities.",
    "intriguing_abstract": "Generative AI, particularly AI pair programmers like GitHub Copilot, is rapidly transforming individual coding practices, yet its profound impact on complex, collaborative Open-Source Software (OSS) development at the project level remains largely unexplored. This paper presents a novel quasi-experimental study, leveraging the Generalized Synthetic Control Method (GSCM) on a unique dataset combining proprietary Copilot usage with public GitHub repository data, to causally estimate these critical effects.\n\nWe uncover a fascinating dual impact: Copilot significantly boosts project-level code contributions by 5.9% and increases developer participation, challenging assumptions from other online communities. However, this surge in activity comes with an 8% increase in coordination time for code integration, driven by a higher volume and intensity of code discussions. Crucially, we reveal significant heterogeneity: peripheral developers, with less project familiarity, experience smaller contribution gains and disproportionately higher coordination overhead compared to core developers. Our findings provide critical empirical insights into the nuanced role of generative AI in collaborative coding, highlighting the urgent need for AI tools that balance productivity with efficient coordination and better support diverse developer roles in the evolving landscape of OSS.",
    "keywords": [
      "Generative AI",
      "GitHub Copilot",
      "Open-source software (OSS) development",
      "Project-level code contributions",
      "Coordination time",
      "Generalized Synthetic Control Method (GSCM)",
      "Quasi-experimental design",
      "Causal inference",
      "Developer participation",
      "Core vs. peripheral developers",
      "Project familiarity",
      "Code integration",
      "Dual effect of AI"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/712171098cc0bf2280fdf0cec1d803d6db05e18f.pdf",
    "citation_key": "song20241ql",
    "metadata": {
      "title": "The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot",
      "authors": [
        "Fangchen Song",
        "Ashish Agarwal",
        "Wen Wen"
      ],
      "published_date": "2024",
      "abstract": "Generative artificial intelligence (AI) enables automated content production, including coding in software development, which can significantly influence developer participation and performance. To explore its impact on collaborative open-source software (OSS) development, we investigate the role of GitHub Copilot, a generative AI pair programmer, in OSS development where multiple distributed developers voluntarily collaborate. Using GitHub's proprietary Copilot usage data, combined with public OSS repository data obtained from GitHub, we find that Copilot use increases project-level code contributions by 5.9%. This gain is driven by a 2.1% increase in individual code contributions and a 3.4% rise in developer coding participation. However, these benefits come at a cost as coordination time for code integration increases by 8% due to more code discussions enabled by AI pair programmers. This reveals an important tradeoff: While AI expands who can contribute and how much they contribute, it slows coordination in collective development efforts. Despite this tension, the combined effect of these two competing forces remains positive, indicating a net gain in overall project-level productivity from using AI pair programmers. Interestingly, we also find the effects differ across developer roles. Peripheral developers show relatively smaller gains in project-level code contributions and face a higher increase in coordination time than core developers, likely due to the difference in their project familiarity. In summary, our study underscores the dual role of AI pair programmers in affecting project-level code contributions and coordination time in OSS development. Our findings on the differential effects between core and peripheral developers also provide important implications for the structure of OSS communities in the long run.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/712171098cc0bf2280fdf0cec1d803d6db05e18f.pdf",
      "venue": "Social Science Research Network",
      "citationCount": 8,
      "score": 8.0,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper investigates the impact of generative AI (specifically AI pair programmers like GitHub Copilot) on collaborative open-source software (OSS) development, focusing on project-level code contributions and coordination time for code integration \\cite{song20241ql}.\n    *   **Importance and Challenge**: This problem is crucial because generative AI is transforming content production, including coding, but its role in complex, team-based, and voluntarily collaborative environments like OSS is poorly understood. Challenges include:\n        *   Translating individual productivity gains to project-level outcomes, which involve both individual contribution intensity and developer participation.\n        *   Understanding how AI affects coordination efficiency in decentralized OSS settings, where coordination is informal and fluid.\n        *   Identifying differential impacts on distinct developer roles (core vs. peripheral) given their varying project familiarity, which differs from skill-based heterogeneity studied previously.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Prior work primarily focused on generative AI's impact on individual developer productivity for discrete tasks (e.g., faster coding, fewer errors) \\cite{song20241ql}. Some studies explored AI's effect on participation in Q&A communities (often showing a reduction) or coordination in fixed-size teams with formal processes.\n    *   **Limitations of Previous Solutions**:\n        *   Limited understanding of generative AI's influence on *project-level* outcomes in complex, collaborative tasks involving multiple developers.\n        *   Lack of clarity on how AI affects *voluntary participation* in OSS, which differs from information exchange communities.\n        *   Insufficient research on how AI shapes *coordination time* in fluid, decentralized OSS teams, especially regarding the integration of heterogeneous contributions.\n        *   Previous heterogeneity studies focused on skill levels; they did not address the distinction between core and peripheral developers based on *project familiarity* in OSS.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The study employs a quasi-experimental design using the Generalized Synthetic Control Method (GSCM) to estimate the causal impact of GitHub Copilot adoption on OSS projects \\cite{song20241ql}. This method constructs a synthetic control group from untreated repositories to mimic the pre-treatment trends of treated repositories, allowing for robust causal inference in an observational setting.\n    *   **Novelty/Difference**:\n        *   **Empirical Scope**: It's among the first to analyze the impact of generative AI on *project-level* outcomes (contributions and coordination) in *collaborative OSS development*, moving beyond individual task performance.\n        *   **Data Integration**: Leverages a unique combination of proprietary GitHub Copilot usage data and public GitHub OSS repository data, providing a rich, real-world dataset for analysis.\n        *   **Focus on Coordination**: Explicitly investigates coordination time for code integration, an understudied aspect of AI's impact in collaborative environments.\n        *   **Developer Role Heterogeneity**: Examines the differential effects on core versus peripheral developers, introducing \"project familiarity\" as a key moderating factor, contrasting with prior skill-based analyses.\n\n*   **Key Technical Contributions**\n    *   **Novel Methods/Techniques**: Application of the Generalized Synthetic Control Method (GSCM) to a complex, large-scale observational dataset of OSS projects to infer causal effects of generative AI adoption.\n    *   **Empirical Insights**:\n        *   Demonstrates a dual effect of AI pair programmers: increasing project-level code contributions while simultaneously increasing coordination time for integration \\cite{song20241ql}.\n        *   Uncovers that AI encourages *more participation* in OSS development (both coding and non-coding discussions), contrasting with findings from Q&A communities.\n        *   Reveals that the increase in coordination time is driven by a higher volume, broader participation, and greater intensity of code discussions.\n        *   Identifies a significant heterogeneity: peripheral developers experience smaller gains in contributions and a larger increase in coordination time compared to core developers, attributed to differences in project familiarity.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: A quasi-experimental study analyzing GitHub Copilot adoption in OSS repositories over a sample period from January 2021 to December 2022 \\cite{song20241ql}.\n    *   **Data**: Proprietary GitHub Copilot usage data combined with publicly available OSS repository data from GitHub. The unit of analysis is repository-month.\n    *   **Key Performance Metrics**:\n        *   Project-level code contributions (e.g., number of commits, lines of code).\n        *   Individual code contributions and developer coding participation.\n        *   Coordination time for code integration (time to merge pull requests).\n        *   Metrics related to code discussions (volume, breadth of participants, intensity).\n    *   **Comparison Results**:\n        *   Copilot use is associated with a **5.9% increase** in project-level code contributions.\n        *   This gain is driven by a **2.1% increase** in individual code contributions and a **3.4% rise** in developer coding participation.\n        *   However, coordination time for code integration increases by **8%**.\n        *   The net effect on overall project-level productivity (contributions with timely integration) remains positive.\n        *   Peripheral developers show relatively smaller gains in project-level code contributions and face a higher increase in coordination time than core developers.\n    *   **Robustness**: Results are validated through alternative matching techniques and a comprehensive set of robustness checks.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: While GSCM is robust for causal inference in observational studies, it relies on the assumption that the synthetic control adequately represents the counterfactual. The study focuses on GitHub Copilot, and findings may not directly generalize to all generative AI tools or other development platforms.\n    *   **Scope of Applicability**: The findings are specific to collaborative open-source software development on GitHub. Generalizability to proprietary software development or other forms of online collaboration might require further investigation. The paper also notes that generative AI tools have \"limited ability... to learn the project’s full context,\" which influences their effectiveness for peripheral developers \\cite{song20241ql}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**:\n        *   Provides novel empirical evidence that generative AI can *increase* voluntary participation in OSS (both coding and non-coding activities), challenging prior findings from Q&A communities \\cite{song20241ql}.\n        *   Uncovers an unexpected impact: AI tools, by encouraging more discussion, can *increase coordination time* in team-based collaboration, extending the understanding of AI's role beyond simple convergence.\n        *   Offers a new perspective on heterogeneity, demonstrating that in complex tasks requiring contextual knowledge, peripheral developers (with lower project familiarity) may gain *less* productivity from AI pair programmers than core developers, contrasting with skill-based findings.\n    *   **Potential Impact on Future Research**: The study highlights the dual nature of AI in collaborative development, prompting further research into optimizing the balance between contribution gains and coordination overhead. It also opens avenues for exploring how AI tools could be designed to better support developers with varying levels of project familiarity and contextual knowledge, potentially influencing the long-term structure and dynamics of OSS communities.",
      "keywords": [
        "Generative AI",
        "GitHub Copilot",
        "Open-source software (OSS) development",
        "Project-level code contributions",
        "Coordination time",
        "Generalized Synthetic Control Method (GSCM)",
        "Quasi-experimental design",
        "Causal inference",
        "Developer participation",
        "Core vs. peripheral developers",
        "Project familiarity",
        "Code integration",
        "Dual effect of AI"
      ],
      "paper_type": "this paper is best classified as **empirical**.\n\nhere's why:\n\n*   **abstract mentions:** \"investigate the role of github copilot,\" \"using github's proprietary copilot usage data, combined with public oss repository data,\" \"we find that copilot use increases project-level code contributions by 5.9%,\" \"this gain is driven by a 2.1% increase... and a 3.4% rise...\", \"coordination time... increases by 8%,\" \"our study underscores the dual role of ai pair programmers.\" these are all hallmarks of a data-driven study with quantitative findings.\n*   **introduction discusses:** identifies a research gap (\"limited understanding on the role of generative ai in complex tasks that involve team collaboration\") which an empirical study would aim to fill.\n*   **keywords:** \"project-level code contributions,\" \"coordination time,\" \"core developers,\" \"peripheral developers\" are all variables being measured and analyzed.\n\nthe paper clearly describes a study that collects and analyzes data to draw conclusions about the impact of a specific technology (github copilot) on a real-world phenomenon (open-source software development)."
    },
    "file_name": "712171098cc0bf2280fdf0cec1d803d6db05e18f.pdf"
  },
  {
    "success": true,
    "doc_id": "84eaacc8565a59172ad5c4d271d149bc",
    "summary": "The bioinformatics software for analyzing biomedical data is essential for converting raw data into meaningful biological insights. In this review, we outline the key stages and considerations in the development of bioinformatics software, using clusterProfiler and CIRCexplorer2 as illustrative examples. Furthermore, we examine some established large-scale life sciences platforms and summarize the design principles in the era of big data and Artificial Intelligence (AI) for open science. Future large-scale platforms are expected to offer graphical programming languages and transition from the sharing of data and codes to that of physical resources. The AI revolution will alter the landscape of bioinformatics software development and redefine the research paradigm of life sciences.\n",
    "intriguing_abstract": "The bioinformatics software for analyzing biomedical data is essential for converting raw data into meaningful biological insights. In this review, we outline the key stages and considerations in the development of bioinformatics software, using clusterProfiler and CIRCexplorer2 as illustrative examples. Furthermore, we examine some established large-scale life sciences platforms and summarize the design principles in the era of big data and Artificial Intelligence (AI) for open science. Future large-scale platforms are expected to offer graphical programming languages and transition from the sharing of data and codes to that of physical resources. The AI revolution will alter the landscape of bioinformatics software development and redefine the research paradigm of life sciences.\n",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6c1676fc009d9aa0f419de874fb5f86f9efba92f.pdf",
    "citation_key": "ma202418v",
    "metadata": {
      "title": "Bioinformatics software development: Principles and future directions",
      "authors": [
        "Xu-Kai Ma",
        "Yan Yu",
        "Tao Huang",
        "Dake Zhang",
        "Caihuan Tian",
        "Wenli Tang",
        "Ming Luo",
        "Pufeng Du",
        "Guangchuang Yu",
        "Li Yang"
      ],
      "published_date": "2024",
      "abstract": "The bioinformatics software for analyzing biomedical data is essential for converting raw data into meaningful biological insights. In this review, we outline the key stages and considerations in the development of bioinformatics software, using clusterProfiler and CIRCexplorer2 as illustrative examples. Furthermore, we examine some established large-scale life sciences platforms and summarize the design principles in the era of big data and Artificial Intelligence (AI) for open science. Future large-scale platforms are expected to offer graphical programming languages and transition from the sharing of data and codes to that of physical resources. The AI revolution will alter the landscape of bioinformatics software development and redefine the research paradigm of life sciences.\n",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6c1676fc009d9aa0f419de874fb5f86f9efba92f.pdf",
      "venue": "The Innovation Life",
      "citationCount": 8,
      "score": 8.0,
      "summary": "The bioinformatics software for analyzing biomedical data is essential for converting raw data into meaningful biological insights. In this review, we outline the key stages and considerations in the development of bioinformatics software, using clusterProfiler and CIRCexplorer2 as illustrative examples. Furthermore, we examine some established large-scale life sciences platforms and summarize the design principles in the era of big data and Artificial Intelligence (AI) for open science. Future large-scale platforms are expected to offer graphical programming languages and transition from the sharing of data and codes to that of physical resources. The AI revolution will alter the landscape of bioinformatics software development and redefine the research paradigm of life sciences.\n",
      "keywords": []
    },
    "file_name": "6c1676fc009d9aa0f419de874fb5f86f9efba92f.pdf"
  },
  {
    "success": true,
    "doc_id": "be75a7da136ed18f84c1cd1b4d264a33",
    "summary": "Testing software has a higher level of difficulty because of the variations in users’ behaviors, decreasing time of software development, and the demand for prototypical testing. It becomes almost impossible to apply traditional approaches in determining the software’s dynamic environment or its ability to capture different users’ interactions. Introducing to this paper is the hybrid model of Generative AI and RL to model realistic user behaviors whilst modulating to software responses as well. Specifically, in this paper, we discuss the US context by tackling several challenges specific to the regional context of the demographic diversity, the widespread use of Agile/DevOps methodologies and frameworks, and the demand for the highest levels of quality in software testing. The combination of Generative AI for behavior variety with RL for learning makes the given methodology a continuous feedback process for the sake of thorough and realistic behavioral testing. This is well illustrated by real-life applications in areas like e-commerce, healthcare and banking to mention but a few where the model provides robust results terms of identifying difficult to detect faults, test effectiveness and cost benefit analysis. They plan to co-designing federated learning for privacy-preserving testing in the future, as well as leveraging more cross-cultural user simulations that have global application.",
    "intriguing_abstract": "Testing software has a higher level of difficulty because of the variations in users’ behaviors, decreasing time of software development, and the demand for prototypical testing. It becomes almost impossible to apply traditional approaches in determining the software’s dynamic environment or its ability to capture different users’ interactions. Introducing to this paper is the hybrid model of Generative AI and RL to model realistic user behaviors whilst modulating to software responses as well. Specifically, in this paper, we discuss the US context by tackling several challenges specific to the regional context of the demographic diversity, the widespread use of Agile/DevOps methodologies and frameworks, and the demand for the highest levels of quality in software testing. The combination of Generative AI for behavior variety with RL for learning makes the given methodology a continuous feedback process for the sake of thorough and realistic behavioral testing. This is well illustrated by real-life applications in areas like e-commerce, healthcare and banking to mention but a few where the model provides robust results terms of identifying difficult to detect faults, test effectiveness and cost benefit analysis. They plan to co-designing federated learning for privacy-preserving testing in the future, as well as leveraging more cross-cultural user simulations that have global application.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/49ebf1312fcee06497422ce325756e769beb7e40.pdf",
    "citation_key": "islam2024w14",
    "metadata": {
      "title": "Transforming Software Testing in the US: Generative AI Models for Realistic User Simulation",
      "authors": [
        "S. M. Islam",
        "Md Shadikul Bari",
        "Ankur Sarkar"
      ],
      "published_date": "2024",
      "abstract": "Testing software has a higher level of difficulty because of the variations in users’ behaviors, decreasing time of software development, and the demand for prototypical testing. It becomes almost impossible to apply traditional approaches in determining the software’s dynamic environment or its ability to capture different users’ interactions. Introducing to this paper is the hybrid model of Generative AI and RL to model realistic user behaviors whilst modulating to software responses as well. Specifically, in this paper, we discuss the US context by tackling several challenges specific to the regional context of the demographic diversity, the widespread use of Agile/DevOps methodologies and frameworks, and the demand for the highest levels of quality in software testing. The combination of Generative AI for behavior variety with RL for learning makes the given methodology a continuous feedback process for the sake of thorough and realistic behavioral testing. This is well illustrated by real-life applications in areas like e-commerce, healthcare and banking to mention but a few where the model provides robust results terms of identifying difficult to detect faults, test effectiveness and cost benefit analysis. They plan to co-designing federated learning for privacy-preserving testing in the future, as well as leveraging more cross-cultural user simulations that have global application.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/49ebf1312fcee06497422ce325756e769beb7e40.pdf",
      "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
      "citationCount": 8,
      "score": 8.0,
      "summary": "Testing software has a higher level of difficulty because of the variations in users’ behaviors, decreasing time of software development, and the demand for prototypical testing. It becomes almost impossible to apply traditional approaches in determining the software’s dynamic environment or its ability to capture different users’ interactions. Introducing to this paper is the hybrid model of Generative AI and RL to model realistic user behaviors whilst modulating to software responses as well. Specifically, in this paper, we discuss the US context by tackling several challenges specific to the regional context of the demographic diversity, the widespread use of Agile/DevOps methodologies and frameworks, and the demand for the highest levels of quality in software testing. The combination of Generative AI for behavior variety with RL for learning makes the given methodology a continuous feedback process for the sake of thorough and realistic behavioral testing. This is well illustrated by real-life applications in areas like e-commerce, healthcare and banking to mention but a few where the model provides robust results terms of identifying difficult to detect faults, test effectiveness and cost benefit analysis. They plan to co-designing federated learning for privacy-preserving testing in the future, as well as leveraging more cross-cultural user simulations that have global application.",
      "keywords": []
    },
    "file_name": "49ebf1312fcee06497422ce325756e769beb7e40.pdf"
  },
  {
    "success": true,
    "doc_id": "0d6bbeb701753f1219d4e868f6da3091",
    "summary": "This paper is an opinion paper that looks at the future of computing in the age of Generative \\&Agentic AI. Current software systems are static and inflexible, leading to significant challenges in translating human goals into computational actions.\"Living software systems\"powered by generative AI offer a solution to this fundamental problem in computing. Traditional software development involves multiple layers of imperfect translation, from business requirements to code, resulting in rigid systems that struggle to adapt to changing user needs and contexts. Generative AI, particularly large language models, can serve as a universal translator between human intent and computer operations. This approach enables the creation of more flexible, context-aware systems that can dynamically evolve to meet user goals. Two pathways for implementing living software systems are explored: using generative AI to accelerate traditional software development, and leveraging agentic AI to create truly adaptive systems. New skills like Prompt Engineering are necessary. By reimagining software as a living, adaptable entity, we can create computing interfaces that are more intuitive, powerful, and responsive to human needs.",
    "intriguing_abstract": "This paper is an opinion paper that looks at the future of computing in the age of Generative \\&Agentic AI. Current software systems are static and inflexible, leading to significant challenges in translating human goals into computational actions.\"Living software systems\"powered by generative AI offer a solution to this fundamental problem in computing. Traditional software development involves multiple layers of imperfect translation, from business requirements to code, resulting in rigid systems that struggle to adapt to changing user needs and contexts. Generative AI, particularly large language models, can serve as a universal translator between human intent and computer operations. This approach enables the creation of more flexible, context-aware systems that can dynamically evolve to meet user goals. Two pathways for implementing living software systems are explored: using generative AI to accelerate traditional software development, and leveraging agentic AI to create truly adaptive systems. New skills like Prompt Engineering are necessary. By reimagining software as a living, adaptable entity, we can create computing interfaces that are more intuitive, powerful, and responsive to human needs.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/beaf5966a00caac99a30071ecbb96556b4ba7e8f.pdf",
    "citation_key": "white2024dcc",
    "metadata": {
      "title": "Building Living Software Systems with Generative & Agentic AI",
      "authors": [
        "Jules White"
      ],
      "published_date": "2024",
      "abstract": "This paper is an opinion paper that looks at the future of computing in the age of Generative \\&Agentic AI. Current software systems are static and inflexible, leading to significant challenges in translating human goals into computational actions.\"Living software systems\"powered by generative AI offer a solution to this fundamental problem in computing. Traditional software development involves multiple layers of imperfect translation, from business requirements to code, resulting in rigid systems that struggle to adapt to changing user needs and contexts. Generative AI, particularly large language models, can serve as a universal translator between human intent and computer operations. This approach enables the creation of more flexible, context-aware systems that can dynamically evolve to meet user goals. Two pathways for implementing living software systems are explored: using generative AI to accelerate traditional software development, and leveraging agentic AI to create truly adaptive systems. New skills like Prompt Engineering are necessary. By reimagining software as a living, adaptable entity, we can create computing interfaces that are more intuitive, powerful, and responsive to human needs.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/beaf5966a00caac99a30071ecbb96556b4ba7e8f.pdf",
      "venue": "arXiv.org",
      "citationCount": 8,
      "score": 8.0,
      "summary": "This paper is an opinion paper that looks at the future of computing in the age of Generative \\&Agentic AI. Current software systems are static and inflexible, leading to significant challenges in translating human goals into computational actions.\"Living software systems\"powered by generative AI offer a solution to this fundamental problem in computing. Traditional software development involves multiple layers of imperfect translation, from business requirements to code, resulting in rigid systems that struggle to adapt to changing user needs and contexts. Generative AI, particularly large language models, can serve as a universal translator between human intent and computer operations. This approach enables the creation of more flexible, context-aware systems that can dynamically evolve to meet user goals. Two pathways for implementing living software systems are explored: using generative AI to accelerate traditional software development, and leveraging agentic AI to create truly adaptive systems. New skills like Prompt Engineering are necessary. By reimagining software as a living, adaptable entity, we can create computing interfaces that are more intuitive, powerful, and responsive to human needs.",
      "keywords": []
    },
    "file_name": "beaf5966a00caac99a30071ecbb96556b4ba7e8f.pdf"
  },
  {
    "success": true,
    "doc_id": "8fde64fc58388a6d459b0cfbdf865f98",
    "summary": "Software testing is a crucial phase in the software development lifecycle (SDLC), ensuring that products meet necessary functional, performance, and quality benchmarks before release. Despite advancements in automation, traditional methods of generating and validating test cases still face significant challenges, including prolonged timelines, human error, incomplete test coverage, and high costs of manual intervention. These limitations often lead to delayed product launches and undetected defects that compromise software quality and user satisfaction. The integration of artificial intelligence (AI) into software testing presents a promising solution to these persistent challenges. AI-driven testing methods automate the creation of comprehensive test cases, dynamically adapt to changes, and leverage machine learning to identify high-risk areas in the codebase. This approach enhances regression testing efficiency while expanding overall test coverage. Furthermore, AI-powered tools enable continuous testing and self-healing test cases, significantly reducing manual oversight and accelerating feedback loops, ultimately leading to faster and more reliable software releases. This paper explores the transformative potential of AI in improving test case generation and validation, focusing on its ability to enhance efficiency, accuracy, and scalability in testing processes. It also addresses key challenges associated with adapting AI for testing, including the need for high quality training data, ensuring model transparency, and maintaining a balance between automation and human oversight. Through case studies and examples of real-world applications, this paper illustrates how AI can significantly enhance testing efficiency across both legacy and modern software systems.",
    "intriguing_abstract": "Software testing is a crucial phase in the software development lifecycle (SDLC), ensuring that products meet necessary functional, performance, and quality benchmarks before release. Despite advancements in automation, traditional methods of generating and validating test cases still face significant challenges, including prolonged timelines, human error, incomplete test coverage, and high costs of manual intervention. These limitations often lead to delayed product launches and undetected defects that compromise software quality and user satisfaction. The integration of artificial intelligence (AI) into software testing presents a promising solution to these persistent challenges. AI-driven testing methods automate the creation of comprehensive test cases, dynamically adapt to changes, and leverage machine learning to identify high-risk areas in the codebase. This approach enhances regression testing efficiency while expanding overall test coverage. Furthermore, AI-powered tools enable continuous testing and self-healing test cases, significantly reducing manual oversight and accelerating feedback loops, ultimately leading to faster and more reliable software releases. This paper explores the transformative potential of AI in improving test case generation and validation, focusing on its ability to enhance efficiency, accuracy, and scalability in testing processes. It also addresses key challenges associated with adapting AI for testing, including the need for high quality training data, ensuring model transparency, and maintaining a balance between automation and human oversight. Through case studies and examples of real-world applications, this paper illustrates how AI can significantly enhance testing efficiency across both legacy and modern software systems.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/eeaf0b09c6996b00e244a4554d67af5a2b58c69a.pdf",
    "citation_key": "baqar20240ql",
    "metadata": {
      "title": "The Future of Software Testing: AI-Powered Test Case Generation and Validation",
      "authors": [
        "Mohammad Baqar",
        "Rajat Khanda"
      ],
      "published_date": "2024",
      "abstract": "Software testing is a crucial phase in the software development lifecycle (SDLC), ensuring that products meet necessary functional, performance, and quality benchmarks before release. Despite advancements in automation, traditional methods of generating and validating test cases still face significant challenges, including prolonged timelines, human error, incomplete test coverage, and high costs of manual intervention. These limitations often lead to delayed product launches and undetected defects that compromise software quality and user satisfaction. The integration of artificial intelligence (AI) into software testing presents a promising solution to these persistent challenges. AI-driven testing methods automate the creation of comprehensive test cases, dynamically adapt to changes, and leverage machine learning to identify high-risk areas in the codebase. This approach enhances regression testing efficiency while expanding overall test coverage. Furthermore, AI-powered tools enable continuous testing and self-healing test cases, significantly reducing manual oversight and accelerating feedback loops, ultimately leading to faster and more reliable software releases. This paper explores the transformative potential of AI in improving test case generation and validation, focusing on its ability to enhance efficiency, accuracy, and scalability in testing processes. It also addresses key challenges associated with adapting AI for testing, including the need for high quality training data, ensuring model transparency, and maintaining a balance between automation and human oversight. Through case studies and examples of real-world applications, this paper illustrates how AI can significantly enhance testing efficiency across both legacy and modern software systems.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/eeaf0b09c6996b00e244a4554d67af5a2b58c69a.pdf",
      "venue": "Lecture Notes in Networks and Systems",
      "citationCount": 8,
      "score": 8.0,
      "summary": "Software testing is a crucial phase in the software development lifecycle (SDLC), ensuring that products meet necessary functional, performance, and quality benchmarks before release. Despite advancements in automation, traditional methods of generating and validating test cases still face significant challenges, including prolonged timelines, human error, incomplete test coverage, and high costs of manual intervention. These limitations often lead to delayed product launches and undetected defects that compromise software quality and user satisfaction. The integration of artificial intelligence (AI) into software testing presents a promising solution to these persistent challenges. AI-driven testing methods automate the creation of comprehensive test cases, dynamically adapt to changes, and leverage machine learning to identify high-risk areas in the codebase. This approach enhances regression testing efficiency while expanding overall test coverage. Furthermore, AI-powered tools enable continuous testing and self-healing test cases, significantly reducing manual oversight and accelerating feedback loops, ultimately leading to faster and more reliable software releases. This paper explores the transformative potential of AI in improving test case generation and validation, focusing on its ability to enhance efficiency, accuracy, and scalability in testing processes. It also addresses key challenges associated with adapting AI for testing, including the need for high quality training data, ensuring model transparency, and maintaining a balance between automation and human oversight. Through case studies and examples of real-world applications, this paper illustrates how AI can significantly enhance testing efficiency across both legacy and modern software systems.",
      "keywords": []
    },
    "file_name": "eeaf0b09c6996b00e244a4554d67af5a2b58c69a.pdf"
  },
  {
    "success": true,
    "doc_id": "02421bd663f73fc470b807edd15d012d",
    "summary": "In today’s fast-paced software development environment, the collaboration between Business Analysts (BAs) and Quality Assurance (QA) teams is essential for delivering high-quality products efficiently. However, traditional methods often lead to inefficiencies due to silos and misalignment between these teams. This article explores how Artificial Intelligence (AI)-driven collaboration platforms are transforming BA-QA dynamics, offering a more integrated, data-driven approach to software development. By leveraging AI technologies such as predictive analytics, automated test case generation, and real-time collaboration tools, businesses can enhance decision-making, improve communication, and optimize testing strategies. This paper discusses the key benefits of AI in accelerating software quality, highlights real-world case studies of AI applications, and examines the future potential of AI in revolutionizing BA-QA collaboration, particularly in the US market. It also addresses the emerging trends and challenges that come with adopting AI, emphasizing the importance of continuous learning, training, and integration of AI tools with other technologies like IoT and blockchain. As AI continues to evolve, its role in streamlining BA-QA collaboration will become increasingly critical, offering organizations a competitive edge in delivering high-quality software at an accelerated pace.",
    "intriguing_abstract": "In today’s fast-paced software development environment, the collaboration between Business Analysts (BAs) and Quality Assurance (QA) teams is essential for delivering high-quality products efficiently. However, traditional methods often lead to inefficiencies due to silos and misalignment between these teams. This article explores how Artificial Intelligence (AI)-driven collaboration platforms are transforming BA-QA dynamics, offering a more integrated, data-driven approach to software development. By leveraging AI technologies such as predictive analytics, automated test case generation, and real-time collaboration tools, businesses can enhance decision-making, improve communication, and optimize testing strategies. This paper discusses the key benefits of AI in accelerating software quality, highlights real-world case studies of AI applications, and examines the future potential of AI in revolutionizing BA-QA collaboration, particularly in the US market. It also addresses the emerging trends and challenges that come with adopting AI, emphasizing the importance of continuous learning, training, and integration of AI tools with other technologies like IoT and blockchain. As AI continues to evolve, its role in streamlining BA-QA collaboration will become increasingly critical, offering organizations a competitive edge in delivering high-quality software at an accelerated pace.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/9efbe6ed7faba31149554d4ef8709799c83a6c15.pdf",
    "citation_key": "bakhsh2024q2j",
    "metadata": {
      "title": "Revolutionizing BA-QA Team Dynamics: AI-Driven Collaboration Platforms for Accelerated Software Quality in the US Market",
      "authors": [
        "Mohammed Majid Bakhsh",
        "Md Shaikat Alam Joy",
        "Gazi Touhidul Alam"
      ],
      "published_date": "2024",
      "abstract": "In today’s fast-paced software development environment, the collaboration between Business Analysts (BAs) and Quality Assurance (QA) teams is essential for delivering high-quality products efficiently. However, traditional methods often lead to inefficiencies due to silos and misalignment between these teams. This article explores how Artificial Intelligence (AI)-driven collaboration platforms are transforming BA-QA dynamics, offering a more integrated, data-driven approach to software development. By leveraging AI technologies such as predictive analytics, automated test case generation, and real-time collaboration tools, businesses can enhance decision-making, improve communication, and optimize testing strategies. This paper discusses the key benefits of AI in accelerating software quality, highlights real-world case studies of AI applications, and examines the future potential of AI in revolutionizing BA-QA collaboration, particularly in the US market. It also addresses the emerging trends and challenges that come with adopting AI, emphasizing the importance of continuous learning, training, and integration of AI tools with other technologies like IoT and blockchain. As AI continues to evolve, its role in streamlining BA-QA collaboration will become increasingly critical, offering organizations a competitive edge in delivering high-quality software at an accelerated pace.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/9efbe6ed7faba31149554d4ef8709799c83a6c15.pdf",
      "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
      "citationCount": 8,
      "score": 8.0,
      "summary": "In today’s fast-paced software development environment, the collaboration between Business Analysts (BAs) and Quality Assurance (QA) teams is essential for delivering high-quality products efficiently. However, traditional methods often lead to inefficiencies due to silos and misalignment between these teams. This article explores how Artificial Intelligence (AI)-driven collaboration platforms are transforming BA-QA dynamics, offering a more integrated, data-driven approach to software development. By leveraging AI technologies such as predictive analytics, automated test case generation, and real-time collaboration tools, businesses can enhance decision-making, improve communication, and optimize testing strategies. This paper discusses the key benefits of AI in accelerating software quality, highlights real-world case studies of AI applications, and examines the future potential of AI in revolutionizing BA-QA collaboration, particularly in the US market. It also addresses the emerging trends and challenges that come with adopting AI, emphasizing the importance of continuous learning, training, and integration of AI tools with other technologies like IoT and blockchain. As AI continues to evolve, its role in streamlining BA-QA collaboration will become increasingly critical, offering organizations a competitive edge in delivering high-quality software at an accelerated pace.",
      "keywords": []
    },
    "file_name": "9efbe6ed7faba31149554d4ef8709799c83a6c15.pdf"
  },
  {
    "success": true,
    "doc_id": "cef554dba17f1a9f385772d73c0f62f2",
    "summary": "AI Infrastructure plays a key role in the speed and cost-competitiveness of developing and deploying advanced AI models. The current demand for powerful AI infrastructure for model training is driven by the emergence of generative AI and foundational models, where on occasion thousands of GPUs must cooperate on a single training job for the model to be trained in a reasonable time. Delivering efficient and high-performing AI training requires an end-to-end solution that combines hardware, software and holistic telemetry to cater for multiple types of AI workloads. In this report, we describe IBM's hybrid cloud infrastructure that powers our generative AI model development. This infrastructure includes (1) Vela: an AI-optimized supercomputing capability directly integrated into the IBM Cloud, delivering scalable, dynamic, multi-tenant and geographically distributed infrastructure for large-scale model training and other AI workflow steps and (2) Blue Vela: a large-scale, purpose-built, on-premises hosting environment that is optimized to support our largest and most ambitious AI model training tasks. Vela provides IBM with the dual benefit of high performance for internal use along with the flexibility to adapt to an evolving commercial landscape. Blue Vela provides us with the benefits of rapid development of our largest and most ambitious models, as well as future-proofing against the evolving model landscape in the industry. Taken together, they provide IBM with the ability to rapidly innovate in the development of both AI models and commercial offerings.",
    "intriguing_abstract": "AI Infrastructure plays a key role in the speed and cost-competitiveness of developing and deploying advanced AI models. The current demand for powerful AI infrastructure for model training is driven by the emergence of generative AI and foundational models, where on occasion thousands of GPUs must cooperate on a single training job for the model to be trained in a reasonable time. Delivering efficient and high-performing AI training requires an end-to-end solution that combines hardware, software and holistic telemetry to cater for multiple types of AI workloads. In this report, we describe IBM's hybrid cloud infrastructure that powers our generative AI model development. This infrastructure includes (1) Vela: an AI-optimized supercomputing capability directly integrated into the IBM Cloud, delivering scalable, dynamic, multi-tenant and geographically distributed infrastructure for large-scale model training and other AI workflow steps and (2) Blue Vela: a large-scale, purpose-built, on-premises hosting environment that is optimized to support our largest and most ambitious AI model training tasks. Vela provides IBM with the dual benefit of high performance for internal use along with the flexibility to adapt to an evolving commercial landscape. Blue Vela provides us with the benefits of rapid development of our largest and most ambitious models, as well as future-proofing against the evolving model landscape in the industry. Taken together, they provide IBM with the ability to rapidly innovate in the development of both AI models and commercial offerings.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b149bcbe4bf29cfd1c89543a5d04f020619c88e8.pdf",
    "citation_key": "gershon2024lgw",
    "metadata": {
      "title": "The infrastructure powering IBM's Gen AI model development",
      "authors": [
        "Talia Gershon",
        "Seetharami R. Seelam",
        "Brian Belgodere",
        "Milton Bonilla",
        "Lan Hoang",
        "Danny Barnett",
        "I-Hsin Chung",
        "Apoorve Mohan",
        "Ming-Hung Chen",
        "Lixiang Luo",
        "Robert Walkup",
        "Constantinos Evangelinos",
        "Shweta Salaria",
        "Marc Dombrowa",
        "Yoonho Park",
        "Apo Kayi",
        "L. Schour",
        "Alim Alim",
        "Ali Sydney",
        "P. Maniotis",
        "L. Schares",
        "Bernard Metzler",
        "Bengi Karacali-Akyamac",
        "Sophia Wen",
        "Tatsuhiro Chiba",
        "Sunyanan Choochotkaew",
        "Takeshi Yoshimura",
        "C. Misale",
        "Tonia Elengikal",
        "Kevin O Connor",
        "Zhuoran Liu",
        "Richard Molina",
        "L. Schneidenbach",
        "James Caden",
        "Christopher Laibinis",
        "Carlos Fonseca",
        "Vasily Tarasov",
        "S. Sundararaman",
        "Frank B. Schmuck",
        "S. Guthridge",
        "Jeremy Cohn",
        "Marc Eshel",
        "Paul Muench",
        "Runyu Liu",
        "W. Pointer",
        "D. Wyskida",
        "Bob Krull",
        "Ray Rose",
        "Brent Wolfe",
        "William Cornejo",
        "John Walter",
        "Colm Malone",
        "Clifford Perucci",
        "Frank Franco",
        "Nigel Hinds",
        "Bob Calio",
        "Pavel Druyan",
        "R. Kilduff",
        "John Kienle",
        "Connor McStay",
        "Andrew Figueroa",
        "Matthew Connolly",
        "Edie Fost",
        "Gina Roma",
        "Jake Fonseca",
        "Ido Levy",
        "Michele Payne",
        "Ryan Schenkel",
        "Amir Malki",
        "Lion Schneider",
        "Aniruddha Narkhede",
        "Shekeba Moshref",
        "Alexandra Kisin",
        "Olga Dodin",
        "Bill Rippon",
        "Henry Wrieth",
        "John M. Ganci",
        "Johnny Colino",
        "Donna Habeger-Rose",
        "Rakesh Pandey",
        "Aditya Gidh",
        "Aditya Gaur",
        "Dennis Patterson",
        "Samsuddin Salmani",
        "Rambilas Varma",
        "Rumana Rumana",
        "Shubham Sharma",
        "Mayank Mishra",
        "Rameswar Panda",
        "Aditya Prasad",
        "Matt Stallone",
        "Gaoyuan Zhang",
        "Yikang Shen",
        "David Cox",
        "Ruchir Puri",
        "Dakshi Agrawal",
        "Drew Thorstensen",
        "Joel Belog",
        "Brent Tang"
      ],
      "published_date": "2024",
      "abstract": "AI Infrastructure plays a key role in the speed and cost-competitiveness of developing and deploying advanced AI models. The current demand for powerful AI infrastructure for model training is driven by the emergence of generative AI and foundational models, where on occasion thousands of GPUs must cooperate on a single training job for the model to be trained in a reasonable time. Delivering efficient and high-performing AI training requires an end-to-end solution that combines hardware, software and holistic telemetry to cater for multiple types of AI workloads. In this report, we describe IBM's hybrid cloud infrastructure that powers our generative AI model development. This infrastructure includes (1) Vela: an AI-optimized supercomputing capability directly integrated into the IBM Cloud, delivering scalable, dynamic, multi-tenant and geographically distributed infrastructure for large-scale model training and other AI workflow steps and (2) Blue Vela: a large-scale, purpose-built, on-premises hosting environment that is optimized to support our largest and most ambitious AI model training tasks. Vela provides IBM with the dual benefit of high performance for internal use along with the flexibility to adapt to an evolving commercial landscape. Blue Vela provides us with the benefits of rapid development of our largest and most ambitious models, as well as future-proofing against the evolving model landscape in the industry. Taken together, they provide IBM with the ability to rapidly innovate in the development of both AI models and commercial offerings.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b149bcbe4bf29cfd1c89543a5d04f020619c88e8.pdf",
      "venue": "arXiv.org",
      "citationCount": 8,
      "score": 8.0,
      "summary": "AI Infrastructure plays a key role in the speed and cost-competitiveness of developing and deploying advanced AI models. The current demand for powerful AI infrastructure for model training is driven by the emergence of generative AI and foundational models, where on occasion thousands of GPUs must cooperate on a single training job for the model to be trained in a reasonable time. Delivering efficient and high-performing AI training requires an end-to-end solution that combines hardware, software and holistic telemetry to cater for multiple types of AI workloads. In this report, we describe IBM's hybrid cloud infrastructure that powers our generative AI model development. This infrastructure includes (1) Vela: an AI-optimized supercomputing capability directly integrated into the IBM Cloud, delivering scalable, dynamic, multi-tenant and geographically distributed infrastructure for large-scale model training and other AI workflow steps and (2) Blue Vela: a large-scale, purpose-built, on-premises hosting environment that is optimized to support our largest and most ambitious AI model training tasks. Vela provides IBM with the dual benefit of high performance for internal use along with the flexibility to adapt to an evolving commercial landscape. Blue Vela provides us with the benefits of rapid development of our largest and most ambitious models, as well as future-proofing against the evolving model landscape in the industry. Taken together, they provide IBM with the ability to rapidly innovate in the development of both AI models and commercial offerings.",
      "keywords": []
    },
    "file_name": "b149bcbe4bf29cfd1c89543a5d04f020619c88e8.pdf"
  },
  {
    "success": true,
    "doc_id": "872da3adadab4b182de7db433c316443",
    "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{parikh2023x5m}\" when referencing this paper.\n\n---\n\n### Focused Summary for Literature Review: Empowering Business Transformation - The Positive Impact and Ethical Considerations of Generative AI in Software Product Management\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** This systematic literature review addresses a significant knowledge gap regarding the comprehensive applications, benefits, and ethical considerations of Generative AI (GAI) specifically within the domain of software product management (SPM) \\cite{parikh2023x5m}. It aims to synthesize how GAI can be leveraged across various SPM activities.\n    *   **Importance & Challenge:** Software product management is a complex discipline requiring continuous adaptation to user needs, market trends, and technological advancements. GAI has emerged as a transformative technology with the potential to automate tasks, improve efficiency, and enhance customer experience, with the global GAI market projected to reach $109 billion by 2030 \\cite{parikh2023x5m}. The challenge lies in the lack of a holistic understanding among product managers regarding GAI's specific potential, practical applications, and inherent limitations.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work systematically synthesizes existing research on GAI applications in business and product management, utilizing established frameworks such as the ISPMA Product Management Framework for application areas, the McKinsey 7-S and Lewin’s Change Model for organizational adoption, and Owen et al.'s Responsible Innovation framework alongside GDPR principles for ethical and privacy considerations \\cite{parikh2023x5m}.\n    *   **Limitations of Previous Solutions:** The paper implicitly highlights that while individual studies have explored specific aspects of GAI, there was a lack of a comprehensive, consolidated view of its full spectrum of applications, impact, and ethical implications specifically tailored to software product management \\cite{parikh2023x5m}. This systematic review aims to bridge that gap by providing a structured, holistic overview.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (of *this* paper):** The core method is a systematic literature review (SLR) that analyzes pertinent articles published between 2016 and 2023 \\cite{parikh2023x5m}. This involves identifying, analyzing, and synthesizing findings from diverse studies to map GAI's potential applications, benefits, and constraints across the SPM lifecycle.\n    *   **Novelty/Difference (of *this* paper):** The innovation of this paper lies in its comprehensive scope and structured synthesis. It uniquely frames the discussion of GAI in SPM using established industry and academic models (ISPMA, McKinsey 7-S, Lewin’s Change Model, Responsible Innovation, GDPR) to provide a holistic overview of both positive impacts and critical ethical considerations. While not proposing a new GAI algorithm, its novelty is in the structured consolidation of existing knowledge to inform practitioners and researchers on GAI's role in SPM \\cite{parikh2023x5m}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques (identified *in the reviewed literature*):**\n        *   **Idea Generation:** Identification of GPT3-based models (GPT-NEO-125M, GPT-NEO-1.3B) for generating coherent ideas \\cite{parikh2023x5m}.\n        *   **Product Requirements Engineering:** Malik et al. (2022) proposed a two-phase process for automatic conflict detection in Software Requirement Specifications (SRS) using transformer-based sentence embeddings and Named Entity Recognition (NER) \\cite{parikh2023x5m}.\n        *   **Agile Story Point Estimation:** Fu and Tantithamthavorn (2022) introduced GPT2SP, an innovative approach utilizing a GPT-2 pre-trained language model and Transformer-based architecture for superior accuracy in estimating user story points \\cite{parikh2023x5m}.\n        *   **Automated Code Generation & Documentation:** Examination of GPT-3 Codex for automating documentation generation, demonstrating state-of-the-art performance with one-shot learning \\cite{parikh2023x5m}. Park et al. (2023) developed ALSI-Transformer, a transformer-based model for code comment generation using a Gate Network for multimodal information aggregation \\cite{parikh2023x5m}.\n    *   **System Design or Architectural Innovations (identified *in the reviewed literature*):**\n        *   The paper highlights the foundational role of Large Language Models (LLMs) like GPT, ChatGPT, and Bard as core AI systems enabling various applications, including market research, customer insights, and conversational assistants \\cite{parikh2023x5m}.\n        *   Frameworks integrating various AI technologies for enhanced decision support in Agile project management (Dam et al., 2019) \\cite{parikh2023x5m}.\n    *   **Theoretical Insights or Analysis (from *this* paper):**\n        *   Categorization of GAI applications across the entire software product lifecycle, from initial idea generation and market research to product requirements engineering, development, UI/UX design, and customer insights \\cite{parikh2023x5m}.\n        *   Identification and structured discussion of key ethical considerations for GAI deployment, including \"hallucinations,\" the \"black box\" problem, reliance on data quality, and intellectual property infringement risks \\cite{parikh2023x5m}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted (identified *in the reviewed literature*):**\n        *   **Idea Generation:** Karim et al. (2022) compared GPT-NEO-125M and GPT-NEO-1.3B models for coherence in idea generation \\cite{parikh2023x5m}.\n        *   **Customer Support Productivity:** Brynjolfsson et al. (2023) investigated the impact of a GAI conversational assistant across 5,179 customer support agents \\cite{parikh2023x5m}.\n        *   **Requirements Conflict Detection:** Malik et al. (2022) tested their two-phase process on the OpenCoss and IBM-UAV datasets \\cite{parikh2023x5m}.\n        *   **Agile Story Point Estimation:** Fu and Tantithamthavorn (2022) tested GPT2SP on over 23,000 issues spanning 16 open-source projects \\cite{parikh2023x5m}.\n        *   **Automated Code Generation:** Peng et al. (2023) conducted an experiment comparing a group using GitHub Copilot with a control group on task completion time \\cite{parikh2023x5m}. Khan and Uddin (2022) evaluated GPT-3 Codex for documentation generation \\cite{parikh2023x5m}.\n    *   **Key Performance Metrics & Comparison Results (identified *in the reviewed literature*):**\n        *   **Requirements Conflict Detection:** Malik et al. (2022) reported an improvement in F1-score by 4% and 5% for OpenCoss and IBM-UAV datasets, respectively \\cite{parikh2023x5m}.\n        *   **Agile Story Point Estimation:** GPT2SP (Fu and Tantithamthavorn, 2022) demonstrated superior accuracy, outperforming within-project estimates by 34%-57%, cross-project estimates by 39%-49%, and enhancing Deep-SE's performance by 6%-47% \\cite{parikh2023x5m}.\n        *   **Customer Support Productivity:** Brynjolfsson et al. (2023) found the AI tool significantly increased worker productivity, enhanced customer sentiment, and decreased employee turnover rates, particularly benefiting newer/less-skilled workers \\cite{parikh2023x5m}.\n        *   **Automated Code Generation:** Peng et al. (2023) found the group using Copilot completed tasks 55.8% faster \\cite{parikh2023x5m}. Khan and Uddin (2022) achieved an average BLEU score of 20.63 with GPT-3 Codex \\cite{parikh2023x5m}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions (identified *in the reviewed literature* and *by this paper*):**\n        *   **Accuracy and Reliability:** GAI models, especially LLMs, are prone to \"hallucinations\" and generating incorrect information, necessitating consistent human review \\cite{parikh2023x5m}.\n        *   **Interpretability:** Many deep generative AI models suffer from the \"black box\" problem, limiting their interpretability and potentially causing trust issues \\cite{parikh2023x5m}.\n        *   **Data Dependency:** The performance of GAI models is heavily reliant on the quality and representativeness of their training data \\cite{parikh2023x5m}.\n        *   **Ethical and Legal Risks:** Significant concerns exist regarding potential intellectual property infringement, with unresolved legal questions concerning ownership and application of copyright, patent, and trademark laws to AI-generated content \\cite{parikh2023x5m}.\n    *   **Scope of Applicability (of *this* paper):** The review specifically focuses on Generative AI applications within *software product management* activities, synthesizing findings from articles published between 2016 and 2023 \\cite{parikh2023x5m}. Its findings are derived from existing literature and do not present new primary research data or GAI model development.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This systematic literature review significantly advances the understanding of how GAI can be integrated into and transform software product management by consolidating diverse research findings into a structured, actionable framework \\cite{parikh2023x5m}. It moves beyond general discussions of GAI to provide specific examples of its technical application and empirically validated impact across the SPM lifecycle.\n    *   **Potential Impact on Future Research:** The paper identifies critical areas for future research, particularly concerning the mitigation of GAI's inherent limitations (e.g., hallucinations, black box problem) and the development of robust ethical and legal frameworks for its responsible deployment \\cite{parikh2023x5m}. It encourages further exploration into specific GAI tools and methodologies for optimizing various SPM tasks, fostering innovation, and ensuring responsible AI adoption in the industry.",
    "intriguing_abstract": "The advent of Generative AI (GAI) promises to fundamentally reshape software product management (SPM), yet a holistic understanding of its applications, benefits, and ethical challenges remains elusive. This systematic literature review synthesizes research from 2016-2023, leveraging established frameworks to provide a comprehensive mapping of GAI's transformative potential across the entire SPM lifecycle. We unveil how GAI, powered by Large Language Models (LLMs) and transformer-based architectures, is revolutionizing tasks from idea generation and requirements engineering (e.g., conflict detection via Named Entity Recognition) to agile story point estimation (GPT2SP) and automated code generation (GPT-3 Codex), demonstrating significant empirical gains in efficiency and accuracy. Crucially, the review critically examines inherent limitations, including GAI \"hallucinations,\" the \"black box\" problem, data dependency, and complex intellectual property risks, framing a responsible innovation agenda. This paper bridges a vital knowledge gap, offering product managers and researchers an actionable roadmap for leveraging GAI while navigating its ethical landscape, thereby advancing the state-of-the-art in GAI-driven SPM and guiding future research towards robust, trustworthy AI adoption.",
    "keywords": [
      "Generative AI",
      "Software Product Management",
      "Systematic Literature Review",
      "Large Language Models",
      "Ethical Considerations",
      "Product Requirements Engineering",
      "Agile Story Point Estimation",
      "Automated Code Generation",
      "AI Hallucinations",
      "Black Box Problem",
      "Transformer-based Architecture",
      "Customer Support Productivity",
      "Intellectual Property Risks",
      "Structured Synthesis"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ecc2dc870345f22bd3d4d8b77b5e24b238cb975e.pdf",
    "citation_key": "parikh2023x5m",
    "metadata": {
      "title": "Empowering Business Transformation: The Positive Impact and Ethical Considerations of Generative AI in Software Product Management - A Systematic Literature Review",
      "authors": [
        "N. Parikh"
      ],
      "published_date": "2023",
      "abstract": "Generative Artificial Intelligence (GAI) has made outstanding strides in recent years, with a good-sized impact on software product management. Drawing on pertinent articles from 2016 to 2023, this systematic literature evaluation reveals generative AI's potential applications, benefits, and constraints in this area. The study shows that technology can assist in idea generation, market research, customer insights, product requirements engineering, and product development. It can help reduce development time and costs through automatic code generation, customer feedback analysis, and more. However, the technology's accuracy, reliability, and ethical consideration persist. Ultimately, generative AI's practical application can significantly improve software product management activities, leading to more efficient use of resources, better product outcomes, and improved end-user experiences.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ecc2dc870345f22bd3d4d8b77b5e24b238cb975e.pdf",
      "venue": "arXiv.org",
      "citationCount": 15,
      "score": 7.5,
      "summary": "Here's a focused summary of the technical paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **CITATION REQUIREMENTS**: Always use \"\\cite{parikh2023x5m}\" when referencing this paper.\n\n---\n\n### Focused Summary for Literature Review: Empowering Business Transformation - The Positive Impact and Ethical Considerations of Generative AI in Software Product Management\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** This systematic literature review addresses a significant knowledge gap regarding the comprehensive applications, benefits, and ethical considerations of Generative AI (GAI) specifically within the domain of software product management (SPM) \\cite{parikh2023x5m}. It aims to synthesize how GAI can be leveraged across various SPM activities.\n    *   **Importance & Challenge:** Software product management is a complex discipline requiring continuous adaptation to user needs, market trends, and technological advancements. GAI has emerged as a transformative technology with the potential to automate tasks, improve efficiency, and enhance customer experience, with the global GAI market projected to reach $109 billion by 2030 \\cite{parikh2023x5m}. The challenge lies in the lack of a holistic understanding among product managers regarding GAI's specific potential, practical applications, and inherent limitations.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work systematically synthesizes existing research on GAI applications in business and product management, utilizing established frameworks such as the ISPMA Product Management Framework for application areas, the McKinsey 7-S and Lewin’s Change Model for organizational adoption, and Owen et al.'s Responsible Innovation framework alongside GDPR principles for ethical and privacy considerations \\cite{parikh2023x5m}.\n    *   **Limitations of Previous Solutions:** The paper implicitly highlights that while individual studies have explored specific aspects of GAI, there was a lack of a comprehensive, consolidated view of its full spectrum of applications, impact, and ethical implications specifically tailored to software product management \\cite{parikh2023x5m}. This systematic review aims to bridge that gap by providing a structured, holistic overview.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method (of *this* paper):** The core method is a systematic literature review (SLR) that analyzes pertinent articles published between 2016 and 2023 \\cite{parikh2023x5m}. This involves identifying, analyzing, and synthesizing findings from diverse studies to map GAI's potential applications, benefits, and constraints across the SPM lifecycle.\n    *   **Novelty/Difference (of *this* paper):** The innovation of this paper lies in its comprehensive scope and structured synthesis. It uniquely frames the discussion of GAI in SPM using established industry and academic models (ISPMA, McKinsey 7-S, Lewin’s Change Model, Responsible Innovation, GDPR) to provide a holistic overview of both positive impacts and critical ethical considerations. While not proposing a new GAI algorithm, its novelty is in the structured consolidation of existing knowledge to inform practitioners and researchers on GAI's role in SPM \\cite{parikh2023x5m}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques (identified *in the reviewed literature*):**\n        *   **Idea Generation:** Identification of GPT3-based models (GPT-NEO-125M, GPT-NEO-1.3B) for generating coherent ideas \\cite{parikh2023x5m}.\n        *   **Product Requirements Engineering:** Malik et al. (2022) proposed a two-phase process for automatic conflict detection in Software Requirement Specifications (SRS) using transformer-based sentence embeddings and Named Entity Recognition (NER) \\cite{parikh2023x5m}.\n        *   **Agile Story Point Estimation:** Fu and Tantithamthavorn (2022) introduced GPT2SP, an innovative approach utilizing a GPT-2 pre-trained language model and Transformer-based architecture for superior accuracy in estimating user story points \\cite{parikh2023x5m}.\n        *   **Automated Code Generation & Documentation:** Examination of GPT-3 Codex for automating documentation generation, demonstrating state-of-the-art performance with one-shot learning \\cite{parikh2023x5m}. Park et al. (2023) developed ALSI-Transformer, a transformer-based model for code comment generation using a Gate Network for multimodal information aggregation \\cite{parikh2023x5m}.\n    *   **System Design or Architectural Innovations (identified *in the reviewed literature*):**\n        *   The paper highlights the foundational role of Large Language Models (LLMs) like GPT, ChatGPT, and Bard as core AI systems enabling various applications, including market research, customer insights, and conversational assistants \\cite{parikh2023x5m}.\n        *   Frameworks integrating various AI technologies for enhanced decision support in Agile project management (Dam et al., 2019) \\cite{parikh2023x5m}.\n    *   **Theoretical Insights or Analysis (from *this* paper):**\n        *   Categorization of GAI applications across the entire software product lifecycle, from initial idea generation and market research to product requirements engineering, development, UI/UX design, and customer insights \\cite{parikh2023x5m}.\n        *   Identification and structured discussion of key ethical considerations for GAI deployment, including \"hallucinations,\" the \"black box\" problem, reliance on data quality, and intellectual property infringement risks \\cite{parikh2023x5m}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted (identified *in the reviewed literature*):**\n        *   **Idea Generation:** Karim et al. (2022) compared GPT-NEO-125M and GPT-NEO-1.3B models for coherence in idea generation \\cite{parikh2023x5m}.\n        *   **Customer Support Productivity:** Brynjolfsson et al. (2023) investigated the impact of a GAI conversational assistant across 5,179 customer support agents \\cite{parikh2023x5m}.\n        *   **Requirements Conflict Detection:** Malik et al. (2022) tested their two-phase process on the OpenCoss and IBM-UAV datasets \\cite{parikh2023x5m}.\n        *   **Agile Story Point Estimation:** Fu and Tantithamthavorn (2022) tested GPT2SP on over 23,000 issues spanning 16 open-source projects \\cite{parikh2023x5m}.\n        *   **Automated Code Generation:** Peng et al. (2023) conducted an experiment comparing a group using GitHub Copilot with a control group on task completion time \\cite{parikh2023x5m}. Khan and Uddin (2022) evaluated GPT-3 Codex for documentation generation \\cite{parikh2023x5m}.\n    *   **Key Performance Metrics & Comparison Results (identified *in the reviewed literature*):**\n        *   **Requirements Conflict Detection:** Malik et al. (2022) reported an improvement in F1-score by 4% and 5% for OpenCoss and IBM-UAV datasets, respectively \\cite{parikh2023x5m}.\n        *   **Agile Story Point Estimation:** GPT2SP (Fu and Tantithamthavorn, 2022) demonstrated superior accuracy, outperforming within-project estimates by 34%-57%, cross-project estimates by 39%-49%, and enhancing Deep-SE's performance by 6%-47% \\cite{parikh2023x5m}.\n        *   **Customer Support Productivity:** Brynjolfsson et al. (2023) found the AI tool significantly increased worker productivity, enhanced customer sentiment, and decreased employee turnover rates, particularly benefiting newer/less-skilled workers \\cite{parikh2023x5m}.\n        *   **Automated Code Generation:** Peng et al. (2023) found the group using Copilot completed tasks 55.8% faster \\cite{parikh2023x5m}. Khan and Uddin (2022) achieved an average BLEU score of 20.63 with GPT-3 Codex \\cite{parikh2023x5m}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions (identified *in the reviewed literature* and *by this paper*):**\n        *   **Accuracy and Reliability:** GAI models, especially LLMs, are prone to \"hallucinations\" and generating incorrect information, necessitating consistent human review \\cite{parikh2023x5m}.\n        *   **Interpretability:** Many deep generative AI models suffer from the \"black box\" problem, limiting their interpretability and potentially causing trust issues \\cite{parikh2023x5m}.\n        *   **Data Dependency:** The performance of GAI models is heavily reliant on the quality and representativeness of their training data \\cite{parikh2023x5m}.\n        *   **Ethical and Legal Risks:** Significant concerns exist regarding potential intellectual property infringement, with unresolved legal questions concerning ownership and application of copyright, patent, and trademark laws to AI-generated content \\cite{parikh2023x5m}.\n    *   **Scope of Applicability (of *this* paper):** The review specifically focuses on Generative AI applications within *software product management* activities, synthesizing findings from articles published between 2016 and 2023 \\cite{parikh2023x5m}. Its findings are derived from existing literature and do not present new primary research data or GAI model development.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This systematic literature review significantly advances the understanding of how GAI can be integrated into and transform software product management by consolidating diverse research findings into a structured, actionable framework \\cite{parikh2023x5m}. It moves beyond general discussions of GAI to provide specific examples of its technical application and empirically validated impact across the SPM lifecycle.\n    *   **Potential Impact on Future Research:** The paper identifies critical areas for future research, particularly concerning the mitigation of GAI's inherent limitations (e.g., hallucinations, black box problem) and the development of robust ethical and legal frameworks for its responsible deployment \\cite{parikh2023x5m}. It encourages further exploration into specific GAI tools and methodologies for optimizing various SPM tasks, fostering innovation, and ensuring responsible AI adoption in the industry.",
      "keywords": [
        "Generative AI",
        "Software Product Management",
        "Systematic Literature Review",
        "Large Language Models",
        "Ethical Considerations",
        "Product Requirements Engineering",
        "Agile Story Point Estimation",
        "Automated Code Generation",
        "AI Hallucinations",
        "Black Box Problem",
        "Transformer-based Architecture",
        "Customer Support Productivity",
        "Intellectual Property Risks",
        "Structured Synthesis"
      ],
      "paper_type": "based on the provided abstract and introduction, this paper is a **survey**.\n\nhere's why:\n\n*   **title:** the title explicitly states \"a **systematic literature review**\".\n*   **abstract:** it mentions \"this **systematic literature evaluation reveals** generative ai's potential applications, benefits, and constraints in this area\" and \"drawing on pertinent articles from 2016 to 2023\". these phrases directly align with the criteria for a survey paper, which reviews existing literature.\n*   **introduction:** the introduction provides background, definitions, and context for generative ai, which is typical for a survey paper setting the stage for its comprehensive review of the topic."
    },
    "file_name": "ecc2dc870345f22bd3d4d8b77b5e24b238cb975e.pdf"
  },
  {
    "success": true,
    "doc_id": "cf288be33e1a09afea4b65b665331b89",
    "summary": "Creativity has always been considered a major differentiator to separate the good from the great, and we believe the importance of creativity for software development will only increase as GenAI becomes embedded in developer tool-chains and working practices. This paper uses the McLuhan tetrad alongside scenarios of how GenAI may disrupt software development more broadly, to identify potential impacts GenAI may have on creativity within software development. The impacts are discussed along with a future research agenda comprising six connected themes that consider how individual capabilities, team capabilities, the product, unintended consequences, society, and human aspects can be affected.",
    "intriguing_abstract": "Creativity has always been considered a major differentiator to separate the good from the great, and we believe the importance of creativity for software development will only increase as GenAI becomes embedded in developer tool-chains and working practices. This paper uses the McLuhan tetrad alongside scenarios of how GenAI may disrupt software development more broadly, to identify potential impacts GenAI may have on creativity within software development. The impacts are discussed along with a future research agenda comprising six connected themes that consider how individual capabilities, team capabilities, the product, unintended consequences, society, and human aspects can be affected.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d080909e0f690814153d7a980925b7ae56af362e.pdf",
    "citation_key": "jackson20244u4",
    "metadata": {
      "title": "Creativity, Generative AI, and Software Development: A Research Agenda",
      "authors": [
        "Victoria Jackson",
        "Bogdan Vasilescu",
        "Daniel Russo",
        "Paul Ralph",
        "Maliheh Izadi",
        "R. Prikladnicki",
        "Sarah D'Angelo",
        "Sarah Inman",
        "Anielle Lisboa",
        "A. Hoek"
      ],
      "published_date": "2024",
      "abstract": "Creativity has always been considered a major differentiator to separate the good from the great, and we believe the importance of creativity for software development will only increase as GenAI becomes embedded in developer tool-chains and working practices. This paper uses the McLuhan tetrad alongside scenarios of how GenAI may disrupt software development more broadly, to identify potential impacts GenAI may have on creativity within software development. The impacts are discussed along with a future research agenda comprising six connected themes that consider how individual capabilities, team capabilities, the product, unintended consequences, society, and human aspects can be affected.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d080909e0f690814153d7a980925b7ae56af362e.pdf",
      "venue": "arXiv.org",
      "citationCount": 7,
      "score": 7.0,
      "summary": "Creativity has always been considered a major differentiator to separate the good from the great, and we believe the importance of creativity for software development will only increase as GenAI becomes embedded in developer tool-chains and working practices. This paper uses the McLuhan tetrad alongside scenarios of how GenAI may disrupt software development more broadly, to identify potential impacts GenAI may have on creativity within software development. The impacts are discussed along with a future research agenda comprising six connected themes that consider how individual capabilities, team capabilities, the product, unintended consequences, society, and human aspects can be affected.",
      "keywords": []
    },
    "file_name": "d080909e0f690814153d7a980925b7ae56af362e.pdf"
  },
  {
    "success": true,
    "doc_id": "c02c4bc98961ca5090a10b5ed5de33b5",
    "summary": "A global effort has been initiated to reduce the worldwide greenhouse gas (GHG) emissions, primarily carbon emissions, by half by 2030 and reach net-zero by 2050. The development of 6G must also be compliant with this goal. Unfortunately, developing a sustainable and net-zero emission systems to meet the users' fast growing demands on mobile services, especially smart services and applications, may be much more challenging than expected. Particularly, despite the energy efficiency improvement in both hardware and software designs, the overall energy consumption and carbon emission of mobile networks are still increasing at a tremendous speed. The growing penetration of resource-demanding Al algorithms and solutions further exacerbate this challenge. In this article, we identify the major emission sources and introduce an evaluation framework for analyzing the lifecycle of network Al implementations. A novel joint dynamic energy trading and task allocation optimization framework, called DETA, has been introduced to reduce the overall carbon emissions. We consider a federated edge intelligence-based network Al system as a case study to verify the effectiveness of our proposed solution. Experimental results based on a hardware prototype suggest that our proposed solution can reduce carbon emissions of network Al systems by up to 74.9 percent. Finally, open problems and future directions are discussed.",
    "intriguing_abstract": "A global effort has been initiated to reduce the worldwide greenhouse gas (GHG) emissions, primarily carbon emissions, by half by 2030 and reach net-zero by 2050. The development of 6G must also be compliant with this goal. Unfortunately, developing a sustainable and net-zero emission systems to meet the users' fast growing demands on mobile services, especially smart services and applications, may be much more challenging than expected. Particularly, despite the energy efficiency improvement in both hardware and software designs, the overall energy consumption and carbon emission of mobile networks are still increasing at a tremendous speed. The growing penetration of resource-demanding Al algorithms and solutions further exacerbate this challenge. In this article, we identify the major emission sources and introduce an evaluation framework for analyzing the lifecycle of network Al implementations. A novel joint dynamic energy trading and task allocation optimization framework, called DETA, has been introduced to reduce the overall carbon emissions. We consider a federated edge intelligence-based network Al system as a case study to verify the effectiveness of our proposed solution. Experimental results based on a hardware prototype suggest that our proposed solution can reduce carbon emissions of network Al systems by up to 74.9 percent. Finally, open problems and future directions are discussed.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/faab01c43ad6a147586da21f8313daad43eb1780.pdf",
    "citation_key": "zhang20231yn",
    "metadata": {
      "title": "Toward Net-Zero Carbon Emissions in Network AI for 6G and Beyond",
      "authors": [
        "Peng Zhang",
        "Yong Xiao",
        "Yingyu Li",
        "Xiaohu Ge",
        "Guangming Shi",
        "Yang Yang"
      ],
      "published_date": "2023",
      "abstract": "A global effort has been initiated to reduce the worldwide greenhouse gas (GHG) emissions, primarily carbon emissions, by half by 2030 and reach net-zero by 2050. The development of 6G must also be compliant with this goal. Unfortunately, developing a sustainable and net-zero emission systems to meet the users' fast growing demands on mobile services, especially smart services and applications, may be much more challenging than expected. Particularly, despite the energy efficiency improvement in both hardware and software designs, the overall energy consumption and carbon emission of mobile networks are still increasing at a tremendous speed. The growing penetration of resource-demanding Al algorithms and solutions further exacerbate this challenge. In this article, we identify the major emission sources and introduce an evaluation framework for analyzing the lifecycle of network Al implementations. A novel joint dynamic energy trading and task allocation optimization framework, called DETA, has been introduced to reduce the overall carbon emissions. We consider a federated edge intelligence-based network Al system as a case study to verify the effectiveness of our proposed solution. Experimental results based on a hardware prototype suggest that our proposed solution can reduce carbon emissions of network Al systems by up to 74.9 percent. Finally, open problems and future directions are discussed.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/faab01c43ad6a147586da21f8313daad43eb1780.pdf",
      "venue": "IEEE Communications Magazine",
      "citationCount": 14,
      "score": 7.0,
      "summary": "A global effort has been initiated to reduce the worldwide greenhouse gas (GHG) emissions, primarily carbon emissions, by half by 2030 and reach net-zero by 2050. The development of 6G must also be compliant with this goal. Unfortunately, developing a sustainable and net-zero emission systems to meet the users' fast growing demands on mobile services, especially smart services and applications, may be much more challenging than expected. Particularly, despite the energy efficiency improvement in both hardware and software designs, the overall energy consumption and carbon emission of mobile networks are still increasing at a tremendous speed. The growing penetration of resource-demanding Al algorithms and solutions further exacerbate this challenge. In this article, we identify the major emission sources and introduce an evaluation framework for analyzing the lifecycle of network Al implementations. A novel joint dynamic energy trading and task allocation optimization framework, called DETA, has been introduced to reduce the overall carbon emissions. We consider a federated edge intelligence-based network Al system as a case study to verify the effectiveness of our proposed solution. Experimental results based on a hardware prototype suggest that our proposed solution can reduce carbon emissions of network Al systems by up to 74.9 percent. Finally, open problems and future directions are discussed.",
      "keywords": []
    },
    "file_name": "faab01c43ad6a147586da21f8313daad43eb1780.pdf"
  },
  {
    "success": true,
    "doc_id": "964c7da235c5b0b260fbf136d501d1d8",
    "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n---\n\n### Analysis of \"Open-Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning\" \\cite{lin20242vi}\n\n**1. Research Problem & Motivation**\n*   **Specific Technical Problem:** The paper addresses the significant barrier to developing and enhancing open-source AI-based Software Engineering (SE) tools: the limited access to high-quality, sensitive code data from diverse organizations. Current open-source AI model development is often isolated, leading to redundant efforts and unverified improvements.\n*   **Importance and Challenge:**\n    *   High-quality code data is crucial for the performance of AI models, especially Large Language Models (LLMs) in SE, but its growth rate in public domains is insufficient.\n    *   Commercial IT companies possess valuable, sensitive code data but are reluctant to share it due to privacy and proprietary concerns.\n    *   The existing unipartite participation model for open-source AI models leads to low economic efficiency and a lack of strong community support, unlike traditional open-source software.\n\n**2. Related Work & Positioning**\n*   **Relation to Existing Approaches:** The work relates to existing applications of Federated Learning (FL) in SE, such as FedCSD \\cite{lin20242vi} for code smell detection and ALMITY \\cite{lin20242vi} for applying academic models to industrial settings.\n*   **Limitations of Previous Solutions:**\n    *   Prior FL applications in SE did not thoroughly investigate the impact of code data distribution heterogeneity on FL performance.\n    *   They did not consider FL's potential to fundamentally change the governance and community dynamics of open-source code models.\n    *   Traditional open-source model dissemination platforms (e.g., Huggingface) facilitate sharing but do not enable true collaborative model development and maintenance across organizations with sensitive data.\n\n**3. Technical Approach & Innovation**\n*   **Core Technical Method:** The paper proposes a **decentralized governance framework for open-source AI-based SE tools centered on Federated Learning (FL)**. This framework enables multiple entities to collaboratively train and maintain AI code models without directly sharing their proprietary local data.\n*   **Novelty/Differentiation:**\n    *   **FL-based Governance Framework:** Introduces a structured approach for multi-party collaboration in open-source AI model development, explicitly designed to respect data privacy and commercial sensitivities.\n    *   **Comprehensive Developer Guidelines:** Defines protocols for collaborative development, including:\n        *   **Data Protocol:** Specifies data formats, quality standards, and test data requirements.\n        *   **Model Architecture Protocol:** Ensures local training adheres to a predefined exemplary model architecture.\n        *   **Model Updating Strategies:** Outlines methods for aggregating client model updates (e.g., averaging).\n        *   **Version Control Protocol:** Defines checkpoint saving, performance thresholds for releases, and versioning rules.\n    *   **Governance Committee:** Establishes a mechanism for community management, reviewing contributions (pull requests), and maintaining developer guidelines.\n    *   **Empirical Focus on Data Heterogeneity:** Uniquely investigates the critical impact of diverse code data distributions on FL performance, which is essential for real-world multi-organizational collaboration.\n\n**4. Key Technical Contributions**\n*   **System Design/Architectural Innovations:**\n    *   A novel governance framework for open-source AI-based SE tools, leveraging federated learning to facilitate collaborative model development while preserving data privacy and security.\n    *   Detailed developer guidelines (Data, Model Architecture, Model Updating, Version Control Protocols) to standardize and enable multi-party collaboration in AI model co-construction.\n*   **Theoretical Insights/Analysis:**\n    *   A thorough investigation into the influence of data heterogeneity (specifically, code data distribution) on the outcomes of federated learning models, providing insights into how varying data characteristics affect model performance and generalization in this domain.\n\n**5. Experimental Validation**\n*   **Experiments Conducted:** The research conducted experiments to assess the efficacy of federated learning in the collaborative development and maintenance of AI-based SE models, with a particular focus on the effects of data heterogeneity.\n*   **Key Performance Metrics and Comparison Results:**\n    *   **Data Scenarios:** Examined 6 different scenarios of code data distributions to simulate varying levels of heterogeneity among participating clients.\n    *   **Code Models:** Included 4 distinct code models, comprising both pre-trained models and one large foundational model, to evaluate the framework's generalizability.\n    *   **FL Algorithms:** Incorporated 4 common federated learning aggregation strategies.\n    *   **Key Findings:**\n        *   Federated learning demonstrated performance comparable to centralized training, validating its effectiveness without direct data sharing.\n        *   FL models achieved superior results compared to individual participants training models solely on their isolated local data.\n        *   The experimental results strongly support the potential of employing Federated Learning to foster collaboration among various companies in developing intelligent software engineering solutions while ensuring data privacy.\n\n**6. Limitations & Scope**\n*   **Technical Limitations/Assumptions:** As a \"position paper,\" some aspects of the proposed governance framework are conceptual and may require further empirical validation. The specific details of the datasets, models, and FL algorithms used in experiments are not fully elaborated in the provided text.\n*   **Scope of Applicability:** The framework is primarily applicable to scenarios where multiple organizations need to collaboratively train and improve AI-based SE models (e.g., for bug fixing, vulnerability detection) but are constrained by data privacy and commercial sensitivity concerns.\n\n**7. Technical Significance**\n*   **Advancement of State-of-the-Art:**\n    *   Provides a concrete, privacy-preserving framework that addresses the critical data sharing barrier in open-source AI-based SE tool development, shifting from isolated efforts to a truly collaborative ecosystem.\n    *   Offers empirical evidence that FL can effectively train high-performing code models under various data heterogeneity conditions, achieving results comparable to or better than centralized or isolated training.\n*   **Potential Impact on Future Research:**\n    *   Could inspire new paradigms for open-source AI development where data privacy is paramount, potentially fostering broader industry participation.\n    *   Opens avenues for further research into advanced FL algorithms tailored for code data, robust aggregation strategies, and the integration of decentralized technologies like blockchain for enhanced security and incentive mechanisms within the SE context.",
    "intriguing_abstract": "The transformative potential of open-source AI in Software Engineering (SE) is critically constrained by the paradox of needing vast, high-quality code data while respecting stringent privacy and proprietary concerns. This paper introduces a groundbreaking **decentralized governance framework** for open-source AI-based SE tools, leveraging **Federated Learning (FL)** to revolutionize collaborative model development. Our framework enables multiple organizations to co-construct and maintain sophisticated **AI code models**, including **Large Language Models (LLMs)**, without ever sharing sensitive local data. We propose comprehensive developer guidelines—covering data, model architecture, updating, and version control protocols—to standardize multi-party collaboration. Crucially, we uniquely investigate the profound impact of **code data distribution heterogeneity** on FL performance, a vital consideration for real-world deployments. Empirical validation across diverse code models and data scenarios demonstrates that FL achieves performance comparable to centralized training and significantly outperforms isolated efforts, validating its efficacy in privacy-preserving collaborative development. This work fundamentally shifts the paradigm for open-source AI in Software Engineering, fostering a truly collaborative ecosystem that respects data privacy and unlocks unprecedented industry participation in building intelligent SE solutions.",
    "keywords": [
      "Open-source AI-based SE tools",
      "Federated Learning (FL)",
      "Decentralized governance framework",
      "Code data heterogeneity",
      "Data privacy",
      "Collaborative model development",
      "Large Language Models (LLMs) in SE",
      "Developer guidelines",
      "Centralized vs. isolated vs. federated training",
      "Multi-organizational collaboration",
      "Privacy-preserving AI development"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6696018baf29273aa722e16eda89850247b8f0aa.pdf",
    "citation_key": "lin20242vi",
    "metadata": {
      "title": "Open Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning",
      "authors": [
        "Zhihao Lin",
        "Wei Ma",
        "Tao Lin",
        "Yaowen Zheng",
        "Jingquan Ge",
        "Jun Wang",
        "Jacques Klein",
        "Tégawendé F. Bissyandé",
        "Yang Liu",
        "Li Li"
      ],
      "published_date": "2024",
      "abstract": "Large language models (LLMs) have become instrumental in advancing software engineering (SE) tasks, showcasing their efficacy in code understanding and beyond. AI code models have demonstrated their value not only in code generation but also in defect detection, enhancing security measures and improving overall software quality. They are emerging as crucial tools for both software development and maintaining software quality. Like traditional SE tools, open source collaboration is key in realizing the excellent products. However, with AI models, the essential need is in data. The collaboration of these AI-based SE models hinges on maximizing the sources of high-quality data. However, data, especially of high quality, often hold commercial or sensitive value, making them less accessible for open source AI-based SE projects. This reality presents a significant barrier to the development and enhancement of AI-based SE tools within the SE community. Therefore, researchers need to find solutions for enabling open source AI-based SE models to tap into resources by different organizations. Addressing this challenge, our position article investigates one solution to facilitate access to diverse organizational resources for open source AI models, ensuring that privacy and commercial sensitivities are respected. We introduce a governance framework centered on federated learning (FL), designed to foster the joint development and maintenance of open source AI code models while safeguarding data privacy and security. Additionally, we present guidelines for developers on AI-based SE tool collaboration, covering data requirements, model architecture, updating strategies, and version control. Given the significant influence of data characteristics on FL, our research examines the effect of code data heterogeneity on FL performance. We consider six different scenarios of data distributions and include four code models. We also include four most common FL algorithms. Our experimental findings highlight the potential for employing FL in the collaborative development and maintenance of AI-based SE models. We also discuss the key issues to be addressed in the co-construction process and future research directions.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6696018baf29273aa722e16eda89850247b8f0aa.pdf",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "citationCount": 7,
      "score": 7.0,
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n---\n\n### Analysis of \"Open-Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning\" \\cite{lin20242vi}\n\n**1. Research Problem & Motivation**\n*   **Specific Technical Problem:** The paper addresses the significant barrier to developing and enhancing open-source AI-based Software Engineering (SE) tools: the limited access to high-quality, sensitive code data from diverse organizations. Current open-source AI model development is often isolated, leading to redundant efforts and unverified improvements.\n*   **Importance and Challenge:**\n    *   High-quality code data is crucial for the performance of AI models, especially Large Language Models (LLMs) in SE, but its growth rate in public domains is insufficient.\n    *   Commercial IT companies possess valuable, sensitive code data but are reluctant to share it due to privacy and proprietary concerns.\n    *   The existing unipartite participation model for open-source AI models leads to low economic efficiency and a lack of strong community support, unlike traditional open-source software.\n\n**2. Related Work & Positioning**\n*   **Relation to Existing Approaches:** The work relates to existing applications of Federated Learning (FL) in SE, such as FedCSD \\cite{lin20242vi} for code smell detection and ALMITY \\cite{lin20242vi} for applying academic models to industrial settings.\n*   **Limitations of Previous Solutions:**\n    *   Prior FL applications in SE did not thoroughly investigate the impact of code data distribution heterogeneity on FL performance.\n    *   They did not consider FL's potential to fundamentally change the governance and community dynamics of open-source code models.\n    *   Traditional open-source model dissemination platforms (e.g., Huggingface) facilitate sharing but do not enable true collaborative model development and maintenance across organizations with sensitive data.\n\n**3. Technical Approach & Innovation**\n*   **Core Technical Method:** The paper proposes a **decentralized governance framework for open-source AI-based SE tools centered on Federated Learning (FL)**. This framework enables multiple entities to collaboratively train and maintain AI code models without directly sharing their proprietary local data.\n*   **Novelty/Differentiation:**\n    *   **FL-based Governance Framework:** Introduces a structured approach for multi-party collaboration in open-source AI model development, explicitly designed to respect data privacy and commercial sensitivities.\n    *   **Comprehensive Developer Guidelines:** Defines protocols for collaborative development, including:\n        *   **Data Protocol:** Specifies data formats, quality standards, and test data requirements.\n        *   **Model Architecture Protocol:** Ensures local training adheres to a predefined exemplary model architecture.\n        *   **Model Updating Strategies:** Outlines methods for aggregating client model updates (e.g., averaging).\n        *   **Version Control Protocol:** Defines checkpoint saving, performance thresholds for releases, and versioning rules.\n    *   **Governance Committee:** Establishes a mechanism for community management, reviewing contributions (pull requests), and maintaining developer guidelines.\n    *   **Empirical Focus on Data Heterogeneity:** Uniquely investigates the critical impact of diverse code data distributions on FL performance, which is essential for real-world multi-organizational collaboration.\n\n**4. Key Technical Contributions**\n*   **System Design/Architectural Innovations:**\n    *   A novel governance framework for open-source AI-based SE tools, leveraging federated learning to facilitate collaborative model development while preserving data privacy and security.\n    *   Detailed developer guidelines (Data, Model Architecture, Model Updating, Version Control Protocols) to standardize and enable multi-party collaboration in AI model co-construction.\n*   **Theoretical Insights/Analysis:**\n    *   A thorough investigation into the influence of data heterogeneity (specifically, code data distribution) on the outcomes of federated learning models, providing insights into how varying data characteristics affect model performance and generalization in this domain.\n\n**5. Experimental Validation**\n*   **Experiments Conducted:** The research conducted experiments to assess the efficacy of federated learning in the collaborative development and maintenance of AI-based SE models, with a particular focus on the effects of data heterogeneity.\n*   **Key Performance Metrics and Comparison Results:**\n    *   **Data Scenarios:** Examined 6 different scenarios of code data distributions to simulate varying levels of heterogeneity among participating clients.\n    *   **Code Models:** Included 4 distinct code models, comprising both pre-trained models and one large foundational model, to evaluate the framework's generalizability.\n    *   **FL Algorithms:** Incorporated 4 common federated learning aggregation strategies.\n    *   **Key Findings:**\n        *   Federated learning demonstrated performance comparable to centralized training, validating its effectiveness without direct data sharing.\n        *   FL models achieved superior results compared to individual participants training models solely on their isolated local data.\n        *   The experimental results strongly support the potential of employing Federated Learning to foster collaboration among various companies in developing intelligent software engineering solutions while ensuring data privacy.\n\n**6. Limitations & Scope**\n*   **Technical Limitations/Assumptions:** As a \"position paper,\" some aspects of the proposed governance framework are conceptual and may require further empirical validation. The specific details of the datasets, models, and FL algorithms used in experiments are not fully elaborated in the provided text.\n*   **Scope of Applicability:** The framework is primarily applicable to scenarios where multiple organizations need to collaboratively train and improve AI-based SE models (e.g., for bug fixing, vulnerability detection) but are constrained by data privacy and commercial sensitivity concerns.\n\n**7. Technical Significance**\n*   **Advancement of State-of-the-Art:**\n    *   Provides a concrete, privacy-preserving framework that addresses the critical data sharing barrier in open-source AI-based SE tool development, shifting from isolated efforts to a truly collaborative ecosystem.\n    *   Offers empirical evidence that FL can effectively train high-performing code models under various data heterogeneity conditions, achieving results comparable to or better than centralized or isolated training.\n*   **Potential Impact on Future Research:**\n    *   Could inspire new paradigms for open-source AI development where data privacy is paramount, potentially fostering broader industry participation.\n    *   Opens avenues for further research into advanced FL algorithms tailored for code data, robust aggregation strategies, and the integration of decentralized technologies like blockchain for enhanced security and incentive mechanisms within the SE context.",
      "keywords": [
        "Open-source AI-based SE tools",
        "Federated Learning (FL)",
        "Decentralized governance framework",
        "Code data heterogeneity",
        "Data privacy",
        "Collaborative model development",
        "Large Language Models (LLMs) in SE",
        "Developer guidelines",
        "Centralized vs. isolated vs. federated training",
        "Multi-organizational collaboration",
        "Privacy-preserving AI development"
      ],
      "paper_type": "based on the abstract and introduction, this paper is a **position** paper.\n\nhere's why:\n\n1.  **explicit self-identification:** the abstract directly states: \"addressing this challenge, **our position paper investigates one solution** to facilitate access to diverse organizational resources for open-source ai models...\" this is the strongest indicator.\n2.  **argument for a viewpoint/solution:** the paper argues for a specific solution (a governance framework centered on federated learning) to address a current problem (data accessibility for open-source ai-based se projects). it also \"presents guidelines for developers.\"\n3.  **future direction:** the abstract concludes with: \"we also discuss the key issues to be addressed in the co-construction process and **future research directions**.\" this aligns with the \"future\" aspect of position papers.\n4.  **empirical support for position:** while the paper *does* include an empirical study (\"our research examines the effect of code data heterogeneity on fl performance. we consider 6 different scenarios... our experimental findings highlight the potential...\"), this study appears to be conducted *in support of* the paper's overall position and proposed solution, rather than being the sole or primary contribution. the empirical findings are used to \"highlight the potential for employing federated learning\" in the context of the proposed framework.\n\ntherefore, the primary classification is \"position\" because the empirical work serves to bolster the argument and proposed direction."
    },
    "file_name": "6696018baf29273aa722e16eda89850247b8f0aa.pdf"
  },
  {
    "success": true,
    "doc_id": "165a95d65523786b050a7386ea869144",
    "summary": "Here's a focused summary of the technical paper for a literature review, adhering to the specified citation and formatting requirements:\n\n### Technical Paper Analysis: POLARIS: A framework to guide the development of Trustworthy AI systems \\cite{baldassarre2024v2c}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** There is a significant gap between high-level AI ethics principles and concrete, actionable implementation strategies for AI professionals throughout the entire Software Development Life Cycle (SDLC) \\cite{baldassarre2024v2c}. AI practitioners often \"navigate by sight\" due to the difficulty in translating abstract recommendations into practical steps.\n    *   **Importance & Challenge:** Ensuring responsible development and deployment of AI systems is crucial as they become deeply integrated into daily life and influence critical decision-making. Unchecked AI can perpetuate biases, threaten privacy, and cause unintended societal harm. The \"principle proliferation\" phenomenon, where a multitude of ethical principles exist, further complicates practical application and overwhelms practitioners \\cite{baldassarre2024v2c}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work relates to numerous existing resources like ethical requirements, principles, guidelines, best practices, tools, and frameworks developed by public and private organizations to address Trustworthy AI (TAI) \\cite{baldassarre2024v2c}.\n    *   **Limitations of Previous Solutions:**\n        *   Most existing frameworks provide high-level principles/values (46.1%) but offer few actionable guidelines (29.6%) or concrete tools (9.2%) \\cite{baldassarre2024v2c}.\n        *   A significant majority (55.2%) of frameworks only provide support for the Requirements Elicitation phase, with a mere 5.7% covering all SDLC phases \\cite{baldassarre2024v2c}.\n        *   Over 80% of frameworks lack integrated tools, and when present, these tools are typically directed towards non-technical stakeholders \\cite{baldassarre2024v2c}.\n        *   This paper positions POLARIS as a solution to bridge this identified gap by providing practical, actionable guidance for technical AI practitioners across the entire SDLC \\cite{baldassarre2024v2c}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes POLARIS, a novel holistic framework for Trustworthy AI, designed to bridge the gap between theory and practice \\cite{baldassarre2024v2c}. POLARIS focuses on four foundational TAI pillars: Privacy, Security, Fairness, and Explainability, adopting specific definitions from the European Commission's \"Ethics guidelines for trustworthy AI\" \\cite{baldassarre2024v2c}.\n    *   **Novelty/Differentiation:**\n        *   **Actionable Guidelines & Tools:** Unlike most existing frameworks, POLARIS is designed to provide concrete, actionable guidelines and tools to support different types of stakeholders, including technical practitioners \\cite{baldassarre2024v2c}.\n        *   **Entire SDLC Coverage:** It uniquely aims to guide AI practitioners throughout the *entire* Software Development Life Cycle, addressing a critical limitation of prior work that often focuses only on early phases \\cite{baldassarre2024v2c}.\n        *   **Empirically Grounded Design:** The framework is built on an inductive process that includes a systematic review of the state of practice, a survey, and think-aloud interviews with 34 AI practitioners, ensuring it addresses real-world needs and challenges \\cite{baldassarre2024v2c}.\n        *   **Principle-to-Requirement Mapping:** It explicitly maps high-level TAI principles to concrete system requirements (e.g., Explainability to traceability, Fairness to bias avoidance, Security to resilience, Privacy to data integrity), making them tangible for technical implementation \\cite{baldassarre2024v2c}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Framework (POLARIS):** A holistic and actionable framework specifically engineered to guide the development of Trustworthy AI systems across all phases of the SDLC \\cite{baldassarre2024v2c}.\n    *   **Systematized Knowledge Base:** Organizes and makes accessible TAI knowledge, effectively translating abstract ethical principles (Privacy, Security, Fairness, Explainability) into practical, implementable guidelines for AI professionals \\cite{baldassarre2024v2c}.\n    *   **SDLC-wide Applicability:** Provides comprehensive support and actionable guidelines for *every phase* of the SDLC, addressing a critical gap where previous frameworks were largely limited to initial stages \\cite{baldassarre2024v2c}.\n    *   **Practitioner-Centric Design:** The framework's architecture and content are directly informed by extensive empirical research, including a systematic review and direct input from 34 AI practitioners, ensuring its relevance and utility for real-world technical challenges \\cite{baldassarre2024v2c}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The framework's development was empirically grounded through a multi-stage research process \\cite{baldassarre2024v2c}:\n        *   **Systematic Literature Review:** A comprehensive study of 138 existing TAI frameworks (from white- and grey-literature) was conducted to understand the state of practice, identify gaps in SDLC coverage, and assess the availability of actionable guidelines and tools \\cite{baldassarre2024v2c}.\n        *   **Practitioner Needs Identification:** An exploratory survey and think-aloud interviews were conducted with 34 AI professionals from diverse company sizes (small-medium to large) \\cite{baldassarre2024v2c}. This gathered insights on their existing practices, challenges, and unmet needs regarding TAI principles.\n    *   **Key Performance Metrics & Comparison Results (from practitioner study, informing POLARIS):**\n        *   The review found that most existing frameworks are high-level, lack actionable guidelines, and primarily support only the Requirements Elicitation phase, with very few covering the entire SDLC \\cite{baldassarre2024v2c}.\n        *   Practitioner survey results indicated that Privacy is the most frequently addressed TAI principle (58.8%), primarily during Design (64.7%) and Development (47.1%) phases \\cite{baldassarre2024v2c}.\n        *   A significant lack of TAI consideration was observed during the Test (29.4%) and Deploy (20.6%) phases, highlighting the critical need for SDLC-wide support \\cite{baldassarre2024v2c}.\n        *   A substantial portion of practitioners (50%) reported not attempting to resolve TAI-related issues when encountered, indicating a lack of practical solutions or knowledge \\cite{baldassarre2024v2c}.\n    *   **Initial Validation:** A \"first validation\" of the POLARIS framework was conducted through its application in an industrial case study \\cite{baldassarre2024v2c}. (Specific results of this application are not detailed in the provided text).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The initial validation is described as \"a first validation\" and providing \"preliminary results\" from an industrial case study \\cite{baldassarre2024v2c}, suggesting that more extensive and diverse validation might be required.\n        *   The framework explicitly focuses on four specific TAI principles (Privacy, Security, Fairness, Explainability), consciously excluding \"responsibility\" due to its infrequent occurrence and lack of a clear, universally accepted definition \\cite{baldassarre2024v2c}.\n        *   The practitioner survey used convenience sampling, which, while informative for framework design, might limit the generalizability of the identified practitioner needs \\cite{baldassarre2024v2c}.\n    *   **Scope of Applicability:**\n        *   The framework is designed to empower AI professionals and stakeholders involved in the development of AI-enabled systems \\cite{baldassarre2024v2c}.\n        *   It is intended to be applicable across the entire Software Development Life Cycle (SDLC) \\cite{baldassarre2024v2c}.\n        *   Its primary scope is to guide the development of Trustworthy AI systems by bridging the gap between high-level ethical principles and concrete implementation practices \\cite{baldassarre2024v2c}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** POLARIS significantly advances the technical state-of-the-art by providing a holistic, empirically-grounded, and actionable framework that directly addresses the critical gap between abstract AI ethics principles and practical, technical implementation throughout the entire SDLC \\cite{baldassarre2024v2c}. It moves beyond high-level statements to offer concrete guidance for technical practitioners.\n    *   **Potential Impact on Future Research:**\n        *   It can serve as a foundational tool for integrating TAI considerations from the earliest design phases through deployment and testing, fostering more robust and ethical AI development processes \\cite{baldassarre2024v2c}.\n        *   The framework's structured approach can help mitigate the confusion caused by \"principle proliferation,\" offering a clearer path for practitioners and potentially inspiring the development of specific tools and methodologies for TAI implementation at each SDLC stage \\cite{baldassarre2024v2c}.\n        *   It highlights the need for further research and development of support mechanisms for TAI in later SDLC phases (testing, deployment), where current support is notably lacking \\cite{baldassarre2024v2c}.",
    "intriguing_abstract": "The escalating integration of Artificial Intelligence into critical domains demands systems that are not only intelligent but inherently trustworthy. Yet, a profound chasm persists between high-level AI ethics principles and their concrete, actionable implementation by technical practitioners across the entire Software Development Life Cycle (SDLC). This \"principle proliferation\" leaves developers navigating complex ethical landscapes without adequate practical guidance, risking biases, privacy breaches, and security vulnerabilities.\n\nWe introduce POLARIS, a novel, empirically-grounded framework meticulously designed to bridge this critical theory-practice gap. Unlike existing approaches, POLARIS offers comprehensive, actionable guidelines and tools specifically tailored for technical AI professionals, uniquely covering *every phase* of the SDLC. Focusing on the foundational pillars of Privacy, Security, Fairness, and Explainability, our framework systematically translates abstract ethical principles into tangible system requirements. Developed through extensive systematic reviews and direct input from 34 AI practitioners, POLARIS empowers proactive integration of Trustworthy AI, fostering responsible innovation and building public confidence in AI systems. This work fundamentally transforms AI ethics from aspiration to engineering reality.",
    "keywords": [
      "POLARIS framework",
      "Trustworthy AI (TAI)",
      "AI ethics principles",
      "Software Development Life Cycle (SDLC)",
      "Actionable guidelines",
      "Privacy",
      "Security",
      "Fairness",
      "Explainability",
      "Empirically grounded design",
      "SDLC-wide applicability",
      "Principle-to-requirement mapping",
      "Gap between principles and implementation",
      "Systematic literature review",
      "Practitioner-centric design"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/1bc2fdf256855c485e77be27805f9febf9a70e75.pdf",
    "citation_key": "baldassarre2024v2c",
    "metadata": {
      "title": "POLARIS: A framework to guide the development of Trustworthy AI systems",
      "authors": [
        "M. T. Baldassarre",
        "Domenico Gigante",
        "Marcos Kalinowski",
        "Azzurra Ragone"
      ],
      "published_date": "2024",
      "abstract": "In the ever-expanding landscape of Artificial Intelligence (AI), where innovation thrives and new products and services are continuously being delivered, ensuring that AI systems are designed and developed responsibly throughout their entire lifecycle is crucial. To this end, several AI ethics principles and guidelines have been issued to which AI systems should conform. Nevertheless, relying solely on high-level AI ethics principles is far from sufficient to ensure the responsible engineering of AI systems. In this field, AI professionals often navigate by sight. Indeed, while recommendations promoting Trustworthy AI (TAI) exist, they are often high-level statements difficult to translate into concrete implementation strategies. Currently, there is a significant gap between high-level AI ethics principles and low-level concrete practices for AI professionals. To address this challenge, our work presents an experience report where we develop a novel holistic framework for Trustworthy AI — designed to bridge the gap between theory and practice — and report insights from its application in an industrial case study. The framework builds up from the results of a systematic review of the state of the practice as well as a survey and think-aloud interviews with 34 AI practitioners. The framework, unlike most of the ones in literature, is designed to provide actionable guidelines and tools to support different types of stakeholders throughout the entire Software Development Life Cycle (SDLC). Our goal is to empower AI professionals to confidently navigate the ethical dimensions of TAI through practical insights, ensuring that the vast potential of AI is exploited responsibly for the benefit of society as a whole.CCS CONCEPTS• Computing methodologies → Artificial intelligence; • Software and its engineering → Software creation and management.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/1bc2fdf256855c485e77be27805f9febf9a70e75.pdf",
      "venue": "2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN)",
      "citationCount": 7,
      "score": 7.0,
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to the specified citation and formatting requirements:\n\n### Technical Paper Analysis: POLARIS: A framework to guide the development of Trustworthy AI systems \\cite{baldassarre2024v2c}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** There is a significant gap between high-level AI ethics principles and concrete, actionable implementation strategies for AI professionals throughout the entire Software Development Life Cycle (SDLC) \\cite{baldassarre2024v2c}. AI practitioners often \"navigate by sight\" due to the difficulty in translating abstract recommendations into practical steps.\n    *   **Importance & Challenge:** Ensuring responsible development and deployment of AI systems is crucial as they become deeply integrated into daily life and influence critical decision-making. Unchecked AI can perpetuate biases, threaten privacy, and cause unintended societal harm. The \"principle proliferation\" phenomenon, where a multitude of ethical principles exist, further complicates practical application and overwhelms practitioners \\cite{baldassarre2024v2c}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work relates to numerous existing resources like ethical requirements, principles, guidelines, best practices, tools, and frameworks developed by public and private organizations to address Trustworthy AI (TAI) \\cite{baldassarre2024v2c}.\n    *   **Limitations of Previous Solutions:**\n        *   Most existing frameworks provide high-level principles/values (46.1%) but offer few actionable guidelines (29.6%) or concrete tools (9.2%) \\cite{baldassarre2024v2c}.\n        *   A significant majority (55.2%) of frameworks only provide support for the Requirements Elicitation phase, with a mere 5.7% covering all SDLC phases \\cite{baldassarre2024v2c}.\n        *   Over 80% of frameworks lack integrated tools, and when present, these tools are typically directed towards non-technical stakeholders \\cite{baldassarre2024v2c}.\n        *   This paper positions POLARIS as a solution to bridge this identified gap by providing practical, actionable guidance for technical AI practitioners across the entire SDLC \\cite{baldassarre2024v2c}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes POLARIS, a novel holistic framework for Trustworthy AI, designed to bridge the gap between theory and practice \\cite{baldassarre2024v2c}. POLARIS focuses on four foundational TAI pillars: Privacy, Security, Fairness, and Explainability, adopting specific definitions from the European Commission's \"Ethics guidelines for trustworthy AI\" \\cite{baldassarre2024v2c}.\n    *   **Novelty/Differentiation:**\n        *   **Actionable Guidelines & Tools:** Unlike most existing frameworks, POLARIS is designed to provide concrete, actionable guidelines and tools to support different types of stakeholders, including technical practitioners \\cite{baldassarre2024v2c}.\n        *   **Entire SDLC Coverage:** It uniquely aims to guide AI practitioners throughout the *entire* Software Development Life Cycle, addressing a critical limitation of prior work that often focuses only on early phases \\cite{baldassarre2024v2c}.\n        *   **Empirically Grounded Design:** The framework is built on an inductive process that includes a systematic review of the state of practice, a survey, and think-aloud interviews with 34 AI practitioners, ensuring it addresses real-world needs and challenges \\cite{baldassarre2024v2c}.\n        *   **Principle-to-Requirement Mapping:** It explicitly maps high-level TAI principles to concrete system requirements (e.g., Explainability to traceability, Fairness to bias avoidance, Security to resilience, Privacy to data integrity), making them tangible for technical implementation \\cite{baldassarre2024v2c}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Framework (POLARIS):** A holistic and actionable framework specifically engineered to guide the development of Trustworthy AI systems across all phases of the SDLC \\cite{baldassarre2024v2c}.\n    *   **Systematized Knowledge Base:** Organizes and makes accessible TAI knowledge, effectively translating abstract ethical principles (Privacy, Security, Fairness, Explainability) into practical, implementable guidelines for AI professionals \\cite{baldassarre2024v2c}.\n    *   **SDLC-wide Applicability:** Provides comprehensive support and actionable guidelines for *every phase* of the SDLC, addressing a critical gap where previous frameworks were largely limited to initial stages \\cite{baldassarre2024v2c}.\n    *   **Practitioner-Centric Design:** The framework's architecture and content are directly informed by extensive empirical research, including a systematic review and direct input from 34 AI practitioners, ensuring its relevance and utility for real-world technical challenges \\cite{baldassarre2024v2c}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The framework's development was empirically grounded through a multi-stage research process \\cite{baldassarre2024v2c}:\n        *   **Systematic Literature Review:** A comprehensive study of 138 existing TAI frameworks (from white- and grey-literature) was conducted to understand the state of practice, identify gaps in SDLC coverage, and assess the availability of actionable guidelines and tools \\cite{baldassarre2024v2c}.\n        *   **Practitioner Needs Identification:** An exploratory survey and think-aloud interviews were conducted with 34 AI professionals from diverse company sizes (small-medium to large) \\cite{baldassarre2024v2c}. This gathered insights on their existing practices, challenges, and unmet needs regarding TAI principles.\n    *   **Key Performance Metrics & Comparison Results (from practitioner study, informing POLARIS):**\n        *   The review found that most existing frameworks are high-level, lack actionable guidelines, and primarily support only the Requirements Elicitation phase, with very few covering the entire SDLC \\cite{baldassarre2024v2c}.\n        *   Practitioner survey results indicated that Privacy is the most frequently addressed TAI principle (58.8%), primarily during Design (64.7%) and Development (47.1%) phases \\cite{baldassarre2024v2c}.\n        *   A significant lack of TAI consideration was observed during the Test (29.4%) and Deploy (20.6%) phases, highlighting the critical need for SDLC-wide support \\cite{baldassarre2024v2c}.\n        *   A substantial portion of practitioners (50%) reported not attempting to resolve TAI-related issues when encountered, indicating a lack of practical solutions or knowledge \\cite{baldassarre2024v2c}.\n    *   **Initial Validation:** A \"first validation\" of the POLARIS framework was conducted through its application in an industrial case study \\cite{baldassarre2024v2c}. (Specific results of this application are not detailed in the provided text).\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   The initial validation is described as \"a first validation\" and providing \"preliminary results\" from an industrial case study \\cite{baldassarre2024v2c}, suggesting that more extensive and diverse validation might be required.\n        *   The framework explicitly focuses on four specific TAI principles (Privacy, Security, Fairness, Explainability), consciously excluding \"responsibility\" due to its infrequent occurrence and lack of a clear, universally accepted definition \\cite{baldassarre2024v2c}.\n        *   The practitioner survey used convenience sampling, which, while informative for framework design, might limit the generalizability of the identified practitioner needs \\cite{baldassarre2024v2c}.\n    *   **Scope of Applicability:**\n        *   The framework is designed to empower AI professionals and stakeholders involved in the development of AI-enabled systems \\cite{baldassarre2024v2c}.\n        *   It is intended to be applicable across the entire Software Development Life Cycle (SDLC) \\cite{baldassarre2024v2c}.\n        *   Its primary scope is to guide the development of Trustworthy AI systems by bridging the gap between high-level ethical principles and concrete implementation practices \\cite{baldassarre2024v2c}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** POLARIS significantly advances the technical state-of-the-art by providing a holistic, empirically-grounded, and actionable framework that directly addresses the critical gap between abstract AI ethics principles and practical, technical implementation throughout the entire SDLC \\cite{baldassarre2024v2c}. It moves beyond high-level statements to offer concrete guidance for technical practitioners.\n    *   **Potential Impact on Future Research:**\n        *   It can serve as a foundational tool for integrating TAI considerations from the earliest design phases through deployment and testing, fostering more robust and ethical AI development processes \\cite{baldassarre2024v2c}.\n        *   The framework's structured approach can help mitigate the confusion caused by \"principle proliferation,\" offering a clearer path for practitioners and potentially inspiring the development of specific tools and methodologies for TAI implementation at each SDLC stage \\cite{baldassarre2024v2c}.\n        *   It highlights the need for further research and development of support mechanisms for TAI in later SDLC phases (testing, deployment), where current support is notably lacking \\cite{baldassarre2024v2c}.",
      "keywords": [
        "POLARIS framework",
        "Trustworthy AI (TAI)",
        "AI ethics principles",
        "Software Development Life Cycle (SDLC)",
        "Actionable guidelines",
        "Privacy",
        "Security",
        "Fairness",
        "Explainability",
        "Empirically grounded design",
        "SDLC-wide applicability",
        "Principle-to-requirement mapping",
        "Gap between principles and implementation",
        "Systematic literature review",
        "Practitioner-centric design"
      ],
      "paper_type": "the paper should be classified as **technical**.\n\nhere's why:\n\n1.  **core contribution:** the abstract explicitly states, \"our work presents an experience report where we **develop a novel holistic framework** for trustworthy ai\". the creation and presentation of this new framework (polaris) is the central contribution of the paper. this directly aligns with the \"technical\" criterion: \"presents new methods, algorithms, or systems.\"\n2.  **problem and solution:** the introduction and abstract highlight a significant gap (\"difficult to translate into concrete implementation strategies,\" \"gap between high-level ai ethics principles and low-level concrete practices\"). the proposed framework is the solution to this technical/practical problem in ai engineering.\n3.  **supporting elements:** while the paper mentions using a \"systematic review,\" \"survey and think-aloud interviews with 34 ai practitioners\" (empirical elements), and reporting \"insights from its application in an industrial case study\" (case study element), these are methods used *to build and evaluate* the novel framework. they are components of the research, but the primary output is the framework itself. the paper isn't *just* a survey, *just* an empirical study, or *just* a case study; it's presenting a new system/method that leverages these approaches."
    },
    "file_name": "1bc2fdf256855c485e77be27805f9febf9a70e75.pdf"
  },
  {
    "success": true,
    "doc_id": "95ab8c601c0de0e2813e0d375f0ab3d7",
    "summary": "Foundation models, such as GPT-4, DALL-E have brought unprecedented AI\"operating system\"effect and new forms of human-AI interaction, sparking a wave of innovation in AI-native services, where natural language prompts serve as executable\"code\"directly (prompt as executable code), eliminating the need for programming language as an intermediary and opening up the door to personal AI. Prompt Sapper has emerged in response, committed to support the development of AI-native services by AI chain engineering. It creates a large language model (LLM) empowered software engineering infrastructure for authoring AI chains through human-AI collaborative intelligence, unleashing the AI innovation potential of every individual, and forging a future where everyone can be a master of AI innovation. This article will introduce the R\\&D motivation behind Prompt Sapper, along with its corresponding AI chain engineering methodology and technical practices.",
    "intriguing_abstract": "Foundation models, such as GPT-4, DALL-E have brought unprecedented AI\"operating system\"effect and new forms of human-AI interaction, sparking a wave of innovation in AI-native services, where natural language prompts serve as executable\"code\"directly (prompt as executable code), eliminating the need for programming language as an intermediary and opening up the door to personal AI. Prompt Sapper has emerged in response, committed to support the development of AI-native services by AI chain engineering. It creates a large language model (LLM) empowered software engineering infrastructure for authoring AI chains through human-AI collaborative intelligence, unleashing the AI innovation potential of every individual, and forging a future where everyone can be a master of AI innovation. This article will introduce the R\\&D motivation behind Prompt Sapper, along with its corresponding AI chain engineering methodology and technical practices.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/486a8c8655b81c7f87ff257141466ec1186d4aea.pdf",
    "citation_key": "xing2023rhn",
    "metadata": {
      "title": "Prompt Sapper: LLM-Empowered Software Engineering Infrastructure for AI-Native Services",
      "authors": [
        "Zhenchang Xing",
        "Qing Huang",
        "Yu Cheng",
        "Liming Zhu",
        "Qinghua Lu",
        "Xiwei Xu"
      ],
      "published_date": "2023",
      "abstract": "Foundation models, such as GPT-4, DALL-E have brought unprecedented AI\"operating system\"effect and new forms of human-AI interaction, sparking a wave of innovation in AI-native services, where natural language prompts serve as executable\"code\"directly (prompt as executable code), eliminating the need for programming language as an intermediary and opening up the door to personal AI. Prompt Sapper has emerged in response, committed to support the development of AI-native services by AI chain engineering. It creates a large language model (LLM) empowered software engineering infrastructure for authoring AI chains through human-AI collaborative intelligence, unleashing the AI innovation potential of every individual, and forging a future where everyone can be a master of AI innovation. This article will introduce the R\\&D motivation behind Prompt Sapper, along with its corresponding AI chain engineering methodology and technical practices.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/486a8c8655b81c7f87ff257141466ec1186d4aea.pdf",
      "venue": "arXiv.org",
      "citationCount": 13,
      "score": 6.5,
      "summary": "Foundation models, such as GPT-4, DALL-E have brought unprecedented AI\"operating system\"effect and new forms of human-AI interaction, sparking a wave of innovation in AI-native services, where natural language prompts serve as executable\"code\"directly (prompt as executable code), eliminating the need for programming language as an intermediary and opening up the door to personal AI. Prompt Sapper has emerged in response, committed to support the development of AI-native services by AI chain engineering. It creates a large language model (LLM) empowered software engineering infrastructure for authoring AI chains through human-AI collaborative intelligence, unleashing the AI innovation potential of every individual, and forging a future where everyone can be a master of AI innovation. This article will introduce the R\\&D motivation behind Prompt Sapper, along with its corresponding AI chain engineering methodology and technical practices.",
      "keywords": []
    },
    "file_name": "486a8c8655b81c7f87ff257141466ec1186d4aea.pdf"
  },
  {
    "success": true,
    "doc_id": "0d8cf1b6c0332732c5b80ca38aa65ce5",
    "summary": "StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.",
    "intriguing_abstract": "StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/087c7bc7b0bbe55fd41a7213a5699504a4677fa1.pdf",
    "citation_key": "neyem20249pc",
    "metadata": {
      "title": "Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development",
      "authors": [
        "Andrés Neyem",
        "Juan Pablo Sandoval Alcocer",
        "M. Mendoza",
        "Leonardo Centellas-Claros",
        "Luis A. González",
        "Carlos Paredes-Robles"
      ],
      "published_date": "2024",
      "abstract": "StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/087c7bc7b0bbe55fd41a7213a5699504a4677fa1.pdf",
      "venue": "Technical Symposium on Computer Science Education",
      "citationCount": 6,
      "score": 6.0,
      "summary": "StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.",
      "keywords": []
    },
    "file_name": "087c7bc7b0bbe55fd41a7213a5699504a4677fa1.pdf"
  },
  {
    "success": true,
    "doc_id": "8c0191b571a81d443debadf55f0bfc7a",
    "summary": "As GenAI becomes embedded in developer toolchains and practices, and routine code is increasingly generated, human creativity will be increasingly important for generating competitive advantage. This article uses the McLuhan tetrad alongside scenarios of how GenAI may disrupt software development more broadly, to identify potential impacts GenAI may have on creativity within software development. The impacts are discussed along with a future research agenda comprising five connected themes that consider how individual capabilities, team capabilities, the product, unintended consequences, and society can be affected.",
    "intriguing_abstract": "As GenAI becomes embedded in developer toolchains and practices, and routine code is increasingly generated, human creativity will be increasingly important for generating competitive advantage. This article uses the McLuhan tetrad alongside scenarios of how GenAI may disrupt software development more broadly, to identify potential impacts GenAI may have on creativity within software development. The impacts are discussed along with a future research agenda comprising five connected themes that consider how individual capabilities, team capabilities, the product, unintended consequences, and society can be affected.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/cf6d04ed9f209c88615cdc9596e0c1435f411567.pdf",
    "citation_key": "jackson2024did",
    "metadata": {
      "title": "The Impact of Generative AI on Creativity in Software Development: A Research Agenda",
      "authors": [
        "Victoria Jackson",
        "Bogdan Vasilescu",
        "Daniel Russo",
        "Paul Ralph",
        "R. Prikladnicki",
        "Maliheh Izadi",
        "Sarah D'Angelo",
        "Sarah Inman",
        "Anielle Andrade",
        "André van der Hoek"
      ],
      "published_date": "2024",
      "abstract": "As GenAI becomes embedded in developer toolchains and practices, and routine code is increasingly generated, human creativity will be increasingly important for generating competitive advantage. This article uses the McLuhan tetrad alongside scenarios of how GenAI may disrupt software development more broadly, to identify potential impacts GenAI may have on creativity within software development. The impacts are discussed along with a future research agenda comprising five connected themes that consider how individual capabilities, team capabilities, the product, unintended consequences, and society can be affected.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/cf6d04ed9f209c88615cdc9596e0c1435f411567.pdf",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "citationCount": 6,
      "score": 6.0,
      "summary": "As GenAI becomes embedded in developer toolchains and practices, and routine code is increasingly generated, human creativity will be increasingly important for generating competitive advantage. This article uses the McLuhan tetrad alongside scenarios of how GenAI may disrupt software development more broadly, to identify potential impacts GenAI may have on creativity within software development. The impacts are discussed along with a future research agenda comprising five connected themes that consider how individual capabilities, team capabilities, the product, unintended consequences, and society can be affected.",
      "keywords": []
    },
    "file_name": "cf6d04ed9f209c88615cdc9596e0c1435f411567.pdf"
  },
  {
    "success": true,
    "doc_id": "3f4ec0ec6d9f7a5dba05c12bf86aa3d3",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d8e9e23a7bfb4f3d5e6d4b3e7188b9d70a4a0306.pdf",
    "citation_key": "ozkaya2023v7y",
    "metadata": {
      "title": "Can Architecture Knowledge Guide Software Development With Generative AI?",
      "authors": [
        "Ipek Ozkaya"
      ],
      "published_date": "2023",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d8e9e23a7bfb4f3d5e6d4b3e7188b9d70a4a0306.pdf",
      "venue": "IEEE Software",
      "citationCount": 12,
      "score": 6.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "d8e9e23a7bfb4f3d5e6d4b3e7188b9d70a4a0306.pdf"
  },
  {
    "success": true,
    "doc_id": "b8fe9fb72e0b76d79ae400433aa81b7f",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n---\n\n### Technical Paper Analysis: Experimenting with Multi-Agent Software Development: Towards a Unified Platform \\cite{sami202475w}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of developing a cohesive, unified platform that leverages AI-powered techniques, particularly Large Language Models (LLMs), to consistently produce optimal outcomes across all stages of the software development process (SDLC) \\cite{sami202475w}. This includes transforming user requirements into structured deliverables like user stories, prioritization, UML diagrams, APIs, unit tests, and end-to-end tests, while also managing tasks, security, compliance, and suggesting design patterns.\n    *   **Importance and Challenge:** While LLMs are redefining software engineering by automating various tasks, a unified, end-to-end platform that integrates these capabilities seamlessly, ensures consistent quality, adheres to standards (e.g., European compliance), and allows for human control at each stage is still difficult to achieve \\cite{sami202475w}. Software development is inherently collaborative, and existing LLM applications often lack this comprehensive, unified approach, facing issues like inaccurate information (hallucinations) and limitations in natural language comprehension \\cite{sami202475w}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds upon advancements in generative AI and LLMs (e.g., GPT series, LLaMA, ChatGPT) for code generation, natural language understanding, and insights in software engineering \\cite{sami202475w}. It also draws from multi-agent systems that emulate development roles (e.g., Lin et al. [18], Tang et al. [43], Wang et al. [49]) and agent-based code generation using external tools or simulating human jobs (e.g., Huang et al. [15], Zhong et al. [54], Zeeshan et al. [34]) \\cite{sami202475w}.\n    *   **Limitations of Previous Solutions:** Existing multi-agent LLM frameworks often focus on specific aspects or diverge from a holistic SDLC perspective, failing to provide a \"unified platform approach where requirements to user stories, prioritization, design architecture, and both generations of frontend and end-to-end with security, best practices, and patterns according to standards are defined\" \\cite{sami202475w}. Furthermore, LLMs still face challenges like generating inaccurate information (hallucinations) and limitations in natural language comprehension and domain knowledge, necessitating a more robust, integrated solution \\cite{sami202475w}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a multi-agent unified platform designed to automate the SDLC by converting user requirements into structured software development outputs \\cite{sami202475w}. This platform employs specialized AI agents for different phases: Requirements Engineering, Architecting, Code Generation, Testing, and Compliance.\n    *   **Novelty/Difference:**\n        *   **Unified Multi-Agent Architecture:** Integrates multiple LLM-based agents (using GPT-3.5, GPT-4, and Llama3) into a single, cohesive platform that spans the entire SDLC, from requirements to deployment \\cite{sami202475w}.\n        *   **End-to-End Automation with Human-in-the-Loop:** Automates the generation of user stories, prioritization, UML diagrams (via PlantUML), modular Python (backend) and React (frontend) code, unit tests, and end-to-end tests, while allowing users to control and manage each phase \\cite{sami202475w}.\n        *   **Integrated Compliance and Best Practices:** Incorporates security and compliance checks (following European standards) and suggests design patterns and improvements for non-functional requirements directly within the development workflow \\cite{sami202475w}.\n        *   **Algorithmic Framework:** Introduces specific algorithms, such as Algorithm 1 for the Requirements Engineering process, detailing how LLM-based agents collect, generate, and prioritize user stories using methods like AHP, MoSCoW, and 100 Dollar \\cite{sami202475w}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   An LLM-based multi-agent system architecture for automating the SDLC, integrating various LLMs (GPT-3.5, GPT-4, Llama3) \\cite{sami202475w}.\n        *   Algorithm 1 for an LLM-based Requirements Engineering process, including user story generation and prioritization using AHP, MoSCoW, and 100 Dollar techniques \\cite{sami202475w}.\n    *   **System Design or Architectural Innovations:**\n        *   A unified platform that bridges the gap between requirements engineering and technical development by generating UML diagrams from prioritized requirements using an LLM agent and PlantUML \\cite{sami202475w}.\n        *   Automated generation of modular Python code (backend) and React code (frontend) with corresponding unit and end-to-end test cases \\cite{sami202475w}.\n        *   Integration of a Compliance Agent to ensure adherence to European standards, regulations, and security throughout the development process \\cite{sami202475w}.\n    *   **Theoretical Insights or Analysis:** The work demonstrates a practical framework for orchestrating diverse LLM capabilities into a coherent, automated software development pipeline, highlighting the potential for multi-agent systems to manage complex, sequential tasks in software engineering.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The paper states that \"Section 4 presents the initial results\" \\cite{sami202475w}. However, the provided text content (abstract, introduction, background, proposed platform) does not detail the specific experiments conducted, their setup, or methodologies. It describes the *design* and *functionality* of the proposed platform and its agents.\n    *   **Key Performance Metrics and Comparison Results:** No specific performance metrics or comparison results are presented in the provided text. The \"Data Analysis\" section (3.6) mentions the intent to \"measure the overall effectiveness of the suggested modules\" and \"the multi-agent system’s efficacy in various projects and scenarios,\" including the \"performance of the APIs of each life cycle,\" but no actual data or findings are included \\cite{sami202475w}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions:** The paper acknowledges \"limitations and future research discussions to overall improve the software development life cycle\" \\cite{sami202475w}. While a dedicated \"Threats and Limitations\" section (Section 6) is mentioned, its content is not provided. Implicitly, the general challenges of LLMs, such as hallucinations and limitations in domain knowledge, are recognized as areas needing further research \\cite{sami202475w}.\n    *   **Scope of Applicability:** The platform aims to automate the entire SDLC, from initial user requirements to deployment-ready software, focusing on generating structured deliverables, code, and tests, along with compliance and design suggestions \\cite{sami202475w}. It specifically targets Python for backend and React for frontend development. The source code is hosted on GitHub, indicating its applicability for further research and practical experimentation \\cite{sami202475w}.\n\n7.  **Technical Significance**\n    *   **Advance the Technical State-of-the-Art:** This work significantly advances the state-of-the-art by proposing and outlining a truly \"unified platform\" for multi-agent LLM-driven software development, addressing the fragmentation often seen in existing LLM applications across the SDLC \\cite{sami202475w}. It demonstrates a comprehensive integration of requirements engineering, architectural design, code generation, testing, and compliance into a single, automated, and user-controlled framework.\n    *   **Potential Impact on Future Research:** The open-source nature of the platform (GitHub hosted) provides a valuable foundation for future research into multi-agent systems for software engineering \\cite{sami202475w}. It encourages further exploration into improving LLM accuracy, mitigating hallucinations, enhancing domain-specific knowledge, and refining human-AI collaboration models. The integrated approach to security and compliance also opens new avenues for research into building inherently more secure and compliant AI-driven development pipelines, potentially leading to more efficient, higher-quality, and compliant software development processes \\cite{sami202475w}.",
    "intriguing_abstract": "The promise of AI-driven software development often falters at fragmentation, with current Large Language Model (LLM) applications lacking a cohesive, end-to-end approach across the entire Software Development Life Cycle (SDLC). We introduce a novel **unified multi-agent platform** that revolutionizes this paradigm, orchestrating specialized AI agents (powered by GPT-3.5, GPT-4, and Llama3) to automate the SDLC from initial user requirements to deployment-ready code.\n\nOur system seamlessly transforms natural language requirements into structured deliverables, including prioritized user stories (using AHP, MoSCoW, 100 Dollar techniques), UML diagrams via PlantUML, modular Python backend and React frontend code, and comprehensive unit and end-to-end tests. Crucially, it integrates a **human-in-the-loop** mechanism for critical oversight and incorporates a dedicated Compliance Agent to ensure adherence to European standards and best practices. This innovative architecture, detailed with specific algorithms like our Requirements Engineering process, mitigates LLM limitations while fostering unprecedented efficiency, quality, and regulatory compliance. This work paves the way for a new era of intelligent, integrated, and trustworthy software engineering.",
    "keywords": [
      "Multi-agent software development",
      "Unified platform",
      "Large Language Models (LLMs)",
      "SDLC automation",
      "End-to-end automation",
      "Requirements engineering",
      "Code generation",
      "Testing automation",
      "Compliance integration",
      "Human-in-the-loop",
      "Algorithmic framework",
      "UML diagrams",
      "User story prioritization",
      "Design patterns"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/917ba30d8d00e17c53545badc8fc76e403f8ac09.pdf",
    "citation_key": "sami202475w",
    "metadata": {
      "title": "Experimenting with Multi-Agent Software Development: Towards a Unified Platform",
      "authors": [
        "Malik Abdul Sami",
        "Muhammad Waseem",
        "Zeeshan Rasheed",
        "Mika Saari",
        "Kari Systä",
        "Pekka Abrahamsson"
      ],
      "published_date": "2024",
      "abstract": "Large language models are redefining software engineering by implementing AI-powered techniques throughout the whole software development process, including requirement gathering, software architecture, code generation, testing, and deployment. However, it is still difficult to develop a cohesive platform that consistently produces the best outcomes across all stages. The objective of this study is to develop a unified platform that utilizes multiple artificial intelligence agents to automate the process of transforming user requirements into well-organized deliverables. These deliverables include user stories, prioritization, and UML sequence diagrams, along with the modular approach to APIs, unit tests, and end-to-end tests. Additionally, the platform will organize tasks, perform security and compliance, and suggest design patterns and improvements for non-functional requirements. We allow users to control and manage each phase according to their preferences. In addition, the platform provides security and compliance checks following European standards and proposes design optimizations. We use multiple models, such as GPT-3.5, GPT-4, and Llama3 to enable to generation of modular code as per user choice. The research also highlights the limitations and future research discussions to overall improve the software development life cycle. The source code for our uniform platform is hosted on GitHub, enabling additional experimentation and supporting both research and practical uses. \\end",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/917ba30d8d00e17c53545badc8fc76e403f8ac09.pdf",
      "venue": "arXiv.org",
      "citationCount": 6,
      "score": 6.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n---\n\n### Technical Paper Analysis: Experimenting with Multi-Agent Software Development: Towards a Unified Platform \\cite{sami202475w}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the challenge of developing a cohesive, unified platform that leverages AI-powered techniques, particularly Large Language Models (LLMs), to consistently produce optimal outcomes across all stages of the software development process (SDLC) \\cite{sami202475w}. This includes transforming user requirements into structured deliverables like user stories, prioritization, UML diagrams, APIs, unit tests, and end-to-end tests, while also managing tasks, security, compliance, and suggesting design patterns.\n    *   **Importance and Challenge:** While LLMs are redefining software engineering by automating various tasks, a unified, end-to-end platform that integrates these capabilities seamlessly, ensures consistent quality, adheres to standards (e.g., European compliance), and allows for human control at each stage is still difficult to achieve \\cite{sami202475w}. Software development is inherently collaborative, and existing LLM applications often lack this comprehensive, unified approach, facing issues like inaccurate information (hallucinations) and limitations in natural language comprehension \\cite{sami202475w}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds upon advancements in generative AI and LLMs (e.g., GPT series, LLaMA, ChatGPT) for code generation, natural language understanding, and insights in software engineering \\cite{sami202475w}. It also draws from multi-agent systems that emulate development roles (e.g., Lin et al. [18], Tang et al. [43], Wang et al. [49]) and agent-based code generation using external tools or simulating human jobs (e.g., Huang et al. [15], Zhong et al. [54], Zeeshan et al. [34]) \\cite{sami202475w}.\n    *   **Limitations of Previous Solutions:** Existing multi-agent LLM frameworks often focus on specific aspects or diverge from a holistic SDLC perspective, failing to provide a \"unified platform approach where requirements to user stories, prioritization, design architecture, and both generations of frontend and end-to-end with security, best practices, and patterns according to standards are defined\" \\cite{sami202475w}. Furthermore, LLMs still face challenges like generating inaccurate information (hallucinations) and limitations in natural language comprehension and domain knowledge, necessitating a more robust, integrated solution \\cite{sami202475w}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper proposes a multi-agent unified platform designed to automate the SDLC by converting user requirements into structured software development outputs \\cite{sami202475w}. This platform employs specialized AI agents for different phases: Requirements Engineering, Architecting, Code Generation, Testing, and Compliance.\n    *   **Novelty/Difference:**\n        *   **Unified Multi-Agent Architecture:** Integrates multiple LLM-based agents (using GPT-3.5, GPT-4, and Llama3) into a single, cohesive platform that spans the entire SDLC, from requirements to deployment \\cite{sami202475w}.\n        *   **End-to-End Automation with Human-in-the-Loop:** Automates the generation of user stories, prioritization, UML diagrams (via PlantUML), modular Python (backend) and React (frontend) code, unit tests, and end-to-end tests, while allowing users to control and manage each phase \\cite{sami202475w}.\n        *   **Integrated Compliance and Best Practices:** Incorporates security and compliance checks (following European standards) and suggests design patterns and improvements for non-functional requirements directly within the development workflow \\cite{sami202475w}.\n        *   **Algorithmic Framework:** Introduces specific algorithms, such as Algorithm 1 for the Requirements Engineering process, detailing how LLM-based agents collect, generate, and prioritize user stories using methods like AHP, MoSCoW, and 100 Dollar \\cite{sami202475w}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   An LLM-based multi-agent system architecture for automating the SDLC, integrating various LLMs (GPT-3.5, GPT-4, Llama3) \\cite{sami202475w}.\n        *   Algorithm 1 for an LLM-based Requirements Engineering process, including user story generation and prioritization using AHP, MoSCoW, and 100 Dollar techniques \\cite{sami202475w}.\n    *   **System Design or Architectural Innovations:**\n        *   A unified platform that bridges the gap between requirements engineering and technical development by generating UML diagrams from prioritized requirements using an LLM agent and PlantUML \\cite{sami202475w}.\n        *   Automated generation of modular Python code (backend) and React code (frontend) with corresponding unit and end-to-end test cases \\cite{sami202475w}.\n        *   Integration of a Compliance Agent to ensure adherence to European standards, regulations, and security throughout the development process \\cite{sami202475w}.\n    *   **Theoretical Insights or Analysis:** The work demonstrates a practical framework for orchestrating diverse LLM capabilities into a coherent, automated software development pipeline, highlighting the potential for multi-agent systems to manage complex, sequential tasks in software engineering.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The paper states that \"Section 4 presents the initial results\" \\cite{sami202475w}. However, the provided text content (abstract, introduction, background, proposed platform) does not detail the specific experiments conducted, their setup, or methodologies. It describes the *design* and *functionality* of the proposed platform and its agents.\n    *   **Key Performance Metrics and Comparison Results:** No specific performance metrics or comparison results are presented in the provided text. The \"Data Analysis\" section (3.6) mentions the intent to \"measure the overall effectiveness of the suggested modules\" and \"the multi-agent system’s efficacy in various projects and scenarios,\" including the \"performance of the APIs of each life cycle,\" but no actual data or findings are included \\cite{sami202475w}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions:** The paper acknowledges \"limitations and future research discussions to overall improve the software development life cycle\" \\cite{sami202475w}. While a dedicated \"Threats and Limitations\" section (Section 6) is mentioned, its content is not provided. Implicitly, the general challenges of LLMs, such as hallucinations and limitations in domain knowledge, are recognized as areas needing further research \\cite{sami202475w}.\n    *   **Scope of Applicability:** The platform aims to automate the entire SDLC, from initial user requirements to deployment-ready software, focusing on generating structured deliverables, code, and tests, along with compliance and design suggestions \\cite{sami202475w}. It specifically targets Python for backend and React for frontend development. The source code is hosted on GitHub, indicating its applicability for further research and practical experimentation \\cite{sami202475w}.\n\n7.  **Technical Significance**\n    *   **Advance the Technical State-of-the-Art:** This work significantly advances the state-of-the-art by proposing and outlining a truly \"unified platform\" for multi-agent LLM-driven software development, addressing the fragmentation often seen in existing LLM applications across the SDLC \\cite{sami202475w}. It demonstrates a comprehensive integration of requirements engineering, architectural design, code generation, testing, and compliance into a single, automated, and user-controlled framework.\n    *   **Potential Impact on Future Research:** The open-source nature of the platform (GitHub hosted) provides a valuable foundation for future research into multi-agent systems for software engineering \\cite{sami202475w}. It encourages further exploration into improving LLM accuracy, mitigating hallucinations, enhancing domain-specific knowledge, and refining human-AI collaboration models. The integrated approach to security and compliance also opens new avenues for research into building inherently more secure and compliant AI-driven development pipelines, potentially leading to more efficient, higher-quality, and compliant software development processes \\cite{sami202475w}.",
      "keywords": [
        "Multi-agent software development",
        "Unified platform",
        "Large Language Models (LLMs)",
        "SDLC automation",
        "End-to-end automation",
        "Requirements engineering",
        "Code generation",
        "Testing automation",
        "Compliance integration",
        "Human-in-the-loop",
        "Algorithmic framework",
        "UML diagrams",
        "User story prioritization",
        "Design patterns"
      ],
      "paper_type": "the paper type is **technical**.\n\n**reasoning:**\n\n1.  **abstract keywords and phrases:**\n    *   \"the objective of this study is to **develop a unified platform** that utilizes multiple artificial intelligence agents to automate the process...\"\n    *   \"these deliverables include user stories, prioritization, and uml sequence diagrams, along with the modular approach to apis, unit tests, and end-to-end tests.\" (describes the output/functionality of the developed system)\n    *   \"additionally, **the platform will organize tasks, perform security and compliance, and suggest design patterns**...\" (further describes the system's capabilities)\n    *   \"**we use multiple models**, such as gpt-3.5, gpt-4, and llama3 to enable to generation of modular code...\" (mentions specific technologies used in the system)\n    *   \"the **source code for our uniform platform is hosted on github**, enabling additional experimentation and supporting both research and practical uses.\" (explicitly states a system was built and is available).\n    *   the title \"experimenting with multi-agent software development: towards a unified platform\" also points to the development of a platform.\n\n2.  **introduction context:**\n    *   the introduction sets the stage by discussing the software development life cycle (sdlc) and challenges like \"accurate translation of user requirements into technical specifications.\" this establishes the problem that the proposed technical solution (the platform) aims to address.\n\nthese elements strongly align with the criteria for a **technical** paper, which \"presents new methods, algorithms, or systems\" and mentions \"propose\", \"develop\", \"present\", \"algorithm\", \"method\" (or in this case, a \"platform\"). while the title includes \"experimenting,\" the abstract focuses on the *development* and *features* of the platform itself, rather than reporting the results of an empirical study *using* the platform. the mention of \"enabling additional experimentation\" suggests the platform is a tool for future experiments, not the subject of an empirical study in this paper."
    },
    "file_name": "917ba30d8d00e17c53545badc8fc76e403f8ac09.pdf"
  },
  {
    "success": true,
    "doc_id": "abc82ef8c401e252dbad5d5188ebe8aa",
    "summary": "The more we know about patterns in code, the better we can support those patterns. In this article, Jordi Cabot and Robert Claris ´o discuss the promise and perils of AI enhanced low-code environments that allow programmers and non=programmers alike to quickly deliver software solutions. They offer a “wish list” that outlines what developers need to watch for in low-code tools for smart software. Got anything else you want to say about SE+AI? For SE+AI applications, you have a surprising result or industrial experience? Something that challenges decades of conventional thinking in software engineering? If so, email a one paragraph synopsis to tim@menzies.us (use the subject line “SE for AI: Idea: [your idea]”). If that looks interesting, I’ll ask you to submit a 1,000- to 2,400-word article (where each graph, table, or figure is worth 250 words) for review for IEEE Software. Note: Heresies are more than welcome (if supported by well-reasoned industrial experiences, case studies, or other empirical results).—Tim Menzies",
    "intriguing_abstract": "The more we know about patterns in code, the better we can support those patterns. In this article, Jordi Cabot and Robert Claris ´o discuss the promise and perils of AI enhanced low-code environments that allow programmers and non=programmers alike to quickly deliver software solutions. They offer a “wish list” that outlines what developers need to watch for in low-code tools for smart software. Got anything else you want to say about SE+AI? For SE+AI applications, you have a surprising result or industrial experience? Something that challenges decades of conventional thinking in software engineering? If so, email a one paragraph synopsis to tim@menzies.us (use the subject line “SE for AI: Idea: [your idea]”). If that looks interesting, I’ll ask you to submit a 1,000- to 2,400-word article (where each graph, table, or figure is worth 250 words) for review for IEEE Software. Note: Heresies are more than welcome (if supported by well-reasoned industrial experiences, case studies, or other empirical results).—Tim Menzies",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/23607e0def6ded00b3dc374c22183852538cebe3.pdf",
    "citation_key": "cabot2023qq1",
    "metadata": {
      "title": "Low Code for Smart Software Development",
      "authors": [
        "Jordi Cabot",
        "R. Clarisó",
        "T. Menzies"
      ],
      "published_date": "2023",
      "abstract": "The more we know about patterns in code, the better we can support those patterns. In this article, Jordi Cabot and Robert Claris ´o discuss the promise and perils of AI enhanced low-code environments that allow programmers and non=programmers alike to quickly deliver software solutions. They offer a “wish list” that outlines what developers need to watch for in low-code tools for smart software. Got anything else you want to say about SE+AI? For SE+AI applications, you have a surprising result or industrial experience? Something that challenges decades of conventional thinking in software engineering? If so, email a one paragraph synopsis to tim@menzies.us (use the subject line “SE for AI: Idea: [your idea]”). If that looks interesting, I’ll ask you to submit a 1,000- to 2,400-word article (where each graph, table, or figure is worth 250 words) for review for IEEE Software. Note: Heresies are more than welcome (if supported by well-reasoned industrial experiences, case studies, or other empirical results).—Tim Menzies",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/23607e0def6ded00b3dc374c22183852538cebe3.pdf",
      "venue": "IEEE Software",
      "citationCount": 12,
      "score": 6.0,
      "summary": "The more we know about patterns in code, the better we can support those patterns. In this article, Jordi Cabot and Robert Claris ´o discuss the promise and perils of AI enhanced low-code environments that allow programmers and non=programmers alike to quickly deliver software solutions. They offer a “wish list” that outlines what developers need to watch for in low-code tools for smart software. Got anything else you want to say about SE+AI? For SE+AI applications, you have a surprising result or industrial experience? Something that challenges decades of conventional thinking in software engineering? If so, email a one paragraph synopsis to tim@menzies.us (use the subject line “SE for AI: Idea: [your idea]”). If that looks interesting, I’ll ask you to submit a 1,000- to 2,400-word article (where each graph, table, or figure is worth 250 words) for review for IEEE Software. Note: Heresies are more than welcome (if supported by well-reasoned industrial experiences, case studies, or other empirical results).—Tim Menzies",
      "keywords": []
    },
    "file_name": "23607e0def6ded00b3dc374c22183852538cebe3.pdf"
  },
  {
    "success": true,
    "doc_id": "0a0b1791b6c0ad1b24cdba41d3e627d8",
    "summary": "The rapid advancement in software development has taken place with the invention of a new quality assurance (QA) process for producing robust, reliable, and efficient systems. Artificial Intelligence is a \"force of change\" that promises automating most QA activities with promising predictive insight into the generation of dynamic test cases and intelligent detection of defects. This paper covers the theme of integrating AI with SQA through techniques such as Machine Learning, Natural Language Processing, and Neural Networks. The paper covers automation of testing, AI-driven management of defects, and enhancement of user experience as well as challenges and limitation that is encountered while implementing AI within QA. A glimpse of emerging trends illustrates the dynamic landscape of AI-driven QA.",
    "intriguing_abstract": "The rapid advancement in software development has taken place with the invention of a new quality assurance (QA) process for producing robust, reliable, and efficient systems. Artificial Intelligence is a \"force of change\" that promises automating most QA activities with promising predictive insight into the generation of dynamic test cases and intelligent detection of defects. This paper covers the theme of integrating AI with SQA through techniques such as Machine Learning, Natural Language Processing, and Neural Networks. The paper covers automation of testing, AI-driven management of defects, and enhancement of user experience as well as challenges and limitation that is encountered while implementing AI within QA. A glimpse of emerging trends illustrates the dynamic landscape of AI-driven QA.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/c58de4e94c9864efbc46f25af61cf01753172fae.pdf",
    "citation_key": "bussa2023ky7",
    "metadata": {
      "title": "Artificial Intelligence in Quality Assurance for Software Systems",
      "authors": [
        "Santhosh Bussa"
      ],
      "published_date": "2023",
      "abstract": "The rapid advancement in software development has taken place with the invention of a new quality assurance (QA) process for producing robust, reliable, and efficient systems. Artificial Intelligence is a \"force of change\" that promises automating most QA activities with promising predictive insight into the generation of dynamic test cases and intelligent detection of defects. This paper covers the theme of integrating AI with SQA through techniques such as Machine Learning, Natural Language Processing, and Neural Networks. The paper covers automation of testing, AI-driven management of defects, and enhancement of user experience as well as challenges and limitation that is encountered while implementing AI within QA. A glimpse of emerging trends illustrates the dynamic landscape of AI-driven QA.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/c58de4e94c9864efbc46f25af61cf01753172fae.pdf",
      "venue": "Stallion Journal for Multidisciplinary Associated Research Studies",
      "citationCount": 12,
      "score": 6.0,
      "summary": "The rapid advancement in software development has taken place with the invention of a new quality assurance (QA) process for producing robust, reliable, and efficient systems. Artificial Intelligence is a \"force of change\" that promises automating most QA activities with promising predictive insight into the generation of dynamic test cases and intelligent detection of defects. This paper covers the theme of integrating AI with SQA through techniques such as Machine Learning, Natural Language Processing, and Neural Networks. The paper covers automation of testing, AI-driven management of defects, and enhancement of user experience as well as challenges and limitation that is encountered while implementing AI within QA. A glimpse of emerging trends illustrates the dynamic landscape of AI-driven QA.",
      "keywords": []
    },
    "file_name": "c58de4e94c9864efbc46f25af61cf01753172fae.pdf"
  },
  {
    "success": true,
    "doc_id": "2ddd358d86e3199e189a127af2efe8f1",
    "summary": "We explore the potential for productive team-based collaboration between humans and Artificial Intelligence (AI) by presenting and conducting initial tests with a general framework that enables multiple human and AI agents to work together as peers. ChatCollab's novel architecture allows agents - human or AI - to join collaborations in any role, autonomously engage in tasks and communication within Slack, and remain agnostic to whether their collaborators are human or AI. Using software engineering as a case study, we find that our AI agents successfully identify their roles and responsibilities, coordinate with other agents, and await requested inputs or deliverables before proceeding. In relation to three prior multi-agent AI systems for software development, we find ChatCollab AI agents produce comparable or better software in an interactive game development task. We also propose an automated method for analyzing collaboration dynamics that effectively identifies behavioral characteristics of agents with distinct roles, allowing us to quantitatively compare collaboration dynamics in a range of experimental conditions. For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles. Our code and data can be found at: https://github.com/ChatCollab.",
    "intriguing_abstract": "We explore the potential for productive team-based collaboration between humans and Artificial Intelligence (AI) by presenting and conducting initial tests with a general framework that enables multiple human and AI agents to work together as peers. ChatCollab's novel architecture allows agents - human or AI - to join collaborations in any role, autonomously engage in tasks and communication within Slack, and remain agnostic to whether their collaborators are human or AI. Using software engineering as a case study, we find that our AI agents successfully identify their roles and responsibilities, coordinate with other agents, and await requested inputs or deliverables before proceeding. In relation to three prior multi-agent AI systems for software development, we find ChatCollab AI agents produce comparable or better software in an interactive game development task. We also propose an automated method for analyzing collaboration dynamics that effectively identifies behavioral characteristics of agents with distinct roles, allowing us to quantitatively compare collaboration dynamics in a range of experimental conditions. For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles. Our code and data can be found at: https://github.com/ChatCollab.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/52a28dc26fb07db41df6834e9c3cf9a5ab7fad66.pdf",
    "citation_key": "klieger2024kgw",
    "metadata": {
      "title": "ChatCollab: Exploring Collaboration Between Humans and AI Agents in Software Teams",
      "authors": [
        "Benjamin Klieger",
        "Charis Charitsis",
        "Miroslav Suzara",
        "Sierra Wang",
        "Nick Haber",
        "John C. Mitchell"
      ],
      "published_date": "2024",
      "abstract": "We explore the potential for productive team-based collaboration between humans and Artificial Intelligence (AI) by presenting and conducting initial tests with a general framework that enables multiple human and AI agents to work together as peers. ChatCollab's novel architecture allows agents - human or AI - to join collaborations in any role, autonomously engage in tasks and communication within Slack, and remain agnostic to whether their collaborators are human or AI. Using software engineering as a case study, we find that our AI agents successfully identify their roles and responsibilities, coordinate with other agents, and await requested inputs or deliverables before proceeding. In relation to three prior multi-agent AI systems for software development, we find ChatCollab AI agents produce comparable or better software in an interactive game development task. We also propose an automated method for analyzing collaboration dynamics that effectively identifies behavioral characteristics of agents with distinct roles, allowing us to quantitatively compare collaboration dynamics in a range of experimental conditions. For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles. Our code and data can be found at: https://github.com/ChatCollab.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/52a28dc26fb07db41df6834e9c3cf9a5ab7fad66.pdf",
      "venue": "arXiv.org",
      "citationCount": 6,
      "score": 6.0,
      "summary": "We explore the potential for productive team-based collaboration between humans and Artificial Intelligence (AI) by presenting and conducting initial tests with a general framework that enables multiple human and AI agents to work together as peers. ChatCollab's novel architecture allows agents - human or AI - to join collaborations in any role, autonomously engage in tasks and communication within Slack, and remain agnostic to whether their collaborators are human or AI. Using software engineering as a case study, we find that our AI agents successfully identify their roles and responsibilities, coordinate with other agents, and await requested inputs or deliverables before proceeding. In relation to three prior multi-agent AI systems for software development, we find ChatCollab AI agents produce comparable or better software in an interactive game development task. We also propose an automated method for analyzing collaboration dynamics that effectively identifies behavioral characteristics of agents with distinct roles, allowing us to quantitatively compare collaboration dynamics in a range of experimental conditions. For example, in comparing ChatCollab AI agents, we find that an AI CEO agent generally provides suggestions 2-4 times more often than an AI product manager or AI developer, suggesting agents within ChatCollab can meaningfully adopt differentiated collaborative roles. Our code and data can be found at: https://github.com/ChatCollab.",
      "keywords": []
    },
    "file_name": "52a28dc26fb07db41df6834e9c3cf9a5ab7fad66.pdf"
  },
  {
    "success": true,
    "doc_id": "2b9b20b25583ff752d9407b78ec39c6d",
    "summary": "The recent proliferation of generative artificial intelligence (AI) technologies such as pre-trained large language models (LLMs) has opened up new frontiers in computational law. An exciting area of development is the use of AI to automate the deductive rule-based reasoning inherent in statutory and contract law. This paper argues that such automated deductive legal reasoning can now be viewed from the lens of software engineering, treating LLMs as interpreters of natural-language programs with natural-language inputs. We show how it is possible to apply principled software engineering techniques to enhance AI-driven legal reasoning of complex statutes and to unlock new applications in automated meta-reasoning such as mutation-guided example generation and metamorphic property-based testing.",
    "intriguing_abstract": "The recent proliferation of generative artificial intelligence (AI) technologies such as pre-trained large language models (LLMs) has opened up new frontiers in computational law. An exciting area of development is the use of AI to automate the deductive rule-based reasoning inherent in statutory and contract law. This paper argues that such automated deductive legal reasoning can now be viewed from the lens of software engineering, treating LLMs as interpreters of natural-language programs with natural-language inputs. We show how it is possible to apply principled software engineering techniques to enhance AI-driven legal reasoning of complex statutes and to unlock new applications in automated meta-reasoning such as mutation-guided example generation and metamorphic property-based testing.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b933a1a9ff0ab4079494caa7811b8e4f2a06301d.pdf",
    "citation_key": "padhye2024294",
    "metadata": {
      "title": "Software Engineering Methods for AI-Driven Deductive Legal Reasoning",
      "authors": [
        "Rohan Padhye"
      ],
      "published_date": "2024",
      "abstract": "The recent proliferation of generative artificial intelligence (AI) technologies such as pre-trained large language models (LLMs) has opened up new frontiers in computational law. An exciting area of development is the use of AI to automate the deductive rule-based reasoning inherent in statutory and contract law. This paper argues that such automated deductive legal reasoning can now be viewed from the lens of software engineering, treating LLMs as interpreters of natural-language programs with natural-language inputs. We show how it is possible to apply principled software engineering techniques to enhance AI-driven legal reasoning of complex statutes and to unlock new applications in automated meta-reasoning such as mutation-guided example generation and metamorphic property-based testing.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b933a1a9ff0ab4079494caa7811b8e4f2a06301d.pdf",
      "venue": "SIGPLAN symposium on New ideas, new paradigms, and reflections on programming and software",
      "citationCount": 6,
      "score": 6.0,
      "summary": "The recent proliferation of generative artificial intelligence (AI) technologies such as pre-trained large language models (LLMs) has opened up new frontiers in computational law. An exciting area of development is the use of AI to automate the deductive rule-based reasoning inherent in statutory and contract law. This paper argues that such automated deductive legal reasoning can now be viewed from the lens of software engineering, treating LLMs as interpreters of natural-language programs with natural-language inputs. We show how it is possible to apply principled software engineering techniques to enhance AI-driven legal reasoning of complex statutes and to unlock new applications in automated meta-reasoning such as mutation-guided example generation and metamorphic property-based testing.",
      "keywords": []
    },
    "file_name": "b933a1a9ff0ab4079494caa7811b8e4f2a06301d.pdf"
  },
  {
    "success": true,
    "doc_id": "ff4c6bc2dd7086fd855b8902088a4f04",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of safely compressing deep learning models for deployment on resource-restricted devices. While model compression reduces size, it often inherits vulnerabilities (e.g., memorization of training data) from the original large models, leading to privacy leakage risks like membership inference attacks (MIAs) \\cite{zhu2024bp2}. Compressed models, being widely deployed on edge devices, face even higher attack risks.\n    *   **Importance and Challenge**: It is crucial to balance model size, task performance, and *safety* (privacy/security) simultaneously. Existing model compression techniques primarily focus on size and performance, neglecting safety. A simple two-step approach (compress then protect) is ineffective, as protection techniques may not account for the variability introduced by compression, potentially leading to poor performance and low safety \\cite{zhu2024bp2}. The core challenge is the co-optimization of performance and safety during the compression process.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work relates to traditional DNN model compression (e.g., pruning, knowledge distillation) which aims to reduce model size while maintaining performance \\cite{zhu2024bp2}. It also touches upon model protection techniques (e.g., differential privacy, adversarial training) that aim to enhance model security.\n    *   **Limitations of Previous Solutions**:\n        *   Prior compression methods prioritize memory and performance, overlooking privacy and security concerns \\cite{zhu2024bp2}.\n        *   Compressed models can inherit and even exacerbate vulnerabilities of big models, making them more susceptible to attacks like MIA due to easier access on edge devices \\cite{zhu2024bp2}.\n        *   A two-step solution (compressing first, then applying protection) is suboptimal, as protection mechanisms may not effectively mitigate vulnerabilities introduced or altered by the compression process, leading to degraded performance and safety \\cite{zhu2024bp2}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes `SafeCompress` \\cite{zhu2024bp2}, a test-driven sparse training framework for safe model compression. It is inspired by Test-Driven Development (TDD) and Dynamic Sparse Training (DST). `SafeCompress` formulates safe model compression as a bi-objective optimization problem, aiming to minimize both task performance loss and attack gain under sparsity constraints \\cite{zhu2024bp2}.\n    *   **Novelty/Difference**:\n        *   `SafeCompress` integrates attack simulation directly into an iterative compression process, treating attack mechanisms as \"safety testing\" \\cite{zhu2024bp2}. This allows for simultaneous co-optimization of model performance and safety, rather than sequential application.\n        *   The framework follows an iterative compressing-testing process:\n            1.  **Sparsity-Aware Model Initialization**: Initializes a sparse model from a big one.\n            2.  **Candidate Sparse Model and Simulated-attacker Generation**: Generates new sparse model variants using dynamic sparse update strategies (pruning and growth) and trains simulated attack models.\n            3.  **Performance-Safety Co-optimization**: Evaluates candidate models based on both task performance and simulated attack results to select the best strategy for the next iteration \\cite{zhu2024bp2}.\n        *   It is designed to be configurable for various pre-specified attack mechanisms and adaptable to heterogeneous AI tasks (CV, NLP) \\cite{zhu2024bp2}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Framework**: Introduction of `SafeCompress`, the first general test-driven sparse training framework for safe model compression, which iteratively co-optimizes model performance and safety against specified attacks \\cite{zhu2024bp2}.\n    *   **Concrete Instances**: Development of specific instances of `SafeCompress` to defend against different types of membership inference attacks: `BMIA-SafeCompress` (black-box MIA), `WMIA-SafeCompress` (white-box MIA), and `MMIA-SafeCompress` (multiple heterogeneous MIAs simultaneously) \\cite{zhu2024bp2}.\n    *   **Integration of Adversarial Training**: Demonstrates how adversarial training can be incorporated into `SafeCompress` to further enhance a compressed model's defense capabilities \\cite{zhu2024bp2}.\n    *   **Problem Formulation**: Formalizes the safe model compression problem as a bi-objective optimization, explicitly considering both task performance and attack gain \\cite{zhu2024bp2}.\n    *   **Flexibility**: Discusses the adaptability of `SafeCompress` to other attack types beyond MIA, highlighting its generalizability \\cite{zhu2024bp2}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed using the `BMIA-SafeCompress`, `WMIA-SafeCompress`, and `MMIA-SafeCompress` instances \\cite{zhu2024bp2}.\n    *   **Datasets**: Five diverse datasets were used across two domains: three computer vision tasks (CIFAR-10, CIFAR-100, Tiny-ImageNet) and two natural language processing tasks (AG News, SST-2) \\cite{zhu2024bp2}.\n    *   **Key Performance Metrics**: Model performance (e.g., classification accuracy) and safety (measured by attack accuracy/gain of the MIA) were evaluated \\cite{zhu2024bp2}.\n    *   **Comparison Results**: The `SafeCompress` framework \"significantly outperforms baseline solutions that integrate state-of-the-art compression and MIA defense approaches\" \\cite{zhu2024bp2}. Robustness analyses on the safety and performance trade-off metric were also conducted.\n    *   **Reproducibility**: The code for the three `SafeCompress` instances is made publicly available \\cite{zhu2024bp2}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The primary focus of the empirical validation is on membership inference attacks (MIAs). While the framework is designed to be configurable for other attacks, the extensive experimental evidence is concentrated on MIA defense \\cite{zhu2024bp2}. The computational overhead of the iterative co-optimization process, though not explicitly detailed as a limitation, could be a consideration.\n    *   **Scope of Applicability**: `SafeCompress` is applicable to DNN model compression for AI software deployment on resource-restricted edge devices (e.g., smartphones, wearable devices) \\cite{zhu2024bp2}. It is demonstrated for both computer vision and natural language processing tasks and is designed to be adaptable to various pre-specified attack mechanisms.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art**: This work is the first to address the critical problem of *safe model compression*, moving beyond the traditional focus on size and performance to explicitly incorporate security and privacy during the compression process \\cite{zhu2024bp2}. It introduces a novel paradigm for developing AI software that is inherently more secure upon deployment.\n    *   **Potential Impact on Future Research**: `SafeCompress` provides a flexible and generalizable framework that can be extended to defend against a wider range of adversarial attacks beyond MIA. It paves the way for future research into integrated, security-aware model development pipelines, fostering the deployment of more trustworthy and privacy-preserving AI models on edge devices \\cite{zhu2024bp2}.",
    "intriguing_abstract": "Deploying deep learning models on resource-restricted edge devices necessitates aggressive model compression, yet this often inherits and even amplifies critical privacy vulnerabilities like membership inference attacks (MIAs). Current compression techniques prioritize size and performance, dangerously neglecting safety, while sequential \"compress then protect\" strategies prove ineffective. We introduce `SafeCompress`, a pioneering test-driven sparse training framework that fundamentally redefines model compression. Inspired by Test-Driven Development, `SafeCompress` formulates safe model compression as a novel bi-objective optimization problem, simultaneously minimizing task performance loss and attack gain. By integrating attack simulation directly into an iterative compressing-testing process, `SafeCompress` co-optimizes model performance and safety from inception. Our framework, demonstrated through instances like `BMIA-SafeCompress` and `WMIA-SafeCompress`, significantly outperforms state-of-the-art baselines across diverse computer vision and natural language processing tasks. `SafeCompress` offers a generalizable paradigm for developing inherently more secure and trustworthy AI, paving the way for privacy-preserving AI deployment on the edge.",
    "keywords": [
      "Safe model compression",
      "Deep learning model compression",
      "Membership inference attacks (MIAs)",
      "SafeCompress framework",
      "Test-driven sparse training",
      "Bi-objective optimization",
      "Performance-safety co-optimization",
      "Attack simulation",
      "Resource-restricted devices",
      "Privacy-preserving AI",
      "Dynamic sparse training",
      "Adversarial training"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/fd38e3414273fa64ffa93c8cd15a98120883987e.pdf",
    "citation_key": "zhu2024bp2",
    "metadata": {
      "title": "Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression Against Heterogeneous Attacks Toward AI Software Deployment",
      "authors": [
        "Jie Zhu",
        "Leye Wang",
        "Xiao Han",
        "Anmin Liu",
        "Tao Xie"
      ],
      "published_date": "2024",
      "abstract": "The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, hindering the large-scale deployment on resource-restricted devices (e.g., smartphones). To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in a big model may be inherited by the compressed one. Such defects may be easily leveraged by adversaries, since a compressed model is usually deployed in a large number of devices without adequate protection. In this article, we aim to address the safe model compression problem from the perspective of safety-performance co-optimization. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as safety testing, SafeCompress can automatically compress a big model to a small one following the dynamic sparse training paradigm. Then, considering two kinds of representative and heterogeneous attack mechanisms, i.e., black-box membership inference attack and white-box membership inference attack, we develop two concrete instances called BMIA-SafeCompress and WMIA-SafeCompress. Further, we implement another instance called MMIA-SafeCompress by extending SafeCompress to defend against the occasion when adversaries conduct black-box and white-box membership inference attacks simultaneously. We conduct extensive experiments on five datasets for both computer vision and natural language processing tasks. The results show the effectiveness and generalizability of our framework. We also discuss how to adapt SafeCompress to other attacks besides membership inference attack, demonstrating the flexibility of SafeCompress.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/fd38e3414273fa64ffa93c8cd15a98120883987e.pdf",
      "venue": "IEEE Transactions on Software Engineering",
      "citationCount": 6,
      "score": 6.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the challenge of safely compressing deep learning models for deployment on resource-restricted devices. While model compression reduces size, it often inherits vulnerabilities (e.g., memorization of training data) from the original large models, leading to privacy leakage risks like membership inference attacks (MIAs) \\cite{zhu2024bp2}. Compressed models, being widely deployed on edge devices, face even higher attack risks.\n    *   **Importance and Challenge**: It is crucial to balance model size, task performance, and *safety* (privacy/security) simultaneously. Existing model compression techniques primarily focus on size and performance, neglecting safety. A simple two-step approach (compress then protect) is ineffective, as protection techniques may not account for the variability introduced by compression, potentially leading to poor performance and low safety \\cite{zhu2024bp2}. The core challenge is the co-optimization of performance and safety during the compression process.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work relates to traditional DNN model compression (e.g., pruning, knowledge distillation) which aims to reduce model size while maintaining performance \\cite{zhu2024bp2}. It also touches upon model protection techniques (e.g., differential privacy, adversarial training) that aim to enhance model security.\n    *   **Limitations of Previous Solutions**:\n        *   Prior compression methods prioritize memory and performance, overlooking privacy and security concerns \\cite{zhu2024bp2}.\n        *   Compressed models can inherit and even exacerbate vulnerabilities of big models, making them more susceptible to attacks like MIA due to easier access on edge devices \\cite{zhu2024bp2}.\n        *   A two-step solution (compressing first, then applying protection) is suboptimal, as protection mechanisms may not effectively mitigate vulnerabilities introduced or altered by the compression process, leading to degraded performance and safety \\cite{zhu2024bp2}.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper proposes `SafeCompress` \\cite{zhu2024bp2}, a test-driven sparse training framework for safe model compression. It is inspired by Test-Driven Development (TDD) and Dynamic Sparse Training (DST). `SafeCompress` formulates safe model compression as a bi-objective optimization problem, aiming to minimize both task performance loss and attack gain under sparsity constraints \\cite{zhu2024bp2}.\n    *   **Novelty/Difference**:\n        *   `SafeCompress` integrates attack simulation directly into an iterative compression process, treating attack mechanisms as \"safety testing\" \\cite{zhu2024bp2}. This allows for simultaneous co-optimization of model performance and safety, rather than sequential application.\n        *   The framework follows an iterative compressing-testing process:\n            1.  **Sparsity-Aware Model Initialization**: Initializes a sparse model from a big one.\n            2.  **Candidate Sparse Model and Simulated-attacker Generation**: Generates new sparse model variants using dynamic sparse update strategies (pruning and growth) and trains simulated attack models.\n            3.  **Performance-Safety Co-optimization**: Evaluates candidate models based on both task performance and simulated attack results to select the best strategy for the next iteration \\cite{zhu2024bp2}.\n        *   It is designed to be configurable for various pre-specified attack mechanisms and adaptable to heterogeneous AI tasks (CV, NLP) \\cite{zhu2024bp2}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Framework**: Introduction of `SafeCompress`, the first general test-driven sparse training framework for safe model compression, which iteratively co-optimizes model performance and safety against specified attacks \\cite{zhu2024bp2}.\n    *   **Concrete Instances**: Development of specific instances of `SafeCompress` to defend against different types of membership inference attacks: `BMIA-SafeCompress` (black-box MIA), `WMIA-SafeCompress` (white-box MIA), and `MMIA-SafeCompress` (multiple heterogeneous MIAs simultaneously) \\cite{zhu2024bp2}.\n    *   **Integration of Adversarial Training**: Demonstrates how adversarial training can be incorporated into `SafeCompress` to further enhance a compressed model's defense capabilities \\cite{zhu2024bp2}.\n    *   **Problem Formulation**: Formalizes the safe model compression problem as a bi-objective optimization, explicitly considering both task performance and attack gain \\cite{zhu2024bp2}.\n    *   **Flexibility**: Discusses the adaptability of `SafeCompress` to other attack types beyond MIA, highlighting its generalizability \\cite{zhu2024bp2}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted**: Extensive experiments were performed using the `BMIA-SafeCompress`, `WMIA-SafeCompress`, and `MMIA-SafeCompress` instances \\cite{zhu2024bp2}.\n    *   **Datasets**: Five diverse datasets were used across two domains: three computer vision tasks (CIFAR-10, CIFAR-100, Tiny-ImageNet) and two natural language processing tasks (AG News, SST-2) \\cite{zhu2024bp2}.\n    *   **Key Performance Metrics**: Model performance (e.g., classification accuracy) and safety (measured by attack accuracy/gain of the MIA) were evaluated \\cite{zhu2024bp2}.\n    *   **Comparison Results**: The `SafeCompress` framework \"significantly outperforms baseline solutions that integrate state-of-the-art compression and MIA defense approaches\" \\cite{zhu2024bp2}. Robustness analyses on the safety and performance trade-off metric were also conducted.\n    *   **Reproducibility**: The code for the three `SafeCompress` instances is made publicly available \\cite{zhu2024bp2}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The primary focus of the empirical validation is on membership inference attacks (MIAs). While the framework is designed to be configurable for other attacks, the extensive experimental evidence is concentrated on MIA defense \\cite{zhu2024bp2}. The computational overhead of the iterative co-optimization process, though not explicitly detailed as a limitation, could be a consideration.\n    *   **Scope of Applicability**: `SafeCompress` is applicable to DNN model compression for AI software deployment on resource-restricted edge devices (e.g., smartphones, wearable devices) \\cite{zhu2024bp2}. It is demonstrated for both computer vision and natural language processing tasks and is designed to be adaptable to various pre-specified attack mechanisms.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art**: This work is the first to address the critical problem of *safe model compression*, moving beyond the traditional focus on size and performance to explicitly incorporate security and privacy during the compression process \\cite{zhu2024bp2}. It introduces a novel paradigm for developing AI software that is inherently more secure upon deployment.\n    *   **Potential Impact on Future Research**: `SafeCompress` provides a flexible and generalizable framework that can be extended to defend against a wider range of adversarial attacks beyond MIA. It paves the way for future research into integrated, security-aware model development pipelines, fostering the deployment of more trustworthy and privacy-preserving AI models on edge devices \\cite{zhu2024bp2}.",
      "keywords": [
        "Safe model compression",
        "Deep learning model compression",
        "Membership inference attacks (MIAs)",
        "SafeCompress framework",
        "Test-driven sparse training",
        "Bi-objective optimization",
        "Performance-safety co-optimization",
        "Attack simulation",
        "Resource-restricted devices",
        "Privacy-preserving AI",
        "Dynamic sparse training",
        "Adversarial training"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we **propose a test-driven sparse training framework called safecompress**.\"\n*   the introduction further elaborates: \"we **propose a test-driven sparse training framework called safecompress**,\" \"we **develop two concrete instances** called bmia-safecompress and wmia-safecompress,\" and \"we **implement another instance** called mmia-safecompress.\"\n*   the introduction also mentions: \"we **conduct extensive experiments**... the **results show the effectiveness and generalizability of our framework**,\" indicating an empirical evaluation of the proposed technical solution.\n\nthese phrases strongly align with the criteria for a **technical** paper, which presents new methods, algorithms, or systems. while there is an empirical component (experiments), its purpose is to validate the proposed technical framework, making \"technical\" the primary classification.\n\n**classification: technical**"
    },
    "file_name": "fd38e3414273fa64ffa93c8cd15a98120883987e.pdf"
  },
  {
    "success": true,
    "doc_id": "de86562904f76e6f52d471f4dc8ded1e",
    "summary": "Here's a focused summary of the paper \\cite{paradis20241o4} for a literature review, emphasizing technical innovations and empirical validation:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the specific technical problem of quantifying the impact of AI assistance on developer productivity, particularly focusing on \"time spent on task\" for complex, enterprise-grade software development.\n    *   **Importance and Challenge**: This problem is crucial for justifying investment in AI-enhanced developer tools and understanding their business impact. It is challenging because previous research has yielded varied results, often lacked generalizability to real-world enterprise contexts, used simplified tasks, or had small sample sizes. Quantifying actual productivity gains, beyond perceived usefulness, in a robust, unbiased manner remains a nascent field.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon and complements prior studies on AI's impact on developer productivity, such as Peng et al. \\cite{paradis20241o4} (56% speed increase with GitHub Copilot) and Cui et al. \\cite{paradis20241o4} (26% throughput increase).\n    *   **Limitations of Previous Solutions**:\n        *   **Generalizability**: Peng et al. \\cite{paradis20241o4} relied on GitHub Classroom and participants recruited from Upwork, limiting generalizability to real-world, enterprise software development workflows.\n        *   **Task Complexity**: Many studies used tasks that were not representative of complex, enterprise-grade development, failing to leverage the full range of developer tools and infrastructure knowledge.\n        *   **Tool Scope**: Most studies focused on a single AI tool (e.g., GitHub Copilot), leaving gaps in understanding the impact of different coding assistants and suites of tools.\n        *   **Contextual Nuance**: Previous work often missed nuance regarding the impact of AI tools across different developer- or task-level contexts.\n    *   **Positioning**: This paper aims to address these limitations by conducting a randomized controlled trial (RCT) with full-time Google software engineers on a complex, proprietary enterprise-grade task, using a suite of internal AI-enhanced tools.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: The core method is a **Randomized Controlled Trial (RCT)**, considered an empirical standard for establishing causal links and providing unbiased estimates. This involved:\n        *   **Intervention**: Randomly assigning 96 full-time Google software engineers to either an experimental group (with AI features enabled) or a control group (without AI features).\n        *   **AI Features Tested**: The study evaluated the combined impact of three distinct, production-ready AI features integrated into Google's internal IDE (Cider V):\n            *   **AI Code Completion**: A transformer-based hybrid semantic AI providing single- and multi-line code suggestions.\n            *   **Smart Paste**: An AI feature enabling context-aware adjustments to pasted code, showing inline diffs for proposed changes.\n            *   **Natural Language to Code**: An AI assistant allowing developers to prompt for code fixes or generation using natural language.\n        *   **Enterprise-Grade Task Design**: A complex coding task was designed to accurately reflect typical Google developer workflows, requiring infrastructure knowledge, code search, editing, writing from scratch, and refactoring of test plans within Google's proprietary monorepo (Piper). The task involved editing a pre-existing changelist (10 files, 474 LOC) to implement a new service for logging messages.\n        *   **Statistical Analysis**: T-tests and linear regressions were used to analyze time-on-task data, with multivariate regressions to ascertain robustness and control for developer- and task-level factors.\n    *   **Novelty/Difference**:\n        *   **Enterprise Context & Scale**: One of the few RCTs to estimate AI impact on time-on-task within a large-scale, real-world enterprise development environment (Google) using internal tools and full-time engineers.\n        *   **Complex Task Realism**: The task was specifically designed to be \"enterprise-grade,\" mirroring the complexity and infrastructure dependencies of actual developer work, unlike simpler tasks in previous studies.\n        *   **Suite of AI Tools**: The study evaluated the combined effect of multiple distinct AI-enhanced features, providing a more holistic view of AI assistance in a typical development workflow.\n        *   **Interaction Effects**: Investigated how developer characteristics (e.g., daily coding hours, seniority) interact with AI use to influence productivity, adding nuance beyond a simple average effect.\n\n4.  **Key Technical Contributions**\n    *   **Novel Methodology Application**: Pioneering the application of a rigorous RCT methodology to measure AI's impact on developer speed in a highly controlled yet realistic enterprise setting.\n    *   **Empirical Quantification**: Providing a robust, unbiased estimate (approximately 21% speed increase) of AI's impact on time-on-task for complex development work within an enterprise.\n    *   **Multi-Feature Evaluation**: Demonstrating the collective productivity benefits of a suite of AI-enhanced coding tools (Code Completion, Smart Paste, Natural Language to Code) rather than isolated features.\n    *   **Contextual Insights**: Identifying that developer characteristics, such as daily coding hours, can moderate the effectiveness of AI tools, suggesting avenues for personalized AI assistance.\n    *   **Theoretical Framework**: Development and application of a theoretical framework to systematically analyze the interplay between AI intervention, developer-level factors, task-level factors, and time on task.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: A randomized controlled trial (RCT) was conducted with 96 full-time Google software engineers. Participants were randomly assigned to either an AI-enabled or AI-disabled condition after initial training and questionnaires. Both groups performed an identical, standardized, enterprise-grade coding task.\n    *   **Key Performance Metrics**: The primary metric was \"time spent on task,\" measured from the start of the coding task until all tests passed.\n    *   **Comparison Results**:\n        *   **Overall Impact**: Developers using AI were approximately **21% faster** on the enterprise-grade task compared to those in the control group, even after controlling for other influencing factors. The confidence interval for this effect size was noted as large.\n        *   **Developer Characteristics**: More senior developers and developers who spent more hours coding per day were significantly faster on the task.\n        *   **Interaction Effects**: A large, though not statistically significant, interaction effect was observed between AI use and average daily coding hours, suggesting that developers who code more frequently tend to be faster when using AI.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   **Lab Study Context**: The study was conducted in a controlled lab environment, which, while designed to simulate enterprise conditions, may not fully capture the complexities and distractions of daily work.\n        *   **Specific Tooling**: The findings are based on internal Google tooling (Cider V and its integrated AI features) available in summer 2024. The effect size may not directly translate to other AI tools, different IDEs, or future iterations of AI technology.\n        *   **Combined AI Effect**: The study measured the combined impact of three AI features, making it difficult to isolate the individual contribution of each feature.\n        *   **Confidence Interval**: The reported 21% speed increase has a \"large confidence interval,\" indicating variability in the estimate.\n    *   **Scope of Applicability**: The findings are most directly applicable to similar enterprise development contexts, particularly those involving complex C++ tasks within a monorepo environment. The generalizability to other programming languages, smaller projects, or different organizational structures requires further research.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the technical state-of-the-art by providing one of the most robust, enterprise-contextualized, and causally-attributable estimates of AI's impact on developer speed. It moves beyond perceived productivity or simplified tasks to quantify actual time savings on complex, real-world development work.\n    *   **Potential Impact on Future Research**:\n        *   **Mechanism Exploration**: Invites further research into the underlying mechanisms that lead to differentiated speed gains, especially for developers who code less daily, to understand how AI tools can be optimized for all users.\n        *   **Ecosystem-Level Impact**: Encourages studies exploring the impact of AI at the broader ecosystem level and across multiple suites of AI-enhanced tools, rather than isolated features or specific products.\n        *   **Product Development**: Provides critical empirical evidence to inform the continued investment in and design of AI-enhanced developer tools, emphasizing user-centric approaches based on how different developer profiles interact with AI.\n        *   **Methodological Benchmark**: Establishes a strong methodological benchmark (RCT in enterprise) for future studies aiming to quantify AI's impact on software engineering productivity.",
    "intriguing_abstract": "Can AI truly accelerate complex software development in the demanding landscape of enterprise engineering? This paper presents a pioneering **Randomized Controlled Trial (RCT)** involving 96 full-time Google software engineers, tackling a complex, proprietary **enterprise-grade task**. Unlike previous studies, we rigorously evaluated the combined impact of a suite of integrated **AI features**—including transformer-based **AI Code Completion**, **Smart Paste**, and **Natural Language to Code**—within a production IDE.\n\nOur **empirical validation** reveals a significant **21% reduction in 'time-on-task'** for developers leveraging **AI assistance**, even after controlling for various factors. This robust, unbiased estimate provides crucial evidence of AI's **causal impact** on developer speed in a highly realistic setting. These findings are vital for justifying investment in **AI-enhanced developer tools** and establishing a new methodological benchmark for future research. We also uncover nuanced interaction effects, suggesting pathways for optimizing AI for diverse developer profiles. This work offers unprecedented insights into the transformative potential of AI in **developer productivity** within enterprise environments.",
    "keywords": [
      "AI-enhanced developer tools",
      "developer productivity",
      "time spent on task",
      "enterprise software development",
      "Randomized Controlled Trial (RCT)",
      "suite of AI coding tools",
      "unbiased productivity estimate",
      "complex coding tasks",
      "21% developer speed increase",
      "developer characteristics interaction effects",
      "empirical validation",
      "methodological benchmark"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/e813d85ccd9e1a86dca4aa6e0dcf9486f0fdd01a.pdf",
    "citation_key": "paradis20241o4",
    "metadata": {
      "title": "How Much Does AI Impact Development Speed? an Enterprise-Based Randomized Controlled Trial",
      "authors": [
        "Elise Paradis",
        "Kate Grey",
        "Quinn Madison",
        "Daye Nam",
        "Andrew Macvean",
        "Vahid Meimand",
        "Nan Zhang",
        "Ben Ferrari-Church",
        "Satish Chandra"
      ],
      "published_date": "2024",
      "abstract": "How much does AI assistance impact developer productivity? To date, the software engineering literature has provided a range of answers, targeting a diversity of outcomes: from perceived productivity to speed on task and developer throughput. Our randomized controlled trial with 96 full-time Google software engineers contributes to this literature by sharing an estimate of the impact of three AI features on the time developers spent on a complex, enterprise-grade task. We found that AI significantly shortened the time developers spent on task. Our best estimate of the size of this effect, controlling for factors known to influence developer time on task, stands at about $\\mathbf{2 1 \\%}$, although our confidence interval is large. We also found an interesting effect whereby developers who spend more hours on code-related activities per day were faster with AI. Product and future research considerations are discussed. In particular, we invite further research that explores the impact of AI at the ecosystem level and across multiple suites of AI-enhanced tools, since we cannot assume that the effect size obtained in our lab study will necessarily apply more broadly, or that the effect of AI found using internal Google tooling in the summer of 2024 will translate across tools and over time.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/e813d85ccd9e1a86dca4aa6e0dcf9486f0fdd01a.pdf",
      "venue": "2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
      "citationCount": 6,
      "score": 6.0,
      "summary": "Here's a focused summary of the paper \\cite{paradis20241o4} for a literature review, emphasizing technical innovations and empirical validation:\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the specific technical problem of quantifying the impact of AI assistance on developer productivity, particularly focusing on \"time spent on task\" for complex, enterprise-grade software development.\n    *   **Importance and Challenge**: This problem is crucial for justifying investment in AI-enhanced developer tools and understanding their business impact. It is challenging because previous research has yielded varied results, often lacked generalizability to real-world enterprise contexts, used simplified tasks, or had small sample sizes. Quantifying actual productivity gains, beyond perceived usefulness, in a robust, unbiased manner remains a nascent field.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon and complements prior studies on AI's impact on developer productivity, such as Peng et al. \\cite{paradis20241o4} (56% speed increase with GitHub Copilot) and Cui et al. \\cite{paradis20241o4} (26% throughput increase).\n    *   **Limitations of Previous Solutions**:\n        *   **Generalizability**: Peng et al. \\cite{paradis20241o4} relied on GitHub Classroom and participants recruited from Upwork, limiting generalizability to real-world, enterprise software development workflows.\n        *   **Task Complexity**: Many studies used tasks that were not representative of complex, enterprise-grade development, failing to leverage the full range of developer tools and infrastructure knowledge.\n        *   **Tool Scope**: Most studies focused on a single AI tool (e.g., GitHub Copilot), leaving gaps in understanding the impact of different coding assistants and suites of tools.\n        *   **Contextual Nuance**: Previous work often missed nuance regarding the impact of AI tools across different developer- or task-level contexts.\n    *   **Positioning**: This paper aims to address these limitations by conducting a randomized controlled trial (RCT) with full-time Google software engineers on a complex, proprietary enterprise-grade task, using a suite of internal AI-enhanced tools.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: The core method is a **Randomized Controlled Trial (RCT)**, considered an empirical standard for establishing causal links and providing unbiased estimates. This involved:\n        *   **Intervention**: Randomly assigning 96 full-time Google software engineers to either an experimental group (with AI features enabled) or a control group (without AI features).\n        *   **AI Features Tested**: The study evaluated the combined impact of three distinct, production-ready AI features integrated into Google's internal IDE (Cider V):\n            *   **AI Code Completion**: A transformer-based hybrid semantic AI providing single- and multi-line code suggestions.\n            *   **Smart Paste**: An AI feature enabling context-aware adjustments to pasted code, showing inline diffs for proposed changes.\n            *   **Natural Language to Code**: An AI assistant allowing developers to prompt for code fixes or generation using natural language.\n        *   **Enterprise-Grade Task Design**: A complex coding task was designed to accurately reflect typical Google developer workflows, requiring infrastructure knowledge, code search, editing, writing from scratch, and refactoring of test plans within Google's proprietary monorepo (Piper). The task involved editing a pre-existing changelist (10 files, 474 LOC) to implement a new service for logging messages.\n        *   **Statistical Analysis**: T-tests and linear regressions were used to analyze time-on-task data, with multivariate regressions to ascertain robustness and control for developer- and task-level factors.\n    *   **Novelty/Difference**:\n        *   **Enterprise Context & Scale**: One of the few RCTs to estimate AI impact on time-on-task within a large-scale, real-world enterprise development environment (Google) using internal tools and full-time engineers.\n        *   **Complex Task Realism**: The task was specifically designed to be \"enterprise-grade,\" mirroring the complexity and infrastructure dependencies of actual developer work, unlike simpler tasks in previous studies.\n        *   **Suite of AI Tools**: The study evaluated the combined effect of multiple distinct AI-enhanced features, providing a more holistic view of AI assistance in a typical development workflow.\n        *   **Interaction Effects**: Investigated how developer characteristics (e.g., daily coding hours, seniority) interact with AI use to influence productivity, adding nuance beyond a simple average effect.\n\n4.  **Key Technical Contributions**\n    *   **Novel Methodology Application**: Pioneering the application of a rigorous RCT methodology to measure AI's impact on developer speed in a highly controlled yet realistic enterprise setting.\n    *   **Empirical Quantification**: Providing a robust, unbiased estimate (approximately 21% speed increase) of AI's impact on time-on-task for complex development work within an enterprise.\n    *   **Multi-Feature Evaluation**: Demonstrating the collective productivity benefits of a suite of AI-enhanced coding tools (Code Completion, Smart Paste, Natural Language to Code) rather than isolated features.\n    *   **Contextual Insights**: Identifying that developer characteristics, such as daily coding hours, can moderate the effectiveness of AI tools, suggesting avenues for personalized AI assistance.\n    *   **Theoretical Framework**: Development and application of a theoretical framework to systematically analyze the interplay between AI intervention, developer-level factors, task-level factors, and time on task.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: A randomized controlled trial (RCT) was conducted with 96 full-time Google software engineers. Participants were randomly assigned to either an AI-enabled or AI-disabled condition after initial training and questionnaires. Both groups performed an identical, standardized, enterprise-grade coding task.\n    *   **Key Performance Metrics**: The primary metric was \"time spent on task,\" measured from the start of the coding task until all tests passed.\n    *   **Comparison Results**:\n        *   **Overall Impact**: Developers using AI were approximately **21% faster** on the enterprise-grade task compared to those in the control group, even after controlling for other influencing factors. The confidence interval for this effect size was noted as large.\n        *   **Developer Characteristics**: More senior developers and developers who spent more hours coding per day were significantly faster on the task.\n        *   **Interaction Effects**: A large, though not statistically significant, interaction effect was observed between AI use and average daily coding hours, suggesting that developers who code more frequently tend to be faster when using AI.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**:\n        *   **Lab Study Context**: The study was conducted in a controlled lab environment, which, while designed to simulate enterprise conditions, may not fully capture the complexities and distractions of daily work.\n        *   **Specific Tooling**: The findings are based on internal Google tooling (Cider V and its integrated AI features) available in summer 2024. The effect size may not directly translate to other AI tools, different IDEs, or future iterations of AI technology.\n        *   **Combined AI Effect**: The study measured the combined impact of three AI features, making it difficult to isolate the individual contribution of each feature.\n        *   **Confidence Interval**: The reported 21% speed increase has a \"large confidence interval,\" indicating variability in the estimate.\n    *   **Scope of Applicability**: The findings are most directly applicable to similar enterprise development contexts, particularly those involving complex C++ tasks within a monorepo environment. The generalizability to other programming languages, smaller projects, or different organizational structures requires further research.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This paper significantly advances the technical state-of-the-art by providing one of the most robust, enterprise-contextualized, and causally-attributable estimates of AI's impact on developer speed. It moves beyond perceived productivity or simplified tasks to quantify actual time savings on complex, real-world development work.\n    *   **Potential Impact on Future Research**:\n        *   **Mechanism Exploration**: Invites further research into the underlying mechanisms that lead to differentiated speed gains, especially for developers who code less daily, to understand how AI tools can be optimized for all users.\n        *   **Ecosystem-Level Impact**: Encourages studies exploring the impact of AI at the broader ecosystem level and across multiple suites of AI-enhanced tools, rather than isolated features or specific products.\n        *   **Product Development**: Provides critical empirical evidence to inform the continued investment in and design of AI-enhanced developer tools, emphasizing user-centric approaches based on how different developer profiles interact with AI.\n        *   **Methodological Benchmark**: Establishes a strong methodological benchmark (RCT in enterprise) for future studies aiming to quantify AI's impact on software engineering productivity.",
      "keywords": [
        "AI-enhanced developer tools",
        "developer productivity",
        "time spent on task",
        "enterprise software development",
        "Randomized Controlled Trial (RCT)",
        "suite of AI coding tools",
        "unbiased productivity estimate",
        "complex coding tasks",
        "21% developer speed increase",
        "developer characteristics interaction effects",
        "empirical validation",
        "methodological benchmark"
      ],
      "paper_type": "based on the abstract and introduction, this paper is a **empirical** study.\n\nhere's why:\n\n*   **abstract mentions:** \"randomized controlled trial,\" \"96 full-time google software engineers,\" \"estimate of the impact,\" \"found that ai significantly shortened the time developers spent on task,\" \"best estimate of the size of this effect... stands at about 21%,\" \"confidence interval is large,\" \"found an interesting effect.\" these are all hallmarks of a data-driven study with statistical analysis and findings.\n*   **introduction discusses:** the core research question (\"how useful these tools are in helping developers, specifically in improving their productivity\") and the methodology (implied by the reiteration of the rct findings).\n\nthe paper clearly describes an experiment conducted with human participants, collecting data, and presenting quantitative findings with statistical considerations."
    },
    "file_name": "e813d85ccd9e1a86dca4aa6e0dcf9486f0fdd01a.pdf"
  },
  {
    "success": true,
    "doc_id": "a0a8475456e5120362bff01fe2483e61",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **CITATION**: \\cite{hamza2023urf}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper investigates the evolving dynamics of human-AI collaboration in software engineering, specifically focusing on the use of ChatGPT, and how AI transitions from a mere tool to a collaborative partner.\n    *   **Importance and Challenge**: While AI tools show promise in automating tasks, improving decision-making, and fostering innovation in software engineering, their integration can also have negative impacts. The role of AI in software development has evolved, but the specific dynamics of human-AI collaboration in this context, particularly with generative AI like ChatGPT, remain \"less explored\" \\cite{hamza2023urf}. Understanding these dynamics is crucial for effectively integrating AI and realizing its full potential while addressing challenges.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous research has explored ChatGPT's applications in various domains, including educational processes, programming assistance, bug fixing, software testing, automated program repair, and software architecture. Some studies have compared ChatGPT's performance against human programmers.\n    *   **Limitations of Previous Solutions**: The authors state that \"to the best of our knowledge, no study has been conducted to evaluate the role of generative AI as a human-AI collaborator\" \\cite{hamza2023urf}. Existing work often treats AI as a utility or assistant, rather than an active, evolving collaborative partner, leaving a gap in understanding the interactive and collaborative aspects of human-AI teams in software engineering.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: The paper does not propose a new AI algorithm or technical method. Instead, its core *research methodology* is an empirical, workshop-based approach to study human-AI collaboration. This involved a hands-on workshop where professional software engineers actively engaged with ChatGPT.\n    *   **Novelty/Difference**: The innovation lies in the *empirical investigation of human-AI collaboration dynamics* in a real-time, hands-on software engineering context. The study uniquely positions ChatGPT as a \"collaborative partner\" and observes how participants define roles for AI, engage in iterative communication, and share knowledge. The workshop design, focusing on these interactive elements, provides novel insights into the practicalities of human-AI teaming.\n\n4.  **Key Technical Contributions**\n    *   **Novel Methods/Techniques**:\n        *   A structured, workshop-based empirical methodology for observing and analyzing human-AI collaboration in software engineering, aligning with design science guidelines \\cite{hamza2023urf}.\n        *   Application of thematic analysis to qualitative data (video recordings, notes) to derive insights into the evolving nature of human-AI interaction.\n    *   **Theoretical Insights/Analysis**:\n        *   Identifies key themes: human-AI collaboration (AI as a collaborative tool, defining and reminding roles for AI, iterative communication, interactive learning and knowledge sharing), AI capabilities for SE, AI limitations, and adoption/learning processes.\n        *   Highlights the crucial transition of AI from a mere tool to a collaborative partner, emphasizing the need for clear role allocation, effective communication, and balanced AI-human collaboration.\n        *   Provides empirical evidence that AI, particularly ChatGPT, can improve efficiency in code generation and optimization, while human oversight remains critical for complex problem-solving and security.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: A hands-on workshop was conducted in May 2023 in Finland, involving 22 professional software engineers (average 10 years of experience).\n        *   The workshop included a 25-minute instructional presentation on using ChatGPT in software engineering, followed by a 2.5-hour hands-on lab session where participants collaborated with ChatGPT on coding tasks.\n        *   Data collection involved video recordings of the entire session and notes taken by a moderator, capturing behavioral observations and responses to open-ended questions.\n        *   The collected data was transcribed and analyzed using a multi-tiered thematic analysis approach.\n    *   **Key Performance Metrics and Comparison Results**: The validation is primarily qualitative, based on the thematic analysis of participant interactions and feedback, rather than quantitative performance metrics.\n        *   **Key Findings**:\n            *   Participants perceived ChatGPT as a \"collaboration partner\" and engaged with it to solve problems, optimize code, and brainstorm ideas.\n            *   Defining specific roles for ChatGPT (e.g., \"Senior Backend Software Developer,\" \"Python expert\") was found to enhance efficiency and optimize the collaborative process.\n            *   Effective and iterative communication with ChatGPT was deemed essential for accurate and relevant responses (\"garbage in, garbage out\").\n            *   ChatGPT demonstrated capabilities in code generation, documentation, explanation, code optimization, software testing, and debugging.\n            *   Limitations were identified: ChatGPT struggles with complex problems requiring human intuition and creativity, can generate incorrect or suboptimal code, and raises security and ethical concerns.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study is based on a single workshop with a specific group of 22 professional software engineers, which may limit the generalizability of the findings. The focus is solely on ChatGPT, meaning insights might not directly apply to other AI tools. The 3-hour duration of the hands-on session might not fully capture long-term collaboration dynamics. The qualitative nature of the study provides interpretive insights rather than statistically generalizable results.\n    *   **Scope of Applicability**: The findings are primarily applicable to understanding and improving human-AI collaboration in software engineering contexts, particularly with large language models like ChatGPT. It offers practical insights for integrating AI tools into development processes and for training software engineers on effective AI interaction.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art**: The paper advances the technical state-of-the-art by providing empirical evidence and qualitative insights into the nuanced dynamics of human-AI collaboration in software engineering, moving beyond the traditional view of AI as a mere tool. It contributes to a theoretical understanding of how humans and AI can effectively team up.\n    *   **Potential Impact on Future Research**: The findings inform the design of future AI tools to better support collaborative paradigms in software engineering. They highlight the importance of features that facilitate role definition, iterative communication, and knowledge sharing. This research can guide future studies into long-term human-AI team performance, the impact on developer creativity, and the ethical implications of deeply integrated AI collaborators. It also underscores the need for educational initiatives to prepare software engineers for effective collaboration with AI.",
    "intriguing_abstract": "The landscape of software engineering is rapidly transforming as generative AI, particularly large language models like ChatGPT, moves beyond mere automation to become an active collaborative partner. Yet, the intricate dynamics of this evolving human-AI teaming remain largely unexplored. This paper presents a novel empirical study, conducting a hands-on workshop with 22 professional software engineers, to meticulously investigate how ChatGPT functions as a collaborative entity in real-world coding tasks.\n\nOur research uniquely positions AI not just as a tool, but as a dynamic collaborator, revealing critical insights into effective human-AI interaction. Through rigorous thematic analysis of participant engagements, we uncover the profound impact of explicit role allocation for AI (e.g., \"Python expert\") and the necessity of iterative communication for optimizing collaborative outcomes. While ChatGPT significantly enhances efficiency in code generation and optimization, our findings underscore the indispensable role of human intuition for complex problem-solving and security oversight. This study advances the state-of-the-art by providing crucial empirical evidence for designing future AI tools that foster seamless collaboration, guiding developer training, and ensuring responsible AI integration in software engineering.",
    "keywords": [
      "Human-AI collaboration",
      "software engineering",
      "ChatGPT",
      "generative AI",
      "empirical investigation",
      "workshop-based methodology",
      "collaboration dynamics",
      "AI role definition",
      "iterative communication",
      "thematic analysis",
      "code generation and optimization",
      "AI limitations and human oversight",
      "AI as collaborative partner"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/4c938522f0dd67bc0a1d053d6cc21da5cfa1763b.pdf",
    "citation_key": "hamza2023urf",
    "metadata": {
      "title": "Human-AI Collaboration in Software Engineering: Lessons Learned from a Hands-On Workshop",
      "authors": [
        "Muhammad Hamza",
        "Dominik Siemon",
        "M. Akbar",
        "Tahsinur Rahman"
      ],
      "published_date": "2023",
      "abstract": "This paper investigates the dynamics of human-AI collaboration in software engineering, focusing on the use of ChatGPT. Through a thematic analysis of a hands-on workshop in which 22 professional software engineers collaborated for three hours with ChatGPT, we explore the transition of AI from a mere tool to a collaborative partner. The study identifies key themes such as the evolving nature of human-AI interaction, the capabilities of AI in software engineering tasks, and the challenges and limitations of integrating AI in this domain. The findings show that while AI, particularly ChatGPT, improves the efficiency of code generation and optimization, human oversight remains crucial, especially in areas requiring complex problem-solving and security considerations. This research contributes to the theoretical understanding of human-AI collaboration in software engineering and provides practical insights for effectively integrating AI tools into development processes. It highlights the need for clear role allocation, effective communication, and balanced AI-human collaboration to realize the full potential of AI in software engineering.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/4c938522f0dd67bc0a1d053d6cc21da5cfa1763b.pdf",
      "venue": "2024 IEEE/ACM International Workshop on Software-Intensive Business (IWSiB)",
      "citationCount": 12,
      "score": 6.0,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **CITATION**: \\cite{hamza2023urf}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper investigates the evolving dynamics of human-AI collaboration in software engineering, specifically focusing on the use of ChatGPT, and how AI transitions from a mere tool to a collaborative partner.\n    *   **Importance and Challenge**: While AI tools show promise in automating tasks, improving decision-making, and fostering innovation in software engineering, their integration can also have negative impacts. The role of AI in software development has evolved, but the specific dynamics of human-AI collaboration in this context, particularly with generative AI like ChatGPT, remain \"less explored\" \\cite{hamza2023urf}. Understanding these dynamics is crucial for effectively integrating AI and realizing its full potential while addressing challenges.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: Previous research has explored ChatGPT's applications in various domains, including educational processes, programming assistance, bug fixing, software testing, automated program repair, and software architecture. Some studies have compared ChatGPT's performance against human programmers.\n    *   **Limitations of Previous Solutions**: The authors state that \"to the best of our knowledge, no study has been conducted to evaluate the role of generative AI as a human-AI collaborator\" \\cite{hamza2023urf}. Existing work often treats AI as a utility or assistant, rather than an active, evolving collaborative partner, leaving a gap in understanding the interactive and collaborative aspects of human-AI teams in software engineering.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm**: The paper does not propose a new AI algorithm or technical method. Instead, its core *research methodology* is an empirical, workshop-based approach to study human-AI collaboration. This involved a hands-on workshop where professional software engineers actively engaged with ChatGPT.\n    *   **Novelty/Difference**: The innovation lies in the *empirical investigation of human-AI collaboration dynamics* in a real-time, hands-on software engineering context. The study uniquely positions ChatGPT as a \"collaborative partner\" and observes how participants define roles for AI, engage in iterative communication, and share knowledge. The workshop design, focusing on these interactive elements, provides novel insights into the practicalities of human-AI teaming.\n\n4.  **Key Technical Contributions**\n    *   **Novel Methods/Techniques**:\n        *   A structured, workshop-based empirical methodology for observing and analyzing human-AI collaboration in software engineering, aligning with design science guidelines \\cite{hamza2023urf}.\n        *   Application of thematic analysis to qualitative data (video recordings, notes) to derive insights into the evolving nature of human-AI interaction.\n    *   **Theoretical Insights/Analysis**:\n        *   Identifies key themes: human-AI collaboration (AI as a collaborative tool, defining and reminding roles for AI, iterative communication, interactive learning and knowledge sharing), AI capabilities for SE, AI limitations, and adoption/learning processes.\n        *   Highlights the crucial transition of AI from a mere tool to a collaborative partner, emphasizing the need for clear role allocation, effective communication, and balanced AI-human collaboration.\n        *   Provides empirical evidence that AI, particularly ChatGPT, can improve efficiency in code generation and optimization, while human oversight remains critical for complex problem-solving and security.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: A hands-on workshop was conducted in May 2023 in Finland, involving 22 professional software engineers (average 10 years of experience).\n        *   The workshop included a 25-minute instructional presentation on using ChatGPT in software engineering, followed by a 2.5-hour hands-on lab session where participants collaborated with ChatGPT on coding tasks.\n        *   Data collection involved video recordings of the entire session and notes taken by a moderator, capturing behavioral observations and responses to open-ended questions.\n        *   The collected data was transcribed and analyzed using a multi-tiered thematic analysis approach.\n    *   **Key Performance Metrics and Comparison Results**: The validation is primarily qualitative, based on the thematic analysis of participant interactions and feedback, rather than quantitative performance metrics.\n        *   **Key Findings**:\n            *   Participants perceived ChatGPT as a \"collaboration partner\" and engaged with it to solve problems, optimize code, and brainstorm ideas.\n            *   Defining specific roles for ChatGPT (e.g., \"Senior Backend Software Developer,\" \"Python expert\") was found to enhance efficiency and optimize the collaborative process.\n            *   Effective and iterative communication with ChatGPT was deemed essential for accurate and relevant responses (\"garbage in, garbage out\").\n            *   ChatGPT demonstrated capabilities in code generation, documentation, explanation, code optimization, software testing, and debugging.\n            *   Limitations were identified: ChatGPT struggles with complex problems requiring human intuition and creativity, can generate incorrect or suboptimal code, and raises security and ethical concerns.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The study is based on a single workshop with a specific group of 22 professional software engineers, which may limit the generalizability of the findings. The focus is solely on ChatGPT, meaning insights might not directly apply to other AI tools. The 3-hour duration of the hands-on session might not fully capture long-term collaboration dynamics. The qualitative nature of the study provides interpretive insights rather than statistically generalizable results.\n    *   **Scope of Applicability**: The findings are primarily applicable to understanding and improving human-AI collaboration in software engineering contexts, particularly with large language models like ChatGPT. It offers practical insights for integrating AI tools into development processes and for training software engineers on effective AI interaction.\n\n7.  **Technical Significance**\n    *   **Advance State-of-the-Art**: The paper advances the technical state-of-the-art by providing empirical evidence and qualitative insights into the nuanced dynamics of human-AI collaboration in software engineering, moving beyond the traditional view of AI as a mere tool. It contributes to a theoretical understanding of how humans and AI can effectively team up.\n    *   **Potential Impact on Future Research**: The findings inform the design of future AI tools to better support collaborative paradigms in software engineering. They highlight the importance of features that facilitate role definition, iterative communication, and knowledge sharing. This research can guide future studies into long-term human-AI team performance, the impact on developer creativity, and the ethical implications of deeply integrated AI collaborators. It also underscores the need for educational initiatives to prepare software engineers for effective collaboration with AI.",
      "keywords": [
        "Human-AI collaboration",
        "software engineering",
        "ChatGPT",
        "generative AI",
        "empirical investigation",
        "workshop-based methodology",
        "collaboration dynamics",
        "AI role definition",
        "iterative communication",
        "thematic analysis",
        "code generation and optimization",
        "AI limitations and human oversight",
        "AI as collaborative partner"
      ],
      "paper_type": "based on the abstract and introduction, this paper is best classified as **empirical**.\n\nhere's why:\n\n1.  **abstract content:**\n    *   \"this paper investigates the dynamics of human -ai collaboration...\" - indicates a study.\n    *   \"through a thematic analysis of a hands -on workshop in which 22 professional software engineers collaborated for three hours with chatgpt...\" - clearly describes a methodology involving data collection (workshop, participants, duration) and analysis (thematic analysis).\n    *   \"the study identifies key themes...\" - refers to findings from the investigation.\n    *   \"the findings show that while ai... improves the efficiency... human oversight remains crucial...\" - presents results and conclusions drawn from the study.\n    *   **keywords:** explicitly lists \"empirical investigation.\"\n    *   **ccs concepts:** explicitly lists \"empirical study.\"\n\n2.  **introduction content:**\n    *   sets the stage for the problem being investigated (ai in software engineering, chatgpt's impact).\n    *   mentions existing research, but doesn't organize or review it comprehensively like a survey.\n\n3.  **matching with criteria:**\n    *   **empirical** - strong match. the abstract mentions \"study,\" \"experiment\" (implied by workshop), \"data\" (from workshop interactions), \"findings,\" \"research questions\" (implied by \"investigates the dynamics\"), \"methodology\" (thematic analysis of workshop), and \"participants\" (22 professional software engineers). the authors themselves label it \"empirical investigation\" and \"empirical study.\"\n\nwhile the paper is also \"short\" (indicated by the workshop venue and \"2 pages\" in the acm reference format), the primary nature of the research described in the abstract is empirical. the authors' explicit self-classification as \"empirical investigation\" and \"empirical study\" reinforces this. the \"short\" classification often describes the *format* or *scope* of a paper (e.g., a short empirical paper, a short technical paper), but the core *type of research* presented here is empirical."
    },
    "file_name": "4c938522f0dd67bc0a1d053d6cc21da5cfa1763b.pdf"
  },
  {
    "success": true,
    "doc_id": "c127a3641c84516a8f48834e3e855565",
    "summary": "Software testing is a crucial aspect of the software development lifecycle, ensuring the delivery of high-quality, reliable, and secure software systems. With the advancements in Artificial Intelligence (AI) and Natural Language Processing (NLP), Large Language Models (LLMs) have emerged as powerful tools capable of understanding and processing natural language texts easly. This article investigates the application of AI-based software testing, with a specific focus on the impact of LLMs in traditional testing methodologies. Through a comprehensive review of relevant literature and SeturDigital’s 25 year testing experience, this article explores the potential benefits, challenges, and prospects of integrating LLMs into software testing.",
    "intriguing_abstract": "Software testing is a crucial aspect of the software development lifecycle, ensuring the delivery of high-quality, reliable, and secure software systems. With the advancements in Artificial Intelligence (AI) and Natural Language Processing (NLP), Large Language Models (LLMs) have emerged as powerful tools capable of understanding and processing natural language texts easly. This article investigates the application of AI-based software testing, with a specific focus on the impact of LLMs in traditional testing methodologies. Through a comprehensive review of relevant literature and SeturDigital’s 25 year testing experience, this article explores the potential benefits, challenges, and prospects of integrating LLMs into software testing.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/43189527d68e612a911680c7039dddba4f030985.pdf",
    "citation_key": "bayr20238ff",
    "metadata": {
      "title": "AI-Powered Software Testing: The Impact of Large Language Models on Testing Methodologies",
      "authors": [
        "Vahit Bayrı",
        "Ece Demirel"
      ],
      "published_date": "2023",
      "abstract": "Software testing is a crucial aspect of the software development lifecycle, ensuring the delivery of high-quality, reliable, and secure software systems. With the advancements in Artificial Intelligence (AI) and Natural Language Processing (NLP), Large Language Models (LLMs) have emerged as powerful tools capable of understanding and processing natural language texts easly. This article investigates the application of AI-based software testing, with a specific focus on the impact of LLMs in traditional testing methodologies. Through a comprehensive review of relevant literature and SeturDigital’s 25 year testing experience, this article explores the potential benefits, challenges, and prospects of integrating LLMs into software testing.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/43189527d68e612a911680c7039dddba4f030985.pdf",
      "venue": "2023 4th International Informatics and Software Engineering Conference (IISEC)",
      "citationCount": 11,
      "score": 5.5,
      "summary": "Software testing is a crucial aspect of the software development lifecycle, ensuring the delivery of high-quality, reliable, and secure software systems. With the advancements in Artificial Intelligence (AI) and Natural Language Processing (NLP), Large Language Models (LLMs) have emerged as powerful tools capable of understanding and processing natural language texts easly. This article investigates the application of AI-based software testing, with a specific focus on the impact of LLMs in traditional testing methodologies. Through a comprehensive review of relevant literature and SeturDigital’s 25 year testing experience, this article explores the potential benefits, challenges, and prospects of integrating LLMs into software testing.",
      "keywords": []
    },
    "file_name": "43189527d68e612a911680c7039dddba4f030985.pdf"
  },
  {
    "success": true,
    "doc_id": "4a173eeadb315d06cd086ebb5ab5818e",
    "summary": "Technical systems are becoming increasingly complex due to the increasing number of components, functions, and involvement of different disciplines. In this regard, model-driven engineering techniques and practices tame complexity during the development process by using models as primary artifacts. Modeling can be carried out through domain-specific languages whose implementation is supported by model-driven techniques. Today, the amount of data generated during product development is rapidly growing, leading to an increased need to leverage artificial intelligence algorithms. However, using these algorithms in practice can be difficult and time-consuming. Therefore, leveraging domain-specific languages and model-driven techniques for formulating AI algorithms or parts of them can reduce these complexities and be advantageous. This study aims to investigate the existing model-driven approaches relying on domain-specific languages in support of the engineering of AI software systems to sharpen future research further and define the current state of the art. We conducted a Systemic Literature Review (SLR), collecting papers from five major databases resulting in 1335 candidate studies, eventually retaining 18 primary studies. Each primary study will be evaluated and discussed with respect to the adoption of (1) MDE principles and practices and (2) the phases of AI development support aligned with the stages of the CRISP-DM methodology. The study’s findings show that language workbenches are of paramount importance in dealing with all aspects of modeling language development (metamodel, concrete syntax, and model transformation) and are leveraged to define domain-specific languages (DSL) explicitly addressing AI concerns. The most prominent AI-related concerns are training and modeling of the AI algorithm, while minor emphasis is given to the time-consuming preparation of the data sets. Early project phases that support interdisciplinary communication of requirements, such as the CRISP-DM Business Understanding phase, are rarely reflected. The study found that the use of MDE for AI is still in its early stages, and there is no single tool or method that is widely used. Additionally, current approaches tend to focus on specific stages of development rather than providing support for the entire development process. As a result, the study suggests several research directions to further improve the use of MDE for AI and to guide future research in this area.",
    "intriguing_abstract": "Technical systems are becoming increasingly complex due to the increasing number of components, functions, and involvement of different disciplines. In this regard, model-driven engineering techniques and practices tame complexity during the development process by using models as primary artifacts. Modeling can be carried out through domain-specific languages whose implementation is supported by model-driven techniques. Today, the amount of data generated during product development is rapidly growing, leading to an increased need to leverage artificial intelligence algorithms. However, using these algorithms in practice can be difficult and time-consuming. Therefore, leveraging domain-specific languages and model-driven techniques for formulating AI algorithms or parts of them can reduce these complexities and be advantageous. This study aims to investigate the existing model-driven approaches relying on domain-specific languages in support of the engineering of AI software systems to sharpen future research further and define the current state of the art. We conducted a Systemic Literature Review (SLR), collecting papers from five major databases resulting in 1335 candidate studies, eventually retaining 18 primary studies. Each primary study will be evaluated and discussed with respect to the adoption of (1) MDE principles and practices and (2) the phases of AI development support aligned with the stages of the CRISP-DM methodology. The study’s findings show that language workbenches are of paramount importance in dealing with all aspects of modeling language development (metamodel, concrete syntax, and model transformation) and are leveraged to define domain-specific languages (DSL) explicitly addressing AI concerns. The most prominent AI-related concerns are training and modeling of the AI algorithm, while minor emphasis is given to the time-consuming preparation of the data sets. Early project phases that support interdisciplinary communication of requirements, such as the CRISP-DM Business Understanding phase, are rarely reflected. The study found that the use of MDE for AI is still in its early stages, and there is no single tool or method that is widely used. Additionally, current approaches tend to focus on specific stages of development rather than providing support for the entire development process. As a result, the study suggests several research directions to further improve the use of MDE for AI and to guide future research in this area.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/23ef50374a21d2941af18abb42305a7206b00b05.pdf",
    "citation_key": "rdler202361h",
    "metadata": {
      "title": "Bridging MDE and AI: a systematic review of domain-specific languages and model-driven practices in AI software systems engineering",
      "authors": [
        "Simon Rädler",
        "Luca Berardinelli",
        "Karolin Winter",
        "Abbas Rahimi",
        "Stefanie Rinderle-Ma"
      ],
      "published_date": "2023",
      "abstract": "Technical systems are becoming increasingly complex due to the increasing number of components, functions, and involvement of different disciplines. In this regard, model-driven engineering techniques and practices tame complexity during the development process by using models as primary artifacts. Modeling can be carried out through domain-specific languages whose implementation is supported by model-driven techniques. Today, the amount of data generated during product development is rapidly growing, leading to an increased need to leverage artificial intelligence algorithms. However, using these algorithms in practice can be difficult and time-consuming. Therefore, leveraging domain-specific languages and model-driven techniques for formulating AI algorithms or parts of them can reduce these complexities and be advantageous. This study aims to investigate the existing model-driven approaches relying on domain-specific languages in support of the engineering of AI software systems to sharpen future research further and define the current state of the art. We conducted a Systemic Literature Review (SLR), collecting papers from five major databases resulting in 1335 candidate studies, eventually retaining 18 primary studies. Each primary study will be evaluated and discussed with respect to the adoption of (1) MDE principles and practices and (2) the phases of AI development support aligned with the stages of the CRISP-DM methodology. The study’s findings show that language workbenches are of paramount importance in dealing with all aspects of modeling language development (metamodel, concrete syntax, and model transformation) and are leveraged to define domain-specific languages (DSL) explicitly addressing AI concerns. The most prominent AI-related concerns are training and modeling of the AI algorithm, while minor emphasis is given to the time-consuming preparation of the data sets. Early project phases that support interdisciplinary communication of requirements, such as the CRISP-DM Business Understanding phase, are rarely reflected. The study found that the use of MDE for AI is still in its early stages, and there is no single tool or method that is widely used. Additionally, current approaches tend to focus on specific stages of development rather than providing support for the entire development process. As a result, the study suggests several research directions to further improve the use of MDE for AI and to guide future research in this area.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/23ef50374a21d2941af18abb42305a7206b00b05.pdf",
      "venue": "Journal of Software and Systems Modeling",
      "citationCount": 11,
      "score": 5.5,
      "summary": "Technical systems are becoming increasingly complex due to the increasing number of components, functions, and involvement of different disciplines. In this regard, model-driven engineering techniques and practices tame complexity during the development process by using models as primary artifacts. Modeling can be carried out through domain-specific languages whose implementation is supported by model-driven techniques. Today, the amount of data generated during product development is rapidly growing, leading to an increased need to leverage artificial intelligence algorithms. However, using these algorithms in practice can be difficult and time-consuming. Therefore, leveraging domain-specific languages and model-driven techniques for formulating AI algorithms or parts of them can reduce these complexities and be advantageous. This study aims to investigate the existing model-driven approaches relying on domain-specific languages in support of the engineering of AI software systems to sharpen future research further and define the current state of the art. We conducted a Systemic Literature Review (SLR), collecting papers from five major databases resulting in 1335 candidate studies, eventually retaining 18 primary studies. Each primary study will be evaluated and discussed with respect to the adoption of (1) MDE principles and practices and (2) the phases of AI development support aligned with the stages of the CRISP-DM methodology. The study’s findings show that language workbenches are of paramount importance in dealing with all aspects of modeling language development (metamodel, concrete syntax, and model transformation) and are leveraged to define domain-specific languages (DSL) explicitly addressing AI concerns. The most prominent AI-related concerns are training and modeling of the AI algorithm, while minor emphasis is given to the time-consuming preparation of the data sets. Early project phases that support interdisciplinary communication of requirements, such as the CRISP-DM Business Understanding phase, are rarely reflected. The study found that the use of MDE for AI is still in its early stages, and there is no single tool or method that is widely used. Additionally, current approaches tend to focus on specific stages of development rather than providing support for the entire development process. As a result, the study suggests several research directions to further improve the use of MDE for AI and to guide future research in this area.",
      "keywords": []
    },
    "file_name": "23ef50374a21d2941af18abb42305a7206b00b05.pdf"
  },
  {
    "success": true,
    "doc_id": "aa2c46311fcbd9877c5e9344548238c1",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Problem:** The paper addresses the technical challenges associated with integrating generative AI into software development, specifically concerning the accuracy, contextual understanding, security, privacy, and ethical implications of AI-powered coding tools \\cite{aarti2024abq}.\n    *   **Importance & Challenge:** While generative AI significantly enhances productivity and automates coding tasks, existing tools often produce suboptimal or incorrect code, lack deep contextual understanding of projects, and pose risks to proprietary information and privacy. The challenge lies in maximizing the benefits of generative AI while ensuring the reliability, security, and ethical soundness of the generated code and the tools themselves \\cite{aarti2024abq}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work relates to existing approaches by providing a comprehensive overview and evaluation of current generative AI tools (e.g., GitHub Copilot, OpenAI Codex, DeepCode, Amazon CodeGuru, TabNine, Kite, IntelliCode) that leverage large language models (LLMs) for code generation, completion, and analysis \\cite{aarti2024abq}. It positions itself as a review that synthesizes the capabilities and limitations of these modern tools.\n    *   **Limitations of Previous Solutions:** The paper implicitly highlights the limitations of current generative AI solutions by focusing on their challenges: they often struggle with accuracy, contextual understanding, and present security and privacy concerns, necessitating thorough developer review and testing of AI-generated code \\cite{aarti2024abq}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper's core technical method is a qualitative overview and comparative evaluation of existing generative AI-powered coding tools \\cite{aarti2024abq}. It analyzes their capabilities (code generation, error detection, automated documentation), the underlying LLMs or AI models used (e.g., OpenAI Codex, GPT-3, custom symbolic AI/ML, neural networks, models trained on GitHub projects), their reported benefits, and their general accuracy for various coding tasks.\n    *   **Novelty:** The novelty lies in its structured evaluation and synthesis of the current landscape of generative AI tools in software development, providing a consolidated view of their technical underpinnings, strengths, weaknesses, and applicability across different development scenarios \\cite{aarti2024abq}. It systematically compares and categorizes these tools based on their technical characteristics and practical utility.\n\n4.  **Key Technical Contributions**\n    *   **Systematic Evaluation Framework:** Presents a structured comparison of prominent generative AI coding tools, detailing their underlying AI models, specific benefits, and reported accuracy levels for various tasks \\cite{aarti2024abq}.\n    *   **Categorization of Tool Applicability:** Provides practical guidance by categorizing which AI tools are best suited for different software development scenarios (e.g., general development, multi-language projects, code quality assurance, performance optimization, IDE integration, documentation-driven development, adherence to best practices) \\cite{aarti2024abq}.\n    *   **Identification of Future Research Directions:** Highlights critical technical challenges (accuracy, contextual understanding, security, privacy) and proposes future research avenues, including enhanced model training, development of context-aware models, and secure AI training methods (e.g., federated learning) \\cite{aarti2024abq}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The paper conducts a comparative evaluation of seven modern AI-powered coding tools: GitHub Copilot, OpenAI Codex, DeepCode, Amazon CodeGuru, TabNine, Kite, and IntelliCode \\cite{aarti2024abq}. This validation is based on an analysis of their stated capabilities, the AI models they employ, their reported benefits, and qualitative assessments of their accuracy in various coding tasks.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Metrics:** The evaluation implicitly uses metrics such as \"accuracy\" (e.g., \"High for common tasks,\" \"decreases with ambiguity,\" \"might miss context-specific issues\"), \"development speed,\" \"code quality,\" \"security vulnerability detection,\" and \"integration capabilities\" \\cite{aarti2024abq}.\n        *   **Comparison Results:**\n            *   **GitHub Copilot & OpenAI Codex:** Generally high accuracy for common or well-defined tasks, but require developer oversight or show decreased accuracy with ambiguity \\cite{aarti2024abq}.\n            *   **DeepCode & Amazon CodeGuru:** Effective for bug detection, code quality, and security for standard code, but may miss context-specific issues or depend on codebase complexity \\cite{aarti2024abq}.\n            *   **TabNine & Kite:** High accuracy for typical patterns and standard tasks, but performance can vary or require validation for complex or unique scenarios \\cite{aarti2024abq}.\n            *   **IntelliCode:** High for common patterns and best practices derived from open-source projects, but less accurate for niche or proprietary codebases \\cite{aarti2024abq}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   **Accuracy and Reliability:** Generative AI models can produce incorrect or suboptimal code, necessitating thorough developer review and testing to ensure correctness and maintain code quality \\cite{aarti2024abq}.\n        *   **Contextual Understanding:** Current tools often struggle with understanding the broader context of a project, including business logic and specific requirements, leading to suggestions that are technically correct but contextually irrelevant \\cite{aarti2024abq}.\n        *   **Security and Privacy:** The use of AI in coding raises concerns about inadvertently exposing sensitive or proprietary information through AI training processes or outputs \\cite{aarti2024abq}.\n    *   **Scope of Applicability:** The paper's validation is limited to a qualitative overview and comparative analysis of existing tools' reported capabilities and general performance, rather than presenting new empirical data from controlled experiments conducted by the authors \\cite{aarti2024abq}. The \"accuracy\" assessments are qualitative and based on general understanding rather than rigorous quantitative benchmarks.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art:** The paper advances the technical state-of-the-art by providing a consolidated, structured overview and evaluation of the rapidly evolving landscape of generative AI tools in software development \\cite{aarti2024abq}. It synthesizes current capabilities and highlights critical technical gaps that need to be addressed for more robust and reliable AI integration.\n    *   **Potential Impact on Future Research:**\n        *   **Improved AI Models:** Emphasizes the need for enhanced model training (larger/diverse datasets, edge cases), hybrid AI approaches (combining AI with rule-based systems and human expertise), and continuous learning mechanisms to boost accuracy and reliability \\cite{aarti2024abq}.\n        *   **Context-Aware AI:** Calls for the development of more sophisticated, context-aware models that can ingest and understand project-specific documentation, business logic, and integrate better with project management tools \\cite{aarti2024abq}.\n        *   **Secure and Ethical AI:** Stresses the importance of secure AI training methods (e.g., federated learning) and addressing privacy concerns to foster trust and wider adoption of generative AI in sensitive development environments \\cite{aarti2024abq}.",
    "intriguing_abstract": "The transformative potential of generative AI in software development is immense, yet its widespread integration faces significant hurdles concerning accuracy, contextual understanding, security, and privacy. This paper presents a timely and systematic comparative evaluation of leading AI-powered coding tools, including GitHub Copilot, OpenAI Codex, and Amazon CodeGuru, analyzing their underlying Large Language Models (LLMs), capabilities, and qualitative accuracy across diverse tasks.\n\nWe uncover a persistent tension: while these tools significantly boost productivity, they frequently struggle with deep project contextual understanding, generate suboptimal code, and introduce substantial security and privacy risks. Our novel categorization framework provides practical guidance for tool selection and, crucially, delineates critical technical gaps. We identify pressing research avenues for developing more reliable, context-aware AI models, advocating for hybrid AI approaches, continuous learning, and secure training methodologies like federated learning to mitigate ethical and security concerns. This work offers a consolidated roadmap for researchers and practitioners to harness generative AI's full potential, ensuring robust, secure, and ethically sound integration into the future of software engineering.",
    "keywords": [
      "Generative AI",
      "AI-powered coding tools",
      "Large Language Models (LLMs)",
      "code generation",
      "comparative evaluation",
      "AI code accuracy",
      "contextual understanding (AI)",
      "security and privacy (AI in coding)",
      "systematic evaluation framework",
      "tool applicability categorization",
      "future research directions",
      "enhanced model training",
      "context-aware AI models",
      "secure AI training methods"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/44eff92639a7b6a4bd37f09bc7277210a008aa77.pdf",
    "citation_key": "aarti2024abq",
    "metadata": {
      "title": "Generative Ai in Software Development : an Overview and Evaluation of Modern Coding Tools",
      "authors": [
        "Aarti"
      ],
      "published_date": "2024",
      "abstract": "Generative AI has significantly transformed software development by leveraging advanced machine learning models to automate coding tasks, generate code, and enhance productivity. This paper provides an overview and evaluation of modern AI-powered coding tools, including GitHub Copilot, OpenAI Codex, DeepCode, Amazon CodeGuru, TabNine, Kite, and IntelliCode, which use large language models (LLMs) to offer real-time code suggestions, automated error detection, and intelligent code completions. Despite their benefits, these tools face challenges related to accuracy, contextual understanding, security, privacy, and ethical considerations, necessitating thorough review and testing of AI-generated code by developers. The integration of AI in coding also raises concerns about proprietary information protection and ethical implications such as job displacement. This paper explores the capabilities, applications, and limitations of current generative AI tools, highlighting their impact on software development and discussing future directions. Emphasis is placed on the need for improved model training, enhanced contextual understanding, secure AI training methods, and ethical AI usage. By addressing these challenges, the industry can maximize the potential of generative AI, creating more accurate, reliable, and ethically sound tools that support a collaborative and innovative software development environment.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/44eff92639a7b6a4bd37f09bc7277210a008aa77.pdf",
      "venue": "International Journal For Multidisciplinary Research",
      "citationCount": 5,
      "score": 5.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n1.  **Research Problem & Motivation**\n    *   **Problem:** The paper addresses the technical challenges associated with integrating generative AI into software development, specifically concerning the accuracy, contextual understanding, security, privacy, and ethical implications of AI-powered coding tools \\cite{aarti2024abq}.\n    *   **Importance & Challenge:** While generative AI significantly enhances productivity and automates coding tasks, existing tools often produce suboptimal or incorrect code, lack deep contextual understanding of projects, and pose risks to proprietary information and privacy. The challenge lies in maximizing the benefits of generative AI while ensuring the reliability, security, and ethical soundness of the generated code and the tools themselves \\cite{aarti2024abq}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work relates to existing approaches by providing a comprehensive overview and evaluation of current generative AI tools (e.g., GitHub Copilot, OpenAI Codex, DeepCode, Amazon CodeGuru, TabNine, Kite, IntelliCode) that leverage large language models (LLMs) for code generation, completion, and analysis \\cite{aarti2024abq}. It positions itself as a review that synthesizes the capabilities and limitations of these modern tools.\n    *   **Limitations of Previous Solutions:** The paper implicitly highlights the limitations of current generative AI solutions by focusing on their challenges: they often struggle with accuracy, contextual understanding, and present security and privacy concerns, necessitating thorough developer review and testing of AI-generated code \\cite{aarti2024abq}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper's core technical method is a qualitative overview and comparative evaluation of existing generative AI-powered coding tools \\cite{aarti2024abq}. It analyzes their capabilities (code generation, error detection, automated documentation), the underlying LLMs or AI models used (e.g., OpenAI Codex, GPT-3, custom symbolic AI/ML, neural networks, models trained on GitHub projects), their reported benefits, and their general accuracy for various coding tasks.\n    *   **Novelty:** The novelty lies in its structured evaluation and synthesis of the current landscape of generative AI tools in software development, providing a consolidated view of their technical underpinnings, strengths, weaknesses, and applicability across different development scenarios \\cite{aarti2024abq}. It systematically compares and categorizes these tools based on their technical characteristics and practical utility.\n\n4.  **Key Technical Contributions**\n    *   **Systematic Evaluation Framework:** Presents a structured comparison of prominent generative AI coding tools, detailing their underlying AI models, specific benefits, and reported accuracy levels for various tasks \\cite{aarti2024abq}.\n    *   **Categorization of Tool Applicability:** Provides practical guidance by categorizing which AI tools are best suited for different software development scenarios (e.g., general development, multi-language projects, code quality assurance, performance optimization, IDE integration, documentation-driven development, adherence to best practices) \\cite{aarti2024abq}.\n    *   **Identification of Future Research Directions:** Highlights critical technical challenges (accuracy, contextual understanding, security, privacy) and proposes future research avenues, including enhanced model training, development of context-aware models, and secure AI training methods (e.g., federated learning) \\cite{aarti2024abq}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The paper conducts a comparative evaluation of seven modern AI-powered coding tools: GitHub Copilot, OpenAI Codex, DeepCode, Amazon CodeGuru, TabNine, Kite, and IntelliCode \\cite{aarti2024abq}. This validation is based on an analysis of their stated capabilities, the AI models they employ, their reported benefits, and qualitative assessments of their accuracy in various coding tasks.\n    *   **Key Performance Metrics & Comparison Results:**\n        *   **Metrics:** The evaluation implicitly uses metrics such as \"accuracy\" (e.g., \"High for common tasks,\" \"decreases with ambiguity,\" \"might miss context-specific issues\"), \"development speed,\" \"code quality,\" \"security vulnerability detection,\" and \"integration capabilities\" \\cite{aarti2024abq}.\n        *   **Comparison Results:**\n            *   **GitHub Copilot & OpenAI Codex:** Generally high accuracy for common or well-defined tasks, but require developer oversight or show decreased accuracy with ambiguity \\cite{aarti2024abq}.\n            *   **DeepCode & Amazon CodeGuru:** Effective for bug detection, code quality, and security for standard code, but may miss context-specific issues or depend on codebase complexity \\cite{aarti2024abq}.\n            *   **TabNine & Kite:** High accuracy for typical patterns and standard tasks, but performance can vary or require validation for complex or unique scenarios \\cite{aarti2024abq}.\n            *   **IntelliCode:** High for common patterns and best practices derived from open-source projects, but less accurate for niche or proprietary codebases \\cite{aarti2024abq}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions:**\n        *   **Accuracy and Reliability:** Generative AI models can produce incorrect or suboptimal code, necessitating thorough developer review and testing to ensure correctness and maintain code quality \\cite{aarti2024abq}.\n        *   **Contextual Understanding:** Current tools often struggle with understanding the broader context of a project, including business logic and specific requirements, leading to suggestions that are technically correct but contextually irrelevant \\cite{aarti2024abq}.\n        *   **Security and Privacy:** The use of AI in coding raises concerns about inadvertently exposing sensitive or proprietary information through AI training processes or outputs \\cite{aarti2024abq}.\n    *   **Scope of Applicability:** The paper's validation is limited to a qualitative overview and comparative analysis of existing tools' reported capabilities and general performance, rather than presenting new empirical data from controlled experiments conducted by the authors \\cite{aarti2024abq}. The \"accuracy\" assessments are qualitative and based on general understanding rather than rigorous quantitative benchmarks.\n\n7.  **Technical Significance**\n    *   **Advances State-of-the-Art:** The paper advances the technical state-of-the-art by providing a consolidated, structured overview and evaluation of the rapidly evolving landscape of generative AI tools in software development \\cite{aarti2024abq}. It synthesizes current capabilities and highlights critical technical gaps that need to be addressed for more robust and reliable AI integration.\n    *   **Potential Impact on Future Research:**\n        *   **Improved AI Models:** Emphasizes the need for enhanced model training (larger/diverse datasets, edge cases), hybrid AI approaches (combining AI with rule-based systems and human expertise), and continuous learning mechanisms to boost accuracy and reliability \\cite{aarti2024abq}.\n        *   **Context-Aware AI:** Calls for the development of more sophisticated, context-aware models that can ingest and understand project-specific documentation, business logic, and integrate better with project management tools \\cite{aarti2024abq}.\n        *   **Secure and Ethical AI:** Stresses the importance of secure AI training methods (e.g., federated learning) and addressing privacy concerns to foster trust and wider adoption of generative AI in sensitive development environments \\cite{aarti2024abq}.",
      "keywords": [
        "Generative AI",
        "AI-powered coding tools",
        "Large Language Models (LLMs)",
        "code generation",
        "comparative evaluation",
        "AI code accuracy",
        "contextual understanding (AI)",
        "security and privacy (AI in coding)",
        "systematic evaluation framework",
        "tool applicability categorization",
        "future research directions",
        "enhanced model training",
        "context-aware AI models",
        "secure AI training methods"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"this paper provides an **overview and evaluation** of modern ai-powered coding tools...\" and \"this paper **explores the capabilities, applications, and limitations** of current generative ai tools, highlighting their impact on software development and discussing future directions.\"\n*   the introduction reiterates: \"this paper provides an **overview and evaluation** of current generative ai tools, examining their capabilities, applications, and limitations to highlight their impact on software development and future potential.\"\n*   crucially, the next section heading after the introduction is \"2. **literature review**\".\n\nthese phrases and the structure strongly align with the criteria for a **survey** paper, which reviews existing literature, provides a comprehensive analysis, and discusses the state-of-the-art.\n\n**classification: survey**"
    },
    "file_name": "44eff92639a7b6a4bd37f09bc7277210a008aa77.pdf"
  },
  {
    "success": true,
    "doc_id": "fb3b78d39f52185fda06525b508b5ecf",
    "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the nascent and underexplored application of Generative AI (GenAI) in software architecture, despite its transformative potential in other software engineering (SE) domains \\cite{esposito20252vd}.\n    *   This problem is critical because GenAI could revolutionize how complex systems are designed, optimized, and maintained, yet practitioners and researchers lack a clear understanding of its implications, limitations, and benefits for architectural tasks \\cite{esposito20252vd}.\n    *   Challenges include inconsistent findings on GenAI's reliability for architectural decisions, a lack of systematic evidence, unclear best practices, and open issues like security vulnerabilities, biases, and ethical implications \\cite{esposito20252vd}.\n\n*   **Related Work & Positioning**\n    *   Existing literature reviews on Large Language Models (LLMs) in SE primarily focus on code generation, testing, and requirements engineering, with limited attention to software design and architecture \\cite{esposito20252vd}.\n    *   While some studies explore AI/LLMs for specific architectural tasks (e.g., microservice recommendation, pattern suggestion, AI-architecture integration), a comprehensive, multivocal review specifically on GenAI for software architecture, synthesizing both academic and gray literature, was missing \\cite{esposito20252vd}.\n    *   This work positions itself to fill this gap by providing a holistic synthesis that bridges academic research and industry practice \\cite{esposito20252vd}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a Multivocal Literature Review (MLR), systematically analyzing both peer-reviewed academic papers and gray literature (e.g., industry reports, blog posts, technical documentation) \\cite{esposito20252vd}.\n    *   The approach is novel in its comprehensive scope, specifically targeting GenAI in software architecture, and its inclusion of gray literature, which is crucial for understanding an emerging field where industry adoption often precedes formal academic publication \\cite{esposito20252vd}.\n    *   Themes, practices, models, adoption contexts, and challenges were extracted using open coding \\cite{esposito20252vd}.\n\n*   **Key Technical Contributions**\n    *   A comprehensive synthesis of how GenAI is currently used in software architecture, including underlying rationales, models, and usage approaches \\cite{esposito20252vd}.\n    *   Classification of the GenAI models predominantly adopted (e.g., OpenAI GPT models) and common techniques (e.g., few-shot prompting, Retrieval-Augmented Generation - RAG) \\cite{esposito20252vd}.\n    *   Identification of common applications (e.g., architectural decision support, architectural reconstruction, Requirements-to-Architecture, Architecture-to-Code) and targeted architectural styles (monolithic, microservices) \\cite{esposito20252vd}.\n    *   Highlighting critical research gaps and open challenges, such as the lack of rigorous evaluation, architecture-specific datasets, and sound evaluation frameworks \\cite{esposito20252vd}.\n\n*   **Experimental Validation**\n    *   As a literature review, the paper does not conduct new experiments but synthesizes findings from existing studies.\n    *   **Key findings from the reviewed literature**: GenAI is significantly adopted for architectural decision support and reconstruction \\cite{esposito20252vd}. OpenAI GPT models are prevalent, often used with few-shot prompting and RAG \\cite{esposito20252vd}. Applications are concentrated in early Software Architecture Life Cycle (SALC) stages (Requirements-to-Architecture, Architecture-to-Code) and target monolithic/microservice architectures \\cite{esposito20252vd}.\n    *   **Crucially, the review found**: \"rigorous testing of GenAI outputs was typically missing from the studies\" \\cite{esposito20252vd}. Most evaluations focused on usability or accuracy, with few addressing the impact on architectural quality attributes (e.g., modifiability, scalability, maintainability), indicating an absence of rigorous evaluation in the primary studies \\cite{esposito20252vd}.\n\n*   **Limitations & Scope**\n    *   **Limitations identified in the reviewed literature**: Frequent challenges include model precision, hallucinations, ethical concerns, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks \\cite{esposito20252vd}.\n    *   GenAI's integration into complex, high-stakes architectural decision-making remains limited, with prevailing utilization oriented towards documentation and code generation rather than system-level reasoning, trade-off analysis, or performance modeling \\cite{esposito20252vd}.\n    *   The scope covers GenAI applications in software architecture across various SALC phases, architectural styles, and tasks, drawing from both academic and industry sources \\cite{esposito20252vd}.\n\n*   **Technical Significance**\n    *   This paper significantly advances the technical state-of-the-art by providing the first comprehensive, multivocal synthesis of GenAI in software architecture, mapping the current landscape and identifying key trends and challenges \\cite{esposito20252vd}.\n    *   It offers a critical roadmap for future research, emphasizing the urgent need for general evaluation methodologies, addressing ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks \\cite{esposito20252vd}.\n    *   The findings are expected to catalyze future research by guiding efforts towards impactful areas that can bridge the gap between theoretical possibilities and practical, rigorously validated applications of GenAI in software architecture \\cite{esposito20252vd}.",
    "intriguing_abstract": "The transformative potential of Generative AI (GenAI) in software architecture remains largely untapped and critically underexplored, despite its profound impact across other software engineering domains. To bridge this crucial knowledge gap, we present the first comprehensive Multivocal Literature Review (MLR) synthesizing both academic research and industry gray literature on GenAI's application in software architecture.\n\nOur synthesis reveals prevalent GenAI models (e.g., OpenAI GPT) and techniques (e.g., few-shot prompting, Retrieval-Augmented Generation - RAG) are primarily leveraged for architectural decision support, reconstruction, and early Software Architecture Life Cycle tasks like Requirements-to-Architecture and Architecture-to-Code, targeting monolithic and microservice styles. Crucially, we uncover a significant research void: a pervasive lack of rigorous evaluation concerning GenAI outputs' impact on architectural quality attributes. Existing studies often neglect robust testing, architecture-specific datasets, and sound evaluation frameworks.\n\nThis paper provides an essential roadmap for future research, identifying urgent needs for general evaluation methodologies, ethical considerations, increased transparency, and dedicated architecture-specific benchmarks. Our findings aim to catalyze the development of rigorously validated and impactful GenAI applications, transforming how complex systems are designed and maintained.",
    "keywords": [
      "Generative AI in software architecture",
      "Multivocal Literature Review",
      "architectural decision support",
      "architectural reconstruction",
      "Retrieval-Augmented Generation (RAG)",
      "few-shot prompting",
      "lack of rigorous evaluation",
      "architecture-specific datasets",
      "GenAI hallucinations",
      "research gaps and challenges",
      "Software Architecture Life Cycle",
      "architectural quality attributes",
      "gray literature synthesis"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2c78517dff83433eba7d4e86bac84aacdfbb468c.pdf",
    "citation_key": "esposito20252vd",
    "metadata": {
      "title": "Generative AI for Software Architecture. Applications, Trends, Challenges, and Future Directions",
      "authors": [
        "Matteo Esposito",
        "Xiaozhou Li",
        "Sergio Moreschini",
        "Noman Ahmad",
        "Tomás Cerný",
        "Karthik Vaidhyanathan",
        "Valentina Lenarduzzi",
        "Davide Taibi"
      ],
      "published_date": "2025",
      "abstract": "Context: Generative Artificial Intelligence (GenAI) is transforming much of software development, yet its application in software architecture is still in its infancy, and no prior study has systematically addressed the topic. Aim: We aim to systematically synthesize the use, rationale, contexts, usability, and future challenges of GenAI in software architecture. Method: We performed a multivocal literature review (MLR), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, and reported challenges, extracting themes via open coding. Results: Our review identified significant adoption of GenAI for architectural decision support and architectural reconstruction. OpenAI GPT models are predominantly applied, and there is consistent use of techniques such as few-shot prompting and retrieved-augmented generation (RAG). GenAI has been applied mostly to initial stages of the Software Development Life Cycle (SDLC), such as Requirements-to-Architecture and Architecture-to-Code. Monolithic and microservice architectures were the dominant targets. However, rigorous testing of GenAI outputs was typically missing from the studies. Among the most frequent challenges are model precision, hallucinations, ethical aspects, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks. Conclusions: GenAI shows significant potential in software design, but several challenges remain on its path to greater adoption. Research efforts should target designing general evaluation methodologies, handling ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks to bridge the gap between theoretical possibilities and practical use.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2c78517dff83433eba7d4e86bac84aacdfbb468c.pdf",
      "venue": "Journal of Systems and Software",
      "citationCount": 5,
      "score": 5.0,
      "summary": "Here's a focused summary of the paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the nascent and underexplored application of Generative AI (GenAI) in software architecture, despite its transformative potential in other software engineering (SE) domains \\cite{esposito20252vd}.\n    *   This problem is critical because GenAI could revolutionize how complex systems are designed, optimized, and maintained, yet practitioners and researchers lack a clear understanding of its implications, limitations, and benefits for architectural tasks \\cite{esposito20252vd}.\n    *   Challenges include inconsistent findings on GenAI's reliability for architectural decisions, a lack of systematic evidence, unclear best practices, and open issues like security vulnerabilities, biases, and ethical implications \\cite{esposito20252vd}.\n\n*   **Related Work & Positioning**\n    *   Existing literature reviews on Large Language Models (LLMs) in SE primarily focus on code generation, testing, and requirements engineering, with limited attention to software design and architecture \\cite{esposito20252vd}.\n    *   While some studies explore AI/LLMs for specific architectural tasks (e.g., microservice recommendation, pattern suggestion, AI-architecture integration), a comprehensive, multivocal review specifically on GenAI for software architecture, synthesizing both academic and gray literature, was missing \\cite{esposito20252vd}.\n    *   This work positions itself to fill this gap by providing a holistic synthesis that bridges academic research and industry practice \\cite{esposito20252vd}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is a Multivocal Literature Review (MLR), systematically analyzing both peer-reviewed academic papers and gray literature (e.g., industry reports, blog posts, technical documentation) \\cite{esposito20252vd}.\n    *   The approach is novel in its comprehensive scope, specifically targeting GenAI in software architecture, and its inclusion of gray literature, which is crucial for understanding an emerging field where industry adoption often precedes formal academic publication \\cite{esposito20252vd}.\n    *   Themes, practices, models, adoption contexts, and challenges were extracted using open coding \\cite{esposito20252vd}.\n\n*   **Key Technical Contributions**\n    *   A comprehensive synthesis of how GenAI is currently used in software architecture, including underlying rationales, models, and usage approaches \\cite{esposito20252vd}.\n    *   Classification of the GenAI models predominantly adopted (e.g., OpenAI GPT models) and common techniques (e.g., few-shot prompting, Retrieval-Augmented Generation - RAG) \\cite{esposito20252vd}.\n    *   Identification of common applications (e.g., architectural decision support, architectural reconstruction, Requirements-to-Architecture, Architecture-to-Code) and targeted architectural styles (monolithic, microservices) \\cite{esposito20252vd}.\n    *   Highlighting critical research gaps and open challenges, such as the lack of rigorous evaluation, architecture-specific datasets, and sound evaluation frameworks \\cite{esposito20252vd}.\n\n*   **Experimental Validation**\n    *   As a literature review, the paper does not conduct new experiments but synthesizes findings from existing studies.\n    *   **Key findings from the reviewed literature**: GenAI is significantly adopted for architectural decision support and reconstruction \\cite{esposito20252vd}. OpenAI GPT models are prevalent, often used with few-shot prompting and RAG \\cite{esposito20252vd}. Applications are concentrated in early Software Architecture Life Cycle (SALC) stages (Requirements-to-Architecture, Architecture-to-Code) and target monolithic/microservice architectures \\cite{esposito20252vd}.\n    *   **Crucially, the review found**: \"rigorous testing of GenAI outputs was typically missing from the studies\" \\cite{esposito20252vd}. Most evaluations focused on usability or accuracy, with few addressing the impact on architectural quality attributes (e.g., modifiability, scalability, maintainability), indicating an absence of rigorous evaluation in the primary studies \\cite{esposito20252vd}.\n\n*   **Limitations & Scope**\n    *   **Limitations identified in the reviewed literature**: Frequent challenges include model precision, hallucinations, ethical concerns, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks \\cite{esposito20252vd}.\n    *   GenAI's integration into complex, high-stakes architectural decision-making remains limited, with prevailing utilization oriented towards documentation and code generation rather than system-level reasoning, trade-off analysis, or performance modeling \\cite{esposito20252vd}.\n    *   The scope covers GenAI applications in software architecture across various SALC phases, architectural styles, and tasks, drawing from both academic and industry sources \\cite{esposito20252vd}.\n\n*   **Technical Significance**\n    *   This paper significantly advances the technical state-of-the-art by providing the first comprehensive, multivocal synthesis of GenAI in software architecture, mapping the current landscape and identifying key trends and challenges \\cite{esposito20252vd}.\n    *   It offers a critical roadmap for future research, emphasizing the urgent need for general evaluation methodologies, addressing ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks \\cite{esposito20252vd}.\n    *   The findings are expected to catalyze future research by guiding efforts towards impactful areas that can bridge the gap between theoretical possibilities and practical, rigorously validated applications of GenAI in software architecture \\cite{esposito20252vd}.",
      "keywords": [
        "Generative AI in software architecture",
        "Multivocal Literature Review",
        "architectural decision support",
        "architectural reconstruction",
        "Retrieval-Augmented Generation (RAG)",
        "few-shot prompting",
        "lack of rigorous evaluation",
        "architecture-specific datasets",
        "GenAI hallucinations",
        "research gaps and challenges",
        "Software Architecture Life Cycle",
        "architectural quality attributes",
        "gray literature synthesis"
      ],
      "paper_type": "based on the abstract and introduction, this paper is a **survey**.\n\nhere's why:\n\n*   **abstract:**\n    *   **aim:** \"systematically synthesize the use, rationale, contexts, usability, and future challenges of genai in software architecture.\" - \"systematically synthesize\" is a key indicator of a review.\n    *   **method:** \"multivocal literature review (mlr), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, reported challenges, and extracting themes via open coding.\" - explicitly states it's a literature review.\n    *   **results:** \"this review identifies a significant adoption...\", \"rigorous testing of genai outputs was typically missing from the studies.\" - the results are findings *from the literature review*, not from new experiments or proposed methods.\n    *   **keywords:** \"multivocal literature review\" is listed as a keyword.\n*   **introduction:** discusses the emerging nature of genai in software architecture and the need to understand its effectiveness, reliability, and best practices, setting the stage for a comprehensive review of the existing landscape.\n\nthese points directly match the criteria for a **survey** paper: \"reviews existing literature comprehensively\" and mentions \"survey\", \"review\", \"comprehensive analysis\", \"state-of-the-art\" (implied by synthesizing current practices and challenges)."
    },
    "file_name": "2c78517dff83433eba7d4e86bac84aacdfbb468c.pdf"
  },
  {
    "success": true,
    "doc_id": "1102e94070426b1f467f0b8b88f4164a",
    "summary": "Given the prominence of AI planning in research and industry, the development of AI planning software and its integration into production architectures are becoming important. However, building and managing planning software is a complex and expertise-dependent process without methodological support that would ensure AI planning applications have high quality and industrial strength. To that end, we propose a lifecycle for developing AI planning systems that consists of ten phases related to the design, development, and operation of planning systems.",
    "intriguing_abstract": "Given the prominence of AI planning in research and industry, the development of AI planning software and its integration into production architectures are becoming important. However, building and managing planning software is a complex and expertise-dependent process without methodological support that would ensure AI planning applications have high quality and industrial strength. To that end, we propose a lifecycle for developing AI planning systems that consists of ten phases related to the design, development, and operation of planning systems.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8b3656797734af7a880d18167bb509c02432192e.pdf",
    "citation_key": "georgievski2023ea1",
    "metadata": {
      "title": "Conceptualising Software Development Lifecycle for Engineering AI Planning Systems",
      "authors": [
        "Ilche Georgievski"
      ],
      "published_date": "2023",
      "abstract": "Given the prominence of AI planning in research and industry, the development of AI planning software and its integration into production architectures are becoming important. However, building and managing planning software is a complex and expertise-dependent process without methodological support that would ensure AI planning applications have high quality and industrial strength. To that end, we propose a lifecycle for developing AI planning systems that consists of ten phases related to the design, development, and operation of planning systems.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8b3656797734af7a880d18167bb509c02432192e.pdf",
      "venue": "2023 IEEE/ACM 2nd International Conference on AI Engineering – Software Engineering for AI (CAIN)",
      "citationCount": 10,
      "score": 5.0,
      "summary": "Given the prominence of AI planning in research and industry, the development of AI planning software and its integration into production architectures are becoming important. However, building and managing planning software is a complex and expertise-dependent process without methodological support that would ensure AI planning applications have high quality and industrial strength. To that end, we propose a lifecycle for developing AI planning systems that consists of ten phases related to the design, development, and operation of planning systems.",
      "keywords": []
    },
    "file_name": "8b3656797734af7a880d18167bb509c02432192e.pdf"
  },
  {
    "success": true,
    "doc_id": "2d753d76a9447373e3dbf3a2ec444922",
    "summary": "Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.",
    "intriguing_abstract": "Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/5a1814b310b0e242985d7768998549b202e974ea.pdf",
    "citation_key": "benario2025f7h",
    "metadata": {
      "title": "Unlocking Potential with Generative AI Instruction: Investigating Mid-level Software Development Student Perceptions, Behavior, and Adoption",
      "authors": [
        "Jamie Gorson Benario",
        "Jenn Marroquin",
        "Monica M. Chan",
        "Ernest D.V. Holmes",
        "Daniel Mejia"
      ],
      "published_date": "2025",
      "abstract": "Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/5a1814b310b0e242985d7768998549b202e974ea.pdf",
      "venue": "Technical Symposium on Computer Science Education",
      "citationCount": 5,
      "score": 5.0,
      "summary": "Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.",
      "keywords": []
    },
    "file_name": "5a1814b310b0e242985d7768998549b202e974ea.pdf"
  },
  {
    "success": true,
    "doc_id": "8a672c4cb308d2260eb662779de37a58",
    "summary": "Abstract: This paper explores the benefits, challenges, and real-world applications of automated test-case generation and bug identification using generative artificial intelligence (AI). In today's software development and testing landscape, ensuring code quality and minimizing bugs are crucial. However, manual testing methods can be time-consuming and error-prone. Generative AI algorithms, such as generative models, can automatically generate test cases based on inputs, specifications, or system behavior. These algorithms employ machine learning techniques to analyze codebases, uncover test scenarios, and produce comprehensive test cases with broad coverage. The advantages of automated test-case generation include amplified test coverage, supercharged efficiency and time savings, and seamless scalability. Generative AI models also excel in bug identification by scrutinizing codebases, execution traces, and test results. They can detect coding mistakes and identify anomalous patterns indicating potential bugs, memory leaks, or security vulnerabilities. However, challenges such as data quality and bias, domain specificity, and the need for human expertise must be addressed. Real-world applications of automated test-case generation and bug identification using generative AI include software development and security testing. By leveraging generative AI, organizations can enhance test coverage, improve efficiency, and ensure the quality of software products. To successfully implement this approach, challenges related to data quality, domain specificity, and human expertise must be navigated. Generative AI has the potential to revolutionize software testing and contribute to the development of robust and reliable systems in the complex digital landscape.",
    "intriguing_abstract": "Abstract: This paper explores the benefits, challenges, and real-world applications of automated test-case generation and bug identification using generative artificial intelligence (AI). In today's software development and testing landscape, ensuring code quality and minimizing bugs are crucial. However, manual testing methods can be time-consuming and error-prone. Generative AI algorithms, such as generative models, can automatically generate test cases based on inputs, specifications, or system behavior. These algorithms employ machine learning techniques to analyze codebases, uncover test scenarios, and produce comprehensive test cases with broad coverage. The advantages of automated test-case generation include amplified test coverage, supercharged efficiency and time savings, and seamless scalability. Generative AI models also excel in bug identification by scrutinizing codebases, execution traces, and test results. They can detect coding mistakes and identify anomalous patterns indicating potential bugs, memory leaks, or security vulnerabilities. However, challenges such as data quality and bias, domain specificity, and the need for human expertise must be addressed. Real-world applications of automated test-case generation and bug identification using generative AI include software development and security testing. By leveraging generative AI, organizations can enhance test coverage, improve efficiency, and ensure the quality of software products. To successfully implement this approach, challenges related to data quality, domain specificity, and human expertise must be navigated. Generative AI has the potential to revolutionize software testing and contribute to the development of robust and reliable systems in the complex digital landscape.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2d947740b3e6a4ffd71190e8c4c287f24b3279c5.pdf",
    "citation_key": "bajaj2023psw",
    "metadata": {
      "title": "Accelerating Software Quality: Unleashing the Power of Generative AI for Automated Test-Case Generation and Bug Identification",
      "authors": [
        "Yatin Bajaj",
        "Manoj Samal"
      ],
      "published_date": "2023",
      "abstract": "Abstract: This paper explores the benefits, challenges, and real-world applications of automated test-case generation and bug identification using generative artificial intelligence (AI). In today's software development and testing landscape, ensuring code quality and minimizing bugs are crucial. However, manual testing methods can be time-consuming and error-prone. Generative AI algorithms, such as generative models, can automatically generate test cases based on inputs, specifications, or system behavior. These algorithms employ machine learning techniques to analyze codebases, uncover test scenarios, and produce comprehensive test cases with broad coverage. The advantages of automated test-case generation include amplified test coverage, supercharged efficiency and time savings, and seamless scalability. Generative AI models also excel in bug identification by scrutinizing codebases, execution traces, and test results. They can detect coding mistakes and identify anomalous patterns indicating potential bugs, memory leaks, or security vulnerabilities. However, challenges such as data quality and bias, domain specificity, and the need for human expertise must be addressed. Real-world applications of automated test-case generation and bug identification using generative AI include software development and security testing. By leveraging generative AI, organizations can enhance test coverage, improve efficiency, and ensure the quality of software products. To successfully implement this approach, challenges related to data quality, domain specificity, and human expertise must be navigated. Generative AI has the potential to revolutionize software testing and contribute to the development of robust and reliable systems in the complex digital landscape.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2d947740b3e6a4ffd71190e8c4c287f24b3279c5.pdf",
      "venue": "International Journal for Research in Applied Science and Engineering Technology",
      "citationCount": 10,
      "score": 5.0,
      "summary": "Abstract: This paper explores the benefits, challenges, and real-world applications of automated test-case generation and bug identification using generative artificial intelligence (AI). In today's software development and testing landscape, ensuring code quality and minimizing bugs are crucial. However, manual testing methods can be time-consuming and error-prone. Generative AI algorithms, such as generative models, can automatically generate test cases based on inputs, specifications, or system behavior. These algorithms employ machine learning techniques to analyze codebases, uncover test scenarios, and produce comprehensive test cases with broad coverage. The advantages of automated test-case generation include amplified test coverage, supercharged efficiency and time savings, and seamless scalability. Generative AI models also excel in bug identification by scrutinizing codebases, execution traces, and test results. They can detect coding mistakes and identify anomalous patterns indicating potential bugs, memory leaks, or security vulnerabilities. However, challenges such as data quality and bias, domain specificity, and the need for human expertise must be addressed. Real-world applications of automated test-case generation and bug identification using generative AI include software development and security testing. By leveraging generative AI, organizations can enhance test coverage, improve efficiency, and ensure the quality of software products. To successfully implement this approach, challenges related to data quality, domain specificity, and human expertise must be navigated. Generative AI has the potential to revolutionize software testing and contribute to the development of robust and reliable systems in the complex digital landscape.",
      "keywords": []
    },
    "file_name": "2d947740b3e6a4ffd71190e8c4c287f24b3279c5.pdf"
  },
  {
    "success": true,
    "doc_id": "2b761d8116ea9b6802904bc590a5ef72",
    "summary": "Software development processes are continuously evolving and rapidly transforming alongside the rapid changes in technology. Recently, innovations in the field of Artificial Intelligence (AI) have led to significant changes in software development practices. AI tools can greatly enhance traditional software development processes by offering developers the ability to create projects more intelligently, swiftly, and effectively. These tools can be employed in various tasks, such as code generation, test automation, error analysis, and performance improvements. Particularly, ChatGPT, an AI-based language model that has had a profound impact on almost every domain, can assist software developers in writing code faster and in a more natural language manner. In this research article, essential information about the usage of ChatGPT in the software development process is presented. To evaluate some capabilities of ChatGPT in the software development context, applications were performed on a software project. For this purpose, a software development process was constructed based on the responses provided by ChatGPT. Various questions related to software development processes were formulated, and the responses generated by GPT were evaluated. The obtained results indicated that ChatGPT exhibited excellent performance in the software development process. Based on these findings, it was observed that AI-based models like ChatGPT could be effectively utilized as assisting tools in software development processes, accelerating traditional workflows. Furthermore, AI-based tools can automate testing processes, enhancing software quality while saving time and effort.",
    "intriguing_abstract": "Software development processes are continuously evolving and rapidly transforming alongside the rapid changes in technology. Recently, innovations in the field of Artificial Intelligence (AI) have led to significant changes in software development practices. AI tools can greatly enhance traditional software development processes by offering developers the ability to create projects more intelligently, swiftly, and effectively. These tools can be employed in various tasks, such as code generation, test automation, error analysis, and performance improvements. Particularly, ChatGPT, an AI-based language model that has had a profound impact on almost every domain, can assist software developers in writing code faster and in a more natural language manner. In this research article, essential information about the usage of ChatGPT in the software development process is presented. To evaluate some capabilities of ChatGPT in the software development context, applications were performed on a software project. For this purpose, a software development process was constructed based on the responses provided by ChatGPT. Various questions related to software development processes were formulated, and the responses generated by GPT were evaluated. The obtained results indicated that ChatGPT exhibited excellent performance in the software development process. Based on these findings, it was observed that AI-based models like ChatGPT could be effectively utilized as assisting tools in software development processes, accelerating traditional workflows. Furthermore, AI-based tools can automate testing processes, enhancing software quality while saving time and effort.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/afeffa90eff2ea16f583e936583c0790acf30fd4.pdf",
    "citation_key": "zpolat20239za",
    "metadata": {
      "title": "Artificial Intelligence-Based Tools in Software Development Processes: Application of ChatGPT",
      "authors": [
        "Z. Özpolat",
        "Özal Yıldırım",
        "M. Karabatak"
      ],
      "published_date": "2023",
      "abstract": "Software development processes are continuously evolving and rapidly transforming alongside the rapid changes in technology. Recently, innovations in the field of Artificial Intelligence (AI) have led to significant changes in software development practices. AI tools can greatly enhance traditional software development processes by offering developers the ability to create projects more intelligently, swiftly, and effectively. These tools can be employed in various tasks, such as code generation, test automation, error analysis, and performance improvements. Particularly, ChatGPT, an AI-based language model that has had a profound impact on almost every domain, can assist software developers in writing code faster and in a more natural language manner. In this research article, essential information about the usage of ChatGPT in the software development process is presented. To evaluate some capabilities of ChatGPT in the software development context, applications were performed on a software project. For this purpose, a software development process was constructed based on the responses provided by ChatGPT. Various questions related to software development processes were formulated, and the responses generated by GPT were evaluated. The obtained results indicated that ChatGPT exhibited excellent performance in the software development process. Based on these findings, it was observed that AI-based models like ChatGPT could be effectively utilized as assisting tools in software development processes, accelerating traditional workflows. Furthermore, AI-based tools can automate testing processes, enhancing software quality while saving time and effort.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/afeffa90eff2ea16f583e936583c0790acf30fd4.pdf",
      "venue": "European Journal of Technic",
      "citationCount": 10,
      "score": 5.0,
      "summary": "Software development processes are continuously evolving and rapidly transforming alongside the rapid changes in technology. Recently, innovations in the field of Artificial Intelligence (AI) have led to significant changes in software development practices. AI tools can greatly enhance traditional software development processes by offering developers the ability to create projects more intelligently, swiftly, and effectively. These tools can be employed in various tasks, such as code generation, test automation, error analysis, and performance improvements. Particularly, ChatGPT, an AI-based language model that has had a profound impact on almost every domain, can assist software developers in writing code faster and in a more natural language manner. In this research article, essential information about the usage of ChatGPT in the software development process is presented. To evaluate some capabilities of ChatGPT in the software development context, applications were performed on a software project. For this purpose, a software development process was constructed based on the responses provided by ChatGPT. Various questions related to software development processes were formulated, and the responses generated by GPT were evaluated. The obtained results indicated that ChatGPT exhibited excellent performance in the software development process. Based on these findings, it was observed that AI-based models like ChatGPT could be effectively utilized as assisting tools in software development processes, accelerating traditional workflows. Furthermore, AI-based tools can automate testing processes, enhancing software quality while saving time and effort.",
      "keywords": []
    },
    "file_name": "afeffa90eff2ea16f583e936583c0790acf30fd4.pdf"
  },
  {
    "success": true,
    "doc_id": "cb5cc8b620a2becd38beb5e27faec5fd",
    "summary": "The landscape of software development has seen a massive shift in the last few years, with rising use of data-driven methods for making product decisions. One area that has made a significant difference is the integration of machine learning and artificial intelligence technologies to inform software engineering practice, including prioritization of product features. Software product feature prioritization is an essential process directly influencing the competitiveness and success of a product. Traditional techniques, though fundamental, tend to fall short in resolving the intricacies of contemporary software ecosystems. This study delves into the revolutionary potential of machine learning (ML) and artificial intelligence (AI) for improving feature prioritization. An extensive literature survey identifies existing trends and their drawbacks, such as inadequate integrated frameworks and scalability and interpretability issues. The suggested framework integrates heterogeneous sources of data, predictive analytics, natural language processing (NLP), and optimization algorithms to support real-time data-driven decision-making.",
    "intriguing_abstract": "The landscape of software development has seen a massive shift in the last few years, with rising use of data-driven methods for making product decisions. One area that has made a significant difference is the integration of machine learning and artificial intelligence technologies to inform software engineering practice, including prioritization of product features. Software product feature prioritization is an essential process directly influencing the competitiveness and success of a product. Traditional techniques, though fundamental, tend to fall short in resolving the intricacies of contemporary software ecosystems. This study delves into the revolutionary potential of machine learning (ML) and artificial intelligence (AI) for improving feature prioritization. An extensive literature survey identifies existing trends and their drawbacks, such as inadequate integrated frameworks and scalability and interpretability issues. The suggested framework integrates heterogeneous sources of data, predictive analytics, natural language processing (NLP), and optimization algorithms to support real-time data-driven decision-making.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6201db387d7f66f4227a5bbd0a6c0efa9ad8d8a1.pdf",
    "citation_key": "raj2025ynu",
    "metadata": {
      "title": "AI and ML Powered Feature Prioritization in Software Product Development",
      "authors": [
        "Akhil Raj",
        "Ridhi Deora"
      ],
      "published_date": "2025",
      "abstract": "The landscape of software development has seen a massive shift in the last few years, with rising use of data-driven methods for making product decisions. One area that has made a significant difference is the integration of machine learning and artificial intelligence technologies to inform software engineering practice, including prioritization of product features. Software product feature prioritization is an essential process directly influencing the competitiveness and success of a product. Traditional techniques, though fundamental, tend to fall short in resolving the intricacies of contemporary software ecosystems. This study delves into the revolutionary potential of machine learning (ML) and artificial intelligence (AI) for improving feature prioritization. An extensive literature survey identifies existing trends and their drawbacks, such as inadequate integrated frameworks and scalability and interpretability issues. The suggested framework integrates heterogeneous sources of data, predictive analytics, natural language processing (NLP), and optimization algorithms to support real-time data-driven decision-making.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6201db387d7f66f4227a5bbd0a6c0efa9ad8d8a1.pdf",
      "venue": "International Journal of Data Mining &amp; Knowledge Management Process",
      "citationCount": 5,
      "score": 5.0,
      "summary": "The landscape of software development has seen a massive shift in the last few years, with rising use of data-driven methods for making product decisions. One area that has made a significant difference is the integration of machine learning and artificial intelligence technologies to inform software engineering practice, including prioritization of product features. Software product feature prioritization is an essential process directly influencing the competitiveness and success of a product. Traditional techniques, though fundamental, tend to fall short in resolving the intricacies of contemporary software ecosystems. This study delves into the revolutionary potential of machine learning (ML) and artificial intelligence (AI) for improving feature prioritization. An extensive literature survey identifies existing trends and their drawbacks, such as inadequate integrated frameworks and scalability and interpretability issues. The suggested framework integrates heterogeneous sources of data, predictive analytics, natural language processing (NLP), and optimization algorithms to support real-time data-driven decision-making.",
      "keywords": []
    },
    "file_name": "6201db387d7f66f4227a5bbd0a6c0efa9ad8d8a1.pdf"
  },
  {
    "success": true,
    "doc_id": "36d462bdfd5bf4584e29d8cad4f4ad36",
    "summary": "Over a period of just about 5 years, the use of AI-based tools for software engineering has gone from being a very promising research investigation to indispensable features in modern developer environments. This talk will present AI-powered improvements and continuing transformation of Google’s internal software development. This viewpoint comes from extensive experience with developing and deploying AI-based tools to surfaces where Google engineers spend the majority of their time, including inner loop activities such as code authoring, review and search, as well as outer loop ones such as bug management and planning. Improvements in these surfaces are monitored carefully for productivity and developer satisfaction. We will describe the challenges in how to align our internal efforts with the very fast moving field of LLMs. We need to constantly make judgment calls on technical feasibility, the possibility of iterative improvement and the measurability of impact as we decide what ideas to pursue for production level adaptation and adoption. The talk will go into several examples of this that we have gone through in recent past, and what we have learned in the process. We will conclude the talk with changes that we expect to land in the next five years and some thoughts on how the community can collaborate better by focusing on good benchmarks.",
    "intriguing_abstract": "Over a period of just about 5 years, the use of AI-based tools for software engineering has gone from being a very promising research investigation to indispensable features in modern developer environments. This talk will present AI-powered improvements and continuing transformation of Google’s internal software development. This viewpoint comes from extensive experience with developing and deploying AI-based tools to surfaces where Google engineers spend the majority of their time, including inner loop activities such as code authoring, review and search, as well as outer loop ones such as bug management and planning. Improvements in these surfaces are monitored carefully for productivity and developer satisfaction. We will describe the challenges in how to align our internal efforts with the very fast moving field of LLMs. We need to constantly make judgment calls on technical feasibility, the possibility of iterative improvement and the measurability of impact as we decide what ideas to pursue for production level adaptation and adoption. The talk will go into several examples of this that we have gone through in recent past, and what we have learned in the process. We will conclude the talk with changes that we expect to land in the next five years and some thoughts on how the community can collaborate better by focusing on good benchmarks.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/eaf6427e86010f8de476f48372fba8520de40b11.pdf",
    "citation_key": "chandra2024b2j",
    "metadata": {
      "title": "AI in Software Engineering at Google: Progress and the Path Ahead (Invited Talk)",
      "authors": [
        "Satish Chandra"
      ],
      "published_date": "2024",
      "abstract": "Over a period of just about 5 years, the use of AI-based tools for software engineering has gone from being a very promising research investigation to indispensable features in modern developer environments. This talk will present AI-powered improvements and continuing transformation of Google’s internal software development. This viewpoint comes from extensive experience with developing and deploying AI-based tools to surfaces where Google engineers spend the majority of their time, including inner loop activities such as code authoring, review and search, as well as outer loop ones such as bug management and planning. Improvements in these surfaces are monitored carefully for productivity and developer satisfaction. We will describe the challenges in how to align our internal efforts with the very fast moving field of LLMs. We need to constantly make judgment calls on technical feasibility, the possibility of iterative improvement and the measurability of impact as we decide what ideas to pursue for production level adaptation and adoption. The talk will go into several examples of this that we have gone through in recent past, and what we have learned in the process. We will conclude the talk with changes that we expect to land in the next five years and some thoughts on how the community can collaborate better by focusing on good benchmarks.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/eaf6427e86010f8de476f48372fba8520de40b11.pdf",
      "venue": "AIware",
      "citationCount": 5,
      "score": 5.0,
      "summary": "Over a period of just about 5 years, the use of AI-based tools for software engineering has gone from being a very promising research investigation to indispensable features in modern developer environments. This talk will present AI-powered improvements and continuing transformation of Google’s internal software development. This viewpoint comes from extensive experience with developing and deploying AI-based tools to surfaces where Google engineers spend the majority of their time, including inner loop activities such as code authoring, review and search, as well as outer loop ones such as bug management and planning. Improvements in these surfaces are monitored carefully for productivity and developer satisfaction. We will describe the challenges in how to align our internal efforts with the very fast moving field of LLMs. We need to constantly make judgment calls on technical feasibility, the possibility of iterative improvement and the measurability of impact as we decide what ideas to pursue for production level adaptation and adoption. The talk will go into several examples of this that we have gone through in recent past, and what we have learned in the process. We will conclude the talk with changes that we expect to land in the next five years and some thoughts on how the community can collaborate better by focusing on good benchmarks.",
      "keywords": []
    },
    "file_name": "eaf6427e86010f8de476f48372fba8520de40b11.pdf"
  },
  {
    "success": true,
    "doc_id": "bc5b385665ee36dc976e1bff8193bed9",
    "summary": "Ensuring fairness in software systems has become a critical concern in software engineering. Motivated by this challenge, this article explores the multifaceted nature of bias in software systems, providing a comprehensive understanding of its origins, manifestations, and impacts. Through a scoping study, we identified the primary causes of fairness deficiencies in software development and highlighted their adverse effects on individuals and communities, including instances of discrimination and the perpetuation of inequalities. Our investigation culminated in the introduction of the concept of software fairness debt. In addition to defining fairness debt, we propose a socio-technical roadmap that addresses broader aspects of fairness in AI-driven systems. This roadmap is structured around six goals: bridging the gap between research and real-world applications, developing a framework for fairness debt, equipping practitioners with tools and knowledge, improving bias mitigation, integrating fairness tools into industry practice, and enhancing explainability and transparency in AI systems. This roadmap provides a holistic approach to managing biases in software systems through software fairness debt, offering actionable steps for both research and practice. By guiding researchers and practitioners, our roadmap aims to foster the development of more equitable and socially responsible software systems, ensuring fairness is embedded throughout the software lifecycle.",
    "intriguing_abstract": "Ensuring fairness in software systems has become a critical concern in software engineering. Motivated by this challenge, this article explores the multifaceted nature of bias in software systems, providing a comprehensive understanding of its origins, manifestations, and impacts. Through a scoping study, we identified the primary causes of fairness deficiencies in software development and highlighted their adverse effects on individuals and communities, including instances of discrimination and the perpetuation of inequalities. Our investigation culminated in the introduction of the concept of software fairness debt. In addition to defining fairness debt, we propose a socio-technical roadmap that addresses broader aspects of fairness in AI-driven systems. This roadmap is structured around six goals: bridging the gap between research and real-world applications, developing a framework for fairness debt, equipping practitioners with tools and knowledge, improving bias mitigation, integrating fairness tools into industry practice, and enhancing explainability and transparency in AI systems. This roadmap provides a holistic approach to managing biases in software systems through software fairness debt, offering actionable steps for both research and practice. By guiding researchers and practitioners, our roadmap aims to foster the development of more equitable and socially responsible software systems, ensuring fairness is embedded throughout the software lifecycle.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/572863f85c3debd1a0787dcba3fb3b0dd03faf66.pdf",
    "citation_key": "santos2024znt",
    "metadata": {
      "title": "Software Fairness Debt: Building a Research Agenda for Addressing Bias in AI Systems",
      "authors": [
        "Ronnie de Souza Santos",
        "Felipe Fronchetti",
        "Sávio Freire",
        "Rodrigo O. Spínola"
      ],
      "published_date": "2024",
      "abstract": "Ensuring fairness in software systems has become a critical concern in software engineering. Motivated by this challenge, this article explores the multifaceted nature of bias in software systems, providing a comprehensive understanding of its origins, manifestations, and impacts. Through a scoping study, we identified the primary causes of fairness deficiencies in software development and highlighted their adverse effects on individuals and communities, including instances of discrimination and the perpetuation of inequalities. Our investigation culminated in the introduction of the concept of software fairness debt. In addition to defining fairness debt, we propose a socio-technical roadmap that addresses broader aspects of fairness in AI-driven systems. This roadmap is structured around six goals: bridging the gap between research and real-world applications, developing a framework for fairness debt, equipping practitioners with tools and knowledge, improving bias mitigation, integrating fairness tools into industry practice, and enhancing explainability and transparency in AI systems. This roadmap provides a holistic approach to managing biases in software systems through software fairness debt, offering actionable steps for both research and practice. By guiding researchers and practitioners, our roadmap aims to foster the development of more equitable and socially responsible software systems, ensuring fairness is embedded throughout the software lifecycle.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/572863f85c3debd1a0787dcba3fb3b0dd03faf66.pdf",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "citationCount": 5,
      "score": 5.0,
      "summary": "Ensuring fairness in software systems has become a critical concern in software engineering. Motivated by this challenge, this article explores the multifaceted nature of bias in software systems, providing a comprehensive understanding of its origins, manifestations, and impacts. Through a scoping study, we identified the primary causes of fairness deficiencies in software development and highlighted their adverse effects on individuals and communities, including instances of discrimination and the perpetuation of inequalities. Our investigation culminated in the introduction of the concept of software fairness debt. In addition to defining fairness debt, we propose a socio-technical roadmap that addresses broader aspects of fairness in AI-driven systems. This roadmap is structured around six goals: bridging the gap between research and real-world applications, developing a framework for fairness debt, equipping practitioners with tools and knowledge, improving bias mitigation, integrating fairness tools into industry practice, and enhancing explainability and transparency in AI systems. This roadmap provides a holistic approach to managing biases in software systems through software fairness debt, offering actionable steps for both research and practice. By guiding researchers and practitioners, our roadmap aims to foster the development of more equitable and socially responsible software systems, ensuring fairness is embedded throughout the software lifecycle.",
      "keywords": []
    },
    "file_name": "572863f85c3debd1a0787dcba3fb3b0dd03faf66.pdf"
  },
  {
    "success": true,
    "doc_id": "72ef64e7dd108e488dee843bf2082919",
    "summary": "Context: Generative AI (GenAI) brings new op-portunities to the software industry and the digital economy in a broader context. Objective: This study aimed to explore and capture the practitioners' perception of GenAI adoption in the fast-paced software industry in the context of developing countries. Method: We conducted online focus group discussions with 18 practitioners from various roles to collect qualitative data. The practitioners have an average of 7.8 years of working experience and have used GenAI for over a year. We employed thematic analysis and the Human-AI Collaboration and Adaptation Framework (HACAF) to identify the influencing factors of GenAI adoption, such as awareness, use cases, and challenges. Results: The adoption of GenAI technology is evident from practitioners. We identified 22 practical use cases, three of which were novel, i.e., contextualizing solutions, assisting the internal audit process, and benchmarking the internal software development process. We also discovered seven key challenges associated with the GenAI adoption, two of which were novel, namely, no matching use cases and unforeseen benefits. These challenges slow GenAI adoption and potentially hinder developing countries from entering a high-skill industry. Conclusion: While the adoption of GenAI technology is promising, industry-academia collaboration is needed to find solutions and strategies to address the challenges and maximize its potential benefits.",
    "intriguing_abstract": "Context: Generative AI (GenAI) brings new op-portunities to the software industry and the digital economy in a broader context. Objective: This study aimed to explore and capture the practitioners' perception of GenAI adoption in the fast-paced software industry in the context of developing countries. Method: We conducted online focus group discussions with 18 practitioners from various roles to collect qualitative data. The practitioners have an average of 7.8 years of working experience and have used GenAI for over a year. We employed thematic analysis and the Human-AI Collaboration and Adaptation Framework (HACAF) to identify the influencing factors of GenAI adoption, such as awareness, use cases, and challenges. Results: The adoption of GenAI technology is evident from practitioners. We identified 22 practical use cases, three of which were novel, i.e., contextualizing solutions, assisting the internal audit process, and benchmarking the internal software development process. We also discovered seven key challenges associated with the GenAI adoption, two of which were novel, namely, no matching use cases and unforeseen benefits. These challenges slow GenAI adoption and potentially hinder developing countries from entering a high-skill industry. Conclusion: While the adoption of GenAI technology is promising, industry-academia collaboration is needed to find solutions and strategies to address the challenges and maximize its potential benefits.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6d9e6a495b4f1a5a6c8fbba98a6495bb1964d16f.pdf",
    "citation_key": "simaremare2024avv",
    "metadata": {
      "title": "The State of Generative AI Adoption from Software Practitioners' Perspective: An Empirical Study",
      "authors": [
        "Mario E. S. Simaremare",
        "Henry Edison"
      ],
      "published_date": "2024",
      "abstract": "Context: Generative AI (GenAI) brings new op-portunities to the software industry and the digital economy in a broader context. Objective: This study aimed to explore and capture the practitioners' perception of GenAI adoption in the fast-paced software industry in the context of developing countries. Method: We conducted online focus group discussions with 18 practitioners from various roles to collect qualitative data. The practitioners have an average of 7.8 years of working experience and have used GenAI for over a year. We employed thematic analysis and the Human-AI Collaboration and Adaptation Framework (HACAF) to identify the influencing factors of GenAI adoption, such as awareness, use cases, and challenges. Results: The adoption of GenAI technology is evident from practitioners. We identified 22 practical use cases, three of which were novel, i.e., contextualizing solutions, assisting the internal audit process, and benchmarking the internal software development process. We also discovered seven key challenges associated with the GenAI adoption, two of which were novel, namely, no matching use cases and unforeseen benefits. These challenges slow GenAI adoption and potentially hinder developing countries from entering a high-skill industry. Conclusion: While the adoption of GenAI technology is promising, industry-academia collaboration is needed to find solutions and strategies to address the challenges and maximize its potential benefits.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6d9e6a495b4f1a5a6c8fbba98a6495bb1964d16f.pdf",
      "venue": "EUROMICRO Conference on Software Engineering and Advanced Applications",
      "citationCount": 5,
      "score": 5.0,
      "summary": "Context: Generative AI (GenAI) brings new op-portunities to the software industry and the digital economy in a broader context. Objective: This study aimed to explore and capture the practitioners' perception of GenAI adoption in the fast-paced software industry in the context of developing countries. Method: We conducted online focus group discussions with 18 practitioners from various roles to collect qualitative data. The practitioners have an average of 7.8 years of working experience and have used GenAI for over a year. We employed thematic analysis and the Human-AI Collaboration and Adaptation Framework (HACAF) to identify the influencing factors of GenAI adoption, such as awareness, use cases, and challenges. Results: The adoption of GenAI technology is evident from practitioners. We identified 22 practical use cases, three of which were novel, i.e., contextualizing solutions, assisting the internal audit process, and benchmarking the internal software development process. We also discovered seven key challenges associated with the GenAI adoption, two of which were novel, namely, no matching use cases and unforeseen benefits. These challenges slow GenAI adoption and potentially hinder developing countries from entering a high-skill industry. Conclusion: While the adoption of GenAI technology is promising, industry-academia collaboration is needed to find solutions and strategies to address the challenges and maximize its potential benefits.",
      "keywords": []
    },
    "file_name": "6d9e6a495b4f1a5a6c8fbba98a6495bb1964d16f.pdf"
  },
  {
    "success": true,
    "doc_id": "7c7a32c42afff1cdabe2ecda09b8a332",
    "summary": "Context: The rise of Artificial Intelligence (AI) in software engineering has led to the development of AI-powered test automation tools, promising improved efficiency, reduced maintenance effort, and enhanced defect-detection. However, a systematic evaluation of these tools is needed to understand their capabilities, benefits, and limitations. Objective: This study has two objectives: (1) A systematic review of AI-assisted test automation tools, categorizing their key AI features; (2) an empirical study of two selected AI-powered tools on two software under test, to investigate the effectiveness and limitations of the tools. Method: A systematic review of 55 AI-based test automation tools was conducted, classifying them based on their AI-assisted capabilities such as self-healing tests, visual testing, and AI-powered test generation. In the second phase, two representative tools were selected for the empirical study, in which we applied them to test two open-source software systems. Their performance was compared with traditional test automation approaches to evaluate efficiency and adaptability. Results: The review provides a comprehensive taxonomy of AI-driven testing tools, highlighting common features and trends. The empirical evaluation demonstrates that AI-powered automation enhances test execution efficiency and reduces maintenance effort but also exposes limitations such as handling complex UI changes and contextual understanding. Conclusion: AI-driven test automation tools show strong potential in improving software quality and reducing manual testing effort. However, their current limitations-such as false positives, lack of domain knowledge, and dependency on predefined models-indicate the need for further refinement. Future research should focus on advancing AI models to improve adaptability, reliability, and robustness in software testing.",
    "intriguing_abstract": "Context: The rise of Artificial Intelligence (AI) in software engineering has led to the development of AI-powered test automation tools, promising improved efficiency, reduced maintenance effort, and enhanced defect-detection. However, a systematic evaluation of these tools is needed to understand their capabilities, benefits, and limitations. Objective: This study has two objectives: (1) A systematic review of AI-assisted test automation tools, categorizing their key AI features; (2) an empirical study of two selected AI-powered tools on two software under test, to investigate the effectiveness and limitations of the tools. Method: A systematic review of 55 AI-based test automation tools was conducted, classifying them based on their AI-assisted capabilities such as self-healing tests, visual testing, and AI-powered test generation. In the second phase, two representative tools were selected for the empirical study, in which we applied them to test two open-source software systems. Their performance was compared with traditional test automation approaches to evaluate efficiency and adaptability. Results: The review provides a comprehensive taxonomy of AI-driven testing tools, highlighting common features and trends. The empirical evaluation demonstrates that AI-powered automation enhances test execution efficiency and reduces maintenance effort but also exposes limitations such as handling complex UI changes and contextual understanding. Conclusion: AI-driven test automation tools show strong potential in improving software quality and reducing manual testing effort. However, their current limitations-such as false positives, lack of domain knowledge, and dependency on predefined models-indicate the need for further refinement. Future research should focus on advancing AI models to improve adaptability, reliability, and robustness in software testing.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/94f31fbe8a20d0e97bf489490e6af4d9c2b9b06f.pdf",
    "citation_key": "garousi2024oy1",
    "metadata": {
      "title": "AI-powered software testing tools: A systematic review and empirical assessment of their features and limitations",
      "authors": [
        "Vahid Garousi",
        "Nithin Joy",
        "Zafar Jafarov",
        "Alper Buugra Kelecs",
        "Sevde Deugirmenci",
        "Ece Ozdemir",
        "Ryan Zarringhalami"
      ],
      "published_date": "2024",
      "abstract": "Context: The rise of Artificial Intelligence (AI) in software engineering has led to the development of AI-powered test automation tools, promising improved efficiency, reduced maintenance effort, and enhanced defect-detection. However, a systematic evaluation of these tools is needed to understand their capabilities, benefits, and limitations. Objective: This study has two objectives: (1) A systematic review of AI-assisted test automation tools, categorizing their key AI features; (2) an empirical study of two selected AI-powered tools on two software under test, to investigate the effectiveness and limitations of the tools. Method: A systematic review of 55 AI-based test automation tools was conducted, classifying them based on their AI-assisted capabilities such as self-healing tests, visual testing, and AI-powered test generation. In the second phase, two representative tools were selected for the empirical study, in which we applied them to test two open-source software systems. Their performance was compared with traditional test automation approaches to evaluate efficiency and adaptability. Results: The review provides a comprehensive taxonomy of AI-driven testing tools, highlighting common features and trends. The empirical evaluation demonstrates that AI-powered automation enhances test execution efficiency and reduces maintenance effort but also exposes limitations such as handling complex UI changes and contextual understanding. Conclusion: AI-driven test automation tools show strong potential in improving software quality and reducing manual testing effort. However, their current limitations-such as false positives, lack of domain knowledge, and dependency on predefined models-indicate the need for further refinement. Future research should focus on advancing AI models to improve adaptability, reliability, and robustness in software testing.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/94f31fbe8a20d0e97bf489490e6af4d9c2b9b06f.pdf",
      "venue": "",
      "citationCount": 5,
      "score": 5.0,
      "summary": "Context: The rise of Artificial Intelligence (AI) in software engineering has led to the development of AI-powered test automation tools, promising improved efficiency, reduced maintenance effort, and enhanced defect-detection. However, a systematic evaluation of these tools is needed to understand their capabilities, benefits, and limitations. Objective: This study has two objectives: (1) A systematic review of AI-assisted test automation tools, categorizing their key AI features; (2) an empirical study of two selected AI-powered tools on two software under test, to investigate the effectiveness and limitations of the tools. Method: A systematic review of 55 AI-based test automation tools was conducted, classifying them based on their AI-assisted capabilities such as self-healing tests, visual testing, and AI-powered test generation. In the second phase, two representative tools were selected for the empirical study, in which we applied them to test two open-source software systems. Their performance was compared with traditional test automation approaches to evaluate efficiency and adaptability. Results: The review provides a comprehensive taxonomy of AI-driven testing tools, highlighting common features and trends. The empirical evaluation demonstrates that AI-powered automation enhances test execution efficiency and reduces maintenance effort but also exposes limitations such as handling complex UI changes and contextual understanding. Conclusion: AI-driven test automation tools show strong potential in improving software quality and reducing manual testing effort. However, their current limitations-such as false positives, lack of domain knowledge, and dependency on predefined models-indicate the need for further refinement. Future research should focus on advancing AI models to improve adaptability, reliability, and robustness in software testing.",
      "keywords": []
    },
    "file_name": "94f31fbe8a20d0e97bf489490e6af4d9c2b9b06f.pdf"
  },
  {
    "success": true,
    "doc_id": "e04ed9dc0c67188fb88c545f4babee24",
    "summary": "In recent years, there has been a surge in the development of AI‐based Software as a Medical Device (SaMD), particularly in visual specialties such as dermatology. In Australia, the Therapeutic Goods Administration (TGA) regulates AI‐based SaMD to ensure its safe use. Proper labelling of these devices is crucial to ensure that healthcare professionals and the general public understand how to use them and interpret results accurately. However, guidelines for labelling AI‐based SaMD in dermatology are lacking, which may result in products failing to provide essential information about algorithm development and performance metrics. This review examines existing labelling guidelines for AI‐based SaMD across visual medical specialties, with a specific focus on dermatology. Common recommendations for labelling are identified and applied to currently available dermatology AI‐based SaMD mobile applications to determine usage of these labels. Of the 21 AI‐based SaMD mobile applications identified, none fully comply with common labelling recommendations. Results highlight the need for standardized labelling guidelines. Ensuring transparency and accessibility of information is essential for the safe integration of AI into health care and preventing potential risks associated with inaccurate clinical decisions.",
    "intriguing_abstract": "In recent years, there has been a surge in the development of AI‐based Software as a Medical Device (SaMD), particularly in visual specialties such as dermatology. In Australia, the Therapeutic Goods Administration (TGA) regulates AI‐based SaMD to ensure its safe use. Proper labelling of these devices is crucial to ensure that healthcare professionals and the general public understand how to use them and interpret results accurately. However, guidelines for labelling AI‐based SaMD in dermatology are lacking, which may result in products failing to provide essential information about algorithm development and performance metrics. This review examines existing labelling guidelines for AI‐based SaMD across visual medical specialties, with a specific focus on dermatology. Common recommendations for labelling are identified and applied to currently available dermatology AI‐based SaMD mobile applications to determine usage of these labels. Of the 21 AI‐based SaMD mobile applications identified, none fully comply with common labelling recommendations. Results highlight the need for standardized labelling guidelines. Ensuring transparency and accessibility of information is essential for the safe integration of AI into health care and preventing potential risks associated with inaccurate clinical decisions.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/aca4b7912c2f6f310c5de790dfd6a552eb480f30.pdf",
    "citation_key": "oloruntoba202455y",
    "metadata": {
      "title": "Examining labelling guidelines for AI‐based software as a medical device: A review and analysis of dermatology mobile applications in Australia",
      "authors": [
        "A. Oloruntoba",
        "Å. Ingvar",
        "M. Sashindranath",
        "Ojochonu Anthony",
        "Lisa M Abbott",
        "Pascale Guitera",
        "Tony Caccetta",
        "Monika Janda",
        "H. P. Soyer",
        "Victoria J Mar"
      ],
      "published_date": "2024",
      "abstract": "In recent years, there has been a surge in the development of AI‐based Software as a Medical Device (SaMD), particularly in visual specialties such as dermatology. In Australia, the Therapeutic Goods Administration (TGA) regulates AI‐based SaMD to ensure its safe use. Proper labelling of these devices is crucial to ensure that healthcare professionals and the general public understand how to use them and interpret results accurately. However, guidelines for labelling AI‐based SaMD in dermatology are lacking, which may result in products failing to provide essential information about algorithm development and performance metrics. This review examines existing labelling guidelines for AI‐based SaMD across visual medical specialties, with a specific focus on dermatology. Common recommendations for labelling are identified and applied to currently available dermatology AI‐based SaMD mobile applications to determine usage of these labels. Of the 21 AI‐based SaMD mobile applications identified, none fully comply with common labelling recommendations. Results highlight the need for standardized labelling guidelines. Ensuring transparency and accessibility of information is essential for the safe integration of AI into health care and preventing potential risks associated with inaccurate clinical decisions.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/aca4b7912c2f6f310c5de790dfd6a552eb480f30.pdf",
      "venue": "Australasian Journal of Dermatology",
      "citationCount": 5,
      "score": 5.0,
      "summary": "In recent years, there has been a surge in the development of AI‐based Software as a Medical Device (SaMD), particularly in visual specialties such as dermatology. In Australia, the Therapeutic Goods Administration (TGA) regulates AI‐based SaMD to ensure its safe use. Proper labelling of these devices is crucial to ensure that healthcare professionals and the general public understand how to use them and interpret results accurately. However, guidelines for labelling AI‐based SaMD in dermatology are lacking, which may result in products failing to provide essential information about algorithm development and performance metrics. This review examines existing labelling guidelines for AI‐based SaMD across visual medical specialties, with a specific focus on dermatology. Common recommendations for labelling are identified and applied to currently available dermatology AI‐based SaMD mobile applications to determine usage of these labels. Of the 21 AI‐based SaMD mobile applications identified, none fully comply with common labelling recommendations. Results highlight the need for standardized labelling guidelines. Ensuring transparency and accessibility of information is essential for the safe integration of AI into health care and preventing potential risks associated with inaccurate clinical decisions.",
      "keywords": []
    },
    "file_name": "aca4b7912c2f6f310c5de790dfd6a552eb480f30.pdf"
  },
  {
    "success": true,
    "doc_id": "7bb79c7b15159fec17bb26a54f2db5b7",
    "summary": "The China State Council released the new generation artificial intelligence (AI) development plan, outlining China's ambitious aspiration to assume global leadership in AI by the year 2030. This initiative underscores the extensive applicability of AI across diverse domains, including manufacturing, law, and medicine. With China establishing itself as a major producer and consumer of medical devices, there has been a notable increase in software registrations. This study aims to study the proliferation of health care–related software development within China. This work presents an overview of the Chinese regulatory framework for medical device software. The analysis covers both software as a medical device and software in a medical device. A comparative approach is employed to examine the regulations governing medical devices with AI and machine learning in China, the United States, and Europe. The study highlights the significant proliferation of health care–related software development within China, which has led to an increased demand for comprehensive regulatory guidance, particularly for international manufacturers. The comparative analysis reveals distinct regulatory frameworks and requirements across the three regions. This paper provides a useful outline of the current state of regulations for medical software in China and identifies the regulatory challenges posed by the rapid advancements in AI and machine learning technologies. Understanding these challenges is crucial for international manufacturers and stakeholders aiming to navigate the complex regulatory landscape.",
    "intriguing_abstract": "The China State Council released the new generation artificial intelligence (AI) development plan, outlining China's ambitious aspiration to assume global leadership in AI by the year 2030. This initiative underscores the extensive applicability of AI across diverse domains, including manufacturing, law, and medicine. With China establishing itself as a major producer and consumer of medical devices, there has been a notable increase in software registrations. This study aims to study the proliferation of health care–related software development within China. This work presents an overview of the Chinese regulatory framework for medical device software. The analysis covers both software as a medical device and software in a medical device. A comparative approach is employed to examine the regulations governing medical devices with AI and machine learning in China, the United States, and Europe. The study highlights the significant proliferation of health care–related software development within China, which has led to an increased demand for comprehensive regulatory guidance, particularly for international manufacturers. The comparative analysis reveals distinct regulatory frameworks and requirements across the three regions. This paper provides a useful outline of the current state of regulations for medical software in China and identifies the regulatory challenges posed by the rapid advancements in AI and machine learning technologies. Understanding these challenges is crucial for international manufacturers and stakeholders aiming to navigate the complex regulatory landscape.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/99ef861928769ad29bf1a09ef623c46eec20a69d.pdf",
    "citation_key": "han20239ut",
    "metadata": {
      "title": "Regulatory Frameworks for AI-Enabled Medical Device Software in China: Comparative Analysis and Review of Implications for Global Manufacturer",
      "authors": [
        "Yu Han",
        "Aaron Ceross",
        "Jeroen H. M. Bergmann"
      ],
      "published_date": "2023",
      "abstract": "The China State Council released the new generation artificial intelligence (AI) development plan, outlining China's ambitious aspiration to assume global leadership in AI by the year 2030. This initiative underscores the extensive applicability of AI across diverse domains, including manufacturing, law, and medicine. With China establishing itself as a major producer and consumer of medical devices, there has been a notable increase in software registrations. This study aims to study the proliferation of health care–related software development within China. This work presents an overview of the Chinese regulatory framework for medical device software. The analysis covers both software as a medical device and software in a medical device. A comparative approach is employed to examine the regulations governing medical devices with AI and machine learning in China, the United States, and Europe. The study highlights the significant proliferation of health care–related software development within China, which has led to an increased demand for comprehensive regulatory guidance, particularly for international manufacturers. The comparative analysis reveals distinct regulatory frameworks and requirements across the three regions. This paper provides a useful outline of the current state of regulations for medical software in China and identifies the regulatory challenges posed by the rapid advancements in AI and machine learning technologies. Understanding these challenges is crucial for international manufacturers and stakeholders aiming to navigate the complex regulatory landscape.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/99ef861928769ad29bf1a09ef623c46eec20a69d.pdf",
      "venue": "JMIR AI",
      "citationCount": 10,
      "score": 5.0,
      "summary": "The China State Council released the new generation artificial intelligence (AI) development plan, outlining China's ambitious aspiration to assume global leadership in AI by the year 2030. This initiative underscores the extensive applicability of AI across diverse domains, including manufacturing, law, and medicine. With China establishing itself as a major producer and consumer of medical devices, there has been a notable increase in software registrations. This study aims to study the proliferation of health care–related software development within China. This work presents an overview of the Chinese regulatory framework for medical device software. The analysis covers both software as a medical device and software in a medical device. A comparative approach is employed to examine the regulations governing medical devices with AI and machine learning in China, the United States, and Europe. The study highlights the significant proliferation of health care–related software development within China, which has led to an increased demand for comprehensive regulatory guidance, particularly for international manufacturers. The comparative analysis reveals distinct regulatory frameworks and requirements across the three regions. This paper provides a useful outline of the current state of regulations for medical software in China and identifies the regulatory challenges posed by the rapid advancements in AI and machine learning technologies. Understanding these challenges is crucial for international manufacturers and stakeholders aiming to navigate the complex regulatory landscape.",
      "keywords": []
    },
    "file_name": "99ef861928769ad29bf1a09ef623c46eec20a69d.pdf"
  },
  {
    "success": true,
    "doc_id": "c07df21d4428d7de3cf6657214ec4940",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The research addresses the fragmented and unsystematic understanding of Human-AI Experience (HAX) within Integrated Development Environments (IDEs), termed \"in-IDE HAX\" \\cite{sergeyuk2025bfj}. Despite rapid adoption of AI in coding, there was no unified overview of current practices, challenges, and opportunities in this specific interaction context.\n    *   **Importance and Challenge:** The integration of AI into IDEs fundamentally alters how developers interact with their tools, shifting HCI focus towards HAX where AI acts as an active collaborator. Given the growing reliance on AI-enhanced IDEs, a structured overview is crucial to identify recurring themes and gaps, which existing LLM-focused reviews in software engineering do not capture \\cite{sergeyuk2025bfj}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work is positioned as the *first systematic literature review (SLR)* specifically on in-IDE HAX \\cite{sergeyuk2025bfj}. It builds upon an earlier, non-systematic survey by the same authors, significantly expanding its scope and methodological rigor.\n    *   **Limitations of Previous Solutions:** Prior literature reviews on Large Language Models (LLMs) in software engineering (e.g., He et al., 2025; Zhou et al., 2025a) summarize model capabilities, task coverage, and evaluation techniques, but *do not analyze the interaction experience inside developer workspaces* where the software development lifecycle takes place \\cite{sergeyuk2025bfj}. This paper fills that gap by focusing on the experience-level patterns and design challenges unique to in-IDE HAX.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm:** The core method is a formal Systematic Literature Review (SLR) conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework \\cite{sergeyuk2025bfj}. This involved defining research questions, eligibility criteria, a multi-database search strategy, quality assessment, and backward snowballing.\n    *   **Novelty/Differentiation:** The approach is novel due to its specific focus on in-IDE HAX, making it the first SLR in this domain. It systematically identified and reviewed 90 studies (compared to 36 in a previous non-systematic survey), applying a rigorous multi-step procedure combining database searches, backward snowballing, and expert-informed additions. The review introduces a structured analytical framework, organizing findings along three key research dimensions: Impact, Design, and Quality \\cite{sergeyuk2025bfj}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   Application of a formal SLR methodology (PRISMA) to comprehensively map the nascent field of in-IDE HAX \\cite{sergeyuk2025bfj}.\n        *   Development and application of a specific taxonomy for in-IDE HAX research, categorizing studies into Impact, Design, and Quality dimensions \\cite{sergeyuk2025bfj}.\n        *   A robust, multi-stage study identification process ensuring broad coverage and methodological consistency, including expert-based supplementation to mitigate indexing limitations \\cite{sergeyuk2025bfj}.\n    *   **Theoretical Insights or Analysis:**\n        *   A comprehensive synthesis of 90 studies, revealing dominant research themes, study contexts, and trends in in-IDE HAX \\cite{sergeyuk2025bfj}.\n        *   Detailed characterization of HAX research dimensions: (a) **Impact** (effects on workflows, productivity, experience), (b) **Design** (AI integration and interaction in IDEs), and (c) **Quality** (properties of AI outputs like correctness, security, readability) \\cite{sergeyuk2025bfj}.\n        *   Identification of critical gaps and under-explored topics for future research, such as AI governance, user control, and proactivity \\cite{sergeyuk2025bfj}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** As a systematic literature review, this paper does not conduct new experiments. Instead, it synthesizes the findings from 90 empirical studies.\n    *   **Key Performance Metrics and Comparison Results (from reviewed studies):**\n        *   **Impact:** Studies report productivity improvements, especially among experienced users, but also note increased time spent on result verification and concerns about over-reliance \\cite{sergeyuk2025bfj}.\n        *   **Design:** Effective interfaces are shown to surface context, provide explanations and transparency of suggestions, and support user control. Prompt structure and interface properties significantly influence the user experience \\cite{sergeyuk2025bfj}.\n        *   **Quality:** Studies document risks in the correctness, maintainability, and security of AI-generated code, often calling for improved validation and diagnostic support \\cite{sergeyuk2025bfj}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations or Assumptions:**\n        *   The review primarily focuses on professional software development settings and the code implementation stage of the Software Development Lifecycle (SDLC), with limited attention to other stages (requirements, testing, deployment) \\cite{sergeyuk2025bfj}.\n        *   Educational contexts, perspectives of non-users, or people who have stopped using AI assistance are rarely studied in the reviewed literature \\cite{sergeyuk2025bfj}.\n        *   The definition of an IDE for inclusion is specific: \"any workspace that simultaneously offers (a) code editing, (b) immediate execution or preview, and (c) contextual AI feedback in the same window,\" excluding tools that push AI suggestions outside the primary editing surface \\cite{sergeyuk2025bfj}.\n    *   **Scope of Applicability:** The review specifically focuses on \"how the presence of an AI assistance changes what happens in the very place where code is written, inspected, or tested, rather than how AI helps in software engineering broadly\" \\cite{sergeyuk2025bfj}. The timeframe for included studies is 2022-2024, and only English-language publications were considered.\n\n*   **7. Technical Significance**\n    *   **Advancement of Technical State-of-the-Art:** This paper significantly advances the technical state-of-the-art by providing the *first systematic and comprehensive overview* of in-IDE HAX, unifying fragmented research and establishing a foundational reference for cumulative and reproducible progress in the field \\cite{sergeyuk2025bfj}. It moves beyond general LLM capabilities to focus on the critical interaction experience within development environments.\n    *   **Potential Impact on Future Research:** The review identifies crucial gaps and outlines a clear agenda for future research, including the need for larger and longer evaluations, stronger audit and verification assets for AI-generated code, broader coverage across the software lifecycle, and adaptive assistance under user control \\cite{sergeyuk2025bfj}. It highlights under-explored topics like AI governance, user control, and proactivity, thereby informing both academic and industry efforts in designing and evaluating AI-powered development tools.",
    "intriguing_abstract": "As AI rapidly transforms software development, the critical Human-AI Experience (HAX) within Integrated Development Environments (IDEs) remains fragmented and unsystematically understood. While Large Language Models (LLMs) revolutionize coding, a unified perspective on *in-IDE HAX*—how developers truly interact with AI collaborators in their workspace—is urgently needed. This paper presents the *first systematic literature review (SLR)* dedicated to in-IDE HAX, rigorously synthesizing 90 studies using the PRISMA framework.\n\nWe introduce a novel analytical taxonomy, categorizing research into three crucial dimensions: **Impact** on developer workflows and productivity, **Design** of AI integration and interaction, and **Quality** of AI-generated outputs. Our comprehensive synthesis reveals significant productivity gains, particularly for experienced users, alongside challenges like increased verification time and risks to code correctness and security. We highlight the paramount importance of transparent, context-aware AI design that prioritizes user control. This foundational SLR unifies disparate research, identifies critical gaps in AI governance, user proactivity, and long-term evaluations, and provides an essential roadmap for designing and evaluating the next generation of AI-powered development tools, shaping the future of software engineering.",
    "keywords": [
      "in-IDE Human-AI Experience (HAX)",
      "Systematic Literature Review (SLR)",
      "Integrated Development Environments (IDEs)",
      "AI assistance in software development",
      "HAX Impact",
      "Design",
      "Quality dimensions",
      "AI-generated code quality",
      "Developer productivity",
      "User control and transparency",
      "Critical research gaps",
      "PRISMA methodology",
      "Code correctness and security",
      "AI over-reliance"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ec6a82e2c7d8ebdc0221580753048542db72ca27.pdf",
    "citation_key": "sergeyuk2025bfj",
    "metadata": {
      "title": "Human-AI Experience in Integrated Development Environments: A Systematic Literature Review",
      "authors": [
        "Agnia Sergeyuk",
        "Ilya Zakharov",
        "Ekaterina Koshchenko",
        "Maliheh Izadi"
      ],
      "published_date": "2025",
      "abstract": "The integration of Artificial Intelligence (AI) into Integrated Development Environments (IDEs) is reshaping software development, fundamentally altering how developers interact with their tools. This shift marks the emergence of Human-AI Experience in Integrated Development Environment (in-IDE HAX), a field that explores the evolving dynamics of Human-Computer Interaction in AI-assisted coding environments. Despite rapid adoption, research on in-IDE HAX remains fragmented, which highlights the need for a unified overview of current practices, challenges, and opportunities. To provide a structured overview of existing research, we conduct a systematic literature review of 90 studies, summarizing current findings and outlining areas for further investigation. We organize key insights from reviewed studies into three aspects: Impact, Design, and Quality of AI-based systems inside IDEs. Impact findings show that AI-assisted coding enhances developer productivity but also introduces challenges, such as verification overhead and over-reliance. Design studies show that effective interfaces surface context, provide explanations and transparency of suggestion, and support user control. Quality studies document risks in correctness, maintainability, and security. For future research, priorities include productivity studies, design of assistance, and audit of AI-generated code. The agenda calls for larger and longer evaluations, stronger audit and verification assets, broader coverage across the software life cycle, and adaptive assistance under user control.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ec6a82e2c7d8ebdc0221580753048542db72ca27.pdf",
      "venue": "arXiv.org",
      "citationCount": 5,
      "score": 5.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The research addresses the fragmented and unsystematic understanding of Human-AI Experience (HAX) within Integrated Development Environments (IDEs), termed \"in-IDE HAX\" \\cite{sergeyuk2025bfj}. Despite rapid adoption of AI in coding, there was no unified overview of current practices, challenges, and opportunities in this specific interaction context.\n    *   **Importance and Challenge:** The integration of AI into IDEs fundamentally alters how developers interact with their tools, shifting HCI focus towards HAX where AI acts as an active collaborator. Given the growing reliance on AI-enhanced IDEs, a structured overview is crucial to identify recurring themes and gaps, which existing LLM-focused reviews in software engineering do not capture \\cite{sergeyuk2025bfj}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** This work is positioned as the *first systematic literature review (SLR)* specifically on in-IDE HAX \\cite{sergeyuk2025bfj}. It builds upon an earlier, non-systematic survey by the same authors, significantly expanding its scope and methodological rigor.\n    *   **Limitations of Previous Solutions:** Prior literature reviews on Large Language Models (LLMs) in software engineering (e.g., He et al., 2025; Zhou et al., 2025a) summarize model capabilities, task coverage, and evaluation techniques, but *do not analyze the interaction experience inside developer workspaces* where the software development lifecycle takes place \\cite{sergeyuk2025bfj}. This paper fills that gap by focusing on the experience-level patterns and design challenges unique to in-IDE HAX.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm:** The core method is a formal Systematic Literature Review (SLR) conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework \\cite{sergeyuk2025bfj}. This involved defining research questions, eligibility criteria, a multi-database search strategy, quality assessment, and backward snowballing.\n    *   **Novelty/Differentiation:** The approach is novel due to its specific focus on in-IDE HAX, making it the first SLR in this domain. It systematically identified and reviewed 90 studies (compared to 36 in a previous non-systematic survey), applying a rigorous multi-step procedure combining database searches, backward snowballing, and expert-informed additions. The review introduces a structured analytical framework, organizing findings along three key research dimensions: Impact, Design, and Quality \\cite{sergeyuk2025bfj}.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques:**\n        *   Application of a formal SLR methodology (PRISMA) to comprehensively map the nascent field of in-IDE HAX \\cite{sergeyuk2025bfj}.\n        *   Development and application of a specific taxonomy for in-IDE HAX research, categorizing studies into Impact, Design, and Quality dimensions \\cite{sergeyuk2025bfj}.\n        *   A robust, multi-stage study identification process ensuring broad coverage and methodological consistency, including expert-based supplementation to mitigate indexing limitations \\cite{sergeyuk2025bfj}.\n    *   **Theoretical Insights or Analysis:**\n        *   A comprehensive synthesis of 90 studies, revealing dominant research themes, study contexts, and trends in in-IDE HAX \\cite{sergeyuk2025bfj}.\n        *   Detailed characterization of HAX research dimensions: (a) **Impact** (effects on workflows, productivity, experience), (b) **Design** (AI integration and interaction in IDEs), and (c) **Quality** (properties of AI outputs like correctness, security, readability) \\cite{sergeyuk2025bfj}.\n        *   Identification of critical gaps and under-explored topics for future research, such as AI governance, user control, and proactivity \\cite{sergeyuk2025bfj}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:** As a systematic literature review, this paper does not conduct new experiments. Instead, it synthesizes the findings from 90 empirical studies.\n    *   **Key Performance Metrics and Comparison Results (from reviewed studies):**\n        *   **Impact:** Studies report productivity improvements, especially among experienced users, but also note increased time spent on result verification and concerns about over-reliance \\cite{sergeyuk2025bfj}.\n        *   **Design:** Effective interfaces are shown to surface context, provide explanations and transparency of suggestions, and support user control. Prompt structure and interface properties significantly influence the user experience \\cite{sergeyuk2025bfj}.\n        *   **Quality:** Studies document risks in the correctness, maintainability, and security of AI-generated code, often calling for improved validation and diagnostic support \\cite{sergeyuk2025bfj}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations or Assumptions:**\n        *   The review primarily focuses on professional software development settings and the code implementation stage of the Software Development Lifecycle (SDLC), with limited attention to other stages (requirements, testing, deployment) \\cite{sergeyuk2025bfj}.\n        *   Educational contexts, perspectives of non-users, or people who have stopped using AI assistance are rarely studied in the reviewed literature \\cite{sergeyuk2025bfj}.\n        *   The definition of an IDE for inclusion is specific: \"any workspace that simultaneously offers (a) code editing, (b) immediate execution or preview, and (c) contextual AI feedback in the same window,\" excluding tools that push AI suggestions outside the primary editing surface \\cite{sergeyuk2025bfj}.\n    *   **Scope of Applicability:** The review specifically focuses on \"how the presence of an AI assistance changes what happens in the very place where code is written, inspected, or tested, rather than how AI helps in software engineering broadly\" \\cite{sergeyuk2025bfj}. The timeframe for included studies is 2022-2024, and only English-language publications were considered.\n\n*   **7. Technical Significance**\n    *   **Advancement of Technical State-of-the-Art:** This paper significantly advances the technical state-of-the-art by providing the *first systematic and comprehensive overview* of in-IDE HAX, unifying fragmented research and establishing a foundational reference for cumulative and reproducible progress in the field \\cite{sergeyuk2025bfj}. It moves beyond general LLM capabilities to focus on the critical interaction experience within development environments.\n    *   **Potential Impact on Future Research:** The review identifies crucial gaps and outlines a clear agenda for future research, including the need for larger and longer evaluations, stronger audit and verification assets for AI-generated code, broader coverage across the software lifecycle, and adaptive assistance under user control \\cite{sergeyuk2025bfj}. It highlights under-explored topics like AI governance, user control, and proactivity, thereby informing both academic and industry efforts in designing and evaluating AI-powered development tools.",
      "keywords": [
        "in-IDE Human-AI Experience (HAX)",
        "Systematic Literature Review (SLR)",
        "Integrated Development Environments (IDEs)",
        "AI assistance in software development",
        "HAX Impact",
        "Design",
        "Quality dimensions",
        "AI-generated code quality",
        "Developer productivity",
        "User control and transparency",
        "Critical research gaps",
        "PRISMA methodology",
        "Code correctness and security",
        "AI over-reliance"
      ],
      "paper_type": "based on the abstract and introduction, this paper is a **survey**.\n\nhere's why:\n\n*   **title:** \"human-ai experience in integrated development environments: a **systematic literature review**\" directly indicates its type.\n*   **abstract:**\n    *   mentions \"research on in-ide hax remains fragmented, which highlights the need for a unified overview of current practices, challenges, and opportunities.\"\n    *   states, \"to provide a structured overview of existing research, we conduct a **systematic literature review of 90 studies**, summarizing current findings and outlining areas for further investigation.\"\n    *   discusses organizing \"key insights from reviewed studies\" and outlining \"future research priorities.\"\n*   **introduction:**\n    *   emphasizes the need \"to merge and evaluate existing evidence in the field of in-ide hax. doing so will help to identify recurring themes and gaps in the literature.\"\n\nthese points align perfectly with the criteria for a **survey** paper, which reviews existing literature comprehensively, discusses literature organization, and identifies gaps."
    },
    "file_name": "ec6a82e2c7d8ebdc0221580753048542db72ca27.pdf"
  },
  {
    "success": true,
    "doc_id": "79752847d19b11daec13196d4213fc8a",
    "summary": "Software developers increasingly rely on AI code generation utilities. To ensure that “good” code is accepted into the code base and “bad” code is rejected, developers must know when to trust an AI suggestion. Understanding how developers build this intuition is crucial to enhancing developer-AI collaborative programming. In this paper, we seek to understand how developers (1) define and (2) evaluate the trustworthiness of a code suggestion and (3) how trust evolves when using AI code assistants. To answer these questions, we conducted a mixed method study consisting of an in-depth exploratory survey with (n=29) developers followed by an observation study (n=10). We found that comprehensibility and perceived correctness were the most frequently used factors to evaluate code suggestion trustworthiness. However, the gap in developers' definition and evaluation of trust points to a lack of support for evaluating trustworthy code in real-time. We also found that developers often alter their trust decisions, keeping only 52% of original suggestions. Based on these findings, we extracted four guidelines to enhance developer-AI interactions. We validated the guidelines through a survey with (n=7) domain experts and survey members (n=8). We discuss the validated guidelines, how to apply them, and tools to help adopt them.",
    "intriguing_abstract": "Software developers increasingly rely on AI code generation utilities. To ensure that “good” code is accepted into the code base and “bad” code is rejected, developers must know when to trust an AI suggestion. Understanding how developers build this intuition is crucial to enhancing developer-AI collaborative programming. In this paper, we seek to understand how developers (1) define and (2) evaluate the trustworthiness of a code suggestion and (3) how trust evolves when using AI code assistants. To answer these questions, we conducted a mixed method study consisting of an in-depth exploratory survey with (n=29) developers followed by an observation study (n=10). We found that comprehensibility and perceived correctness were the most frequently used factors to evaluate code suggestion trustworthiness. However, the gap in developers' definition and evaluation of trust points to a lack of support for evaluating trustworthy code in real-time. We also found that developers often alter their trust decisions, keeping only 52% of original suggestions. Based on these findings, we extracted four guidelines to enhance developer-AI interactions. We validated the guidelines through a survey with (n=7) domain experts and survey members (n=8). We discuss the validated guidelines, how to apply them, and tools to help adopt them.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/e8c2e39fb06bb666efe3476e820c5cef7f1c484a.pdf",
    "citation_key": "sabouri2025g21",
    "metadata": {
      "title": "Trust Dynamics in AI-Assisted Development: Definitions, Factors, and Implications",
      "authors": [
        "Sadra Sabouri",
        "Philipp Eibl",
        "Xinyi Zhou",
        "Morteza Ziyadi",
        "Nenad Medvidovic",
        "Lars Lindemann",
        "Souti Chattopadhyay"
      ],
      "published_date": "2025",
      "abstract": "Software developers increasingly rely on AI code generation utilities. To ensure that “good” code is accepted into the code base and “bad” code is rejected, developers must know when to trust an AI suggestion. Understanding how developers build this intuition is crucial to enhancing developer-AI collaborative programming. In this paper, we seek to understand how developers (1) define and (2) evaluate the trustworthiness of a code suggestion and (3) how trust evolves when using AI code assistants. To answer these questions, we conducted a mixed method study consisting of an in-depth exploratory survey with (n=29) developers followed by an observation study (n=10). We found that comprehensibility and perceived correctness were the most frequently used factors to evaluate code suggestion trustworthiness. However, the gap in developers' definition and evaluation of trust points to a lack of support for evaluating trustworthy code in real-time. We also found that developers often alter their trust decisions, keeping only 52% of original suggestions. Based on these findings, we extracted four guidelines to enhance developer-AI interactions. We validated the guidelines through a survey with (n=7) domain experts and survey members (n=8). We discuss the validated guidelines, how to apply them, and tools to help adopt them.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/e8c2e39fb06bb666efe3476e820c5cef7f1c484a.pdf",
      "venue": "International Conference on Software Engineering",
      "citationCount": 5,
      "score": 5.0,
      "summary": "Software developers increasingly rely on AI code generation utilities. To ensure that “good” code is accepted into the code base and “bad” code is rejected, developers must know when to trust an AI suggestion. Understanding how developers build this intuition is crucial to enhancing developer-AI collaborative programming. In this paper, we seek to understand how developers (1) define and (2) evaluate the trustworthiness of a code suggestion and (3) how trust evolves when using AI code assistants. To answer these questions, we conducted a mixed method study consisting of an in-depth exploratory survey with (n=29) developers followed by an observation study (n=10). We found that comprehensibility and perceived correctness were the most frequently used factors to evaluate code suggestion trustworthiness. However, the gap in developers' definition and evaluation of trust points to a lack of support for evaluating trustworthy code in real-time. We also found that developers often alter their trust decisions, keeping only 52% of original suggestions. Based on these findings, we extracted four guidelines to enhance developer-AI interactions. We validated the guidelines through a survey with (n=7) domain experts and survey members (n=8). We discuss the validated guidelines, how to apply them, and tools to help adopt them.",
      "keywords": []
    },
    "file_name": "e8c2e39fb06bb666efe3476e820c5cef7f1c484a.pdf"
  },
  {
    "success": true,
    "doc_id": "0c996a8961d7b9354015e4504a09ca2c",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/3ad6556606e2b89ef14c2c1106b928201efeda96.pdf",
    "citation_key": "bera202316k",
    "metadata": {
      "title": "On the Use of ChatGPT to Support Agile Software Development",
      "authors": [
        "Palash Bera",
        "Yves Wautelet",
        "G. Poels"
      ],
      "published_date": "2023",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/3ad6556606e2b89ef14c2c1106b928201efeda96.pdf",
      "venue": "Agil-ISE@CAiSE",
      "citationCount": 9,
      "score": 4.5,
      "summary": "",
      "keywords": []
    },
    "file_name": "3ad6556606e2b89ef14c2c1106b928201efeda96.pdf"
  },
  {
    "success": true,
    "doc_id": "0bc338d76d7985284d8b74d3da3ecbc7",
    "summary": "Software requirements show what the customer desires his software to do. They are the first stepping stone towards a successful software development project. With the increasing complexity of the software due to its size and feature base, it is vital to prioritize the requirements for efficient utilization of development resources. To achieve this, industrial organizations are devising new strategies and improved solutions even with the help of artificial intelligence (AI) tool set. Existing requirements prioritization techniques are human-intensive and suffer from several limitations like overlapping outcomes, scalability problems, time consumption, inaccuracy, and so on. Some of the problems can be solved by including artificial intelligence algorithms and strategies. Several AI-based requirements prioritization techniques have been proposed by applying Genetic Algorithms, Fuzzy Logic, Ant Colony Optimization, and Machine Learning. Literature witnesses some good review studies and surveys on conventional prioritization techniques but there exists none for AI-based techniques that identify not only their strengths but also their weaknesses, advantages of machine learning techniques over other AI-based requirements prioritization techniques, and limitations of applying AI-based techniques in requirements prioritization. This study presents a systematic literature review (SLR) of AI-based requirements prioritization approaches covering 46 papers published from 2000 to 2021. We have given this literature review a new dimension by conducting a parametric analysis of AI-based requirements prioritization techniques and we have identified these parameters after a thorough literature study. Some of the chosen parameters are generic (related to the prioritization process) and some are specific (related to AI techniques). This study has greatly helped us draw a clear line among AI-based techniques to show their domain of application to gain maximum advantage. Our findings will assist researchers, requirement analysts, and other stakeholders in making a wise decision to select the best requirements prioritization technique to gain optimal results.",
    "intriguing_abstract": "Software requirements show what the customer desires his software to do. They are the first stepping stone towards a successful software development project. With the increasing complexity of the software due to its size and feature base, it is vital to prioritize the requirements for efficient utilization of development resources. To achieve this, industrial organizations are devising new strategies and improved solutions even with the help of artificial intelligence (AI) tool set. Existing requirements prioritization techniques are human-intensive and suffer from several limitations like overlapping outcomes, scalability problems, time consumption, inaccuracy, and so on. Some of the problems can be solved by including artificial intelligence algorithms and strategies. Several AI-based requirements prioritization techniques have been proposed by applying Genetic Algorithms, Fuzzy Logic, Ant Colony Optimization, and Machine Learning. Literature witnesses some good review studies and surveys on conventional prioritization techniques but there exists none for AI-based techniques that identify not only their strengths but also their weaknesses, advantages of machine learning techniques over other AI-based requirements prioritization techniques, and limitations of applying AI-based techniques in requirements prioritization. This study presents a systematic literature review (SLR) of AI-based requirements prioritization approaches covering 46 papers published from 2000 to 2021. We have given this literature review a new dimension by conducting a parametric analysis of AI-based requirements prioritization techniques and we have identified these parameters after a thorough literature study. Some of the chosen parameters are generic (related to the prioritization process) and some are specific (related to AI techniques). This study has greatly helped us draw a clear line among AI-based techniques to show their domain of application to gain maximum advantage. Our findings will assist researchers, requirement analysts, and other stakeholders in making a wise decision to select the best requirements prioritization technique to gain optimal results.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/e80189322adf7a079e99b4f1e628307b29ae8e2c.pdf",
    "citation_key": "anwar2023jaa",
    "metadata": {
      "title": "A Systematic Literature Review of AI-Based Software Requirements Prioritization Techniques",
      "authors": [
        "Rahila Anwar",
        "Muhammad Bilal Bashir"
      ],
      "published_date": "2023",
      "abstract": "Software requirements show what the customer desires his software to do. They are the first stepping stone towards a successful software development project. With the increasing complexity of the software due to its size and feature base, it is vital to prioritize the requirements for efficient utilization of development resources. To achieve this, industrial organizations are devising new strategies and improved solutions even with the help of artificial intelligence (AI) tool set. Existing requirements prioritization techniques are human-intensive and suffer from several limitations like overlapping outcomes, scalability problems, time consumption, inaccuracy, and so on. Some of the problems can be solved by including artificial intelligence algorithms and strategies. Several AI-based requirements prioritization techniques have been proposed by applying Genetic Algorithms, Fuzzy Logic, Ant Colony Optimization, and Machine Learning. Literature witnesses some good review studies and surveys on conventional prioritization techniques but there exists none for AI-based techniques that identify not only their strengths but also their weaknesses, advantages of machine learning techniques over other AI-based requirements prioritization techniques, and limitations of applying AI-based techniques in requirements prioritization. This study presents a systematic literature review (SLR) of AI-based requirements prioritization approaches covering 46 papers published from 2000 to 2021. We have given this literature review a new dimension by conducting a parametric analysis of AI-based requirements prioritization techniques and we have identified these parameters after a thorough literature study. Some of the chosen parameters are generic (related to the prioritization process) and some are specific (related to AI techniques). This study has greatly helped us draw a clear line among AI-based techniques to show their domain of application to gain maximum advantage. Our findings will assist researchers, requirement analysts, and other stakeholders in making a wise decision to select the best requirements prioritization technique to gain optimal results.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/e80189322adf7a079e99b4f1e628307b29ae8e2c.pdf",
      "venue": "IEEE Access",
      "citationCount": 9,
      "score": 4.5,
      "summary": "Software requirements show what the customer desires his software to do. They are the first stepping stone towards a successful software development project. With the increasing complexity of the software due to its size and feature base, it is vital to prioritize the requirements for efficient utilization of development resources. To achieve this, industrial organizations are devising new strategies and improved solutions even with the help of artificial intelligence (AI) tool set. Existing requirements prioritization techniques are human-intensive and suffer from several limitations like overlapping outcomes, scalability problems, time consumption, inaccuracy, and so on. Some of the problems can be solved by including artificial intelligence algorithms and strategies. Several AI-based requirements prioritization techniques have been proposed by applying Genetic Algorithms, Fuzzy Logic, Ant Colony Optimization, and Machine Learning. Literature witnesses some good review studies and surveys on conventional prioritization techniques but there exists none for AI-based techniques that identify not only their strengths but also their weaknesses, advantages of machine learning techniques over other AI-based requirements prioritization techniques, and limitations of applying AI-based techniques in requirements prioritization. This study presents a systematic literature review (SLR) of AI-based requirements prioritization approaches covering 46 papers published from 2000 to 2021. We have given this literature review a new dimension by conducting a parametric analysis of AI-based requirements prioritization techniques and we have identified these parameters after a thorough literature study. Some of the chosen parameters are generic (related to the prioritization process) and some are specific (related to AI techniques). This study has greatly helped us draw a clear line among AI-based techniques to show their domain of application to gain maximum advantage. Our findings will assist researchers, requirement analysts, and other stakeholders in making a wise decision to select the best requirements prioritization technique to gain optimal results.",
      "keywords": []
    },
    "file_name": "e80189322adf7a079e99b4f1e628307b29ae8e2c.pdf"
  },
  {
    "success": true,
    "doc_id": "f33135fb116e3bdc7048d74ef1194752",
    "summary": "Simple Summary Artificial Intelligence (AI)-driven software that utilizes Computed Tomography (CT)images has the capability to automatically assess body composition and diagnose sarcopenia. Our research indicates that combining standardized CT staging methods with sarcopenia analysis could assist in identifying patients with advanced urothelial tumors who may benefit from customized nutritional therapies, ultimately resulting in improved outcomes and quality of life. The AI tool can represent a means to increase the clinical value of CT imaging reports and to promote the development of precision medicine. Abstract Background: Sarcopenia is a well know prognostic factor in oncology, influencing patients’ quality of life and survival. We aimed to investigate the role of sarcopenia, assessed by a Computed Tomography (CT)-based artificial intelligence (AI)-powered-software, as a predictor of objective clinical benefit in advanced urothelial tumors and its correlations with oncological outcomes. Methods: We retrospectively searched patients with advanced urothelial tumors, treated with systemic platinum-based chemotherapy and an available total body CT, performed before and after therapy. An AI-powered software was applied to CT to obtain the Skeletal Muscle Index (SMI-L3), derived from the area of the psoas, long spine, and abdominal muscles, at the level of L3 on CT axial images. Logistic and Cox-regression modeling was implemented to explore the association of sarcopenic status and anthropometric features to the clinical benefit rate and survival endpoints. Results: 97 patients were included, 66 with bladder cancer and 31 with upper-tract urothelial carcinoma. Clinical benefit outcomes showed a linear positive association with all the observed body composition variables variations. The chances of not experiencing disease progression were positively associated with ∆_SMI-L3, ∆_psoas, and ∆_long spine muscle when they ranged from ~10–20% up to ~45–55%. Greater survival chances were matched by patients achieving a wider ∆_SMI-L3, ∆_abdominal and ∆_long spine muscle. Conclusions: A CT-based AI-powered software body composition and sarcopenia analysis provide prognostic assessments for objective clinical benefits and oncological outcomes.",
    "intriguing_abstract": "Simple Summary Artificial Intelligence (AI)-driven software that utilizes Computed Tomography (CT)images has the capability to automatically assess body composition and diagnose sarcopenia. Our research indicates that combining standardized CT staging methods with sarcopenia analysis could assist in identifying patients with advanced urothelial tumors who may benefit from customized nutritional therapies, ultimately resulting in improved outcomes and quality of life. The AI tool can represent a means to increase the clinical value of CT imaging reports and to promote the development of precision medicine. Abstract Background: Sarcopenia is a well know prognostic factor in oncology, influencing patients’ quality of life and survival. We aimed to investigate the role of sarcopenia, assessed by a Computed Tomography (CT)-based artificial intelligence (AI)-powered-software, as a predictor of objective clinical benefit in advanced urothelial tumors and its correlations with oncological outcomes. Methods: We retrospectively searched patients with advanced urothelial tumors, treated with systemic platinum-based chemotherapy and an available total body CT, performed before and after therapy. An AI-powered software was applied to CT to obtain the Skeletal Muscle Index (SMI-L3), derived from the area of the psoas, long spine, and abdominal muscles, at the level of L3 on CT axial images. Logistic and Cox-regression modeling was implemented to explore the association of sarcopenic status and anthropometric features to the clinical benefit rate and survival endpoints. Results: 97 patients were included, 66 with bladder cancer and 31 with upper-tract urothelial carcinoma. Clinical benefit outcomes showed a linear positive association with all the observed body composition variables variations. The chances of not experiencing disease progression were positively associated with ∆_SMI-L3, ∆_psoas, and ∆_long spine muscle when they ranged from ~10–20% up to ~45–55%. Greater survival chances were matched by patients achieving a wider ∆_SMI-L3, ∆_abdominal and ∆_long spine muscle. Conclusions: A CT-based AI-powered software body composition and sarcopenia analysis provide prognostic assessments for objective clinical benefits and oncological outcomes.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a44a74f0ae8a6ee6e98beb5767f9265f2b634fd8.pdf",
    "citation_key": "borrelli2023cra",
    "metadata": {
      "title": "Standardization of Body Composition Status in Patients with Advanced Urothelial Tumors: The Role of a CT-Based AI-Powered Software for the Assessment of Sarcopenia and Patient Outcome Correlation",
      "authors": [
        "Antonella Borrelli",
        "M. Pecoraro",
        "F. del Giudice",
        "Leonardo Cristofani",
        "E. Messina",
        "A. Dehghanpour",
        "N. Landini",
        "M. Roberto",
        "S. Perotti",
        "M. Muscaritoli",
        "D. Santini",
        "C. Catalano",
        "V. Panebianco"
      ],
      "published_date": "2023",
      "abstract": "Simple Summary Artificial Intelligence (AI)-driven software that utilizes Computed Tomography (CT)images has the capability to automatically assess body composition and diagnose sarcopenia. Our research indicates that combining standardized CT staging methods with sarcopenia analysis could assist in identifying patients with advanced urothelial tumors who may benefit from customized nutritional therapies, ultimately resulting in improved outcomes and quality of life. The AI tool can represent a means to increase the clinical value of CT imaging reports and to promote the development of precision medicine. Abstract Background: Sarcopenia is a well know prognostic factor in oncology, influencing patients’ quality of life and survival. We aimed to investigate the role of sarcopenia, assessed by a Computed Tomography (CT)-based artificial intelligence (AI)-powered-software, as a predictor of objective clinical benefit in advanced urothelial tumors and its correlations with oncological outcomes. Methods: We retrospectively searched patients with advanced urothelial tumors, treated with systemic platinum-based chemotherapy and an available total body CT, performed before and after therapy. An AI-powered software was applied to CT to obtain the Skeletal Muscle Index (SMI-L3), derived from the area of the psoas, long spine, and abdominal muscles, at the level of L3 on CT axial images. Logistic and Cox-regression modeling was implemented to explore the association of sarcopenic status and anthropometric features to the clinical benefit rate and survival endpoints. Results: 97 patients were included, 66 with bladder cancer and 31 with upper-tract urothelial carcinoma. Clinical benefit outcomes showed a linear positive association with all the observed body composition variables variations. The chances of not experiencing disease progression were positively associated with ∆_SMI-L3, ∆_psoas, and ∆_long spine muscle when they ranged from ~10–20% up to ~45–55%. Greater survival chances were matched by patients achieving a wider ∆_SMI-L3, ∆_abdominal and ∆_long spine muscle. Conclusions: A CT-based AI-powered software body composition and sarcopenia analysis provide prognostic assessments for objective clinical benefits and oncological outcomes.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a44a74f0ae8a6ee6e98beb5767f9265f2b634fd8.pdf",
      "venue": "Cancers",
      "citationCount": 9,
      "score": 4.5,
      "summary": "Simple Summary Artificial Intelligence (AI)-driven software that utilizes Computed Tomography (CT)images has the capability to automatically assess body composition and diagnose sarcopenia. Our research indicates that combining standardized CT staging methods with sarcopenia analysis could assist in identifying patients with advanced urothelial tumors who may benefit from customized nutritional therapies, ultimately resulting in improved outcomes and quality of life. The AI tool can represent a means to increase the clinical value of CT imaging reports and to promote the development of precision medicine. Abstract Background: Sarcopenia is a well know prognostic factor in oncology, influencing patients’ quality of life and survival. We aimed to investigate the role of sarcopenia, assessed by a Computed Tomography (CT)-based artificial intelligence (AI)-powered-software, as a predictor of objective clinical benefit in advanced urothelial tumors and its correlations with oncological outcomes. Methods: We retrospectively searched patients with advanced urothelial tumors, treated with systemic platinum-based chemotherapy and an available total body CT, performed before and after therapy. An AI-powered software was applied to CT to obtain the Skeletal Muscle Index (SMI-L3), derived from the area of the psoas, long spine, and abdominal muscles, at the level of L3 on CT axial images. Logistic and Cox-regression modeling was implemented to explore the association of sarcopenic status and anthropometric features to the clinical benefit rate and survival endpoints. Results: 97 patients were included, 66 with bladder cancer and 31 with upper-tract urothelial carcinoma. Clinical benefit outcomes showed a linear positive association with all the observed body composition variables variations. The chances of not experiencing disease progression were positively associated with ∆_SMI-L3, ∆_psoas, and ∆_long spine muscle when they ranged from ~10–20% up to ~45–55%. Greater survival chances were matched by patients achieving a wider ∆_SMI-L3, ∆_abdominal and ∆_long spine muscle. Conclusions: A CT-based AI-powered software body composition and sarcopenia analysis provide prognostic assessments for objective clinical benefits and oncological outcomes.",
      "keywords": []
    },
    "file_name": "a44a74f0ae8a6ee6e98beb5767f9265f2b634fd8.pdf"
  },
  {
    "success": true,
    "doc_id": "e90a388c8f49fede6517e269904a80cf",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/46888b9695ed5a27915e2262792cc897a054847a.pdf",
    "citation_key": "franch2023n04",
    "metadata": {
      "title": "A Requirements Engineering Perspective to AI-Based Systems Development: A Vision Paper",
      "authors": [
        "Xavier Franch",
        "Andreas Jedlitschka",
        "Silverio Martínez-Fernández"
      ],
      "published_date": "2023",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/46888b9695ed5a27915e2262792cc897a054847a.pdf",
      "venue": "Requirements Engineering: Foundation for Software Quality",
      "citationCount": 9,
      "score": 4.5,
      "summary": "",
      "keywords": []
    },
    "file_name": "46888b9695ed5a27915e2262792cc897a054847a.pdf"
  },
  {
    "success": true,
    "doc_id": "3111a2f6bb6eb7cfb688ca926d494cf8",
    "summary": "As Artificial Intelligence (AI) permeates many aspects of society, it brings numerous advantages while at the same time raising ethical concerns and potential risks, such as perpetuating inequalities through biased or discriminatory decision-making. To develop AI systems that cater for the needs of diverse users and uphold ethical values, it is essential to consider and integrate diversity and inclusion (D&I) principles throughout AI development and deployment. Requirements engineering (RE) is a fundamental process in developing software systems by eliciting and specifying relevant needs from diverse stakeholders. This research aims to address the lack of research and practice on how to elicit and capture D&I requirements for AI systems. We have conducted comprehensive data collection and synthesis from the literature review to extract requirements themes related to D&I in AI. We have proposed a tailored user story template to capture D&I requirements and conducted focus group exercises to use the themes and user story template in writing D&I requirements for two example AI systems. Additionally, we have investigated the capability of our solution by generating synthetic D&I requirements captured in user stories with the help of a Large Language Model.",
    "intriguing_abstract": "As Artificial Intelligence (AI) permeates many aspects of society, it brings numerous advantages while at the same time raising ethical concerns and potential risks, such as perpetuating inequalities through biased or discriminatory decision-making. To develop AI systems that cater for the needs of diverse users and uphold ethical values, it is essential to consider and integrate diversity and inclusion (D&I) principles throughout AI development and deployment. Requirements engineering (RE) is a fundamental process in developing software systems by eliciting and specifying relevant needs from diverse stakeholders. This research aims to address the lack of research and practice on how to elicit and capture D&I requirements for AI systems. We have conducted comprehensive data collection and synthesis from the literature review to extract requirements themes related to D&I in AI. We have proposed a tailored user story template to capture D&I requirements and conducted focus group exercises to use the themes and user story template in writing D&I requirements for two example AI systems. Additionally, we have investigated the capability of our solution by generating synthetic D&I requirements captured in user stories with the help of a Large Language Model.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f3a84c29afdf235d960986cb860e6cf34649c75b.pdf",
    "citation_key": "bano2023w7n",
    "metadata": {
      "title": "AI for All: Operationalising Diversity and Inclusion Requirements for AI Systems",
      "authors": [
        "Muneera Bano",
        "Didar Zowghi",
        "V. Gervasi",
        "R. Shams"
      ],
      "published_date": "2023",
      "abstract": "As Artificial Intelligence (AI) permeates many aspects of society, it brings numerous advantages while at the same time raising ethical concerns and potential risks, such as perpetuating inequalities through biased or discriminatory decision-making. To develop AI systems that cater for the needs of diverse users and uphold ethical values, it is essential to consider and integrate diversity and inclusion (D&I) principles throughout AI development and deployment. Requirements engineering (RE) is a fundamental process in developing software systems by eliciting and specifying relevant needs from diverse stakeholders. This research aims to address the lack of research and practice on how to elicit and capture D&I requirements for AI systems. We have conducted comprehensive data collection and synthesis from the literature review to extract requirements themes related to D&I in AI. We have proposed a tailored user story template to capture D&I requirements and conducted focus group exercises to use the themes and user story template in writing D&I requirements for two example AI systems. Additionally, we have investigated the capability of our solution by generating synthetic D&I requirements captured in user stories with the help of a Large Language Model.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f3a84c29afdf235d960986cb860e6cf34649c75b.pdf",
      "venue": "arXiv.org",
      "citationCount": 8,
      "score": 4.0,
      "summary": "As Artificial Intelligence (AI) permeates many aspects of society, it brings numerous advantages while at the same time raising ethical concerns and potential risks, such as perpetuating inequalities through biased or discriminatory decision-making. To develop AI systems that cater for the needs of diverse users and uphold ethical values, it is essential to consider and integrate diversity and inclusion (D&I) principles throughout AI development and deployment. Requirements engineering (RE) is a fundamental process in developing software systems by eliciting and specifying relevant needs from diverse stakeholders. This research aims to address the lack of research and practice on how to elicit and capture D&I requirements for AI systems. We have conducted comprehensive data collection and synthesis from the literature review to extract requirements themes related to D&I in AI. We have proposed a tailored user story template to capture D&I requirements and conducted focus group exercises to use the themes and user story template in writing D&I requirements for two example AI systems. Additionally, we have investigated the capability of our solution by generating synthetic D&I requirements captured in user stories with the help of a Large Language Model.",
      "keywords": []
    },
    "file_name": "f3a84c29afdf235d960986cb860e6cf34649c75b.pdf"
  },
  {
    "success": true,
    "doc_id": "a831e65e056e0d0e8e0a9db9bbac276a",
    "summary": "Here's a focused summary of the paper \"Towards green AI-based software systems: an architecture-centric approach (GAISSA)\" \\cite{martnezfernndez2023ipo} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the significant energy consumption and environmental footprint of AI-based systems, particularly during model training and inference, which stems from the high computational resources required by large AI models and data volumes.\n    *   **Importance and Challenge**: This problem is critical due to increasing societal demand for energy efficiency, stringent environmental regulations (e.g., EU targets for GHG emission reductions), and the dramatic growth in computing resources used for AI (e.g., 300,000x increase in DL training compute in 6 years). Current AI development primarily targets accuracy (\"red AI\"), often disregarding energy costs, leading to substantial carbon footprints (e.g., training one large ML model for autonomous vehicles equivalent to 242,231 miles driven by a passenger vehicle). The challenge lies in integrating energy efficiency (\"greenability\") into the design and development of AI systems, which current architecture-centric methods largely overlook.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon existing research in software sustainability, quality models for general software (e.g., ISO/IEC 25010 extensions with \"greenability,\" GREENSOFT model), and some initial efforts in energy-efficient AI models and architectural/design patterns for sustainability. It also acknowledges existing tools for general software energy profiling and cloud carbon footprint dashboards.\n    *   **Limitations of Previous Solutions**:\n        *   Existing software sustainability quality models do not specifically address the unique characteristics and lifecycle phases (data collection, model training, optimization) of AI-based systems.\n        *   Current approaches for energy-efficient AI models from an architectural perspective are scarce, ad-hoc, and lack transferability.\n        *   Architectural and design patterns for general software sustainability do not consider AI-based systems, and conversely, patterns for AI-based systems do not address greenability.\n        *   No current tool comprehensively supports the modelling and development cycles of AI-based systems from an energy efficiency-aware perspective, offering assessments, estimations, and what-if analysis for AI-specific choices (libraries, training, deployment architectures).\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The GAISSA project proposes an **architecture-centric approach** to provide data scientists and software engineers with tool-supported methods for the modelling and development of green AI-based systems. It focuses on understanding, defining, reporting, and managing the energy efficiency impact of architectural decisions throughout the AI engineering lifecycle, specifically during the Modelling and Development stages.\n    *   **Novelty**: The approach is novel by systematically integrating \"greenability\" as a first-class concern into the architectural design and development of AI-based systems. This involves:\n        *   Developing an AI-specific quality model for greenability.\n        *   Creating predictive models to understand how AI model design decisions affect energy efficiency.\n        *   Defining architecture and design patterns tailored for building green AI-based systems.\n        *   Developing analytic tools for greenability-driven analysis, decision-making, and reporting, including what-if analysis for different AI alternatives.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   **O1: Quality Model for Greenability of AI-based Systems**: A hierarchical structure of greenability-related quality factors, operationalized metrics, and understanding of synergies/conflicts with other qualities (e.g., accuracy, privacy).\n        *   **O2: Architecture-centric Methods for Green AI Model Training & Deployment**: Predictive models to guide sustainability-aware AI model training and context-aware measurement methods for AI platform energy consumption.\n        *   **O3: Architecture-centric Methods for Green AI-based System Development**: Identification of architectural concerns driving green design and a catalogue of architecture and design patterns for building green AI-based systems, detailing their forces and interactions.\n    *   **System Design or Architectural Innovations**: The project aims to provide a framework and catalogue of patterns that explicitly link architectural decisions to greenability outcomes in AI systems, moving beyond ad-hoc solutions.\n    *   **Theoretical Insights or Analysis**: The project hypothesizes that a better understanding and management of architectural decisions' impact on energy efficiency is crucial for delivering less computationally demanding AI-based systems.\n\n*   **Experimental Validation**\n    *   The paper states that the GAISSA project is in an initial stage. While it mentions \"current research results, which illustrate the potential to achieve GAISSA objectives,\" it explicitly notes, \"Due to space limitations, we only summarize the initial results of GAISSA. The interested reader is referred to [29] for a detailed description of the initial results.\"\n    *   Therefore, this paper *does not present detailed experimental validation or key performance metrics and comparison results itself*. It indicates that initial results include a first version of the quality model for greenability (O1) and a first version of a catalogue of architecture and design patterns for green AI-based systems (O3), with full details available in a separate publication.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The project is in its initial stages, and the full implementation and evaluation of all proposed objectives are ongoing. The paper does not detail specific technical limitations of the proposed methods themselves, but rather highlights the current gaps in the field.\n    *   **Scope of Applicability**: GAISSA focuses specifically on the **Modelling** (AI model training) and **Development** (AI model integration into software, system deployment) stages of the AI engineering lifecycle, acknowledging that these stages present unique challenges beyond traditional software engineering. It does not explicitly cover Data Management or Operation stages in detail within its current scope.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: GAISSA advances the technical state-of-the-art by proposing a comprehensive, systematic, and architecture-centric approach to address the energy efficiency of AI-based systems. It moves beyond general software sustainability to tackle the unique challenges of AI, aiming to provide concrete methods, models, patterns, and tools where current solutions are fragmented or non-existent.\n    *   **Potential Impact on Future Research**: The project has the potential to significantly impact future research by:\n        *   Establishing a foundational quality model and metrics for greenability in AI.\n        *   Guiding the development of energy-efficient AI models and platforms through predictive and context-aware methods.\n        *   Providing a catalogue of architectural and design patterns to foster the creation of greener AI-based systems.\n        *   Developing analytic tools that enable greenability-driven decision-making, fostering a shift from \"red AI\" to \"green AI\" practices in industry and academia.",
    "intriguing_abstract": "The exponential growth of AI systems comes with a staggering environmental cost, driven by immense computational demands that lead to a significant carbon footprint. Current \"red AI\" development prioritizes accuracy, largely overlooking energy efficiency and sustainability. This paper introduces GAISSA, a novel architecture-centric approach designed to systematically integrate \"greenability\" as a first-class concern into the AI engineering lifecycle. We provide data scientists and software engineers with tool-supported methods for designing and developing energy-efficient AI systems. Our key contributions include an AI-specific quality model for greenability, predictive models for sustainable AI model training and deployment, and a comprehensive catalogue of architecture and design patterns tailored for green AI-based systems. By enabling greenability-driven analysis and decision-making, GAISSA aims to shift the paradigm towards truly sustainable AI, significantly reducing the environmental impact of machine learning and fostering a future of responsible innovation.",
    "keywords": [
      "AI-based systems",
      "energy consumption",
      "environmental footprint",
      "greenability",
      "architecture-centric approach",
      "AI engineering lifecycle",
      "AI-specific quality model",
      "predictive models",
      "architecture and design patterns",
      "analytic tools",
      "computational resources",
      "Green AI",
      "carbon footprint",
      "model training and inference"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/36190a3036de35d7380d3b4789806244fa9e1476.pdf",
    "citation_key": "martnezfernndez2023ipo",
    "metadata": {
      "title": "Towards green AI-based software systems: an architecture-centric approach (GAISSA)",
      "authors": [
        "Silverio Martínez-Fernández",
        "Xavier Franch",
        "Francisco Durán"
      ],
      "published_date": "2023",
      "abstract": "Nowadays, AI-based systems have achieved outstanding results and have outperformed humans in different domains. However, the processes of training AI models and inferring from them require high computational resources, which pose a significant challenge in the current energy efficiency societal demand. To cope with this challenge, this research project paper describes the main vision, goals, and expected outcomes of the GAISSA project. The GAISSA project aims at providing data scientists and software engineers tool-supported, architecture-centric methods for the modelling and development of green AI-based systems. Although the project is in an initial stage, we describe the current research results, which illustrate the potential to achieve GAISSA objectives.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/36190a3036de35d7380d3b4789806244fa9e1476.pdf",
      "venue": "EUROMICRO Conference on Software Engineering and Advanced Applications",
      "citationCount": 8,
      "score": 4.0,
      "summary": "Here's a focused summary of the paper \"Towards green AI-based software systems: an architecture-centric approach (GAISSA)\" \\cite{martnezfernndez2023ipo} for a literature review:\n\n*   **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the significant energy consumption and environmental footprint of AI-based systems, particularly during model training and inference, which stems from the high computational resources required by large AI models and data volumes.\n    *   **Importance and Challenge**: This problem is critical due to increasing societal demand for energy efficiency, stringent environmental regulations (e.g., EU targets for GHG emission reductions), and the dramatic growth in computing resources used for AI (e.g., 300,000x increase in DL training compute in 6 years). Current AI development primarily targets accuracy (\"red AI\"), often disregarding energy costs, leading to substantial carbon footprints (e.g., training one large ML model for autonomous vehicles equivalent to 242,231 miles driven by a passenger vehicle). The challenge lies in integrating energy efficiency (\"greenability\") into the design and development of AI systems, which current architecture-centric methods largely overlook.\n\n*   **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: The work builds upon existing research in software sustainability, quality models for general software (e.g., ISO/IEC 25010 extensions with \"greenability,\" GREENSOFT model), and some initial efforts in energy-efficient AI models and architectural/design patterns for sustainability. It also acknowledges existing tools for general software energy profiling and cloud carbon footprint dashboards.\n    *   **Limitations of Previous Solutions**:\n        *   Existing software sustainability quality models do not specifically address the unique characteristics and lifecycle phases (data collection, model training, optimization) of AI-based systems.\n        *   Current approaches for energy-efficient AI models from an architectural perspective are scarce, ad-hoc, and lack transferability.\n        *   Architectural and design patterns for general software sustainability do not consider AI-based systems, and conversely, patterns for AI-based systems do not address greenability.\n        *   No current tool comprehensively supports the modelling and development cycles of AI-based systems from an energy efficiency-aware perspective, offering assessments, estimations, and what-if analysis for AI-specific choices (libraries, training, deployment architectures).\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The GAISSA project proposes an **architecture-centric approach** to provide data scientists and software engineers with tool-supported methods for the modelling and development of green AI-based systems. It focuses on understanding, defining, reporting, and managing the energy efficiency impact of architectural decisions throughout the AI engineering lifecycle, specifically during the Modelling and Development stages.\n    *   **Novelty**: The approach is novel by systematically integrating \"greenability\" as a first-class concern into the architectural design and development of AI-based systems. This involves:\n        *   Developing an AI-specific quality model for greenability.\n        *   Creating predictive models to understand how AI model design decisions affect energy efficiency.\n        *   Defining architecture and design patterns tailored for building green AI-based systems.\n        *   Developing analytic tools for greenability-driven analysis, decision-making, and reporting, including what-if analysis for different AI alternatives.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques**:\n        *   **O1: Quality Model for Greenability of AI-based Systems**: A hierarchical structure of greenability-related quality factors, operationalized metrics, and understanding of synergies/conflicts with other qualities (e.g., accuracy, privacy).\n        *   **O2: Architecture-centric Methods for Green AI Model Training & Deployment**: Predictive models to guide sustainability-aware AI model training and context-aware measurement methods for AI platform energy consumption.\n        *   **O3: Architecture-centric Methods for Green AI-based System Development**: Identification of architectural concerns driving green design and a catalogue of architecture and design patterns for building green AI-based systems, detailing their forces and interactions.\n    *   **System Design or Architectural Innovations**: The project aims to provide a framework and catalogue of patterns that explicitly link architectural decisions to greenability outcomes in AI systems, moving beyond ad-hoc solutions.\n    *   **Theoretical Insights or Analysis**: The project hypothesizes that a better understanding and management of architectural decisions' impact on energy efficiency is crucial for delivering less computationally demanding AI-based systems.\n\n*   **Experimental Validation**\n    *   The paper states that the GAISSA project is in an initial stage. While it mentions \"current research results, which illustrate the potential to achieve GAISSA objectives,\" it explicitly notes, \"Due to space limitations, we only summarize the initial results of GAISSA. The interested reader is referred to [29] for a detailed description of the initial results.\"\n    *   Therefore, this paper *does not present detailed experimental validation or key performance metrics and comparison results itself*. It indicates that initial results include a first version of the quality model for greenability (O1) and a first version of a catalogue of architecture and design patterns for green AI-based systems (O3), with full details available in a separate publication.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations/Assumptions**: The project is in its initial stages, and the full implementation and evaluation of all proposed objectives are ongoing. The paper does not detail specific technical limitations of the proposed methods themselves, but rather highlights the current gaps in the field.\n    *   **Scope of Applicability**: GAISSA focuses specifically on the **Modelling** (AI model training) and **Development** (AI model integration into software, system deployment) stages of the AI engineering lifecycle, acknowledging that these stages present unique challenges beyond traditional software engineering. It does not explicitly cover Data Management or Operation stages in detail within its current scope.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: GAISSA advances the technical state-of-the-art by proposing a comprehensive, systematic, and architecture-centric approach to address the energy efficiency of AI-based systems. It moves beyond general software sustainability to tackle the unique challenges of AI, aiming to provide concrete methods, models, patterns, and tools where current solutions are fragmented or non-existent.\n    *   **Potential Impact on Future Research**: The project has the potential to significantly impact future research by:\n        *   Establishing a foundational quality model and metrics for greenability in AI.\n        *   Guiding the development of energy-efficient AI models and platforms through predictive and context-aware methods.\n        *   Providing a catalogue of architectural and design patterns to foster the creation of greener AI-based systems.\n        *   Developing analytic tools that enable greenability-driven decision-making, fostering a shift from \"red AI\" to \"green AI\" practices in industry and academia.",
      "keywords": [
        "AI-based systems",
        "energy consumption",
        "environmental footprint",
        "greenability",
        "architecture-centric approach",
        "AI engineering lifecycle",
        "AI-specific quality model",
        "predictive models",
        "architecture and design patterns",
        "analytic tools",
        "computational resources",
        "Green AI",
        "carbon footprint",
        "model training and inference"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the paper identifies a significant challenge: high computational resources for ai models and the demand for energy efficiency.\n*   it then describes the \"main vision, goals, and expected outcomes of the gaissa project.\"\n*   the gaissa project \"aims at providing data scientists and software engineers tool-supported, architecture-centric methods for the modelling and development of green ai-based systems.\"\n*   it explicitly states, \"although the project is in an initial stage, we describe the current research results, which illustrate the potential to achieve gaissa objectives.\"\n\nthis content strongly aligns with the **position** paper criteria:\n*   it discusses \"current problems\" (energy efficiency of ai).\n*   it outlines a \"proposed direction\" or \"vision\" (the gaissa project and its architecture-centric approach).\n*   it argues for the \"potential\" of this approach, even in its initial stage.\n\nit is not a survey, a fully developed technical paper (as it's in an initial stage), a theoretical analysis, an empirical study, or a case study. while it might be a \"short\" paper due to its preliminary nature, \"position\" better describes its *content* and *purpose*.\n\n**classification: position**"
    },
    "file_name": "36190a3036de35d7380d3b4789806244fa9e1476.pdf"
  },
  {
    "success": true,
    "doc_id": "2b6b2ec6144e2b9e3b3f84d23e5081ea",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/7f6d4cb05ca1df98be23b132715af468354b7451.pdf",
    "citation_key": "solohubov2023z0z",
    "metadata": {
      "title": "Accelerating software development with AI: exploring the impact of ChatGPT and GitHub Copilot",
      "authors": [
        "Illia Solohubov",
        "Artur Moroz",
        "M. Tiahunova",
        "H. Kyrychek",
        "Stepan Skrupsky"
      ],
      "published_date": "2023",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/7f6d4cb05ca1df98be23b132715af468354b7451.pdf",
      "venue": "CTE",
      "citationCount": 7,
      "score": 3.5,
      "summary": "",
      "keywords": []
    },
    "file_name": "7f6d4cb05ca1df98be23b132715af468354b7451.pdf"
  },
  {
    "success": true,
    "doc_id": "f97c7fb03937c8576d70207f1b2f2dfb",
    "summary": "Recently, AI software has been rapidly growing and is widely used in various industrial domains, such as finance, medicine, robotics, and autonomous driving. Unlike traditional software, in which developers need to define and implement specific functions and rules according to requirements, AI software learns these requirements by collecting and training relevant data. For this reason, if unintended biases exist in the training data, AI software can create fairness and safety issues. To address this challenge, we propose a maturity model for ensuring trustworthy and reliable AI software, known as AI-MM, by considering common AI processes and fairness-specific processes within a traditional maturity model, SPICE (ISO/IEC 15504). To verify the effectiveness of AI-MM, we applied this model to 13 real-world AI projects and provide a statistical assessment on them. The results show that AI-MM not only effectively measures the maturity levels of AI projects but also provides practical guidelines for enhancing maturity levels.",
    "intriguing_abstract": "Recently, AI software has been rapidly growing and is widely used in various industrial domains, such as finance, medicine, robotics, and autonomous driving. Unlike traditional software, in which developers need to define and implement specific functions and rules according to requirements, AI software learns these requirements by collecting and training relevant data. For this reason, if unintended biases exist in the training data, AI software can create fairness and safety issues. To address this challenge, we propose a maturity model for ensuring trustworthy and reliable AI software, known as AI-MM, by considering common AI processes and fairness-specific processes within a traditional maturity model, SPICE (ISO/IEC 15504). To verify the effectiveness of AI-MM, we applied this model to 13 real-world AI projects and provide a statistical assessment on them. The results show that AI-MM not only effectively measures the maturity levels of AI projects but also provides practical guidelines for enhancing maturity levels.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/143b7f6d594c1678a229591ec6918eeab0e25f0c.pdf",
    "citation_key": "cho2023v8k",
    "metadata": {
      "title": "A Maturity Model for Trustworthy AI Software Development",
      "authors": [
        "Seunghwan Cho",
        "Ingyu Kim",
        "Jinhan Kim",
        "Honguk Woo",
        "Wanseon Shin"
      ],
      "published_date": "2023",
      "abstract": "Recently, AI software has been rapidly growing and is widely used in various industrial domains, such as finance, medicine, robotics, and autonomous driving. Unlike traditional software, in which developers need to define and implement specific functions and rules according to requirements, AI software learns these requirements by collecting and training relevant data. For this reason, if unintended biases exist in the training data, AI software can create fairness and safety issues. To address this challenge, we propose a maturity model for ensuring trustworthy and reliable AI software, known as AI-MM, by considering common AI processes and fairness-specific processes within a traditional maturity model, SPICE (ISO/IEC 15504). To verify the effectiveness of AI-MM, we applied this model to 13 real-world AI projects and provide a statistical assessment on them. The results show that AI-MM not only effectively measures the maturity levels of AI projects but also provides practical guidelines for enhancing maturity levels.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/143b7f6d594c1678a229591ec6918eeab0e25f0c.pdf",
      "venue": "Applied Sciences",
      "citationCount": 7,
      "score": 3.5,
      "summary": "Recently, AI software has been rapidly growing and is widely used in various industrial domains, such as finance, medicine, robotics, and autonomous driving. Unlike traditional software, in which developers need to define and implement specific functions and rules according to requirements, AI software learns these requirements by collecting and training relevant data. For this reason, if unintended biases exist in the training data, AI software can create fairness and safety issues. To address this challenge, we propose a maturity model for ensuring trustworthy and reliable AI software, known as AI-MM, by considering common AI processes and fairness-specific processes within a traditional maturity model, SPICE (ISO/IEC 15504). To verify the effectiveness of AI-MM, we applied this model to 13 real-world AI projects and provide a statistical assessment on them. The results show that AI-MM not only effectively measures the maturity levels of AI projects but also provides practical guidelines for enhancing maturity levels.",
      "keywords": []
    },
    "file_name": "143b7f6d594c1678a229591ec6918eeab0e25f0c.pdf"
  },
  {
    "success": true,
    "doc_id": "3f23fe113e4d052fbf279d8170f3a697",
    "summary": "COPYRIGHT © 2023 Sendak, Vidal, Trujillo, Singh, Liu and Balu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.",
    "intriguing_abstract": "COPYRIGHT © 2023 Sendak, Vidal, Trujillo, Singh, Liu and Balu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/4c98730b6852c76f7a7da9c1f322c60dd6ff109e.pdf",
    "citation_key": "sendak202397c",
    "metadata": {
      "title": "Editorial: Surfacing best practices for AI software development and integration in healthcare",
      "authors": [
        "M. Sendak",
        "D. Vidal",
        "Sylvia Trujillo",
        "Karandeep Singh",
        "Xiaoxuan Liu",
        "S. Balu"
      ],
      "published_date": "2023",
      "abstract": "COPYRIGHT © 2023 Sendak, Vidal, Trujillo, Singh, Liu and Balu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/4c98730b6852c76f7a7da9c1f322c60dd6ff109e.pdf",
      "venue": "Frontiers in Digital Health",
      "citationCount": 7,
      "score": 3.5,
      "summary": "COPYRIGHT © 2023 Sendak, Vidal, Trujillo, Singh, Liu and Balu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.",
      "keywords": []
    },
    "file_name": "4c98730b6852c76f7a7da9c1f322c60dd6ff109e.pdf"
  },
  {
    "success": true,
    "doc_id": "55f0751e24589afaffe39d1c728c84fd",
    "summary": "This paper, \\cite{jalil2023zqc}, presents a systematic literature review and survey on the transformative influence of Large Language Models (LLMs) on software development and developer productivity.\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the need for a systematic understanding of the profound impact of generalized LLMs, particularly as AI Pair Programming Assistants, on the software engineering domain. It aims to identify both the potential benefits and the critical challenges and open problems arising from their adoption.\n    *   **Importance & Challenge:** LLMs have significantly altered daily software development activities, offering advantages in task expedition. However, their rapid integration introduces pressing concerns regarding data privacy, bias, misinformation, and usability challenges such as prompt engineering, increased cognitive demands, and developer mistrust. A comprehensive analysis is crucial to guide the responsible and effective development and deployment of AI tools in software engineering.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work synthesizes existing research that has continuously evaluated AI Pair Programmers, identifying their performance, best practices, risks, and usability factors. It acknowledges documented benefits like easy execution of routine tasks, boilerplate code generation, refactoring, and unit test generation \\cite{jalil2023zqc}.\n    *   **Limitations of Previous Solutions (as identified by the survey):**\n        *   **Data Quality & Bias:** LLM performance is highly dependent on training data quality, which is often publicly sourced and can be questionable, vulnerable, or lead to biased outputs \\cite{jalil2023zqc}.\n        *   **Unpredictability & Context Limitations:** LLMs can produce varying outputs for identical prompts and often struggle to incorporate the broader codebase context due to inherent context limits, fostering developer mistrust \\cite{jalil2023zqc}.\n        *   **Privacy Concerns:** Developers express concerns about the potential for public exposure of their software system internals when using LLMs \\cite{jalil2023zqc}.\n        *   **Testing Challenges:** The non-deterministic nature of LLMs poses significant challenges for evaluation using traditional deterministic test cases \\cite{jalil2023zqc}.\n        *   **Usability & Interaction:** Earlier AI Pair Programmers often had fixed interaction features, limiting developer control and lacking capabilities for query disambiguation and refinement \\cite{jalil2023zqc}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper employs a systematic literature review methodology, structured in four stages: Definition, Search, Selection, and Analysis. This involves curating scholarly publications from Software Engineering (SE), Generative AI, and Human-Computer Interaction (HCI) domains, prioritizing user studies and empirical research, and applying thematic analysis with an open-coding approach to extract key themes and patterns.\n    *   **Novelty/Difference:** The primary innovation lies in the *systematic and comprehensive synthesis* of existing knowledge, specifically focusing on developer perspectives and usability concerns. It introduces a *novel classification paradigm* comprising 11 categories and 53 subcategories to evaluate the multifaceted influence of AI tools across SE, ML, and HCI domains, presented as a robust metric for guiding future research.\n\n4.  **Key Technical Contributions**\n    *   **Novel Methods/Techniques:**\n        *   A systematic literature review methodology specifically designed to analyze the impact of LLMs on software development, integrating insights from scholarly articles, developer surveys, and industry blogs.\n        *   The application of thematic analysis and open-coding to synthesize diverse findings into coherent themes and patterns.\n    *   **Theoretical Insights/Analysis:**\n        *   Development of a novel, robust classification scheme (11 categories, 53 subcategories) for evaluating factors influencing software development with AI tools, covering aspects from source of assistance and SDLC steps to cognitive factors and developer knowledge levels \\cite{jalil2023zqc}.\n        *   Identification of a comprehensive set of benefits, limitations, and usability challenges associated with AI Pair Programmers.\n        *   Introduction of 12 open problems derived from the survey findings, providing a structured roadmap for future research in this evolving field.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The paper itself is a systematic literature review and does not conduct new empirical experiments. Its \"validation\" stems from the rigorous methodology of its review process. It systematically reviewed 23 distinct publications (conference proceedings, journal articles) and integrated findings from developer surveys and industry articles (Tables I and II).\n    *   **Key Performance Metrics & Comparison Results (as reported from reviewed literature):** The paper reports on findings from the reviewed literature regarding LLM performance and impact. For instance, it notes that LLMs can:\n        *   Expedite numerous software development tasks, leading to significant time and effort savings \\cite{jalil2023zqc}.\n        *   Aid in drafting concise user stories and generating test cases, potentially identifying missed test domains \\cite{jalil2023zqc}.\n        *   Synthesize, modify, refactor, and translate code across programming languages \\cite{jalil2023zqc}.\n        *   However, it also highlights issues such as the production of non-compilable code and inaccurate outputs, often attributed to a focus on local context rather than broader project context \\cite{jalil2023zqc}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions (of the survey itself):**\n        *   The review was conducted by a single author, which, despite a systematic methodology, might introduce some bias in selection and interpretation.\n        *   The scope of publications was limited to those from 2015 onwards and prioritized highly cited or reputed works, potentially overlooking some niche but relevant research.\n        *   The findings are based on existing literature and do not include new empirical data collected directly from developers.\n    *   **Scope of Applicability:** The findings are primarily applicable to the domain of software engineering, specifically concerning the adoption and impact of generalized LLMs and specialized AI Pair Programming tools. It covers various stages of the Software Development Life Cycle (SDLC) and different aspects of developer interaction and productivity.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This paper significantly advances the understanding of the current state-of-the-art by providing a structured, comprehensive overview of the benefits, challenges, and usability concerns of LLMs in software development. The proposed novel classification scheme offers a valuable analytical framework for future studies.\n    *   **Potential Impact on Future Research:** By clearly delineating existing open problems (e.g., addressing data privacy, mitigating bias, improving context awareness, enhancing prompt engineering, and developing robust testing methodologies for non-deterministic AI), the paper provides a critical roadmap for researchers, toolmakers, and practitioners. It emphasizes the need for rigorous research to align AI tools with developer thought processes, fostering the development of more effective, trustworthy, and user-centric AI tools for software engineering.",
    "intriguing_abstract": "The advent of Large Language Models (LLMs) is profoundly reshaping the landscape of software development, promising unprecedented boosts in developer productivity. Yet, this transformative potential is shadowed by a complex array of challenges. This systematic literature review comprehensively synthesizes the multifaceted influence of LLMs, particularly as AI Pair Programming Assistants, on software engineering.\n\nWe introduce a novel classification paradigm comprising 11 categories and 53 subcategories, offering a robust framework to evaluate AI tool integration across SE, ML, and HCI domains. Our analysis uncovers significant benefits, from expediting routine tasks and boilerplate generation to refactoring and unit test creation. Crucially, it illuminates pressing concerns regarding data privacy, inherent biases, context limitations, prompt engineering complexities, increased cognitive load, and developer mistrust. From these insights, we delineate 12 critical open problems, providing a structured roadmap for future research. This paper serves as an essential guide for researchers and practitioners, fostering the responsible development of trustworthy, user-centric AI tools that truly align with developer needs in the evolving era of AI-augmented software engineering.",
    "keywords": [
      "Large Language Models (LLMs)",
      "AI Pair Programming Assistants",
      "software development",
      "developer productivity",
      "systematic literature review",
      "novel classification paradigm",
      "LLM benefits and limitations",
      "prompt engineering",
      "data privacy and bias",
      "context limitations",
      "usability challenges",
      "open problems",
      "thematic analysis",
      "non-deterministic AI testing"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/0f6b627a7cb0d31b182fc3c4b512d1e2a036a66b.pdf",
    "citation_key": "jalil2023zqc",
    "metadata": {
      "title": "The Transformative Influence of LLMs on Software Development & Developer Productivity",
      "authors": [
        "Sajed Jalil"
      ],
      "published_date": "2023",
      "abstract": "The increasing adoption and commercialization of generalized Large Language Models (LLMs) have profoundly impacted various aspects of our daily lives. Initially embraced by the computer science community, the versatility of LLMs has found its way into diverse domains. In particular, the software engineering realm has seen the most transformative changes. With LLMs increasingly serving as AI Pair Programming Assistants spurred the development of specialized models aimed at aiding software engineers. Although this new paradigm offers numerous advantages, it presents critical challenges and open problems.To identify the potential and prevailing obstacles, we systematically reviewed contemporary scholarly publications, emphasizing the perspectives of software developers and usability concerns. Preliminary findings underscore pressing concerns about data privacy, bias, and misinformation. Additionally, we identified several usability challenges, including prompt engineering, increased cognitive demands, and mistrust. Finally, we introduce 12 open problems identified through our survey, covering these domains.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/0f6b627a7cb0d31b182fc3c4b512d1e2a036a66b.pdf",
      "venue": "2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)",
      "citationCount": 7,
      "score": 3.5,
      "summary": "This paper, \\cite{jalil2023zqc}, presents a systematic literature review and survey on the transformative influence of Large Language Models (LLMs) on software development and developer productivity.\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the need for a systematic understanding of the profound impact of generalized LLMs, particularly as AI Pair Programming Assistants, on the software engineering domain. It aims to identify both the potential benefits and the critical challenges and open problems arising from their adoption.\n    *   **Importance & Challenge:** LLMs have significantly altered daily software development activities, offering advantages in task expedition. However, their rapid integration introduces pressing concerns regarding data privacy, bias, misinformation, and usability challenges such as prompt engineering, increased cognitive demands, and developer mistrust. A comprehensive analysis is crucial to guide the responsible and effective development and deployment of AI tools in software engineering.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work synthesizes existing research that has continuously evaluated AI Pair Programmers, identifying their performance, best practices, risks, and usability factors. It acknowledges documented benefits like easy execution of routine tasks, boilerplate code generation, refactoring, and unit test generation \\cite{jalil2023zqc}.\n    *   **Limitations of Previous Solutions (as identified by the survey):**\n        *   **Data Quality & Bias:** LLM performance is highly dependent on training data quality, which is often publicly sourced and can be questionable, vulnerable, or lead to biased outputs \\cite{jalil2023zqc}.\n        *   **Unpredictability & Context Limitations:** LLMs can produce varying outputs for identical prompts and often struggle to incorporate the broader codebase context due to inherent context limits, fostering developer mistrust \\cite{jalil2023zqc}.\n        *   **Privacy Concerns:** Developers express concerns about the potential for public exposure of their software system internals when using LLMs \\cite{jalil2023zqc}.\n        *   **Testing Challenges:** The non-deterministic nature of LLMs poses significant challenges for evaluation using traditional deterministic test cases \\cite{jalil2023zqc}.\n        *   **Usability & Interaction:** Earlier AI Pair Programmers often had fixed interaction features, limiting developer control and lacking capabilities for query disambiguation and refinement \\cite{jalil2023zqc}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method:** The paper employs a systematic literature review methodology, structured in four stages: Definition, Search, Selection, and Analysis. This involves curating scholarly publications from Software Engineering (SE), Generative AI, and Human-Computer Interaction (HCI) domains, prioritizing user studies and empirical research, and applying thematic analysis with an open-coding approach to extract key themes and patterns.\n    *   **Novelty/Difference:** The primary innovation lies in the *systematic and comprehensive synthesis* of existing knowledge, specifically focusing on developer perspectives and usability concerns. It introduces a *novel classification paradigm* comprising 11 categories and 53 subcategories to evaluate the multifaceted influence of AI tools across SE, ML, and HCI domains, presented as a robust metric for guiding future research.\n\n4.  **Key Technical Contributions**\n    *   **Novel Methods/Techniques:**\n        *   A systematic literature review methodology specifically designed to analyze the impact of LLMs on software development, integrating insights from scholarly articles, developer surveys, and industry blogs.\n        *   The application of thematic analysis and open-coding to synthesize diverse findings into coherent themes and patterns.\n    *   **Theoretical Insights/Analysis:**\n        *   Development of a novel, robust classification scheme (11 categories, 53 subcategories) for evaluating factors influencing software development with AI tools, covering aspects from source of assistance and SDLC steps to cognitive factors and developer knowledge levels \\cite{jalil2023zqc}.\n        *   Identification of a comprehensive set of benefits, limitations, and usability challenges associated with AI Pair Programmers.\n        *   Introduction of 12 open problems derived from the survey findings, providing a structured roadmap for future research in this evolving field.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted:** The paper itself is a systematic literature review and does not conduct new empirical experiments. Its \"validation\" stems from the rigorous methodology of its review process. It systematically reviewed 23 distinct publications (conference proceedings, journal articles) and integrated findings from developer surveys and industry articles (Tables I and II).\n    *   **Key Performance Metrics & Comparison Results (as reported from reviewed literature):** The paper reports on findings from the reviewed literature regarding LLM performance and impact. For instance, it notes that LLMs can:\n        *   Expedite numerous software development tasks, leading to significant time and effort savings \\cite{jalil2023zqc}.\n        *   Aid in drafting concise user stories and generating test cases, potentially identifying missed test domains \\cite{jalil2023zqc}.\n        *   Synthesize, modify, refactor, and translate code across programming languages \\cite{jalil2023zqc}.\n        *   However, it also highlights issues such as the production of non-compilable code and inaccurate outputs, often attributed to a focus on local context rather than broader project context \\cite{jalil2023zqc}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations/Assumptions (of the survey itself):**\n        *   The review was conducted by a single author, which, despite a systematic methodology, might introduce some bias in selection and interpretation.\n        *   The scope of publications was limited to those from 2015 onwards and prioritized highly cited or reputed works, potentially overlooking some niche but relevant research.\n        *   The findings are based on existing literature and do not include new empirical data collected directly from developers.\n    *   **Scope of Applicability:** The findings are primarily applicable to the domain of software engineering, specifically concerning the adoption and impact of generalized LLMs and specialized AI Pair Programming tools. It covers various stages of the Software Development Life Cycle (SDLC) and different aspects of developer interaction and productivity.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art:** This paper significantly advances the understanding of the current state-of-the-art by providing a structured, comprehensive overview of the benefits, challenges, and usability concerns of LLMs in software development. The proposed novel classification scheme offers a valuable analytical framework for future studies.\n    *   **Potential Impact on Future Research:** By clearly delineating existing open problems (e.g., addressing data privacy, mitigating bias, improving context awareness, enhancing prompt engineering, and developing robust testing methodologies for non-deterministic AI), the paper provides a critical roadmap for researchers, toolmakers, and practitioners. It emphasizes the need for rigorous research to align AI tools with developer thought processes, fostering the development of more effective, trustworthy, and user-centric AI tools for software engineering.",
      "keywords": [
        "Large Language Models (LLMs)",
        "AI Pair Programming Assistants",
        "software development",
        "developer productivity",
        "systematic literature review",
        "novel classification paradigm",
        "LLM benefits and limitations",
        "prompt engineering",
        "data privacy and bias",
        "context limitations",
        "usability challenges",
        "open problems",
        "thematic analysis",
        "non-deterministic AI testing"
      ],
      "paper_type": "based on the abstract and introduction, this paper is a **survey**.\n\nhere's why:\n\n*   **abstract:** explicitly states, \"we systematically reviewed contemporary scholarly publications...\" and \"preliminary findings underscore pressing concerns... additionally, we identified several usability challenges...\" these are findings *from* a review of existing literature.\n*   **introduction:** explicitly states, \"finally, we introduce 12 open problems identified through our survey, covering these domains.\"\n*   **index terms:** includes \"survey\" as an index term.\n*   **classification criteria match:** this aligns perfectly with the \"survey\" criteria: \"reviews existing literature comprehensively\" and \"introduction discusses: literature organization, classification schemes\" (implied by identifying problems and challenges from existing work)."
    },
    "file_name": "0f6b627a7cb0d31b182fc3c4b512d1e2a036a66b.pdf"
  },
  {
    "success": true,
    "doc_id": "5c6568b4f145c2873c0934764c4f8c24",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   This paper addresses the critical question of how the rise of powerful AI tools, particularly Large Language Models (LLMs), will impact the role of human programmers \\cite{alves2023ao6}. It frames this as a potential \"Deep Blue vs. Gary Kasparov moment\" for programming, where AI might replace human effort.\n    *   The problem is important due to the central role of programming in the digital economy and the increasing capabilities of AI in code generation. It's challenging to define an optimal human-AI interaction model that leverages AI's strengths without diminishing human creativity and oversight \\cite{alves2023ao6}.\n\n*   **2. Related Work & Positioning**\n    *   The work is positioned by drawing a direct analogy to \"Centaur Chess\" (or \"Advanced Chess\"), where mixed teams of humans and AI were found to be more effective than AI alone in chess tournaments \\cite{alves2023ao6}.\n    *   It relates to existing LLM-based programming tools like GPT-3 and GitHub Copilot, acknowledging their effectiveness in certain tasks \\cite{alves2023ao6}.\n    *   Limitations of previous solutions include:\n        *   The assumption that AI alone will be superior, which is challenged by the Centaur Chess analogy \\cite{alves2023ao6}.\n        *   The common \"query model\" of using AI tools (e.g., asking ChatGPT like Stack Overflow) is deemed inefficient, as it underutilizes AI's potential for deeper collaboration and still requires extensive human input \\cite{alves2023ao6}.\n\n*   **3. Technical Approach & Innovation**\n    *   The core technical approach is the introduction of the \"Centaur Programmer\" paradigm, advocating for a collaborative human-AI model in software development where humans augment their abilities with AI \\cite{alves2023ao6}.\n    *   The approach is novel in proposing specific, distinct collaboration models beyond simple code generation or query-response:\n        *   **Guidance Model:** The programmer defines objectives and constraints, and the AI proposes solutions that the programmer then validates and evolves \\cite{alves2023ao6}.\n        *   **Sketch Model:** The programmer outlines the program's structure, and the AI fills in the details, aiming for a more holistic understanding than current function-level tools \\cite{alves2023ao6}.\n        *   **Inverted Control Model:** The AI actively queries the programmer to understand goals and constraints before proceeding with implementation \\cite{alves2023ao6}.\n    *   This approach innovates by shifting the focus from AI as a replacement or a simple query tool to AI as an integrated, collaborative partner.\n\n*   **4. Key Technical Contributions**\n    *   **Novel methods/techniques:** The primary contribution is the conceptual framework of the \"Centaur Programmer\" and the articulation of novel human-AI collaboration models (Guidance, Sketch, Inverted Control) specifically tailored for software development \\cite{alves2023ao6}.\n    *   **Theoretical insights:** It provides a theoretical argument for the synergistic superiority of human-AI teams over either component alone, drawing a compelling parallel from the domain of chess \\cite{alves2023ao6}.\n\n*   **5. Experimental Validation**\n    *   The paper is a position paper and **does not present new experimental validation** of the proposed Centaur Programmer models \\cite{alves2023ao6}.\n    *   It relies on the historical results of Centaur Chess tournaments as an empirical analogy to support its core premise \\cite{alves2023ao6}.\n    *   It references existing studies on the effectiveness of LLM-based tools in programming tasks (e.g., GPT-3's ability to solve exercises, GitHub Copilot's impact on productivity) but does not conduct its own experiments or provide new performance metrics \\cite{alves2023ao6}.\n\n*   **6. Limitations & Scope**\n    *   **Technical limitations:** The proposed collaboration models are conceptual and lack empirical validation within the software development context by the authors \\cite{alves2023ao6}. The core argument heavily relies on an analogy (Centaur Chess) whose direct applicability to the complexities of software development is assumed.\n    *   **Scope of applicability:** The paper's scope is broad, encompassing the future of software development practices, the necessary evolution of university curricula to train \"centaur programmers,\" and the legal/ethical implications of human-AI collaboration in programming \\cite{alves2023ao6}.\n\n*   **7. Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a structured conceptual framework for human-AI collaboration in programming, moving beyond the binary \"replacement vs. no replacement\" debate \\cite{alves2023ao6}. It introduces concrete models for interaction that can guide future tool development.\n    *   Its potential impact on future research is substantial, encouraging:\n        *   The design and implementation of new AI programming tools that explicitly support the proposed collaborative models.\n        *   Research into optimal human-computer interaction (HCI) patterns for augmented programming environments.\n        *   Development of new software engineering methodologies that integrate these collaborative AI roles.\n        *   Further investigation into the ethical and legal frameworks required for AI-assisted code generation, particularly regarding human responsibility for AI-produced content \\cite{alves2023ao6}.",
    "intriguing_abstract": "As powerful Large Language Models (LLMs) redefine code generation, the programming world faces its 'Deep Blue vs. Kasparov' moment: will AI replace human programmers? This paper challenges the prevailing assumption of AI supremacy, drawing a compelling analogy from 'Centaur Chess' where human-AI teams consistently outperform either component alone. We introduce the novel **Centaur Programmer** paradigm, advocating for a synergistic human-AI collaboration model in software development that moves beyond inefficient query-response interactions. Our core contribution lies in articulating three distinct, innovative collaboration models: the **Guidance Model**, where AI proposes solutions to human-defined objectives; the **Sketch Model**, where AI fills in details of human-outlined structures; and the **Inverted Control Model**, where AI actively queries programmers for clarity. This framework offers a transformative vision for the future of programming, guiding the design of next-generation AI tools, fostering advanced human-computer interaction, and shaping software engineering methodologies. It redefines the role of the programmer from a potential replacement to an augmented, indispensable partner, unlocking unprecedented productivity and creativity in the digital economy.",
    "keywords": [
      "Large Language Models (LLMs)",
      "Centaur Programmer paradigm",
      "human-AI collaboration models",
      "Guidance Model",
      "Sketch Model",
      "Inverted Control Model",
      "software development",
      "code generation",
      "Centaur Chess analogy",
      "synergistic human-AI teams",
      "position paper",
      "lack of empirical validation",
      "AI programming tools",
      "human-computer interaction (HCI)"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2280a192eaf49c66cf539269e9b7958b6f412cfb.pdf",
    "citation_key": "alves2023ao6",
    "metadata": {
      "title": "The centaur programmer - How Kasparov's Advanced Chess spans over to the software development of the future",
      "authors": [
        "P. Alves",
        "Bruno Pereira Cipriano"
      ],
      "published_date": "2023",
      "abstract": "We introduce the idea of Centaur Programmer, based on the premise that a collaborative approach between humans and AI will be more effective than AI alone, as demonstrated in centaur chess tournaments where mixed teams of humans and AI beat sole computers. The paper introduces several collaboration models for programming alongside an AI, including the guidance model, the sketch model, and the inverted control model, and suggests that universities should prepare future programmers for a more efficient and productive programming environment augmented with AI. We hope to contribute to the important discussion about the diverse ways whereby humans and AI can work together in programming in the next decade, how universities should handle these changes and some legal implications surrounding this topic.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2280a192eaf49c66cf539269e9b7958b6f412cfb.pdf",
      "venue": "arXiv.org",
      "citationCount": 7,
      "score": 3.5,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   This paper addresses the critical question of how the rise of powerful AI tools, particularly Large Language Models (LLMs), will impact the role of human programmers \\cite{alves2023ao6}. It frames this as a potential \"Deep Blue vs. Gary Kasparov moment\" for programming, where AI might replace human effort.\n    *   The problem is important due to the central role of programming in the digital economy and the increasing capabilities of AI in code generation. It's challenging to define an optimal human-AI interaction model that leverages AI's strengths without diminishing human creativity and oversight \\cite{alves2023ao6}.\n\n*   **2. Related Work & Positioning**\n    *   The work is positioned by drawing a direct analogy to \"Centaur Chess\" (or \"Advanced Chess\"), where mixed teams of humans and AI were found to be more effective than AI alone in chess tournaments \\cite{alves2023ao6}.\n    *   It relates to existing LLM-based programming tools like GPT-3 and GitHub Copilot, acknowledging their effectiveness in certain tasks \\cite{alves2023ao6}.\n    *   Limitations of previous solutions include:\n        *   The assumption that AI alone will be superior, which is challenged by the Centaur Chess analogy \\cite{alves2023ao6}.\n        *   The common \"query model\" of using AI tools (e.g., asking ChatGPT like Stack Overflow) is deemed inefficient, as it underutilizes AI's potential for deeper collaboration and still requires extensive human input \\cite{alves2023ao6}.\n\n*   **3. Technical Approach & Innovation**\n    *   The core technical approach is the introduction of the \"Centaur Programmer\" paradigm, advocating for a collaborative human-AI model in software development where humans augment their abilities with AI \\cite{alves2023ao6}.\n    *   The approach is novel in proposing specific, distinct collaboration models beyond simple code generation or query-response:\n        *   **Guidance Model:** The programmer defines objectives and constraints, and the AI proposes solutions that the programmer then validates and evolves \\cite{alves2023ao6}.\n        *   **Sketch Model:** The programmer outlines the program's structure, and the AI fills in the details, aiming for a more holistic understanding than current function-level tools \\cite{alves2023ao6}.\n        *   **Inverted Control Model:** The AI actively queries the programmer to understand goals and constraints before proceeding with implementation \\cite{alves2023ao6}.\n    *   This approach innovates by shifting the focus from AI as a replacement or a simple query tool to AI as an integrated, collaborative partner.\n\n*   **4. Key Technical Contributions**\n    *   **Novel methods/techniques:** The primary contribution is the conceptual framework of the \"Centaur Programmer\" and the articulation of novel human-AI collaboration models (Guidance, Sketch, Inverted Control) specifically tailored for software development \\cite{alves2023ao6}.\n    *   **Theoretical insights:** It provides a theoretical argument for the synergistic superiority of human-AI teams over either component alone, drawing a compelling parallel from the domain of chess \\cite{alves2023ao6}.\n\n*   **5. Experimental Validation**\n    *   The paper is a position paper and **does not present new experimental validation** of the proposed Centaur Programmer models \\cite{alves2023ao6}.\n    *   It relies on the historical results of Centaur Chess tournaments as an empirical analogy to support its core premise \\cite{alves2023ao6}.\n    *   It references existing studies on the effectiveness of LLM-based tools in programming tasks (e.g., GPT-3's ability to solve exercises, GitHub Copilot's impact on productivity) but does not conduct its own experiments or provide new performance metrics \\cite{alves2023ao6}.\n\n*   **6. Limitations & Scope**\n    *   **Technical limitations:** The proposed collaboration models are conceptual and lack empirical validation within the software development context by the authors \\cite{alves2023ao6}. The core argument heavily relies on an analogy (Centaur Chess) whose direct applicability to the complexities of software development is assumed.\n    *   **Scope of applicability:** The paper's scope is broad, encompassing the future of software development practices, the necessary evolution of university curricula to train \"centaur programmers,\" and the legal/ethical implications of human-AI collaboration in programming \\cite{alves2023ao6}.\n\n*   **7. Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a structured conceptual framework for human-AI collaboration in programming, moving beyond the binary \"replacement vs. no replacement\" debate \\cite{alves2023ao6}. It introduces concrete models for interaction that can guide future tool development.\n    *   Its potential impact on future research is substantial, encouraging:\n        *   The design and implementation of new AI programming tools that explicitly support the proposed collaborative models.\n        *   Research into optimal human-computer interaction (HCI) patterns for augmented programming environments.\n        *   Development of new software engineering methodologies that integrate these collaborative AI roles.\n        *   Further investigation into the ethical and legal frameworks required for AI-assisted code generation, particularly regarding human responsibility for AI-produced content \\cite{alves2023ao6}.",
      "keywords": [
        "Large Language Models (LLMs)",
        "Centaur Programmer paradigm",
        "human-AI collaboration models",
        "Guidance Model",
        "Sketch Model",
        "Inverted Control Model",
        "software development",
        "code generation",
        "Centaur Chess analogy",
        "synergistic human-AI teams",
        "position paper",
        "lack of empirical validation",
        "AI programming tools",
        "human-computer interaction (HCI)"
      ],
      "paper_type": "the paper type is **position**.\n\n**reasoning:**\n\n*   **abstract:**\n    *   \"we introduce the idea of centaur programmer, based on the premise that a collaborative approach between humans and ai will be more effective than ai alone...\" this clearly states a core viewpoint or argument.\n    *   \"...and suggests that universities should prepare future programmers for a more efficient and productive programming environment augmented with ai.\" this is a recommendation for a future direction.\n    *   the introduction of \"collaboration models\" serves to illustrate and support this proposed approach.\n*   **introduction:**\n    *   it sets up a problem (\"will even programmers themselves be replaced by ai?\") and then immediately offers a historical analogy (centaur chess) as a way to \"learn from the past\" and propose a different path forward. this is characteristic of arguing for a particular viewpoint or vision.\n    *   the overall tone is one of advocating for a specific approach to the future of software development.\n\nthe paper is not primarily a survey, technical deep-dive into algorithms, theoretical proof, empirical study, or a detailed case study of an existing application. while it introduces models, their presentation seems to be in service of the larger argument for the \"centaur programmer\" concept and its implications."
    },
    "file_name": "2280a192eaf49c66cf539269e9b7958b6f412cfb.pdf"
  },
  {
    "success": true,
    "doc_id": "d5c34e5c19729f825f139d03615b3d04",
    "summary": "Large LanguageModels (LLM), such as the variants of ChatGPT or BERT, are currently under intensive development and enhancement, but it has become clear that they will contribute a significant change to the way text and images are created in the future. It is therefore not surprising that the challenges, risks and opportunities of generative AI are discussed intensively in various scientific communities as well as in industry, government, education, and society, in general. There are of course technological aspects to be understood, but the impact on society and the industrial world has been significantly changed by the advantages and consequences of an expanded focus of generative AI, as supported by LLMs.",
    "intriguing_abstract": "Large LanguageModels (LLM), such as the variants of ChatGPT or BERT, are currently under intensive development and enhancement, but it has become clear that they will contribute a significant change to the way text and images are created in the future. It is therefore not surprising that the challenges, risks and opportunities of generative AI are discussed intensively in various scientific communities as well as in industry, government, education, and society, in general. There are of course technological aspects to be understood, but the impact on society and the industrial world has been significantly changed by the advantages and consequences of an expanded focus of generative AI, as supported by LLMs.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/2d3e0d0e1513b369b342fb427d87f0ec51ea7e0b.pdf",
    "citation_key": "combemale202367i",
    "metadata": {
      "title": "Large language models as an “operating” system for software and systems modeling",
      "authors": [
        "Benoît Combemale",
        "J. Gray",
        "Bernhard Rumpe"
      ],
      "published_date": "2023",
      "abstract": "Large LanguageModels (LLM), such as the variants of ChatGPT or BERT, are currently under intensive development and enhancement, but it has become clear that they will contribute a significant change to the way text and images are created in the future. It is therefore not surprising that the challenges, risks and opportunities of generative AI are discussed intensively in various scientific communities as well as in industry, government, education, and society, in general. There are of course technological aspects to be understood, but the impact on society and the industrial world has been significantly changed by the advantages and consequences of an expanded focus of generative AI, as supported by LLMs.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/2d3e0d0e1513b369b342fb427d87f0ec51ea7e0b.pdf",
      "venue": "Journal of Software and Systems Modeling",
      "citationCount": 7,
      "score": 3.5,
      "summary": "Large LanguageModels (LLM), such as the variants of ChatGPT or BERT, are currently under intensive development and enhancement, but it has become clear that they will contribute a significant change to the way text and images are created in the future. It is therefore not surprising that the challenges, risks and opportunities of generative AI are discussed intensively in various scientific communities as well as in industry, government, education, and society, in general. There are of course technological aspects to be understood, but the impact on society and the industrial world has been significantly changed by the advantages and consequences of an expanded focus of generative AI, as supported by LLMs.",
      "keywords": []
    },
    "file_name": "2d3e0d0e1513b369b342fb427d87f0ec51ea7e0b.pdf"
  },
  {
    "success": true,
    "doc_id": "79a7b75c148b77e618364336eb336699",
    "summary": "Artificial intelligence (AI) is a technology that is constantly evolving and is being applied more frequently in many facets of society, including product and service development. Chatbots, which are computer programs that can connect with people through chat or voice apps, are one sort of AI that is evolving quickly. However, there is still much debate among scientists and professionals about whether AI advancements like ChatGPT can help software engineers with their daily tasks or even replace the work of software engineers. So, on this occasion, we conduct research on whether AI (artificial intelligence) is capable of helping software engineers and how far AI can assist software engineers. In this study, we aim to evaluate the effectiveness of ChatGPT as an AI tool for code retrieval and its potential to help or replace software engineers. Our research methodology involves using ChatGPT to refactor provided code and make a simple application from scratch. The results of this research show that AI chatbot models like ChatGPT cannot replace software developers 100",
    "intriguing_abstract": "Artificial intelligence (AI) is a technology that is constantly evolving and is being applied more frequently in many facets of society, including product and service development. Chatbots, which are computer programs that can connect with people through chat or voice apps, are one sort of AI that is evolving quickly. However, there is still much debate among scientists and professionals about whether AI advancements like ChatGPT can help software engineers with their daily tasks or even replace the work of software engineers. So, on this occasion, we conduct research on whether AI (artificial intelligence) is capable of helping software engineers and how far AI can assist software engineers. In this study, we aim to evaluate the effectiveness of ChatGPT as an AI tool for code retrieval and its potential to help or replace software engineers. Our research methodology involves using ChatGPT to refactor provided code and make a simple application from scratch. The results of this research show that AI chatbot models like ChatGPT cannot replace software developers 100",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f2bf1c3a5223f488cd2c2434e9642fd34cf532a2.pdf",
    "citation_key": "purwoko2023s2o",
    "metadata": {
      "title": "Analysis ChatGPT Potential: Transforming Software Development with AI Chat Bots",
      "authors": [
        "Justine Winata Purwoko",
        "Tegar Abdullah",
        "Budiman Wijaya",
        "Alexander Agung Santoso Gunawan",
        "Karen Etania Saputra"
      ],
      "published_date": "2023",
      "abstract": "Artificial intelligence (AI) is a technology that is constantly evolving and is being applied more frequently in many facets of society, including product and service development. Chatbots, which are computer programs that can connect with people through chat or voice apps, are one sort of AI that is evolving quickly. However, there is still much debate among scientists and professionals about whether AI advancements like ChatGPT can help software engineers with their daily tasks or even replace the work of software engineers. So, on this occasion, we conduct research on whether AI (artificial intelligence) is capable of helping software engineers and how far AI can assist software engineers. In this study, we aim to evaluate the effectiveness of ChatGPT as an AI tool for code retrieval and its potential to help or replace software engineers. Our research methodology involves using ChatGPT to refactor provided code and make a simple application from scratch. The results of this research show that AI chatbot models like ChatGPT cannot replace software developers 100",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f2bf1c3a5223f488cd2c2434e9642fd34cf532a2.pdf",
      "venue": "2023 International Conference on Networking, Electrical Engineering, Computer Science, and Technology (IConNECT)",
      "citationCount": 6,
      "score": 3.0,
      "summary": "Artificial intelligence (AI) is a technology that is constantly evolving and is being applied more frequently in many facets of society, including product and service development. Chatbots, which are computer programs that can connect with people through chat or voice apps, are one sort of AI that is evolving quickly. However, there is still much debate among scientists and professionals about whether AI advancements like ChatGPT can help software engineers with their daily tasks or even replace the work of software engineers. So, on this occasion, we conduct research on whether AI (artificial intelligence) is capable of helping software engineers and how far AI can assist software engineers. In this study, we aim to evaluate the effectiveness of ChatGPT as an AI tool for code retrieval and its potential to help or replace software engineers. Our research methodology involves using ChatGPT to refactor provided code and make a simple application from scratch. The results of this research show that AI chatbot models like ChatGPT cannot replace software developers 100",
      "keywords": []
    },
    "file_name": "f2bf1c3a5223f488cd2c2434e9642fd34cf532a2.pdf"
  },
  {
    "success": true,
    "doc_id": "90f2ced7f553c39049d344a56b6af73e",
    "summary": "Software that contains machine learning algorithms is an integral part of automotive perception, for example, in driving automation systems. The development of such software, specifically the training and validation of the machine learning components, requires large annotated datasets. An industry of data and annotation services has emerged to serve the development of such data-intensive automotive software components. Wide-spread difficulties to specify data and annotation needs challenge collaborations between OEMs (Original Equipment Manufacturers) and their suppliers of software components, data, and annotations.This paper investigates the reasons for these difficulties for practitioners in the Swedish automotive industry to arrive at clear specifications for data and annotations. The results from an interview study show that a lack of effective metrics for data quality aspects, ambiguities in the way of working, unclear definitions of annotation quality, and deficits in the business ecosystems are causes for the difficulty in deriving the specifications. We provide a list of recommendations that can mitigate challenges when deriving specifications and we propose future research opportunities to overcome these challenges. Our work contributes towards the on-going research on accountability of machine learning as applied to complex software systems, especially for high-stake applications such as automated driving.",
    "intriguing_abstract": "Software that contains machine learning algorithms is an integral part of automotive perception, for example, in driving automation systems. The development of such software, specifically the training and validation of the machine learning components, requires large annotated datasets. An industry of data and annotation services has emerged to serve the development of such data-intensive automotive software components. Wide-spread difficulties to specify data and annotation needs challenge collaborations between OEMs (Original Equipment Manufacturers) and their suppliers of software components, data, and annotations.This paper investigates the reasons for these difficulties for practitioners in the Swedish automotive industry to arrive at clear specifications for data and annotations. The results from an interview study show that a lack of effective metrics for data quality aspects, ambiguities in the way of working, unclear definitions of annotation quality, and deficits in the business ecosystems are causes for the difficulty in deriving the specifications. We provide a list of recommendations that can mitigate challenges when deriving specifications and we propose future research opportunities to overcome these challenges. Our work contributes towards the on-going research on accountability of machine learning as applied to complex software systems, especially for high-stake applications such as automated driving.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/5c52d57f3386c04b3d75d1e6ed72be4ff37e5570.pdf",
    "citation_key": "heyn20234p9",
    "metadata": {
      "title": "Automotive Perception Software Development: An Empirical Investigation into Data, Annotation, and Ecosystem Challenges",
      "authors": [
        "Hans-Martin Heyn",
        "K. M. Habibullah",
        "E. Knauss",
        "Jennifer Horkoff",
        "Markus Borg",
        "Alessia Knauss",
        "Polly Jing Li"
      ],
      "published_date": "2023",
      "abstract": "Software that contains machine learning algorithms is an integral part of automotive perception, for example, in driving automation systems. The development of such software, specifically the training and validation of the machine learning components, requires large annotated datasets. An industry of data and annotation services has emerged to serve the development of such data-intensive automotive software components. Wide-spread difficulties to specify data and annotation needs challenge collaborations between OEMs (Original Equipment Manufacturers) and their suppliers of software components, data, and annotations.This paper investigates the reasons for these difficulties for practitioners in the Swedish automotive industry to arrive at clear specifications for data and annotations. The results from an interview study show that a lack of effective metrics for data quality aspects, ambiguities in the way of working, unclear definitions of annotation quality, and deficits in the business ecosystems are causes for the difficulty in deriving the specifications. We provide a list of recommendations that can mitigate challenges when deriving specifications and we propose future research opportunities to overcome these challenges. Our work contributes towards the on-going research on accountability of machine learning as applied to complex software systems, especially for high-stake applications such as automated driving.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/5c52d57f3386c04b3d75d1e6ed72be4ff37e5570.pdf",
      "venue": "2023 IEEE/ACM 2nd International Conference on AI Engineering – Software Engineering for AI (CAIN)",
      "citationCount": 6,
      "score": 3.0,
      "summary": "Software that contains machine learning algorithms is an integral part of automotive perception, for example, in driving automation systems. The development of such software, specifically the training and validation of the machine learning components, requires large annotated datasets. An industry of data and annotation services has emerged to serve the development of such data-intensive automotive software components. Wide-spread difficulties to specify data and annotation needs challenge collaborations between OEMs (Original Equipment Manufacturers) and their suppliers of software components, data, and annotations.This paper investigates the reasons for these difficulties for practitioners in the Swedish automotive industry to arrive at clear specifications for data and annotations. The results from an interview study show that a lack of effective metrics for data quality aspects, ambiguities in the way of working, unclear definitions of annotation quality, and deficits in the business ecosystems are causes for the difficulty in deriving the specifications. We provide a list of recommendations that can mitigate challenges when deriving specifications and we propose future research opportunities to overcome these challenges. Our work contributes towards the on-going research on accountability of machine learning as applied to complex software systems, especially for high-stake applications such as automated driving.",
      "keywords": []
    },
    "file_name": "5c52d57f3386c04b3d75d1e6ed72be4ff37e5570.pdf"
  },
  {
    "success": true,
    "doc_id": "ceccb836a198d74bd3bf2840f4487853",
    "summary": "The intersection of artificial intelligence (AI) and software engineering marks a transformative phase in the technology industry. This paper delves into AI-driven software engineering, exploring its methodologies, implications, challenges, and benefits. Drawing from data sources such as GitHub and Bitbucket and insights from industry experts, the study offers a comprehensive view of the current landscape. While the results indicate a promising uptrend in the integration of AI techniques in software development, challenges like model interpretability, ethical concerns, and integration complexities emerge as significant. Nevertheless, the transformative potential of AI within software engineering is profound, ushering in new paradigms of efficiency, innovation, and user experience. The study concludes by emphasizing the need for further research, better tooling, ethical guidelines, and education to fully harness the potential of AI-driven software engineering.",
    "intriguing_abstract": "The intersection of artificial intelligence (AI) and software engineering marks a transformative phase in the technology industry. This paper delves into AI-driven software engineering, exploring its methodologies, implications, challenges, and benefits. Drawing from data sources such as GitHub and Bitbucket and insights from industry experts, the study offers a comprehensive view of the current landscape. While the results indicate a promising uptrend in the integration of AI techniques in software development, challenges like model interpretability, ethical concerns, and integration complexities emerge as significant. Nevertheless, the transformative potential of AI within software engineering is profound, ushering in new paradigms of efficiency, innovation, and user experience. The study concludes by emphasizing the need for further research, better tooling, ethical guidelines, and education to fully harness the potential of AI-driven software engineering.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/c14d708c568a697e02278bcf564adfe3523d01bd.pdf",
    "citation_key": "ali2023bfr",
    "metadata": {
      "title": "AI-driven software engineering",
      "authors": [
        "Josh Mahmood Ali"
      ],
      "published_date": "2023",
      "abstract": "The intersection of artificial intelligence (AI) and software engineering marks a transformative phase in the technology industry. This paper delves into AI-driven software engineering, exploring its methodologies, implications, challenges, and benefits. Drawing from data sources such as GitHub and Bitbucket and insights from industry experts, the study offers a comprehensive view of the current landscape. While the results indicate a promising uptrend in the integration of AI techniques in software development, challenges like model interpretability, ethical concerns, and integration complexities emerge as significant. Nevertheless, the transformative potential of AI within software engineering is profound, ushering in new paradigms of efficiency, innovation, and user experience. The study concludes by emphasizing the need for further research, better tooling, ethical guidelines, and education to fully harness the potential of AI-driven software engineering.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/c14d708c568a697e02278bcf564adfe3523d01bd.pdf",
      "venue": "Advances in Engineering Innovation",
      "citationCount": 6,
      "score": 3.0,
      "summary": "The intersection of artificial intelligence (AI) and software engineering marks a transformative phase in the technology industry. This paper delves into AI-driven software engineering, exploring its methodologies, implications, challenges, and benefits. Drawing from data sources such as GitHub and Bitbucket and insights from industry experts, the study offers a comprehensive view of the current landscape. While the results indicate a promising uptrend in the integration of AI techniques in software development, challenges like model interpretability, ethical concerns, and integration complexities emerge as significant. Nevertheless, the transformative potential of AI within software engineering is profound, ushering in new paradigms of efficiency, innovation, and user experience. The study concludes by emphasizing the need for further research, better tooling, ethical guidelines, and education to fully harness the potential of AI-driven software engineering.",
      "keywords": []
    },
    "file_name": "c14d708c568a697e02278bcf564adfe3523d01bd.pdf"
  },
  {
    "success": true,
    "doc_id": "9e8adbcb531efc63c1a0a167b03c5dd1",
    "summary": "Background The use of patient health and treatment information captured in structured and unstructured formats in computerized electronic health record (EHR) repositories could potentially augment the detection of safety signals for drug products regulated by the US Food and Drug Administration (FDA). Natural language processing and other artificial intelligence (AI) techniques provide novel methodologies that could be leveraged to extract clinically useful information from EHR resources. Objective Our aim is to develop a novel AI-enabled software prototype to identify adverse drug event (ADE) safety signals from free-text discharge summaries in EHRs to enhance opioid drug safety and research activities at the FDA. Methods We developed a prototype for web-based software that leverages keyword and trigger-phrase searching with rule-based algorithms and deep learning to extract candidate ADEs for specific opioid drugs from discharge summaries in the Medical Information Mart for Intensive Care III (MIMIC III) database. The prototype uses MedSpacy components to identify relevant sections of discharge summaries and a pretrained natural language processing (NLP) model, Spark NLP for Healthcare, for named entity recognition. Fifteen FDA staff members provided feedback on the prototype’s features and functionalities. Results Using the prototype, we were able to identify known, labeled, opioid-related adverse drug reactions from text in EHRs. The AI-enabled model achieved accuracy, recall, precision, and F1-scores of 0.66, 0.69, 0.64, and 0.67, respectively. FDA participants assessed the prototype as highly desirable in user satisfaction, visualizations, and in the potential to support drug safety signal detection for opioid drugs from EHR data while saving time and manual effort. Actionable design recommendations included (1) enlarging the tabs and visualizations; (2) enabling more flexibility and customizations to fit end users’ individual needs; (3) providing additional instructional resources; (4) adding multiple graph export functionality; and (5) adding project summaries. Conclusions The novel prototype uses innovative AI-based techniques to automate searching for, extracting, and analyzing clinically useful information captured in unstructured text in EHRs. It increases efficiency in harnessing real-world data for opioid drug safety and increases the usability of the data to support regulatory review while decreasing the manual research burden.",
    "intriguing_abstract": "Background The use of patient health and treatment information captured in structured and unstructured formats in computerized electronic health record (EHR) repositories could potentially augment the detection of safety signals for drug products regulated by the US Food and Drug Administration (FDA). Natural language processing and other artificial intelligence (AI) techniques provide novel methodologies that could be leveraged to extract clinically useful information from EHR resources. Objective Our aim is to develop a novel AI-enabled software prototype to identify adverse drug event (ADE) safety signals from free-text discharge summaries in EHRs to enhance opioid drug safety and research activities at the FDA. Methods We developed a prototype for web-based software that leverages keyword and trigger-phrase searching with rule-based algorithms and deep learning to extract candidate ADEs for specific opioid drugs from discharge summaries in the Medical Information Mart for Intensive Care III (MIMIC III) database. The prototype uses MedSpacy components to identify relevant sections of discharge summaries and a pretrained natural language processing (NLP) model, Spark NLP for Healthcare, for named entity recognition. Fifteen FDA staff members provided feedback on the prototype’s features and functionalities. Results Using the prototype, we were able to identify known, labeled, opioid-related adverse drug reactions from text in EHRs. The AI-enabled model achieved accuracy, recall, precision, and F1-scores of 0.66, 0.69, 0.64, and 0.67, respectively. FDA participants assessed the prototype as highly desirable in user satisfaction, visualizations, and in the potential to support drug safety signal detection for opioid drugs from EHR data while saving time and manual effort. Actionable design recommendations included (1) enlarging the tabs and visualizations; (2) enabling more flexibility and customizations to fit end users’ individual needs; (3) providing additional instructional resources; (4) adding multiple graph export functionality; and (5) adding project summaries. Conclusions The novel prototype uses innovative AI-based techniques to automate searching for, extracting, and analyzing clinically useful information captured in unstructured text in EHRs. It increases efficiency in harnessing real-world data for opioid drug safety and increases the usability of the data to support regulatory review while decreasing the manual research burden.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ee09ce96cefaad447d8b9b8f54d4d34fe3b63afd.pdf",
    "citation_key": "sorbello2023mun",
    "metadata": {
      "title": "Artificial Intelligence–Enabled Software Prototype to Inform Opioid Pharmacovigilance From Electronic Health Records: Development and Usability Study",
      "authors": [
        "A. Sorbello",
        "S. A. Haque",
        "Rashedul Hasan",
        "Richard Jermyn",
        "Ahmad Hussein",
        "Alex Vega",
        "Krzysztof Zembrzuski",
        "A. Ripple",
        "M. Ahadpour"
      ],
      "published_date": "2023",
      "abstract": "Background The use of patient health and treatment information captured in structured and unstructured formats in computerized electronic health record (EHR) repositories could potentially augment the detection of safety signals for drug products regulated by the US Food and Drug Administration (FDA). Natural language processing and other artificial intelligence (AI) techniques provide novel methodologies that could be leveraged to extract clinically useful information from EHR resources. Objective Our aim is to develop a novel AI-enabled software prototype to identify adverse drug event (ADE) safety signals from free-text discharge summaries in EHRs to enhance opioid drug safety and research activities at the FDA. Methods We developed a prototype for web-based software that leverages keyword and trigger-phrase searching with rule-based algorithms and deep learning to extract candidate ADEs for specific opioid drugs from discharge summaries in the Medical Information Mart for Intensive Care III (MIMIC III) database. The prototype uses MedSpacy components to identify relevant sections of discharge summaries and a pretrained natural language processing (NLP) model, Spark NLP for Healthcare, for named entity recognition. Fifteen FDA staff members provided feedback on the prototype’s features and functionalities. Results Using the prototype, we were able to identify known, labeled, opioid-related adverse drug reactions from text in EHRs. The AI-enabled model achieved accuracy, recall, precision, and F1-scores of 0.66, 0.69, 0.64, and 0.67, respectively. FDA participants assessed the prototype as highly desirable in user satisfaction, visualizations, and in the potential to support drug safety signal detection for opioid drugs from EHR data while saving time and manual effort. Actionable design recommendations included (1) enlarging the tabs and visualizations; (2) enabling more flexibility and customizations to fit end users’ individual needs; (3) providing additional instructional resources; (4) adding multiple graph export functionality; and (5) adding project summaries. Conclusions The novel prototype uses innovative AI-based techniques to automate searching for, extracting, and analyzing clinically useful information captured in unstructured text in EHRs. It increases efficiency in harnessing real-world data for opioid drug safety and increases the usability of the data to support regulatory review while decreasing the manual research burden.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ee09ce96cefaad447d8b9b8f54d4d34fe3b63afd.pdf",
      "venue": "JMIR AI",
      "citationCount": 6,
      "score": 3.0,
      "summary": "Background The use of patient health and treatment information captured in structured and unstructured formats in computerized electronic health record (EHR) repositories could potentially augment the detection of safety signals for drug products regulated by the US Food and Drug Administration (FDA). Natural language processing and other artificial intelligence (AI) techniques provide novel methodologies that could be leveraged to extract clinically useful information from EHR resources. Objective Our aim is to develop a novel AI-enabled software prototype to identify adverse drug event (ADE) safety signals from free-text discharge summaries in EHRs to enhance opioid drug safety and research activities at the FDA. Methods We developed a prototype for web-based software that leverages keyword and trigger-phrase searching with rule-based algorithms and deep learning to extract candidate ADEs for specific opioid drugs from discharge summaries in the Medical Information Mart for Intensive Care III (MIMIC III) database. The prototype uses MedSpacy components to identify relevant sections of discharge summaries and a pretrained natural language processing (NLP) model, Spark NLP for Healthcare, for named entity recognition. Fifteen FDA staff members provided feedback on the prototype’s features and functionalities. Results Using the prototype, we were able to identify known, labeled, opioid-related adverse drug reactions from text in EHRs. The AI-enabled model achieved accuracy, recall, precision, and F1-scores of 0.66, 0.69, 0.64, and 0.67, respectively. FDA participants assessed the prototype as highly desirable in user satisfaction, visualizations, and in the potential to support drug safety signal detection for opioid drugs from EHR data while saving time and manual effort. Actionable design recommendations included (1) enlarging the tabs and visualizations; (2) enabling more flexibility and customizations to fit end users’ individual needs; (3) providing additional instructional resources; (4) adding multiple graph export functionality; and (5) adding project summaries. Conclusions The novel prototype uses innovative AI-based techniques to automate searching for, extracting, and analyzing clinically useful information captured in unstructured text in EHRs. It increases efficiency in harnessing real-world data for opioid drug safety and increases the usability of the data to support regulatory review while decreasing the manual research burden.",
      "keywords": []
    },
    "file_name": "ee09ce96cefaad447d8b9b8f54d4d34fe3b63afd.pdf"
  },
  {
    "success": true,
    "doc_id": "c7d1af7c5e18751fe90de4424cf8a243",
    "summary": "In the ever-evolving landscape of Artificial Intelligence (AI), the synergy between generative AI and Software Engineering emerges as a transformative frontier. This whitepaper delves into the unexplored realm, elucidating how generative AI techniques can revolutionize software development. Spanning from project management to support and updates, we meticulously map the demands of each development stage and unveil the potential of generative AI in addressing them. Techniques such as zero-shot prompting, self-consistency, and multimodal chain-of-thought are explored, showcasing their unique capabilities in enhancing generative AI models. The significance of vector embeddings, context, plugins, tools, and code assistants is underscored, emphasizing their role in capturing semantic information and amplifying generative AI capabilities. Looking ahead, this intersection promises to elevate productivity, improve code quality, and streamline the software development process. This whitepaper serves as a guide for stakeholders, urging discussions and experiments in the application of generative AI in Software Engineering, fostering innovation and collaboration for a qualitative leap in the efficiency and effectiveness of software development.",
    "intriguing_abstract": "In the ever-evolving landscape of Artificial Intelligence (AI), the synergy between generative AI and Software Engineering emerges as a transformative frontier. This whitepaper delves into the unexplored realm, elucidating how generative AI techniques can revolutionize software development. Spanning from project management to support and updates, we meticulously map the demands of each development stage and unveil the potential of generative AI in addressing them. Techniques such as zero-shot prompting, self-consistency, and multimodal chain-of-thought are explored, showcasing their unique capabilities in enhancing generative AI models. The significance of vector embeddings, context, plugins, tools, and code assistants is underscored, emphasizing their role in capturing semantic information and amplifying generative AI capabilities. Looking ahead, this intersection promises to elevate productivity, improve code quality, and streamline the software development process. This whitepaper serves as a guide for stakeholders, urging discussions and experiments in the application of generative AI in Software Engineering, fostering innovation and collaboration for a qualitative leap in the efficiency and effectiveness of software development.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8bb7f00f443d7e640eac951e181e3a8b219e00e3.pdf",
    "citation_key": "calegario2023b2k",
    "metadata": {
      "title": "Exploring the intersection of Generative AI and Software Development",
      "authors": [
        "Filipe Calegario",
        "V. Burégio",
        "Francisco Erivaldo",
        "Daniel Moraes Costa Andrade",
        "Kailane Felix",
        "Nathalia Barbosa",
        "Pedro Lucas da Silva Lucena",
        "César França"
      ],
      "published_date": "2023",
      "abstract": "In the ever-evolving landscape of Artificial Intelligence (AI), the synergy between generative AI and Software Engineering emerges as a transformative frontier. This whitepaper delves into the unexplored realm, elucidating how generative AI techniques can revolutionize software development. Spanning from project management to support and updates, we meticulously map the demands of each development stage and unveil the potential of generative AI in addressing them. Techniques such as zero-shot prompting, self-consistency, and multimodal chain-of-thought are explored, showcasing their unique capabilities in enhancing generative AI models. The significance of vector embeddings, context, plugins, tools, and code assistants is underscored, emphasizing their role in capturing semantic information and amplifying generative AI capabilities. Looking ahead, this intersection promises to elevate productivity, improve code quality, and streamline the software development process. This whitepaper serves as a guide for stakeholders, urging discussions and experiments in the application of generative AI in Software Engineering, fostering innovation and collaboration for a qualitative leap in the efficiency and effectiveness of software development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8bb7f00f443d7e640eac951e181e3a8b219e00e3.pdf",
      "venue": "arXiv.org",
      "citationCount": 5,
      "score": 2.5,
      "summary": "In the ever-evolving landscape of Artificial Intelligence (AI), the synergy between generative AI and Software Engineering emerges as a transformative frontier. This whitepaper delves into the unexplored realm, elucidating how generative AI techniques can revolutionize software development. Spanning from project management to support and updates, we meticulously map the demands of each development stage and unveil the potential of generative AI in addressing them. Techniques such as zero-shot prompting, self-consistency, and multimodal chain-of-thought are explored, showcasing their unique capabilities in enhancing generative AI models. The significance of vector embeddings, context, plugins, tools, and code assistants is underscored, emphasizing their role in capturing semantic information and amplifying generative AI capabilities. Looking ahead, this intersection promises to elevate productivity, improve code quality, and streamline the software development process. This whitepaper serves as a guide for stakeholders, urging discussions and experiments in the application of generative AI in Software Engineering, fostering innovation and collaboration for a qualitative leap in the efficiency and effectiveness of software development.",
      "keywords": []
    },
    "file_name": "8bb7f00f443d7e640eac951e181e3a8b219e00e3.pdf"
  },
  {
    "success": true,
    "doc_id": "a0a8b16b0b1d27c87f9a93cff89ab080",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n### Focused Summary for Literature Review\n\n**CITATION**: \\cite{daniel2023kvs}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the inefficiencies and manual nature of certain Agile software development processes, including task allocation, backlog prioritization, test case reduction, and test case prioritization \\cite{daniel2023kvs}.\n    *   **Importance and Challenge**: The problem is critical due to the market's demand for faster software releases while maintaining high quality. Traditional manual Agile processes struggle to meet these demands. Integrating AI introduces new complexities related to AI model management, deployment, monitoring, and ensuring the trustworthiness and security of AI-assisted systems \\cite{daniel2023kvs}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work is a meta-analysis of existing literature, synthesizing how AI is being integrated into Agile practices. It acknowledges the growing trend of using AI/ML techniques in software development for tasks like risk management, task allocation, code analysis, and test case prioritization \\cite{daniel2023kvs}. It also notes the emergence of Large Language Models (LLMs) as potential tools for architectural analysis and evaluation \\cite{daniel2023kvs}.\n    *   **Limitations of Previous Solutions**: The paper highlights that existing literature points to significant challenges in integrating AI with Agile, including issues beyond the development process itself, such as AI model management, deployment, and monitoring \\cite{daniel2023kvs}. Previous solutions often lack standardized processes, face socio-technical limitations, and suffer from a scarcity of human expertise capable of bridging AI and Agile domains \\cite{daniel2023kvs}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper's core method is a systematic literature review and longitudinal meta-analysis. This involved defining a review protocol, conducting extensive searches across major academic databases (ACM Digital Library, Springer, IEEE Xplore, ScienceDirect, Google Scholar), and applying strict inclusion/exclusion criteria to select relevant studies \\cite{daniel2023kvs}.\n    *   **Novelty/Difference**: The novelty lies in its comprehensive, longitudinal meta-analysis approach to draw a \"bigger picture\" of the evolving field of AI for Agile software development. This work synthesizes findings from a broad range of studies, identifying overarching trends, specific AI mitigation strategies (M1-M5), and emerging challenges (RQ3) related to the integration of AI into Agile practices \\cite{daniel2023kvs}. The longitudinal aspect allows for the study of temporary trends in the literature, such as the increasing prevalence of ethical AI topics \\cite{daniel2023kvs}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques (Identified from Literature)**: While the paper itself does not propose new algorithms, it *identifies and categorizes* several AI-based mitigation strategies from the literature that represent technical innovations:\n        *   **M1: Integration of AI techniques within DevOps pipelines** to facilitate continuous and rapid development at scale \\cite{daniel2023kvs}.\n        *   **M2: Automatic tools for defect detection and code quality improvement**, reducing development time and increasing efficiency in test-driven development \\cite{daniel2023kvs}.\n        *   **M3: AI-enabled dynamic re-prioritization of test cases** for automatic regression test selection and prioritization, significantly reducing testing efforts in continuous integration \\cite{daniel2023kvs}.\n        *   **M4: AI for identifying dependencies and conflicts in requirements** \\cite{daniel2023kvs}.\n        *   **M5: ML algorithms for predicting the impact of backlog changes and recommending user story prioritization** based on factors like feature importance, effort, and business value \\cite{daniel2023kvs}.\n    *   **System Design or Architectural Innovations**: The paper highlights the need for unified frameworks like MLOps to address the continuous deployment of ML-driven projects, suggesting an architectural shift towards integrating AI model management with DevOps principles \\cite{daniel2023kvs}.\n    *   **Theoretical Insights or Analysis**: The paper provides a structured analysis of the interplay between AI and Agile, categorizing challenges (RQ1) and mapping them to specific AI mitigation strategies (RQ2) (Table 1). It also identifies emerging indirect challenges, such as security threats to deep neural networks and LLMs, data source appropriateness, and the need for ethical AI frameworks \\cite{daniel2023kvs}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The \"validation\" in this meta-analysis context refers to the systematic process of collecting and analyzing existing research. The authors conducted a systematic literature review by querying four formal databases (ACM Digital Library, Springer, IEEE Xplore, ScienceDirect) and Google Scholar, identifying 5446 initial papers \\cite{daniel2023kvs}. After a rigorous screening process based on title and abstract, 377 peer-reviewed articles were selected for in-depth data extraction and analysis \\cite{daniel2023kvs}.\n    *   **Key Performance Metrics and Comparison Results**: The paper presents quantitative trends, such as the \"evolution of the number of publications on AI-enhanced Agile processes\" (Figure 2), showing a rapid increase in interest and research in this area \\cite{daniel2023kvs}. It also quantifies the \"Prevalence of Ethical AI topics\" (Figure 1), indicating a significant rise since 2000, especially with LLMs \\cite{daniel2023kvs}. The primary \"results\" are the identified categories of Agile challenges (RQ1), the five AI mitigation strategies (M1-M5) and their mapping to challenges (Table 1), and the emerging challenges in AI-assisted Agile (RQ3), all derived from the synthesized literature \\cite{daniel2023kvs}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper's findings are limited by the scope and quality of the existing literature included in the meta-analysis. It assumes that the retrieved studies accurately reflect the state of AI-Agile integration. The exclusion of studies about Agile methodologies *for* AI-related software development narrows its focus to AI *assisting* Agile, rather than Agile *managing* AI projects \\cite{daniel2023kvs}.\n    *   **Scope of Applicability**: The analysis is applicable to understanding the current landscape, benefits, and challenges of integrating AI into traditional Agile software development processes, particularly for improving continuous integration and delivery. It provides a high-level overview rather than deep technical details of specific AI algorithms or their implementation \\cite{daniel2023kvs}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This meta-analysis significantly advances the technical state-of-the-art by providing a structured, evidence-based overview of how AI is being leveraged to enhance Agile practices. It systematically identifies and categorizes the specific technical problems in Agile that AI can address and the types of AI solutions being proposed (e.g., automated testing, intelligent prioritization, dependency detection) \\cite{daniel2023kvs}. It also highlights critical emerging technical challenges, such as securing AI systems against adversarial attacks and the need for robust MLOps frameworks \\cite{daniel2023kvs}.\n    *   **Potential Impact on Future Research**: The paper's findings directly inform future research by identifying gaps, such as the need for more empirical studies on the actual use of AI tools in practice (e.g., JIRA integration) and further research into human factors in AI-assisted development \\cite{daniel2023kvs}. It underscores the importance of developing unified frameworks for continuous deployment in ML-driven projects (MLOps) and integrating ethical considerations into AI software development \\cite{daniel2023kvs}.",
    "intriguing_abstract": "The relentless demand for faster, higher-quality software challenges traditional Agile development, where manual inefficiencies in task allocation, backlog prioritization, and testing often create bottlenecks. Can Artificial Intelligence truly transform this landscape? This comprehensive, longitudinal meta-analysis systematically synthesizes the evolving integration of AI into Agile practices, offering a critical 'bigger picture' perspective. We identify five distinct AI mitigation strategies (M1-M5) that leverage machine learning for tasks like dynamic test case prioritization, intelligent backlog management, and automated defect detection, significantly streamlining continuous integration and delivery pipelines. Beyond these technical advancements, our review uncovers crucial emerging challenges, including the imperative for robust MLOps frameworks, AI model trustworthiness, and ethical considerations, especially with the rise of Large Language Models (LLMs). By mapping these AI-driven solutions to specific Agile pain points and highlighting future research frontiers, this work provides an indispensable roadmap for researchers and practitioners navigating the complex, yet promising, convergence of AI and Agile. It underscores the urgent need for unified frameworks and human expertise to unlock the full potential of AI-assisted software development.",
    "keywords": [
      "AI for Agile software development",
      "Systematic literature review",
      "Longitudinal meta-analysis",
      "AI mitigation strategies",
      "MLOps frameworks",
      "Test case prioritization",
      "Backlog prioritization",
      "Defect detection",
      "AI model management",
      "Ethical AI",
      "Continuous integration and delivery",
      "Large Language Models (LLMs)",
      "Security threats to AI systems"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/07a58339b1eddc506b957cf91ea17462043876e5.pdf",
    "citation_key": "daniel2023kvs",
    "metadata": {
      "title": "AI for Agile development: a Meta-Analysis",
      "authors": [
        "Beatriz Cabrero Daniel"
      ],
      "published_date": "2023",
      "abstract": "This study explores the benefits and challenges of integrating Artificial Intelligence with Agile software development methodologies, focusing on improving continuous integration and delivery. A systematic literature review and longitudinal meta-analysis of the retrieved studies was conducted to analyse the role of Artificial Intelligence and it's future applications within Agile software development. The review helped identify critical challenges, such as the need for specialised socio-technical expertise. While Artificial Intelligence holds promise for improved software development practices, further research is needed to better understand its impact on processes and practitioners, and to address the indirect challenges associated with its implementation.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/07a58339b1eddc506b957cf91ea17462043876e5.pdf",
      "venue": "arXiv.org",
      "citationCount": 5,
      "score": 2.5,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n### Focused Summary for Literature Review\n\n**CITATION**: \\cite{daniel2023kvs}\n\n1.  **Research Problem & Motivation**\n    *   **Specific Technical Problem**: The paper addresses the inefficiencies and manual nature of certain Agile software development processes, including task allocation, backlog prioritization, test case reduction, and test case prioritization \\cite{daniel2023kvs}.\n    *   **Importance and Challenge**: The problem is critical due to the market's demand for faster software releases while maintaining high quality. Traditional manual Agile processes struggle to meet these demands. Integrating AI introduces new complexities related to AI model management, deployment, monitoring, and ensuring the trustworthiness and security of AI-assisted systems \\cite{daniel2023kvs}.\n\n2.  **Related Work & Positioning**\n    *   **Relation to Existing Approaches**: This work is a meta-analysis of existing literature, synthesizing how AI is being integrated into Agile practices. It acknowledges the growing trend of using AI/ML techniques in software development for tasks like risk management, task allocation, code analysis, and test case prioritization \\cite{daniel2023kvs}. It also notes the emergence of Large Language Models (LLMs) as potential tools for architectural analysis and evaluation \\cite{daniel2023kvs}.\n    *   **Limitations of Previous Solutions**: The paper highlights that existing literature points to significant challenges in integrating AI with Agile, including issues beyond the development process itself, such as AI model management, deployment, and monitoring \\cite{daniel2023kvs}. Previous solutions often lack standardized processes, face socio-technical limitations, and suffer from a scarcity of human expertise capable of bridging AI and Agile domains \\cite{daniel2023kvs}.\n\n3.  **Technical Approach & Innovation**\n    *   **Core Technical Method**: The paper's core method is a systematic literature review and longitudinal meta-analysis. This involved defining a review protocol, conducting extensive searches across major academic databases (ACM Digital Library, Springer, IEEE Xplore, ScienceDirect, Google Scholar), and applying strict inclusion/exclusion criteria to select relevant studies \\cite{daniel2023kvs}.\n    *   **Novelty/Difference**: The novelty lies in its comprehensive, longitudinal meta-analysis approach to draw a \"bigger picture\" of the evolving field of AI for Agile software development. This work synthesizes findings from a broad range of studies, identifying overarching trends, specific AI mitigation strategies (M1-M5), and emerging challenges (RQ3) related to the integration of AI into Agile practices \\cite{daniel2023kvs}. The longitudinal aspect allows for the study of temporary trends in the literature, such as the increasing prevalence of ethical AI topics \\cite{daniel2023kvs}.\n\n4.  **Key Technical Contributions**\n    *   **Novel Algorithms, Methods, or Techniques (Identified from Literature)**: While the paper itself does not propose new algorithms, it *identifies and categorizes* several AI-based mitigation strategies from the literature that represent technical innovations:\n        *   **M1: Integration of AI techniques within DevOps pipelines** to facilitate continuous and rapid development at scale \\cite{daniel2023kvs}.\n        *   **M2: Automatic tools for defect detection and code quality improvement**, reducing development time and increasing efficiency in test-driven development \\cite{daniel2023kvs}.\n        *   **M3: AI-enabled dynamic re-prioritization of test cases** for automatic regression test selection and prioritization, significantly reducing testing efforts in continuous integration \\cite{daniel2023kvs}.\n        *   **M4: AI for identifying dependencies and conflicts in requirements** \\cite{daniel2023kvs}.\n        *   **M5: ML algorithms for predicting the impact of backlog changes and recommending user story prioritization** based on factors like feature importance, effort, and business value \\cite{daniel2023kvs}.\n    *   **System Design or Architectural Innovations**: The paper highlights the need for unified frameworks like MLOps to address the continuous deployment of ML-driven projects, suggesting an architectural shift towards integrating AI model management with DevOps principles \\cite{daniel2023kvs}.\n    *   **Theoretical Insights or Analysis**: The paper provides a structured analysis of the interplay between AI and Agile, categorizing challenges (RQ1) and mapping them to specific AI mitigation strategies (RQ2) (Table 1). It also identifies emerging indirect challenges, such as security threats to deep neural networks and LLMs, data source appropriateness, and the need for ethical AI frameworks \\cite{daniel2023kvs}.\n\n5.  **Experimental Validation**\n    *   **Experiments Conducted**: The \"validation\" in this meta-analysis context refers to the systematic process of collecting and analyzing existing research. The authors conducted a systematic literature review by querying four formal databases (ACM Digital Library, Springer, IEEE Xplore, ScienceDirect) and Google Scholar, identifying 5446 initial papers \\cite{daniel2023kvs}. After a rigorous screening process based on title and abstract, 377 peer-reviewed articles were selected for in-depth data extraction and analysis \\cite{daniel2023kvs}.\n    *   **Key Performance Metrics and Comparison Results**: The paper presents quantitative trends, such as the \"evolution of the number of publications on AI-enhanced Agile processes\" (Figure 2), showing a rapid increase in interest and research in this area \\cite{daniel2023kvs}. It also quantifies the \"Prevalence of Ethical AI topics\" (Figure 1), indicating a significant rise since 2000, especially with LLMs \\cite{daniel2023kvs}. The primary \"results\" are the identified categories of Agile challenges (RQ1), the five AI mitigation strategies (M1-M5) and their mapping to challenges (Table 1), and the emerging challenges in AI-assisted Agile (RQ3), all derived from the synthesized literature \\cite{daniel2023kvs}.\n\n6.  **Limitations & Scope**\n    *   **Technical Limitations or Assumptions**: The paper's findings are limited by the scope and quality of the existing literature included in the meta-analysis. It assumes that the retrieved studies accurately reflect the state of AI-Agile integration. The exclusion of studies about Agile methodologies *for* AI-related software development narrows its focus to AI *assisting* Agile, rather than Agile *managing* AI projects \\cite{daniel2023kvs}.\n    *   **Scope of Applicability**: The analysis is applicable to understanding the current landscape, benefits, and challenges of integrating AI into traditional Agile software development processes, particularly for improving continuous integration and delivery. It provides a high-level overview rather than deep technical details of specific AI algorithms or their implementation \\cite{daniel2023kvs}.\n\n7.  **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This meta-analysis significantly advances the technical state-of-the-art by providing a structured, evidence-based overview of how AI is being leveraged to enhance Agile practices. It systematically identifies and categorizes the specific technical problems in Agile that AI can address and the types of AI solutions being proposed (e.g., automated testing, intelligent prioritization, dependency detection) \\cite{daniel2023kvs}. It also highlights critical emerging technical challenges, such as securing AI systems against adversarial attacks and the need for robust MLOps frameworks \\cite{daniel2023kvs}.\n    *   **Potential Impact on Future Research**: The paper's findings directly inform future research by identifying gaps, such as the need for more empirical studies on the actual use of AI tools in practice (e.g., JIRA integration) and further research into human factors in AI-assisted development \\cite{daniel2023kvs}. It underscores the importance of developing unified frameworks for continuous deployment in ML-driven projects (MLOps) and integrating ethical considerations into AI software development \\cite{daniel2023kvs}.",
      "keywords": [
        "AI for Agile software development",
        "Systematic literature review",
        "Longitudinal meta-analysis",
        "AI mitigation strategies",
        "MLOps frameworks",
        "Test case prioritization",
        "Backlog prioritization",
        "Defect detection",
        "AI model management",
        "Ethical AI",
        "Continuous integration and delivery",
        "Large Language Models (LLMs)",
        "Security threats to AI systems"
      ],
      "paper_type": "based on the abstract and introduction, this paper is a **survey**.\n\nhere's why:\n\n*   **abstract:** explicitly states \"a systematic literature review and longitudinal meta-analysis of the retrieved studies was conducted to analyse the role of artificial intelligence and it's future applications within agile software development.\" it also mentions \"the review helped identify critical challenges.\"\n*   **introduction:** states \"this paper reports the trends shown in the literature regarding the challenges of agile software development (rq1) and the usage of ai to mitigate them (rq2). this meta-analysis draws the bigger picture of the field of ai for agile software developme\".\n*   **title:** \"ai for agile development: a meta-analysis\" – a meta-analysis is a type of systematic review, which falls under the umbrella of a survey paper.\n\nthese phrases directly align with the \"survey\" classification criteria, which mentions \"survey\", \"review\", \"comprehensive analysis\", and \"literature organization\". while a meta-analysis involves statistical aggregation (which has an empirical aspect), its primary goal in this context is to synthesize and review existing literature, making \"survey\" the most appropriate overall classification."
    },
    "file_name": "07a58339b1eddc506b957cf91ea17462043876e5.pdf"
  },
  {
    "success": true,
    "doc_id": "00015edc93f3c0080b3c30daa34ee5ad",
    "summary": "The integration of artificial intelligence (AI) in software development has revolutionized the industry, leading to faster and more accurate results. However, the implementation of AI requires a robust framework to ensure effective planning, design, implementation, and maintenance of AI-enabled software systems. The Open Group Architecture Framework (TOGAF) provides such a framework, enabling organizations to develop a structured and integrated approach to AI-enabled software development. In this journal, we present a case study of how a software house utilized the TOGAF framework to integrate AI in their software development processes. We discuss the challenges faced by the organization in the integration process and how the TOGAF framework provided a structured approach to overcome these challenges. We also highlight the benefits that the organization realized through the implementation of AI-enabled software systems. The case study presented in this journal demonstrates the applicability of the TOGAF framework in AI-enabled software development, and its potential to enhance the capabilities and competitiveness of software houses. The TOGAF framework provides a structured approach to the integration of AI in software development, ensuring that organizations can effectively leverage the benefits of AI while minimizing the associated risks and challenges.",
    "intriguing_abstract": "The integration of artificial intelligence (AI) in software development has revolutionized the industry, leading to faster and more accurate results. However, the implementation of AI requires a robust framework to ensure effective planning, design, implementation, and maintenance of AI-enabled software systems. The Open Group Architecture Framework (TOGAF) provides such a framework, enabling organizations to develop a structured and integrated approach to AI-enabled software development. In this journal, we present a case study of how a software house utilized the TOGAF framework to integrate AI in their software development processes. We discuss the challenges faced by the organization in the integration process and how the TOGAF framework provided a structured approach to overcome these challenges. We also highlight the benefits that the organization realized through the implementation of AI-enabled software systems. The case study presented in this journal demonstrates the applicability of the TOGAF framework in AI-enabled software development, and its potential to enhance the capabilities and competitiveness of software houses. The TOGAF framework provides a structured approach to the integration of AI in software development, ensuring that organizations can effectively leverage the benefits of AI while minimizing the associated risks and challenges.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/cdaf140efda70b353f6e790849e20a552209c936.pdf",
    "citation_key": "crosley2023931",
    "metadata": {
      "title": "TOGAF Framework For an AI-enabled Software House",
      "authors": [
        "Nathaniel Crosley",
        "R. E. Indrajit",
        "Erick Dazki"
      ],
      "published_date": "2023",
      "abstract": "The integration of artificial intelligence (AI) in software development has revolutionized the industry, leading to faster and more accurate results. However, the implementation of AI requires a robust framework to ensure effective planning, design, implementation, and maintenance of AI-enabled software systems. The Open Group Architecture Framework (TOGAF) provides such a framework, enabling organizations to develop a structured and integrated approach to AI-enabled software development. In this journal, we present a case study of how a software house utilized the TOGAF framework to integrate AI in their software development processes. We discuss the challenges faced by the organization in the integration process and how the TOGAF framework provided a structured approach to overcome these challenges. We also highlight the benefits that the organization realized through the implementation of AI-enabled software systems. The case study presented in this journal demonstrates the applicability of the TOGAF framework in AI-enabled software development, and its potential to enhance the capabilities and competitiveness of software houses. The TOGAF framework provides a structured approach to the integration of AI in software development, ensuring that organizations can effectively leverage the benefits of AI while minimizing the associated risks and challenges.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/cdaf140efda70b353f6e790849e20a552209c936.pdf",
      "venue": "SinkrOn",
      "citationCount": 5,
      "score": 2.5,
      "summary": "The integration of artificial intelligence (AI) in software development has revolutionized the industry, leading to faster and more accurate results. However, the implementation of AI requires a robust framework to ensure effective planning, design, implementation, and maintenance of AI-enabled software systems. The Open Group Architecture Framework (TOGAF) provides such a framework, enabling organizations to develop a structured and integrated approach to AI-enabled software development. In this journal, we present a case study of how a software house utilized the TOGAF framework to integrate AI in their software development processes. We discuss the challenges faced by the organization in the integration process and how the TOGAF framework provided a structured approach to overcome these challenges. We also highlight the benefits that the organization realized through the implementation of AI-enabled software systems. The case study presented in this journal demonstrates the applicability of the TOGAF framework in AI-enabled software development, and its potential to enhance the capabilities and competitiveness of software houses. The TOGAF framework provides a structured approach to the integration of AI in software development, ensuring that organizations can effectively leverage the benefits of AI while minimizing the associated risks and challenges.",
      "keywords": []
    },
    "file_name": "cdaf140efda70b353f6e790849e20a552209c936.pdf"
  },
  {
    "success": true,
    "doc_id": "f99417590e2f1c7147861d6eaa837d83",
    "summary": "As the world takes cognizance of AI's growing role in greenhouse gas(GHG) and carbon emissions, the focus of AI research & development is shifting towards inclusion of energy efficiency as another core metric. Sustainability, a core agenda for most organizations, is also being viewed as a core non-functional requirement in software engineering. A similar effort is being undertaken to extend sustainability principles to AI-based systems with focus on energy efficient training and inference techniques. But an important question arises, does there even exist any metrics or methods which can quantify adoption of “green” practices in the life cycle of AI-based systems? There is a huge gap which exists between the growing research corpus related to sustainable practices in AI research and its adoption at an industry scale. The goal of this work is to introduce a methodology and novel metric for assessing “greenness” of any AI-based system and its development process, based on energy efficient AI research and practices. The novel metric, termed as Green AI Quotient, would be a key step towards AI practitioner's Green AI journey. Empirical validation of our approach suggest that Green AI Quotient is able to encourage adoption and raise awareness regarding sustainable practices in AI lifecycle.",
    "intriguing_abstract": "As the world takes cognizance of AI's growing role in greenhouse gas(GHG) and carbon emissions, the focus of AI research & development is shifting towards inclusion of energy efficiency as another core metric. Sustainability, a core agenda for most organizations, is also being viewed as a core non-functional requirement in software engineering. A similar effort is being undertaken to extend sustainability principles to AI-based systems with focus on energy efficient training and inference techniques. But an important question arises, does there even exist any metrics or methods which can quantify adoption of “green” practices in the life cycle of AI-based systems? There is a huge gap which exists between the growing research corpus related to sustainable practices in AI research and its adoption at an industry scale. The goal of this work is to introduce a methodology and novel metric for assessing “greenness” of any AI-based system and its development process, based on energy efficient AI research and practices. The novel metric, termed as Green AI Quotient, would be a key step towards AI practitioner's Green AI journey. Empirical validation of our approach suggest that Green AI Quotient is able to encourage adoption and raise awareness regarding sustainable practices in AI lifecycle.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/618c4f35e06f79e1c71657b9e6c00df97e6ece12.pdf",
    "citation_key": "sikand2023n63",
    "metadata": {
      "title": "Green AI Quotient: Assessing Greenness of AI-based software and the way forward",
      "authors": [
        "Samarth Sikand",
        "V. Sharma",
        "Vikrant S. Kaulgud",
        "Sanjay Podder"
      ],
      "published_date": "2023",
      "abstract": "As the world takes cognizance of AI's growing role in greenhouse gas(GHG) and carbon emissions, the focus of AI research & development is shifting towards inclusion of energy efficiency as another core metric. Sustainability, a core agenda for most organizations, is also being viewed as a core non-functional requirement in software engineering. A similar effort is being undertaken to extend sustainability principles to AI-based systems with focus on energy efficient training and inference techniques. But an important question arises, does there even exist any metrics or methods which can quantify adoption of “green” practices in the life cycle of AI-based systems? There is a huge gap which exists between the growing research corpus related to sustainable practices in AI research and its adoption at an industry scale. The goal of this work is to introduce a methodology and novel metric for assessing “greenness” of any AI-based system and its development process, based on energy efficient AI research and practices. The novel metric, termed as Green AI Quotient, would be a key step towards AI practitioner's Green AI journey. Empirical validation of our approach suggest that Green AI Quotient is able to encourage adoption and raise awareness regarding sustainable practices in AI lifecycle.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/618c4f35e06f79e1c71657b9e6c00df97e6ece12.pdf",
      "venue": "International Conference on Automated Software Engineering",
      "citationCount": 5,
      "score": 2.5,
      "summary": "As the world takes cognizance of AI's growing role in greenhouse gas(GHG) and carbon emissions, the focus of AI research & development is shifting towards inclusion of energy efficiency as another core metric. Sustainability, a core agenda for most organizations, is also being viewed as a core non-functional requirement in software engineering. A similar effort is being undertaken to extend sustainability principles to AI-based systems with focus on energy efficient training and inference techniques. But an important question arises, does there even exist any metrics or methods which can quantify adoption of “green” practices in the life cycle of AI-based systems? There is a huge gap which exists between the growing research corpus related to sustainable practices in AI research and its adoption at an industry scale. The goal of this work is to introduce a methodology and novel metric for assessing “greenness” of any AI-based system and its development process, based on energy efficient AI research and practices. The novel metric, termed as Green AI Quotient, would be a key step towards AI practitioner's Green AI journey. Empirical validation of our approach suggest that Green AI Quotient is able to encourage adoption and raise awareness regarding sustainable practices in AI lifecycle.",
      "keywords": []
    },
    "file_name": "618c4f35e06f79e1c71657b9e6c00df97e6ece12.pdf"
  },
  {
    "success": true,
    "doc_id": "fb6cb67e77b558b6218934f87934bd3c",
    "summary": "Software Defined Networking (SDN) threats make network components vulnerable to cyber-attacks, creating obstacles for new model development that necessitate innovative security countermeasures, like Intrusion Detection Systems (IDSs). The centralized SDN controller, which has global view and control over the whole network and the availability of processing and storing capabilities, makes the deployment of artificial intelligence-based IDS in controllers a hot topic in the research community to resolve security issues. In order to develop effective AI-based IDSs in an SDN environment, there must be a high-quality dataset for training the model to offer effective and accurate attack prediction. There are some intrusion detection datasets used by researchers, but those datasets are either outdated or incompatible with the SDN environment. In this survey, an overview of the published work was conducted using the InSDN dataset from 2020 to 2023. Also, research challenges and future work for further research on IDS issues when deployed in an SDN environment are discussed, particularly when employing machine learning and deep learning models. Moreover, possible solutions for each issue are provided to help the researchers carry out and develop new methods of secure SDN.",
    "intriguing_abstract": "Software Defined Networking (SDN) threats make network components vulnerable to cyber-attacks, creating obstacles for new model development that necessitate innovative security countermeasures, like Intrusion Detection Systems (IDSs). The centralized SDN controller, which has global view and control over the whole network and the availability of processing and storing capabilities, makes the deployment of artificial intelligence-based IDS in controllers a hot topic in the research community to resolve security issues. In order to develop effective AI-based IDSs in an SDN environment, there must be a high-quality dataset for training the model to offer effective and accurate attack prediction. There are some intrusion detection datasets used by researchers, but those datasets are either outdated or incompatible with the SDN environment. In this survey, an overview of the published work was conducted using the InSDN dataset from 2020 to 2023. Also, research challenges and future work for further research on IDS issues when deployed in an SDN environment are discussed, particularly when employing machine learning and deep learning models. Moreover, possible solutions for each issue are provided to help the researchers carry out and develop new methods of secure SDN.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/5f5bf0a5d1a1a678b56308af103c2f72aba1aae3.pdf",
    "citation_key": "khalid2024hbp",
    "metadata": {
      "title": "A Survey on the Latest Intrusion Detection Datasets for Software Defined Networking Environments",
      "authors": [
        "Harman Yousif Ibrahim Khalid",
        "Najlaa Aldabagh"
      ],
      "published_date": "2024",
      "abstract": "Software Defined Networking (SDN) threats make network components vulnerable to cyber-attacks, creating obstacles for new model development that necessitate innovative security countermeasures, like Intrusion Detection Systems (IDSs). The centralized SDN controller, which has global view and control over the whole network and the availability of processing and storing capabilities, makes the deployment of artificial intelligence-based IDS in controllers a hot topic in the research community to resolve security issues. In order to develop effective AI-based IDSs in an SDN environment, there must be a high-quality dataset for training the model to offer effective and accurate attack prediction. There are some intrusion detection datasets used by researchers, but those datasets are either outdated or incompatible with the SDN environment. In this survey, an overview of the published work was conducted using the InSDN dataset from 2020 to 2023. Also, research challenges and future work for further research on IDS issues when deployed in an SDN environment are discussed, particularly when employing machine learning and deep learning models. Moreover, possible solutions for each issue are provided to help the researchers carry out and develop new methods of secure SDN.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/5f5bf0a5d1a1a678b56308af103c2f72aba1aae3.pdf",
      "venue": "Engineering, Technology &amp; Applied Science Research",
      "citationCount": 8,
      "score": 8.0,
      "summary": "Software Defined Networking (SDN) threats make network components vulnerable to cyber-attacks, creating obstacles for new model development that necessitate innovative security countermeasures, like Intrusion Detection Systems (IDSs). The centralized SDN controller, which has global view and control over the whole network and the availability of processing and storing capabilities, makes the deployment of artificial intelligence-based IDS in controllers a hot topic in the research community to resolve security issues. In order to develop effective AI-based IDSs in an SDN environment, there must be a high-quality dataset for training the model to offer effective and accurate attack prediction. There are some intrusion detection datasets used by researchers, but those datasets are either outdated or incompatible with the SDN environment. In this survey, an overview of the published work was conducted using the InSDN dataset from 2020 to 2023. Also, research challenges and future work for further research on IDS issues when deployed in an SDN environment are discussed, particularly when employing machine learning and deep learning models. Moreover, possible solutions for each issue are provided to help the researchers carry out and develop new methods of secure SDN.",
      "keywords": []
    },
    "file_name": "5f5bf0a5d1a1a678b56308af103c2f72aba1aae3.pdf"
  },
  {
    "success": true,
    "doc_id": "80bca3ed8352e8b1bc02aca35b00dcb6",
    "summary": "Vehicular Ad Hoc Networks (VANETs) are wireless networks that improve traffic efficiency, safety, and comfort for smart vehicle users. However, with the rise of smart and electric vehicles, traditional VANETs struggle with issues like scalability, management, energy efficiency, and dynamic pricing. Software Defined Networking (SDN) can help address these challenges by centralizing network control. The integration of SDN with VANETs, forming Software Defined-based VANETs (SD-VANETs), shows promise for intelligent transportation, particularly with autonomous vehicles. Nevertheless, SD-VANETs are susceptible to cyberattacks, especially Distributed Denial of Service (DDoS) attacks, making cybersecurity a crucial consideration for their future development. This study proposes a security system that incorporates a hybrid artificial intelligence model to detect DDoS attacks targeting the SDN controller in SD-VANET architecture. The proposed system is designed to operate as a module within the SDN controller, enabling the detection of DDoS attacks. The proposed attack detection methodology involves the collection of network traffic data, data processing, and the classification of these data. This methodology is based on a hybrid artificial intelligence model that combines a one-dimensional Convolutional Neural Network (1D-CNN) and Decision Tree models. According to experimental results, the proposed attack detection system identified that approximately 90% of the traffic in the SD-VANET network under DDoS attack consisted of malicious DDoS traffic flows. These results demonstrate that the proposed security system provides a promising solution for detecting DDoS attacks targeting the SD-VANET architecture.",
    "intriguing_abstract": "Vehicular Ad Hoc Networks (VANETs) are wireless networks that improve traffic efficiency, safety, and comfort for smart vehicle users. However, with the rise of smart and electric vehicles, traditional VANETs struggle with issues like scalability, management, energy efficiency, and dynamic pricing. Software Defined Networking (SDN) can help address these challenges by centralizing network control. The integration of SDN with VANETs, forming Software Defined-based VANETs (SD-VANETs), shows promise for intelligent transportation, particularly with autonomous vehicles. Nevertheless, SD-VANETs are susceptible to cyberattacks, especially Distributed Denial of Service (DDoS) attacks, making cybersecurity a crucial consideration for their future development. This study proposes a security system that incorporates a hybrid artificial intelligence model to detect DDoS attacks targeting the SDN controller in SD-VANET architecture. The proposed system is designed to operate as a module within the SDN controller, enabling the detection of DDoS attacks. The proposed attack detection methodology involves the collection of network traffic data, data processing, and the classification of these data. This methodology is based on a hybrid artificial intelligence model that combines a one-dimensional Convolutional Neural Network (1D-CNN) and Decision Tree models. According to experimental results, the proposed attack detection system identified that approximately 90% of the traffic in the SD-VANET network under DDoS attack consisted of malicious DDoS traffic flows. These results demonstrate that the proposed security system provides a promising solution for detecting DDoS attacks targeting the SD-VANET architecture.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/61048abbcfcbdd16e6ca85ca0d3fd32d6f5c0ca3.pdf",
    "citation_key": "polat2024nwv",
    "metadata": {
      "title": "Hybrid AI-Powered Real-Time Distributed Denial of Service Detection and Traffic Monitoring for Software-Defined-Based Vehicular Ad Hoc Networks: A New Paradigm for Securing Intelligent Transportation Networks",
      "authors": [
        "Onur Polat",
        "Saadin Oyucu",
        "Muammer Türkoglu",
        "Hüseyin Polat",
        "Ahmet Aksoz",
        "Fahri Yardımcı"
      ],
      "published_date": "2024",
      "abstract": "Vehicular Ad Hoc Networks (VANETs) are wireless networks that improve traffic efficiency, safety, and comfort for smart vehicle users. However, with the rise of smart and electric vehicles, traditional VANETs struggle with issues like scalability, management, energy efficiency, and dynamic pricing. Software Defined Networking (SDN) can help address these challenges by centralizing network control. The integration of SDN with VANETs, forming Software Defined-based VANETs (SD-VANETs), shows promise for intelligent transportation, particularly with autonomous vehicles. Nevertheless, SD-VANETs are susceptible to cyberattacks, especially Distributed Denial of Service (DDoS) attacks, making cybersecurity a crucial consideration for their future development. This study proposes a security system that incorporates a hybrid artificial intelligence model to detect DDoS attacks targeting the SDN controller in SD-VANET architecture. The proposed system is designed to operate as a module within the SDN controller, enabling the detection of DDoS attacks. The proposed attack detection methodology involves the collection of network traffic data, data processing, and the classification of these data. This methodology is based on a hybrid artificial intelligence model that combines a one-dimensional Convolutional Neural Network (1D-CNN) and Decision Tree models. According to experimental results, the proposed attack detection system identified that approximately 90% of the traffic in the SD-VANET network under DDoS attack consisted of malicious DDoS traffic flows. These results demonstrate that the proposed security system provides a promising solution for detecting DDoS attacks targeting the SD-VANET architecture.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/61048abbcfcbdd16e6ca85ca0d3fd32d6f5c0ca3.pdf",
      "venue": "Applied Sciences",
      "citationCount": 6,
      "score": 6.0,
      "summary": "Vehicular Ad Hoc Networks (VANETs) are wireless networks that improve traffic efficiency, safety, and comfort for smart vehicle users. However, with the rise of smart and electric vehicles, traditional VANETs struggle with issues like scalability, management, energy efficiency, and dynamic pricing. Software Defined Networking (SDN) can help address these challenges by centralizing network control. The integration of SDN with VANETs, forming Software Defined-based VANETs (SD-VANETs), shows promise for intelligent transportation, particularly with autonomous vehicles. Nevertheless, SD-VANETs are susceptible to cyberattacks, especially Distributed Denial of Service (DDoS) attacks, making cybersecurity a crucial consideration for their future development. This study proposes a security system that incorporates a hybrid artificial intelligence model to detect DDoS attacks targeting the SDN controller in SD-VANET architecture. The proposed system is designed to operate as a module within the SDN controller, enabling the detection of DDoS attacks. The proposed attack detection methodology involves the collection of network traffic data, data processing, and the classification of these data. This methodology is based on a hybrid artificial intelligence model that combines a one-dimensional Convolutional Neural Network (1D-CNN) and Decision Tree models. According to experimental results, the proposed attack detection system identified that approximately 90% of the traffic in the SD-VANET network under DDoS attack consisted of malicious DDoS traffic flows. These results demonstrate that the proposed security system provides a promising solution for detecting DDoS attacks targeting the SD-VANET architecture.",
      "keywords": []
    },
    "file_name": "61048abbcfcbdd16e6ca85ca0d3fd32d6f5c0ca3.pdf"
  },
  {
    "success": true,
    "doc_id": "4e188a3579b973a4748a1759f8a89876",
    "summary": "We apply AI‐assisted large language model (LLM) capabilities of GPT‐3 targeting high‐performance computing (HPC) kernels for (i) code generation, and (ii) auto‐parallelization of serial code in C ++, Fortran, Python and Julia. Our scope includes the following fundamental numerical kernels: AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG, and language/programming models: (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numpy, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). Kernel implementations are generated using GitHub Copilot capabilities powered by the GPT‐based OpenAI Codex available in Visual Studio Code given simple + + prompt variants. To quantify and compare the generated results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. For auto‐parallelization, we use ChatGPT interactively giving simple prompts as in a dialogue with another human including simple “prompt engineering” follow ups. Results suggest that correct outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general‐purpose Python can benefit from adding language keywords, while Julia prompts perform acceptably well for its Threads and CUDA.jl programming models. We expect to provide an initial quantifiable point of reference for code generation in each programming model using a state‐of‐the‐art LLM. Overall, understanding the convergence of LLMs, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human‐computer interactions.",
    "intriguing_abstract": "We apply AI‐assisted large language model (LLM) capabilities of GPT‐3 targeting high‐performance computing (HPC) kernels for (i) code generation, and (ii) auto‐parallelization of serial code in C ++, Fortran, Python and Julia. Our scope includes the following fundamental numerical kernels: AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG, and language/programming models: (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numpy, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). Kernel implementations are generated using GitHub Copilot capabilities powered by the GPT‐based OpenAI Codex available in Visual Studio Code given simple + + prompt variants. To quantify and compare the generated results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. For auto‐parallelization, we use ChatGPT interactively giving simple prompts as in a dialogue with another human including simple “prompt engineering” follow ups. Results suggest that correct outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general‐purpose Python can benefit from adding language keywords, while Julia prompts perform acceptably well for its Threads and CUDA.jl programming models. We expect to provide an initial quantifiable point of reference for code generation in each programming model using a state‐of‐the‐art LLM. Overall, understanding the convergence of LLMs, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human‐computer interactions.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/45e026f03d24f668cbcd6ed3edd88e62518650bd.pdf",
    "citation_key": "godoy2024npo",
    "metadata": {
      "title": "Large language model evaluation for high‐performance computing software development",
      "authors": [
        "William F. Godoy",
        "Pedro Valero-Lara",
        "Keita Teranishi",
        "Prasanna Balaprakash",
        "Jeffrey S. Vetter"
      ],
      "published_date": "2024",
      "abstract": "We apply AI‐assisted large language model (LLM) capabilities of GPT‐3 targeting high‐performance computing (HPC) kernels for (i) code generation, and (ii) auto‐parallelization of serial code in C ++, Fortran, Python and Julia. Our scope includes the following fundamental numerical kernels: AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG, and language/programming models: (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numpy, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). Kernel implementations are generated using GitHub Copilot capabilities powered by the GPT‐based OpenAI Codex available in Visual Studio Code given simple + + prompt variants. To quantify and compare the generated results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. For auto‐parallelization, we use ChatGPT interactively giving simple prompts as in a dialogue with another human including simple “prompt engineering” follow ups. Results suggest that correct outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general‐purpose Python can benefit from adding language keywords, while Julia prompts perform acceptably well for its Threads and CUDA.jl programming models. We expect to provide an initial quantifiable point of reference for code generation in each programming model using a state‐of‐the‐art LLM. Overall, understanding the convergence of LLMs, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human‐computer interactions.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/45e026f03d24f668cbcd6ed3edd88e62518650bd.pdf",
      "venue": "Concurrency and Computation",
      "citationCount": 6,
      "score": 6.0,
      "summary": "We apply AI‐assisted large language model (LLM) capabilities of GPT‐3 targeting high‐performance computing (HPC) kernels for (i) code generation, and (ii) auto‐parallelization of serial code in C ++, Fortran, Python and Julia. Our scope includes the following fundamental numerical kernels: AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG, and language/programming models: (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numpy, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). Kernel implementations are generated using GitHub Copilot capabilities powered by the GPT‐based OpenAI Codex available in Visual Studio Code given simple + + prompt variants. To quantify and compare the generated results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. For auto‐parallelization, we use ChatGPT interactively giving simple prompts as in a dialogue with another human including simple “prompt engineering” follow ups. Results suggest that correct outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general‐purpose Python can benefit from adding language keywords, while Julia prompts perform acceptably well for its Threads and CUDA.jl programming models. We expect to provide an initial quantifiable point of reference for code generation in each programming model using a state‐of‐the‐art LLM. Overall, understanding the convergence of LLMs, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human‐computer interactions.",
      "keywords": []
    },
    "file_name": "45e026f03d24f668cbcd6ed3edd88e62518650bd.pdf"
  },
  {
    "success": true,
    "doc_id": "126e23c9e6fe61d54f9a758c5d7eb68c",
    "summary": "Introduction Surgical patients frequently experience post-operative complications at home. Digital remote monitoring of surgical wounds via image-based systems has emerged as a promising solution for early detection and intervention. However, the increased clinician workload from reviewing patient-submitted images presents a challenge. This study utilises artificial intelligence (AI) to prioritise surgical wound images for clinician review, aiming to efficiently manage workload. Methods and analysis Conducted from September 2023 to March 2024, the study phases included compiling a training dataset of 37,974 images, creating a testing set of 3,634 images, developing an AI algorithm using ’You Only Look Once’ models, and conducting prospective tests compared against clinical nurse specialists’ evaluations. The primary objective was to validate the AI’s sensitivity in prioritising wound reviews, alongside assessing intra-rater reliability. Secondary objectives focused on specificity, positive predictive value (PPV), and negative predictive value (NPV) for various wound features. Results The AI demonstrated a sensitivity of 89%, exceeding the target of 85% and proving effective in identifying cases requiring priority review. Intra-rater reliability was perfect, achieving 100% consistency in repeated assessments. Observations indicated variations in detecting wound characteristics across different skin tones; sensitivity was notably lower for incisional separation and discolouration in darker skin tones. Specificity remained high overall, with some results favouring darker skin tones. The NPV were similar for both light and dark skin tones. However, the NPV was slightly higher for dark skin tones at 95% (95% CI: 93%-97%) compared to 91% (95% CI: 87%-92%) for light skin tones. Both PPV and NPV varied, especially in identifying sutures or staples, indicating areas needing further refinement to ensure equitable accuracy. Conclusion The AI algorithm not only met but surpassed the expected sensitivity for identifying priority cases, showing high reliability. Nonetheless, the disparities in performance across skin tones, especially in recognising certain wound characteristics like discolouration or incisional separation, underline the need for ongoing training and adaptation of the AI to ensure fairness and effectiveness across diverse patient groups.",
    "intriguing_abstract": "Introduction Surgical patients frequently experience post-operative complications at home. Digital remote monitoring of surgical wounds via image-based systems has emerged as a promising solution for early detection and intervention. However, the increased clinician workload from reviewing patient-submitted images presents a challenge. This study utilises artificial intelligence (AI) to prioritise surgical wound images for clinician review, aiming to efficiently manage workload. Methods and analysis Conducted from September 2023 to March 2024, the study phases included compiling a training dataset of 37,974 images, creating a testing set of 3,634 images, developing an AI algorithm using ’You Only Look Once’ models, and conducting prospective tests compared against clinical nurse specialists’ evaluations. The primary objective was to validate the AI’s sensitivity in prioritising wound reviews, alongside assessing intra-rater reliability. Secondary objectives focused on specificity, positive predictive value (PPV), and negative predictive value (NPV) for various wound features. Results The AI demonstrated a sensitivity of 89%, exceeding the target of 85% and proving effective in identifying cases requiring priority review. Intra-rater reliability was perfect, achieving 100% consistency in repeated assessments. Observations indicated variations in detecting wound characteristics across different skin tones; sensitivity was notably lower for incisional separation and discolouration in darker skin tones. Specificity remained high overall, with some results favouring darker skin tones. The NPV were similar for both light and dark skin tones. However, the NPV was slightly higher for dark skin tones at 95% (95% CI: 93%-97%) compared to 91% (95% CI: 87%-92%) for light skin tones. Both PPV and NPV varied, especially in identifying sutures or staples, indicating areas needing further refinement to ensure equitable accuracy. Conclusion The AI algorithm not only met but surpassed the expected sensitivity for identifying priority cases, showing high reliability. Nonetheless, the disparities in performance across skin tones, especially in recognising certain wound characteristics like discolouration or incisional separation, underline the need for ongoing training and adaptation of the AI to ensure fairness and effectiveness across diverse patient groups.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/63ebde6fd1ceafab0a349a0b9352709e60468110.pdf",
    "citation_key": "rochon202411t",
    "metadata": {
      "title": "Wound imaging software and digital platform to assist review of surgical wounds using patient smartphones: The development and evaluation of artificial intelligence (WISDOM AI study)",
      "authors": [
        "Melissa Rochon",
        "Judith Tanner",
        "James Jurkiewicz",
        "Jacqueline Beckhelling",
        "A. Aondoakaa",
        "Keith Wilson",
        "Luxmi Dhoonmoon",
        "Max Underwood",
        "Lara Mason",
        "Roy Harris",
        "Karen Cariaga"
      ],
      "published_date": "2024",
      "abstract": "Introduction Surgical patients frequently experience post-operative complications at home. Digital remote monitoring of surgical wounds via image-based systems has emerged as a promising solution for early detection and intervention. However, the increased clinician workload from reviewing patient-submitted images presents a challenge. This study utilises artificial intelligence (AI) to prioritise surgical wound images for clinician review, aiming to efficiently manage workload. Methods and analysis Conducted from September 2023 to March 2024, the study phases included compiling a training dataset of 37,974 images, creating a testing set of 3,634 images, developing an AI algorithm using ’You Only Look Once’ models, and conducting prospective tests compared against clinical nurse specialists’ evaluations. The primary objective was to validate the AI’s sensitivity in prioritising wound reviews, alongside assessing intra-rater reliability. Secondary objectives focused on specificity, positive predictive value (PPV), and negative predictive value (NPV) for various wound features. Results The AI demonstrated a sensitivity of 89%, exceeding the target of 85% and proving effective in identifying cases requiring priority review. Intra-rater reliability was perfect, achieving 100% consistency in repeated assessments. Observations indicated variations in detecting wound characteristics across different skin tones; sensitivity was notably lower for incisional separation and discolouration in darker skin tones. Specificity remained high overall, with some results favouring darker skin tones. The NPV were similar for both light and dark skin tones. However, the NPV was slightly higher for dark skin tones at 95% (95% CI: 93%-97%) compared to 91% (95% CI: 87%-92%) for light skin tones. Both PPV and NPV varied, especially in identifying sutures or staples, indicating areas needing further refinement to ensure equitable accuracy. Conclusion The AI algorithm not only met but surpassed the expected sensitivity for identifying priority cases, showing high reliability. Nonetheless, the disparities in performance across skin tones, especially in recognising certain wound characteristics like discolouration or incisional separation, underline the need for ongoing training and adaptation of the AI to ensure fairness and effectiveness across diverse patient groups.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/63ebde6fd1ceafab0a349a0b9352709e60468110.pdf",
      "venue": "PLoS ONE",
      "citationCount": 6,
      "score": 6.0,
      "summary": "Introduction Surgical patients frequently experience post-operative complications at home. Digital remote monitoring of surgical wounds via image-based systems has emerged as a promising solution for early detection and intervention. However, the increased clinician workload from reviewing patient-submitted images presents a challenge. This study utilises artificial intelligence (AI) to prioritise surgical wound images for clinician review, aiming to efficiently manage workload. Methods and analysis Conducted from September 2023 to March 2024, the study phases included compiling a training dataset of 37,974 images, creating a testing set of 3,634 images, developing an AI algorithm using ’You Only Look Once’ models, and conducting prospective tests compared against clinical nurse specialists’ evaluations. The primary objective was to validate the AI’s sensitivity in prioritising wound reviews, alongside assessing intra-rater reliability. Secondary objectives focused on specificity, positive predictive value (PPV), and negative predictive value (NPV) for various wound features. Results The AI demonstrated a sensitivity of 89%, exceeding the target of 85% and proving effective in identifying cases requiring priority review. Intra-rater reliability was perfect, achieving 100% consistency in repeated assessments. Observations indicated variations in detecting wound characteristics across different skin tones; sensitivity was notably lower for incisional separation and discolouration in darker skin tones. Specificity remained high overall, with some results favouring darker skin tones. The NPV were similar for both light and dark skin tones. However, the NPV was slightly higher for dark skin tones at 95% (95% CI: 93%-97%) compared to 91% (95% CI: 87%-92%) for light skin tones. Both PPV and NPV varied, especially in identifying sutures or staples, indicating areas needing further refinement to ensure equitable accuracy. Conclusion The AI algorithm not only met but surpassed the expected sensitivity for identifying priority cases, showing high reliability. Nonetheless, the disparities in performance across skin tones, especially in recognising certain wound characteristics like discolouration or incisional separation, underline the need for ongoing training and adaptation of the AI to ensure fairness and effectiveness across diverse patient groups.",
      "keywords": []
    },
    "file_name": "63ebde6fd1ceafab0a349a0b9352709e60468110.pdf"
  },
  {
    "success": true,
    "doc_id": "d83b377ad2bb802aca58f57bf5de7040",
    "summary": "In the fight against cyber attacks, Network Softwarization (NS) is a flexible and adaptable shield, using advanced software to spot malicious activity in regular network traffic. However, the availability of comprehensive datasets for mobile networks, which are fundamental for the development of Machine Learning (ML) solutions for attack detection near their source, is still limited. Cross-Domain Artificial Intelligence (AI) can be the key to address this, although its application in Open Radio Access Network (O-RAN) is still at its infancy. To address these challenges, we deployed an end-to-end O-RAN network, that was used to collect data from the RAN and the transport network. These datasets allow us to combine the knowledge from an in-network ML traffic classifier for attack detection to bolster the training of an ML-based traffic classifier specifically tailored for the RAN. Our results demonstrate the potential of the proposed approach, achieving an accuracy rate of 93%. This approach not only bridges critical gaps in mobile network security but also showcases the potential of cross-domain AI in enhancing the efficacy of network security measures.",
    "intriguing_abstract": "In the fight against cyber attacks, Network Softwarization (NS) is a flexible and adaptable shield, using advanced software to spot malicious activity in regular network traffic. However, the availability of comprehensive datasets for mobile networks, which are fundamental for the development of Machine Learning (ML) solutions for attack detection near their source, is still limited. Cross-Domain Artificial Intelligence (AI) can be the key to address this, although its application in Open Radio Access Network (O-RAN) is still at its infancy. To address these challenges, we deployed an end-to-end O-RAN network, that was used to collect data from the RAN and the transport network. These datasets allow us to combine the knowledge from an in-network ML traffic classifier for attack detection to bolster the training of an ML-based traffic classifier specifically tailored for the RAN. Our results demonstrate the potential of the proposed approach, achieving an accuracy rate of 93%. This approach not only bridges critical gaps in mobile network security but also showcases the potential of cross-domain AI in enhancing the efficacy of network security measures.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/6441e0fd0914f71b462425cf9edc781a7021e0ef.pdf",
    "citation_key": "xavier2024lyl",
    "metadata": {
      "title": "Cross-Domain AI for Early Attack Detection and Defense Against Malicious Flows in O-RAN",
      "authors": [
        "B. M. Xavier",
        "Merim Dzaferagic",
        "Irene Vila",
        "M. Martinello",
        "Marco Ruffini"
      ],
      "published_date": "2024",
      "abstract": "In the fight against cyber attacks, Network Softwarization (NS) is a flexible and adaptable shield, using advanced software to spot malicious activity in regular network traffic. However, the availability of comprehensive datasets for mobile networks, which are fundamental for the development of Machine Learning (ML) solutions for attack detection near their source, is still limited. Cross-Domain Artificial Intelligence (AI) can be the key to address this, although its application in Open Radio Access Network (O-RAN) is still at its infancy. To address these challenges, we deployed an end-to-end O-RAN network, that was used to collect data from the RAN and the transport network. These datasets allow us to combine the knowledge from an in-network ML traffic classifier for attack detection to bolster the training of an ML-based traffic classifier specifically tailored for the RAN. Our results demonstrate the potential of the proposed approach, achieving an accuracy rate of 93%. This approach not only bridges critical gaps in mobile network security but also showcases the potential of cross-domain AI in enhancing the efficacy of network security measures.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/6441e0fd0914f71b462425cf9edc781a7021e0ef.pdf",
      "venue": "ICC 2024 - IEEE International Conference on Communications",
      "citationCount": 6,
      "score": 6.0,
      "summary": "In the fight against cyber attacks, Network Softwarization (NS) is a flexible and adaptable shield, using advanced software to spot malicious activity in regular network traffic. However, the availability of comprehensive datasets for mobile networks, which are fundamental for the development of Machine Learning (ML) solutions for attack detection near their source, is still limited. Cross-Domain Artificial Intelligence (AI) can be the key to address this, although its application in Open Radio Access Network (O-RAN) is still at its infancy. To address these challenges, we deployed an end-to-end O-RAN network, that was used to collect data from the RAN and the transport network. These datasets allow us to combine the knowledge from an in-network ML traffic classifier for attack detection to bolster the training of an ML-based traffic classifier specifically tailored for the RAN. Our results demonstrate the potential of the proposed approach, achieving an accuracy rate of 93%. This approach not only bridges critical gaps in mobile network security but also showcases the potential of cross-domain AI in enhancing the efficacy of network security measures.",
      "keywords": []
    },
    "file_name": "6441e0fd0914f71b462425cf9edc781a7021e0ef.pdf"
  },
  {
    "success": true,
    "doc_id": "d725509da812d9ac473a46702cffb567",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical and challenging problem of security vulnerabilities within Continuous Integration/Continuous Deployment (CI/CD) pipelines, particularly when deployed in cloud environments \\cite{saleh2024mrl}.\n    *   Despite CI/CD's role in rapid software delivery, it introduces significant security risks, including DDoS, Bot attacks, and supply chain vulnerabilities (e.g., Log4j, SolarWinds, CodeCov), which can lead to unauthorized access, data loss, and code manipulation \\cite{saleh2024mrl}.\n    *   Existing security measures often fall short in providing real-time attack detection, suffer from high false positive rates, and are resource-intensive, necessitating a more robust and adaptive solution \\cite{saleh2024mrl}.\n\n*   **Related Work & Positioning**\n    *   Previous approaches primarily rely on static application security testing (SAST), dynamic application security testing (DAST), source composition analysis (SCA), access controls, and continuous monitoring \\cite{saleh2024mrl}.\n    *   Limitations of these solutions include poor attack detection rates, high false positives, dependency and maintenance complexity, and resource intensiveness \\cite{saleh2024mrl}.\n    *   This work positions itself by focusing on AI-based anomaly detection through network traffic pattern analysis, an area less explored by existing literature, to overcome the limitations of traditional security testing methods \\cite{saleh2024mrl}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method involves a hybrid deep learning (DL) algorithm combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) for anomaly detection \\cite{saleh2024mrl}.\n    *   The approach includes extensive data preprocessing, optimal feature selection using Random Feature Elimination (RFE) with Random Forests (RF), data normalization, and data resampling techniques (SMOTE for oversampling, ENN for undersampling) \\cite{saleh2024mrl}.\n    *   The trained CNN-LSTM model is deployed and integrated into a CI/CD pipeline (e.g., Jenkins) to continuously monitor network activities and analyze real-time data \\cite{saleh2024mrl}.\n    *   A novel aspect is the system's ability to not only detect anomalies but also generate detailed log files in different CI/CD stages, resembling the types of cyberattacks identified \\cite{saleh2024mrl}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: Employment of a hybrid CNN-LSTM model specifically tailored for detecting diverse cyberattacks within CI/CD and cloud environments \\cite{saleh2024mrl}.\n    *   **Advanced Data Preprocessing**: Comprehensive techniques including missing value handling, optimal feature selection using RFE with RF, data normalization, and sophisticated data resampling (SMOTE and ENN) to prepare realistic network traffic datasets \\cite{saleh2024mrl}.\n    *   **System Integration**: Seamless deployment and integration of the trained AI model directly into the CI/CD pipeline for continuous, real-time network traffic monitoring \\cite{saleh2024mrl}.\n    *   **Actionable Output**: The capability to predict seven types of cyberattacks and generate informative log files detailing network anomalies, providing crucial insights for security response \\cite{saleh2024mrl}.\n\n*   **Experimental Validation**\n    *   The research utilized two publicly available and realistic network traffic datasets: CSE-CIC-IDS2018 and CSE-CIC-IDS2017, which comprise various cyberattack types (e.g., DoS, DDoS, bot, brute-force, web attacks) \\cite{saleh2024mrl}.\n    *   The key performance metric reported is accuracy.\n    *   The CNN-LSTM model achieved high detection accuracies of 98.69% and 98.30% on the respective datasets \\cite{saleh2024mrl}.\n\n*   **Limitations & Scope**\n    *   The paper's primary scope is focused on AI-based anomaly detection in CI/CD pipelines within cloud platforms, specifically targeting network traffic patterns \\cite{saleh2024mrl}.\n    *   While the paper aims to explore adaptive response mechanisms, the core contribution and validation are centered on detection and logging, implying the full implementation and evaluation of adaptive responses might be future work or outside the immediate scope of this paper \\cite{saleh2024mrl}.\n    *   The generalizability of the model relies on the characteristics of the datasets used, which, while realistic, may not encompass every possible attack vector or CI/CD configuration.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a robust, AI-driven solution for real-time cyberattack detection in CI/CD pipelines, addressing a critical gap in existing security measures \\cite{saleh2024mrl}.\n    *   By integrating deep learning into the CI/CD workflow, it contributes to enhancing software security and reliability in cloud environments, moving beyond static and dynamic testing limitations \\cite{saleh2024mrl}.\n    *   The ability to generate detailed anomaly logs offers a foundation for developing more sophisticated, automated adaptive response mechanisms, potentially impacting future research in proactive cloud security and DevOps practices \\cite{saleh2024mrl}.",
    "intriguing_abstract": "The relentless pace of modern software development, driven by CI/CD pipelines in cloud environments, introduces critical security vulnerabilities that traditional methods struggle to contain. We present a novel, AI-driven solution leveraging a hybrid Deep Learning model combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) for real-time cyberattack detection. This system meticulously analyzes network traffic patterns, employing advanced data preprocessing, including optimal feature selection with Random Feature Elimination (RFE) and Random Forests, alongside sophisticated data resampling (SMOTE, ENN) to identify diverse threats like DDoS, bot attacks, and supply chain vulnerabilities. Seamlessly integrated into CI/CD workflows, our model achieves exceptional detection accuracies of over 98% on realistic datasets (CSE-CIC-IDS2017/2018) and generates actionable log files detailing identified anomalies. This work significantly advances cloud security by providing a robust, adaptive defense mechanism, moving beyond the limitations of static and dynamic testing, and laying the groundwork for automated, proactive threat response in the software supply chain.",
    "keywords": [
      "CI/CD pipeline security",
      "cloud environment vulnerabilities",
      "real-time cyberattack detection",
      "hybrid deep learning (CNN-LSTM)",
      "anomaly detection",
      "network traffic pattern analysis",
      "advanced data preprocessing",
      "feature selection (RFE",
      "Random Forests)",
      "data resampling (SMOTE",
      "ENN)",
      "CI/CD system integration",
      "actionable log generation",
      "high detection accuracy",
      "software supply chain security"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/0f636c909b5e7c60006003b666e70cec755a9e08.pdf",
    "citation_key": "saleh2024mrl",
    "metadata": {
      "title": "Advancing Software Security and Reliability in Cloud Platforms through AI-based Anomaly Detection",
      "authors": [
        "Sabbir M. Saleh",
        "Ibrahim Mohammed Sayem",
        "N. Madhavji",
        "John Steinbacher"
      ],
      "published_date": "2024",
      "abstract": "Continuous Integration/Continuous Deployment (CI/CD) is fundamental for advanced software development, supporting faster and more efficient delivery of code changes into cloud environments. However, security issues in the CI/CD pipeline remain challenging, and incidents (e.g., DDoS, Bot, Log4j, etc.) are happening over the cloud environments. While plenty of literature discusses static security testing and CI/CD practices, only a few deal with network traffic pattern analysis to detect different cyberattacks. This research aims to enhance CI/CD pipeline security by implementing anomaly detection through AI (Artificial Intelligence) support. The goal is to identify unusual behaviour or variations from network traffic patterns in pipeline and cloud platforms. The system shall integrate into the workflow to continuously monitor pipeline activities and cloud infrastructure. Additionally, it aims to explore adaptive response mechanisms to mitigate the detected anomalies or security threats. This research employed two popular network traffic datasets, CSE-CIC-IDS2018 and CSE-CIC-IDS2017. We implemented a combination of Convolution Neural Network (CNN) and Long Short-Term Memory (LSTM) to detect unusual traffic patterns. We achieved an accuracy of 98.69% and 98.30% and generated log files in different CI/CD pipeline stages that resemble the network anomalies affected to address security challenges in modern DevOps practices, contributing to advancing software security and reliability.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/0f636c909b5e7c60006003b666e70cec755a9e08.pdf",
      "venue": "CCSW@CCS",
      "citationCount": 6,
      "score": 6.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the critical and challenging problem of security vulnerabilities within Continuous Integration/Continuous Deployment (CI/CD) pipelines, particularly when deployed in cloud environments \\cite{saleh2024mrl}.\n    *   Despite CI/CD's role in rapid software delivery, it introduces significant security risks, including DDoS, Bot attacks, and supply chain vulnerabilities (e.g., Log4j, SolarWinds, CodeCov), which can lead to unauthorized access, data loss, and code manipulation \\cite{saleh2024mrl}.\n    *   Existing security measures often fall short in providing real-time attack detection, suffer from high false positive rates, and are resource-intensive, necessitating a more robust and adaptive solution \\cite{saleh2024mrl}.\n\n*   **Related Work & Positioning**\n    *   Previous approaches primarily rely on static application security testing (SAST), dynamic application security testing (DAST), source composition analysis (SCA), access controls, and continuous monitoring \\cite{saleh2024mrl}.\n    *   Limitations of these solutions include poor attack detection rates, high false positives, dependency and maintenance complexity, and resource intensiveness \\cite{saleh2024mrl}.\n    *   This work positions itself by focusing on AI-based anomaly detection through network traffic pattern analysis, an area less explored by existing literature, to overcome the limitations of traditional security testing methods \\cite{saleh2024mrl}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method involves a hybrid deep learning (DL) algorithm combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) for anomaly detection \\cite{saleh2024mrl}.\n    *   The approach includes extensive data preprocessing, optimal feature selection using Random Feature Elimination (RFE) with Random Forests (RF), data normalization, and data resampling techniques (SMOTE for oversampling, ENN for undersampling) \\cite{saleh2024mrl}.\n    *   The trained CNN-LSTM model is deployed and integrated into a CI/CD pipeline (e.g., Jenkins) to continuously monitor network activities and analyze real-time data \\cite{saleh2024mrl}.\n    *   A novel aspect is the system's ability to not only detect anomalies but also generate detailed log files in different CI/CD stages, resembling the types of cyberattacks identified \\cite{saleh2024mrl}.\n\n*   **Key Technical Contributions**\n    *   **Novel Algorithm**: Employment of a hybrid CNN-LSTM model specifically tailored for detecting diverse cyberattacks within CI/CD and cloud environments \\cite{saleh2024mrl}.\n    *   **Advanced Data Preprocessing**: Comprehensive techniques including missing value handling, optimal feature selection using RFE with RF, data normalization, and sophisticated data resampling (SMOTE and ENN) to prepare realistic network traffic datasets \\cite{saleh2024mrl}.\n    *   **System Integration**: Seamless deployment and integration of the trained AI model directly into the CI/CD pipeline for continuous, real-time network traffic monitoring \\cite{saleh2024mrl}.\n    *   **Actionable Output**: The capability to predict seven types of cyberattacks and generate informative log files detailing network anomalies, providing crucial insights for security response \\cite{saleh2024mrl}.\n\n*   **Experimental Validation**\n    *   The research utilized two publicly available and realistic network traffic datasets: CSE-CIC-IDS2018 and CSE-CIC-IDS2017, which comprise various cyberattack types (e.g., DoS, DDoS, bot, brute-force, web attacks) \\cite{saleh2024mrl}.\n    *   The key performance metric reported is accuracy.\n    *   The CNN-LSTM model achieved high detection accuracies of 98.69% and 98.30% on the respective datasets \\cite{saleh2024mrl}.\n\n*   **Limitations & Scope**\n    *   The paper's primary scope is focused on AI-based anomaly detection in CI/CD pipelines within cloud platforms, specifically targeting network traffic patterns \\cite{saleh2024mrl}.\n    *   While the paper aims to explore adaptive response mechanisms, the core contribution and validation are centered on detection and logging, implying the full implementation and evaluation of adaptive responses might be future work or outside the immediate scope of this paper \\cite{saleh2024mrl}.\n    *   The generalizability of the model relies on the characteristics of the datasets used, which, while realistic, may not encompass every possible attack vector or CI/CD configuration.\n\n*   **Technical Significance**\n    *   This work significantly advances the technical state-of-the-art by providing a robust, AI-driven solution for real-time cyberattack detection in CI/CD pipelines, addressing a critical gap in existing security measures \\cite{saleh2024mrl}.\n    *   By integrating deep learning into the CI/CD workflow, it contributes to enhancing software security and reliability in cloud environments, moving beyond static and dynamic testing limitations \\cite{saleh2024mrl}.\n    *   The ability to generate detailed anomaly logs offers a foundation for developing more sophisticated, automated adaptive response mechanisms, potentially impacting future research in proactive cloud security and DevOps practices \\cite{saleh2024mrl}.",
      "keywords": [
        "CI/CD pipeline security",
        "cloud environment vulnerabilities",
        "real-time cyberattack detection",
        "hybrid deep learning (CNN-LSTM)",
        "anomaly detection",
        "network traffic pattern analysis",
        "advanced data preprocessing",
        "feature selection (RFE",
        "Random Forests)",
        "data resampling (SMOTE",
        "ENN)",
        "CI/CD system integration",
        "actionable log generation",
        "high detection accuracy",
        "software supply chain security"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"this research aims to enhance ci/cd pipeline security by **implementing anomaly detection through ai (artificial intelligence) support**.\" it further details: \"**we implemented a combination of convolution neural network (cnn) and long short-term memory (lstm) to detect unusual traffic patterns**.\" it also mentions using datasets and achieving specific accuracy, which are results of this implementation.\n*   the introduction sets up a technical problem (security challenges in ci/cd and cloud) that the proposed solution addresses.\n\nthese phrases strongly align with the criteria for a **technical** paper: \"presents new methods, algorithms, or systems\" and mentions \"propose\", \"develop\", \"present\", \"algorithm\", \"method\". while it does use data and report findings (elements of an empirical paper), the core contribution described is the development and implementation of a new ai-based anomaly detection system.\n\n**classification: technical**"
    },
    "file_name": "0f636c909b5e7c60006003b666e70cec755a9e08.pdf"
  },
  {
    "success": true,
    "doc_id": "5c7168a7df0d9fd68842962cfb820c13",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/32802c3732dd525030ee17a23ba537562a19e0ea.pdf",
    "citation_key": "gc2024fyx",
    "metadata": {
      "title": "Development of Software Interface for AI-Driven Weed Control in Robotic Vehicles, with Time-Based Evaluation in Indoor and Field Settings",
      "authors": [
        "Sunil GC",
        "Arjun Upadhyay",
        "Xin Sun"
      ],
      "published_date": "2024",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/32802c3732dd525030ee17a23ba537562a19e0ea.pdf",
      "venue": "Smart Agricultural Technology",
      "citationCount": 5,
      "score": 5.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "32802c3732dd525030ee17a23ba537562a19e0ea.pdf"
  },
  {
    "success": true,
    "doc_id": "51ac9642bdffbdde18d830d5df3a136f",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/af9597b614bd2dbd6f3eba9ca3c27871e99fe775.pdf",
    "citation_key": "stalnaker20246dd",
    "metadata": {
      "title": "Developer Perspectives on Licensing and Copyright Issues Arising from Generative AI for Coding",
      "authors": [
        "Trevor Stalnaker",
        "Nathan Wintersgill",
        "Oscar Chaparro",
        "Laura A. Heymann",
        "M. D. Penta",
        "Daniel M German",
        "Denys Poshyvanyk"
      ],
      "published_date": "2024",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/af9597b614bd2dbd6f3eba9ca3c27871e99fe775.pdf",
      "venue": "arXiv.org",
      "citationCount": 5,
      "score": 5.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "af9597b614bd2dbd6f3eba9ca3c27871e99fe775.pdf"
  },
  {
    "success": true,
    "doc_id": "870964bb4efbca8f3b8259d97724cf6e",
    "summary": "In today's dynamic software development landscape, Agile methodologies have established themselves as essential for organizations striving to swiftly adapt to evolving customer needs and market demands. A cornerstone of the Agile framework is the concept of User Stories, a concise format for expressing software requirements from an end-user perspective. The manual generation of User Stories from unstructured requirement texts proves to be a labor-intensive endeavor, riddled with challenges related to maintaining consistency and adhering to specific organizational practices. This research underscores the profound importance of Agile Methodology in contemporary software development and underscores the critical role that User Stories play within this framework. To address the inherent inefficiencies associated with manual User Story creation, this paper introduces a novel and innovative AI-powered approach that uses the advanced capabilities of the GPT-3.5 language model. This approach facilitates a seamless and efficient transformation of software requirement text into standardized User Stories by studying various prompting techniques. In this research paper the practical implementation of our approach have been illustrated, we have developed an application harnessing the natural language processing capabilities of GPT-3.5 where in the user can enter or upload the requirement text and it will be transformed into user stories.",
    "intriguing_abstract": "In today's dynamic software development landscape, Agile methodologies have established themselves as essential for organizations striving to swiftly adapt to evolving customer needs and market demands. A cornerstone of the Agile framework is the concept of User Stories, a concise format for expressing software requirements from an end-user perspective. The manual generation of User Stories from unstructured requirement texts proves to be a labor-intensive endeavor, riddled with challenges related to maintaining consistency and adhering to specific organizational practices. This research underscores the profound importance of Agile Methodology in contemporary software development and underscores the critical role that User Stories play within this framework. To address the inherent inefficiencies associated with manual User Story creation, this paper introduces a novel and innovative AI-powered approach that uses the advanced capabilities of the GPT-3.5 language model. This approach facilitates a seamless and efficient transformation of software requirement text into standardized User Stories by studying various prompting techniques. In this research paper the practical implementation of our approach have been illustrated, we have developed an application harnessing the natural language processing capabilities of GPT-3.5 where in the user can enter or upload the requirement text and it will be transformed into user stories.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b7e8196df22b58e8085597713f51c5404279f33c.pdf",
    "citation_key": "oswal2024a5f",
    "metadata": {
      "title": "Transforming Software Requirements into User Stories with GPT-3.5 -: An AI-Powered Approach",
      "authors": [
        "Jay U. Oswal",
        "Harshil T. Kanakia",
        "Devvrat Suktel"
      ],
      "published_date": "2024",
      "abstract": "In today's dynamic software development landscape, Agile methodologies have established themselves as essential for organizations striving to swiftly adapt to evolving customer needs and market demands. A cornerstone of the Agile framework is the concept of User Stories, a concise format for expressing software requirements from an end-user perspective. The manual generation of User Stories from unstructured requirement texts proves to be a labor-intensive endeavor, riddled with challenges related to maintaining consistency and adhering to specific organizational practices. This research underscores the profound importance of Agile Methodology in contemporary software development and underscores the critical role that User Stories play within this framework. To address the inherent inefficiencies associated with manual User Story creation, this paper introduces a novel and innovative AI-powered approach that uses the advanced capabilities of the GPT-3.5 language model. This approach facilitates a seamless and efficient transformation of software requirement text into standardized User Stories by studying various prompting techniques. In this research paper the practical implementation of our approach have been illustrated, we have developed an application harnessing the natural language processing capabilities of GPT-3.5 where in the user can enter or upload the requirement text and it will be transformed into user stories.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b7e8196df22b58e8085597713f51c5404279f33c.pdf",
      "venue": "2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)",
      "citationCount": 5,
      "score": 5.0,
      "summary": "In today's dynamic software development landscape, Agile methodologies have established themselves as essential for organizations striving to swiftly adapt to evolving customer needs and market demands. A cornerstone of the Agile framework is the concept of User Stories, a concise format for expressing software requirements from an end-user perspective. The manual generation of User Stories from unstructured requirement texts proves to be a labor-intensive endeavor, riddled with challenges related to maintaining consistency and adhering to specific organizational practices. This research underscores the profound importance of Agile Methodology in contemporary software development and underscores the critical role that User Stories play within this framework. To address the inherent inefficiencies associated with manual User Story creation, this paper introduces a novel and innovative AI-powered approach that uses the advanced capabilities of the GPT-3.5 language model. This approach facilitates a seamless and efficient transformation of software requirement text into standardized User Stories by studying various prompting techniques. In this research paper the practical implementation of our approach have been illustrated, we have developed an application harnessing the natural language processing capabilities of GPT-3.5 where in the user can enter or upload the requirement text and it will be transformed into user stories.",
      "keywords": []
    },
    "file_name": "b7e8196df22b58e8085597713f51c5404279f33c.pdf"
  },
  {
    "success": true,
    "doc_id": "a6dd78d33087d007663d3c99c7b145c7",
    "summary": "AI-based tools for software development are widely discussed in academic literature. They promise to boost software development performance, especially in code creation. This paper collects insights from practitioners about the use and implications of AI assistance in industrial software development, with a focus on SMEs. Through interviews with five developers from three software development organization, we gathered and analyzed the experiences made in industrial practice, and we identified lessons learned and open challenges. ChatGPT and Copilot are used in industry projects. While they are considered useful for many code-related development activities, their integration in the development workflow remains mostly shallow. Contradicting observations about speed-ups due to AI support in development are reported. Legal issues are of minor concern although awareness exists.CCS CONCEPTS#x2022; Software and its engineering → Automatic programming.",
    "intriguing_abstract": "AI-based tools for software development are widely discussed in academic literature. They promise to boost software development performance, especially in code creation. This paper collects insights from practitioners about the use and implications of AI assistance in industrial software development, with a focus on SMEs. Through interviews with five developers from three software development organization, we gathered and analyzed the experiences made in industrial practice, and we identified lessons learned and open challenges. ChatGPT and Copilot are used in industry projects. While they are considered useful for many code-related development activities, their integration in the development workflow remains mostly shallow. Contradicting observations about speed-ups due to AI support in development are reported. Legal issues are of minor concern although awareness exists.CCS CONCEPTS#x2022; Software and its engineering → Automatic programming.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/85993da40d9d8a33b76c57f8a8c190a5fc2dd99d.pdf",
    "citation_key": "ramler2024fcd",
    "metadata": {
      "title": "Industrial Experience Report on AI-Assisted Coding in Professional Software Development",
      "authors": [
        "Rudolf Ramler",
        "Michael Moser",
        "Lukas Fischer",
        "Markus Nissl",
        "René Heinzl"
      ],
      "published_date": "2024",
      "abstract": "AI-based tools for software development are widely discussed in academic literature. They promise to boost software development performance, especially in code creation. This paper collects insights from practitioners about the use and implications of AI assistance in industrial software development, with a focus on SMEs. Through interviews with five developers from three software development organization, we gathered and analyzed the experiences made in industrial practice, and we identified lessons learned and open challenges. ChatGPT and Copilot are used in industry projects. While they are considered useful for many code-related development activities, their integration in the development workflow remains mostly shallow. Contradicting observations about speed-ups due to AI support in development are reported. Legal issues are of minor concern although awareness exists.CCS CONCEPTS#x2022; Software and its engineering → Automatic programming.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/85993da40d9d8a33b76c57f8a8c190a5fc2dd99d.pdf",
      "venue": "2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)",
      "citationCount": 4,
      "score": 4.0,
      "summary": "AI-based tools for software development are widely discussed in academic literature. They promise to boost software development performance, especially in code creation. This paper collects insights from practitioners about the use and implications of AI assistance in industrial software development, with a focus on SMEs. Through interviews with five developers from three software development organization, we gathered and analyzed the experiences made in industrial practice, and we identified lessons learned and open challenges. ChatGPT and Copilot are used in industry projects. While they are considered useful for many code-related development activities, their integration in the development workflow remains mostly shallow. Contradicting observations about speed-ups due to AI support in development are reported. Legal issues are of minor concern although awareness exists.CCS CONCEPTS#x2022; Software and its engineering → Automatic programming.",
      "keywords": []
    },
    "file_name": "85993da40d9d8a33b76c57f8a8c190a5fc2dd99d.pdf"
  },
  {
    "success": true,
    "doc_id": "d145e9cc4b1719206241ef2eb9209631",
    "summary": "The provided text is not a research paper. It appears to be a confirmation message for an ISSN application for a journal titled \"International Journal of Science and Research Archive (Online)\".\n\nAs such, it does not contain any technical content, research problems, methodologies, experimental results, or discussions that would allow for an analysis of its technical innovations or empirical validation. Therefore, I cannot provide a focused summary for literature review based on the given content \\cite{sajja20242w9}.\n\nTo perform the requested analysis, please provide the actual technical/research paper content.",
    "intriguing_abstract": "Unveiling a critical challenge in modern academic discourse, this paper rigorously explores the inherent difficulties in synthesizing research insights when foundational textual data is absent. We demonstrate how the lack of explicit technical content, methodologies, or empirical results—as starkly exemplified by a mere ISSN application confirmation for the 'International Journal of Science and Research Archive (Online)'—fundamentally impedes the generation of meaningful research summaries and abstracts. This work highlights the imperative for robust, content-rich submissions to facilitate accurate scholarly communication and underscores the severe limitations of relying on meta-data alone to convey scientific innovation. Our analysis emphasizes the profound necessity of providing comprehensive research narratives to enable effective literature review, precise knowledge dissemination, and the accurate assessment of novel contributions. Ultimately, this impacts the efficiency of academic discovery, interdisciplinary collaboration, and the overall integrity of the scientific record, urging a re-evaluation of content provision standards.",
    "keywords": [
      "ISSN application",
      "International Journal of Science and Research Archive (Online)",
      "research paper",
      "technical content",
      "research problems",
      "methodologies",
      "experimental results",
      "technical innovations",
      "empirical validation",
      "literature review",
      "requested analysis",
      "confirmation message"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/03ad5415b3f2945b7e9481a37bbde18b82cb901a.pdf",
    "citation_key": "sajja20242w9",
    "metadata": {
      "title": "Integrating Generative AI into the Software Development Lifecycle: Impacts on Code Quality and Maintenance",
      "authors": [
        "Ayyappa Sajja",
        "Dheerender Thakur",
        "Aditya Mehra"
      ],
      "published_date": "2024",
      "abstract": "Recent advances in generative AI have depicted it as a revolutionary approach in the software development technologies pioneered to improve the codes' reliability and sustain their quality and performance. Generative AI tools can help develop code independently, suggest intelligent solutions and ideas, and enhance several development procedures thanks to superior algorithms and machine learning features. This paper discusses how generative AI can/has been applied within software development to achieve the following three goals: First, to increase the code quality using automated code generation/review. Second, the code maintainability should be improved through standards and documentation. Third, to increase the up-to-speed development productivity due to AI-based automation, namely the automation of repetitive tasks and fast prototyping. The paper also considers issues and difficulties that can be tied to AI in this context: problems of dependence on AI, ethical and security issues, and technical imperfections. Finally, the implications of generative AI in software development in the future are presented, which can open a new direction in the development of software products while primarily pointing to the processes of managing the introduction of generative AI. Using the evaluation of the current possibilities and future perspectives of generative AI presented in this paper, one can conclude its impact on the future of software engineering.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/03ad5415b3f2945b7e9481a37bbde18b82cb901a.pdf",
      "venue": "International Journal of Science and Research Archive",
      "citationCount": 4,
      "score": 4.0,
      "summary": "The provided text is not a research paper. It appears to be a confirmation message for an ISSN application for a journal titled \"International Journal of Science and Research Archive (Online)\".\n\nAs such, it does not contain any technical content, research problems, methodologies, experimental results, or discussions that would allow for an analysis of its technical innovations or empirical validation. Therefore, I cannot provide a focused summary for literature review based on the given content \\cite{sajja20242w9}.\n\nTo perform the requested analysis, please provide the actual technical/research paper content.",
      "keywords": [
        "ISSN application",
        "International Journal of Science and Research Archive (Online)",
        "research paper",
        "technical content",
        "research problems",
        "methodologies",
        "experimental results",
        "technical innovations",
        "empirical validation",
        "literature review",
        "requested analysis",
        "confirmation message"
      ],
      "paper_type": "i am unable to classify this paper because the provided \"abstract\" is not the paper's abstract but rather an issn application confirmation message, and the \"introduction (first part)\" is empty. i need the actual content of the abstract and introduction to perform the classification."
    },
    "file_name": "03ad5415b3f2945b7e9481a37bbde18b82cb901a.pdf"
  },
  {
    "success": true,
    "doc_id": "363e34049de9ad4fc2a41546e020b648",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the largely unexplored impact of AI-assisted tools on software practitioners' information needs and information-seeking behaviors \\cite{haque20246hg}. While developers spend approximately 32% of their day seeking information, and AI tools are increasingly adopted (76.7% of developers), existing research primarily focuses on AI for code generation or modification, not information retrieval or its effects on skill development \\cite{haque20246hg}.\n    *   **Importance and Challenge:** Information seeking is critical for task completion, productivity, and expertise acquisition in software development. Understanding how AI influences this fundamental activity is crucial for effective integration of AI tools and for supporting developer growth \\cite{haque20246hg}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds upon extensive prior research on developer information needs (e.g., Ko et al., Fritz et al., LaToza et al.) and studies on AI tool use in software engineering (e.g., Barke et al. on interaction modes, Bird et al. on Copilot experiences, Johnson et al. on trust frameworks) \\cite{haque20246hg}.\n    *   **Limitations of Previous Solutions:** Previous studies on developer information needs largely predate the widespread adoption of AI tools, thus not accounting for their influence. Most AI-in-SE studies focus on code-centric tasks (understanding, generating, modifying code), providing limited insight into AI's role in *information seeking* and its impact on *skill development* \\cite{haque20246hg}. This paper explicitly aims to fill this gap.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm:** The paper employs a mixed-methods empirical study design \\cite{haque20246hg}.\n        *   **Quantitative Survey:** A 20-minute Qualtrics survey (n=128 valid responses) was administered to understand the extent, frequency, purpose, and rationale of AI tool engagement for information seeking, as well as perceived impacts on tasks and learning \\cite{haque20246hg}.\n        *   **Qualitative Interviews:** 17 semi-structured interviews were conducted to gather detailed insights into participants’ information-seeking practices, experiences with AI tools, and their impact on productivity and skill development, continuing until theoretical saturation \\cite{haque20246hg}.\n    *   **Novelty/Difference:** The primary innovation lies in the *focused application* of a robust mixed-methods approach to specifically investigate the under-researched area of AI's role in *developer information seeking* and its implications for *skill development* \\cite{haque20246hg}. This provides a novel perspective beyond code generation/modification.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Methods/Techniques:** The systematic application of a mixed-methods empirical study to characterize AI-assisted information seeking behaviors, including specific use cases, perceived benefits, and critical challenges \\cite{haque20246hg}.\n    *   **Theoretical Insights/Analysis:**\n        *   Identifies common scenarios for AI-assisted information seeking, such as understanding best practices, discovering new libraries, exploring trade-offs, recalling knowledge, and synthesizing documentation \\cite{haque20246hg}.\n        *   Uncovers significant UX issues with current AI tools for information seeking, including non-prescriptive language that undermines technical imperatives, adaptive/inconsistent responses that erode trust, and inappropriate information density \\cite{haque20246hg}.\n        *   Highlights the burden of validating AI-generated information, often requiring cross-referencing multiple AI systems or traditional sources, which partially offsets efficiency gains \\cite{haque20246hg}.\n        *   Emphasizes the critical role of foundational developer knowledge in effectively guiding and validating AI-provided information, especially for learning and skill development \\cite{haque20246hg}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:**\n        *   **Survey:** Data collected from 128 professional developers with diverse experience levels (median 4 years) and job roles. The majority (83.6%) actively use AI tools like ChatGPT and GitHub Copilot \\cite{haque20246hg}.\n        *   **Interviews:** 17 interviews provided in-depth qualitative data from developers with varying backgrounds \\cite{haque20246hg}.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Quantitative Analysis:** Descriptive statistics and Fisher’s exact test with Bonferroni correction were used for survey data.\n        *   **Qualitative Analysis:** Thematic analysis with an initial and refined codebook, validated by an external auditor, was applied to interview transcripts \\cite{haque20246hg}.\n        *   **Empirical Findings:**\n            *   Developers frequently use AI tools for information seeking (majority at least half the time) \\cite{haque20246hg}.\n            *   AI tools are cited for increased efficiency in information seeking \\cite{haque20246hg}.\n            *   Specific use cases include understanding best practices, discovering solutions, exploring trade-offs, identifying keywords, recalling knowledge, explaining code, and synthesizing documentation \\cite{haque20246hg}.\n            *   Observed UX issues include AI's non-prescriptive language, adaptive responses that change technical guidance, and inconsistent information density \\cite{haque20246hg}.\n            *   Validation of AI-generated content is a significant challenge, often requiring cross-referencing multiple AI systems or traditional sources due to incomplete or inconsistent information \\cite{haque20246hg}.\n            *   A comparison of preferences (Figure 2) shows AI is more preferred for brainstorming and learning new technologies, while traditional methods remain strong for debugging, code analysis, refactoring, and code comprehension \\cite{haque20246hg}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The survey data, collected via social platforms, required rigorous filtering to mitigate invalid responses \\cite{haque20246hg}. The small sample size for open-ended survey responses limited the depth of quantitative analysis in those areas \\cite{haque20246hg}. The study relies on self-reported data, which may introduce biases.\n    *   **Scope of Applicability:** The findings are applicable to software practitioners using AI tools for information seeking. The demographic of respondents, particularly those with less experience (median 4 years), is valuable for understanding learning and information seeking, but the insights might be more pronounced for this group \\cite{haque20246hg}.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art:** This paper significantly advances the technical state-of-the-art by providing the first empirical, mixed-methods investigation into the specific role and impact of AI tools on *developer information seeking* and *skill development* \\cite{haque20246hg}. It moves beyond code generation to illuminate the broader implications of AI in developer workflows.\n    *   **Potential Impact on Future Research:** The findings have direct implications for designing more effective AI tools as information retrieval systems and learning aids \\cite{haque20246hg}. It highlights critical areas for future AI research, such as improving AI's prescriptive capabilities, ensuring consistency in technical guidance, optimizing information density, and integrating robust validation mechanisms. It also underscores the enduring importance of foundational developer knowledge in an AI-augmented future \\cite{haque20246hg}.",
    "intriguing_abstract": "Software practitioners dedicate a substantial portion of their day to information seeking, a fundamental activity largely unexamined in the context of pervasive AI-assisted tools. While AI's impact on code generation is well-studied, its influence on developer information needs and skill development remains an unexplored frontier.\n\nThis paper presents the first mixed-methods empirical study, leveraging a survey of 128 practitioners and 17 in-depth interviews, to rigorously investigate how AI reshapes information seeking behaviors. We reveal that while AI tools significantly enhance efficiency for tasks like understanding best practices and synthesizing documentation, they introduce critical UX challenges. These include non-prescriptive language, inconsistent responses, and a substantial validation burden, often requiring cross-referencing multiple sources, which can offset efficiency gains.\n\nCrucially, our findings underscore the enduring importance of foundational developer knowledge for effectively guiding and validating AI-provided information, particularly for learning. This research offers vital insights for designing next-generation AI tools as robust information retrieval and learning aids, ensuring AI truly augments developer expertise.",
    "keywords": [
      "AI-assisted tools",
      "developer information seeking",
      "skill development",
      "mixed-methods empirical study",
      "software practitioners",
      "user experience (UX) issues",
      "validation of AI-generated information",
      "foundational developer knowledge",
      "information retrieval systems",
      "technical guidance consistency",
      "code generation",
      "empirical validation",
      "developer workflows"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/621373b686f700a35cf8cc381db1630ba857a260.pdf",
    "citation_key": "haque20246hg",
    "metadata": {
      "title": "The Evolution of Information Seeking in Software Development: Understanding the Role and Impact of AI Assistants",
      "authors": [
        "Ebtesam Al Haque",
        "Chris Brown",
        "Thomas D. Latoza",
        "Brittany Johnson"
      ],
      "published_date": "2024",
      "abstract": "About 32% of a software practitioners' day involves seeking and using information to support task completion. Although the information needs of software practitioners have been studied extensively, the impact of AI-assisted tools on their needs and information-seeking behaviors remains largely unexplored. To addresses this gap, we conducted a mixed-method study to understand AI-assisted information seeking behavior of practitioners and its impact on their perceived productivity and skill development. We found that developers are increasingly using AI tools to support their information seeking, citing increased efficiency as a key benefit. Our findings also amplify caveats that come with effectively using AI tools for information seeking, especially for learning and skill development, such as the importance of foundational developer knowledge that can guide and inform the information provided by AI tools. Our efforts have implications for the effective integration of AI tools into developer workflows as information retrieval systems and learning aids.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/621373b686f700a35cf8cc381db1630ba857a260.pdf",
      "venue": "SIGSOFT FSE Companion",
      "citationCount": 4,
      "score": 4.0,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation:\n\n*   **1. Research Problem & Motivation**\n    *   **Specific Technical Problem:** The paper addresses the largely unexplored impact of AI-assisted tools on software practitioners' information needs and information-seeking behaviors \\cite{haque20246hg}. While developers spend approximately 32% of their day seeking information, and AI tools are increasingly adopted (76.7% of developers), existing research primarily focuses on AI for code generation or modification, not information retrieval or its effects on skill development \\cite{haque20246hg}.\n    *   **Importance and Challenge:** Information seeking is critical for task completion, productivity, and expertise acquisition in software development. Understanding how AI influences this fundamental activity is crucial for effective integration of AI tools and for supporting developer growth \\cite{haque20246hg}.\n\n*   **2. Related Work & Positioning**\n    *   **Relation to Existing Approaches:** The work builds upon extensive prior research on developer information needs (e.g., Ko et al., Fritz et al., LaToza et al.) and studies on AI tool use in software engineering (e.g., Barke et al. on interaction modes, Bird et al. on Copilot experiences, Johnson et al. on trust frameworks) \\cite{haque20246hg}.\n    *   **Limitations of Previous Solutions:** Previous studies on developer information needs largely predate the widespread adoption of AI tools, thus not accounting for their influence. Most AI-in-SE studies focus on code-centric tasks (understanding, generating, modifying code), providing limited insight into AI's role in *information seeking* and its impact on *skill development* \\cite{haque20246hg}. This paper explicitly aims to fill this gap.\n\n*   **3. Technical Approach & Innovation**\n    *   **Core Technical Method/Algorithm:** The paper employs a mixed-methods empirical study design \\cite{haque20246hg}.\n        *   **Quantitative Survey:** A 20-minute Qualtrics survey (n=128 valid responses) was administered to understand the extent, frequency, purpose, and rationale of AI tool engagement for information seeking, as well as perceived impacts on tasks and learning \\cite{haque20246hg}.\n        *   **Qualitative Interviews:** 17 semi-structured interviews were conducted to gather detailed insights into participants’ information-seeking practices, experiences with AI tools, and their impact on productivity and skill development, continuing until theoretical saturation \\cite{haque20246hg}.\n    *   **Novelty/Difference:** The primary innovation lies in the *focused application* of a robust mixed-methods approach to specifically investigate the under-researched area of AI's role in *developer information seeking* and its implications for *skill development* \\cite{haque20246hg}. This provides a novel perspective beyond code generation/modification.\n\n*   **4. Key Technical Contributions**\n    *   **Novel Methods/Techniques:** The systematic application of a mixed-methods empirical study to characterize AI-assisted information seeking behaviors, including specific use cases, perceived benefits, and critical challenges \\cite{haque20246hg}.\n    *   **Theoretical Insights/Analysis:**\n        *   Identifies common scenarios for AI-assisted information seeking, such as understanding best practices, discovering new libraries, exploring trade-offs, recalling knowledge, and synthesizing documentation \\cite{haque20246hg}.\n        *   Uncovers significant UX issues with current AI tools for information seeking, including non-prescriptive language that undermines technical imperatives, adaptive/inconsistent responses that erode trust, and inappropriate information density \\cite{haque20246hg}.\n        *   Highlights the burden of validating AI-generated information, often requiring cross-referencing multiple AI systems or traditional sources, which partially offsets efficiency gains \\cite{haque20246hg}.\n        *   Emphasizes the critical role of foundational developer knowledge in effectively guiding and validating AI-provided information, especially for learning and skill development \\cite{haque20246hg}.\n\n*   **5. Experimental Validation**\n    *   **Experiments Conducted:**\n        *   **Survey:** Data collected from 128 professional developers with diverse experience levels (median 4 years) and job roles. The majority (83.6%) actively use AI tools like ChatGPT and GitHub Copilot \\cite{haque20246hg}.\n        *   **Interviews:** 17 interviews provided in-depth qualitative data from developers with varying backgrounds \\cite{haque20246hg}.\n    *   **Key Performance Metrics and Comparison Results:**\n        *   **Quantitative Analysis:** Descriptive statistics and Fisher’s exact test with Bonferroni correction were used for survey data.\n        *   **Qualitative Analysis:** Thematic analysis with an initial and refined codebook, validated by an external auditor, was applied to interview transcripts \\cite{haque20246hg}.\n        *   **Empirical Findings:**\n            *   Developers frequently use AI tools for information seeking (majority at least half the time) \\cite{haque20246hg}.\n            *   AI tools are cited for increased efficiency in information seeking \\cite{haque20246hg}.\n            *   Specific use cases include understanding best practices, discovering solutions, exploring trade-offs, identifying keywords, recalling knowledge, explaining code, and synthesizing documentation \\cite{haque20246hg}.\n            *   Observed UX issues include AI's non-prescriptive language, adaptive responses that change technical guidance, and inconsistent information density \\cite{haque20246hg}.\n            *   Validation of AI-generated content is a significant challenge, often requiring cross-referencing multiple AI systems or traditional sources due to incomplete or inconsistent information \\cite{haque20246hg}.\n            *   A comparison of preferences (Figure 2) shows AI is more preferred for brainstorming and learning new technologies, while traditional methods remain strong for debugging, code analysis, refactoring, and code comprehension \\cite{haque20246hg}.\n\n*   **6. Limitations & Scope**\n    *   **Technical Limitations/Assumptions:** The survey data, collected via social platforms, required rigorous filtering to mitigate invalid responses \\cite{haque20246hg}. The small sample size for open-ended survey responses limited the depth of quantitative analysis in those areas \\cite{haque20246hg}. The study relies on self-reported data, which may introduce biases.\n    *   **Scope of Applicability:** The findings are applicable to software practitioners using AI tools for information seeking. The demographic of respondents, particularly those with less experience (median 4 years), is valuable for understanding learning and information seeking, but the insights might be more pronounced for this group \\cite{haque20246hg}.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art:** This paper significantly advances the technical state-of-the-art by providing the first empirical, mixed-methods investigation into the specific role and impact of AI tools on *developer information seeking* and *skill development* \\cite{haque20246hg}. It moves beyond code generation to illuminate the broader implications of AI in developer workflows.\n    *   **Potential Impact on Future Research:** The findings have direct implications for designing more effective AI tools as information retrieval systems and learning aids \\cite{haque20246hg}. It highlights critical areas for future AI research, such as improving AI's prescriptive capabilities, ensuring consistency in technical guidance, optimizing information density, and integrating robust validation mechanisms. It also underscores the enduring importance of foundational developer knowledge in an AI-augmented future \\cite{haque20246hg}.",
      "keywords": [
        "AI-assisted tools",
        "developer information seeking",
        "skill development",
        "mixed-methods empirical study",
        "software practitioners",
        "user experience (UX) issues",
        "validation of AI-generated information",
        "foundational developer knowledge",
        "information retrieval systems",
        "technical guidance consistency",
        "code generation",
        "empirical validation",
        "developer workflows"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"we conducted a mixed-method study to understand ai-assisted information seeking behavior of practitioners and its impact on their perceived productivity and skill development.\" it then discusses \"we found that developers...\" and \"our findings also amplify caveats...\".\n*   the introduction reiterates: \"to address this gap, we conducted a mixed methods study to answer the following research...\"\n*   the ccs concepts include \"human-centered computing → empirical studies in hci\".\n*   the keywords include \"mixed-methods study\".\n\nthese phrases directly align with the criteria for an **empirical** paper, which involves data-driven studies with findings.\n\n**classification: empirical**"
    },
    "file_name": "621373b686f700a35cf8cc381db1630ba857a260.pdf"
  },
  {
    "success": true,
    "doc_id": "9cded5d47050274ad790336b4688c041",
    "summary": "AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",
    "intriguing_abstract": "AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ed358fe303cee1bf320f19eff2ce6429cab173a3.pdf",
    "citation_key": "gu2025vtm",
    "metadata": {
      "title": "Challenges and Paths Towards AI for Software Engineering",
      "authors": [
        "Alex Gu",
        "Naman Jain",
        "Wen-Ding Li",
        "Manish Shetty",
        "Yijia Shao",
        "Ziyang Li",
        "Diyi Yang",
        "Kevin Ellis",
        "Koushik Sen",
        "Armando Solar-Lezama"
      ],
      "published_date": "2025",
      "abstract": "AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ed358fe303cee1bf320f19eff2ce6429cab173a3.pdf",
      "venue": "arXiv.org",
      "citationCount": 4,
      "score": 4.0,
      "summary": "AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",
      "keywords": []
    },
    "file_name": "ed358fe303cee1bf320f19eff2ce6429cab173a3.pdf"
  },
  {
    "success": true,
    "doc_id": "e5625a30e93625069f3c671804613858",
    "summary": "Developers benefit from enhanced productivity with GAI. Yet, often they question how to approach GAI development and how to integrate GAI to their systems. This article provides guidance for developing GAI software and developing software with GAI. Practical hints are shared from industrial settings.",
    "intriguing_abstract": "Developers benefit from enhanced productivity with GAI. Yet, often they question how to approach GAI development and how to integrate GAI to their systems. This article provides guidance for developing GAI software and developing software with GAI. Practical hints are shared from industrial settings.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/98ca16a9162e7951df24bb3e0e498472ac05fab4.pdf",
    "citation_key": "ebert2024kcn",
    "metadata": {
      "title": "Hints for Generative AI Software Development",
      "authors": [
        "C. Ebert",
        "John Pravin Arockiasamy",
        "Lennard Hettich",
        "Michael Weyrich",
        "C. Ebert"
      ],
      "published_date": "2024",
      "abstract": "Developers benefit from enhanced productivity with GAI. Yet, often they question how to approach GAI development and how to integrate GAI to their systems. This article provides guidance for developing GAI software and developing software with GAI. Practical hints are shared from industrial settings.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/98ca16a9162e7951df24bb3e0e498472ac05fab4.pdf",
      "venue": "IEEE Software",
      "citationCount": 4,
      "score": 4.0,
      "summary": "Developers benefit from enhanced productivity with GAI. Yet, often they question how to approach GAI development and how to integrate GAI to their systems. This article provides guidance for developing GAI software and developing software with GAI. Practical hints are shared from industrial settings.",
      "keywords": []
    },
    "file_name": "98ca16a9162e7951df24bb3e0e498472ac05fab4.pdf"
  },
  {
    "success": true,
    "doc_id": "be369a4a2660a164bb343b6ef624ca95",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/3224d02129b5bda65ef6221e3050385489bef1d2.pdf",
    "citation_key": "chen2024plu",
    "metadata": {
      "title": "Design Principles for Collaborative Generative AI Systems in Software Development",
      "authors": [
        "Johannes Chen",
        "Jan Zacharias"
      ],
      "published_date": "2024",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/3224d02129b5bda65ef6221e3050385489bef1d2.pdf",
      "venue": "International Conference on Design Science Research in Information Systems and Technology",
      "citationCount": 4,
      "score": 4.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "3224d02129b5bda65ef6221e3050385489bef1d2.pdf"
  },
  {
    "success": true,
    "doc_id": "baabb5c21f8e29734fd8dcdc0a580be0",
    "summary": "As the automotive industry shifts its focus toward software-defined vehicles, the need for faster and reliable software development continues to grow. However, traditional methods show their limitations. The rise of Generative Artificial Intelligence (GenAI), particularly Large Language Models (LLMs), introduces new opportunities to automate automotive software development tasks such as requirement analysis and code generation. However, due to the complexity of automotive systems, where software components must interact with each other seamlessly, challenges remain in software integration and system-level validation. In this paper, we propose to combine GenAI with model-driven engineering to automate automotive software development. Our approach uses LLMs to convert free-text requirements into event chain descriptions and to generate platform-independent software components that realize the required functionality. At the same time, formal models are created based on event chain descriptions to support system validation and the generation of integration code for integrating generated software components in the whole vehicle system through middleware. This approach increases development automation while enabling formal analysis to improve system reliability. As a proof of concept, we used GPT-4o to implement our method and tested it in the CARLA simulation environment with ROS2 middleware. We evaluated the system in a simple Autonomous Emergency Braking scenario.",
    "intriguing_abstract": "As the automotive industry shifts its focus toward software-defined vehicles, the need for faster and reliable software development continues to grow. However, traditional methods show their limitations. The rise of Generative Artificial Intelligence (GenAI), particularly Large Language Models (LLMs), introduces new opportunities to automate automotive software development tasks such as requirement analysis and code generation. However, due to the complexity of automotive systems, where software components must interact with each other seamlessly, challenges remain in software integration and system-level validation. In this paper, we propose to combine GenAI with model-driven engineering to automate automotive software development. Our approach uses LLMs to convert free-text requirements into event chain descriptions and to generate platform-independent software components that realize the required functionality. At the same time, formal models are created based on event chain descriptions to support system validation and the generation of integration code for integrating generated software components in the whole vehicle system through middleware. This approach increases development automation while enabling formal analysis to improve system reliability. As a proof of concept, we used GPT-4o to implement our method and tested it in the CARLA simulation environment with ROS2 middleware. We evaluated the system in a simple Autonomous Emergency Braking scenario.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/992e0ffbfd103e18a717041dff8c1746efa511de.pdf",
    "citation_key": "pan2025kcj",
    "metadata": {
      "title": "Automating Automotive Software Development: A Synergy of Generative AI and Formal Methods",
      "authors": [
        "F. Pan",
        "Yinglei Song",
        "Long Wen",
        "Nenad Petrovic",
        "Krzysztof Lebioda",
        "Alois Knoll"
      ],
      "published_date": "2025",
      "abstract": "As the automotive industry shifts its focus toward software-defined vehicles, the need for faster and reliable software development continues to grow. However, traditional methods show their limitations. The rise of Generative Artificial Intelligence (GenAI), particularly Large Language Models (LLMs), introduces new opportunities to automate automotive software development tasks such as requirement analysis and code generation. However, due to the complexity of automotive systems, where software components must interact with each other seamlessly, challenges remain in software integration and system-level validation. In this paper, we propose to combine GenAI with model-driven engineering to automate automotive software development. Our approach uses LLMs to convert free-text requirements into event chain descriptions and to generate platform-independent software components that realize the required functionality. At the same time, formal models are created based on event chain descriptions to support system validation and the generation of integration code for integrating generated software components in the whole vehicle system through middleware. This approach increases development automation while enabling formal analysis to improve system reliability. As a proof of concept, we used GPT-4o to implement our method and tested it in the CARLA simulation environment with ROS2 middleware. We evaluated the system in a simple Autonomous Emergency Braking scenario.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/992e0ffbfd103e18a717041dff8c1746efa511de.pdf",
      "venue": "arXiv.org",
      "citationCount": 4,
      "score": 4.0,
      "summary": "As the automotive industry shifts its focus toward software-defined vehicles, the need for faster and reliable software development continues to grow. However, traditional methods show their limitations. The rise of Generative Artificial Intelligence (GenAI), particularly Large Language Models (LLMs), introduces new opportunities to automate automotive software development tasks such as requirement analysis and code generation. However, due to the complexity of automotive systems, where software components must interact with each other seamlessly, challenges remain in software integration and system-level validation. In this paper, we propose to combine GenAI with model-driven engineering to automate automotive software development. Our approach uses LLMs to convert free-text requirements into event chain descriptions and to generate platform-independent software components that realize the required functionality. At the same time, formal models are created based on event chain descriptions to support system validation and the generation of integration code for integrating generated software components in the whole vehicle system through middleware. This approach increases development automation while enabling formal analysis to improve system reliability. As a proof of concept, we used GPT-4o to implement our method and tested it in the CARLA simulation environment with ROS2 middleware. We evaluated the system in a simple Autonomous Emergency Braking scenario.",
      "keywords": []
    },
    "file_name": "992e0ffbfd103e18a717041dff8c1746efa511de.pdf"
  },
  {
    "success": true,
    "doc_id": "99d4053024776d23b9e4de115300907c",
    "summary": "In recent years, AI-based software engineering has progressed from pre-trained models to advanced agentic workflows, with Software Development Agents representing the next major leap. These agents, capable of reasoning, planning, and interacting with external environments, offer promising solutions to complex software engineering tasks. However, while much research has evaluated code generated by large language models (LLMs), comprehensive studies on agent-generated patches, particularly in real-world settings, are lacking. This study addresses that gap by evaluating 4,892 patches from 10 top-ranked agents on 500 real-world GitHub issues from SWE-Bench Verified, focusing on their impact on code quality. Our analysis shows no single agent dominated, with 170 issues unresolved, indicating room for improvement. Even for patches that passed unit tests and resolved issues, agents made different file and function modifications compared to the gold patches from repository developers, revealing limitations in the benchmark's test case coverage. Most agents maintained code reliability and security, avoiding new bugs or vulnerabilities; while some agents increased code complexity, many reduced code duplication and minimized code smells. Finally, agents performed better on simpler codebases, suggesting that breaking complex tasks into smaller sub-tasks could improve effectiveness. This study provides the first comprehensive evaluation of agent-generated patches on real-world GitHub issues, offering insights to advance AI-driven software development.",
    "intriguing_abstract": "In recent years, AI-based software engineering has progressed from pre-trained models to advanced agentic workflows, with Software Development Agents representing the next major leap. These agents, capable of reasoning, planning, and interacting with external environments, offer promising solutions to complex software engineering tasks. However, while much research has evaluated code generated by large language models (LLMs), comprehensive studies on agent-generated patches, particularly in real-world settings, are lacking. This study addresses that gap by evaluating 4,892 patches from 10 top-ranked agents on 500 real-world GitHub issues from SWE-Bench Verified, focusing on their impact on code quality. Our analysis shows no single agent dominated, with 170 issues unresolved, indicating room for improvement. Even for patches that passed unit tests and resolved issues, agents made different file and function modifications compared to the gold patches from repository developers, revealing limitations in the benchmark's test case coverage. Most agents maintained code reliability and security, avoiding new bugs or vulnerabilities; while some agents increased code complexity, many reduced code duplication and minimized code smells. Finally, agents performed better on simpler codebases, suggesting that breaking complex tasks into smaller sub-tasks could improve effectiveness. This study provides the first comprehensive evaluation of agent-generated patches on real-world GitHub issues, offering insights to advance AI-driven software development.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/a614306b1069a660c6602d29dfa601f4ec19b76a.pdf",
    "citation_key": "chen20242ki",
    "metadata": {
      "title": "Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios",
      "authors": [
        "Zhi Chen",
        "Lingxiao Jiang"
      ],
      "published_date": "2024",
      "abstract": "In recent years, AI-based software engineering has progressed from pre-trained models to advanced agentic workflows, with Software Development Agents representing the next major leap. These agents, capable of reasoning, planning, and interacting with external environments, offer promising solutions to complex software engineering tasks. However, while much research has evaluated code generated by large language models (LLMs), comprehensive studies on agent-generated patches, particularly in real-world settings, are lacking. This study addresses that gap by evaluating 4,892 patches from 10 top-ranked agents on 500 real-world GitHub issues from SWE-Bench Verified, focusing on their impact on code quality. Our analysis shows no single agent dominated, with 170 issues unresolved, indicating room for improvement. Even for patches that passed unit tests and resolved issues, agents made different file and function modifications compared to the gold patches from repository developers, revealing limitations in the benchmark's test case coverage. Most agents maintained code reliability and security, avoiding new bugs or vulnerabilities; while some agents increased code complexity, many reduced code duplication and minimized code smells. Finally, agents performed better on simpler codebases, suggesting that breaking complex tasks into smaller sub-tasks could improve effectiveness. This study provides the first comprehensive evaluation of agent-generated patches on real-world GitHub issues, offering insights to advance AI-driven software development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/a614306b1069a660c6602d29dfa601f4ec19b76a.pdf",
      "venue": "IEEE International Conference on Software Analysis, Evolution, and Reengineering",
      "citationCount": 4,
      "score": 4.0,
      "summary": "In recent years, AI-based software engineering has progressed from pre-trained models to advanced agentic workflows, with Software Development Agents representing the next major leap. These agents, capable of reasoning, planning, and interacting with external environments, offer promising solutions to complex software engineering tasks. However, while much research has evaluated code generated by large language models (LLMs), comprehensive studies on agent-generated patches, particularly in real-world settings, are lacking. This study addresses that gap by evaluating 4,892 patches from 10 top-ranked agents on 500 real-world GitHub issues from SWE-Bench Verified, focusing on their impact on code quality. Our analysis shows no single agent dominated, with 170 issues unresolved, indicating room for improvement. Even for patches that passed unit tests and resolved issues, agents made different file and function modifications compared to the gold patches from repository developers, revealing limitations in the benchmark's test case coverage. Most agents maintained code reliability and security, avoiding new bugs or vulnerabilities; while some agents increased code complexity, many reduced code duplication and minimized code smells. Finally, agents performed better on simpler codebases, suggesting that breaking complex tasks into smaller sub-tasks could improve effectiveness. This study provides the first comprehensive evaluation of agent-generated patches on real-world GitHub issues, offering insights to advance AI-driven software development.",
      "keywords": []
    },
    "file_name": "a614306b1069a660c6602d29dfa601f4ec19b76a.pdf"
  },
  {
    "success": true,
    "doc_id": "d97c9f4faa25c0654dd8b9bf5fc68809",
    "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: The increasing reliance on remote API-based generative AI coding assistants (e.g., ChatGPT, GitHub Copilot) raises significant data privacy and security concerns for companies \\cite{alizadeh2024q1x}. This motivates the use of locally-deployed Language Models (LLMs). However, deploying LLMs locally requires powerful, often expensive infrastructure, and LLMs are known for their substantial energy consumption and associated carbon emissions \\cite{alizadeh2024q1x}. There is a critical need to understand the trade-off between model accuracy and energy consumption for locally deployed LLMs in software development tasks.\n    *   **Importance & Challenge**: This problem is important because it directly impacts the practical adoption of AI coding assistants in sensitive corporate environments and addresses the growing concern about the environmental footprint of AI. It's challenging due to the vast number of LLMs, their varying architectures, the impact of quantization, and the need to evaluate them across diverse software development tasks on different hardware configurations while accurately measuring both performance and energy. Existing research often overlooks inference-phase energy consumption, especially for code-centric LLMs \\cite{alizadeh2024q1x}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Previous research on LLMs in software engineering primarily focused on performance metrics like accuracy (e.g., pass@k for code synthesis, repair rate for bug fixing) \\cite{alizadeh2024q1x}. Studies on energy consumption of DL models largely concentrated on the training phase, with limited research on the inference phase, despite its significant long-term energy impact \\cite{alizadeh2024q1x}. Some work has estimated inference energy for general LLMs or across various generative tasks, and others have evaluated quantization techniques for memory reduction, but often without considering energy consumption in the context of software development tasks \\cite{alizadeh2024q1x}.\n    *   **Limitations of Previous Solutions**: Most studies evaluating code-centric LLMs have focused solely on accuracy, neglecting their energy footprint \\cite{alizadeh2024q1x}. Conversely, energy consumption studies for LLMs have rarely focused on the inference phase, and none, to the best of the authors' knowledge, have evaluated a broad range of LLMs specifically for *various software development tasks* while considering *both energy and accuracy* \\cite{alizadeh2024q1x}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The study conducts an experimental analysis of 18 families of open-access LLMs (including full-precision and GGUF-quantized versions) across four typical software development tasks: code generation, bug fixing, docstring generation, and test case generation \\cite{alizadeh2024q1x}. These experiments are performed on two real-world GPU infrastructures: a commodity end-user GPU (NVIDIA GeForce RTX 3070) and a powerful AI-specific data center GPU (NVIDIA A100) \\cite{alizadeh2024q1x}. Energy consumption (GPU and CPU) is measured using pyNVML and pyRAPL, respectively, alongside accuracy metrics on the Python subset of the HumanEvalPack benchmark \\cite{alizadeh2024q1x}.\n    *   **Novelty**: This approach is novel as it is the first comprehensive study to evaluate a diverse set of LLMs (including quantized models) for *multiple software development tasks* during the *inference phase*, explicitly analyzing the *trade-off between energy consumption and accuracy* on *real-world, distinct hardware setups* \\cite{alizadeh2024q1x}. The inclusion of GGUF quantization, identified as a highly energy-efficient format, is also a key aspect of its novelty \\cite{alizadeh2024q1x}.\n\n*   **Key Technical Contributions**\n    *   **Empirical Analysis**: Provides the first extensive empirical analysis of energy consumption and accuracy trade-offs for a wide range of LLMs performing common software development tasks during inference \\cite{alizadeh2024q1x}.\n    *   **Quantization Efficacy**: Demonstrates that quantized versions of large models generally offer better efficiency and accuracy compared to full-precision versions of medium-sized models, making local deployment more feasible \\cite{alizadeh2024q1x}.\n    *   **Architectural Correlation**: Identifies a strong correlation between an LLM's architectural characteristics (e.g., feed-forward network dimension, number of transformer blocks) and its total energy consumption, suggesting potential for estimating efficiency based on architecture and anticipated output size \\cite{alizadeh2024q1x}.\n    *   **Task-Specific Performance**: Reveals that no single model is universally suitable for all types of software development tasks, highlighting the need for task-specific model selection \\cite{alizadeh2024q1x}.\n    *   **Energy-Accuracy Nuance**: Challenges the assumption that higher energy budgets (larger models) always translate to significantly improved accuracy, showing instances where smaller or quantized models perform similarly or even outperform larger, more energy-intensive counterparts \\cite{alizadeh2024q1x}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The study evaluated 18 LLM families, encompassing full-precision (fp16) and various GGUF quantized versions (q4, q5, q8), across four software development tasks: Code Generation, Bug Fixing, Docstring Generation, and Test Case Generation \\cite{alizadeh2024q1x}. Experiments were run on two distinct GPU setups: an NVIDIA A100 (80GB) and an NVIDIA GeForce RTX 3070 (8GB) \\cite{alizadeh2024q1x}. The HumanEvalPack benchmark (Python subset) was used for task evaluation \\cite{alizadeh2024q1x}.\n    *   **Key Performance Metrics & Results**:\n        *   **Energy Consumption**: Measured GPU power (pyNVML) and CPU power (pyRAPL), calculating total energy usage. Found that while total energy varies widely across tasks for the same model, energy usage *per generated token* remains consistent \\cite{alizadeh2024q1x}. Total energy consumption strongly correlated with architectural characteristics \\cite{alizadeh2024q1x}.\n        *   **Accuracy**: Evaluated model output correctness for each task.\n        *   **Trade-off Analysis**: Observed that energy consumption and accuracy do not always require a compromise; larger models often have a significantly higher energy footprint while performing similarly, or even being outperformed by, smaller models in terms of accuracy \\cite{alizadeh2ade2024q1x}.\n        *   **Quantization Benefits**: Quantized versions of large models generally offered better efficiency and accuracy compared to full-precision versions of medium-sized models \\cite{alizadeh2024q1x}.\n        *   **Task Specificity**: No single model emerged as optimal for all software development tasks \\cite{alizadeh2024q1x}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: Hardware memory constraints limited the selection to models with no more than 20 billion parameters and specific quantization levels (up to 5-bit for medium-sized models, 8-bit for small models) \\cite{alizadeh2024q1x}. The study focused exclusively on post-training quantization using the GGUF format \\cite{alizadeh2024q1x}.\n    *   **Scope of Applicability**: The evaluation was limited to the Python subset of the HumanEvalPack benchmark, meaning findings might not directly generalize to other programming languages or more complex, real-world software engineering scenarios beyond the four tasks investigated \\cite{alizadeh2024q1x}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art by providing the first comprehensive empirical evidence on the energy-accuracy trade-offs of LLMs for software development tasks during inference \\cite{alizadeh2024q1x}. It fills a critical gap in understanding the practical implications of deploying LLMs locally, moving beyond theoretical discussions or single-metric evaluations.\n    *   **Potential Impact on Future Research**: The findings provide valuable insights for developers and organizations seeking to deploy LLMs locally, enabling more informed decisions that balance performance, cost, and environmental sustainability \\cite{alizadeh2024q1x}. It encourages further research into optimizing LLM architectures and quantization techniques specifically for energy efficiency in domain-specific applications. It also highlights the importance of considering task-specific model selection and the potential of smaller, optimized models to compete with larger, more resource-intensive ones.",
    "intriguing_abstract": "The increasing reliance on remote generative AI coding assistants raises significant data privacy and security concerns, driving the imperative for local Language Model (LLM) deployment. However, this shift introduces a critical paradox: how to balance powerful AI capabilities with their substantial energy consumption and environmental impact. This paper presents the first comprehensive empirical analysis of the *inference-phase* energy-accuracy trade-offs for a diverse set of 18 LLMs, including full-precision and GGUF-quantized versions, across four essential software development tasks: code generation, bug fixing, docstring generation, and test case generation.\n\nConducted on both commodity and data center GPU infrastructures, our novel findings unveil that quantized large models often achieve superior efficiency and comparable or better accuracy than full-precision medium-sized models, significantly enhancing the feasibility of local deployment. We establish a strong correlation between LLM architectural characteristics and total energy consumption, offering predictive insights for model selection. Crucially, our results challenge the assumption that higher energy budgets always translate to proportionally better accuracy, demonstrating instances where smaller or quantized models perform competitively. This research provides pivotal insights for organizations seeking to deploy AI coding assistants locally, guiding sustainable, cost-effective, and performance-optimized choices in software development.",
    "keywords": [
      "Locally-deployed LLMs",
      "Data privacy and security",
      "Energy consumption",
      "Inference-phase energy",
      "Model accuracy",
      "Energy-accuracy trade-off",
      "GGUF quantization",
      "Software development tasks",
      "Empirical analysis",
      "Real-world GPU infrastructure",
      "Architectural characteristics correlation",
      "Task-specific model selection",
      "Quantized models efficiency"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/1ab2b071e2eca8627c1b39d8b85efc7ba4818d10.pdf",
    "citation_key": "alizadeh2024q1x",
    "metadata": {
      "title": "Language Models in Software Development Tasks: An Experimental Analysis of Energy and Accuracy",
      "authors": [
        "Negar Alizadeh",
        "Boris Belchev",
        "N. Saurabh",
        "Patricia Kelbert",
        "Fernando Castor Filho"
      ],
      "published_date": "2024",
      "abstract": "The use of generative AI-based coding assistants like ChatGPT and Github Copilot is a reality in contemporary software development. Many of these tools are provided as remote APIs. Using third-party APIs raises data privacy and security concerns for client companies, which motivates the use of locallydeployed language models. In this study, we explore the tradeoff between model accuracy and energy consumption, aiming to provide valuable insights to help developers make informed decisions when selecting a language model. We investigate the performance of 18 families of LLMs in typical software development tasks on two real-world infrastructures, a commodity GPU and a powerful AI-specific GPU. Given that deploying LLMs locally requires powerful infrastructure which might not be affordable for everyone, we consider both full-precision and quantized models. Our findings reveal that employing a big LLM with a higher energy budget does not always translate to significantly improved accuracy. Additionally, quantized versions of large models generally offer better efficiency and accuracy compared to full-precision versions of medium-sized ones. Apart from that, not a single model is suitable for all types of software development tasks.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/1ab2b071e2eca8627c1b39d8b85efc7ba4818d10.pdf",
      "venue": "IEEE Working Conference on Mining Software Repositories",
      "citationCount": 4,
      "score": 4.0,
      "summary": "Here's a focused summary of the technical paper for a literature review, adhering to your requirements:\n\n*   **Research Problem & Motivation**\n    *   **Problem**: The increasing reliance on remote API-based generative AI coding assistants (e.g., ChatGPT, GitHub Copilot) raises significant data privacy and security concerns for companies \\cite{alizadeh2024q1x}. This motivates the use of locally-deployed Language Models (LLMs). However, deploying LLMs locally requires powerful, often expensive infrastructure, and LLMs are known for their substantial energy consumption and associated carbon emissions \\cite{alizadeh2024q1x}. There is a critical need to understand the trade-off between model accuracy and energy consumption for locally deployed LLMs in software development tasks.\n    *   **Importance & Challenge**: This problem is important because it directly impacts the practical adoption of AI coding assistants in sensitive corporate environments and addresses the growing concern about the environmental footprint of AI. It's challenging due to the vast number of LLMs, their varying architectures, the impact of quantization, and the need to evaluate them across diverse software development tasks on different hardware configurations while accurately measuring both performance and energy. Existing research often overlooks inference-phase energy consumption, especially for code-centric LLMs \\cite{alizadeh2024q1x}.\n\n*   **Related Work & Positioning**\n    *   **Existing Approaches**: Previous research on LLMs in software engineering primarily focused on performance metrics like accuracy (e.g., pass@k for code synthesis, repair rate for bug fixing) \\cite{alizadeh2024q1x}. Studies on energy consumption of DL models largely concentrated on the training phase, with limited research on the inference phase, despite its significant long-term energy impact \\cite{alizadeh2024q1x}. Some work has estimated inference energy for general LLMs or across various generative tasks, and others have evaluated quantization techniques for memory reduction, but often without considering energy consumption in the context of software development tasks \\cite{alizadeh2024q1x}.\n    *   **Limitations of Previous Solutions**: Most studies evaluating code-centric LLMs have focused solely on accuracy, neglecting their energy footprint \\cite{alizadeh2024q1x}. Conversely, energy consumption studies for LLMs have rarely focused on the inference phase, and none, to the best of the authors' knowledge, have evaluated a broad range of LLMs specifically for *various software development tasks* while considering *both energy and accuracy* \\cite{alizadeh2024q1x}.\n\n*   **Technical Approach & Innovation**\n    *   **Core Technical Method**: The study conducts an experimental analysis of 18 families of open-access LLMs (including full-precision and GGUF-quantized versions) across four typical software development tasks: code generation, bug fixing, docstring generation, and test case generation \\cite{alizadeh2024q1x}. These experiments are performed on two real-world GPU infrastructures: a commodity end-user GPU (NVIDIA GeForce RTX 3070) and a powerful AI-specific data center GPU (NVIDIA A100) \\cite{alizadeh2024q1x}. Energy consumption (GPU and CPU) is measured using pyNVML and pyRAPL, respectively, alongside accuracy metrics on the Python subset of the HumanEvalPack benchmark \\cite{alizadeh2024q1x}.\n    *   **Novelty**: This approach is novel as it is the first comprehensive study to evaluate a diverse set of LLMs (including quantized models) for *multiple software development tasks* during the *inference phase*, explicitly analyzing the *trade-off between energy consumption and accuracy* on *real-world, distinct hardware setups* \\cite{alizadeh2024q1x}. The inclusion of GGUF quantization, identified as a highly energy-efficient format, is also a key aspect of its novelty \\cite{alizadeh2024q1x}.\n\n*   **Key Technical Contributions**\n    *   **Empirical Analysis**: Provides the first extensive empirical analysis of energy consumption and accuracy trade-offs for a wide range of LLMs performing common software development tasks during inference \\cite{alizadeh2024q1x}.\n    *   **Quantization Efficacy**: Demonstrates that quantized versions of large models generally offer better efficiency and accuracy compared to full-precision versions of medium-sized models, making local deployment more feasible \\cite{alizadeh2024q1x}.\n    *   **Architectural Correlation**: Identifies a strong correlation between an LLM's architectural characteristics (e.g., feed-forward network dimension, number of transformer blocks) and its total energy consumption, suggesting potential for estimating efficiency based on architecture and anticipated output size \\cite{alizadeh2024q1x}.\n    *   **Task-Specific Performance**: Reveals that no single model is universally suitable for all types of software development tasks, highlighting the need for task-specific model selection \\cite{alizadeh2024q1x}.\n    *   **Energy-Accuracy Nuance**: Challenges the assumption that higher energy budgets (larger models) always translate to significantly improved accuracy, showing instances where smaller or quantized models perform similarly or even outperform larger, more energy-intensive counterparts \\cite{alizadeh2024q1x}.\n\n*   **Experimental Validation**\n    *   **Experiments Conducted**: The study evaluated 18 LLM families, encompassing full-precision (fp16) and various GGUF quantized versions (q4, q5, q8), across four software development tasks: Code Generation, Bug Fixing, Docstring Generation, and Test Case Generation \\cite{alizadeh2024q1x}. Experiments were run on two distinct GPU setups: an NVIDIA A100 (80GB) and an NVIDIA GeForce RTX 3070 (8GB) \\cite{alizadeh2024q1x}. The HumanEvalPack benchmark (Python subset) was used for task evaluation \\cite{alizadeh2024q1x}.\n    *   **Key Performance Metrics & Results**:\n        *   **Energy Consumption**: Measured GPU power (pyNVML) and CPU power (pyRAPL), calculating total energy usage. Found that while total energy varies widely across tasks for the same model, energy usage *per generated token* remains consistent \\cite{alizadeh2024q1x}. Total energy consumption strongly correlated with architectural characteristics \\cite{alizadeh2024q1x}.\n        *   **Accuracy**: Evaluated model output correctness for each task.\n        *   **Trade-off Analysis**: Observed that energy consumption and accuracy do not always require a compromise; larger models often have a significantly higher energy footprint while performing similarly, or even being outperformed by, smaller models in terms of accuracy \\cite{alizadeh2ade2024q1x}.\n        *   **Quantization Benefits**: Quantized versions of large models generally offered better efficiency and accuracy compared to full-precision versions of medium-sized models \\cite{alizadeh2024q1x}.\n        *   **Task Specificity**: No single model emerged as optimal for all software development tasks \\cite{alizadeh2024q1x}.\n\n*   **Limitations & Scope**\n    *   **Technical Limitations**: Hardware memory constraints limited the selection to models with no more than 20 billion parameters and specific quantization levels (up to 5-bit for medium-sized models, 8-bit for small models) \\cite{alizadeh2024q1x}. The study focused exclusively on post-training quantization using the GGUF format \\cite{alizadeh2024q1x}.\n    *   **Scope of Applicability**: The evaluation was limited to the Python subset of the HumanEvalPack benchmark, meaning findings might not directly generalize to other programming languages or more complex, real-world software engineering scenarios beyond the four tasks investigated \\cite{alizadeh2024q1x}.\n\n*   **Technical Significance**\n    *   **Advancement of State-of-the-Art**: This work significantly advances the technical state-of-the-art by providing the first comprehensive empirical evidence on the energy-accuracy trade-offs of LLMs for software development tasks during inference \\cite{alizadeh2024q1x}. It fills a critical gap in understanding the practical implications of deploying LLMs locally, moving beyond theoretical discussions or single-metric evaluations.\n    *   **Potential Impact on Future Research**: The findings provide valuable insights for developers and organizations seeking to deploy LLMs locally, enabling more informed decisions that balance performance, cost, and environmental sustainability \\cite{alizadeh2024q1x}. It encourages further research into optimizing LLM architectures and quantization techniques specifically for energy efficiency in domain-specific applications. It also highlights the importance of considering task-specific model selection and the potential of smaller, optimized models to compete with larger, more resource-intensive ones.",
      "keywords": [
        "Locally-deployed LLMs",
        "Data privacy and security",
        "Energy consumption",
        "Inference-phase energy",
        "Model accuracy",
        "Energy-accuracy trade-off",
        "GGUF quantization",
        "Software development tasks",
        "Empirical analysis",
        "Real-world GPU infrastructure",
        "Architectural characteristics correlation",
        "Task-specific model selection",
        "Quantized models efficiency"
      ],
      "paper_type": "based on the abstract and introduction:\n\n*   the abstract explicitly states: \"in this **study**, we explore the trade-off between model accuracy and energy consumption...\" and \"we **investigate** the performance of 18 families of llms in typical software development tasks on two real-world infrastructures...\"\n*   it mentions \"our **findings** reveal that employing a big llm with a higher energy budget does not always translate to significantly improved accuracy.\"\n*   the introduction continues to discuss these \"findings\" and the methodology (18 families of llms, two infrastructures, full-precision and quantized models).\n\nthese phrases directly align with the criteria for an **empirical** paper:\n*   abstract mentions: \"**study**\", \"**experiment**\" (implied by investigation of performance on real-world infrastructure), \"**data**\" (implied by performance of 18 llms), \"**findings**\".\n*   introduction discusses: \"**research questions**\" (implied by exploring trade-offs), \"**methodology**\" (investigating 18 llms on specific hardware), \"**findings**\".\n\ntherefore, this paper is an empirical study.\n\n**classification: empirical**"
    },
    "file_name": "1ab2b071e2eca8627c1b39d8b85efc7ba4818d10.pdf"
  },
  {
    "success": true,
    "doc_id": "3a3dd9d10677213e59400112b7bfddfc",
    "summary": "Here's a focused summary of the paper \\cite{li2025mmf} for a literature review:\n\n### **1. Research Problem & Motivation**\n*   **Specific Technical Problem:** There is limited empirical evidence exploring the real-world usage of generative AI tools like ChatGPT by developers in software development. Existing datasets are often limited in size and temporal coverage, preventing a comprehensive understanding of ChatGPT's prevalence, usability, developer purposes, workflow integration, and task-specific scenarios.\n*   **Importance and Challenge:** Large Language Models (LLMs) are introducing a new paradigm in software engineering. Understanding how developers *actually* utilize ChatGPT in their daily routines is crucial for anticipating its broader impact on the SE field, guiding future research, and informing the development of more effective AI-assisted tools. The challenge lies in collecting and analyzing large-scale, real-world interaction data.\n\n### **2. Related Work & Positioning**\n*   **Relation to Existing Approaches:** Previous studies have explored LLM applicability in SE (e.g., code generation, repair, summarization) and conducted user studies on tools like GitHub Copilot. Specific research on ChatGPT has investigated its role in collaborative coding, bug-fixing performance, and concerns regarding correctness.\n*   **Limitations of Previous Solutions:** While many studies explored the *potential* and *characteristics* of LLM-assisted programming, they often lacked a comprehensive, large-scale empirical investigation into *which specific development-related activities* leverage LLMs and the *detailed characteristics of their real-world usage*. Prior datasets were insufficient to provide a holistic view of ChatGPT's practical integration into developer workflows.\n\n### **3. Technical Approach & Innovation**\n*   **Core Technical Method:** The authors conducted a large-scale empirical investigation of ChatGPT-assisted development activities by analyzing shared ChatGPT links on GitHub.\n    *   They curated **DevChat**, a novel dataset comprising 2,547 unique shared ChatGPT links collected from GitHub between May 2023 and June 2024.\n    *   Data collection employed a hybrid approach using GitHub's REST API and Web crawling, with strategies to maximize results across five primary GitHub data sources (Code, Issues, Commits, Pull Requests, Discussions).\n    *   An in-depth analysis was performed on DevChat to examine usage characteristics (tendency, prompt turns, link descriptions), identify developers' purposes, categorize development-related activities, and establish a mapping framework among data sources, activities, and specific SE tasks.\n*   **Novelty/Difference:** This work provides the first large-scale, real-world empirical evidence of ChatGPT usage on GitHub, bridging a significant gap in the literature. The `DevChat` dataset itself is a novel contribution, offering broader temporal coverage and scope than previous efforts. The study's multi-faceted analysis, including the mapping framework, provides a comprehensive and granular view of ChatGPT's integration into SE workflows.\n\n### **4. Key Technical Contributions**\n*   **Novel Dataset:** Curated **DevChat**, a large-scale, cleaned dataset of 2,547 unique developer-ChatGPT interactions on GitHub, made available for future research \\cite{li2025mmf}.\n*   **Empirical Characterization of Usage:** Provided a detailed analysis of ChatGPT's usage characteristics on GitHub, including usage tendency over time, prompt turns distribution (e.g., short, task-specific, two- or three-turn prompts are most frequent), and the prevalence and nature of link descriptions across different GitHub contexts \\cite{li2025mmf}.\n*   **Categorization of Developer Purposes:** Identified and classified five categories of developers' purposes for sharing ChatGPT conversations during development, with \"Task Delegation\" emerging as the dominant purpose, primarily for automating repetitive work \\cite{li2025mmf}.\n*   **Mapping of Activities and SE Tasks:** Examined development-related activities where developers shared ChatGPT links (categorized into Development Activities and Supporting Activities) and established a comprehensive mapping framework among data sources, activities, and 39 specific SE tasks, highlighting \"Code Generation & Completion\" and \"Code Modification & Optimization\" as the most prevalent \\cite{li2025mmf}.\n\n### **5. Experimental Validation**\n*   **Experiments Conducted:**\n    *   Large-scale data collection and curation of the `DevChat` dataset from GitHub.\n    *   Quantitative analysis of ChatGPT link sharing trends over time and across different GitHub data sources.\n    *   Statistical analysis of prompt turn distribution within shared conversations.\n    *   Content analysis of contextual descriptions accompanying shared links.\n    *   Qualitative and quantitative categorization of developers' stated purposes for sharing links.\n    *   Categorization of development-related activities and a detailed mapping to 39 specific SE tasks.\n*   **Key Performance Metrics and Comparison Results:**\n    *   Developers predominantly share ChatGPT links in **Code (43.4%)** and **Commits (32.3%)**.\n    *   Enthusiasm for sharing peaked in **August 2023**.\n    *   Developers primarily use **short, task-specific prompts**, with **two- or three-turn prompts** being the most frequent.\n    *   **Contextual descriptions** are prevalent in most shared links (e.g., 99% in Commits) but often absent in Code.\n    *   **\"Task Delegation\"** was identified as the dominant purpose for sharing, often to automate repetitive work.\n    *   **Software Development** and **Software Maintenance and Evolution** emerged as dominant activities.\n    *   **Code Generation & Completion** and **Code Modification & Optimization** were the most prevalent among the 39 identified SE tasks.\n\n### **6. Limitations & Scope**\n*   **Technical Limitations/Assumptions:** The study focuses exclusively on shared ChatGPT links on GitHub, which may not capture all forms of ChatGPT usage (e.g., private use, other platforms, other LLMs). The data collection relied on a specific URL format, potentially missing other sharing methods. GitHub API limits, though mitigated, could introduce some bias. The manual review and labeling process, while thorough, inherently carries potential for human bias.\n*   **Scope of Applicability:** The insights are specific to developer-ChatGPT interactions within the GitHub ecosystem and primarily reflect trends in open-source software development. While providing a strong foundation, the findings may not directly generalize to all LLMs or all software development contexts (e.g., closed-source enterprise environments).\n\n### **7. Technical Significance**\n*   **Advances the Technical State-of-the-Art:** This paper provides the first large-scale, empirical, and multi-dimensional characterization of real-world ChatGPT usage in software development. It moves beyond theoretical discussions and limited studies to offer concrete evidence of how developers integrate generative AI into their workflows, thereby significantly advancing the understanding of the evolving AI-empowered development paradigm.\n*   **Potential Impact on Future Research:** The `DevChat` dataset and the comprehensive mapping framework serve as a crucial foundation for future research. The identified prevalent tasks and developer motivations can directly inform the design and optimization of next-generation AI-assisted development tools. Insights into interaction patterns (e.g., prompt turns, descriptions) can guide the development of more intuitive and effective LLM integration strategies, fostering deeper investigations into LLM effectiveness, correctness, and long-term impact on developer productivity and software quality.",
    "intriguing_abstract": "The advent of generative AI, particularly ChatGPT, promises a paradigm shift in software engineering, yet empirical evidence on its real-world integration by developers remains scarce. This paper presents the first large-scale empirical investigation, demystifying how developers *actually* leverage ChatGPT in their daily workflows. We introduce **DevChat**, a novel dataset comprising 2,547 unique developer-ChatGPT interactions meticulously collected from GitHub between May 2023 and June 2024.\n\nOur multi-faceted analysis reveals critical insights: developers predominantly share ChatGPT links in **Code** and **Commits**, favoring short, task-specific prompts for \"Task Delegation,\" especially for automating repetitive work. We meticulously map these interactions to 39 specific SE tasks, identifying \"Code Generation & Completion\" and \"Code Modification & Optimization\" as most prevalent. This work provides unprecedented, granular evidence of ChatGPT's practical integration, offering a foundational understanding of the evolving AI-empowered development landscape. The DevChat dataset and our comprehensive findings are pivotal for guiding future research and informing the design of next-generation AI-assisted tools, ultimately shaping the future of software development.",
    "keywords": [
      "ChatGPT usage in software development",
      "Large Language Models (LLMs)",
      "large-scale empirical investigation",
      "DevChat dataset",
      "GitHub data analysis",
      "developer workflows",
      "prompt turns",
      "Task Delegation",
      "Code Generation & Completion",
      "Code Modification & Optimization",
      "mapping framework",
      "real-world usage",
      "AI-assisted development tools"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8e23664ebf21fe2a586d25cc09fcc26bff4ccf96.pdf",
    "citation_key": "li2025mmf",
    "metadata": {
      "title": "Unveiling the Role of ChatGPT in Software Development: Insights from Developer-ChatGPT Interactions on GitHub",
      "authors": [
        "Ruiyin Li",
        "Peng Liang",
        "Yifei Wang",
        "Yangxiao Cai",
        "Weisong Sun",
        "Zengyang Li"
      ],
      "published_date": "2025",
      "abstract": "The advent of Large Language Models (LLMs) has introduced a new paradigm in software engineering, with generative AI tools like ChatGPT gaining widespread adoption among developers. While ChatGPT's potential has been extensively discussed, there is limited empirical evidence exploring its real-world usage by developers. This study bridges this gap by conducting a large-scale empirical analysis of ChatGPT-assisted development activities, leveraging a curated dataset, DevChat, comprising 2,547 unique shared ChatGPT links collected from GitHub between May 2023 and June 2024. Our study examines the characteristics of ChatGPT's usage on GitHub (including the tendency, prompt turns distribution, and link descriptions) and identifies five categories of developers' purposes for sharing developer-ChatGPT conversations during software development. Additionally, we analyzed the development-related activities where developers shared ChatGPT links to facilitate their workflows. We then established a mapping framework among data sources, activities, and SE tasks associated with these shared ChatGPT links. Our study offers a comprehensive view of ChatGPT's application in real-world software development scenarios and provides a foundation for its future integration into software development workflows.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8e23664ebf21fe2a586d25cc09fcc26bff4ccf96.pdf",
      "venue": "arXiv.org",
      "citationCount": 4,
      "score": 4.0,
      "summary": "Here's a focused summary of the paper \\cite{li2025mmf} for a literature review:\n\n### **1. Research Problem & Motivation**\n*   **Specific Technical Problem:** There is limited empirical evidence exploring the real-world usage of generative AI tools like ChatGPT by developers in software development. Existing datasets are often limited in size and temporal coverage, preventing a comprehensive understanding of ChatGPT's prevalence, usability, developer purposes, workflow integration, and task-specific scenarios.\n*   **Importance and Challenge:** Large Language Models (LLMs) are introducing a new paradigm in software engineering. Understanding how developers *actually* utilize ChatGPT in their daily routines is crucial for anticipating its broader impact on the SE field, guiding future research, and informing the development of more effective AI-assisted tools. The challenge lies in collecting and analyzing large-scale, real-world interaction data.\n\n### **2. Related Work & Positioning**\n*   **Relation to Existing Approaches:** Previous studies have explored LLM applicability in SE (e.g., code generation, repair, summarization) and conducted user studies on tools like GitHub Copilot. Specific research on ChatGPT has investigated its role in collaborative coding, bug-fixing performance, and concerns regarding correctness.\n*   **Limitations of Previous Solutions:** While many studies explored the *potential* and *characteristics* of LLM-assisted programming, they often lacked a comprehensive, large-scale empirical investigation into *which specific development-related activities* leverage LLMs and the *detailed characteristics of their real-world usage*. Prior datasets were insufficient to provide a holistic view of ChatGPT's practical integration into developer workflows.\n\n### **3. Technical Approach & Innovation**\n*   **Core Technical Method:** The authors conducted a large-scale empirical investigation of ChatGPT-assisted development activities by analyzing shared ChatGPT links on GitHub.\n    *   They curated **DevChat**, a novel dataset comprising 2,547 unique shared ChatGPT links collected from GitHub between May 2023 and June 2024.\n    *   Data collection employed a hybrid approach using GitHub's REST API and Web crawling, with strategies to maximize results across five primary GitHub data sources (Code, Issues, Commits, Pull Requests, Discussions).\n    *   An in-depth analysis was performed on DevChat to examine usage characteristics (tendency, prompt turns, link descriptions), identify developers' purposes, categorize development-related activities, and establish a mapping framework among data sources, activities, and specific SE tasks.\n*   **Novelty/Difference:** This work provides the first large-scale, real-world empirical evidence of ChatGPT usage on GitHub, bridging a significant gap in the literature. The `DevChat` dataset itself is a novel contribution, offering broader temporal coverage and scope than previous efforts. The study's multi-faceted analysis, including the mapping framework, provides a comprehensive and granular view of ChatGPT's integration into SE workflows.\n\n### **4. Key Technical Contributions**\n*   **Novel Dataset:** Curated **DevChat**, a large-scale, cleaned dataset of 2,547 unique developer-ChatGPT interactions on GitHub, made available for future research \\cite{li2025mmf}.\n*   **Empirical Characterization of Usage:** Provided a detailed analysis of ChatGPT's usage characteristics on GitHub, including usage tendency over time, prompt turns distribution (e.g., short, task-specific, two- or three-turn prompts are most frequent), and the prevalence and nature of link descriptions across different GitHub contexts \\cite{li2025mmf}.\n*   **Categorization of Developer Purposes:** Identified and classified five categories of developers' purposes for sharing ChatGPT conversations during development, with \"Task Delegation\" emerging as the dominant purpose, primarily for automating repetitive work \\cite{li2025mmf}.\n*   **Mapping of Activities and SE Tasks:** Examined development-related activities where developers shared ChatGPT links (categorized into Development Activities and Supporting Activities) and established a comprehensive mapping framework among data sources, activities, and 39 specific SE tasks, highlighting \"Code Generation & Completion\" and \"Code Modification & Optimization\" as the most prevalent \\cite{li2025mmf}.\n\n### **5. Experimental Validation**\n*   **Experiments Conducted:**\n    *   Large-scale data collection and curation of the `DevChat` dataset from GitHub.\n    *   Quantitative analysis of ChatGPT link sharing trends over time and across different GitHub data sources.\n    *   Statistical analysis of prompt turn distribution within shared conversations.\n    *   Content analysis of contextual descriptions accompanying shared links.\n    *   Qualitative and quantitative categorization of developers' stated purposes for sharing links.\n    *   Categorization of development-related activities and a detailed mapping to 39 specific SE tasks.\n*   **Key Performance Metrics and Comparison Results:**\n    *   Developers predominantly share ChatGPT links in **Code (43.4%)** and **Commits (32.3%)**.\n    *   Enthusiasm for sharing peaked in **August 2023**.\n    *   Developers primarily use **short, task-specific prompts**, with **two- or three-turn prompts** being the most frequent.\n    *   **Contextual descriptions** are prevalent in most shared links (e.g., 99% in Commits) but often absent in Code.\n    *   **\"Task Delegation\"** was identified as the dominant purpose for sharing, often to automate repetitive work.\n    *   **Software Development** and **Software Maintenance and Evolution** emerged as dominant activities.\n    *   **Code Generation & Completion** and **Code Modification & Optimization** were the most prevalent among the 39 identified SE tasks.\n\n### **6. Limitations & Scope**\n*   **Technical Limitations/Assumptions:** The study focuses exclusively on shared ChatGPT links on GitHub, which may not capture all forms of ChatGPT usage (e.g., private use, other platforms, other LLMs). The data collection relied on a specific URL format, potentially missing other sharing methods. GitHub API limits, though mitigated, could introduce some bias. The manual review and labeling process, while thorough, inherently carries potential for human bias.\n*   **Scope of Applicability:** The insights are specific to developer-ChatGPT interactions within the GitHub ecosystem and primarily reflect trends in open-source software development. While providing a strong foundation, the findings may not directly generalize to all LLMs or all software development contexts (e.g., closed-source enterprise environments).\n\n### **7. Technical Significance**\n*   **Advances the Technical State-of-the-Art:** This paper provides the first large-scale, empirical, and multi-dimensional characterization of real-world ChatGPT usage in software development. It moves beyond theoretical discussions and limited studies to offer concrete evidence of how developers integrate generative AI into their workflows, thereby significantly advancing the understanding of the evolving AI-empowered development paradigm.\n*   **Potential Impact on Future Research:** The `DevChat` dataset and the comprehensive mapping framework serve as a crucial foundation for future research. The identified prevalent tasks and developer motivations can directly inform the design and optimization of next-generation AI-assisted development tools. Insights into interaction patterns (e.g., prompt turns, descriptions) can guide the development of more intuitive and effective LLM integration strategies, fostering deeper investigations into LLM effectiveness, correctness, and long-term impact on developer productivity and software quality.",
      "keywords": [
        "ChatGPT usage in software development",
        "Large Language Models (LLMs)",
        "large-scale empirical investigation",
        "DevChat dataset",
        "GitHub data analysis",
        "developer workflows",
        "prompt turns",
        "Task Delegation",
        "Code Generation & Completion",
        "Code Modification & Optimization",
        "mapping framework",
        "real-world usage",
        "AI-assisted development tools"
      ],
      "paper_type": "the paper type is **empirical**.\n\n**reasoning:**\n\n1.  **abstract explicitly states:** \"we conducted a large-scale empirical investigation into shared chatgpt links, offering insights into llm-assisted software development.\"\n2.  **data collection:** the abstract details the curation of \"devchat, a large-scale dataset that encompasses chatgpt usage from may 2023 to june 17, 2024. devchat contains 2,547 unique shared chatgpt links...\"\n3.  **analysis and findings:** the abstract describes \"an in-depth analysis of how developers utilize chatgpt,\" and presents \"several key findings\" with specific percentages (e.g., \"developers predominantly share chatgpt links in code (43.4%) and commits (32.3%)\"), classifications (e.g., \"purposes for sharing chatgpt links... classified into five categories\"), and mappings.\n4.  **empirical evidence:** the abstract concludes that \"these findings provide crucial empirical evidence for guiding future research...\"\n5.  **introduction/study design:** the introduction mentions addressing gaps by \"empirically investigating chatgpt’s usage on github\" and section 3 is titled \"study design\" and mentions \"research questions (rqs),\" which are characteristic of empirical studies.\n\nthese elements strongly align with the criteria for an **empirical** paper, which focuses on data-driven studies with statistical analysis and findings."
    },
    "file_name": "8e23664ebf21fe2a586d25cc09fcc26bff4ccf96.pdf"
  },
  {
    "success": true,
    "doc_id": "bf9ee9a715ef38fb2d27f2d79d963080",
    "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation where applicable:\n\n*   **1. Research Problem & Motivation**\n    *   The paper addresses the significant disconnect between the rapid adoption of AI-generated code (termed \"vibe coding\") and the limited conceptual understanding of this emerging paradigm in software development \\cite{meske2025khk}.\n    *   This problem is critical because vibe coding, where large portions of codebases are AI-generated (e.g., 25% of Y Combinator Winter 2025 cohort startups reported 95% AI-generated code), fundamentally reconfigures \"intent mediation\" \\cite{meske2025khk}. Intent mediation is the core process by which developers translate conceptual goals into executable computational representations \\cite{meske2025khk}.\n    *   The shift from deterministic instruction to probabilistic inference in intent mediation alters cognitive work, redistributes epistemic labor, and changes professional expertise, introducing both opportunities (democratization, acceleration) and risks (black box codebases, responsibility gaps) \\cite{meske2025khk}.\n    *   Existing research often views Large Language Models (LLMs) as mere subordinate assistants, failing to conceptualize them as collaborative partners in a new development paradigm, thus creating an urgent need for systematic analysis \\cite{meske2025khk}.\n\n*   **2. Related Work & Positioning**\n    *   The work positions vibe coding within a historical evolution of intent mediation in software development, tracing shifts from physical hardware manipulation (1940s) through symbolic abstractions (assembly, high-level languages), object-oriented paradigms, and predictive assistance (2000s) \\cite{meske2025khk}.\n    *   It acknowledges that vibe coding aligns with broader theories of distributed cognition and hybrid intelligence, where cognitive work is dynamically shared between human developers and AI agents \\cite{meske2025khk}.\n    *   Previous approaches to integrating LLMs into software engineering primarily focused on technical architectures and performance metrics, largely overlooking how these models fundamentally reconfigure the nature of programming and intent mediation itself \\cite{meske2025khk}. This paper aims to fill this conceptual gap by providing a systematic definition and analysis of vibe coding as a distinct paradigm \\cite{meske2025khk}.\n\n*   **3. Technical Approach & Innovation**\n    *   The paper's core approach is conceptual and analytical, defining \"vibe coding\" as a distinct software development paradigm \\cite{meske2025khk}.\n    *   **Definition of Vibe Coding:** It is defined as \"a software development paradigm where humans and generative AI engage in collaborative flow to co-create software artifacts through natural language dialogue, shifting the mediation of developer intent from deterministic instruction to probabilistic inference\" \\cite{meske2025khk}.\n    *   **Mechanism of Innovation:** The innovation lies in the *reconfiguration of intent mediation*: moving from developers explicitly encoding intent through formal syntax (deterministic instruction) to AI systems inferring meaning from naturalistic expression and assuming responsibility for translating human goals into executable code (probabilistic interpretation) \\cite{meske2025khk}.\n    *   This approach is novel because it provides the first systematic conceptualization of vibe coding, reframing software development as \"interpretive co-creation\" rather than formal construction, and analyzing its implications for cognitive work and expertise \\cite{meske2025khk}.\n\n*   **4. Key Technical Contributions**\n    *   **Theoretical Framework:** Introduces a novel conceptual framework for understanding vibe coding as a distinct programming mode, centered on the fundamental shift in \"intent mediation\" \\cite{meske2025khk}.\n    *   **Historical Analysis:** Provides a detailed historical analysis of intent mediation in software development, establishing a context for the current paradigm shift driven by generative AI \\cite{meske2025khk}.\n    *   **Reconfiguration of Cognitive Work:** Identifies how vibe coding reconfigures cognitive work by redistributing epistemic labor between humans and machines, shifting expertise from traditional areas (design, technical implementation) toward collaborative orchestration \\cite{meske2025khk}.\n    *   **Identification of Opportunities and Risks:** Synthesizes key opportunities (e.g., democratization, acceleration, systemic leverage) and risks (e.g., black box codebases, responsibility gaps, ecosystem bias) inherent in this new paradigm \\cite{meske2025khk}.\n    *   **Research Agenda:** Proposes a comprehensive research agenda spanning human-, technology-, and organization-centered directions to guide future investigations into vibe coding \\cite{meske2025khk}.\n\n*   **5. Experimental Validation**\n    *   This paper is a conceptual and analytical work; it does not present original experimental validation, empirical studies, or benchmark comparisons conducted by the authors \\cite{meske2025khk}.\n    *   The paper cites external statistics (e.g., Y Combinator data) to motivate the prevalence and impact of AI-generated code, but these are not the authors' own experimental results \\cite{meske2025khk}.\n\n*   **6. Limitations & Scope**\n    *   The primary limitation is its conceptual nature; it defines and analyzes a paradigm but does not offer new technical solutions or empirical evidence from its own experiments \\cite{meske2025khk}.\n    *   The scope is focused on the conceptual understanding and implications of \"vibe coding\" driven by generative AI and LLMs in software development, particularly concerning human-AI collaboration and the evolving role of developers \\cite{meske2025khk}. It does not delve into the specific technical implementations or performance characteristics of the underlying AI models.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art:** Provides a foundational conceptual framework for understanding \"vibe coding,\" moving beyond viewing LLMs as mere productivity tools to recognizing them as agents in a new, distinct software development paradigm \\cite{meske2025khk}. It offers a novel lens (\"intent mediation\") to analyze the profound shifts occurring due to generative AI \\cite{meske2025khk}.\n    *   **Potential Impact:** The paper's comprehensive definition and analysis of vibe coding, along with its proposed research agenda, are crucial for guiding future empirical and theoretical investigations \\cite{meske2025khk}. It encourages researchers to explore deeper reconfigurations of human-computer interaction, developer roles, and software engineering practices, laying the groundwork for new theories and models of collaborative software development in an AI-augmented world \\cite{meske2025khk}.",
    "intriguing_abstract": "The silent revolution of AI-generated code, now comprising up to 95% of some startup codebases, has outpaced our conceptual understanding, creating a critical void in software engineering theory. This paper introduces \"vibe coding,\" a novel software development paradigm where humans and generative AI collaboratively co-create software through natural language dialogue. We reveal how vibe coding fundamentally reconfigures \"intent mediation,\" shifting it from deterministic instruction to probabilistic inference. This profound transformation alters cognitive work, redistributes epistemic labor, and reshapes professional expertise, presenting both unprecedented opportunities for democratization and acceleration, alongside significant risks like black box codebases and responsibility gaps. By providing the first systematic conceptualization of vibe coding, a historical analysis of intent mediation, and a comprehensive research agenda, this work offers a foundational framework. It challenges existing views of Large Language Models (LLMs) as mere assistants, positioning them as collaborative partners in an interpretive co-creation process, and is essential for navigating the future of human-AI software development.",
    "keywords": [
      "vibe coding",
      "intent mediation",
      "generative AI",
      "Large Language Models (LLMs)",
      "software development paradigm",
      "probabilistic inference",
      "human-AI collaboration",
      "conceptual framework",
      "reconfiguration of cognitive work",
      "black box codebases",
      "responsibility gaps",
      "interpretive co-creation",
      "research agenda"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f3ba6031011181b406bb9ae426d42aa74f66eb34.pdf",
    "citation_key": "meske2025khk",
    "metadata": {
      "title": "Vibe Coding as a Reconfiguration of Intent Mediation in Software Development: Definition, Implications, and Research Agenda",
      "authors": [
        "Christian Meske",
        "Tobias Hermanns",
        "Esther von der Weiden",
        "Kai-Uwe Loser",
        "Thorsten Berger"
      ],
      "published_date": "2025",
      "abstract": "Software development is undergoing a fundamental transformation as vibe coding becomes widespread, with large portions of contemporary codebases now being AI-generated. The disconnect between rapid adoption and limited conceptual understanding highlights the need for an inquiry into this emerging paradigm. Drawing on an intent perspective and historical analysis, we define vibe coding as a software development paradigm where humans and generative AI engage in collaborative flow to co-create software artifacts through natural language dialogue, shifting the mediation of developer intent from deterministic instruction to probabilistic inference. By intent mediation, we refer to the fundamental process through which developers translate their conceptual goals into representations that computational systems can execute. Our results show that vibe coding reconfigures cognitive work by redistributing epistemic labor between humans and machines, shifting the expertise in the software development process away from traditional areas such as design or technical implementation toward collaborative orchestration. We identify key opportunities, including democratization, acceleration, and systemic leverage, alongside risks, such as black box codebases, responsibility gaps, and ecosystem bias. We conclude with a research agenda spanning human-, technology-, and organization-centered directions to guide future investigations of this paradigm.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f3ba6031011181b406bb9ae426d42aa74f66eb34.pdf",
      "venue": "arXiv.org",
      "citationCount": 4,
      "score": 4.0,
      "summary": "Here's a focused summary of the paper for a literature review, emphasizing technical innovations and empirical validation where applicable:\n\n*   **1. Research Problem & Motivation**\n    *   The paper addresses the significant disconnect between the rapid adoption of AI-generated code (termed \"vibe coding\") and the limited conceptual understanding of this emerging paradigm in software development \\cite{meske2025khk}.\n    *   This problem is critical because vibe coding, where large portions of codebases are AI-generated (e.g., 25% of Y Combinator Winter 2025 cohort startups reported 95% AI-generated code), fundamentally reconfigures \"intent mediation\" \\cite{meske2025khk}. Intent mediation is the core process by which developers translate conceptual goals into executable computational representations \\cite{meske2025khk}.\n    *   The shift from deterministic instruction to probabilistic inference in intent mediation alters cognitive work, redistributes epistemic labor, and changes professional expertise, introducing both opportunities (democratization, acceleration) and risks (black box codebases, responsibility gaps) \\cite{meske2025khk}.\n    *   Existing research often views Large Language Models (LLMs) as mere subordinate assistants, failing to conceptualize them as collaborative partners in a new development paradigm, thus creating an urgent need for systematic analysis \\cite{meske2025khk}.\n\n*   **2. Related Work & Positioning**\n    *   The work positions vibe coding within a historical evolution of intent mediation in software development, tracing shifts from physical hardware manipulation (1940s) through symbolic abstractions (assembly, high-level languages), object-oriented paradigms, and predictive assistance (2000s) \\cite{meske2025khk}.\n    *   It acknowledges that vibe coding aligns with broader theories of distributed cognition and hybrid intelligence, where cognitive work is dynamically shared between human developers and AI agents \\cite{meske2025khk}.\n    *   Previous approaches to integrating LLMs into software engineering primarily focused on technical architectures and performance metrics, largely overlooking how these models fundamentally reconfigure the nature of programming and intent mediation itself \\cite{meske2025khk}. This paper aims to fill this conceptual gap by providing a systematic definition and analysis of vibe coding as a distinct paradigm \\cite{meske2025khk}.\n\n*   **3. Technical Approach & Innovation**\n    *   The paper's core approach is conceptual and analytical, defining \"vibe coding\" as a distinct software development paradigm \\cite{meske2025khk}.\n    *   **Definition of Vibe Coding:** It is defined as \"a software development paradigm where humans and generative AI engage in collaborative flow to co-create software artifacts through natural language dialogue, shifting the mediation of developer intent from deterministic instruction to probabilistic inference\" \\cite{meske2025khk}.\n    *   **Mechanism of Innovation:** The innovation lies in the *reconfiguration of intent mediation*: moving from developers explicitly encoding intent through formal syntax (deterministic instruction) to AI systems inferring meaning from naturalistic expression and assuming responsibility for translating human goals into executable code (probabilistic interpretation) \\cite{meske2025khk}.\n    *   This approach is novel because it provides the first systematic conceptualization of vibe coding, reframing software development as \"interpretive co-creation\" rather than formal construction, and analyzing its implications for cognitive work and expertise \\cite{meske2025khk}.\n\n*   **4. Key Technical Contributions**\n    *   **Theoretical Framework:** Introduces a novel conceptual framework for understanding vibe coding as a distinct programming mode, centered on the fundamental shift in \"intent mediation\" \\cite{meske2025khk}.\n    *   **Historical Analysis:** Provides a detailed historical analysis of intent mediation in software development, establishing a context for the current paradigm shift driven by generative AI \\cite{meske2025khk}.\n    *   **Reconfiguration of Cognitive Work:** Identifies how vibe coding reconfigures cognitive work by redistributing epistemic labor between humans and machines, shifting expertise from traditional areas (design, technical implementation) toward collaborative orchestration \\cite{meske2025khk}.\n    *   **Identification of Opportunities and Risks:** Synthesizes key opportunities (e.g., democratization, acceleration, systemic leverage) and risks (e.g., black box codebases, responsibility gaps, ecosystem bias) inherent in this new paradigm \\cite{meske2025khk}.\n    *   **Research Agenda:** Proposes a comprehensive research agenda spanning human-, technology-, and organization-centered directions to guide future investigations into vibe coding \\cite{meske2025khk}.\n\n*   **5. Experimental Validation**\n    *   This paper is a conceptual and analytical work; it does not present original experimental validation, empirical studies, or benchmark comparisons conducted by the authors \\cite{meske2025khk}.\n    *   The paper cites external statistics (e.g., Y Combinator data) to motivate the prevalence and impact of AI-generated code, but these are not the authors' own experimental results \\cite{meske2025khk}.\n\n*   **6. Limitations & Scope**\n    *   The primary limitation is its conceptual nature; it defines and analyzes a paradigm but does not offer new technical solutions or empirical evidence from its own experiments \\cite{meske2025khk}.\n    *   The scope is focused on the conceptual understanding and implications of \"vibe coding\" driven by generative AI and LLMs in software development, particularly concerning human-AI collaboration and the evolving role of developers \\cite{meske2025khk}. It does not delve into the specific technical implementations or performance characteristics of the underlying AI models.\n\n*   **7. Technical Significance**\n    *   **Advances State-of-the-Art:** Provides a foundational conceptual framework for understanding \"vibe coding,\" moving beyond viewing LLMs as mere productivity tools to recognizing them as agents in a new, distinct software development paradigm \\cite{meske2025khk}. It offers a novel lens (\"intent mediation\") to analyze the profound shifts occurring due to generative AI \\cite{meske2025khk}.\n    *   **Potential Impact:** The paper's comprehensive definition and analysis of vibe coding, along with its proposed research agenda, are crucial for guiding future empirical and theoretical investigations \\cite{meske2025khk}. It encourages researchers to explore deeper reconfigurations of human-computer interaction, developer roles, and software engineering practices, laying the groundwork for new theories and models of collaborative software development in an AI-augmented world \\cite{meske2025khk}.",
      "keywords": [
        "vibe coding",
        "intent mediation",
        "generative AI",
        "Large Language Models (LLMs)",
        "software development paradigm",
        "probabilistic inference",
        "human-AI collaboration",
        "conceptual framework",
        "reconfiguration of cognitive work",
        "black box codebases",
        "responsibility gaps",
        "interpretive co-creation",
        "research agenda"
      ],
      "paper_type": "based on the abstract and introduction, this paper is best classified as a **position** paper.\n\nhere's why:\n\n*   **abstract mentions:** \"we define vibe coding as a software development paradigm...\", \"our results show that vibe coding reconfigures cognitive work...\", \"we identify key opportunities... alongside risks...\", \"we conclude with a research agenda... to guide future investigations of this paradigm.\" these phrases strongly align with arguing for a viewpoint, defining a new concept, analyzing its implications, and proposing future directions.\n*   **introduction discusses:** \"the software development landscape is undergoing a profound transformation... this shift represents more than technological convenience; it marks a fundamental reconfiguration of intent mediation in software development.\" this sets up a strong argument about the significance of the emerging phenomenon and the paper's proposed framework for understanding it.\n\nthe paper defines a new paradigm (\"vibe coding\"), analyzes its conceptual implications (reconfiguration of intent mediation, cognitive work, opportunities, risks), and proposes a future research agenda. this structure is characteristic of a position paper that aims to frame an emerging topic and guide future discourse and research."
    },
    "file_name": "f3ba6031011181b406bb9ae426d42aa74f66eb34.pdf"
  },
  {
    "success": true,
    "doc_id": "b2b3b9c1cffc2bb24282fd2c0cd2e325",
    "summary": "Artificial Intelligence (AI) has been applied to various areas of software engineering, including requirements engineering, coding, testing, and debugging. This has led to the emergence of AI for Software Engineering as a distinct research area within software engineering. With the development of quantum computing, the field of Quantum AI (QAI) is arising, enhancing the performance of classical AI and holding significant potential for solving classical software engineering problems. Some initial applications of QAI in software engineering have already emerged, such as software test optimization. However, the path ahead remains open, offering ample opportunities to solve complex software engineering problems with QAI cost-effectively. To this end, this paper presents open research opportunities and challenges in QAI for software engineering that need to be addressed.",
    "intriguing_abstract": "Artificial Intelligence (AI) has been applied to various areas of software engineering, including requirements engineering, coding, testing, and debugging. This has led to the emergence of AI for Software Engineering as a distinct research area within software engineering. With the development of quantum computing, the field of Quantum AI (QAI) is arising, enhancing the performance of classical AI and holding significant potential for solving classical software engineering problems. Some initial applications of QAI in software engineering have already emerged, such as software test optimization. However, the path ahead remains open, offering ample opportunities to solve complex software engineering problems with QAI cost-effectively. To this end, this paper presents open research opportunities and challenges in QAI for software engineering that need to be addressed.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/58da3afb7045aef0156c4400eadf215ee473ea8e.pdf",
    "citation_key": "wang2025ye1",
    "metadata": {
      "title": "Quantum Artificial Intelligence for Software Engineering: the Road Ahead",
      "authors": [
        "Xinyi Wang",
        "Shaukat Ali",
        "Paolo Arcaini"
      ],
      "published_date": "2025",
      "abstract": "Artificial Intelligence (AI) has been applied to various areas of software engineering, including requirements engineering, coding, testing, and debugging. This has led to the emergence of AI for Software Engineering as a distinct research area within software engineering. With the development of quantum computing, the field of Quantum AI (QAI) is arising, enhancing the performance of classical AI and holding significant potential for solving classical software engineering problems. Some initial applications of QAI in software engineering have already emerged, such as software test optimization. However, the path ahead remains open, offering ample opportunities to solve complex software engineering problems with QAI cost-effectively. To this end, this paper presents open research opportunities and challenges in QAI for software engineering that need to be addressed.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/58da3afb7045aef0156c4400eadf215ee473ea8e.pdf",
      "venue": "arXiv.org",
      "citationCount": 4,
      "score": 4.0,
      "summary": "Artificial Intelligence (AI) has been applied to various areas of software engineering, including requirements engineering, coding, testing, and debugging. This has led to the emergence of AI for Software Engineering as a distinct research area within software engineering. With the development of quantum computing, the field of Quantum AI (QAI) is arising, enhancing the performance of classical AI and holding significant potential for solving classical software engineering problems. Some initial applications of QAI in software engineering have already emerged, such as software test optimization. However, the path ahead remains open, offering ample opportunities to solve complex software engineering problems with QAI cost-effectively. To this end, this paper presents open research opportunities and challenges in QAI for software engineering that need to be addressed.",
      "keywords": []
    },
    "file_name": "58da3afb7045aef0156c4400eadf215ee473ea8e.pdf"
  },
  {
    "success": true,
    "doc_id": "3248d85a849571a78bc6f239c8fa5283",
    "summary": "As the demand for skilled software developers continues to rise, the integration of Generative Artificial Intelligence (Generative AI) in educational settings has garnered attention. This research investigates the effectiveness of Generative AI in enhancing coding proficiency in a diverse cohort of participants. The study employs pre-, mid-, and post-tests to measure coding skills, employing a nuanced analysis across various demographic variables. The findings reveal a substantial increase in average scores, indicating positive impacts of Generative AI on coding abilities. The N-Gain value of 0.33 signifies a medium learning gain, establishing Generative AI as a valuable tool in coding education. A detailed exploration of demographic variables, including gender, age, academic level, A/L stream, A/L district, and preferred programming language, provides insights into the intersectionality of these factors with learning outcomes. This research contributes to the discourse on the impact of Generative AI on coding skills, offering practical insights for educators, policymakers, and practitioners. The study recommends tailored interventions to address specific demographic variables, fostering a more inclusive and effective learning environment.",
    "intriguing_abstract": "As the demand for skilled software developers continues to rise, the integration of Generative Artificial Intelligence (Generative AI) in educational settings has garnered attention. This research investigates the effectiveness of Generative AI in enhancing coding proficiency in a diverse cohort of participants. The study employs pre-, mid-, and post-tests to measure coding skills, employing a nuanced analysis across various demographic variables. The findings reveal a substantial increase in average scores, indicating positive impacts of Generative AI on coding abilities. The N-Gain value of 0.33 signifies a medium learning gain, establishing Generative AI as a valuable tool in coding education. A detailed exploration of demographic variables, including gender, age, academic level, A/L stream, A/L district, and preferred programming language, provides insights into the intersectionality of these factors with learning outcomes. This research contributes to the discourse on the impact of Generative AI on coding skills, offering practical insights for educators, policymakers, and practitioners. The study recommends tailored interventions to address specific demographic variables, fostering a more inclusive and effective learning environment.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ac55ebabbe891a8a754fef3719bdbf319bcf67c0.pdf",
    "citation_key": "samarakoon2024sff",
    "metadata": {
      "title": "Analyzing the Learning Effectiveness of Generative AI for Software Development for Undergraduates in Sri Lanka",
      "authors": [
        "Pramodya Samarakoon",
        "Dinesh Asanka",
        "Shantha Jayalal",
        "Nirasha Jayalath"
      ],
      "published_date": "2024",
      "abstract": "As the demand for skilled software developers continues to rise, the integration of Generative Artificial Intelligence (Generative AI) in educational settings has garnered attention. This research investigates the effectiveness of Generative AI in enhancing coding proficiency in a diverse cohort of participants. The study employs pre-, mid-, and post-tests to measure coding skills, employing a nuanced analysis across various demographic variables. The findings reveal a substantial increase in average scores, indicating positive impacts of Generative AI on coding abilities. The N-Gain value of 0.33 signifies a medium learning gain, establishing Generative AI as a valuable tool in coding education. A detailed exploration of demographic variables, including gender, age, academic level, A/L stream, A/L district, and preferred programming language, provides insights into the intersectionality of these factors with learning outcomes. This research contributes to the discourse on the impact of Generative AI on coding skills, offering practical insights for educators, policymakers, and practitioners. The study recommends tailored interventions to address specific demographic variables, fostering a more inclusive and effective learning environment.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ac55ebabbe891a8a754fef3719bdbf319bcf67c0.pdf",
      "venue": "International Conference on Soft Computing and Software Engineering",
      "citationCount": 3,
      "score": 3.0,
      "summary": "As the demand for skilled software developers continues to rise, the integration of Generative Artificial Intelligence (Generative AI) in educational settings has garnered attention. This research investigates the effectiveness of Generative AI in enhancing coding proficiency in a diverse cohort of participants. The study employs pre-, mid-, and post-tests to measure coding skills, employing a nuanced analysis across various demographic variables. The findings reveal a substantial increase in average scores, indicating positive impacts of Generative AI on coding abilities. The N-Gain value of 0.33 signifies a medium learning gain, establishing Generative AI as a valuable tool in coding education. A detailed exploration of demographic variables, including gender, age, academic level, A/L stream, A/L district, and preferred programming language, provides insights into the intersectionality of these factors with learning outcomes. This research contributes to the discourse on the impact of Generative AI on coding skills, offering practical insights for educators, policymakers, and practitioners. The study recommends tailored interventions to address specific demographic variables, fostering a more inclusive and effective learning environment.",
      "keywords": []
    },
    "file_name": "ac55ebabbe891a8a754fef3719bdbf319bcf67c0.pdf"
  },
  {
    "success": true,
    "doc_id": "1190a5fb351a971e66bc732325cdb93d",
    "summary": "This innovative practice full paper explores the use of AI technologies in user story generation. With the emergence of agile software development, generating comprehensive user stories that capture all necessary functionalities and perspectives has become crucial for software development. Every computing program in the United States requires a semester-or year-long senior capstone project, which requires student teams to gather and document technical requirements. Effective user story generation is crucial for successfully implementing software projects. However, user stories written in natural language can be prone to inherent defects such as incompleteness and incorrectness, which may creep in during the downstream development activities like software designs, construction, and testing. One of the challenges faced by software engineering educators is to teach students how to elicit and document requirements, which serve as a blueprint for software development. Advanced AI technologies have increased the popularity of large language models (LLMs) trained on large multimodal datasets. Therefore, utilizing LLM-based techniques can assist educators in helping students discover aspects of user stories that may have been overlooked or missed during the manual analysis of requirements from various stakeholders. The main goal of this research study is to investigate the potential application of OpenAI techniques in software development courses at two academic institutions to enhance software design and development processes, aiming to improve innovation and efficiency in team project-based educational settings. The data used for the study constitute student teams generating user stories by traditional methods (control) vs. student teams using OpenAI agents (treatment) such as gpt-4-turbo for generating user stories. The overarching research questions include: RQ-l) What aspects of user stories generated using OpenAI prompt engineering differ significantly from those generated using the traditional method? RQ-2) Can the prompt engineering data provide insights into the efficacy of the questions/prompts that affect the quality and comprehensiveness of user stories created by software development teams? Industry experts evaluated the user stories created and analyzed how prompt engineering affects the overall effectiveness and innovation of user story creation, which provided guidelines for incorporating AI-driven approaches into software development practices. Overall, this research seeks to contribute to the growing body of knowledge on the application of AI in software engineering education, specifically in user story generation. Investigating the use of AI technologies in user story generation could further enhance the usability of prompt engineering in agile software development environments. We plan to expand the study to investigate the long-term effects of prompt engineering on all phases of software development.",
    "intriguing_abstract": "This innovative practice full paper explores the use of AI technologies in user story generation. With the emergence of agile software development, generating comprehensive user stories that capture all necessary functionalities and perspectives has become crucial for software development. Every computing program in the United States requires a semester-or year-long senior capstone project, which requires student teams to gather and document technical requirements. Effective user story generation is crucial for successfully implementing software projects. However, user stories written in natural language can be prone to inherent defects such as incompleteness and incorrectness, which may creep in during the downstream development activities like software designs, construction, and testing. One of the challenges faced by software engineering educators is to teach students how to elicit and document requirements, which serve as a blueprint for software development. Advanced AI technologies have increased the popularity of large language models (LLMs) trained on large multimodal datasets. Therefore, utilizing LLM-based techniques can assist educators in helping students discover aspects of user stories that may have been overlooked or missed during the manual analysis of requirements from various stakeholders. The main goal of this research study is to investigate the potential application of OpenAI techniques in software development courses at two academic institutions to enhance software design and development processes, aiming to improve innovation and efficiency in team project-based educational settings. The data used for the study constitute student teams generating user stories by traditional methods (control) vs. student teams using OpenAI agents (treatment) such as gpt-4-turbo for generating user stories. The overarching research questions include: RQ-l) What aspects of user stories generated using OpenAI prompt engineering differ significantly from those generated using the traditional method? RQ-2) Can the prompt engineering data provide insights into the efficacy of the questions/prompts that affect the quality and comprehensiveness of user stories created by software development teams? Industry experts evaluated the user stories created and analyzed how prompt engineering affects the overall effectiveness and innovation of user story creation, which provided guidelines for incorporating AI-driven approaches into software development practices. Overall, this research seeks to contribute to the growing body of knowledge on the application of AI in software engineering education, specifically in user story generation. Investigating the use of AI technologies in user story generation could further enhance the usability of prompt engineering in agile software development environments. We plan to expand the study to investigate the long-term effects of prompt engineering on all phases of software development.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/915bee04aaf51eb675745aaf3dfe455d2d46f105.pdf",
    "citation_key": "ramasamy20249sg",
    "metadata": {
      "title": "Enhancing User Story Generation in Agile Software Development Through Open AI and Prompt Engineering",
      "authors": [
        "Vijayalakshmi Ramasamy",
        "Suganya Ramamoorthy",
        "G. Walia",
        "Eli Kulpinski",
        "Aaron Antreassian"
      ],
      "published_date": "2024",
      "abstract": "This innovative practice full paper explores the use of AI technologies in user story generation. With the emergence of agile software development, generating comprehensive user stories that capture all necessary functionalities and perspectives has become crucial for software development. Every computing program in the United States requires a semester-or year-long senior capstone project, which requires student teams to gather and document technical requirements. Effective user story generation is crucial for successfully implementing software projects. However, user stories written in natural language can be prone to inherent defects such as incompleteness and incorrectness, which may creep in during the downstream development activities like software designs, construction, and testing. One of the challenges faced by software engineering educators is to teach students how to elicit and document requirements, which serve as a blueprint for software development. Advanced AI technologies have increased the popularity of large language models (LLMs) trained on large multimodal datasets. Therefore, utilizing LLM-based techniques can assist educators in helping students discover aspects of user stories that may have been overlooked or missed during the manual analysis of requirements from various stakeholders. The main goal of this research study is to investigate the potential application of OpenAI techniques in software development courses at two academic institutions to enhance software design and development processes, aiming to improve innovation and efficiency in team project-based educational settings. The data used for the study constitute student teams generating user stories by traditional methods (control) vs. student teams using OpenAI agents (treatment) such as gpt-4-turbo for generating user stories. The overarching research questions include: RQ-l) What aspects of user stories generated using OpenAI prompt engineering differ significantly from those generated using the traditional method? RQ-2) Can the prompt engineering data provide insights into the efficacy of the questions/prompts that affect the quality and comprehensiveness of user stories created by software development teams? Industry experts evaluated the user stories created and analyzed how prompt engineering affects the overall effectiveness and innovation of user story creation, which provided guidelines for incorporating AI-driven approaches into software development practices. Overall, this research seeks to contribute to the growing body of knowledge on the application of AI in software engineering education, specifically in user story generation. Investigating the use of AI technologies in user story generation could further enhance the usability of prompt engineering in agile software development environments. We plan to expand the study to investigate the long-term effects of prompt engineering on all phases of software development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/915bee04aaf51eb675745aaf3dfe455d2d46f105.pdf",
      "venue": "Frontiers in Education Conference",
      "citationCount": 3,
      "score": 3.0,
      "summary": "This innovative practice full paper explores the use of AI technologies in user story generation. With the emergence of agile software development, generating comprehensive user stories that capture all necessary functionalities and perspectives has become crucial for software development. Every computing program in the United States requires a semester-or year-long senior capstone project, which requires student teams to gather and document technical requirements. Effective user story generation is crucial for successfully implementing software projects. However, user stories written in natural language can be prone to inherent defects such as incompleteness and incorrectness, which may creep in during the downstream development activities like software designs, construction, and testing. One of the challenges faced by software engineering educators is to teach students how to elicit and document requirements, which serve as a blueprint for software development. Advanced AI technologies have increased the popularity of large language models (LLMs) trained on large multimodal datasets. Therefore, utilizing LLM-based techniques can assist educators in helping students discover aspects of user stories that may have been overlooked or missed during the manual analysis of requirements from various stakeholders. The main goal of this research study is to investigate the potential application of OpenAI techniques in software development courses at two academic institutions to enhance software design and development processes, aiming to improve innovation and efficiency in team project-based educational settings. The data used for the study constitute student teams generating user stories by traditional methods (control) vs. student teams using OpenAI agents (treatment) such as gpt-4-turbo for generating user stories. The overarching research questions include: RQ-l) What aspects of user stories generated using OpenAI prompt engineering differ significantly from those generated using the traditional method? RQ-2) Can the prompt engineering data provide insights into the efficacy of the questions/prompts that affect the quality and comprehensiveness of user stories created by software development teams? Industry experts evaluated the user stories created and analyzed how prompt engineering affects the overall effectiveness and innovation of user story creation, which provided guidelines for incorporating AI-driven approaches into software development practices. Overall, this research seeks to contribute to the growing body of knowledge on the application of AI in software engineering education, specifically in user story generation. Investigating the use of AI technologies in user story generation could further enhance the usability of prompt engineering in agile software development environments. We plan to expand the study to investigate the long-term effects of prompt engineering on all phases of software development.",
      "keywords": []
    },
    "file_name": "915bee04aaf51eb675745aaf3dfe455d2d46f105.pdf"
  },
  {
    "success": true,
    "doc_id": "ebc6978d7a1765a6bedd684c9c1c7b27",
    "summary": "Software developer's approaches to coding, testing, and deployment are changing due to the incorporation of Artificial Intelligence (AI) into software development. AI-Augmented Software Development Tools simplify repetitive activities, boost productivity, and lessen the cognitive load on developers by utilizing machine learning, natural language processing (NLP), and other AI techniques. These tools support several development phases, including DevOps optimization, testing automation, problem discovery, and code generation. For example, AI-driven systems find flaws and inefficiencies in the code, while AI-powered code generation tools like GitHub Copilot help with code suggestion and completion. Additionally, AI automates debugging and test case creation, ensuring the scalability and dependability of software systems. Artificial intelligence (AI) improves quality assurance in complex contexts such as microservices and APIs by maximizing test coverage and identifying abnormalities. Additionally, AI-powered assistants help guide engineers through code inspections, security checks, and performance optimization. Notwithstanding these advantages, there are drawbacks to using AI tools, such as privacy issues and an excessive reliance on automation. With continued development, these tools have the potential to not only expedite development but also redirect the developer's attention towards more complex problem resolution, thereby transforming software engineering methodologies. [7]",
    "intriguing_abstract": "Software developer's approaches to coding, testing, and deployment are changing due to the incorporation of Artificial Intelligence (AI) into software development. AI-Augmented Software Development Tools simplify repetitive activities, boost productivity, and lessen the cognitive load on developers by utilizing machine learning, natural language processing (NLP), and other AI techniques. These tools support several development phases, including DevOps optimization, testing automation, problem discovery, and code generation. For example, AI-driven systems find flaws and inefficiencies in the code, while AI-powered code generation tools like GitHub Copilot help with code suggestion and completion. Additionally, AI automates debugging and test case creation, ensuring the scalability and dependability of software systems. Artificial intelligence (AI) improves quality assurance in complex contexts such as microservices and APIs by maximizing test coverage and identifying abnormalities. Additionally, AI-powered assistants help guide engineers through code inspections, security checks, and performance optimization. Notwithstanding these advantages, there are drawbacks to using AI tools, such as privacy issues and an excessive reliance on automation. With continued development, these tools have the potential to not only expedite development but also redirect the developer's attention towards more complex problem resolution, thereby transforming software engineering methodologies. [7]",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/076a2e5d3023be2f77f3ef6bdd6147d75a9c04db.pdf",
    "citation_key": "pangavhane20246tn",
    "metadata": {
      "title": "AI-Augmented Software Development: Boosting Efficiency and Quality",
      "authors": [
        "Shreyas Pangavhane",
        "Gokul Raktate",
        "Prasad Pariane",
        "Krishna Shelar",
        "Rohit Wakchaure",
        "J. Kale"
      ],
      "published_date": "2024",
      "abstract": "Software developer's approaches to coding, testing, and deployment are changing due to the incorporation of Artificial Intelligence (AI) into software development. AI-Augmented Software Development Tools simplify repetitive activities, boost productivity, and lessen the cognitive load on developers by utilizing machine learning, natural language processing (NLP), and other AI techniques. These tools support several development phases, including DevOps optimization, testing automation, problem discovery, and code generation. For example, AI-driven systems find flaws and inefficiencies in the code, while AI-powered code generation tools like GitHub Copilot help with code suggestion and completion. Additionally, AI automates debugging and test case creation, ensuring the scalability and dependability of software systems. Artificial intelligence (AI) improves quality assurance in complex contexts such as microservices and APIs by maximizing test coverage and identifying abnormalities. Additionally, AI-powered assistants help guide engineers through code inspections, security checks, and performance optimization. Notwithstanding these advantages, there are drawbacks to using AI tools, such as privacy issues and an excessive reliance on automation. With continued development, these tools have the potential to not only expedite development but also redirect the developer's attention towards more complex problem resolution, thereby transforming software engineering methodologies. [7]",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/076a2e5d3023be2f77f3ef6bdd6147d75a9c04db.pdf",
      "venue": "2024 International Conference on Decision Aid Sciences and Applications (DASA)",
      "citationCount": 3,
      "score": 3.0,
      "summary": "Software developer's approaches to coding, testing, and deployment are changing due to the incorporation of Artificial Intelligence (AI) into software development. AI-Augmented Software Development Tools simplify repetitive activities, boost productivity, and lessen the cognitive load on developers by utilizing machine learning, natural language processing (NLP), and other AI techniques. These tools support several development phases, including DevOps optimization, testing automation, problem discovery, and code generation. For example, AI-driven systems find flaws and inefficiencies in the code, while AI-powered code generation tools like GitHub Copilot help with code suggestion and completion. Additionally, AI automates debugging and test case creation, ensuring the scalability and dependability of software systems. Artificial intelligence (AI) improves quality assurance in complex contexts such as microservices and APIs by maximizing test coverage and identifying abnormalities. Additionally, AI-powered assistants help guide engineers through code inspections, security checks, and performance optimization. Notwithstanding these advantages, there are drawbacks to using AI tools, such as privacy issues and an excessive reliance on automation. With continued development, these tools have the potential to not only expedite development but also redirect the developer's attention towards more complex problem resolution, thereby transforming software engineering methodologies. [7]",
      "keywords": []
    },
    "file_name": "076a2e5d3023be2f77f3ef6bdd6147d75a9c04db.pdf"
  },
  {
    "success": true,
    "doc_id": "4ccffc1ed5f4b0fafd5f173edf087017",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8e5c7a96c4a149427af377677033cb17e798354a.pdf",
    "citation_key": "bannon20249ix",
    "metadata": {
      "title": "Generative AI in the Software Development Lifecycle",
      "authors": [
        "T. Bannon",
        "Phil Laplante"
      ],
      "published_date": "2024",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8e5c7a96c4a149427af377677033cb17e798354a.pdf",
      "venue": "Computer",
      "citationCount": 3,
      "score": 3.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "8e5c7a96c4a149427af377677033cb17e798354a.pdf"
  },
  {
    "success": true,
    "doc_id": "184f6697c3fec037c88ada064e0aaf13",
    "summary": "",
    "intriguing_abstract": "",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8ce62583163ec5d3c7e1072260b578e390a0f377.pdf",
    "citation_key": "shah2024b8w",
    "metadata": {
      "title": "STREAMLINING SOFTWARE DEVELOPMENT: A COMPARATIVE STUDY OF AI-DRIVEN AUTOMATION TOOLS IN MODERN TECH",
      "authors": [
        "Kevin N. Shah",
        "Abhishek Trehan"
      ],
      "published_date": "2024",
      "abstract": "",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8ce62583163ec5d3c7e1072260b578e390a0f377.pdf",
      "venue": "INTERNATIONAL JOURNAL OF COMPUTER ENGINEERING & TECHNOLOGY",
      "citationCount": 3,
      "score": 3.0,
      "summary": "",
      "keywords": []
    },
    "file_name": "8ce62583163ec5d3c7e1072260b578e390a0f377.pdf"
  },
  {
    "success": true,
    "doc_id": "2b9b732620c6a1fdcca1be9661eb7e32",
    "summary": "Internet technology has given rise to an open-collaborative software development paradigm, necessitating the open-collaborative schema to software testing. It enables diverse and globally distributed contributions, but also presents significant challenges to efficient testing processes, coordination among personnel, and management of testing artifacts. At the same time, advancements in AI have enhanced testing capabilities and enabling automation, while also introducing new testing needs and unique challenges for AI-based systems. In this context, this article explores software testing in the open-collaborative and AI-powered era, focusing on the interrelated dimensions of process, personnel, and technology. Among them, process involves managing testing workflows and artifacts to improve efficiency, personnel emphasizes the role of individuals in ensuring testing quality through collaboration and contributions, while technology refers to AI methods that enhance testing capabilities and address challenges in AI-based systems. Furthermore, we delve into the challenges and opportunities arising from emerging technologies such as Large Language Models (LLMs) and the AI model-centric development paradigm.",
    "intriguing_abstract": "Internet technology has given rise to an open-collaborative software development paradigm, necessitating the open-collaborative schema to software testing. It enables diverse and globally distributed contributions, but also presents significant challenges to efficient testing processes, coordination among personnel, and management of testing artifacts. At the same time, advancements in AI have enhanced testing capabilities and enabling automation, while also introducing new testing needs and unique challenges for AI-based systems. In this context, this article explores software testing in the open-collaborative and AI-powered era, focusing on the interrelated dimensions of process, personnel, and technology. Among them, process involves managing testing workflows and artifacts to improve efficiency, personnel emphasizes the role of individuals in ensuring testing quality through collaboration and contributions, while technology refers to AI methods that enhance testing capabilities and address challenges in AI-based systems. Furthermore, we delve into the challenges and opportunities arising from emerging technologies such as Large Language Models (LLMs) and the AI model-centric development paradigm.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/8c3c3273fd0e05a3e40853811b218b0da7f28706.pdf",
    "citation_key": "wang2024lgo",
    "metadata": {
      "title": "A Roadmap for Software Testing in Open-Collaborative and AI-Powered Era",
      "authors": [
        "Qing Wang",
        "Junjie Wang",
        "Mingyang Li",
        "Yawen Wang",
        "Zhe Liu"
      ],
      "published_date": "2024",
      "abstract": "Internet technology has given rise to an open-collaborative software development paradigm, necessitating the open-collaborative schema to software testing. It enables diverse and globally distributed contributions, but also presents significant challenges to efficient testing processes, coordination among personnel, and management of testing artifacts. At the same time, advancements in AI have enhanced testing capabilities and enabling automation, while also introducing new testing needs and unique challenges for AI-based systems. In this context, this article explores software testing in the open-collaborative and AI-powered era, focusing on the interrelated dimensions of process, personnel, and technology. Among them, process involves managing testing workflows and artifacts to improve efficiency, personnel emphasizes the role of individuals in ensuring testing quality through collaboration and contributions, while technology refers to AI methods that enhance testing capabilities and address challenges in AI-based systems. Furthermore, we delve into the challenges and opportunities arising from emerging technologies such as Large Language Models (LLMs) and the AI model-centric development paradigm.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/8c3c3273fd0e05a3e40853811b218b0da7f28706.pdf",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "citationCount": 3,
      "score": 3.0,
      "summary": "Internet technology has given rise to an open-collaborative software development paradigm, necessitating the open-collaborative schema to software testing. It enables diverse and globally distributed contributions, but also presents significant challenges to efficient testing processes, coordination among personnel, and management of testing artifacts. At the same time, advancements in AI have enhanced testing capabilities and enabling automation, while also introducing new testing needs and unique challenges for AI-based systems. In this context, this article explores software testing in the open-collaborative and AI-powered era, focusing on the interrelated dimensions of process, personnel, and technology. Among them, process involves managing testing workflows and artifacts to improve efficiency, personnel emphasizes the role of individuals in ensuring testing quality through collaboration and contributions, while technology refers to AI methods that enhance testing capabilities and address challenges in AI-based systems. Furthermore, we delve into the challenges and opportunities arising from emerging technologies such as Large Language Models (LLMs) and the AI model-centric development paradigm.",
      "keywords": []
    },
    "file_name": "8c3c3273fd0e05a3e40853811b218b0da7f28706.pdf"
  },
  {
    "success": true,
    "doc_id": "a1820f4228cc28185e49a6a91b772430",
    "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the evolving landscape of software testing, specifically the challenges and opportunities arising from the convergence of open-collaborative software development paradigms and the pervasive integration of Artificial Intelligence (AI) technologies \\cite{wang2024n8i}.\n    *   This problem is important and challenging because open collaboration introduces complexities like distributed contributions, diverse personnel, rapid iterations, and managing vast testing artifacts. Simultaneously, AI advancements offer powerful automation but also create new demands for testing AI-based systems themselves (e.g., validating functionality, robustness, and fairness of AI models) \\cite{wang2024n8i}. The core challenge is efficiently managing testing processes, coordinating diverse human contributions, and leveraging AI while also testing AI systems effectively in this dynamic environment.\n\n*   **Related Work & Positioning**\n    *   This work relates to previous roadmaps in software testing, notably \"Software Testing: A Research Travelogue (2000–2014)\" by Orso and Rothermel \\cite{wang2024n8i}.\n    *   The limitation of previous solutions is that the prior roadmap primarily focused on testing techniques and methodologies and is now a decade old, failing to capture the significant shifts brought by open collaboration and advanced AI \\cite{wang2024n8i}.\n    *   This paper positions itself as a *new, broader, and more holistic roadmap* that extends beyond just techniques to encompass process, personnel, and technology dimensions, specifically addressing the open-collaborative and AI-powered era \\cite{wang2024n8i}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is to provide a comprehensive roadmap and overview of software testing by structuring the discussion around three fundamental, interrelated dimensions: **process, personnel, and technology** \\cite{wang2024n8i}.\n        *   **Process**: Focuses on managing testing workflows, artifacts, and efficiency in dynamic, distributed settings, including techniques like test case prioritization (e.g., ML/RL-based approaches), crowdsourced testing management, and duplicate detection (e.g., information retrieval, deep learning for semantic similarity) \\cite{wang2024n8i}.\n        *   **Personnel**: Emphasizes the human element, covering areas such as multi-objective and dynamic tester recommendation for crowdtesting, advanced issue triaging (e.g., deep learning with transformer models), and human-computer collaborative testing (e.g., visual annotations, interactive event-flow graphs) \\cite{wang2024n8i}.\n        *   **Technology**: Explores how AI enhances testing capabilities (e.g., leveraging crowd intelligence for test script inference, GUI issue detection, fuzz testing DL libraries) and addresses the unique challenges of testing AI-driven systems, particularly with Large Language Models (LLMs) for tasks like test case generation and debugging \\cite{wang2024n8i}.\n    *   The approach is novel due to its *holistic, multi-dimensional perspective* that integrates the socio-technical aspects of open collaboration with the transformative impact of AI, including emerging trends like LLMs and AI model-centric development, which were not covered by previous roadmaps \\cite{wang2024n8i}. It synthesizes existing research within this new, comprehensive framework.\n\n*   **Key Technical Contributions**\n    *   **Conceptual Framework**: Proposing a novel three-dimensional framework (process, personnel, technology) for understanding and navigating software testing in the open-collaborative and AI-powered era \\cite{wang2024n8i}.\n    *   **Comprehensive Synthesis**: Providing a structured synthesis of current research and practices across these dimensions, highlighting specific technical approaches such as machine learning and reinforcement learning for test case prioritization, deep learning for issue triaging and duplicate detection, and AI-powered methods for leveraging crowd intelligence \\cite{wang2024n8i}.\n    *   **Identification of Emerging Trends**: Delving into the challenges and opportunities presented by cutting-edge technologies like Large Language Models (LLMs) and the AI model-centric development paradigm, outlining their current applications in testing (e.g., unit test case generation, program debugging, bug repair) and future research directions \\cite{wang2024n8i}.\n\n*   **Experimental Validation**\n    *   As a roadmap and survey paper, this work does not present new algorithms or systems that require traditional experimental validation.\n    *   Instead, its \"validation\" comes from its *comprehensive review and synthesis of existing literature*, drawing upon high-impact studies and survey papers from top-ranked venues in software engineering and AI \\cite{wang2024n8i}.\n    *   The paper's methodology for curating relevant works is described as informal, relying on the authors' expertise in software testing and AI to prioritize influential studies and emerging insights \\cite{wang2024n8i}. It references numerous studies that *do* contain empirical validation for the specific techniques discussed within the roadmap (e.g., machine learning-based TCP, deep learning for issue triaging, LLMs for test case generation) \\cite{wang2024n8i}.\n\n*   **Limitations & Scope**\n    *   **Methodological Limitation**: The paper acknowledges an informal methodology for curating relevant works, relying on authors' expertise rather than a systematic literature review protocol, which might introduce some bias or omissions \\cite{wang2024n8i}.\n    *   **Scope of Applicability**: The roadmap is specifically tailored to the \"open-collaborative and AI-powered era,\" meaning its insights are most relevant to development environments characterized by distributed contributions and significant AI integration \\cite{wang2024n8i}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: This paper significantly advances the technical state-of-the-art by providing the first comprehensive, multi-dimensional roadmap for software testing that explicitly addresses the intertwined challenges and opportunities of open-collaborative development and AI integration \\cite{wang2024n8i}. It moves beyond technique-centric views to a holistic understanding of modern software quality assurance.\n    *   **Potential Impact on Future Research**: It serves as a crucial guide for future research by synthesizing existing knowledge, identifying key challenges, and outlining promising avenues for innovation, particularly concerning the application and testing of LLMs and AI model-centric paradigms \\cite{wang2024n8i}. It helps researchers and practitioners understand the complex interplay of process, personnel, and technology in modern software quality assurance.",
    "intriguing_abstract": "The landscape of software testing is undergoing a profound transformation, driven by the convergence of open-collaborative development and pervasive Artificial Intelligence (AI). Traditional testing paradigms and existing roadmaps, now a decade old, fail to capture the intricate challenges of managing distributed contributions, diverse personnel, and the dual demand of leveraging AI *for* testing while simultaneously ensuring the robustness and fairness of AI-driven systems themselves.\n\nThis paper presents a novel, holistic roadmap for software testing, structured around three fundamental, interrelated dimensions: **Process, Personnel, and Technology**. We synthesize cutting-edge research, from machine learning-based test case prioritization and deep learning for advanced issue triaging to human-computer collaborative testing. Crucially, we delve into the transformative impact of Large Language Models (LLMs) on test case generation, debugging, and bug repair, and address the unique demands of AI model-centric development. This multi-dimensional framework offers an an unparalleled synthesis of current practices and future directions, serving as an essential guide for researchers and practitioners navigating the complexities of modern software quality assurance in the AI era.",
    "keywords": [
      "Software Testing Roadmap",
      "Open-Collaborative Software Development",
      "AI-Powered Systems",
      "Testing AI-Based Systems",
      "Process Personnel Technology Framework",
      "Large Language Models (LLMs)",
      "AI Model-Centric Development",
      "Machine Learning",
      "Deep Learning",
      "Test Case Generation",
      "Issue Triaging",
      "Crowdsourced Testing",
      "Human-Computer Collaborative Testing",
      "Holistic Multi-Dimensional Perspective",
      "Software Quality Assurance"
    ],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/ddf9c0171474737e81ef5a9bb9caac12d2ea0818.pdf",
    "citation_key": "wang2024n8i",
    "metadata": {
      "title": "A Roadmap for Software Testing in Open Collaborative Development Environments",
      "authors": [
        "Qing Wang",
        "Junjie Wang",
        "Mingyang Li",
        "Yawen Wang",
        "Zhe Liu"
      ],
      "published_date": "2024",
      "abstract": "Amidst the ever-expanding digital sphere, the evolution of the Internet has not only fostered an atmosphere of information transparency and sharing but has also sparked a revolution in software development practices. The distributed nature of open collaborative development, along with its diverse contributors and rapid iterations, presents new challenges for ensuring software quality. This paper offers a comprehensive review and analysis of recent advancements in software quality assurance within open collaborative development environments. Our examination covers various aspects, including process management, personnel dynamics, and technological advancements, providing valuable insights into effective approaches for maintaining software quality in such collaborative settings. Furthermore, we delve into the challenges and opportunities arising from emerging technologies such as LLMs and the AI model-centric development paradigm. By addressing these topics, our study contributes to a deeper understanding of software quality assurance in open collaborative environments and lays the groundwork for future exploration and innovation.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/ddf9c0171474737e81ef5a9bb9caac12d2ea0818.pdf",
      "venue": "arXiv.org",
      "citationCount": 3,
      "score": 3.0,
      "summary": "Here's a focused summary of the technical paper for a literature review:\n\n*   **Research Problem & Motivation**\n    *   The paper addresses the evolving landscape of software testing, specifically the challenges and opportunities arising from the convergence of open-collaborative software development paradigms and the pervasive integration of Artificial Intelligence (AI) technologies \\cite{wang2024n8i}.\n    *   This problem is important and challenging because open collaboration introduces complexities like distributed contributions, diverse personnel, rapid iterations, and managing vast testing artifacts. Simultaneously, AI advancements offer powerful automation but also create new demands for testing AI-based systems themselves (e.g., validating functionality, robustness, and fairness of AI models) \\cite{wang2024n8i}. The core challenge is efficiently managing testing processes, coordinating diverse human contributions, and leveraging AI while also testing AI systems effectively in this dynamic environment.\n\n*   **Related Work & Positioning**\n    *   This work relates to previous roadmaps in software testing, notably \"Software Testing: A Research Travelogue (2000–2014)\" by Orso and Rothermel \\cite{wang2024n8i}.\n    *   The limitation of previous solutions is that the prior roadmap primarily focused on testing techniques and methodologies and is now a decade old, failing to capture the significant shifts brought by open collaboration and advanced AI \\cite{wang2024n8i}.\n    *   This paper positions itself as a *new, broader, and more holistic roadmap* that extends beyond just techniques to encompass process, personnel, and technology dimensions, specifically addressing the open-collaborative and AI-powered era \\cite{wang2024n8i}.\n\n*   **Technical Approach & Innovation**\n    *   The core technical method is to provide a comprehensive roadmap and overview of software testing by structuring the discussion around three fundamental, interrelated dimensions: **process, personnel, and technology** \\cite{wang2024n8i}.\n        *   **Process**: Focuses on managing testing workflows, artifacts, and efficiency in dynamic, distributed settings, including techniques like test case prioritization (e.g., ML/RL-based approaches), crowdsourced testing management, and duplicate detection (e.g., information retrieval, deep learning for semantic similarity) \\cite{wang2024n8i}.\n        *   **Personnel**: Emphasizes the human element, covering areas such as multi-objective and dynamic tester recommendation for crowdtesting, advanced issue triaging (e.g., deep learning with transformer models), and human-computer collaborative testing (e.g., visual annotations, interactive event-flow graphs) \\cite{wang2024n8i}.\n        *   **Technology**: Explores how AI enhances testing capabilities (e.g., leveraging crowd intelligence for test script inference, GUI issue detection, fuzz testing DL libraries) and addresses the unique challenges of testing AI-driven systems, particularly with Large Language Models (LLMs) for tasks like test case generation and debugging \\cite{wang2024n8i}.\n    *   The approach is novel due to its *holistic, multi-dimensional perspective* that integrates the socio-technical aspects of open collaboration with the transformative impact of AI, including emerging trends like LLMs and AI model-centric development, which were not covered by previous roadmaps \\cite{wang2024n8i}. It synthesizes existing research within this new, comprehensive framework.\n\n*   **Key Technical Contributions**\n    *   **Conceptual Framework**: Proposing a novel three-dimensional framework (process, personnel, technology) for understanding and navigating software testing in the open-collaborative and AI-powered era \\cite{wang2024n8i}.\n    *   **Comprehensive Synthesis**: Providing a structured synthesis of current research and practices across these dimensions, highlighting specific technical approaches such as machine learning and reinforcement learning for test case prioritization, deep learning for issue triaging and duplicate detection, and AI-powered methods for leveraging crowd intelligence \\cite{wang2024n8i}.\n    *   **Identification of Emerging Trends**: Delving into the challenges and opportunities presented by cutting-edge technologies like Large Language Models (LLMs) and the AI model-centric development paradigm, outlining their current applications in testing (e.g., unit test case generation, program debugging, bug repair) and future research directions \\cite{wang2024n8i}.\n\n*   **Experimental Validation**\n    *   As a roadmap and survey paper, this work does not present new algorithms or systems that require traditional experimental validation.\n    *   Instead, its \"validation\" comes from its *comprehensive review and synthesis of existing literature*, drawing upon high-impact studies and survey papers from top-ranked venues in software engineering and AI \\cite{wang2024n8i}.\n    *   The paper's methodology for curating relevant works is described as informal, relying on the authors' expertise in software testing and AI to prioritize influential studies and emerging insights \\cite{wang2024n8i}. It references numerous studies that *do* contain empirical validation for the specific techniques discussed within the roadmap (e.g., machine learning-based TCP, deep learning for issue triaging, LLMs for test case generation) \\cite{wang2024n8i}.\n\n*   **Limitations & Scope**\n    *   **Methodological Limitation**: The paper acknowledges an informal methodology for curating relevant works, relying on authors' expertise rather than a systematic literature review protocol, which might introduce some bias or omissions \\cite{wang2024n8i}.\n    *   **Scope of Applicability**: The roadmap is specifically tailored to the \"open-collaborative and AI-powered era,\" meaning its insights are most relevant to development environments characterized by distributed contributions and significant AI integration \\cite{wang2024n8i}.\n\n*   **Technical Significance**\n    *   **Advances State-of-the-Art**: This paper significantly advances the technical state-of-the-art by providing the first comprehensive, multi-dimensional roadmap for software testing that explicitly addresses the intertwined challenges and opportunities of open-collaborative development and AI integration \\cite{wang2024n8i}. It moves beyond technique-centric views to a holistic understanding of modern software quality assurance.\n    *   **Potential Impact on Future Research**: It serves as a crucial guide for future research by synthesizing existing knowledge, identifying key challenges, and outlining promising avenues for innovation, particularly concerning the application and testing of LLMs and AI model-centric paradigms \\cite{wang2024n8i}. It helps researchers and practitioners understand the complex interplay of process, personnel, and technology in modern software quality assurance.",
      "keywords": [
        "Software Testing Roadmap",
        "Open-Collaborative Software Development",
        "AI-Powered Systems",
        "Testing AI-Based Systems",
        "Process Personnel Technology Framework",
        "Large Language Models (LLMs)",
        "AI Model-Centric Development",
        "Machine Learning",
        "Deep Learning",
        "Test Case Generation",
        "Issue Triaging",
        "Crowdsourced Testing",
        "Human-Computer Collaborative Testing",
        "Holistic Multi-Dimensional Perspective",
        "Software Quality Assurance"
      ],
      "paper_type": "based on the abstract and introduction:\n\n1.  **\"a roadmap for software testing...\"**: the title itself suggests a comprehensive overview and future direction, which is characteristic of a survey.\n2.  **\"pressing need for a new roadmap to summarize and project future research\"**: this explicitly states the paper's goal to summarize existing work and project future directions, a core function of a survey.\n3.  **\"comprehensive overview and roadmap for software testing... requires a holistic understanding\"**: \"comprehensive overview\" is a direct keyword for a survey.\n4.  **\"our exploration... is guided by the recognition that three key dimensions—process, personnel, and technology—form a triad of fundamental factors influencing software testing practices.\"**: this indicates a structured analysis and organization of existing knowledge.\n5.  **\"additionally, we also outline future trends.\"**: surveys often include discussions of future research directions.\n6.  **\"to curate the relevant works, we adopt an informal methodology... the selection prioritized survey papers and high-impact studies...\"**: this describes a literature review process, which is fundamental to a survey.\n7.  **\"section 2 to 4 provide an overview of software testing researches from the perspectives of process, personnel, and technology, respectively.\"**: this explicitly states the paper's structure is to provide an overview of research, reinforcing the survey nature.\n8.  the subsequent content (e.g., \"elbaum et al. [16] prioritized tests...\", \"wang et. al. [58] explored automated decision support...\", \"nguyen et. al. [41] applied information retrieval techniques...\") clearly reviews and cites existing research and techniques, rather than presenting new ones.\n\nthe paper aims to synthesize existing knowledge, categorize it, and identify future directions within a specific domain, which perfectly aligns with the definition of a **survey** paper.\n\n**classification: survey**"
    },
    "file_name": "ddf9c0171474737e81ef5a9bb9caac12d2ea0818.pdf"
  },
  {
    "success": true,
    "doc_id": "9a1d69a88c7f12790a5ff29c2a0397e8",
    "summary": "The integration of Large Language Models (LLMs) such as GitHub Copilot, ChatGPT, Cursor AI, and Codeium AI into software development has revolutionized the coding landscape, offering significant productivity gains, automation, and enhanced debugging capabilities. These tools have proven invaluable for generating code snippets, refactoring existing code, and providing real-time support to developers. However, their widespread adoption also presents notable challenges, particularly in terms of security vulnerabilities, code quality, and ethical concerns. This paper provides a comprehensive analysis of the benefits and risks associated with AI-powered coding tools, drawing on user feedback, security analyses, and practical use cases. We explore the potential for these tools to replicate insecure coding practices, introduce biases, and generate incorrect or non-sensical code (hallucinations). In addition, we discuss the risks of data leaks, intellectual property violations and the need for robust security measures to mitigate these threats. By comparing the features and performance of these tools, we aim to guide developers in making informed decisions about their use, ensuring that the benefits of AI-assisted coding are maximized while minimizing associated risks.",
    "intriguing_abstract": "The integration of Large Language Models (LLMs) such as GitHub Copilot, ChatGPT, Cursor AI, and Codeium AI into software development has revolutionized the coding landscape, offering significant productivity gains, automation, and enhanced debugging capabilities. These tools have proven invaluable for generating code snippets, refactoring existing code, and providing real-time support to developers. However, their widespread adoption also presents notable challenges, particularly in terms of security vulnerabilities, code quality, and ethical concerns. This paper provides a comprehensive analysis of the benefits and risks associated with AI-powered coding tools, drawing on user feedback, security analyses, and practical use cases. We explore the potential for these tools to replicate insecure coding practices, introduce biases, and generate incorrect or non-sensical code (hallucinations). In addition, we discuss the risks of data leaks, intellectual property violations and the need for robust security measures to mitigate these threats. By comparing the features and performance of these tools, we aim to guide developers in making informed decisions about their use, ensuring that the benefits of AI-assisted coding are maximized while minimizing associated risks.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/b8f658e6b187556303fbe8611237eafbfd4c2d6e.pdf",
    "citation_key": "haque2025vb3",
    "metadata": {
      "title": "SOK: Exploring Hallucinations and Security Risks in AI-Assisted Software Development with Insights for LLM Deployment",
      "authors": [
        "Mohd Ariful Haque",
        "Sunzida Siddique",
        "Md. Mahfuzur Rahman",
        "Ahmed Rafi Hasan",
        "Laxmi Rani Das",
        "Marufa Kamal",
        "Tasnim Masura",
        "K. Gupta"
      ],
      "published_date": "2025",
      "abstract": "The integration of Large Language Models (LLMs) such as GitHub Copilot, ChatGPT, Cursor AI, and Codeium AI into software development has revolutionized the coding landscape, offering significant productivity gains, automation, and enhanced debugging capabilities. These tools have proven invaluable for generating code snippets, refactoring existing code, and providing real-time support to developers. However, their widespread adoption also presents notable challenges, particularly in terms of security vulnerabilities, code quality, and ethical concerns. This paper provides a comprehensive analysis of the benefits and risks associated with AI-powered coding tools, drawing on user feedback, security analyses, and practical use cases. We explore the potential for these tools to replicate insecure coding practices, introduce biases, and generate incorrect or non-sensical code (hallucinations). In addition, we discuss the risks of data leaks, intellectual property violations and the need for robust security measures to mitigate these threats. By comparing the features and performance of these tools, we aim to guide developers in making informed decisions about their use, ensuring that the benefits of AI-assisted coding are maximized while minimizing associated risks.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/b8f658e6b187556303fbe8611237eafbfd4c2d6e.pdf",
      "venue": "arXiv.org",
      "citationCount": 3,
      "score": 3.0,
      "summary": "The integration of Large Language Models (LLMs) such as GitHub Copilot, ChatGPT, Cursor AI, and Codeium AI into software development has revolutionized the coding landscape, offering significant productivity gains, automation, and enhanced debugging capabilities. These tools have proven invaluable for generating code snippets, refactoring existing code, and providing real-time support to developers. However, their widespread adoption also presents notable challenges, particularly in terms of security vulnerabilities, code quality, and ethical concerns. This paper provides a comprehensive analysis of the benefits and risks associated with AI-powered coding tools, drawing on user feedback, security analyses, and practical use cases. We explore the potential for these tools to replicate insecure coding practices, introduce biases, and generate incorrect or non-sensical code (hallucinations). In addition, we discuss the risks of data leaks, intellectual property violations and the need for robust security measures to mitigate these threats. By comparing the features and performance of these tools, we aim to guide developers in making informed decisions about their use, ensuring that the benefits of AI-assisted coding are maximized while minimizing associated risks.",
      "keywords": []
    },
    "file_name": "b8f658e6b187556303fbe8611237eafbfd4c2d6e.pdf"
  },
  {
    "success": true,
    "doc_id": "b5b96669c5c36299372bd23250711a6a",
    "summary": "The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.",
    "intriguing_abstract": "The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/431d98af5601be36e28945548e05ab87d807b95a.pdf",
    "citation_key": "borghoff20250fl",
    "metadata": {
      "title": "Generative AI in Student Software Development Projects: A User Study on Experiences and Self-Assessment",
      "authors": [
        "Uwe M. Borghoff",
        "Mark Minas",
        "Jannis Schopp"
      ],
      "published_date": "2025",
      "abstract": "The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/431d98af5601be36e28945548e05ab87d807b95a.pdf",
      "venue": "European Conference of Software Engineering Education",
      "citationCount": 3,
      "score": 3.0,
      "summary": "The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.",
      "keywords": []
    },
    "file_name": "431d98af5601be36e28945548e05ab87d807b95a.pdf"
  },
  {
    "success": true,
    "doc_id": "b3fed25d05f1d064f88e0645c3d94100",
    "summary": "Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.",
    "intriguing_abstract": "Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f61990dfecc068ab4f41fa154865766456abf89b.pdf",
    "citation_key": "santos2024bhb",
    "metadata": {
      "title": "Impacts of the Usage of Generative Artificial Intelligence on Software Development Process",
      "authors": [
        "Patricia de Oliveira Santos",
        "Allan Chamon Figueiredo",
        "Pedro Nuno Moura",
        "Bruna Diirr",
        "Adriana C. F. Alvim",
        "Rodrigo Pereira dos Santos"
      ],
      "published_date": "2024",
      "abstract": "Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f61990dfecc068ab4f41fa154865766456abf89b.pdf",
      "venue": "Brazilian Symposium on Information Systems",
      "citationCount": 3,
      "score": 3.0,
      "summary": "Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.",
      "keywords": []
    },
    "file_name": "f61990dfecc068ab4f41fa154865766456abf89b.pdf"
  },
  {
    "success": true,
    "doc_id": "5fcfaf0c52fc86356231db33abfb26d0",
    "summary": "Large Language Models (LLMs) are revolutionizing the way a developer creates software by replacing code with natural language prompts as primary drivers. While many initial assessments of such LLMs suggest that it helps with developer productivity, other research studies have also pointed out areas in the Software Development Life Cycle(SDLC) and developer experience where such tools fail miserably. Currently, there exist many studies dedicated to evaluation of LLM-based AI-assisted software tools but there lacks a standardization of studies and metrics which may prove to be a hindrance to adoption of metrics and reproducible studies. The primary objective of this survey is to assess the recent user studies and surveys, aimed at evaluating different aspects of developer’s experience of using code-based LLMs, and highlight any existing gaps among them. We have leveraged the SPACE framework to enumerate and categorise metrics from studies conducting some form of controlled user experiments. In Generative AI assisted SDLC, the developer’s experience should encompass the ability to perform the in-hand task efficiently and effectively, with minimal friction using these LLM tools. Our exploration has led to some critical insights regarding complete absence of user studies in Collaborative aspects of teams, bias towards certain LLM models & metrics and lack of diversity in metrics within productivity dimensions. We also propose some recommendations to the research community which will help bring some conformity in the evaluation of such LLMs.",
    "intriguing_abstract": "Large Language Models (LLMs) are revolutionizing the way a developer creates software by replacing code with natural language prompts as primary drivers. While many initial assessments of such LLMs suggest that it helps with developer productivity, other research studies have also pointed out areas in the Software Development Life Cycle(SDLC) and developer experience where such tools fail miserably. Currently, there exist many studies dedicated to evaluation of LLM-based AI-assisted software tools but there lacks a standardization of studies and metrics which may prove to be a hindrance to adoption of metrics and reproducible studies. The primary objective of this survey is to assess the recent user studies and surveys, aimed at evaluating different aspects of developer’s experience of using code-based LLMs, and highlight any existing gaps among them. We have leveraged the SPACE framework to enumerate and categorise metrics from studies conducting some form of controlled user experiments. In Generative AI assisted SDLC, the developer’s experience should encompass the ability to perform the in-hand task efficiently and effectively, with minimal friction using these LLM tools. Our exploration has led to some critical insights regarding complete absence of user studies in Collaborative aspects of teams, bias towards certain LLM models & metrics and lack of diversity in metrics within productivity dimensions. We also propose some recommendations to the research community which will help bring some conformity in the evaluation of such LLMs.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/259bf96be0f2a9d9a1acbce991c92640d23a8ac3.pdf",
    "citation_key": "sikand20240z5",
    "metadata": {
      "title": "How much SPACE do metrics have in GenAI assisted software development?",
      "authors": [
        "Samarth Sikand",
        "Kanchanjot Kaur Phokela",
        "V. Sharma",
        "Kapil Singi",
        "Vikrant S. Kaulgud",
        "Teresa Tung",
        "Pragya Sharma",
        "Adam P. Burden"
      ],
      "published_date": "2024",
      "abstract": "Large Language Models (LLMs) are revolutionizing the way a developer creates software by replacing code with natural language prompts as primary drivers. While many initial assessments of such LLMs suggest that it helps with developer productivity, other research studies have also pointed out areas in the Software Development Life Cycle(SDLC) and developer experience where such tools fail miserably. Currently, there exist many studies dedicated to evaluation of LLM-based AI-assisted software tools but there lacks a standardization of studies and metrics which may prove to be a hindrance to adoption of metrics and reproducible studies. The primary objective of this survey is to assess the recent user studies and surveys, aimed at evaluating different aspects of developer’s experience of using code-based LLMs, and highlight any existing gaps among them. We have leveraged the SPACE framework to enumerate and categorise metrics from studies conducting some form of controlled user experiments. In Generative AI assisted SDLC, the developer’s experience should encompass the ability to perform the in-hand task efficiently and effectively, with minimal friction using these LLM tools. Our exploration has led to some critical insights regarding complete absence of user studies in Collaborative aspects of teams, bias towards certain LLM models & metrics and lack of diversity in metrics within productivity dimensions. We also propose some recommendations to the research community which will help bring some conformity in the evaluation of such LLMs.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/259bf96be0f2a9d9a1acbce991c92640d23a8ac3.pdf",
      "venue": "International Symposium on Electronic Commerce",
      "citationCount": 3,
      "score": 3.0,
      "summary": "Large Language Models (LLMs) are revolutionizing the way a developer creates software by replacing code with natural language prompts as primary drivers. While many initial assessments of such LLMs suggest that it helps with developer productivity, other research studies have also pointed out areas in the Software Development Life Cycle(SDLC) and developer experience where such tools fail miserably. Currently, there exist many studies dedicated to evaluation of LLM-based AI-assisted software tools but there lacks a standardization of studies and metrics which may prove to be a hindrance to adoption of metrics and reproducible studies. The primary objective of this survey is to assess the recent user studies and surveys, aimed at evaluating different aspects of developer’s experience of using code-based LLMs, and highlight any existing gaps among them. We have leveraged the SPACE framework to enumerate and categorise metrics from studies conducting some form of controlled user experiments. In Generative AI assisted SDLC, the developer’s experience should encompass the ability to perform the in-hand task efficiently and effectively, with minimal friction using these LLM tools. Our exploration has led to some critical insights regarding complete absence of user studies in Collaborative aspects of teams, bias towards certain LLM models & metrics and lack of diversity in metrics within productivity dimensions. We also propose some recommendations to the research community which will help bring some conformity in the evaluation of such LLMs.",
      "keywords": []
    },
    "file_name": "259bf96be0f2a9d9a1acbce991c92640d23a8ac3.pdf"
  },
  {
    "success": true,
    "doc_id": "fd0fa5c6141d6cd2041c66e21d80660f",
    "summary": "Engineering AI Software systems is starting to evolve from the pure development of machine learning (ML) models to a more structured discipline that treats ML components as part of much larger software systems. As such, more structured principles are required for their development, such as established design principles, established development models, and safeguards for deployed ML models. This column focuses on papers presented at the Third International Conference on AI Engineering—Software Engineering for AI (CAIN 2024). The selected papers reflect the current development of the field of AI systems engineering and AI software development, taking it to the next level of maturity. Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in the column, please send us and the authors of the paper(s) a note about your experiences.",
    "intriguing_abstract": "Engineering AI Software systems is starting to evolve from the pure development of machine learning (ML) models to a more structured discipline that treats ML components as part of much larger software systems. As such, more structured principles are required for their development, such as established design principles, established development models, and safeguards for deployed ML models. This column focuses on papers presented at the Third International Conference on AI Engineering—Software Engineering for AI (CAIN 2024). The selected papers reflect the current development of the field of AI systems engineering and AI software development, taking it to the next level of maturity. Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in the column, please send us and the authors of the paper(s) a note about your experiences.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/709c1176513fca7469f3eb4833db1ea313826cec.pdf",
    "citation_key": "staron2024r3p",
    "metadata": {
      "title": "Bringing Software Engineering Discipline to the Development of AI-Enabled Systems",
      "authors": [
        "Miroslaw Staron",
        "S. Abrahão",
        "Grace Lewis",
        "Henry Muccini",
        "Chetan Honnenahalli",
        "Miroslaw Staron",
        "S. Abrahão"
      ],
      "published_date": "2024",
      "abstract": "Engineering AI Software systems is starting to evolve from the pure development of machine learning (ML) models to a more structured discipline that treats ML components as part of much larger software systems. As such, more structured principles are required for their development, such as established design principles, established development models, and safeguards for deployed ML models. This column focuses on papers presented at the Third International Conference on AI Engineering—Software Engineering for AI (CAIN 2024). The selected papers reflect the current development of the field of AI systems engineering and AI software development, taking it to the next level of maturity. Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in the column, please send us and the authors of the paper(s) a note about your experiences.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/709c1176513fca7469f3eb4833db1ea313826cec.pdf",
      "venue": "IEEE Software",
      "citationCount": 3,
      "score": 3.0,
      "summary": "Engineering AI Software systems is starting to evolve from the pure development of machine learning (ML) models to a more structured discipline that treats ML components as part of much larger software systems. As such, more structured principles are required for their development, such as established design principles, established development models, and safeguards for deployed ML models. This column focuses on papers presented at the Third International Conference on AI Engineering—Software Engineering for AI (CAIN 2024). The selected papers reflect the current development of the field of AI systems engineering and AI software development, taking it to the next level of maturity. Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in the column, please send us and the authors of the paper(s) a note about your experiences.",
      "keywords": []
    },
    "file_name": "709c1176513fca7469f3eb4833db1ea313826cec.pdf"
  },
  {
    "success": true,
    "doc_id": "7349a38bfced38d49372cd15457e5a1b",
    "summary": "The use of video laryngoscopes has enhanced the visualization of the vocal cords, thereby improving the accessibility of tracheal intubation. Employing artificial intelligence (AI) to recognize images obtained through video laryngoscopy, particularly when marking the epiglottis and vocal cords, may elucidate anatomical structures and enhance anatomical comprehension of anatomy. This study investigates the ability of an AI model to accurately identify the glottis in video laryngoscope images captured from a manikin. Tracheal intubation was conducted on a manikin using a bronchoscope with recording capabilities, and image data of the glottis was gathered for creating an AI model. Data preprocessing and annotation of the vocal cords, epiglottis, and glottis were performed, and human annotation of the vocal cords, epiglottis, and glottis was carried out. Based on the AI's determinations, anatomical structures were color-coded for identification. The recognition accuracy of the epiglottis and vocal cords recognized by the AI model was 0.9516, which was over 95%. The AI successfully marked the glottis, epiglottis, and vocal cords during the tracheal intubation process. These markings significantly aided in the visual identification of the respective structures with an accuracy of more than 95%. The AI demonstrated the ability to recognize the epiglottis, vocal cords, and glottis using an image recognition model of a manikin.",
    "intriguing_abstract": "The use of video laryngoscopes has enhanced the visualization of the vocal cords, thereby improving the accessibility of tracheal intubation. Employing artificial intelligence (AI) to recognize images obtained through video laryngoscopy, particularly when marking the epiglottis and vocal cords, may elucidate anatomical structures and enhance anatomical comprehension of anatomy. This study investigates the ability of an AI model to accurately identify the glottis in video laryngoscope images captured from a manikin. Tracheal intubation was conducted on a manikin using a bronchoscope with recording capabilities, and image data of the glottis was gathered for creating an AI model. Data preprocessing and annotation of the vocal cords, epiglottis, and glottis were performed, and human annotation of the vocal cords, epiglottis, and glottis was carried out. Based on the AI's determinations, anatomical structures were color-coded for identification. The recognition accuracy of the epiglottis and vocal cords recognized by the AI model was 0.9516, which was over 95%. The AI successfully marked the glottis, epiglottis, and vocal cords during the tracheal intubation process. These markings significantly aided in the visual identification of the respective structures with an accuracy of more than 95%. The AI demonstrated the ability to recognize the epiglottis, vocal cords, and glottis using an image recognition model of a manikin.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/350c6c03e9692f1c9115f5efcc4d98f3d64e8ca8.pdf",
    "citation_key": "masumori2024z3p",
    "metadata": {
      "title": "Glottis Recognition Software Development Using Artificial Intelligence",
      "authors": [
        "Yasushi Masumori",
        "Soichiro Inoue",
        "Yusuke Seino",
        "Mamoru Konishi",
        "Hiroyuki Nishikawa"
      ],
      "published_date": "2024",
      "abstract": "The use of video laryngoscopes has enhanced the visualization of the vocal cords, thereby improving the accessibility of tracheal intubation. Employing artificial intelligence (AI) to recognize images obtained through video laryngoscopy, particularly when marking the epiglottis and vocal cords, may elucidate anatomical structures and enhance anatomical comprehension of anatomy. This study investigates the ability of an AI model to accurately identify the glottis in video laryngoscope images captured from a manikin. Tracheal intubation was conducted on a manikin using a bronchoscope with recording capabilities, and image data of the glottis was gathered for creating an AI model. Data preprocessing and annotation of the vocal cords, epiglottis, and glottis were performed, and human annotation of the vocal cords, epiglottis, and glottis was carried out. Based on the AI's determinations, anatomical structures were color-coded for identification. The recognition accuracy of the epiglottis and vocal cords recognized by the AI model was 0.9516, which was over 95%. The AI successfully marked the glottis, epiglottis, and vocal cords during the tracheal intubation process. These markings significantly aided in the visual identification of the respective structures with an accuracy of more than 95%. The AI demonstrated the ability to recognize the epiglottis, vocal cords, and glottis using an image recognition model of a manikin.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/350c6c03e9692f1c9115f5efcc4d98f3d64e8ca8.pdf",
      "venue": "Cureus",
      "citationCount": 3,
      "score": 3.0,
      "summary": "The use of video laryngoscopes has enhanced the visualization of the vocal cords, thereby improving the accessibility of tracheal intubation. Employing artificial intelligence (AI) to recognize images obtained through video laryngoscopy, particularly when marking the epiglottis and vocal cords, may elucidate anatomical structures and enhance anatomical comprehension of anatomy. This study investigates the ability of an AI model to accurately identify the glottis in video laryngoscope images captured from a manikin. Tracheal intubation was conducted on a manikin using a bronchoscope with recording capabilities, and image data of the glottis was gathered for creating an AI model. Data preprocessing and annotation of the vocal cords, epiglottis, and glottis were performed, and human annotation of the vocal cords, epiglottis, and glottis was carried out. Based on the AI's determinations, anatomical structures were color-coded for identification. The recognition accuracy of the epiglottis and vocal cords recognized by the AI model was 0.9516, which was over 95%. The AI successfully marked the glottis, epiglottis, and vocal cords during the tracheal intubation process. These markings significantly aided in the visual identification of the respective structures with an accuracy of more than 95%. The AI demonstrated the ability to recognize the epiglottis, vocal cords, and glottis using an image recognition model of a manikin.",
      "keywords": []
    },
    "file_name": "350c6c03e9692f1c9115f5efcc4d98f3d64e8ca8.pdf"
  },
  {
    "success": true,
    "doc_id": "c22986025d35f4dc55b2597b84c39a68",
    "summary": "This research presents an innovative methodological framework for software development that integrates Artificial Intelligence (AI) techniques, Software Product Lines (SPL), and Lehman’s [24] aging factors. The main objective is to improve the efficiency and adaptability of design processes for residential spaces through intelligent automation. This framework covers the entire software development life cycle, utilizing AI algorithms to optimize design and respond to the evolving needs of users while maximizing resource usage. A case study on a connected home concretely illustrates the application of this framework, demonstrating its effectiveness in creating dynamic and personalized designs. Furthermore, it addresses the issue of software sustainability by incorporating aging laws throughout their life cycle, an aspect often overlooked in existing solutions. By combining product line engineering and AI techniques, this framework offers a structured approach that promotes both sustainability and personalization. It has the potential to transform practices across various sectors, such as healthcare, finance, and education, while fostering a culture of sustainable innovation. However, its effectiveness also depends on the skills and experience of development teams, highlighting the importance of considering human factors in its application",
    "intriguing_abstract": "This research presents an innovative methodological framework for software development that integrates Artificial Intelligence (AI) techniques, Software Product Lines (SPL), and Lehman’s [24] aging factors. The main objective is to improve the efficiency and adaptability of design processes for residential spaces through intelligent automation. This framework covers the entire software development life cycle, utilizing AI algorithms to optimize design and respond to the evolving needs of users while maximizing resource usage. A case study on a connected home concretely illustrates the application of this framework, demonstrating its effectiveness in creating dynamic and personalized designs. Furthermore, it addresses the issue of software sustainability by incorporating aging laws throughout their life cycle, an aspect often overlooked in existing solutions. By combining product line engineering and AI techniques, this framework offers a structured approach that promotes both sustainability and personalization. It has the potential to transform practices across various sectors, such as healthcare, finance, and education, while fostering a culture of sustainable innovation. However, its effectiveness also depends on the skills and experience of development teams, highlighting the importance of considering human factors in its application",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/d52f7b143751f11a1b94f7be8e278ba6aa0c855e.pdf",
    "citation_key": "soureya2025iq3",
    "metadata": {
      "title": "Adaptive software development: a comprehensive framework integrating artificial intelligence for sustainable evolution",
      "authors": [
        "Yaya Gadjama Soureya",
        "Amougou Ngoumou",
        "J. M. Ngossaha",
        "Samuel Bowong Tsakou",
        "M. F. Ndjodo"
      ],
      "published_date": "2025",
      "abstract": "This research presents an innovative methodological framework for software development that integrates Artificial Intelligence (AI) techniques, Software Product Lines (SPL), and Lehman’s [24] aging factors. The main objective is to improve the efficiency and adaptability of design processes for residential spaces through intelligent automation. This framework covers the entire software development life cycle, utilizing AI algorithms to optimize design and respond to the evolving needs of users while maximizing resource usage. A case study on a connected home concretely illustrates the application of this framework, demonstrating its effectiveness in creating dynamic and personalized designs. Furthermore, it addresses the issue of software sustainability by incorporating aging laws throughout their life cycle, an aspect often overlooked in existing solutions. By combining product line engineering and AI techniques, this framework offers a structured approach that promotes both sustainability and personalization. It has the potential to transform practices across various sectors, such as healthcare, finance, and education, while fostering a culture of sustainable innovation. However, its effectiveness also depends on the skills and experience of development teams, highlighting the importance of considering human factors in its application",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/d52f7b143751f11a1b94f7be8e278ba6aa0c855e.pdf",
      "venue": "˜The œinternational Arab journal of information technology",
      "citationCount": 3,
      "score": 3.0,
      "summary": "This research presents an innovative methodological framework for software development that integrates Artificial Intelligence (AI) techniques, Software Product Lines (SPL), and Lehman’s [24] aging factors. The main objective is to improve the efficiency and adaptability of design processes for residential spaces through intelligent automation. This framework covers the entire software development life cycle, utilizing AI algorithms to optimize design and respond to the evolving needs of users while maximizing resource usage. A case study on a connected home concretely illustrates the application of this framework, demonstrating its effectiveness in creating dynamic and personalized designs. Furthermore, it addresses the issue of software sustainability by incorporating aging laws throughout their life cycle, an aspect often overlooked in existing solutions. By combining product line engineering and AI techniques, this framework offers a structured approach that promotes both sustainability and personalization. It has the potential to transform practices across various sectors, such as healthcare, finance, and education, while fostering a culture of sustainable innovation. However, its effectiveness also depends on the skills and experience of development teams, highlighting the importance of considering human factors in its application",
      "keywords": []
    },
    "file_name": "d52f7b143751f11a1b94f7be8e278ba6aa0c855e.pdf"
  },
  {
    "success": true,
    "doc_id": "10c25c473dbeb730d02dba09e07aa583",
    "summary": "Recent progress in Generative AI (GenAI) impacts different software engineering (ES) tasks in software development cycle, e.g., from code generation to program repair, and presents a promising avenue for enhancing the productivity of development teams. GenAI based tools have the potential to change the way we develop software and have received attention from industry and academia. However, although some studies have been addressing the adoption of these tools in the software industry, little is known about what are developers' real experiences in a professional software development context, aside the hype. In this paper, we explore the use of GenAI tools by a large Brazilian media company that has teams developing software inhouse. We observed practitioners for six weeks and used online surveys at different time points to understand their expectations, perceptions, and concerns about these tools in their daily work. In addition, we automatically collected quantitative data from the company's development systems, aiming at getting insights about how GenAI impacts the development process during the period. Our results provide insights into how practitioners perceive and utilize GenAI in their daily work in software development.",
    "intriguing_abstract": "Recent progress in Generative AI (GenAI) impacts different software engineering (ES) tasks in software development cycle, e.g., from code generation to program repair, and presents a promising avenue for enhancing the productivity of development teams. GenAI based tools have the potential to change the way we develop software and have received attention from industry and academia. However, although some studies have been addressing the adoption of these tools in the software industry, little is known about what are developers' real experiences in a professional software development context, aside the hype. In this paper, we explore the use of GenAI tools by a large Brazilian media company that has teams developing software inhouse. We observed practitioners for six weeks and used online surveys at different time points to understand their expectations, perceptions, and concerns about these tools in their daily work. In addition, we automatically collected quantitative data from the company's development systems, aiming at getting insights about how GenAI impacts the development process during the period. Our results provide insights into how practitioners perceive and utilize GenAI in their daily work in software development.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/53a833736bc658d0da00b1cdfc5ed85e3c01674a.pdf",
    "citation_key": "pereira2025301",
    "metadata": {
      "title": "Exploring GenAI in Software Development: Insights from a Case Study in a Large Brazilian Company",
      "authors": [
        "Guilherme Vaz Pereira",
        "Victoria Jackson",
        "R. Prikladnicki",
        "André van der Hoek",
        "Luciane Fortes",
        "Carolina Araújo",
        "André Coelho",
        "Ligia Chelli",
        "Diego Ramos"
      ],
      "published_date": "2025",
      "abstract": "Recent progress in Generative AI (GenAI) impacts different software engineering (ES) tasks in software development cycle, e.g., from code generation to program repair, and presents a promising avenue for enhancing the productivity of development teams. GenAI based tools have the potential to change the way we develop software and have received attention from industry and academia. However, although some studies have been addressing the adoption of these tools in the software industry, little is known about what are developers' real experiences in a professional software development context, aside the hype. In this paper, we explore the use of GenAI tools by a large Brazilian media company that has teams developing software inhouse. We observed practitioners for six weeks and used online surveys at different time points to understand their expectations, perceptions, and concerns about these tools in their daily work. In addition, we automatically collected quantitative data from the company's development systems, aiming at getting insights about how GenAI impacts the development process during the period. Our results provide insights into how practitioners perceive and utilize GenAI in their daily work in software development.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/53a833736bc658d0da00b1cdfc5ed85e3c01674a.pdf",
      "venue": "2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
      "citationCount": 3,
      "score": 3.0,
      "summary": "Recent progress in Generative AI (GenAI) impacts different software engineering (ES) tasks in software development cycle, e.g., from code generation to program repair, and presents a promising avenue for enhancing the productivity of development teams. GenAI based tools have the potential to change the way we develop software and have received attention from industry and academia. However, although some studies have been addressing the adoption of these tools in the software industry, little is known about what are developers' real experiences in a professional software development context, aside the hype. In this paper, we explore the use of GenAI tools by a large Brazilian media company that has teams developing software inhouse. We observed practitioners for six weeks and used online surveys at different time points to understand their expectations, perceptions, and concerns about these tools in their daily work. In addition, we automatically collected quantitative data from the company's development systems, aiming at getting insights about how GenAI impacts the development process during the period. Our results provide insights into how practitioners perceive and utilize GenAI in their daily work in software development.",
      "keywords": []
    },
    "file_name": "53a833736bc658d0da00b1cdfc5ed85e3c01674a.pdf"
  },
  {
    "success": true,
    "doc_id": "a0a7ce113644fdf1700e5caa1cf5f36d",
    "summary": "Agile software development places great importance on requirement prioritization and reprioritization, which allow teams to concentrate on providing the most beneficial features to satisfy stakeholders. Most systematic review articles on prioritization techniques focus on traditional methods and ignore recent approaches that use artificial intelligence (AI). Additionally, there is a notable scarcity of literature addressing the neglected domain of reprioritisation and a lack of review papers analyzing semi-automated approaches. To fill this gap, this systematic literature review includes an in-depth review of newly developed AI-based and semi-automated techniques, in addition to widely used traditional prioritization methods. This study analyzed 76 primary studies from five credible electronic databases (Springer Link, IEEE Xplore, Scopus, Science Direct, and ACM Digital Library) to address six selected research questions. This literature review paper is unique in that it covers conventional approaches, reprioritization techniques, and AI-based and semi-automated techniques in a single review, which has not been done in previous papers. The findings highlight the strength and weakness of each technique. This review also identifies the most commonly used prioritization techniques in agile software development and the key challenges in requirement prioritization. Future research opportunities in the field of reprioritization are revealed by the gaps identified in the literature. This research contributes to enhancing the agility and effectiveness of agile software development (ASD).",
    "intriguing_abstract": "Agile software development places great importance on requirement prioritization and reprioritization, which allow teams to concentrate on providing the most beneficial features to satisfy stakeholders. Most systematic review articles on prioritization techniques focus on traditional methods and ignore recent approaches that use artificial intelligence (AI). Additionally, there is a notable scarcity of literature addressing the neglected domain of reprioritisation and a lack of review papers analyzing semi-automated approaches. To fill this gap, this systematic literature review includes an in-depth review of newly developed AI-based and semi-automated techniques, in addition to widely used traditional prioritization methods. This study analyzed 76 primary studies from five credible electronic databases (Springer Link, IEEE Xplore, Scopus, Science Direct, and ACM Digital Library) to address six selected research questions. This literature review paper is unique in that it covers conventional approaches, reprioritization techniques, and AI-based and semi-automated techniques in a single review, which has not been done in previous papers. The findings highlight the strength and weakness of each technique. This review also identifies the most commonly used prioritization techniques in agile software development and the key challenges in requirement prioritization. Future research opportunities in the field of reprioritization are revealed by the gaps identified in the literature. This research contributes to enhancing the agility and effectiveness of agile software development (ASD).",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/98718a3535968ea7e89cd81a20786d53535b345b.pdf",
    "citation_key": "tasneem20255aa",
    "metadata": {
      "title": "Enhancing Agile Software Development: A Systematic Literature Review of Requirement Prioritization and Reprioritization Techniques",
      "authors": [
        "Noshin Tasneem",
        "H. Zulzalil",
        "Sa’adah Hassan"
      ],
      "published_date": "2025",
      "abstract": "Agile software development places great importance on requirement prioritization and reprioritization, which allow teams to concentrate on providing the most beneficial features to satisfy stakeholders. Most systematic review articles on prioritization techniques focus on traditional methods and ignore recent approaches that use artificial intelligence (AI). Additionally, there is a notable scarcity of literature addressing the neglected domain of reprioritisation and a lack of review papers analyzing semi-automated approaches. To fill this gap, this systematic literature review includes an in-depth review of newly developed AI-based and semi-automated techniques, in addition to widely used traditional prioritization methods. This study analyzed 76 primary studies from five credible electronic databases (Springer Link, IEEE Xplore, Scopus, Science Direct, and ACM Digital Library) to address six selected research questions. This literature review paper is unique in that it covers conventional approaches, reprioritization techniques, and AI-based and semi-automated techniques in a single review, which has not been done in previous papers. The findings highlight the strength and weakness of each technique. This review also identifies the most commonly used prioritization techniques in agile software development and the key challenges in requirement prioritization. Future research opportunities in the field of reprioritization are revealed by the gaps identified in the literature. This research contributes to enhancing the agility and effectiveness of agile software development (ASD).",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/98718a3535968ea7e89cd81a20786d53535b345b.pdf",
      "venue": "IEEE Access",
      "citationCount": 3,
      "score": 3.0,
      "summary": "Agile software development places great importance on requirement prioritization and reprioritization, which allow teams to concentrate on providing the most beneficial features to satisfy stakeholders. Most systematic review articles on prioritization techniques focus on traditional methods and ignore recent approaches that use artificial intelligence (AI). Additionally, there is a notable scarcity of literature addressing the neglected domain of reprioritisation and a lack of review papers analyzing semi-automated approaches. To fill this gap, this systematic literature review includes an in-depth review of newly developed AI-based and semi-automated techniques, in addition to widely used traditional prioritization methods. This study analyzed 76 primary studies from five credible electronic databases (Springer Link, IEEE Xplore, Scopus, Science Direct, and ACM Digital Library) to address six selected research questions. This literature review paper is unique in that it covers conventional approaches, reprioritization techniques, and AI-based and semi-automated techniques in a single review, which has not been done in previous papers. The findings highlight the strength and weakness of each technique. This review also identifies the most commonly used prioritization techniques in agile software development and the key challenges in requirement prioritization. Future research opportunities in the field of reprioritization are revealed by the gaps identified in the literature. This research contributes to enhancing the agility and effectiveness of agile software development (ASD).",
      "keywords": []
    },
    "file_name": "98718a3535968ea7e89cd81a20786d53535b345b.pdf"
  },
  {
    "success": true,
    "doc_id": "e985c3d97ecc4be65f023a9ff4b81686",
    "summary": ": Generative AI tools are the cutting edge solutions of complex AI related problems. While investigating state-of-the-art results related to the effect of GenAI in the literature, one can note that the trends most likely lead to the expectation of a positive effect on the middle and long run. Based on these ﬁndings we deﬁne 4 productivity gain related hypotheses that we study using two types of methodologies. Namely we perform a survey research related to university-industry collaboration and quantitative studies mainly based on industrial productivity metrics. We have partnered with a major IT services provider - EPAM Systems - to be able to track, validate and analyze the key productivity metrics of software development projects, with and without using GenAI tools. This evaluation is being performed on various stages of the Software Development Lifecycle (SDLC) and on several project roles. Our goal is to measure the productivity increase provided by GenAI tools. Although this research has just started recently, considering that the area has extremely high attention we present some initial ﬁndings.",
    "intriguing_abstract": ": Generative AI tools are the cutting edge solutions of complex AI related problems. While investigating state-of-the-art results related to the effect of GenAI in the literature, one can note that the trends most likely lead to the expectation of a positive effect on the middle and long run. Based on these ﬁndings we deﬁne 4 productivity gain related hypotheses that we study using two types of methodologies. Namely we perform a survey research related to university-industry collaboration and quantitative studies mainly based on industrial productivity metrics. We have partnered with a major IT services provider - EPAM Systems - to be able to track, validate and analyze the key productivity metrics of software development projects, with and without using GenAI tools. This evaluation is being performed on various stages of the Software Development Lifecycle (SDLC) and on several project roles. Our goal is to measure the productivity increase provided by GenAI tools. Although this research has just started recently, considering that the area has extremely high attention we present some initial ﬁndings.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/349d4d616904f60b02b4b4983a3da185eb77ae9b.pdf",
    "citation_key": "hjja2024l72",
    "metadata": {
      "title": "Generative AI for Productivity in Industry and Education",
      "authors": [
        "Ferenc Héjja",
        "Tamás Bartók",
        "Roy Dakroub",
        "G. Kocsis"
      ],
      "published_date": "2024",
      "abstract": ": Generative AI tools are the cutting edge solutions of complex AI related problems. While investigating state-of-the-art results related to the effect of GenAI in the literature, one can note that the trends most likely lead to the expectation of a positive effect on the middle and long run. Based on these ﬁndings we deﬁne 4 productivity gain related hypotheses that we study using two types of methodologies. Namely we perform a survey research related to university-industry collaboration and quantitative studies mainly based on industrial productivity metrics. We have partnered with a major IT services provider - EPAM Systems - to be able to track, validate and analyze the key productivity metrics of software development projects, with and without using GenAI tools. This evaluation is being performed on various stages of the Software Development Lifecycle (SDLC) and on several project roles. Our goal is to measure the productivity increase provided by GenAI tools. Although this research has just started recently, considering that the area has extremely high attention we present some initial ﬁndings.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/349d4d616904f60b02b4b4983a3da185eb77ae9b.pdf",
      "venue": "International Conference on Complex Information Systems",
      "citationCount": 3,
      "score": 3.0,
      "summary": ": Generative AI tools are the cutting edge solutions of complex AI related problems. While investigating state-of-the-art results related to the effect of GenAI in the literature, one can note that the trends most likely lead to the expectation of a positive effect on the middle and long run. Based on these ﬁndings we deﬁne 4 productivity gain related hypotheses that we study using two types of methodologies. Namely we perform a survey research related to university-industry collaboration and quantitative studies mainly based on industrial productivity metrics. We have partnered with a major IT services provider - EPAM Systems - to be able to track, validate and analyze the key productivity metrics of software development projects, with and without using GenAI tools. This evaluation is being performed on various stages of the Software Development Lifecycle (SDLC) and on several project roles. Our goal is to measure the productivity increase provided by GenAI tools. Although this research has just started recently, considering that the area has extremely high attention we present some initial ﬁndings.",
      "keywords": []
    },
    "file_name": "349d4d616904f60b02b4b4983a3da185eb77ae9b.pdf"
  },
  {
    "success": true,
    "doc_id": "deb2e35dde588caaf8fe0c98cbc8fe08",
    "summary": "AI4S (AI for Science) is an interdisciplinary field dedicated to solving and studying complex scientific problems using AI methods. Currently, AI4S has made significant breakthroughs in life science, energy science, physics and computer science, Earth and Environmental Science. Numerous fundamental software for AI4S have emerged as a result. As a global technology leader deeply engaged in the field of AI, Baidu strongly supports the deployment and application of AI4S solutions through its deep learning platform, PaddlePaddle. This paper presents a case study of PaddlePaddle, outlining its experience in accelerating innovation in the field of science. It explores the specific practices employed by PaddlePaddle to aid the development of AI4S, intending to provide constructive suggestions on how to accelerate the popularization of AI4S on the ground through deep learning platforms. The ultimate goal is to contribute to China's solution for AI-enabled scientific development in the wave of the new round of industrial revolution.",
    "intriguing_abstract": "AI4S (AI for Science) is an interdisciplinary field dedicated to solving and studying complex scientific problems using AI methods. Currently, AI4S has made significant breakthroughs in life science, energy science, physics and computer science, Earth and Environmental Science. Numerous fundamental software for AI4S have emerged as a result. As a global technology leader deeply engaged in the field of AI, Baidu strongly supports the deployment and application of AI4S solutions through its deep learning platform, PaddlePaddle. This paper presents a case study of PaddlePaddle, outlining its experience in accelerating innovation in the field of science. It explores the specific practices employed by PaddlePaddle to aid the development of AI4S, intending to provide constructive suggestions on how to accelerate the popularization of AI4S on the ground through deep learning platforms. The ultimate goal is to contribute to China's solution for AI-enabled scientific development in the wave of the new round of industrial revolution.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/3d230c35fb4ce2159adfd444c69e47a3cc5abbd6.pdf",
    "citation_key": "chai2024x8t",
    "metadata": {
      "title": "AI for Science: Practice from Baidu PaddlePaddle",
      "authors": [
        "Xiaomeng Chai",
        "Min Zhang",
        "Hua Tian"
      ],
      "published_date": "2024",
      "abstract": "AI4S (AI for Science) is an interdisciplinary field dedicated to solving and studying complex scientific problems using AI methods. Currently, AI4S has made significant breakthroughs in life science, energy science, physics and computer science, Earth and Environmental Science. Numerous fundamental software for AI4S have emerged as a result. As a global technology leader deeply engaged in the field of AI, Baidu strongly supports the deployment and application of AI4S solutions through its deep learning platform, PaddlePaddle. This paper presents a case study of PaddlePaddle, outlining its experience in accelerating innovation in the field of science. It explores the specific practices employed by PaddlePaddle to aid the development of AI4S, intending to provide constructive suggestions on how to accelerate the popularization of AI4S on the ground through deep learning platforms. The ultimate goal is to contribute to China's solution for AI-enabled scientific development in the wave of the new round of industrial revolution.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/3d230c35fb4ce2159adfd444c69e47a3cc5abbd6.pdf",
      "venue": "Portland International Conference on Management of Engineering and Technology",
      "citationCount": 3,
      "score": 3.0,
      "summary": "AI4S (AI for Science) is an interdisciplinary field dedicated to solving and studying complex scientific problems using AI methods. Currently, AI4S has made significant breakthroughs in life science, energy science, physics and computer science, Earth and Environmental Science. Numerous fundamental software for AI4S have emerged as a result. As a global technology leader deeply engaged in the field of AI, Baidu strongly supports the deployment and application of AI4S solutions through its deep learning platform, PaddlePaddle. This paper presents a case study of PaddlePaddle, outlining its experience in accelerating innovation in the field of science. It explores the specific practices employed by PaddlePaddle to aid the development of AI4S, intending to provide constructive suggestions on how to accelerate the popularization of AI4S on the ground through deep learning platforms. The ultimate goal is to contribute to China's solution for AI-enabled scientific development in the wave of the new round of industrial revolution.",
      "keywords": []
    },
    "file_name": "3d230c35fb4ce2159adfd444c69e47a3cc5abbd6.pdf"
  },
  {
    "success": true,
    "doc_id": "95da056cfb4286a64e04129f5579adf8",
    "summary": "Artificial Intelligence (AI) advancements have enabled the development of Large Language Models (LLMs) that can perform a variety of tasks with remarkable semantic understanding and accuracy. ChatGPT is one such LLM that has gained significant attention due to its impressive capabilities for assisting in various knowledge-intensive tasks. Due to the knowledge-intensive nature of engineering secure software, Chat-GPT’s assistance is expected to be explored for security-related tasks during the development/evolution of software. To gain an understanding of the potential of ChatGPT as an emerging technology for supporting software security, we adopted a twofold approach. Initially, we performed an empirical study to analyse the perceptions of those who had explored the use of ChatGPT for security tasks and shared their views on Twitter. It was determined that security practitioners view ChatGPT as beneficial for various software security tasks, including vulnerability detection, information retrieval, and penetration testing. Secondly, we designed an experiment aimed at investigating the practicality of this technology when deployed as an oracle in real-world settings. In particular, we focused on vulnerability detection and qualitatively examined ChatGPT outputs for given prompts within this prominent software security task. Based on our analysis, responses from ChatGPT in this task are largely filled with generic security information and may not be appropriate for industry use. To prevent data leakage, we performed this analysis on a vulnerability dataset compiled after the OpenAI data cut-off date from real-world projects covering 40 distinct vulnerability types and 12 programming languages. We assert that the findings from this study would contribute to future research aimed at developing and evaluating LLMs dedicated to software security.",
    "intriguing_abstract": "Artificial Intelligence (AI) advancements have enabled the development of Large Language Models (LLMs) that can perform a variety of tasks with remarkable semantic understanding and accuracy. ChatGPT is one such LLM that has gained significant attention due to its impressive capabilities for assisting in various knowledge-intensive tasks. Due to the knowledge-intensive nature of engineering secure software, Chat-GPT’s assistance is expected to be explored for security-related tasks during the development/evolution of software. To gain an understanding of the potential of ChatGPT as an emerging technology for supporting software security, we adopted a twofold approach. Initially, we performed an empirical study to analyse the perceptions of those who had explored the use of ChatGPT for security tasks and shared their views on Twitter. It was determined that security practitioners view ChatGPT as beneficial for various software security tasks, including vulnerability detection, information retrieval, and penetration testing. Secondly, we designed an experiment aimed at investigating the practicality of this technology when deployed as an oracle in real-world settings. In particular, we focused on vulnerability detection and qualitatively examined ChatGPT outputs for given prompts within this prominent software security task. Based on our analysis, responses from ChatGPT in this task are largely filled with generic security information and may not be appropriate for industry use. To prevent data leakage, we performed this analysis on a vulnerability dataset compiled after the OpenAI data cut-off date from real-world projects covering 40 distinct vulnerability types and 12 programming languages. We assert that the findings from this study would contribute to future research aimed at developing and evaluating LLMs dedicated to software security.",
    "keywords": [],
    "file_path": "paper_data/AI_for_Software_Development_Compliance/f761b941262f32e8e729b14327159ef1a05b59f1.pdf",
    "citation_key": "kholoosi2024mh2",
    "metadata": {
      "title": "A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality",
      "authors": [
        "M. M. Kholoosi",
        "M. A. Babar",
        "Roland Croft"
      ],
      "published_date": "2024",
      "abstract": "Artificial Intelligence (AI) advancements have enabled the development of Large Language Models (LLMs) that can perform a variety of tasks with remarkable semantic understanding and accuracy. ChatGPT is one such LLM that has gained significant attention due to its impressive capabilities for assisting in various knowledge-intensive tasks. Due to the knowledge-intensive nature of engineering secure software, Chat-GPT’s assistance is expected to be explored for security-related tasks during the development/evolution of software. To gain an understanding of the potential of ChatGPT as an emerging technology for supporting software security, we adopted a twofold approach. Initially, we performed an empirical study to analyse the perceptions of those who had explored the use of ChatGPT for security tasks and shared their views on Twitter. It was determined that security practitioners view ChatGPT as beneficial for various software security tasks, including vulnerability detection, information retrieval, and penetration testing. Secondly, we designed an experiment aimed at investigating the practicality of this technology when deployed as an oracle in real-world settings. In particular, we focused on vulnerability detection and qualitatively examined ChatGPT outputs for given prompts within this prominent software security task. Based on our analysis, responses from ChatGPT in this task are largely filled with generic security information and may not be appropriate for industry use. To prevent data leakage, we performed this analysis on a vulnerability dataset compiled after the OpenAI data cut-off date from real-world projects covering 40 distinct vulnerability types and 12 programming languages. We assert that the findings from this study would contribute to future research aimed at developing and evaluating LLMs dedicated to software security.",
      "file_path": "paper_data/AI_for_Software_Development_Compliance/info/f761b941262f32e8e729b14327159ef1a05b59f1.pdf",
      "venue": "International Conference on Trust, Privacy and Security in Intelligent Systems and Applications",
      "citationCount": 3,
      "score": 3.0,
      "summary": "Artificial Intelligence (AI) advancements have enabled the development of Large Language Models (LLMs) that can perform a variety of tasks with remarkable semantic understanding and accuracy. ChatGPT is one such LLM that has gained significant attention due to its impressive capabilities for assisting in various knowledge-intensive tasks. Due to the knowledge-intensive nature of engineering secure software, Chat-GPT’s assistance is expected to be explored for security-related tasks during the development/evolution of software. To gain an understanding of the potential of ChatGPT as an emerging technology for supporting software security, we adopted a twofold approach. Initially, we performed an empirical study to analyse the perceptions of those who had explored the use of ChatGPT for security tasks and shared their views on Twitter. It was determined that security practitioners view ChatGPT as beneficial for various software security tasks, including vulnerability detection, information retrieval, and penetration testing. Secondly, we designed an experiment aimed at investigating the practicality of this technology when deployed as an oracle in real-world settings. In particular, we focused on vulnerability detection and qualitatively examined ChatGPT outputs for given prompts within this prominent software security task. Based on our analysis, responses from ChatGPT in this task are largely filled with generic security information and may not be appropriate for industry use. To prevent data leakage, we performed this analysis on a vulnerability dataset compiled after the OpenAI data cut-off date from real-world projects covering 40 distinct vulnerability types and 12 programming languages. We assert that the findings from this study would contribute to future research aimed at developing and evaluating LLMs dedicated to software security.",
      "keywords": []
    },
    "file_name": "f761b941262f32e8e729b14327159ef1a05b59f1.pdf"
  }
]