{
    "eb22629ba7dd88761c39173f8abc69b589acc5cd.pdf": {
        "title": "Generative AI for Software Practitioners",
        "authors": [
            "C. Ebert",
            "Panos Louridas",
            "C. Ebert"
        ],
        "published_date": "2023",
        "abstract": "Generative artificial intelligence (AI) tools, such as Bard, ChatGPT, and CoPilot, have rapidly gained widespread usage. They also have the potential to boost software engineering productivity. In this article, we elaborate technologies and usage of generative AI in the software industry. We address questions, such as: How does generative AI improve software productivity? How to connect generative AI to software development, and what are the risks? Which technologies have what sorts of benefits? Practitioner guidance and case studies are shared from our industry context. I look forward to hearing from you about this column and the technologies that matter most for your work.\u2014Christof Ebert",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/eb22629ba7dd88761c39173f8abc69b589acc5cd.pdf",
        "venue": "IEEE Software",
        "citationCount": 0,
        "score": 0
    },
    "5e16600a03b824911557e78f7d5521d5c3339cd9.pdf": {
        "title": "The Role of Generative AI in Software Development Productivity: A Pilot Case Study",
        "authors": [
            "Mariana Coutinho",
            "Lorena Marques",
            "Anderson Santos",
            "Marcio Dahia",
            "C\u00e9sar Fran\u00e7a",
            "Ronnie de Souza Santos"
        ],
        "published_date": "2024",
        "abstract": "With software development increasingly reliant on innovative technologies, there is a growing interest in exploring the potential of generative AI tools to streamline processes and enhance productivity. In this scenario, this paper investigates the integration of generative AI tools within software development, focusing on understanding their uses, benefits, and challenges to software professionals, in particular, looking at aspects of productivity. Through a pilot case study involving software practitioners working in different roles, we gathered valuable experiences on the integration of generative AI tools into their daily work routines. Our findings reveal a generally positive perception of these tools in individual productivity while also highlighting the need to address identified limitations. Overall, our research sets the stage for further exploration into the evolving landscape of software development practices with the integration of generative AI tools.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/5e16600a03b824911557e78f7d5521d5c3339cd9.pdf",
        "venue": "AIware",
        "citationCount": 0,
        "score": 0
    },
    "44eff92639a7b6a4bd37f09bc7277210a008aa77.pdf": {
        "title": "Generative Ai in Software Development : an Overview and Evaluation of Modern Coding Tools",
        "authors": [
            "Aarti"
        ],
        "published_date": "2024",
        "abstract": "Generative AI has significantly transformed software development by leveraging advanced machine learning models to automate coding tasks, generate code, and enhance productivity. This paper provides an overview and evaluation of modern AI-powered coding tools, including GitHub Copilot, OpenAI Codex, DeepCode, Amazon CodeGuru, TabNine, Kite, and IntelliCode, which use large language models (LLMs) to offer real-time code suggestions, automated error detection, and intelligent code completions. Despite their benefits, these tools face challenges related to accuracy, contextual understanding, security, privacy, and ethical considerations, necessitating thorough review and testing of AI-generated code by developers. The integration of AI in coding also raises concerns about proprietary information protection and ethical implications such as job displacement. This paper explores the capabilities, applications, and limitations of current generative AI tools, highlighting their impact on software development and discussing future directions. Emphasis is placed on the need for improved model training, enhanced contextual understanding, secure AI training methods, and ethical AI usage. By addressing these challenges, the industry can maximize the potential of generative AI, creating more accurate, reliable, and ethically sound tools that support a collaborative and innovative software development environment.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/44eff92639a7b6a4bd37f09bc7277210a008aa77.pdf",
        "venue": "International Journal For Multidisciplinary Research",
        "citationCount": 0,
        "score": 0
    },
    "6a03b02e61b447ce1456624853d7accfd24a2711.pdf": {
        "title": "Software engineering for Responsible AI: An empirical study and operationalised patterns",
        "authors": [
            "Q. Lu",
            "Liming Zhu",
            "Xiwei Xu",
            "J. Whittle",
            "David M. Douglas",
            "Conrad Sanderson"
        ],
        "published_date": "2021",
        "abstract": "AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to develop responsible AI systems. To address this shortcoming, we perform an empirical study involving interviews with 21 scientists and engineers to understand the practitioners' views on AI ethics principles and their implementation. Our major findings are: (1) the current practice is often a done-once-and-forget type of ethical risk assessment at a particular development step, which is not sufficient for highly uncertain and continual learning AI systems; (2) ethical requirements are either omitted or mostly stated as high-level objectives, and not specified explicitly in verifiable way as system outputs or outcomes; (3) although ethical requirements have the characteristics of cross-cutting quality and non-functional requirements amenable to architecture and design analysis, system-level architecture and design are under-explored; (4) there is a strong desire for continuously monitoring and validating AI systems post deployment for ethical requirements but current operation practices provide limited guidance. To address these findings, we suggest a preliminary list of patterns to provide operationalised guidance for developing responsible AI systems.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/6a03b02e61b447ce1456624853d7accfd24a2711.pdf",
        "venue": "2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
        "citationCount": 0,
        "score": 0
    },
    "98ca16a9162e7951df24bb3e0e498472ac05fab4.pdf": {
        "title": "Hints for Generative AI Software Development",
        "authors": [
            "C. Ebert",
            "John Pravin Arockiasamy",
            "Lennard Hettich",
            "Michael Weyrich",
            "C. Ebert"
        ],
        "published_date": "2024",
        "abstract": "Developers benefit from enhanced productivity with GAI. Yet, often they question how to approach GAI development and how to integrate GAI to their systems. This article provides guidance for developing GAI software and developing software with GAI. Practical hints are shared from industrial settings.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/98ca16a9162e7951df24bb3e0e498472ac05fab4.pdf",
        "venue": "IEEE Software",
        "citationCount": 0,
        "score": 0
    },
    "f0953d67eed1d0da53a321a3731c086e754e775e.pdf": {
        "title": "The future of software development: integrating AI and machine learning into front-end technologies",
        "authors": [
            "Harrison Oke Ekpobimi",
            "Regina Coelis Kandekere",
            "Adebamigbe Fasanmade"
        ],
        "published_date": "2024",
        "abstract": "This paper explores the integration of artificial intelligence (AI) and machine learning into front-end development, highlighting the transformative potential these technologies hold for the future of software development. By automating routine tasks, enhancing predictive capabilities, and improving user engagement, AI and machine learning are set to revolutionize how digital applications are created and experienced. However, this integration is accompanied by significant technical challenges, including the complexity of AI systems, performance concerns, and ethical issues such as data privacy and bias. The paper also discusses current applications and emerging trends in AI-powered front-end technologies, providing a comprehensive overview of the benefits and obstacles. It emphasizes the importance of ongoing research, innovation, and ethical considerations in maintaining the U.S. tech sector's competitive edge in this rapidly evolving field. The findings suggest that while AI and machine learning offer substantial opportunities for innovation, careful implementation is essential to ensure these technologies contribute positively to the future of software development.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/f0953d67eed1d0da53a321a3731c086e754e775e.pdf",
        "venue": "Global Journal of Advanced Research and Reviews",
        "citationCount": 0,
        "score": 0
    },
    "f2bf1c3a5223f488cd2c2434e9642fd34cf532a2.pdf": {
        "title": "Analysis ChatGPT Potential: Transforming Software Development with AI Chat Bots",
        "authors": [
            "Justine Winata Purwoko",
            "Tegar Abdullah",
            "Budiman Wijaya",
            "Alexander Agung Santoso Gunawan",
            "Karen Etania Saputra"
        ],
        "published_date": "2023",
        "abstract": "Artificial intelligence (AI) is a technology that is constantly evolving and is being applied more frequently in many facets of society, including product and service development. Chatbots, which are computer programs that can connect with people through chat or voice apps, are one sort of AI that is evolving quickly. However, there is still much debate among scientists and professionals about whether AI advancements like ChatGPT can help software engineers with their daily tasks or even replace the work of software engineers. So, on this occasion, we conduct research on whether AI (artificial intelligence) is capable of helping software engineers and how far AI can assist software engineers. In this study, we aim to evaluate the effectiveness of ChatGPT as an AI tool for code retrieval and its potential to help or replace software engineers. Our research methodology involves using ChatGPT to refactor provided code and make a simple application from scratch. The results of this research show that AI chatbot models like ChatGPT cannot replace software developers 100",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/f2bf1c3a5223f488cd2c2434e9642fd34cf532a2.pdf",
        "venue": "2023 International Conference on Networking, Electrical Engineering, Computer Science, and Technology (IConNECT)",
        "citationCount": 0,
        "score": 0
    },
    "2c78517dff83433eba7d4e86bac84aacdfbb468c.pdf": {
        "title": "Generative AI for Software Architecture. Applications, Trends, Challenges, and Future Directions",
        "authors": [
            "Matteo Esposito",
            "Xiaozhou Li",
            "Sergio Moreschini",
            "Noman Ahmad",
            "Tom\u00e1s Cern\u00fd",
            "Karthik Vaidhyanathan",
            "Valentina Lenarduzzi",
            "Davide Taibi"
        ],
        "published_date": "2025",
        "abstract": "Context: Generative Artificial Intelligence (GenAI) is transforming much of software development, yet its application in software architecture is still in its infancy, and no prior study has systematically addressed the topic. Aim: We aim to systematically synthesize the use, rationale, contexts, usability, and future challenges of GenAI in software architecture. Method: We performed a multivocal literature review (MLR), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, and reported challenges, extracting themes via open coding. Results: Our review identified significant adoption of GenAI for architectural decision support and architectural reconstruction. OpenAI GPT models are predominantly applied, and there is consistent use of techniques such as few-shot prompting and retrieved-augmented generation (RAG). GenAI has been applied mostly to initial stages of the Software Development Life Cycle (SDLC), such as Requirements-to-Architecture and Architecture-to-Code. Monolithic and microservice architectures were the dominant targets. However, rigorous testing of GenAI outputs was typically missing from the studies. Among the most frequent challenges are model precision, hallucinations, ethical aspects, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks. Conclusions: GenAI shows significant potential in software design, but several challenges remain on its path to greater adoption. Research efforts should target designing general evaluation methodologies, handling ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks to bridge the gap between theoretical possibilities and practical use.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/2c78517dff83433eba7d4e86bac84aacdfbb468c.pdf",
        "venue": "Journal of Systems and Software",
        "citationCount": 0,
        "score": 0
    },
    "8e23664ebf21fe2a586d25cc09fcc26bff4ccf96.pdf": {
        "title": "Unveiling the Role of ChatGPT in Software Development: Insights from Developer-ChatGPT Interactions on GitHub",
        "authors": [
            "Ruiyin Li",
            "Peng Liang",
            "Yifei Wang",
            "Yangxiao Cai",
            "Weisong Sun",
            "Zengyang Li"
        ],
        "published_date": "2025",
        "abstract": "The advent of Large Language Models (LLMs) has introduced a new paradigm in software engineering, with generative AI tools like ChatGPT gaining widespread adoption among developers. While ChatGPT's potential has been extensively discussed, there is limited empirical evidence exploring its real-world usage by developers. This study bridges this gap by conducting a large-scale empirical analysis of ChatGPT-assisted development activities, leveraging a curated dataset, DevChat, comprising 2,547 unique shared ChatGPT links collected from GitHub between May 2023 and June 2024. Our study examines the characteristics of ChatGPT's usage on GitHub (including the tendency, prompt turns distribution, and link descriptions) and identifies five categories of developers' purposes for sharing developer-ChatGPT conversations during software development. Additionally, we analyzed the development-related activities where developers shared ChatGPT links to facilitate their workflows. We then established a mapping framework among data sources, activities, and SE tasks associated with these shared ChatGPT links. Our study offers a comprehensive view of ChatGPT's application in real-world software development scenarios and provides a foundation for its future integration into software development workflows.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/8e23664ebf21fe2a586d25cc09fcc26bff4ccf96.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "49ebf1312fcee06497422ce325756e769beb7e40.pdf": {
        "title": "Transforming Software Testing in the US: Generative AI Models for Realistic User Simulation",
        "authors": [
            "S. M. Islam",
            "Md Shadikul Bari",
            "Ankur Sarkar"
        ],
        "published_date": "2024",
        "abstract": "Testing software has a higher level of difficulty because of the variations in users\u2019 behaviors, decreasing time of software development, and the demand for prototypical testing. It becomes almost impossible to apply traditional approaches in determining the software\u2019s dynamic environment or its ability to capture different users\u2019 interactions. Introducing to this paper is the hybrid model of Generative AI and RL to model realistic user behaviors whilst modulating to software responses as well. Specifically, in this paper, we discuss the US context by tackling several challenges specific to the regional context of the demographic diversity, the widespread use of Agile/DevOps methodologies and frameworks, and the demand for the highest levels of quality in software testing. The combination of Generative AI for behavior variety with RL for learning makes the given methodology a continuous feedback process for the sake of thorough and realistic behavioral testing. This is well illustrated by real-life applications in areas like e-commerce, healthcare and banking to mention but a few where the model provides robust results terms of identifying difficult to detect faults, test effectiveness and cost benefit analysis. They plan to co-designing federated learning for privacy-preserving testing in the future, as well as leveraging more cross-cultural user simulations that have global application.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/49ebf1312fcee06497422ce325756e769beb7e40.pdf",
        "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
        "citationCount": 0,
        "score": 0
    },
    "7133df341c91fc262c1d2757d0e13a29dcbb6e3c.pdf": {
        "title": "The Future of Software Engineering in an AI-Driven World",
        "authors": [
            "Valerio Terragni",
            "Partha S. Roop",
            "Kelly Blincoe"
        ],
        "published_date": "2024",
        "abstract": "A paradigm shift is underway in Software Engineering, with AI systems such as LLMs gaining increasing importance for improving software development productivity. This trend is anticipated to persist. In the next five years, we will likely see an increasing symbiotic partnership between human developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this paper, we present our vision of the future of software development in an AI-Driven world and explore the key challenges that our research community should address to realize this vision.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/7133df341c91fc262c1d2757d0e13a29dcbb6e3c.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "9eb9cf56cc8b616c121c0c90c2419480e9747765.pdf": {
        "title": "Integrating Generative AI for Advancing Agile Software Development and Mitigating Project Management Challenges",
        "authors": [
            "A. Bahi",
            "Jihane Gharib",
            "Youssef Gahi"
        ],
        "published_date": "2024",
        "abstract": "\u2014 Agile software development emphasizes iterative progress, adaptability, and stakeholder collaboration. It champions flexible planning, continuous improvement, and rapid delivery, aiming to respond swiftly to change and deliver value efficiently. Integrating Generative Artificial Intelligence (AI) into Agile software development processes presents a promising avenue for overcoming project management challenges and enhancing the efficiency and effectiveness of software development endeavors. This paper explores the potential benefits of leveraging Generative AI in Agile methodologies, aiming to streamline development workflows, foster innovation, and mitigate common project management challenges. By harnessing the capabilities of Generative AI for tasks such as code generation, automated testing, and predictive analytics, Agile teams can augment their productivity, accelerate delivery cycles, and improve the quality of software products. Additionally, Generative AI offers opportunities for enhancing collaboration, facilitating decision-making, and addressing uncertainties inherent in Agile project management. Through an in-depth analysis of the integration of Generative AI within Agile frameworks, this paper provides insights into how organizations can harness the transformative potential of AI to advance Agile software development practices and navigate the complexities of modern software projects more effectively.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/9eb9cf56cc8b616c121c0c90c2419480e9747765.pdf",
        "venue": "International Journal of Advanced Computer Science and Applications",
        "citationCount": 0,
        "score": 0
    },
    "eaf6427e86010f8de476f48372fba8520de40b11.pdf": {
        "title": "AI in Software Engineering at Google: Progress and the Path Ahead (Invited Talk)",
        "authors": [
            "Satish Chandra"
        ],
        "published_date": "2024",
        "abstract": "Over a period of just about 5 years, the use of AI-based tools for software engineering has gone from being a very promising research investigation to indispensable features in modern developer environments. This talk will present AI-powered improvements and continuing transformation of Google\u2019s internal software development. This viewpoint comes from extensive experience with developing and deploying AI-based tools to surfaces where Google engineers spend the majority of their time, including inner loop activities such as code authoring, review and search, as well as outer loop ones such as bug management and planning. Improvements in these surfaces are monitored carefully for productivity and developer satisfaction. We will describe the challenges in how to align our internal efforts with the very fast moving field of LLMs. We need to constantly make judgment calls on technical feasibility, the possibility of iterative improvement and the measurability of impact as we decide what ideas to pursue for production level adaptation and adoption. The talk will go into several examples of this that we have gone through in recent past, and what we have learned in the process. We will conclude the talk with changes that we expect to land in the next five years and some thoughts on how the community can collaborate better by focusing on good benchmarks.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/eaf6427e86010f8de476f48372fba8520de40b11.pdf",
        "venue": "AIware",
        "citationCount": 0,
        "score": 0
    },
    "36190a3036de35d7380d3b4789806244fa9e1476.pdf": {
        "title": "Towards green AI-based software systems: an architecture-centric approach (GAISSA)",
        "authors": [
            "Silverio Mart\u00ednez-Fern\u00e1ndez",
            "Xavier Franch",
            "Francisco Dur\u00e1n"
        ],
        "published_date": "2023",
        "abstract": "Nowadays, AI-based systems have achieved outstanding results and have outperformed humans in different domains. However, the processes of training AI models and inferring from them require high computational resources, which pose a significant challenge in the current energy efficiency societal demand. To cope with this challenge, this research project paper describes the main vision, goals, and expected outcomes of the GAISSA project. The GAISSA project aims at providing data scientists and software engineers tool-supported, architecture-centric methods for the modelling and development of green AI-based systems. Although the project is in an initial stage, we describe the current research results, which illustrate the potential to achieve GAISSA objectives.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/36190a3036de35d7380d3b4789806244fa9e1476.pdf",
        "venue": "EUROMICRO Conference on Software Engineering and Advanced Applications",
        "citationCount": 0,
        "score": 0
    },
    "0f34a8d56ce65c62d5ac1e51e9b7e34b3ac96813.pdf": {
        "title": "Transforming Software Development: Evaluating the Efficiency and Challenges of GitHub Copilot in Real-World Projects",
        "authors": [
            "Ruchika Pandey",
            "Prabhat Singh",
            "Raymond Wei",
            "Shaila Shankar"
        ],
        "published_date": "2024",
        "abstract": "Generative AI technologies promise to transform the product development lifecycle. This study evaluates the efficiency gains, areas for improvement, and emerging challenges of using GitHub Copilot, an AI-powered coding assistant. We identified 15 software development tasks and assessed Copilot's benefits through real-world projects on large proprietary code bases. Our findings indicate significant reductions in developer toil, with up to 50% time saved in code documentation and autocompletion, and 30-40% in repetitive coding tasks, unit test generation, debugging, and pair programming. However, Copilot struggles with complex tasks, large functions, multiple files, and proprietary contexts, particularly with C/C++ code. We project a 33-36% time reduction for coding-related tasks in a cloud-first software development lifecycle. This study aims to quantify productivity improvements, identify underperforming scenarios, examine practical benefits and challenges, investigate performance variations across programming languages, and discuss emerging issues related to code quality, security, and developer experience.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/0f34a8d56ce65c62d5ac1e51e9b7e34b3ac96813.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "65bb41fd0575d025e2d4fcb50b7fa8c5a7e3c10e.pdf": {
        "title": "Accelerating Software Development Using Generative AI: ChatGPT Case Study",
        "authors": [
            "Asha Rajbhoj",
            "Akanksha Somase",
            "Piyush Kulkarni",
            "Vinay Kulkarni"
        ],
        "published_date": "2024",
        "abstract": "The Software Development Life Cycle (SDLC) comprises multiple phases, each requiring Subject Matter Experts (SMEs) with phase-specific skills. The efficacy and quality of deliverables of each phase are skill dependent. In recent times, Generative AI techniques, including Large-scale Language Models (LLMs) like GPT, have become significant players in software engineering. These models, trained on extensive text data, can offer valuable contributions to software development. Interacting with LLMs involves feeding prompts with the context information and guiding the generation of textual responses. The quality of the response is dependent on the quality of the prompt given. This paper proposes a systematic prompting approach based on meta-model concepts for SDLC phases. The approach is validated using ChatGPT for small but complex business application development. We share the approach and our experience, learnings, benefits obtained, and the challenges encountered while applying the approach using ChatGPT. Our experience indicates that Generative AI techniques, such as ChatGPT, have the potential to reduce the skills barrier and accelerate software development substantially.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/65bb41fd0575d025e2d4fcb50b7fa8c5a7e3c10e.pdf",
        "venue": "International Symposium on Electronic Commerce",
        "citationCount": 0,
        "score": 0
    },
    "e813d85ccd9e1a86dca4aa6e0dcf9486f0fdd01a.pdf": {
        "title": "How Much Does AI Impact Development Speed? an Enterprise-Based Randomized Controlled Trial",
        "authors": [
            "Elise Paradis",
            "Kate Grey",
            "Quinn Madison",
            "Daye Nam",
            "Andrew Macvean",
            "Vahid Meimand",
            "Nan Zhang",
            "Ben Ferrari-Church",
            "Satish Chandra"
        ],
        "published_date": "2024",
        "abstract": "How much does AI assistance impact developer productivity? To date, the software engineering literature has provided a range of answers, targeting a diversity of outcomes: from perceived productivity to speed on task and developer throughput. Our randomized controlled trial with 96 full-time Google software engineers contributes to this literature by sharing an estimate of the impact of three AI features on the time developers spent on a complex, enterprise-grade task. We found that AI significantly shortened the time developers spent on task. Our best estimate of the size of this effect, controlling for factors known to influence developer time on task, stands at about $\\mathbf{2 1 \\%}$, although our confidence interval is large. We also found an interesting effect whereby developers who spend more hours on code-related activities per day were faster with AI. Product and future research considerations are discussed. In particular, we invite further research that explores the impact of AI at the ecosystem level and across multiple suites of AI-enhanced tools, since we cannot assume that the effect size obtained in our lab study will necessarily apply more broadly, or that the effect of AI found using internal Google tooling in the summer of 2024 will translate across tools and over time.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/e813d85ccd9e1a86dca4aa6e0dcf9486f0fdd01a.pdf",
        "venue": "2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
        "citationCount": 0,
        "score": 0
    },
    "e9a4ad74859cda6ad9d50cdd53722d3ce76d0ae1.pdf": {
        "title": "Generative AI for Pull Request Descriptions: Adoption, Impact, and Developer Interventions",
        "authors": [
            "Tao Xiao",
            "Hideaki Hata",
            "Christoph Treude",
            "Kenichi Matsumoto"
        ],
        "published_date": "2024",
        "abstract": "GitHub's Copilot for Pull Requests (PRs) is a promising service aiming to automate various developer tasks related to PRs, such as generating summaries of changes or providing complete walkthroughs with links to the relevant code. As this innovative technology gains traction in the Open Source Software (OSS) community, it is crucial to examine its early adoption and its impact on the development process. Additionally, it offers a unique opportunity to observe how developers respond when they disagree with the generated content. In our study, we employ a mixed-methods approach, blending quantitative analysis with qualitative insights, to examine 18,256 PRs in which parts of the descriptions were crafted by generative AI. Our findings indicate that: (1) Copilot for PRs, though in its infancy, is seeing a marked uptick in adoption. (2) PRs enhanced by Copilot for PRs require less review time and have a higher likelihood of being merged. (3) Developers using Copilot for PRs often complement the automated descriptions with their manual input. These results offer valuable insights into the growing integration of generative AI in software development.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/e9a4ad74859cda6ad9d50cdd53722d3ce76d0ae1.pdf",
        "venue": "Proc. ACM Softw. Eng.",
        "citationCount": 0,
        "score": 0
    },
    "5a1814b310b0e242985d7768998549b202e974ea.pdf": {
        "title": "Unlocking Potential with Generative AI Instruction: Investigating Mid-level Software Development Student Perceptions, Behavior, and Adoption",
        "authors": [
            "Jamie Gorson Benario",
            "Jenn Marroquin",
            "Monica M. Chan",
            "Ernest D.V. Holmes",
            "Daniel Mejia"
        ],
        "published_date": "2025",
        "abstract": "Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/5a1814b310b0e242985d7768998549b202e974ea.pdf",
        "venue": "Technical Symposium on Computer Science Education",
        "citationCount": 0,
        "score": 0
    },
    "8fbfc75459634ab4941aafce7b23962b054b5014.pdf": {
        "title": "The Future of AI-Driven Software Engineering",
        "authors": [
            "Valerio Terragni",
            "Annie Vella",
            "Partha S. Roop",
            "Kelly Blincoe"
        ],
        "published_date": "2025",
        "abstract": "A paradigm shift is underway in Software Engineering, with AI systems such as LLMs playing an increasingly important role in boosting software development productivity. This trend is anticipated to persist. In the next years, we expect a growing symbiotic partnership between human software developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this article, we present our vision of the future of software development in an AI-driven world and explore the key challenges that our research community should address to realize this vision.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/8fbfc75459634ab4941aafce7b23962b054b5014.pdf",
        "venue": "ACM Transactions on Software Engineering and Methodology",
        "citationCount": 0,
        "score": 0
    },
    "a9b3d3313e8918541c4c348fb2a95020a5242ac4.pdf": {
        "title": "Federated Learning for Software Engineering: A Case Study of Code Clone Detection and Defect Prediction",
        "authors": [
            "Yanming Yang",
            "Xing Hu",
            "Zhipeng Gao",
            "Jinfu Chen",
            "Chao Ni",
            "Xin Xia",
            "David Lo"
        ],
        "published_date": "2024",
        "abstract": "In various research domains, artificial intelligence (AI) has gained significant prominence, leading to the development of numerous learning-based models in research laboratories, which are evaluated using benchmark datasets. While the models proposed in previous studies may demonstrate satisfactory performance on benchmark datasets, translating academic findings into practical applications for industry practitioners presents challenges. This can entail either the direct adoption of trained academic models into industrial applications, leading to a performance decrease, or retraining models with industrial data, a task often hindered by insufficient data instances or skewed data distributions. Real-world industrial data is typically significantly more intricate than benchmark datasets, frequently exhibiting data-skewing issues, such as label distribution skews and quantity skews. Furthermore, accessing industrial data, particularly source code, can prove challenging for Software Engineering (SE) researchers due to privacy policies. This limitation hinders SE researchers\u2019 ability to gain insights into industry developers\u2019 concerns and subsequently enhance their proposed models. To bridge the divide between academic models and industrial applications, we introduce a federated learning (FL)-based framework called Almity. Our aim is to simplify the process of implementing research findings into practical use for both SE researchers and industry developers. Almity enhances model performance on sensitive skewed data distributions while ensuring data privacy and security. It introduces an innovative aggregation strategy that takes into account three key attributes: data scale, data balance, and minority class learnability. This strategy is employed to refine model parameters, thereby enhancing model performance on sensitive skewed datasets. In our evaluation, we employ two well-established SE tasks, i.e., code clone detection and defect prediction, as evaluation tasks. We compare the performance of Almity on both machine learning (ML) and deep learning (DL) models against two mainstream training methods, specifically the Centralized Training Method (CTM) and Vanilla Federated Learning (VFL), to validate the effectiveness and generalizability of Almity. Our experimental results demonstrate that our framework is not only feasible but also practical in real-world scenarios. Almity consistently enhances the performance of learning-based models, outperforming baseline training methods across all types of data distributions.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/a9b3d3313e8918541c4c348fb2a95020a5242ac4.pdf",
        "venue": "IEEE Transactions on Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "9efbe6ed7faba31149554d4ef8709799c83a6c15.pdf": {
        "title": "Revolutionizing BA-QA Team Dynamics: AI-Driven Collaboration Platforms for Accelerated Software Quality in the US Market",
        "authors": [
            "Mohammed Majid Bakhsh",
            "Md Shaikat Alam Joy",
            "Gazi Touhidul Alam"
        ],
        "published_date": "2024",
        "abstract": "In today\u2019s fast-paced software development environment, the collaboration between Business Analysts (BAs) and Quality Assurance (QA) teams is essential for delivering high-quality products efficiently. However, traditional methods often lead to inefficiencies due to silos and misalignment between these teams. This article explores how Artificial Intelligence (AI)-driven collaboration platforms are transforming BA-QA dynamics, offering a more integrated, data-driven approach to software development. By leveraging AI technologies such as predictive analytics, automated test case generation, and real-time collaboration tools, businesses can enhance decision-making, improve communication, and optimize testing strategies. This paper discusses the key benefits of AI in accelerating software quality, highlights real-world case studies of AI applications, and examines the future potential of AI in revolutionizing BA-QA collaboration, particularly in the US market. It also addresses the emerging trends and challenges that come with adopting AI, emphasizing the importance of continuous learning, training, and integration of AI tools with other technologies like IoT and blockchain. As AI continues to evolve, its role in streamlining BA-QA collaboration will become increasingly critical, offering organizations a competitive edge in delivering high-quality software at an accelerated pace.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/9efbe6ed7faba31149554d4ef8709799c83a6c15.pdf",
        "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
        "citationCount": 0,
        "score": 0
    },
    "00df5cf0d83c48657d453ab8083d8805a67f744f.pdf": {
        "title": "Measuring the Carbon Intensity of AI in Cloud Instances",
        "authors": [
            "Jesse Dodge",
            "Taylor Prewitt",
            "R\u00e9mi Tachet des Combes",
            "Erika Odmark",
            "Roy Schwartz",
            "Emma Strubell",
            "A. Luccioni",
            "Noah A. Smith",
            "Nicole DeCario",
            "Will Buchanan"
        ],
        "published_date": "2022",
        "abstract": "The advent of cloud computing has provided people around the world with unprecedented access to computational power and enabled rapid growth in technologies such as machine learning, the computational demands of which incur a high energy cost and a commensurate carbon footprint. As a result, recent scholarship has called for better estimates of the greenhouse gas impact of AI: data scientists today do not have easy or reliable access to measurements of this information, which precludes development of actionable tactics. We argue that cloud providers presenting information about software carbon intensity to users is a fundamental stepping stone towards minimizing emissions. In this paper, we provide a framework for measuring software carbon intensity, and propose to measure operational carbon emissions by using location-based and time-specific marginal emissions data per energy unit. We provide measurements of operational software carbon intensity for a set of modern models covering natural language processing and computer vision applications, and a wide range of model sizes, including pretraining of a 6.1 billion parameter language model. We then evaluate a suite of approaches for reducing emissions on the Microsoft Azure cloud compute platform: using cloud instances in different geographic regions, using cloud instances at different times of day, and dynamically pausing cloud instances when the marginal carbon intensity is above a certain threshold. We confirm previous results that the geographic region of the data center plays a significant role in the carbon intensity for a given cloud instance, and find that choosing an appropriate region can have the largest operational emissions reduction impact. We also present new results showing that the time of day has meaningful impact on operational software carbon intensity.Finally, we conclude with recommendations for how machine learning practitioners can use software carbon intensity information to reduce environmental impact.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/00df5cf0d83c48657d453ab8083d8805a67f744f.pdf",
        "venue": "Conference on Fairness, Accountability and Transparency",
        "citationCount": 0,
        "score": 0
    },
    "ecc2dc870345f22bd3d4d8b77b5e24b238cb975e.pdf": {
        "title": "Empowering Business Transformation: The Positive Impact and Ethical Considerations of Generative AI in Software Product Management - A Systematic Literature Review",
        "authors": [
            "N. Parikh"
        ],
        "published_date": "2023",
        "abstract": "Generative Artificial Intelligence (GAI) has made outstanding strides in recent years, with a good-sized impact on software product management. Drawing on pertinent articles from 2016 to 2023, this systematic literature evaluation reveals generative AI's potential applications, benefits, and constraints in this area. The study shows that technology can assist in idea generation, market research, customer insights, product requirements engineering, and product development. It can help reduce development time and costs through automatic code generation, customer feedback analysis, and more. However, the technology's accuracy, reliability, and ethical consideration persist. Ultimately, generative AI's practical application can significantly improve software product management activities, leading to more efficient use of resources, better product outcomes, and improved end-user experiences.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/ecc2dc870345f22bd3d4d8b77b5e24b238cb975e.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "52ad599144f4f42bab61a8c132698296fa9758b7.pdf": {
        "title": "The Diversity Crisis of Software Engineering for Artificial Intelligence",
        "authors": [
            "Bram Adams",
            "Foutse Khomh"
        ],
        "published_date": "2020",
        "abstract": "Artificial Intelligence (AI) is experiencing a \"diversity crisis.\"1 Several reports1-3 have shown how the breakthrough of modern AI has not yet been able to improve on existing diversity challenges regarding gender, race, geography, and other factors, neither for the end users of those products nor the companies and organizations building them. Plenty of examples have surfaced in which biased data engineering practices or existing data sets led to incorrect, painful, or sometimes even harmful consequences for unassuming end users.4 The problem is that ruling out such biases is not straightforward due to the sheer number of different bias types.5 To have a chance to eliminate as many biases as possible, most of the experts agree that the teams and organizations building AI products should be made more diverse.1-3 This harkens back to Linus' law6 for open source development (\"given enough eyeballs, all bugs are shallow\") but applied to the development process of AI products.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/52ad599144f4f42bab61a8c132698296fa9758b7.pdf",
        "venue": "IEEE Software",
        "citationCount": 0,
        "score": 0
    },
    "d36c958ee9615f3f28f09e2f17e71dbd663793af.pdf": {
        "title": "Software Transparency as a Key Requirement for Self-Driving Cars",
        "authors": [
            "L. M. Cysneiros",
            "Majid Raffi",
            "Julio Cesar Sampaio do Prado Leite"
        ],
        "published_date": "2018",
        "abstract": "Self-Driving cars is a fast-growing area of study both in academia and industry. It is part of a broader domain which involves the development of software for Highly Automated Vehicles (HAV) and notions extracted from Artificial Intelligence/Autonomous Systems (AI/AS). There are many challenges that must be overcome to deliver self-driving cars in a manner that is readily accepted by consumers and society. Studies have shown that although many people are comfortable with the idea of AI helping them to operate their houses or schedule appointments, not many people are comfortable with the idea of cars being driven by AI algorithms. At the same time, insurance companies are concerned about vehicle liability issues and how to demonstrate who/what caused an accident. We believe that self-driving cars that demonstrate transparency in their operations will increase consumer trust which is pivotal to its acceptance and will pave the way for its commercialization and daily use. In this work, we investigate how to pursue the elicitation and modeling of transparency as a Non-Functional Requirement (NFR) to produce self-driving cars that are more robust.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/d36c958ee9615f3f28f09e2f17e71dbd663793af.pdf",
        "venue": "IEEE International Requirements Engineering Conference",
        "citationCount": 0,
        "score": 0
    },
    "58090cdbb7526f4e22c09387814ee060dab1de54.pdf": {
        "title": "Requirements Engineering Challenges in Building AI-Based Complex Systems",
        "authors": [
            "H. Belani",
            "M. Vukovi\u0107",
            "Z. Car"
        ],
        "published_date": "2019",
        "abstract": "This paper identifies and tackles the challenges of the requirements engineering discipline when applied to development of AI-based complex systems. Due to their complex behaviour, there is an immanent need for a tailored development process for such systems. However, there is still no widely used and specifically tailored process in place to effectively and efficiently deal with requirements suitable for specifying a software solution that uses machine learning. By analysing the related work from software engineering and artificial intelligence fields, potential contributions have been recognized from agent-based software engineering and goal-oriented requirements engineering research, as well as examples from large product development companies. The challenges have been discussed, with proposals given how and when to tackle them. RE4AI taxonomy has also been outlined, to inform the tailoring of development process.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/58090cdbb7526f4e22c09387814ee060dab1de54.pdf",
        "venue": "2019 IEEE 27th International Requirements Engineering Conference Workshops (REW)",
        "citationCount": 0,
        "score": 0
    },
    "bcd82c396a9076e485300fc2a5207e9cfa77fdce.pdf": {
        "title": "The Use of AI in Software Engineering: A Synthetic Knowledge Synthesis of the Recent Research Literature",
        "authors": [
            "Peter Kokol"
        ],
        "published_date": "2024",
        "abstract": "Artificial intelligence (AI) has witnessed an exponential increase in use in various applications. Recently, the academic community started to research and inject new AI-based approaches to provide solutions to traditional software-engineering problems. However, a comprehensive and holistic understanding of the current status needs to be included. To close the above gap, synthetic knowledge synthesis was used to induce the research landscape of the contemporary research literature on the use of AI in software engineering. The synthesis resulted in 15 research categories and 5 themes\u2014namely, natural language processing in software engineering, use of artificial intelligence in the management of the software development life cycle, use of machine learning in fault/defect prediction and effort estimation, employment of deep learning in intelligent software engineering and code management, and mining software repositories to improve software quality. The most productive country was China (n = 2042), followed by the United States (n = 1193), India (n = 934), Germany (n = 445), and Canada (n = 381). A high percentage (n = 47.4%) of papers were funded, showing the strong interest in this research topic. The convergence of AI and software engineering can significantly reduce the required resources, improve the quality, enhance the user experience, and improve the well-being of software developers.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/bcd82c396a9076e485300fc2a5207e9cfa77fdce.pdf",
        "venue": "Inf.",
        "citationCount": 0,
        "score": 0
    },
    "d8f32d89af6284893c30611f51f1b01798849b26.pdf": {
        "title": "Towards a model-driven approach for multiexperience AI-based user interfaces",
        "authors": [
            "Elena Planas",
            "Gwendal Daniel",
            "Marco Brambilla",
            "Jordi Cabot"
        ],
        "published_date": "2021",
        "abstract": "Software systems start to include other types of interfaces beyond the \u201ctraditional\u201d Graphical-User Interfaces (GUIs). In particular, Conversational User Interfaces (CUIs) such as chat and voice are becoming more and more popular. These new types of interfaces embed smart natural language processing components to understand user requests and respond to them. To provide an integrated user experience all the user interfaces in the system should be aware of each other and be able to collaborate. This is what is known as a multiexperience User Interface. Despite their many benefits, multiexperience UIs are challenging to build. So far CUIs are created as standalone components using a platform-dependent set of libraries and technologies. This raises significant integration, evolution and maintenance issues. This paper explores the application of model-driven techniques to the development of software applications embedding a multiexperience User Interface. We will discuss how raising the abstraction level at which these interfaces are defined enables a faster development and a better deployment and integration of each interface with the rest of the software system and the other interfaces with whom it may need to collaborate. In particular, we propose a new Domain Specific Language (DSL) for specifying several types of CUIs and show how this DSL can be part of an integrated modeling environment able to describe the interactions between the modeled CUIs and the other models of the system (including the models of the GUI). We will use the standard Interaction Flow Modeling Language (IFML) as an example \u201chost\u201d language.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/d8f32d89af6284893c30611f51f1b01798849b26.pdf",
        "venue": "Journal of Software and Systems Modeling",
        "citationCount": 0,
        "score": 0
    },
    "0f6b627a7cb0d31b182fc3c4b512d1e2a036a66b.pdf": {
        "title": "The Transformative Influence of LLMs on Software Development & Developer Productivity",
        "authors": [
            "Sajed Jalil"
        ],
        "published_date": "2023",
        "abstract": "The increasing adoption and commercialization of generalized Large Language Models (LLMs) have profoundly impacted various aspects of our daily lives. Initially embraced by the computer science community, the versatility of LLMs has found its way into diverse domains. In particular, the software engineering realm has seen the most transformative changes. With LLMs increasingly serving as AI Pair Programming Assistants spurred the development of specialized models aimed at aiding software engineers. Although this new paradigm offers numerous advantages, it presents critical challenges and open problems.To identify the potential and prevailing obstacles, we systematically reviewed contemporary scholarly publications, emphasizing the perspectives of software developers and usability concerns. Preliminary findings underscore pressing concerns about data privacy, bias, and misinformation. Additionally, we identified several usability challenges, including prompt engineering, increased cognitive demands, and mistrust. Finally, we introduce 12 open problems identified through our survey, covering these domains.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/0f6b627a7cb0d31b182fc3c4b512d1e2a036a66b.pdf",
        "venue": "2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)",
        "citationCount": 0,
        "score": 0
    },
    "dccd738bc67c1e4b807b07872ff065fadc4253da.pdf": {
        "title": "Towards a Roadmap on Software Engineering for Responsible AI",
        "authors": [
            "Q. Lu",
            "Liming Zhu",
            "Xiwei Xu",
            "J. Whittle",
            "Zhenchang Xing"
        ],
        "published_date": "2022",
        "abstract": "Although AI is transforming the world, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and frameworks for responsible AI have been issued recently. However, they are high level and difficult to put into practice. On the other hand, most AI researchers focus on algorithmic solutions, while the responsible AI challenges actually crosscut the entire engineering lifecycle and components of AI systems. To close the gap in operationalizing responsible AI, this paper aims to develop a roadmap on software engineering for responsible AI. The roadmap focuses on (i) establishing multi-level governance for responsible AI systems, (ii) setting up the development processes incorporating process-oriented practices for responsible AI systems, and (iii) building responsible-AI-by-design into AI systems through system-level architectural style, patterns and techniques. CCS CONCEPTS \u2022 Software and its engineering;",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/dccd738bc67c1e4b807b07872ff065fadc4253da.pdf",
        "venue": "2022 IEEE/ACM 1st International Conference on AI Engineering \u2013 Software Engineering for AI (CAIN)",
        "citationCount": 0,
        "score": 0
    },
    "c4817cb447db4254d7829215fb85207585eb9064.pdf": {
        "title": "AI-Driven Continuous Integration and Continuous Deployment in Software Engineering",
        "authors": [
            "Abdul Sajid Mohammed",
            "Venkata Ramana Saddi",
            "Santhosh Kumar Gopal",
            "S. Dhanasekaran",
            "Mahaveer Singh Naruka"
        ],
        "published_date": "2024",
        "abstract": "AI driven Continuous Integration and Continuous Deployment is a new way of managing and continually updating a software project. This process, powered by Artificial Intelligence, automates the entire software delivery and deployment process - from code submission to monitoring and bug fixing. It eliminates manual errors and allows for multiple versions to be tested in parallel, saving time and effort. By increasing agility, it allows organizations to launch new features to production faster than ever. Continuous Integration and Continuous Deployment leverages artificial intelligence in implementation and execution. It automates the process of integration, testing, packaging and deployment. Furthermore, AI is used to detect and fix bugs which can prevent delays and costly production bugs. AI driven Continuous Integration and Continuous Deployment has become an increasingly popular development strategy. It helps reduce the overall cost and accelerate the software's production cycles, making it easier for developers to quickly get their features and services in the hands of the market.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/c4817cb447db4254d7829215fb85207585eb9064.pdf",
        "venue": "International Conference on Database Theory",
        "citationCount": 0,
        "score": 0
    },
    "1bc2fdf256855c485e77be27805f9febf9a70e75.pdf": {
        "title": "POLARIS: A framework to guide the development of Trustworthy AI systems",
        "authors": [
            "M. T. Baldassarre",
            "Domenico Gigante",
            "Marcos Kalinowski",
            "Azzurra Ragone"
        ],
        "published_date": "2024",
        "abstract": "In the ever-expanding landscape of Artificial Intelligence (AI), where innovation thrives and new products and services are continuously being delivered, ensuring that AI systems are designed and developed responsibly throughout their entire lifecycle is crucial. To this end, several AI ethics principles and guidelines have been issued to which AI systems should conform. Nevertheless, relying solely on high-level AI ethics principles is far from sufficient to ensure the responsible engineering of AI systems. In this field, AI professionals often navigate by sight. Indeed, while recommendations promoting Trustworthy AI (TAI) exist, they are often high-level statements difficult to translate into concrete implementation strategies. Currently, there is a significant gap between high-level AI ethics principles and low-level concrete practices for AI professionals. To address this challenge, our work presents an experience report where we develop a novel holistic framework for Trustworthy AI \u2014 designed to bridge the gap between theory and practice \u2014 and report insights from its application in an industrial case study. The framework builds up from the results of a systematic review of the state of the practice as well as a survey and think-aloud interviews with 34 AI practitioners. The framework, unlike most of the ones in literature, is designed to provide actionable guidelines and tools to support different types of stakeholders throughout the entire Software Development Life Cycle (SDLC). Our goal is to empower AI professionals to confidently navigate the ethical dimensions of TAI through practical insights, ensuring that the vast potential of AI is exploited responsibly for the benefit of society as a whole.CCS CONCEPTS\u2022 Computing methodologies \u2192 Artificial intelligence; \u2022 Software and its engineering \u2192 Software creation and management.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/1bc2fdf256855c485e77be27805f9febf9a70e75.pdf",
        "venue": "2024 IEEE/ACM 3rd International Conference on AI Engineering \u2013 Software Engineering for AI (CAIN)",
        "citationCount": 0,
        "score": 0
    },
    "a80cb0325b78c303916cb66d6d33fe0aed8c8311.pdf": {
        "title": "Towards AI-Native Software Engineering (SE 3.0): A Vision and a Challenge Roadmap",
        "authors": [
            "Ahmed E. Hassan",
            "G. Oliva",
            "Dayi Lin",
            "Boyuan Chen",
            "Zhen Ming Jiang"
        ],
        "published_date": "2024",
        "abstract": "The rise of AI-assisted software engineering (SE 2.0), powered by Foundation Models (FMs) and FM-powered copilots, has shown promise in improving developer productivity. However, it has also exposed inherent limitations, such as cognitive overload on developers and inefficiencies. We propose a shift towards Software Engineering 3.0 (SE 3.0), an AI-native approach characterized by intent-first, conversation-oriented development between human developers and AI teammates. SE 3.0 envisions AI systems evolving beyond task-driven copilots into intelligent collaborators, capable of deeply understanding and reasoning about software engineering principles and intents. We outline the key components of the SE 3.0 technology stack, which includes Teammate.next for adaptive and personalized AI partnership, IDE.next for intent-first conversation-oriented development, Compiler.next for multi-objective code synthesis, and Runtime.next for SLA-aware execution with edge-computing support. Our vision addresses the inefficiencies and cognitive strain of SE 2.0 by fostering a symbiotic relationship between human developers and AI, maximizing their complementary strengths. We also present a roadmap of challenges that must be overcome to realize our vision of SE 3.0. This paper lays the foundation for future discussions on the role of AI in the next era of software engineering.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/a80cb0325b78c303916cb66d6d33fe0aed8c8311.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "d16ed45e038674d1597e6a3e9b7fa1e9f57c8457.pdf": {
        "title": "Towards an AI\u2010driven business development framework: A multi\u2010case study",
        "authors": [
            "Meenu Mary John",
            "H. H. Olsson",
            "Jan Bosch"
        ],
        "published_date": "2022",
        "abstract": "Artificial intelligence (AI) and the use of machine learning (ML) and deep learning (DL) technologies are becoming increasingly popular in companies. These technologies enable companies to leverage big quantities of data to improve system performance and accelerate business development. However, despite the appeal of ML/DL, there is a lack of systematic and structured methods and processes to help data scientists and other company roles and functions to develop, deploy and evolve models. In this paper, based on multi\u2010case study research in six companies, we explore practices and challenges practitioners experience in developing ML/DL models as part of large software\u2010intensive embedded systems. Based on our empirical findings, we derive a conceptual framework in which we identify three high\u2010level activities that companies perform in parallel with the development, deployment and evolution of models. Within this framework, we outline activities, iterations and triggers that optimize model design as well as roles and company functions. In this way, we provide practitioners with a blueprint for effectively integrating ML/DL model development into the business to achieve better results than other (algorithmic) approaches. In addition, we show how this framework helps companies solve the challenges we have identified and discuss checkpoints for terminating the business case.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/d16ed45e038674d1597e6a3e9b7fa1e9f57c8457.pdf",
        "venue": "J. Softw. Evol. Process.",
        "citationCount": 0,
        "score": 0
    },
    "ad44a987fd8828c2ba93ccca6d20c80994b3b9cf.pdf": {
        "title": "Solving Separation-of-Concerns Problems in Collaborative Design of Human-AI Systems through Leaky Abstractions",
        "authors": [
            "Hariharan Subramonyam",
            "Jane Im",
            "C. Seifert",
            "Eytan Adar"
        ],
        "published_date": "2022",
        "abstract": "In conventional software development, user experience (UX) designers and engineers collaborate through separation of concerns (SoC): designers create human interface specifications, and engineers build to those specifications. However, we argue that Human-AI systems thwart SoC because human needs must shape the design of the AI interface, the underlying AI sub-components, and training data. How do designers and engineers currently collaborate on AI and UX design? To find out, we interviewed 21 industry professionals (UX researchers, AI engineers, data scientists, and managers) across 14 organizations about their collaborative work practices and associated challenges. We find that hidden information encapsulated by SoC challenges collaboration across design and engineering concerns. Practitioners describe inventing ad-hoc representations exposing low-level design and implementation details (which we characterize as leaky abstractions) to \u201cpuncture\u201d SoC and share information across expertise boundaries. We identify how leaky abstractions are employed to collaborate at the AI-UX boundary and formalize a process of creating and using leaky abstractions.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/ad44a987fd8828c2ba93ccca6d20c80994b3b9cf.pdf",
        "venue": "International Conference on Human Factors in Computing Systems",
        "citationCount": 0,
        "score": 0
    },
    "21c6beb2a6df81f424e3d1283fbb9cc3157a3115.pdf": {
        "title": "A Taxonomy of Software Engineering Challenges for Machine Learning Systems: An Empirical Investigation",
        "authors": [
            "Lucy Ellen Lwakatare",
            "Aiswarya Raj",
            "J. Bosch",
            "H. H. Olsson",
            "I. Crnkovic"
        ],
        "published_date": "2019",
        "abstract": "Artificial intelligence enabled systems have been an inevitable part of everyday life. However, efficient software engineering principles and processes need to be considered and extended when developing AI- enabled systems. The objective of this study is to identify and classify software engineering challenges that are faced by different companies when developing software-intensive systems that incorporate machine learning components. Using case study approach, we explored the development of machine learning systems from six different companies across various domains and identified main software engineering challenges. The challenges are mapped into a proposed taxonomy that depicts the evolution of use of ML components in software-intensive system in industrial settings. Our study provides insights to software engineering community and research to guide discussions and future research into applied machine learning.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/21c6beb2a6df81f424e3d1283fbb9cc3157a3115.pdf",
        "venue": "International Conference on Agile Software Development",
        "citationCount": 0,
        "score": 0
    },
    "41e2d221f01ecbf0fa76124c9fb2fdcc5f890112.pdf": {
        "title": "Ethically Aligned Design: An Empirical Evaluation of the RESOLVEDD-Strategy in Software and Systems Development Context",
        "authors": [
            "Ville Vakkuri",
            "Kai-Kristian Kemell",
            "P. Abrahamsson"
        ],
        "published_date": "2019",
        "abstract": "Use of artificial intelligence (AI) in human contexts calls for ethical considerations for the design and development of AI-based systems. However, little knowledge currently exists on how to provide useful and tangible tools that could help software developers and designers implement ethical considerations into practice. In this paper, we empirically evaluate a method that enables ethically aligned design in a decision-making process. Though this method, titled the RESOLVEDD strategy, originates from the field of business ethics, it is being applied in other fields as well. We tested the RESOLVEDD strategy in a multiple case study of five student projects where the use of ethical tools was given as one of the design requirements. A key finding from the study indicates that simply the presence of an ethical tool has an effect on ethical consideration, creating more responsibility even in instances where the use of the tool is not intrinsically motivated.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/41e2d221f01ecbf0fa76124c9fb2fdcc5f890112.pdf",
        "venue": "EUROMICRO Conference on Software Engineering and Advanced Applications",
        "citationCount": 0,
        "score": 0
    },
    "ec6a82e2c7d8ebdc0221580753048542db72ca27.pdf": {
        "title": "Human-AI Experience in Integrated Development Environments: A Systematic Literature Review",
        "authors": [
            "Agnia Sergeyuk",
            "Ilya Zakharov",
            "Ekaterina Koshchenko",
            "Maliheh Izadi"
        ],
        "published_date": "2025",
        "abstract": "The integration of Artificial Intelligence (AI) into Integrated Development Environments (IDEs) is reshaping software development, fundamentally altering how developers interact with their tools. This shift marks the emergence of Human-AI Experience in Integrated Development Environment (in-IDE HAX), a field that explores the evolving dynamics of Human-Computer Interaction in AI-assisted coding environments. Despite rapid adoption, research on in-IDE HAX remains fragmented, which highlights the need for a unified overview of current practices, challenges, and opportunities. To provide a structured overview of existing research, we conduct a systematic literature review of 90 studies, summarizing current findings and outlining areas for further investigation. We organize key insights from reviewed studies into three aspects: Impact, Design, and Quality of AI-based systems inside IDEs. Impact findings show that AI-assisted coding enhances developer productivity but also introduces challenges, such as verification overhead and over-reliance. Design studies show that effective interfaces surface context, provide explanations and transparency of suggestion, and support user control. Quality studies document risks in correctness, maintainability, and security. For future research, priorities include productivity studies, design of assistance, and audit of AI-generated code. The agenda calls for larger and longer evaluations, stronger audit and verification assets, broader coverage across the software life cycle, and adaptive assistance under user control.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/ec6a82e2c7d8ebdc0221580753048542db72ca27.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "4d3e1d7aebf1bbfe7191e45f844d61f93617b569.pdf": {
        "title": "Agility in Software 2.0 - Notebook Interfaces and MLOps with Buttresses and Rebars",
        "authors": [
            "Markus Borg"
        ],
        "published_date": "2021",
        "abstract": "Artificial intelligence through machine learning is increasingly used in the digital society. Solutions based on machine learning bring both great opportunities, thus coined\"Software 2.0,\"but also great challenges for the engineering community to tackle. Due to the experimental approach used by data scientists when developing machine learning models, agility is an essential characteristic. In this keynote address, we discuss two contemporary development phenomena that are fundamental in machine learning development, i.e., notebook interfaces and MLOps. First, we present a solution that can remedy some of the intrinsic weaknesses of working in notebooks by supporting easy transitions to integrated development environments. Second, we propose reinforced engineering of AI systems by introducing metaphorical buttresses and rebars in the MLOps context. Machine learning-based solutions are dynamic in nature, and we argue that reinforced continuous engineering is required to quality assure the trustworthy AI systems of tomorrow.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/4d3e1d7aebf1bbfe7191e45f844d61f93617b569.pdf",
        "venue": "International Conference on Lean and Agile Software Development",
        "citationCount": 0,
        "score": 0
    },
    "07358d921b00ccfad1ea2fdbe8eb5f73d4ed5f12.pdf": {
        "title": "From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures",
        "authors": [
            "Tobias Eisenreich",
            "Sandro Speth",
            "Stefan Wagner"
        ],
        "published_date": "2024",
        "abstract": "Designing domain models and software architectures represents a significant challenge in software development, as the resulting architectures play a vital role in fulfilling the system\u2019s quality of service. Due to time pressure, architects often model only one architecture based on their known limited domain understanding, patterns, and experience instead of thoroughly analyzing the domain and evaluating multiple candidates, selecting the best fitting. Existing approaches try to generate domain models based on requirements, but still require time-consuming manual effort to achieve good results. Therefore, in this vision paper, we propose a method to generate software architecture candidates semi-automatically based on requirements using artificial intelligence techniques. We further envision an automatic evaluation and trade-off analysis of the generated architecture candidates using, e.g., the architecture trade-off analysis method combined with large language models and quantitative analyses. To evaluate this approach, we aim to analyze the quality of the generated architecture models and the efficiency and effectiveness of our proposed process by conducting qualitative studies.CCS CONCEPTS \u2022 Software and its engineering \u2192 Designing software; Software architectures; System description languages; \u2022 Computing methodologies \u2192 Artificial intelligence.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/07358d921b00ccfad1ea2fdbe8eb5f73d4ed5f12.pdf",
        "venue": "2024 IEEE/ACM International Workshop on Designing Software (Designing)",
        "citationCount": 0,
        "score": 0
    },
    "877ae5a0bc9eb975d23467a13459a028f2ac8774.pdf": {
        "title": "DevOps for AI \u2013 Challenges in Development of AI-enabled Applications",
        "authors": [
            "Lucy Ellen Lwakatare",
            "I. Crnkovic",
            "J. Bosch"
        ],
        "published_date": "2020",
        "abstract": "When developing software systems that contain Machine Learning (ML) based components, the development process become significantly more complex. The central part of the ML process is training iterations to find the best possible prediction model. Modern software development processes, such as DevOps, have widely been adopted and typically emphasise frequent development iterations and continuous delivery of software changes. Despite the ability of modern approaches in solving some of the problems faced when building ML-based software systems, there are no established procedures on how to combine them with processes in ML workflow in practice today. This paper points out the challenges in development of complex systems that include ML components, and discuss possible solutions driven by the combination of DevOps and ML workflow processes. Industrial cases are presented to illustrate these challenges and the possible solutions.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/877ae5a0bc9eb975d23467a13459a028f2ac8774.pdf",
        "venue": "International Conference on Software, Telecommunications and Computer Networks",
        "citationCount": 0,
        "score": 0
    },
    "9644a2716a1be2562f1bb8f4d7929871050dd8cd.pdf": {
        "title": "Artificial Intelligence in Software Requirements Engineering: State-of-the-Art",
        "authors": [
            "Kaihua Liu",
            "S. Reddivari",
            "Kalyan Reddivari"
        ],
        "published_date": "2022",
        "abstract": "Requirements Engineering (RE) is a very important activity in the software development life cycle. Poorly executed RE steps can result in poor quality software and expensive maintenance cost. Although researchers have previously related and applied artificial intelligence (AI) to RE, little is known about the specific role of AI in RE process. In particular, there are insufficient understandings about how AI should be incorporated in the RE process to produce high quality, clear and detailed requirements. In this paper, we present the current state-of-the-art of AI in RE. We reviewed the literature published between January 2015 to December 2021 in order to understand how the state of the art of AI branches such as machine learning, classification, and natural language processing (NLP) has advanced the field of RE. Each recent study is summarized and the advancement to the RE field is presented. There is an apparent direction of applying NLP techniques and supervised learning techniques such as classification to requirements documents. This study provides a summary and direction of the AI applications in the field of RE.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/9644a2716a1be2562f1bb8f4d7929871050dd8cd.pdf",
        "venue": "IEEE International Conference on Information Reuse and Integration",
        "citationCount": 0,
        "score": 0
    },
    "e80189322adf7a079e99b4f1e628307b29ae8e2c.pdf": {
        "title": "A Systematic Literature Review of AI-Based Software Requirements Prioritization Techniques",
        "authors": [
            "Rahila Anwar",
            "Muhammad Bilal Bashir"
        ],
        "published_date": "2023",
        "abstract": "Software requirements show what the customer desires his software to do. They are the first stepping stone towards a successful software development project. With the increasing complexity of the software due to its size and feature base, it is vital to prioritize the requirements for efficient utilization of development resources. To achieve this, industrial organizations are devising new strategies and improved solutions even with the help of artificial intelligence (AI) tool set. Existing requirements prioritization techniques are human-intensive and suffer from several limitations like overlapping outcomes, scalability problems, time consumption, inaccuracy, and so on. Some of the problems can be solved by including artificial intelligence algorithms and strategies. Several AI-based requirements prioritization techniques have been proposed by applying Genetic Algorithms, Fuzzy Logic, Ant Colony Optimization, and Machine Learning. Literature witnesses some good review studies and surveys on conventional prioritization techniques but there exists none for AI-based techniques that identify not only their strengths but also their weaknesses, advantages of machine learning techniques over other AI-based requirements prioritization techniques, and limitations of applying AI-based techniques in requirements prioritization. This study presents a systematic literature review (SLR) of AI-based requirements prioritization approaches covering 46 papers published from 2000 to 2021. We have given this literature review a new dimension by conducting a parametric analysis of AI-based requirements prioritization techniques and we have identified these parameters after a thorough literature study. Some of the chosen parameters are generic (related to the prioritization process) and some are specific (related to AI techniques). This study has greatly helped us draw a clear line among AI-based techniques to show their domain of application to gain maximum advantage. Our findings will assist researchers, requirement analysts, and other stakeholders in making a wise decision to select the best requirements prioritization technique to gain optimal results.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/e80189322adf7a079e99b4f1e628307b29ae8e2c.pdf",
        "venue": "IEEE Access",
        "citationCount": 0,
        "score": 0
    },
    "ff8c9fdd9d5a1d63a10abfd114c9f47b1a9d6160.pdf": {
        "title": "AI-Driven Innovations in Software Engineering: A Review of Current Practices and Future Directions",
        "authors": [
            "M. Alenezi",
            "Mohammed Akour"
        ],
        "published_date": "2025",
        "abstract": "The software engineering landscape is undergoing a significant transformation with the advent of artificial intelligence (AI). AI technologies are poised to redefine traditional software development practices, offering innovative solutions to long-standing challenges. This paper explores the integration of AI into software engineering processes, aiming to identify its impacts, benefits, and the challenges that accompany this paradigm shift. A comprehensive analysis of current AI applications in software engineering is conducted, supported by case studies and theoretical models. The study examines various phases of software development to assess where AI contributes most effectively. The integration of AI enhances productivity, improves code quality, and accelerates development cycles. Key areas of impact include automated code generation, intelligent debugging, predictive maintenance, and enhanced decision-making processes. AI is revolutionizing software engineering by introducing automation and intelligence into the development lifecycle. Embracing AI-driven tools and methodologies is essential for staying competitive in the evolving technological landscape.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/ff8c9fdd9d5a1d63a10abfd114c9f47b1a9d6160.pdf",
        "venue": "Applied Sciences",
        "citationCount": 0,
        "score": 0
    },
    "bbab45f57c7c0be7371d7139cf2aafb5772eaa9f.pdf": {
        "title": "Rethinking Software Engineering in the Foundation Model Era: From Task-Driven AI Copilots to Goal-Driven AI Pair Programmers",
        "authors": [
            "Ahmed E. Hassan",
            "G. Oliva",
            "Dayi Lin",
            "Boyuan Chen",
            "Zhen Ming Jiang"
        ],
        "published_date": "2024",
        "abstract": "The advent of Foundation Models (FMs) and AI-powered copilots has transformed the landscape of software development, offering unprecedented code completion capabilities and enhancing developer productivity. However, the current task-driven nature of these copilots falls short in addressing the broader goals and complexities inherent in software engineering (SE). In this paper, we propose a paradigm shift towards goal-driven AI-powered pair programmers that collaborate with human developers in a more holistic and context-aware manner. We envision AI pair programmers that are goal-driven, human partners, SE-aware, and self-learning. These AI partners engage in iterative, conversation-driven development processes, aligning closely with human goals and facilitating informed decision-making. We discuss the desired attributes of such AI pair programmers and outline key challenges that must be addressed to realize this vision. Ultimately, our work represents a shift from AI-augmented SE to AI-transformed SE by replacing code completion with a collaborative partnership between humans and AI that enhances both productivity and software quality.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/bbab45f57c7c0be7371d7139cf2aafb5772eaa9f.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "6564470d2722c273725b219f90cc9f90428eb95a.pdf": {
        "title": "Generative Artificial Intelligence Assistants in Software Development Education: A Vision for Integrating Generative Artificial Intelligence Into Educational Practice, Not Instinctively Defending Against It",
        "authors": [
            "Christopher Bull",
            "Ahmed Kharrufa"
        ],
        "published_date": "2023",
        "abstract": "The use of Generative AI in software development is gaining traction. But what are the potentials and implications on software development education? We gathered insights on the use of Generative AI from professional software developers and make some pedagogical recommendations.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/6564470d2722c273725b219f90cc9f90428eb95a.pdf",
        "venue": "IEEE Software",
        "citationCount": 0,
        "score": 0
    },
    "ddf9c0171474737e81ef5a9bb9caac12d2ea0818.pdf": {
        "title": "A Roadmap for Software Testing in Open Collaborative Development Environments",
        "authors": [
            "Qing Wang",
            "Junjie Wang",
            "Mingyang Li",
            "Yawen Wang",
            "Zhe Liu"
        ],
        "published_date": "2024",
        "abstract": "Amidst the ever-expanding digital sphere, the evolution of the Internet has not only fostered an atmosphere of information transparency and sharing but has also sparked a revolution in software development practices. The distributed nature of open collaborative development, along with its diverse contributors and rapid iterations, presents new challenges for ensuring software quality. This paper offers a comprehensive review and analysis of recent advancements in software quality assurance within open collaborative development environments. Our examination covers various aspects, including process management, personnel dynamics, and technological advancements, providing valuable insights into effective approaches for maintaining software quality in such collaborative settings. Furthermore, we delve into the challenges and opportunities arising from emerging technologies such as LLMs and the AI model-centric development paradigm. By addressing these topics, our study contributes to a deeper understanding of software quality assurance in open collaborative environments and lays the groundwork for future exploration and innovation.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/ddf9c0171474737e81ef5a9bb9caac12d2ea0818.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "f3ba6031011181b406bb9ae426d42aa74f66eb34.pdf": {
        "title": "Vibe Coding as a Reconfiguration of Intent Mediation in Software Development: Definition, Implications, and Research Agenda",
        "authors": [
            "Christian Meske",
            "Tobias Hermanns",
            "Esther von der Weiden",
            "Kai-Uwe Loser",
            "Thorsten Berger"
        ],
        "published_date": "2025",
        "abstract": "Software development is undergoing a fundamental transformation as vibe coding becomes widespread, with large portions of contemporary codebases now being AI-generated. The disconnect between rapid adoption and limited conceptual understanding highlights the need for an inquiry into this emerging paradigm. Drawing on an intent perspective and historical analysis, we define vibe coding as a software development paradigm where humans and generative AI engage in collaborative flow to co-create software artifacts through natural language dialogue, shifting the mediation of developer intent from deterministic instruction to probabilistic inference. By intent mediation, we refer to the fundamental process through which developers translate their conceptual goals into representations that computational systems can execute. Our results show that vibe coding reconfigures cognitive work by redistributing epistemic labor between humans and machines, shifting the expertise in the software development process away from traditional areas such as design or technical implementation toward collaborative orchestration. We identify key opportunities, including democratization, acceleration, and systemic leverage, alongside risks, such as black box codebases, responsibility gaps, and ecosystem bias. We conclude with a research agenda spanning human-, technology-, and organization-centered directions to guide future investigations of this paradigm.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/f3ba6031011181b406bb9ae426d42aa74f66eb34.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "712171098cc0bf2280fdf0cec1d803d6db05e18f.pdf": {
        "title": "The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot",
        "authors": [
            "Fangchen Song",
            "Ashish Agarwal",
            "Wen Wen"
        ],
        "published_date": "2024",
        "abstract": "Generative artificial intelligence (AI) enables automated content production, including coding in software development, which can significantly influence developer participation and performance. To explore its impact on collaborative open-source software (OSS) development, we investigate the role of GitHub Copilot, a generative AI pair programmer, in OSS development where multiple distributed developers voluntarily collaborate. Using GitHub's proprietary Copilot usage data, combined with public OSS repository data obtained from GitHub, we find that Copilot use increases project-level code contributions by 5.9%. This gain is driven by a 2.1% increase in individual code contributions and a 3.4% rise in developer coding participation. However, these benefits come at a cost as coordination time for code integration increases by 8% due to more code discussions enabled by AI pair programmers. This reveals an important tradeoff: While AI expands who can contribute and how much they contribute, it slows coordination in collective development efforts. Despite this tension, the combined effect of these two competing forces remains positive, indicating a net gain in overall project-level productivity from using AI pair programmers. Interestingly, we also find the effects differ across developer roles. Peripheral developers show relatively smaller gains in project-level code contributions and face a higher increase in coordination time than core developers, likely due to the difference in their project familiarity. In summary, our study underscores the dual role of AI pair programmers in affecting project-level code contributions and coordination time in OSS development. Our findings on the differential effects between core and peripheral developers also provide important implications for the structure of OSS communities in the long run.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/712171098cc0bf2280fdf0cec1d803d6db05e18f.pdf",
        "venue": "Social Science Research Network",
        "citationCount": 0,
        "score": 0
    },
    "349d4d616904f60b02b4b4983a3da185eb77ae9b.pdf": {
        "title": "Generative AI for Productivity in Industry and Education",
        "authors": [
            "Ferenc H\u00e9jja",
            "Tam\u00e1s Bart\u00f3k",
            "Roy Dakroub",
            "G. Kocsis"
        ],
        "published_date": "2024",
        "abstract": ": Generative AI tools are the cutting edge solutions of complex AI related problems. While investigating state-of-the-art results related to the effect of GenAI in the literature, one can note that the trends most likely lead to the expectation of a positive effect on the middle and long run. Based on these \ufb01ndings we de\ufb01ne 4 productivity gain related hypotheses that we study using two types of methodologies. Namely we perform a survey research related to university-industry collaboration and quantitative studies mainly based on industrial productivity metrics. We have partnered with a major IT services provider - EPAM Systems - to be able to track, validate and analyze the key productivity metrics of software development projects, with and without using GenAI tools. This evaluation is being performed on various stages of the Software Development Lifecycle (SDLC) and on several project roles. Our goal is to measure the productivity increase provided by GenAI tools. Although this research has just started recently, considering that the area has extremely high attention we present some initial \ufb01ndings.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/349d4d616904f60b02b4b4983a3da185eb77ae9b.pdf",
        "venue": "International Conference on Complex Information Systems",
        "citationCount": 0,
        "score": 0
    },
    "143b7f6d594c1678a229591ec6918eeab0e25f0c.pdf": {
        "title": "A Maturity Model for Trustworthy AI Software Development",
        "authors": [
            "Seunghwan Cho",
            "Ingyu Kim",
            "Jinhan Kim",
            "Honguk Woo",
            "Wanseon Shin"
        ],
        "published_date": "2023",
        "abstract": "Recently, AI software has been rapidly growing and is widely used in various industrial domains, such as finance, medicine, robotics, and autonomous driving. Unlike traditional software, in which developers need to define and implement specific functions and rules according to requirements, AI software learns these requirements by collecting and training relevant data. For this reason, if unintended biases exist in the training data, AI software can create fairness and safety issues. To address this challenge, we propose a maturity model for ensuring trustworthy and reliable AI software, known as AI-MM, by considering common AI processes and fairness-specific processes within a traditional maturity model, SPICE (ISO/IEC 15504). To verify the effectiveness of AI-MM, we applied this model to 13 real-world AI projects and provide a statistical assessment on them. The results show that AI-MM not only effectively measures the maturity levels of AI projects but also provides practical guidelines for enhancing maturity levels.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/143b7f6d594c1678a229591ec6918eeab0e25f0c.pdf",
        "venue": "Applied Sciences",
        "citationCount": 0,
        "score": 0
    },
    "a0650855634a156db81a01dcdceff931e9f1ac04.pdf": {
        "title": "The Soar Cognitive Architecture",
        "authors": [
            "J. Laird"
        ],
        "published_date": "2012",
        "abstract": "",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/a0650855634a156db81a01dcdceff931e9f1ac04.pdf",
        "venue": "",
        "citationCount": 0,
        "score": 0
    },
    "e8c2e39fb06bb666efe3476e820c5cef7f1c484a.pdf": {
        "title": "Trust Dynamics in AI-Assisted Development: Definitions, Factors, and Implications",
        "authors": [
            "Sadra Sabouri",
            "Philipp Eibl",
            "Xinyi Zhou",
            "Morteza Ziyadi",
            "Nenad Medvidovic",
            "Lars Lindemann",
            "Souti Chattopadhyay"
        ],
        "published_date": "2025",
        "abstract": "Software developers increasingly rely on AI code generation utilities. To ensure that \u201cgood\u201d code is accepted into the code base and \u201cbad\u201d code is rejected, developers must know when to trust an AI suggestion. Understanding how developers build this intuition is crucial to enhancing developer-AI collaborative programming. In this paper, we seek to understand how developers (1) define and (2) evaluate the trustworthiness of a code suggestion and (3) how trust evolves when using AI code assistants. To answer these questions, we conducted a mixed method study consisting of an in-depth exploratory survey with (n=29) developers followed by an observation study (n=10). We found that comprehensibility and perceived correctness were the most frequently used factors to evaluate code suggestion trustworthiness. However, the gap in developers' definition and evaluation of trust points to a lack of support for evaluating trustworthy code in real-time. We also found that developers often alter their trust decisions, keeping only 52% of original suggestions. Based on these findings, we extracted four guidelines to enhance developer-AI interactions. We validated the guidelines through a survey with (n=7) domain experts and survey members (n=8). We discuss the validated guidelines, how to apply them, and tools to help adopt them.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/e8c2e39fb06bb666efe3476e820c5cef7f1c484a.pdf",
        "venue": "International Conference on Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "621373b686f700a35cf8cc381db1630ba857a260.pdf": {
        "title": "The Evolution of Information Seeking in Software Development: Understanding the Role and Impact of AI Assistants",
        "authors": [
            "Ebtesam Al Haque",
            "Chris Brown",
            "Thomas D. Latoza",
            "Brittany Johnson"
        ],
        "published_date": "2024",
        "abstract": "About 32% of a software practitioners' day involves seeking and using information to support task completion. Although the information needs of software practitioners have been studied extensively, the impact of AI-assisted tools on their needs and information-seeking behaviors remains largely unexplored. To addresses this gap, we conducted a mixed-method study to understand AI-assisted information seeking behavior of practitioners and its impact on their perceived productivity and skill development. We found that developers are increasingly using AI tools to support their information seeking, citing increased efficiency as a key benefit. Our findings also amplify caveats that come with effectively using AI tools for information seeking, especially for learning and skill development, such as the importance of foundational developer knowledge that can guide and inform the information provided by AI tools. Our efforts have implications for the effective integration of AI tools into developer workflows as information retrieval systems and learning aids.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/621373b686f700a35cf8cc381db1630ba857a260.pdf",
        "venue": "SIGSOFT FSE Companion",
        "citationCount": 0,
        "score": 0
    },
    "1d07e5b6f978cf69c0186f3d5f434fa92d471e46.pdf": {
        "title": "OpenHands: An Open Platform for AI Software Developers as Generalist Agents",
        "authors": [
            "Xingyao Wang",
            "Boxuan Li",
            "Yufan Song",
            "Frank F. Xu",
            "Xiangru Tang",
            "Mingchen Zhuge",
            "Jiayi Pan",
            "Yueqi Song",
            "Bowen Li",
            "Jaskirat Singh",
            "Hoang H. Tran",
            "Fuqiang Li",
            "Ren Ma",
            "Mingzhang Zheng",
            "Bill Qian",
            "Yanjun Shao",
            "Niklas Muennighoff",
            "Yizhe Zhang",
            "Binyuan Hui",
            "Junyang Lin",
            "Robert Brennan",
            "Hao Peng",
            "Heng Ji",
            "Graham Neubig"
        ],
        "published_date": "2024",
        "abstract": "Software is one of the most powerful tools that we humans have at our disposal; it allows a skilled programmer to interact with the world in complex and profound ways. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and affect change in their surrounding environments. In this paper, we introduce OpenHands (f.k.a. OpenDevin), a platform for the development of powerful and flexible AI agents that interact with the world in similar ways to those of a human developer: by writing code, interacting with a command line, and browsing the web. We describe how the platform allows for the implementation of new agents, safe interaction with sandboxed environments for code execution, coordination between multiple agents, and incorporation of evaluation benchmarks. Based on our currently incorporated benchmarks, we perform an evaluation of agents over 15 challenging tasks, including software engineering (e.g., SWE-BENCH) and web browsing (e.g., WEBARENA), among others. Released under the permissive MIT license, OpenHands is a community project spanning academia and industry with more than 2.1K contributions from over 188 contributors.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/1d07e5b6f978cf69c0186f3d5f434fa92d471e46.pdf",
        "venue": "International Conference on Learning Representations",
        "citationCount": 0,
        "score": 0
    },
    "b5187ab65ad87597e880505a66b048497a8c4a8d.pdf": {
        "title": "Transforming Software Development with Generative AI: Empirical Insights on Collaboration and Workflow",
        "authors": [
            "Rasmus Ulfsnes",
            "N. B. Moe",
            "V. Stray",
            "Marianne Skarpen"
        ],
        "published_date": "2024",
        "abstract": "Generative AI (GenAI) has fundamentally changed how knowledge workers, such as software developers, solve tasks and collaborate to build software products. Introducing innovative tools like ChatGPT and Copilot has created new opportunities to assist and augment software developers across various problems. We conducted an empirical study involving interviews with 13 data scientists, managers, developers, designers, and frontend developers to investigate the usage of GenAI. Our study reveals that ChatGPT signifies a paradigm shift in the workflow of software developers. The technology empowers developers by enabling them to work more efficiently, speed up the learning process, and increase motivation by reducing tedious and repetitive tasks. Moreover, our results indicate a change in teamwork collaboration due to software engineers using GenAI for help instead of asking co-workers which impacts the learning loop in agile teams.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/b5187ab65ad87597e880505a66b048497a8c4a8d.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "03ad5415b3f2945b7e9481a37bbde18b82cb901a.pdf": {
        "title": "Integrating Generative AI into the Software Development Lifecycle: Impacts on Code Quality and Maintenance",
        "authors": [
            "Ayyappa Sajja",
            "Dheerender Thakur",
            "Aditya Mehra"
        ],
        "published_date": "2024",
        "abstract": "Recent advances in generative AI have depicted it as a revolutionary approach in the software development technologies pioneered to improve the codes' reliability and sustain their quality and performance. Generative AI tools can help develop code independently, suggest intelligent solutions and ideas, and enhance several development procedures thanks to superior algorithms and machine learning features. This paper discusses how generative AI can/has been applied within software development to achieve the following three goals: First, to increase the code quality using automated code generation/review. Second, the code maintainability should be improved through standards and documentation. Third, to increase the up-to-speed development productivity due to AI-based automation, namely the automation of repetitive tasks and fast prototyping. The paper also considers issues and difficulties that can be tied to AI in this context: problems of dependence on AI, ethical and security issues, and technical imperfections. Finally, the implications of generative AI in software development in the future are presented, which can open a new direction in the development of software products while primarily pointing to the processes of managing the introduction of generative AI. Using the evaluation of the current possibilities and future perspectives of generative AI presented in this paper, one can conclude its impact on the future of software engineering.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/03ad5415b3f2945b7e9481a37bbde18b82cb901a.pdf",
        "venue": "International Journal of Science and Research Archive",
        "citationCount": 0,
        "score": 0
    },
    "a78b0eb79ddc4b17ac16b4b599e7ee8aca12036d.pdf": {
        "title": "Using AI Assistants in Software Development: A Qualitative Study on Security Practices and Concerns",
        "authors": [
            "J. Klemmer",
            "Stefan Albert Horstmann",
            "Nikhil Patnaik",
            "Cordelia Ludden",
            "Cordell Burton",
            "Carson Powers",
            "Fabio Massacci",
            "Akond Rahman",
            "Daniel Votipka",
            "H. Lipford",
            "Awais Rashid",
            "Alena Naiakshina",
            "Sascha Fahl Cispa Helmholtz Center for Information Security",
            "R. Bochum",
            "U. Bristol",
            "Tufts University",
            "V. U. Amsterdam",
            "U. Trento",
            "Auburn University",
            "University of North Carolina at Charlotte"
        ],
        "published_date": "2024",
        "abstract": "Following the recent release of AI assistants, such as OpenAI's ChatGPT and GitHub Copilot, the software industry quickly utilized these tools for software development tasks, e.g., generating code or consulting AI for advice. While recent research has demonstrated that AI-generated code can contain security issues, how software professionals balance AI assistant usage and security remains unclear. This paper investigates how software professionals use AI assistants in secure software development, what security implications and considerations arise, and what impact they foresee on security in software development. We conducted 27 semi-structured interviews with software professionals, including software engineers, team leads, and security testers. We also reviewed 190 relevant Reddit posts and comments to gain insights into the current discourse surrounding AI assistants for software development. Our analysis of the interviews and Reddit posts finds that, despite many security and quality concerns, participants widely use AI assistants for security-critical tasks, e.g., code generation, threat modeling, and vulnerability detection. Participants' overall mistrust leads to checking AI suggestions in similar ways to human code. However, they expect improvements and, therefore, a heavier use of AI for security tasks in the future. We conclude with recommendations for software professionals to critically check AI suggestions, for AI creators to improve suggestion security and capabilities for ethical security tasks, and for academic researchers to consider general-purpose AI in software development.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/a78b0eb79ddc4b17ac16b4b599e7ee8aca12036d.pdf",
        "venue": "Conference on Computer and Communications Security",
        "citationCount": 0,
        "score": 0
    },
    "1d59c7a29723aa56271ff0252b79fb378655cf21.pdf": {
        "title": "SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?",
        "authors": [
            "John Yang",
            "Carlos E. Jimenez",
            "Alex L. Zhang",
            "Kilian Adriano Lieret",
            "Joyce Yang",
            "Xindi Wu",
            "Ori Press",
            "Niklas Muennighoff",
            "Gabriele Synnaeve",
            "Karthik R. Narasimhan",
            "Diyi Yang",
            "Sida Wang",
            "Ofir Press"
        ],
        "published_date": "2024",
        "abstract": "Autonomous systems for software engineering are now capable of fixing bugs and developing features. These systems are commonly evaluated on SWE-bench (Jimenez et al., 2024a), which assesses their ability to solve software issues from GitHub repositories. However, SWE-bench uses only Python repositories, with problem statements presented predominantly as text and lacking visual elements such as images. This limited coverage motivates our inquiry into how existing systems might perform on unrepresented software engineering domains (e.g., front-end, game development, DevOps), which use different programming languages and paradigms. Therefore, we propose SWE-bench Multimodal (SWE-bench M), to evaluate systems on their ability to fix bugs in visual, user-facing JavaScript software. SWE-bench M features 617 task instances collected from 17 JavaScript libraries used for web interface design, diagramming, data visualization, syntax highlighting, and interactive mapping. Each SWE-bench M task instance contains at least one image in its problem statement or unit tests. Our analysis finds that top-performing SWE-bench systems struggle with SWE-bench M, revealing limitations in visual problem-solving and cross-language generalization. Lastly, we show that SWE-agent's flexible language-agnostic features enable it to substantially outperform alternatives on SWE-bench M, resolving 12% of task instances compared to 6% for the next best system.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/1d59c7a29723aa56271ff0252b79fb378655cf21.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "f70b2f20be241f445a61f33c4b8e76e554760340.pdf": {
        "title": "Software Engineering for Machine Learning: A Case Study",
        "authors": [
            "Saleema Amershi",
            "Andrew Begel",
            "C. Bird",
            "R. Deline",
            "H. Gall",
            "Ece Kamar",
            "Nachiappan Nagappan",
            "Besmira Nushi",
            "Thomas Zimmermann"
        ],
        "published_date": "2019",
        "abstract": "Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be \"entangled\" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/f70b2f20be241f445a61f33c4b8e76e554760340.pdf",
        "venue": "2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
        "citationCount": 0,
        "score": 0
    },
    "2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0.pdf": {
        "title": "Sustainable AI: Environmental Implications, Challenges and Opportunities",
        "authors": [
            "Carole-Jean Wu",
            "R. Raghavendra",
            "Udit Gupta",
            "Bilge Acun",
            "Newsha Ardalani",
            "Kiwan Maeng",
            "Gloria Chang",
            "Fiona Aga Behram",
            "James Huang",
            "Charles Bai",
            "M. Gschwind",
            "Anurag Gupta",
            "Myle Ott",
            "Anastasia Melnikov",
            "Salvatore Candido",
            "David Brooks",
            "Geeta Chauhan",
            "Benjamin Lee",
            "Hsien-Hsin S. Lee",
            "Bugra Akyildiz",
            "Maximilian Balandat",
            "Joe Spisak",
            "R. Jain",
            "M. Rabbat",
            "K. Hazelwood"
        ],
        "published_date": "2021",
        "abstract": "This paper explores the environmental impact of the super-linear growth trends for AI from a holistic perspective, spanning Data, Algorithms, and System Hardware. We characterize the carbon footprint of AI computing by examining the model development cycle across industry-scale machine learning use cases and, at the same time, considering the life cycle of system hardware. Taking a step further, we capture the operational and manufacturing carbon footprint of AI computing and present an end-to-end analysis for what and how hardware-software design and at-scale optimization can help reduce the overall carbon footprint of AI. Based on the industry experience and lessons learned, we share the key challenges and chart out important development directions across the many dimensions of AI. We hope the key messages and insights presented in this paper can inspire the community to advance the field of AI in an environmentally-responsible manner.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0.pdf",
        "venue": "Conference on Machine Learning and Systems",
        "citationCount": 0,
        "score": 0
    },
    "7944923a8865d978ef92bfef0a19d97b71fe5b3d.pdf": {
        "title": "Advancements in software engineering using AI",
        "authors": [
            "Hazem W. Marar"
        ],
        "published_date": "2024",
        "abstract": "The integration of Artificial Intelligence (AI) into the space of software engineering marks a transformative period that reshapes traditional development processes and propels the industry into a new era of innovation. This exploration delves into the multifaceted impact of AI, from its roots in early symbolic AI to the contemporary dominance of machine learning and deep learning. AI\u2019s applications span various domains, but its significance in software engineering lies in its ability to enhance efficiency, improve software quality, and introduce novel approaches to problem-solving. From automating routine tasks to streamlining complex development workflows, AI acts as a virtual collaborator, allowing human developers to focus on higher-order thinking and creativity. This study introduces the application of AI in software engineering. reverse-engineering, and development environments. Moreover, ethical considerations, challenges, and future trends, including explainable AI, reinforcement learning, and human-AI collaboration, are presented.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/7944923a8865d978ef92bfef0a19d97b71fe5b3d.pdf",
        "venue": "Computer Software and Media Applications",
        "citationCount": 0,
        "score": 0
    },
    "f2a621a360a13211a877923b68af3c147155c9a6.pdf": {
        "title": "Applications of AI in classical software engineering",
        "authors": [
            "Marco Barenkamp",
            "Jonas Rebstadt",
            "Oliver Thomas"
        ],
        "published_date": "2020",
        "abstract": "Although Artificial Intelligence (AI) has become a buzzword for self-organizing IT applications, its relevance to software engineering has hardly been analyzed systematically. This study combines a systematic review of previous research in the field and five qualitative interviews with software developers who use or want to use AI tools in their daily work routines, to assess the status of development, future development potentials and equally the risks of AI application to software engineering. The study classifies the insights in the software development life cycle. The analysis results that major achievements and future potentials of AI are a) the automation of lengthy routine jobs in software development and testing using algorithms, e.g. for debugging and documentation, b) the structured analysis of big data pools to discover patterns and novel information clusters and c) the systematic evaluation of these data in neural networks. AI thus contributes to speed up development processes, realize development cost reductions and efficiency gains. AI to date depends on man-made structures and is mainly reproductive, but the automation of software engineering routines entails a major advantage: Human developers multiply their creative potential when using AI tools effectively.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/f2a621a360a13211a877923b68af3c147155c9a6.pdf",
        "venue": "AI Perspectives",
        "citationCount": 0,
        "score": 0
    },
    "2ff388eb4516519660eb9b4a006f90ed4d67c40b.pdf": {
        "title": "HINT: Integration Testing for AI-based features with Humans in the Loop",
        "authors": [
            "Quan Ze Chen",
            "Tobias Schnabel",
            "Besmira Nushi",
            "Saleema Amershi"
        ],
        "published_date": "2022",
        "abstract": "The dynamic nature of AI technologies makes testing human-AI interaction and collaboration challenging \u2013 especially before such features are deployed in the wild. This presents a challenge for designers and AI practitioners as early feedback for iteration is often unavailable in the development phase. In this paper, we take inspiration from integration testing concepts in software development and present HINT (Human-AI INtegration Testing), a crowd-based framework for testing AI-based experiences integrated with a humans-in-the-loop workflow. HINT supports early testing of AI-based features within the context of realistic user tasks and makes use of successive sessions to simulate AI experiences that evolve over-time. Finally, it provides practitioners with reports to evaluate and compare aspects of these experiences. Through a crowd-based study, we demonstrate the need for over-time testing where user behaviors evolve as they interact with an AI system. We also show that HINT is able to capture and reveal these distinct user behavior patterns across a variety of common AI performance modalities using two AI-based feature prototypes. We further evaluated HINT\u2019s potential to support practitioners\u2019 evaluation of human-AI interaction experiences pre-deployment through semi-structured interviews with 13 practitioners.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/2ff388eb4516519660eb9b4a006f90ed4d67c40b.pdf",
        "venue": "International Conference on Intelligent User Interfaces",
        "citationCount": 0,
        "score": 0
    },
    "8b910aaa410dd1a5b3c0be5134394af23bc6b848.pdf": {
        "title": "Future of software development with generative AI",
        "authors": [
            "Jaakko Sauvola",
            "Sasu Tarkoma",
            "Mika Klemettinen",
            "J. Riekki",
            "David S. Doermann"
        ],
        "published_date": "2024",
        "abstract": "Generative AI is regarded as a major disruption to software development. Platforms, repositories, clouds, and the automation of tools and processes have been proven to improve productivity, cost, and quality. Generative AI, with its rapidly expanding capabilities, is a major step forward in this field. As a new key enabling technology, it can be used for many purposes, from creative dimensions to replacing repetitive and manual tasks. The number of opportunities increases with the capabilities of large-language models (LLMs). This has raised concerns about ethics, education, regulation, intellectual property, and even criminal activities. We analyzed the potential of generative AI and LLM technologies for future software development paths. We propose four primary scenarios, model trajectories for transitions between them, and reflect against relevant software development operations. The motivation for this research is clear: the software development industry needs new tools to understand the potential, limitations, and risks of generative AI, as well as guidelines for using it.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/8b910aaa410dd1a5b3c0be5134394af23bc6b848.pdf",
        "venue": "International Conference on Automated Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "ce3f027b68dad014a58aa35f52380932c8d0b209.pdf": {
        "title": "Do Users Write More Insecure Code with AI Assistants?",
        "authors": [
            "Neil Perry",
            "Megha Srivastava",
            "Deepak Kumar",
            "D. Boneh"
        ],
        "published_date": "2022",
        "abstract": "AI code assistants have emerged as powerful tools that can aid in the software development life-cycle and can improve developer productivity. Unfortunately, such assistants have also been found to produce insecure code in lab environments, raising significant concerns about their usage in practice. In this paper, we conduct a user study to examine how users interact with AI code assistants to solve a variety of security related tasks. Overall, we find that participants who had access to an AI assistant wrote significantly less secure code than those without access to an assistant. Participants with access to an AI assistant were also more likely to believe they wrote secure code, suggesting that such tools may lead users to be overconfident about security flaws in their code. To better inform the design of future AI-based code assistants, we release our user-study apparatus to researchers seeking to build on our work.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/ce3f027b68dad014a58aa35f52380932c8d0b209.pdf",
        "venue": "Conference on Computer and Communications Security",
        "citationCount": 0,
        "score": 0
    },
    "443f16b95edec746a5259644540c44204f2d91c3.pdf": {
        "title": "The Potential of Artificial Intelligence as a Method of Software Developer's Productivity Improvement",
        "authors": [
            "Ekaterina A. Moroz",
            "Vladimir O. Grizkevich",
            "I. M. Novozhilov"
        ],
        "published_date": "2022",
        "abstract": "Artificial Intelligence finds application at all stages of Software Engineering, and uses the Neural Networks, Machine Learning, Natural Language Processing concepts. This paper attempts to review the instance of such approach - neural network programmer\u2019s assistant Copilot, based on Codex, the AI system developed by OpenAI. The differences between Codex language model\u2019s versions and analogous systems were analyzed. The main problems and gaps of this innovation, such as correct commands formulation, copyrighting, safety issues, inefficient code, good practice examples and restrictions are also considered. Additionally, the opportunities for Copilot\u2019s growth, development and possible features\u2019 proposed recommendations were suggested.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/443f16b95edec746a5259644540c44204f2d91c3.pdf",
        "venue": "2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus)",
        "citationCount": 0,
        "score": 0
    },
    "4c938522f0dd67bc0a1d053d6cc21da5cfa1763b.pdf": {
        "title": "Human-AI Collaboration in Software Engineering: Lessons Learned from a Hands-On Workshop",
        "authors": [
            "Muhammad Hamza",
            "Dominik Siemon",
            "M. Akbar",
            "Tahsinur Rahman"
        ],
        "published_date": "2023",
        "abstract": "This paper investigates the dynamics of human-AI collaboration in software engineering, focusing on the use of ChatGPT. Through a thematic analysis of a hands-on workshop in which 22 professional software engineers collaborated for three hours with ChatGPT, we explore the transition of AI from a mere tool to a collaborative partner. The study identifies key themes such as the evolving nature of human-AI interaction, the capabilities of AI in software engineering tasks, and the challenges and limitations of integrating AI in this domain. The findings show that while AI, particularly ChatGPT, improves the efficiency of code generation and optimization, human oversight remains crucial, especially in areas requiring complex problem-solving and security considerations. This research contributes to the theoretical understanding of human-AI collaboration in software engineering and provides practical insights for effectively integrating AI tools into development processes. It highlights the need for clear role allocation, effective communication, and balanced AI-human collaboration to realize the full potential of AI in software engineering.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/4c938522f0dd67bc0a1d053d6cc21da5cfa1763b.pdf",
        "venue": "2024 IEEE/ACM International Workshop on Software-Intensive Business (IWSiB)",
        "citationCount": 0,
        "score": 0
    },
    "8281b1dcf71dac90a5c95a36f5c4b988ff1ec259.pdf": {
        "title": "A Comparative Review of AI Techniques for Automated Code Generation in Software Development: Advancements, Challenges, and Future Directions",
        "authors": [
            "A. Odeh",
            "Nada Odeh",
            "Abdul Salam Mohammed"
        ],
        "published_date": "2024",
        "abstract": "Artificial Intelligence (AI), as one of the most important fields of computer science, plays a significant role in the software development life cycle process, especially in the implementation phase, where developers require considerable effort to convert software requirements and design into code. Automated Code Generation (ACG) using AI can help in this phase. Automating the code generation process is becoming increasingly popular as a solution to address various software development challenges and increase productivity. In this work, we provide a comprehensive review and discussion of traditional and AI techniques used for ACG, their challenges, and limitations. By analysing a selection of related studies, we will identify all AI methods and algorithms used for ACG, extracting the evaluation metrics and criteria such as Accuracy, Efficiency, Scalability, Correctness, Generalization, and more. These criteria will be used to perform a comparative result for AI methods used for ACG, exploring their applications, strengths, weaknesses, performance, and future applications.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/8281b1dcf71dac90a5c95a36f5c4b988ff1ec259.pdf",
        "venue": "TEM Journal",
        "citationCount": 0,
        "score": 0
    },
    "848b49ca819d30943d36ac803f9275969f33f413.pdf": {
        "title": "What Is an AI Engineer? An Empirical Analysis of Job Ads in The Netherlands",
        "authors": [
            "M. Meesters",
            "P. Heck",
            "A. Serebrenik"
        ],
        "published_date": "2022",
        "abstract": "Recently, the job market for Artificial Intelligence (AI) engineers has exploded. Since the role of AI engineer is relatively new, limited research has been done on the requirements as set by the industry. Moreover, the definition of an AI engineer is less established than for a data scientist or a software engineer. In this study we explore, based on job ads, the requirements from the job market for the position of AI engineer in The Netherlands. We retrieved job ad data between April 2018 and April 2021 from a large job ad database, Jobfeed from TextKernel. The job ads were selected with a process similar to the selection of primary studies in a literature review. We characterize the 367 resulting job ads based on meta-data such as publication date, industry/sector, educational background and job titles. To answer our research questions we have further coded 125 job ads manually. The job tasks of AI engineers are concentrated in five categories: business understanding, data engineering, modeling, software development and operations engineering. Companies ask for AI engineers with different profiles: 1) data science engineer with focus on modeling, 2) AI software engineer with focus on software development, 3) generalist AI engineer with focus on both models and software. Furthermore, we present the tools and technologies mentioned in the selected job ads, and the soft skills. Our research helps to understand the expectations companies have for professionals building AI-enabled systems. Understanding these expectations is crucial both for prospective AI engineers and educational institutions in charge of training those prospective engineers. Our research also helps to better define the profession of AI engineering. We do this by proposing an extended AI engineering life-cycle that includes a business understanding phase.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/848b49ca819d30943d36ac803f9275969f33f413.pdf",
        "venue": "2022 IEEE/ACM 1st International Conference on AI Engineering \u2013 Software Engineering for AI (CAIN)",
        "citationCount": 0,
        "score": 0
    },
    "bdb97f6f85eba3a9786216fa4de033cf82385b60.pdf": {
        "title": "Empowering Agile-Based Generative Software Development through Human-AI Teamwork",
        "authors": [
            "Sai Zhang",
            "Zhenchang Xing",
            "Ronghui Guo",
            "Fangzhou Xu",
            "Lei Chen",
            "Zhaoyuan Zhang",
            "Xiaowang Zhang",
            "Zhiyong Feng",
            "Zhiqiang Zhuang"
        ],
        "published_date": "2024",
        "abstract": "In software development, the raw requirements proposed by users are frequently incomplete, which impedes the complete implementation of software functionalities. With the emergence of large language models, the exploration of generating software through user requirements has attracted attention. Recent methods with the top-down waterfall model employ a questioning approach for requirement completion, attempting to explore further user requirements. However, users, constrained by their domain knowledge, result in a lack of effective acceptance criteria during the requirement completion, failing to fully capture the implicit needs of the user. Moreover, the cumulative errors of the waterfall model can lead to discrepancies between the generated code and user requirements. The Agile methodologies reduce cumulative errors of the waterfall model through lightweight iteration and collaboration with users, but the challenge lies in ensuring semantic consistency between user requirements and the code generated by the agent. To address these challenges, we propose AgileGen, an agile-based generative software development through human-AI teamwork. Unlike existing questioning agents, AgileGen adopts a novel collaborative approach that breaks free from the constraints of domain knowledge by initiating the end-user perspective to complete the acceptance criteria. By introducing the Gherkin language, AgileGen attempts for the first time to use testable requirement descriptions as a bridge for semantic consistency between requirements and code, aiming to ensure that software products meet actual user requirements by defining user scenarios that include acceptance criteria. Additionally, we innovate in the human-AI teamwork model, allowing users to participate in decision-making processes they do well and significantly enhancing the completeness of software functionality. To ensure semantic consistency between requirements and generated code, we derive consistency factors from Gherkin to drive the subsequent software code generation. Finally, to improve the reliability of user scenarios, we also introduce a memory pool mechanism, collecting user decision-making scenarios and recommending them to new users with similar requirements. AgileGen, as a user-friendly interactive system, significantly outperformed existing best methods by 16.4% and garnered higher user satisfaction.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/bdb97f6f85eba3a9786216fa4de033cf82385b60.pdf",
        "venue": "ACM Transactions on Software Engineering and Methodology",
        "citationCount": 0,
        "score": 0
    },
    "14b42a095728221f9ea1698c9749634574c9980e.pdf": {
        "title": "The State of the ML-universe: 10 Years of Artificial Intelligence & Machine Learning Software Development on GitHub",
        "authors": [
            "Danielle Gonzalez",
            "Thomas Zimmermann",
            "Nachiappan Nagappan"
        ],
        "published_date": "2020",
        "abstract": "In the last few years, artificial intelligence (AI) and machine learning (ML) have become ubiquitous terms. These powerful techniques have escaped obscurity in academic communities with the recent onslaught of AI & ML tools, frameworks, and libraries that make these techniques accessible to a wider audience of developers. As a result, applying AI & ML to solve existing and emergent problems is an increasingly popular practice. However, little is known about this domain from the software engineering perspective. Many AI & ML tools and applications are open source, hosted on platforms such as GitHub that provide rich tools for large-scale distributed software development. Despite widespread use and popularity, these repositories have never been examined as a community to identify unique properties, development patterns, and trends. In this paper, we conducted a large-scale empirical study of AI & ML Tool (700) and Application (4,524) repositories hosted on GitHub to develop such a characterization. While not the only platform hosting AI & ML development, GitHub facilitates collecting a rich data set for each repository with high traceability between issues, commits, pull requests and users. To compare the AI & ML community to the wider population of repositories, we also analyzed a set of 4,101 unrelated repositories. We enhance this characterization with an elaborate study of developer workflow that measures collaboration and autonomy within a repository. We've captured key insights of this community's 10 year history such as it's primary language (Python) and most popular repositories (Tensorflow, Tesseract). Our findings show the AI & ML community has unique characteristics that should be accounted for in future research.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/14b42a095728221f9ea1698c9749634574c9980e.pdf",
        "venue": "IEEE Working Conference on Mining Software Repositories",
        "citationCount": 0,
        "score": 0
    },
    "93a751ed488a22a266a360517fe32b8a6e98f7e7.pdf": {
        "title": "ChatGPT as a Software Development Bot: A Project-Based Study",
        "authors": [
            "Muhammad Waseem",
            "Teerath Das",
            "Aakash Ahmad",
            "Peng Liang",
            "Mahdi Fahmideh",
            "T. Mikkonen"
        ],
        "published_date": "2023",
        "abstract": "Artificial Intelligence has demonstrated its significance in software engineering through notable improvements in productivity, accuracy, collaboration, and learning outcomes. This study examines the impact of generative AI tools, specifically ChatGPT, on the software development experiences of undergraduate students. Over a three-month project with seven students, ChatGPT was used as a support tool. The research focused on assessing ChatGPT's effectiveness, benefits, limitations, and its influence on learning. Results showed that ChatGPT significantly addresses skill gaps in software development education, enhancing efficiency, accuracy, and collaboration. It also improved participants' fundamental understanding and soft skills. The study highlights the importance of incorporating AI tools like ChatGPT in education to bridge skill gaps and increase productivity, but stresses the need for a balanced approach to technology use. Future research should focus on optimizing ChatGPT's application in various development contexts to maximize learning and address specific challenges.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/93a751ed488a22a266a360517fe32b8a6e98f7e7.pdf",
        "venue": "International Conference on Evaluation of Novel Approaches to Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "35afb57a646592c3a471a4f010d00e1b13dd3c43.pdf": {
        "title": "From Copilot to Pilot: Towards AI Supported Software Development",
        "authors": [
            "Rohith Pudari",
            "Neil A. Ernst"
        ],
        "published_date": "2023",
        "abstract": "AI-supported programming has arrived, as shown by the introduction and successes of large language models for code, such as Copilot/Codex (Github/OpenAI) and AlphaCode (DeepMind). Above human average performance on programming challenges is now possible. However, software engineering is much more than solving programming contests. Moving beyond code completion to AI-supported software engineering will require an AI system that can, among other things, understand how to avoid code smells, to follow language idioms, and eventually (maybe!) propose rational software designs. In this study, we explore the current limitations of AI-supported code completion tools like Copilot and offer a simple taxonomy for understanding the classification of AI-supported code completion tools in this space. We first perform an exploratory study on Copilot's code suggestions for language idioms and code smells. Copilot does not follow language idioms and avoid code smells in most of our test scenarios. We then conduct additional investigation to determine the current boundaries of AI-supported code completion tools like Copilot by introducing a taxonomy of software abstraction hierarchies where 'basic programming functionality' such as code compilation and syntax checking is at the least abstract level, software architecture analysis and design are at the most abstract level. We conclude by providing a discussion on challenges for future development of AI-supported code completion tools to reach the design level of abstraction in our taxonomy.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/35afb57a646592c3a471a4f010d00e1b13dd3c43.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "07a58339b1eddc506b957cf91ea17462043876e5.pdf": {
        "title": "AI for Agile development: a Meta-Analysis",
        "authors": [
            "Beatriz Cabrero Daniel"
        ],
        "published_date": "2023",
        "abstract": "This study explores the benefits and challenges of integrating Artificial Intelligence with Agile software development methodologies, focusing on improving continuous integration and delivery. A systematic literature review and longitudinal meta-analysis of the retrieved studies was conducted to analyse the role of Artificial Intelligence and it's future applications within Agile software development. The review helped identify critical challenges, such as the need for specialised socio-technical expertise. While Artificial Intelligence holds promise for improved software development practices, further research is needed to better understand its impact on processes and practitioners, and to address the indirect challenges associated with its implementation.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/07a58339b1eddc506b957cf91ea17462043876e5.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "0e41ae9360a962430650d5bb174de223aa8deea5.pdf": {
        "title": "Navigating the Complexity of Generative AI Adoption in Software Engineering",
        "authors": [
            "Daniel Russo"
        ],
        "published_date": "2023",
        "abstract": "This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares\u2013Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/0e41ae9360a962430650d5bb174de223aa8deea5.pdf",
        "venue": "ACM Transactions on Software Engineering and Methodology",
        "citationCount": 0,
        "score": 0
    },
    "7438adc120459c8743411ffb9e4ed71443d66840.pdf": {
        "title": "A Rapid Review of Responsible AI frameworks: How to guide the development of ethical AI",
        "authors": [
            "Vita Santa Barletta",
            "D. Caivano",
            "Domenico Gigante",
            "Azzurra Ragone"
        ],
        "published_date": "2023",
        "abstract": "In the last years, the raise of Artificial Intelligence (AI), and its pervasiveness in our lives, has sparked a flourishing debate about the ethical principles that should lead its implementation and use in society. Driven by these concerns, we conduct a rapid review of several frameworks providing principles, guidelines, and/or tools to help practitioners in the development and deployment of Responsible AI (RAI) applications. We map each framework w.r.t. the different Software Development Life Cycle (SDLC) phases discovering that most of these frameworks fall just in the Requirements Elicitation phase, leaving the other phases uncovered. Very few of these frameworks offer supporting tools for practitioners, and they are mainly provided by private companies. Our results reveal that there is not a \"catching-all\" framework supporting both technical and non-technical stakeholders in the implementation of real-world projects. Our findings highlight the lack of a comprehensive framework encompassing all RAI principles and all (SDLC) phases that could be navigated by users with different skill sets and with different goals.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/7438adc120459c8743411ffb9e4ed71443d66840.pdf",
        "venue": "International Conference on Evaluation & Assessment in Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "572863f85c3debd1a0787dcba3fb3b0dd03faf66.pdf": {
        "title": "Software Fairness Debt: Building a Research Agenda for Addressing Bias in AI Systems",
        "authors": [
            "Ronnie de Souza Santos",
            "Felipe Fronchetti",
            "S\u00e1vio Freire",
            "Rodrigo O. Sp\u00ednola"
        ],
        "published_date": "2024",
        "abstract": "Ensuring fairness in software systems has become a critical concern in software engineering. Motivated by this challenge, this article explores the multifaceted nature of bias in software systems, providing a comprehensive understanding of its origins, manifestations, and impacts. Through a scoping study, we identified the primary causes of fairness deficiencies in software development and highlighted their adverse effects on individuals and communities, including instances of discrimination and the perpetuation of inequalities. Our investigation culminated in the introduction of the concept of software fairness debt. In addition to defining fairness debt, we propose a socio-technical roadmap that addresses broader aspects of fairness in AI-driven systems. This roadmap is structured around six goals: bridging the gap between research and real-world applications, developing a framework for fairness debt, equipping practitioners with tools and knowledge, improving bias mitigation, integrating fairness tools into industry practice, and enhancing explainability and transparency in AI systems. This roadmap provides a holistic approach to managing biases in software systems through software fairness debt, offering actionable steps for both research and practice. By guiding researchers and practitioners, our roadmap aims to foster the development of more equitable and socially responsible software systems, ensuring fairness is embedded throughout the software lifecycle.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/572863f85c3debd1a0787dcba3fb3b0dd03faf66.pdf",
        "venue": "ACM Transactions on Software Engineering and Methodology",
        "citationCount": 0,
        "score": 0
    },
    "ded0f3ac4c904f0f91bb937bb2bfd5fcb591c777.pdf": {
        "title": "Safety and Performance, Why not Both? Bi-Objective Optimized Model Compression toward AI Software Deployment",
        "authors": [
            "Jie Zhu",
            "Leye Wang",
            "Xiao Han"
        ],
        "published_date": "2022",
        "abstract": "The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, which hinders the large-scale deployment on resource-restricted devices (e.g., smartphones). To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in the big model may be inherited by the compressed one. Such defects may be easily leveraged by attackers, since the compressed models are usually deployed in a large number of devices without adequate protection. In this paper, we try to address the safe model compression problem from a safety-performance co-optimization perspective. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as the safety test, SafeCompress can automatically compress a big model to a small one following the dynamic sparse training paradigm. Further, considering a representative attack, i.e., membership inference attack (MIA), we develop a concrete safe model compression mechanism, called MIA-SafeCompress. Extensive experiments are conducted to evaluate MIA-SafeCompress on five datasets for both computer vision and natural language processing tasks. The results verify the effectiveness and generalization of our method. We also discuss how to adapt SafeCompress to other attacks besides MIA, demonstrating the flexibility of SafeCompress.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/ded0f3ac4c904f0f91bb937bb2bfd5fcb591c777.pdf",
        "venue": "International Conference on Automated Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "f82e4ff4f003581330338aaae71f60316e58dd26.pdf": {
        "title": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
        "authors": [
            "Marc G. Bellemare",
            "Yavar Naddaf",
            "J. Veness",
            "Michael Bowling"
        ],
        "published_date": "2012",
        "abstract": "In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/f82e4ff4f003581330338aaae71f60316e58dd26.pdf",
        "venue": "Journal of Artificial Intelligence Research",
        "citationCount": 0,
        "score": 0
    },
    "c58de4e94c9864efbc46f25af61cf01753172fae.pdf": {
        "title": "Artificial Intelligence in Quality Assurance for Software Systems",
        "authors": [
            "Santhosh Bussa"
        ],
        "published_date": "2023",
        "abstract": "The rapid advancement in software development has taken place with the invention of a new quality assurance (QA) process for producing robust, reliable, and efficient systems. Artificial Intelligence is a \"force of change\" that promises automating most QA activities with promising predictive insight into the generation of dynamic test cases and intelligent detection of defects. This paper covers the theme of integrating AI with SQA through techniques such as Machine Learning, Natural Language Processing, and Neural Networks. The paper covers automation of testing, AI-driven management of defects, and enhancement of user experience as well as challenges and limitation that is encountered while implementing AI within QA. A glimpse of emerging trends illustrates the dynamic landscape of AI-driven QA.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/c58de4e94c9864efbc46f25af61cf01753172fae.pdf",
        "venue": "Stallion Journal for Multidisciplinary Associated Research Studies",
        "citationCount": 0,
        "score": 0
    },
    "259bf96be0f2a9d9a1acbce991c92640d23a8ac3.pdf": {
        "title": "How much SPACE do metrics have in GenAI assisted software development?",
        "authors": [
            "Samarth Sikand",
            "Kanchanjot Kaur Phokela",
            "V. Sharma",
            "Kapil Singi",
            "Vikrant S. Kaulgud",
            "Teresa Tung",
            "Pragya Sharma",
            "Adam P. Burden"
        ],
        "published_date": "2024",
        "abstract": "Large Language Models (LLMs) are revolutionizing the way a developer creates software by replacing code with natural language prompts as primary drivers. While many initial assessments of such LLMs suggest that it helps with developer productivity, other research studies have also pointed out areas in the Software Development Life Cycle(SDLC) and developer experience where such tools fail miserably. Currently, there exist many studies dedicated to evaluation of LLM-based AI-assisted software tools but there lacks a standardization of studies and metrics which may prove to be a hindrance to adoption of metrics and reproducible studies. The primary objective of this survey is to assess the recent user studies and surveys, aimed at evaluating different aspects of developer\u2019s experience of using code-based LLMs, and highlight any existing gaps among them. We have leveraged the SPACE framework to enumerate and categorise metrics from studies conducting some form of controlled user experiments. In Generative AI assisted SDLC, the developer\u2019s experience should encompass the ability to perform the in-hand task efficiently and effectively, with minimal friction using these LLM tools. Our exploration has led to some critical insights regarding complete absence of user studies in Collaborative aspects of teams, bias towards certain LLM models & metrics and lack of diversity in metrics within productivity dimensions. We also propose some recommendations to the research community which will help bring some conformity in the evaluation of such LLMs.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/259bf96be0f2a9d9a1acbce991c92640d23a8ac3.pdf",
        "venue": "International Symposium on Electronic Commerce",
        "citationCount": 0,
        "score": 0
    },
    "02a8df1c16ae5d085be35d4418baad35f1f74764.pdf": {
        "title": "Smart Energy Management System based on Reconfigurable AI Chip and Electrical Vehicles",
        "authors": [
            "Huakun Huang",
            "M. Ogbodo",
            "Zhishang Wang",
            "Chen Qiu",
            "Masayuki Hisada",
            "Abderazek Ben Abdallah"
        ],
        "published_date": "2021",
        "abstract": "Energy conservation has become a crucial issue for today\u2019s sustainable development. However, converting the energy system to renewable ones and improving the energy efficiency are enormous challenges for current energy sectors. To overcome such challenges, we propose in this work a smart software-hardware (SW-HW) platform and design for a smart energy management system. The platform combines the advantages of SW (refers to user interface) and HW (i.e., AI chip) in terms of high speed and low power. Electric vehicles (EVs) then intelligently and autonomously charge or discharge their batteries. Therefore, the VPP can efficiently manage all the distributed EV batteries as a huge smart power-storage facility. In this way, EV batteries are able to store the extra electricity produced by renewable energy resources, such as solar installations, wind farms, etc. This will bring about greater flexibility and scalability to the power grid and the green vehicle networks.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/02a8df1c16ae5d085be35d4418baad35f1f74764.pdf",
        "venue": "International Conference on Big Data and Smart Computing",
        "citationCount": 0,
        "score": 0
    },
    "38819caf3755331f512e25c4fd2adf20077f33d1.pdf": {
        "title": "\u201cThis is Just a Prototype\u201d: How Ethics Are Ignored in Software Startup-Like Environments",
        "authors": [
            "Ville Vakkuri",
            "Kai-Kristian Kemell",
            "Marianna Jantunen",
            "P. Abrahamsson"
        ],
        "published_date": "2020",
        "abstract": "Artificial Intelligence (AI) solutions are becoming increasingly common in software development endeavors, and consequently exert a growing societal influence as well. Due to their unique nature, AI based systems influence a wide range of stakeholders with or without their consent, and thus the development of these systems necessitates a higher degree of ethical consideration than is currently carried out in most cases. Various practical examples of AI failures have also highlighted this need. However, there is only limited research on methods and tools for implementing AI ethics in software development, and we currently have little knowledge of the state of practice. In this study, we explore the state of the art in startup-like environments where majority of the AI software today gets developed. Based on a multiple case study, we discuss the current state of practice and highlight issues. The cases underline the complete ignorance of ethical consideration in AI endeavors. We also outline existing good practices that can already support the implementation of AI ethics, such as documentation and error handling.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/38819caf3755331f512e25c4fd2adf20077f33d1.pdf",
        "venue": "International Conference on Agile Software Development",
        "citationCount": 0,
        "score": 0
    },
    "fd38e3414273fa64ffa93c8cd15a98120883987e.pdf": {
        "title": "Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression Against Heterogeneous Attacks Toward AI Software Deployment",
        "authors": [
            "Jie Zhu",
            "Leye Wang",
            "Xiao Han",
            "Anmin Liu",
            "Tao Xie"
        ],
        "published_date": "2024",
        "abstract": "The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, hindering the large-scale deployment on resource-restricted devices (e.g., smartphones). To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in a big model may be inherited by the compressed one. Such defects may be easily leveraged by adversaries, since a compressed model is usually deployed in a large number of devices without adequate protection. In this article, we aim to address the safe model compression problem from the perspective of safety-performance co-optimization. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as safety testing, SafeCompress can automatically compress a big model to a small one following the dynamic sparse training paradigm. Then, considering two kinds of representative and heterogeneous attack mechanisms, i.e., black-box membership inference attack and white-box membership inference attack, we develop two concrete instances called BMIA-SafeCompress and WMIA-SafeCompress. Further, we implement another instance called MMIA-SafeCompress by extending SafeCompress to defend against the occasion when adversaries conduct black-box and white-box membership inference attacks simultaneously. We conduct extensive experiments on five datasets for both computer vision and natural language processing tasks. The results show the effectiveness and generalizability of our framework. We also discuss how to adapt SafeCompress to other attacks besides membership inference attack, demonstrating the flexibility of SafeCompress.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/fd38e3414273fa64ffa93c8cd15a98120883987e.pdf",
        "venue": "IEEE Transactions on Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "13e1ea3c8cfd18b652e547ffc0ef8c7ad30403ae.pdf": {
        "title": "How Do Software Companies Deal with Artificial Intelligence Ethics? A Gap Analysis",
        "authors": [
            "Ville Vakkuri",
            "Kai-Kristian Kemell",
            "Joel Tolvanen",
            "Marianna Jantunen",
            "Erika Halme",
            "P. Abrahamsson"
        ],
        "published_date": "2022",
        "abstract": "The public and academic discussion on Artificial Intelligence (AI) ethics is accelerating and the general public is becoming more aware AI ethics issues such as data privacy in these systems. To guide ethical development of AI systems, governmental and institutional actors, as well as companies, have drafted various guidelines for ethical AI. Though these guidelines are becoming increasingly common, they have been criticized for a lack of impact on industrial practice. There seems to be a gap between research and practice in the area, though its exact nature remains unknown. In this paper, we present a gap analysis of the current state of the art by comparing practices of 39 companies that work with AI systems to the seven key requirements for trustworthy AI presented in the \u201cThe Ethics Guidelines for Trustworthy Artificial Intelligence\u201d. The key finding of this paper is that there is indeed notable gap between AI ethics guidelines and practice. Especially practices considering the novel requirements for software development, requirements of societal and environmental well-being and diversity, nondiscrimination and fairness were not tackled by companies.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/13e1ea3c8cfd18b652e547ffc0ef8c7ad30403ae.pdf",
        "venue": "International Conference on Evaluation & Assessment in Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "59071b1d99b6fa15dffc45de782f634d274a2c45.pdf": {
        "title": "MarsCode Agent: AI-native Automated Bug Fixing",
        "authors": [
            "Yizhou Liu",
            "Pengfei Gao",
            "Xinchen Wang",
            "Jie Liu",
            "Yexuan Shi",
            "Zhao Zhang",
            "Chao Peng"
        ],
        "published_date": "2024",
        "abstract": "Recent advances in large language models (LLMs) have shown significant potential to automate various software development tasks, including code completion, test generation, and bug fixing. However, the application of LLMs for automated bug fixing remains challenging due to the complexity and diversity of real-world software systems. In this paper, we introduce MarsCode Agent, a novel framework that leverages LLMs to automatically identify and repair bugs in software code. MarsCode Agent combines the power of LLMs with advanced code analysis techniques to accurately localize faults and generate patches. Our approach follows a systematic process of planning, bug reproduction, fault localization, candidate patch generation, and validation to ensure high-quality bug fixes. We evaluated MarsCode Agent on SWE-bench, a comprehensive benchmark of real-world software projects, and our results show that MarsCode Agent achieves a high success rate in bug fixing compared to most of the existing automated approaches.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/59071b1d99b6fa15dffc45de782f634d274a2c45.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "618c4f35e06f79e1c71657b9e6c00df97e6ece12.pdf": {
        "title": "Green AI Quotient: Assessing Greenness of AI-based software and the way forward",
        "authors": [
            "Samarth Sikand",
            "V. Sharma",
            "Vikrant S. Kaulgud",
            "Sanjay Podder"
        ],
        "published_date": "2023",
        "abstract": "As the world takes cognizance of AI's growing role in greenhouse gas(GHG) and carbon emissions, the focus of AI research & development is shifting towards inclusion of energy efficiency as another core metric. Sustainability, a core agenda for most organizations, is also being viewed as a core non-functional requirement in software engineering. A similar effort is being undertaken to extend sustainability principles to AI-based systems with focus on energy efficient training and inference techniques. But an important question arises, does there even exist any metrics or methods which can quantify adoption of \u201cgreen\u201d practices in the life cycle of AI-based systems? There is a huge gap which exists between the growing research corpus related to sustainable practices in AI research and its adoption at an industry scale. The goal of this work is to introduce a methodology and novel metric for assessing \u201cgreenness\u201d of any AI-based system and its development process, based on energy efficient AI research and practices. The novel metric, termed as Green AI Quotient, would be a key step towards AI practitioner's Green AI journey. Empirical validation of our approach suggest that Green AI Quotient is able to encourage adoption and raise awareness regarding sustainable practices in AI lifecycle.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/618c4f35e06f79e1c71657b9e6c00df97e6ece12.pdf",
        "venue": "International Conference on Automated Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "91aae70e76aa43426b6ee2d8ce8f6213377bf475.pdf": {
        "title": "Non-Functional Requirements Orienting the Development of Socially Responsible Software",
        "authors": [
            "L. M. Cysneiros",
            "Julio Cesar Sampaio do Prado Leite"
        ],
        "published_date": "2020",
        "abstract": "Nowadays, software is ubiquitous and present in almost everything we buy and use. Artificial intelligence (AI) is becoming prevalent in software products. The use of AI entices consumer inquisitiveness, promising software products that can make our lives easier, productive, and in some mission-critical applications safer. Similar reasoning can be applied to systems exploring Internet of Things, cloud services, and mobile technologies. However, there is a trust deficit when it comes to accepting AI as well as the other above-mentioned features, as a reliable technology platform. This paper argues that the more critical the domain is, the less consumers seem to trust software to make decisions on their behalf or even to be used. Aspects such as safety, privacy, and ethics challenges the perception of trustworthy computing. In the past two decades, several works have suggested that Corporate Social Responsibility (CSR) may play an essential role in creating a trust paradigm between customers and businesses promoting loyalty, customer retention and thus enhancing customer trust and increasing corporate profit. We believe that the software industry will need soon rather than later to encourage trust in their embedded software. A promising approach lies in adapting principles associated with CSR to guide the software development processes. Such an approach could help to achieve two goals: Deliver trustworthy software and, if desired, deliver socially responsible software. We believe that Non-Functional Requirements (NFR) will play a crucial role in this endeavor. This paper highlights a first approach to establishing a basic set of NFRs that should always be carefully considered when developing software, as to aim socially responsible software.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/91aae70e76aa43426b6ee2d8ce8f6213377bf475.pdf",
        "venue": "BPMDS/EMMSAD@CAiSE",
        "citationCount": 0,
        "score": 0
    },
    "917ba30d8d00e17c53545badc8fc76e403f8ac09.pdf": {
        "title": "Experimenting with Multi-Agent Software Development: Towards a Unified Platform",
        "authors": [
            "Malik Abdul Sami",
            "Muhammad Waseem",
            "Zeeshan Rasheed",
            "Mika Saari",
            "Kari Syst\u00e4",
            "Pekka Abrahamsson"
        ],
        "published_date": "2024",
        "abstract": "Large language models are redefining software engineering by implementing AI-powered techniques throughout the whole software development process, including requirement gathering, software architecture, code generation, testing, and deployment. However, it is still difficult to develop a cohesive platform that consistently produces the best outcomes across all stages. The objective of this study is to develop a unified platform that utilizes multiple artificial intelligence agents to automate the process of transforming user requirements into well-organized deliverables. These deliverables include user stories, prioritization, and UML sequence diagrams, along with the modular approach to APIs, unit tests, and end-to-end tests. Additionally, the platform will organize tasks, perform security and compliance, and suggest design patterns and improvements for non-functional requirements. We allow users to control and manage each phase according to their preferences. In addition, the platform provides security and compliance checks following European standards and proposes design optimizations. We use multiple models, such as GPT-3.5, GPT-4, and Llama3 to enable to generation of modular code as per user choice. The research also highlights the limitations and future research discussions to overall improve the software development life cycle. The source code for our uniform platform is hosted on GitHub, enabling additional experimentation and supporting both research and practical uses. \\end",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/917ba30d8d00e17c53545badc8fc76e403f8ac09.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "e5bafaae57503b59a59386d0b74fc6eb40225ba8.pdf": {
        "title": "Sea Change in Software Development: Economic and Productivity Analysis of the AI-Powered Developer Lifecycle",
        "authors": [
            "Thomas Dohmke",
            "M. Iansiti",
            "Gregory L. Richards"
        ],
        "published_date": "2023",
        "abstract": "This study examines the impact of GitHub Copilot on a large sample of Copilot users (n=934,533). The analysis shows that users on average accept nearly 30% of the suggested code, leading to increased productivity. Furthermore, our research demonstrates that the acceptance rate rises over time and is particularly high among less experienced developers, providing them with substantial benefits. Additionally, our estimations indicate that the adoption of generative AI productivity tools could potentially contribute to a $1.5 trillion increase in global GDP by 2030. Moreover, our investigation sheds light on the diverse contributors in the generative AI landscape, including major technology companies, startups, academia, and individual developers. The findings suggest that the driving force behind generative AI software innovation lies within the open-source ecosystem, particularly in the United States. Remarkably, a majority of repositories on GitHub are led by individual developers. As more developers embrace these tools and acquire proficiency in the art of prompting with generative AI, it becomes evident that this novel approach to software development has forged a unique inextricable link between humans and artificial intelligence. This symbiotic relationship has the potential to shape the construction of the world's software for future generations.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/e5bafaae57503b59a59386d0b74fc6eb40225ba8.pdf",
        "venue": "",
        "citationCount": 0,
        "score": 0
    },
    "d0b6c5820ae12bb42a82f5f56de37a70c8b3b98a.pdf": {
        "title": "XAIR: A Systematic Metareview of Explainable AI (XAI) Aligned to the Software Development Process",
        "authors": [
            "Tobias Clement",
            "Nils Kemmerzell",
            "Mohamed Abdelaal",
            "M. Amberg"
        ],
        "published_date": "2023",
        "abstract": "Currently, explainability represents a major barrier that Artificial Intelligence (AI) is facing in regard to its practical implementation in various application domains. To combat the lack of understanding of AI-based systems, Explainable AI (XAI) aims to make black-box AI models more transparent and comprehensible for humans. Fortunately, plenty of XAI methods have been introduced to tackle the explainability problem from different perspectives. However, due to the vast search space, it is challenging for ML practitioners and data scientists to start with the development of XAI software and to optimally select the most suitable XAI methods. To tackle this challenge, we introduce XAIR, a novel systematic metareview of the most promising XAI methods and tools. XAIR differentiates itself from existing reviews by aligning its results to the five steps of the software development process, including requirement analysis, design, implementation, evaluation, and deployment. Through this mapping, we aim to create a better understanding of the individual steps of developing XAI software and to foster the creation of real-world AI applications that incorporate explainability. Finally, we conclude with highlighting new directions for future research.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/d0b6c5820ae12bb42a82f5f56de37a70c8b3b98a.pdf",
        "venue": "Machine Learning and Knowledge Extraction",
        "citationCount": 0,
        "score": 0
    },
    "28c67bda234f006fc174e8ded3490c21b57bc79b.pdf": {
        "title": "AI Tool Use and Adoption in Software Development by Individuals and Organizations: A Grounded Theory Study",
        "authors": [
            "Ze Shi Li",
            "Nowshin Nawar Arony",
            "Ahmed Musa Awon",
            "Daniela E. Damian",
            "Bowen Xu"
        ],
        "published_date": "2024",
        "abstract": "AI assistance tools such as ChatGPT, Copilot, and Gemini have dramatically impacted the nature of software development in recent years. Numerous studies have studied the positive benefits that practitioners have achieved from using these tools in their work. While there is a growing body of knowledge regarding the usability aspects of leveraging AI tools, we still lack concrete details on the issues that organizations and practitioners need to consider should they want to explore increasing adoption or use of AI tools. In this study, we conducted a mixed methods study involving interviews with 26 industry practitioners and 395 survey respondents. We found that there are several motives and challenges that impact individuals and organizations and developed a theory of AI Tool Adoption. For example, we found creating a culture of sharing of AI best practices and tips as a key motive for practitioners' adopting and using AI tools. In total, we identified 2 individual motives, 4 individual challenges, 3 organizational motives, and 3 organizational challenges, and 3 interleaved relationships. The 3 interleaved relationships act in a push-pull manner where motives pull practitioners to increase the use of AI tools and challenges push practitioners away from using AI tools.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/28c67bda234f006fc174e8ded3490c21b57bc79b.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "0f636c909b5e7c60006003b666e70cec755a9e08.pdf": {
        "title": "Advancing Software Security and Reliability in Cloud Platforms through AI-based Anomaly Detection",
        "authors": [
            "Sabbir M. Saleh",
            "Ibrahim Mohammed Sayem",
            "N. Madhavji",
            "John Steinbacher"
        ],
        "published_date": "2024",
        "abstract": "Continuous Integration/Continuous Deployment (CI/CD) is fundamental for advanced software development, supporting faster and more efficient delivery of code changes into cloud environments. However, security issues in the CI/CD pipeline remain challenging, and incidents (e.g., DDoS, Bot, Log4j, etc.) are happening over the cloud environments. While plenty of literature discusses static security testing and CI/CD practices, only a few deal with network traffic pattern analysis to detect different cyberattacks. This research aims to enhance CI/CD pipeline security by implementing anomaly detection through AI (Artificial Intelligence) support. The goal is to identify unusual behaviour or variations from network traffic patterns in pipeline and cloud platforms. The system shall integrate into the workflow to continuously monitor pipeline activities and cloud infrastructure. Additionally, it aims to explore adaptive response mechanisms to mitigate the detected anomalies or security threats. This research employed two popular network traffic datasets, CSE-CIC-IDS2018 and CSE-CIC-IDS2017. We implemented a combination of Convolution Neural Network (CNN) and Long Short-Term Memory (LSTM) to detect unusual traffic patterns. We achieved an accuracy of 98.69% and 98.30% and generated log files in different CI/CD pipeline stages that resemble the network anomalies affected to address security challenges in modern DevOps practices, contributing to advancing software security and reliability.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/0f636c909b5e7c60006003b666e70cec755a9e08.pdf",
        "venue": "CCSW@CCS",
        "citationCount": 0,
        "score": 0
    },
    "431d98af5601be36e28945548e05ab87d807b95a.pdf": {
        "title": "Generative AI in Student Software Development Projects: A User Study on Experiences and Self-Assessment",
        "authors": [
            "Uwe M. Borghoff",
            "Mark Minas",
            "Jannis Schopp"
        ],
        "published_date": "2025",
        "abstract": "The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/431d98af5601be36e28945548e05ab87d807b95a.pdf",
        "venue": "European Conference of Software Engineering Education",
        "citationCount": 0,
        "score": 0
    },
    "73e2f9db60f2bc5590f3b926b7801d66c5e69448.pdf": {
        "title": "From Code Generation to Software Testing: AI Copilot With Context-Based Retrieval-Augmented Generation",
        "authors": [
            "Yuchen Wang",
            "Shangxin Guo",
            "Chee Wei Tan"
        ],
        "published_date": "2025",
        "abstract": "The rapid pace of large-scale software development places increasing demands on traditional testing methodologies. We propose a novel perspective on software testing, highlighting the transformative potential of AI-driven technologies in modern software development practices.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/73e2f9db60f2bc5590f3b926b7801d66c5e69448.pdf",
        "venue": "IEEE Software",
        "citationCount": 0,
        "score": 0
    },
    "6d9e6a495b4f1a5a6c8fbba98a6495bb1964d16f.pdf": {
        "title": "The State of Generative AI Adoption from Software Practitioners' Perspective: An Empirical Study",
        "authors": [
            "Mario E. S. Simaremare",
            "Henry Edison"
        ],
        "published_date": "2024",
        "abstract": "Context: Generative AI (GenAI) brings new op-portunities to the software industry and the digital economy in a broader context. Objective: This study aimed to explore and capture the practitioners' perception of GenAI adoption in the fast-paced software industry in the context of developing countries. Method: We conducted online focus group discussions with 18 practitioners from various roles to collect qualitative data. The practitioners have an average of 7.8 years of working experience and have used GenAI for over a year. We employed thematic analysis and the Human-AI Collaboration and Adaptation Framework (HACAF) to identify the influencing factors of GenAI adoption, such as awareness, use cases, and challenges. Results: The adoption of GenAI technology is evident from practitioners. We identified 22 practical use cases, three of which were novel, i.e., contextualizing solutions, assisting the internal audit process, and benchmarking the internal software development process. We also discovered seven key challenges associated with the GenAI adoption, two of which were novel, namely, no matching use cases and unforeseen benefits. These challenges slow GenAI adoption and potentially hinder developing countries from entering a high-skill industry. Conclusion: While the adoption of GenAI technology is promising, industry-academia collaboration is needed to find solutions and strategies to address the challenges and maximize its potential benefits.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/6d9e6a495b4f1a5a6c8fbba98a6495bb1964d16f.pdf",
        "venue": "EUROMICRO Conference on Software Engineering and Advanced Applications",
        "citationCount": 0,
        "score": 0
    },
    "14e50dab3238b6824a9100d88893eb4582842d3b.pdf": {
        "title": "ModelOps: Cloud-Based Lifecycle Management for Reliable and Trusted AI",
        "authors": [
            "W. Hummer",
            "Vinod Muthusamy",
            "T. Rausch",
            "Parijat Dube",
            "K. E. Maghraoui",
            "Anupama Murthi",
            "Punleuk Oum"
        ],
        "published_date": "2019",
        "abstract": "This paper proposes a cloud-based framework and platform for end-to-end development and lifecycle management of artificial intelligence (AI) applications. We build on our previous work on platform-level support for cloud-managed deep learning services, and show how the principles of software lifecycle management can be leveraged and extended to enable automation, trust, reliability, traceability, quality control, and reproducibility of AI pipelines. Based on a discussion of use cases and current challenges, we describe a framework for managingAI application lifecycles and its key components. We also show concrete examples that illustrate how this framework enables managing and executing model training and continuous learning pipelines while infusing trusted AI principles.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/14e50dab3238b6824a9100d88893eb4582842d3b.pdf",
        "venue": "2019 IEEE International Conference on Cloud Engineering (IC2E)",
        "citationCount": 0,
        "score": 0
    },
    "35be040f55ef240ca94dc1c5c0b002a1d70fbfe8.pdf": {
        "title": "CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI",
        "authors": [
            "Amanda Fernandez",
            "Kimberly A. Cornell"
        ],
        "published_date": "2024",
        "abstract": "As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create \"black box\" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/35be040f55ef240ca94dc1c5c0b002a1d70fbfe8.pdf",
        "venue": "Technical Symposium on Computer Science Education",
        "citationCount": 0,
        "score": 0
    },
    "403cc4091b9843d475268f88c0b99081d6a397f1.pdf": {
        "title": "An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project",
        "authors": [
            "Sanka Rasnayaka",
            "Guanlin Wang",
            "Ridwan Shariffdeen",
            "Ganesh Neelakanta Iyer"
        ],
        "published_date": "2024",
        "abstract": "Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student\u2019s perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.CCS CONCEPTS\u2022 Software and its engineering \u2192 Software development techniques; \u2022 Applied computing \u2192 Education.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/403cc4091b9843d475268f88c0b99081d6a397f1.pdf",
        "venue": "2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)",
        "citationCount": 0,
        "score": 0
    },
    "53a833736bc658d0da00b1cdfc5ed85e3c01674a.pdf": {
        "title": "Exploring GenAI in Software Development: Insights from a Case Study in a Large Brazilian Company",
        "authors": [
            "Guilherme Vaz Pereira",
            "Victoria Jackson",
            "R. Prikladnicki",
            "Andr\u00e9 van der Hoek",
            "Luciane Fortes",
            "Carolina Ara\u00fajo",
            "Andr\u00e9 Coelho",
            "Ligia Chelli",
            "Diego Ramos"
        ],
        "published_date": "2025",
        "abstract": "Recent progress in Generative AI (GenAI) impacts different software engineering (ES) tasks in software development cycle, e.g., from code generation to program repair, and presents a promising avenue for enhancing the productivity of development teams. GenAI based tools have the potential to change the way we develop software and have received attention from industry and academia. However, although some studies have been addressing the adoption of these tools in the software industry, little is known about what are developers' real experiences in a professional software development context, aside the hype. In this paper, we explore the use of GenAI tools by a large Brazilian media company that has teams developing software inhouse. We observed practitioners for six weeks and used online surveys at different time points to understand their expectations, perceptions, and concerns about these tools in their daily work. In addition, we automatically collected quantitative data from the company's development systems, aiming at getting insights about how GenAI impacts the development process during the period. Our results provide insights into how practitioners perceive and utilize GenAI in their daily work in software development.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/53a833736bc658d0da00b1cdfc5ed85e3c01674a.pdf",
        "venue": "2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
        "citationCount": 0,
        "score": 0
    },
    "6696018baf29273aa722e16eda89850247b8f0aa.pdf": {
        "title": "Open Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning",
        "authors": [
            "Zhihao Lin",
            "Wei Ma",
            "Tao Lin",
            "Yaowen Zheng",
            "Jingquan Ge",
            "Jun Wang",
            "Jacques Klein",
            "T\u00e9gawend\u00e9 F. Bissyand\u00e9",
            "Yang Liu",
            "Li Li"
        ],
        "published_date": "2024",
        "abstract": "Large language models (LLMs) have become instrumental in advancing software engineering (SE) tasks, showcasing their efficacy in code understanding and beyond. AI code models have demonstrated their value not only in code generation but also in defect detection, enhancing security measures and improving overall software quality. They are emerging as crucial tools for both software development and maintaining software quality. Like traditional SE tools, open source collaboration is key in realizing the excellent products. However, with AI models, the essential need is in data. The collaboration of these AI-based SE models hinges on maximizing the sources of high-quality data. However, data, especially of high quality, often hold commercial or sensitive value, making them less accessible for open source AI-based SE projects. This reality presents a significant barrier to the development and enhancement of AI-based SE tools within the SE community. Therefore, researchers need to find solutions for enabling open source AI-based SE models to tap into resources by different organizations. Addressing this challenge, our position article investigates one solution to facilitate access to diverse organizational resources for open source AI models, ensuring that privacy and commercial sensitivities are respected. We introduce a governance framework centered on federated learning (FL), designed to foster the joint development and maintenance of open source AI code models while safeguarding data privacy and security. Additionally, we present guidelines for developers on AI-based SE tool collaboration, covering data requirements, model architecture, updating strategies, and version control. Given the significant influence of data characteristics on FL, our research examines the effect of code data heterogeneity on FL performance. We consider six different scenarios of data distributions and include four code models. We also include four most common FL algorithms. Our experimental findings highlight the potential for employing FL in the collaborative development and maintenance of AI-based SE models. We also discuss the key issues to be addressed in the co-construction process and future research directions.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/6696018baf29273aa722e16eda89850247b8f0aa.pdf",
        "venue": "ACM Transactions on Software Engineering and Methodology",
        "citationCount": 0,
        "score": 0
    },
    "15abedb29536d50afeeec739a25358255cbda3e8.pdf": {
        "title": "The Impact of AI on Developer Productivity: Evidence from GitHub Copilot",
        "authors": [
            "Sida Peng",
            "Eirini Kalliamvakou",
            "Peter Cihon",
            "Mert Demirer"
        ],
        "published_date": "2023",
        "abstract": "Generative AI tools hold promise to increase human productivity. This paper presents results from a controlled experiment with GitHub Copilot, an AI pair programmer. Recruited software developers were asked to implement an HTTP server in JavaScript as quickly as possible. The treatment group, with access to the AI pair programmer, completed the task 55.8% faster than the control group. Observed heterogenous effects show promise for AI pair programmers to help people transition into software development careers.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/15abedb29536d50afeeec739a25358255cbda3e8.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "afeffa90eff2ea16f583e936583c0790acf30fd4.pdf": {
        "title": "Artificial Intelligence-Based Tools in Software Development Processes: Application of ChatGPT",
        "authors": [
            "Z. \u00d6zpolat",
            "\u00d6zal Y\u0131ld\u0131r\u0131m",
            "M. Karabatak"
        ],
        "published_date": "2023",
        "abstract": "Software development processes are continuously evolving and rapidly transforming alongside the rapid changes in technology. Recently, innovations in the field of Artificial Intelligence (AI) have led to significant changes in software development practices. AI tools can greatly enhance traditional software development processes by offering developers the ability to create projects more intelligently, swiftly, and effectively. These tools can be employed in various tasks, such as code generation, test automation, error analysis, and performance improvements. Particularly, ChatGPT, an AI-based language model that has had a profound impact on almost every domain, can assist software developers in writing code faster and in a more natural language manner. In this research article, essential information about the usage of ChatGPT in the software development process is presented. To evaluate some capabilities of ChatGPT in the software development context, applications were performed on a software project. For this purpose, a software development process was constructed based on the responses provided by ChatGPT. Various questions related to software development processes were formulated, and the responses generated by GPT were evaluated. The obtained results indicated that ChatGPT exhibited excellent performance in the software development process. Based on these findings, it was observed that AI-based models like ChatGPT could be effectively utilized as assisting tools in software development processes, accelerating traditional workflows. Furthermore, AI-based tools can automate testing processes, enhancing software quality while saving time and effort.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/afeffa90eff2ea16f583e936583c0790acf30fd4.pdf",
        "venue": "European Journal of Technic",
        "citationCount": 0,
        "score": 0
    },
    "f61990dfecc068ab4f41fa154865766456abf89b.pdf": {
        "title": "Impacts of the Usage of Generative Artificial Intelligence on Software Development Process",
        "authors": [
            "Patricia de Oliveira Santos",
            "Allan Chamon Figueiredo",
            "Pedro Nuno Moura",
            "Bruna Diirr",
            "Adriana C. F. Alvim",
            "Rodrigo Pereira dos Santos"
        ],
        "published_date": "2024",
        "abstract": "Context: Over the years, tools have been created to improve the execution of development process activities. The emergence of generative Artificial Intelligence (AI) and, more recently, the launch and dissemination of Copilot, ChatGPT-3 and other generative tools, have broadened the discussion about the possibility of using conversational generative AI tools in diverse development tasks. Problem: There is still a lack of secondary studies to map the literature about how software development process activities can be affected by the usage of generative AI tools. Solution: This study aims to identify in which activities of the software development process Natural Language (NL) generative AI tools have been used and how they can impact requirements specification, design/architecture, development and testing activities. IS Theory: The study was developed under the aegis of the Task Technology Fit theory. Method: This work presents the results of a Systematic Mapping Review (SMR) carried out to collect research results that investigate the application of generative AI tools in the software development process. Results: Results indicate that the main activities affected are development and testing and that, although there are still some issues to be addressed, there are benefits in using AI generative tools compared to using more traditional methods like human-human pair programming and code testing made by software engineering professionals. Contribution: It was possible to collect studies to identify in which activities of the software development process generative AI tools can be applied and what are the impacts of using this technology.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/f61990dfecc068ab4f41fa154865766456abf89b.pdf",
        "venue": "Brazilian Symposium on Information Systems",
        "citationCount": 0,
        "score": 0
    },
    "23607e0def6ded00b3dc374c22183852538cebe3.pdf": {
        "title": "Low Code for Smart Software Development",
        "authors": [
            "Jordi Cabot",
            "R. Claris\u00f3",
            "T. Menzies"
        ],
        "published_date": "2023",
        "abstract": "The more we know about patterns in code, the better we can support those patterns. In this article, Jordi Cabot and Robert Claris \u00b4o discuss the promise and perils of AI enhanced low-code environments that allow programmers and non=programmers alike to quickly deliver software solutions. They offer a \u201cwish list\u201d that outlines what developers need to watch for in low-code tools for smart software. Got anything else you want to say about SE+AI? For SE+AI applications, you have a surprising result or industrial experience? Something that challenges decades of conventional thinking in software engineering? If so, email a one paragraph synopsis to tim@menzies.us (use the subject line \u201cSE for AI: Idea: [your idea]\u201d). If that looks interesting, I\u2019ll ask you to submit a 1,000- to 2,400-word article (where each graph, table, or figure is worth 250 words) for review for IEEE Software. Note: Heresies are more than welcome (if supported by well-reasoned industrial experiences, case studies, or other empirical results).\u2014Tim Menzies",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/23607e0def6ded00b3dc374c22183852538cebe3.pdf",
        "venue": "IEEE Software",
        "citationCount": 0,
        "score": 0
    },
    "752e1ee49aeb941cbd7616b8c901237a0a5d2a83.pdf": {
        "title": "Ethics in AI through the practitioner's view: a grounded theory literature review",
        "authors": [
            "Aastha Pant",
            "Rashina Hoda",
            "C. Tantithamthavorn",
            "Burak Turhan"
        ],
        "published_date": "2022",
        "abstract": "The term ethics is widely used, explored, and debated in the context of developing Artificial Intelligence (AI) based software systems. In recent years, numerous incidents have raised the profile of ethical issues in AI development and led to public concerns about the proliferation of AI technology in our everyday lives. But what do we know about the views and experiences of those who develop these systems \u2013 the AI practitioners? We conducted a grounded theory literature review (GTLR) of 38 primary empirical studies that included AI practitioners\u2019 views on ethics in AI and analysed them to derive five categories: practitioner awareness, perception, need, challenge, and approach. These are underpinned by multiple codes and concepts that we explain with evidence from the included studies. We present a taxonomy of ethics in AI from practitioners\u2019 viewpoints to assist AI practitioners in identifying and understanding the different aspects of AI ethics. The taxonomy provides a landscape view of the key aspects that concern AI practitioners when it comes to ethics in AI. We also share an agenda for future research studies and recommendations for practitioners, managers, and organisations to help in their efforts to better consider and implement ethics in AI.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/752e1ee49aeb941cbd7616b8c901237a0a5d2a83.pdf",
        "venue": "Empirical Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "267e19842ee07b786572629d464cca56a0e1c6b3.pdf": {
        "title": "MLOps: A Guide to its Adoption in the Context of Responsible AI",
        "authors": [
            "B. M. A. Matsui",
            "Denise H. Goya"
        ],
        "published_date": "2022",
        "abstract": "DevOps practices have increasingly been applied to software development as well as the machine learning lifecycle, in a process known as MLOps. Currently, many professionals have written about this topic, but still few results can be found in the academic and scientific literature on MLOps and how to to implement it effectively. Considering aspects of responsible AI, this number is even lower, opening up a field of research with many possibilities. This article presents five steps to guide the understanding and adoption of MLOps in the context of responsible AI. The study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement MLOps practices to develop their systems, following responsible AI principles.CCS CONCEPTS\u2022 Software and its engineering \u2192 Software creation and management; \u2022 Computing methodologies \u2192 Machine learning.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/267e19842ee07b786572629d464cca56a0e1c6b3.pdf",
        "venue": "2022 IEEE/ACM 1st International Workshop on Software Engineering for Responsible Artificial Intelligence (SE4RAI)",
        "citationCount": 0,
        "score": 0
    },
    "2874c1b39e848bd32848de7a40a7b52fbab2c58a.pdf": {
        "title": "What is Software Quality for AI Engineers? Towards a Thinning of the Fog",
        "authors": [
            "Valentina Golendukhina",
            "Valentina Lenarduzzi",
            "M. Felderer"
        ],
        "published_date": "2022",
        "abstract": "It is often overseen that AI-enabled systems are also software systems and therefore rely on software quality assurance (SQA). Thus, the goal of this study is to investigate the software quality assurance strategies adopted during the development, integration, and maintenance of AI/ML components and code. We conducted semi-structured interviews with representatives of ten Austrian SMEs that develop AI-enabled systems. A qualitative analysis of the interview data identified 12 issues in the development of AI/ML components. Furthermore, we identified when quality issues arise in AI/ML components and how they are detected. The results of this study should guide future work on software quality assurance processes and techniques for AI/ML components.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/2874c1b39e848bd32848de7a40a7b52fbab2c58a.pdf",
        "venue": "2022 IEEE/ACM 1st International Conference on AI Engineering \u2013 Software Engineering for AI (CAIN)",
        "citationCount": 0,
        "score": 0
    },
    "3f063ccf18e0c9d42f6ecff72dc516ceeac9d4b0.pdf": {
        "title": "Operationalising AI ethics through the agile software development lifecycle: a case study of AI-enabled mobile health applications",
        "authors": [
            "L. M. Amugongo",
            "Alexander Kriebitz",
            "Auxane Boch",
            "C. L\u00fctge"
        ],
        "published_date": "2023",
        "abstract": "Although numerous ethical principles and guidelines have been proposed to guide the development of artificial intelligence (AI) systems, it has proven difficult to translate these principles into actionable practices beyond mere adherence to ethical ideas. This is particularly challenging in the context of AI systems for healthcare, which requires balancing the potential benefits of the solution against the risks to patients and the wider community, including minorities and underserved populations. To address this challenge, we propose a shift from one-size-fits-all ethical principles to contextualized case-based ethical frameworks. This study uses an AI-enabled mHealth application as a case study. Our framework is built on existing ethical guidelines and principles, including the AI4People framework, the EU High-Level Expert Group on trustworthy AI, and wider human rights considerations. Additionally, we incorporate relational perspectives to address human value concerns and moral tensions between individual rights and public health. Our approach is based on \u201dethics by design,\u201d where ethical principles are integrated throughout the entire AI development pipeline, ensuring that ethical considerations are not an afterthought but implemented from the beginning. For our case study, we identified 7 ethical principles: fairness, agility, precision, safeguarding humanity, respect for others, trust and accountability, and robustness and reproducibility. We believe that the best way to mitigate and address ethical consequences is by implementing ethical principles in the software development processes that developers commonly use. Finally, we provide examples of how our case-based framework can be applied in practice, using examples of AI-driven mobile applications in healthcare.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/3f063ccf18e0c9d42f6ecff72dc516ceeac9d4b0.pdf",
        "venue": "AI and Ethics",
        "citationCount": 0,
        "score": 0
    },
    "1ab2b071e2eca8627c1b39d8b85efc7ba4818d10.pdf": {
        "title": "Language Models in Software Development Tasks: An Experimental Analysis of Energy and Accuracy",
        "authors": [
            "Negar Alizadeh",
            "Boris Belchev",
            "N. Saurabh",
            "Patricia Kelbert",
            "Fernando Castor Filho"
        ],
        "published_date": "2024",
        "abstract": "The use of generative AI-based coding assistants like ChatGPT and Github Copilot is a reality in contemporary software development. Many of these tools are provided as remote APIs. Using third-party APIs raises data privacy and security concerns for client companies, which motivates the use of locallydeployed language models. In this study, we explore the tradeoff between model accuracy and energy consumption, aiming to provide valuable insights to help developers make informed decisions when selecting a language model. We investigate the performance of 18 families of LLMs in typical software development tasks on two real-world infrastructures, a commodity GPU and a powerful AI-specific GPU. Given that deploying LLMs locally requires powerful infrastructure which might not be affordable for everyone, we consider both full-precision and quantized models. Our findings reveal that employing a big LLM with a higher energy budget does not always translate to significantly improved accuracy. Additionally, quantized versions of large models generally offer better efficiency and accuracy compared to full-precision versions of medium-sized ones. Apart from that, not a single model is suitable for all types of software development tasks.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/1ab2b071e2eca8627c1b39d8b85efc7ba4818d10.pdf",
        "venue": "IEEE Working Conference on Mining Software Repositories",
        "citationCount": 0,
        "score": 0
    },
    "cf6d04ed9f209c88615cdc9596e0c1435f411567.pdf": {
        "title": "The Impact of Generative AI on Creativity in Software Development: A Research Agenda",
        "authors": [
            "Victoria Jackson",
            "Bogdan Vasilescu",
            "Daniel Russo",
            "Paul Ralph",
            "R. Prikladnicki",
            "Maliheh Izadi",
            "Sarah D'Angelo",
            "Sarah Inman",
            "Anielle Andrade",
            "Andr\u00e9 van der Hoek"
        ],
        "published_date": "2024",
        "abstract": "As GenAI becomes embedded in developer toolchains and practices, and routine code is increasingly generated, human creativity will be increasingly important for generating competitive advantage. This article uses the McLuhan tetrad alongside scenarios of how GenAI may disrupt software development more broadly, to identify potential impacts GenAI may have on creativity within software development. The impacts are discussed along with a future research agenda comprising five connected themes that consider how individual capabilities, team capabilities, the product, unintended consequences, and society can be affected.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/cf6d04ed9f209c88615cdc9596e0c1435f411567.pdf",
        "venue": "ACM Transactions on Software Engineering and Methodology",
        "citationCount": 0,
        "score": 0
    },
    "9b90291103892b9f9665c11461d7bc9ea40ea9ec.pdf": {
        "title": "MONAI: An open-source framework for deep learning in healthcare",
        "authors": [
            "M. Cardoso",
            "Wenqi Li",
            "Richard Brown",
            "Nic Ma",
            "E. Kerfoot",
            "Yiheng Wang",
            "Benjamin Murrey",
            "A. Myronenko",
            "Can Zhao",
            "Dong Yang",
            "V. Nath",
            "Yufan He",
            "Ziyue Xu",
            "Ali Hatamizadeh",
            "Wenjie Zhu",
            "Yun Liu",
            "Mingxin Zheng",
            "Yucheng Tang",
            "Isaac Yang",
            "Michael Zephyr",
            "Behrooz Hashemian",
            "Sachidanand Alle",
            "Mohammad Zalbagi Darestani",
            "C. Budd",
            "M. Modat",
            "Tom Kamiel Magda Vercauteren",
            "Guotai Wang",
            "Yiwen Li",
            "Yipeng Hu",
            "Yunguan Fu",
            "Benjamin L. Gorman",
            "Hans J. Johnson",
            "Brad W. Genereaux",
            "B. S. Erdal",
            "Vikash Gupta",
            "A. Diaz-Pinto",
            "Andre Dourson",
            "L. Maier-Hein",
            "P. Jaeger",
            "M. Baumgartner",
            "Jayashree Kalpathy-Cramer",
            "Mona G. Flores",
            "J. Kirby",
            "L. Cooper",
            "H. Roth",
            "Daguang Xu",
            "David Bericat",
            "R. Floca",
            "S. K. Zhou",
            "Haris Shuaib",
            "K. Farahani",
            "K. Maier-Hein",
            "S. Aylward",
            "Prerna Dogra",
            "S. Ourselin",
            "Andrew Feng"
        ],
        "published_date": "2022",
        "abstract": "Artificial Intelligence (AI) is having a tremendous impact across most areas of science. Applications of AI in healthcare have the potential to improve our ability to detect, diagnose, prognose, and intervene on human disease. For AI models to be used clinically, they need to be made safe, reproducible and robust, and the underlying software framework must be aware of the particularities (e.g. geometry, physiology, physics) of medical data being processed. This work introduces MONAI, a freely available, community-supported, and consortium-led PyTorch-based framework for deep learning in healthcare. MONAI extends PyTorch to support medical data, with a particular focus on imaging, and provide purpose-specific AI model architectures, transformations and utilities that streamline the development and deployment of medical AI models. MONAI follows best practices for software-development, providing an easy-to-use, robust, well-documented, and well-tested software framework. MONAI preserves the simple, additive, and compositional approach of its underlying PyTorch libraries. MONAI is being used by and receiving contributions from research, clinical and industrial teams from around the world, who are pursuing applications spanning nearly every aspect of healthcare.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/9b90291103892b9f9665c11461d7bc9ea40ea9ec.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "8908d069c4cb45ac2dd937e8c48712a766b037f6.pdf": {
        "title": "AI lifecycle models need to be revised",
        "authors": [
            "Mark Haakman",
            "Lu\u00eds Cruz",
            "Hennie Huijgens",
            "Arie van Deursen"
        ],
        "published_date": "2020",
        "abstract": "Tech-leading organizations are embracing the forthcoming artificial intelligence revolution. Intelligent systems are replacing and cooperating with traditional software components. Thus, the same development processes and standards in software engineering ought to be complied in artificial intelligence systems. This study aims to understand the processes by which artificial intelligence-based systems are developed and how state-of-the-art lifecycle models fit the current needs of the industry. We conducted an exploratory case study at ING, a global bank with a strong European base. We interviewed 17 people with different roles and from different departments within the organization. We have found that the following stages have been overlooked by previous lifecycle models: data collection, feasibility study, documentation, model monitoring, and model risk assessment. Our work shows that the real challenges of applying Machine Learning go much beyond sophisticated learning algorithms \u2013 more focus is needed on the entire lifecycle. In particular, regardless of the existing development tools for Machine Learning, we observe that they are still not meeting the particularities of this field.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/8908d069c4cb45ac2dd937e8c48712a766b037f6.pdf",
        "venue": "Empirical Software Engineering",
        "citationCount": 0,
        "score": 0
    },
    "7547680408358916e66917d03436fca7540a7528.pdf": {
        "title": "CodeNet: A Large-Scale AI for Code Dataset for Learning a Diversity of Coding Tasks",
        "authors": [
            "Ruchi Puri",
            "David S. Kung",
            "G. Janssen",
            "Wei Zhang",
            "Giacomo Domeniconi",
            "Vladmir A. Zolotov",
            "Julian Dolby",
            "Jie Chen",
            "M. Choudhury",
            "Lindsey Decker",
            "Veronika Thost",
            "Luca Buratti",
            "Saurabh Pujar",
            "Ulrich Finkler"
        ],
        "published_date": "2021",
        "abstract": "Over the last several decades, software has been woven into the fabric of every aspect of our society. As software development surges and code infrastructure of enterprise applications ages, it is now more critical than ever to increase software development productivity and modernize legacy applications. Advances in deep learning and machine learning algorithms have enabled numerous breakthroughs, motivating researchers to leverage AI techniques to improve software development efficiency. Thus, the fast-emerging research area of AI for Code has garnered new interest and gathered momentum. In this paper, we present a large-scale dataset CodeNet, consisting of over 14 million code samples and about 500 million lines of code in 55 different programming languages, which is aimed at teaching AI to code. In addition to its large scale, CodeNet has a rich set of high-quality annotations to benchmark and help accelerate research in AI techniques for a variety of critical coding tasks, including code similarity and classification, code translation between a large variety of programming languages, and code performance (runtime and memory) improvement techniques. Additionally, CodeNet provides sample input and output test sets for 98.5% of the code samples, which can be used as an oracle for determining code correctness and potentially guide reinforcement learning for code quality improvements. As a usability feature, we provide several pre-processing tools in CodeNet to transform source code into representations that can be readily used as inputs into machine learning models. Results of code classification and code similarity experiments using the CodeNet dataset are provided as a reference. We hope that the scale, diversity and rich, high-quality annotations of CodeNet will offer unprecedented research opportunities at the intersection of AI and Software Engineering.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/7547680408358916e66917d03436fca7540a7528.pdf",
        "venue": "NeurIPS Datasets and Benchmarks",
        "citationCount": 0,
        "score": 0
    },
    "439ee9451908eef05f3937e67ce5816f2b90d2a5.pdf": {
        "title": "Time for AI (Ethics) Maturity Model Is Now",
        "authors": [
            "Ville Vakkuri",
            "Marianna Jantunen",
            "Erika Halme",
            "Kai-Kristian Kemell",
            "Anh Nguyen-Duc",
            "T. Mikkonen",
            "P. Abrahamsson"
        ],
        "published_date": "2021",
        "abstract": "There appears to be a common agreement that ethical concerns are of high importance when it comes to systems equipped with some sort of Artificial Intelligence (AI). Demands for ethical AI are declared from all directions. As a response, in recent years, public bodies, governments, and universities have rushed in to provide a set of principles to be considered when AI based systems are designed and used. We have learned, however, that high-level principles do not turn easily into actionable advice for practitioners. Hence, also companies are publishing their own ethical guidelines to guide their AI development. This paper argues that AI software is still software and needs to be approached from the software development perspective. The software engineering paradigm has introduced maturity model thinking, which provides a roadmap for companies to improve their performance from the selected viewpoints known as the key capabilities. We want to voice out a call for action for the development of a maturity model for AI software. We wish to discuss whether the focus should be on AI ethics or, more broadly, the quality of an AI system, called a maturity model for the development of AI systems.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/439ee9451908eef05f3937e67ce5816f2b90d2a5.pdf",
        "venue": "SafeAI@AAAI",
        "citationCount": 0,
        "score": 0
    },
    "3ec861b28e230f4622d9e6950cabce00244baa26.pdf": {
        "title": "A Decade of Progress: A Systematic Literature Review on the Integration of AI in Software Engineering Phases and Activities (2013-2023)",
        "authors": [
            "U. Durrani",
            "Mustafa Akpinar",
            "M. Fatih Adak",
            "Abdullah Talha Kabakus",
            "Muhammed Maruf \u00d6zt\u00fcrk",
            "Mohammed Saleh"
        ],
        "published_date": "2024",
        "abstract": "The synergy between software engineering (SE) and artificial intelligence (AI) catalyzes software development, as numerous recent studies illustrate an intensified intersection between these domains. This systematic literature review examines the integration of AI techniques or methodologies across SE phases and related activities spanning from 2013 to 2023, resulting in the selection of 110 research papers. Investigating the profound influence of AI techniques, including machine learning, deep learning, natural language processing, optimization algorithms, and expert systems, across various SE phases\u2014such as planning, requirement engineering, design, development, testing, deployment, and maintenance\u2014is the focal point of this study. Notably, the extensive adoption of machine learning and deep learning algorithms in the development and testing phases has enhanced software quality through defect prediction, code recommendation, and vulnerability detection initiatives. Furthermore, natural language processing\u2019s role in automating requirements classification and sentiment analysis has streamlined SE practices. Optimization algorithms have also demonstrated efficacy in refining SE activities such as feature location and software repair action predictions, augmenting precision and efficiency in maintenance endeavors. Prospective research emphasizes the imperative of interpretable AI models and the exploration of novel AI paradigms, including explainable AI and reinforcement learning, to promote ethical and efficient software development practices. This paper fills the gap identified in AI techniques dedicated to improving SE phases. The review concludes that AI in SE is revolutionizing the discipline, enhancing software quality, efficiency, and innovation, with ongoing efforts targeting the mitigation of identified limitations and the augmentation of AI capabilities for intelligent and dependable SE.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/3ec861b28e230f4622d9e6950cabce00244baa26.pdf",
        "venue": "IEEE Access",
        "citationCount": 0,
        "score": 0
    },
    "62c3142956d54db158d190ce691e3c13e7897412.pdf": {
        "title": "Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims",
        "authors": [
            "Miles Brundage",
            "S. Avin",
            "Jasmine Wang",
            "Haydn Belfield",
            "Gretchen Krueger",
            "Gillian K. Hadfield",
            "Heidy Khlaaf",
            "Jingying Yang",
            "H. Toner",
            "Ruth Fong",
            "Tegan Maharaj",
            "Pang Wei Koh",
            "Sara Hooker",
            "Jade Leung",
            "Andrew Trask",
            "Emma Bluemke",
            "Jonathan Lebensbold",
            "Cullen O'Keefe",
            "Mark Koren",
            "T. Ryffel",
            "JB Rubinovitz",
            "T. Besiroglu",
            "F. Carugati",
            "Jack Clark",
            "P. Eckersley",
            "Sarah de Haas",
            "Maritza L. Johnson",
            "B. Laurie",
            "A. Ingerman",
            "Igor Krawczuk",
            "Amanda Askell",
            "Rosario Cammarota",
            "A. Lohn",
            "David Krueger",
            "C. Stix",
            "Peter Henderson",
            "L. Graham",
            "Carina E. A. Prunkl",
            "Bianca Martin",
            "Elizabeth Seger",
            "Noa Zilberman",
            "Se'an 'O h'Eigeartaigh",
            "F. Kroeger",
            "Girish Sastry",
            "R. Kagan",
            "Adrian Weller",
            "Brian Tse",
            "Elizabeth Barnes",
            "A. Dafoe",
            "P. Scharre",
            "Ariel Herbert-Voss",
            "Martijn Rasser",
            "Shagun Sodhani",
            "Carrick Flynn",
            "T. Gilbert",
            "Lisa Dyer",
            "Saif Khan",
            "Yoshua Bengio",
            "Markus Anderljung"
        ],
        "published_date": "2020",
        "abstract": "With the recent wave of progress in artificial intelligence (AI) has come a growing awareness of the large-scale impacts of AI systems, and recognition that existing regulations and norms in industry and academia are insufficient to ensure responsible AI development. In order for AI developers to earn trust from system users, customers, civil society, governments, and other stakeholders that they are building AI responsibly, they will need to make verifiable claims to which they can be held accountable. Those outside of a given organization also need effective means of scrutinizing such claims. This report suggests various steps that different stakeholders can take to improve the verifiability of claims made about AI systems and their associated development processes, with a focus on providing evidence about the safety, security, fairness, and privacy protection of AI systems. We analyze ten mechanisms for this purpose--spanning institutions, software, and hardware--and make recommendations aimed at implementing, exploring, or improving those mechanisms.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/62c3142956d54db158d190ce691e3c13e7897412.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "2280a192eaf49c66cf539269e9b7958b6f412cfb.pdf": {
        "title": "The centaur programmer - How Kasparov's Advanced Chess spans over to the software development of the future",
        "authors": [
            "P. Alves",
            "Bruno Pereira Cipriano"
        ],
        "published_date": "2023",
        "abstract": "We introduce the idea of Centaur Programmer, based on the premise that a collaborative approach between humans and AI will be more effective than AI alone, as demonstrated in centaur chess tournaments where mixed teams of humans and AI beat sole computers. The paper introduces several collaboration models for programming alongside an AI, including the guidance model, the sketch model, and the inverted control model, and suggests that universities should prepare future programmers for a more efficient and productive programming environment augmented with AI. We hope to contribute to the important discussion about the diverse ways whereby humans and AI can work together in programming in the next decade, how universities should handle these changes and some legal implications surrounding this topic.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/2280a192eaf49c66cf539269e9b7958b6f412cfb.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "98718a3535968ea7e89cd81a20786d53535b345b.pdf": {
        "title": "Enhancing Agile Software Development: A Systematic Literature Review of Requirement Prioritization and Reprioritization Techniques",
        "authors": [
            "Noshin Tasneem",
            "H. Zulzalil",
            "Sa\u2019adah Hassan"
        ],
        "published_date": "2025",
        "abstract": "Agile software development places great importance on requirement prioritization and reprioritization, which allow teams to concentrate on providing the most beneficial features to satisfy stakeholders. Most systematic review articles on prioritization techniques focus on traditional methods and ignore recent approaches that use artificial intelligence (AI). Additionally, there is a notable scarcity of literature addressing the neglected domain of reprioritisation and a lack of review papers analyzing semi-automated approaches. To fill this gap, this systematic literature review includes an in-depth review of newly developed AI-based and semi-automated techniques, in addition to widely used traditional prioritization methods. This study analyzed 76 primary studies from five credible electronic databases (Springer Link, IEEE Xplore, Scopus, Science Direct, and ACM Digital Library) to address six selected research questions. This literature review paper is unique in that it covers conventional approaches, reprioritization techniques, and AI-based and semi-automated techniques in a single review, which has not been done in previous papers. The findings highlight the strength and weakness of each technique. This review also identifies the most commonly used prioritization techniques in agile software development and the key challenges in requirement prioritization. Future research opportunities in the field of reprioritization are revealed by the gaps identified in the literature. This research contributes to enhancing the agility and effectiveness of agile software development (ASD).",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/98718a3535968ea7e89cd81a20786d53535b345b.pdf",
        "venue": "IEEE Access",
        "citationCount": 0,
        "score": 0
    },
    "06e5d18d333bd7cbf10072d52abdda3309ae9a50.pdf": {
        "title": "A secure and flexible edge computing scheme for AI-driven industrial IoT",
        "authors": [
            "Yan Zhao",
            "Ning Hu",
            "Yue Zhao",
            "Zhihan Zhu"
        ],
        "published_date": "2021",
        "abstract": "",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/06e5d18d333bd7cbf10072d52abdda3309ae9a50.pdf",
        "venue": "Cluster Computing",
        "citationCount": 0,
        "score": 0
    },
    "05086329135fdb15049a5ac8edd7f980762f2097.pdf": {
        "title": "What Is Really Different in Engineering AI-Enabled Systems?",
        "authors": [
            "Ipek Ozkaya"
        ],
        "published_date": "2020",
        "abstract": "Advances in machine learning (ML) algorithms and increasing availability of computational power have resulted in huge investments in systems that aspire to exploit artificial intelligence (AI), in particular ML. AIenabled systems, software-reliant systems that include data and components that implement algorithms mimicking learning and problem solving, have inherently different characteristics than software systems alone.1 However, the development and sustainment of such systems also have many parallels with building, deploying, and sustaining software systems. A common observation is that although software systems are deterministic and you can build and test to a specification, AI-enabled systems, in particular those that include ML components, are generally probabilistic. Systems with ML components can have a high margin of error due to the uncertainty that often follows predictive algorithms. The margin of error can be related to the inability to predict the result in advance or the same result cannot be reproduced. This characteristic makes AI-enabled systems hard to test and verify.2 Consequently, it is easy to assume that what we know about designing and reasoning about software systems does not immediately apply in AI engineering. AI-enabled systems are software systems. The sneaky part about engineering AI systems is they are \"just like\" conventional software systems we can design and reason about until they?re not.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/05086329135fdb15049a5ac8edd7f980762f2097.pdf",
        "venue": "IEEE Software",
        "citationCount": 0,
        "score": 0
    },
    "8c3c3273fd0e05a3e40853811b218b0da7f28706.pdf": {
        "title": "A Roadmap for Software Testing in Open-Collaborative and AI-Powered Era",
        "authors": [
            "Qing Wang",
            "Junjie Wang",
            "Mingyang Li",
            "Yawen Wang",
            "Zhe Liu"
        ],
        "published_date": "2024",
        "abstract": "Internet technology has given rise to an open-collaborative software development paradigm, necessitating the open-collaborative schema to software testing. It enables diverse and globally distributed contributions, but also presents significant challenges to efficient testing processes, coordination among personnel, and management of testing artifacts. At the same time, advancements in AI have enhanced testing capabilities and enabling automation, while also introducing new testing needs and unique challenges for AI-based systems. In this context, this article explores software testing in the open-collaborative and AI-powered era, focusing on the interrelated dimensions of process, personnel, and technology. Among them, process involves managing testing workflows and artifacts to improve efficiency, personnel emphasizes the role of individuals in ensuring testing quality through collaboration and contributions, while technology refers to AI methods that enhance testing capabilities and address challenges in AI-based systems. Furthermore, we delve into the challenges and opportunities arising from emerging technologies such as Large Language Models (LLMs) and the AI model-centric development paradigm.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/8c3c3273fd0e05a3e40853811b218b0da7f28706.pdf",
        "venue": "ACM Transactions on Software Engineering and Methodology",
        "citationCount": 0,
        "score": 0
    },
    "9471912f9e788a4b2ac1ba4e73098c04517ee9e8.pdf": {
        "title": "AI-Driven accessibility: Transformative software solutions for empowering individuals with disabilities",
        "authors": [
            "Nnaemeka Valentine Eziamaka",
            "Theodore Narku Odonkor",
            "Adetola Adewale Akinsulire"
        ],
        "published_date": "2024",
        "abstract": "The integration of artificial intelligence (AI) in developing software solutions marks a pivotal advancement in enhancing accessibility for individuals with disabilities. This paper explores the transformative potential of AI-driven technologies designed to empower those with physical, sensory, and cognitive impairments. AI's capability to learn and adapt to diverse user needs enables the creation of personalized and intuitive applications, offering unprecedented levels of independence and inclusion. AI-driven accessibility solutions encompass various innovations, including speech recognition, natural language processing (NLP), and computer vision. Speech recognition technologies facilitate communication for individuals with speech and hearing impairments by converting spoken language into text and vice versa. NLP advancements have enabled the development of sophisticated text-to-speech systems, which can read aloud text content for visually impaired users, and text prediction tools that assist users with motor impairments in typing efficiently. Furthermore, computer vision technology provides real-time image and video recognition, aiding visually impaired users in navigating their environment and identifying objects. These AI-driven tools are integrated into everyday devices and platforms, significantly enhancing their utility and accessibility. For instance, AI-powered screen readers and voice assistants are now embedded in smartphones and computers, providing seamless access to information and digital services. Educational software leveraging AI ensures that learning materials are accessible to all students, regardless of their disabilities, by providing tailored content and support. The impact of AI-driven accessibility solutions extends beyond personal empowerment to societal inclusion. By enabling greater participation in education, employment, and social activities, these technologies help bridge the gap between individuals with disabilities and their peers. Companies and organizations benefit from the diverse talents and perspectives of a more inclusive workforce, driving innovation and economic growth. However, the development and implementation of AI-driven accessibility solutions also present challenges. Ensuring data privacy and security, avoiding bias in AI algorithms, and maintaining affordability and user-friendliness are critical considerations. Ongoing research, collaboration among stakeholders, and inclusive design practices are essential to address these challenges and maximize the benefits of AI for accessibility. In conclusion, AI-driven accessibility solutions are revolutionizing the way individuals with disabilities interact with the world. By harnessing the power of AI, these technologies offer transformative opportunities for independence, inclusion, and empowerment, ultimately contributing to a more equitable and accessible society. \nKeywords: Al-Driven, Accessibility, Transformative, Disabilities, Empowering.",
        "file_path": "paper_data/AI_for_Software_Development_Compliance/9471912f9e788a4b2ac1ba4e73098c04517ee9e8.pdf",
        "venue": "International journal of applied research in social sciences",
        "citationCount": 0,
        "score": 0
    }
}