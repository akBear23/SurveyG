\subsection*{Traditional AI/ML for Code and Artifact Analysis}

Automated compliance checking is a cornerstone for ensuring software adheres to established rules, standards, and regulatory requirements throughout the software development lifecycle. This subsection explores the application of traditional Artificial Intelligence (AI) and Machine Learning (ML) techniques, including Natural Language Processing (NLP) and static analysis, to systematically analyze software requirements, design documents, and source code. The objective is to identify deviations from established norms, thereby reducing manual effort, improving accuracy, and streamlining early-stage compliance verification through reactive detection of implicit rule violations and explicit checking against formalized knowledge.

Early and ongoing efforts in leveraging AI for software engineering, particularly in the requirements phase, have established foundational groundwork for compliance verification. Natural Language Processing (NLP) techniques are extensively used to analyze textual requirements documents for ambiguities, inconsistencies, or potential non-compliance. \cite{liu2022g3w} provides a comprehensive review of AI in Software Requirements Engineering (RE), highlighting the significant role of NLP and supervised learning techniques like classification in analyzing requirements. This approach is crucial for identifying implicit rules or making them explicit and detectable, serving as an initial step towards automated compliance checking. Similarly, \cite{durrani2024qoz} further emphasizes NLP's role in automating requirements classification and sentiment analysis, which streamlines RE practices and can help flag compliance-critical requirements for closer scrutiny. However, the complexity of requirements for AI-based systems themselves presents unique challenges, as highlighted by \cite{belani20194yc}. Issues such as the "black-box" nature of ML models and their inherent data dependencies complicate traditional RE activities, impacting the traceability and auditability of requirements for AI systems used in compliance, thereby posing a meta-challenge for trustworthy AI-driven compliance.

Beyond requirements, traditional AI/ML techniques extend to the analysis of design documents and architectural artifacts. Knowledge-based systems, often relying on formalized ontologies and rule engines, enable explicit checking against predefined compliance rules. These systems can represent regulatory text and software artifacts in a structured manner, allowing for logical inference to identify non-compliant designs or architectural structures. More recently, AI, including advanced NLP capabilities, has been applied to semi-automatically generate software architectures from textual requirements. For instance, \cite{eisenreich20243sq} proposes an iterative, AI-based process that leverages Large Language Models (LLMs) to generate initial domain models and architecture candidates from natural language requirements. While utilizing modern LLMs, the underlying task of translating natural language into structured design artifacts and evaluating them against quality attributes (which can include compliance) represents an evolution of traditional AI's role in design analysis, aiming to reduce manual effort and explore more design alternatives.

For source code and other executable artifacts, Machine Learning (ML) classifiers and pattern mining techniques are widely employed. ML classifiers, trained on labeled datasets of compliant and non-compliant code snippets or design patterns, can automatically categorize new artifacts, significantly reducing manual effort in compliance audits. For example, in the domain of software quality and security (which are often compliance concerns), AI-based defect prediction (SDP) frameworks like DePaaS, as discussed by \cite{pandit2022w11}, utilize various ML models to isolate defective software modules and identify risky code changes. This directly contributes to compliance by flagging code that deviates from quality standards. \cite{durrani2024qoz} further corroborates this, noting the extensive adoption of ML and deep learning algorithms in development and testing phases for "defect prediction, code recommendation, and vulnerability detection initiatives." These initiatives often involve analyzing code features (e.g., from Abstract Syntax Trees, control flow graphs) to detect patterns indicative of security vulnerabilities or violations of secure coding standards. Similarly, API usage pattern mining employs data mining techniques to learn common or "correct" sequences of API calls from existing codebases. Deviations from these learned patterns can signal potential non-compliance with coding standards, security policies, or resource management rules, offering a reactive detection mechanism for implicit rule violations. Furthermore, AI-based software testing, as reviewed by \cite{bayr20238ff}, enhances traditional testing methodologies to ensure quality, reliability, and security, directly contributing to compliance verification in the later stages of the development lifecycle.

Despite their utility, traditional AI/ML approaches face several limitations. Their effectiveness often hinges on the quality and quantity of labeled data, which can be expensive and time-consuming to acquire for specific compliance domains. The explicit formalization of complex compliance rules into knowledge-based systems or training data for ML models can also be challenging. Scalability can be an issue with complex, evolving regulations, requiring continuous model retraining and rule updates. Moreover, the interpretability of some ML models, often referred to as the "black-box" problem, can hinder auditability and trust in highly regulated environments, making it difficult to justify compliance decisions to human auditors or regulatory bodies. This challenge is particularly acute when the AI system itself is subject to compliance, as discussed by \cite{belani20194yc}. Nevertheless, these techniques have significantly advanced the automation of compliance checking, moving the field from purely manual reviews to more efficient, data-driven, and reactive verification processes, laying the groundwork for more proactive and advanced AI applications.