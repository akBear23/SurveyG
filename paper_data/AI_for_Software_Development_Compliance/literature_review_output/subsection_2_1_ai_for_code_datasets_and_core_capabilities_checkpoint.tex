\subsection{AI for Code: Datasets and Core Capabilities}
The foundational advancement of Artificial Intelligence in software engineering is intrinsically linked to the development of robust data infrastructure and the establishment of core AI capabilities for understanding, processing, and manipulating code. This subsection delves into the essential data resources and initial AI systems that have addressed the data bottleneck, enabling the development of models capable of tasks such as code similarity, classification, and translation, thereby laying the groundwork for more sophisticated compliance-related analyses.

Historically, a significant impediment to AI for code research was the scarcity of large-scale, diverse, and richly annotated code datasets. This data bottleneck limited the training of sophisticated models capable of generalizing across various programming languages and tasks. A pivotal contribution to overcoming this challenge was the introduction of CodeNet by \textcite{puri2021d34}. CodeNet represents a monumental dataset, comprising over 14 million code samples and 500 million lines of code spanning 55 programming languages. This scale and linguistic diversity significantly surpassed its predecessors, such as POJ-104 and GCJ, which were often limited in scope or lacked comprehensive metadata. CodeNet's richness is further enhanced by crucial metadata, including submission status (e.g., Accepted, Wrong Answer), execution time, memory usage, problem descriptions, and input/output test cases. The methodologies employed for its creation involved rigorous data curation, meticulous cleansing using Jaccard similarity to identify and flag near-duplicates, and the provision of pre-processing tools for tokenization and parse-tree generation. These efforts ensured the high quality and usability of the data for training robust AI models. However, despite its scale, CodeNet primarily consists of solutions to competitive programming problems, which may introduce biases towards specific algorithmic patterns and pedagogical code, potentially limiting its direct applicability to complex enterprise-level software with diverse architectural patterns, proprietary APIs, and varied coding styles \cite{puri2021d34}. Furthermore, the provenance of such scraped data raises concerns regarding potential license contamination and the overall quality of code from public sources.

The availability of such large-scale datasets has been instrumental in enabling the development of foundational AI capabilities for code. These capabilities often begin with learning effective code representations. Models like CodeBERT \cite{feng2020codebert} and GraphCodeBERT \cite{guo2020graphcodebert} (though not explicitly in the filtered list, these are seminal examples of such foundational models that leverage large code corpora) are pre-trained on vast amounts of code and natural language to learn rich, contextual embeddings of code. These learned representations underpin a variety of core tasks:
\begin{itemize}
    \item \textbf{Code Similarity and Clone Detection}: Identifying functionally similar or duplicated code segments, crucial for refactoring, plagiarism detection, and identifying potential vulnerabilities.
    \item \textbf{Code Classification}: Categorizing code based on programming language, task type, or intent, which supports automated code organization and analysis.
    \item \textbf{Code Translation/Transpilation}: Converting code between different programming languages, a complex task that benefits from deep semantic understanding.
    \item \textbf{Code Summarization}: Generating concise natural language descriptions of code snippets, aiding documentation and code comprehension.
    \item \textbf{Code Search}: Enabling developers to find relevant code based on natural language queries, improving productivity.
\end{itemize}

Building upon these representational capabilities, initial generative AI models have emerged, aiming to automate code creation and assist developers. These tools leverage the patterns learned from extensive code datasets to generate code snippets, complete functions, and even suggest solutions to programming problems. For instance, generative AI algorithms are increasingly employed for automated test-case generation and bug identification, analyzing codebases and execution traces to uncover test scenarios and detect anomalous patterns indicative of bugs or vulnerabilities \cite{bajaj2023psw}. This capability promises amplified test coverage and efficiency gains, directly contributing to software quality.

However, the initial capabilities of AI for code, particularly in code generation, are not without significant limitations, necessitating critical human oversight. While these tools can generate functional code, they often struggle with accuracy and deep contextual understanding, frequently producing suboptimal, incorrect, or contextually irrelevant code \cite{aarti2024abq}. A critical evaluation by \textcite{pudari2023oep} demonstrated that even prominent AI code completion tools largely fail to suggest idiomatic code or adhere to established best practices as their primary suggestions. This suggests that current models are heavily influenced by the frequency of patterns in their training data rather than their optimality or adherence to higher-level software quality attributes, requiring developers to critically review and often correct AI-generated output. Furthermore, the integration of generative AI into software development introduces security risks, as AI-generated code can inadvertently replicate insecure coding practices, introduce biases, or even "hallucinate" non-sensical or vulnerable code \cite{haque2025vb3}. These issues underscore the need for robust security measures, thorough developer review, and continuous testing to mitigate the risks associated with AI-assisted code generation.

In conclusion, the foundational efforts in creating large-scale, diverse, and richly annotated datasets like CodeNet \cite{puri2021d34} have been instrumental in overcoming the data bottleneck for AI in code. These datasets have enabled the development of initial AI capabilities ranging from basic code understanding and representation to foundational tasks like code similarity, classification, translation, and initial code generation. While these advancements significantly enhance software development, the inherent limitations in the quality, security, and contextual understanding of AI-generated code \cite{aarti2024abq, pudari2023oep, haque2025vb3} highlight the continuous need for improved data curation, more sophisticated AI models, and robust human oversight. These foundational capabilities are indispensable for building future AI systems capable of performing complex compliance-related analyses, such as automated security auditing, license compliance checking, and adherence to coding standards, by providing the underlying intelligence to understand and interact with code at a deep level.