\subsection*{Early Graph Neural Network Models: Fixed-Point Iteration}

The initial conceptualization of Graph Neural Networks (GNNs) emerged from the challenge of extending neural network capabilities to non-Euclidean graph domains, particularly focusing on models that learn node representations through an iterative information propagation process, aiming to reach a stable fixed-point. These pioneering models laid the crucial theoretical and mathematical groundwork for the entire field, establishing the idea of learning structural information through local aggregation.

One of the earliest and most influential works in this direction was proposed by \cite{Gori05}, which introduced a novel "neural network for graphs." This model conceptualized node states as being updated iteratively based on their previous state and the states of their neighbors, along with the features of the edges connecting them. The core idea was to propagate information across the graph until the node states converged to a stable equilibrium, effectively encoding the structural context of each node into its representation. This foundational work established the paradigm of a state-transition system on graphs, where node embeddings are derived from a recursive update rule.

Building upon this initial framework, \cite{Scarselli09} formalized the Graph Neural Network (GNN) model, defining it as an extension of recursive neural networks capable of processing general graph structures. Their model explicitly defined a node's state (embedding) as the fixed-point of a contraction mapping, ensuring convergence and uniqueness of the solution. The GNN model, as formulated by \cite{Scarselli09}, utilized an iterative update function to compute the state of each node, considering its own features and the features of its neighbors and incident edges, until a stable fixed-point was attained. This theoretical underpinning demonstrated the GNN's ability to approximate universal functions on graphs, meaning it could, in principle, learn any computable function on graph-structured data. The output function then mapped these learned fixed-point states to task-specific predictions, such as node or graph classification.

Despite their theoretical elegance and foundational importance in establishing the GNN paradigm, these early fixed-point models faced significant practical limitations that hindered their widespread adoption. A primary concern was computational complexity; reaching a stable fixed-point often required numerous iterative steps, making training and inference computationally expensive, especially for large graphs. The convergence of these fixed-point iterations was also a practical challenge, as guaranteeing and achieving convergence in real-world scenarios could be difficult. Furthermore, the scalability of these models to large graphs was severely limited due to the global nature of fixed-point computation, which often necessitated processing the entire graph repeatedly. Training these models involved backpropagating gradients through potentially many unrolled fixed-point iterations, which could be cumbersome and prone to vanishing or exploding gradients. These practical constraints, particularly concerning computational efficiency, convergence guarantees, and scalability, spurred subsequent research into more efficient and scalable GNN architectures that moved away from strict fixed-point iteration in favor of finite-layer message-passing schemes.