\subsection{Self-Supervised and Generative Pre-training for GNNs}

The pervasive scarcity of labeled graph data presents a significant bottleneck for training powerful Graph Neural Networks (GNNs) in numerous real-world applications. To circumvent this, researchers have increasingly focused on developing robust pre-training strategies that leverage vast amounts of unlabeled graph data to learn transferable representations. This paradigm aims to overcome issues like negative transfer and enhance generalization across diverse downstream tasks, thereby maximizing the utility of GNNs. This section delves into the evolution of self-supervised and generative pre-training methods, highlighting their core principles, key advancements, and remaining challenges.

Early foundational work systematically investigated strategies for pre-training GNNs by designing various self-supervised pretext tasks. \cite{hu2019r47} pioneered a comprehensive approach by proposing tasks at both node and graph levels. Node-level tasks included context prediction (predicting a node's K-hop neighborhood) and attribute masking (reconstructing masked node/edge attributes), while graph-level tasks focused on predicting graph-level properties or generating graph summaries. This combined strategy was crucial for learning meaningful local and global representations and was shown to effectively mitigate negative transfer, a common pitfall when naively applying pre-training. Beyond these, other predictive self-supervised tasks include link prediction, predicting structural roles or properties (e.g., node centrality, community membership proxies), and graph reconstruction via autoencoders \cite{xie2021n52}. These methods train GNNs to capture inherent graph characteristics by generating labels directly from the graph structure itself.

A dominant and highly influential paradigm in self-supervised learning for GNNs is contrastive learning. Inspired by its success in computer vision and natural language processing, contrastive methods aim to learn robust representations by maximizing the mutual information between different augmented "views" of a graph or its components. The core idea is to pull positive pairs (different augmentations of the same graph or node) closer in the embedding space while pushing negative pairs (augmentations of different graphs or nodes) further apart. Key to this approach is the design of effective graph augmentation strategies, which can involve node/edge dropping, feature masking, subgraph sampling, or diffusion-based transformations \cite{xie2021n52}.

Seminal works in contrastive graph learning include Deep Graph Infomax (DGI) \cite{velickovic2019deep}, which maximizes mutual information between node representations and a global graph summary, distinguishing positive local-global pairs from corrupted negative ones. GraphCL \cite{you2020graphcl} further generalized this by exploring various graph augmentation strategies to generate diverse views, demonstrating that the choice of augmentation is critical for effective pre-training. GRACE \cite{zhu2020deep} extended this to node-level contrastive learning, applying both feature and structure corruption to generate two distinct views of a node, then maximizing agreement between their representations. While effective, traditional contrastive methods often rely on carefully constructed negative samples, which can be computationally intensive or challenging to define optimally. Addressing this, \cite{zhang20211dl} proposed a conceptually simple yet effective model that moves away from explicit negative sampling. Inspired by Canonical Correlation Analysis (CCA), their method generates two views of an input graph through augmentation but optimizes a feature-level objective to learn invariant representations and prevent degenerated solutions by decorrelating features in different dimensions. This approach essentially aims to discard augmentation-variant information, offering an alternative to traditional contrastive objectives.

Beyond self-supervised predictive and contrastive tasks, generative pre-training approaches model the underlying graph structure and features directly. Building upon the concept of learning general graph knowledge, \cite{hu2020u8o} introduced GPT-GNN, a generative pre-training framework that models the likelihood of an attributed graph by explicitly factorizing the generation process into coupled attribute and edge generation tasks. This novel dependency-aware factorization allowed the GNN to capture the intricate interplay between node features and graph structure, providing a more holistic understanding of the graph compared to simpler self-supervised pretext tasks. Such generative models aim to learn the data distribution of graphs, enabling them to synthesize new graphs or reconstruct corrupted ones, thereby acquiring a deep understanding of graph topology and feature dependencies.

The utility of self-supervised pre-training extends to complex graph types, such as Heterogeneous Information Networks (HINs). \cite{wei20246l2} demonstrated how self-supervised GNNs can enhance feature extraction in HINs, addressing challenges like heterogeneity and redundancy by flexibly combining different types of additional information. This highlights the adaptability of self-supervision in mining deep features from diverse and complex graph data, improving model adaptability and overall performance. Furthermore, \cite{lu20213kr} recognized the inherent objective divergence between pre-training and downstream fine-tuning. They proposed L2P-GNN, which leverages a meta-learning framework to explicitly optimize the GNN's ability to rapidly adapt to new tasks during pre-training, thereby learning more transferable prior knowledge and bridging the gap between the two phases.

The progression from simple self-supervised pretext tasks to sophisticated contrastive and generative modeling highlights a clear trajectory in GNN research: from learning general graph knowledge to efficiently leveraging that knowledge for specific, often low-resource, tasks. While significant strides have been made in overcoming labeled data scarcity and mitigating negative transfer, persistent challenges remain. These include designing truly universal pre-training objectives that inherently support diverse downstream tasks without requiring extensive task-specific engineering, and developing more principled graph augmentation strategies for contrastive learning that are robust across various graph domains. Future research will likely focus on exploring more theoretically grounded approaches to view generation, developing unified frameworks that combine the strengths of predictive, contrastive, and generative methods, and extending these paradigms to increasingly complex graph structures such as dynamic, temporal, and heterogeneous graphs.