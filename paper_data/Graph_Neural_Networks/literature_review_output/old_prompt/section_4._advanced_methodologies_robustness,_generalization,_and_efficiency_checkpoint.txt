\section*{4. Advanced Methodologies: Robustness, Generalization, and Efficiency}
The remarkable progress of Graph Neural Networks (GNNs) has been significantly driven by the development of sophisticated methodologies that address their limitations in real-world deployment. While earlier advancements focused on enhancing expressiveness and mitigating fundamental issues like over-smoothing and heterophily, the current frontier emphasizes making GNNs more robust, generalizable, and efficient. This section delves into these advanced techniques, which are crucial for transitioning GNNs from theoretical promise to practical applicability across diverse domains. It explores the evolution of self-supervised learning and pre-training, enabling GNNs to learn from vast amounts of unlabeled graph data and generalize to new tasks. Furthermore, it examines the emergence of prompt-based adaptation, a paradigm shift for efficient transfer learning, including the integration of multi-modal information with large language models. Critical concerns regarding GNN robustness against adversarial attacks and their resilience to inherent data imperfections are also addressed, highlighting the ongoing "arms race" between attackers and defenders. Finally, the section investigates geometric and equivariant GNNs, which are specifically designed to respect physical symmetries and incorporate spatial information, proving indispensable for applications in fields like molecular modeling and physics simulations. These advanced methodologies collectively aim to equip GNNs with the necessary capabilities for reliable and effective operation in complex, dynamic, and often imperfect real-world environments \cite{wu2022ptq, zhang20222g3, velickovic2023p4r}.

\subsection*{Self-Supervised Learning and Pre-training Strategies}
The success of deep learning models in other domains, particularly in natural language processing and computer vision, has been heavily reliant on large-scale pre-training using self-supervised learning (SSL) objectives, followed by fine-tuning on downstream tasks. This paradigm has proven instrumental in improving generalization and addressing data scarcity, and GNNs are increasingly adopting similar strategies \cite{xie2021n52}. The motivation stems from the fact that labeled graph data is often expensive or difficult to obtain, while unlabeled graph structures are abundant. Self-supervised learning for GNNs typically involves creating auxiliary tasks that allow the model to learn meaningful node or graph representations without explicit human annotations.

Early approaches to pre-training GNNs focused on tasks like predicting node attributes, reconstructing graph structure (e.g., edges or subgraphs), or maximizing mutual information between node embeddings and their contexts \cite{hu2019r47, lu20213kr}. Generative pre-training, exemplified by models like GPT-GNN \cite{hu2020u8o}, aims to generate graph structures or node features, thereby learning a comprehensive understanding of graph topology and attributes. More recently, contrastive learning has emerged as a dominant paradigm, where GNNs learn by maximizing agreement between different augmented views of the same node or graph, while minimizing agreement with negative samples \cite{zhang20211dl}. This involves creating multiple perturbed versions of a graph (e.g., via edge dropping, feature masking, or subgraph sampling) and training the GNN to produce similar embeddings for different views of the same entity. Such methods have shown significant promise in learning robust and transferable representations, particularly for tasks like link prediction in biomedical networks \cite{long2022l97} or enhancing feature extraction in heterogeneous information networks \cite{wei20246l2}.

While SSL and pre-training offer substantial benefits in terms of generalization and data efficiency, they present unique challenges in the graph domain. The choice of graph augmentation strategies can significantly impact the quality of learned representations, and designing augmentations that preserve essential semantic or structural information while introducing sufficient perturbation remains an active research area \cite{zhao2020bmj}. Furthermore, the computational cost of pre-training on very large graphs can be prohibitive, necessitating scalable architectures and training strategies \cite{vasimuddin2021x7c}. The "task-agnostic" nature of many pre-training objectives might also lead to a mismatch with specific downstream tasks, requiring careful fine-tuning or more task-aware pre-training designs. For instance, pre-training for molecular property prediction often requires domain-specific inductive biases, as seen in models like Mole-BERT \cite{xia2023bpu}. The evolution of these strategies reflects a continuous effort to balance the generality of learned representations with the specificity required for high performance on diverse real-world applications.

\subsection*{Prompt-based Adaptation and Multi-modal Learning}
Building upon the success of pre-trained GNNs, prompt-based adaptation has emerged as a powerful paradigm for efficient transfer learning, particularly for few-shot or low-resource scenarios. Inspired by the success of prompt engineering in Large Language Models (LLMs), this approach aims to adapt a pre-trained GNN to diverse downstream tasks by formulating the task as a "prompt" rather than requiring extensive fine-tuning of all model parameters. This significantly reduces the number of trainable parameters and accelerates adaptation, making GNNs more efficient for real-world deployment across a multitude of tasks \cite{sun2022d18, fang2022tjj}.

Prompt tuning for GNNs typically involves adding a small, learnable "prompt" module (e.g., a set of virtual nodes, edges, or feature vectors) to the input graph or intermediate layers of a pre-trained GNN. This prompt is then optimized for a specific downstream task, guiding the pre-trained model to extract relevant information without altering its core learned representations. Models like GPPT \cite{sun2022d18} and GraphPrompt \cite{liu2023ent} demonstrate how this strategy can achieve competitive performance with full fine-tuning while being significantly more parameter-efficient. The flexibility of prompting also extends to multi-task learning, where a single pre-trained GNN can be adapted to multiple objectives using different prompts \cite{sun2023vsl}.

A particularly exciting and rapidly developing direction is the integration of GNNs with large language models (LLMs) for multi-modal learning. This addresses the limitation that GNNs primarily operate on graph topology and node features, often lacking the rich semantic understanding that LLMs possess. By leveraging LLMs, GNNs can incorporate textual descriptions, external knowledge, or even user queries to enhance their understanding of graph entities and relationships. For instance, GNNs can be used to process graph structures, while LLMs interpret associated text, with prompt-based interfaces facilitating their interaction. This synergy enables tasks like knowledge graph completion with natural language queries, text-guided graph neural networks for 3D instance segmentation \cite{huang2021lpu}, or even learning language with extremely weak text supervision on graphs \cite{li202444f}. Recent work explores how LLMs can even improve the adversarial robustness of GNNs by providing semantic context for defense strategies \cite{zhang2024370}. The Hybrid-LLM-GNN framework, for example, integrates LLMs and GNNs for enhanced materials property prediction, demonstrating the power of combining symbolic and structural reasoning \cite{li2024gue}. However, challenges remain in effectively aligning the discrete, structural nature of graphs with the continuous, semantic space of language models, and in designing prompts that are robust and generalizable across diverse multi-modal tasks \cite{castroospina2024iy2}. The interpretability of such hybrid models also becomes more complex, as disentangling the contributions of graph structure and linguistic prompts is non-trivial.

\subsection*{Robustness to Adversarial Attacks and Data Imperfections}
The deployment of GNNs in critical applications, such as cybersecurity \cite{mitra2024x43, bilot20234ui}, fraud detection \cite{duan2024que}, and medical diagnostics \cite{abadal2024w7e}, necessitates strong guarantees of robustness against adversarial attacks and resilience to inherent data imperfections. This area has become an intense "arms race" between attackers seeking to compromise GNN integrity and defenders striving to build more secure models \cite{dai2022hsi, zhang20222g3}.

Adversarial attacks on GNNs can be broadly categorized into poisoning attacks (at training time) and evasion attacks (at inference time). Poisoning attacks aim to inject malicious nodes or perturb graph structures and features in the training data to degrade model performance or induce specific misclassifications \cite{zhang2020b0m, zou2021qkz}. Backdoor attacks, a specific type of poisoning, embed hidden triggers in the training graph such that a GNN behaves maliciously only when these triggers are present in the input \cite{dai2023tuj}. Evasion attacks, on the other hand, involve subtly perturbing the graph structure or node features of a test instance to cause misclassification without altering the model itself \cite{zgner2019bbi, xu2019l8n}. The non-Euclidean nature of graph data makes these attacks particularly challenging to detect and defend against, as small, imperceptible changes in topology can have cascading effects through message passing.

Defense strategies against adversarial attacks include adversarial training \cite{gosch20237yi}, where models are trained on adversarially perturbed graphs to improve their resilience. Robust aggregation mechanisms, which filter out noisy or malicious messages, and certified robustness methods, which provide provable guarantees on model predictions within a certain perturbation budget, are also actively researched \cite{xia2024xc9, abbahaddou2024bq2}. Graph structure learning, where the GNN learns to adaptively refine or prune its input graph, can also enhance robustness by mitigating the impact of malicious edges \cite{jin2020dh4}. However, a critical analysis reveals that many proposed defenses are evaluated against simplified attack models or specific perturbation types, and their effectiveness against adaptive, stronger attacks remains questionable \cite{mujkanovic20238fi}. There is a clear trade-off between robustness and accuracy, where highly robust models may sacrifice some performance on clean data.

Beyond adversarial attacks, GNNs must also contend with inherent data imperfections, such as noisy labels \cite{dai2022xze}, missing features, and various forms of bias. Data augmentation techniques can help improve robustness to noise \cite{zhao2020bmj}, while methods for learning with weak information \cite{liu2023v3e} or sparse labels \cite{wang2024htw} are crucial for real-world datasets. Addressing data bias, which can lead to unfair or discriminatory outcomes, is another significant concern \cite{dong2021qcg, fan2022m67}. Techniques like disentangled causal substructure learning \cite{fan2022m67} and re-balancing strategies \cite{li20245zy} aim to mitigate bias and improve fairness in GNN predictions. The challenge lies in developing methods that are simultaneously robust to diverse imperfections, computationally efficient, and maintain high predictive performance, often requiring a delicate balance between these competing objectives \cite{zhang2024ctj}.

\subsection*{Geometric and Equivariant Graph Neural Networks}
For domains where physical symmetries and spatial arrangements are paramount, such as molecular modeling, materials science, and physics simulations, standard GNNs that are merely permutation-invariant fall short. These applications demand models that are not only invariant to permutations of nodes but also *equivariant* to geometric transformations (e.g., rotations, translations, reflections) of the input coordinates. Geometric and equivariant GNNs are specifically designed to incorporate these inductive biases, ensuring that the model's output transforms predictably when its input undergoes a geometric transformation \cite{han20227gn}.

The core idea behind equivariant GNNs, particularly E(n)-equivariant GNNs (where E(n) is the Euclidean group in n dimensions), is to operate directly on 3D coordinates and vector features, ensuring that intermediate representations and final predictions respect the underlying symmetries of the physical system. This is achieved by designing message-passing functions that are themselves equivariant, often by using basis functions that transform correctly under rotations and translations \cite{satorras2021pzl}. For instance, models like E(n) Equivariant Graph Neural Networks \cite{satorras2021pzl} and GemNet \cite{klicpera20215fk} explicitly incorporate relative positional information and directional features, enabling them to accurately predict molecular properties or interatomic potentials \cite{batzner2021t07, reiser2022b08}. The expressive power of these models is significantly enhanced by their ability to encode geometric relationships, as demonstrated by theoretical analyses \cite{joshi20239d0}. Positional encodings, which are critical for standard GNNs to capture structural information beyond connectivity, are also adapted to be equivariant and stable in this context \cite{wang2022p2r}.

The development of geometric GNNs has revolutionized applications in drug discovery \cite{jiang2020gaq, li2021v1l}, materials design \cite{fung20212kw, fang2024p34}, and protein structure prediction \cite{xia2021s85}, where the precise spatial arrangement of atoms and molecules dictates their properties and interactions. They allow for data-efficient learning, as the built-in symmetries reduce the need for extensive data augmentation to cover all possible orientations. Recent advancements include using geometric GNNs to derive descriptor-free collective variables for molecular dynamics simulations \cite{zhang202483k} and exploring their application in learning equivariant representations of neural networks themselves \cite{kofinas2024t2b}. Physics-informed GNNs, which embed physical laws directly into the network architecture, further extend this concept for applications like water distribution systems \cite{ashraf202443e} and deformation prediction \cite{saleh2024d2a}.

However, geometric and equivariant GNNs are not without limitations. Their computational complexity can be higher due to the need to handle vector and tensor representations that transform correctly. The design of truly universal equivariant layers that can capture all relevant symmetries for arbitrary tasks remains an open challenge. Furthermore, while they excel at geometric tasks, their benefits might be less pronounced in purely topological or abstract graph problems. The question of whether high-degree representations are always necessary in equivariant GNNs is also being actively investigated, suggesting potential for more efficient designs \cite{cen2024md8}. Despite these challenges, the ability of equivariant GNNs to bridge the gap between abstract graph structures and concrete physical realities marks a significant step towards more physically consistent and powerful graph learning models \cite{shi2024g4z}.