\section{Introduction}
The ubiquitous nature of graph-structured data in diverse scientific and engineering domains, ranging from social networks and biological systems to urban infrastructure and recommender systems, has presented a persistent challenge for traditional machine learning paradigms \cite{wu20193b0, zhou20188n6, velickovic2023p4r, wu2022ptq}. Unlike Euclidean data, graphs inherently encode complex relational information, where the connections between entities are as significant as the entities themselves. Graph Neural Networks (GNNs) have emerged as a transformative paradigm, extending the success of deep learning to this non-Euclidean data landscape. By enabling models to learn representations directly from graph structures, GNNs have unlocked unprecedented capabilities for tasks such as node classification, link prediction, and graph classification, demonstrating their profound impact across numerous fields \cite{khemani2024i8r, wang2023zr0}.

The fundamental motivation behind the development of GNNs stems from the critical need to effectively process and leverage relational information. Traditional machine learning models, designed for independent and identically distributed (i.i.d.) data, often struggle to capture the intricate dependencies and structural patterns inherent in graphs. Early attempts to apply machine learning to graphs relied on hand-crafted features or graph kernel methods, which, while foundational, often lacked scalability and the ability to learn complex, hierarchical representations end-to-end \cite{garg2020z6o}. GNNs address this by iteratively aggregating information from a node's local neighborhood, effectively propagating and transforming features across the graph structure. This message-passing mechanism allows GNNs to learn rich, context-aware node and graph embeddings, which has fueled their rapid adoption and continuous evolution. However, this powerful paradigm also introduces unique challenges, such as limitations in expressive power, susceptibility to over-smoothing, and difficulties in handling heterophilous graphs, which necessitate ongoing research and innovation. This comprehensive literature review aims to consolidate the vast and rapidly expanding knowledge base surrounding GNNs, providing a structured understanding of their evolution, diverse methodologies, impactful applications, and future trajectory, while critically identifying existing research gaps and promising directions.

\subsection{The Rise of Graph Neural Networks}
The ascent of Graph Neural Networks marks a pivotal shift in machine learning, offering a principled approach to process data residing in non-Euclidean spaces \cite{wu20193b0, zhou20188n6}. Prior to GNNs, applying deep learning to graph-structured data was largely constrained by the need to flatten or linearize graph information, often leading to a loss of crucial topological context. GNNs overcome this by generalizing convolutional operations to arbitrary graph structures, allowing nodes to iteratively aggregate information from their neighbors, thereby learning representations that capture both node features and structural roles \cite{velickovic2023p4r}. This message-passing paradigm, initially inspired by spectral graph theory and later refined through spatial approaches, provided the foundational mechanism for GNNs to learn from relational data \cite{kipf2016semi, hamilton2017inductive}.

However, the early success of GNNs was accompanied by recognized limitations. A significant theoretical barrier was their inherent expressive power, often proven to be no more powerful than the 1-dimensional Weisfeiler-Lehman (1-WL) isomorphism test \cite{xu2018c8q, morris20185sd, garg2020z6o}. This meant that many GNN architectures struggled to distinguish between non-isomorphic graphs that the 1-WL test could not differentiate, limiting their ability to capture complex structural patterns like specific cycle sizes or graph diameters \cite{chen2020e6g, oono2019usb}. This limitation spurred an "arms race" in GNN research, driving the development of more expressive architectures. For instance, Path Neural Networks (PathNNs) \cite{michel2023hc4} explicitly leverage path information, with variants like `ËœAP` demonstrating the ability to distinguish graphs that are even 3-WL indistinguishable, thereby significantly surpassing the 1-WL bottleneck. Similarly, non-convolutional GNNs, such as the Random Walk with Unifying Memory (RUM) network \cite{wang2024oi8}, have been introduced to jointly address limited expressiveness, over-smoothing, and over-squashing by entirely eschewing convolution operators in favor of random walk trajectories and recurrent neural networks. These advancements highlight a critical evolutionary trend: moving beyond local, fixed-neighborhood aggregation to incorporate more global, complex, and memory-dependent structural information, as also seen in the exploration of fractional calculus in GNNs to capture non-local dependencies and memory effects \cite{kang2024fsk}.

\subsection{Importance of Graph-Structured Data}
The intrinsic importance of graph-structured data lies in its ability to naturally represent complex systems where entities and their relationships are paramount. This relational paradigm is pervasive across virtually every scientific and industrial domain, making GNNs indispensable for unlocking insights from these intricate datasets. In social sciences, GNNs model interactions in social networks for tasks like recommendation systems \cite{gao2022f3h, wu2020dc8, fan2019k6u, sharma2022liz}, where understanding user-item relationships and social influence is crucial for personalized content delivery \cite{ying20189jc, wang2019vol}. The sheer scale and dynamic nature of these graphs necessitate efficient and scalable GNN designs \cite{chen2024gbe, vasimuddin2021x7c}.

In molecular science and drug discovery, molecules are inherently graphs, with atoms as nodes and chemical bonds as edges. GNNs excel at learning molecular properties, predicting drug-target interactions, and accelerating materials design by capturing complex structural and chemical information \cite{jiang2020gaq, reiser2022b08, klicpera20215fk, batzner2021t07, fung20212kw, xia2021s85, li2021v1l, xia2023bpu, wander2024nnn, carlo2024a3g, vinh20243q3, smith2024q8n, fang2024p34, zhang202483k, li2024gue, gnanabaskaran20245dg, yao2024pyk, fang2024zd6}. Similarly, in neuroscience, brain connectomes are modeled as graphs to understand brain disorders and functions \cite{bessadok2021bfy, cui2022mjr, cui2022pap, zhao2022fvg, mohammadi202476q, luo2024h2k, abuhantash202458c, abadal2024w7e}. The ability of GNNs to model non-local dependencies and memory effects, as explored by fractional-order GNNs \cite{kang2024fsk}, is particularly relevant for capturing the complex, often non-Markovian, dynamics of biological systems.

Furthermore, GNNs have found critical applications in urban computing for traffic forecasting \cite{li2020fil, jin2023e18, zhou2024t2r}, cybersecurity for anomaly detection and threat intelligence \cite{mitra2024x43, bilot20234ui, shen2021sbk, hin2022g19, nguyen2021g12, li2024r82}, and even computer vision for tasks involving irregular data like point clouds and scene graphs \cite{chen2022mmu}. The challenges GNNs address are fundamental: processing non-Euclidean data, handling varying neighborhood sizes, and learning complex, often long-range, dependencies. For instance, the issue of heterophily, where connected nodes have dissimilar features, is a common real-world phenomenon that traditional GNNs struggle with due to their homophily assumption \cite{ma2021sim, zhu2020c3j}. Solutions like GloGNN \cite{li2022315} explicitly address this by learning global node correlations, demonstrating that effective GNN design must critically evaluate and adapt to the underlying graph properties. The pervasive nature of graph-structured data, coupled with the unique capabilities of GNNs to model these relationships, underscores their transformative potential across scientific and industrial landscapes.

\subsection{Scope and Structure of the Review}
This comprehensive literature review aims to provide a structured and critical understanding of the Graph Neural Network landscape, consolidating fragmented knowledge, identifying key research gaps, and charting future directions. Our exploration begins by tracing the evolution of GNN architectures, from early spectral and spatial methods to more advanced designs that tackle challenges like limited expressiveness, over-smoothing, and over-squashing \cite{rusch2023xev, cai2020k4b, chen2019s47, oono2019usb, peng2024t2s}. We will critically examine how innovative approaches, such as Path Neural Networks \cite{michel2023hc4} and non-convolutional models like RUM \cite{wang2024oi8}, have pushed the boundaries of expressive power, enabling GNNs to capture more intricate structural patterns than their 1-WL-limited predecessors.

A significant portion of this review will delve into the methodological advancements, including techniques for handling graph heterophily \cite{li2022315, ma2021sim, zhu2020c3j, zheng2022qxr}, enhancing robustness against adversarial attacks \cite{zhang2020b0m, xu2019l8n, zgner2019bbi, zhang2020jrt, gosch20237yi, geisler2021dcq, mujkanovic20238fi, dai2022xze, dai2023tuj}, and improving the explainability of GNN predictions \cite{ying2019rza, yuan20208v3, yuan2020fnk, vu2020zkj, lucic2021p70, zhang2021wgf, agarwal2022xfp, cui2022pap, chen2024woq, bui2024zy9, luo2024euy, wang2024j6z}. For instance, the challenge of explainability, often addressed by identifying important nodes or edges, is critically re-evaluated by methods like SubgraphX \cite{yuan2021pgd}, which directly identifies intuitive subgraphs, highlighting a shift towards more human-intelligible explanations. We will also analyze the critical role of evaluation methodologies, as exemplified by studies that expose pitfalls in current link prediction benchmarks and propose more realistic settings with hard negative sampling \cite{li2023o4c}. This critical analysis will extend to identifying why certain limitations persist, often due to theoretical barriers (e.g., the inherent trade-off between local aggregation and global information capture) or practical constraints (e.g., scalability for extremely large graphs). The review will then explore the broad spectrum of applications, from recommender systems \cite{gao2022f3h} and computer vision \cite{chen2022mmu} to materials science and cybersecurity, before concluding with a discussion of emerging trends, open challenges, and promising future research directions.