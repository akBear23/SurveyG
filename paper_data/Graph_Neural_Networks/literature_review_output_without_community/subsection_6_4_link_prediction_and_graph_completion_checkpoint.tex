\subsection{Link Prediction and Graph Completion}

Link prediction, a cornerstone task in graph analysis, involves inferring missing connections or predicting future interactions within a graph. Its significance spans diverse applications, from completing knowledge graphs and discovering drug interactions to analyzing social networks and powering recommender systems. Historically, approaches relied on predefined heuristics (e.g., common neighbors, Adamic-Adar) or matrix factorization methods. However, these methods often struggle to capture the complex, non-linear structural patterns inherent in real-world graphs, motivating the advent of Graph Neural Networks (GNNs) in this domain.

A foundational shift occurred with the introduction of the SEAL (Subgraph Embedding for Link prediction) framework by \cite{zhang2018kdl}. This work demonstrated GNNs' superior capability over traditional methods by learning general graph structure features directly from local enclosing subgraphs. Crucially, \cite{zhang2018kdl} provided a novel theoretical justification through the $\beta$-decaying heuristic theory, proving that high-order heuristics (like Katz index or rooted PageRank) can be accurately approximated from small $h$-hop enclosing subgraphs. This insight resolved the perceived need for global network information, enabling GNNs to effectively capture complex structural patterns for graph completion by integrating structural node labels, latent embeddings, and explicit attributes within these localized contexts.

While SEAL showcased the power of subgraph-based GNNs, many early GNNs for link prediction adopted a simpler paradigm: learning node embeddings via message passing and then using a simple decoder (e.g., dot product or MLP) on concatenated node embeddings to predict link existence. However, these basic GNNs often struggle to capture the rich structural information (e.g., neighborhood overlap, common neighbors, triangle counts) that is crucial for accurate link prediction, sometimes performing worse than simple heuristic methods \cite{yun2022s4i}. This limitation stems from their inherent architectural constraints, often equivalent to the 1-Weisfeiler-Leman test, which limits their ability to distinguish between certain non-isomorphic graphs and count specific graph motifs.

To address this expressiveness bottleneck and enhance GNNs' ability to leverage structural cues, models like Neo-GNNs \cite{yun2022s4i} were proposed. Neo-GNNs explicitly learn useful structural features from the adjacency matrix and estimate overlapped neighborhoods, effectively generalizing neighborhood overlap-based heuristic methods and handling multi-hop structural patterns. Building on the success of subgraph-based GNNs like SEAL, further advancements aimed to combine their expressivity with the efficiency of full-graph GNNs. \cite{chamberlain2022fym} introduced ELPH (Efficient Link Prediction with Hashing) and BUDDY, which approximate key subgraph components (like distance-based node labels) using "subgraph sketching" techniques (e.g., HyperLogLog, MinHashing). This allows ELPH to achieve the expressive power of subgraph GNNs, capable of counting triangles and distinguishing automorphic nodes, but within a full-graph message passing framework, leading to significantly faster and more scalable link prediction without explicit subgraph extraction. BUDDY further enhances scalability by precomputing these sketches, enabling application to massive datasets that exceed GPU memory.

A particularly critical application of link prediction is Knowledge Graph Completion (KGC), where the goal is to infer missing facts (relations between entities) in multi-relational graphs. GNNs have proven highly effective for KGC, as extensively surveyed by \cite{ye20226hn}. Specialized GNN architectures, such as Relational Graph Convolutional Networks (R-GCNs) and Compositional GNNs (CompGCNs), have been developed to handle the diverse relation types and heterogeneous nature of knowledge graphs, learning embeddings that capture both entity and relation semantics for accurate link prediction.

As real-world graphs are inherently dynamic, the need for GNNs to handle temporal information for link prediction is paramount. For instance, in sequential recommendation, the task of predicting the next item a user will interact with can be framed as a dynamic link prediction problem. \cite{zhang20212ke} proposed Dynamic Graph Neural Network for Sequential Recommendation (DGSR), which models user sequences and dynamic collaborative signals within a unified framework, converting next-item prediction into a link prediction task in an evolving graph. For a broader understanding of how GNNs are adapted for temporal graphs, including temporal link prediction, readers can refer to the comprehensive survey by \cite{longa202399q}.

The reliability of link prediction models is also a significant concern, especially in high-stakes applications. This necessitates rigorous evaluation and uncertainty quantification. \cite{li2023o4c} critically evaluated existing benchmarking practices for GNN-based link prediction, exposing common pitfalls such as underreported baseline performance, inconsistent data splits, and the use of "easy" negative samples that do not reflect real-world challenges. They proposed a standardized benchmarking methodology and introduced the Heuristic Related Sampling Technique (HeaRT) to generate more challenging and realistic negative samples, thereby fostering more robust and reproducible evaluations. Furthermore, to provide statistically guaranteed uncertainty estimates for GNN-based link predictions, \cite{zhao2024g5p} introduced conformalized link prediction, a distribution-free and model-agnostic approach built upon conformal prediction. This method addresses the challenges of applying conformal prediction to dependent graph data and improves efficiency by aligning graph structure with a power-law distribution, ensuring more reliable predictions.

In summary, GNNs have profoundly transformed link prediction and graph completion. The journey began with foundational models like SEAL \cite{zhang2018kdl} demonstrating superiority over traditional heuristics by learning from local subgraphs. Subsequent research focused on enhancing GNNs' ability to capture crucial structural information \cite{yun2022s4i} and developing efficient, expressive subgraph-aware models that avoid explicit subgraph construction \cite{chamberlain2022fym}. The field has also seen significant advancements in specialized applications like Knowledge Graph Completion \cite{ye20226hn} and dynamic link prediction \cite{zhang20212ke}. Concurrently, there has been a critical emphasis on rigorous benchmarking \cite{li2023o4c} and ensuring the trustworthiness of predictions through uncertainty quantification \cite{zhao2024g5p}. Future research will likely continue to push the boundaries of scalability, dynamic modeling, and the integration of multi-modal information to build truly intelligent and reliable graph completion systems.