\subsection{Addressing Structural Heterogeneity and Disparity}

Real-world graphs rarely conform to a single, uniform structural pattern; instead, they often exhibit a complex interplay of mixed homophilic (nodes with similar attributes connect) and heterophilic (nodes with dissimilar attributes connect) connections. This inherent structural diversity, rigorously termed 'structural disparity' \cite{mao202313j}, poses a pervasive challenge for Graph Neural Networks (GNNs). Traditional "one-size-fits-all" aggregation strategies, which typically assume homophily and perform low-pass filtering by averaging neighbor features, often lead to suboptimal performance and significant disparities across different node subgroups \cite{zheng2022qxr}.

The challenge of heterophily has been a long-standing concern in GNN research. Early approaches sought to mitigate the detrimental effects of aggregating dissimilar neighbor information. A common strategy involved explicitly separating a node's own features (ego-features) from its neighbors' aggregated features (neighbor-features) before combining them, allowing the model to weigh their importance differently. Other methods expanded the receptive field to capture higher-order or multi-hop neighbors, recognizing that homophilous nodes might be structurally distant in heterophilic graphs \cite{zheng2022qxr}. For instance, models like MixHop or GPR-GNN implicitly or explicitly aggregated information from multi-hop neighborhoods to capture both local and broader structural patterns. The theoretical underpinnings for these diverse aggregation strategies were later unified by frameworks such as that proposed by \cite{zhu2021zc3}, which interpreted various GNN propagation mechanisms as optimal solutions to an objective function incorporating flexible graph convolutional kernels. This framework demonstrated how GNNs could be designed with specific low-pass, high-pass, or all-pass filtering capabilities, providing a principled way to understand and develop models that could adapt to different frequency components of graph signals.

Despite these advancements, a comprehensive understanding and systematic solution for graphs exhibiting *mixed* homophily and heterophily within a single structure remained elusive. The fundamental limitations of uniform aggregation were rigorously diagnosed by \cite{mao202313j}. This seminal work formally introduced "structural disparity," highlighting the pervasive existence of mixed patterns and demonstrating that GNNs suffer from significant "performance disparity" on minority structural patterns. Through extensive diagnostic analyses and a novel theoretical framework, \cite{mao202313j} provided compelling evidence that a single, globally applied aggregation strategy is inherently flawed for such complex structural mixtures. This research underscored the critical need for GNNs that can dynamically adapt their aggregation behavior based on the local structural context of each node.

Building directly upon these diagnostic insights, recent innovations have focused on developing adaptive filtering mechanisms that move beyond global assumptions. \cite{luan202272y} revisited heterophily from the perspective of post-aggregation node similarity and introduced new, more informative homophily metrics. Based on these insights, they proposed the Adaptive Channel Mixing (ACM) framework, which augments baseline GNNs by adaptively exploiting three distinct channels—aggregation (low-pass), diversification (high-pass, implemented as $I - \hat{A}$), and identity—node-wisely and locally in each layer. This allows GNNs to extract richer localized information tailored to diverse node heterophily situations, demonstrating significant performance gains on heterophilic datasets without incurring substantial computational overhead.

Further advancing this adaptive paradigm, \cite{han2024rkj} proposed Node-wise Filtering in Graph Neural Networks via a Mixture of Experts (NODE-MOE). This framework represents a significant leap towards truly localized information processing by dynamically applying different aggregation strategies to individual nodes based on their local structural context. NODE-MOE employs a sophisticated gating mechanism that learns to estimate a node's structural pattern from contextual features, subsequently selecting and applying an appropriate "expert" GNN filter. These experts are initialized with diverse filter types, such as low-pass (for homophilic patterns), high-pass (for heterophilic patterns), and constant filters, allowing the model to adaptively capture relevant information for each node. This dynamic, node-wise approach significantly enhances GNN robustness and accuracy across diverse structural patterns within a single graph, effectively moving beyond the limitations of uniform aggregation. Concurrently, other approaches like GloGNN \cite{li2022315} tackle heterophily by learning a signed coefficient matrix for global aggregation, implicitly combining low-pass and high-pass filtering across all nodes, and achieving linear time complexity for scalability.

The progression from early, often heuristic-driven, attempts to mitigate heterophily to the rigorous diagnosis of structural disparity \cite{mao202313j}, and finally to sophisticated adaptive, node-wise filtering mechanisms like ACM \cite{luan202272y} and NODE-MOE \cite{han2024rkj}, underscores a critical evolution in GNN research. While these adaptive methods offer powerful solutions, challenges remain. Future research could focus on developing more interpretable gating mechanisms for mixture-of-experts models, exploring the computational overhead of such adaptive approaches on web-scale graphs, or designing novel expert GNN architectures that can capture even finer-grained structural nuances beyond simple low-pass and high-pass filtering. Furthermore, integrating these adaptive filtering techniques with mechanisms for handling dynamic graph structures or multi-modal node features could lead to even more robust and versatile GNNs capable of addressing the multifaceted structural complexities prevalent in real-world networks \cite{zheng2022qxr}.