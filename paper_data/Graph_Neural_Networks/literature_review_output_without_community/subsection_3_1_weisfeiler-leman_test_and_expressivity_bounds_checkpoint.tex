\subsection{Weisfeiler-Leman Test and Expressivity Bounds}

The Weisfeiler-Leman (WL) test serves as a cornerstone theoretical tool for rigorously characterizing the expressive power of Graph Neural Networks (GNNs). Specifically, its 1-dimensional variant (1-WL), often referred to as the color refinement algorithm, provides a fundamental framework for understanding the inherent limitations of standard Message Passing Neural Networks (MPNNs) in distinguishing between non-isomorphic graphs \cite{morris20185sd, xu2019powerful, jegelka20222lq}. The 1-WL test operates through an iterative node color refinement process: nodes are initially assigned colors (e.g., based on their features or a constant), and in each subsequent step, a node's color is updated based on its current color and the multiset of colors of its immediate neighbors. This process continues until no node's color changes, indicating a fixed point, or until a maximum number of iterations is reached. If two graphs cannot be distinguished by their final color distributions, they are considered 1-WL equivalent.

A foundational result in GNN theory established that standard MPNNs, which aggregate information from local neighborhoods in a permutation-invariant manner, are provably no more powerful than the 1-WL test in distinguishing non-isomorphic graphs \cite{morris20185sd, xu2019powerful, dinverno2024vkw, feng2022914}. This implies that if the 1-WL test fails to differentiate between two graphs, a standard MPNN, such as a Graph Convolutional Network (GCN) or GraphSAGE, will also fail to distinguish them. The Graph Isomorphism Network (GIN) was specifically designed to achieve the maximum discriminative power of the 1-WL test by employing an injective aggregation function \cite{xu2019powerful, jegelka20222lq}. This equivalence to the 1-WL test creates a significant expressivity bottleneck, limiting GNNs' ability to capture complex structural properties and differentiate between certain non-isomorphic graphs. For instance, the 1-WL test, and consequently standard MPNNs, cannot distinguish between non-isomorphic regular graphs (e.g., certain strongly regular graphs) or even simple graphs like cycles of the same length but different structures if their local neighborhoods appear identical \cite{jegelka20222lq}.

The implications of this theoretical bound are profound, as many real-world graph problems demand finer distinctions than the 1-WL test can provide. The inability to distinguish between structurally different graphs poses a challenge for tasks such as molecular property prediction, where subtle structural variations can lead to drastically different chemical properties. More broadly, a wide range of GNNs, including popular architectures like GCN, GAT, and GIN, have been shown to be incapable of computing fundamental graph properties such as girth, circumference, diameter, radius, or counting k-cliques \cite{garg2020z6o, jegelka20222lq}. This limitation arises because these properties often require global information or the ability to distinguish between local structures that appear identical to a 1-WL perspective.

This foundational understanding, developed through early theoretical work, has motivated extensive research into developing more powerful GNN architectures capable of surpassing these limitations. The 1-WL test is merely the first step in a hierarchy of increasingly powerful Weisfeiler-Leman tests (k-WL tests), where k-WL operates on k-tuples of nodes rather than individual nodes, allowing for the detection of more intricate structural differences \cite{morris20185sd, jegelka20222lq}. This hierarchy provides a theoretical roadmap for designing GNNs with enhanced expressive power. For example, while standard MPNNs are bounded by 1-WL, extensions like K-hop message passing GNNs, which aggregate information from neighbors up to K hops away, have been shown to be strictly more powerful than 1-WL, capable of distinguishing almost all regular graphs with a modest K. However, even K-hop message passing is bounded by the 3-WL test, failing on some simple regular graphs \cite{feng20225sa}. This highlights a chronological progression in understanding the limitations and exploring methods to incrementally enhance GNN expressivity.

The ongoing challenge of GNN expressivity is continually addressed by the research community, not only through novel architectural designs but also through rigorous evaluation. The theoretical limits of GNNs underscore the need for benchmarks that include datasets challenging enough to differentiate the expressive power of various GNN architectures. For instance, comprehensive benchmarking efforts, such as those by \cite{dwivedi20239ab}, implicitly acknowledge the importance of GNN expressivity by highlighting that traditional, small datasets often fail to differentiate the capabilities of various GNN models. These benchmarks are designed to include datasets that test specific theoretical graph properties, thereby enabling researchers to evaluate how well GNNs can discriminate between complex graph structures.

In conclusion, the 1-WL test remains a critical theoretical lens through which the expressive power of GNNs is understood and evaluated. The inherent limitations it reveals for standard MPNNs have spurred continuous innovation in GNN architecture design, driving the quest for models that can capture increasingly intricate graph properties and distinctions. This pursuit is consistently validated and guided by robust theoretical analysis and rigorous benchmarking efforts, pushing the boundaries of what GNNs can model and understand about complex graph structures.