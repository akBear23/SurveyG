\subsection*{Reporting Guidelines for AI Interventions (CONSORT-AI, SPIRIT-AI)}

The rapid proliferation of artificial intelligence (AI) interventions in healthcare necessitates robust and transparent reporting standards to ensure the rigor, reproducibility, and critical appraisal of clinical trials. Without such guidelines, the unique complexities of AI models, their development, evaluation, and interaction with human users can lead to opaque research, hindering trust and safe clinical translation. To address this, specialized reporting guidelines such as CONSORT-AI and SPIRIT-AI have been developed to standardize the documentation of AI-driven medical research \cite{ibrahim2021rcn}.

The Consolidated Standards of Reporting Trials-Artificial Intelligence (CONSORT-AI) extension and its companion guideline for trial protocols, Standard Protocol Items: Recommendations for Interventional Trials-Artificial Intelligence (SPIRIT-AI), represent a significant step towards enhancing transparency in AI clinical trials \cite{chan2020egf, rivera2020sg1}. Developed through a rigorous multi-stakeholder consensus process involving literature reviews, expert consultations, Delphi surveys, and consensus meetings, these guidelines aim to provide a minimum set of reporting items essential for AI interventions \cite{chan2020egf, rivera2020sg1}. CONSORT-AI, for instance, adds 14 new items to the core CONSORT 2010 statement, recommending detailed descriptions of the AI intervention, including instructions for use, required skills, the clinical setting, handling of inputs and outputs, the nature of human-AI interaction, and an analysis of error cases \cite{chan2020egf}. Similarly, SPIRIT-AI extends the SPIRIT 2013 statement with 15 new items, ensuring that the design and methodology of planned AI trials are comprehensively documented from the outset \cite{rivera2020sg1}. These guidelines are crucial for assisting editors, peer reviewers, and the broader scientific community in understanding, interpreting, and critically appraising the quality and potential biases of AI clinical trials \cite{parums2021k6f}.

The development of these AI-specific guidelines was spurred by empirical evidence highlighting significant deficiencies in the reporting and methodological quality of early AI clinical trials. Systematic reviews conducted around the time of their publication revealed pervasive issues; for example, \cite{zhou2021vqt} found that a substantial majority (72.3\%) of randomized controlled trials evaluating AI prediction tools did not reference the CONSORT statement, indicating a widespread lack of adherence to established reporting standards. This review also identified frequent methodological weaknesses, such as high risks of bias in blinding and outcome assessment, underscoring the urgent need for more structured reporting to improve research quality and clinical impact \cite{zhou2021vqt}. Beyond CONSORT-AI and SPIRIT-AI, other specialized guidelines like DECIDE-AI have emerged to address specific aspects, such as the early-stage clinical evaluation of AI-driven decision support systems, providing a checklist of minimal reporting items to facilitate appraisal and replicability in developmental studies \cite{vasey2022yhn}. The collective importance of these guidelines in promoting awareness of essential content for AI studies in healthcare has been further emphasized by comprehensive reviews of study reporting guidelines \cite{shelmerdine2021xi6}.

Despite their foundational role in standardizing reporting practices and enhancing the transparency of AI clinical trials, these guidelines have acknowledged limitations, particularly in fully capturing the complex nuances of real-world implementation outcomes. While they provide structured recommendations for documenting model development and evaluation, a critical gap remains in systematically assessing how well AI interventions integrate into clinical workflows and achieve sustained adoption. A recent systematic review by \cite{sande20248hm} empirically demonstrated this oversight, revealing that a significant proportion of AI clinical trials, even those adhering to existing reporting guidelines, largely neglect to report crucial implementation outcomes such as acceptability, appropriateness, adoption, and sustainability. This finding suggests that current guidelines, while excellent for technical and clinical efficacy reporting, may not adequately prompt researchers to evaluate the practical success of AI integration into healthcare systems \cite{sande20248hm}. This limitation resonates with broader calls to bridge the "chasm from model performance to clinical impact" by improving the implementation and evaluation of AI, advocating for a shift towards implementation science and real-world evidence \cite{marwaha2022gj3}.

In conclusion, CONSORT-AI and SPIRIT-AI, alongside other specialized guidelines like DECIDE-AI, play a crucial role in standardizing the reporting of AI clinical trials, thereby enhancing their transparency, reproducibility, and critical appraisal. By providing structured recommendations for documenting model development, evaluation, and human-AI interaction, they facilitate robust regulatory review and build trust in AI-driven medical research. However, their current scope highlights an ongoing challenge: the need for continuous evolution to encompass a more comprehensive evaluation of AI's real-world implementation, adoption, and sustained clinical impact. Future iterations and complementary guidelines will likely need to integrate implementation science frameworks more explicitly to ensure that AI innovations not only demonstrate technical prowess but also deliver tangible and sustainable value at the bedside.