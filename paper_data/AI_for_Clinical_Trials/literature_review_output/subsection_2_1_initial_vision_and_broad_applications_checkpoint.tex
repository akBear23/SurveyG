\subsection*{Initial Vision and Broad Applications}

Emerging from the recognized inefficiencies and complexities inherent in traditional drug development, the earliest literature on Artificial Intelligence (AI) in clinical trials articulated a broad, transformative vision. These foundational works, predominantly systematic and scoping reviews, sought to map the extensive potential of AI across the entire clinical trial lifecycle, from initial drug discovery to post-market surveillance. They established the initial conceptual framework, highlighting vast opportunities for efficiency gains, cost reductions, and improved outcomes, thereby defining the scope and setting the research agenda for subsequent, more targeted investigations. This period was characterized by an aspirational outlook, envisioning AI as a powerful tool to address long-standing bottlenecks in drug development \cite{Weng2017, agrawal2018svf}.

A foundational scoping review by \cite{Weng2017} provided an early understanding of AI's nascent presence and identified initial opportunities across various stages of clinical trials. This work was crucial in recognizing AI's potential, particularly in areas like accelerating drug discovery and optimizing trial design. Expanding on this broad perspective, \cite{agrawal2018svf} articulated a more comprehensive vision for AI across the entire drug discovery and development pipeline. This seminal review conceptually laid out how AI could accelerate various stages, from initial compound identification and preclinical research (further explored in Section 5.3) to optimizing clinical study designs (detailed in Section 3.2), improving patient selection (discussed in Section 3.1), and streamlining the analysis of trial data. Similarly, \cite{kundavaram2018ii1} explored the potential of predictive analytics and generative AI, even at this early stage, to optimize cancer outcomes through early identification, personalized therapy, and dynamic patient monitoring, showcasing an early recognition of AI's role in precision medicine within trials. These initial conceptualizations, while highly optimistic, largely reflected an "embryonic stage" of AI application, characterized by aspirational mapping of potential rather than empirically validated solutions \cite{mak2021pi8}.

As this broad vision began to solidify, subsequent reviews started to elaborate on the *types* of applications, moving beyond general statements to outline conceptual mechanisms. \cite{Weng2019} further detailed the opportunities for integrating AI into clinical trials, emphasizing its potential for significant efficiency gains and cost reductions through automation and enhanced predictive capabilities. For instance, in the upstream drug discovery phase, AI was envisioned to revolutionize target identification, lead optimization, and virtual screening of compound libraries, promising to significantly reduce the time and cost associated with traditional methods \cite{Weng2019}. Within trial operations, AI's role in optimizing clinical study designs was highlighted, including the conceptual use of predictive analytics for more accurate sample size estimation, patient stratification, and the facilitation of adaptive trial designs \cite{Weng2019}. A particularly challenging bottleneck, patient recruitment, also saw early dedicated attention, with \cite{WANG2019} providing a focused review on AI applications for this stage, detailing how techniques such as Natural Language Processing (NLP) and machine learning (ML) could conceptually be leveraged to identify eligible patients more effectively from electronic health records (EHRs), thereby accelerating enrollment and reducing trial timelines.

Synthesizing this evolving understanding, \cite{CHEN2020} offered a comprehensive overview of AI's role across the entire clinical trial lifecycle, from initial design and patient selection to data analysis and post-market surveillance. This review solidified the initial conceptual framework, underscoring AI's potential to improve trial design through predictive modeling, enhance patient matching, streamline data management, and derive deeper insights from complex datasets. These foundational reviews, predominantly employing literature synthesis, were instrumental in mapping the intellectual landscape. They collectively presented a compelling narrative of AI's potential to transform clinical research by enhancing efficiency, reducing costs, and ultimately accelerating the delivery of new therapies to patients.

However, this initial, largely optimistic vision often glossed over the formidable practical and methodological hurdles that would soon become central to the field. While these early papers successfully defined the problem space and proposed a wide array of potential solutions, they frequently lacked the critical discussion of implementation challenges, data quality issues, or the complexities of rigorous evaluation. The recognition of these limitations began to emerge concurrently with the broad conceptualization. For example, the need for specialized reporting guidelines for AI interventions, such as CONSORT-AI and SPIRIT-AI, developed around this period \cite{chan2020egf, shelmerdine2021xi6}, implicitly acknowledged that traditional reporting standards were insufficient for the unique characteristics of AI studies. Furthermore, meta-research from this era highlighted significant methodological weaknesses in AI diagnostic accuracy studies, noting "incomplete uptake" of quality assessment tools and "inconsistent reporting," particularly concerning patient selection and risk of bias \cite{jayakumar2022sav}. These insights underscore that while the initial vision was expansive and crucial for galvanizing interest, it was simultaneously an "embryonic stage" where the practicalities of robust implementation and evaluation were still nascent, setting the stage for the detailed exploration of bottlenecks in Section 2.2. The analytical contribution of this early literature was primarily in conceptualizing the problem and proposing a wide array of potential solutions, thereby serving as crucial starting points that shaped the subsequent trajectory of the field.